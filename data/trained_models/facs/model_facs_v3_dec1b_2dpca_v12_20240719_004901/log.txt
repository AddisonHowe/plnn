Args:
Namespace(name='model_facs_v3_dec1b_2dpca_v12', outdir='out/model_training/model_facs_v3_dec1b_2dpca_v12', training_data='data/training_data/facs_v3/pca/dec1_fitonsubset/transition1_subset_epi_tr_ce_an_pc12/training', validation_data='data/training_data/facs_v3/pca/dec1_fitonsubset/transition1_subset_epi_tr_ce_an_pc12/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=10, batch_size=50, patience=200, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, quadratic_a=1.0, quadratic_b=1.0, ndims=2, nparams=2, nsigs=2, ncells=800, ncells_sample=800, model_do_sample=False, dt=0.005, dt_schedule='stepped', dt_schedule_bounds=[50, 500, 1000], dt_schedule_scales=[0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', kernel='multiscale', bw_range=[0.2, 0.5, 0.9, 1.1, 1.3, 1.5, 2.0], optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 724886934

Training model...

Saving initial model state to: out/model_training/model_facs_v3_dec1b_2dpca_v12_20240719_004901/states/model_facs_v3_dec1b_2dpca_v12_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.3511627543798914		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3511627543798914 | validation: 1.2613996429646948]
	TIME [epoch: 28.8 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12_20240719_004901/states/model_facs_v3_dec1b_2dpca_v12_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.2702570304138943		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2702570304138943 | validation: 1.105337299930716]
	TIME [epoch: 9.95 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12_20240719_004901/states/model_facs_v3_dec1b_2dpca_v12_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.2118623181373565		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2118623181373565 | validation: 1.069052463090354]
	TIME [epoch: 9.97 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12_20240719_004901/states/model_facs_v3_dec1b_2dpca_v12_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.1603089741076038		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1603089741076038 | validation: 1.0081281781137446]
	TIME [epoch: 9.98 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12_20240719_004901/states/model_facs_v3_dec1b_2dpca_v12_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.0964572509224197		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0964572509224197 | validation: 0.9259525039566651]
	TIME [epoch: 9.97 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12_20240719_004901/states/model_facs_v3_dec1b_2dpca_v12_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.046346052800102		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.046346052800102 | validation: 0.8462207342443143]
	TIME [epoch: 9.93 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12_20240719_004901/states/model_facs_v3_dec1b_2dpca_v12_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.9682375487155456		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9682375487155456 | validation: 0.8020775641578464]
	TIME [epoch: 9.99 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12_20240719_004901/states/model_facs_v3_dec1b_2dpca_v12_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.9129436716178626		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9129436716178626 | validation: 0.7923010923191371]
	TIME [epoch: 9.97 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12_20240719_004901/states/model_facs_v3_dec1b_2dpca_v12_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.9035975984559386		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9035975984559386 | validation: 0.7228469574157166]
	TIME [epoch: 9.99 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12_20240719_004901/states/model_facs_v3_dec1b_2dpca_v12_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.7968766082808733		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7968766082808733 | validation: 0.7320660326979889]
	TIME [epoch: 9.97 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.702258317555479		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.702258317555479 | validation: 0.6433474467624419]
	TIME [epoch: 9.98 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12_20240719_004901/states/model_facs_v3_dec1b_2dpca_v12_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.7843530185496714		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7843530185496714 | validation: 0.6583575114281817]
	TIME [epoch: 9.92 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.6813575176467405		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6813575176467405 | validation: 0.596994607074885]
	TIME [epoch: 9.94 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12_20240719_004901/states/model_facs_v3_dec1b_2dpca_v12_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5863631462216995		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5863631462216995 | validation: 0.5481195917205804]
	TIME [epoch: 9.98 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12_20240719_004901/states/model_facs_v3_dec1b_2dpca_v12_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5863423083343151		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5863423083343151 | validation: 0.5770225614542516]
	TIME [epoch: 9.99 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5682673760431042		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5682673760431042 | validation: 0.46091341324711915]
	TIME [epoch: 9.99 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12_20240719_004901/states/model_facs_v3_dec1b_2dpca_v12_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5962532684663815		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5962532684663815 | validation: 0.523263417423233]
	TIME [epoch: 9.99 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.49141932621432544		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.49141932621432544 | validation: 0.41988344640853326]
	TIME [epoch: 9.99 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12_20240719_004901/states/model_facs_v3_dec1b_2dpca_v12_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4681948233939235		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4681948233939235 | validation: 0.40412345415499795]
	TIME [epoch: 9.97 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12_20240719_004901/states/model_facs_v3_dec1b_2dpca_v12_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4152958308605666		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4152958308605666 | validation: 0.3891846383324026]
	TIME [epoch: 9.97 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12_20240719_004901/states/model_facs_v3_dec1b_2dpca_v12_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.49493637317793016		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.49493637317793016 | validation: 0.4162797090570488]
	TIME [epoch: 9.94 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4481517270393895		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4481517270393895 | validation: 0.36459866038771854]
	TIME [epoch: 9.93 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12_20240719_004901/states/model_facs_v3_dec1b_2dpca_v12_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4372804531172063		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4372804531172063 | validation: 0.35194133066531696]
	TIME [epoch: 10.2 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12_20240719_004901/states/model_facs_v3_dec1b_2dpca_v12_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.39413588530979543		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.39413588530979543 | validation: 0.3471954854872151]
	TIME [epoch: 9.95 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12_20240719_004901/states/model_facs_v3_dec1b_2dpca_v12_24.pth
	Model improved!!!
EPOCH 25/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3926267340667306		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3926267340667306 | validation: 0.3547388148296708]
	TIME [epoch: 9.94 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.42600198411573104		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.42600198411573104 | validation: 0.3945403315752172]
	TIME [epoch: 9.95 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.39114957967997405		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.39114957967997405 | validation: 0.33739270677940636]
	TIME [epoch: 9.95 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12_20240719_004901/states/model_facs_v3_dec1b_2dpca_v12_27.pth
	Model improved!!!
EPOCH 28/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3904291076756849		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3904291076756849 | validation: 0.31573352579027864]
	TIME [epoch: 9.95 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12_20240719_004901/states/model_facs_v3_dec1b_2dpca_v12_28.pth
	Model improved!!!
EPOCH 29/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.43253404987658683		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.43253404987658683 | validation: 0.3284831536278209]
	TIME [epoch: 9.95 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3744786644856844		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3744786644856844 | validation: 0.3403341110965539]
	TIME [epoch: 9.94 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.37265778647537395		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.37265778647537395 | validation: 0.31323189542149077]
	TIME [epoch: 9.94 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12_20240719_004901/states/model_facs_v3_dec1b_2dpca_v12_31.pth
	Model improved!!!
EPOCH 32/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3913943759554363		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3913943759554363 | validation: 0.31266129554436184]
	TIME [epoch: 9.97 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12_20240719_004901/states/model_facs_v3_dec1b_2dpca_v12_32.pth
	Model improved!!!
EPOCH 33/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.36028975127629886		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.36028975127629886 | validation: 0.3183572528363824]
	TIME [epoch: 9.99 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3819237418575144		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3819237418575144 | validation: 0.3026207945041955]
	TIME [epoch: 10 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12_20240719_004901/states/model_facs_v3_dec1b_2dpca_v12_34.pth
	Model improved!!!
EPOCH 35/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4000353064949107		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4000353064949107 | validation: 0.3262706384982924]
	TIME [epoch: 9.99 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3502980052096869		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3502980052096869 | validation: 0.29051997688375436]
	TIME [epoch: 9.99 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12_20240719_004901/states/model_facs_v3_dec1b_2dpca_v12_36.pth
	Model improved!!!
EPOCH 37/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3411123833273704		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3411123833273704 | validation: 0.2862760111358125]
	TIME [epoch: 9.98 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12_20240719_004901/states/model_facs_v3_dec1b_2dpca_v12_37.pth
	Model improved!!!
EPOCH 38/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3375413844664716		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3375413844664716 | validation: 0.2957762153217259]
	TIME [epoch: 9.99 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3774743859962024		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3774743859962024 | validation: 0.28690741029945477]
	TIME [epoch: 9.98 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3385635574466934		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3385635574466934 | validation: 0.27661466243432953]
	TIME [epoch: 9.98 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12_20240719_004901/states/model_facs_v3_dec1b_2dpca_v12_40.pth
	Model improved!!!
EPOCH 41/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.34081765949769793		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.34081765949769793 | validation: 0.2898477904127265]
	TIME [epoch: 9.95 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3465214637077856		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3465214637077856 | validation: 0.2942729622901714]
	TIME [epoch: 9.99 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.35451135514740334		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.35451135514740334 | validation: 0.2791391343235659]
	TIME [epoch: 9.97 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3323456857495317		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3323456857495317 | validation: 0.2758745356030501]
	TIME [epoch: 9.93 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12_20240719_004901/states/model_facs_v3_dec1b_2dpca_v12_44.pth
	Model improved!!!
EPOCH 45/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.329041802822341		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.329041802822341 | validation: 0.2692765582467871]
	TIME [epoch: 9.95 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12_20240719_004901/states/model_facs_v3_dec1b_2dpca_v12_45.pth
	Model improved!!!
EPOCH 46/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.32175550669520664		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.32175550669520664 | validation: 0.3056246312108739]
	TIME [epoch: 9.98 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3308916666308284		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3308916666308284 | validation: 0.332021031733204]
	TIME [epoch: 9.98 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3523082879103982		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3523082879103982 | validation: 0.2588754487234189]
	TIME [epoch: 10 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12_20240719_004901/states/model_facs_v3_dec1b_2dpca_v12_48.pth
	Model improved!!!
EPOCH 49/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3323644216147769		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3323644216147769 | validation: 0.2687725724665103]
	TIME [epoch: 10 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.31627982045952274		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.31627982045952274 | validation: 0.2720886481314355]
	TIME [epoch: 9.98 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3216703776002812		[learning rate: 0.0099705]
	Learning Rate: 0.00997052
	LOSS [training: 0.3216703776002812 | validation: 0.29913081920531853]
	TIME [epoch: 35.9 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.34073976743756035		[learning rate: 0.0099353]
	Learning Rate: 0.00993527
	LOSS [training: 0.34073976743756035 | validation: 0.2518928495481244]
	TIME [epoch: 19.2 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12_20240719_004901/states/model_facs_v3_dec1b_2dpca_v12_52.pth
	Model improved!!!
EPOCH 53/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.30442710179149607		[learning rate: 0.0099001]
	Learning Rate: 0.00990013
	LOSS [training: 0.30442710179149607 | validation: 0.2799041669576024]
	TIME [epoch: 19.2 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3323254094254226		[learning rate: 0.0098651]
	Learning Rate: 0.00986512
	LOSS [training: 0.3323254094254226 | validation: 0.2599158286880956]
	TIME [epoch: 19.2 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.32773046911530285		[learning rate: 0.0098302]
	Learning Rate: 0.00983024
	LOSS [training: 0.32773046911530285 | validation: 0.25824806301323955]
	TIME [epoch: 19.2 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3214842992084927		[learning rate: 0.0097955]
	Learning Rate: 0.00979548
	LOSS [training: 0.3214842992084927 | validation: 0.2537986536017974]
	TIME [epoch: 19.2 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2929251271842021		[learning rate: 0.0097608]
	Learning Rate: 0.00976084
	LOSS [training: 0.2929251271842021 | validation: 0.2605191431088949]
	TIME [epoch: 19.2 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29078332728981043		[learning rate: 0.0097263]
	Learning Rate: 0.00972632
	LOSS [training: 0.29078332728981043 | validation: 0.24807797737095613]
	TIME [epoch: 19.2 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12_20240719_004901/states/model_facs_v3_dec1b_2dpca_v12_58.pth
	Model improved!!!
EPOCH 59/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3173699120986502		[learning rate: 0.0096919]
	Learning Rate: 0.00969193
	LOSS [training: 0.3173699120986502 | validation: 0.2694175577494871]
	TIME [epoch: 19.2 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3264443494742093		[learning rate: 0.0096577]
	Learning Rate: 0.00965766
	LOSS [training: 0.3264443494742093 | validation: 0.26834759191207125]
	TIME [epoch: 19.2 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.307303264331611		[learning rate: 0.0096235]
	Learning Rate: 0.00962351
	LOSS [training: 0.307303264331611 | validation: 0.24206154812164082]
	TIME [epoch: 19.2 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12_20240719_004901/states/model_facs_v3_dec1b_2dpca_v12_61.pth
	Model improved!!!
EPOCH 62/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2965303767149793		[learning rate: 0.0095895]
	Learning Rate: 0.00958948
	LOSS [training: 0.2965303767149793 | validation: 0.2675922629691311]
	TIME [epoch: 19.2 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.31022164814390113		[learning rate: 0.0095556]
	Learning Rate: 0.00955557
	LOSS [training: 0.31022164814390113 | validation: 0.24754747160173518]
	TIME [epoch: 19.2 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.30027770642269863		[learning rate: 0.0095218]
	Learning Rate: 0.00952177
	LOSS [training: 0.30027770642269863 | validation: 0.24301858947191762]
	TIME [epoch: 19.2 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3075400295359346		[learning rate: 0.0094881]
	Learning Rate: 0.0094881
	LOSS [training: 0.3075400295359346 | validation: 0.23342942962011154]
	TIME [epoch: 19.2 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12_20240719_004901/states/model_facs_v3_dec1b_2dpca_v12_65.pth
	Model improved!!!
EPOCH 66/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3005709593348535		[learning rate: 0.0094546]
	Learning Rate: 0.00945455
	LOSS [training: 0.3005709593348535 | validation: 0.24977191130474244]
	TIME [epoch: 19.2 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2944133476684806		[learning rate: 0.0094211]
	Learning Rate: 0.00942112
	LOSS [training: 0.2944133476684806 | validation: 0.2283838279313483]
	TIME [epoch: 19.2 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12_20240719_004901/states/model_facs_v3_dec1b_2dpca_v12_67.pth
	Model improved!!!
EPOCH 68/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29395630682862434		[learning rate: 0.0093878]
	Learning Rate: 0.00938781
	LOSS [training: 0.29395630682862434 | validation: 0.2549254447561366]
	TIME [epoch: 19.2 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.30167013693084527		[learning rate: 0.0093546]
	Learning Rate: 0.00935461
	LOSS [training: 0.30167013693084527 | validation: 0.23573919269896842]
	TIME [epoch: 19.2 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3002585408206168		[learning rate: 0.0093215]
	Learning Rate: 0.00932153
	LOSS [training: 0.3002585408206168 | validation: 0.23284547642990808]
	TIME [epoch: 19.2 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3083201490398583		[learning rate: 0.0092886]
	Learning Rate: 0.00928857
	LOSS [training: 0.3083201490398583 | validation: 0.22848648348622783]
	TIME [epoch: 19.2 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28956048403806683		[learning rate: 0.0092557]
	Learning Rate: 0.00925572
	LOSS [training: 0.28956048403806683 | validation: 0.2439166128540589]
	TIME [epoch: 19.2 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3119256660049418		[learning rate: 0.009223]
	Learning Rate: 0.00922299
	LOSS [training: 0.3119256660049418 | validation: 0.22699471897517953]
	TIME [epoch: 19.2 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12_20240719_004901/states/model_facs_v3_dec1b_2dpca_v12_73.pth
	Model improved!!!
EPOCH 74/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2965384255034715		[learning rate: 0.0091904]
	Learning Rate: 0.00919038
	LOSS [training: 0.2965384255034715 | validation: 0.24794195908963795]
	TIME [epoch: 19.2 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28204936719790613		[learning rate: 0.0091579]
	Learning Rate: 0.00915788
	LOSS [training: 0.28204936719790613 | validation: 0.2553417412881026]
	TIME [epoch: 19.2 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29017188076006944		[learning rate: 0.0091255]
	Learning Rate: 0.00912549
	LOSS [training: 0.29017188076006944 | validation: 0.25108309237445897]
	TIME [epoch: 19.2 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.281284256767631		[learning rate: 0.0090932]
	Learning Rate: 0.00909323
	LOSS [training: 0.281284256767631 | validation: 0.224873962697202]
	TIME [epoch: 19.2 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12_20240719_004901/states/model_facs_v3_dec1b_2dpca_v12_77.pth
	Model improved!!!
EPOCH 78/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29003006256479164		[learning rate: 0.0090611]
	Learning Rate: 0.00906107
	LOSS [training: 0.29003006256479164 | validation: 0.2595211851895769]
	TIME [epoch: 19.2 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.30734009055760253		[learning rate: 0.009029]
	Learning Rate: 0.00902903
	LOSS [training: 0.30734009055760253 | validation: 0.24373628058935898]
	TIME [epoch: 19.2 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2836876349257212		[learning rate: 0.0089971]
	Learning Rate: 0.0089971
	LOSS [training: 0.2836876349257212 | validation: 0.22781271196601743]
	TIME [epoch: 19.2 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2874646590178816		[learning rate: 0.0089653]
	Learning Rate: 0.00896528
	LOSS [training: 0.2874646590178816 | validation: 0.24277412449237518]
	TIME [epoch: 19.2 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2927946711902009		[learning rate: 0.0089336]
	Learning Rate: 0.00893358
	LOSS [training: 0.2927946711902009 | validation: 0.24693941201691177]
	TIME [epoch: 19.2 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2961039989997529		[learning rate: 0.008902]
	Learning Rate: 0.00890199
	LOSS [training: 0.2961039989997529 | validation: 0.21929251294986885]
	TIME [epoch: 19.2 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12_20240719_004901/states/model_facs_v3_dec1b_2dpca_v12_83.pth
	Model improved!!!
EPOCH 84/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28427888279996466		[learning rate: 0.0088705]
	Learning Rate: 0.00887051
	LOSS [training: 0.28427888279996466 | validation: 0.24008065181625948]
	TIME [epoch: 19.2 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27972194655623667		[learning rate: 0.0088391]
	Learning Rate: 0.00883914
	LOSS [training: 0.27972194655623667 | validation: 0.2410869131985734]
	TIME [epoch: 19.2 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.31169241467101233		[learning rate: 0.0088079]
	Learning Rate: 0.00880789
	LOSS [training: 0.31169241467101233 | validation: 0.2350734323679355]
	TIME [epoch: 19.2 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28861208314516434		[learning rate: 0.0087767]
	Learning Rate: 0.00877674
	LOSS [training: 0.28861208314516434 | validation: 0.2369209763476099]
	TIME [epoch: 19.2 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28151889243549805		[learning rate: 0.0087457]
	Learning Rate: 0.00874571
	LOSS [training: 0.28151889243549805 | validation: 0.22900590774560894]
	TIME [epoch: 19.2 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2825532610887169		[learning rate: 0.0087148]
	Learning Rate: 0.00871478
	LOSS [training: 0.2825532610887169 | validation: 0.22805234920813744]
	TIME [epoch: 19.2 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3060235246989853		[learning rate: 0.008684]
	Learning Rate: 0.00868396
	LOSS [training: 0.3060235246989853 | validation: 0.22316708641854296]
	TIME [epoch: 19.2 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2844064485158201		[learning rate: 0.0086533]
	Learning Rate: 0.00865326
	LOSS [training: 0.2844064485158201 | validation: 0.23352048476454149]
	TIME [epoch: 19.2 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27935449242982785		[learning rate: 0.0086227]
	Learning Rate: 0.00862265
	LOSS [training: 0.27935449242982785 | validation: 0.22805619844769048]
	TIME [epoch: 19.2 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2770043958850407		[learning rate: 0.0085922]
	Learning Rate: 0.00859216
	LOSS [training: 0.2770043958850407 | validation: 0.23508792053845345]
	TIME [epoch: 19.2 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28493409120072705		[learning rate: 0.0085618]
	Learning Rate: 0.00856178
	LOSS [training: 0.28493409120072705 | validation: 0.22302532377145132]
	TIME [epoch: 19.2 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29783281304169434		[learning rate: 0.0085315]
	Learning Rate: 0.0085315
	LOSS [training: 0.29783281304169434 | validation: 0.24805176984899405]
	TIME [epoch: 19.2 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28909224672291123		[learning rate: 0.0085013]
	Learning Rate: 0.00850134
	LOSS [training: 0.28909224672291123 | validation: 0.22378829462213518]
	TIME [epoch: 19.2 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2793044985647455		[learning rate: 0.0084713]
	Learning Rate: 0.00847127
	LOSS [training: 0.2793044985647455 | validation: 0.2336536628164744]
	TIME [epoch: 19.2 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29096728386061477		[learning rate: 0.0084413]
	Learning Rate: 0.00844132
	LOSS [training: 0.29096728386061477 | validation: 0.2242385962528049]
	TIME [epoch: 19.2 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2762210338679448		[learning rate: 0.0084115]
	Learning Rate: 0.00841147
	LOSS [training: 0.2762210338679448 | validation: 0.2260952614196544]
	TIME [epoch: 19.2 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2709123326867465		[learning rate: 0.0083817]
	Learning Rate: 0.00838172
	LOSS [training: 0.2709123326867465 | validation: 0.23879900281944405]
	TIME [epoch: 19.2 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29046317399994737		[learning rate: 0.0083521]
	Learning Rate: 0.00835208
	LOSS [training: 0.29046317399994737 | validation: 0.239626966503447]
	TIME [epoch: 19.2 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28370857552749507		[learning rate: 0.0083225]
	Learning Rate: 0.00832255
	LOSS [training: 0.28370857552749507 | validation: 0.2217793001364341]
	TIME [epoch: 19.2 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.275616829707472		[learning rate: 0.0082931]
	Learning Rate: 0.00829312
	LOSS [training: 0.275616829707472 | validation: 0.24059754207847933]
	TIME [epoch: 19.2 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28186594880470867		[learning rate: 0.0082638]
	Learning Rate: 0.00826379
	LOSS [training: 0.28186594880470867 | validation: 0.2275075030990607]
	TIME [epoch: 19.2 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27730885914101866		[learning rate: 0.0082346]
	Learning Rate: 0.00823457
	LOSS [training: 0.27730885914101866 | validation: 0.23853492529684422]
	TIME [epoch: 19.2 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.287264808532719		[learning rate: 0.0082055]
	Learning Rate: 0.00820545
	LOSS [training: 0.287264808532719 | validation: 0.2414922577750885]
	TIME [epoch: 19.2 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28539395434564335		[learning rate: 0.0081764]
	Learning Rate: 0.00817644
	LOSS [training: 0.28539395434564335 | validation: 0.22094658262237768]
	TIME [epoch: 19.2 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2726878588770422		[learning rate: 0.0081475]
	Learning Rate: 0.00814752
	LOSS [training: 0.2726878588770422 | validation: 0.22608401883009108]
	TIME [epoch: 19.2 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2722542966750635		[learning rate: 0.0081187]
	Learning Rate: 0.00811871
	LOSS [training: 0.2722542966750635 | validation: 0.22114061349968606]
	TIME [epoch: 19.2 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27789646841893995		[learning rate: 0.00809]
	Learning Rate: 0.00809
	LOSS [training: 0.27789646841893995 | validation: 0.22328522266217826]
	TIME [epoch: 19.2 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2802403827706343		[learning rate: 0.0080614]
	Learning Rate: 0.0080614
	LOSS [training: 0.2802403827706343 | validation: 0.23201362597427444]
	TIME [epoch: 19.2 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2978362659334204		[learning rate: 0.0080329]
	Learning Rate: 0.00803289
	LOSS [training: 0.2978362659334204 | validation: 0.22892960730473835]
	TIME [epoch: 19.2 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27177893325527663		[learning rate: 0.0080045]
	Learning Rate: 0.00800448
	LOSS [training: 0.27177893325527663 | validation: 0.22690296439387905]
	TIME [epoch: 19.2 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2763853034731991		[learning rate: 0.0079762]
	Learning Rate: 0.00797618
	LOSS [training: 0.2763853034731991 | validation: 0.22305351976733725]
	TIME [epoch: 19.2 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28490305202356414		[learning rate: 0.007948]
	Learning Rate: 0.00794797
	LOSS [training: 0.28490305202356414 | validation: 0.21878908558784213]
	TIME [epoch: 19.2 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12_20240719_004901/states/model_facs_v3_dec1b_2dpca_v12_115.pth
	Model improved!!!
EPOCH 116/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27408841271058293		[learning rate: 0.0079199]
	Learning Rate: 0.00791987
	LOSS [training: 0.27408841271058293 | validation: 0.21882337469277086]
	TIME [epoch: 19.1 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2697421117940016		[learning rate: 0.0078919]
	Learning Rate: 0.00789186
	LOSS [training: 0.2697421117940016 | validation: 0.21979207101337855]
	TIME [epoch: 19.1 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2830860899162871		[learning rate: 0.007864]
	Learning Rate: 0.00786395
	LOSS [training: 0.2830860899162871 | validation: 0.22839566649813645]
	TIME [epoch: 19.1 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27631385809797643		[learning rate: 0.0078361]
	Learning Rate: 0.00783615
	LOSS [training: 0.27631385809797643 | validation: 0.22094053514794246]
	TIME [epoch: 19.2 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27783602811710195		[learning rate: 0.0078084]
	Learning Rate: 0.00780844
	LOSS [training: 0.27783602811710195 | validation: 0.22249601831686966]
	TIME [epoch: 19.1 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27410539080948676		[learning rate: 0.0077808]
	Learning Rate: 0.00778083
	LOSS [training: 0.27410539080948676 | validation: 0.21292143566426464]
	TIME [epoch: 19.1 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12_20240719_004901/states/model_facs_v3_dec1b_2dpca_v12_121.pth
	Model improved!!!
EPOCH 122/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2813467396439761		[learning rate: 0.0077533]
	Learning Rate: 0.00775331
	LOSS [training: 0.2813467396439761 | validation: 0.21524943988340772]
	TIME [epoch: 19.2 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27301700991508626		[learning rate: 0.0077259]
	Learning Rate: 0.00772589
	LOSS [training: 0.27301700991508626 | validation: 0.2159297060375905]
	TIME [epoch: 19.1 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26440658841823045		[learning rate: 0.0076986]
	Learning Rate: 0.00769857
	LOSS [training: 0.26440658841823045 | validation: 0.22512310786656645]
	TIME [epoch: 19.2 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2716849802912917		[learning rate: 0.0076714]
	Learning Rate: 0.00767135
	LOSS [training: 0.2716849802912917 | validation: 0.211238017853597]
	TIME [epoch: 19.2 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12_20240719_004901/states/model_facs_v3_dec1b_2dpca_v12_125.pth
	Model improved!!!
EPOCH 126/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.281701770530175		[learning rate: 0.0076442]
	Learning Rate: 0.00764422
	LOSS [training: 0.281701770530175 | validation: 0.22764719336912548]
	TIME [epoch: 19.3 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27735556570432257		[learning rate: 0.0076172]
	Learning Rate: 0.00761719
	LOSS [training: 0.27735556570432257 | validation: 0.21947184494224709]
	TIME [epoch: 19.2 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26947774951165254		[learning rate: 0.0075903]
	Learning Rate: 0.00759025
	LOSS [training: 0.26947774951165254 | validation: 0.2258229008570925]
	TIME [epoch: 19.3 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27653690284593824		[learning rate: 0.0075634]
	Learning Rate: 0.00756341
	LOSS [training: 0.27653690284593824 | validation: 0.22715427612576217]
	TIME [epoch: 19.3 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29244002052129775		[learning rate: 0.0075367]
	Learning Rate: 0.00753667
	LOSS [training: 0.29244002052129775 | validation: 0.21760460968856615]
	TIME [epoch: 19.2 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26291000841555956		[learning rate: 0.00751]
	Learning Rate: 0.00751002
	LOSS [training: 0.26291000841555956 | validation: 0.2206107657930713]
	TIME [epoch: 19.2 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2738189204676145		[learning rate: 0.0074835]
	Learning Rate: 0.00748346
	LOSS [training: 0.2738189204676145 | validation: 0.22065386065277887]
	TIME [epoch: 19.2 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.267011125208165		[learning rate: 0.007457]
	Learning Rate: 0.007457
	LOSS [training: 0.267011125208165 | validation: 0.2196538604988926]
	TIME [epoch: 19.2 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2727661571135776		[learning rate: 0.0074306]
	Learning Rate: 0.00743063
	LOSS [training: 0.2727661571135776 | validation: 0.23414516680165803]
	TIME [epoch: 19.2 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2621346392954063		[learning rate: 0.0074044]
	Learning Rate: 0.00740435
	LOSS [training: 0.2621346392954063 | validation: 0.2171971276861686]
	TIME [epoch: 19.2 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2724782042041372		[learning rate: 0.0073782]
	Learning Rate: 0.00737817
	LOSS [training: 0.2724782042041372 | validation: 0.22313237277353853]
	TIME [epoch: 19.2 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26517793947865126		[learning rate: 0.0073521]
	Learning Rate: 0.00735208
	LOSS [training: 0.26517793947865126 | validation: 0.20797611785829245]
	TIME [epoch: 19.2 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12_20240719_004901/states/model_facs_v3_dec1b_2dpca_v12_137.pth
	Model improved!!!
EPOCH 138/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.271527773655109		[learning rate: 0.0073261]
	Learning Rate: 0.00732608
	LOSS [training: 0.271527773655109 | validation: 0.21361212119191783]
	TIME [epoch: 19.1 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.265129321501584		[learning rate: 0.0073002]
	Learning Rate: 0.00730018
	LOSS [training: 0.265129321501584 | validation: 0.21952686330167137]
	TIME [epoch: 19.1 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2746544568237033		[learning rate: 0.0072744]
	Learning Rate: 0.00727436
	LOSS [training: 0.2746544568237033 | validation: 0.21410628378216626]
	TIME [epoch: 19.1 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2724559667341108		[learning rate: 0.0072486]
	Learning Rate: 0.00724864
	LOSS [training: 0.2724559667341108 | validation: 0.22425401425666633]
	TIME [epoch: 19.1 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2630608815431632		[learning rate: 0.007223]
	Learning Rate: 0.007223
	LOSS [training: 0.2630608815431632 | validation: 0.21807178952739661]
	TIME [epoch: 19.1 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2689922027302553		[learning rate: 0.0071975]
	Learning Rate: 0.00719746
	LOSS [training: 0.2689922027302553 | validation: 0.2181430677523374]
	TIME [epoch: 19.2 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.260788054534631		[learning rate: 0.007172]
	Learning Rate: 0.00717201
	LOSS [training: 0.260788054534631 | validation: 0.21614003378109242]
	TIME [epoch: 19.2 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2739870388726463		[learning rate: 0.0071467]
	Learning Rate: 0.00714665
	LOSS [training: 0.2739870388726463 | validation: 0.22476512848497693]
	TIME [epoch: 19.2 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26880114523702814		[learning rate: 0.0071214]
	Learning Rate: 0.00712138
	LOSS [training: 0.26880114523702814 | validation: 0.21983446187708947]
	TIME [epoch: 19.2 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.270250798864172		[learning rate: 0.0070962]
	Learning Rate: 0.0070962
	LOSS [training: 0.270250798864172 | validation: 0.22670422719274885]
	TIME [epoch: 19.2 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27685827363785503		[learning rate: 0.0070711]
	Learning Rate: 0.0070711
	LOSS [training: 0.27685827363785503 | validation: 0.2176724128294966]
	TIME [epoch: 19.2 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26566564230029543		[learning rate: 0.0070461]
	Learning Rate: 0.0070461
	LOSS [training: 0.26566564230029543 | validation: 0.22276903292671418]
	TIME [epoch: 19.2 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.267418983101241		[learning rate: 0.0070212]
	Learning Rate: 0.00702118
	LOSS [training: 0.267418983101241 | validation: 0.21728512570044325]
	TIME [epoch: 19.1 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27068894836627183		[learning rate: 0.0069964]
	Learning Rate: 0.00699635
	LOSS [training: 0.27068894836627183 | validation: 0.21743521563102228]
	TIME [epoch: 19.2 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26591620726967913		[learning rate: 0.0069716]
	Learning Rate: 0.00697161
	LOSS [training: 0.26591620726967913 | validation: 0.2128102345393145]
	TIME [epoch: 19.1 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26421598729912404		[learning rate: 0.006947]
	Learning Rate: 0.00694696
	LOSS [training: 0.26421598729912404 | validation: 0.2141008536194668]
	TIME [epoch: 19.2 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2644129219282553		[learning rate: 0.0069224]
	Learning Rate: 0.00692239
	LOSS [training: 0.2644129219282553 | validation: 0.21956345755668805]
	TIME [epoch: 19.1 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2687797880159064		[learning rate: 0.0068979]
	Learning Rate: 0.00689792
	LOSS [training: 0.2687797880159064 | validation: 0.21374234101813902]
	TIME [epoch: 19.2 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2613519479607667		[learning rate: 0.0068735]
	Learning Rate: 0.00687352
	LOSS [training: 0.2613519479607667 | validation: 0.24098539635222918]
	TIME [epoch: 19.1 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2894202493951017		[learning rate: 0.0068492]
	Learning Rate: 0.00684922
	LOSS [training: 0.2894202493951017 | validation: 0.22196830180825944]
	TIME [epoch: 19.2 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2738792460183919		[learning rate: 0.006825]
	Learning Rate: 0.006825
	LOSS [training: 0.2738792460183919 | validation: 0.21732236958086953]
	TIME [epoch: 19.1 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26781069744092423		[learning rate: 0.0068009]
	Learning Rate: 0.00680086
	LOSS [training: 0.26781069744092423 | validation: 0.21956290399552608]
	TIME [epoch: 19.2 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2692166702455142		[learning rate: 0.0067768]
	Learning Rate: 0.00677681
	LOSS [training: 0.2692166702455142 | validation: 0.21732033095163064]
	TIME [epoch: 19.1 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2676314816849358		[learning rate: 0.0067529]
	Learning Rate: 0.00675285
	LOSS [training: 0.2676314816849358 | validation: 0.2127764106656679]
	TIME [epoch: 19.2 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26793765767482985		[learning rate: 0.006729]
	Learning Rate: 0.00672897
	LOSS [training: 0.26793765767482985 | validation: 0.22025275877568432]
	TIME [epoch: 19.1 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2781978064431521		[learning rate: 0.0067052]
	Learning Rate: 0.00670518
	LOSS [training: 0.2781978064431521 | validation: 0.21505989884475887]
	TIME [epoch: 19.2 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2673232071214979		[learning rate: 0.0066815]
	Learning Rate: 0.00668147
	LOSS [training: 0.2673232071214979 | validation: 0.21620395025935507]
	TIME [epoch: 19.2 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.269312706136782		[learning rate: 0.0066578]
	Learning Rate: 0.00665784
	LOSS [training: 0.269312706136782 | validation: 0.20970658917110394]
	TIME [epoch: 19.2 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2591509244808103		[learning rate: 0.0066343]
	Learning Rate: 0.0066343
	LOSS [training: 0.2591509244808103 | validation: 0.2244282203390874]
	TIME [epoch: 19.1 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26583339105850395		[learning rate: 0.0066108]
	Learning Rate: 0.00661084
	LOSS [training: 0.26583339105850395 | validation: 0.21461223276358127]
	TIME [epoch: 19.2 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2646641751805926		[learning rate: 0.0065875]
	Learning Rate: 0.00658746
	LOSS [training: 0.2646641751805926 | validation: 0.23792515946319637]
	TIME [epoch: 19.1 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27883037447935893		[learning rate: 0.0065642]
	Learning Rate: 0.00656416
	LOSS [training: 0.27883037447935893 | validation: 0.2198948613623334]
	TIME [epoch: 19.1 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2597861444013854		[learning rate: 0.006541]
	Learning Rate: 0.00654095
	LOSS [training: 0.2597861444013854 | validation: 0.22720445133403167]
	TIME [epoch: 19.2 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26039457118556864		[learning rate: 0.0065178]
	Learning Rate: 0.00651782
	LOSS [training: 0.26039457118556864 | validation: 0.21948341849429687]
	TIME [epoch: 19.2 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2672353163164349		[learning rate: 0.0064948]
	Learning Rate: 0.00649477
	LOSS [training: 0.2672353163164349 | validation: 0.21865095489451397]
	TIME [epoch: 19.1 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2628905342407185		[learning rate: 0.0064718]
	Learning Rate: 0.00647181
	LOSS [training: 0.2628905342407185 | validation: 0.2136291627110447]
	TIME [epoch: 19.2 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2683965202613263		[learning rate: 0.0064489]
	Learning Rate: 0.00644892
	LOSS [training: 0.2683965202613263 | validation: 0.22324268666116528]
	TIME [epoch: 19.2 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27084092663091613		[learning rate: 0.0064261]
	Learning Rate: 0.00642612
	LOSS [training: 0.27084092663091613 | validation: 0.22388826878415613]
	TIME [epoch: 19.2 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2775573264567714		[learning rate: 0.0064034]
	Learning Rate: 0.00640339
	LOSS [training: 0.2775573264567714 | validation: 0.21656959997794992]
	TIME [epoch: 19.2 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.262788300306003		[learning rate: 0.0063808]
	Learning Rate: 0.00638075
	LOSS [training: 0.262788300306003 | validation: 0.21253563520072416]
	TIME [epoch: 19.2 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25473517013850183		[learning rate: 0.0063582]
	Learning Rate: 0.00635819
	LOSS [training: 0.25473517013850183 | validation: 0.2273769878735279]
	TIME [epoch: 19.1 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2599371087362375		[learning rate: 0.0063357]
	Learning Rate: 0.0063357
	LOSS [training: 0.2599371087362375 | validation: 0.2083440555849526]
	TIME [epoch: 19.2 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2713481892894954		[learning rate: 0.0063133]
	Learning Rate: 0.0063133
	LOSS [training: 0.2713481892894954 | validation: 0.21941964447991275]
	TIME [epoch: 19.1 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2577508110399724		[learning rate: 0.006291]
	Learning Rate: 0.00629097
	LOSS [training: 0.2577508110399724 | validation: 0.22372289272554663]
	TIME [epoch: 19.2 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2681131902324156		[learning rate: 0.0062687]
	Learning Rate: 0.00626873
	LOSS [training: 0.2681131902324156 | validation: 0.21731181759078763]
	TIME [epoch: 19.1 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2570986920595942		[learning rate: 0.0062466]
	Learning Rate: 0.00624656
	LOSS [training: 0.2570986920595942 | validation: 0.208401387884448]
	TIME [epoch: 19.2 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2561824099257466		[learning rate: 0.0062245]
	Learning Rate: 0.00622447
	LOSS [training: 0.2561824099257466 | validation: 0.22206131878603816]
	TIME [epoch: 19.2 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25685575578973435		[learning rate: 0.0062025]
	Learning Rate: 0.00620246
	LOSS [training: 0.25685575578973435 | validation: 0.22779232581767067]
	TIME [epoch: 19.2 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27134435949848684		[learning rate: 0.0061805]
	Learning Rate: 0.00618053
	LOSS [training: 0.27134435949848684 | validation: 0.21337756243169656]
	TIME [epoch: 19.1 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2573506264042131		[learning rate: 0.0061587]
	Learning Rate: 0.00615867
	LOSS [training: 0.2573506264042131 | validation: 0.21526958102047183]
	TIME [epoch: 19.2 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26251234017477326		[learning rate: 0.0061369]
	Learning Rate: 0.00613689
	LOSS [training: 0.26251234017477326 | validation: 0.2145938291176856]
	TIME [epoch: 19.2 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2579693530231533		[learning rate: 0.0061152]
	Learning Rate: 0.00611519
	LOSS [training: 0.2579693530231533 | validation: 0.21995057210360658]
	TIME [epoch: 19.2 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2612415097358746		[learning rate: 0.0060936]
	Learning Rate: 0.00609357
	LOSS [training: 0.2612415097358746 | validation: 0.22080940227670295]
	TIME [epoch: 19.2 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2632756814046873		[learning rate: 0.006072]
	Learning Rate: 0.00607202
	LOSS [training: 0.2632756814046873 | validation: 0.21543540129846828]
	TIME [epoch: 19.2 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.271154977891991		[learning rate: 0.0060505]
	Learning Rate: 0.00605055
	LOSS [training: 0.271154977891991 | validation: 0.2077747552681753]
	TIME [epoch: 19.2 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12_20240719_004901/states/model_facs_v3_dec1b_2dpca_v12_192.pth
	Model improved!!!
EPOCH 193/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.261904804147348		[learning rate: 0.0060292]
	Learning Rate: 0.00602915
	LOSS [training: 0.261904804147348 | validation: 0.21557021194133452]
	TIME [epoch: 19.2 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26519331426011145		[learning rate: 0.0060078]
	Learning Rate: 0.00600783
	LOSS [training: 0.26519331426011145 | validation: 0.21683769927342073]
	TIME [epoch: 19.2 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25545028037214085		[learning rate: 0.0059866]
	Learning Rate: 0.00598659
	LOSS [training: 0.25545028037214085 | validation: 0.21604140791719129]
	TIME [epoch: 19.2 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2584876955298843		[learning rate: 0.0059654]
	Learning Rate: 0.00596542
	LOSS [training: 0.2584876955298843 | validation: 0.21031380894025356]
	TIME [epoch: 19.2 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25180271203736276		[learning rate: 0.0059443]
	Learning Rate: 0.00594433
	LOSS [training: 0.25180271203736276 | validation: 0.2223973151345468]
	TIME [epoch: 19.2 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2732433815799991		[learning rate: 0.0059233]
	Learning Rate: 0.0059233
	LOSS [training: 0.2732433815799991 | validation: 0.2142492164912317]
	TIME [epoch: 19.2 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.257806689213167		[learning rate: 0.0059024]
	Learning Rate: 0.00590236
	LOSS [training: 0.257806689213167 | validation: 0.2265172738466564]
	TIME [epoch: 19.2 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27423563372958676		[learning rate: 0.0058815]
	Learning Rate: 0.00588149
	LOSS [training: 0.27423563372958676 | validation: 0.21570511430222714]
	TIME [epoch: 19.2 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26188358425808883		[learning rate: 0.0058607]
	Learning Rate: 0.00586069
	LOSS [training: 0.26188358425808883 | validation: 0.21418575141985965]
	TIME [epoch: 19.2 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2550690649282414		[learning rate: 0.00584]
	Learning Rate: 0.00583996
	LOSS [training: 0.2550690649282414 | validation: 0.22165498735075317]
	TIME [epoch: 19.2 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27209683566799625		[learning rate: 0.0058193]
	Learning Rate: 0.00581931
	LOSS [training: 0.27209683566799625 | validation: 0.21780772879084828]
	TIME [epoch: 19.2 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2633606843347909		[learning rate: 0.0057987]
	Learning Rate: 0.00579874
	LOSS [training: 0.2633606843347909 | validation: 0.21619545647988364]
	TIME [epoch: 19.2 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2752782478044615		[learning rate: 0.0057782]
	Learning Rate: 0.00577823
	LOSS [training: 0.2752782478044615 | validation: 0.21004698823915063]
	TIME [epoch: 19.2 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.259022681828805		[learning rate: 0.0057578]
	Learning Rate: 0.0057578
	LOSS [training: 0.259022681828805 | validation: 0.2228344698042844]
	TIME [epoch: 19.2 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25894755334119474		[learning rate: 0.0057374]
	Learning Rate: 0.00573744
	LOSS [training: 0.25894755334119474 | validation: 0.2179938448478039]
	TIME [epoch: 19.2 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2577544023008839		[learning rate: 0.0057171]
	Learning Rate: 0.00571715
	LOSS [training: 0.2577544023008839 | validation: 0.21518616986639846]
	TIME [epoch: 19.2 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2578941337902459		[learning rate: 0.0056969]
	Learning Rate: 0.00569693
	LOSS [training: 0.2578941337902459 | validation: 0.21753833274937354]
	TIME [epoch: 19.2 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26426610291015434		[learning rate: 0.0056768]
	Learning Rate: 0.00567679
	LOSS [training: 0.26426610291015434 | validation: 0.2094103305347581]
	TIME [epoch: 19.2 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25050272120701766		[learning rate: 0.0056567]
	Learning Rate: 0.00565671
	LOSS [training: 0.25050272120701766 | validation: 0.2132079975460727]
	TIME [epoch: 19.2 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2737968351523496		[learning rate: 0.0056367]
	Learning Rate: 0.00563671
	LOSS [training: 0.2737968351523496 | validation: 0.22125557791301861]
	TIME [epoch: 19.2 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2598463981618496		[learning rate: 0.0056168]
	Learning Rate: 0.00561678
	LOSS [training: 0.2598463981618496 | validation: 0.21901618051417665]
	TIME [epoch: 19.2 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2591352966092501		[learning rate: 0.0055969]
	Learning Rate: 0.00559691
	LOSS [training: 0.2591352966092501 | validation: 0.20868108882735292]
	TIME [epoch: 19.2 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25446037418356093		[learning rate: 0.0055771]
	Learning Rate: 0.00557712
	LOSS [training: 0.25446037418356093 | validation: 0.21669168747038206]
	TIME [epoch: 19.2 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2616606726775677		[learning rate: 0.0055574]
	Learning Rate: 0.0055574
	LOSS [training: 0.2616606726775677 | validation: 0.21770556902035737]
	TIME [epoch: 19.2 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.254012408432127		[learning rate: 0.0055378]
	Learning Rate: 0.00553775
	LOSS [training: 0.254012408432127 | validation: 0.21949297003259388]
	TIME [epoch: 19.2 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26441445420612525		[learning rate: 0.0055182]
	Learning Rate: 0.00551817
	LOSS [training: 0.26441445420612525 | validation: 0.21976652298905872]
	TIME [epoch: 19.2 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25488932502188394		[learning rate: 0.0054987]
	Learning Rate: 0.00549865
	LOSS [training: 0.25488932502188394 | validation: 0.22538290797196722]
	TIME [epoch: 19.2 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26615765798186664		[learning rate: 0.0054792]
	Learning Rate: 0.00547921
	LOSS [training: 0.26615765798186664 | validation: 0.21306903265760896]
	TIME [epoch: 19.2 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25228243185839133		[learning rate: 0.0054598]
	Learning Rate: 0.00545983
	LOSS [training: 0.25228243185839133 | validation: 0.224164315967246]
	TIME [epoch: 19.2 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2560600060996768		[learning rate: 0.0054405]
	Learning Rate: 0.00544053
	LOSS [training: 0.2560600060996768 | validation: 0.21179977721615942]
	TIME [epoch: 19.2 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26030935083292456		[learning rate: 0.0054213]
	Learning Rate: 0.00542129
	LOSS [training: 0.26030935083292456 | validation: 0.21353745443817132]
	TIME [epoch: 19.2 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2615166305623944		[learning rate: 0.0054021]
	Learning Rate: 0.00540212
	LOSS [training: 0.2615166305623944 | validation: 0.22687664470815455]
	TIME [epoch: 19.2 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2569755514043208		[learning rate: 0.005383]
	Learning Rate: 0.00538302
	LOSS [training: 0.2569755514043208 | validation: 0.2144241629612702]
	TIME [epoch: 19.2 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25729469368419683		[learning rate: 0.005364]
	Learning Rate: 0.00536398
	LOSS [training: 0.25729469368419683 | validation: 0.21418128248487212]
	TIME [epoch: 19.2 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2578074355902141		[learning rate: 0.005345]
	Learning Rate: 0.00534501
	LOSS [training: 0.2578074355902141 | validation: 0.2055363494249863]
	TIME [epoch: 19.2 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12_20240719_004901/states/model_facs_v3_dec1b_2dpca_v12_227.pth
	Model improved!!!
EPOCH 228/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2563950124545961		[learning rate: 0.0053261]
	Learning Rate: 0.00532611
	LOSS [training: 0.2563950124545961 | validation: 0.22188880727957455]
	TIME [epoch: 19.2 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2580531078695864		[learning rate: 0.0053073]
	Learning Rate: 0.00530728
	LOSS [training: 0.2580531078695864 | validation: 0.2111684977066952]
	TIME [epoch: 19.2 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2524336484835962		[learning rate: 0.0052885]
	Learning Rate: 0.00528851
	LOSS [training: 0.2524336484835962 | validation: 0.21505493035307777]
	TIME [epoch: 19.2 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26391147361653217		[learning rate: 0.0052698]
	Learning Rate: 0.00526981
	LOSS [training: 0.26391147361653217 | validation: 0.21401020514587268]
	TIME [epoch: 19.2 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2559889748240571		[learning rate: 0.0052512]
	Learning Rate: 0.00525117
	LOSS [training: 0.2559889748240571 | validation: 0.21324727691731912]
	TIME [epoch: 19.2 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25566371686292383		[learning rate: 0.0052326]
	Learning Rate: 0.0052326
	LOSS [training: 0.25566371686292383 | validation: 0.2116648372346091]
	TIME [epoch: 19.2 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2680316485619529		[learning rate: 0.0052141]
	Learning Rate: 0.0052141
	LOSS [training: 0.2680316485619529 | validation: 0.2131009176079106]
	TIME [epoch: 19.2 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2605424450435107		[learning rate: 0.0051957]
	Learning Rate: 0.00519566
	LOSS [training: 0.2605424450435107 | validation: 0.20916009754953668]
	TIME [epoch: 19.2 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2606721548207911		[learning rate: 0.0051773]
	Learning Rate: 0.00517729
	LOSS [training: 0.2606721548207911 | validation: 0.2115431391622929]
	TIME [epoch: 19.2 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2530240552662307		[learning rate: 0.005159]
	Learning Rate: 0.00515898
	LOSS [training: 0.2530240552662307 | validation: 0.20973125890530828]
	TIME [epoch: 19.2 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26291749785491847		[learning rate: 0.0051407]
	Learning Rate: 0.00514074
	LOSS [training: 0.26291749785491847 | validation: 0.21572286407872823]
	TIME [epoch: 19.2 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.260359430791786		[learning rate: 0.0051226]
	Learning Rate: 0.00512256
	LOSS [training: 0.260359430791786 | validation: 0.21361983215948852]
	TIME [epoch: 19.2 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2488447224109304		[learning rate: 0.0051044]
	Learning Rate: 0.00510445
	LOSS [training: 0.2488447224109304 | validation: 0.21178883536315624]
	TIME [epoch: 19.2 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2554962453387598		[learning rate: 0.0050864]
	Learning Rate: 0.0050864
	LOSS [training: 0.2554962453387598 | validation: 0.21630134918467098]
	TIME [epoch: 19.2 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25752462636912293		[learning rate: 0.0050684]
	Learning Rate: 0.00506841
	LOSS [training: 0.25752462636912293 | validation: 0.21682814762881736]
	TIME [epoch: 19.2 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2513843718150184		[learning rate: 0.0050505]
	Learning Rate: 0.00505049
	LOSS [training: 0.2513843718150184 | validation: 0.21395092751163108]
	TIME [epoch: 19.2 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25874836122530315		[learning rate: 0.0050326]
	Learning Rate: 0.00503263
	LOSS [training: 0.25874836122530315 | validation: 0.2165811771874985]
	TIME [epoch: 19.2 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2606509499714314		[learning rate: 0.0050148]
	Learning Rate: 0.00501483
	LOSS [training: 0.2606509499714314 | validation: 0.20757523217813514]
	TIME [epoch: 19.2 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25193761466534276		[learning rate: 0.0049971]
	Learning Rate: 0.0049971
	LOSS [training: 0.25193761466534276 | validation: 0.21762126835639545]
	TIME [epoch: 19.2 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25612564500069407		[learning rate: 0.0049794]
	Learning Rate: 0.00497943
	LOSS [training: 0.25612564500069407 | validation: 0.21381725599881607]
	TIME [epoch: 19.2 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.259949104906186		[learning rate: 0.0049618]
	Learning Rate: 0.00496182
	LOSS [training: 0.259949104906186 | validation: 0.21121427366805784]
	TIME [epoch: 19.2 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25298277506976014		[learning rate: 0.0049443]
	Learning Rate: 0.00494427
	LOSS [training: 0.25298277506976014 | validation: 0.21083999713563525]
	TIME [epoch: 19.2 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2513088962655343		[learning rate: 0.0049268]
	Learning Rate: 0.00492679
	LOSS [training: 0.2513088962655343 | validation: 0.21065384528144993]
	TIME [epoch: 19.2 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2614386803866012		[learning rate: 0.0049094]
	Learning Rate: 0.00490937
	LOSS [training: 0.2614386803866012 | validation: 0.21208302193912282]
	TIME [epoch: 19.2 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26518165073665		[learning rate: 0.004892]
	Learning Rate: 0.00489201
	LOSS [training: 0.26518165073665 | validation: 0.21614169115674922]
	TIME [epoch: 19.2 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25624019997713227		[learning rate: 0.0048747]
	Learning Rate: 0.00487471
	LOSS [training: 0.25624019997713227 | validation: 0.20901363221211872]
	TIME [epoch: 19.2 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25635799816606497		[learning rate: 0.0048575]
	Learning Rate: 0.00485747
	LOSS [training: 0.25635799816606497 | validation: 0.20934477303212828]
	TIME [epoch: 19.2 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26044561847705133		[learning rate: 0.0048403]
	Learning Rate: 0.00484029
	LOSS [training: 0.26044561847705133 | validation: 0.2144030324375339]
	TIME [epoch: 19.2 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2516420140651474		[learning rate: 0.0048232]
	Learning Rate: 0.00482318
	LOSS [training: 0.2516420140651474 | validation: 0.21198670624295318]
	TIME [epoch: 19.2 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25338917963697943		[learning rate: 0.0048061]
	Learning Rate: 0.00480612
	LOSS [training: 0.25338917963697943 | validation: 0.21367352221052416]
	TIME [epoch: 19.2 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25168714451505125		[learning rate: 0.0047891]
	Learning Rate: 0.00478913
	LOSS [training: 0.25168714451505125 | validation: 0.2114869673217199]
	TIME [epoch: 19.2 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25167603283457224		[learning rate: 0.0047722]
	Learning Rate: 0.00477219
	LOSS [training: 0.25167603283457224 | validation: 0.21279579666880552]
	TIME [epoch: 19.2 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25711783682281575		[learning rate: 0.0047553]
	Learning Rate: 0.00475532
	LOSS [training: 0.25711783682281575 | validation: 0.21256520345952445]
	TIME [epoch: 19.2 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25755557588716493		[learning rate: 0.0047385]
	Learning Rate: 0.0047385
	LOSS [training: 0.25755557588716493 | validation: 0.2126475617927245]
	TIME [epoch: 19.2 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2588265953970326		[learning rate: 0.0047217]
	Learning Rate: 0.00472175
	LOSS [training: 0.2588265953970326 | validation: 0.22240210017540055]
	TIME [epoch: 19.3 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25685468981118326		[learning rate: 0.004705]
	Learning Rate: 0.00470505
	LOSS [training: 0.25685468981118326 | validation: 0.2139854653522928]
	TIME [epoch: 19.2 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25673898136533496		[learning rate: 0.0046884]
	Learning Rate: 0.00468841
	LOSS [training: 0.25673898136533496 | validation: 0.21062121568700282]
	TIME [epoch: 19.2 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25870391947671245		[learning rate: 0.0046718]
	Learning Rate: 0.00467183
	LOSS [training: 0.25870391947671245 | validation: 0.21008474351994305]
	TIME [epoch: 19.2 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25327669945766845		[learning rate: 0.0046553]
	Learning Rate: 0.00465531
	LOSS [training: 0.25327669945766845 | validation: 0.21506915613252273]
	TIME [epoch: 19.2 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2519519755310378		[learning rate: 0.0046388]
	Learning Rate: 0.00463885
	LOSS [training: 0.2519519755310378 | validation: 0.211350048110103]
	TIME [epoch: 19.2 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25200470248117707		[learning rate: 0.0046224]
	Learning Rate: 0.00462245
	LOSS [training: 0.25200470248117707 | validation: 0.21411960344309283]
	TIME [epoch: 19.2 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2649440387476025		[learning rate: 0.0046061]
	Learning Rate: 0.0046061
	LOSS [training: 0.2649440387476025 | validation: 0.20864999035901483]
	TIME [epoch: 19.2 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2560796941271689		[learning rate: 0.0045898]
	Learning Rate: 0.00458981
	LOSS [training: 0.2560796941271689 | validation: 0.21569098089353095]
	TIME [epoch: 19.2 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2473956335668311		[learning rate: 0.0045736]
	Learning Rate: 0.00457358
	LOSS [training: 0.2473956335668311 | validation: 0.2130334387585126]
	TIME [epoch: 19.2 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2521499051306026		[learning rate: 0.0045574]
	Learning Rate: 0.00455741
	LOSS [training: 0.2521499051306026 | validation: 0.2155744002440855]
	TIME [epoch: 19.2 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25610210674784195		[learning rate: 0.0045413]
	Learning Rate: 0.00454129
	LOSS [training: 0.25610210674784195 | validation: 0.21443700253534265]
	TIME [epoch: 19.2 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2629698059210827		[learning rate: 0.0045252]
	Learning Rate: 0.00452523
	LOSS [training: 0.2629698059210827 | validation: 0.2128667039881879]
	TIME [epoch: 19.2 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25370100575335597		[learning rate: 0.0045092]
	Learning Rate: 0.00450923
	LOSS [training: 0.25370100575335597 | validation: 0.2182163782073645]
	TIME [epoch: 19.2 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2605259023365057		[learning rate: 0.0044933]
	Learning Rate: 0.00449329
	LOSS [training: 0.2605259023365057 | validation: 0.2096994357269435]
	TIME [epoch: 19.2 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25483667351299777		[learning rate: 0.0044774]
	Learning Rate: 0.0044774
	LOSS [training: 0.25483667351299777 | validation: 0.2156286416613657]
	TIME [epoch: 19.2 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2522204141017576		[learning rate: 0.0044616]
	Learning Rate: 0.00446156
	LOSS [training: 0.2522204141017576 | validation: 0.20964701507574324]
	TIME [epoch: 19.2 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25535303149202937		[learning rate: 0.0044458]
	Learning Rate: 0.00444579
	LOSS [training: 0.25535303149202937 | validation: 0.2126743245095093]
	TIME [epoch: 19.2 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2664645464540065		[learning rate: 0.0044301]
	Learning Rate: 0.00443007
	LOSS [training: 0.2664645464540065 | validation: 0.2148698584555322]
	TIME [epoch: 19.2 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25348943261715134		[learning rate: 0.0044144]
	Learning Rate: 0.0044144
	LOSS [training: 0.25348943261715134 | validation: 0.2126747422779942]
	TIME [epoch: 19.2 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2542293412442654		[learning rate: 0.0043988]
	Learning Rate: 0.00439879
	LOSS [training: 0.2542293412442654 | validation: 0.21232490342291194]
	TIME [epoch: 19.2 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.253555113946727		[learning rate: 0.0043832]
	Learning Rate: 0.00438324
	LOSS [training: 0.253555113946727 | validation: 0.21185958623172096]
	TIME [epoch: 19.2 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25208205995078226		[learning rate: 0.0043677]
	Learning Rate: 0.00436774
	LOSS [training: 0.25208205995078226 | validation: 0.21094781309915261]
	TIME [epoch: 19.2 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.250079256932283		[learning rate: 0.0043523]
	Learning Rate: 0.00435229
	LOSS [training: 0.250079256932283 | validation: 0.21591273823780194]
	TIME [epoch: 19.2 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25051629928524477		[learning rate: 0.0043369]
	Learning Rate: 0.0043369
	LOSS [training: 0.25051629928524477 | validation: 0.21057626917833555]
	TIME [epoch: 19.2 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25180494716211693		[learning rate: 0.0043216]
	Learning Rate: 0.00432156
	LOSS [training: 0.25180494716211693 | validation: 0.21510510236413166]
	TIME [epoch: 19.2 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.257698321843614		[learning rate: 0.0043063]
	Learning Rate: 0.00430628
	LOSS [training: 0.257698321843614 | validation: 0.20862261990845163]
	TIME [epoch: 19.2 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2487255047621623		[learning rate: 0.0042911]
	Learning Rate: 0.00429106
	LOSS [training: 0.2487255047621623 | validation: 0.2219099157541596]
	TIME [epoch: 19.2 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2673514473830607		[learning rate: 0.0042759]
	Learning Rate: 0.00427588
	LOSS [training: 0.2673514473830607 | validation: 0.2147473449473421]
	TIME [epoch: 19.2 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26387878325938346		[learning rate: 0.0042608]
	Learning Rate: 0.00426076
	LOSS [training: 0.26387878325938346 | validation: 0.21068905415986974]
	TIME [epoch: 19.2 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2575104056998861		[learning rate: 0.0042457]
	Learning Rate: 0.00424569
	LOSS [training: 0.2575104056998861 | validation: 0.21437585213015317]
	TIME [epoch: 19.2 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2511355944031029		[learning rate: 0.0042307]
	Learning Rate: 0.00423068
	LOSS [training: 0.2511355944031029 | validation: 0.20759533190327514]
	TIME [epoch: 19.2 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2490590543043715		[learning rate: 0.0042157]
	Learning Rate: 0.00421572
	LOSS [training: 0.2490590543043715 | validation: 0.2111952931473255]
	TIME [epoch: 19.2 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2558823106499601		[learning rate: 0.0042008]
	Learning Rate: 0.00420081
	LOSS [training: 0.2558823106499601 | validation: 0.21659112878081538]
	TIME [epoch: 19.2 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2507976000678213		[learning rate: 0.004186]
	Learning Rate: 0.00418596
	LOSS [training: 0.2507976000678213 | validation: 0.21251232578010554]
	TIME [epoch: 19.2 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25371469870190705		[learning rate: 0.0041712]
	Learning Rate: 0.00417116
	LOSS [training: 0.25371469870190705 | validation: 0.21297066905909717]
	TIME [epoch: 19.2 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26160741745062926		[learning rate: 0.0041564]
	Learning Rate: 0.00415641
	LOSS [training: 0.26160741745062926 | validation: 0.20911413308827767]
	TIME [epoch: 19.2 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24754859518336123		[learning rate: 0.0041417]
	Learning Rate: 0.00414171
	LOSS [training: 0.24754859518336123 | validation: 0.21531980636792786]
	TIME [epoch: 19.2 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2517007769396566		[learning rate: 0.0041271]
	Learning Rate: 0.00412706
	LOSS [training: 0.2517007769396566 | validation: 0.21456528421622534]
	TIME [epoch: 19.2 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2504230043779942		[learning rate: 0.0041125]
	Learning Rate: 0.00411247
	LOSS [training: 0.2504230043779942 | validation: 0.21230680395093895]
	TIME [epoch: 19.2 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25011148725886173		[learning rate: 0.0040979]
	Learning Rate: 0.00409793
	LOSS [training: 0.25011148725886173 | validation: 0.20877337735512383]
	TIME [epoch: 19.2 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25240152491309337		[learning rate: 0.0040834]
	Learning Rate: 0.00408344
	LOSS [training: 0.25240152491309337 | validation: 0.20870019160988415]
	TIME [epoch: 19.2 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.252504443383986		[learning rate: 0.004069]
	Learning Rate: 0.004069
	LOSS [training: 0.252504443383986 | validation: 0.22950175085822822]
	TIME [epoch: 19.2 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25126325582435405		[learning rate: 0.0040546]
	Learning Rate: 0.00405461
	LOSS [training: 0.25126325582435405 | validation: 0.21415375771472805]
	TIME [epoch: 19.2 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24906099214232028		[learning rate: 0.0040403]
	Learning Rate: 0.00404027
	LOSS [training: 0.24906099214232028 | validation: 0.21166571275237783]
	TIME [epoch: 19.2 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2541693833072431		[learning rate: 0.004026]
	Learning Rate: 0.00402598
	LOSS [training: 0.2541693833072431 | validation: 0.21158325718662657]
	TIME [epoch: 19.2 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24796270770960716		[learning rate: 0.0040117]
	Learning Rate: 0.00401175
	LOSS [training: 0.24796270770960716 | validation: 0.2071409935497573]
	TIME [epoch: 19.2 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2553512953924768		[learning rate: 0.0039976]
	Learning Rate: 0.00399756
	LOSS [training: 0.2553512953924768 | validation: 0.21123496970473715]
	TIME [epoch: 19.2 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2527556287685127		[learning rate: 0.0039834]
	Learning Rate: 0.00398342
	LOSS [training: 0.2527556287685127 | validation: 0.22073605575153382]
	TIME [epoch: 19.2 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25686405440720805		[learning rate: 0.0039693]
	Learning Rate: 0.00396934
	LOSS [training: 0.25686405440720805 | validation: 0.21563037340463218]
	TIME [epoch: 19.2 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2529899684740708		[learning rate: 0.0039553]
	Learning Rate: 0.0039553
	LOSS [training: 0.2529899684740708 | validation: 0.22231701204675444]
	TIME [epoch: 19.2 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25075380194958097		[learning rate: 0.0039413]
	Learning Rate: 0.00394131
	LOSS [training: 0.25075380194958097 | validation: 0.21925106991530088]
	TIME [epoch: 19.2 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2510516098678121		[learning rate: 0.0039274]
	Learning Rate: 0.00392738
	LOSS [training: 0.2510516098678121 | validation: 0.20741912310351823]
	TIME [epoch: 19.2 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25347027647774295		[learning rate: 0.0039135]
	Learning Rate: 0.00391349
	LOSS [training: 0.25347027647774295 | validation: 0.2089696561573658]
	TIME [epoch: 19.2 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24873478977897587		[learning rate: 0.0038997]
	Learning Rate: 0.00389965
	LOSS [training: 0.24873478977897587 | validation: 0.21451453442980375]
	TIME [epoch: 19.2 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24959335011104475		[learning rate: 0.0038859]
	Learning Rate: 0.00388586
	LOSS [training: 0.24959335011104475 | validation: 0.2205528922795327]
	TIME [epoch: 19.2 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2569676962617067		[learning rate: 0.0038721]
	Learning Rate: 0.00387212
	LOSS [training: 0.2569676962617067 | validation: 0.21167896776745918]
	TIME [epoch: 19.2 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2438686978407684		[learning rate: 0.0038584]
	Learning Rate: 0.00385843
	LOSS [training: 0.2438686978407684 | validation: 0.21719162880686538]
	TIME [epoch: 19.2 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25785279229417213		[learning rate: 0.0038448]
	Learning Rate: 0.00384478
	LOSS [training: 0.25785279229417213 | validation: 0.2108408176060955]
	TIME [epoch: 19.2 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2517576902626481		[learning rate: 0.0038312]
	Learning Rate: 0.00383119
	LOSS [training: 0.2517576902626481 | validation: 0.21723716228285167]
	TIME [epoch: 19.2 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25518888697870057		[learning rate: 0.0038176]
	Learning Rate: 0.00381764
	LOSS [training: 0.25518888697870057 | validation: 0.20777959622285266]
	TIME [epoch: 19.2 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24751753203793062		[learning rate: 0.0038041]
	Learning Rate: 0.00380414
	LOSS [training: 0.24751753203793062 | validation: 0.20883473602585645]
	TIME [epoch: 19.2 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24539003249106353		[learning rate: 0.0037907]
	Learning Rate: 0.00379069
	LOSS [training: 0.24539003249106353 | validation: 0.21422408641232055]
	TIME [epoch: 19.2 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24817708576730269		[learning rate: 0.0037773]
	Learning Rate: 0.00377728
	LOSS [training: 0.24817708576730269 | validation: 0.215039129002845]
	TIME [epoch: 19.2 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24862204700390675		[learning rate: 0.0037639]
	Learning Rate: 0.00376393
	LOSS [training: 0.24862204700390675 | validation: 0.2231198434188409]
	TIME [epoch: 19.2 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25201793409573353		[learning rate: 0.0037506]
	Learning Rate: 0.00375062
	LOSS [training: 0.25201793409573353 | validation: 0.21543758640380126]
	TIME [epoch: 19.2 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2539671476273219		[learning rate: 0.0037374]
	Learning Rate: 0.00373735
	LOSS [training: 0.2539671476273219 | validation: 0.21294200210259948]
	TIME [epoch: 19.2 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2548142875696059		[learning rate: 0.0037241]
	Learning Rate: 0.00372414
	LOSS [training: 0.2548142875696059 | validation: 0.21399396544886287]
	TIME [epoch: 19.2 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2613448630064577		[learning rate: 0.003711]
	Learning Rate: 0.00371097
	LOSS [training: 0.2613448630064577 | validation: 0.20842948043593018]
	TIME [epoch: 19.2 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24992815620262865		[learning rate: 0.0036978]
	Learning Rate: 0.00369785
	LOSS [training: 0.24992815620262865 | validation: 0.2060698001042584]
	TIME [epoch: 19.2 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24660019085466087		[learning rate: 0.0036848]
	Learning Rate: 0.00368477
	LOSS [training: 0.24660019085466087 | validation: 0.20802976470207835]
	TIME [epoch: 19.2 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2555871959635066		[learning rate: 0.0036717]
	Learning Rate: 0.00367174
	LOSS [training: 0.2555871959635066 | validation: 0.21689775751013135]
	TIME [epoch: 19.2 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.250091453932276		[learning rate: 0.0036588]
	Learning Rate: 0.00365875
	LOSS [training: 0.250091453932276 | validation: 0.21444148236158705]
	TIME [epoch: 19.2 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25034347290068665		[learning rate: 0.0036458]
	Learning Rate: 0.00364582
	LOSS [training: 0.25034347290068665 | validation: 0.2153072278692175]
	TIME [epoch: 19.2 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2611235848827421		[learning rate: 0.0036329]
	Learning Rate: 0.00363292
	LOSS [training: 0.2611235848827421 | validation: 0.20907051328457774]
	TIME [epoch: 19.2 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25133055220711553		[learning rate: 0.0036201]
	Learning Rate: 0.00362008
	LOSS [training: 0.25133055220711553 | validation: 0.21923688206822728]
	TIME [epoch: 19.2 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25045405002887483		[learning rate: 0.0036073]
	Learning Rate: 0.00360728
	LOSS [training: 0.25045405002887483 | validation: 0.21011314601210085]
	TIME [epoch: 19.2 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2574505433435954		[learning rate: 0.0035945]
	Learning Rate: 0.00359452
	LOSS [training: 0.2574505433435954 | validation: 0.21914372833398388]
	TIME [epoch: 19.2 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2590739813029692		[learning rate: 0.0035818]
	Learning Rate: 0.00358181
	LOSS [training: 0.2590739813029692 | validation: 0.20951512066518294]
	TIME [epoch: 19.2 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25144439994516166		[learning rate: 0.0035691]
	Learning Rate: 0.00356914
	LOSS [training: 0.25144439994516166 | validation: 0.2132204607520598]
	TIME [epoch: 19.2 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24709018941005026		[learning rate: 0.0035565]
	Learning Rate: 0.00355652
	LOSS [training: 0.24709018941005026 | validation: 0.2168924901865231]
	TIME [epoch: 19.2 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24658150248268793		[learning rate: 0.0035439]
	Learning Rate: 0.00354395
	LOSS [training: 0.24658150248268793 | validation: 0.20935784612341912]
	TIME [epoch: 19.2 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2496342114927629		[learning rate: 0.0035314]
	Learning Rate: 0.00353141
	LOSS [training: 0.2496342114927629 | validation: 0.21317925204417848]
	TIME [epoch: 19.2 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24942754926699925		[learning rate: 0.0035189]
	Learning Rate: 0.00351893
	LOSS [training: 0.24942754926699925 | validation: 0.20937453714355453]
	TIME [epoch: 19.2 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24626888946912628		[learning rate: 0.0035065]
	Learning Rate: 0.00350648
	LOSS [training: 0.24626888946912628 | validation: 0.2080677847228983]
	TIME [epoch: 19.2 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24979447998035517		[learning rate: 0.0034941]
	Learning Rate: 0.00349408
	LOSS [training: 0.24979447998035517 | validation: 0.2127941958078238]
	TIME [epoch: 19.2 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.251924491019055		[learning rate: 0.0034817]
	Learning Rate: 0.00348173
	LOSS [training: 0.251924491019055 | validation: 0.21609941673276803]
	TIME [epoch: 19.2 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25170678451516426		[learning rate: 0.0034694]
	Learning Rate: 0.00346942
	LOSS [training: 0.25170678451516426 | validation: 0.21280427707907132]
	TIME [epoch: 19.2 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25559419175519404		[learning rate: 0.0034571]
	Learning Rate: 0.00345715
	LOSS [training: 0.25559419175519404 | validation: 0.215899386567191]
	TIME [epoch: 19.2 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2562373094226886		[learning rate: 0.0034449]
	Learning Rate: 0.00344492
	LOSS [training: 0.2562373094226886 | validation: 0.20824573523019935]
	TIME [epoch: 19.2 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2457784767257256		[learning rate: 0.0034327]
	Learning Rate: 0.00343274
	LOSS [training: 0.2457784767257256 | validation: 0.21567796123598332]
	TIME [epoch: 19.2 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2530832551829944		[learning rate: 0.0034206]
	Learning Rate: 0.0034206
	LOSS [training: 0.2530832551829944 | validation: 0.21515539679914322]
	TIME [epoch: 19.2 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.258486785750465		[learning rate: 0.0034085]
	Learning Rate: 0.00340851
	LOSS [training: 0.258486785750465 | validation: 0.21167185673202954]
	TIME [epoch: 19.2 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24764637654204966		[learning rate: 0.0033965]
	Learning Rate: 0.00339645
	LOSS [training: 0.24764637654204966 | validation: 0.20938822860555514]
	TIME [epoch: 19.2 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24914617840156703		[learning rate: 0.0033844]
	Learning Rate: 0.00338444
	LOSS [training: 0.24914617840156703 | validation: 0.20926611856372107]
	TIME [epoch: 19.2 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25050987147654363		[learning rate: 0.0033725]
	Learning Rate: 0.00337247
	LOSS [training: 0.25050987147654363 | validation: 0.20934106916155995]
	TIME [epoch: 19.2 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24579257070918414		[learning rate: 0.0033605]
	Learning Rate: 0.00336055
	LOSS [training: 0.24579257070918414 | validation: 0.2093894787794553]
	TIME [epoch: 19.2 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25010097966355		[learning rate: 0.0033487]
	Learning Rate: 0.00334867
	LOSS [training: 0.25010097966355 | validation: 0.2092373040230892]
	TIME [epoch: 19.2 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25318359517615296		[learning rate: 0.0033368]
	Learning Rate: 0.00333682
	LOSS [training: 0.25318359517615296 | validation: 0.21692461855636974]
	TIME [epoch: 19.2 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24583527287449172		[learning rate: 0.003325]
	Learning Rate: 0.00332502
	LOSS [training: 0.24583527287449172 | validation: 0.21635125941944994]
	TIME [epoch: 19.2 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25061647122150804		[learning rate: 0.0033133]
	Learning Rate: 0.00331327
	LOSS [training: 0.25061647122150804 | validation: 0.21285120868686835]
	TIME [epoch: 19.2 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2473445547536446		[learning rate: 0.0033016]
	Learning Rate: 0.00330155
	LOSS [training: 0.2473445547536446 | validation: 0.21498133801248476]
	TIME [epoch: 19.2 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25339848675671495		[learning rate: 0.0032899]
	Learning Rate: 0.00328988
	LOSS [training: 0.25339848675671495 | validation: 0.2164516240049225]
	TIME [epoch: 19.2 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2510177624631589		[learning rate: 0.0032782]
	Learning Rate: 0.00327824
	LOSS [training: 0.2510177624631589 | validation: 0.21008630537328238]
	TIME [epoch: 19.2 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2530383938935999		[learning rate: 0.0032666]
	Learning Rate: 0.00326665
	LOSS [training: 0.2530383938935999 | validation: 0.2146993089124185]
	TIME [epoch: 19.2 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24726583648987663		[learning rate: 0.0032551]
	Learning Rate: 0.0032551
	LOSS [training: 0.24726583648987663 | validation: 0.21205015130852306]
	TIME [epoch: 19.2 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2484441774604619		[learning rate: 0.0032436]
	Learning Rate: 0.00324359
	LOSS [training: 0.2484441774604619 | validation: 0.2109271764137175]
	TIME [epoch: 19.2 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24922895212567933		[learning rate: 0.0032321]
	Learning Rate: 0.00323212
	LOSS [training: 0.24922895212567933 | validation: 0.212090215482436]
	TIME [epoch: 19.2 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2470899522922548		[learning rate: 0.0032207]
	Learning Rate: 0.00322069
	LOSS [training: 0.2470899522922548 | validation: 0.21300809254662462]
	TIME [epoch: 19.2 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24893061077111836		[learning rate: 0.0032093]
	Learning Rate: 0.0032093
	LOSS [training: 0.24893061077111836 | validation: 0.21662965550035068]
	TIME [epoch: 19.2 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24930106906234242		[learning rate: 0.003198]
	Learning Rate: 0.00319795
	LOSS [training: 0.24930106906234242 | validation: 0.2106646467838909]
	TIME [epoch: 19.2 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24859654938286624		[learning rate: 0.0031866]
	Learning Rate: 0.00318664
	LOSS [training: 0.24859654938286624 | validation: 0.2096025060746666]
	TIME [epoch: 19.2 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25698169831584444		[learning rate: 0.0031754]
	Learning Rate: 0.00317537
	LOSS [training: 0.25698169831584444 | validation: 0.21050437817932072]
	TIME [epoch: 19.2 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2515429309692802		[learning rate: 0.0031641]
	Learning Rate: 0.00316415
	LOSS [training: 0.2515429309692802 | validation: 0.21378546958948563]
	TIME [epoch: 19.2 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.247660039465615		[learning rate: 0.003153]
	Learning Rate: 0.00315296
	LOSS [training: 0.247660039465615 | validation: 0.20637980407030812]
	TIME [epoch: 19.2 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24666767190196293		[learning rate: 0.0031418]
	Learning Rate: 0.00314181
	LOSS [training: 0.24666767190196293 | validation: 0.21289204492142316]
	TIME [epoch: 19.2 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24710148000942755		[learning rate: 0.0031307]
	Learning Rate: 0.0031307
	LOSS [training: 0.24710148000942755 | validation: 0.21453913936646468]
	TIME [epoch: 19.2 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2472459057252656		[learning rate: 0.0031196]
	Learning Rate: 0.00311963
	LOSS [training: 0.2472459057252656 | validation: 0.21560945884659674]
	TIME [epoch: 19.2 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24749857985089288		[learning rate: 0.0031086]
	Learning Rate: 0.00310859
	LOSS [training: 0.24749857985089288 | validation: 0.2142167596497769]
	TIME [epoch: 19.2 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25168383981141607		[learning rate: 0.0030976]
	Learning Rate: 0.0030976
	LOSS [training: 0.25168383981141607 | validation: 0.2076270653991923]
	TIME [epoch: 19.2 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2477540820170262		[learning rate: 0.0030866]
	Learning Rate: 0.00308665
	LOSS [training: 0.2477540820170262 | validation: 0.2128362022322013]
	TIME [epoch: 19.2 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2478743136733963		[learning rate: 0.0030757]
	Learning Rate: 0.00307573
	LOSS [training: 0.2478743136733963 | validation: 0.20588932439123736]
	TIME [epoch: 19.2 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2588491987586614		[learning rate: 0.0030649]
	Learning Rate: 0.00306486
	LOSS [training: 0.2588491987586614 | validation: 0.20938752126111612]
	TIME [epoch: 19.2 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2510655905239502		[learning rate: 0.003054]
	Learning Rate: 0.00305402
	LOSS [training: 0.2510655905239502 | validation: 0.21160637743762578]
	TIME [epoch: 19.2 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25325897666447134		[learning rate: 0.0030432]
	Learning Rate: 0.00304322
	LOSS [training: 0.25325897666447134 | validation: 0.21012673765745796]
	TIME [epoch: 19.2 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24916380023071252		[learning rate: 0.0030325]
	Learning Rate: 0.00303246
	LOSS [training: 0.24916380023071252 | validation: 0.21008600652084883]
	TIME [epoch: 19.2 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24545125681532476		[learning rate: 0.0030217]
	Learning Rate: 0.00302174
	LOSS [training: 0.24545125681532476 | validation: 0.21229037012897214]
	TIME [epoch: 19.2 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24940899569216204		[learning rate: 0.003011]
	Learning Rate: 0.00301105
	LOSS [training: 0.24940899569216204 | validation: 0.21198708154555074]
	TIME [epoch: 19.2 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24487354071144987		[learning rate: 0.0030004]
	Learning Rate: 0.0030004
	LOSS [training: 0.24487354071144987 | validation: 0.2160384308036288]
	TIME [epoch: 19.2 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2504520312996402		[learning rate: 0.0029898]
	Learning Rate: 0.00298979
	LOSS [training: 0.2504520312996402 | validation: 0.21221552843210878]
	TIME [epoch: 19.2 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24807243716814667		[learning rate: 0.0029792]
	Learning Rate: 0.00297922
	LOSS [training: 0.24807243716814667 | validation: 0.2155551902642731]
	TIME [epoch: 19.2 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25561243957231017		[learning rate: 0.0029687]
	Learning Rate: 0.00296869
	LOSS [training: 0.25561243957231017 | validation: 0.20875009075647338]
	TIME [epoch: 19.2 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2440507805303108		[learning rate: 0.0029582]
	Learning Rate: 0.00295819
	LOSS [training: 0.2440507805303108 | validation: 0.2096700533908126]
	TIME [epoch: 19.2 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2534721047046594		[learning rate: 0.0029477]
	Learning Rate: 0.00294773
	LOSS [training: 0.2534721047046594 | validation: 0.21363992543580718]
	TIME [epoch: 19.2 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24623876503846712		[learning rate: 0.0029373]
	Learning Rate: 0.0029373
	LOSS [training: 0.24623876503846712 | validation: 0.21597841353838693]
	TIME [epoch: 19.2 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2501865437027521		[learning rate: 0.0029269]
	Learning Rate: 0.00292692
	LOSS [training: 0.2501865437027521 | validation: 0.21315069768246886]
	TIME [epoch: 19.2 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24403965472185454		[learning rate: 0.0029166]
	Learning Rate: 0.00291657
	LOSS [training: 0.24403965472185454 | validation: 0.2170100871480763]
	TIME [epoch: 19.2 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25046990042980133		[learning rate: 0.0029063]
	Learning Rate: 0.00290625
	LOSS [training: 0.25046990042980133 | validation: 0.21246903868590178]
	TIME [epoch: 19.2 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2553167428594085		[learning rate: 0.002896]
	Learning Rate: 0.00289598
	LOSS [training: 0.2553167428594085 | validation: 0.215243066519993]
	TIME [epoch: 19.2 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24550479576808168		[learning rate: 0.0028857]
	Learning Rate: 0.00288573
	LOSS [training: 0.24550479576808168 | validation: 0.21133235521867794]
	TIME [epoch: 19.2 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25181288053339035		[learning rate: 0.0028755]
	Learning Rate: 0.00287553
	LOSS [training: 0.25181288053339035 | validation: 0.2076132378454724]
	TIME [epoch: 19.2 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24606537664664593		[learning rate: 0.0028654]
	Learning Rate: 0.00286536
	LOSS [training: 0.24606537664664593 | validation: 0.21159857306405358]
	TIME [epoch: 19.3 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24777366190141428		[learning rate: 0.0028552]
	Learning Rate: 0.00285523
	LOSS [training: 0.24777366190141428 | validation: 0.21139729107676525]
	TIME [epoch: 19.2 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24834534712137754		[learning rate: 0.0028451]
	Learning Rate: 0.00284513
	LOSS [training: 0.24834534712137754 | validation: 0.20473225160937258]
	TIME [epoch: 19.3 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12_20240719_004901/states/model_facs_v3_dec1b_2dpca_v12_405.pth
	Model improved!!!
EPOCH 406/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24550544611733263		[learning rate: 0.0028351]
	Learning Rate: 0.00283507
	LOSS [training: 0.24550544611733263 | validation: 0.21476422912237325]
	TIME [epoch: 19.2 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25607061859165187		[learning rate: 0.002825]
	Learning Rate: 0.00282505
	LOSS [training: 0.25607061859165187 | validation: 0.20921062078048247]
	TIME [epoch: 19.2 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2513255621423939		[learning rate: 0.0028151]
	Learning Rate: 0.00281506
	LOSS [training: 0.2513255621423939 | validation: 0.21246067013075615]
	TIME [epoch: 19.2 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24444013882934845		[learning rate: 0.0028051]
	Learning Rate: 0.0028051
	LOSS [training: 0.24444013882934845 | validation: 0.20844915393521307]
	TIME [epoch: 19.2 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25804845759031353		[learning rate: 0.0027952]
	Learning Rate: 0.00279518
	LOSS [training: 0.25804845759031353 | validation: 0.20725478343516474]
	TIME [epoch: 19.2 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2506532896151145		[learning rate: 0.0027853]
	Learning Rate: 0.0027853
	LOSS [training: 0.2506532896151145 | validation: 0.2095670672859556]
	TIME [epoch: 19.2 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.242098472272154		[learning rate: 0.0027754]
	Learning Rate: 0.00277545
	LOSS [training: 0.242098472272154 | validation: 0.21161360364079346]
	TIME [epoch: 19.2 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2453070996603733		[learning rate: 0.0027656]
	Learning Rate: 0.00276564
	LOSS [training: 0.2453070996603733 | validation: 0.21227155117413124]
	TIME [epoch: 19.2 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24724423814052696		[learning rate: 0.0027559]
	Learning Rate: 0.00275586
	LOSS [training: 0.24724423814052696 | validation: 0.21223634521226348]
	TIME [epoch: 19.2 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2484608457529108		[learning rate: 0.0027461]
	Learning Rate: 0.00274611
	LOSS [training: 0.2484608457529108 | validation: 0.20897629400156426]
	TIME [epoch: 19.2 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2492926261831737		[learning rate: 0.0027364]
	Learning Rate: 0.0027364
	LOSS [training: 0.2492926261831737 | validation: 0.21066859208683617]
	TIME [epoch: 19.2 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25130144897951895		[learning rate: 0.0027267]
	Learning Rate: 0.00272672
	LOSS [training: 0.25130144897951895 | validation: 0.21124062509967154]
	TIME [epoch: 19.2 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24993881383594674		[learning rate: 0.0027171]
	Learning Rate: 0.00271708
	LOSS [training: 0.24993881383594674 | validation: 0.21115965122940414]
	TIME [epoch: 19.2 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24932003577745743		[learning rate: 0.0027075]
	Learning Rate: 0.00270747
	LOSS [training: 0.24932003577745743 | validation: 0.21379022603642342]
	TIME [epoch: 19.2 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24952357147877177		[learning rate: 0.0026979]
	Learning Rate: 0.0026979
	LOSS [training: 0.24952357147877177 | validation: 0.21729089968220636]
	TIME [epoch: 19.2 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25337606525859296		[learning rate: 0.0026884]
	Learning Rate: 0.00268836
	LOSS [training: 0.25337606525859296 | validation: 0.21501496310201268]
	TIME [epoch: 19.2 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24849731228765867		[learning rate: 0.0026789]
	Learning Rate: 0.00267885
	LOSS [training: 0.24849731228765867 | validation: 0.21667060862935666]
	TIME [epoch: 19.2 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2507282926707368		[learning rate: 0.0026694]
	Learning Rate: 0.00266938
	LOSS [training: 0.2507282926707368 | validation: 0.20599991177985916]
	TIME [epoch: 19.2 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24971621315654122		[learning rate: 0.0026599]
	Learning Rate: 0.00265994
	LOSS [training: 0.24971621315654122 | validation: 0.2086867978899853]
	TIME [epoch: 19.2 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2502752549640365		[learning rate: 0.0026505]
	Learning Rate: 0.00265053
	LOSS [training: 0.2502752549640365 | validation: 0.20714756056710537]
	TIME [epoch: 19.2 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24791002077203192		[learning rate: 0.0026412]
	Learning Rate: 0.00264116
	LOSS [training: 0.24791002077203192 | validation: 0.21153700034514095]
	TIME [epoch: 19.2 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24525632725150368		[learning rate: 0.0026318]
	Learning Rate: 0.00263182
	LOSS [training: 0.24525632725150368 | validation: 0.21439957353034406]
	TIME [epoch: 19.2 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24991025179353907		[learning rate: 0.0026225]
	Learning Rate: 0.00262251
	LOSS [training: 0.24991025179353907 | validation: 0.2043438641483281]
	TIME [epoch: 19.2 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12_20240719_004901/states/model_facs_v3_dec1b_2dpca_v12_428.pth
	Model improved!!!
EPOCH 429/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24547612882316416		[learning rate: 0.0026132]
	Learning Rate: 0.00261324
	LOSS [training: 0.24547612882316416 | validation: 0.21007765712942908]
	TIME [epoch: 19.2 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26144706313204347		[learning rate: 0.002604]
	Learning Rate: 0.002604
	LOSS [training: 0.26144706313204347 | validation: 0.2106378462031564]
	TIME [epoch: 19.2 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.252356904145908		[learning rate: 0.0025948]
	Learning Rate: 0.00259479
	LOSS [training: 0.252356904145908 | validation: 0.20749784696966897]
	TIME [epoch: 19.2 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2525277149448842		[learning rate: 0.0025856]
	Learning Rate: 0.00258562
	LOSS [training: 0.2525277149448842 | validation: 0.2102257036293099]
	TIME [epoch: 19.2 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24415084553384866		[learning rate: 0.0025765]
	Learning Rate: 0.00257647
	LOSS [training: 0.24415084553384866 | validation: 0.213444163101971]
	TIME [epoch: 19.2 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24493553878019456		[learning rate: 0.0025674]
	Learning Rate: 0.00256736
	LOSS [training: 0.24493553878019456 | validation: 0.20761330173876055]
	TIME [epoch: 19.2 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2485333999499623		[learning rate: 0.0025583]
	Learning Rate: 0.00255828
	LOSS [training: 0.2485333999499623 | validation: 0.21205618353989544]
	TIME [epoch: 19.2 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2523549927021054		[learning rate: 0.0025492]
	Learning Rate: 0.00254924
	LOSS [training: 0.2523549927021054 | validation: 0.21031461799063805]
	TIME [epoch: 19.2 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2511515454876912		[learning rate: 0.0025402]
	Learning Rate: 0.00254022
	LOSS [training: 0.2511515454876912 | validation: 0.208474254545104]
	TIME [epoch: 19.2 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25541846931889045		[learning rate: 0.0025312]
	Learning Rate: 0.00253124
	LOSS [training: 0.25541846931889045 | validation: 0.20880436586366988]
	TIME [epoch: 19.2 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2509192756890366		[learning rate: 0.0025223]
	Learning Rate: 0.00252229
	LOSS [training: 0.2509192756890366 | validation: 0.21710748481260475]
	TIME [epoch: 19.2 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24438469562923046		[learning rate: 0.0025134]
	Learning Rate: 0.00251337
	LOSS [training: 0.24438469562923046 | validation: 0.2130989346618411]
	TIME [epoch: 19.2 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2500254583836929		[learning rate: 0.0025045]
	Learning Rate: 0.00250448
	LOSS [training: 0.2500254583836929 | validation: 0.21363029570504835]
	TIME [epoch: 19.2 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2543427623848137		[learning rate: 0.0024956]
	Learning Rate: 0.00249563
	LOSS [training: 0.2543427623848137 | validation: 0.21357022499657757]
	TIME [epoch: 19.2 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2495914795820208		[learning rate: 0.0024868]
	Learning Rate: 0.0024868
	LOSS [training: 0.2495914795820208 | validation: 0.20894825384456656]
	TIME [epoch: 19.2 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24980759626851276		[learning rate: 0.002478]
	Learning Rate: 0.00247801
	LOSS [training: 0.24980759626851276 | validation: 0.20871319044912018]
	TIME [epoch: 19.2 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25050964173454454		[learning rate: 0.0024692]
	Learning Rate: 0.00246924
	LOSS [training: 0.25050964173454454 | validation: 0.21063533372509413]
	TIME [epoch: 19.2 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24545201472873798		[learning rate: 0.0024605]
	Learning Rate: 0.00246051
	LOSS [training: 0.24545201472873798 | validation: 0.2167109285705387]
	TIME [epoch: 19.2 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24988592269611765		[learning rate: 0.0024518]
	Learning Rate: 0.00245181
	LOSS [training: 0.24988592269611765 | validation: 0.20724257676454655]
	TIME [epoch: 19.2 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2455171105859211		[learning rate: 0.0024431]
	Learning Rate: 0.00244314
	LOSS [training: 0.2455171105859211 | validation: 0.20925765863497933]
	TIME [epoch: 19.2 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2431689267551703		[learning rate: 0.0024345]
	Learning Rate: 0.0024345
	LOSS [training: 0.2431689267551703 | validation: 0.2146401674617287]
	TIME [epoch: 19.2 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24567361103895913		[learning rate: 0.0024259]
	Learning Rate: 0.00242589
	LOSS [training: 0.24567361103895913 | validation: 0.21017155653003847]
	TIME [epoch: 19.2 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24862008741194805		[learning rate: 0.0024173]
	Learning Rate: 0.00241732
	LOSS [training: 0.24862008741194805 | validation: 0.2141302361731487]
	TIME [epoch: 19.2 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25497772831032023		[learning rate: 0.0024088]
	Learning Rate: 0.00240877
	LOSS [training: 0.25497772831032023 | validation: 0.21581308521119852]
	TIME [epoch: 19.2 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25042621397523296		[learning rate: 0.0024002]
	Learning Rate: 0.00240025
	LOSS [training: 0.25042621397523296 | validation: 0.21079085133877765]
	TIME [epoch: 19.2 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24777891911410974		[learning rate: 0.0023918]
	Learning Rate: 0.00239176
	LOSS [training: 0.24777891911410974 | validation: 0.21291249859191802]
	TIME [epoch: 19.2 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2455645724701636		[learning rate: 0.0023833]
	Learning Rate: 0.0023833
	LOSS [training: 0.2455645724701636 | validation: 0.2098840675616404]
	TIME [epoch: 19.2 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24840023589169477		[learning rate: 0.0023749]
	Learning Rate: 0.00237488
	LOSS [training: 0.24840023589169477 | validation: 0.21537493319885873]
	TIME [epoch: 19.2 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2489207451729654		[learning rate: 0.0023665]
	Learning Rate: 0.00236648
	LOSS [training: 0.2489207451729654 | validation: 0.21629025337980928]
	TIME [epoch: 19.2 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25209370308548507		[learning rate: 0.0023581]
	Learning Rate: 0.00235811
	LOSS [training: 0.25209370308548507 | validation: 0.2120033239604167]
	TIME [epoch: 19.2 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2489643339596701		[learning rate: 0.0023498]
	Learning Rate: 0.00234977
	LOSS [training: 0.2489643339596701 | validation: 0.21109131460985786]
	TIME [epoch: 19.2 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.244691583609278		[learning rate: 0.0023415]
	Learning Rate: 0.00234146
	LOSS [training: 0.244691583609278 | validation: 0.2126163272699631]
	TIME [epoch: 19.2 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24665148346011498		[learning rate: 0.0023332]
	Learning Rate: 0.00233318
	LOSS [training: 0.24665148346011498 | validation: 0.21046166396515736]
	TIME [epoch: 19.2 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24790046753615855		[learning rate: 0.0023249]
	Learning Rate: 0.00232493
	LOSS [training: 0.24790046753615855 | validation: 0.2101599823154879]
	TIME [epoch: 19.2 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2447383674040482		[learning rate: 0.0023167]
	Learning Rate: 0.00231671
	LOSS [training: 0.2447383674040482 | validation: 0.21175798193057466]
	TIME [epoch: 19.2 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24226785594093062		[learning rate: 0.0023085]
	Learning Rate: 0.00230852
	LOSS [training: 0.24226785594093062 | validation: 0.20973640530048893]
	TIME [epoch: 19.2 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2522993123696948		[learning rate: 0.0023004]
	Learning Rate: 0.00230035
	LOSS [training: 0.2522993123696948 | validation: 0.21067156440775112]
	TIME [epoch: 19.2 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24636104366611364		[learning rate: 0.0022922]
	Learning Rate: 0.00229222
	LOSS [training: 0.24636104366611364 | validation: 0.21116883537059022]
	TIME [epoch: 19.2 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24537860944359235		[learning rate: 0.0022841]
	Learning Rate: 0.00228411
	LOSS [training: 0.24537860944359235 | validation: 0.21164743688314017]
	TIME [epoch: 19.2 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24141894325100602		[learning rate: 0.002276]
	Learning Rate: 0.00227604
	LOSS [training: 0.24141894325100602 | validation: 0.21336264178104775]
	TIME [epoch: 19.2 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24967316949482812		[learning rate: 0.002268]
	Learning Rate: 0.00226799
	LOSS [training: 0.24967316949482812 | validation: 0.20572458951134925]
	TIME [epoch: 19.3 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24833079757380794		[learning rate: 0.00226]
	Learning Rate: 0.00225997
	LOSS [training: 0.24833079757380794 | validation: 0.21376744543160378]
	TIME [epoch: 19.2 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24234393182945477		[learning rate: 0.002252]
	Learning Rate: 0.00225198
	LOSS [training: 0.24234393182945477 | validation: 0.2130581784255999]
	TIME [epoch: 19.2 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24616712636289126		[learning rate: 0.002244]
	Learning Rate: 0.00224401
	LOSS [training: 0.24616712636289126 | validation: 0.21023095538314857]
	TIME [epoch: 19.2 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2517943705951718		[learning rate: 0.0022361]
	Learning Rate: 0.00223608
	LOSS [training: 0.2517943705951718 | validation: 0.21006145154887648]
	TIME [epoch: 19.2 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2512936703239243		[learning rate: 0.0022282]
	Learning Rate: 0.00222817
	LOSS [training: 0.2512936703239243 | validation: 0.216037316048811]
	TIME [epoch: 19.2 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24499521955713952		[learning rate: 0.0022203]
	Learning Rate: 0.00222029
	LOSS [training: 0.24499521955713952 | validation: 0.21400403115246164]
	TIME [epoch: 19.3 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24825949220570018		[learning rate: 0.0022124]
	Learning Rate: 0.00221244
	LOSS [training: 0.24825949220570018 | validation: 0.21162075816254342]
	TIME [epoch: 19.2 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24522150341217216		[learning rate: 0.0022046]
	Learning Rate: 0.00220462
	LOSS [training: 0.24522150341217216 | validation: 0.21662925390691537]
	TIME [epoch: 19.2 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2462706253104807		[learning rate: 0.0021968]
	Learning Rate: 0.00219682
	LOSS [training: 0.2462706253104807 | validation: 0.21058432188806325]
	TIME [epoch: 19.2 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24359219926770495		[learning rate: 0.0021891]
	Learning Rate: 0.00218905
	LOSS [training: 0.24359219926770495 | validation: 0.20946817077222457]
	TIME [epoch: 19.2 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24532437835635393		[learning rate: 0.0021813]
	Learning Rate: 0.00218131
	LOSS [training: 0.24532437835635393 | validation: 0.21039772313493957]
	TIME [epoch: 19.2 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24811440388740022		[learning rate: 0.0021736]
	Learning Rate: 0.0021736
	LOSS [training: 0.24811440388740022 | validation: 0.23600623147676716]
	TIME [epoch: 19.2 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26898684129963485		[learning rate: 0.0021659]
	Learning Rate: 0.00216591
	LOSS [training: 0.26898684129963485 | validation: 0.23484914221210212]
	TIME [epoch: 19.2 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2534806300609812		[learning rate: 0.0021583]
	Learning Rate: 0.00215825
	LOSS [training: 0.2534806300609812 | validation: 0.22074135884875262]
	TIME [epoch: 19.2 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2493677558971429		[learning rate: 0.0021506]
	Learning Rate: 0.00215062
	LOSS [training: 0.2493677558971429 | validation: 0.21720248382025095]
	TIME [epoch: 19.2 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24773839040277054		[learning rate: 0.002143]
	Learning Rate: 0.00214302
	LOSS [training: 0.24773839040277054 | validation: 0.21368233094661596]
	TIME [epoch: 19.2 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.248441247457442		[learning rate: 0.0021354]
	Learning Rate: 0.00213544
	LOSS [training: 0.248441247457442 | validation: 0.21392946787783118]
	TIME [epoch: 19.2 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2415701545938397		[learning rate: 0.0021279]
	Learning Rate: 0.00212789
	LOSS [training: 0.2415701545938397 | validation: 0.2153331557392281]
	TIME [epoch: 19.3 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24583610316165286		[learning rate: 0.0021204]
	Learning Rate: 0.00212036
	LOSS [training: 0.24583610316165286 | validation: 0.21531788524946846]
	TIME [epoch: 19.2 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24361623061176943		[learning rate: 0.0021129]
	Learning Rate: 0.00211287
	LOSS [training: 0.24361623061176943 | validation: 0.2110149314377975]
	TIME [epoch: 19.2 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24518125311957162		[learning rate: 0.0021054]
	Learning Rate: 0.00210539
	LOSS [training: 0.24518125311957162 | validation: 0.2107538262243514]
	TIME [epoch: 19.2 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24623316377071133		[learning rate: 0.0020979]
	Learning Rate: 0.00209795
	LOSS [training: 0.24623316377071133 | validation: 0.21452245812502824]
	TIME [epoch: 19.2 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24632267821400042		[learning rate: 0.0020905]
	Learning Rate: 0.00209053
	LOSS [training: 0.24632267821400042 | validation: 0.20749616019567715]
	TIME [epoch: 19.2 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24273331280949065		[learning rate: 0.0020831]
	Learning Rate: 0.00208314
	LOSS [training: 0.24273331280949065 | validation: 0.21109971349450046]
	TIME [epoch: 19.2 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24319964564833052		[learning rate: 0.0020758]
	Learning Rate: 0.00207577
	LOSS [training: 0.24319964564833052 | validation: 0.2080231151999908]
	TIME [epoch: 19.2 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24258628538610083		[learning rate: 0.0020684]
	Learning Rate: 0.00206843
	LOSS [training: 0.24258628538610083 | validation: 0.21152919140694254]
	TIME [epoch: 19.2 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24339978760008207		[learning rate: 0.0020611]
	Learning Rate: 0.00206112
	LOSS [training: 0.24339978760008207 | validation: 0.207585973522544]
	TIME [epoch: 19.2 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25053709322949547		[learning rate: 0.0020538]
	Learning Rate: 0.00205383
	LOSS [training: 0.25053709322949547 | validation: 0.2070125454705689]
	TIME [epoch: 19.2 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2453769824617907		[learning rate: 0.0020466]
	Learning Rate: 0.00204657
	LOSS [training: 0.2453769824617907 | validation: 0.20611075813423096]
	TIME [epoch: 19.2 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24589077932114742		[learning rate: 0.0020393]
	Learning Rate: 0.00203933
	LOSS [training: 0.24589077932114742 | validation: 0.20760508937194416]
	TIME [epoch: 19.2 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24644408133965792		[learning rate: 0.0020321]
	Learning Rate: 0.00203212
	LOSS [training: 0.24644408133965792 | validation: 0.20866432547574215]
	TIME [epoch: 19.2 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24418124979169387		[learning rate: 0.0020249]
	Learning Rate: 0.00202493
	LOSS [training: 0.24418124979169387 | validation: 0.21281525622809805]
	TIME [epoch: 57.6 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24744752301341613		[learning rate: 0.0020178]
	Learning Rate: 0.00201777
	LOSS [training: 0.24744752301341613 | validation: 0.20721915929282492]
	TIME [epoch: 40.9 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2414740997204203		[learning rate: 0.0020106]
	Learning Rate: 0.00201064
	LOSS [training: 0.2414740997204203 | validation: 0.2119651925861777]
	TIME [epoch: 40.9 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2500340116452772		[learning rate: 0.0020035]
	Learning Rate: 0.00200353
	LOSS [training: 0.2500340116452772 | validation: 0.2101387903084885]
	TIME [epoch: 41 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2448158146964279		[learning rate: 0.0019964]
	Learning Rate: 0.00199644
	LOSS [training: 0.2448158146964279 | validation: 0.20619667710017375]
	TIME [epoch: 41 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24511557175023033		[learning rate: 0.0019894]
	Learning Rate: 0.00198938
	LOSS [training: 0.24511557175023033 | validation: 0.2115072548884772]
	TIME [epoch: 40.9 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24457490249263789		[learning rate: 0.0019823]
	Learning Rate: 0.00198235
	LOSS [training: 0.24457490249263789 | validation: 0.20981042133945899]
	TIME [epoch: 41 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24515650575964562		[learning rate: 0.0019753]
	Learning Rate: 0.00197534
	LOSS [training: 0.24515650575964562 | validation: 0.21261053144861886]
	TIME [epoch: 40.9 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24234575635396605		[learning rate: 0.0019684]
	Learning Rate: 0.00196835
	LOSS [training: 0.24234575635396605 | validation: 0.21542688659458512]
	TIME [epoch: 40.9 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24664407023966847		[learning rate: 0.0019614]
	Learning Rate: 0.00196139
	LOSS [training: 0.24664407023966847 | validation: 0.2082360833256462]
	TIME [epoch: 41 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24154107021628227		[learning rate: 0.0019545]
	Learning Rate: 0.00195445
	LOSS [training: 0.24154107021628227 | validation: 0.2124838046237497]
	TIME [epoch: 40.9 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2518406136905327		[learning rate: 0.0019475]
	Learning Rate: 0.00194754
	LOSS [training: 0.2518406136905327 | validation: 0.21389219549398225]
	TIME [epoch: 40.9 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2464064629636923		[learning rate: 0.0019407]
	Learning Rate: 0.00194066
	LOSS [training: 0.2464064629636923 | validation: 0.21720652971727333]
	TIME [epoch: 41 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24880632543676148		[learning rate: 0.0019338]
	Learning Rate: 0.00193379
	LOSS [training: 0.24880632543676148 | validation: 0.20686616371190053]
	TIME [epoch: 40.9 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24482530407077507		[learning rate: 0.001927]
	Learning Rate: 0.00192696
	LOSS [training: 0.24482530407077507 | validation: 0.21138622415169506]
	TIME [epoch: 40.9 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24109537930742683		[learning rate: 0.0019201]
	Learning Rate: 0.00192014
	LOSS [training: 0.24109537930742683 | validation: 0.20862553306115714]
	TIME [epoch: 40.9 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2475978158535237		[learning rate: 0.0019134]
	Learning Rate: 0.00191335
	LOSS [training: 0.2475978158535237 | validation: 0.21420510641080187]
	TIME [epoch: 41 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24036918916000963		[learning rate: 0.0019066]
	Learning Rate: 0.00190659
	LOSS [training: 0.24036918916000963 | validation: 0.20628038148735342]
	TIME [epoch: 40.9 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24059236732725206		[learning rate: 0.0018998]
	Learning Rate: 0.00189984
	LOSS [training: 0.24059236732725206 | validation: 0.20801720378651467]
	TIME [epoch: 40.9 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25245481396008324		[learning rate: 0.0018931]
	Learning Rate: 0.00189313
	LOSS [training: 0.25245481396008324 | validation: 0.2082039446608832]
	TIME [epoch: 40.9 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2454293760456295		[learning rate: 0.0018864]
	Learning Rate: 0.00188643
	LOSS [training: 0.2454293760456295 | validation: 0.21235857511236697]
	TIME [epoch: 40.9 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24037326956436708		[learning rate: 0.0018798]
	Learning Rate: 0.00187976
	LOSS [training: 0.24037326956436708 | validation: 0.20725859996412116]
	TIME [epoch: 41 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2412537395992279		[learning rate: 0.0018731]
	Learning Rate: 0.00187311
	LOSS [training: 0.2412537395992279 | validation: 0.21223221696671946]
	TIME [epoch: 41 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24333671270800414		[learning rate: 0.0018665]
	Learning Rate: 0.00186649
	LOSS [training: 0.24333671270800414 | validation: 0.21124099052467032]
	TIME [epoch: 40.9 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24282958643044014		[learning rate: 0.0018599]
	Learning Rate: 0.00185989
	LOSS [training: 0.24282958643044014 | validation: 0.21223130527074]
	TIME [epoch: 40.9 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24392539528446336		[learning rate: 0.0018533]
	Learning Rate: 0.00185331
	LOSS [training: 0.24392539528446336 | validation: 0.2108305276777318]
	TIME [epoch: 41 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24678172599771006		[learning rate: 0.0018468]
	Learning Rate: 0.00184676
	LOSS [training: 0.24678172599771006 | validation: 0.2113720681509772]
	TIME [epoch: 41 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24739671984236797		[learning rate: 0.0018402]
	Learning Rate: 0.00184023
	LOSS [training: 0.24739671984236797 | validation: 0.2096030737471843]
	TIME [epoch: 40.9 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.250441480955272		[learning rate: 0.0018337]
	Learning Rate: 0.00183372
	LOSS [training: 0.250441480955272 | validation: 0.20866096779366225]
	TIME [epoch: 40.9 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2488438684052671		[learning rate: 0.0018272]
	Learning Rate: 0.00182724
	LOSS [training: 0.2488438684052671 | validation: 0.20875141059004027]
	TIME [epoch: 41 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24805198654686145		[learning rate: 0.0018208]
	Learning Rate: 0.00182078
	LOSS [training: 0.24805198654686145 | validation: 0.2062960688211061]
	TIME [epoch: 41 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24561424673751994		[learning rate: 0.0018143]
	Learning Rate: 0.00181434
	LOSS [training: 0.24561424673751994 | validation: 0.21019792678259588]
	TIME [epoch: 41 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24512719633625749		[learning rate: 0.0018079]
	Learning Rate: 0.00180792
	LOSS [training: 0.24512719633625749 | validation: 0.20865781227419525]
	TIME [epoch: 41 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2448053725396678		[learning rate: 0.0018015]
	Learning Rate: 0.00180153
	LOSS [training: 0.2448053725396678 | validation: 0.20789500942542544]
	TIME [epoch: 41 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2428611641680162		[learning rate: 0.0017952]
	Learning Rate: 0.00179516
	LOSS [training: 0.2428611641680162 | validation: 0.20625057586338347]
	TIME [epoch: 41 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23956324375574634		[learning rate: 0.0017888]
	Learning Rate: 0.00178881
	LOSS [training: 0.23956324375574634 | validation: 0.2082746742581622]
	TIME [epoch: 40.9 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24361613726955686		[learning rate: 0.0017825]
	Learning Rate: 0.00178248
	LOSS [training: 0.24361613726955686 | validation: 0.20794716464199778]
	TIME [epoch: 41 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24023291304140157		[learning rate: 0.0017762]
	Learning Rate: 0.00177618
	LOSS [training: 0.24023291304140157 | validation: 0.20930831434613717]
	TIME [epoch: 40.9 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24451430596116622		[learning rate: 0.0017699]
	Learning Rate: 0.0017699
	LOSS [training: 0.24451430596116622 | validation: 0.21343705010891262]
	TIME [epoch: 40.9 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2477251606205604		[learning rate: 0.0017636]
	Learning Rate: 0.00176364
	LOSS [training: 0.2477251606205604 | validation: 0.21423841249452594]
	TIME [epoch: 40.9 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2438914781066822		[learning rate: 0.0017574]
	Learning Rate: 0.0017574
	LOSS [training: 0.2438914781066822 | validation: 0.21370471563433996]
	TIME [epoch: 40.9 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25085066085054347		[learning rate: 0.0017512]
	Learning Rate: 0.00175119
	LOSS [training: 0.25085066085054347 | validation: 0.2136329180877738]
	TIME [epoch: 40.9 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2461676746539444		[learning rate: 0.001745]
	Learning Rate: 0.001745
	LOSS [training: 0.2461676746539444 | validation: 0.2096470729705177]
	TIME [epoch: 41 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24870539737556363		[learning rate: 0.0017388]
	Learning Rate: 0.00173883
	LOSS [training: 0.24870539737556363 | validation: 0.20897636849404946]
	TIME [epoch: 40.9 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24269464755140577		[learning rate: 0.0017327]
	Learning Rate: 0.00173268
	LOSS [training: 0.24269464755140577 | validation: 0.20695534752939096]
	TIME [epoch: 40.9 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24702988587004945		[learning rate: 0.0017266]
	Learning Rate: 0.00172655
	LOSS [training: 0.24702988587004945 | validation: 0.2096157570673272]
	TIME [epoch: 40.9 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24618903370849685		[learning rate: 0.0017204]
	Learning Rate: 0.00172045
	LOSS [training: 0.24618903370849685 | validation: 0.210601749905714]
	TIME [epoch: 41 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24922751651142241		[learning rate: 0.0017144]
	Learning Rate: 0.00171436
	LOSS [training: 0.24922751651142241 | validation: 0.20975081968638679]
	TIME [epoch: 40.9 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24439558408587017		[learning rate: 0.0017083]
	Learning Rate: 0.0017083
	LOSS [training: 0.24439558408587017 | validation: 0.20997182086577304]
	TIME [epoch: 41 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24965343032340218		[learning rate: 0.0017023]
	Learning Rate: 0.00170226
	LOSS [training: 0.24965343032340218 | validation: 0.2048298688412126]
	TIME [epoch: 40.9 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24081392030292004		[learning rate: 0.0016962]
	Learning Rate: 0.00169624
	LOSS [training: 0.24081392030292004 | validation: 0.20888691290778844]
	TIME [epoch: 40.9 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2430330525181926		[learning rate: 0.0016902]
	Learning Rate: 0.00169024
	LOSS [training: 0.2430330525181926 | validation: 0.20939951199588255]
	TIME [epoch: 41 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24509540048989256		[learning rate: 0.0016843]
	Learning Rate: 0.00168426
	LOSS [training: 0.24509540048989256 | validation: 0.21113485762702236]
	TIME [epoch: 41 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24669490229445631		[learning rate: 0.0016783]
	Learning Rate: 0.00167831
	LOSS [training: 0.24669490229445631 | validation: 0.21580852160706127]
	TIME [epoch: 40.9 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24565803250619297		[learning rate: 0.0016724]
	Learning Rate: 0.00167237
	LOSS [training: 0.24565803250619297 | validation: 0.21301132917061488]
	TIME [epoch: 41 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2420534029213783		[learning rate: 0.0016665]
	Learning Rate: 0.00166646
	LOSS [training: 0.2420534029213783 | validation: 0.20873724568027735]
	TIME [epoch: 41 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24513766287327288		[learning rate: 0.0016606]
	Learning Rate: 0.00166057
	LOSS [training: 0.24513766287327288 | validation: 0.20987903832875668]
	TIME [epoch: 40.9 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2407889415530602		[learning rate: 0.0016547]
	Learning Rate: 0.00165469
	LOSS [training: 0.2407889415530602 | validation: 0.2127315319086322]
	TIME [epoch: 40.9 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24293039410517514		[learning rate: 0.0016488]
	Learning Rate: 0.00164884
	LOSS [training: 0.24293039410517514 | validation: 0.20927397650561752]
	TIME [epoch: 40.9 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24625158027887348		[learning rate: 0.001643]
	Learning Rate: 0.00164301
	LOSS [training: 0.24625158027887348 | validation: 0.21038850013289334]
	TIME [epoch: 40.9 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24014896686784873		[learning rate: 0.0016372]
	Learning Rate: 0.0016372
	LOSS [training: 0.24014896686784873 | validation: 0.21062923012631632]
	TIME [epoch: 41 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.247698975320126		[learning rate: 0.0016314]
	Learning Rate: 0.00163141
	LOSS [training: 0.247698975320126 | validation: 0.2121367134229149]
	TIME [epoch: 41 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2474211643905866		[learning rate: 0.0016256]
	Learning Rate: 0.00162564
	LOSS [training: 0.2474211643905866 | validation: 0.20934328294813792]
	TIME [epoch: 41 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24563578963211893		[learning rate: 0.0016199]
	Learning Rate: 0.0016199
	LOSS [training: 0.24563578963211893 | validation: 0.20935401001702864]
	TIME [epoch: 40.9 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24249775580772415		[learning rate: 0.0016142]
	Learning Rate: 0.00161417
	LOSS [training: 0.24249775580772415 | validation: 0.20803910217493068]
	TIME [epoch: 41 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24238912055424564		[learning rate: 0.0016085]
	Learning Rate: 0.00160846
	LOSS [training: 0.24238912055424564 | validation: 0.21152833716168912]
	TIME [epoch: 40.9 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.242204227072878		[learning rate: 0.0016028]
	Learning Rate: 0.00160277
	LOSS [training: 0.242204227072878 | validation: 0.2108365840917661]
	TIME [epoch: 40.9 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24275427438807703		[learning rate: 0.0015971]
	Learning Rate: 0.0015971
	LOSS [training: 0.24275427438807703 | validation: 0.20552864887179786]
	TIME [epoch: 41 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.242978947556542		[learning rate: 0.0015915]
	Learning Rate: 0.00159146
	LOSS [training: 0.242978947556542 | validation: 0.20816782986026436]
	TIME [epoch: 41 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24338552259682023		[learning rate: 0.0015858]
	Learning Rate: 0.00158583
	LOSS [training: 0.24338552259682023 | validation: 0.2080582794118257]
	TIME [epoch: 40.9 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24472253460498247		[learning rate: 0.0015802]
	Learning Rate: 0.00158022
	LOSS [training: 0.24472253460498247 | validation: 0.2084676221716178]
	TIME [epoch: 41 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24742884233187912		[learning rate: 0.0015746]
	Learning Rate: 0.00157463
	LOSS [training: 0.24742884233187912 | validation: 0.20741518239555376]
	TIME [epoch: 40.9 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24608053032884933		[learning rate: 0.0015691]
	Learning Rate: 0.00156907
	LOSS [training: 0.24608053032884933 | validation: 0.21054831749569755]
	TIME [epoch: 41 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24490117823193214		[learning rate: 0.0015635]
	Learning Rate: 0.00156352
	LOSS [training: 0.24490117823193214 | validation: 0.2061163617150787]
	TIME [epoch: 41 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24665766752512128		[learning rate: 0.001558]
	Learning Rate: 0.00155799
	LOSS [training: 0.24665766752512128 | validation: 0.21315411036338455]
	TIME [epoch: 40.9 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24220142683579673		[learning rate: 0.0015525]
	Learning Rate: 0.00155248
	LOSS [training: 0.24220142683579673 | validation: 0.21318426919646769]
	TIME [epoch: 40.9 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2455654584211563		[learning rate: 0.001547]
	Learning Rate: 0.00154699
	LOSS [training: 0.2455654584211563 | validation: 0.2068950517194809]
	TIME [epoch: 40.9 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24267620518872554		[learning rate: 0.0015415]
	Learning Rate: 0.00154152
	LOSS [training: 0.24267620518872554 | validation: 0.21032768078757808]
	TIME [epoch: 40.9 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24735322608117494		[learning rate: 0.0015361]
	Learning Rate: 0.00153607
	LOSS [training: 0.24735322608117494 | validation: 0.2096913469933072]
	TIME [epoch: 40.9 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24550288086047836		[learning rate: 0.0015306]
	Learning Rate: 0.00153064
	LOSS [training: 0.24550288086047836 | validation: 0.2102257293389344]
	TIME [epoch: 40.9 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24371962548000145		[learning rate: 0.0015252]
	Learning Rate: 0.00152522
	LOSS [training: 0.24371962548000145 | validation: 0.20542357614675236]
	TIME [epoch: 41 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24671660438640775		[learning rate: 0.0015198]
	Learning Rate: 0.00151983
	LOSS [training: 0.24671660438640775 | validation: 0.20499115791221403]
	TIME [epoch: 41 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24291986868031054		[learning rate: 0.0015145]
	Learning Rate: 0.00151446
	LOSS [training: 0.24291986868031054 | validation: 0.2081469273120883]
	TIME [epoch: 41 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24048361149352593		[learning rate: 0.0015091]
	Learning Rate: 0.0015091
	LOSS [training: 0.24048361149352593 | validation: 0.20995486609335226]
	TIME [epoch: 41 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2469564959929507		[learning rate: 0.0015038]
	Learning Rate: 0.00150376
	LOSS [training: 0.2469564959929507 | validation: 0.20625666995847852]
	TIME [epoch: 40.9 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24321432471891194		[learning rate: 0.0014984]
	Learning Rate: 0.00149845
	LOSS [training: 0.24321432471891194 | validation: 0.20871731363536922]
	TIME [epoch: 40.9 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2432412222097549		[learning rate: 0.0014931]
	Learning Rate: 0.00149315
	LOSS [training: 0.2432412222097549 | validation: 0.20964920435746565]
	TIME [epoch: 41 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24322573410127477		[learning rate: 0.0014879]
	Learning Rate: 0.00148787
	LOSS [training: 0.24322573410127477 | validation: 0.20727004818619554]
	TIME [epoch: 40.9 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24426565886932503		[learning rate: 0.0014826]
	Learning Rate: 0.00148261
	LOSS [training: 0.24426565886932503 | validation: 0.20378920481907228]
	TIME [epoch: 40.9 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12_20240719_004901/states/model_facs_v3_dec1b_2dpca_v12_589.pth
	Model improved!!!
EPOCH 590/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2426574998403674		[learning rate: 0.0014774]
	Learning Rate: 0.00147736
	LOSS [training: 0.2426574998403674 | validation: 0.20831342569093664]
	TIME [epoch: 41 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24407887999157682		[learning rate: 0.0014721]
	Learning Rate: 0.00147214
	LOSS [training: 0.24407887999157682 | validation: 0.20956087246357974]
	TIME [epoch: 41 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24206367370481865		[learning rate: 0.0014669]
	Learning Rate: 0.00146693
	LOSS [training: 0.24206367370481865 | validation: 0.2111405179491502]
	TIME [epoch: 41 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24316535513989643		[learning rate: 0.0014617]
	Learning Rate: 0.00146175
	LOSS [training: 0.24316535513989643 | validation: 0.20920838459207153]
	TIME [epoch: 41 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24125788731268027		[learning rate: 0.0014566]
	Learning Rate: 0.00145658
	LOSS [training: 0.24125788731268027 | validation: 0.20772791058376489]
	TIME [epoch: 40.9 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24257874715715144		[learning rate: 0.0014514]
	Learning Rate: 0.00145143
	LOSS [training: 0.24257874715715144 | validation: 0.2069340767550875]
	TIME [epoch: 40.9 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24044666269626735		[learning rate: 0.0014463]
	Learning Rate: 0.00144629
	LOSS [training: 0.24044666269626735 | validation: 0.20991166336838232]
	TIME [epoch: 41 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24547021847847442		[learning rate: 0.0014412]
	Learning Rate: 0.00144118
	LOSS [training: 0.24547021847847442 | validation: 0.22308453440007175]
	TIME [epoch: 41 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2454543597667327		[learning rate: 0.0014361]
	Learning Rate: 0.00143608
	LOSS [training: 0.2454543597667327 | validation: 0.21605488397318426]
	TIME [epoch: 40.9 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2450232017594294		[learning rate: 0.001431]
	Learning Rate: 0.001431
	LOSS [training: 0.2450232017594294 | validation: 0.21307600018890044]
	TIME [epoch: 41 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24042383544125057		[learning rate: 0.0014259]
	Learning Rate: 0.00142594
	LOSS [training: 0.24042383544125057 | validation: 0.21074051686741183]
	TIME [epoch: 40.9 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24020047583854945		[learning rate: 0.0014209]
	Learning Rate: 0.0014209
	LOSS [training: 0.24020047583854945 | validation: 0.21302827608247007]
	TIME [epoch: 41 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2453851250462206		[learning rate: 0.0014159]
	Learning Rate: 0.00141588
	LOSS [training: 0.2453851250462206 | validation: 0.21175275553514283]
	TIME [epoch: 40.9 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24174958315464257		[learning rate: 0.0014109]
	Learning Rate: 0.00141087
	LOSS [training: 0.24174958315464257 | validation: 0.21158783267720893]
	TIME [epoch: 41 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.242887028915767		[learning rate: 0.0014059]
	Learning Rate: 0.00140588
	LOSS [training: 0.242887028915767 | validation: 0.20793134838517555]
	TIME [epoch: 40.9 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24456482974777397		[learning rate: 0.0014009]
	Learning Rate: 0.00140091
	LOSS [training: 0.24456482974777397 | validation: 0.2082756241492893]
	TIME [epoch: 40.9 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24541662105707515		[learning rate: 0.001396]
	Learning Rate: 0.00139596
	LOSS [training: 0.24541662105707515 | validation: 0.2088115662008559]
	TIME [epoch: 41 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24466848722530452		[learning rate: 0.001391]
	Learning Rate: 0.00139102
	LOSS [training: 0.24466848722530452 | validation: 0.2121195184936555]
	TIME [epoch: 41 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23957497423641683		[learning rate: 0.0013861]
	Learning Rate: 0.0013861
	LOSS [training: 0.23957497423641683 | validation: 0.2038232127615951]
	TIME [epoch: 40.9 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24452536913127423		[learning rate: 0.0013812]
	Learning Rate: 0.0013812
	LOSS [training: 0.24452536913127423 | validation: 0.20975296614999928]
	TIME [epoch: 41 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24583647591674226		[learning rate: 0.0013763]
	Learning Rate: 0.00137632
	LOSS [training: 0.24583647591674226 | validation: 0.20833828970724574]
	TIME [epoch: 40.9 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24908776745530445		[learning rate: 0.0013714]
	Learning Rate: 0.00137145
	LOSS [training: 0.24908776745530445 | validation: 0.20659390464925198]
	TIME [epoch: 41 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24310454742270093		[learning rate: 0.0013666]
	Learning Rate: 0.0013666
	LOSS [training: 0.24310454742270093 | validation: 0.20913756161839983]
	TIME [epoch: 40.9 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2450429956520802		[learning rate: 0.0013618]
	Learning Rate: 0.00136177
	LOSS [training: 0.2450429956520802 | validation: 0.20588697549447002]
	TIME [epoch: 41 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23813389215677463		[learning rate: 0.001357]
	Learning Rate: 0.00135695
	LOSS [training: 0.23813389215677463 | validation: 0.20589829840846746]
	TIME [epoch: 40.9 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2453636149803177		[learning rate: 0.0013522]
	Learning Rate: 0.00135215
	LOSS [training: 0.2453636149803177 | validation: 0.20898079067194403]
	TIME [epoch: 40.9 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2456721455766029		[learning rate: 0.0013474]
	Learning Rate: 0.00134737
	LOSS [training: 0.2456721455766029 | validation: 0.20927083165212562]
	TIME [epoch: 40.9 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2448740816401418		[learning rate: 0.0013426]
	Learning Rate: 0.00134261
	LOSS [training: 0.2448740816401418 | validation: 0.2070072367320755]
	TIME [epoch: 40.9 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24567181570392657		[learning rate: 0.0013379]
	Learning Rate: 0.00133786
	LOSS [training: 0.24567181570392657 | validation: 0.2108486413873966]
	TIME [epoch: 41 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24575233577795377		[learning rate: 0.0013331]
	Learning Rate: 0.00133313
	LOSS [training: 0.24575233577795377 | validation: 0.2071615197410782]
	TIME [epoch: 40.9 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24225107682771882		[learning rate: 0.0013284]
	Learning Rate: 0.00132841
	LOSS [training: 0.24225107682771882 | validation: 0.2065489873526683]
	TIME [epoch: 40.9 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24633513607184002		[learning rate: 0.0013237]
	Learning Rate: 0.00132372
	LOSS [training: 0.24633513607184002 | validation: 0.20957785189449005]
	TIME [epoch: 40.9 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24137180896511465		[learning rate: 0.001319]
	Learning Rate: 0.00131904
	LOSS [training: 0.24137180896511465 | validation: 0.20733884696575328]
	TIME [epoch: 40.9 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23940572226056114		[learning rate: 0.0013144]
	Learning Rate: 0.00131437
	LOSS [training: 0.23940572226056114 | validation: 0.20979930846617906]
	TIME [epoch: 41 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2447599206523058		[learning rate: 0.0013097]
	Learning Rate: 0.00130972
	LOSS [training: 0.2447599206523058 | validation: 0.20365933587291823]
	TIME [epoch: 40.9 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12_20240719_004901/states/model_facs_v3_dec1b_2dpca_v12_624.pth
	Model improved!!!
EPOCH 625/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24421974155989867		[learning rate: 0.0013051]
	Learning Rate: 0.00130509
	LOSS [training: 0.24421974155989867 | validation: 0.20761248695216783]
	TIME [epoch: 41 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24070821209407703		[learning rate: 0.0013005]
	Learning Rate: 0.00130048
	LOSS [training: 0.24070821209407703 | validation: 0.2063659536321401]
	TIME [epoch: 40.9 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2398291651983995		[learning rate: 0.0012959]
	Learning Rate: 0.00129588
	LOSS [training: 0.2398291651983995 | validation: 0.2110648601834705]
	TIME [epoch: 41 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2490753532550423		[learning rate: 0.0012913]
	Learning Rate: 0.0012913
	LOSS [training: 0.2490753532550423 | validation: 0.20877136105013588]
	TIME [epoch: 41 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2408584391482308		[learning rate: 0.0012867]
	Learning Rate: 0.00128673
	LOSS [training: 0.2408584391482308 | validation: 0.2091782081552182]
	TIME [epoch: 41 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24571360710232423		[learning rate: 0.0012822]
	Learning Rate: 0.00128218
	LOSS [training: 0.24571360710232423 | validation: 0.2126319920043862]
	TIME [epoch: 41 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24276837360924994		[learning rate: 0.0012776]
	Learning Rate: 0.00127765
	LOSS [training: 0.24276837360924994 | validation: 0.20655119856261037]
	TIME [epoch: 41 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24800731009769525		[learning rate: 0.0012731]
	Learning Rate: 0.00127313
	LOSS [training: 0.24800731009769525 | validation: 0.2074875778837232]
	TIME [epoch: 41 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24547035117167648		[learning rate: 0.0012686]
	Learning Rate: 0.00126863
	LOSS [training: 0.24547035117167648 | validation: 0.20460937530916873]
	TIME [epoch: 41 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2421849036569659		[learning rate: 0.0012641]
	Learning Rate: 0.00126414
	LOSS [training: 0.2421849036569659 | validation: 0.20561218416206625]
	TIME [epoch: 41 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24319966993177936		[learning rate: 0.0012597]
	Learning Rate: 0.00125967
	LOSS [training: 0.24319966993177936 | validation: 0.2095628686849158]
	TIME [epoch: 41 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24445331936091838		[learning rate: 0.0012552]
	Learning Rate: 0.00125521
	LOSS [training: 0.24445331936091838 | validation: 0.21066754035719076]
	TIME [epoch: 41 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24147447536081948		[learning rate: 0.0012508]
	Learning Rate: 0.00125078
	LOSS [training: 0.24147447536081948 | validation: 0.2088546831333431]
	TIME [epoch: 41 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23840919763041366		[learning rate: 0.0012464]
	Learning Rate: 0.00124635
	LOSS [training: 0.23840919763041366 | validation: 0.20323647692279914]
	TIME [epoch: 41 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12_20240719_004901/states/model_facs_v3_dec1b_2dpca_v12_638.pth
	Model improved!!!
EPOCH 639/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23898730545471158		[learning rate: 0.0012419]
	Learning Rate: 0.00124195
	LOSS [training: 0.23898730545471158 | validation: 0.20684805384763977]
	TIME [epoch: 40.9 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24340770152619215		[learning rate: 0.0012376]
	Learning Rate: 0.00123755
	LOSS [training: 0.24340770152619215 | validation: 0.2068311951571497]
	TIME [epoch: 40.9 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24137021283610807		[learning rate: 0.0012332]
	Learning Rate: 0.00123318
	LOSS [training: 0.24137021283610807 | validation: 0.20927740208187648]
	TIME [epoch: 40.9 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2450936166137665		[learning rate: 0.0012288]
	Learning Rate: 0.00122882
	LOSS [training: 0.2450936166137665 | validation: 0.20439867727340846]
	TIME [epoch: 40.9 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24490777709194297		[learning rate: 0.0012245]
	Learning Rate: 0.00122447
	LOSS [training: 0.24490777709194297 | validation: 0.20537147591597793]
	TIME [epoch: 40.9 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24159643862792082		[learning rate: 0.0012201]
	Learning Rate: 0.00122014
	LOSS [training: 0.24159643862792082 | validation: 0.2052689360931296]
	TIME [epoch: 40.9 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2446001956072412		[learning rate: 0.0012158]
	Learning Rate: 0.00121583
	LOSS [training: 0.2446001956072412 | validation: 0.20617114104917902]
	TIME [epoch: 41 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2412900848045534		[learning rate: 0.0012115]
	Learning Rate: 0.00121153
	LOSS [training: 0.2412900848045534 | validation: 0.20646149027171612]
	TIME [epoch: 40.9 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24909948440783047		[learning rate: 0.0012072]
	Learning Rate: 0.00120724
	LOSS [training: 0.24909948440783047 | validation: 0.20752980061784818]
	TIME [epoch: 40.9 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24708591927452028		[learning rate: 0.001203]
	Learning Rate: 0.00120297
	LOSS [training: 0.24708591927452028 | validation: 0.2055976550534777]
	TIME [epoch: 41 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2429473373399024		[learning rate: 0.0011987]
	Learning Rate: 0.00119872
	LOSS [training: 0.2429473373399024 | validation: 0.2078178879902537]
	TIME [epoch: 40.9 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24596063996926557		[learning rate: 0.0011945]
	Learning Rate: 0.00119448
	LOSS [training: 0.24596063996926557 | validation: 0.20262854428961682]
	TIME [epoch: 41 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12_20240719_004901/states/model_facs_v3_dec1b_2dpca_v12_650.pth
	Model improved!!!
EPOCH 651/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2422728061463173		[learning rate: 0.0011903]
	Learning Rate: 0.00119026
	LOSS [training: 0.2422728061463173 | validation: 0.20236520420702336]
	TIME [epoch: 40.9 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12_20240719_004901/states/model_facs_v3_dec1b_2dpca_v12_651.pth
	Model improved!!!
EPOCH 652/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23994088916100312		[learning rate: 0.001186]
	Learning Rate: 0.00118605
	LOSS [training: 0.23994088916100312 | validation: 0.20707347028066758]
	TIME [epoch: 40.9 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2426020540245549		[learning rate: 0.0011819]
	Learning Rate: 0.00118185
	LOSS [training: 0.2426020540245549 | validation: 0.20573852970330764]
	TIME [epoch: 40.9 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24382355671235978		[learning rate: 0.0011777]
	Learning Rate: 0.00117768
	LOSS [training: 0.24382355671235978 | validation: 0.20531520212743676]
	TIME [epoch: 40.9 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24452209365037902		[learning rate: 0.0011735]
	Learning Rate: 0.00117351
	LOSS [training: 0.24452209365037902 | validation: 0.20828104385233243]
	TIME [epoch: 40.9 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24439205251862184		[learning rate: 0.0011694]
	Learning Rate: 0.00116936
	LOSS [training: 0.24439205251862184 | validation: 0.20474454471902642]
	TIME [epoch: 40.9 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24326718083593427		[learning rate: 0.0011652]
	Learning Rate: 0.00116523
	LOSS [training: 0.24326718083593427 | validation: 0.2064659753555042]
	TIME [epoch: 40.9 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2401414623073845		[learning rate: 0.0011611]
	Learning Rate: 0.00116111
	LOSS [training: 0.2401414623073845 | validation: 0.20496341513084787]
	TIME [epoch: 40.9 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24082166605068453		[learning rate: 0.001157]
	Learning Rate: 0.001157
	LOSS [training: 0.24082166605068453 | validation: 0.21062381211317288]
	TIME [epoch: 40.9 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24375730332745657		[learning rate: 0.0011529]
	Learning Rate: 0.00115291
	LOSS [training: 0.24375730332745657 | validation: 0.2079757461528972]
	TIME [epoch: 40.9 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24421196120878705		[learning rate: 0.0011488]
	Learning Rate: 0.00114883
	LOSS [training: 0.24421196120878705 | validation: 0.20694068994335355]
	TIME [epoch: 40.9 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2453397725783896		[learning rate: 0.0011448]
	Learning Rate: 0.00114477
	LOSS [training: 0.2453397725783896 | validation: 0.20634907788709017]
	TIME [epoch: 40.9 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24414491022160098		[learning rate: 0.0011407]
	Learning Rate: 0.00114072
	LOSS [training: 0.24414491022160098 | validation: 0.2118469009281762]
	TIME [epoch: 40.9 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24365590343125146		[learning rate: 0.0011367]
	Learning Rate: 0.00113669
	LOSS [training: 0.24365590343125146 | validation: 0.2109205708385895]
	TIME [epoch: 40.9 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24226865772023032		[learning rate: 0.0011327]
	Learning Rate: 0.00113267
	LOSS [training: 0.24226865772023032 | validation: 0.2061048384464515]
	TIME [epoch: 40.9 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24261353517604065		[learning rate: 0.0011287]
	Learning Rate: 0.00112866
	LOSS [training: 0.24261353517604065 | validation: 0.20359054055721745]
	TIME [epoch: 40.9 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2424103892309877		[learning rate: 0.0011247]
	Learning Rate: 0.00112467
	LOSS [training: 0.2424103892309877 | validation: 0.20838402515066717]
	TIME [epoch: 40.9 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24417368386892233		[learning rate: 0.0011207]
	Learning Rate: 0.00112069
	LOSS [training: 0.24417368386892233 | validation: 0.20846115357668488]
	TIME [epoch: 40.9 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2440000401806844		[learning rate: 0.0011167]
	Learning Rate: 0.00111673
	LOSS [training: 0.2440000401806844 | validation: 0.20473735247120853]
	TIME [epoch: 40.9 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2407630883144538		[learning rate: 0.0011128]
	Learning Rate: 0.00111278
	LOSS [training: 0.2407630883144538 | validation: 0.20512482966505444]
	TIME [epoch: 40.9 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24383146612645482		[learning rate: 0.0011088]
	Learning Rate: 0.00110885
	LOSS [training: 0.24383146612645482 | validation: 0.20844801613866087]
	TIME [epoch: 40.9 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24320471309457592		[learning rate: 0.0011049]
	Learning Rate: 0.00110493
	LOSS [training: 0.24320471309457592 | validation: 0.20769821070425026]
	TIME [epoch: 40.9 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24466406351755307		[learning rate: 0.001101]
	Learning Rate: 0.00110102
	LOSS [training: 0.24466406351755307 | validation: 0.20846081099131508]
	TIME [epoch: 40.9 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24093351294174628		[learning rate: 0.0010971]
	Learning Rate: 0.00109713
	LOSS [training: 0.24093351294174628 | validation: 0.20553823184371933]
	TIME [epoch: 40.9 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2476384814499413		[learning rate: 0.0010932]
	Learning Rate: 0.00109325
	LOSS [training: 0.2476384814499413 | validation: 0.2103056938815842]
	TIME [epoch: 40.9 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.242971607655982		[learning rate: 0.0010894]
	Learning Rate: 0.00108938
	LOSS [training: 0.242971607655982 | validation: 0.20623344020484904]
	TIME [epoch: 40.9 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24293606848595228		[learning rate: 0.0010855]
	Learning Rate: 0.00108553
	LOSS [training: 0.24293606848595228 | validation: 0.20859469987706075]
	TIME [epoch: 40.9 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2439933085726312		[learning rate: 0.0010817]
	Learning Rate: 0.00108169
	LOSS [training: 0.2439933085726312 | validation: 0.20776688410397087]
	TIME [epoch: 40.9 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24574118654650903		[learning rate: 0.0010779]
	Learning Rate: 0.00107786
	LOSS [training: 0.24574118654650903 | validation: 0.20822096455638653]
	TIME [epoch: 40.9 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24509282005840272		[learning rate: 0.0010741]
	Learning Rate: 0.00107405
	LOSS [training: 0.24509282005840272 | validation: 0.20863852089149537]
	TIME [epoch: 40.9 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2407848366109553		[learning rate: 0.0010703]
	Learning Rate: 0.00107025
	LOSS [training: 0.2407848366109553 | validation: 0.20643012237858566]
	TIME [epoch: 40.9 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24679491990546387		[learning rate: 0.0010665]
	Learning Rate: 0.00106647
	LOSS [training: 0.24679491990546387 | validation: 0.20649193961694295]
	TIME [epoch: 40.9 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24358357714121134		[learning rate: 0.0010627]
	Learning Rate: 0.0010627
	LOSS [training: 0.24358357714121134 | validation: 0.20487640373305305]
	TIME [epoch: 40.9 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24143473185716982		[learning rate: 0.0010589]
	Learning Rate: 0.00105894
	LOSS [training: 0.24143473185716982 | validation: 0.20839668753721577]
	TIME [epoch: 40.9 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24399532963614434		[learning rate: 0.0010552]
	Learning Rate: 0.0010552
	LOSS [training: 0.24399532963614434 | validation: 0.20320459525854484]
	TIME [epoch: 40.9 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23996785228330952		[learning rate: 0.0010515]
	Learning Rate: 0.00105147
	LOSS [training: 0.23996785228330952 | validation: 0.2048570980439366]
	TIME [epoch: 40.9 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24209174071763162		[learning rate: 0.0010477]
	Learning Rate: 0.00104775
	LOSS [training: 0.24209174071763162 | validation: 0.20674776115912824]
	TIME [epoch: 40.9 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24478001231363397		[learning rate: 0.001044]
	Learning Rate: 0.00104404
	LOSS [training: 0.24478001231363397 | validation: 0.20520537986951976]
	TIME [epoch: 40.9 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24393332462608638		[learning rate: 0.0010404]
	Learning Rate: 0.00104035
	LOSS [training: 0.24393332462608638 | validation: 0.20654604663606296]
	TIME [epoch: 40.9 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24577098712425258		[learning rate: 0.0010367]
	Learning Rate: 0.00103667
	LOSS [training: 0.24577098712425258 | validation: 0.20670119087396727]
	TIME [epoch: 40.9 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24147585816497374		[learning rate: 0.001033]
	Learning Rate: 0.00103301
	LOSS [training: 0.24147585816497374 | validation: 0.21097686710449529]
	TIME [epoch: 40.9 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24671277935363078		[learning rate: 0.0010294]
	Learning Rate: 0.00102935
	LOSS [training: 0.24671277935363078 | validation: 0.21583695701313146]
	TIME [epoch: 40.9 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24152132950695612		[learning rate: 0.0010257]
	Learning Rate: 0.00102571
	LOSS [training: 0.24152132950695612 | validation: 0.21222741726115477]
	TIME [epoch: 40.9 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24266488294796626		[learning rate: 0.0010221]
	Learning Rate: 0.00102209
	LOSS [training: 0.24266488294796626 | validation: 0.20950484693872556]
	TIME [epoch: 40.9 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.240706689404986		[learning rate: 0.0010185]
	Learning Rate: 0.00101847
	LOSS [training: 0.240706689404986 | validation: 0.2051315967385095]
	TIME [epoch: 40.8 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24804514924625143		[learning rate: 0.0010149]
	Learning Rate: 0.00101487
	LOSS [training: 0.24804514924625143 | validation: 0.20636701839899513]
	TIME [epoch: 40.8 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24109552236793444		[learning rate: 0.0010113]
	Learning Rate: 0.00101128
	LOSS [training: 0.24109552236793444 | validation: 0.20741110904330698]
	TIME [epoch: 40.9 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24226267371321406		[learning rate: 0.0010077]
	Learning Rate: 0.0010077
	LOSS [training: 0.24226267371321406 | validation: 0.20537788538017895]
	TIME [epoch: 40.9 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24014718420765577		[learning rate: 0.0010041]
	Learning Rate: 0.00100414
	LOSS [training: 0.24014718420765577 | validation: 0.20738427430442535]
	TIME [epoch: 40.9 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24485729058130856		[learning rate: 0.0010006]
	Learning Rate: 0.00100059
	LOSS [training: 0.24485729058130856 | validation: 0.20502156022555057]
	TIME [epoch: 40.9 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2407171031384493		[learning rate: 0.00099705]
	Learning Rate: 0.000997052
	LOSS [training: 0.2407171031384493 | validation: 0.2054594808119011]
	TIME [epoch: 40.8 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2421485966251629		[learning rate: 0.00099353]
	Learning Rate: 0.000993527
	LOSS [training: 0.2421485966251629 | validation: 0.2054948641516232]
	TIME [epoch: 40.9 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23953328951070796		[learning rate: 0.00099001]
	Learning Rate: 0.000990013
	LOSS [training: 0.23953328951070796 | validation: 0.2117260816897534]
	TIME [epoch: 40.9 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24236504844312187		[learning rate: 0.00098651]
	Learning Rate: 0.000986513
	LOSS [training: 0.24236504844312187 | validation: 0.20832811977779236]
	TIME [epoch: 40.9 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2503744674657576		[learning rate: 0.00098302]
	Learning Rate: 0.000983024
	LOSS [training: 0.2503744674657576 | validation: 0.21202542681957323]
	TIME [epoch: 40.9 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24665050602189778		[learning rate: 0.00097955]
	Learning Rate: 0.000979548
	LOSS [training: 0.24665050602189778 | validation: 0.2040731488369789]
	TIME [epoch: 40.9 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24441890446958478		[learning rate: 0.00097608]
	Learning Rate: 0.000976084
	LOSS [training: 0.24441890446958478 | validation: 0.20328418241057963]
	TIME [epoch: 40.9 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2480289991990999		[learning rate: 0.00097263]
	Learning Rate: 0.000972632
	LOSS [training: 0.2480289991990999 | validation: 0.20583758996186238]
	TIME [epoch: 40.9 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23675137753761807		[learning rate: 0.00096919]
	Learning Rate: 0.000969193
	LOSS [training: 0.23675137753761807 | validation: 0.2047956626692326]
	TIME [epoch: 40.9 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24041346130712057		[learning rate: 0.00096577]
	Learning Rate: 0.000965766
	LOSS [training: 0.24041346130712057 | validation: 0.2059487145828364]
	TIME [epoch: 40.9 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24306642110272572		[learning rate: 0.00096235]
	Learning Rate: 0.000962351
	LOSS [training: 0.24306642110272572 | validation: 0.2063549966360934]
	TIME [epoch: 40.9 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24321799005946412		[learning rate: 0.00095895]
	Learning Rate: 0.000958948
	LOSS [training: 0.24321799005946412 | validation: 0.2057835136997046]
	TIME [epoch: 40.9 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2448947879457396		[learning rate: 0.00095556]
	Learning Rate: 0.000955557
	LOSS [training: 0.2448947879457396 | validation: 0.2053460401774972]
	TIME [epoch: 40.9 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.238754288830919		[learning rate: 0.00095218]
	Learning Rate: 0.000952178
	LOSS [training: 0.238754288830919 | validation: 0.2037445560312204]
	TIME [epoch: 40.8 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.242930602110312		[learning rate: 0.00094881]
	Learning Rate: 0.00094881
	LOSS [training: 0.242930602110312 | validation: 0.20509737290439306]
	TIME [epoch: 40.9 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24094008507530454		[learning rate: 0.00094546]
	Learning Rate: 0.000945455
	LOSS [training: 0.24094008507530454 | validation: 0.2036220252473849]
	TIME [epoch: 40.9 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24496423211059834		[learning rate: 0.00094211]
	Learning Rate: 0.000942112
	LOSS [training: 0.24496423211059834 | validation: 0.20644861691852806]
	TIME [epoch: 40.9 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24357705017753442		[learning rate: 0.00093878]
	Learning Rate: 0.000938781
	LOSS [training: 0.24357705017753442 | validation: 0.2052773399566356]
	TIME [epoch: 40.9 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24562984679140018		[learning rate: 0.00093546]
	Learning Rate: 0.000935461
	LOSS [training: 0.24562984679140018 | validation: 0.20719553466382376]
	TIME [epoch: 40.9 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24376924418700588		[learning rate: 0.00093215]
	Learning Rate: 0.000932153
	LOSS [training: 0.24376924418700588 | validation: 0.20579357457671224]
	TIME [epoch: 40.9 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2423005722990095		[learning rate: 0.00092886]
	Learning Rate: 0.000928857
	LOSS [training: 0.2423005722990095 | validation: 0.2073986539694404]
	TIME [epoch: 40.9 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24164678792799707		[learning rate: 0.00092557]
	Learning Rate: 0.000925572
	LOSS [training: 0.24164678792799707 | validation: 0.20418186928697798]
	TIME [epoch: 40.9 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24262572859292797		[learning rate: 0.0009223]
	Learning Rate: 0.000922299
	LOSS [training: 0.24262572859292797 | validation: 0.2085243864476059]
	TIME [epoch: 40.9 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24299702723752592		[learning rate: 0.00091904]
	Learning Rate: 0.000919038
	LOSS [training: 0.24299702723752592 | validation: 0.20746708371476275]
	TIME [epoch: 40.8 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24388351469921868		[learning rate: 0.00091579]
	Learning Rate: 0.000915788
	LOSS [training: 0.24388351469921868 | validation: 0.2067469198533794]
	TIME [epoch: 40.9 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23996895323235864		[learning rate: 0.00091255]
	Learning Rate: 0.000912549
	LOSS [training: 0.23996895323235864 | validation: 0.2104120348593339]
	TIME [epoch: 40.9 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24206128274742142		[learning rate: 0.00090932]
	Learning Rate: 0.000909323
	LOSS [training: 0.24206128274742142 | validation: 0.2067184177108982]
	TIME [epoch: 40.8 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24078832965637995		[learning rate: 0.00090611]
	Learning Rate: 0.000906107
	LOSS [training: 0.24078832965637995 | validation: 0.2086028013123966]
	TIME [epoch: 40.9 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24105960629080223		[learning rate: 0.0009029]
	Learning Rate: 0.000902903
	LOSS [training: 0.24105960629080223 | validation: 0.2070130323361273]
	TIME [epoch: 40.8 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24647127415633982		[learning rate: 0.00089971]
	Learning Rate: 0.00089971
	LOSS [training: 0.24647127415633982 | validation: 0.20762986384382764]
	TIME [epoch: 40.9 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24473972352392134		[learning rate: 0.00089653]
	Learning Rate: 0.000896529
	LOSS [training: 0.24473972352392134 | validation: 0.2061428873273489]
	TIME [epoch: 40.9 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2442489941294552		[learning rate: 0.00089336]
	Learning Rate: 0.000893358
	LOSS [training: 0.2442489941294552 | validation: 0.20479484534283593]
	TIME [epoch: 40.9 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23998241038773974		[learning rate: 0.0008902]
	Learning Rate: 0.000890199
	LOSS [training: 0.23998241038773974 | validation: 0.20532549689182758]
	TIME [epoch: 40.8 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24477897836738946		[learning rate: 0.00088705]
	Learning Rate: 0.000887051
	LOSS [training: 0.24477897836738946 | validation: 0.20645814444312677]
	TIME [epoch: 40.9 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24132195570797907		[learning rate: 0.00088391]
	Learning Rate: 0.000883914
	LOSS [training: 0.24132195570797907 | validation: 0.2042011598334066]
	TIME [epoch: 40.9 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24077404076289377		[learning rate: 0.00088079]
	Learning Rate: 0.000880789
	LOSS [training: 0.24077404076289377 | validation: 0.20443168130467754]
	TIME [epoch: 40.9 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23913850676311746		[learning rate: 0.00087767]
	Learning Rate: 0.000877674
	LOSS [training: 0.23913850676311746 | validation: 0.20544509079044343]
	TIME [epoch: 40.9 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24658876549504594		[learning rate: 0.00087457]
	Learning Rate: 0.000874571
	LOSS [training: 0.24658876549504594 | validation: 0.20521312745593448]
	TIME [epoch: 40.9 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24639612133194433		[learning rate: 0.00087148]
	Learning Rate: 0.000871478
	LOSS [training: 0.24639612133194433 | validation: 0.20670111644083455]
	TIME [epoch: 40.9 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24089034847310034		[learning rate: 0.0008684]
	Learning Rate: 0.000868396
	LOSS [training: 0.24089034847310034 | validation: 0.20355320017813644]
	TIME [epoch: 40.9 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24229759689461938		[learning rate: 0.00086533]
	Learning Rate: 0.000865326
	LOSS [training: 0.24229759689461938 | validation: 0.20440625040614796]
	TIME [epoch: 40.9 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24283112563125708		[learning rate: 0.00086227]
	Learning Rate: 0.000862266
	LOSS [training: 0.24283112563125708 | validation: 0.20226119192944822]
	TIME [epoch: 40.9 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12_20240719_004901/states/model_facs_v3_dec1b_2dpca_v12_742.pth
	Model improved!!!
EPOCH 743/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23959323690124704		[learning rate: 0.00085922]
	Learning Rate: 0.000859216
	LOSS [training: 0.23959323690124704 | validation: 0.20679341275254312]
	TIME [epoch: 41 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24330988337410484		[learning rate: 0.00085618]
	Learning Rate: 0.000856178
	LOSS [training: 0.24330988337410484 | validation: 0.2047890151784058]
	TIME [epoch: 41 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2441279995437938		[learning rate: 0.00085315]
	Learning Rate: 0.00085315
	LOSS [training: 0.2441279995437938 | validation: 0.20727003300497865]
	TIME [epoch: 40.9 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24544117465614068		[learning rate: 0.00085013]
	Learning Rate: 0.000850134
	LOSS [training: 0.24544117465614068 | validation: 0.2058927730416542]
	TIME [epoch: 41 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24581144604910335		[learning rate: 0.00084713]
	Learning Rate: 0.000847127
	LOSS [training: 0.24581144604910335 | validation: 0.2051766851022884]
	TIME [epoch: 41 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24166013019723728		[learning rate: 0.00084413]
	Learning Rate: 0.000844132
	LOSS [training: 0.24166013019723728 | validation: 0.20789800026626262]
	TIME [epoch: 40.9 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2414783577547047		[learning rate: 0.00084115]
	Learning Rate: 0.000841147
	LOSS [training: 0.2414783577547047 | validation: 0.20558269699278525]
	TIME [epoch: 40.9 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24083805729906127		[learning rate: 0.00083817]
	Learning Rate: 0.000838172
	LOSS [training: 0.24083805729906127 | validation: 0.20675051784301166]
	TIME [epoch: 40.9 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24063019284415244		[learning rate: 0.00083521]
	Learning Rate: 0.000835209
	LOSS [training: 0.24063019284415244 | validation: 0.20552247468300813]
	TIME [epoch: 40.9 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24544557441169992		[learning rate: 0.00083225]
	Learning Rate: 0.000832255
	LOSS [training: 0.24544557441169992 | validation: 0.20347246512742423]
	TIME [epoch: 40.9 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23941981134845527		[learning rate: 0.00082931]
	Learning Rate: 0.000829312
	LOSS [training: 0.23941981134845527 | validation: 0.2060773176864009]
	TIME [epoch: 40.8 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23880900430780663		[learning rate: 0.00082638]
	Learning Rate: 0.000826379
	LOSS [training: 0.23880900430780663 | validation: 0.20680927120520326]
	TIME [epoch: 40.9 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2434769918421669		[learning rate: 0.00082346]
	Learning Rate: 0.000823457
	LOSS [training: 0.2434769918421669 | validation: 0.20628771006461039]
	TIME [epoch: 40.9 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2415388220256269		[learning rate: 0.00082055]
	Learning Rate: 0.000820545
	LOSS [training: 0.2415388220256269 | validation: 0.20474601237031803]
	TIME [epoch: 40.9 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24214614576609758		[learning rate: 0.00081764]
	Learning Rate: 0.000817644
	LOSS [training: 0.24214614576609758 | validation: 0.2065129084243699]
	TIME [epoch: 40.9 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24203993169783491		[learning rate: 0.00081475]
	Learning Rate: 0.000814752
	LOSS [training: 0.24203993169783491 | validation: 0.2071423335354945]
	TIME [epoch: 40.9 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24353723928072615		[learning rate: 0.00081187]
	Learning Rate: 0.000811871
	LOSS [training: 0.24353723928072615 | validation: 0.2045879688834494]
	TIME [epoch: 40.9 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24161694774913478		[learning rate: 0.000809]
	Learning Rate: 0.000809
	LOSS [training: 0.24161694774913478 | validation: 0.20616907794988965]
	TIME [epoch: 40.9 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2424093553667004		[learning rate: 0.00080614]
	Learning Rate: 0.00080614
	LOSS [training: 0.2424093553667004 | validation: 0.20398540376629257]
	TIME [epoch: 40.9 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23898209485099917		[learning rate: 0.00080329]
	Learning Rate: 0.000803289
	LOSS [training: 0.23898209485099917 | validation: 0.20746117436782732]
	TIME [epoch: 40.9 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24179064932676053		[learning rate: 0.00080045]
	Learning Rate: 0.000800448
	LOSS [training: 0.24179064932676053 | validation: 0.20797341123509527]
	TIME [epoch: 40.9 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2393924394783626		[learning rate: 0.00079762]
	Learning Rate: 0.000797618
	LOSS [training: 0.2393924394783626 | validation: 0.2085741520626485]
	TIME [epoch: 40.9 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24080463638236463		[learning rate: 0.0007948]
	Learning Rate: 0.000794797
	LOSS [training: 0.24080463638236463 | validation: 0.20910102565863617]
	TIME [epoch: 40.9 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24169768011143175		[learning rate: 0.00079199]
	Learning Rate: 0.000791987
	LOSS [training: 0.24169768011143175 | validation: 0.2114928022390865]
	TIME [epoch: 40.9 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24461691940692545		[learning rate: 0.00078919]
	Learning Rate: 0.000789186
	LOSS [training: 0.24461691940692545 | validation: 0.2110356154917786]
	TIME [epoch: 40.9 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23838289358608386		[learning rate: 0.0007864]
	Learning Rate: 0.000786396
	LOSS [training: 0.23838289358608386 | validation: 0.21216919076257185]
	TIME [epoch: 40.9 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24051530233627508		[learning rate: 0.00078361]
	Learning Rate: 0.000783615
	LOSS [training: 0.24051530233627508 | validation: 0.2106737430102445]
	TIME [epoch: 40.9 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24378636052895133		[learning rate: 0.00078084]
	Learning Rate: 0.000780844
	LOSS [training: 0.24378636052895133 | validation: 0.20779612160777788]
	TIME [epoch: 40.9 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24107755404517092		[learning rate: 0.00077808]
	Learning Rate: 0.000778082
	LOSS [training: 0.24107755404517092 | validation: 0.20727340674202144]
	TIME [epoch: 40.9 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2410461812778885		[learning rate: 0.00077533]
	Learning Rate: 0.000775331
	LOSS [training: 0.2410461812778885 | validation: 0.2070961233302926]
	TIME [epoch: 40.9 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2406535601834797		[learning rate: 0.00077259]
	Learning Rate: 0.000772589
	LOSS [training: 0.2406535601834797 | validation: 0.20847286496534018]
	TIME [epoch: 40.9 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24121633000366002		[learning rate: 0.00076986]
	Learning Rate: 0.000769857
	LOSS [training: 0.24121633000366002 | validation: 0.2056947319242617]
	TIME [epoch: 40.9 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.239753759746251		[learning rate: 0.00076714]
	Learning Rate: 0.000767135
	LOSS [training: 0.239753759746251 | validation: 0.20525118541687934]
	TIME [epoch: 40.9 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24015091596053154		[learning rate: 0.00076442]
	Learning Rate: 0.000764422
	LOSS [training: 0.24015091596053154 | validation: 0.20637159258666182]
	TIME [epoch: 40.9 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2427367634944063		[learning rate: 0.00076172]
	Learning Rate: 0.000761719
	LOSS [training: 0.2427367634944063 | validation: 0.20174809744279068]
	TIME [epoch: 40.9 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12_20240719_004901/states/model_facs_v3_dec1b_2dpca_v12_777.pth
	Model improved!!!
EPOCH 778/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2410958481754585		[learning rate: 0.00075903]
	Learning Rate: 0.000759026
	LOSS [training: 0.2410958481754585 | validation: 0.20503796490311604]
	TIME [epoch: 40.9 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2436662995992851		[learning rate: 0.00075634]
	Learning Rate: 0.000756342
	LOSS [training: 0.2436662995992851 | validation: 0.20390216637643438]
	TIME [epoch: 40.9 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2443854619672634		[learning rate: 0.00075367]
	Learning Rate: 0.000753667
	LOSS [training: 0.2443854619672634 | validation: 0.20600967724194974]
	TIME [epoch: 40.9 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2430298856774957		[learning rate: 0.000751]
	Learning Rate: 0.000751002
	LOSS [training: 0.2430298856774957 | validation: 0.20971507136374606]
	TIME [epoch: 40.9 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.242571375797099		[learning rate: 0.00074835]
	Learning Rate: 0.000748346
	LOSS [training: 0.242571375797099 | validation: 0.20759926871426465]
	TIME [epoch: 40.9 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24212528859847607		[learning rate: 0.0007457]
	Learning Rate: 0.0007457
	LOSS [training: 0.24212528859847607 | validation: 0.20971176477095993]
	TIME [epoch: 40.9 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24283020729384672		[learning rate: 0.00074306]
	Learning Rate: 0.000743063
	LOSS [training: 0.24283020729384672 | validation: 0.20914689694065966]
	TIME [epoch: 40.9 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24216452278108488		[learning rate: 0.00074044]
	Learning Rate: 0.000740435
	LOSS [training: 0.24216452278108488 | validation: 0.20742468873582115]
	TIME [epoch: 40.9 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2459570626010514		[learning rate: 0.00073782]
	Learning Rate: 0.000737817
	LOSS [training: 0.2459570626010514 | validation: 0.20971452416257966]
	TIME [epoch: 40.9 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24024148971447137		[learning rate: 0.00073521]
	Learning Rate: 0.000735208
	LOSS [training: 0.24024148971447137 | validation: 0.20855930774489884]
	TIME [epoch: 40.9 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24112923459966384		[learning rate: 0.00073261]
	Learning Rate: 0.000732608
	LOSS [training: 0.24112923459966384 | validation: 0.20841371250037283]
	TIME [epoch: 40.9 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2409536818556698		[learning rate: 0.00073002]
	Learning Rate: 0.000730018
	LOSS [training: 0.2409536818556698 | validation: 0.20554739871722888]
	TIME [epoch: 40.9 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24162835733011825		[learning rate: 0.00072744]
	Learning Rate: 0.000727436
	LOSS [training: 0.24162835733011825 | validation: 0.2071860273615223]
	TIME [epoch: 40.9 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2439584813891907		[learning rate: 0.00072486]
	Learning Rate: 0.000724864
	LOSS [training: 0.2439584813891907 | validation: 0.2091284009589432]
	TIME [epoch: 40.9 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2394893608177159		[learning rate: 0.0007223]
	Learning Rate: 0.000722301
	LOSS [training: 0.2394893608177159 | validation: 0.2070187197991062]
	TIME [epoch: 40.9 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24319922243329242		[learning rate: 0.00071975]
	Learning Rate: 0.000719746
	LOSS [training: 0.24319922243329242 | validation: 0.2080977631087404]
	TIME [epoch: 41 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24015751844868483		[learning rate: 0.0007172]
	Learning Rate: 0.000717201
	LOSS [training: 0.24015751844868483 | validation: 0.20643361692666612]
	TIME [epoch: 40.9 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24088911019233805		[learning rate: 0.00071467]
	Learning Rate: 0.000714665
	LOSS [training: 0.24088911019233805 | validation: 0.20606059651070802]
	TIME [epoch: 41 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24155347380934064		[learning rate: 0.00071214]
	Learning Rate: 0.000712138
	LOSS [training: 0.24155347380934064 | validation: 0.20608960567909657]
	TIME [epoch: 40.9 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23916698836189496		[learning rate: 0.00070962]
	Learning Rate: 0.00070962
	LOSS [training: 0.23916698836189496 | validation: 0.2046109632892117]
	TIME [epoch: 40.9 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.241023445233193		[learning rate: 0.00070711]
	Learning Rate: 0.00070711
	LOSS [training: 0.241023445233193 | validation: 0.2087970273645369]
	TIME [epoch: 40.9 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24359824005606748		[learning rate: 0.00070461]
	Learning Rate: 0.00070461
	LOSS [training: 0.24359824005606748 | validation: 0.21053507436409316]
	TIME [epoch: 40.9 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24144325251733822		[learning rate: 0.00070212]
	Learning Rate: 0.000702118
	LOSS [training: 0.24144325251733822 | validation: 0.21037388203243976]
	TIME [epoch: 40.9 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24216008963824667		[learning rate: 0.00069964]
	Learning Rate: 0.000699635
	LOSS [training: 0.24216008963824667 | validation: 0.20939834557283987]
	TIME [epoch: 40.9 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2438438229363208		[learning rate: 0.00069716]
	Learning Rate: 0.000697161
	LOSS [training: 0.2438438229363208 | validation: 0.20649400583126615]
	TIME [epoch: 41 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24017905671633166		[learning rate: 0.0006947]
	Learning Rate: 0.000694696
	LOSS [training: 0.24017905671633166 | validation: 0.2100306849012207]
	TIME [epoch: 40.9 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23686913849995092		[learning rate: 0.00069224]
	Learning Rate: 0.00069224
	LOSS [training: 0.23686913849995092 | validation: 0.20968969423667533]
	TIME [epoch: 41 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24025775024297458		[learning rate: 0.00068979]
	Learning Rate: 0.000689792
	LOSS [training: 0.24025775024297458 | validation: 0.20596161607690586]
	TIME [epoch: 40.9 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24153502423079395		[learning rate: 0.00068735]
	Learning Rate: 0.000687352
	LOSS [training: 0.24153502423079395 | validation: 0.20890347910860366]
	TIME [epoch: 40.9 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24150212984244868		[learning rate: 0.00068492]
	Learning Rate: 0.000684922
	LOSS [training: 0.24150212984244868 | validation: 0.20956014770704706]
	TIME [epoch: 40.9 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23980059925838645		[learning rate: 0.0006825]
	Learning Rate: 0.0006825
	LOSS [training: 0.23980059925838645 | validation: 0.20926858878545077]
	TIME [epoch: 40.9 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2406128505819276		[learning rate: 0.00068009]
	Learning Rate: 0.000680086
	LOSS [training: 0.2406128505819276 | validation: 0.21148321473099738]
	TIME [epoch: 40.9 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24169363736124938		[learning rate: 0.00067768]
	Learning Rate: 0.000677682
	LOSS [training: 0.24169363736124938 | validation: 0.2109930871096287]
	TIME [epoch: 40.9 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2434776627413353		[learning rate: 0.00067529]
	Learning Rate: 0.000675285
	LOSS [training: 0.2434776627413353 | validation: 0.20809701467157082]
	TIME [epoch: 40.9 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24138344125843947		[learning rate: 0.0006729]
	Learning Rate: 0.000672897
	LOSS [training: 0.24138344125843947 | validation: 0.20874751086795734]
	TIME [epoch: 41 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24176734552853965		[learning rate: 0.00067052]
	Learning Rate: 0.000670518
	LOSS [training: 0.24176734552853965 | validation: 0.20667518237167476]
	TIME [epoch: 40.9 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.239609342067439		[learning rate: 0.00066815]
	Learning Rate: 0.000668147
	LOSS [training: 0.239609342067439 | validation: 0.21621031550986514]
	TIME [epoch: 40.9 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24177369207173047		[learning rate: 0.00066578]
	Learning Rate: 0.000665784
	LOSS [training: 0.24177369207173047 | validation: 0.20961359002357494]
	TIME [epoch: 40.9 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24655949526354673		[learning rate: 0.00066343]
	Learning Rate: 0.00066343
	LOSS [training: 0.24655949526354673 | validation: 0.21134697583580145]
	TIME [epoch: 41 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2424299477217858		[learning rate: 0.00066108]
	Learning Rate: 0.000661084
	LOSS [training: 0.2424299477217858 | validation: 0.20751952009081184]
	TIME [epoch: 41 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24121603884145779		[learning rate: 0.00065875]
	Learning Rate: 0.000658746
	LOSS [training: 0.24121603884145779 | validation: 0.21288452472853564]
	TIME [epoch: 40.9 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24026780338465778		[learning rate: 0.00065642]
	Learning Rate: 0.000656417
	LOSS [training: 0.24026780338465778 | validation: 0.20972535214996163]
	TIME [epoch: 40.9 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23899643492633912		[learning rate: 0.0006541]
	Learning Rate: 0.000654095
	LOSS [training: 0.23899643492633912 | validation: 0.20846684287662728]
	TIME [epoch: 40.9 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23670863866588285		[learning rate: 0.00065178]
	Learning Rate: 0.000651782
	LOSS [training: 0.23670863866588285 | validation: 0.2077194717610474]
	TIME [epoch: 40.9 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2440712652462627		[learning rate: 0.00064948]
	Learning Rate: 0.000649477
	LOSS [training: 0.2440712652462627 | validation: 0.21199372718994444]
	TIME [epoch: 41 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24048462856634323		[learning rate: 0.00064718]
	Learning Rate: 0.000647181
	LOSS [training: 0.24048462856634323 | validation: 0.20992926588560926]
	TIME [epoch: 41 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23851446571872334		[learning rate: 0.00064489]
	Learning Rate: 0.000644892
	LOSS [training: 0.23851446571872334 | validation: 0.21135321405018717]
	TIME [epoch: 41 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2468593718658565		[learning rate: 0.00064261]
	Learning Rate: 0.000642612
	LOSS [training: 0.2468593718658565 | validation: 0.21163463123191822]
	TIME [epoch: 40.9 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24286551093570227		[learning rate: 0.00064034]
	Learning Rate: 0.000640339
	LOSS [training: 0.24286551093570227 | validation: 0.21166524455619623]
	TIME [epoch: 40.9 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2421407690520124		[learning rate: 0.00063808]
	Learning Rate: 0.000638075
	LOSS [training: 0.2421407690520124 | validation: 0.20737767207463897]
	TIME [epoch: 40.9 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2425705943843712		[learning rate: 0.00063582]
	Learning Rate: 0.000635819
	LOSS [training: 0.2425705943843712 | validation: 0.20766211100257062]
	TIME [epoch: 40.9 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2443308585758558		[learning rate: 0.00063357]
	Learning Rate: 0.00063357
	LOSS [training: 0.2443308585758558 | validation: 0.2054820853226509]
	TIME [epoch: 40.9 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24073354966281468		[learning rate: 0.00063133]
	Learning Rate: 0.00063133
	LOSS [training: 0.24073354966281468 | validation: 0.20586088816948173]
	TIME [epoch: 40.9 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24550566987790354		[learning rate: 0.0006291]
	Learning Rate: 0.000629098
	LOSS [training: 0.24550566987790354 | validation: 0.20712995472293755]
	TIME [epoch: 40.9 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23795060977594062		[learning rate: 0.00062687]
	Learning Rate: 0.000626873
	LOSS [training: 0.23795060977594062 | validation: 0.20558403889634785]
	TIME [epoch: 41 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24086950380954023		[learning rate: 0.00062466]
	Learning Rate: 0.000624656
	LOSS [training: 0.24086950380954023 | validation: 0.2045860438462186]
	TIME [epoch: 41 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24213903694190533		[learning rate: 0.00062245]
	Learning Rate: 0.000622447
	LOSS [training: 0.24213903694190533 | validation: 0.20735265927306576]
	TIME [epoch: 40.9 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2407503809863009		[learning rate: 0.00062025]
	Learning Rate: 0.000620246
	LOSS [training: 0.2407503809863009 | validation: 0.20990113542957284]
	TIME [epoch: 40.9 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2404250276523405		[learning rate: 0.00061805]
	Learning Rate: 0.000618053
	LOSS [training: 0.2404250276523405 | validation: 0.20657678652148995]
	TIME [epoch: 40.9 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23868519782329103		[learning rate: 0.00061587]
	Learning Rate: 0.000615867
	LOSS [training: 0.23868519782329103 | validation: 0.20959990150975144]
	TIME [epoch: 40.9 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24157684875095073		[learning rate: 0.00061369]
	Learning Rate: 0.00061369
	LOSS [training: 0.24157684875095073 | validation: 0.2086384032270321]
	TIME [epoch: 41 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23911013575065057		[learning rate: 0.00061152]
	Learning Rate: 0.000611519
	LOSS [training: 0.23911013575065057 | validation: 0.20675854116525477]
	TIME [epoch: 40.9 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24014017852485658		[learning rate: 0.00060936]
	Learning Rate: 0.000609357
	LOSS [training: 0.24014017852485658 | validation: 0.20863870947796062]
	TIME [epoch: 41 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2385441768357257		[learning rate: 0.0006072]
	Learning Rate: 0.000607202
	LOSS [training: 0.2385441768357257 | validation: 0.20936096289853942]
	TIME [epoch: 41 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24029912837045106		[learning rate: 0.00060506]
	Learning Rate: 0.000605055
	LOSS [training: 0.24029912837045106 | validation: 0.21103619927648648]
	TIME [epoch: 40.9 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2405442205862531		[learning rate: 0.00060292]
	Learning Rate: 0.000602915
	LOSS [training: 0.2405442205862531 | validation: 0.20834370010198314]
	TIME [epoch: 41 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24310581273088785		[learning rate: 0.00060078]
	Learning Rate: 0.000600784
	LOSS [training: 0.24310581273088785 | validation: 0.20824769066102294]
	TIME [epoch: 40.9 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24288369060927095		[learning rate: 0.00059866]
	Learning Rate: 0.000598659
	LOSS [training: 0.24288369060927095 | validation: 0.211128047811316]
	TIME [epoch: 40.9 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24486350415245672		[learning rate: 0.00059654]
	Learning Rate: 0.000596542
	LOSS [training: 0.24486350415245672 | validation: 0.2034903276507079]
	TIME [epoch: 40.9 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24457945778988877		[learning rate: 0.00059443]
	Learning Rate: 0.000594432
	LOSS [training: 0.24457945778988877 | validation: 0.20309587434614523]
	TIME [epoch: 40.9 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24012153109422085		[learning rate: 0.00059233]
	Learning Rate: 0.00059233
	LOSS [training: 0.24012153109422085 | validation: 0.20194730355760077]
	TIME [epoch: 41 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23912198630503453		[learning rate: 0.00059024]
	Learning Rate: 0.000590236
	LOSS [training: 0.23912198630503453 | validation: 0.20642876182619596]
	TIME [epoch: 41 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23892780208869938		[learning rate: 0.00058815]
	Learning Rate: 0.000588149
	LOSS [training: 0.23892780208869938 | validation: 0.19966791961655359]
	TIME [epoch: 41 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12_20240719_004901/states/model_facs_v3_dec1b_2dpca_v12_850.pth
	Model improved!!!
EPOCH 851/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24172144392281572		[learning rate: 0.00058607]
	Learning Rate: 0.000586069
	LOSS [training: 0.24172144392281572 | validation: 0.20598975624013124]
	TIME [epoch: 40.9 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24466743772317281		[learning rate: 0.000584]
	Learning Rate: 0.000583996
	LOSS [training: 0.24466743772317281 | validation: 0.205574037015668]
	TIME [epoch: 40.9 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2429938503178578		[learning rate: 0.00058193]
	Learning Rate: 0.000581931
	LOSS [training: 0.2429938503178578 | validation: 0.20620739949025563]
	TIME [epoch: 40.9 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24359538047116527		[learning rate: 0.00057987]
	Learning Rate: 0.000579874
	LOSS [training: 0.24359538047116527 | validation: 0.20348194827533872]
	TIME [epoch: 41 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24372931488962044		[learning rate: 0.00057782]
	Learning Rate: 0.000577823
	LOSS [training: 0.24372931488962044 | validation: 0.20614290146405317]
	TIME [epoch: 40.9 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24009191502759228		[learning rate: 0.00057578]
	Learning Rate: 0.00057578
	LOSS [training: 0.24009191502759228 | validation: 0.2060067526306074]
	TIME [epoch: 40.9 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2408152093541808		[learning rate: 0.00057374]
	Learning Rate: 0.000573744
	LOSS [training: 0.2408152093541808 | validation: 0.20665857057920495]
	TIME [epoch: 40.9 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24118001562369407		[learning rate: 0.00057171]
	Learning Rate: 0.000571715
	LOSS [training: 0.24118001562369407 | validation: 0.2075713870688339]
	TIME [epoch: 40.9 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2458858054367649		[learning rate: 0.00056969]
	Learning Rate: 0.000569693
	LOSS [training: 0.2458858054367649 | validation: 0.20700359264877538]
	TIME [epoch: 40.9 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24121331571537633		[learning rate: 0.00056768]
	Learning Rate: 0.000567679
	LOSS [training: 0.24121331571537633 | validation: 0.20540008207006305]
	TIME [epoch: 40.9 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24330195646889297		[learning rate: 0.00056567]
	Learning Rate: 0.000565671
	LOSS [training: 0.24330195646889297 | validation: 0.2086100528281464]
	TIME [epoch: 40.9 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24116895647707806		[learning rate: 0.00056367]
	Learning Rate: 0.000563671
	LOSS [training: 0.24116895647707806 | validation: 0.20372270745594473]
	TIME [epoch: 40.9 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2412788950320741		[learning rate: 0.00056168]
	Learning Rate: 0.000561678
	LOSS [training: 0.2412788950320741 | validation: 0.20848590175765888]
	TIME [epoch: 40.9 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23778684427461375		[learning rate: 0.00055969]
	Learning Rate: 0.000559692
	LOSS [training: 0.23778684427461375 | validation: 0.20100587192201408]
	TIME [epoch: 40.9 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23911526911168066		[learning rate: 0.00055771]
	Learning Rate: 0.000557712
	LOSS [training: 0.23911526911168066 | validation: 0.20414040872836353]
	TIME [epoch: 40.9 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2423243037545354		[learning rate: 0.00055574]
	Learning Rate: 0.00055574
	LOSS [training: 0.2423243037545354 | validation: 0.2069183122888422]
	TIME [epoch: 40.9 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24214587125108442		[learning rate: 0.00055377]
	Learning Rate: 0.000553775
	LOSS [training: 0.24214587125108442 | validation: 0.20445693682472682]
	TIME [epoch: 40.9 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.243017979171113		[learning rate: 0.00055182]
	Learning Rate: 0.000551817
	LOSS [training: 0.243017979171113 | validation: 0.20603014374173395]
	TIME [epoch: 40.9 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23946299740205523		[learning rate: 0.00054987]
	Learning Rate: 0.000549865
	LOSS [training: 0.23946299740205523 | validation: 0.20414501840448582]
	TIME [epoch: 40.9 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23921592923183835		[learning rate: 0.00054792]
	Learning Rate: 0.000547921
	LOSS [training: 0.23921592923183835 | validation: 0.21067925111893696]
	TIME [epoch: 40.9 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24516066280156446		[learning rate: 0.00054598]
	Learning Rate: 0.000545983
	LOSS [training: 0.24516066280156446 | validation: 0.20849590178921762]
	TIME [epoch: 40.9 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23875910543947443		[learning rate: 0.00054405]
	Learning Rate: 0.000544053
	LOSS [training: 0.23875910543947443 | validation: 0.20919338263731277]
	TIME [epoch: 40.9 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2398115993485663		[learning rate: 0.00054213]
	Learning Rate: 0.000542129
	LOSS [training: 0.2398115993485663 | validation: 0.20561157276796246]
	TIME [epoch: 40.9 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23882456557806134		[learning rate: 0.00054021]
	Learning Rate: 0.000540212
	LOSS [training: 0.23882456557806134 | validation: 0.21013200134797944]
	TIME [epoch: 40.9 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2450007699124119		[learning rate: 0.0005383]
	Learning Rate: 0.000538302
	LOSS [training: 0.2450007699124119 | validation: 0.20523508521083517]
	TIME [epoch: 40.9 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24484881001364286		[learning rate: 0.0005364]
	Learning Rate: 0.000536398
	LOSS [training: 0.24484881001364286 | validation: 0.21078247486552434]
	TIME [epoch: 40.9 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24231764223772365		[learning rate: 0.0005345]
	Learning Rate: 0.000534501
	LOSS [training: 0.24231764223772365 | validation: 0.2062852938330666]
	TIME [epoch: 41 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24109957565886275		[learning rate: 0.00053261]
	Learning Rate: 0.000532611
	LOSS [training: 0.24109957565886275 | validation: 0.20091743085854552]
	TIME [epoch: 40.9 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24278966371289756		[learning rate: 0.00053073]
	Learning Rate: 0.000530728
	LOSS [training: 0.24278966371289756 | validation: 0.20872456159695257]
	TIME [epoch: 40.9 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24441688498087377		[learning rate: 0.00052885]
	Learning Rate: 0.000528851
	LOSS [training: 0.24441688498087377 | validation: 0.20428364506292299]
	TIME [epoch: 40.9 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23925420877736114		[learning rate: 0.00052698]
	Learning Rate: 0.000526981
	LOSS [training: 0.23925420877736114 | validation: 0.20729105086565047]
	TIME [epoch: 40.9 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23905957643865808		[learning rate: 0.00052512]
	Learning Rate: 0.000525117
	LOSS [training: 0.23905957643865808 | validation: 0.20479510486169775]
	TIME [epoch: 40.9 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24122719649357208		[learning rate: 0.00052326]
	Learning Rate: 0.000523261
	LOSS [training: 0.24122719649357208 | validation: 0.2070753999014178]
	TIME [epoch: 41 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23968721100533627		[learning rate: 0.00052141]
	Learning Rate: 0.00052141
	LOSS [training: 0.23968721100533627 | validation: 0.20926500096996953]
	TIME [epoch: 40.8 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24066398405818287		[learning rate: 0.00051957]
	Learning Rate: 0.000519566
	LOSS [training: 0.24066398405818287 | validation: 0.20658361432057815]
	TIME [epoch: 40.9 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24628804637623847		[learning rate: 0.00051773]
	Learning Rate: 0.000517729
	LOSS [training: 0.24628804637623847 | validation: 0.20785319608761887]
	TIME [epoch: 40.9 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24493012578920312		[learning rate: 0.0005159]
	Learning Rate: 0.000515898
	LOSS [training: 0.24493012578920312 | validation: 0.20492286896129505]
	TIME [epoch: 40.8 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24150985335508438		[learning rate: 0.00051407]
	Learning Rate: 0.000514074
	LOSS [training: 0.24150985335508438 | validation: 0.2070137360908227]
	TIME [epoch: 40.7 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24391813502563078		[learning rate: 0.00051226]
	Learning Rate: 0.000512256
	LOSS [training: 0.24391813502563078 | validation: 0.20567724565036177]
	TIME [epoch: 41 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24548283730906093		[learning rate: 0.00051044]
	Learning Rate: 0.000510445
	LOSS [training: 0.24548283730906093 | validation: 0.20506622353001208]
	TIME [epoch: 40.9 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2433489127089711		[learning rate: 0.00050864]
	Learning Rate: 0.00050864
	LOSS [training: 0.2433489127089711 | validation: 0.20440077371129858]
	TIME [epoch: 41 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2416306938805477		[learning rate: 0.00050684]
	Learning Rate: 0.000506841
	LOSS [training: 0.2416306938805477 | validation: 0.20397686901693052]
	TIME [epoch: 40.9 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23668649536484102		[learning rate: 0.00050505]
	Learning Rate: 0.000505049
	LOSS [training: 0.23668649536484102 | validation: 0.20985108837773572]
	TIME [epoch: 40.9 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24048986578904719		[learning rate: 0.00050326]
	Learning Rate: 0.000503263
	LOSS [training: 0.24048986578904719 | validation: 0.20655429708950618]
	TIME [epoch: 40.9 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2435944900891156		[learning rate: 0.00050148]
	Learning Rate: 0.000501483
	LOSS [training: 0.2435944900891156 | validation: 0.20780824190716868]
	TIME [epoch: 40.8 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2402890984994689		[learning rate: 0.00049971]
	Learning Rate: 0.00049971
	LOSS [training: 0.2402890984994689 | validation: 0.21092722471650366]
	TIME [epoch: 40.9 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24259092135981927		[learning rate: 0.00049794]
	Learning Rate: 0.000497943
	LOSS [training: 0.24259092135981927 | validation: 0.20421173100254247]
	TIME [epoch: 40.9 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2426443928237675		[learning rate: 0.00049618]
	Learning Rate: 0.000496182
	LOSS [training: 0.2426443928237675 | validation: 0.20656734157389098]
	TIME [epoch: 40.9 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2414418061770788		[learning rate: 0.00049443]
	Learning Rate: 0.000494427
	LOSS [training: 0.2414418061770788 | validation: 0.20394422480196783]
	TIME [epoch: 40.8 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24062501869255323		[learning rate: 0.00049268]
	Learning Rate: 0.000492679
	LOSS [training: 0.24062501869255323 | validation: 0.20404961995841564]
	TIME [epoch: 41 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24106156232166545		[learning rate: 0.00049094]
	Learning Rate: 0.000490937
	LOSS [training: 0.24106156232166545 | validation: 0.2065296651738801]
	TIME [epoch: 40.8 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2379855185721039		[learning rate: 0.0004892]
	Learning Rate: 0.000489201
	LOSS [training: 0.2379855185721039 | validation: 0.2046719699616793]
	TIME [epoch: 40.8 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24411836165908937		[learning rate: 0.00048747]
	Learning Rate: 0.000487471
	LOSS [training: 0.24411836165908937 | validation: 0.20328178977613248]
	TIME [epoch: 40.8 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2419266478807407		[learning rate: 0.00048575]
	Learning Rate: 0.000485747
	LOSS [training: 0.2419266478807407 | validation: 0.2021175224956985]
	TIME [epoch: 40.8 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23977720742385153		[learning rate: 0.00048403]
	Learning Rate: 0.000484029
	LOSS [training: 0.23977720742385153 | validation: 0.20380781305634205]
	TIME [epoch: 40.8 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24157922833434428		[learning rate: 0.00048232]
	Learning Rate: 0.000482318
	LOSS [training: 0.24157922833434428 | validation: 0.2046066950618822]
	TIME [epoch: 40.7 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23880387540704975		[learning rate: 0.00048061]
	Learning Rate: 0.000480612
	LOSS [training: 0.23880387540704975 | validation: 0.20869515124382126]
	TIME [epoch: 40.8 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2387105110302514		[learning rate: 0.00047891]
	Learning Rate: 0.000478913
	LOSS [training: 0.2387105110302514 | validation: 0.2054711559962422]
	TIME [epoch: 40.8 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2398291671536893		[learning rate: 0.00047722]
	Learning Rate: 0.000477219
	LOSS [training: 0.2398291671536893 | validation: 0.20305570759111707]
	TIME [epoch: 40.8 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24130670921162592		[learning rate: 0.00047553]
	Learning Rate: 0.000475532
	LOSS [training: 0.24130670921162592 | validation: 0.21013585029821683]
	TIME [epoch: 40.8 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24225916968981895		[learning rate: 0.00047385]
	Learning Rate: 0.00047385
	LOSS [training: 0.24225916968981895 | validation: 0.20654212538863748]
	TIME [epoch: 40.8 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2444934961990554		[learning rate: 0.00047217]
	Learning Rate: 0.000472175
	LOSS [training: 0.2444934961990554 | validation: 0.20597032729461895]
	TIME [epoch: 40.8 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24103550076113098		[learning rate: 0.0004705]
	Learning Rate: 0.000470505
	LOSS [training: 0.24103550076113098 | validation: 0.20718884145922495]
	TIME [epoch: 40.8 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24039364142560427		[learning rate: 0.00046884]
	Learning Rate: 0.000468841
	LOSS [training: 0.24039364142560427 | validation: 0.20635540430585747]
	TIME [epoch: 40.8 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24323960451612223		[learning rate: 0.00046718]
	Learning Rate: 0.000467183
	LOSS [training: 0.24323960451612223 | validation: 0.20732957346427044]
	TIME [epoch: 40.8 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24004750317473933		[learning rate: 0.00046553]
	Learning Rate: 0.000465531
	LOSS [training: 0.24004750317473933 | validation: 0.20640667991723688]
	TIME [epoch: 40.8 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24078031747738426		[learning rate: 0.00046388]
	Learning Rate: 0.000463885
	LOSS [training: 0.24078031747738426 | validation: 0.20893504941686297]
	TIME [epoch: 40.8 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24067012067594937		[learning rate: 0.00046224]
	Learning Rate: 0.000462245
	LOSS [training: 0.24067012067594937 | validation: 0.20466775320659739]
	TIME [epoch: 40.8 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2375961235772244		[learning rate: 0.00046061]
	Learning Rate: 0.00046061
	LOSS [training: 0.2375961235772244 | validation: 0.2065557684928419]
	TIME [epoch: 40.8 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24231060695829112		[learning rate: 0.00045898]
	Learning Rate: 0.000458981
	LOSS [training: 0.24231060695829112 | validation: 0.2084167966715858]
	TIME [epoch: 40.8 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23740661806541033		[learning rate: 0.00045736]
	Learning Rate: 0.000457358
	LOSS [training: 0.23740661806541033 | validation: 0.20713255529294178]
	TIME [epoch: 40.8 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2426805624266002		[learning rate: 0.00045574]
	Learning Rate: 0.000455741
	LOSS [training: 0.2426805624266002 | validation: 0.20702994418585013]
	TIME [epoch: 40.8 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23986003910903234		[learning rate: 0.00045413]
	Learning Rate: 0.000454129
	LOSS [training: 0.23986003910903234 | validation: 0.20562553069482745]
	TIME [epoch: 40.8 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2391664885102184		[learning rate: 0.00045252]
	Learning Rate: 0.000452523
	LOSS [training: 0.2391664885102184 | validation: 0.20545142165945088]
	TIME [epoch: 40.8 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24082962296962887		[learning rate: 0.00045092]
	Learning Rate: 0.000450923
	LOSS [training: 0.24082962296962887 | validation: 0.20841333137771598]
	TIME [epoch: 40.8 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23658232901098228		[learning rate: 0.00044933]
	Learning Rate: 0.000449329
	LOSS [training: 0.23658232901098228 | validation: 0.21018349882353005]
	TIME [epoch: 40.8 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2401303624196026		[learning rate: 0.00044774]
	Learning Rate: 0.00044774
	LOSS [training: 0.2401303624196026 | validation: 0.20890751035403926]
	TIME [epoch: 40.8 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23880010539928045		[learning rate: 0.00044616]
	Learning Rate: 0.000446156
	LOSS [training: 0.23880010539928045 | validation: 0.20781011519706913]
	TIME [epoch: 40.8 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2372444111199361		[learning rate: 0.00044458]
	Learning Rate: 0.000444579
	LOSS [training: 0.2372444111199361 | validation: 0.2034442163909734]
	TIME [epoch: 40.8 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23865536937636891		[learning rate: 0.00044301]
	Learning Rate: 0.000443007
	LOSS [training: 0.23865536937636891 | validation: 0.20710683392089763]
	TIME [epoch: 40.8 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.239472678795274		[learning rate: 0.00044144]
	Learning Rate: 0.00044144
	LOSS [training: 0.239472678795274 | validation: 0.20566406345104088]
	TIME [epoch: 40.8 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24279343421915375		[learning rate: 0.00043988]
	Learning Rate: 0.000439879
	LOSS [training: 0.24279343421915375 | validation: 0.2078077982911189]
	TIME [epoch: 40.8 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24004013945244176		[learning rate: 0.00043832]
	Learning Rate: 0.000438324
	LOSS [training: 0.24004013945244176 | validation: 0.20860125545568226]
	TIME [epoch: 40.8 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2380675198244909		[learning rate: 0.00043677]
	Learning Rate: 0.000436774
	LOSS [training: 0.2380675198244909 | validation: 0.2096553003400799]
	TIME [epoch: 40.7 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24036758561015018		[learning rate: 0.00043523]
	Learning Rate: 0.000435229
	LOSS [training: 0.24036758561015018 | validation: 0.20376706576901218]
	TIME [epoch: 40.8 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23988288637889874		[learning rate: 0.00043369]
	Learning Rate: 0.00043369
	LOSS [training: 0.23988288637889874 | validation: 0.2050360506531947]
	TIME [epoch: 40.8 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2385773496814326		[learning rate: 0.00043216]
	Learning Rate: 0.000432156
	LOSS [training: 0.2385773496814326 | validation: 0.20496989992142023]
	TIME [epoch: 40.8 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2413938692004218		[learning rate: 0.00043063]
	Learning Rate: 0.000430628
	LOSS [training: 0.2413938692004218 | validation: 0.2059053341325574]
	TIME [epoch: 40.8 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2417564048139401		[learning rate: 0.00042911]
	Learning Rate: 0.000429106
	LOSS [training: 0.2417564048139401 | validation: 0.20481398146698887]
	TIME [epoch: 41 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23956218393300996		[learning rate: 0.00042759]
	Learning Rate: 0.000427588
	LOSS [training: 0.23956218393300996 | validation: 0.20857135621192638]
	TIME [epoch: 40.8 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24034960068141573		[learning rate: 0.00042608]
	Learning Rate: 0.000426076
	LOSS [training: 0.24034960068141573 | validation: 0.2063648367134066]
	TIME [epoch: 40.8 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24236810621415536		[learning rate: 0.00042457]
	Learning Rate: 0.000424569
	LOSS [training: 0.24236810621415536 | validation: 0.2050167580933988]
	TIME [epoch: 40.8 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24135096506260703		[learning rate: 0.00042307]
	Learning Rate: 0.000423068
	LOSS [training: 0.24135096506260703 | validation: 0.20479654783981652]
	TIME [epoch: 40.8 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23933662355776097		[learning rate: 0.00042157]
	Learning Rate: 0.000421572
	LOSS [training: 0.23933662355776097 | validation: 0.20453700924491386]
	TIME [epoch: 40.8 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24222804659383165		[learning rate: 0.00042008]
	Learning Rate: 0.000420081
	LOSS [training: 0.24222804659383165 | validation: 0.20672777853731591]
	TIME [epoch: 40.8 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24141814788480764		[learning rate: 0.0004186]
	Learning Rate: 0.000418596
	LOSS [training: 0.24141814788480764 | validation: 0.2109258235009423]
	TIME [epoch: 40.8 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23926811704893977		[learning rate: 0.00041712]
	Learning Rate: 0.000417116
	LOSS [training: 0.23926811704893977 | validation: 0.20370024385633564]
	TIME [epoch: 40.8 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24040159501594527		[learning rate: 0.00041564]
	Learning Rate: 0.000415641
	LOSS [training: 0.24040159501594527 | validation: 0.20681043318218156]
	TIME [epoch: 41 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2382535000788386		[learning rate: 0.00041417]
	Learning Rate: 0.000414171
	LOSS [training: 0.2382535000788386 | validation: 0.20502007369319827]
	TIME [epoch: 40.9 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23828148044773234		[learning rate: 0.00041271]
	Learning Rate: 0.000412706
	LOSS [training: 0.23828148044773234 | validation: 0.20670900413497462]
	TIME [epoch: 40.9 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23707215447941823		[learning rate: 0.00041125]
	Learning Rate: 0.000411247
	LOSS [training: 0.23707215447941823 | validation: 0.20545867410535404]
	TIME [epoch: 40.8 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24037539445204936		[learning rate: 0.00040979]
	Learning Rate: 0.000409793
	LOSS [training: 0.24037539445204936 | validation: 0.20927151027181115]
	TIME [epoch: 40.9 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2427666381377881		[learning rate: 0.00040834]
	Learning Rate: 0.000408344
	LOSS [training: 0.2427666381377881 | validation: 0.20697176783151533]
	TIME [epoch: 41 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24281059226557566		[learning rate: 0.0004069]
	Learning Rate: 0.0004069
	LOSS [training: 0.24281059226557566 | validation: 0.20819306054889272]
	TIME [epoch: 41 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23968561533575275		[learning rate: 0.00040546]
	Learning Rate: 0.000405461
	LOSS [training: 0.23968561533575275 | validation: 0.20122791787344457]
	TIME [epoch: 40.8 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23772953618070794		[learning rate: 0.00040403]
	Learning Rate: 0.000404027
	LOSS [training: 0.23772953618070794 | validation: 0.2085266917206984]
	TIME [epoch: 40.8 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23912094123051575		[learning rate: 0.0004026]
	Learning Rate: 0.000402598
	LOSS [training: 0.23912094123051575 | validation: 0.20499127228770356]
	TIME [epoch: 40.8 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.241366590018835		[learning rate: 0.00040117]
	Learning Rate: 0.000401175
	LOSS [training: 0.241366590018835 | validation: 0.20877220747631312]
	TIME [epoch: 40.8 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24060727221756617		[learning rate: 0.00039976]
	Learning Rate: 0.000399756
	LOSS [training: 0.24060727221756617 | validation: 0.20455010319144268]
	TIME [epoch: 40.8 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24166392633841285		[learning rate: 0.00039834]
	Learning Rate: 0.000398342
	LOSS [training: 0.24166392633841285 | validation: 0.20550679753585607]
	TIME [epoch: 40.8 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2418451056640761		[learning rate: 0.00039693]
	Learning Rate: 0.000396934
	LOSS [training: 0.2418451056640761 | validation: 0.20706381980286315]
	TIME [epoch: 40.8 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24380822804822144		[learning rate: 0.00039553]
	Learning Rate: 0.00039553
	LOSS [training: 0.24380822804822144 | validation: 0.20576647133496442]
	TIME [epoch: 40.8 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2435863531586692		[learning rate: 0.00039413]
	Learning Rate: 0.000394131
	LOSS [training: 0.2435863531586692 | validation: 0.20952024815873566]
	TIME [epoch: 40.8 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2393401134540111		[learning rate: 0.00039274]
	Learning Rate: 0.000392738
	LOSS [training: 0.2393401134540111 | validation: 0.20367142708560076]
	TIME [epoch: 40.8 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2417440854129316		[learning rate: 0.00039135]
	Learning Rate: 0.000391349
	LOSS [training: 0.2417440854129316 | validation: 0.2031123777299053]
	TIME [epoch: 40.8 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.237715097740306		[learning rate: 0.00038997]
	Learning Rate: 0.000389965
	LOSS [training: 0.237715097740306 | validation: 0.20805335725209514]
	TIME [epoch: 40.8 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24151802915096873		[learning rate: 0.00038859]
	Learning Rate: 0.000388586
	LOSS [training: 0.24151802915096873 | validation: 0.20837613047513664]
	TIME [epoch: 40.8 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2368782326745422		[learning rate: 0.00038721]
	Learning Rate: 0.000387212
	LOSS [training: 0.2368782326745422 | validation: 0.206800857514517]
	TIME [epoch: 40.8 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24098566785131884		[learning rate: 0.00038584]
	Learning Rate: 0.000385843
	LOSS [training: 0.24098566785131884 | validation: 0.2110264288322797]
	TIME [epoch: 40.8 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24048751415523792		[learning rate: 0.00038448]
	Learning Rate: 0.000384478
	LOSS [training: 0.24048751415523792 | validation: 0.20568006240860032]
	TIME [epoch: 40.8 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2401702818417366		[learning rate: 0.00038312]
	Learning Rate: 0.000383119
	LOSS [training: 0.2401702818417366 | validation: 0.2077529949589149]
	TIME [epoch: 40.8 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24254287723063764		[learning rate: 0.00038176]
	Learning Rate: 0.000381764
	LOSS [training: 0.24254287723063764 | validation: 0.20686765346069763]
	TIME [epoch: 40.8 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23783545516453194		[learning rate: 0.00038041]
	Learning Rate: 0.000380414
	LOSS [training: 0.23783545516453194 | validation: 0.20545668471221984]
	TIME [epoch: 40.8 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24196642708448068		[learning rate: 0.00037907]
	Learning Rate: 0.000379069
	LOSS [training: 0.24196642708448068 | validation: 0.20887409548643587]
	TIME [epoch: 40.8 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24260722692619818		[learning rate: 0.00037773]
	Learning Rate: 0.000377728
	LOSS [training: 0.24260722692619818 | validation: 0.20370899236456128]
	TIME [epoch: 40.8 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23847121598693402		[learning rate: 0.00037639]
	Learning Rate: 0.000376393
	LOSS [training: 0.23847121598693402 | validation: 0.20328816493971474]
	TIME [epoch: 40.8 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23843912586699192		[learning rate: 0.00037506]
	Learning Rate: 0.000375062
	LOSS [training: 0.23843912586699192 | validation: 0.20596533118425545]
	TIME [epoch: 40.8 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24353831405039728		[learning rate: 0.00037374]
	Learning Rate: 0.000373735
	LOSS [training: 0.24353831405039728 | validation: 0.20579915357488]
	TIME [epoch: 40.8 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.238161811530855		[learning rate: 0.00037241]
	Learning Rate: 0.000372414
	LOSS [training: 0.238161811530855 | validation: 0.205012734800249]
	TIME [epoch: 40.8 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2415995825526939		[learning rate: 0.0003711]
	Learning Rate: 0.000371097
	LOSS [training: 0.2415995825526939 | validation: 0.20612372815168428]
	TIME [epoch: 40.8 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2403057075159626		[learning rate: 0.00036978]
	Learning Rate: 0.000369785
	LOSS [training: 0.2403057075159626 | validation: 0.2080531267398975]
	TIME [epoch: 40.8 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24154500716822383		[learning rate: 0.00036848]
	Learning Rate: 0.000368477
	LOSS [training: 0.24154500716822383 | validation: 0.20462236227323402]
	TIME [epoch: 40.8 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23864080350789763		[learning rate: 0.00036717]
	Learning Rate: 0.000367174
	LOSS [training: 0.23864080350789763 | validation: 0.20279764194619995]
	TIME [epoch: 40.8 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24171118882306106		[learning rate: 0.00036588]
	Learning Rate: 0.000365875
	LOSS [training: 0.24171118882306106 | validation: 0.20799933192532385]
	TIME [epoch: 40.8 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23842691467029928		[learning rate: 0.00036458]
	Learning Rate: 0.000364582
	LOSS [training: 0.23842691467029928 | validation: 0.20622424612424167]
	TIME [epoch: 40.8 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24216803277918778		[learning rate: 0.00036329]
	Learning Rate: 0.000363293
	LOSS [training: 0.24216803277918778 | validation: 0.20851930784081577]
	TIME [epoch: 40.8 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24054491524139152		[learning rate: 0.00036201]
	Learning Rate: 0.000362008
	LOSS [training: 0.24054491524139152 | validation: 0.20738101019693303]
	TIME [epoch: 40.8 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23936231710371458		[learning rate: 0.00036073]
	Learning Rate: 0.000360728
	LOSS [training: 0.23936231710371458 | validation: 0.20322274631968745]
	TIME [epoch: 40.8 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2425902199859686		[learning rate: 0.00035945]
	Learning Rate: 0.000359452
	LOSS [training: 0.2425902199859686 | validation: 0.2034186224738792]
	TIME [epoch: 40.8 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24080662305729347		[learning rate: 0.00035818]
	Learning Rate: 0.000358181
	LOSS [training: 0.24080662305729347 | validation: 0.2083129410171804]
	TIME [epoch: 40.8 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23809528544798056		[learning rate: 0.00035691]
	Learning Rate: 0.000356914
	LOSS [training: 0.23809528544798056 | validation: 0.20521102413103942]
	TIME [epoch: 40.8 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2416684113129501		[learning rate: 0.00035565]
	Learning Rate: 0.000355652
	LOSS [training: 0.2416684113129501 | validation: 0.20639775834361562]
	TIME [epoch: 40.8 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23996386877912554		[learning rate: 0.00035439]
	Learning Rate: 0.000354395
	LOSS [training: 0.23996386877912554 | validation: 0.20416706327763096]
	TIME [epoch: 40.8 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2399971888518566		[learning rate: 0.00035314]
	Learning Rate: 0.000353141
	LOSS [training: 0.2399971888518566 | validation: 0.20492240025124478]
	TIME [epoch: 40.8 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24134400644607212		[learning rate: 0.00035189]
	Learning Rate: 0.000351893
	LOSS [training: 0.24134400644607212 | validation: 0.20458415559619275]
	TIME [epoch: 40.8 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24237503792117518		[learning rate: 0.00035065]
	Learning Rate: 0.000350648
	LOSS [training: 0.24237503792117518 | validation: 0.20906886841375344]
	TIME [epoch: 40.8 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2381907471092273		[learning rate: 0.00034941]
	Learning Rate: 0.000349408
	LOSS [training: 0.2381907471092273 | validation: 0.2068514153593172]
	TIME [epoch: 40.8 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24030571191240666		[learning rate: 0.00034817]
	Learning Rate: 0.000348173
	LOSS [training: 0.24030571191240666 | validation: 0.20589940031984577]
	TIME [epoch: 40.8 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24074613994916053		[learning rate: 0.00034694]
	Learning Rate: 0.000346942
	LOSS [training: 0.24074613994916053 | validation: 0.20675069658060058]
	TIME [epoch: 40.8 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.243840262455019		[learning rate: 0.00034571]
	Learning Rate: 0.000345715
	LOSS [training: 0.243840262455019 | validation: 0.20383181516988072]
	TIME [epoch: 40.8 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23844238485646121		[learning rate: 0.00034449]
	Learning Rate: 0.000344492
	LOSS [training: 0.23844238485646121 | validation: 0.20296846430614543]
	TIME [epoch: 104 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2404008081641291		[learning rate: 0.00034327]
	Learning Rate: 0.000343274
	LOSS [training: 0.2404008081641291 | validation: 0.20913133319394223]
	TIME [epoch: 86.5 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24286091863934992		[learning rate: 0.00034206]
	Learning Rate: 0.00034206
	LOSS [training: 0.24286091863934992 | validation: 0.2078531277981937]
	TIME [epoch: 86.5 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24022921986143783		[learning rate: 0.00034085]
	Learning Rate: 0.000340851
	LOSS [training: 0.24022921986143783 | validation: 0.20367217950442154]
	TIME [epoch: 86.5 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23814920602398582		[learning rate: 0.00033965]
	Learning Rate: 0.000339645
	LOSS [training: 0.23814920602398582 | validation: 0.210280321749389]
	TIME [epoch: 86.5 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24534324139669095		[learning rate: 0.00033844]
	Learning Rate: 0.000338444
	LOSS [training: 0.24534324139669095 | validation: 0.20275326299041083]
	TIME [epoch: 86.5 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23975886722074546		[learning rate: 0.00033725]
	Learning Rate: 0.000337247
	LOSS [training: 0.23975886722074546 | validation: 0.20432483558145279]
	TIME [epoch: 86.5 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24111472991851055		[learning rate: 0.00033605]
	Learning Rate: 0.000336055
	LOSS [training: 0.24111472991851055 | validation: 0.20713596344704457]
	TIME [epoch: 86.5 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23883970706106453		[learning rate: 0.00033487]
	Learning Rate: 0.000334867
	LOSS [training: 0.23883970706106453 | validation: 0.207445213627031]
	TIME [epoch: 86.5 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23926355171118793		[learning rate: 0.00033368]
	Learning Rate: 0.000333682
	LOSS [training: 0.23926355171118793 | validation: 0.20392967309727367]
	TIME [epoch: 86.5 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23870490030962033		[learning rate: 0.0003325]
	Learning Rate: 0.000332503
	LOSS [training: 0.23870490030962033 | validation: 0.20294502689360297]
	TIME [epoch: 86.5 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2407409754802371		[learning rate: 0.00033133]
	Learning Rate: 0.000331327
	LOSS [training: 0.2407409754802371 | validation: 0.2071608249572651]
	TIME [epoch: 86.5 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2429232907946343		[learning rate: 0.00033016]
	Learning Rate: 0.000330155
	LOSS [training: 0.2429232907946343 | validation: 0.20662827500242348]
	TIME [epoch: 86.5 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23987035837126078		[learning rate: 0.00032899]
	Learning Rate: 0.000328988
	LOSS [training: 0.23987035837126078 | validation: 0.20907217579866672]
	TIME [epoch: 86.5 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24287273915248528		[learning rate: 0.00032782]
	Learning Rate: 0.000327824
	LOSS [training: 0.24287273915248528 | validation: 0.20587297088883147]
	TIME [epoch: 86.5 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.236576725385272		[learning rate: 0.00032667]
	Learning Rate: 0.000326665
	LOSS [training: 0.236576725385272 | validation: 0.20512193728751513]
	TIME [epoch: 86.5 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24129056469013185		[learning rate: 0.00032551]
	Learning Rate: 0.00032551
	LOSS [training: 0.24129056469013185 | validation: 0.20467977186295153]
	TIME [epoch: 86.5 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24182464848378105		[learning rate: 0.00032436]
	Learning Rate: 0.000324359
	LOSS [training: 0.24182464848378105 | validation: 0.20512814070251323]
	TIME [epoch: 86.5 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23758067941041872		[learning rate: 0.00032321]
	Learning Rate: 0.000323212
	LOSS [training: 0.23758067941041872 | validation: 0.2052680729469567]
	TIME [epoch: 86.6 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24505088052987137		[learning rate: 0.00032207]
	Learning Rate: 0.000322069
	LOSS [training: 0.24505088052987137 | validation: 0.20613129288769114]
	TIME [epoch: 86.5 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2388225821750347		[learning rate: 0.00032093]
	Learning Rate: 0.00032093
	LOSS [training: 0.2388225821750347 | validation: 0.2081926710715769]
	TIME [epoch: 86.5 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2380698613063015		[learning rate: 0.0003198]
	Learning Rate: 0.000319795
	LOSS [training: 0.2380698613063015 | validation: 0.20555402855844468]
	TIME [epoch: 86.5 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23851698202028773		[learning rate: 0.00031866]
	Learning Rate: 0.000318664
	LOSS [training: 0.23851698202028773 | validation: 0.20689527548227787]
	TIME [epoch: 86.6 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.240903496908475		[learning rate: 0.00031754]
	Learning Rate: 0.000317537
	LOSS [training: 0.240903496908475 | validation: 0.20569517563276776]
	TIME [epoch: 86.5 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24241894357934882		[learning rate: 0.00031641]
	Learning Rate: 0.000316414
	LOSS [training: 0.24241894357934882 | validation: 0.20588225206026728]
	TIME [epoch: 86.5 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24083442435591107		[learning rate: 0.0003153]
	Learning Rate: 0.000315296
	LOSS [training: 0.24083442435591107 | validation: 0.20766292134417924]
	TIME [epoch: 86.5 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24427737235485059		[learning rate: 0.00031418]
	Learning Rate: 0.000314181
	LOSS [training: 0.24427737235485059 | validation: 0.2036228703917517]
	TIME [epoch: 86.5 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23996272523872497		[learning rate: 0.00031307]
	Learning Rate: 0.00031307
	LOSS [training: 0.23996272523872497 | validation: 0.2071402962171578]
	TIME [epoch: 86.5 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24002599521649567		[learning rate: 0.00031196]
	Learning Rate: 0.000311963
	LOSS [training: 0.24002599521649567 | validation: 0.20518268713360505]
	TIME [epoch: 86.5 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2369071316516984		[learning rate: 0.00031086]
	Learning Rate: 0.00031086
	LOSS [training: 0.2369071316516984 | validation: 0.20570743392264026]
	TIME [epoch: 86.5 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24346819302400766		[learning rate: 0.00030976]
	Learning Rate: 0.00030976
	LOSS [training: 0.24346819302400766 | validation: 0.20622140439834813]
	TIME [epoch: 86.5 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2388951389767199		[learning rate: 0.00030866]
	Learning Rate: 0.000308665
	LOSS [training: 0.2388951389767199 | validation: 0.21058597976509946]
	TIME [epoch: 86.5 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24048704998967796		[learning rate: 0.00030757]
	Learning Rate: 0.000307573
	LOSS [training: 0.24048704998967796 | validation: 0.2084902859214941]
	TIME [epoch: 86.4 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2401079271652328		[learning rate: 0.00030649]
	Learning Rate: 0.000306486
	LOSS [training: 0.2401079271652328 | validation: 0.21000346712637144]
	TIME [epoch: 86.4 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2403227293144098		[learning rate: 0.0003054]
	Learning Rate: 0.000305402
	LOSS [training: 0.2403227293144098 | validation: 0.20479380234497016]
	TIME [epoch: 86.4 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2414148586569637		[learning rate: 0.00030432]
	Learning Rate: 0.000304322
	LOSS [training: 0.2414148586569637 | validation: 0.20548221892306212]
	TIME [epoch: 86.5 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23824250723715235		[learning rate: 0.00030325]
	Learning Rate: 0.000303246
	LOSS [training: 0.23824250723715235 | validation: 0.20755543097805185]
	TIME [epoch: 86.5 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2381690880341969		[learning rate: 0.00030217]
	Learning Rate: 0.000302174
	LOSS [training: 0.2381690880341969 | validation: 0.20349449202216138]
	TIME [epoch: 86.5 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24003588881945406		[learning rate: 0.0003011]
	Learning Rate: 0.000301105
	LOSS [training: 0.24003588881945406 | validation: 0.20261125739210958]
	TIME [epoch: 86.5 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23881914108166014		[learning rate: 0.00030004]
	Learning Rate: 0.00030004
	LOSS [training: 0.23881914108166014 | validation: 0.2028894214482853]
	TIME [epoch: 86.5 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.241993523125158		[learning rate: 0.00029898]
	Learning Rate: 0.000298979
	LOSS [training: 0.241993523125158 | validation: 0.20566494918663772]
	TIME [epoch: 86.5 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2367504513691424		[learning rate: 0.00029792]
	Learning Rate: 0.000297922
	LOSS [training: 0.2367504513691424 | validation: 0.20283461691467766]
	TIME [epoch: 86.5 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24185088598270202		[learning rate: 0.00029687]
	Learning Rate: 0.000296868
	LOSS [training: 0.24185088598270202 | validation: 0.2088232412715599]
	TIME [epoch: 86.5 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2407765726566821		[learning rate: 0.00029582]
	Learning Rate: 0.000295819
	LOSS [training: 0.2407765726566821 | validation: 0.20539614103526027]
	TIME [epoch: 86.5 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24342315654817345		[learning rate: 0.00029477]
	Learning Rate: 0.000294773
	LOSS [training: 0.24342315654817345 | validation: 0.20169509775063857]
	TIME [epoch: 86.5 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.239500964668141		[learning rate: 0.00029373]
	Learning Rate: 0.00029373
	LOSS [training: 0.239500964668141 | validation: 0.20863951405658954]
	TIME [epoch: 86.4 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23879564137655676		[learning rate: 0.00029269]
	Learning Rate: 0.000292692
	LOSS [training: 0.23879564137655676 | validation: 0.20297293197864463]
	TIME [epoch: 86.5 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24304234214060091		[learning rate: 0.00029166]
	Learning Rate: 0.000291657
	LOSS [training: 0.24304234214060091 | validation: 0.2040815558304508]
	TIME [epoch: 86.5 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24162112520990534		[learning rate: 0.00029063]
	Learning Rate: 0.000290625
	LOSS [training: 0.24162112520990534 | validation: 0.20555034063747502]
	TIME [epoch: 86.5 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24498315715831265		[learning rate: 0.0002896]
	Learning Rate: 0.000289598
	LOSS [training: 0.24498315715831265 | validation: 0.2071783646878614]
	TIME [epoch: 86.5 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23873366368122872		[learning rate: 0.00028857]
	Learning Rate: 0.000288574
	LOSS [training: 0.23873366368122872 | validation: 0.2071335167943233]
	TIME [epoch: 86.5 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v12_20240719_004901/states/model_facs_v3_dec1b_2dpca_v12_1051.pth
Halted early. No improvement in validation loss for 200 epochs.
Finished training in 34211.657 seconds.
