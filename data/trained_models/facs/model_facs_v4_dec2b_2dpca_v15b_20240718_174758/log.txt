Args:
Namespace(name='model_facs_v4_dec2b_2dpca_v15b', outdir='out/model_training/model_facs_v4_dec2b_2dpca_v15b', training_data='data/training_data/facs_v4/pca/dec2_fitonsubset/transition2_subset_ce_pn_m_pc12/training', validation_data='data/training_data/facs_v4/pca/dec2_fitonsubset/transition2_subset_ce_pn_m_pc12/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=10, batch_size=50, patience=200, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, quadratic_a=1.0, quadratic_b=1.0, ndims=2, nparams=2, nsigs=2, ncells=100, ncells_sample=100, model_do_sample=False, dt=0.005, dt_schedule='stepped', dt_schedule_bounds=[50, 100, 200, 300], dt_schedule_scales=[0.5, 0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', kernel='multiscale', bw_range=[0.2, 0.5, 0.9, 1.1, 1.3, 1.5, 2.0], optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 458175512

Training model...

Saving initial model state to: out/model_training/model_facs_v4_dec2b_2dpca_v15b_20240718_174758/states/model_facs_v4_dec2b_2dpca_v15b_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8394859992969443		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8394859992969443 | validation: 0.9336103768753825]
	TIME [epoch: 25 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v15b_20240718_174758/states/model_facs_v4_dec2b_2dpca_v15b_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6470449229206505		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6470449229206505 | validation: 0.9189417015008198]
	TIME [epoch: 3.5 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v15b_20240718_174758/states/model_facs_v4_dec2b_2dpca_v15b_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6834284812655457		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6834284812655457 | validation: 0.7995537244756823]
	TIME [epoch: 3.49 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v15b_20240718_174758/states/model_facs_v4_dec2b_2dpca_v15b_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5851623579329981		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5851623579329981 | validation: 0.7600906914027822]
	TIME [epoch: 3.48 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v15b_20240718_174758/states/model_facs_v4_dec2b_2dpca_v15b_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5046238211655599		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5046238211655599 | validation: 0.6842927026572693]
	TIME [epoch: 3.49 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v15b_20240718_174758/states/model_facs_v4_dec2b_2dpca_v15b_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49157132868829206		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.49157132868829206 | validation: 0.6641658676348459]
	TIME [epoch: 3.47 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v15b_20240718_174758/states/model_facs_v4_dec2b_2dpca_v15b_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4569333835211998		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4569333835211998 | validation: 0.7328472498890024]
	TIME [epoch: 3.48 sec]
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4487207683537216		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4487207683537216 | validation: 0.6544524514622473]
	TIME [epoch: 3.47 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v15b_20240718_174758/states/model_facs_v4_dec2b_2dpca_v15b_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.450690440348501		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.450690440348501 | validation: 0.656773041281747]
	TIME [epoch: 3.49 sec]
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4259207882569658		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4259207882569658 | validation: 0.6967797239036979]
	TIME [epoch: 3.48 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4467878485525477		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4467878485525477 | validation: 0.6406142011346019]
	TIME [epoch: 3.48 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v15b_20240718_174758/states/model_facs_v4_dec2b_2dpca_v15b_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.458274036796036		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.458274036796036 | validation: 0.6136488164732278]
	TIME [epoch: 3.52 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v15b_20240718_174758/states/model_facs_v4_dec2b_2dpca_v15b_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40857086955715627		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.40857086955715627 | validation: 0.572816603644397]
	TIME [epoch: 3.48 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v15b_20240718_174758/states/model_facs_v4_dec2b_2dpca_v15b_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4215358513967933		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4215358513967933 | validation: 0.6852346308480054]
	TIME [epoch: 3.73 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3768321634538238		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3768321634538238 | validation: 0.5234604285320176]
	TIME [epoch: 3.47 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v15b_20240718_174758/states/model_facs_v4_dec2b_2dpca_v15b_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30948017004640865		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.30948017004640865 | validation: 0.4894279539531703]
	TIME [epoch: 3.48 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v15b_20240718_174758/states/model_facs_v4_dec2b_2dpca_v15b_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3141054745512194		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3141054745512194 | validation: 0.49488149146089305]
	TIME [epoch: 3.48 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31372556513537997		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.31372556513537997 | validation: 0.5555762188454654]
	TIME [epoch: 3.47 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29771994190131523		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.29771994190131523 | validation: 0.4438416370494017]
	TIME [epoch: 3.47 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v15b_20240718_174758/states/model_facs_v4_dec2b_2dpca_v15b_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24735892375278457		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24735892375278457 | validation: 0.4075636468063638]
	TIME [epoch: 3.48 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v15b_20240718_174758/states/model_facs_v4_dec2b_2dpca_v15b_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2503493218855053		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2503493218855053 | validation: 0.41132009539515757]
	TIME [epoch: 3.51 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2509114736667252		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2509114736667252 | validation: 0.3977034771941791]
	TIME [epoch: 3.47 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v15b_20240718_174758/states/model_facs_v4_dec2b_2dpca_v15b_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20832535006985062		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20832535006985062 | validation: 0.3727343186568911]
	TIME [epoch: 3.48 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v15b_20240718_174758/states/model_facs_v4_dec2b_2dpca_v15b_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21000170149684655		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.21000170149684655 | validation: 0.43703304644504903]
	TIME [epoch: 3.48 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2756904813852359		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2756904813852359 | validation: 0.3980889314426546]
	TIME [epoch: 3.48 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23544445475612513		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23544445475612513 | validation: 0.49656809559956555]
	TIME [epoch: 3.47 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22840773575584628		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22840773575584628 | validation: 0.3907076826355369]
	TIME [epoch: 3.47 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21101056128690793		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.21101056128690793 | validation: 0.5285882849520471]
	TIME [epoch: 3.47 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25029711649726166		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.25029711649726166 | validation: 0.4264224710192327]
	TIME [epoch: 3.48 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21088608692940158		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.21088608692940158 | validation: 0.38838333381951284]
	TIME [epoch: 3.47 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23904591985149298		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23904591985149298 | validation: 0.37039312613997727]
	TIME [epoch: 3.48 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v15b_20240718_174758/states/model_facs_v4_dec2b_2dpca_v15b_31.pth
	Model improved!!!
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20586918717332892		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20586918717332892 | validation: 0.3709472540501536]
	TIME [epoch: 3.48 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26860946102347877		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.26860946102347877 | validation: 0.8274742391667512]
	TIME [epoch: 3.49 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33017310314106624		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.33017310314106624 | validation: 0.3674502124693643]
	TIME [epoch: 3.48 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v15b_20240718_174758/states/model_facs_v4_dec2b_2dpca_v15b_34.pth
	Model improved!!!
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18823855779595344		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18823855779595344 | validation: 0.3392236949184433]
	TIME [epoch: 3.49 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v15b_20240718_174758/states/model_facs_v4_dec2b_2dpca_v15b_35.pth
	Model improved!!!
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2246148812976585		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2246148812976585 | validation: 0.42475686371454374]
	TIME [epoch: 3.48 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21130999228515437		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.21130999228515437 | validation: 0.35409597949666494]
	TIME [epoch: 3.49 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23229545383664618		[learning rate: 0.0099882]
	Learning Rate: 0.0099882
	LOSS [training: 0.23229545383664618 | validation: 0.3667199461201649]
	TIME [epoch: 3.48 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23662941099432644		[learning rate: 0.0099411]
	Learning Rate: 0.00994113
	LOSS [training: 0.23662941099432644 | validation: 0.42381953172762415]
	TIME [epoch: 3.47 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22480644842777528		[learning rate: 0.0098943]
	Learning Rate: 0.00989429
	LOSS [training: 0.22480644842777528 | validation: 0.4143133563695224]
	TIME [epoch: 3.47 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22816481869754446		[learning rate: 0.0098477]
	Learning Rate: 0.00984767
	LOSS [training: 0.22816481869754446 | validation: 0.35933908492297284]
	TIME [epoch: 3.48 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19452902422944235		[learning rate: 0.0098013]
	Learning Rate: 0.00980126
	LOSS [training: 0.19452902422944235 | validation: 0.39501784228895087]
	TIME [epoch: 3.48 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2172651027437375		[learning rate: 0.0097551]
	Learning Rate: 0.00975508
	LOSS [training: 0.2172651027437375 | validation: 0.42669706964157067]
	TIME [epoch: 3.48 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2566137126799679		[learning rate: 0.0097091]
	Learning Rate: 0.00970911
	LOSS [training: 0.2566137126799679 | validation: 0.3977664261731784]
	TIME [epoch: 3.48 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27117028368015267		[learning rate: 0.0096634]
	Learning Rate: 0.00966336
	LOSS [training: 0.27117028368015267 | validation: 0.4701832709069815]
	TIME [epoch: 3.48 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2528590833382874		[learning rate: 0.0096178]
	Learning Rate: 0.00961783
	LOSS [training: 0.2528590833382874 | validation: 0.40311694964372663]
	TIME [epoch: 3.47 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19687768732099276		[learning rate: 0.0095725]
	Learning Rate: 0.00957251
	LOSS [training: 0.19687768732099276 | validation: 0.3340191986708734]
	TIME [epoch: 3.47 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v15b_20240718_174758/states/model_facs_v4_dec2b_2dpca_v15b_47.pth
	Model improved!!!
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16394905144218397		[learning rate: 0.0095274]
	Learning Rate: 0.0095274
	LOSS [training: 0.16394905144218397 | validation: 0.31449072917016035]
	TIME [epoch: 3.5 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v15b_20240718_174758/states/model_facs_v4_dec2b_2dpca_v15b_48.pth
	Model improved!!!
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16344356106869862		[learning rate: 0.0094825]
	Learning Rate: 0.0094825
	LOSS [training: 0.16344356106869862 | validation: 0.347022044888619]
	TIME [epoch: 3.48 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19099745075929497		[learning rate: 0.0094378]
	Learning Rate: 0.00943782
	LOSS [training: 0.19099745075929497 | validation: 0.421909755602791]
	TIME [epoch: 3.48 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17967752988325011		[learning rate: 0.0093933]
	Learning Rate: 0.00939335
	LOSS [training: 0.17967752988325011 | validation: 0.3324891388787971]
	TIME [epoch: 26.5 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17686075615676547		[learning rate: 0.0093491]
	Learning Rate: 0.00934909
	LOSS [training: 0.17686075615676547 | validation: 0.35348190572230537]
	TIME [epoch: 6.68 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21487648243377522		[learning rate: 0.009305]
	Learning Rate: 0.00930503
	LOSS [training: 0.21487648243377522 | validation: 0.38730610684771094]
	TIME [epoch: 6.68 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19808076733422136		[learning rate: 0.0092612]
	Learning Rate: 0.00926119
	LOSS [training: 0.19808076733422136 | validation: 0.35815465086904275]
	TIME [epoch: 6.68 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17481689334685424		[learning rate: 0.0092175]
	Learning Rate: 0.00921755
	LOSS [training: 0.17481689334685424 | validation: 0.44157626716128623]
	TIME [epoch: 6.68 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18340967005313177		[learning rate: 0.0091741]
	Learning Rate: 0.00917411
	LOSS [training: 0.18340967005313177 | validation: 0.3402753296495529]
	TIME [epoch: 6.67 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16057393518757745		[learning rate: 0.0091309]
	Learning Rate: 0.00913088
	LOSS [training: 0.16057393518757745 | validation: 0.42290337639919373]
	TIME [epoch: 6.66 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21616593515582186		[learning rate: 0.0090879]
	Learning Rate: 0.00908786
	LOSS [training: 0.21616593515582186 | validation: 0.32583197899754124]
	TIME [epoch: 6.67 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18192917431662983		[learning rate: 0.009045]
	Learning Rate: 0.00904503
	LOSS [training: 0.18192917431662983 | validation: 0.32378294728419493]
	TIME [epoch: 6.67 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1740043201025638		[learning rate: 0.0090024]
	Learning Rate: 0.00900241
	LOSS [training: 0.1740043201025638 | validation: 0.349761651984346]
	TIME [epoch: 6.67 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21194198363350822		[learning rate: 0.00896]
	Learning Rate: 0.00895999
	LOSS [training: 0.21194198363350822 | validation: 0.4361917961734324]
	TIME [epoch: 6.67 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19921684462908995		[learning rate: 0.0089178]
	Learning Rate: 0.00891777
	LOSS [training: 0.19921684462908995 | validation: 0.37431592476948294]
	TIME [epoch: 6.67 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2170372227651146		[learning rate: 0.0088758]
	Learning Rate: 0.00887575
	LOSS [training: 0.2170372227651146 | validation: 0.43999180996779474]
	TIME [epoch: 6.66 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1951318175218416		[learning rate: 0.0088339]
	Learning Rate: 0.00883393
	LOSS [training: 0.1951318175218416 | validation: 0.41862546044810844]
	TIME [epoch: 6.66 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17732729781880727		[learning rate: 0.0087923]
	Learning Rate: 0.0087923
	LOSS [training: 0.17732729781880727 | validation: 0.3834475392620331]
	TIME [epoch: 6.67 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17649961081777032		[learning rate: 0.0087509]
	Learning Rate: 0.00875087
	LOSS [training: 0.17649961081777032 | validation: 0.3461478271790011]
	TIME [epoch: 6.66 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16992219517344054		[learning rate: 0.0087096]
	Learning Rate: 0.00870964
	LOSS [training: 0.16992219517344054 | validation: 0.42767991442957726]
	TIME [epoch: 6.67 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17008236602745655		[learning rate: 0.0086686]
	Learning Rate: 0.00866859
	LOSS [training: 0.17008236602745655 | validation: 0.31016891641644817]
	TIME [epoch: 6.67 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v15b_20240718_174758/states/model_facs_v4_dec2b_2dpca_v15b_68.pth
	Model improved!!!
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1594075622947375		[learning rate: 0.0086277]
	Learning Rate: 0.00862775
	LOSS [training: 0.1594075622947375 | validation: 0.37703798722964055]
	TIME [epoch: 6.69 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18514741317970967		[learning rate: 0.0085871]
	Learning Rate: 0.00858709
	LOSS [training: 0.18514741317970967 | validation: 0.37469206900008434]
	TIME [epoch: 6.66 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18715032590961705		[learning rate: 0.0085466]
	Learning Rate: 0.00854663
	LOSS [training: 0.18715032590961705 | validation: 0.3685941446576547]
	TIME [epoch: 6.66 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18867998558948396		[learning rate: 0.0085064]
	Learning Rate: 0.00850636
	LOSS [training: 0.18867998558948396 | validation: 0.39050864905427934]
	TIME [epoch: 6.66 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1692894814800763		[learning rate: 0.0084663]
	Learning Rate: 0.00846627
	LOSS [training: 0.1692894814800763 | validation: 0.3971574223090969]
	TIME [epoch: 6.66 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1860768758281925		[learning rate: 0.0084264]
	Learning Rate: 0.00842638
	LOSS [training: 0.1860768758281925 | validation: 0.36238153878484125]
	TIME [epoch: 6.66 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16520682932161476		[learning rate: 0.0083867]
	Learning Rate: 0.00838667
	LOSS [training: 0.16520682932161476 | validation: 0.3872647163714884]
	TIME [epoch: 6.66 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1901057403110526		[learning rate: 0.0083472]
	Learning Rate: 0.00834715
	LOSS [training: 0.1901057403110526 | validation: 0.28346451210222356]
	TIME [epoch: 6.68 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v15b_20240718_174758/states/model_facs_v4_dec2b_2dpca_v15b_76.pth
	Model improved!!!
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1855876030563916		[learning rate: 0.0083078]
	Learning Rate: 0.00830782
	LOSS [training: 0.1855876030563916 | validation: 0.3072420695795586]
	TIME [epoch: 6.66 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16187775881551306		[learning rate: 0.0082687]
	Learning Rate: 0.00826867
	LOSS [training: 0.16187775881551306 | validation: 0.291547281415097]
	TIME [epoch: 6.68 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14862517598317565		[learning rate: 0.0082297]
	Learning Rate: 0.00822971
	LOSS [training: 0.14862517598317565 | validation: 0.3766369457233946]
	TIME [epoch: 6.66 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15019305733888447		[learning rate: 0.0081909]
	Learning Rate: 0.00819093
	LOSS [training: 0.15019305733888447 | validation: 0.5428031539458553]
	TIME [epoch: 6.66 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21849693555418548		[learning rate: 0.0081523]
	Learning Rate: 0.00815233
	LOSS [training: 0.21849693555418548 | validation: 0.4004841730408167]
	TIME [epoch: 6.66 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21194856925534342		[learning rate: 0.0081139]
	Learning Rate: 0.00811392
	LOSS [training: 0.21194856925534342 | validation: 0.35738242677874693]
	TIME [epoch: 6.66 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18478879041886936		[learning rate: 0.0080757]
	Learning Rate: 0.00807569
	LOSS [training: 0.18478879041886936 | validation: 0.3394304192005487]
	TIME [epoch: 6.67 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15381883419459713		[learning rate: 0.0080376]
	Learning Rate: 0.00803763
	LOSS [training: 0.15381883419459713 | validation: 0.33959190048183097]
	TIME [epoch: 6.65 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1704394365607827		[learning rate: 0.0079998]
	Learning Rate: 0.00799976
	LOSS [training: 0.1704394365607827 | validation: 0.38183451253541456]
	TIME [epoch: 6.66 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1698244228286569		[learning rate: 0.0079621]
	Learning Rate: 0.00796206
	LOSS [training: 0.1698244228286569 | validation: 0.3048984348921577]
	TIME [epoch: 6.65 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15430372319973507		[learning rate: 0.0079245]
	Learning Rate: 0.00792455
	LOSS [training: 0.15430372319973507 | validation: 0.35837337046477824]
	TIME [epoch: 6.67 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2180673151391667		[learning rate: 0.0078872]
	Learning Rate: 0.0078872
	LOSS [training: 0.2180673151391667 | validation: 0.4907021240157909]
	TIME [epoch: 6.66 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17693457033470864		[learning rate: 0.00785]
	Learning Rate: 0.00785004
	LOSS [training: 0.17693457033470864 | validation: 0.31130508756008557]
	TIME [epoch: 6.66 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1370382065915624		[learning rate: 0.007813]
	Learning Rate: 0.00781305
	LOSS [training: 0.1370382065915624 | validation: 0.3288780610790404]
	TIME [epoch: 6.67 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12967969189767978		[learning rate: 0.0077762]
	Learning Rate: 0.00777623
	LOSS [training: 0.12967969189767978 | validation: 0.37852437585046]
	TIME [epoch: 6.66 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1520513184319094		[learning rate: 0.0077396]
	Learning Rate: 0.00773959
	LOSS [training: 0.1520513184319094 | validation: 0.3211581077764585]
	TIME [epoch: 6.67 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18480082753900937		[learning rate: 0.0077031]
	Learning Rate: 0.00770312
	LOSS [training: 0.18480082753900937 | validation: 0.3587972528033276]
	TIME [epoch: 6.66 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1962477546511752		[learning rate: 0.0076668]
	Learning Rate: 0.00766682
	LOSS [training: 0.1962477546511752 | validation: 0.3535958422829636]
	TIME [epoch: 6.66 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13498805250793597		[learning rate: 0.0076307]
	Learning Rate: 0.0076307
	LOSS [training: 0.13498805250793597 | validation: 0.35130025132831333]
	TIME [epoch: 6.66 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15308909378536395		[learning rate: 0.0075947]
	Learning Rate: 0.00759474
	LOSS [training: 0.15308909378536395 | validation: 0.29748297941166574]
	TIME [epoch: 6.67 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1598845281850792		[learning rate: 0.007559]
	Learning Rate: 0.00755895
	LOSS [training: 0.1598845281850792 | validation: 0.38424732681510465]
	TIME [epoch: 6.66 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18546073154776832		[learning rate: 0.0075233]
	Learning Rate: 0.00752333
	LOSS [training: 0.18546073154776832 | validation: 0.37115000485453914]
	TIME [epoch: 6.66 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1595868551953046		[learning rate: 0.0074879]
	Learning Rate: 0.00748788
	LOSS [training: 0.1595868551953046 | validation: 0.3261365233846753]
	TIME [epoch: 6.66 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16635877770082994		[learning rate: 0.0074526]
	Learning Rate: 0.0074526
	LOSS [training: 0.16635877770082994 | validation: 0.32561443895457254]
	TIME [epoch: 6.66 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17509584961017063		[learning rate: 0.0074175]
	Learning Rate: 0.00741748
	LOSS [training: 0.17509584961017063 | validation: 0.37226684090811135]
	TIME [epoch: 34.4 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18988620347563778		[learning rate: 0.0073825]
	Learning Rate: 0.00738253
	LOSS [training: 0.18988620347563778 | validation: 0.36963293093914396]
	TIME [epoch: 14.5 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1633597468979578		[learning rate: 0.0073477]
	Learning Rate: 0.00734774
	LOSS [training: 0.1633597468979578 | validation: 0.3128330768036635]
	TIME [epoch: 14.5 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14020157467395822		[learning rate: 0.0073131]
	Learning Rate: 0.00731312
	LOSS [training: 0.14020157467395822 | validation: 0.2932328997035846]
	TIME [epoch: 14.5 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13761782208869622		[learning rate: 0.0072787]
	Learning Rate: 0.00727866
	LOSS [training: 0.13761782208869622 | validation: 0.37366228438117427]
	TIME [epoch: 14.5 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15678667839903976		[learning rate: 0.0072444]
	Learning Rate: 0.00724436
	LOSS [training: 0.15678667839903976 | validation: 0.5328827442419567]
	TIME [epoch: 14.5 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.157332416153045		[learning rate: 0.0072102]
	Learning Rate: 0.00721022
	LOSS [training: 0.157332416153045 | validation: 0.30449322777010707]
	TIME [epoch: 14.5 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14876426203287468		[learning rate: 0.0071762]
	Learning Rate: 0.00717625
	LOSS [training: 0.14876426203287468 | validation: 0.29324146506774956]
	TIME [epoch: 14.5 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15332232351818664		[learning rate: 0.0071424]
	Learning Rate: 0.00714243
	LOSS [training: 0.15332232351818664 | validation: 0.3056791475978002]
	TIME [epoch: 14.5 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16480942117502115		[learning rate: 0.0071088]
	Learning Rate: 0.00710878
	LOSS [training: 0.16480942117502115 | validation: 0.43941308030291026]
	TIME [epoch: 14.5 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19373346288860743		[learning rate: 0.0070753]
	Learning Rate: 0.00707528
	LOSS [training: 0.19373346288860743 | validation: 0.4022364286219222]
	TIME [epoch: 14.5 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18806190709881832		[learning rate: 0.0070419]
	Learning Rate: 0.00704194
	LOSS [training: 0.18806190709881832 | validation: 0.4358071024940743]
	TIME [epoch: 14.5 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13753390014563377		[learning rate: 0.0070088]
	Learning Rate: 0.00700876
	LOSS [training: 0.13753390014563377 | validation: 0.3858848117031851]
	TIME [epoch: 14.5 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15599238759241954		[learning rate: 0.0069757]
	Learning Rate: 0.00697573
	LOSS [training: 0.15599238759241954 | validation: 0.3338043745122543]
	TIME [epoch: 14.5 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12980619710451274		[learning rate: 0.0069429]
	Learning Rate: 0.00694286
	LOSS [training: 0.12980619710451274 | validation: 0.3424719155229797]
	TIME [epoch: 14.5 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1502685252797668		[learning rate: 0.0069101]
	Learning Rate: 0.00691014
	LOSS [training: 0.1502685252797668 | validation: 0.3054157114986562]
	TIME [epoch: 14.5 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18153647615952864		[learning rate: 0.0068776]
	Learning Rate: 0.00687758
	LOSS [training: 0.18153647615952864 | validation: 0.3380500161101108]
	TIME [epoch: 14.5 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17484244831034731		[learning rate: 0.0068452]
	Learning Rate: 0.00684518
	LOSS [training: 0.17484244831034731 | validation: 0.3124156363207554]
	TIME [epoch: 14.5 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16235621396330627		[learning rate: 0.0068129]
	Learning Rate: 0.00681292
	LOSS [training: 0.16235621396330627 | validation: 0.3668821689507405]
	TIME [epoch: 14.5 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12549450462791192		[learning rate: 0.0067808]
	Learning Rate: 0.00678082
	LOSS [training: 0.12549450462791192 | validation: 0.3555116526000191]
	TIME [epoch: 14.5 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14598915124612002		[learning rate: 0.0067489]
	Learning Rate: 0.00674887
	LOSS [training: 0.14598915124612002 | validation: 0.42399874462496295]
	TIME [epoch: 14.5 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16149829281837344		[learning rate: 0.0067171]
	Learning Rate: 0.00671706
	LOSS [training: 0.16149829281837344 | validation: 0.4574069396865571]
	TIME [epoch: 14.5 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1732461279730663		[learning rate: 0.0066854]
	Learning Rate: 0.00668541
	LOSS [training: 0.1732461279730663 | validation: 0.29589863602060096]
	TIME [epoch: 14.5 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1479444162756103		[learning rate: 0.0066539]
	Learning Rate: 0.00665391
	LOSS [training: 0.1479444162756103 | validation: 0.2980856435777906]
	TIME [epoch: 14.5 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13419247895901704		[learning rate: 0.0066226]
	Learning Rate: 0.00662256
	LOSS [training: 0.13419247895901704 | validation: 0.338104221296219]
	TIME [epoch: 14.5 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1361697526720224		[learning rate: 0.0065913]
	Learning Rate: 0.00659135
	LOSS [training: 0.1361697526720224 | validation: 0.3106684562027389]
	TIME [epoch: 14.5 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1502778397554272		[learning rate: 0.0065603]
	Learning Rate: 0.00656029
	LOSS [training: 0.1502778397554272 | validation: 0.3277669755427582]
	TIME [epoch: 14.5 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14575017199401805		[learning rate: 0.0065294]
	Learning Rate: 0.00652938
	LOSS [training: 0.14575017199401805 | validation: 0.37140963570950647]
	TIME [epoch: 14.4 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15341583796868974		[learning rate: 0.0064986]
	Learning Rate: 0.00649861
	LOSS [training: 0.15341583796868974 | validation: 0.3050556604383319]
	TIME [epoch: 14.5 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13635328756616935		[learning rate: 0.006468]
	Learning Rate: 0.00646799
	LOSS [training: 0.13635328756616935 | validation: 0.3936154726369953]
	TIME [epoch: 14.5 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15781648010061702		[learning rate: 0.0064375]
	Learning Rate: 0.00643751
	LOSS [training: 0.15781648010061702 | validation: 0.4220835447511687]
	TIME [epoch: 14.5 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19706858210864775		[learning rate: 0.0064072]
	Learning Rate: 0.00640718
	LOSS [training: 0.19706858210864775 | validation: 0.31195977490875165]
	TIME [epoch: 14.5 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16233636086326161		[learning rate: 0.006377]
	Learning Rate: 0.00637698
	LOSS [training: 0.16233636086326161 | validation: 0.30443900391190193]
	TIME [epoch: 14.5 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13169426012444413		[learning rate: 0.0063469]
	Learning Rate: 0.00634694
	LOSS [training: 0.13169426012444413 | validation: 0.26515640978709504]
	TIME [epoch: 14.5 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v15b_20240718_174758/states/model_facs_v4_dec2b_2dpca_v15b_134.pth
	Model improved!!!
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12428121500774632		[learning rate: 0.006317]
	Learning Rate: 0.00631703
	LOSS [training: 0.12428121500774632 | validation: 0.40888704016041416]
	TIME [epoch: 14.5 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1318948324039023		[learning rate: 0.0062873]
	Learning Rate: 0.00628726
	LOSS [training: 0.1318948324039023 | validation: 0.30947629223937545]
	TIME [epoch: 14.5 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1567344659130571		[learning rate: 0.0062576]
	Learning Rate: 0.00625764
	LOSS [training: 0.1567344659130571 | validation: 0.33149081145744375]
	TIME [epoch: 14.4 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14447884210568418		[learning rate: 0.0062281]
	Learning Rate: 0.00622815
	LOSS [training: 0.14447884210568418 | validation: 0.32648013134409837]
	TIME [epoch: 14.5 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14127555309265338		[learning rate: 0.0061988]
	Learning Rate: 0.0061988
	LOSS [training: 0.14127555309265338 | validation: 0.3037009069817189]
	TIME [epoch: 14.5 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1553483456992536		[learning rate: 0.0061696]
	Learning Rate: 0.00616959
	LOSS [training: 0.1553483456992536 | validation: 0.42816353871056745]
	TIME [epoch: 14.4 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14216367168154176		[learning rate: 0.0061405]
	Learning Rate: 0.00614052
	LOSS [training: 0.14216367168154176 | validation: 0.3563913179178349]
	TIME [epoch: 14.4 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16561116853240693		[learning rate: 0.0061116]
	Learning Rate: 0.00611158
	LOSS [training: 0.16561116853240693 | validation: 0.3270515150175429]
	TIME [epoch: 14.5 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12637569398781043		[learning rate: 0.0060828]
	Learning Rate: 0.00608279
	LOSS [training: 0.12637569398781043 | validation: 0.3283273288926571]
	TIME [epoch: 14.4 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11943949045798097		[learning rate: 0.0060541]
	Learning Rate: 0.00605412
	LOSS [training: 0.11943949045798097 | validation: 0.3595593435559866]
	TIME [epoch: 14.5 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13926007428542447		[learning rate: 0.0060256]
	Learning Rate: 0.0060256
	LOSS [training: 0.13926007428542447 | validation: 0.3115132249314612]
	TIME [epoch: 14.4 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11558037295474433		[learning rate: 0.0059972]
	Learning Rate: 0.0059972
	LOSS [training: 0.11558037295474433 | validation: 0.29557747861934663]
	TIME [epoch: 14.4 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13306994412078044		[learning rate: 0.0059689]
	Learning Rate: 0.00596894
	LOSS [training: 0.13306994412078044 | validation: 0.31912331048327053]
	TIME [epoch: 14.4 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14524539353559973		[learning rate: 0.0059408]
	Learning Rate: 0.00594082
	LOSS [training: 0.14524539353559973 | validation: 0.32541999295622265]
	TIME [epoch: 14.5 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1371295199872333		[learning rate: 0.0059128]
	Learning Rate: 0.00591282
	LOSS [training: 0.1371295199872333 | validation: 0.36041104504904503]
	TIME [epoch: 14.4 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1586271504909103		[learning rate: 0.005885]
	Learning Rate: 0.00588496
	LOSS [training: 0.1586271504909103 | validation: 0.29290670137083274]
	TIME [epoch: 14.4 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14964110029842734		[learning rate: 0.0058572]
	Learning Rate: 0.00585723
	LOSS [training: 0.14964110029842734 | validation: 0.2960115419791245]
	TIME [epoch: 14.5 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12381544388496629		[learning rate: 0.0058296]
	Learning Rate: 0.00582963
	LOSS [training: 0.12381544388496629 | validation: 0.3211292578530209]
	TIME [epoch: 14.4 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16611529249471102		[learning rate: 0.0058022]
	Learning Rate: 0.00580216
	LOSS [training: 0.16611529249471102 | validation: 0.3917055997342422]
	TIME [epoch: 14.5 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15821728889911935		[learning rate: 0.0057748]
	Learning Rate: 0.00577482
	LOSS [training: 0.15821728889911935 | validation: 0.3098195908210369]
	TIME [epoch: 14.4 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1279926787846184		[learning rate: 0.0057476]
	Learning Rate: 0.00574761
	LOSS [training: 0.1279926787846184 | validation: 0.3699330052842992]
	TIME [epoch: 14.4 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14736780132100782		[learning rate: 0.0057205]
	Learning Rate: 0.00572052
	LOSS [training: 0.14736780132100782 | validation: 0.3734987455614843]
	TIME [epoch: 14.5 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13724222131633904		[learning rate: 0.0056936]
	Learning Rate: 0.00569357
	LOSS [training: 0.13724222131633904 | validation: 0.3551752204971345]
	TIME [epoch: 14.5 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15683885037278428		[learning rate: 0.0056667]
	Learning Rate: 0.00566674
	LOSS [training: 0.15683885037278428 | validation: 0.3936754274171742]
	TIME [epoch: 14.5 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16665290387398754		[learning rate: 0.00564]
	Learning Rate: 0.00564004
	LOSS [training: 0.16665290387398754 | validation: 0.33987347703030957]
	TIME [epoch: 14.5 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.145708450562876		[learning rate: 0.0056135]
	Learning Rate: 0.00561346
	LOSS [training: 0.145708450562876 | validation: 0.42300801411068745]
	TIME [epoch: 14.4 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1365742377338896		[learning rate: 0.005587]
	Learning Rate: 0.00558701
	LOSS [training: 0.1365742377338896 | validation: 0.3517976072269796]
	TIME [epoch: 14.5 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15165805125663565		[learning rate: 0.0055607]
	Learning Rate: 0.00556068
	LOSS [training: 0.15165805125663565 | validation: 0.3491125105261069]
	TIME [epoch: 14.5 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13596346172044563		[learning rate: 0.0055345]
	Learning Rate: 0.00553448
	LOSS [training: 0.13596346172044563 | validation: 0.42175536878351305]
	TIME [epoch: 14.4 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15968111851140432		[learning rate: 0.0055084]
	Learning Rate: 0.0055084
	LOSS [training: 0.15968111851140432 | validation: 0.30729767421521326]
	TIME [epoch: 14.4 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1425313726886789		[learning rate: 0.0054824]
	Learning Rate: 0.00548245
	LOSS [training: 0.1425313726886789 | validation: 0.32984318276884644]
	TIME [epoch: 14.5 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15457885271510474		[learning rate: 0.0054566]
	Learning Rate: 0.00545661
	LOSS [training: 0.15457885271510474 | validation: 0.3547884122571786]
	TIME [epoch: 14.4 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15063022148889094		[learning rate: 0.0054309]
	Learning Rate: 0.0054309
	LOSS [training: 0.15063022148889094 | validation: 0.3044542342627121]
	TIME [epoch: 14.5 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11988408151983983		[learning rate: 0.0054053]
	Learning Rate: 0.00540531
	LOSS [training: 0.11988408151983983 | validation: 0.34012450377297804]
	TIME [epoch: 14.5 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15985808435483218		[learning rate: 0.0053798]
	Learning Rate: 0.00537984
	LOSS [training: 0.15985808435483218 | validation: 0.3834319933536209]
	TIME [epoch: 14.4 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14840725316686826		[learning rate: 0.0053545]
	Learning Rate: 0.00535449
	LOSS [training: 0.14840725316686826 | validation: 0.29992170403512775]
	TIME [epoch: 14.4 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14032262946669924		[learning rate: 0.0053293]
	Learning Rate: 0.00532926
	LOSS [training: 0.14032262946669924 | validation: 0.4311621987895051]
	TIME [epoch: 14.5 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1646185849833595		[learning rate: 0.0053041]
	Learning Rate: 0.00530415
	LOSS [training: 0.1646185849833595 | validation: 0.42524641198685686]
	TIME [epoch: 14.4 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14651592720144369		[learning rate: 0.0052792]
	Learning Rate: 0.00527915
	LOSS [training: 0.14651592720144369 | validation: 0.30153041937446057]
	TIME [epoch: 14.5 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13974417594433536		[learning rate: 0.0052543]
	Learning Rate: 0.00525428
	LOSS [training: 0.13974417594433536 | validation: 0.32877905854033235]
	TIME [epoch: 14.5 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14161930407630816		[learning rate: 0.0052295]
	Learning Rate: 0.00522952
	LOSS [training: 0.14161930407630816 | validation: 0.3218227790364695]
	TIME [epoch: 14.5 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2047434146064251		[learning rate: 0.0052049]
	Learning Rate: 0.00520487
	LOSS [training: 0.2047434146064251 | validation: 0.3849356247490162]
	TIME [epoch: 14.4 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13740440238108315		[learning rate: 0.0051803]
	Learning Rate: 0.00518035
	LOSS [training: 0.13740440238108315 | validation: 0.27633662366916023]
	TIME [epoch: 14.5 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11856870749504747		[learning rate: 0.0051559]
	Learning Rate: 0.00515594
	LOSS [training: 0.11856870749504747 | validation: 0.29793815808019164]
	TIME [epoch: 14.4 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1349449460932091		[learning rate: 0.0051316]
	Learning Rate: 0.00513164
	LOSS [training: 0.1349449460932091 | validation: 0.3025878738208222]
	TIME [epoch: 14.5 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13414614671094197		[learning rate: 0.0051075]
	Learning Rate: 0.00510746
	LOSS [training: 0.13414614671094197 | validation: 0.3561289972251147]
	TIME [epoch: 14.5 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15575745994143886		[learning rate: 0.0050834]
	Learning Rate: 0.00508339
	LOSS [training: 0.15575745994143886 | validation: 0.41086689635996654]
	TIME [epoch: 14.4 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14325784581643353		[learning rate: 0.0050594]
	Learning Rate: 0.00505944
	LOSS [training: 0.14325784581643353 | validation: 0.3876524256630119]
	TIME [epoch: 14.5 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15607968546407253		[learning rate: 0.0050356]
	Learning Rate: 0.0050356
	LOSS [training: 0.15607968546407253 | validation: 0.3430261225637721]
	TIME [epoch: 14.4 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1335552647049591		[learning rate: 0.0050119]
	Learning Rate: 0.00501187
	LOSS [training: 0.1335552647049591 | validation: 0.3110041237265662]
	TIME [epoch: 14.5 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14043204158806893		[learning rate: 0.0049883]
	Learning Rate: 0.00498826
	LOSS [training: 0.14043204158806893 | validation: 0.3062300807715019]
	TIME [epoch: 14.5 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13479875102400493		[learning rate: 0.0049648]
	Learning Rate: 0.00496475
	LOSS [training: 0.13479875102400493 | validation: 0.3123918824008607]
	TIME [epoch: 14.4 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14650275426739948		[learning rate: 0.0049414]
	Learning Rate: 0.00494136
	LOSS [training: 0.14650275426739948 | validation: 0.27868061462743665]
	TIME [epoch: 14.5 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13872460095513622		[learning rate: 0.0049181]
	Learning Rate: 0.00491807
	LOSS [training: 0.13872460095513622 | validation: 0.4463222061297528]
	TIME [epoch: 14.5 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14830883505643444		[learning rate: 0.0048949]
	Learning Rate: 0.0048949
	LOSS [training: 0.14830883505643444 | validation: 0.3514513324679025]
	TIME [epoch: 14.5 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12999855835453333		[learning rate: 0.0048718]
	Learning Rate: 0.00487183
	LOSS [training: 0.12999855835453333 | validation: 0.3029607484673608]
	TIME [epoch: 14.5 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11782576877037522		[learning rate: 0.0048489]
	Learning Rate: 0.00484888
	LOSS [training: 0.11782576877037522 | validation: 0.29871099673651524]
	TIME [epoch: 14.5 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13556044376251764		[learning rate: 0.004826]
	Learning Rate: 0.00482603
	LOSS [training: 0.13556044376251764 | validation: 0.3784267238141042]
	TIME [epoch: 14.5 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1392862331693309		[learning rate: 0.0048033]
	Learning Rate: 0.00480329
	LOSS [training: 0.1392862331693309 | validation: 0.41301205640203914]
	TIME [epoch: 14.5 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15462204382787162		[learning rate: 0.0047807]
	Learning Rate: 0.00478065
	LOSS [training: 0.15462204382787162 | validation: 0.3437204021838971]
	TIME [epoch: 14.5 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13996302653691356		[learning rate: 0.0047581]
	Learning Rate: 0.00475813
	LOSS [training: 0.13996302653691356 | validation: 0.33621267829481216]
	TIME [epoch: 14.4 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1247520328539129		[learning rate: 0.0047357]
	Learning Rate: 0.0047357
	LOSS [training: 0.1247520328539129 | validation: 0.3352327865422979]
	TIME [epoch: 14.4 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14299893275031544		[learning rate: 0.0047134]
	Learning Rate: 0.00471339
	LOSS [training: 0.14299893275031544 | validation: 0.345311550641317]
	TIME [epoch: 14.5 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12779020956994103		[learning rate: 0.0046912]
	Learning Rate: 0.00469118
	LOSS [training: 0.12779020956994103 | validation: 0.2969668262240233]
	TIME [epoch: 14.5 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11794887431610661		[learning rate: 0.0046691]
	Learning Rate: 0.00466907
	LOSS [training: 0.11794887431610661 | validation: 0.3279155543173495]
	TIME [epoch: 14.4 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16237173441474373		[learning rate: 0.0046471]
	Learning Rate: 0.00464707
	LOSS [training: 0.16237173441474373 | validation: 0.3475894639127792]
	TIME [epoch: 14.5 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13603928235093588		[learning rate: 0.0046252]
	Learning Rate: 0.00462518
	LOSS [training: 0.13603928235093588 | validation: 0.307600327194387]
	TIME [epoch: 50.8 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1412264521781957		[learning rate: 0.0046034]
	Learning Rate: 0.00460338
	LOSS [training: 0.1412264521781957 | validation: 0.3081071991137244]
	TIME [epoch: 31.2 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1317907272067755		[learning rate: 0.0045817]
	Learning Rate: 0.00458169
	LOSS [training: 0.1317907272067755 | validation: 0.37285831028183436]
	TIME [epoch: 31.1 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13727488922028752		[learning rate: 0.0045601]
	Learning Rate: 0.0045601
	LOSS [training: 0.13727488922028752 | validation: 0.36417882149734976]
	TIME [epoch: 31.1 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14402576469134673		[learning rate: 0.0045386]
	Learning Rate: 0.00453861
	LOSS [training: 0.14402576469134673 | validation: 0.4013035178688751]
	TIME [epoch: 31.1 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19043365098652223		[learning rate: 0.0045172]
	Learning Rate: 0.00451723
	LOSS [training: 0.19043365098652223 | validation: 0.34471684472764474]
	TIME [epoch: 31.1 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12933858550985528		[learning rate: 0.0044959]
	Learning Rate: 0.00449594
	LOSS [training: 0.12933858550985528 | validation: 0.3239057412260103]
	TIME [epoch: 31.1 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12920302731214195		[learning rate: 0.0044748]
	Learning Rate: 0.00447475
	LOSS [training: 0.12920302731214195 | validation: 0.33749541934533167]
	TIME [epoch: 31.1 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1563616666534623		[learning rate: 0.0044537]
	Learning Rate: 0.00445367
	LOSS [training: 0.1563616666534623 | validation: 0.35644288560103404]
	TIME [epoch: 31.6 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13088529318970274		[learning rate: 0.0044327]
	Learning Rate: 0.00443268
	LOSS [training: 0.13088529318970274 | validation: 0.2785071753398567]
	TIME [epoch: 31.1 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12571334981426768		[learning rate: 0.0044118]
	Learning Rate: 0.0044118
	LOSS [training: 0.12571334981426768 | validation: 0.33711641681638116]
	TIME [epoch: 31.1 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14245521685854057		[learning rate: 0.004391]
	Learning Rate: 0.00439101
	LOSS [training: 0.14245521685854057 | validation: 0.3051571520589908]
	TIME [epoch: 31.1 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13676223987776753		[learning rate: 0.0043703]
	Learning Rate: 0.00437032
	LOSS [training: 0.13676223987776753 | validation: 0.3624210547354784]
	TIME [epoch: 31.1 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12936882690114093		[learning rate: 0.0043497]
	Learning Rate: 0.00434972
	LOSS [training: 0.12936882690114093 | validation: 0.33165385927929986]
	TIME [epoch: 31.1 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12540567314967424		[learning rate: 0.0043292]
	Learning Rate: 0.00432923
	LOSS [training: 0.12540567314967424 | validation: 0.3938198816290179]
	TIME [epoch: 31.1 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13264279382404648		[learning rate: 0.0043088]
	Learning Rate: 0.00430883
	LOSS [training: 0.13264279382404648 | validation: 0.344512562185167]
	TIME [epoch: 31.1 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13803914336501566		[learning rate: 0.0042885]
	Learning Rate: 0.00428852
	LOSS [training: 0.13803914336501566 | validation: 0.301804704823091]
	TIME [epoch: 31.1 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14362383110322358		[learning rate: 0.0042683]
	Learning Rate: 0.00426831
	LOSS [training: 0.14362383110322358 | validation: 0.3739809809087272]
	TIME [epoch: 31.1 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13584693201215803		[learning rate: 0.0042482]
	Learning Rate: 0.0042482
	LOSS [training: 0.13584693201215803 | validation: 0.3771035198006057]
	TIME [epoch: 31.1 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12590239100241218		[learning rate: 0.0042282]
	Learning Rate: 0.00422818
	LOSS [training: 0.12590239100241218 | validation: 0.30070323915625996]
	TIME [epoch: 31.1 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12739127148119003		[learning rate: 0.0042083]
	Learning Rate: 0.00420826
	LOSS [training: 0.12739127148119003 | validation: 0.35601465498624013]
	TIME [epoch: 31.1 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15242620969177262		[learning rate: 0.0041884]
	Learning Rate: 0.00418843
	LOSS [training: 0.15242620969177262 | validation: 0.3710773307592922]
	TIME [epoch: 31.1 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13302614415745911		[learning rate: 0.0041687]
	Learning Rate: 0.00416869
	LOSS [training: 0.13302614415745911 | validation: 0.4306262515719277]
	TIME [epoch: 31.1 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13329203940936735		[learning rate: 0.0041491]
	Learning Rate: 0.00414905
	LOSS [training: 0.13329203940936735 | validation: 0.3006554697911754]
	TIME [epoch: 31.1 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11786161388122074		[learning rate: 0.0041295]
	Learning Rate: 0.0041295
	LOSS [training: 0.11786161388122074 | validation: 0.33453563220619853]
	TIME [epoch: 31.1 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1462098153891367		[learning rate: 0.00411]
	Learning Rate: 0.00411004
	LOSS [training: 0.1462098153891367 | validation: 0.371914280326177]
	TIME [epoch: 31.2 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1293420476663772		[learning rate: 0.0040907]
	Learning Rate: 0.00409067
	LOSS [training: 0.1293420476663772 | validation: 0.37353315513630486]
	TIME [epoch: 31.1 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11517970049443241		[learning rate: 0.0040714]
	Learning Rate: 0.0040714
	LOSS [training: 0.11517970049443241 | validation: 0.3895502691320905]
	TIME [epoch: 31.1 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1532006982953058		[learning rate: 0.0040522]
	Learning Rate: 0.00405221
	LOSS [training: 0.1532006982953058 | validation: 0.2978577022055942]
	TIME [epoch: 31.1 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11391502606131684		[learning rate: 0.0040331]
	Learning Rate: 0.00403312
	LOSS [training: 0.11391502606131684 | validation: 0.3315776755446922]
	TIME [epoch: 31.1 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15384289711629173		[learning rate: 0.0040141]
	Learning Rate: 0.00401411
	LOSS [training: 0.15384289711629173 | validation: 0.43102317596993445]
	TIME [epoch: 31.1 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1502749693561426		[learning rate: 0.0039952]
	Learning Rate: 0.0039952
	LOSS [training: 0.1502749693561426 | validation: 0.3196915361424396]
	TIME [epoch: 31.1 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13717295356132336		[learning rate: 0.0039764]
	Learning Rate: 0.00397637
	LOSS [training: 0.13717295356132336 | validation: 0.3480780614610189]
	TIME [epoch: 31.2 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12264725629900187		[learning rate: 0.0039576]
	Learning Rate: 0.00395764
	LOSS [training: 0.12264725629900187 | validation: 0.28003214218132805]
	TIME [epoch: 31.1 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16807902016736548		[learning rate: 0.003939]
	Learning Rate: 0.00393899
	LOSS [training: 0.16807902016736548 | validation: 0.3479919279619963]
	TIME [epoch: 31.1 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1455573927275114		[learning rate: 0.0039204]
	Learning Rate: 0.00392043
	LOSS [training: 0.1455573927275114 | validation: 0.33656324976921387]
	TIME [epoch: 31.1 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13220872717419954		[learning rate: 0.003902]
	Learning Rate: 0.00390195
	LOSS [training: 0.13220872717419954 | validation: 0.3463662782213169]
	TIME [epoch: 31.1 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12911281760061424		[learning rate: 0.0038836]
	Learning Rate: 0.00388357
	LOSS [training: 0.12911281760061424 | validation: 0.4295720680283191]
	TIME [epoch: 31.1 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14858107859160682		[learning rate: 0.0038653]
	Learning Rate: 0.00386527
	LOSS [training: 0.14858107859160682 | validation: 0.34307679381115413]
	TIME [epoch: 31.1 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11927811646140504		[learning rate: 0.0038471]
	Learning Rate: 0.00384705
	LOSS [training: 0.11927811646140504 | validation: 0.3419430100096636]
	TIME [epoch: 31.1 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1406326233305547		[learning rate: 0.0038289]
	Learning Rate: 0.00382893
	LOSS [training: 0.1406326233305547 | validation: 0.3194514132469093]
	TIME [epoch: 31.1 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1340292950062839		[learning rate: 0.0038109]
	Learning Rate: 0.00381088
	LOSS [training: 0.1340292950062839 | validation: 0.3595068545324499]
	TIME [epoch: 31.1 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13797721260070986		[learning rate: 0.0037929]
	Learning Rate: 0.00379293
	LOSS [training: 0.13797721260070986 | validation: 0.3340448336200061]
	TIME [epoch: 31.1 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13003644213178955		[learning rate: 0.0037751]
	Learning Rate: 0.00377505
	LOSS [training: 0.13003644213178955 | validation: 0.31291726215449783]
	TIME [epoch: 31.2 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12008682590588549		[learning rate: 0.0037573]
	Learning Rate: 0.00375726
	LOSS [training: 0.12008682590588549 | validation: 0.3081093595539004]
	TIME [epoch: 31.1 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12337060976641614		[learning rate: 0.0037396]
	Learning Rate: 0.00373956
	LOSS [training: 0.12337060976641614 | validation: 0.3230017831677959]
	TIME [epoch: 31.1 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1314730872727373		[learning rate: 0.0037219]
	Learning Rate: 0.00372194
	LOSS [training: 0.1314730872727373 | validation: 0.3175242981890275]
	TIME [epoch: 31.1 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15484877972856756		[learning rate: 0.0037044]
	Learning Rate: 0.0037044
	LOSS [training: 0.15484877972856756 | validation: 0.31062918064551]
	TIME [epoch: 31.1 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13234110239247646		[learning rate: 0.0036869]
	Learning Rate: 0.00368695
	LOSS [training: 0.13234110239247646 | validation: 0.3229008443190754]
	TIME [epoch: 31.1 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14726545780742123		[learning rate: 0.0036696]
	Learning Rate: 0.00366957
	LOSS [training: 0.14726545780742123 | validation: 0.43044289258063695]
	TIME [epoch: 31.1 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17538209092631213		[learning rate: 0.0036523]
	Learning Rate: 0.00365228
	LOSS [training: 0.17538209092631213 | validation: 0.31359892564619507]
	TIME [epoch: 31.1 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13819978575735528		[learning rate: 0.0036351]
	Learning Rate: 0.00363507
	LOSS [training: 0.13819978575735528 | validation: 0.31809378764328183]
	TIME [epoch: 31.1 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13054685054939633		[learning rate: 0.0036179]
	Learning Rate: 0.00361794
	LOSS [training: 0.13054685054939633 | validation: 0.31757780020071275]
	TIME [epoch: 31.1 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13335786637369412		[learning rate: 0.0036009]
	Learning Rate: 0.00360089
	LOSS [training: 0.13335786637369412 | validation: 0.3231961898940012]
	TIME [epoch: 31.1 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12577449885945677		[learning rate: 0.0035839]
	Learning Rate: 0.00358393
	LOSS [training: 0.12577449885945677 | validation: 0.35253712618347743]
	TIME [epoch: 31.2 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11759867634234801		[learning rate: 0.003567]
	Learning Rate: 0.00356704
	LOSS [training: 0.11759867634234801 | validation: 0.30557077561195367]
	TIME [epoch: 31.1 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14342266658507047		[learning rate: 0.0035502]
	Learning Rate: 0.00355023
	LOSS [training: 0.14342266658507047 | validation: 0.2815833348569328]
	TIME [epoch: 31.1 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12091422762843859		[learning rate: 0.0035335]
	Learning Rate: 0.0035335
	LOSS [training: 0.12091422762843859 | validation: 0.294141280953743]
	TIME [epoch: 31.1 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12944736710815394		[learning rate: 0.0035168]
	Learning Rate: 0.00351685
	LOSS [training: 0.12944736710815394 | validation: 0.33236734799653755]
	TIME [epoch: 31.1 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13147618975461256		[learning rate: 0.0035003]
	Learning Rate: 0.00350028
	LOSS [training: 0.13147618975461256 | validation: 0.32886122738680373]
	TIME [epoch: 31.1 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14028508798062858		[learning rate: 0.0034838]
	Learning Rate: 0.00348378
	LOSS [training: 0.14028508798062858 | validation: 0.3928117755238694]
	TIME [epoch: 31.1 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13210641085821728		[learning rate: 0.0034674]
	Learning Rate: 0.00346737
	LOSS [training: 0.13210641085821728 | validation: 0.2972934962452357]
	TIME [epoch: 31.1 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12796939655189032		[learning rate: 0.003451]
	Learning Rate: 0.00345103
	LOSS [training: 0.12796939655189032 | validation: 0.3606476802631851]
	TIME [epoch: 31.1 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1238298684126348		[learning rate: 0.0034348]
	Learning Rate: 0.00343477
	LOSS [training: 0.1238298684126348 | validation: 0.31939036413923233]
	TIME [epoch: 31.1 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11062223460352083		[learning rate: 0.0034186]
	Learning Rate: 0.00341858
	LOSS [training: 0.11062223460352083 | validation: 0.42376975487840896]
	TIME [epoch: 31.1 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12300705528996522		[learning rate: 0.0034025]
	Learning Rate: 0.00340247
	LOSS [training: 0.12300705528996522 | validation: 0.314526725725384]
	TIME [epoch: 31.2 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13989256225941754		[learning rate: 0.0033864]
	Learning Rate: 0.00338644
	LOSS [training: 0.13989256225941754 | validation: 0.2949756832792736]
	TIME [epoch: 31.1 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12545651845121208		[learning rate: 0.0033705]
	Learning Rate: 0.00337048
	LOSS [training: 0.12545651845121208 | validation: 0.3108304278569784]
	TIME [epoch: 31.1 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12003829000154187		[learning rate: 0.0033546]
	Learning Rate: 0.0033546
	LOSS [training: 0.12003829000154187 | validation: 0.31036072202679854]
	TIME [epoch: 31.1 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13197339883327977		[learning rate: 0.0033388]
	Learning Rate: 0.00333879
	LOSS [training: 0.13197339883327977 | validation: 0.27556130454624783]
	TIME [epoch: 31.1 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13018455255783062		[learning rate: 0.0033231]
	Learning Rate: 0.00332306
	LOSS [training: 0.13018455255783062 | validation: 0.29685593662137877]
	TIME [epoch: 31.1 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12431449221085597		[learning rate: 0.0033074]
	Learning Rate: 0.0033074
	LOSS [training: 0.12431449221085597 | validation: 0.3087583276729561]
	TIME [epoch: 31.1 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.149760644411809		[learning rate: 0.0032918]
	Learning Rate: 0.00329182
	LOSS [training: 0.149760644411809 | validation: 0.28928096190495606]
	TIME [epoch: 31.1 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12099164917404535		[learning rate: 0.0032763]
	Learning Rate: 0.00327631
	LOSS [training: 0.12099164917404535 | validation: 0.3039931878798217]
	TIME [epoch: 31.1 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1405399233886408		[learning rate: 0.0032609]
	Learning Rate: 0.00326087
	LOSS [training: 0.1405399233886408 | validation: 0.28305194921358845]
	TIME [epoch: 31.1 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13280453190092947		[learning rate: 0.0032455]
	Learning Rate: 0.0032455
	LOSS [training: 0.13280453190092947 | validation: 0.3326296889043965]
	TIME [epoch: 31.1 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12169090543868356		[learning rate: 0.0032302]
	Learning Rate: 0.00323021
	LOSS [training: 0.12169090543868356 | validation: 0.3230491711973883]
	TIME [epoch: 31.1 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12765373327519497		[learning rate: 0.003215]
	Learning Rate: 0.00321499
	LOSS [training: 0.12765373327519497 | validation: 0.27572697460990275]
	TIME [epoch: 31.1 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1190989840889205		[learning rate: 0.0031998]
	Learning Rate: 0.00319984
	LOSS [training: 0.1190989840889205 | validation: 0.34036039510845617]
	TIME [epoch: 31.2 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10756381255225675		[learning rate: 0.0031848]
	Learning Rate: 0.00318476
	LOSS [training: 0.10756381255225675 | validation: 0.30704347114793756]
	TIME [epoch: 31.1 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1277541063431612		[learning rate: 0.0031698]
	Learning Rate: 0.00316975
	LOSS [training: 0.1277541063431612 | validation: 0.3314247610299426]
	TIME [epoch: 31.1 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16089638398947165		[learning rate: 0.0031548]
	Learning Rate: 0.00315482
	LOSS [training: 0.16089638398947165 | validation: 0.312110268196391]
	TIME [epoch: 31.1 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10530872239298594		[learning rate: 0.00314]
	Learning Rate: 0.00313995
	LOSS [training: 0.10530872239298594 | validation: 0.32736538376940805]
	TIME [epoch: 31.1 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10809850824582919		[learning rate: 0.0031252]
	Learning Rate: 0.00312516
	LOSS [training: 0.10809850824582919 | validation: 0.3286660961697076]
	TIME [epoch: 31.1 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14245356130150477		[learning rate: 0.0031104]
	Learning Rate: 0.00311043
	LOSS [training: 0.14245356130150477 | validation: 0.2961936831331663]
	TIME [epoch: 31.1 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13148266597771993		[learning rate: 0.0030958]
	Learning Rate: 0.00309577
	LOSS [training: 0.13148266597771993 | validation: 0.3095723728178997]
	TIME [epoch: 31.1 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1641305063470662		[learning rate: 0.0030812]
	Learning Rate: 0.00308119
	LOSS [training: 0.1641305063470662 | validation: 0.38251211541472807]
	TIME [epoch: 31.1 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12410125720565451		[learning rate: 0.0030667]
	Learning Rate: 0.00306667
	LOSS [training: 0.12410125720565451 | validation: 0.2945677182566453]
	TIME [epoch: 31.1 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11612359394454498		[learning rate: 0.0030522]
	Learning Rate: 0.00305222
	LOSS [training: 0.11612359394454498 | validation: 0.3135333333772763]
	TIME [epoch: 31.1 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1174624311075732		[learning rate: 0.0030378]
	Learning Rate: 0.00303783
	LOSS [training: 0.1174624311075732 | validation: 0.3098356647232913]
	TIME [epoch: 31.1 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13140640367976858		[learning rate: 0.0030235]
	Learning Rate: 0.00302352
	LOSS [training: 0.13140640367976858 | validation: 0.42909749446867285]
	TIME [epoch: 31.1 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.131847682735264		[learning rate: 0.0030093]
	Learning Rate: 0.00300927
	LOSS [training: 0.131847682735264 | validation: 0.2990454839265891]
	TIME [epoch: 31.1 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12354109482420184		[learning rate: 0.0029951]
	Learning Rate: 0.00299509
	LOSS [training: 0.12354109482420184 | validation: 0.32627540520014836]
	TIME [epoch: 31.1 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13511817330910034		[learning rate: 0.002981]
	Learning Rate: 0.00298098
	LOSS [training: 0.13511817330910034 | validation: 0.3372177122401492]
	TIME [epoch: 31.1 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12402894669196957		[learning rate: 0.0029669]
	Learning Rate: 0.00296693
	LOSS [training: 0.12402894669196957 | validation: 0.28719763160512596]
	TIME [epoch: 31.1 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.123750661183847		[learning rate: 0.002953]
	Learning Rate: 0.00295295
	LOSS [training: 0.123750661183847 | validation: 0.31974609434515155]
	TIME [epoch: 31 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11089153478898535		[learning rate: 0.002939]
	Learning Rate: 0.00293904
	LOSS [training: 0.11089153478898535 | validation: 0.3149838467545461]
	TIME [epoch: 31.1 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12288792131289486		[learning rate: 0.0029252]
	Learning Rate: 0.00292519
	LOSS [training: 0.12288792131289486 | validation: 0.3433968601432807]
	TIME [epoch: 31.1 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1373654872018156		[learning rate: 0.0029114]
	Learning Rate: 0.0029114
	LOSS [training: 0.1373654872018156 | validation: 0.3519310857182762]
	TIME [epoch: 31.1 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13196226811606113		[learning rate: 0.0028977]
	Learning Rate: 0.00289769
	LOSS [training: 0.13196226811606113 | validation: 0.3274647465183281]
	TIME [epoch: 31.1 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11281063106586887		[learning rate: 0.002884]
	Learning Rate: 0.00288403
	LOSS [training: 0.11281063106586887 | validation: 0.3410085097640087]
	TIME [epoch: 84.3 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12608727337165412		[learning rate: 0.0028704]
	Learning Rate: 0.00287044
	LOSS [training: 0.12608727337165412 | validation: 0.31857251395938924]
	TIME [epoch: 64.4 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12599044766567602		[learning rate: 0.0028569]
	Learning Rate: 0.00285692
	LOSS [training: 0.12599044766567602 | validation: 0.3554463868939152]
	TIME [epoch: 64.4 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13785160256179466		[learning rate: 0.0028435]
	Learning Rate: 0.00284345
	LOSS [training: 0.13785160256179466 | validation: 0.31116129811369847]
	TIME [epoch: 64.4 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12162846283158534		[learning rate: 0.0028301]
	Learning Rate: 0.00283005
	LOSS [training: 0.12162846283158534 | validation: 0.314905560217781]
	TIME [epoch: 64.4 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11839098597166625		[learning rate: 0.0028167]
	Learning Rate: 0.00281672
	LOSS [training: 0.11839098597166625 | validation: 0.30600499161286837]
	TIME [epoch: 64.4 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12009161631050917		[learning rate: 0.0028034]
	Learning Rate: 0.00280345
	LOSS [training: 0.12009161631050917 | validation: 0.31056444914463244]
	TIME [epoch: 64.4 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1342728726732882		[learning rate: 0.0027902]
	Learning Rate: 0.00279024
	LOSS [training: 0.1342728726732882 | validation: 0.30256272689185904]
	TIME [epoch: 64.4 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13783627222901826		[learning rate: 0.0027771]
	Learning Rate: 0.00277709
	LOSS [training: 0.13783627222901826 | validation: 0.2879069510449055]
	TIME [epoch: 64.4 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14255670107907428		[learning rate: 0.002764]
	Learning Rate: 0.002764
	LOSS [training: 0.14255670107907428 | validation: 0.31863845504564464]
	TIME [epoch: 64.3 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10593298508609644		[learning rate: 0.002751]
	Learning Rate: 0.00275098
	LOSS [training: 0.10593298508609644 | validation: 0.299090906757504]
	TIME [epoch: 64.3 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11676135887884703		[learning rate: 0.002738]
	Learning Rate: 0.00273802
	LOSS [training: 0.11676135887884703 | validation: 0.3317639156716919]
	TIME [epoch: 64.4 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13321474402621467		[learning rate: 0.0027251]
	Learning Rate: 0.00272511
	LOSS [training: 0.13321474402621467 | validation: 0.30287923291663393]
	TIME [epoch: 64.3 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09789850948170799		[learning rate: 0.0027123]
	Learning Rate: 0.00271227
	LOSS [training: 0.09789850948170799 | validation: 0.3727494434755421]
	TIME [epoch: 64.3 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12336446507489499		[learning rate: 0.0026995]
	Learning Rate: 0.00269949
	LOSS [training: 0.12336446507489499 | validation: 0.3211077923444253]
	TIME [epoch: 64.4 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12154225800160334		[learning rate: 0.0026868]
	Learning Rate: 0.00268677
	LOSS [training: 0.12154225800160334 | validation: 0.3551901544780438]
	TIME [epoch: 64.4 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12240615714128274		[learning rate: 0.0026741]
	Learning Rate: 0.00267411
	LOSS [training: 0.12240615714128274 | validation: 0.33765183786297365]
	TIME [epoch: 64.4 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10991981376632812		[learning rate: 0.0026615]
	Learning Rate: 0.00266151
	LOSS [training: 0.10991981376632812 | validation: 0.284377867741623]
	TIME [epoch: 64.4 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10719875584788124		[learning rate: 0.002649]
	Learning Rate: 0.00264897
	LOSS [training: 0.10719875584788124 | validation: 0.3676868122306801]
	TIME [epoch: 64.4 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11732714431573167		[learning rate: 0.0026365]
	Learning Rate: 0.00263649
	LOSS [training: 0.11732714431573167 | validation: 0.3364219498053441]
	TIME [epoch: 64.4 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11355050930252508		[learning rate: 0.0026241]
	Learning Rate: 0.00262406
	LOSS [training: 0.11355050930252508 | validation: 0.30018164480963855]
	TIME [epoch: 64.4 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1257022924209873		[learning rate: 0.0026117]
	Learning Rate: 0.0026117
	LOSS [training: 0.1257022924209873 | validation: 0.33060289486034405]
	TIME [epoch: 64.4 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09818745774331464		[learning rate: 0.0025994]
	Learning Rate: 0.00259939
	LOSS [training: 0.09818745774331464 | validation: 0.32615991583090964]
	TIME [epoch: 64.4 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13651485220379184		[learning rate: 0.0025871]
	Learning Rate: 0.00258714
	LOSS [training: 0.13651485220379184 | validation: 0.44782207871556867]
	TIME [epoch: 64.3 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14413771184267707		[learning rate: 0.002575]
	Learning Rate: 0.00257495
	LOSS [training: 0.14413771184267707 | validation: 0.3189402866492954]
	TIME [epoch: 64.3 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11294930009908326		[learning rate: 0.0025628]
	Learning Rate: 0.00256282
	LOSS [training: 0.11294930009908326 | validation: 0.28453962941939875]
	TIME [epoch: 64.3 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1473338943612647		[learning rate: 0.0025507]
	Learning Rate: 0.00255074
	LOSS [training: 0.1473338943612647 | validation: 0.3407216645726295]
	TIME [epoch: 64.4 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.128060241384518		[learning rate: 0.0025387]
	Learning Rate: 0.00253872
	LOSS [training: 0.128060241384518 | validation: 0.3505067412863446]
	TIME [epoch: 64.3 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11456633662049401		[learning rate: 0.0025268]
	Learning Rate: 0.00252676
	LOSS [training: 0.11456633662049401 | validation: 0.35920053834618754]
	TIME [epoch: 64.4 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09994231073260632		[learning rate: 0.0025149]
	Learning Rate: 0.00251485
	LOSS [training: 0.09994231073260632 | validation: 0.3084215188106905]
	TIME [epoch: 64.3 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12875862256787618		[learning rate: 0.002503]
	Learning Rate: 0.002503
	LOSS [training: 0.12875862256787618 | validation: 0.30083967335977857]
	TIME [epoch: 64.3 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12501470399864195		[learning rate: 0.0024912]
	Learning Rate: 0.00249121
	LOSS [training: 0.12501470399864195 | validation: 0.2959959397375318]
	TIME [epoch: 64.3 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11855477637878287		[learning rate: 0.0024795]
	Learning Rate: 0.00247947
	LOSS [training: 0.11855477637878287 | validation: 0.32290625054961497]
	TIME [epoch: 64.4 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1244246412980721		[learning rate: 0.0024678]
	Learning Rate: 0.00246779
	LOSS [training: 0.1244246412980721 | validation: 0.29840765913166745]
	TIME [epoch: 64.3 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12986066072757851		[learning rate: 0.0024562]
	Learning Rate: 0.00245616
	LOSS [training: 0.12986066072757851 | validation: 0.3219110027118347]
	TIME [epoch: 64.4 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v15b_20240718_174758/states/model_facs_v4_dec2b_2dpca_v15b_335.pth
Halted early. No improvement in validation loss for 200 epochs.
Finished training in 7440.611 seconds.
