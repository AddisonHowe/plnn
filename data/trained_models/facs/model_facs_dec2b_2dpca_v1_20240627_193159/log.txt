Args:
Namespace(name='model_facs_dec2b_2dpca_v1', outdir='out/model_training/model_facs_dec2b_2dpca_v1', training_data='data/training_data/facs/pca/dec2_fitonsubset/transition2_subset_ce_pn_m_pc12/training', validation_data='data/training_data/facs/pca/dec2_fitonsubset/transition2_subset_ce_pn_m_pc12/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=10, batch_size=50, patience=200, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, ncells_sample=500, model_do_sample=False, dt=0.001, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 2037635554

Training model...

Saving initial model state to: out/model_training/model_facs_dec2b_2dpca_v1_20240627_193159/states/model_facs_dec2b_2dpca_v1_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7044820327985427		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7044820327985427 | validation: 0.5563369746780529]
	TIME [epoch: 59.8 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v1_20240627_193159/states/model_facs_dec2b_2dpca_v1_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4700029324154459		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4700029324154459 | validation: 0.4979953717540217]
	TIME [epoch: 36.6 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v1_20240627_193159/states/model_facs_dec2b_2dpca_v1_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4001316687530731		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4001316687530731 | validation: 0.49056542369203493]
	TIME [epoch: 36.6 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v1_20240627_193159/states/model_facs_dec2b_2dpca_v1_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3748906403850342		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3748906403850342 | validation: 0.44376568805385025]
	TIME [epoch: 36.6 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v1_20240627_193159/states/model_facs_dec2b_2dpca_v1_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35078823675539683		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.35078823675539683 | validation: 0.4150745749136496]
	TIME [epoch: 36.6 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v1_20240627_193159/states/model_facs_dec2b_2dpca_v1_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3404872361553096		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3404872361553096 | validation: 0.4684902707477583]
	TIME [epoch: 36.6 sec]
EPOCH 7/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32897483361358837		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.32897483361358837 | validation: 0.3542863366256238]
	TIME [epoch: 36.6 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v1_20240627_193159/states/model_facs_dec2b_2dpca_v1_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28176774741391375		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.28176774741391375 | validation: 0.3220473979448055]
	TIME [epoch: 36.6 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v1_20240627_193159/states/model_facs_dec2b_2dpca_v1_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3246136633450721		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3246136633450721 | validation: 0.31916985057933445]
	TIME [epoch: 36.5 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v1_20240627_193159/states/model_facs_dec2b_2dpca_v1_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23675432147054692		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23675432147054692 | validation: 0.3045907651465917]
	TIME [epoch: 36.6 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v1_20240627_193159/states/model_facs_dec2b_2dpca_v1_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2306657419583714		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2306657419583714 | validation: 0.2780174647731006]
	TIME [epoch: 36.6 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v1_20240627_193159/states/model_facs_dec2b_2dpca_v1_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2247356561627359		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2247356561627359 | validation: 0.2724842548596307]
	TIME [epoch: 36.6 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v1_20240627_193159/states/model_facs_dec2b_2dpca_v1_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22078959726898395		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22078959726898395 | validation: 0.26294698088748236]
	TIME [epoch: 36.5 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v1_20240627_193159/states/model_facs_dec2b_2dpca_v1_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20108464801563128		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20108464801563128 | validation: 0.3326262527863419]
	TIME [epoch: 36.5 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2047360979635707		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2047360979635707 | validation: 0.26485488823610925]
	TIME [epoch: 36.6 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21147065349161337		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.21147065349161337 | validation: 0.265426299735418]
	TIME [epoch: 36.6 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1801486314896276		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1801486314896276 | validation: 0.2434482686234951]
	TIME [epoch: 36.6 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v1_20240627_193159/states/model_facs_dec2b_2dpca_v1_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21300284738418437		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.21300284738418437 | validation: 0.32809192563384265]
	TIME [epoch: 36.6 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20096936065365184		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20096936065365184 | validation: 0.2482870402560201]
	TIME [epoch: 36.6 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16846744204268854		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16846744204268854 | validation: 0.23454406710286427]
	TIME [epoch: 36.6 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v1_20240627_193159/states/model_facs_dec2b_2dpca_v1_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18259694669439056		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18259694669439056 | validation: 0.23075194791134282]
	TIME [epoch: 36.6 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v1_20240627_193159/states/model_facs_dec2b_2dpca_v1_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15404753773059848		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15404753773059848 | validation: 0.2364492112968323]
	TIME [epoch: 36.6 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18919081966589837		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18919081966589837 | validation: 0.21854255736955297]
	TIME [epoch: 36.6 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v1_20240627_193159/states/model_facs_dec2b_2dpca_v1_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1638068991334826		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1638068991334826 | validation: 0.22837864017428047]
	TIME [epoch: 36.6 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14987565190312732		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14987565190312732 | validation: 0.2416440792696283]
	TIME [epoch: 36.6 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15610110997027773		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15610110997027773 | validation: 0.29753123609563903]
	TIME [epoch: 36.6 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19744770145693535		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.19744770145693535 | validation: 0.22527487941826865]
	TIME [epoch: 36.6 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1352311078416419		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1352311078416419 | validation: 0.2363270368153259]
	TIME [epoch: 36.6 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17083367090251808		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17083367090251808 | validation: 0.2351515775288208]
	TIME [epoch: 36.6 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15199725145554197		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15199725145554197 | validation: 0.2626455496808927]
	TIME [epoch: 36.6 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18656334912976938		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18656334912976938 | validation: 0.21559240267994165]
	TIME [epoch: 36.5 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v1_20240627_193159/states/model_facs_dec2b_2dpca_v1_31.pth
	Model improved!!!
EPOCH 32/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14215791370674585		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14215791370674585 | validation: 0.2413467233322479]
	TIME [epoch: 36.6 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1614636167168278		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1614636167168278 | validation: 0.1957006714112988]
	TIME [epoch: 36.6 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v1_20240627_193159/states/model_facs_dec2b_2dpca_v1_33.pth
	Model improved!!!
EPOCH 34/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14108671327543948		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14108671327543948 | validation: 0.20153557292984547]
	TIME [epoch: 36.6 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14673159256695437		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14673159256695437 | validation: 0.20030063142300214]
	TIME [epoch: 36.4 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14628299723313726		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14628299723313726 | validation: 0.18635867916285528]
	TIME [epoch: 36.6 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v1_20240627_193159/states/model_facs_dec2b_2dpca_v1_36.pth
	Model improved!!!
EPOCH 37/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14289937465246486		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14289937465246486 | validation: 0.25469893623446843]
	TIME [epoch: 36.6 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16504696706965238		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16504696706965238 | validation: 0.208533818023337]
	TIME [epoch: 36.6 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15180902188173667		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15180902188173667 | validation: 0.19525341765287296]
	TIME [epoch: 36.6 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15057245778291414		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15057245778291414 | validation: 0.20719689003921485]
	TIME [epoch: 36.6 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13947839292923322		[learning rate: 0.0099646]
	Learning Rate: 0.00996464
	LOSS [training: 0.13947839292923322 | validation: 0.20078664334991092]
	TIME [epoch: 36.6 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1474957247937117		[learning rate: 0.0099206]
	Learning Rate: 0.00992061
	LOSS [training: 0.1474957247937117 | validation: 0.20899916904725488]
	TIME [epoch: 36.6 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15288522791487885		[learning rate: 0.0098768]
	Learning Rate: 0.00987678
	LOSS [training: 0.15288522791487885 | validation: 0.21576919127406186]
	TIME [epoch: 36.6 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13173848024128149		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 0.13173848024128149 | validation: 0.22831419806792605]
	TIME [epoch: 36.6 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1431179883662697		[learning rate: 0.0097897]
	Learning Rate: 0.0097897
	LOSS [training: 0.1431179883662697 | validation: 0.23514105886415995]
	TIME [epoch: 36.6 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12804753236832672		[learning rate: 0.0097464]
	Learning Rate: 0.00974644
	LOSS [training: 0.12804753236832672 | validation: 0.18852167586052815]
	TIME [epoch: 36.6 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12405033946972266		[learning rate: 0.0097034]
	Learning Rate: 0.00970338
	LOSS [training: 0.12405033946972266 | validation: 0.20116476080319834]
	TIME [epoch: 36.6 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14026991938988617		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 0.14026991938988617 | validation: 0.17921232035394266]
	TIME [epoch: 36.6 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v1_20240627_193159/states/model_facs_dec2b_2dpca_v1_48.pth
	Model improved!!!
EPOCH 49/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14869722219774778		[learning rate: 0.0096178]
	Learning Rate: 0.00961783
	LOSS [training: 0.14869722219774778 | validation: 0.2040055531497031]
	TIME [epoch: 36.6 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13536256411047265		[learning rate: 0.0095753]
	Learning Rate: 0.00957533
	LOSS [training: 0.13536256411047265 | validation: 0.21706674293016542]
	TIME [epoch: 36.6 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13562924017852804		[learning rate: 0.009533]
	Learning Rate: 0.00953303
	LOSS [training: 0.13562924017852804 | validation: 0.22527250376443825]
	TIME [epoch: 36.5 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13644118512260067		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 0.13644118512260067 | validation: 0.22079654255516298]
	TIME [epoch: 36.6 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13734523399339557		[learning rate: 0.009449]
	Learning Rate: 0.00944897
	LOSS [training: 0.13734523399339557 | validation: 0.1901252390741489]
	TIME [epoch: 36.6 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1323866180886076		[learning rate: 0.0094072]
	Learning Rate: 0.00940722
	LOSS [training: 0.1323866180886076 | validation: 0.18839663421020536]
	TIME [epoch: 36.6 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12323551205303107		[learning rate: 0.0093657]
	Learning Rate: 0.00936566
	LOSS [training: 0.12323551205303107 | validation: 0.17009623996366946]
	TIME [epoch: 36.6 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v1_20240627_193159/states/model_facs_dec2b_2dpca_v1_55.pth
	Model improved!!!
EPOCH 56/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12009860132935843		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 0.12009860132935843 | validation: 0.19158295773238582]
	TIME [epoch: 36.6 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13412120673435798		[learning rate: 0.0092831]
	Learning Rate: 0.00928308
	LOSS [training: 0.13412120673435798 | validation: 0.22835906371651069]
	TIME [epoch: 36.6 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13355299381377608		[learning rate: 0.0092421]
	Learning Rate: 0.00924207
	LOSS [training: 0.13355299381377608 | validation: 0.17881134435107218]
	TIME [epoch: 36.6 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11537160175724233		[learning rate: 0.0092012]
	Learning Rate: 0.00920124
	LOSS [training: 0.11537160175724233 | validation: 0.16476769016648068]
	TIME [epoch: 36.6 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v1_20240627_193159/states/model_facs_dec2b_2dpca_v1_59.pth
	Model improved!!!
EPOCH 60/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12891618644325092		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 0.12891618644325092 | validation: 0.19098286758381292]
	TIME [epoch: 36.6 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11914183748679645		[learning rate: 0.0091201]
	Learning Rate: 0.00912011
	LOSS [training: 0.11914183748679645 | validation: 0.17830231357034654]
	TIME [epoch: 36.6 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1247871713875149		[learning rate: 0.0090798]
	Learning Rate: 0.00907981
	LOSS [training: 0.1247871713875149 | validation: 0.1945642309752557]
	TIME [epoch: 36.6 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11153369408430813		[learning rate: 0.0090397]
	Learning Rate: 0.0090397
	LOSS [training: 0.11153369408430813 | validation: 0.26260630805696794]
	TIME [epoch: 36.6 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1489518366369394		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 0.1489518366369394 | validation: 0.18360070786665836]
	TIME [epoch: 36.5 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12305253443931652		[learning rate: 0.00896]
	Learning Rate: 0.00895999
	LOSS [training: 0.12305253443931652 | validation: 0.19017769371856993]
	TIME [epoch: 36.6 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12368734377253032		[learning rate: 0.0089204]
	Learning Rate: 0.00892041
	LOSS [training: 0.12368734377253032 | validation: 0.26836666778317053]
	TIME [epoch: 36.6 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12766817423374976		[learning rate: 0.008881]
	Learning Rate: 0.00888099
	LOSS [training: 0.12766817423374976 | validation: 0.17456278753234503]
	TIME [epoch: 36.6 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1190309488817409		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 0.1190309488817409 | validation: 0.17533522109406707]
	TIME [epoch: 36.6 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11560041620973811		[learning rate: 0.0088027]
	Learning Rate: 0.00880269
	LOSS [training: 0.11560041620973811 | validation: 0.16135867499204345]
	TIME [epoch: 36.6 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v1_20240627_193159/states/model_facs_dec2b_2dpca_v1_69.pth
	Model improved!!!
EPOCH 70/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12486564991594565		[learning rate: 0.0087638]
	Learning Rate: 0.0087638
	LOSS [training: 0.12486564991594565 | validation: 0.23144706091032102]
	TIME [epoch: 36.6 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1275177411286643		[learning rate: 0.0087251]
	Learning Rate: 0.00872508
	LOSS [training: 0.1275177411286643 | validation: 0.21695007880269182]
	TIME [epoch: 36.5 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14682443532882078		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 0.14682443532882078 | validation: 0.17670290227520347]
	TIME [epoch: 36.5 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11846718922264632		[learning rate: 0.0086481]
	Learning Rate: 0.00864815
	LOSS [training: 0.11846718922264632 | validation: 0.2041487719188145]
	TIME [epoch: 36.6 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12222438293811684		[learning rate: 0.0086099]
	Learning Rate: 0.00860994
	LOSS [training: 0.12222438293811684 | validation: 0.17246318654108528]
	TIME [epoch: 36.6 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10710024571038498		[learning rate: 0.0085719]
	Learning Rate: 0.0085719
	LOSS [training: 0.10710024571038498 | validation: 0.1641135562597415]
	TIME [epoch: 36.6 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1168987555125448		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 0.1168987555125448 | validation: 0.1843580162875277]
	TIME [epoch: 36.6 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12203246204602328		[learning rate: 0.0084963]
	Learning Rate: 0.00849632
	LOSS [training: 0.12203246204602328 | validation: 0.2591087090023462]
	TIME [epoch: 36.6 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13159258236295632		[learning rate: 0.0084588]
	Learning Rate: 0.00845878
	LOSS [training: 0.13159258236295632 | validation: 0.19466202719645415]
	TIME [epoch: 36.6 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11173979726414933		[learning rate: 0.0084214]
	Learning Rate: 0.00842141
	LOSS [training: 0.11173979726414933 | validation: 0.19071878590563324]
	TIME [epoch: 36.6 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11278551832468095		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 0.11278551832468095 | validation: 0.18276696357232494]
	TIME [epoch: 36.6 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11415898579287778		[learning rate: 0.0083472]
	Learning Rate: 0.00834715
	LOSS [training: 0.11415898579287778 | validation: 0.17404192664938292]
	TIME [epoch: 36.6 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1265805444558821		[learning rate: 0.0083103]
	Learning Rate: 0.00831027
	LOSS [training: 0.1265805444558821 | validation: 0.17323154898071028]
	TIME [epoch: 36.6 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13891585806450307		[learning rate: 0.0082736]
	Learning Rate: 0.00827356
	LOSS [training: 0.13891585806450307 | validation: 0.20837326383333063]
	TIME [epoch: 36.6 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11300682513486397		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 0.11300682513486397 | validation: 0.1784599150256806]
	TIME [epoch: 36.6 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11526666130105993		[learning rate: 0.0082006]
	Learning Rate: 0.00820061
	LOSS [training: 0.11526666130105993 | validation: 0.1736571157811857]
	TIME [epoch: 36.6 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11114445092565466		[learning rate: 0.0081644]
	Learning Rate: 0.00816438
	LOSS [training: 0.11114445092565466 | validation: 0.17346566239300784]
	TIME [epoch: 36.6 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12397489570424809		[learning rate: 0.0081283]
	Learning Rate: 0.0081283
	LOSS [training: 0.12397489570424809 | validation: 0.18198458255365857]
	TIME [epoch: 36.6 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11361652535405195		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 0.11361652535405195 | validation: 0.15963336812783657]
	TIME [epoch: 36.6 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v1_20240627_193159/states/model_facs_dec2b_2dpca_v1_88.pth
	Model improved!!!
EPOCH 89/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10838813947719754		[learning rate: 0.0080566]
	Learning Rate: 0.00805664
	LOSS [training: 0.10838813947719754 | validation: 0.18647225265474002]
	TIME [epoch: 36.6 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11825422575315334		[learning rate: 0.008021]
	Learning Rate: 0.00802104
	LOSS [training: 0.11825422575315334 | validation: 0.1594124727201576]
	TIME [epoch: 36.6 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v1_20240627_193159/states/model_facs_dec2b_2dpca_v1_90.pth
	Model improved!!!
EPOCH 91/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11872830497840665		[learning rate: 0.0079856]
	Learning Rate: 0.0079856
	LOSS [training: 0.11872830497840665 | validation: 0.16772241667415863]
	TIME [epoch: 36.5 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1048852353231888		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 0.1048852353231888 | validation: 0.17446764511465823]
	TIME [epoch: 36.6 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10560838837386924		[learning rate: 0.0079152]
	Learning Rate: 0.00791519
	LOSS [training: 0.10560838837386924 | validation: 0.1684740394377717]
	TIME [epoch: 36.6 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11617255478785989		[learning rate: 0.0078802]
	Learning Rate: 0.00788022
	LOSS [training: 0.11617255478785989 | validation: 0.16284422993240458]
	TIME [epoch: 36.6 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10481105042884298		[learning rate: 0.0078454]
	Learning Rate: 0.00784541
	LOSS [training: 0.10481105042884298 | validation: 0.18874999836026438]
	TIME [epoch: 36.6 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10216835286079555		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 0.10216835286079555 | validation: 0.18666313511580157]
	TIME [epoch: 36.5 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1154539910626746		[learning rate: 0.0077762]
	Learning Rate: 0.00777623
	LOSS [training: 0.1154539910626746 | validation: 0.1956392547486438]
	TIME [epoch: 36.5 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10451446852711384		[learning rate: 0.0077419]
	Learning Rate: 0.00774188
	LOSS [training: 0.10451446852711384 | validation: 0.19932683988266092]
	TIME [epoch: 36.5 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10716340933177859		[learning rate: 0.0077077]
	Learning Rate: 0.00770767
	LOSS [training: 0.10716340933177859 | validation: 0.2078854470560077]
	TIME [epoch: 36.6 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10826967667766334		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 0.10826967667766334 | validation: 0.1555467567305094]
	TIME [epoch: 36.6 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v1_20240627_193159/states/model_facs_dec2b_2dpca_v1_100.pth
	Model improved!!!
EPOCH 101/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10153901812305144		[learning rate: 0.0076397]
	Learning Rate: 0.00763971
	LOSS [training: 0.10153901812305144 | validation: 0.16714813826791997]
	TIME [epoch: 36.6 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10695489094688435		[learning rate: 0.007606]
	Learning Rate: 0.00760596
	LOSS [training: 0.10695489094688435 | validation: 0.17205310552073838]
	TIME [epoch: 36.5 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09978225178111381		[learning rate: 0.0075724]
	Learning Rate: 0.00757235
	LOSS [training: 0.09978225178111381 | validation: 0.3217422383187166]
	TIME [epoch: 36.6 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1428838250465534		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 0.1428838250465534 | validation: 0.16811520225017007]
	TIME [epoch: 36.5 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12018371682158677		[learning rate: 0.0075056]
	Learning Rate: 0.00750559
	LOSS [training: 0.12018371682158677 | validation: 0.1688362969288849]
	TIME [epoch: 36.6 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10417943989320336		[learning rate: 0.0074724]
	Learning Rate: 0.00747242
	LOSS [training: 0.10417943989320336 | validation: 0.18478977065725857]
	TIME [epoch: 36.5 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09996439511046433		[learning rate: 0.0074394]
	Learning Rate: 0.00743941
	LOSS [training: 0.09996439511046433 | validation: 0.18258314213027965]
	TIME [epoch: 36.5 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10151820848666031		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 0.10151820848666031 | validation: 0.1601091290989359]
	TIME [epoch: 36.6 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11370909604505189		[learning rate: 0.0073738]
	Learning Rate: 0.00737382
	LOSS [training: 0.11370909604505189 | validation: 0.1885601315960931]
	TIME [epoch: 36.5 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11224601311158619		[learning rate: 0.0073412]
	Learning Rate: 0.00734124
	LOSS [training: 0.11224601311158619 | validation: 0.2303073604280609]
	TIME [epoch: 36.6 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11622146627036271		[learning rate: 0.0073088]
	Learning Rate: 0.0073088
	LOSS [training: 0.11622146627036271 | validation: 0.16595224729125224]
	TIME [epoch: 36.5 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1061913260637275		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 0.1061913260637275 | validation: 0.19072490560391142]
	TIME [epoch: 36.5 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11016660173769652		[learning rate: 0.0072444]
	Learning Rate: 0.00724436
	LOSS [training: 0.11016660173769652 | validation: 0.16643897161760204]
	TIME [epoch: 36.5 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11195504746069374		[learning rate: 0.0072124]
	Learning Rate: 0.00721235
	LOSS [training: 0.11195504746069374 | validation: 0.17949830792179494]
	TIME [epoch: 36.6 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10261454720419458		[learning rate: 0.0071805]
	Learning Rate: 0.00718049
	LOSS [training: 0.10261454720419458 | validation: 0.16079097159910002]
	TIME [epoch: 36.5 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10611577488055837		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 0.10611577488055837 | validation: 0.17359458118570908]
	TIME [epoch: 36.6 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11433284211353083		[learning rate: 0.0071172]
	Learning Rate: 0.00711718
	LOSS [training: 0.11433284211353083 | validation: 0.16399751021036935]
	TIME [epoch: 36.6 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10371456121528688		[learning rate: 0.0070857]
	Learning Rate: 0.00708573
	LOSS [training: 0.10371456121528688 | validation: 0.2094761534568534]
	TIME [epoch: 36.5 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10189011330207713		[learning rate: 0.0070544]
	Learning Rate: 0.00705442
	LOSS [training: 0.10189011330207713 | validation: 0.15804741251647794]
	TIME [epoch: 36.6 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10615618270997085		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 0.10615618270997085 | validation: 0.19184399942573876]
	TIME [epoch: 36.5 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1062913289768952		[learning rate: 0.0069922]
	Learning Rate: 0.00699222
	LOSS [training: 0.1062913289768952 | validation: 0.170711718716495]
	TIME [epoch: 36.5 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10916281929246989		[learning rate: 0.0069613]
	Learning Rate: 0.00696133
	LOSS [training: 0.10916281929246989 | validation: 0.171270754317397]
	TIME [epoch: 36.6 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10685132430400139		[learning rate: 0.0069306]
	Learning Rate: 0.00693057
	LOSS [training: 0.10685132430400139 | validation: 0.166294692852243]
	TIME [epoch: 36.6 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10931455517812286		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 0.10931455517812286 | validation: 0.16217223300906417]
	TIME [epoch: 36.6 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10912001462764317		[learning rate: 0.0068695]
	Learning Rate: 0.00686947
	LOSS [training: 0.10912001462764317 | validation: 0.1796919265508111]
	TIME [epoch: 36.5 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10347390216051873		[learning rate: 0.0068391]
	Learning Rate: 0.00683912
	LOSS [training: 0.10347390216051873 | validation: 0.16756038505439463]
	TIME [epoch: 36.6 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09798488442893855		[learning rate: 0.0068089]
	Learning Rate: 0.0068089
	LOSS [training: 0.09798488442893855 | validation: 0.15175238700878535]
	TIME [epoch: 36.5 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v1_20240627_193159/states/model_facs_dec2b_2dpca_v1_127.pth
	Model improved!!!
EPOCH 128/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10383304480075262		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 0.10383304480075262 | validation: 0.16517457935419982]
	TIME [epoch: 36.6 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09513280170608025		[learning rate: 0.0067489]
	Learning Rate: 0.00674887
	LOSS [training: 0.09513280170608025 | validation: 0.18279955860109548]
	TIME [epoch: 36.5 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10593981886902806		[learning rate: 0.006719]
	Learning Rate: 0.00671905
	LOSS [training: 0.10593981886902806 | validation: 0.1677918658122559]
	TIME [epoch: 36.6 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10589295696620786		[learning rate: 0.0066894]
	Learning Rate: 0.00668936
	LOSS [training: 0.10589295696620786 | validation: 0.20221190069979914]
	TIME [epoch: 36.6 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09901688518470826		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 0.09901688518470826 | validation: 0.15509476783009413]
	TIME [epoch: 36.6 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10550304036800458		[learning rate: 0.0066304]
	Learning Rate: 0.00663038
	LOSS [training: 0.10550304036800458 | validation: 0.20331893020194727]
	TIME [epoch: 36.5 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13986166299640315		[learning rate: 0.0066011]
	Learning Rate: 0.00660109
	LOSS [training: 0.13986166299640315 | validation: 0.199525406265915]
	TIME [epoch: 36.6 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1175716854359646		[learning rate: 0.0065719]
	Learning Rate: 0.00657192
	LOSS [training: 0.1175716854359646 | validation: 0.17128661802708048]
	TIME [epoch: 36.6 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09867927591225126		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 0.09867927591225126 | validation: 0.15854913331407033]
	TIME [epoch: 36.5 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0984826482247179		[learning rate: 0.006514]
	Learning Rate: 0.00651398
	LOSS [training: 0.0984826482247179 | validation: 0.17467030486716575]
	TIME [epoch: 36.5 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09600794704285712		[learning rate: 0.0064852]
	Learning Rate: 0.00648519
	LOSS [training: 0.09600794704285712 | validation: 0.16178952865288265]
	TIME [epoch: 36.6 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09550160337746395		[learning rate: 0.0064565]
	Learning Rate: 0.00645654
	LOSS [training: 0.09550160337746395 | validation: 0.15711042185851148]
	TIME [epoch: 36.6 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10320418799300332		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 0.10320418799300332 | validation: 0.16509034568066894]
	TIME [epoch: 36.6 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09933287474110705		[learning rate: 0.0063996]
	Learning Rate: 0.00639961
	LOSS [training: 0.09933287474110705 | validation: 0.1851836656176456]
	TIME [epoch: 36.6 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11784569341923783		[learning rate: 0.0063713]
	Learning Rate: 0.00637134
	LOSS [training: 0.11784569341923783 | validation: 0.1591118152868387]
	TIME [epoch: 36.6 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09790623411491864		[learning rate: 0.0063432]
	Learning Rate: 0.00634319
	LOSS [training: 0.09790623411491864 | validation: 0.17857585626900593]
	TIME [epoch: 36.6 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09809680145377767		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 0.09809680145377767 | validation: 0.1742475916695342]
	TIME [epoch: 36.6 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10235788093972231		[learning rate: 0.0062873]
	Learning Rate: 0.00628726
	LOSS [training: 0.10235788093972231 | validation: 0.16850437909563146]
	TIME [epoch: 36.6 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10051765685821945		[learning rate: 0.0062595]
	Learning Rate: 0.00625948
	LOSS [training: 0.10051765685821945 | validation: 0.17109603315675542]
	TIME [epoch: 36.6 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09799205667475777		[learning rate: 0.0062318]
	Learning Rate: 0.00623183
	LOSS [training: 0.09799205667475777 | validation: 0.1785119381540631]
	TIME [epoch: 36.5 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10137615711939336		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 0.10137615711939336 | validation: 0.17007872693822848]
	TIME [epoch: 36.5 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09837027440969287		[learning rate: 0.0061769]
	Learning Rate: 0.00617688
	LOSS [training: 0.09837027440969287 | validation: 0.18544177898665742]
	TIME [epoch: 36.6 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1000073277525307		[learning rate: 0.0061496]
	Learning Rate: 0.00614959
	LOSS [training: 0.1000073277525307 | validation: 0.19483363909584722]
	TIME [epoch: 36.6 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11104282503768881		[learning rate: 0.0061224]
	Learning Rate: 0.00612242
	LOSS [training: 0.11104282503768881 | validation: 0.16348480870711693]
	TIME [epoch: 36.6 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1009350917275584		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 0.1009350917275584 | validation: 0.16378423228129557]
	TIME [epoch: 36.6 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1012921631914619		[learning rate: 0.0060684]
	Learning Rate: 0.00606844
	LOSS [training: 0.1012921631914619 | validation: 0.17202876198215988]
	TIME [epoch: 36.5 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10051159957354874		[learning rate: 0.0060416]
	Learning Rate: 0.00604163
	LOSS [training: 0.10051159957354874 | validation: 0.14423949199076985]
	TIME [epoch: 36.6 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v1_20240627_193159/states/model_facs_dec2b_2dpca_v1_154.pth
	Model improved!!!
EPOCH 155/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09283929039872163		[learning rate: 0.0060149]
	Learning Rate: 0.00601493
	LOSS [training: 0.09283929039872163 | validation: 0.16920855071408752]
	TIME [epoch: 36.6 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09752060995394488		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 0.09752060995394488 | validation: 0.18079743640891355]
	TIME [epoch: 36.6 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09538489493730129		[learning rate: 0.0059619]
	Learning Rate: 0.0059619
	LOSS [training: 0.09538489493730129 | validation: 0.15570595370582077]
	TIME [epoch: 36.6 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09484086669647276		[learning rate: 0.0059356]
	Learning Rate: 0.00593556
	LOSS [training: 0.09484086669647276 | validation: 0.16471499326946426]
	TIME [epoch: 36.5 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09542451349534663		[learning rate: 0.0059093]
	Learning Rate: 0.00590933
	LOSS [training: 0.09542451349534663 | validation: 0.16989857849526635]
	TIME [epoch: 36.6 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09751610331842443		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 0.09751610331842443 | validation: 0.1626543246763974]
	TIME [epoch: 36.5 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10533830592072255		[learning rate: 0.0058572]
	Learning Rate: 0.00585723
	LOSS [training: 0.10533830592072255 | validation: 0.17118696124561755]
	TIME [epoch: 36.6 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09944400587210382		[learning rate: 0.0058314]
	Learning Rate: 0.00583135
	LOSS [training: 0.09944400587210382 | validation: 0.16347987280116758]
	TIME [epoch: 36.6 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09697443590971874		[learning rate: 0.0058056]
	Learning Rate: 0.00580559
	LOSS [training: 0.09697443590971874 | validation: 0.21770035565988646]
	TIME [epoch: 36.6 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09892620326125345		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 0.09892620326125345 | validation: 0.1567349228170766]
	TIME [epoch: 36.6 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09407749835302762		[learning rate: 0.0057544]
	Learning Rate: 0.0057544
	LOSS [training: 0.09407749835302762 | validation: 0.17230695591770728]
	TIME [epoch: 36.5 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09332753567467912		[learning rate: 0.005729]
	Learning Rate: 0.00572897
	LOSS [training: 0.09332753567467912 | validation: 0.15673640356872712]
	TIME [epoch: 36.5 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1009949320640194		[learning rate: 0.0057037]
	Learning Rate: 0.00570366
	LOSS [training: 0.1009949320640194 | validation: 0.15140959033357537]
	TIME [epoch: 36.5 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0970502352788305		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 0.0970502352788305 | validation: 0.15267921012869112]
	TIME [epoch: 36.5 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09409821027971714		[learning rate: 0.0056534]
	Learning Rate: 0.00565337
	LOSS [training: 0.09409821027971714 | validation: 0.15369451554237268]
	TIME [epoch: 36.6 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10156529598359039		[learning rate: 0.0056284]
	Learning Rate: 0.0056284
	LOSS [training: 0.10156529598359039 | validation: 0.1843806947725356]
	TIME [epoch: 36.6 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10664466281097948		[learning rate: 0.0056035]
	Learning Rate: 0.00560353
	LOSS [training: 0.10664466281097948 | validation: 0.16936831714560815]
	TIME [epoch: 36.6 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08993905255267834		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 0.08993905255267834 | validation: 0.17412370462081686]
	TIME [epoch: 36.6 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09351363236065283		[learning rate: 0.0055541]
	Learning Rate: 0.00555412
	LOSS [training: 0.09351363236065283 | validation: 0.1673830597494142]
	TIME [epoch: 36.6 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10363089537640276		[learning rate: 0.0055296]
	Learning Rate: 0.00552958
	LOSS [training: 0.10363089537640276 | validation: 0.153520336879894]
	TIME [epoch: 36.5 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08832228164118525		[learning rate: 0.0055052]
	Learning Rate: 0.00550515
	LOSS [training: 0.08832228164118525 | validation: 0.15587209386523374]
	TIME [epoch: 36.5 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0905588442303222		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 0.0905588442303222 | validation: 0.1494480274264839]
	TIME [epoch: 36.4 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09350706286471662		[learning rate: 0.0054566]
	Learning Rate: 0.00545661
	LOSS [training: 0.09350706286471662 | validation: 0.1538782579034383]
	TIME [epoch: 36.5 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09826792110421911		[learning rate: 0.0054325]
	Learning Rate: 0.0054325
	LOSS [training: 0.09826792110421911 | validation: 0.15833849064911973]
	TIME [epoch: 36.5 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09316003635276737		[learning rate: 0.0054085]
	Learning Rate: 0.0054085
	LOSS [training: 0.09316003635276737 | validation: 0.15501727787665306]
	TIME [epoch: 36.5 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09230773273710996		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 0.09230773273710996 | validation: 0.1551399619940631]
	TIME [epoch: 36.5 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0956664115152584		[learning rate: 0.0053608]
	Learning Rate: 0.00536081
	LOSS [training: 0.0956664115152584 | validation: 0.14548763380756372]
	TIME [epoch: 36.5 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09193126719880557		[learning rate: 0.0053371]
	Learning Rate: 0.00533713
	LOSS [training: 0.09193126719880557 | validation: 0.1548054333263056]
	TIME [epoch: 36.6 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09616023463896203		[learning rate: 0.0053135]
	Learning Rate: 0.00531355
	LOSS [training: 0.09616023463896203 | validation: 0.1530014881639254]
	TIME [epoch: 36.6 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0919778260457534		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 0.0919778260457534 | validation: 0.15530681363429974]
	TIME [epoch: 36.6 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0931532563728089		[learning rate: 0.0052667]
	Learning Rate: 0.0052667
	LOSS [training: 0.0931532563728089 | validation: 0.1905097763836427]
	TIME [epoch: 36.6 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1015361803541579		[learning rate: 0.0052434]
	Learning Rate: 0.00524343
	LOSS [training: 0.1015361803541579 | validation: 0.16023148040155089]
	TIME [epoch: 36.6 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09237145845181106		[learning rate: 0.0052203]
	Learning Rate: 0.00522026
	LOSS [training: 0.09237145845181106 | validation: 0.1582992505329217]
	TIME [epoch: 36.5 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09869571542000014		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 0.09869571542000014 | validation: 0.1466166455504869]
	TIME [epoch: 36.5 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09193151090265972		[learning rate: 0.0051742]
	Learning Rate: 0.00517423
	LOSS [training: 0.09193151090265972 | validation: 0.1561681245371488]
	TIME [epoch: 36.6 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09552942575256568		[learning rate: 0.0051514]
	Learning Rate: 0.00515137
	LOSS [training: 0.09552942575256568 | validation: 0.18261813276608313]
	TIME [epoch: 36.6 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0903724875579025		[learning rate: 0.0051286]
	Learning Rate: 0.00512861
	LOSS [training: 0.0903724875579025 | validation: 0.1464403743859038]
	TIME [epoch: 36.6 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09570974871005569		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 0.09570974871005569 | validation: 0.14862467650907746]
	TIME [epoch: 36.6 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0912227370999374		[learning rate: 0.0050834]
	Learning Rate: 0.00508339
	LOSS [training: 0.0912227370999374 | validation: 0.16299937483105142]
	TIME [epoch: 36.6 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0944149101840351		[learning rate: 0.0050609]
	Learning Rate: 0.00506093
	LOSS [training: 0.0944149101840351 | validation: 0.15380077037881065]
	TIME [epoch: 36.6 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09485650667204108		[learning rate: 0.0050386]
	Learning Rate: 0.00503857
	LOSS [training: 0.09485650667204108 | validation: 0.1686000172332771]
	TIME [epoch: 36.6 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09460855893795528		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 0.09460855893795528 | validation: 0.19852004772418524]
	TIME [epoch: 36.6 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09094716287659974		[learning rate: 0.0049941]
	Learning Rate: 0.00499415
	LOSS [training: 0.09094716287659974 | validation: 0.19161644372243747]
	TIME [epoch: 36.6 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09177343321316293		[learning rate: 0.0049721]
	Learning Rate: 0.00497208
	LOSS [training: 0.09177343321316293 | validation: 0.1717343174693146]
	TIME [epoch: 36.6 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0918642110311099		[learning rate: 0.0049501]
	Learning Rate: 0.00495012
	LOSS [training: 0.0918642110311099 | validation: 0.15396669544561079]
	TIME [epoch: 36.6 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09800663733102033		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 0.09800663733102033 | validation: 0.14788835584509327]
	TIME [epoch: 36.5 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08997038792431701		[learning rate: 0.0049065]
	Learning Rate: 0.00490647
	LOSS [training: 0.08997038792431701 | validation: 0.17082255321105286]
	TIME [epoch: 36.6 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08993812824555467		[learning rate: 0.0048848]
	Learning Rate: 0.00488479
	LOSS [training: 0.08993812824555467 | validation: 0.14844693426527159]
	TIME [epoch: 36.6 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09509680402692812		[learning rate: 0.0048632]
	Learning Rate: 0.00486321
	LOSS [training: 0.09509680402692812 | validation: 0.16402053018225973]
	TIME [epoch: 36.6 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0929987789196337		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 0.0929987789196337 | validation: 0.1642548268523491]
	TIME [epoch: 36.6 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08924721775231224		[learning rate: 0.0048203]
	Learning Rate: 0.00482033
	LOSS [training: 0.08924721775231224 | validation: 0.1667887464932959]
	TIME [epoch: 36.6 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09878580765434133		[learning rate: 0.004799]
	Learning Rate: 0.00479903
	LOSS [training: 0.09878580765434133 | validation: 0.1480864225920231]
	TIME [epoch: 36.6 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.092656495682754		[learning rate: 0.0047778]
	Learning Rate: 0.00477783
	LOSS [training: 0.092656495682754 | validation: 0.15542079229480815]
	TIME [epoch: 36.6 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08937902248852504		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.08937902248852504 | validation: 0.18087044670682934]
	TIME [epoch: 36.6 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09104803595791917		[learning rate: 0.0047357]
	Learning Rate: 0.0047357
	LOSS [training: 0.09104803595791917 | validation: 0.15452315707104844]
	TIME [epoch: 36.6 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10456831569524039		[learning rate: 0.0047148]
	Learning Rate: 0.00471478
	LOSS [training: 0.10456831569524039 | validation: 0.17552512074502458]
	TIME [epoch: 36.6 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10716466667226072		[learning rate: 0.0046939]
	Learning Rate: 0.00469395
	LOSS [training: 0.10716466667226072 | validation: 0.16136120806605012]
	TIME [epoch: 36.6 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09132921901846114		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 0.09132921901846114 | validation: 0.1467153017476502]
	TIME [epoch: 36.6 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08762882160396532		[learning rate: 0.0046526]
	Learning Rate: 0.00465256
	LOSS [training: 0.08762882160396532 | validation: 0.15090492499101932]
	TIME [epoch: 36.6 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08772417723655948		[learning rate: 0.004632]
	Learning Rate: 0.00463201
	LOSS [training: 0.08772417723655948 | validation: 0.1540980622150151]
	TIME [epoch: 36.6 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08459080868536872		[learning rate: 0.0046115]
	Learning Rate: 0.00461154
	LOSS [training: 0.08459080868536872 | validation: 0.15405202436717894]
	TIME [epoch: 36.6 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09180505003187174		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 0.09180505003187174 | validation: 0.16936968397574817]
	TIME [epoch: 36.6 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1157022790816139		[learning rate: 0.0045709]
	Learning Rate: 0.00457088
	LOSS [training: 0.1157022790816139 | validation: 0.1659085276351194]
	TIME [epoch: 36.6 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09120380080558002		[learning rate: 0.0045507]
	Learning Rate: 0.00455069
	LOSS [training: 0.09120380080558002 | validation: 0.15282937500761634]
	TIME [epoch: 36.6 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08848406665625164		[learning rate: 0.0045306]
	Learning Rate: 0.00453058
	LOSS [training: 0.08848406665625164 | validation: 0.17172835629425034]
	TIME [epoch: 36.6 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08990734825252825		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 0.08990734825252825 | validation: 0.1494242329160461]
	TIME [epoch: 36.6 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08721162218148423		[learning rate: 0.0044906]
	Learning Rate: 0.00449063
	LOSS [training: 0.08721162218148423 | validation: 0.17058445545564224]
	TIME [epoch: 36.6 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09029690673032949		[learning rate: 0.0044708]
	Learning Rate: 0.00447079
	LOSS [training: 0.09029690673032949 | validation: 0.15241601040528224]
	TIME [epoch: 36.6 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08826090792637838		[learning rate: 0.004451]
	Learning Rate: 0.00445104
	LOSS [training: 0.08826090792637838 | validation: 0.15601283716756714]
	TIME [epoch: 36.6 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09287225702236206		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 0.09287225702236206 | validation: 0.16084597018490668]
	TIME [epoch: 36.6 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08742643321148387		[learning rate: 0.0044118]
	Learning Rate: 0.0044118
	LOSS [training: 0.08742643321148387 | validation: 0.18932178091991758]
	TIME [epoch: 36.6 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09219120110041597		[learning rate: 0.0043923]
	Learning Rate: 0.0043923
	LOSS [training: 0.09219120110041597 | validation: 0.160993397675795]
	TIME [epoch: 36.6 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08935133673744641		[learning rate: 0.0043729]
	Learning Rate: 0.0043729
	LOSS [training: 0.08935133673744641 | validation: 0.17292596433374333]
	TIME [epoch: 36.6 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08887515942731565		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 0.08887515942731565 | validation: 0.16058850211739523]
	TIME [epoch: 36.6 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09298169327967909		[learning rate: 0.0043343]
	Learning Rate: 0.00433434
	LOSS [training: 0.09298169327967909 | validation: 0.14652821495166332]
	TIME [epoch: 36.6 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08747026519478096		[learning rate: 0.0043152]
	Learning Rate: 0.00431519
	LOSS [training: 0.08747026519478096 | validation: 0.1756281654306254]
	TIME [epoch: 36.6 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08802066529195206		[learning rate: 0.0042961]
	Learning Rate: 0.00429612
	LOSS [training: 0.08802066529195206 | validation: 0.1512272222046218]
	TIME [epoch: 36.6 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08744018323562743		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 0.08744018323562743 | validation: 0.17254115556805535]
	TIME [epoch: 36.6 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09023684291027752		[learning rate: 0.0042582]
	Learning Rate: 0.00425825
	LOSS [training: 0.09023684291027752 | validation: 0.15163151052941545]
	TIME [epoch: 36.6 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08658987430052816		[learning rate: 0.0042394]
	Learning Rate: 0.00423943
	LOSS [training: 0.08658987430052816 | validation: 0.14753632443543135]
	TIME [epoch: 36.6 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09110314494892903		[learning rate: 0.0042207]
	Learning Rate: 0.0042207
	LOSS [training: 0.09110314494892903 | validation: 0.16195246884365294]
	TIME [epoch: 36.6 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08489451788606286		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 0.08489451788606286 | validation: 0.15949264619468384]
	TIME [epoch: 36.6 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0924858620939609		[learning rate: 0.0041835]
	Learning Rate: 0.00418349
	LOSS [training: 0.0924858620939609 | validation: 0.14269534025466105]
	TIME [epoch: 36.6 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v1_20240627_193159/states/model_facs_dec2b_2dpca_v1_237.pth
	Model improved!!!
EPOCH 238/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08305503485784912		[learning rate: 0.004165]
	Learning Rate: 0.004165
	LOSS [training: 0.08305503485784912 | validation: 0.1506200127548738]
	TIME [epoch: 36.6 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08783309400298475		[learning rate: 0.0041466]
	Learning Rate: 0.0041466
	LOSS [training: 0.08783309400298475 | validation: 0.1789858142769451]
	TIME [epoch: 36.6 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09407208334603157		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 0.09407208334603157 | validation: 0.16325379923797578]
	TIME [epoch: 36.6 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08950978578249794		[learning rate: 0.00411]
	Learning Rate: 0.00411004
	LOSS [training: 0.08950978578249794 | validation: 0.16195071909785558]
	TIME [epoch: 36.6 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08628057733704386		[learning rate: 0.0040919]
	Learning Rate: 0.00409188
	LOSS [training: 0.08628057733704386 | validation: 0.15132317494553066]
	TIME [epoch: 36.6 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08652501572222968		[learning rate: 0.0040738]
	Learning Rate: 0.0040738
	LOSS [training: 0.08652501572222968 | validation: 0.14246143675998718]
	TIME [epoch: 36.6 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v1_20240627_193159/states/model_facs_dec2b_2dpca_v1_243.pth
	Model improved!!!
EPOCH 244/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08424001134002615		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.08424001134002615 | validation: 0.15284085982702109]
	TIME [epoch: 36.5 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09255029440582238		[learning rate: 0.0040379]
	Learning Rate: 0.00403788
	LOSS [training: 0.09255029440582238 | validation: 0.1530039222136553]
	TIME [epoch: 36.5 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.087726227084977		[learning rate: 0.00402]
	Learning Rate: 0.00402004
	LOSS [training: 0.087726227084977 | validation: 0.13946863512808463]
	TIME [epoch: 36.6 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v1_20240627_193159/states/model_facs_dec2b_2dpca_v1_246.pth
	Model improved!!!
EPOCH 247/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09265600794768274		[learning rate: 0.0040023]
	Learning Rate: 0.00400228
	LOSS [training: 0.09265600794768274 | validation: 0.14439199321348734]
	TIME [epoch: 36.6 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08837620903381031		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 0.08837620903381031 | validation: 0.17139228783319257]
	TIME [epoch: 36.5 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08851151622520345		[learning rate: 0.003967]
	Learning Rate: 0.00396699
	LOSS [training: 0.08851151622520345 | validation: 0.14940283219833464]
	TIME [epoch: 36.6 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08646109592450657		[learning rate: 0.0039495]
	Learning Rate: 0.00394947
	LOSS [training: 0.08646109592450657 | validation: 0.15279750043013263]
	TIME [epoch: 36.5 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08780712110140196		[learning rate: 0.003932]
	Learning Rate: 0.00393202
	LOSS [training: 0.08780712110140196 | validation: 0.15354592208905424]
	TIME [epoch: 36.6 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09084232145339279		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 0.09084232145339279 | validation: 0.15494892488275022]
	TIME [epoch: 36.6 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09097781465822327		[learning rate: 0.0038973]
	Learning Rate: 0.00389735
	LOSS [training: 0.09097781465822327 | validation: 0.14508194364267027]
	TIME [epoch: 36.6 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08395148606756167		[learning rate: 0.0038801]
	Learning Rate: 0.00388013
	LOSS [training: 0.08395148606756167 | validation: 0.16697489216714884]
	TIME [epoch: 36.6 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09122207106478634		[learning rate: 0.003863]
	Learning Rate: 0.00386299
	LOSS [training: 0.09122207106478634 | validation: 0.17552107040813492]
	TIME [epoch: 36.6 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08766651999657		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 0.08766651999657 | validation: 0.15515282488256818]
	TIME [epoch: 36.6 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08857062083422303		[learning rate: 0.0038289]
	Learning Rate: 0.00382893
	LOSS [training: 0.08857062083422303 | validation: 0.18416637896376165]
	TIME [epoch: 36.5 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09406551130874272		[learning rate: 0.003812]
	Learning Rate: 0.00381201
	LOSS [training: 0.09406551130874272 | validation: 0.16090972385925872]
	TIME [epoch: 36.5 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08699181114743638		[learning rate: 0.0037952]
	Learning Rate: 0.00379517
	LOSS [training: 0.08699181114743638 | validation: 0.15370534087856436]
	TIME [epoch: 36.5 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09092520429342692		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 0.09092520429342692 | validation: 0.14413695994174472]
	TIME [epoch: 36.6 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0853358465325779		[learning rate: 0.0037617]
	Learning Rate: 0.0037617
	LOSS [training: 0.0853358465325779 | validation: 0.14158848925687514]
	TIME [epoch: 36.6 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08599197652652268		[learning rate: 0.0037451]
	Learning Rate: 0.00374508
	LOSS [training: 0.08599197652652268 | validation: 0.15794792468928467]
	TIME [epoch: 36.6 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08748289002531648		[learning rate: 0.0037285]
	Learning Rate: 0.00372854
	LOSS [training: 0.08748289002531648 | validation: 0.1495973662643793]
	TIME [epoch: 36.6 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08793104445986842		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 0.08793104445986842 | validation: 0.14811608398497317]
	TIME [epoch: 36.6 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08509128806704482		[learning rate: 0.0036957]
	Learning Rate: 0.00369566
	LOSS [training: 0.08509128806704482 | validation: 0.15583430763702016]
	TIME [epoch: 36.6 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08450342556615617		[learning rate: 0.0036793]
	Learning Rate: 0.00367933
	LOSS [training: 0.08450342556615617 | validation: 0.17227262335099033]
	TIME [epoch: 36.6 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08595215862820824		[learning rate: 0.0036631]
	Learning Rate: 0.00366308
	LOSS [training: 0.08595215862820824 | validation: 0.1717092045067364]
	TIME [epoch: 36.6 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08920692550709017		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 0.08920692550709017 | validation: 0.18228465576804267]
	TIME [epoch: 36.6 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09104714477655597		[learning rate: 0.0036308]
	Learning Rate: 0.00363078
	LOSS [training: 0.09104714477655597 | validation: 0.15448054659812444]
	TIME [epoch: 36.6 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.084187936712545		[learning rate: 0.0036147]
	Learning Rate: 0.00361474
	LOSS [training: 0.084187936712545 | validation: 0.14960159015305324]
	TIME [epoch: 36.6 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08461136535617514		[learning rate: 0.0035988]
	Learning Rate: 0.00359877
	LOSS [training: 0.08461136535617514 | validation: 0.15045650183479825]
	TIME [epoch: 36.5 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0846465618203566		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 0.0846465618203566 | validation: 0.15015814191033258]
	TIME [epoch: 36.6 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09181673837679893		[learning rate: 0.003567]
	Learning Rate: 0.00356704
	LOSS [training: 0.09181673837679893 | validation: 0.14694613520699676]
	TIME [epoch: 36.6 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08374174513701904		[learning rate: 0.0035513]
	Learning Rate: 0.00355128
	LOSS [training: 0.08374174513701904 | validation: 0.1594387923847027]
	TIME [epoch: 36.6 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08720607920941761		[learning rate: 0.0035356]
	Learning Rate: 0.00353559
	LOSS [training: 0.08720607920941761 | validation: 0.15918600421729218]
	TIME [epoch: 36.5 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08349060953917616		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 0.08349060953917616 | validation: 0.16395201375380622]
	TIME [epoch: 36.6 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09016334360574071		[learning rate: 0.0035044]
	Learning Rate: 0.00350441
	LOSS [training: 0.09016334360574071 | validation: 0.14932719891668733]
	TIME [epoch: 36.6 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08297013091130498		[learning rate: 0.0034889]
	Learning Rate: 0.00348893
	LOSS [training: 0.08297013091130498 | validation: 0.14560939695635117]
	TIME [epoch: 36.6 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08687071980640099		[learning rate: 0.0034735]
	Learning Rate: 0.00347352
	LOSS [training: 0.08687071980640099 | validation: 0.14686547969010175]
	TIME [epoch: 36.6 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08450938528259959		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.08450938528259959 | validation: 0.15579900632736207]
	TIME [epoch: 36.5 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08541123265646025		[learning rate: 0.0034429]
	Learning Rate: 0.00344289
	LOSS [training: 0.08541123265646025 | validation: 0.15321663038858993]
	TIME [epoch: 36.5 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0842542297554008		[learning rate: 0.0034277]
	Learning Rate: 0.00342768
	LOSS [training: 0.0842542297554008 | validation: 0.15313710745102463]
	TIME [epoch: 36.6 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08673101859929153		[learning rate: 0.0034125]
	Learning Rate: 0.00341253
	LOSS [training: 0.08673101859929153 | validation: 0.15292161383272432]
	TIME [epoch: 36.6 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08448655578492874		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 0.08448655578492874 | validation: 0.15994302294198925]
	TIME [epoch: 36.6 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08406535020704756		[learning rate: 0.0033824]
	Learning Rate: 0.00338245
	LOSS [training: 0.08406535020704756 | validation: 0.16195279973452953]
	TIME [epoch: 36.6 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08454854365823064		[learning rate: 0.0033675]
	Learning Rate: 0.0033675
	LOSS [training: 0.08454854365823064 | validation: 0.152801856259216]
	TIME [epoch: 36.6 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08683636184628361		[learning rate: 0.0033526]
	Learning Rate: 0.00335262
	LOSS [training: 0.08683636184628361 | validation: 0.1490035756993102]
	TIME [epoch: 36.6 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0906689389999204		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 0.0906689389999204 | validation: 0.13881719994138547]
	TIME [epoch: 36.6 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v1_20240627_193159/states/model_facs_dec2b_2dpca_v1_288.pth
	Model improved!!!
EPOCH 289/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08730041806668187		[learning rate: 0.0033231]
	Learning Rate: 0.00332306
	LOSS [training: 0.08730041806668187 | validation: 0.14612652526275496]
	TIME [epoch: 36.6 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08981337739112986		[learning rate: 0.0033084]
	Learning Rate: 0.00330838
	LOSS [training: 0.08981337739112986 | validation: 0.15092953008742052]
	TIME [epoch: 36.4 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08286611527773752		[learning rate: 0.0032938]
	Learning Rate: 0.00329376
	LOSS [training: 0.08286611527773752 | validation: 0.14427070406648085]
	TIME [epoch: 36.5 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08456114921779066		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 0.08456114921779066 | validation: 0.16869368412937935]
	TIME [epoch: 36.5 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08264320577761279		[learning rate: 0.0032647]
	Learning Rate: 0.00326472
	LOSS [training: 0.08264320577761279 | validation: 0.14834026605149286]
	TIME [epoch: 36.5 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08419147772134242		[learning rate: 0.0032503]
	Learning Rate: 0.0032503
	LOSS [training: 0.08419147772134242 | validation: 0.15310667551997104]
	TIME [epoch: 36.5 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08525005934403752		[learning rate: 0.0032359]
	Learning Rate: 0.00323594
	LOSS [training: 0.08525005934403752 | validation: 0.15242181976008895]
	TIME [epoch: 36.5 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08579094835741372		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 0.08579094835741372 | validation: 0.15095754306139839]
	TIME [epoch: 36.6 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08243388670505189		[learning rate: 0.0032074]
	Learning Rate: 0.00320741
	LOSS [training: 0.08243388670505189 | validation: 0.15315488593678248]
	TIME [epoch: 36.6 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08474422805669803		[learning rate: 0.0031932]
	Learning Rate: 0.00319323
	LOSS [training: 0.08474422805669803 | validation: 0.1589593337280849]
	TIME [epoch: 36.6 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08962748719287796		[learning rate: 0.0031791]
	Learning Rate: 0.00317913
	LOSS [training: 0.08962748719287796 | validation: 0.16223248333060586]
	TIME [epoch: 36.6 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08120376767795515		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 0.08120376767795515 | validation: 0.16081985973963203]
	TIME [epoch: 36.6 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.086650716257956		[learning rate: 0.0031511]
	Learning Rate: 0.0031511
	LOSS [training: 0.086650716257956 | validation: 0.16289561845441136]
	TIME [epoch: 36.6 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08762011644254665		[learning rate: 0.0031372]
	Learning Rate: 0.00313717
	LOSS [training: 0.08762011644254665 | validation: 0.1472614313470739]
	TIME [epoch: 36.5 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08113925560386323		[learning rate: 0.0031233]
	Learning Rate: 0.00312331
	LOSS [training: 0.08113925560386323 | validation: 0.14449110737036217]
	TIME [epoch: 36.5 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08508827190409862		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 0.08508827190409862 | validation: 0.1463537772967346]
	TIME [epoch: 36.6 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08662756567313538		[learning rate: 0.0030958]
	Learning Rate: 0.00309577
	LOSS [training: 0.08662756567313538 | validation: 0.13673698519086278]
	TIME [epoch: 36.6 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v1_20240627_193159/states/model_facs_dec2b_2dpca_v1_305.pth
	Model improved!!!
EPOCH 306/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0839203009553095		[learning rate: 0.0030821]
	Learning Rate: 0.0030821
	LOSS [training: 0.0839203009553095 | validation: 0.14542652327684044]
	TIME [epoch: 36.5 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08377581439936137		[learning rate: 0.0030685]
	Learning Rate: 0.00306848
	LOSS [training: 0.08377581439936137 | validation: 0.16810325522963895]
	TIME [epoch: 36.6 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08469819825984239		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 0.08469819825984239 | validation: 0.15112887709699815]
	TIME [epoch: 36.5 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08194629415680962		[learning rate: 0.0030414]
	Learning Rate: 0.00304142
	LOSS [training: 0.08194629415680962 | validation: 0.14171015549054417]
	TIME [epoch: 36.5 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0839701350526519		[learning rate: 0.003028]
	Learning Rate: 0.00302799
	LOSS [training: 0.0839701350526519 | validation: 0.16433170092939142]
	TIME [epoch: 36.5 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09434034452857379		[learning rate: 0.0030146]
	Learning Rate: 0.00301461
	LOSS [training: 0.09434034452857379 | validation: 0.14959774085580418]
	TIME [epoch: 36.6 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08378282600527445		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 0.08378282600527445 | validation: 0.14468243501601943]
	TIME [epoch: 36.5 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0834484322608265		[learning rate: 0.002988]
	Learning Rate: 0.00298803
	LOSS [training: 0.0834484322608265 | validation: 0.158296750089667]
	TIME [epoch: 36.5 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08387881320655843		[learning rate: 0.0029748]
	Learning Rate: 0.00297483
	LOSS [training: 0.08387881320655843 | validation: 0.15142971139894298]
	TIME [epoch: 36.5 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08152621157119573		[learning rate: 0.0029617]
	Learning Rate: 0.00296168
	LOSS [training: 0.08152621157119573 | validation: 0.15803179102590964]
	TIME [epoch: 36.5 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08938968933324791		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.08938968933324791 | validation: 0.1539472132555454]
	TIME [epoch: 36.5 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08604175926753461		[learning rate: 0.0029356]
	Learning Rate: 0.00293557
	LOSS [training: 0.08604175926753461 | validation: 0.14435628878165066]
	TIME [epoch: 36.5 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08208350931574446		[learning rate: 0.0029226]
	Learning Rate: 0.0029226
	LOSS [training: 0.08208350931574446 | validation: 0.16286936263160057]
	TIME [epoch: 36.5 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08365144756170222		[learning rate: 0.0029097]
	Learning Rate: 0.00290969
	LOSS [training: 0.08365144756170222 | validation: 0.1569382750466536]
	TIME [epoch: 36.5 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0822708205224445		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 0.0822708205224445 | validation: 0.1485932978575842]
	TIME [epoch: 36.5 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08243638575502424		[learning rate: 0.002884]
	Learning Rate: 0.00288403
	LOSS [training: 0.08243638575502424 | validation: 0.15052823428407539]
	TIME [epoch: 36.5 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08457673284398944		[learning rate: 0.0028713]
	Learning Rate: 0.00287129
	LOSS [training: 0.08457673284398944 | validation: 0.150204203054313]
	TIME [epoch: 36.5 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0809177699420918		[learning rate: 0.0028586]
	Learning Rate: 0.0028586
	LOSS [training: 0.0809177699420918 | validation: 0.1565953778243111]
	TIME [epoch: 36.5 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08438137471079221		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 0.08438137471079221 | validation: 0.16769858083756156]
	TIME [epoch: 36.5 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08557651810943127		[learning rate: 0.0028334]
	Learning Rate: 0.0028334
	LOSS [training: 0.08557651810943127 | validation: 0.1553236839451125]
	TIME [epoch: 36.5 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0847866197024819		[learning rate: 0.0028209]
	Learning Rate: 0.00282088
	LOSS [training: 0.0847866197024819 | validation: 0.18781594853125885]
	TIME [epoch: 36.5 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08716077152389298		[learning rate: 0.0028084]
	Learning Rate: 0.00280842
	LOSS [training: 0.08716077152389298 | validation: 0.16014378753493047]
	TIME [epoch: 36.5 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0849971967167992		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 0.0849971967167992 | validation: 0.15197594327372038]
	TIME [epoch: 36.5 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08244863679739012		[learning rate: 0.0027837]
	Learning Rate: 0.00278366
	LOSS [training: 0.08244863679739012 | validation: 0.15519482229880635]
	TIME [epoch: 36.6 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08081250649208777		[learning rate: 0.0027714]
	Learning Rate: 0.00277136
	LOSS [training: 0.08081250649208777 | validation: 0.14587878013830002]
	TIME [epoch: 36.5 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08386258351179009		[learning rate: 0.0027591]
	Learning Rate: 0.00275911
	LOSS [training: 0.08386258351179009 | validation: 0.15012806562251774]
	TIME [epoch: 36.5 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08154368706379177		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 0.08154368706379177 | validation: 0.14117099246234058]
	TIME [epoch: 36.5 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0797684863529599		[learning rate: 0.0027348]
	Learning Rate: 0.00273478
	LOSS [training: 0.0797684863529599 | validation: 0.14541738267577214]
	TIME [epoch: 36.5 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08403573565477092		[learning rate: 0.0027227]
	Learning Rate: 0.0027227
	LOSS [training: 0.08403573565477092 | validation: 0.15855196107237396]
	TIME [epoch: 36.5 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08177797484827222		[learning rate: 0.0027107]
	Learning Rate: 0.00271067
	LOSS [training: 0.08177797484827222 | validation: 0.15297185460756804]
	TIME [epoch: 36.5 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08360317177286178		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 0.08360317177286178 | validation: 0.14275566421322045]
	TIME [epoch: 36.5 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0842510548242559		[learning rate: 0.0026868]
	Learning Rate: 0.00268677
	LOSS [training: 0.0842510548242559 | validation: 0.14223222637710545]
	TIME [epoch: 36.5 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08244058438569009		[learning rate: 0.0026749]
	Learning Rate: 0.0026749
	LOSS [training: 0.08244058438569009 | validation: 0.1502108857164444]
	TIME [epoch: 36.5 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08703557237163809		[learning rate: 0.0026631]
	Learning Rate: 0.00266308
	LOSS [training: 0.08703557237163809 | validation: 0.14951495039445936]
	TIME [epoch: 36.5 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0815759793879439		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 0.0815759793879439 | validation: 0.14822933619402776]
	TIME [epoch: 36.5 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08429509208001104		[learning rate: 0.0026396]
	Learning Rate: 0.0026396
	LOSS [training: 0.08429509208001104 | validation: 0.1607496428925574]
	TIME [epoch: 36.5 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0807817668949388		[learning rate: 0.0026279]
	Learning Rate: 0.00262794
	LOSS [training: 0.0807817668949388 | validation: 0.15941486923052844]
	TIME [epoch: 36.5 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08417150765263412		[learning rate: 0.0026163]
	Learning Rate: 0.00261633
	LOSS [training: 0.08417150765263412 | validation: 0.1580105740697541]
	TIME [epoch: 36.5 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08511937352286046		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 0.08511937352286046 | validation: 0.15179990012140757]
	TIME [epoch: 36.5 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08031455136775201		[learning rate: 0.0025933]
	Learning Rate: 0.00259326
	LOSS [training: 0.08031455136775201 | validation: 0.15349207312760021]
	TIME [epoch: 36.5 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08396980091794382		[learning rate: 0.0025818]
	Learning Rate: 0.0025818
	LOSS [training: 0.08396980091794382 | validation: 0.14475253573037103]
	TIME [epoch: 36.5 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08134585319028408		[learning rate: 0.0025704]
	Learning Rate: 0.0025704
	LOSS [training: 0.08134585319028408 | validation: 0.1518957425858882]
	TIME [epoch: 36.5 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08058409097706362		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.08058409097706362 | validation: 0.15837954278118552]
	TIME [epoch: 36.5 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08565629223513467		[learning rate: 0.0025477]
	Learning Rate: 0.00254773
	LOSS [training: 0.08565629223513467 | validation: 0.16421441158586955]
	TIME [epoch: 36.5 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0826676146972479		[learning rate: 0.0025365]
	Learning Rate: 0.00253648
	LOSS [training: 0.0826676146972479 | validation: 0.14880308086602956]
	TIME [epoch: 36.5 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08502585732548026		[learning rate: 0.0025253]
	Learning Rate: 0.00252527
	LOSS [training: 0.08502585732548026 | validation: 0.1462257402748376]
	TIME [epoch: 36.5 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08651840060339691		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.08651840060339691 | validation: 0.1509942196911454]
	TIME [epoch: 36.5 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0854383697840029		[learning rate: 0.002503]
	Learning Rate: 0.002503
	LOSS [training: 0.0854383697840029 | validation: 0.1501244303987417]
	TIME [epoch: 36.5 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0794466254958347		[learning rate: 0.0024919]
	Learning Rate: 0.00249194
	LOSS [training: 0.0794466254958347 | validation: 0.14849320695208953]
	TIME [epoch: 36.5 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07956272454179533		[learning rate: 0.0024809]
	Learning Rate: 0.00248093
	LOSS [training: 0.07956272454179533 | validation: 0.1457313482589282]
	TIME [epoch: 36.5 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0800035926881922		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 0.0800035926881922 | validation: 0.14135389762160894]
	TIME [epoch: 36.6 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08136741766478439		[learning rate: 0.0024591]
	Learning Rate: 0.00245906
	LOSS [training: 0.08136741766478439 | validation: 0.15176881656855482]
	TIME [epoch: 36.5 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08367004437799427		[learning rate: 0.0024482]
	Learning Rate: 0.0024482
	LOSS [training: 0.08367004437799427 | validation: 0.1611409782456634]
	TIME [epoch: 36.5 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08355167651908402		[learning rate: 0.0024374]
	Learning Rate: 0.00243738
	LOSS [training: 0.08355167651908402 | validation: 0.14872054240808236]
	TIME [epoch: 36.5 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08304983706816313		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.08304983706816313 | validation: 0.15375611449062218]
	TIME [epoch: 36.5 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08148469425830426		[learning rate: 0.0024159]
	Learning Rate: 0.00241589
	LOSS [training: 0.08148469425830426 | validation: 0.14765528135186606]
	TIME [epoch: 36.5 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08226998407602533		[learning rate: 0.0024052]
	Learning Rate: 0.00240521
	LOSS [training: 0.08226998407602533 | validation: 0.17335780669973083]
	TIME [epoch: 36.5 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08384005692834519		[learning rate: 0.0023946]
	Learning Rate: 0.00239459
	LOSS [training: 0.08384005692834519 | validation: 0.14841880961750303]
	TIME [epoch: 36.5 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08329500221457893		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 0.08329500221457893 | validation: 0.16523489480902262]
	TIME [epoch: 36.5 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08405109978237855		[learning rate: 0.0023735]
	Learning Rate: 0.00237347
	LOSS [training: 0.08405109978237855 | validation: 0.15186407272724234]
	TIME [epoch: 36.5 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08457596884033587		[learning rate: 0.002363]
	Learning Rate: 0.00236299
	LOSS [training: 0.08457596884033587 | validation: 0.1417977917771823]
	TIME [epoch: 36.5 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08375156946134092		[learning rate: 0.0023525]
	Learning Rate: 0.00235255
	LOSS [training: 0.08375156946134092 | validation: 0.14859460236484714]
	TIME [epoch: 36.5 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08271908370120476		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.08271908370120476 | validation: 0.14436161440542503]
	TIME [epoch: 36.5 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08323180925381037		[learning rate: 0.0023318]
	Learning Rate: 0.00233181
	LOSS [training: 0.08323180925381037 | validation: 0.13846229509550628]
	TIME [epoch: 36.5 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08402454494135694		[learning rate: 0.0023215]
	Learning Rate: 0.0023215
	LOSS [training: 0.08402454494135694 | validation: 0.15186514013360583]
	TIME [epoch: 36.5 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08215371947966452		[learning rate: 0.0023112]
	Learning Rate: 0.00231125
	LOSS [training: 0.08215371947966452 | validation: 0.1487932162018061]
	TIME [epoch: 36.5 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08283493094876956		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.08283493094876956 | validation: 0.1530245813969648]
	TIME [epoch: 36.5 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07866996501513297		[learning rate: 0.0022909]
	Learning Rate: 0.00229087
	LOSS [training: 0.07866996501513297 | validation: 0.14787277832618081]
	TIME [epoch: 36.5 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08216247695490442		[learning rate: 0.0022807]
	Learning Rate: 0.00228075
	LOSS [training: 0.08216247695490442 | validation: 0.14580572361464433]
	TIME [epoch: 36.5 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08333581793524932		[learning rate: 0.0022707]
	Learning Rate: 0.00227067
	LOSS [training: 0.08333581793524932 | validation: 0.14509066287360575]
	TIME [epoch: 36.5 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08401329038871455		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.08401329038871455 | validation: 0.14720977507063865]
	TIME [epoch: 36.5 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08271916689425489		[learning rate: 0.0022506]
	Learning Rate: 0.00225065
	LOSS [training: 0.08271916689425489 | validation: 0.1425726454936382]
	TIME [epoch: 36.5 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08265791813284833		[learning rate: 0.0022407]
	Learning Rate: 0.0022407
	LOSS [training: 0.08265791813284833 | validation: 0.14830076581456206]
	TIME [epoch: 36.5 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08222324040079163		[learning rate: 0.0022308]
	Learning Rate: 0.0022308
	LOSS [training: 0.08222324040079163 | validation: 0.15464893180181355]
	TIME [epoch: 36.5 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07954544737971406		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.07954544737971406 | validation: 0.14663733654588496]
	TIME [epoch: 36.5 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08075459166140073		[learning rate: 0.0022111]
	Learning Rate: 0.00221114
	LOSS [training: 0.08075459166140073 | validation: 0.15112155292011958]
	TIME [epoch: 36.5 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08384548572194699		[learning rate: 0.0022014]
	Learning Rate: 0.00220137
	LOSS [training: 0.08384548572194699 | validation: 0.14067634872247137]
	TIME [epoch: 36.5 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08017480125526946		[learning rate: 0.0021916]
	Learning Rate: 0.00219164
	LOSS [training: 0.08017480125526946 | validation: 0.14315525129503845]
	TIME [epoch: 36.5 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08193386989835982		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.08193386989835982 | validation: 0.15685269644549288]
	TIME [epoch: 36.5 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08406250002437152		[learning rate: 0.0021723]
	Learning Rate: 0.00217232
	LOSS [training: 0.08406250002437152 | validation: 0.14949280722082453]
	TIME [epoch: 36.5 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08162948817913743		[learning rate: 0.0021627]
	Learning Rate: 0.00216272
	LOSS [training: 0.08162948817913743 | validation: 0.15264496357342075]
	TIME [epoch: 36.5 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08221475409941553		[learning rate: 0.0021532]
	Learning Rate: 0.00215316
	LOSS [training: 0.08221475409941553 | validation: 0.14238843947223095]
	TIME [epoch: 36.5 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07988535895474322		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.07988535895474322 | validation: 0.14814955588566908]
	TIME [epoch: 36.5 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08124187449568962		[learning rate: 0.0021342]
	Learning Rate: 0.00213418
	LOSS [training: 0.08124187449568962 | validation: 0.1509227261972221]
	TIME [epoch: 36.5 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08341173620824648		[learning rate: 0.0021247]
	Learning Rate: 0.00212475
	LOSS [training: 0.08341173620824648 | validation: 0.1435779984660214]
	TIME [epoch: 36.5 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08216668724625058		[learning rate: 0.0021154]
	Learning Rate: 0.00211536
	LOSS [training: 0.08216668724625058 | validation: 0.15405706519639895]
	TIME [epoch: 36.5 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08103952131945914		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.08103952131945914 | validation: 0.14425744405541582]
	TIME [epoch: 36.5 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08251687437720853		[learning rate: 0.0020967]
	Learning Rate: 0.00209671
	LOSS [training: 0.08251687437720853 | validation: 0.149577812342508]
	TIME [epoch: 36.5 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08113525832670254		[learning rate: 0.0020874]
	Learning Rate: 0.00208745
	LOSS [training: 0.08113525832670254 | validation: 0.14087228488529419]
	TIME [epoch: 36.5 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08719504134070813		[learning rate: 0.0020782]
	Learning Rate: 0.00207822
	LOSS [training: 0.08719504134070813 | validation: 0.1602332503945092]
	TIME [epoch: 36.5 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08097369570230235		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.08097369570230235 | validation: 0.14638008781077416]
	TIME [epoch: 36.5 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08102510869643834		[learning rate: 0.0020599]
	Learning Rate: 0.0020599
	LOSS [training: 0.08102510869643834 | validation: 0.14632400608316792]
	TIME [epoch: 36.5 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08032951100500695		[learning rate: 0.0020508]
	Learning Rate: 0.0020508
	LOSS [training: 0.08032951100500695 | validation: 0.15783652001919624]
	TIME [epoch: 36.5 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0808143504958689		[learning rate: 0.0020417]
	Learning Rate: 0.00204174
	LOSS [training: 0.0808143504958689 | validation: 0.1457939076607022]
	TIME [epoch: 36.5 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08024427473368037		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.08024427473368037 | validation: 0.1588373392332206]
	TIME [epoch: 36.5 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0813360823903001		[learning rate: 0.0020237]
	Learning Rate: 0.00202374
	LOSS [training: 0.0813360823903001 | validation: 0.1520522709813381]
	TIME [epoch: 36.5 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08036234252717693		[learning rate: 0.0020148]
	Learning Rate: 0.00201479
	LOSS [training: 0.08036234252717693 | validation: 0.15111388216860644]
	TIME [epoch: 36.5 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08087057151380474		[learning rate: 0.0020059]
	Learning Rate: 0.00200589
	LOSS [training: 0.08087057151380474 | validation: 0.14754421313801935]
	TIME [epoch: 36.5 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08247326973373696		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.08247326973373696 | validation: 0.15241949040498964]
	TIME [epoch: 36.5 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08117657160623823		[learning rate: 0.0019882]
	Learning Rate: 0.00198821
	LOSS [training: 0.08117657160623823 | validation: 0.14735943627226583]
	TIME [epoch: 36.5 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08121198689250594		[learning rate: 0.0019794]
	Learning Rate: 0.00197942
	LOSS [training: 0.08121198689250594 | validation: 0.13938438940192904]
	TIME [epoch: 36.5 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08095086795518477		[learning rate: 0.0019707]
	Learning Rate: 0.00197068
	LOSS [training: 0.08095086795518477 | validation: 0.14845838855224905]
	TIME [epoch: 36.5 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0813030369809968		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.0813030369809968 | validation: 0.14134364511447417]
	TIME [epoch: 36.5 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08129139252155564		[learning rate: 0.0019533]
	Learning Rate: 0.0019533
	LOSS [training: 0.08129139252155564 | validation: 0.14207706628835967]
	TIME [epoch: 36.5 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08140365744094269		[learning rate: 0.0019447]
	Learning Rate: 0.00194467
	LOSS [training: 0.08140365744094269 | validation: 0.15530301266742946]
	TIME [epoch: 36.5 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08171238821624602		[learning rate: 0.0019361]
	Learning Rate: 0.00193608
	LOSS [training: 0.08171238821624602 | validation: 0.14195796707072866]
	TIME [epoch: 36.5 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08255191338141168		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.08255191338141168 | validation: 0.15525286433914892]
	TIME [epoch: 36.5 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08069378515572856		[learning rate: 0.001919]
	Learning Rate: 0.00191901
	LOSS [training: 0.08069378515572856 | validation: 0.15410467043814371]
	TIME [epoch: 36.5 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07830216706349394		[learning rate: 0.0019105]
	Learning Rate: 0.00191053
	LOSS [training: 0.07830216706349394 | validation: 0.15103867706384344]
	TIME [epoch: 36.5 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07884951347695257		[learning rate: 0.0019021]
	Learning Rate: 0.00190209
	LOSS [training: 0.07884951347695257 | validation: 0.1488983763891214]
	TIME [epoch: 36.5 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07820261288575676		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.07820261288575676 | validation: 0.15318678210319192]
	TIME [epoch: 36.5 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08248078016258749		[learning rate: 0.0018853]
	Learning Rate: 0.00188532
	LOSS [training: 0.08248078016258749 | validation: 0.14740394556190425]
	TIME [epoch: 36.5 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08000003556344551		[learning rate: 0.001877]
	Learning Rate: 0.00187699
	LOSS [training: 0.08000003556344551 | validation: 0.15131424447795583]
	TIME [epoch: 36.5 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08224515307223441		[learning rate: 0.0018687]
	Learning Rate: 0.0018687
	LOSS [training: 0.08224515307223441 | validation: 0.14730316531173313]
	TIME [epoch: 36.6 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08036600136131115		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.08036600136131115 | validation: 0.1418243276458902]
	TIME [epoch: 36.5 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07729412553613506		[learning rate: 0.0018522]
	Learning Rate: 0.00185222
	LOSS [training: 0.07729412553613506 | validation: 0.14718273481485816]
	TIME [epoch: 36.5 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0796896871684837		[learning rate: 0.001844]
	Learning Rate: 0.00184404
	LOSS [training: 0.0796896871684837 | validation: 0.14748249511597014]
	TIME [epoch: 36.5 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08290519770038776		[learning rate: 0.0018359]
	Learning Rate: 0.00183589
	LOSS [training: 0.08290519770038776 | validation: 0.14321044620447587]
	TIME [epoch: 36.5 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07509058568419338		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.07509058568419338 | validation: 0.13554628181485365]
	TIME [epoch: 36.5 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v1_20240627_193159/states/model_facs_dec2b_2dpca_v1_424.pth
	Model improved!!!
EPOCH 425/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08145231825173366		[learning rate: 0.0018197]
	Learning Rate: 0.0018197
	LOSS [training: 0.08145231825173366 | validation: 0.14324437107182914]
	TIME [epoch: 36.5 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08187920613527414		[learning rate: 0.0018117]
	Learning Rate: 0.00181166
	LOSS [training: 0.08187920613527414 | validation: 0.14527628348104776]
	TIME [epoch: 36.5 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08077065397939479		[learning rate: 0.0018037]
	Learning Rate: 0.00180366
	LOSS [training: 0.08077065397939479 | validation: 0.15715259187125702]
	TIME [epoch: 36.5 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08098749040168754		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.08098749040168754 | validation: 0.15526114278751232]
	TIME [epoch: 36.5 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0796586196058517		[learning rate: 0.0017878]
	Learning Rate: 0.00178775
	LOSS [training: 0.0796586196058517 | validation: 0.13884260038316515]
	TIME [epoch: 36.5 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0811304471455643		[learning rate: 0.0017799]
	Learning Rate: 0.00177985
	LOSS [training: 0.0811304471455643 | validation: 0.1458579543298195]
	TIME [epoch: 36.5 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07990694037974491		[learning rate: 0.001772]
	Learning Rate: 0.00177199
	LOSS [training: 0.07990694037974491 | validation: 0.14844041388093293]
	TIME [epoch: 36.5 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08211440938970058		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.08211440938970058 | validation: 0.13589541045671255]
	TIME [epoch: 36.5 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08181623088883298		[learning rate: 0.0017564]
	Learning Rate: 0.00175637
	LOSS [training: 0.08181623088883298 | validation: 0.14902861149415014]
	TIME [epoch: 36.5 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08147098867838756		[learning rate: 0.0017486]
	Learning Rate: 0.00174861
	LOSS [training: 0.08147098867838756 | validation: 0.15001736017986383]
	TIME [epoch: 36.5 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08021348748963829		[learning rate: 0.0017409]
	Learning Rate: 0.00174088
	LOSS [training: 0.08021348748963829 | validation: 0.14067062971176772]
	TIME [epoch: 36.5 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08042415480393958		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.08042415480393958 | validation: 0.14257066322271478]
	TIME [epoch: 36.5 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08451940915699342		[learning rate: 0.0017255]
	Learning Rate: 0.00172553
	LOSS [training: 0.08451940915699342 | validation: 0.15634040886776088]
	TIME [epoch: 36.5 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0793102340256002		[learning rate: 0.0017179]
	Learning Rate: 0.00171791
	LOSS [training: 0.0793102340256002 | validation: 0.14996614539738748]
	TIME [epoch: 36.5 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08137094106907655		[learning rate: 0.0017103]
	Learning Rate: 0.00171032
	LOSS [training: 0.08137094106907655 | validation: 0.14631962826863726]
	TIME [epoch: 36.5 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08101451535308499		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.08101451535308499 | validation: 0.14537989171221574]
	TIME [epoch: 36.5 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08394785510942238		[learning rate: 0.0016952]
	Learning Rate: 0.00169524
	LOSS [training: 0.08394785510942238 | validation: 0.16618859576367132]
	TIME [epoch: 36.5 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0823628590942311		[learning rate: 0.0016877]
	Learning Rate: 0.00168775
	LOSS [training: 0.0823628590942311 | validation: 0.14919122067974047]
	TIME [epoch: 36.5 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08015513152381366		[learning rate: 0.0016803]
	Learning Rate: 0.00168029
	LOSS [training: 0.08015513152381366 | validation: 0.15270901386503122]
	TIME [epoch: 36.5 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07956788687653099		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.07956788687653099 | validation: 0.14124064293807084]
	TIME [epoch: 36.5 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07915794732454436		[learning rate: 0.0016655]
	Learning Rate: 0.00166548
	LOSS [training: 0.07915794732454436 | validation: 0.144068596979011]
	TIME [epoch: 36.5 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08018356691042754		[learning rate: 0.0016581]
	Learning Rate: 0.00165812
	LOSS [training: 0.08018356691042754 | validation: 0.14915137451054716]
	TIME [epoch: 36.5 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08051779666251593		[learning rate: 0.0016508]
	Learning Rate: 0.00165079
	LOSS [training: 0.08051779666251593 | validation: 0.15283230652448793]
	TIME [epoch: 36.6 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0793518092666868		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.0793518092666868 | validation: 0.1592074900859754]
	TIME [epoch: 36.5 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07724887985944742		[learning rate: 0.0016362]
	Learning Rate: 0.00163624
	LOSS [training: 0.07724887985944742 | validation: 0.14466699233593544]
	TIME [epoch: 36.6 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07930563223775237		[learning rate: 0.001629]
	Learning Rate: 0.00162901
	LOSS [training: 0.07930563223775237 | validation: 0.15193468705973123]
	TIME [epoch: 36.5 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08285128168362658		[learning rate: 0.0016218]
	Learning Rate: 0.00162181
	LOSS [training: 0.08285128168362658 | validation: 0.15563776204822047]
	TIME [epoch: 36.5 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07860500892425319		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.07860500892425319 | validation: 0.15487624822667403]
	TIME [epoch: 36.5 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08182601239822127		[learning rate: 0.0016075]
	Learning Rate: 0.00160751
	LOSS [training: 0.08182601239822127 | validation: 0.14863738545889113]
	TIME [epoch: 36.5 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08146760060682876		[learning rate: 0.0016004]
	Learning Rate: 0.00160041
	LOSS [training: 0.08146760060682876 | validation: 0.1476355014361015]
	TIME [epoch: 36.5 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07843726549330272		[learning rate: 0.0015933]
	Learning Rate: 0.00159334
	LOSS [training: 0.07843726549330272 | validation: 0.14174031538861612]
	TIME [epoch: 36.6 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07967197375689665		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.07967197375689665 | validation: 0.1514751871732352]
	TIME [epoch: 36.5 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07958190513123965		[learning rate: 0.0015793]
	Learning Rate: 0.00157929
	LOSS [training: 0.07958190513123965 | validation: 0.14211692140995244]
	TIME [epoch: 36.5 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08098932175746566		[learning rate: 0.0015723]
	Learning Rate: 0.00157231
	LOSS [training: 0.08098932175746566 | validation: 0.1432786306144633]
	TIME [epoch: 36.5 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08199820842780506		[learning rate: 0.0015654]
	Learning Rate: 0.00156536
	LOSS [training: 0.08199820842780506 | validation: 0.14290742580152085]
	TIME [epoch: 36.5 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07940147215184037		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.07940147215184037 | validation: 0.1442840634117574]
	TIME [epoch: 36.5 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07705842883567157		[learning rate: 0.0015516]
	Learning Rate: 0.00155156
	LOSS [training: 0.07705842883567157 | validation: 0.14814729039763672]
	TIME [epoch: 36.5 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08143132198753175		[learning rate: 0.0015447]
	Learning Rate: 0.00154471
	LOSS [training: 0.08143132198753175 | validation: 0.1435740142198814]
	TIME [epoch: 36.5 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08088775424800954		[learning rate: 0.0015379]
	Learning Rate: 0.00153788
	LOSS [training: 0.08088775424800954 | validation: 0.15018649230785341]
	TIME [epoch: 36.5 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08182229892509936		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.08182229892509936 | validation: 0.14212962882592795]
	TIME [epoch: 36.5 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08115656776173294		[learning rate: 0.0015243]
	Learning Rate: 0.00152432
	LOSS [training: 0.08115656776173294 | validation: 0.15054361836630845]
	TIME [epoch: 36.5 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07964310106498097		[learning rate: 0.0015176]
	Learning Rate: 0.00151759
	LOSS [training: 0.07964310106498097 | validation: 0.14686273649613837]
	TIME [epoch: 36.5 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0792095192487632		[learning rate: 0.0015109]
	Learning Rate: 0.00151088
	LOSS [training: 0.0792095192487632 | validation: 0.1474250115296408]
	TIME [epoch: 36.5 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0771645254544868		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.0771645254544868 | validation: 0.14987085150115687]
	TIME [epoch: 36.5 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08067530725566426		[learning rate: 0.0014976]
	Learning Rate: 0.00149756
	LOSS [training: 0.08067530725566426 | validation: 0.149243336717247]
	TIME [epoch: 36.5 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08058154462141626		[learning rate: 0.0014909]
	Learning Rate: 0.00149094
	LOSS [training: 0.08058154462141626 | validation: 0.15811648387171662]
	TIME [epoch: 36.5 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08418297620177738		[learning rate: 0.0014844]
	Learning Rate: 0.00148436
	LOSS [training: 0.08418297620177738 | validation: 0.15834618020919186]
	TIME [epoch: 36.5 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07933931347927957		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.07933931347927957 | validation: 0.14513757959354803]
	TIME [epoch: 36.5 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08044385508515665		[learning rate: 0.0014713]
	Learning Rate: 0.00147127
	LOSS [training: 0.08044385508515665 | validation: 0.14583328571028617]
	TIME [epoch: 36.6 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08037090399208366		[learning rate: 0.0014648]
	Learning Rate: 0.00146477
	LOSS [training: 0.08037090399208366 | validation: 0.14978280273955197]
	TIME [epoch: 36.5 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07834510143888515		[learning rate: 0.0014583]
	Learning Rate: 0.0014583
	LOSS [training: 0.07834510143888515 | validation: 0.14617520155608502]
	TIME [epoch: 36.5 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08094143063201477		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.08094143063201477 | validation: 0.14890256898005433]
	TIME [epoch: 36.5 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0792456726811534		[learning rate: 0.0014454]
	Learning Rate: 0.00144544
	LOSS [training: 0.0792456726811534 | validation: 0.15059566584606324]
	TIME [epoch: 36.6 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0792260027606163		[learning rate: 0.0014391]
	Learning Rate: 0.00143905
	LOSS [training: 0.0792260027606163 | validation: 0.15104377795013468]
	TIME [epoch: 36.5 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07921946276689121		[learning rate: 0.0014327]
	Learning Rate: 0.0014327
	LOSS [training: 0.07921946276689121 | validation: 0.14759341990559466]
	TIME [epoch: 36.5 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0806342517677056		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.0806342517677056 | validation: 0.1522824841795825]
	TIME [epoch: 36.5 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08107087908174326		[learning rate: 0.0014201]
	Learning Rate: 0.00142006
	LOSS [training: 0.08107087908174326 | validation: 0.1464532703196129]
	TIME [epoch: 36.5 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08039597519347089		[learning rate: 0.0014138]
	Learning Rate: 0.00141379
	LOSS [training: 0.08039597519347089 | validation: 0.14625608198035386]
	TIME [epoch: 36.5 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07986251271466198		[learning rate: 0.0014075]
	Learning Rate: 0.00140754
	LOSS [training: 0.07986251271466198 | validation: 0.145745293113225]
	TIME [epoch: 36.5 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08175502963169992		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.08175502963169992 | validation: 0.14565154272345496]
	TIME [epoch: 36.5 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07934603975951202		[learning rate: 0.0013951]
	Learning Rate: 0.00139513
	LOSS [training: 0.07934603975951202 | validation: 0.14565751202410826]
	TIME [epoch: 36.6 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08021386445246709		[learning rate: 0.001389]
	Learning Rate: 0.00138897
	LOSS [training: 0.08021386445246709 | validation: 0.14374026214724694]
	TIME [epoch: 36.6 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07784777697601554		[learning rate: 0.0013828]
	Learning Rate: 0.00138283
	LOSS [training: 0.07784777697601554 | validation: 0.1383240895733082]
	TIME [epoch: 36.6 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07728147058706812		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.07728147058706812 | validation: 0.1471016586964459]
	TIME [epoch: 36.5 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0791636518502333		[learning rate: 0.0013706]
	Learning Rate: 0.00137064
	LOSS [training: 0.0791636518502333 | validation: 0.14677111675187757]
	TIME [epoch: 36.6 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08260573317994306		[learning rate: 0.0013646]
	Learning Rate: 0.00136458
	LOSS [training: 0.08260573317994306 | validation: 0.15667840823031096]
	TIME [epoch: 36.5 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08080666418495705		[learning rate: 0.0013586]
	Learning Rate: 0.00135855
	LOSS [training: 0.08080666418495705 | validation: 0.15195608635815913]
	TIME [epoch: 36.5 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07983901258961759		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.07983901258961759 | validation: 0.15042587572104357]
	TIME [epoch: 36.5 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08178123474683		[learning rate: 0.0013466]
	Learning Rate: 0.00134658
	LOSS [training: 0.08178123474683 | validation: 0.14430583309392767]
	TIME [epoch: 36.4 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08140673393704755		[learning rate: 0.0013406]
	Learning Rate: 0.00134063
	LOSS [training: 0.08140673393704755 | validation: 0.15281143369288186]
	TIME [epoch: 36.5 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07756201192059503		[learning rate: 0.0013347]
	Learning Rate: 0.0013347
	LOSS [training: 0.07756201192059503 | validation: 0.14880503053810992]
	TIME [epoch: 36.5 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07951326027104375		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.07951326027104375 | validation: 0.14610419116648324]
	TIME [epoch: 36.5 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07806568100458403		[learning rate: 0.0013229]
	Learning Rate: 0.00132293
	LOSS [training: 0.07806568100458403 | validation: 0.14492555134607293]
	TIME [epoch: 36.5 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07958520963759692		[learning rate: 0.0013171]
	Learning Rate: 0.00131709
	LOSS [training: 0.07958520963759692 | validation: 0.1416865492790463]
	TIME [epoch: 36.6 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0794156275798493		[learning rate: 0.0013113]
	Learning Rate: 0.00131127
	LOSS [training: 0.0794156275798493 | validation: 0.14419542514683734]
	TIME [epoch: 36.5 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0775377075560724		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.0775377075560724 | validation: 0.14625001405578233]
	TIME [epoch: 36.6 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08100947014096976		[learning rate: 0.0012997]
	Learning Rate: 0.00129971
	LOSS [training: 0.08100947014096976 | validation: 0.1464815422160934]
	TIME [epoch: 36.5 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0808505660474398		[learning rate: 0.001294]
	Learning Rate: 0.00129397
	LOSS [training: 0.0808505660474398 | validation: 0.14267966770855506]
	TIME [epoch: 36.6 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07864085363482105		[learning rate: 0.0012882]
	Learning Rate: 0.00128825
	LOSS [training: 0.07864085363482105 | validation: 0.14326778255584657]
	TIME [epoch: 36.5 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08040137148322898		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.08040137148322898 | validation: 0.15001928081721733]
	TIME [epoch: 36.5 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07833766355500975		[learning rate: 0.0012769]
	Learning Rate: 0.00127689
	LOSS [training: 0.07833766355500975 | validation: 0.14856514092033807]
	TIME [epoch: 36.5 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07958599841160005		[learning rate: 0.0012712]
	Learning Rate: 0.00127125
	LOSS [training: 0.07958599841160005 | validation: 0.1447221503534113]
	TIME [epoch: 36.5 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07902140802437228		[learning rate: 0.0012656]
	Learning Rate: 0.00126563
	LOSS [training: 0.07902140802437228 | validation: 0.1474347660499501]
	TIME [epoch: 36.6 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0790310394322245		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.0790310394322245 | validation: 0.14370808976961802]
	TIME [epoch: 36.5 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07903357392382518		[learning rate: 0.0012545]
	Learning Rate: 0.00125447
	LOSS [training: 0.07903357392382518 | validation: 0.14039656410340937]
	TIME [epoch: 36.5 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07753687606766116		[learning rate: 0.0012489]
	Learning Rate: 0.00124893
	LOSS [training: 0.07753687606766116 | validation: 0.14475970162143606]
	TIME [epoch: 36.5 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07791836271584082		[learning rate: 0.0012434]
	Learning Rate: 0.00124341
	LOSS [training: 0.07791836271584082 | validation: 0.1431518890336642]
	TIME [epoch: 36.6 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0787455312529255		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.0787455312529255 | validation: 0.14859927882935506]
	TIME [epoch: 36.5 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08016861334686323		[learning rate: 0.0012324]
	Learning Rate: 0.00123245
	LOSS [training: 0.08016861334686323 | validation: 0.14452831775240377]
	TIME [epoch: 36.6 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08036750705775139		[learning rate: 0.001227]
	Learning Rate: 0.001227
	LOSS [training: 0.08036750705775139 | validation: 0.14683913224396694]
	TIME [epoch: 36.5 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07937249328353464		[learning rate: 0.0012216]
	Learning Rate: 0.00122158
	LOSS [training: 0.07937249328353464 | validation: 0.1578064159702488]
	TIME [epoch: 36.5 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08170537994675102		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.08170537994675102 | validation: 0.15593256046483386]
	TIME [epoch: 36.4 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07808566195776652		[learning rate: 0.0012108]
	Learning Rate: 0.00121081
	LOSS [training: 0.07808566195776652 | validation: 0.1547274007863294]
	TIME [epoch: 36.6 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07785391787478582		[learning rate: 0.0012055]
	Learning Rate: 0.00120546
	LOSS [training: 0.07785391787478582 | validation: 0.14801956678485426]
	TIME [epoch: 36.5 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07880888737376487		[learning rate: 0.0012001]
	Learning Rate: 0.00120014
	LOSS [training: 0.07880888737376487 | validation: 0.14592046502670114]
	TIME [epoch: 36.6 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07713995670492688		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.07713995670492688 | validation: 0.1496571311819365]
	TIME [epoch: 36.5 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07827228270296513		[learning rate: 0.0011896]
	Learning Rate: 0.00118956
	LOSS [training: 0.07827228270296513 | validation: 0.15368379154710038]
	TIME [epoch: 36.5 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07948921456380473		[learning rate: 0.0011843]
	Learning Rate: 0.0011843
	LOSS [training: 0.07948921456380473 | validation: 0.1494212439483168]
	TIME [epoch: 36.5 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07980065068723878		[learning rate: 0.0011791]
	Learning Rate: 0.00117907
	LOSS [training: 0.07980065068723878 | validation: 0.14097391377572083]
	TIME [epoch: 36.5 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0796519468148643		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.0796519468148643 | validation: 0.14353208178342836]
	TIME [epoch: 36.5 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07901892405863364		[learning rate: 0.0011687]
	Learning Rate: 0.00116867
	LOSS [training: 0.07901892405863364 | validation: 0.14546133287758606]
	TIME [epoch: 36.5 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07970294834388958		[learning rate: 0.0011635]
	Learning Rate: 0.00116351
	LOSS [training: 0.07970294834388958 | validation: 0.14734581072667824]
	TIME [epoch: 36.5 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08096557907622035		[learning rate: 0.0011584]
	Learning Rate: 0.00115837
	LOSS [training: 0.08096557907622035 | validation: 0.14553039832891113]
	TIME [epoch: 36.5 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08057216238653744		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.08057216238653744 | validation: 0.15213184968756102]
	TIME [epoch: 36.5 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08087761219513499		[learning rate: 0.0011482]
	Learning Rate: 0.00114815
	LOSS [training: 0.08087761219513499 | validation: 0.1445674969594895]
	TIME [epoch: 36.5 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07846931459746957		[learning rate: 0.0011431]
	Learning Rate: 0.00114308
	LOSS [training: 0.07846931459746957 | validation: 0.1411369703592509]
	TIME [epoch: 36.5 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07977118306270573		[learning rate: 0.001138]
	Learning Rate: 0.00113803
	LOSS [training: 0.07977118306270573 | validation: 0.14208498315921317]
	TIME [epoch: 36.5 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07739608384800656		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.07739608384800656 | validation: 0.15018224294341762]
	TIME [epoch: 36.5 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08019595768144035		[learning rate: 0.001128]
	Learning Rate: 0.001128
	LOSS [training: 0.08019595768144035 | validation: 0.1565981138702719]
	TIME [epoch: 36.5 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07891996535984862		[learning rate: 0.001123]
	Learning Rate: 0.00112301
	LOSS [training: 0.07891996535984862 | validation: 0.14842919761282533]
	TIME [epoch: 36.5 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0791425285573345		[learning rate: 0.0011181]
	Learning Rate: 0.00111805
	LOSS [training: 0.0791425285573345 | validation: 0.14530434961408997]
	TIME [epoch: 36.5 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07823326293481395		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.07823326293481395 | validation: 0.14596978718163658]
	TIME [epoch: 36.5 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08002913727424395		[learning rate: 0.0011082]
	Learning Rate: 0.00110819
	LOSS [training: 0.08002913727424395 | validation: 0.14217908156838818]
	TIME [epoch: 36.5 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07841231850431782		[learning rate: 0.0011033]
	Learning Rate: 0.0011033
	LOSS [training: 0.07841231850431782 | validation: 0.14258187957457974]
	TIME [epoch: 36.5 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07870329185246679		[learning rate: 0.0010984]
	Learning Rate: 0.00109842
	LOSS [training: 0.07870329185246679 | validation: 0.14465245689029405]
	TIME [epoch: 36.5 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07947313801157996		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.07947313801157996 | validation: 0.1473550185543783]
	TIME [epoch: 36.5 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08102946899468427		[learning rate: 0.0010887]
	Learning Rate: 0.00108874
	LOSS [training: 0.08102946899468427 | validation: 0.14275146959943066]
	TIME [epoch: 36.5 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07960719277939628		[learning rate: 0.0010839]
	Learning Rate: 0.00108393
	LOSS [training: 0.07960719277939628 | validation: 0.14453308029070638]
	TIME [epoch: 36.5 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07773617767128108		[learning rate: 0.0010791]
	Learning Rate: 0.00107914
	LOSS [training: 0.07773617767128108 | validation: 0.1447170308461432]
	TIME [epoch: 36.5 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0786155530551652		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.0786155530551652 | validation: 0.14818851783844092]
	TIME [epoch: 36.5 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07912417198927135		[learning rate: 0.0010696]
	Learning Rate: 0.00106962
	LOSS [training: 0.07912417198927135 | validation: 0.14358541837102803]
	TIME [epoch: 36.5 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08091167035834199		[learning rate: 0.0010649]
	Learning Rate: 0.0010649
	LOSS [training: 0.08091167035834199 | validation: 0.14989576811991429]
	TIME [epoch: 36.5 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08004068320755428		[learning rate: 0.0010602]
	Learning Rate: 0.00106019
	LOSS [training: 0.08004068320755428 | validation: 0.14236718656384414]
	TIME [epoch: 36.6 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07752785418936847		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.07752785418936847 | validation: 0.13904759645013404]
	TIME [epoch: 36.5 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07849867631272103		[learning rate: 0.0010508]
	Learning Rate: 0.00105084
	LOSS [training: 0.07849867631272103 | validation: 0.14712307363935634]
	TIME [epoch: 36.5 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07889960982244518		[learning rate: 0.0010462]
	Learning Rate: 0.0010462
	LOSS [training: 0.07889960982244518 | validation: 0.13920520870878278]
	TIME [epoch: 36.5 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0789381546844686		[learning rate: 0.0010416]
	Learning Rate: 0.00104158
	LOSS [training: 0.0789381546844686 | validation: 0.1476919796115379]
	TIME [epoch: 36.5 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07828013973665231		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.07828013973665231 | validation: 0.14447306649677685]
	TIME [epoch: 36.5 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07845423172803367		[learning rate: 0.0010324]
	Learning Rate: 0.0010324
	LOSS [training: 0.07845423172803367 | validation: 0.15215614718853573]
	TIME [epoch: 36.5 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0811426945346151		[learning rate: 0.0010278]
	Learning Rate: 0.00102783
	LOSS [training: 0.0811426945346151 | validation: 0.14378047166519758]
	TIME [epoch: 36.5 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07632384320667637		[learning rate: 0.0010233]
	Learning Rate: 0.00102329
	LOSS [training: 0.07632384320667637 | validation: 0.1466418483434217]
	TIME [epoch: 36.5 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07865800442670863		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.07865800442670863 | validation: 0.14637645978263544]
	TIME [epoch: 36.5 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07947043164699699		[learning rate: 0.0010143]
	Learning Rate: 0.00101427
	LOSS [training: 0.07947043164699699 | validation: 0.14810621652835762]
	TIME [epoch: 36.5 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07790356617174363		[learning rate: 0.0010098]
	Learning Rate: 0.00100979
	LOSS [training: 0.07790356617174363 | validation: 0.15307212755092317]
	TIME [epoch: 36.5 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0781450078053502		[learning rate: 0.0010053]
	Learning Rate: 0.00100533
	LOSS [training: 0.0781450078053502 | validation: 0.14348871999780333]
	TIME [epoch: 36.5 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07769060207457897		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.07769060207457897 | validation: 0.1518436813941146]
	TIME [epoch: 36.5 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07892035404089429		[learning rate: 0.00099646]
	Learning Rate: 0.000996464
	LOSS [training: 0.07892035404089429 | validation: 0.14521930866611948]
	TIME [epoch: 36.4 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07849249379868965		[learning rate: 0.00099206]
	Learning Rate: 0.000992061
	LOSS [training: 0.07849249379868965 | validation: 0.1525505949018761]
	TIME [epoch: 36.4 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07893843446483542		[learning rate: 0.00098768]
	Learning Rate: 0.000987678
	LOSS [training: 0.07893843446483542 | validation: 0.1439227905182112]
	TIME [epoch: 36.5 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07987963147190735		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.07987963147190735 | validation: 0.14242702012386096]
	TIME [epoch: 36.6 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07771924259768684		[learning rate: 0.00097897]
	Learning Rate: 0.00097897
	LOSS [training: 0.07771924259768684 | validation: 0.14369458449149577]
	TIME [epoch: 36.4 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07879546663475878		[learning rate: 0.00097464]
	Learning Rate: 0.000974644
	LOSS [training: 0.07879546663475878 | validation: 0.14189593349025947]
	TIME [epoch: 36.5 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0768211471999087		[learning rate: 0.00097034]
	Learning Rate: 0.000970338
	LOSS [training: 0.0768211471999087 | validation: 0.14715091926464008]
	TIME [epoch: 36.5 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07732026988637906		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.07732026988637906 | validation: 0.14274285626635766]
	TIME [epoch: 36.5 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07851549007567997		[learning rate: 0.00096178]
	Learning Rate: 0.000961783
	LOSS [training: 0.07851549007567997 | validation: 0.1486949092184907]
	TIME [epoch: 36.5 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07748337499873494		[learning rate: 0.00095753]
	Learning Rate: 0.000957533
	LOSS [training: 0.07748337499873494 | validation: 0.14039107522451594]
	TIME [epoch: 36.5 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08043571876864632		[learning rate: 0.0009533]
	Learning Rate: 0.000953303
	LOSS [training: 0.08043571876864632 | validation: 0.14604868435396548]
	TIME [epoch: 36.5 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07728993484638545		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.07728993484638545 | validation: 0.1451003978440545]
	TIME [epoch: 36.5 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0812050453262161		[learning rate: 0.0009449]
	Learning Rate: 0.000944897
	LOSS [training: 0.0812050453262161 | validation: 0.14757835230232258]
	TIME [epoch: 36.5 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08044462561565059		[learning rate: 0.00094072]
	Learning Rate: 0.000940723
	LOSS [training: 0.08044462561565059 | validation: 0.14816133812543428]
	TIME [epoch: 36.4 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07865132714677439		[learning rate: 0.00093657]
	Learning Rate: 0.000936566
	LOSS [training: 0.07865132714677439 | validation: 0.1507948434861712]
	TIME [epoch: 36.5 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07759357764354138		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.07759357764354138 | validation: 0.1519625114530216]
	TIME [epoch: 36.5 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0814681695994734		[learning rate: 0.00092831]
	Learning Rate: 0.000928309
	LOSS [training: 0.0814681695994734 | validation: 0.14093994363838255]
	TIME [epoch: 36.5 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07759947077209238		[learning rate: 0.00092421]
	Learning Rate: 0.000924207
	LOSS [training: 0.07759947077209238 | validation: 0.15147033568033894]
	TIME [epoch: 36.5 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07942995419842297		[learning rate: 0.00092012]
	Learning Rate: 0.000920124
	LOSS [training: 0.07942995419842297 | validation: 0.14760793002279418]
	TIME [epoch: 36.5 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07949864013163091		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.07949864013163091 | validation: 0.14354221570256775]
	TIME [epoch: 36.5 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07847748429531905		[learning rate: 0.00091201]
	Learning Rate: 0.000912011
	LOSS [training: 0.07847748429531905 | validation: 0.14278877257505992]
	TIME [epoch: 36.5 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08006721758868747		[learning rate: 0.00090798]
	Learning Rate: 0.000907981
	LOSS [training: 0.08006721758868747 | validation: 0.14265038724017456]
	TIME [epoch: 36.5 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07827190406172889		[learning rate: 0.00090397]
	Learning Rate: 0.00090397
	LOSS [training: 0.07827190406172889 | validation: 0.15118442223891976]
	TIME [epoch: 36.5 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07829056989608053		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.07829056989608053 | validation: 0.14219629317682253]
	TIME [epoch: 36.5 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07651591805234358		[learning rate: 0.000896]
	Learning Rate: 0.000895999
	LOSS [training: 0.07651591805234358 | validation: 0.1389605964679293]
	TIME [epoch: 36.4 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07578691146910352		[learning rate: 0.00089204]
	Learning Rate: 0.000892041
	LOSS [training: 0.07578691146910352 | validation: 0.1439339066670295]
	TIME [epoch: 36.5 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07736041372679153		[learning rate: 0.0008881]
	Learning Rate: 0.000888099
	LOSS [training: 0.07736041372679153 | validation: 0.1431692997178716]
	TIME [epoch: 36.5 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07829175161876553		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.07829175161876553 | validation: 0.14911552378919102]
	TIME [epoch: 36.4 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07877858976699435		[learning rate: 0.00088027]
	Learning Rate: 0.000880269
	LOSS [training: 0.07877858976699435 | validation: 0.14325684470975655]
	TIME [epoch: 36.4 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07835660775276128		[learning rate: 0.00087638]
	Learning Rate: 0.00087638
	LOSS [training: 0.07835660775276128 | validation: 0.1458772833257643]
	TIME [epoch: 36.5 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07959316899828653		[learning rate: 0.00087251]
	Learning Rate: 0.000872508
	LOSS [training: 0.07959316899828653 | validation: 0.14704810254232462]
	TIME [epoch: 36.5 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07973482302534654		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.07973482302534654 | validation: 0.1453738096791336]
	TIME [epoch: 36.5 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08017926985893034		[learning rate: 0.00086481]
	Learning Rate: 0.000864815
	LOSS [training: 0.08017926985893034 | validation: 0.14138045150747394]
	TIME [epoch: 36.5 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07835691976203037		[learning rate: 0.00086099]
	Learning Rate: 0.000860994
	LOSS [training: 0.07835691976203037 | validation: 0.14888966521082034]
	TIME [epoch: 36.4 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0806601759626108		[learning rate: 0.00085719]
	Learning Rate: 0.00085719
	LOSS [training: 0.0806601759626108 | validation: 0.1494030730897783]
	TIME [epoch: 36.5 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07525228289814137		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.07525228289814137 | validation: 0.1458153800089791]
	TIME [epoch: 36.5 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0776346897656969		[learning rate: 0.00084963]
	Learning Rate: 0.000849632
	LOSS [training: 0.0776346897656969 | validation: 0.1449232633970318]
	TIME [epoch: 36.5 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07741685533294755		[learning rate: 0.00084588]
	Learning Rate: 0.000845878
	LOSS [training: 0.07741685533294755 | validation: 0.15129100767702336]
	TIME [epoch: 36.6 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07884214469916376		[learning rate: 0.00084214]
	Learning Rate: 0.000842141
	LOSS [training: 0.07884214469916376 | validation: 0.14535969078101263]
	TIME [epoch: 36.4 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08083095807387297		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.08083095807387297 | validation: 0.14258181591280897]
	TIME [epoch: 36.4 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07924366375560424		[learning rate: 0.00083472]
	Learning Rate: 0.000834715
	LOSS [training: 0.07924366375560424 | validation: 0.14179376443161726]
	TIME [epoch: 36.4 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07977289849128999		[learning rate: 0.00083103]
	Learning Rate: 0.000831028
	LOSS [training: 0.07977289849128999 | validation: 0.14255936605708422]
	TIME [epoch: 36.6 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07821462912321557		[learning rate: 0.00082736]
	Learning Rate: 0.000827356
	LOSS [training: 0.07821462912321557 | validation: 0.14618736578111202]
	TIME [epoch: 36.5 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0747917912358799		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.0747917912358799 | validation: 0.1489809996551847]
	TIME [epoch: 36.5 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07933634599176617		[learning rate: 0.00082006]
	Learning Rate: 0.000820061
	LOSS [training: 0.07933634599176617 | validation: 0.14688062110115285]
	TIME [epoch: 36.4 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07775143477517679		[learning rate: 0.00081644]
	Learning Rate: 0.000816438
	LOSS [training: 0.07775143477517679 | validation: 0.15257025402417693]
	TIME [epoch: 36.4 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08006681250993239		[learning rate: 0.00081283]
	Learning Rate: 0.000812831
	LOSS [training: 0.08006681250993239 | validation: 0.14736547307882567]
	TIME [epoch: 36.4 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07953306328027342		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.07953306328027342 | validation: 0.1424498157628223]
	TIME [epoch: 36.5 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0781133687839334		[learning rate: 0.00080566]
	Learning Rate: 0.000805664
	LOSS [training: 0.0781133687839334 | validation: 0.14795629519576745]
	TIME [epoch: 36.4 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07839176842430214		[learning rate: 0.0008021]
	Learning Rate: 0.000802104
	LOSS [training: 0.07839176842430214 | validation: 0.1487492240272349]
	TIME [epoch: 36.4 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07849973759672466		[learning rate: 0.00079856]
	Learning Rate: 0.00079856
	LOSS [training: 0.07849973759672466 | validation: 0.1411685933160927]
	TIME [epoch: 36.5 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08150458621575628		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.08150458621575628 | validation: 0.1416625962457826]
	TIME [epoch: 36.4 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08017463528598989		[learning rate: 0.00079152]
	Learning Rate: 0.000791519
	LOSS [training: 0.08017463528598989 | validation: 0.1454081051438646]
	TIME [epoch: 36.6 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0779098087988864		[learning rate: 0.00078802]
	Learning Rate: 0.000788022
	LOSS [training: 0.0779098087988864 | validation: 0.14194336951725167]
	TIME [epoch: 36.5 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07773078602240516		[learning rate: 0.00078454]
	Learning Rate: 0.000784541
	LOSS [training: 0.07773078602240516 | validation: 0.14561771722038605]
	TIME [epoch: 36.6 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07793325446948776		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.07793325446948776 | validation: 0.14579448969394418]
	TIME [epoch: 36.5 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07740860199536		[learning rate: 0.00077762]
	Learning Rate: 0.000777623
	LOSS [training: 0.07740860199536 | validation: 0.14654301135798198]
	TIME [epoch: 36.5 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08003065545132029		[learning rate: 0.00077419]
	Learning Rate: 0.000774188
	LOSS [training: 0.08003065545132029 | validation: 0.14485655376967452]
	TIME [epoch: 36.5 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07879000186838682		[learning rate: 0.00077077]
	Learning Rate: 0.000770767
	LOSS [training: 0.07879000186838682 | validation: 0.15001531886550012]
	TIME [epoch: 36.5 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07717560015228117		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.07717560015228117 | validation: 0.1477841169391631]
	TIME [epoch: 36.3 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07742864651268683		[learning rate: 0.00076397]
	Learning Rate: 0.000763971
	LOSS [training: 0.07742864651268683 | validation: 0.14707554753324312]
	TIME [epoch: 36.4 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07672579967610854		[learning rate: 0.0007606]
	Learning Rate: 0.000760596
	LOSS [training: 0.07672579967610854 | validation: 0.15137005995483546]
	TIME [epoch: 36.4 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07546669085830876		[learning rate: 0.00075724]
	Learning Rate: 0.000757235
	LOSS [training: 0.07546669085830876 | validation: 0.1433607725418515]
	TIME [epoch: 36.5 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07791177027143095		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.07791177027143095 | validation: 0.1419526658388301]
	TIME [epoch: 36.4 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0774378695118743		[learning rate: 0.00075056]
	Learning Rate: 0.000750559
	LOSS [training: 0.0774378695118743 | validation: 0.14195802327101867]
	TIME [epoch: 36.4 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v1_20240627_193159/states/model_facs_dec2b_2dpca_v1_625.pth
Halted early. No improvement in validation loss for 200 epochs.
Finished training in 22934.188 seconds.
