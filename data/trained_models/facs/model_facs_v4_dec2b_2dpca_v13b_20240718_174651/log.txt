Args:
Namespace(name='model_facs_v4_dec2b_2dpca_v13b', outdir='out/model_training/model_facs_v4_dec2b_2dpca_v13b', training_data='data/training_data/facs_v4/pca/dec2_fitonsubset/transition2_subset_ce_pn_m_pc12/training', validation_data='data/training_data/facs_v4/pca/dec2_fitonsubset/transition2_subset_ce_pn_m_pc12/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=10, batch_size=50, patience=200, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, quadratic_a=1.0, quadratic_b=1.0, ndims=2, nparams=2, nsigs=2, ncells=400, ncells_sample=400, model_do_sample=False, dt=0.005, dt_schedule='stepped', dt_schedule_bounds=[50, 100, 200, 300], dt_schedule_scales=[0.5, 0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', kernel='multiscale', bw_range=[0.2, 0.5, 0.9, 1.1, 1.3, 1.5, 2.0], optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 2669086185

Training model...

Saving initial model state to: out/model_training/model_facs_v4_dec2b_2dpca_v13b_20240718_174651/states/model_facs_v4_dec2b_2dpca_v13b_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9284626507491359		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9284626507491359 | validation: 1.0533240919162943]
	TIME [epoch: 28.6 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13b_20240718_174651/states/model_facs_v4_dec2b_2dpca_v13b_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7054187547784125		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7054187547784125 | validation: 1.051137828771615]
	TIME [epoch: 4.92 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13b_20240718_174651/states/model_facs_v4_dec2b_2dpca_v13b_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6630791444745014		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6630791444745014 | validation: 0.9801796746791356]
	TIME [epoch: 4.92 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13b_20240718_174651/states/model_facs_v4_dec2b_2dpca_v13b_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7014364349650194		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7014364349650194 | validation: 0.8808082654071439]
	TIME [epoch: 4.94 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13b_20240718_174651/states/model_facs_v4_dec2b_2dpca_v13b_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5925088452733248		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5925088452733248 | validation: 0.8583002040144085]
	TIME [epoch: 4.93 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13b_20240718_174651/states/model_facs_v4_dec2b_2dpca_v13b_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5571299776387919		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5571299776387919 | validation: 0.823211361612617]
	TIME [epoch: 4.92 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13b_20240718_174651/states/model_facs_v4_dec2b_2dpca_v13b_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5311143769059293		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5311143769059293 | validation: 0.8552212846767306]
	TIME [epoch: 4.92 sec]
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5347773359558164		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5347773359558164 | validation: 1.1060190114278416]
	TIME [epoch: 4.92 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5535511922695963		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5535511922695963 | validation: 0.769281191010645]
	TIME [epoch: 4.91 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13b_20240718_174651/states/model_facs_v4_dec2b_2dpca_v13b_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5533754708436276		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5533754708436276 | validation: 0.7679342011887914]
	TIME [epoch: 4.92 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13b_20240718_174651/states/model_facs_v4_dec2b_2dpca_v13b_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46028520474371115		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.46028520474371115 | validation: 0.7372784440081387]
	TIME [epoch: 4.94 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13b_20240718_174651/states/model_facs_v4_dec2b_2dpca_v13b_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4310424150560286		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4310424150560286 | validation: 0.754039254671536]
	TIME [epoch: 4.99 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.453430017208201		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.453430017208201 | validation: 0.7239927321010408]
	TIME [epoch: 4.92 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13b_20240718_174651/states/model_facs_v4_dec2b_2dpca_v13b_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4488669548088179		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4488669548088179 | validation: 0.7061351270467532]
	TIME [epoch: 4.92 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13b_20240718_174651/states/model_facs_v4_dec2b_2dpca_v13b_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4382595299625149		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4382595299625149 | validation: 0.7256608026370465]
	TIME [epoch: 4.91 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41340738523535037		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.41340738523535037 | validation: 0.7114710472971628]
	TIME [epoch: 4.92 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3971674991622257		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3971674991622257 | validation: 0.5972990143921976]
	TIME [epoch: 4.91 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13b_20240718_174651/states/model_facs_v4_dec2b_2dpca_v13b_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4129294656213919		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4129294656213919 | validation: 0.6157451997805051]
	TIME [epoch: 4.92 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31935343568925684		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.31935343568925684 | validation: 0.524419587618559]
	TIME [epoch: 4.92 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13b_20240718_174651/states/model_facs_v4_dec2b_2dpca_v13b_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35641953094330603		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.35641953094330603 | validation: 0.588477969790044]
	TIME [epoch: 4.91 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33097814115911356		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.33097814115911356 | validation: 0.5115466790892585]
	TIME [epoch: 4.91 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13b_20240718_174651/states/model_facs_v4_dec2b_2dpca_v13b_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30749596702410686		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.30749596702410686 | validation: 0.6892629675945431]
	TIME [epoch: 4.92 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29258091751802046		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.29258091751802046 | validation: 0.4909446170689009]
	TIME [epoch: 4.92 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13b_20240718_174651/states/model_facs_v4_dec2b_2dpca_v13b_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25503567060882504		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.25503567060882504 | validation: 0.4768855258531904]
	TIME [epoch: 4.92 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13b_20240718_174651/states/model_facs_v4_dec2b_2dpca_v13b_24.pth
	Model improved!!!
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30227992412854576		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.30227992412854576 | validation: 0.5008704013291078]
	TIME [epoch: 4.92 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25601519688823166		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.25601519688823166 | validation: 0.47829557057768274]
	TIME [epoch: 4.91 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2634056149272419		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2634056149272419 | validation: 0.7406047137935815]
	TIME [epoch: 4.92 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3397996973571397		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3397996973571397 | validation: 0.4371341162112227]
	TIME [epoch: 4.92 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13b_20240718_174651/states/model_facs_v4_dec2b_2dpca_v13b_28.pth
	Model improved!!!
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2280833794992227		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2280833794992227 | validation: 0.4771831552807372]
	TIME [epoch: 4.93 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2552601744138093		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2552601744138093 | validation: 0.48089453790712056]
	TIME [epoch: 4.95 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2147892437548989		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2147892437548989 | validation: 0.41011973113421946]
	TIME [epoch: 4.92 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13b_20240718_174651/states/model_facs_v4_dec2b_2dpca_v13b_31.pth
	Model improved!!!
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3098098998999476		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3098098998999476 | validation: 0.5868917071928715]
	TIME [epoch: 4.93 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27150207725699177		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.27150207725699177 | validation: 0.4173989414601229]
	TIME [epoch: 4.92 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2288779623132167		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2288779623132167 | validation: 0.44584039331980335]
	TIME [epoch: 4.92 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24795415340237031		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24795415340237031 | validation: 0.41081641899575855]
	TIME [epoch: 4.91 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24295654215907952		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24295654215907952 | validation: 0.5315383102097252]
	TIME [epoch: 4.91 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25072231317994154		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.25072231317994154 | validation: 0.42605802333066856]
	TIME [epoch: 4.92 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21626397997084731		[learning rate: 0.0099882]
	Learning Rate: 0.0099882
	LOSS [training: 0.21626397997084731 | validation: 0.4410459942792583]
	TIME [epoch: 4.91 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22989923002607754		[learning rate: 0.0099411]
	Learning Rate: 0.00994113
	LOSS [training: 0.22989923002607754 | validation: 0.385027240299791]
	TIME [epoch: 4.91 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13b_20240718_174651/states/model_facs_v4_dec2b_2dpca_v13b_39.pth
	Model improved!!!
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1953019651962655		[learning rate: 0.0098943]
	Learning Rate: 0.00989429
	LOSS [training: 0.1953019651962655 | validation: 0.5207289666113429]
	TIME [epoch: 4.92 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3082182543228871		[learning rate: 0.0098477]
	Learning Rate: 0.00984767
	LOSS [training: 0.3082182543228871 | validation: 0.40143703222780397]
	TIME [epoch: 4.92 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20475203322291774		[learning rate: 0.0098013]
	Learning Rate: 0.00980126
	LOSS [training: 0.20475203322291774 | validation: 0.4389965452499595]
	TIME [epoch: 4.92 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2454737077062306		[learning rate: 0.0097551]
	Learning Rate: 0.00975508
	LOSS [training: 0.2454737077062306 | validation: 0.5429688300173]
	TIME [epoch: 4.91 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28830648418503535		[learning rate: 0.0097091]
	Learning Rate: 0.00970911
	LOSS [training: 0.28830648418503535 | validation: 0.4220490571479941]
	TIME [epoch: 4.91 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22288624944527624		[learning rate: 0.0096634]
	Learning Rate: 0.00966336
	LOSS [training: 0.22288624944527624 | validation: 0.38109645879381143]
	TIME [epoch: 4.92 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13b_20240718_174651/states/model_facs_v4_dec2b_2dpca_v13b_45.pth
	Model improved!!!
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21435843932140414		[learning rate: 0.0096178]
	Learning Rate: 0.00961783
	LOSS [training: 0.21435843932140414 | validation: 0.4358565875217943]
	TIME [epoch: 4.92 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18390458615150235		[learning rate: 0.0095725]
	Learning Rate: 0.00957251
	LOSS [training: 0.18390458615150235 | validation: 0.4442851808138424]
	TIME [epoch: 4.93 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30098229172924124		[learning rate: 0.0095274]
	Learning Rate: 0.0095274
	LOSS [training: 0.30098229172924124 | validation: 0.4301203456285282]
	TIME [epoch: 4.95 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23343597057745963		[learning rate: 0.0094825]
	Learning Rate: 0.0094825
	LOSS [training: 0.23343597057745963 | validation: 0.409956406801805]
	TIME [epoch: 4.93 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22689756012949802		[learning rate: 0.0094378]
	Learning Rate: 0.00943782
	LOSS [training: 0.22689756012949802 | validation: 0.6857460082232347]
	TIME [epoch: 4.93 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28656930531448266		[learning rate: 0.0093933]
	Learning Rate: 0.00939335
	LOSS [training: 0.28656930531448266 | validation: 0.3637689527629797]
	TIME [epoch: 31.3 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13b_20240718_174651/states/model_facs_v4_dec2b_2dpca_v13b_51.pth
	Model improved!!!
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1828026144257182		[learning rate: 0.0093491]
	Learning Rate: 0.00934909
	LOSS [training: 0.1828026144257182 | validation: 0.40697647107502555]
	TIME [epoch: 9.51 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21784848720944816		[learning rate: 0.009305]
	Learning Rate: 0.00930503
	LOSS [training: 0.21784848720944816 | validation: 0.436758102766313]
	TIME [epoch: 9.49 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22550166196194155		[learning rate: 0.0092612]
	Learning Rate: 0.00926119
	LOSS [training: 0.22550166196194155 | validation: 0.5044211095239135]
	TIME [epoch: 9.47 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2176899100642726		[learning rate: 0.0092175]
	Learning Rate: 0.00921755
	LOSS [training: 0.2176899100642726 | validation: 0.4247624744037965]
	TIME [epoch: 9.46 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24207181351620827		[learning rate: 0.0091741]
	Learning Rate: 0.00917411
	LOSS [training: 0.24207181351620827 | validation: 0.405438262197257]
	TIME [epoch: 9.46 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18678559667228484		[learning rate: 0.0091309]
	Learning Rate: 0.00913088
	LOSS [training: 0.18678559667228484 | validation: 0.35897584949326783]
	TIME [epoch: 9.49 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13b_20240718_174651/states/model_facs_v4_dec2b_2dpca_v13b_57.pth
	Model improved!!!
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1747351003501918		[learning rate: 0.0090879]
	Learning Rate: 0.00908786
	LOSS [training: 0.1747351003501918 | validation: 0.40173681269287426]
	TIME [epoch: 9.54 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2614570385230405		[learning rate: 0.009045]
	Learning Rate: 0.00904503
	LOSS [training: 0.2614570385230405 | validation: 0.7559958036125817]
	TIME [epoch: 9.49 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2531157623571067		[learning rate: 0.0090024]
	Learning Rate: 0.00900241
	LOSS [training: 0.2531157623571067 | validation: 0.3919257104473522]
	TIME [epoch: 9.48 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25269538806569847		[learning rate: 0.00896]
	Learning Rate: 0.00895999
	LOSS [training: 0.25269538806569847 | validation: 0.5485627051335336]
	TIME [epoch: 9.47 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2126093495657751		[learning rate: 0.0089178]
	Learning Rate: 0.00891777
	LOSS [training: 0.2126093495657751 | validation: 0.43704614789353485]
	TIME [epoch: 9.49 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22654737795232224		[learning rate: 0.0088758]
	Learning Rate: 0.00887575
	LOSS [training: 0.22654737795232224 | validation: 0.41367213243631595]
	TIME [epoch: 9.49 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21199762245955586		[learning rate: 0.0088339]
	Learning Rate: 0.00883393
	LOSS [training: 0.21199762245955586 | validation: 0.4200088284302469]
	TIME [epoch: 9.48 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2688651547508658		[learning rate: 0.0087923]
	Learning Rate: 0.0087923
	LOSS [training: 0.2688651547508658 | validation: 0.3613555951721767]
	TIME [epoch: 9.5 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18392533727683125		[learning rate: 0.0087509]
	Learning Rate: 0.00875087
	LOSS [training: 0.18392533727683125 | validation: 0.43900327814503987]
	TIME [epoch: 9.49 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1939833242004284		[learning rate: 0.0087096]
	Learning Rate: 0.00870964
	LOSS [training: 0.1939833242004284 | validation: 0.49076624962723353]
	TIME [epoch: 9.48 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18474680721417622		[learning rate: 0.0086686]
	Learning Rate: 0.00866859
	LOSS [training: 0.18474680721417622 | validation: 0.5702905391901416]
	TIME [epoch: 9.49 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24684946451448492		[learning rate: 0.0086277]
	Learning Rate: 0.00862775
	LOSS [training: 0.24684946451448492 | validation: 0.36364061099163264]
	TIME [epoch: 9.48 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1921744588937271		[learning rate: 0.0085871]
	Learning Rate: 0.00858709
	LOSS [training: 0.1921744588937271 | validation: 0.37174146519882584]
	TIME [epoch: 9.48 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19367432702062598		[learning rate: 0.0085466]
	Learning Rate: 0.00854663
	LOSS [training: 0.19367432702062598 | validation: 0.3895478992438637]
	TIME [epoch: 9.48 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17027405147111277		[learning rate: 0.0085064]
	Learning Rate: 0.00850636
	LOSS [training: 0.17027405147111277 | validation: 0.39346733134197487]
	TIME [epoch: 9.49 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24480392065889192		[learning rate: 0.0084663]
	Learning Rate: 0.00846627
	LOSS [training: 0.24480392065889192 | validation: 0.42134847435942446]
	TIME [epoch: 9.49 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17790325201191678		[learning rate: 0.0084264]
	Learning Rate: 0.00842638
	LOSS [training: 0.17790325201191678 | validation: 0.3851982945766873]
	TIME [epoch: 9.48 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19456854004525692		[learning rate: 0.0083867]
	Learning Rate: 0.00838667
	LOSS [training: 0.19456854004525692 | validation: 0.534844533978428]
	TIME [epoch: 9.47 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22020834651547538		[learning rate: 0.0083472]
	Learning Rate: 0.00834715
	LOSS [training: 0.22020834651547538 | validation: 0.3559753529297137]
	TIME [epoch: 9.48 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13b_20240718_174651/states/model_facs_v4_dec2b_2dpca_v13b_76.pth
	Model improved!!!
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18281545578305902		[learning rate: 0.0083078]
	Learning Rate: 0.00830782
	LOSS [training: 0.18281545578305902 | validation: 0.40409318072199935]
	TIME [epoch: 9.5 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2034441389764841		[learning rate: 0.0082687]
	Learning Rate: 0.00826867
	LOSS [training: 0.2034441389764841 | validation: 0.36742858282799973]
	TIME [epoch: 9.49 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17523312592853268		[learning rate: 0.0082297]
	Learning Rate: 0.00822971
	LOSS [training: 0.17523312592853268 | validation: 0.523725574007015]
	TIME [epoch: 9.5 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24342963728761358		[learning rate: 0.0081909]
	Learning Rate: 0.00819093
	LOSS [training: 0.24342963728761358 | validation: 0.4187082359008013]
	TIME [epoch: 9.52 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17642596509643116		[learning rate: 0.0081523]
	Learning Rate: 0.00815233
	LOSS [training: 0.17642596509643116 | validation: 0.34162835125026614]
	TIME [epoch: 9.49 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13b_20240718_174651/states/model_facs_v4_dec2b_2dpca_v13b_81.pth
	Model improved!!!
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1996381035291083		[learning rate: 0.0081139]
	Learning Rate: 0.00811392
	LOSS [training: 0.1996381035291083 | validation: 0.41558053422238206]
	TIME [epoch: 9.51 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2130945128079953		[learning rate: 0.0080757]
	Learning Rate: 0.00807569
	LOSS [training: 0.2130945128079953 | validation: 0.39574966755647356]
	TIME [epoch: 9.5 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1820943338874705		[learning rate: 0.0080376]
	Learning Rate: 0.00803763
	LOSS [training: 0.1820943338874705 | validation: 0.3629548063473131]
	TIME [epoch: 9.49 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19435282549496458		[learning rate: 0.0079998]
	Learning Rate: 0.00799976
	LOSS [training: 0.19435282549496458 | validation: 0.3950498887410637]
	TIME [epoch: 9.48 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1866484827039534		[learning rate: 0.0079621]
	Learning Rate: 0.00796206
	LOSS [training: 0.1866484827039534 | validation: 0.4934197396788602]
	TIME [epoch: 9.49 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33664163015747084		[learning rate: 0.0079245]
	Learning Rate: 0.00792455
	LOSS [training: 0.33664163015747084 | validation: 0.3989518697015795]
	TIME [epoch: 9.5 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20721416743246143		[learning rate: 0.0078872]
	Learning Rate: 0.0078872
	LOSS [training: 0.20721416743246143 | validation: 0.3525424495439616]
	TIME [epoch: 9.49 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16850676700641676		[learning rate: 0.00785]
	Learning Rate: 0.00785004
	LOSS [training: 0.16850676700641676 | validation: 0.3045456853796517]
	TIME [epoch: 9.47 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13b_20240718_174651/states/model_facs_v4_dec2b_2dpca_v13b_89.pth
	Model improved!!!
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16532414997432368		[learning rate: 0.007813]
	Learning Rate: 0.00781305
	LOSS [training: 0.16532414997432368 | validation: 0.561825592012903]
	TIME [epoch: 9.5 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2315794448013721		[learning rate: 0.0077762]
	Learning Rate: 0.00777623
	LOSS [training: 0.2315794448013721 | validation: 0.49126456822668274]
	TIME [epoch: 9.5 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1720020273621882		[learning rate: 0.0077396]
	Learning Rate: 0.00773959
	LOSS [training: 0.1720020273621882 | validation: 0.3344154640773468]
	TIME [epoch: 9.5 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18206772333035867		[learning rate: 0.0077031]
	Learning Rate: 0.00770312
	LOSS [training: 0.18206772333035867 | validation: 0.4541994428053693]
	TIME [epoch: 9.49 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16657939324931945		[learning rate: 0.0076668]
	Learning Rate: 0.00766682
	LOSS [training: 0.16657939324931945 | validation: 0.35149092705525414]
	TIME [epoch: 9.48 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2284218634279476		[learning rate: 0.0076307]
	Learning Rate: 0.0076307
	LOSS [training: 0.2284218634279476 | validation: 0.3834931620317298]
	TIME [epoch: 9.48 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1697522462266095		[learning rate: 0.0075947]
	Learning Rate: 0.00759474
	LOSS [training: 0.1697522462266095 | validation: 0.38622707365490105]
	TIME [epoch: 9.49 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20085664237888512		[learning rate: 0.007559]
	Learning Rate: 0.00755895
	LOSS [training: 0.20085664237888512 | validation: 0.3481805819613481]
	TIME [epoch: 9.5 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17967647040950419		[learning rate: 0.0075233]
	Learning Rate: 0.00752333
	LOSS [training: 0.17967647040950419 | validation: 0.4029435641778979]
	TIME [epoch: 9.48 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18717615348579003		[learning rate: 0.0074879]
	Learning Rate: 0.00748788
	LOSS [training: 0.18717615348579003 | validation: 0.31361179907535264]
	TIME [epoch: 9.48 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1805327998494929		[learning rate: 0.0074526]
	Learning Rate: 0.0074526
	LOSS [training: 0.1805327998494929 | validation: 0.4798785747402882]
	TIME [epoch: 9.47 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16464962702062327		[learning rate: 0.0074175]
	Learning Rate: 0.00741748
	LOSS [training: 0.16464962702062327 | validation: 0.3408608019542816]
	TIME [epoch: 42.3 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15681358799985617		[learning rate: 0.0073825]
	Learning Rate: 0.00738253
	LOSS [training: 0.15681358799985617 | validation: 0.3417846664206504]
	TIME [epoch: 20.4 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1780479695835644		[learning rate: 0.0073477]
	Learning Rate: 0.00734774
	LOSS [training: 0.1780479695835644 | validation: 0.4658745918270607]
	TIME [epoch: 20.4 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1582947921228201		[learning rate: 0.0073131]
	Learning Rate: 0.00731312
	LOSS [training: 0.1582947921228201 | validation: 0.5642936266212465]
	TIME [epoch: 20.4 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.238411087590401		[learning rate: 0.0072787]
	Learning Rate: 0.00727866
	LOSS [training: 0.238411087590401 | validation: 0.43402188622589544]
	TIME [epoch: 20.4 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19919872897706234		[learning rate: 0.0072444]
	Learning Rate: 0.00724436
	LOSS [training: 0.19919872897706234 | validation: 0.35215171246506083]
	TIME [epoch: 20.4 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15972226660256592		[learning rate: 0.0072102]
	Learning Rate: 0.00721022
	LOSS [training: 0.15972226660256592 | validation: 0.3417225114009793]
	TIME [epoch: 20.4 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17578216528613952		[learning rate: 0.0071762]
	Learning Rate: 0.00717625
	LOSS [training: 0.17578216528613952 | validation: 0.3796464593527639]
	TIME [epoch: 20.4 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.160844346744927		[learning rate: 0.0071424]
	Learning Rate: 0.00714243
	LOSS [training: 0.160844346744927 | validation: 0.39762687335305946]
	TIME [epoch: 20.4 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16875168320850586		[learning rate: 0.0071088]
	Learning Rate: 0.00710878
	LOSS [training: 0.16875168320850586 | validation: 0.3173592736630616]
	TIME [epoch: 20.4 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1566405441789491		[learning rate: 0.0070753]
	Learning Rate: 0.00707528
	LOSS [training: 0.1566405441789491 | validation: 0.3561292510580296]
	TIME [epoch: 20.4 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1951263649894282		[learning rate: 0.0070419]
	Learning Rate: 0.00704194
	LOSS [training: 0.1951263649894282 | validation: 0.4723072940318621]
	TIME [epoch: 20.4 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1558068969064922		[learning rate: 0.0070088]
	Learning Rate: 0.00700876
	LOSS [training: 0.1558068969064922 | validation: 0.3160213954346234]
	TIME [epoch: 20.4 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.201636765541138		[learning rate: 0.0069757]
	Learning Rate: 0.00697573
	LOSS [training: 0.201636765541138 | validation: 0.43913272679938997]
	TIME [epoch: 20.4 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15387844467189174		[learning rate: 0.0069429]
	Learning Rate: 0.00694286
	LOSS [training: 0.15387844467189174 | validation: 0.3342231527738448]
	TIME [epoch: 20.4 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1809161747436613		[learning rate: 0.0069101]
	Learning Rate: 0.00691014
	LOSS [training: 0.1809161747436613 | validation: 0.3366777325156549]
	TIME [epoch: 20.4 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1891481864717019		[learning rate: 0.0068776]
	Learning Rate: 0.00687758
	LOSS [training: 0.1891481864717019 | validation: 0.34645598420834356]
	TIME [epoch: 20.4 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17528046322813828		[learning rate: 0.0068452]
	Learning Rate: 0.00684518
	LOSS [training: 0.17528046322813828 | validation: 0.3444632627767563]
	TIME [epoch: 20.4 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15583800461361502		[learning rate: 0.0068129]
	Learning Rate: 0.00681292
	LOSS [training: 0.15583800461361502 | validation: 0.3619749639538056]
	TIME [epoch: 20.4 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15980301207632203		[learning rate: 0.0067808]
	Learning Rate: 0.00678082
	LOSS [training: 0.15980301207632203 | validation: 0.3958444329008601]
	TIME [epoch: 20.4 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1908611726441273		[learning rate: 0.0067489]
	Learning Rate: 0.00674887
	LOSS [training: 0.1908611726441273 | validation: 0.3866888534800657]
	TIME [epoch: 20.4 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1900564343512933		[learning rate: 0.0067171]
	Learning Rate: 0.00671706
	LOSS [training: 0.1900564343512933 | validation: 0.3290137857074042]
	TIME [epoch: 20.4 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1411193533568488		[learning rate: 0.0066854]
	Learning Rate: 0.00668541
	LOSS [training: 0.1411193533568488 | validation: 0.3634268741572979]
	TIME [epoch: 20.4 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13640825462221284		[learning rate: 0.0066539]
	Learning Rate: 0.00665391
	LOSS [training: 0.13640825462221284 | validation: 0.5258818750297984]
	TIME [epoch: 20.4 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17670253466584213		[learning rate: 0.0066226]
	Learning Rate: 0.00662256
	LOSS [training: 0.17670253466584213 | validation: 0.3485638264446547]
	TIME [epoch: 20.4 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16234889599507699		[learning rate: 0.0065913]
	Learning Rate: 0.00659135
	LOSS [training: 0.16234889599507699 | validation: 0.36002745327547225]
	TIME [epoch: 20.4 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16415746285889987		[learning rate: 0.0065603]
	Learning Rate: 0.00656029
	LOSS [training: 0.16415746285889987 | validation: 0.34182020904388666]
	TIME [epoch: 20.4 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18514056673977183		[learning rate: 0.0065294]
	Learning Rate: 0.00652938
	LOSS [training: 0.18514056673977183 | validation: 0.35475908308731124]
	TIME [epoch: 20.4 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15580560429329804		[learning rate: 0.0064986]
	Learning Rate: 0.00649861
	LOSS [training: 0.15580560429329804 | validation: 0.37738238553560066]
	TIME [epoch: 20.5 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1592438907505721		[learning rate: 0.006468]
	Learning Rate: 0.00646799
	LOSS [training: 0.1592438907505721 | validation: 0.32016029534456847]
	TIME [epoch: 20.4 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18523642292280645		[learning rate: 0.0064375]
	Learning Rate: 0.00643751
	LOSS [training: 0.18523642292280645 | validation: 0.366012068607713]
	TIME [epoch: 20.4 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16799694426254774		[learning rate: 0.0064072]
	Learning Rate: 0.00640718
	LOSS [training: 0.16799694426254774 | validation: 0.40141014141914977]
	TIME [epoch: 20.4 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16569730178622216		[learning rate: 0.006377]
	Learning Rate: 0.00637698
	LOSS [training: 0.16569730178622216 | validation: 0.3428534765298217]
	TIME [epoch: 20.4 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17087525650050644		[learning rate: 0.0063469]
	Learning Rate: 0.00634694
	LOSS [training: 0.17087525650050644 | validation: 0.3422910372088651]
	TIME [epoch: 20.4 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1728416863721326		[learning rate: 0.006317]
	Learning Rate: 0.00631703
	LOSS [training: 0.1728416863721326 | validation: 0.794345667393773]
	TIME [epoch: 20.4 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21014190749017492		[learning rate: 0.0062873]
	Learning Rate: 0.00628726
	LOSS [training: 0.21014190749017492 | validation: 0.326667153183395]
	TIME [epoch: 20.4 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1459549538604774		[learning rate: 0.0062576]
	Learning Rate: 0.00625764
	LOSS [training: 0.1459549538604774 | validation: 0.4172171564827391]
	TIME [epoch: 20.4 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14901765045735743		[learning rate: 0.0062281]
	Learning Rate: 0.00622815
	LOSS [training: 0.14901765045735743 | validation: 0.33949178210695363]
	TIME [epoch: 20.4 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14603316867785554		[learning rate: 0.0061988]
	Learning Rate: 0.0061988
	LOSS [training: 0.14603316867785554 | validation: 0.3077082640303935]
	TIME [epoch: 20.4 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16153750978822365		[learning rate: 0.0061696]
	Learning Rate: 0.00616959
	LOSS [training: 0.16153750978822365 | validation: 0.34745874196535675]
	TIME [epoch: 20.4 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18703965658568894		[learning rate: 0.0061405]
	Learning Rate: 0.00614052
	LOSS [training: 0.18703965658568894 | validation: 0.2797252297614554]
	TIME [epoch: 20.4 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13b_20240718_174651/states/model_facs_v4_dec2b_2dpca_v13b_141.pth
	Model improved!!!
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15436417565277166		[learning rate: 0.0061116]
	Learning Rate: 0.00611158
	LOSS [training: 0.15436417565277166 | validation: 0.30980190979313826]
	TIME [epoch: 20.4 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15242567308736688		[learning rate: 0.0060828]
	Learning Rate: 0.00608279
	LOSS [training: 0.15242567308736688 | validation: 0.3351798929729315]
	TIME [epoch: 20.4 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13836896741659638		[learning rate: 0.0060541]
	Learning Rate: 0.00605412
	LOSS [training: 0.13836896741659638 | validation: 0.35930804671869765]
	TIME [epoch: 20.4 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18053839957494167		[learning rate: 0.0060256]
	Learning Rate: 0.0060256
	LOSS [training: 0.18053839957494167 | validation: 0.4100692799980006]
	TIME [epoch: 20.4 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18379972360313276		[learning rate: 0.0059972]
	Learning Rate: 0.0059972
	LOSS [training: 0.18379972360313276 | validation: 0.5920536044030514]
	TIME [epoch: 20.4 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19466395892751742		[learning rate: 0.0059689]
	Learning Rate: 0.00596894
	LOSS [training: 0.19466395892751742 | validation: 0.3153288188644611]
	TIME [epoch: 20.4 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.159310509247435		[learning rate: 0.0059408]
	Learning Rate: 0.00594082
	LOSS [training: 0.159310509247435 | validation: 0.31865763715390394]
	TIME [epoch: 20.4 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13580481842013004		[learning rate: 0.0059128]
	Learning Rate: 0.00591282
	LOSS [training: 0.13580481842013004 | validation: 0.34261602501156496]
	TIME [epoch: 20.4 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15421204776521263		[learning rate: 0.005885]
	Learning Rate: 0.00588496
	LOSS [training: 0.15421204776521263 | validation: 0.28496924363689335]
	TIME [epoch: 20.4 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14870152751192853		[learning rate: 0.0058572]
	Learning Rate: 0.00585723
	LOSS [training: 0.14870152751192853 | validation: 0.43214916615151805]
	TIME [epoch: 20.4 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19325575886905608		[learning rate: 0.0058296]
	Learning Rate: 0.00582963
	LOSS [training: 0.19325575886905608 | validation: 0.32782621121629113]
	TIME [epoch: 20.4 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1593829987166104		[learning rate: 0.0058022]
	Learning Rate: 0.00580216
	LOSS [training: 0.1593829987166104 | validation: 0.3755869459335591]
	TIME [epoch: 20.4 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17748065054455686		[learning rate: 0.0057748]
	Learning Rate: 0.00577482
	LOSS [training: 0.17748065054455686 | validation: 0.35497138382013904]
	TIME [epoch: 20.4 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16270331295608126		[learning rate: 0.0057476]
	Learning Rate: 0.00574761
	LOSS [training: 0.16270331295608126 | validation: 0.3058728990797483]
	TIME [epoch: 20.4 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17261389338812322		[learning rate: 0.0057205]
	Learning Rate: 0.00572052
	LOSS [training: 0.17261389338812322 | validation: 0.3342843023931639]
	TIME [epoch: 20.4 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14702007146291926		[learning rate: 0.0056936]
	Learning Rate: 0.00569357
	LOSS [training: 0.14702007146291926 | validation: 0.30345012484358025]
	TIME [epoch: 20.4 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14435300342942192		[learning rate: 0.0056667]
	Learning Rate: 0.00566674
	LOSS [training: 0.14435300342942192 | validation: 0.313192724217443]
	TIME [epoch: 20.4 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1283061675713938		[learning rate: 0.00564]
	Learning Rate: 0.00564004
	LOSS [training: 0.1283061675713938 | validation: 0.294669617630678]
	TIME [epoch: 20.4 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.142336447526822		[learning rate: 0.0056135]
	Learning Rate: 0.00561346
	LOSS [training: 0.142336447526822 | validation: 0.3872833815146892]
	TIME [epoch: 20.4 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13477526815623875		[learning rate: 0.005587]
	Learning Rate: 0.00558701
	LOSS [training: 0.13477526815623875 | validation: 0.3410351510106051]
	TIME [epoch: 20.4 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13971322742935102		[learning rate: 0.0055607]
	Learning Rate: 0.00556068
	LOSS [training: 0.13971322742935102 | validation: 0.32702994979160943]
	TIME [epoch: 20.4 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15938907252663445		[learning rate: 0.0055345]
	Learning Rate: 0.00553448
	LOSS [training: 0.15938907252663445 | validation: 0.5004165189349792]
	TIME [epoch: 20.4 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16300176657465654		[learning rate: 0.0055084]
	Learning Rate: 0.0055084
	LOSS [training: 0.16300176657465654 | validation: 0.36196374674445136]
	TIME [epoch: 20.4 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13560552515555985		[learning rate: 0.0054824]
	Learning Rate: 0.00548245
	LOSS [training: 0.13560552515555985 | validation: 0.40937661463785824]
	TIME [epoch: 20.4 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19590933863335278		[learning rate: 0.0054566]
	Learning Rate: 0.00545661
	LOSS [training: 0.19590933863335278 | validation: 0.32880182763605853]
	TIME [epoch: 20.4 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.172109013532009		[learning rate: 0.0054309]
	Learning Rate: 0.0054309
	LOSS [training: 0.172109013532009 | validation: 0.3216770702518116]
	TIME [epoch: 20.4 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16389064629876846		[learning rate: 0.0054053]
	Learning Rate: 0.00540531
	LOSS [training: 0.16389064629876846 | validation: 0.32460311358790817]
	TIME [epoch: 20.4 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12846685075741918		[learning rate: 0.0053798]
	Learning Rate: 0.00537984
	LOSS [training: 0.12846685075741918 | validation: 0.35489971766725587]
	TIME [epoch: 20.4 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16166251008185095		[learning rate: 0.0053545]
	Learning Rate: 0.00535449
	LOSS [training: 0.16166251008185095 | validation: 0.28344768218265115]
	TIME [epoch: 20.4 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12882611506530156		[learning rate: 0.0053293]
	Learning Rate: 0.00532926
	LOSS [training: 0.12882611506530156 | validation: 0.34700732668810935]
	TIME [epoch: 20.4 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1448772973225452		[learning rate: 0.0053041]
	Learning Rate: 0.00530415
	LOSS [training: 0.1448772973225452 | validation: 0.3954749679331869]
	TIME [epoch: 20.4 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14232474992784128		[learning rate: 0.0052792]
	Learning Rate: 0.00527915
	LOSS [training: 0.14232474992784128 | validation: 0.33015785187530405]
	TIME [epoch: 20.4 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14670070685277523		[learning rate: 0.0052543]
	Learning Rate: 0.00525428
	LOSS [training: 0.14670070685277523 | validation: 0.3298119289622021]
	TIME [epoch: 20.4 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1493716594685111		[learning rate: 0.0052295]
	Learning Rate: 0.00522952
	LOSS [training: 0.1493716594685111 | validation: 0.3095149727116095]
	TIME [epoch: 20.4 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16469561289308832		[learning rate: 0.0052049]
	Learning Rate: 0.00520487
	LOSS [training: 0.16469561289308832 | validation: 0.34378083836528217]
	TIME [epoch: 20.4 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14945351343789468		[learning rate: 0.0051803]
	Learning Rate: 0.00518035
	LOSS [training: 0.14945351343789468 | validation: 0.3304860623458448]
	TIME [epoch: 20.4 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14252477857705093		[learning rate: 0.0051559]
	Learning Rate: 0.00515594
	LOSS [training: 0.14252477857705093 | validation: 0.4079786653132524]
	TIME [epoch: 20.4 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15544187814582405		[learning rate: 0.0051316]
	Learning Rate: 0.00513164
	LOSS [training: 0.15544187814582405 | validation: 0.29419051956678316]
	TIME [epoch: 20.4 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14228012424278014		[learning rate: 0.0051075]
	Learning Rate: 0.00510746
	LOSS [training: 0.14228012424278014 | validation: 0.3282916987637229]
	TIME [epoch: 20.4 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14351483672061124		[learning rate: 0.0050834]
	Learning Rate: 0.00508339
	LOSS [training: 0.14351483672061124 | validation: 0.3283445762353021]
	TIME [epoch: 20.4 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13999172854655595		[learning rate: 0.0050594]
	Learning Rate: 0.00505944
	LOSS [training: 0.13999172854655595 | validation: 0.30727729481041427]
	TIME [epoch: 20.4 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13568022861248177		[learning rate: 0.0050356]
	Learning Rate: 0.0050356
	LOSS [training: 0.13568022861248177 | validation: 0.37659683456437526]
	TIME [epoch: 20.5 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1654316294589075		[learning rate: 0.0050119]
	Learning Rate: 0.00501187
	LOSS [training: 0.1654316294589075 | validation: 0.3746296820212341]
	TIME [epoch: 20.3 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15979144562056505		[learning rate: 0.0049883]
	Learning Rate: 0.00498826
	LOSS [training: 0.15979144562056505 | validation: 0.5496255796918301]
	TIME [epoch: 20.4 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15889393744252467		[learning rate: 0.0049648]
	Learning Rate: 0.00496475
	LOSS [training: 0.15889393744252467 | validation: 0.3156080722944308]
	TIME [epoch: 20.4 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16037875825013126		[learning rate: 0.0049414]
	Learning Rate: 0.00494136
	LOSS [training: 0.16037875825013126 | validation: 0.4661987654762998]
	TIME [epoch: 20.3 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17197650868107617		[learning rate: 0.0049181]
	Learning Rate: 0.00491807
	LOSS [training: 0.17197650868107617 | validation: 0.3339135906218397]
	TIME [epoch: 20.5 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13903929178496804		[learning rate: 0.0048949]
	Learning Rate: 0.0048949
	LOSS [training: 0.13903929178496804 | validation: 0.30389479783015444]
	TIME [epoch: 20.4 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12473793611642651		[learning rate: 0.0048718]
	Learning Rate: 0.00487183
	LOSS [training: 0.12473793611642651 | validation: 0.3602562445839755]
	TIME [epoch: 20.4 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1369512805733688		[learning rate: 0.0048489]
	Learning Rate: 0.00484888
	LOSS [training: 0.1369512805733688 | validation: 0.33711839074028055]
	TIME [epoch: 20.3 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17120519916487215		[learning rate: 0.004826]
	Learning Rate: 0.00482603
	LOSS [training: 0.17120519916487215 | validation: 0.3218064701939461]
	TIME [epoch: 20.4 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1656139693690512		[learning rate: 0.0048033]
	Learning Rate: 0.00480329
	LOSS [training: 0.1656139693690512 | validation: 0.33170934065375074]
	TIME [epoch: 20.5 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1393732527641017		[learning rate: 0.0047807]
	Learning Rate: 0.00478065
	LOSS [training: 0.1393732527641017 | validation: 0.32665024918247343]
	TIME [epoch: 20.4 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13999532981786175		[learning rate: 0.0047581]
	Learning Rate: 0.00475813
	LOSS [training: 0.13999532981786175 | validation: 0.3028571364133402]
	TIME [epoch: 20.3 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1434736357940193		[learning rate: 0.0047357]
	Learning Rate: 0.0047357
	LOSS [training: 0.1434736357940193 | validation: 0.291563875426427]
	TIME [epoch: 20.4 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1441811036278869		[learning rate: 0.0047134]
	Learning Rate: 0.00471339
	LOSS [training: 0.1441811036278869 | validation: 0.35513638243596335]
	TIME [epoch: 20.4 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14850523876544908		[learning rate: 0.0046912]
	Learning Rate: 0.00469118
	LOSS [training: 0.14850523876544908 | validation: 0.3136865203390573]
	TIME [epoch: 20.4 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13986433242941565		[learning rate: 0.0046691]
	Learning Rate: 0.00466907
	LOSS [training: 0.13986433242941565 | validation: 0.31414255741902264]
	TIME [epoch: 20.4 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12214474820826329		[learning rate: 0.0046471]
	Learning Rate: 0.00464707
	LOSS [training: 0.12214474820826329 | validation: 0.3228163355004156]
	TIME [epoch: 20.4 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1493226000551086		[learning rate: 0.0046252]
	Learning Rate: 0.00462518
	LOSS [training: 0.1493226000551086 | validation: 0.3180163453225478]
	TIME [epoch: 65.6 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14162557836189438		[learning rate: 0.0046034]
	Learning Rate: 0.00460338
	LOSS [training: 0.14162557836189438 | validation: 0.3092832235565135]
	TIME [epoch: 43.6 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14002012669518643		[learning rate: 0.0045817]
	Learning Rate: 0.00458169
	LOSS [training: 0.14002012669518643 | validation: 0.32753580396704335]
	TIME [epoch: 43.5 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14859278585811256		[learning rate: 0.0045601]
	Learning Rate: 0.0045601
	LOSS [training: 0.14859278585811256 | validation: 0.31884531029357044]
	TIME [epoch: 43.5 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14573429561380913		[learning rate: 0.0045386]
	Learning Rate: 0.00453861
	LOSS [training: 0.14573429561380913 | validation: 0.3099036242946105]
	TIME [epoch: 43.5 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13372369492480682		[learning rate: 0.0045172]
	Learning Rate: 0.00451723
	LOSS [training: 0.13372369492480682 | validation: 0.31426291526855615]
	TIME [epoch: 43.5 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1400771514959184		[learning rate: 0.0044959]
	Learning Rate: 0.00449594
	LOSS [training: 0.1400771514959184 | validation: 0.304725859037168]
	TIME [epoch: 43.6 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13693438744578154		[learning rate: 0.0044748]
	Learning Rate: 0.00447475
	LOSS [training: 0.13693438744578154 | validation: 0.3068116526630003]
	TIME [epoch: 43.5 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14229547262441183		[learning rate: 0.0044537]
	Learning Rate: 0.00445367
	LOSS [training: 0.14229547262441183 | validation: 0.30093515845048135]
	TIME [epoch: 43.5 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15344484754295293		[learning rate: 0.0044327]
	Learning Rate: 0.00443268
	LOSS [training: 0.15344484754295293 | validation: 0.29948532435468234]
	TIME [epoch: 43.5 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1332657255191729		[learning rate: 0.0044118]
	Learning Rate: 0.0044118
	LOSS [training: 0.1332657255191729 | validation: 0.3461337013250203]
	TIME [epoch: 43.5 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15668659987298397		[learning rate: 0.004391]
	Learning Rate: 0.00439101
	LOSS [training: 0.15668659987298397 | validation: 0.29241565827912097]
	TIME [epoch: 43.5 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13030630168434476		[learning rate: 0.0043703]
	Learning Rate: 0.00437032
	LOSS [training: 0.13030630168434476 | validation: 0.34183836303378873]
	TIME [epoch: 43.5 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12187770277102723		[learning rate: 0.0043497]
	Learning Rate: 0.00434972
	LOSS [training: 0.12187770277102723 | validation: 0.344580391647002]
	TIME [epoch: 43.5 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1485458335076686		[learning rate: 0.0043292]
	Learning Rate: 0.00432923
	LOSS [training: 0.1485458335076686 | validation: 0.35226158394777674]
	TIME [epoch: 43.5 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14850004250475837		[learning rate: 0.0043088]
	Learning Rate: 0.00430883
	LOSS [training: 0.14850004250475837 | validation: 0.3330694407777406]
	TIME [epoch: 43.5 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13205693096229265		[learning rate: 0.0042885]
	Learning Rate: 0.00428852
	LOSS [training: 0.13205693096229265 | validation: 0.3163267653714359]
	TIME [epoch: 43.5 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14984071538211394		[learning rate: 0.0042683]
	Learning Rate: 0.00426831
	LOSS [training: 0.14984071538211394 | validation: 0.316344202587951]
	TIME [epoch: 43.5 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16507544955305775		[learning rate: 0.0042482]
	Learning Rate: 0.0042482
	LOSS [training: 0.16507544955305775 | validation: 0.392824083721664]
	TIME [epoch: 43.5 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13190435552191782		[learning rate: 0.0042282]
	Learning Rate: 0.00422818
	LOSS [training: 0.13190435552191782 | validation: 0.32034825900873526]
	TIME [epoch: 43.5 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13108470532355054		[learning rate: 0.0042083]
	Learning Rate: 0.00420826
	LOSS [training: 0.13108470532355054 | validation: 0.30034093988516053]
	TIME [epoch: 43.5 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1350274280430564		[learning rate: 0.0041884]
	Learning Rate: 0.00418843
	LOSS [training: 0.1350274280430564 | validation: 0.3323245053730935]
	TIME [epoch: 43.5 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16564262367780025		[learning rate: 0.0041687]
	Learning Rate: 0.00416869
	LOSS [training: 0.16564262367780025 | validation: 0.3123114080053673]
	TIME [epoch: 43.5 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13803802931392553		[learning rate: 0.0041491]
	Learning Rate: 0.00414905
	LOSS [training: 0.13803802931392553 | validation: 0.3016190244023493]
	TIME [epoch: 43.5 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13183136939276627		[learning rate: 0.0041295]
	Learning Rate: 0.0041295
	LOSS [training: 0.13183136939276627 | validation: 0.3492312428779082]
	TIME [epoch: 43.5 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1348456293669245		[learning rate: 0.00411]
	Learning Rate: 0.00411004
	LOSS [training: 0.1348456293669245 | validation: 0.31992913527724814]
	TIME [epoch: 43.5 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13379509793815925		[learning rate: 0.0040907]
	Learning Rate: 0.00409067
	LOSS [training: 0.13379509793815925 | validation: 0.3081283312298803]
	TIME [epoch: 43.5 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13354364822308568		[learning rate: 0.0040714]
	Learning Rate: 0.0040714
	LOSS [training: 0.13354364822308568 | validation: 0.28515578350526466]
	TIME [epoch: 43.5 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13810930971282742		[learning rate: 0.0040522]
	Learning Rate: 0.00405221
	LOSS [training: 0.13810930971282742 | validation: 0.3700824294177442]
	TIME [epoch: 43.5 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12478326054850197		[learning rate: 0.0040331]
	Learning Rate: 0.00403312
	LOSS [training: 0.12478326054850197 | validation: 0.3168476971307762]
	TIME [epoch: 43.5 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13262021671500085		[learning rate: 0.0040141]
	Learning Rate: 0.00401411
	LOSS [training: 0.13262021671500085 | validation: 0.32168603732443446]
	TIME [epoch: 43.5 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12267334793484516		[learning rate: 0.0039952]
	Learning Rate: 0.0039952
	LOSS [training: 0.12267334793484516 | validation: 0.31269114893913674]
	TIME [epoch: 43.5 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1364658716061055		[learning rate: 0.0039764]
	Learning Rate: 0.00397637
	LOSS [training: 0.1364658716061055 | validation: 0.28314329188002463]
	TIME [epoch: 43.5 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12632559242178681		[learning rate: 0.0039576]
	Learning Rate: 0.00395764
	LOSS [training: 0.12632559242178681 | validation: 0.3145800666894887]
	TIME [epoch: 43.5 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13849039408003974		[learning rate: 0.003939]
	Learning Rate: 0.00393899
	LOSS [training: 0.13849039408003974 | validation: 0.3530362460549451]
	TIME [epoch: 43.5 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11685682602418344		[learning rate: 0.0039204]
	Learning Rate: 0.00392043
	LOSS [training: 0.11685682602418344 | validation: 0.3072622576531684]
	TIME [epoch: 43.5 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16780876956875923		[learning rate: 0.003902]
	Learning Rate: 0.00390195
	LOSS [training: 0.16780876956875923 | validation: 0.32373902802982374]
	TIME [epoch: 43.6 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12919762501914694		[learning rate: 0.0038836]
	Learning Rate: 0.00388357
	LOSS [training: 0.12919762501914694 | validation: 0.31476636064159713]
	TIME [epoch: 43.6 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12345716655443778		[learning rate: 0.0038653]
	Learning Rate: 0.00386527
	LOSS [training: 0.12345716655443778 | validation: 0.334154366501968]
	TIME [epoch: 43.5 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12153553655255939		[learning rate: 0.0038471]
	Learning Rate: 0.00384705
	LOSS [training: 0.12153553655255939 | validation: 0.3173988991490625]
	TIME [epoch: 43.5 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13550999818674658		[learning rate: 0.0038289]
	Learning Rate: 0.00382893
	LOSS [training: 0.13550999818674658 | validation: 0.4663833731283121]
	TIME [epoch: 43.5 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14468000140388432		[learning rate: 0.0038109]
	Learning Rate: 0.00381088
	LOSS [training: 0.14468000140388432 | validation: 0.3409009480195762]
	TIME [epoch: 43.5 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13413501556856183		[learning rate: 0.0037929]
	Learning Rate: 0.00379293
	LOSS [training: 0.13413501556856183 | validation: 0.30194970338225907]
	TIME [epoch: 43.5 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14348975306933565		[learning rate: 0.0037751]
	Learning Rate: 0.00377505
	LOSS [training: 0.14348975306933565 | validation: 0.43758784736693596]
	TIME [epoch: 43.5 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13876742925075897		[learning rate: 0.0037573]
	Learning Rate: 0.00375726
	LOSS [training: 0.13876742925075897 | validation: 0.2967687260897113]
	TIME [epoch: 43.5 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1302862044894739		[learning rate: 0.0037396]
	Learning Rate: 0.00373956
	LOSS [training: 0.1302862044894739 | validation: 0.32000253498323217]
	TIME [epoch: 43.5 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12718049202057968		[learning rate: 0.0037219]
	Learning Rate: 0.00372194
	LOSS [training: 0.12718049202057968 | validation: 0.3068982397232727]
	TIME [epoch: 43.5 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12781616300735713		[learning rate: 0.0037044]
	Learning Rate: 0.0037044
	LOSS [training: 0.12781616300735713 | validation: 0.3681169830810456]
	TIME [epoch: 43.5 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1290491257260314		[learning rate: 0.0036869]
	Learning Rate: 0.00368695
	LOSS [training: 0.1290491257260314 | validation: 0.3038034232344375]
	TIME [epoch: 43.5 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1320373144773867		[learning rate: 0.0036696]
	Learning Rate: 0.00366957
	LOSS [training: 0.1320373144773867 | validation: 0.4693892375999778]
	TIME [epoch: 43.5 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13493088401634407		[learning rate: 0.0036523]
	Learning Rate: 0.00365228
	LOSS [training: 0.13493088401634407 | validation: 0.3310620720721246]
	TIME [epoch: 43.5 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11908614449991595		[learning rate: 0.0036351]
	Learning Rate: 0.00363507
	LOSS [training: 0.11908614449991595 | validation: 0.3161335141239304]
	TIME [epoch: 43.5 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11463872549758253		[learning rate: 0.0036179]
	Learning Rate: 0.00361794
	LOSS [training: 0.11463872549758253 | validation: 0.3029008157917061]
	TIME [epoch: 43.5 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12777865793863968		[learning rate: 0.0036009]
	Learning Rate: 0.00360089
	LOSS [training: 0.12777865793863968 | validation: 0.31336503396124055]
	TIME [epoch: 43.5 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11698115283085438		[learning rate: 0.0035839]
	Learning Rate: 0.00358393
	LOSS [training: 0.11698115283085438 | validation: 0.3482072888156854]
	TIME [epoch: 43.5 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14605784427696983		[learning rate: 0.003567]
	Learning Rate: 0.00356704
	LOSS [training: 0.14605784427696983 | validation: 0.3260747307228452]
	TIME [epoch: 43.5 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15721937759407376		[learning rate: 0.0035502]
	Learning Rate: 0.00355023
	LOSS [training: 0.15721937759407376 | validation: 0.3186303058901624]
	TIME [epoch: 43.5 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12897485325120905		[learning rate: 0.0035335]
	Learning Rate: 0.0035335
	LOSS [training: 0.12897485325120905 | validation: 0.35298948674687347]
	TIME [epoch: 43.5 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12018576138763933		[learning rate: 0.0035168]
	Learning Rate: 0.00351685
	LOSS [training: 0.12018576138763933 | validation: 0.32736515098135344]
	TIME [epoch: 43.5 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13153399926661286		[learning rate: 0.0035003]
	Learning Rate: 0.00350028
	LOSS [training: 0.13153399926661286 | validation: 0.3430757388706388]
	TIME [epoch: 43.5 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13684597522604902		[learning rate: 0.0034838]
	Learning Rate: 0.00348378
	LOSS [training: 0.13684597522604902 | validation: 0.317052087244843]
	TIME [epoch: 43.5 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12232164712528451		[learning rate: 0.0034674]
	Learning Rate: 0.00346737
	LOSS [training: 0.12232164712528451 | validation: 0.3425990240474984]
	TIME [epoch: 43.5 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13916844612360293		[learning rate: 0.003451]
	Learning Rate: 0.00345103
	LOSS [training: 0.13916844612360293 | validation: 0.3108177586977111]
	TIME [epoch: 43.5 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13163178801140496		[learning rate: 0.0034348]
	Learning Rate: 0.00343477
	LOSS [training: 0.13163178801140496 | validation: 0.3040152985981727]
	TIME [epoch: 43.5 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13331294992900905		[learning rate: 0.0034186]
	Learning Rate: 0.00341858
	LOSS [training: 0.13331294992900905 | validation: 0.3412568840763286]
	TIME [epoch: 43.5 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13293465534308463		[learning rate: 0.0034025]
	Learning Rate: 0.00340247
	LOSS [training: 0.13293465534308463 | validation: 0.31684382900617597]
	TIME [epoch: 43.5 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13458071838115582		[learning rate: 0.0033864]
	Learning Rate: 0.00338644
	LOSS [training: 0.13458071838115582 | validation: 0.3794981015851673]
	TIME [epoch: 43.5 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13372847858184908		[learning rate: 0.0033705]
	Learning Rate: 0.00337048
	LOSS [training: 0.13372847858184908 | validation: 0.30972115164786496]
	TIME [epoch: 43.5 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13178946951112783		[learning rate: 0.0033546]
	Learning Rate: 0.0033546
	LOSS [training: 0.13178946951112783 | validation: 0.3145534607231548]
	TIME [epoch: 43.5 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11923634504647138		[learning rate: 0.0033388]
	Learning Rate: 0.00333879
	LOSS [training: 0.11923634504647138 | validation: 0.35450455320431107]
	TIME [epoch: 43.5 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12835244385450412		[learning rate: 0.0033231]
	Learning Rate: 0.00332306
	LOSS [training: 0.12835244385450412 | validation: 0.3246924643521143]
	TIME [epoch: 43.5 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12957908245015715		[learning rate: 0.0033074]
	Learning Rate: 0.0033074
	LOSS [training: 0.12957908245015715 | validation: 0.33082190034171544]
	TIME [epoch: 43.5 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13306702793436218		[learning rate: 0.0032918]
	Learning Rate: 0.00329182
	LOSS [training: 0.13306702793436218 | validation: 0.3007379280322009]
	TIME [epoch: 43.5 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13496256669554507		[learning rate: 0.0032763]
	Learning Rate: 0.00327631
	LOSS [training: 0.13496256669554507 | validation: 0.2891284836357806]
	TIME [epoch: 43.5 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14793922561892967		[learning rate: 0.0032609]
	Learning Rate: 0.00326087
	LOSS [training: 0.14793922561892967 | validation: 0.4140996616424751]
	TIME [epoch: 43.5 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16853635529319838		[learning rate: 0.0032455]
	Learning Rate: 0.0032455
	LOSS [training: 0.16853635529319838 | validation: 0.3605488329843853]
	TIME [epoch: 43.5 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14191003500219132		[learning rate: 0.0032302]
	Learning Rate: 0.00323021
	LOSS [training: 0.14191003500219132 | validation: 0.32817584289637]
	TIME [epoch: 43.5 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12937981106919305		[learning rate: 0.003215]
	Learning Rate: 0.00321499
	LOSS [training: 0.12937981106919305 | validation: 0.36729833828426395]
	TIME [epoch: 43.5 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14461741659237481		[learning rate: 0.0031998]
	Learning Rate: 0.00319984
	LOSS [training: 0.14461741659237481 | validation: 0.378685953861256]
	TIME [epoch: 43.5 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19811882829450983		[learning rate: 0.0031848]
	Learning Rate: 0.00318476
	LOSS [training: 0.19811882829450983 | validation: 0.38748264080372125]
	TIME [epoch: 43.5 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1670854774042324		[learning rate: 0.0031698]
	Learning Rate: 0.00316975
	LOSS [training: 0.1670854774042324 | validation: 0.34855231094409417]
	TIME [epoch: 43.4 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1596073088469196		[learning rate: 0.0031548]
	Learning Rate: 0.00315482
	LOSS [training: 0.1596073088469196 | validation: 0.3454962845162558]
	TIME [epoch: 43.5 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1338048882756666		[learning rate: 0.00314]
	Learning Rate: 0.00313995
	LOSS [training: 0.1338048882756666 | validation: 0.3412508635703582]
	TIME [epoch: 43.5 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12500165108456066		[learning rate: 0.0031252]
	Learning Rate: 0.00312516
	LOSS [training: 0.12500165108456066 | validation: 0.3342600797413067]
	TIME [epoch: 43.5 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12499739582647101		[learning rate: 0.0031104]
	Learning Rate: 0.00311043
	LOSS [training: 0.12499739582647101 | validation: 0.3375616788801298]
	TIME [epoch: 43.5 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1337785553215599		[learning rate: 0.0030958]
	Learning Rate: 0.00309577
	LOSS [training: 0.1337785553215599 | validation: 0.3299449928527391]
	TIME [epoch: 43.5 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13147220513449748		[learning rate: 0.0030812]
	Learning Rate: 0.00308119
	LOSS [training: 0.13147220513449748 | validation: 0.3155760928191538]
	TIME [epoch: 43.5 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13340760015298944		[learning rate: 0.0030667]
	Learning Rate: 0.00306667
	LOSS [training: 0.13340760015298944 | validation: 0.3376398755572374]
	TIME [epoch: 43.5 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1138170190879723		[learning rate: 0.0030522]
	Learning Rate: 0.00305222
	LOSS [training: 0.1138170190879723 | validation: 0.2996777740047556]
	TIME [epoch: 43.5 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12824565414755423		[learning rate: 0.0030378]
	Learning Rate: 0.00303783
	LOSS [training: 0.12824565414755423 | validation: 0.34985313032307164]
	TIME [epoch: 43.5 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13017886741228135		[learning rate: 0.0030235]
	Learning Rate: 0.00302352
	LOSS [training: 0.13017886741228135 | validation: 0.3398408035398652]
	TIME [epoch: 43.5 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13925286220863434		[learning rate: 0.0030093]
	Learning Rate: 0.00300927
	LOSS [training: 0.13925286220863434 | validation: 0.32044599285370223]
	TIME [epoch: 43.5 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1427072270779315		[learning rate: 0.0029951]
	Learning Rate: 0.00299509
	LOSS [training: 0.1427072270779315 | validation: 0.38579237884132694]
	TIME [epoch: 43.5 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13367789959057108		[learning rate: 0.002981]
	Learning Rate: 0.00298098
	LOSS [training: 0.13367789959057108 | validation: 0.3429286001941106]
	TIME [epoch: 43.5 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12707441223001098		[learning rate: 0.0029669]
	Learning Rate: 0.00296693
	LOSS [training: 0.12707441223001098 | validation: 0.30066153466459244]
	TIME [epoch: 43.5 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11628020913676745		[learning rate: 0.002953]
	Learning Rate: 0.00295295
	LOSS [training: 0.11628020913676745 | validation: 0.351799577376106]
	TIME [epoch: 43.5 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10951412119582021		[learning rate: 0.002939]
	Learning Rate: 0.00293904
	LOSS [training: 0.10951412119582021 | validation: 0.2893305153513107]
	TIME [epoch: 43.5 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12203191165172297		[learning rate: 0.0029252]
	Learning Rate: 0.00292519
	LOSS [training: 0.12203191165172297 | validation: 0.2956416122044626]
	TIME [epoch: 43.5 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12228640857269406		[learning rate: 0.0029114]
	Learning Rate: 0.0029114
	LOSS [training: 0.12228640857269406 | validation: 0.2877987727512876]
	TIME [epoch: 43.5 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11552950208295949		[learning rate: 0.0028977]
	Learning Rate: 0.00289769
	LOSS [training: 0.11552950208295949 | validation: 0.35060097761962283]
	TIME [epoch: 43.5 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11329938277587184		[learning rate: 0.002884]
	Learning Rate: 0.00288403
	LOSS [training: 0.11329938277587184 | validation: 0.32618210311970874]
	TIME [epoch: 112 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1482970126377415		[learning rate: 0.0028704]
	Learning Rate: 0.00287044
	LOSS [training: 0.1482970126377415 | validation: 0.341747495335059]
	TIME [epoch: 90 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15278192772256408		[learning rate: 0.0028569]
	Learning Rate: 0.00285692
	LOSS [training: 0.15278192772256408 | validation: 0.41756870813811353]
	TIME [epoch: 89.8 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14888196812023613		[learning rate: 0.0028435]
	Learning Rate: 0.00284345
	LOSS [training: 0.14888196812023613 | validation: 0.34283121964533847]
	TIME [epoch: 89.8 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12853593390574794		[learning rate: 0.0028301]
	Learning Rate: 0.00283005
	LOSS [training: 0.12853593390574794 | validation: 0.3131510639322175]
	TIME [epoch: 89.9 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12237638950776009		[learning rate: 0.0028167]
	Learning Rate: 0.00281672
	LOSS [training: 0.12237638950776009 | validation: 0.2942525583074735]
	TIME [epoch: 89.8 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12388231682361554		[learning rate: 0.0028034]
	Learning Rate: 0.00280345
	LOSS [training: 0.12388231682361554 | validation: 0.30059395889586266]
	TIME [epoch: 89.8 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11380655757920947		[learning rate: 0.0027902]
	Learning Rate: 0.00279024
	LOSS [training: 0.11380655757920947 | validation: 0.3592350716690221]
	TIME [epoch: 89.8 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13887193041036067		[learning rate: 0.0027771]
	Learning Rate: 0.00277709
	LOSS [training: 0.13887193041036067 | validation: 0.3008339389915411]
	TIME [epoch: 89.8 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14674062184103942		[learning rate: 0.002764]
	Learning Rate: 0.002764
	LOSS [training: 0.14674062184103942 | validation: 0.3105849291056765]
	TIME [epoch: 89.8 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1342563206096265		[learning rate: 0.002751]
	Learning Rate: 0.00275098
	LOSS [training: 0.1342563206096265 | validation: 0.360361464718945]
	TIME [epoch: 89.9 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11495097094947451		[learning rate: 0.002738]
	Learning Rate: 0.00273802
	LOSS [training: 0.11495097094947451 | validation: 0.30827506188491116]
	TIME [epoch: 90 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12139708717248404		[learning rate: 0.0027251]
	Learning Rate: 0.00272511
	LOSS [training: 0.12139708717248404 | validation: 0.2996008340569036]
	TIME [epoch: 90 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12959071379684078		[learning rate: 0.0027123]
	Learning Rate: 0.00271227
	LOSS [training: 0.12959071379684078 | validation: 0.3380365612727221]
	TIME [epoch: 89.9 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13233230198371643		[learning rate: 0.0026995]
	Learning Rate: 0.00269949
	LOSS [training: 0.13233230198371643 | validation: 0.2986119385745316]
	TIME [epoch: 90 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13653477494204985		[learning rate: 0.0026868]
	Learning Rate: 0.00268677
	LOSS [training: 0.13653477494204985 | validation: 0.38961048403279475]
	TIME [epoch: 89.8 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14634898568664556		[learning rate: 0.0026741]
	Learning Rate: 0.00267411
	LOSS [training: 0.14634898568664556 | validation: 0.33758041671965067]
	TIME [epoch: 90 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1352375642550439		[learning rate: 0.0026615]
	Learning Rate: 0.00266151
	LOSS [training: 0.1352375642550439 | validation: 0.34243066877604256]
	TIME [epoch: 89.8 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13099824192140763		[learning rate: 0.002649]
	Learning Rate: 0.00264897
	LOSS [training: 0.13099824192140763 | validation: 0.33289532183172055]
	TIME [epoch: 89.8 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11713163950212023		[learning rate: 0.0026365]
	Learning Rate: 0.00263649
	LOSS [training: 0.11713163950212023 | validation: 0.31627895818578017]
	TIME [epoch: 89.8 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12551499581675063		[learning rate: 0.0026241]
	Learning Rate: 0.00262406
	LOSS [training: 0.12551499581675063 | validation: 0.3486728354614069]
	TIME [epoch: 89.7 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11855567293069193		[learning rate: 0.0026117]
	Learning Rate: 0.0026117
	LOSS [training: 0.11855567293069193 | validation: 0.28538832335905534]
	TIME [epoch: 90 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12929699226851157		[learning rate: 0.0025994]
	Learning Rate: 0.00259939
	LOSS [training: 0.12929699226851157 | validation: 0.3030495322015269]
	TIME [epoch: 89.9 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11915285306904838		[learning rate: 0.0025871]
	Learning Rate: 0.00258714
	LOSS [training: 0.11915285306904838 | validation: 0.30691571477389945]
	TIME [epoch: 89.8 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12667177690801174		[learning rate: 0.002575]
	Learning Rate: 0.00257495
	LOSS [training: 0.12667177690801174 | validation: 0.31298992571844375]
	TIME [epoch: 89.8 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12614098591017733		[learning rate: 0.0025628]
	Learning Rate: 0.00256282
	LOSS [training: 0.12614098591017733 | validation: 0.34459073684118563]
	TIME [epoch: 89.8 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1168383912263195		[learning rate: 0.0025507]
	Learning Rate: 0.00255074
	LOSS [training: 0.1168383912263195 | validation: 0.31820583798018975]
	TIME [epoch: 89.8 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1196570515118015		[learning rate: 0.0025387]
	Learning Rate: 0.00253872
	LOSS [training: 0.1196570515118015 | validation: 0.36834618483308357]
	TIME [epoch: 89.8 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12525753042302273		[learning rate: 0.0025268]
	Learning Rate: 0.00252676
	LOSS [training: 0.12525753042302273 | validation: 0.3553989865850419]
	TIME [epoch: 89.8 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12637111459003836		[learning rate: 0.0025149]
	Learning Rate: 0.00251485
	LOSS [training: 0.12637111459003836 | validation: 0.3762603114575232]
	TIME [epoch: 89.9 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13455218476060338		[learning rate: 0.002503]
	Learning Rate: 0.002503
	LOSS [training: 0.13455218476060338 | validation: 0.349555581202082]
	TIME [epoch: 89.8 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12895632592153683		[learning rate: 0.0024912]
	Learning Rate: 0.00249121
	LOSS [training: 0.12895632592153683 | validation: 0.3055097661850438]
	TIME [epoch: 89.8 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1304505131510605		[learning rate: 0.0024795]
	Learning Rate: 0.00247947
	LOSS [training: 0.1304505131510605 | validation: 0.358712198618604]
	TIME [epoch: 89.9 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13205497724789794		[learning rate: 0.0024678]
	Learning Rate: 0.00246779
	LOSS [training: 0.13205497724789794 | validation: 0.3108413088851221]
	TIME [epoch: 89.8 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12480182928654024		[learning rate: 0.0024562]
	Learning Rate: 0.00245616
	LOSS [training: 0.12480182928654024 | validation: 0.31125641759739914]
	TIME [epoch: 89.8 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13475126595729095		[learning rate: 0.0024446]
	Learning Rate: 0.00244458
	LOSS [training: 0.13475126595729095 | validation: 0.40584394908845256]
	TIME [epoch: 89.8 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13932327492167101		[learning rate: 0.0024331]
	Learning Rate: 0.00243307
	LOSS [training: 0.13932327492167101 | validation: 0.3447653623234584]
	TIME [epoch: 89.8 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13217815115067016		[learning rate: 0.0024216]
	Learning Rate: 0.0024216
	LOSS [training: 0.13217815115067016 | validation: 0.3454932684877765]
	TIME [epoch: 90 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13281646791552373		[learning rate: 0.0024102]
	Learning Rate: 0.00241019
	LOSS [training: 0.13281646791552373 | validation: 0.30555623147991307]
	TIME [epoch: 89.8 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12262373987372978		[learning rate: 0.0023988]
	Learning Rate: 0.00239883
	LOSS [training: 0.12262373987372978 | validation: 0.30317150279711313]
	TIME [epoch: 89.8 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1264787450906422		[learning rate: 0.0023875]
	Learning Rate: 0.00238753
	LOSS [training: 0.1264787450906422 | validation: 0.30667439825202303]
	TIME [epoch: 89.8 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10884084805528998		[learning rate: 0.0023763]
	Learning Rate: 0.00237628
	LOSS [training: 0.10884084805528998 | validation: 0.35093131783336784]
	TIME [epoch: 89.8 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13b_20240718_174651/states/model_facs_v4_dec2b_2dpca_v13b_342.pth
Halted early. No improvement in validation loss for 200 epochs.
Finished training in 11020.654 seconds.
