Args:
Namespace(name='model_facs_dec1b_2dpca_v6', outdir='out/model_training/model_facs_dec1b_2dpca_v6', training_data='data/training_data/facs/pca/dec1_fitonsubset/transition1_subset_epi_tr_ce_an_pc12/training', validation_data='data/training_data/facs/pca/dec1_fitonsubset/transition1_subset_epi_tr_ce_an_pc12/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=10, batch_size=50, patience=200, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=100, ncells_sample=100, model_do_sample=False, dt=0.005, dt_schedule='stepped', dt_schedule_bounds=[500, 1000, 1500], dt_schedule_scales=[0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=True, sigma=0.02, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', kernel='multiscale', bw_range=[0.2, 0.5, 0.9, 1.1, 1.3, 1.5, 2.0], optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 7718889

Training model...

Saving initial model state to: out/model_training/model_facs_dec1b_2dpca_v6_20240710_202109/states/model_facs_dec1b_2dpca_v6_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.228444159986321		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.228444159986321 | validation: 1.120983053881529]
	TIME [epoch: 35.9 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v6_20240710_202109/states/model_facs_dec1b_2dpca_v6_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.1317234169980177		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1317234169980177 | validation: 1.1601055820382364]
	TIME [epoch: 6.73 sec]
EPOCH 3/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.0478585751106764		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0478585751106764 | validation: 0.9134588363306824]
	TIME [epoch: 6.72 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v6_20240710_202109/states/model_facs_dec1b_2dpca_v6_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.0173309615388806		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0173309615388806 | validation: 0.9048000148858373]
	TIME [epoch: 6.72 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v6_20240710_202109/states/model_facs_dec1b_2dpca_v6_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.9244281925306895		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9244281925306895 | validation: 0.8758123788766203]
	TIME [epoch: 6.71 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v6_20240710_202109/states/model_facs_dec1b_2dpca_v6_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.8426726202208564		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8426726202208564 | validation: 0.8320887488218766]
	TIME [epoch: 6.72 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v6_20240710_202109/states/model_facs_dec1b_2dpca_v6_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.8993032726926342		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8993032726926342 | validation: 0.7371334845208481]
	TIME [epoch: 6.73 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v6_20240710_202109/states/model_facs_dec1b_2dpca_v6_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7615571680225229		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7615571680225229 | validation: 0.8427645296594017]
	TIME [epoch: 6.82 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.8248956157966999		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8248956157966999 | validation: 0.6857089218061396]
	TIME [epoch: 6.72 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v6_20240710_202109/states/model_facs_dec1b_2dpca_v6_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7900590285219246		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7900590285219246 | validation: 0.6387799765838504]
	TIME [epoch: 6.72 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v6_20240710_202109/states/model_facs_dec1b_2dpca_v6_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7018375980425618		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7018375980425618 | validation: 0.6476452095965117]
	TIME [epoch: 6.72 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6632486135457478		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6632486135457478 | validation: 0.5920735913156583]
	TIME [epoch: 6.73 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v6_20240710_202109/states/model_facs_dec1b_2dpca_v6_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7153700656950388		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7153700656950388 | validation: 0.7249256580874683]
	TIME [epoch: 6.73 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6228960683891919		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6228960683891919 | validation: 0.5516898142182164]
	TIME [epoch: 6.72 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v6_20240710_202109/states/model_facs_dec1b_2dpca_v6_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5700726944008152		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5700726944008152 | validation: 0.5825578620876947]
	TIME [epoch: 6.72 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7151883649369576		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7151883649369576 | validation: 0.5750708050507795]
	TIME [epoch: 6.71 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6634472014773838		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6634472014773838 | validation: 0.6775475649414652]
	TIME [epoch: 6.71 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6157807659662625		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6157807659662625 | validation: 0.5336695726864902]
	TIME [epoch: 6.71 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v6_20240710_202109/states/model_facs_dec1b_2dpca_v6_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6502815205494178		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6502815205494178 | validation: 0.8553638695709637]
	TIME [epoch: 6.71 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5692580396476735		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5692580396476735 | validation: 0.5492236740468226]
	TIME [epoch: 6.73 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5980893708853218		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5980893708853218 | validation: 0.5678740995404725]
	TIME [epoch: 6.72 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6166968724360091		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6166968724360091 | validation: 0.6374704206395997]
	TIME [epoch: 6.71 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6502536752421322		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6502536752421322 | validation: 0.7173372040636867]
	TIME [epoch: 6.71 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6832207825769769		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6832207825769769 | validation: 0.6325222444502833]
	TIME [epoch: 6.72 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6514695570826743		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6514695570826743 | validation: 0.6310941048764306]
	TIME [epoch: 6.71 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5952960782799541		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5952960782799541 | validation: 0.6004883660799119]
	TIME [epoch: 6.71 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5621365155120427		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5621365155120427 | validation: 0.5407291558288814]
	TIME [epoch: 6.71 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5659799652309164		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5659799652309164 | validation: 0.5358582726603194]
	TIME [epoch: 6.73 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.594322823736463		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.594322823736463 | validation: 0.5532460504279717]
	TIME [epoch: 6.71 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5388976035323818		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5388976035323818 | validation: 0.5940841583833282]
	TIME [epoch: 6.7 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6766150836706276		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6766150836706276 | validation: 0.6697091275089335]
	TIME [epoch: 6.7 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5990931966838554		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5990931966838554 | validation: 0.5452266501402308]
	TIME [epoch: 6.71 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5219631179209845		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5219631179209845 | validation: 0.5618927118550427]
	TIME [epoch: 6.71 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.51623615974419		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.51623615974419 | validation: 0.5755806049504677]
	TIME [epoch: 6.71 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.561836867791		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.561836867791 | validation: 0.57184254937636]
	TIME [epoch: 6.72 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5393171691541166		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5393171691541166 | validation: 0.4961824627410971]
	TIME [epoch: 6.71 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v6_20240710_202109/states/model_facs_dec1b_2dpca_v6_36.pth
	Model improved!!!
EPOCH 37/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7160604285615533		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7160604285615533 | validation: 0.6250225091279483]
	TIME [epoch: 6.71 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.606903614481173		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.606903614481173 | validation: 0.7127865342855796]
	TIME [epoch: 6.71 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6070225329900336		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6070225329900336 | validation: 0.5311687812277023]
	TIME [epoch: 6.71 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5080401665158525		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5080401665158525 | validation: 0.6537700060968238]
	TIME [epoch: 6.71 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5437254419658885		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5437254419658885 | validation: 0.5003982115300769]
	TIME [epoch: 6.72 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5769024112558642		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5769024112558642 | validation: 0.518035209785309]
	TIME [epoch: 6.72 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5291127698536771		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5291127698536771 | validation: 0.4889114554377074]
	TIME [epoch: 6.72 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v6_20240710_202109/states/model_facs_dec1b_2dpca_v6_43.pth
	Model improved!!!
EPOCH 44/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.48787587874258204		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.48787587874258204 | validation: 0.46554711730919535]
	TIME [epoch: 6.72 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v6_20240710_202109/states/model_facs_dec1b_2dpca_v6_44.pth
	Model improved!!!
EPOCH 45/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5214034868254488		[learning rate: 0.0099823]
	Learning Rate: 0.0099823
	LOSS [training: 0.5214034868254488 | validation: 0.5558743804221664]
	TIME [epoch: 6.72 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5330851479619949		[learning rate: 0.0099426]
	Learning Rate: 0.0099426
	LOSS [training: 0.5330851479619949 | validation: 0.5689908085037979]
	TIME [epoch: 6.71 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5384809872996454		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 0.5384809872996454 | validation: 0.45427823039790577]
	TIME [epoch: 6.71 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v6_20240710_202109/states/model_facs_dec1b_2dpca_v6_47.pth
	Model improved!!!
EPOCH 48/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.506598903288569		[learning rate: 0.0098637]
	Learning Rate: 0.00986367
	LOSS [training: 0.506598903288569 | validation: 0.5328877807509842]
	TIME [epoch: 6.72 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5234077046740049		[learning rate: 0.0098244]
	Learning Rate: 0.00982444
	LOSS [training: 0.5234077046740049 | validation: 0.46288052229800797]
	TIME [epoch: 6.71 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.47338732729754096		[learning rate: 0.0097854]
	Learning Rate: 0.00978536
	LOSS [training: 0.47338732729754096 | validation: 0.43898504805916205]
	TIME [epoch: 6.71 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v6_20240710_202109/states/model_facs_dec1b_2dpca_v6_50.pth
	Model improved!!!
EPOCH 51/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.48839005242410166		[learning rate: 0.0097464]
	Learning Rate: 0.00974644
	LOSS [training: 0.48839005242410166 | validation: 0.4736061467429898]
	TIME [epoch: 6.72 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.49774893314249524		[learning rate: 0.0097077]
	Learning Rate: 0.00970768
	LOSS [training: 0.49774893314249524 | validation: 0.5362774239303534]
	TIME [epoch: 6.71 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4955279079241027		[learning rate: 0.0096691]
	Learning Rate: 0.00966907
	LOSS [training: 0.4955279079241027 | validation: 0.4895240294240172]
	TIME [epoch: 6.71 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.45961842639045586		[learning rate: 0.0096306]
	Learning Rate: 0.00963061
	LOSS [training: 0.45961842639045586 | validation: 0.4205381616521581]
	TIME [epoch: 6.73 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v6_20240710_202109/states/model_facs_dec1b_2dpca_v6_54.pth
	Model improved!!!
EPOCH 55/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5045337855129545		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 0.5045337855129545 | validation: 0.5941978051467226]
	TIME [epoch: 6.72 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5740631058001748		[learning rate: 0.0095542]
	Learning Rate: 0.00955415
	LOSS [training: 0.5740631058001748 | validation: 0.4337422601401001]
	TIME [epoch: 6.71 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4656476174295705		[learning rate: 0.0095162]
	Learning Rate: 0.00951616
	LOSS [training: 0.4656476174295705 | validation: 0.41958844206843465]
	TIME [epoch: 6.71 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v6_20240710_202109/states/model_facs_dec1b_2dpca_v6_57.pth
	Model improved!!!
EPOCH 58/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.45276572627455586		[learning rate: 0.0094783]
	Learning Rate: 0.00947831
	LOSS [training: 0.45276572627455586 | validation: 0.40298051659874207]
	TIME [epoch: 6.71 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v6_20240710_202109/states/model_facs_dec1b_2dpca_v6_58.pth
	Model improved!!!
EPOCH 59/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4792836327869079		[learning rate: 0.0094406]
	Learning Rate: 0.00944061
	LOSS [training: 0.4792836327869079 | validation: 0.4320751193686753]
	TIME [epoch: 6.71 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.48309733326650633		[learning rate: 0.0094031]
	Learning Rate: 0.00940306
	LOSS [training: 0.48309733326650633 | validation: 0.46687686574205634]
	TIME [epoch: 6.71 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4571516383321744		[learning rate: 0.0093657]
	Learning Rate: 0.00936566
	LOSS [training: 0.4571516383321744 | validation: 0.44244203233376644]
	TIME [epoch: 6.71 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.43432036995047335		[learning rate: 0.0093284]
	Learning Rate: 0.00932841
	LOSS [training: 0.43432036995047335 | validation: 0.42965167541170357]
	TIME [epoch: 6.71 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4416835365538108		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 0.4416835365538108 | validation: 0.472527229619332]
	TIME [epoch: 6.72 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4369675317242663		[learning rate: 0.0092544]
	Learning Rate: 0.00925435
	LOSS [training: 0.4369675317242663 | validation: 0.422766137916201]
	TIME [epoch: 6.71 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4336244132296705		[learning rate: 0.0092175]
	Learning Rate: 0.00921755
	LOSS [training: 0.4336244132296705 | validation: 0.4911284536240682]
	TIME [epoch: 6.71 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.46343908809950096		[learning rate: 0.0091809]
	Learning Rate: 0.00918089
	LOSS [training: 0.46343908809950096 | validation: 0.3855036163870131]
	TIME [epoch: 6.71 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v6_20240710_202109/states/model_facs_dec1b_2dpca_v6_66.pth
	Model improved!!!
EPOCH 67/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.40687542125561627		[learning rate: 0.0091444]
	Learning Rate: 0.00914437
	LOSS [training: 0.40687542125561627 | validation: 0.4225849399883795]
	TIME [epoch: 6.72 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4232364680393749		[learning rate: 0.009108]
	Learning Rate: 0.009108
	LOSS [training: 0.4232364680393749 | validation: 0.5008915105739071]
	TIME [epoch: 6.72 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4095142785444689		[learning rate: 0.0090718]
	Learning Rate: 0.00907178
	LOSS [training: 0.4095142785444689 | validation: 0.3866533670753202]
	TIME [epoch: 6.71 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.41679984476540816		[learning rate: 0.0090357]
	Learning Rate: 0.00903569
	LOSS [training: 0.41679984476540816 | validation: 0.4747523155618095]
	TIME [epoch: 6.71 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4430511453010739		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 0.4430511453010739 | validation: 0.43282435604148334]
	TIME [epoch: 6.71 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.40118992263726405		[learning rate: 0.008964]
	Learning Rate: 0.00896396
	LOSS [training: 0.40118992263726405 | validation: 0.5344866349666264]
	TIME [epoch: 6.71 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.45292261226612596		[learning rate: 0.0089283]
	Learning Rate: 0.00892831
	LOSS [training: 0.45292261226612596 | validation: 0.3952976388243861]
	TIME [epoch: 6.71 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3915791459652485		[learning rate: 0.0088928]
	Learning Rate: 0.0088928
	LOSS [training: 0.3915791459652485 | validation: 0.4326348791859219]
	TIME [epoch: 6.73 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.377838959573802		[learning rate: 0.0088574]
	Learning Rate: 0.00885743
	LOSS [training: 0.377838959573802 | validation: 0.3914802107990944]
	TIME [epoch: 6.72 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.42866328064271664		[learning rate: 0.0088222]
	Learning Rate: 0.0088222
	LOSS [training: 0.42866328064271664 | validation: 0.454952690330548]
	TIME [epoch: 6.72 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.38558868045961403		[learning rate: 0.0087871]
	Learning Rate: 0.00878711
	LOSS [training: 0.38558868045961403 | validation: 0.3518643669435351]
	TIME [epoch: 6.71 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v6_20240710_202109/states/model_facs_dec1b_2dpca_v6_77.pth
	Model improved!!!
EPOCH 78/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4245464871832651		[learning rate: 0.0087522]
	Learning Rate: 0.00875216
	LOSS [training: 0.4245464871832651 | validation: 0.39729584195955636]
	TIME [epoch: 6.71 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4214177918820148		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 0.4214177918820148 | validation: 0.4574639042045027]
	TIME [epoch: 6.72 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3885966777360131		[learning rate: 0.0086827]
	Learning Rate: 0.00868268
	LOSS [training: 0.3885966777360131 | validation: 0.4210026464588171]
	TIME [epoch: 6.71 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.38245849609699517		[learning rate: 0.0086481]
	Learning Rate: 0.00864815
	LOSS [training: 0.38245849609699517 | validation: 0.453728020692321]
	TIME [epoch: 6.73 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.40429921294283244		[learning rate: 0.0086138]
	Learning Rate: 0.00861375
	LOSS [training: 0.40429921294283244 | validation: 0.3946390100678115]
	TIME [epoch: 6.72 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.353960497501817		[learning rate: 0.0085795]
	Learning Rate: 0.00857949
	LOSS [training: 0.353960497501817 | validation: 0.400498553818332]
	TIME [epoch: 6.71 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3682071807491324		[learning rate: 0.0085454]
	Learning Rate: 0.00854537
	LOSS [training: 0.3682071807491324 | validation: 0.3933029196516695]
	TIME [epoch: 6.71 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.37863161680406177		[learning rate: 0.0085114]
	Learning Rate: 0.00851138
	LOSS [training: 0.37863161680406177 | validation: 0.44589849314881463]
	TIME [epoch: 6.71 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.43464824614161		[learning rate: 0.0084775]
	Learning Rate: 0.00847753
	LOSS [training: 0.43464824614161 | validation: 0.3875536812840295]
	TIME [epoch: 6.71 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3682024230427582		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 0.3682024230427582 | validation: 0.36448525437911916]
	TIME [epoch: 6.71 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3725391739664259		[learning rate: 0.0084102]
	Learning Rate: 0.00841023
	LOSS [training: 0.3725391739664259 | validation: 0.41972473118970777]
	TIME [epoch: 6.73 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3916177151084794		[learning rate: 0.0083768]
	Learning Rate: 0.00837678
	LOSS [training: 0.3916177151084794 | validation: 0.39943064904412395]
	TIME [epoch: 6.72 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.35331454017167563		[learning rate: 0.0083435]
	Learning Rate: 0.00834346
	LOSS [training: 0.35331454017167563 | validation: 0.47690264217354505]
	TIME [epoch: 6.71 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.39626391125287586		[learning rate: 0.0083103]
	Learning Rate: 0.00831027
	LOSS [training: 0.39626391125287586 | validation: 0.3607682769687543]
	TIME [epoch: 6.71 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3631281800907702		[learning rate: 0.0082772]
	Learning Rate: 0.00827722
	LOSS [training: 0.3631281800907702 | validation: 0.3611295758805684]
	TIME [epoch: 6.71 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.38735861030912644		[learning rate: 0.0082443]
	Learning Rate: 0.0082443
	LOSS [training: 0.38735861030912644 | validation: 0.6067089075784267]
	TIME [epoch: 6.75 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.58343229123376		[learning rate: 0.0082115]
	Learning Rate: 0.00821151
	LOSS [training: 0.58343229123376 | validation: 0.7585390099454494]
	TIME [epoch: 6.77 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6544279820330152		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 0.6544279820330152 | validation: 0.4506806570849511]
	TIME [epoch: 6.79 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.44955318296654706		[learning rate: 0.0081463]
	Learning Rate: 0.00814632
	LOSS [training: 0.44955318296654706 | validation: 0.4292350929035524]
	TIME [epoch: 6.79 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.42667454286923623		[learning rate: 0.0081139]
	Learning Rate: 0.00811392
	LOSS [training: 0.42667454286923623 | validation: 0.3964158074198719]
	TIME [epoch: 6.78 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.38391253419396226		[learning rate: 0.0080816]
	Learning Rate: 0.00808165
	LOSS [training: 0.38391253419396226 | validation: 0.39330871945839585]
	TIME [epoch: 6.82 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3797942167171286		[learning rate: 0.0080495]
	Learning Rate: 0.00804951
	LOSS [training: 0.3797942167171286 | validation: 0.3816088962063905]
	TIME [epoch: 6.72 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.446961601067613		[learning rate: 0.0080175]
	Learning Rate: 0.00801749
	LOSS [training: 0.446961601067613 | validation: 0.790759185006392]
	TIME [epoch: 6.73 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5746045122111201		[learning rate: 0.0079856]
	Learning Rate: 0.0079856
	LOSS [training: 0.5746045122111201 | validation: 0.3857390895409768]
	TIME [epoch: 6.8 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.38032498860233194		[learning rate: 0.0079538]
	Learning Rate: 0.00795384
	LOSS [training: 0.38032498860233194 | validation: 0.38399989515685345]
	TIME [epoch: 6.8 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3562487096097971		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 0.3562487096097971 | validation: 0.4317096956728667]
	TIME [epoch: 6.81 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.36742810533982734		[learning rate: 0.0078907]
	Learning Rate: 0.0078907
	LOSS [training: 0.36742810533982734 | validation: 0.3759934656546296]
	TIME [epoch: 6.81 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4006053698514096		[learning rate: 0.0078593]
	Learning Rate: 0.00785931
	LOSS [training: 0.4006053698514096 | validation: 0.438068256491505]
	TIME [epoch: 6.76 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.38172823164314357		[learning rate: 0.0078281]
	Learning Rate: 0.00782805
	LOSS [training: 0.38172823164314357 | validation: 0.5301330926809599]
	TIME [epoch: 6.72 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3997062282274894		[learning rate: 0.0077969]
	Learning Rate: 0.00779692
	LOSS [training: 0.3997062282274894 | validation: 0.3441246145518454]
	TIME [epoch: 6.72 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v6_20240710_202109/states/model_facs_dec1b_2dpca_v6_107.pth
	Model improved!!!
EPOCH 108/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3849066930508358		[learning rate: 0.0077659]
	Learning Rate: 0.00776591
	LOSS [training: 0.3849066930508358 | validation: 0.6847938059319354]
	TIME [epoch: 6.74 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6097614070896816		[learning rate: 0.007735]
	Learning Rate: 0.00773502
	LOSS [training: 0.6097614070896816 | validation: 0.49606739617781265]
	TIME [epoch: 6.73 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4030869238551534		[learning rate: 0.0077043]
	Learning Rate: 0.00770426
	LOSS [training: 0.4030869238551534 | validation: 0.3653286922891873]
	TIME [epoch: 6.72 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3669954590739966		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 0.3669954590739966 | validation: 0.378023751821453]
	TIME [epoch: 6.72 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.35520641259387714		[learning rate: 0.0076431]
	Learning Rate: 0.00764309
	LOSS [training: 0.35520641259387714 | validation: 0.38510316111896725]
	TIME [epoch: 6.72 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3532416550512895		[learning rate: 0.0076127]
	Learning Rate: 0.00761269
	LOSS [training: 0.3532416550512895 | validation: 0.38662603181191213]
	TIME [epoch: 6.72 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.35680124995185936		[learning rate: 0.0075824]
	Learning Rate: 0.00758242
	LOSS [training: 0.35680124995185936 | validation: 0.33876707956111207]
	TIME [epoch: 6.72 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v6_20240710_202109/states/model_facs_dec1b_2dpca_v6_114.pth
	Model improved!!!
EPOCH 115/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3506835985297265		[learning rate: 0.0075523]
	Learning Rate: 0.00755226
	LOSS [training: 0.3506835985297265 | validation: 0.3713095109479093]
	TIME [epoch: 6.73 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.37755538686452644		[learning rate: 0.0075222]
	Learning Rate: 0.00752222
	LOSS [training: 0.37755538686452644 | validation: 0.3448578893716404]
	TIME [epoch: 6.72 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3814634095275451		[learning rate: 0.0074923]
	Learning Rate: 0.0074923
	LOSS [training: 0.3814634095275451 | validation: 0.8845389035331012]
	TIME [epoch: 6.72 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5183110209967565		[learning rate: 0.0074625]
	Learning Rate: 0.0074625
	LOSS [training: 0.5183110209967565 | validation: 0.4351007837712163]
	TIME [epoch: 6.72 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4051417646483743		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 0.4051417646483743 | validation: 0.47808139446581055]
	TIME [epoch: 6.72 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4624827255554518		[learning rate: 0.0074033]
	Learning Rate: 0.00740326
	LOSS [training: 0.4624827255554518 | validation: 0.525246859808138]
	TIME [epoch: 6.72 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.474354564149557		[learning rate: 0.0073738]
	Learning Rate: 0.00737382
	LOSS [training: 0.474354564149557 | validation: 0.5762196673735843]
	TIME [epoch: 6.71 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4647296752548065		[learning rate: 0.0073445]
	Learning Rate: 0.00734449
	LOSS [training: 0.4647296752548065 | validation: 0.3942396097038798]
	TIME [epoch: 6.74 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6351007621462736		[learning rate: 0.0073153]
	Learning Rate: 0.00731528
	LOSS [training: 0.6351007621462736 | validation: 0.6755971575026098]
	TIME [epoch: 6.72 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6482841992724683		[learning rate: 0.0072862]
	Learning Rate: 0.00728618
	LOSS [training: 0.6482841992724683 | validation: 0.5885516008720406]
	TIME [epoch: 6.71 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4960796025939183		[learning rate: 0.0072572]
	Learning Rate: 0.0072572
	LOSS [training: 0.4960796025939183 | validation: 0.48070676705304693]
	TIME [epoch: 6.72 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4481449874579975		[learning rate: 0.0072283]
	Learning Rate: 0.00722834
	LOSS [training: 0.4481449874579975 | validation: 0.45111563486749445]
	TIME [epoch: 6.72 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4201208709978749		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 0.4201208709978749 | validation: 0.7313707452618725]
	TIME [epoch: 6.72 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.49148282680683164		[learning rate: 0.007171]
	Learning Rate: 0.00717095
	LOSS [training: 0.49148282680683164 | validation: 0.4134897575660572]
	TIME [epoch: 6.72 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.37265979596890797		[learning rate: 0.0071424]
	Learning Rate: 0.00714243
	LOSS [training: 0.37265979596890797 | validation: 0.3673815886717395]
	TIME [epoch: 6.73 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4671143888572543		[learning rate: 0.007114]
	Learning Rate: 0.00711403
	LOSS [training: 0.4671143888572543 | validation: 0.4874100802474615]
	TIME [epoch: 6.72 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.42784003857634106		[learning rate: 0.0070857]
	Learning Rate: 0.00708573
	LOSS [training: 0.42784003857634106 | validation: 0.4205671691007901]
	TIME [epoch: 6.71 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4072512673120638		[learning rate: 0.0070575]
	Learning Rate: 0.00705755
	LOSS [training: 0.4072512673120638 | validation: 0.39327605990111175]
	TIME [epoch: 6.71 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.38784186332269893		[learning rate: 0.0070295]
	Learning Rate: 0.00702948
	LOSS [training: 0.38784186332269893 | validation: 0.3785321644588213]
	TIME [epoch: 6.71 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.37915117317929514		[learning rate: 0.0070015]
	Learning Rate: 0.00700152
	LOSS [training: 0.37915117317929514 | validation: 0.46249136817382447]
	TIME [epoch: 6.72 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.36178219826021196		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 0.36178219826021196 | validation: 0.43325882375016445]
	TIME [epoch: 6.73 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.384001100397391		[learning rate: 0.0069459]
	Learning Rate: 0.00694594
	LOSS [training: 0.384001100397391 | validation: 0.3577911511550558]
	TIME [epoch: 6.72 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.36007918045268533		[learning rate: 0.0069183]
	Learning Rate: 0.00691831
	LOSS [training: 0.36007918045268533 | validation: 0.35470033329544226]
	TIME [epoch: 6.72 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3667623961317472		[learning rate: 0.0068908]
	Learning Rate: 0.00689079
	LOSS [training: 0.3667623961317472 | validation: 0.3700750970935337]
	TIME [epoch: 6.72 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.9865669723378995		[learning rate: 0.0068634]
	Learning Rate: 0.00686339
	LOSS [training: 0.9865669723378995 | validation: 2.0721688207314424]
	TIME [epoch: 6.71 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 9/9] avg loss: 3.374542206870237		[learning rate: 0.0068361]
	Learning Rate: 0.00683609
	LOSS [training: 3.374542206870237 | validation: 6.22024788511229]
	TIME [epoch: 6.71 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 9/9] avg loss: 3.0222402832358695		[learning rate: 0.0068089]
	Learning Rate: 0.0068089
	LOSS [training: 3.0222402832358695 | validation: 1.4097643659590662]
	TIME [epoch: 6.72 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.77633808177601		[learning rate: 0.0067818]
	Learning Rate: 0.00678182
	LOSS [training: 1.77633808177601 | validation: 1.022688803097689]
	TIME [epoch: 6.73 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.3081416094925309		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 1.3081416094925309 | validation: 0.837339299472573]
	TIME [epoch: 6.72 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.8852303433816262		[learning rate: 0.006728]
	Learning Rate: 0.00672798
	LOSS [training: 0.8852303433816262 | validation: 0.5947545763012583]
	TIME [epoch: 6.71 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7902912207083205		[learning rate: 0.0067012]
	Learning Rate: 0.00670122
	LOSS [training: 0.7902912207083205 | validation: 0.5780548754272958]
	TIME [epoch: 6.72 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.802714386302351		[learning rate: 0.0066746]
	Learning Rate: 0.00667457
	LOSS [training: 0.802714386302351 | validation: 0.5535777783840853]
	TIME [epoch: 6.72 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6599133454415756		[learning rate: 0.006648]
	Learning Rate: 0.00664802
	LOSS [training: 0.6599133454415756 | validation: 0.5163741849872421]
	TIME [epoch: 6.72 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.586892687157054		[learning rate: 0.0066216]
	Learning Rate: 0.00662158
	LOSS [training: 0.586892687157054 | validation: 0.4838620181905954]
	TIME [epoch: 6.71 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6222737617442499		[learning rate: 0.0065952]
	Learning Rate: 0.00659524
	LOSS [training: 0.6222737617442499 | validation: 0.49914469436037046]
	TIME [epoch: 6.74 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5363897423013521		[learning rate: 0.006569]
	Learning Rate: 0.00656901
	LOSS [training: 0.5363897423013521 | validation: 0.4470698306718857]
	TIME [epoch: 6.72 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5540100476760191		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 0.5540100476760191 | validation: 0.4506954676582401]
	TIME [epoch: 6.71 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.8623281842318158		[learning rate: 0.0065169]
	Learning Rate: 0.00651686
	LOSS [training: 0.8623281842318158 | validation: 0.9040236294108361]
	TIME [epoch: 6.72 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.8985822987990464		[learning rate: 0.0064909]
	Learning Rate: 0.00649094
	LOSS [training: 1.8985822987990464 | validation: 2.844012289363244]
	TIME [epoch: 6.71 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 9/9] avg loss: 3.238438962879253		[learning rate: 0.0064651]
	Learning Rate: 0.00646512
	LOSS [training: 3.238438962879253 | validation: 3.2815063231668455]
	TIME [epoch: 6.71 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 9/9] avg loss: 3.607376567351262		[learning rate: 0.0064394]
	Learning Rate: 0.00643941
	LOSS [training: 3.607376567351262 | validation: 3.620235915324389]
	TIME [epoch: 6.72 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 9/9] avg loss: 3.3525969237348474		[learning rate: 0.0064138]
	Learning Rate: 0.0064138
	LOSS [training: 3.3525969237348474 | validation: 2.9586782771089366]
	TIME [epoch: 6.73 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 9/9] avg loss: 3.205625602376553		[learning rate: 0.0063883]
	Learning Rate: 0.00638829
	LOSS [training: 3.205625602376553 | validation: 2.3292416076533127]
	TIME [epoch: 6.72 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.404286468843044		[learning rate: 0.0063629]
	Learning Rate: 0.00636288
	LOSS [training: 1.404286468843044 | validation: 1.0713578632730163]
	TIME [epoch: 6.72 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.1146521552108117		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 1.1146521552108117 | validation: 1.2355858479102986]
	TIME [epoch: 6.71 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.349985364296312		[learning rate: 0.0063124]
	Learning Rate: 0.00631237
	LOSS [training: 1.349985364296312 | validation: 1.1479834920313123]
	TIME [epoch: 6.72 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.380143701941227		[learning rate: 0.0062873]
	Learning Rate: 0.00628726
	LOSS [training: 1.380143701941227 | validation: 1.3033529873066625]
	TIME [epoch: 6.72 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.4614368218328115		[learning rate: 0.0062623]
	Learning Rate: 0.00626226
	LOSS [training: 1.4614368218328115 | validation: 1.318277576764207]
	TIME [epoch: 6.73 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.3519042107798311		[learning rate: 0.0062373]
	Learning Rate: 0.00623735
	LOSS [training: 1.3519042107798311 | validation: 1.161667003952413]
	TIME [epoch: 6.72 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.090744859674361		[learning rate: 0.0062125]
	Learning Rate: 0.00621254
	LOSS [training: 1.090744859674361 | validation: 0.8443485272570579]
	TIME [epoch: 6.71 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.8656808485358929		[learning rate: 0.0061878]
	Learning Rate: 0.00618783
	LOSS [training: 0.8656808485358929 | validation: 0.6634871612693256]
	TIME [epoch: 6.72 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.3483362512068877		[learning rate: 0.0061632]
	Learning Rate: 0.00616322
	LOSS [training: 1.3483362512068877 | validation: 1.497217568383324]
	TIME [epoch: 6.72 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.0542762916081534		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 1.0542762916081534 | validation: 0.62945676930312]
	TIME [epoch: 6.72 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.776043390466793		[learning rate: 0.0061143]
	Learning Rate: 0.00611429
	LOSS [training: 0.776043390466793 | validation: 0.6896645542087448]
	TIME [epoch: 6.71 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7751731309804707		[learning rate: 0.00609]
	Learning Rate: 0.00608997
	LOSS [training: 0.7751731309804707 | validation: 0.565153647612658]
	TIME [epoch: 6.73 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6326008512204526		[learning rate: 0.0060658]
	Learning Rate: 0.00606575
	LOSS [training: 0.6326008512204526 | validation: 0.523365395167094]
	TIME [epoch: 6.73 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7162151584954803		[learning rate: 0.0060416]
	Learning Rate: 0.00604163
	LOSS [training: 0.7162151584954803 | validation: 0.5549321165965029]
	TIME [epoch: 6.72 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.1065765460976111		[learning rate: 0.0060176]
	Learning Rate: 0.0060176
	LOSS [training: 1.1065765460976111 | validation: 2.6382716551902696]
	TIME [epoch: 6.72 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 9/9] avg loss: 2.892959216134978		[learning rate: 0.0059937]
	Learning Rate: 0.00599366
	LOSS [training: 2.892959216134978 | validation: 2.1801827620569405]
	TIME [epoch: 6.72 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 9/9] avg loss: 2.474021214135626		[learning rate: 0.0059698]
	Learning Rate: 0.00596982
	LOSS [training: 2.474021214135626 | validation: 2.4083795304015707]
	TIME [epoch: 6.72 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 9/9] avg loss: 2.042175369264772		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 2.042175369264772 | validation: 1.5690053239058508]
	TIME [epoch: 6.72 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.6974179357674442		[learning rate: 0.0059224]
	Learning Rate: 0.00592243
	LOSS [training: 1.6974179357674442 | validation: 1.4666914903299104]
	TIME [epoch: 6.73 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.1886802485815215		[learning rate: 0.0058989]
	Learning Rate: 0.00589888
	LOSS [training: 1.1886802485815215 | validation: 0.8244150930219369]
	TIME [epoch: 6.72 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7477894277723425		[learning rate: 0.0058754]
	Learning Rate: 0.00587541
	LOSS [training: 0.7477894277723425 | validation: 0.5154562900085234]
	TIME [epoch: 6.71 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.678945546506144		[learning rate: 0.005852]
	Learning Rate: 0.00585205
	LOSS [training: 0.678945546506144 | validation: 0.5685435906668117]
	TIME [epoch: 6.71 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6467754768561262		[learning rate: 0.0058288]
	Learning Rate: 0.00582877
	LOSS [training: 0.6467754768561262 | validation: 0.5794068048068631]
	TIME [epoch: 6.71 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6066056906180529		[learning rate: 0.0058056]
	Learning Rate: 0.00580559
	LOSS [training: 0.6066056906180529 | validation: 0.5253201835751988]
	TIME [epoch: 6.71 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6135740443811434		[learning rate: 0.0057825]
	Learning Rate: 0.0057825
	LOSS [training: 0.6135740443811434 | validation: 0.5686524483142257]
	TIME [epoch: 6.72 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.573461430097328		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 0.573461430097328 | validation: 0.5006712840681341]
	TIME [epoch: 6.73 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5925277792899545		[learning rate: 0.0057366]
	Learning Rate: 0.00573659
	LOSS [training: 0.5925277792899545 | validation: 0.556065710288569]
	TIME [epoch: 6.72 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5278733686376618		[learning rate: 0.0057138]
	Learning Rate: 0.00571377
	LOSS [training: 0.5278733686376618 | validation: 0.5288542074631767]
	TIME [epoch: 6.72 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5469123418277868		[learning rate: 0.005691]
	Learning Rate: 0.00569105
	LOSS [training: 0.5469123418277868 | validation: 0.4499793048538865]
	TIME [epoch: 6.71 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.576601249037323		[learning rate: 0.0056684]
	Learning Rate: 0.00566841
	LOSS [training: 0.576601249037323 | validation: 1.068882844999037]
	TIME [epoch: 6.72 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 9/9] avg loss: 2.6161458769535906		[learning rate: 0.0056459]
	Learning Rate: 0.00564587
	LOSS [training: 2.6161458769535906 | validation: 4.4118397623570225]
	TIME [epoch: 6.71 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 9/9] avg loss: 4.388383568408224		[learning rate: 0.0056234]
	Learning Rate: 0.00562341
	LOSS [training: 4.388383568408224 | validation: 4.965743416543489]
	TIME [epoch: 6.72 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 9/9] avg loss: 4.225924547825336		[learning rate: 0.005601]
	Learning Rate: 0.00560105
	LOSS [training: 4.225924547825336 | validation: 4.019254715626327]
	TIME [epoch: 6.72 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 9/9] avg loss: 4.085416445784719		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 4.085416445784719 | validation: 4.252250706446478]
	TIME [epoch: 6.71 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 9/9] avg loss: 3.8179665648021563		[learning rate: 0.0055566]
	Learning Rate: 0.00555658
	LOSS [training: 3.8179665648021563 | validation: 3.7620311335996304]
	TIME [epoch: 6.72 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 9/9] avg loss: 3.144062017628395		[learning rate: 0.0055345]
	Learning Rate: 0.00553448
	LOSS [training: 3.144062017628395 | validation: 2.5197690042410628]
	TIME [epoch: 6.72 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 9/9] avg loss: 2.4052742183429805		[learning rate: 0.0055125]
	Learning Rate: 0.00551247
	LOSS [training: 2.4052742183429805 | validation: 1.4103480762561387]
	TIME [epoch: 6.71 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.5329205888822433		[learning rate: 0.0054905]
	Learning Rate: 0.00549054
	LOSS [training: 1.5329205888822433 | validation: 1.562216787054179]
	TIME [epoch: 6.72 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.53765335008955		[learning rate: 0.0054687]
	Learning Rate: 0.00546871
	LOSS [training: 1.53765335008955 | validation: 1.3678098305954218]
	TIME [epoch: 6.73 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.472161419282241		[learning rate: 0.005447]
	Learning Rate: 0.00544696
	LOSS [training: 1.472161419282241 | validation: 1.364551467415955]
	TIME [epoch: 6.71 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.566065874149188		[learning rate: 0.0054253]
	Learning Rate: 0.00542529
	LOSS [training: 1.566065874149188 | validation: 1.4341094129278944]
	TIME [epoch: 6.72 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.5263501348711221		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 1.5263501348711221 | validation: 1.914776420879011]
	TIME [epoch: 6.71 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 9/9] avg loss: 2.27577946021568		[learning rate: 0.0053822]
	Learning Rate: 0.00538222
	LOSS [training: 2.27577946021568 | validation: 2.1381423305205742]
	TIME [epoch: 6.71 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.9607565283674664		[learning rate: 0.0053608]
	Learning Rate: 0.00536081
	LOSS [training: 1.9607565283674664 | validation: 2.0972992110406077]
	TIME [epoch: 6.71 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 9/9] avg loss: 2.2008862580969923		[learning rate: 0.0053395]
	Learning Rate: 0.00533949
	LOSS [training: 2.2008862580969923 | validation: 2.6196379259949487]
	TIME [epoch: 6.71 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 9/9] avg loss: 2.4187829245311026		[learning rate: 0.0053183]
	Learning Rate: 0.00531826
	LOSS [training: 2.4187829245311026 | validation: 1.346199243761689]
	TIME [epoch: 6.72 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 9/9] avg loss: 2.0319980164351423		[learning rate: 0.0052971]
	Learning Rate: 0.0052971
	LOSS [training: 2.0319980164351423 | validation: 2.262248734816916]
	TIME [epoch: 6.71 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.6924671275462195		[learning rate: 0.005276]
	Learning Rate: 0.00527604
	LOSS [training: 1.6924671275462195 | validation: 1.0893099154858514]
	TIME [epoch: 6.71 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.9309707687247015		[learning rate: 0.0052551]
	Learning Rate: 0.00525505
	LOSS [training: 1.9309707687247015 | validation: 2.70082352459498]
	TIME [epoch: 6.71 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.7314482137773906		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 1.7314482137773906 | validation: 1.326922116096983]
	TIME [epoch: 6.71 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.6004268550992746		[learning rate: 0.0052133]
	Learning Rate: 0.00521333
	LOSS [training: 1.6004268550992746 | validation: 1.3501429666380385]
	TIME [epoch: 6.71 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.4281980862399821		[learning rate: 0.0051926]
	Learning Rate: 0.0051926
	LOSS [training: 1.4281980862399821 | validation: 2.3838613630271794]
	TIME [epoch: 6.71 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.900988812203512		[learning rate: 0.0051719]
	Learning Rate: 0.00517194
	LOSS [training: 1.900988812203512 | validation: 2.0229092206717794]
	TIME [epoch: 6.72 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 9/9] avg loss: 2.019702244740574		[learning rate: 0.0051514]
	Learning Rate: 0.00515137
	LOSS [training: 2.019702244740574 | validation: 2.0598295140250324]
	TIME [epoch: 6.7 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.682731895107215		[learning rate: 0.0051309]
	Learning Rate: 0.00513089
	LOSS [training: 1.682731895107215 | validation: 1.7945825777300335]
	TIME [epoch: 6.7 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.5981366267552697		[learning rate: 0.0051105]
	Learning Rate: 0.00511048
	LOSS [training: 1.5981366267552697 | validation: 1.2990439397360425]
	TIME [epoch: 6.71 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.5317254461817784		[learning rate: 0.0050902]
	Learning Rate: 0.00509015
	LOSS [training: 1.5317254461817784 | validation: 1.3347818516757093]
	TIME [epoch: 6.71 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.6491347082978496		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 1.6491347082978496 | validation: 1.3832589796616346]
	TIME [epoch: 6.7 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.6159735537752522		[learning rate: 0.0050497]
	Learning Rate: 0.00504974
	LOSS [training: 1.6159735537752522 | validation: 1.3347165342147853]
	TIME [epoch: 6.72 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.5023870311917666		[learning rate: 0.0050297]
	Learning Rate: 0.00502966
	LOSS [training: 1.5023870311917666 | validation: 1.2506788855715842]
	TIME [epoch: 6.84 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.403608759251465		[learning rate: 0.0050097]
	Learning Rate: 0.00500965
	LOSS [training: 1.403608759251465 | validation: 1.137889896235381]
	TIME [epoch: 6.71 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.2543898857033002		[learning rate: 0.0049897]
	Learning Rate: 0.00498973
	LOSS [training: 1.2543898857033002 | validation: 1.029859238062889]
	TIME [epoch: 6.7 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.1431765925478574		[learning rate: 0.0049699]
	Learning Rate: 0.00496988
	LOSS [training: 1.1431765925478574 | validation: 0.9672420494358827]
	TIME [epoch: 6.71 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.064522250934413		[learning rate: 0.0049501]
	Learning Rate: 0.00495012
	LOSS [training: 1.064522250934413 | validation: 0.8119843908779923]
	TIME [epoch: 6.71 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.878097762404179		[learning rate: 0.0049304]
	Learning Rate: 0.00493043
	LOSS [training: 0.878097762404179 | validation: 0.7214834197639425]
	TIME [epoch: 6.71 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.0257142079413597		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 1.0257142079413597 | validation: 0.9219107660107071]
	TIME [epoch: 6.72 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.1095960526769348		[learning rate: 0.0048913]
	Learning Rate: 0.00489129
	LOSS [training: 1.1095960526769348 | validation: 0.9543952910760114]
	TIME [epoch: 6.71 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.0709711029233673		[learning rate: 0.0048718]
	Learning Rate: 0.00487183
	LOSS [training: 1.0709711029233673 | validation: 0.8967123465847884]
	TIME [epoch: 6.7 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.0458753142637232		[learning rate: 0.0048525]
	Learning Rate: 0.00485245
	LOSS [training: 1.0458753142637232 | validation: 0.8950966805575827]
	TIME [epoch: 6.71 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.0064222636324271		[learning rate: 0.0048332]
	Learning Rate: 0.00483316
	LOSS [training: 1.0064222636324271 | validation: 0.8970670736920179]
	TIME [epoch: 6.7 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.9843706081219867		[learning rate: 0.0048139]
	Learning Rate: 0.00481393
	LOSS [training: 0.9843706081219867 | validation: 0.8721101250304016]
	TIME [epoch: 6.71 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.9824341458391836		[learning rate: 0.0047948]
	Learning Rate: 0.00479479
	LOSS [training: 0.9824341458391836 | validation: 0.7788957333460669]
	TIME [epoch: 6.7 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.9934212744980455		[learning rate: 0.0047757]
	Learning Rate: 0.00477572
	LOSS [training: 0.9934212744980455 | validation: 0.8457293115676416]
	TIME [epoch: 6.72 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.989591311811099		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.989591311811099 | validation: 0.8425956809658113]
	TIME [epoch: 6.71 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.9802421743280632		[learning rate: 0.0047378]
	Learning Rate: 0.0047378
	LOSS [training: 0.9802421743280632 | validation: 0.7031417491586828]
	TIME [epoch: 6.71 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.883385453085202		[learning rate: 0.004719]
	Learning Rate: 0.00471896
	LOSS [training: 0.883385453085202 | validation: 0.6878932458260428]
	TIME [epoch: 6.71 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.8723196800141213		[learning rate: 0.0047002]
	Learning Rate: 0.00470019
	LOSS [training: 0.8723196800141213 | validation: 0.7703879074209926]
	TIME [epoch: 6.71 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.9518741129849393		[learning rate: 0.0046815]
	Learning Rate: 0.0046815
	LOSS [training: 0.9518741129849393 | validation: 0.881225062555702]
	TIME [epoch: 6.71 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.0247554611418748		[learning rate: 0.0046629]
	Learning Rate: 0.00466288
	LOSS [training: 1.0247554611418748 | validation: 0.9024144173062305]
	TIME [epoch: 6.71 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.054194331005779		[learning rate: 0.0046443]
	Learning Rate: 0.00464433
	LOSS [training: 1.054194331005779 | validation: 0.9440921757012969]
	TIME [epoch: 6.71 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.0685681038415487		[learning rate: 0.0046259]
	Learning Rate: 0.00462586
	LOSS [training: 1.0685681038415487 | validation: 0.9339520720555472]
	TIME [epoch: 6.71 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.0429176791485122		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 1.0429176791485122 | validation: 0.8930117895972552]
	TIME [epoch: 6.71 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.9777085727487146		[learning rate: 0.0045891]
	Learning Rate: 0.00458913
	LOSS [training: 0.9777085727487146 | validation: 0.8716032959171128]
	TIME [epoch: 6.7 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.9271451494475905		[learning rate: 0.0045709]
	Learning Rate: 0.00457088
	LOSS [training: 0.9271451494475905 | validation: 0.811304116463505]
	TIME [epoch: 6.71 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.8940051942047563		[learning rate: 0.0045527]
	Learning Rate: 0.0045527
	LOSS [training: 0.8940051942047563 | validation: 0.7979442329548172]
	TIME [epoch: 6.7 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.916416512415085		[learning rate: 0.0045346]
	Learning Rate: 0.00453459
	LOSS [training: 0.916416512415085 | validation: 0.7957338577517665]
	TIME [epoch: 6.71 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.8484637919808509		[learning rate: 0.0045166]
	Learning Rate: 0.00451656
	LOSS [training: 0.8484637919808509 | validation: 0.7586625216592762]
	TIME [epoch: 6.71 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.8465999612285362		[learning rate: 0.0044986]
	Learning Rate: 0.0044986
	LOSS [training: 0.8465999612285362 | validation: 0.7567899990583713]
	TIME [epoch: 6.7 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7884851247275224		[learning rate: 0.0044807]
	Learning Rate: 0.0044807
	LOSS [training: 0.7884851247275224 | validation: 0.7258238519159265]
	TIME [epoch: 6.7 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6837835082190193		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 0.6837835082190193 | validation: 0.5105438230047952]
	TIME [epoch: 6.71 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5904378062877057		[learning rate: 0.0044451]
	Learning Rate: 0.00444513
	LOSS [training: 0.5904378062877057 | validation: 0.5319508022594537]
	TIME [epoch: 6.71 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5683406998902354		[learning rate: 0.0044275]
	Learning Rate: 0.00442745
	LOSS [training: 0.5683406998902354 | validation: 0.5370201149461639]
	TIME [epoch: 6.71 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5278682224597016		[learning rate: 0.0044098]
	Learning Rate: 0.00440984
	LOSS [training: 0.5278682224597016 | validation: 0.44335197795263487]
	TIME [epoch: 6.71 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.48131782182321575		[learning rate: 0.0043923]
	Learning Rate: 0.0043923
	LOSS [training: 0.48131782182321575 | validation: 0.4391844777550503]
	TIME [epoch: 6.71 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4954168903461153		[learning rate: 0.0043748]
	Learning Rate: 0.00437483
	LOSS [training: 0.4954168903461153 | validation: 0.49645641225415627]
	TIME [epoch: 6.71 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4596101605272707		[learning rate: 0.0043574]
	Learning Rate: 0.00435743
	LOSS [training: 0.4596101605272707 | validation: 0.4282897499539189]
	TIME [epoch: 6.71 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.41421561424571507		[learning rate: 0.0043401]
	Learning Rate: 0.0043401
	LOSS [training: 0.41421561424571507 | validation: 0.4272860140867828]
	TIME [epoch: 6.71 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.42892572743023955		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 0.42892572743023955 | validation: 0.43745825356432777]
	TIME [epoch: 6.71 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.40111281669837706		[learning rate: 0.0043056]
	Learning Rate: 0.00430565
	LOSS [training: 0.40111281669837706 | validation: 0.3869053854000418]
	TIME [epoch: 6.71 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.39961908731737417		[learning rate: 0.0042885]
	Learning Rate: 0.00428852
	LOSS [training: 0.39961908731737417 | validation: 0.41749689524048045]
	TIME [epoch: 6.72 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6350659825264557		[learning rate: 0.0042715]
	Learning Rate: 0.00427147
	LOSS [training: 0.6350659825264557 | validation: 0.5984300165893234]
	TIME [epoch: 6.71 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5938182359519845		[learning rate: 0.0042545]
	Learning Rate: 0.00425448
	LOSS [training: 0.5938182359519845 | validation: 0.540846611048267]
	TIME [epoch: 6.7 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.45832125953022806		[learning rate: 0.0042376]
	Learning Rate: 0.00423756
	LOSS [training: 0.45832125953022806 | validation: 0.4049965912704936]
	TIME [epoch: 6.71 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.46953258383858043		[learning rate: 0.0042207]
	Learning Rate: 0.0042207
	LOSS [training: 0.46953258383858043 | validation: 1.2935816492746306]
	TIME [epoch: 6.71 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6653868805822446		[learning rate: 0.0042039]
	Learning Rate: 0.00420391
	LOSS [training: 0.6653868805822446 | validation: 0.6397865085484856]
	TIME [epoch: 6.7 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.0870648019684908		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 1.0870648019684908 | validation: 1.0716001132316968]
	TIME [epoch: 6.71 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.622149885784433		[learning rate: 0.0041705]
	Learning Rate: 0.00417054
	LOSS [training: 1.622149885784433 | validation: 2.551354928455832]
	TIME [epoch: 6.72 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 9/9] avg loss: 2.8105859634095083		[learning rate: 0.004154]
	Learning Rate: 0.00415395
	LOSS [training: 2.8105859634095083 | validation: 2.647513612209602]
	TIME [epoch: 6.71 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 9/9] avg loss: 2.5177781762792986		[learning rate: 0.0041374]
	Learning Rate: 0.00413743
	LOSS [training: 2.5177781762792986 | validation: 2.2977449266439165]
	TIME [epoch: 6.71 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 9/9] avg loss: 2.3934050909147144		[learning rate: 0.004121]
	Learning Rate: 0.00412098
	LOSS [training: 2.3934050909147144 | validation: 1.9682693805138023]
	TIME [epoch: 6.71 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.5614765780543918		[learning rate: 0.0041046]
	Learning Rate: 0.00410458
	LOSS [training: 1.5614765780543918 | validation: 1.4810386615381401]
	TIME [epoch: 6.71 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.1747128674768363		[learning rate: 0.0040883]
	Learning Rate: 0.00408826
	LOSS [training: 1.1747128674768363 | validation: 1.645629489038334]
	TIME [epoch: 6.71 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.830927830101457		[learning rate: 0.004072]
	Learning Rate: 0.004072
	LOSS [training: 1.830927830101457 | validation: 1.7881970276364847]
	TIME [epoch: 6.71 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.401047952231889		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 1.401047952231889 | validation: 1.4691219930855186]
	TIME [epoch: 6.71 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.4837702771771477		[learning rate: 0.0040397]
	Learning Rate: 0.00403967
	LOSS [training: 1.4837702771771477 | validation: 1.469276842638601]
	TIME [epoch: 6.71 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.7341847277316031		[learning rate: 0.0040236]
	Learning Rate: 0.00402361
	LOSS [training: 1.7341847277316031 | validation: 1.7804779314726815]
	TIME [epoch: 6.71 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 9/9] avg loss: 2.056092122050062		[learning rate: 0.0040076]
	Learning Rate: 0.0040076
	LOSS [training: 2.056092122050062 | validation: 2.012934249103577]
	TIME [epoch: 6.71 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 9/9] avg loss: 2.730350882849927		[learning rate: 0.0039917]
	Learning Rate: 0.00399166
	LOSS [training: 2.730350882849927 | validation: 2.845797362674186]
	TIME [epoch: 6.71 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 9/9] avg loss: 2.3538238330305576		[learning rate: 0.0039758]
	Learning Rate: 0.00397579
	LOSS [training: 2.3538238330305576 | validation: 2.0410988417940166]
	TIME [epoch: 6.71 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.9054141588151896		[learning rate: 0.00396]
	Learning Rate: 0.00395997
	LOSS [training: 1.9054141588151896 | validation: 1.3437908613982668]
	TIME [epoch: 6.72 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.257061654577897		[learning rate: 0.0039442]
	Learning Rate: 0.00394422
	LOSS [training: 1.257061654577897 | validation: 0.9876675792432643]
	TIME [epoch: 6.71 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.0656080831245858		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 1.0656080831245858 | validation: 1.0034238267065545]
	TIME [epoch: 6.71 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.318604748730151		[learning rate: 0.0039129]
	Learning Rate: 0.00391291
	LOSS [training: 1.318604748730151 | validation: 1.0350922076855373]
	TIME [epoch: 6.71 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.052720403856143		[learning rate: 0.0038973]
	Learning Rate: 0.00389735
	LOSS [training: 1.052720403856143 | validation: 0.8695106794356289]
	TIME [epoch: 6.71 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.8801872312064574		[learning rate: 0.0038818]
	Learning Rate: 0.00388185
	LOSS [training: 0.8801872312064574 | validation: 0.7849290345085249]
	TIME [epoch: 6.71 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7771124010994307		[learning rate: 0.0038664]
	Learning Rate: 0.00386641
	LOSS [training: 0.7771124010994307 | validation: 0.7865993213924447]
	TIME [epoch: 6.7 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7801812948771907		[learning rate: 0.003851]
	Learning Rate: 0.00385103
	LOSS [training: 0.7801812948771907 | validation: 0.7655306932962952]
	TIME [epoch: 6.72 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.76141563090744		[learning rate: 0.0038357]
	Learning Rate: 0.00383571
	LOSS [training: 0.76141563090744 | validation: 0.7689664773196114]
	TIME [epoch: 6.71 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7606921943848939		[learning rate: 0.0038205]
	Learning Rate: 0.00382046
	LOSS [training: 0.7606921943848939 | validation: 0.7532709975659797]
	TIME [epoch: 6.71 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7038185176540989		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 0.7038185176540989 | validation: 0.687925031690338]
	TIME [epoch: 6.71 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6772005841764382		[learning rate: 0.0037901]
	Learning Rate: 0.00379013
	LOSS [training: 0.6772005841764382 | validation: 0.7022750284165178]
	TIME [epoch: 6.71 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6405178306381204		[learning rate: 0.0037751]
	Learning Rate: 0.00377505
	LOSS [training: 0.6405178306381204 | validation: 0.6287968559401357]
	TIME [epoch: 6.75 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6051765484937515		[learning rate: 0.00376]
	Learning Rate: 0.00376004
	LOSS [training: 0.6051765484937515 | validation: 0.5752839775657927]
	TIME [epoch: 6.71 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5623325952991547		[learning rate: 0.0037451]
	Learning Rate: 0.00374508
	LOSS [training: 0.5623325952991547 | validation: 0.6001337915337863]
	TIME [epoch: 6.73 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5774753544188436		[learning rate: 0.0037302]
	Learning Rate: 0.00373019
	LOSS [training: 0.5774753544188436 | validation: 0.5665137710590484]
	TIME [epoch: 6.71 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5619774939158179		[learning rate: 0.0037154]
	Learning Rate: 0.00371535
	LOSS [training: 0.5619774939158179 | validation: 0.6092424781820613]
	TIME [epoch: 6.7 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5444453098617376		[learning rate: 0.0037006]
	Learning Rate: 0.00370058
	LOSS [training: 0.5444453098617376 | validation: 0.5485975850134003]
	TIME [epoch: 6.71 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5714748159203858		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 0.5714748159203858 | validation: 0.5631648419389024]
	TIME [epoch: 6.73 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5480428164523998		[learning rate: 0.0036712]
	Learning Rate: 0.0036712
	LOSS [training: 0.5480428164523998 | validation: 0.5439646375962988]
	TIME [epoch: 6.71 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5106215055353311		[learning rate: 0.0036566]
	Learning Rate: 0.0036566
	LOSS [training: 0.5106215055353311 | validation: 0.544493530366713]
	TIME [epoch: 6.71 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5221408579682769		[learning rate: 0.0036421]
	Learning Rate: 0.00364205
	LOSS [training: 0.5221408579682769 | validation: 0.5544396957372728]
	TIME [epoch: 6.72 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5894188940699556		[learning rate: 0.0036276]
	Learning Rate: 0.00362757
	LOSS [training: 0.5894188940699556 | validation: 0.5808850658817282]
	TIME [epoch: 6.71 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5289565150646393		[learning rate: 0.0036131]
	Learning Rate: 0.00361314
	LOSS [training: 0.5289565150646393 | validation: 0.5242783527649697]
	TIME [epoch: 6.71 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.49552396479351646		[learning rate: 0.0035988]
	Learning Rate: 0.00359877
	LOSS [training: 0.49552396479351646 | validation: 0.511797306282839]
	TIME [epoch: 6.71 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4905889554909479		[learning rate: 0.0035845]
	Learning Rate: 0.00358445
	LOSS [training: 0.4905889554909479 | validation: 0.5061998789758336]
	TIME [epoch: 6.72 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.47016189416422083		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 0.47016189416422083 | validation: 0.43075995234359815]
	TIME [epoch: 6.71 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5816831031845223		[learning rate: 0.003556]
	Learning Rate: 0.003556
	LOSS [training: 0.5816831031845223 | validation: 0.6687068735755939]
	TIME [epoch: 6.72 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.8394273762652845		[learning rate: 0.0035419]
	Learning Rate: 0.00354185
	LOSS [training: 0.8394273762652845 | validation: 1.046886197408376]
	TIME [epoch: 6.72 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.8189364945256665		[learning rate: 0.0035278]
	Learning Rate: 0.00352777
	LOSS [training: 1.8189364945256665 | validation: 3.008886844962334]
	TIME [epoch: 6.71 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 9/9] avg loss: 2.8865098822531627		[learning rate: 0.0035137]
	Learning Rate: 0.00351374
	LOSS [training: 2.8865098822531627 | validation: 1.45849498773954]
	TIME [epoch: 6.71 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.794208800202469		[learning rate: 0.0034998]
	Learning Rate: 0.00349976
	LOSS [training: 1.794208800202469 | validation: 2.639414137246805]
	TIME [epoch: 6.71 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 9/9] avg loss: 2.4538791355807636		[learning rate: 0.0034858]
	Learning Rate: 0.00348584
	LOSS [training: 2.4538791355807636 | validation: 2.4925971598513295]
	TIME [epoch: 6.71 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 9/9] avg loss: 2.480330726461101		[learning rate: 0.003472]
	Learning Rate: 0.00347198
	LOSS [training: 2.480330726461101 | validation: 2.2583282334416688]
	TIME [epoch: 6.71 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 9/9] avg loss: 2.719684264509753		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 2.719684264509753 | validation: 3.0119193785239937]
	TIME [epoch: 6.73 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 9/9] avg loss: 2.7087205854238743		[learning rate: 0.0034444]
	Learning Rate: 0.00344441
	LOSS [training: 2.7087205854238743 | validation: 2.4509733294537455]
	TIME [epoch: 6.82 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 9/9] avg loss: 2.720475504727327		[learning rate: 0.0034307]
	Learning Rate: 0.00343071
	LOSS [training: 2.720475504727327 | validation: 2.6560627993324126]
	TIME [epoch: 6.71 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 9/9] avg loss: 2.702098788050835		[learning rate: 0.0034171]
	Learning Rate: 0.00341707
	LOSS [training: 2.702098788050835 | validation: 2.747701747588273]
	TIME [epoch: 6.71 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 9/9] avg loss: 2.6518719947503295		[learning rate: 0.0034035]
	Learning Rate: 0.00340348
	LOSS [training: 2.6518719947503295 | validation: 2.610437217531308]
	TIME [epoch: 6.71 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v6_20240710_202109/states/model_facs_dec1b_2dpca_v6_315.pth
Halted early. No improvement in validation loss for 200 epochs.
Finished training in 2189.928 seconds.
