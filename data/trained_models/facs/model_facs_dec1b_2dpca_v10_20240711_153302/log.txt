Args:
Namespace(name='model_facs_dec1b_2dpca_v10', outdir='out/model_training/model_facs_dec1b_2dpca_v10', training_data='data/training_data/facs/pca/dec1_fitonsubset/transition1_subset_epi_tr_ce_an_pc12/training', validation_data='data/training_data/facs/pca/dec1_fitonsubset/transition1_subset_epi_tr_ce_an_pc12/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=10, batch_size=50, patience=200, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, quadratic_a=1.0, quadratic_b=1.0, ndims=2, nparams=2, nsigs=2, ncells=400, ncells_sample=400, model_do_sample=False, dt=0.005, dt_schedule='stepped', dt_schedule_bounds=[500, 1000, 1500], dt_schedule_scales=[0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=True, sigma=0.4, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', kernel='multiscale', bw_range=[0.2, 0.5, 0.9, 1.1, 1.3, 1.5, 2.0], optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 1314755728

Training model...

Saving initial model state to: out/model_training/model_facs_dec1b_2dpca_v10_20240711_153302/states/model_facs_dec1b_2dpca_v10_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.1132134222438892		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1132134222438892 | validation: 0.8720186797545193]
	TIME [epoch: 39.2 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v10_20240711_153302/states/model_facs_dec1b_2dpca_v10_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.9948725829314089		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9948725829314089 | validation: 0.8290172725233763]
	TIME [epoch: 10.2 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v10_20240711_153302/states/model_facs_dec1b_2dpca_v10_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.9540029742066406		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9540029742066406 | validation: 0.7920986523751365]
	TIME [epoch: 10.2 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v10_20240711_153302/states/model_facs_dec1b_2dpca_v10_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.9004335071625351		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9004335071625351 | validation: 0.7349101324377852]
	TIME [epoch: 10.2 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v10_20240711_153302/states/model_facs_dec1b_2dpca_v10_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7953501422928401		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7953501422928401 | validation: 0.7127769066300489]
	TIME [epoch: 10.2 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v10_20240711_153302/states/model_facs_dec1b_2dpca_v10_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7815652657943962		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7815652657943962 | validation: 0.6633580766584654]
	TIME [epoch: 10.2 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v10_20240711_153302/states/model_facs_dec1b_2dpca_v10_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7344080546645285		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7344080546645285 | validation: 0.6669252609974397]
	TIME [epoch: 10.2 sec]
EPOCH 8/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.723050122141039		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.723050122141039 | validation: 0.6545040273687233]
	TIME [epoch: 10.2 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v10_20240711_153302/states/model_facs_dec1b_2dpca_v10_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6331931057388329		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6331931057388329 | validation: 0.534722135062337]
	TIME [epoch: 10.2 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v10_20240711_153302/states/model_facs_dec1b_2dpca_v10_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6036604664077625		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6036604664077625 | validation: 0.6223712331809506]
	TIME [epoch: 10.2 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6255079458789307		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6255079458789307 | validation: 0.5551050080911196]
	TIME [epoch: 10.2 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5673733969309586		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5673733969309586 | validation: 0.5332577584734292]
	TIME [epoch: 10.2 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v10_20240711_153302/states/model_facs_dec1b_2dpca_v10_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5800194672365885		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5800194672365885 | validation: 0.5366216694727118]
	TIME [epoch: 10.2 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.49302629861551633		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.49302629861551633 | validation: 0.5764746494940018]
	TIME [epoch: 10.2 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6014383370276994		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6014383370276994 | validation: 0.6478067018763185]
	TIME [epoch: 10.2 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7206988737131661		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7206988737131661 | validation: 0.5165083163406942]
	TIME [epoch: 10.2 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v10_20240711_153302/states/model_facs_dec1b_2dpca_v10_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5474284859446173		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5474284859446173 | validation: 0.4587043672755266]
	TIME [epoch: 10.2 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v10_20240711_153302/states/model_facs_dec1b_2dpca_v10_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.508790662448896		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.508790662448896 | validation: 0.5548197793901812]
	TIME [epoch: 10.2 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6178260241944441		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6178260241944441 | validation: 0.43988959952330087]
	TIME [epoch: 10.2 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v10_20240711_153302/states/model_facs_dec1b_2dpca_v10_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4998461805434362		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4998461805434362 | validation: 0.43759596611282997]
	TIME [epoch: 10.2 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v10_20240711_153302/states/model_facs_dec1b_2dpca_v10_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5313048522283461		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5313048522283461 | validation: 0.48495918281286904]
	TIME [epoch: 10.2 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4787964993246374		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4787964993246374 | validation: 0.46129860560780767]
	TIME [epoch: 10.2 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4532746614869459		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4532746614869459 | validation: 0.45252386406992395]
	TIME [epoch: 10.2 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6183443890814287		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6183443890814287 | validation: 0.5216984173815298]
	TIME [epoch: 10.2 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5103962025097672		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5103962025097672 | validation: 0.44376851476415]
	TIME [epoch: 10.2 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.46338308307251364		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.46338308307251364 | validation: 0.5071397186972866]
	TIME [epoch: 10.2 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.49469512274321886		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.49469512274321886 | validation: 0.4655319053289425]
	TIME [epoch: 10.2 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.44981437782885586		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.44981437782885586 | validation: 0.4785878906100448]
	TIME [epoch: 10.2 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.45222993722659616		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.45222993722659616 | validation: 0.5579570240933304]
	TIME [epoch: 10.2 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.519159856457771		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.519159856457771 | validation: 0.5349350585317614]
	TIME [epoch: 10.2 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.45492636830392136		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.45492636830392136 | validation: 0.4372214833665531]
	TIME [epoch: 10.2 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v10_20240711_153302/states/model_facs_dec1b_2dpca_v10_31.pth
	Model improved!!!
EPOCH 32/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.48803920425044844		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.48803920425044844 | validation: 0.5313812029038271]
	TIME [epoch: 10.2 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5221904426900533		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5221904426900533 | validation: 0.4385091508543254]
	TIME [epoch: 10.2 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5296030072490875		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5296030072490875 | validation: 0.4478956225479364]
	TIME [epoch: 10.2 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5072351394267276		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5072351394267276 | validation: 0.43667586987815393]
	TIME [epoch: 10.2 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v10_20240711_153302/states/model_facs_dec1b_2dpca_v10_35.pth
	Model improved!!!
EPOCH 36/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.46884788601446226		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.46884788601446226 | validation: 0.5157984393395351]
	TIME [epoch: 10.5 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.563164394124992		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.563164394124992 | validation: 0.4060568692920746]
	TIME [epoch: 10.2 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v10_20240711_153302/states/model_facs_dec1b_2dpca_v10_37.pth
	Model improved!!!
EPOCH 38/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.43729509664117616		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.43729509664117616 | validation: 0.4339763552290002]
	TIME [epoch: 10.2 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.47454299248722936		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.47454299248722936 | validation: 0.4614110518872946]
	TIME [epoch: 10.2 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.43272654960035184		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.43272654960035184 | validation: 0.4941811718369845]
	TIME [epoch: 10.2 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.46846428079364316		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.46846428079364316 | validation: 0.5505014161160869]
	TIME [epoch: 10.2 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.47389901715541133		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.47389901715541133 | validation: 0.4639725382056869]
	TIME [epoch: 10.2 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.44651799134023673		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.44651799134023673 | validation: 0.4153975946269514]
	TIME [epoch: 10.2 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.43824330844068565		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.43824330844068565 | validation: 0.47070544251104207]
	TIME [epoch: 10.2 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4610924800205541		[learning rate: 0.0099823]
	Learning Rate: 0.0099823
	LOSS [training: 0.4610924800205541 | validation: 0.4133060172621268]
	TIME [epoch: 10.2 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.44486868175894645		[learning rate: 0.0099426]
	Learning Rate: 0.0099426
	LOSS [training: 0.44486868175894645 | validation: 0.462597054007135]
	TIME [epoch: 10.2 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.449405875022184		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 0.449405875022184 | validation: 0.3692784870967754]
	TIME [epoch: 10.2 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v10_20240711_153302/states/model_facs_dec1b_2dpca_v10_47.pth
	Model improved!!!
EPOCH 48/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4521415877648683		[learning rate: 0.0098637]
	Learning Rate: 0.00986367
	LOSS [training: 0.4521415877648683 | validation: 0.3826079977790721]
	TIME [epoch: 10.2 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.40485184319262735		[learning rate: 0.0098244]
	Learning Rate: 0.00982444
	LOSS [training: 0.40485184319262735 | validation: 0.3963345049353911]
	TIME [epoch: 10.2 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.44651757871395337		[learning rate: 0.0097854]
	Learning Rate: 0.00978536
	LOSS [training: 0.44651757871395337 | validation: 0.3808034301310496]
	TIME [epoch: 10.2 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.40094668370253866		[learning rate: 0.0097464]
	Learning Rate: 0.00974644
	LOSS [training: 0.40094668370253866 | validation: 0.5152379011931898]
	TIME [epoch: 10.2 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4576399420813304		[learning rate: 0.0097077]
	Learning Rate: 0.00970768
	LOSS [training: 0.4576399420813304 | validation: 0.4089396168140089]
	TIME [epoch: 10.2 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4152204667835366		[learning rate: 0.0096691]
	Learning Rate: 0.00966907
	LOSS [training: 0.4152204667835366 | validation: 0.46463384340139147]
	TIME [epoch: 10.2 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.41181200446437516		[learning rate: 0.0096306]
	Learning Rate: 0.00963061
	LOSS [training: 0.41181200446437516 | validation: 0.47123628363690157]
	TIME [epoch: 10.2 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5015363821673272		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 0.5015363821673272 | validation: 0.39287322274667746]
	TIME [epoch: 10.2 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4369714875535126		[learning rate: 0.0095542]
	Learning Rate: 0.00955415
	LOSS [training: 0.4369714875535126 | validation: 0.3703204375847941]
	TIME [epoch: 10.2 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3808693828480274		[learning rate: 0.0095162]
	Learning Rate: 0.00951616
	LOSS [training: 0.3808693828480274 | validation: 0.4197140675927905]
	TIME [epoch: 10.2 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4503240459494084		[learning rate: 0.0094783]
	Learning Rate: 0.00947831
	LOSS [training: 0.4503240459494084 | validation: 0.38811352943769173]
	TIME [epoch: 10.2 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.38569783632711385		[learning rate: 0.0094406]
	Learning Rate: 0.00944061
	LOSS [training: 0.38569783632711385 | validation: 0.4108119493874197]
	TIME [epoch: 10.2 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3894765008890746		[learning rate: 0.0094031]
	Learning Rate: 0.00940306
	LOSS [training: 0.3894765008890746 | validation: 0.3597544466875774]
	TIME [epoch: 10.2 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v10_20240711_153302/states/model_facs_dec1b_2dpca_v10_60.pth
	Model improved!!!
EPOCH 61/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.44976804909262413		[learning rate: 0.0093657]
	Learning Rate: 0.00936566
	LOSS [training: 0.44976804909262413 | validation: 0.4017259613361068]
	TIME [epoch: 10.2 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3741056431631676		[learning rate: 0.0093284]
	Learning Rate: 0.00932841
	LOSS [training: 0.3741056431631676 | validation: 0.3796808829453676]
	TIME [epoch: 10.2 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3820531615442767		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 0.3820531615442767 | validation: 0.4172074858577021]
	TIME [epoch: 10.2 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.39219134733806227		[learning rate: 0.0092544]
	Learning Rate: 0.00925435
	LOSS [training: 0.39219134733806227 | validation: 0.41689903631871567]
	TIME [epoch: 10.2 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.37162375333856007		[learning rate: 0.0092175]
	Learning Rate: 0.00921755
	LOSS [training: 0.37162375333856007 | validation: 0.40537432428340364]
	TIME [epoch: 10.2 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3830757530100426		[learning rate: 0.0091809]
	Learning Rate: 0.00918089
	LOSS [training: 0.3830757530100426 | validation: 0.35406781128122844]
	TIME [epoch: 10.2 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v10_20240711_153302/states/model_facs_dec1b_2dpca_v10_66.pth
	Model improved!!!
EPOCH 67/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3710517086271555		[learning rate: 0.0091444]
	Learning Rate: 0.00914437
	LOSS [training: 0.3710517086271555 | validation: 0.39973016539357986]
	TIME [epoch: 10.2 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3731803930191547		[learning rate: 0.009108]
	Learning Rate: 0.009108
	LOSS [training: 0.3731803930191547 | validation: 0.36218832113916466]
	TIME [epoch: 10.2 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.41774034229596385		[learning rate: 0.0090718]
	Learning Rate: 0.00907178
	LOSS [training: 0.41774034229596385 | validation: 0.37901188582337353]
	TIME [epoch: 10.2 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.375460847727005		[learning rate: 0.0090357]
	Learning Rate: 0.00903569
	LOSS [training: 0.375460847727005 | validation: 0.3515688079262696]
	TIME [epoch: 10.2 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v10_20240711_153302/states/model_facs_dec1b_2dpca_v10_70.pth
	Model improved!!!
EPOCH 71/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.34883889784197597		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 0.34883889784197597 | validation: 0.34976716525566715]
	TIME [epoch: 10.2 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v10_20240711_153302/states/model_facs_dec1b_2dpca_v10_71.pth
	Model improved!!!
EPOCH 72/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.36558744629588147		[learning rate: 0.008964]
	Learning Rate: 0.00896396
	LOSS [training: 0.36558744629588147 | validation: 0.3875038712931828]
	TIME [epoch: 10.2 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4128475960494188		[learning rate: 0.0089283]
	Learning Rate: 0.00892831
	LOSS [training: 0.4128475960494188 | validation: 0.34920699554720785]
	TIME [epoch: 10.2 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v10_20240711_153302/states/model_facs_dec1b_2dpca_v10_73.pth
	Model improved!!!
EPOCH 74/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4029108764912663		[learning rate: 0.0088928]
	Learning Rate: 0.0088928
	LOSS [training: 0.4029108764912663 | validation: 0.3388121761836468]
	TIME [epoch: 10.2 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v10_20240711_153302/states/model_facs_dec1b_2dpca_v10_74.pth
	Model improved!!!
EPOCH 75/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3955736319742078		[learning rate: 0.0088574]
	Learning Rate: 0.00885743
	LOSS [training: 0.3955736319742078 | validation: 0.46227758619485054]
	TIME [epoch: 10.3 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3580421550183161		[learning rate: 0.0088222]
	Learning Rate: 0.0088222
	LOSS [training: 0.3580421550183161 | validation: 0.33651214082998576]
	TIME [epoch: 10.2 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v10_20240711_153302/states/model_facs_dec1b_2dpca_v10_76.pth
	Model improved!!!
EPOCH 77/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.37785914152938704		[learning rate: 0.0087871]
	Learning Rate: 0.00878711
	LOSS [training: 0.37785914152938704 | validation: 0.38240531198921845]
	TIME [epoch: 10.2 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4840046196724636		[learning rate: 0.0087522]
	Learning Rate: 0.00875216
	LOSS [training: 0.4840046196724636 | validation: 0.3500322864482957]
	TIME [epoch: 10.2 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3309505823753638		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 0.3309505823753638 | validation: 0.35661898828016225]
	TIME [epoch: 10.2 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3646028839444612		[learning rate: 0.0086827]
	Learning Rate: 0.00868268
	LOSS [training: 0.3646028839444612 | validation: 0.33869713950118985]
	TIME [epoch: 10.2 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3372715232192798		[learning rate: 0.0086481]
	Learning Rate: 0.00864815
	LOSS [training: 0.3372715232192798 | validation: 0.3848038356403474]
	TIME [epoch: 10.2 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3843410819151276		[learning rate: 0.0086138]
	Learning Rate: 0.00861375
	LOSS [training: 0.3843410819151276 | validation: 0.3482124792292565]
	TIME [epoch: 10.2 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3546026250547189		[learning rate: 0.0085795]
	Learning Rate: 0.00857949
	LOSS [training: 0.3546026250547189 | validation: 0.3494953228255587]
	TIME [epoch: 10.2 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.35549090001887873		[learning rate: 0.0085454]
	Learning Rate: 0.00854537
	LOSS [training: 0.35549090001887873 | validation: 0.35410808362304536]
	TIME [epoch: 10.2 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3492254273602183		[learning rate: 0.0085114]
	Learning Rate: 0.00851138
	LOSS [training: 0.3492254273602183 | validation: 0.33217444433527443]
	TIME [epoch: 10.2 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v10_20240711_153302/states/model_facs_dec1b_2dpca_v10_85.pth
	Model improved!!!
EPOCH 86/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.36682579093656353		[learning rate: 0.0084775]
	Learning Rate: 0.00847753
	LOSS [training: 0.36682579093656353 | validation: 0.34020284747519186]
	TIME [epoch: 10.2 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3454372695544773		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 0.3454372695544773 | validation: 0.33390575421829494]
	TIME [epoch: 10.2 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32730302814988393		[learning rate: 0.0084102]
	Learning Rate: 0.00841023
	LOSS [training: 0.32730302814988393 | validation: 0.34122029186455227]
	TIME [epoch: 10.2 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.33738126043751726		[learning rate: 0.0083768]
	Learning Rate: 0.00837678
	LOSS [training: 0.33738126043751726 | validation: 0.35958087800818817]
	TIME [epoch: 10.2 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.36569296509787347		[learning rate: 0.0083435]
	Learning Rate: 0.00834346
	LOSS [training: 0.36569296509787347 | validation: 0.3154854789489707]
	TIME [epoch: 10.2 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v10_20240711_153302/states/model_facs_dec1b_2dpca_v10_90.pth
	Model improved!!!
EPOCH 91/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3543189748456196		[learning rate: 0.0083103]
	Learning Rate: 0.00831027
	LOSS [training: 0.3543189748456196 | validation: 0.378536094240406]
	TIME [epoch: 10.2 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.35871576049606957		[learning rate: 0.0082772]
	Learning Rate: 0.00827722
	LOSS [training: 0.35871576049606957 | validation: 0.3206353695933884]
	TIME [epoch: 10.2 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.33128847451208165		[learning rate: 0.0082443]
	Learning Rate: 0.0082443
	LOSS [training: 0.33128847451208165 | validation: 0.38569224869065794]
	TIME [epoch: 10.2 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.36105372874994757		[learning rate: 0.0082115]
	Learning Rate: 0.00821151
	LOSS [training: 0.36105372874994757 | validation: 0.32049102832722565]
	TIME [epoch: 10.2 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.33379542018077424		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 0.33379542018077424 | validation: 0.4623198914153061]
	TIME [epoch: 10.2 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.35765612229231636		[learning rate: 0.0081463]
	Learning Rate: 0.00814632
	LOSS [training: 0.35765612229231636 | validation: 0.35033560933543184]
	TIME [epoch: 10.2 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.33337507485666285		[learning rate: 0.0081139]
	Learning Rate: 0.00811392
	LOSS [training: 0.33337507485666285 | validation: 0.32699281833927774]
	TIME [epoch: 10.2 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3455316046988586		[learning rate: 0.0080816]
	Learning Rate: 0.00808165
	LOSS [training: 0.3455316046988586 | validation: 0.36622930061391457]
	TIME [epoch: 10.2 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.342723823335327		[learning rate: 0.0080495]
	Learning Rate: 0.00804951
	LOSS [training: 0.342723823335327 | validation: 0.3929929034695997]
	TIME [epoch: 10.2 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.33156812075728737		[learning rate: 0.0080175]
	Learning Rate: 0.00801749
	LOSS [training: 0.33156812075728737 | validation: 0.37146705819654524]
	TIME [epoch: 10.2 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3464559039329638		[learning rate: 0.0079856]
	Learning Rate: 0.0079856
	LOSS [training: 0.3464559039329638 | validation: 0.32060844881690154]
	TIME [epoch: 10.2 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3148817271132548		[learning rate: 0.0079538]
	Learning Rate: 0.00795384
	LOSS [training: 0.3148817271132548 | validation: 0.3153593334241377]
	TIME [epoch: 10.2 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v10_20240711_153302/states/model_facs_dec1b_2dpca_v10_102.pth
	Model improved!!!
EPOCH 103/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3316039868513012		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 0.3316039868513012 | validation: 0.41057325917388815]
	TIME [epoch: 10.2 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3182133326452587		[learning rate: 0.0078907]
	Learning Rate: 0.0078907
	LOSS [training: 0.3182133326452587 | validation: 0.30862751650715725]
	TIME [epoch: 10.2 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v10_20240711_153302/states/model_facs_dec1b_2dpca_v10_104.pth
	Model improved!!!
EPOCH 105/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3435498377079901		[learning rate: 0.0078593]
	Learning Rate: 0.00785931
	LOSS [training: 0.3435498377079901 | validation: 0.30142866765248716]
	TIME [epoch: 10.2 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v10_20240711_153302/states/model_facs_dec1b_2dpca_v10_105.pth
	Model improved!!!
EPOCH 106/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3052940320117458		[learning rate: 0.0078281]
	Learning Rate: 0.00782805
	LOSS [training: 0.3052940320117458 | validation: 0.32713619391401094]
	TIME [epoch: 10.3 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3477721388982796		[learning rate: 0.0077969]
	Learning Rate: 0.00779692
	LOSS [training: 0.3477721388982796 | validation: 0.4699888036199787]
	TIME [epoch: 10.2 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3661834799043673		[learning rate: 0.0077659]
	Learning Rate: 0.00776591
	LOSS [training: 0.3661834799043673 | validation: 0.3212803862289296]
	TIME [epoch: 10.2 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4123446973344081		[learning rate: 0.007735]
	Learning Rate: 0.00773502
	LOSS [training: 0.4123446973344081 | validation: 0.42977733415796016]
	TIME [epoch: 10.2 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.43715652538173133		[learning rate: 0.0077043]
	Learning Rate: 0.00770426
	LOSS [training: 0.43715652538173133 | validation: 0.3744738465031245]
	TIME [epoch: 10.2 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3535705273377973		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 0.3535705273377973 | validation: 0.3304091920417479]
	TIME [epoch: 10.2 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.34961307336222247		[learning rate: 0.0076431]
	Learning Rate: 0.00764309
	LOSS [training: 0.34961307336222247 | validation: 0.5295818454581117]
	TIME [epoch: 10.2 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.35843253172292383		[learning rate: 0.0076127]
	Learning Rate: 0.00761269
	LOSS [training: 0.35843253172292383 | validation: 0.3212389212548555]
	TIME [epoch: 10.2 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.30897871451258585		[learning rate: 0.0075824]
	Learning Rate: 0.00758242
	LOSS [training: 0.30897871451258585 | validation: 0.3623237149431603]
	TIME [epoch: 10.3 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.34221803331952766		[learning rate: 0.0075523]
	Learning Rate: 0.00755226
	LOSS [training: 0.34221803331952766 | validation: 0.3530280766127575]
	TIME [epoch: 10.2 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.31476029145884077		[learning rate: 0.0075222]
	Learning Rate: 0.00752222
	LOSS [training: 0.31476029145884077 | validation: 0.359186617346603]
	TIME [epoch: 10.2 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3406848842056326		[learning rate: 0.0074923]
	Learning Rate: 0.0074923
	LOSS [training: 0.3406848842056326 | validation: 0.34689102526676063]
	TIME [epoch: 10.3 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3045696747105131		[learning rate: 0.0074625]
	Learning Rate: 0.0074625
	LOSS [training: 0.3045696747105131 | validation: 0.32656425534591044]
	TIME [epoch: 10.2 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.358041012138119		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 0.358041012138119 | validation: 0.3120784286115761]
	TIME [epoch: 10.3 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.31094651857726396		[learning rate: 0.0074033]
	Learning Rate: 0.00740326
	LOSS [training: 0.31094651857726396 | validation: 0.3836292242637259]
	TIME [epoch: 10.2 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.304981697901356		[learning rate: 0.0073738]
	Learning Rate: 0.00737382
	LOSS [training: 0.304981697901356 | validation: 0.32641814597305235]
	TIME [epoch: 10.2 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3364848768454423		[learning rate: 0.0073445]
	Learning Rate: 0.00734449
	LOSS [training: 0.3364848768454423 | validation: 0.28839730720355516]
	TIME [epoch: 10.2 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v10_20240711_153302/states/model_facs_dec1b_2dpca_v10_122.pth
	Model improved!!!
EPOCH 123/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3008981482466188		[learning rate: 0.0073153]
	Learning Rate: 0.00731528
	LOSS [training: 0.3008981482466188 | validation: 0.3748034685357541]
	TIME [epoch: 10.3 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3601832493241806		[learning rate: 0.0072862]
	Learning Rate: 0.00728618
	LOSS [training: 0.3601832493241806 | validation: 0.36826158399898423]
	TIME [epoch: 10.2 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.34644234653992806		[learning rate: 0.0072572]
	Learning Rate: 0.0072572
	LOSS [training: 0.34644234653992806 | validation: 0.3156282246183245]
	TIME [epoch: 10.2 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3796513913585407		[learning rate: 0.0072283]
	Learning Rate: 0.00722834
	LOSS [training: 0.3796513913585407 | validation: 0.3730513602737512]
	TIME [epoch: 10.2 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2946511145923986		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 0.2946511145923986 | validation: 0.33257315212579697]
	TIME [epoch: 10.2 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3002597302359431		[learning rate: 0.007171]
	Learning Rate: 0.00717095
	LOSS [training: 0.3002597302359431 | validation: 0.3094001904821583]
	TIME [epoch: 10.2 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.28593847212879486		[learning rate: 0.0071424]
	Learning Rate: 0.00714243
	LOSS [training: 0.28593847212879486 | validation: 0.31777392877978605]
	TIME [epoch: 10.2 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3144141735670939		[learning rate: 0.007114]
	Learning Rate: 0.00711403
	LOSS [training: 0.3144141735670939 | validation: 0.33375860366078713]
	TIME [epoch: 10.2 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3747220908161351		[learning rate: 0.0070857]
	Learning Rate: 0.00708573
	LOSS [training: 0.3747220908161351 | validation: 0.2979937744090977]
	TIME [epoch: 10.2 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2822428965251844		[learning rate: 0.0070575]
	Learning Rate: 0.00705755
	LOSS [training: 0.2822428965251844 | validation: 0.2891094260494949]
	TIME [epoch: 10.3 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.300744588267327		[learning rate: 0.0070295]
	Learning Rate: 0.00702948
	LOSS [training: 0.300744588267327 | validation: 0.29725925858901314]
	TIME [epoch: 10.2 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.29255656117423295		[learning rate: 0.0070015]
	Learning Rate: 0.00700152
	LOSS [training: 0.29255656117423295 | validation: 0.3409770452724646]
	TIME [epoch: 10.2 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.33493478643858515		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 0.33493478643858515 | validation: 0.30472282114470006]
	TIME [epoch: 10.2 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5665454760514015		[learning rate: 0.0069459]
	Learning Rate: 0.00694594
	LOSS [training: 0.5665454760514015 | validation: 0.44420283432628394]
	TIME [epoch: 10.2 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4558641672319152		[learning rate: 0.0069183]
	Learning Rate: 0.00691831
	LOSS [training: 0.4558641672319152 | validation: 0.30680512965701245]
	TIME [epoch: 10.2 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3109793594075352		[learning rate: 0.0068908]
	Learning Rate: 0.00689079
	LOSS [training: 0.3109793594075352 | validation: 0.2809798977023072]
	TIME [epoch: 10.2 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v10_20240711_153302/states/model_facs_dec1b_2dpca_v10_138.pth
	Model improved!!!
EPOCH 139/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3148987225182285		[learning rate: 0.0068634]
	Learning Rate: 0.00686339
	LOSS [training: 0.3148987225182285 | validation: 0.3253228028084623]
	TIME [epoch: 10.2 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.30033155090136576		[learning rate: 0.0068361]
	Learning Rate: 0.00683609
	LOSS [training: 0.30033155090136576 | validation: 0.3109188512756809]
	TIME [epoch: 10.2 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2863646218847859		[learning rate: 0.0068089]
	Learning Rate: 0.0068089
	LOSS [training: 0.2863646218847859 | validation: 0.2775167827487034]
	TIME [epoch: 10.2 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v10_20240711_153302/states/model_facs_dec1b_2dpca_v10_141.pth
	Model improved!!!
EPOCH 142/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.28329850258888123		[learning rate: 0.0067818]
	Learning Rate: 0.00678182
	LOSS [training: 0.28329850258888123 | validation: 0.2890370268401626]
	TIME [epoch: 10.2 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.30110182516885425		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 0.30110182516885425 | validation: 0.34374951221525574]
	TIME [epoch: 10.2 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.31188702871522966		[learning rate: 0.006728]
	Learning Rate: 0.00672798
	LOSS [training: 0.31188702871522966 | validation: 0.3604129406451223]
	TIME [epoch: 10.2 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4047536349595455		[learning rate: 0.0067012]
	Learning Rate: 0.00670122
	LOSS [training: 0.4047536349595455 | validation: 0.3885458509202749]
	TIME [epoch: 10.2 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3610109543388833		[learning rate: 0.0066746]
	Learning Rate: 0.00667457
	LOSS [training: 0.3610109543388833 | validation: 0.31276732562840726]
	TIME [epoch: 10.2 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.34326255326462785		[learning rate: 0.006648]
	Learning Rate: 0.00664802
	LOSS [training: 0.34326255326462785 | validation: 0.31269315929229796]
	TIME [epoch: 10.2 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3172831426087136		[learning rate: 0.0066216]
	Learning Rate: 0.00662158
	LOSS [training: 0.3172831426087136 | validation: 0.35788123520528464]
	TIME [epoch: 10.2 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3473422698122858		[learning rate: 0.0065952]
	Learning Rate: 0.00659524
	LOSS [training: 0.3473422698122858 | validation: 0.2942841982195976]
	TIME [epoch: 10.2 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.31638204071529574		[learning rate: 0.006569]
	Learning Rate: 0.00656901
	LOSS [training: 0.31638204071529574 | validation: 0.2994464583869364]
	TIME [epoch: 10.2 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3113294586927321		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 0.3113294586927321 | validation: 0.33241384435610777]
	TIME [epoch: 10.2 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32267380257396155		[learning rate: 0.0065169]
	Learning Rate: 0.00651686
	LOSS [training: 0.32267380257396155 | validation: 0.3021041287700266]
	TIME [epoch: 10.2 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.30837505344591254		[learning rate: 0.0064909]
	Learning Rate: 0.00649094
	LOSS [training: 0.30837505344591254 | validation: 0.29860722891984987]
	TIME [epoch: 10.2 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.30292798831311657		[learning rate: 0.0064651]
	Learning Rate: 0.00646512
	LOSS [training: 0.30292798831311657 | validation: 0.35972047244502325]
	TIME [epoch: 10.2 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.35490473337509854		[learning rate: 0.0064394]
	Learning Rate: 0.00643941
	LOSS [training: 0.35490473337509854 | validation: 0.3138185941375071]
	TIME [epoch: 10.2 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3043413408848858		[learning rate: 0.0064138]
	Learning Rate: 0.0064138
	LOSS [training: 0.3043413408848858 | validation: 0.2981243909000147]
	TIME [epoch: 10.2 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.30406538785138476		[learning rate: 0.0063883]
	Learning Rate: 0.00638829
	LOSS [training: 0.30406538785138476 | validation: 0.3134286138541025]
	TIME [epoch: 10.2 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3036285716823024		[learning rate: 0.0063629]
	Learning Rate: 0.00636288
	LOSS [training: 0.3036285716823024 | validation: 0.3004827897601034]
	TIME [epoch: 10.2 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3074391741091706		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 0.3074391741091706 | validation: 0.3042532543631357]
	TIME [epoch: 10.2 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2877877228901713		[learning rate: 0.0063124]
	Learning Rate: 0.00631237
	LOSS [training: 0.2877877228901713 | validation: 0.3032628943358841]
	TIME [epoch: 10.2 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3130089278741331		[learning rate: 0.0062873]
	Learning Rate: 0.00628726
	LOSS [training: 0.3130089278741331 | validation: 0.3390574487918204]
	TIME [epoch: 10.2 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2912852227360865		[learning rate: 0.0062623]
	Learning Rate: 0.00626226
	LOSS [training: 0.2912852227360865 | validation: 0.3346623191776691]
	TIME [epoch: 10.2 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.29033417512342735		[learning rate: 0.0062373]
	Learning Rate: 0.00623735
	LOSS [training: 0.29033417512342735 | validation: 0.3038770456560365]
	TIME [epoch: 10.2 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3042458693525758		[learning rate: 0.0062125]
	Learning Rate: 0.00621254
	LOSS [training: 0.3042458693525758 | validation: 0.28843901410210904]
	TIME [epoch: 10.2 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2977582909352334		[learning rate: 0.0061878]
	Learning Rate: 0.00618783
	LOSS [training: 0.2977582909352334 | validation: 0.30824276839984766]
	TIME [epoch: 10.2 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3424976185873861		[learning rate: 0.0061632]
	Learning Rate: 0.00616322
	LOSS [training: 0.3424976185873861 | validation: 0.30312568711782545]
	TIME [epoch: 10.2 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.33939220053273494		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 0.33939220053273494 | validation: 0.2791970792878698]
	TIME [epoch: 10.2 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.30615646495806964		[learning rate: 0.0061143]
	Learning Rate: 0.00611429
	LOSS [training: 0.30615646495806964 | validation: 0.2887186919629457]
	TIME [epoch: 10.2 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2977008534224495		[learning rate: 0.00609]
	Learning Rate: 0.00608997
	LOSS [training: 0.2977008534224495 | validation: 0.33448934130287267]
	TIME [epoch: 10.2 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3470334562710493		[learning rate: 0.0060658]
	Learning Rate: 0.00606575
	LOSS [training: 0.3470334562710493 | validation: 0.3474103587930453]
	TIME [epoch: 10.2 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3067871424326669		[learning rate: 0.0060416]
	Learning Rate: 0.00604163
	LOSS [training: 0.3067871424326669 | validation: 0.3040886473422549]
	TIME [epoch: 10.2 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.287613009340239		[learning rate: 0.0060176]
	Learning Rate: 0.0060176
	LOSS [training: 0.287613009340239 | validation: 0.29671160985142164]
	TIME [epoch: 10.2 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.30301298144952526		[learning rate: 0.0059937]
	Learning Rate: 0.00599366
	LOSS [training: 0.30301298144952526 | validation: 0.2814415438736806]
	TIME [epoch: 10.2 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.27858906065538624		[learning rate: 0.0059698]
	Learning Rate: 0.00596982
	LOSS [training: 0.27858906065538624 | validation: 0.3795367405538076]
	TIME [epoch: 10.2 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.37443808591190897		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 0.37443808591190897 | validation: 0.31536786629014674]
	TIME [epoch: 10.2 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2932714382568585		[learning rate: 0.0059224]
	Learning Rate: 0.00592243
	LOSS [training: 0.2932714382568585 | validation: 0.2918197188454134]
	TIME [epoch: 10.2 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.28233711655915533		[learning rate: 0.0058989]
	Learning Rate: 0.00589888
	LOSS [training: 0.28233711655915533 | validation: 0.2866188887000925]
	TIME [epoch: 10.2 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2830253170302936		[learning rate: 0.0058754]
	Learning Rate: 0.00587541
	LOSS [training: 0.2830253170302936 | validation: 0.29346608028685567]
	TIME [epoch: 10.2 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2905409880516854		[learning rate: 0.005852]
	Learning Rate: 0.00585205
	LOSS [training: 0.2905409880516854 | validation: 0.30833590976267733]
	TIME [epoch: 10.2 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.28924206972721955		[learning rate: 0.0058288]
	Learning Rate: 0.00582877
	LOSS [training: 0.28924206972721955 | validation: 0.3310297028515462]
	TIME [epoch: 10.2 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.28293125812263625		[learning rate: 0.0058056]
	Learning Rate: 0.00580559
	LOSS [training: 0.28293125812263625 | validation: 0.32935628521439175]
	TIME [epoch: 10.2 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2739678268222747		[learning rate: 0.0057825]
	Learning Rate: 0.0057825
	LOSS [training: 0.2739678268222747 | validation: 0.2886803709072038]
	TIME [epoch: 10.2 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.27250710632487385		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 0.27250710632487385 | validation: 0.3236494991792406]
	TIME [epoch: 10.2 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3282437040239722		[learning rate: 0.0057366]
	Learning Rate: 0.00573659
	LOSS [training: 0.3282437040239722 | validation: 0.3108188310258093]
	TIME [epoch: 10.3 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.29512797646329036		[learning rate: 0.0057138]
	Learning Rate: 0.00571377
	LOSS [training: 0.29512797646329036 | validation: 0.28198950051111]
	TIME [epoch: 10.2 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2815334578430951		[learning rate: 0.005691]
	Learning Rate: 0.00569105
	LOSS [training: 0.2815334578430951 | validation: 0.27425161279171384]
	TIME [epoch: 10.2 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v10_20240711_153302/states/model_facs_dec1b_2dpca_v10_186.pth
	Model improved!!!
EPOCH 187/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.27929478358504023		[learning rate: 0.0056684]
	Learning Rate: 0.00566841
	LOSS [training: 0.27929478358504023 | validation: 0.31140755300758577]
	TIME [epoch: 10.2 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.30001326676749573		[learning rate: 0.0056459]
	Learning Rate: 0.00564587
	LOSS [training: 0.30001326676749573 | validation: 0.2969003081105994]
	TIME [epoch: 10.2 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2927458152540516		[learning rate: 0.0056234]
	Learning Rate: 0.00562341
	LOSS [training: 0.2927458152540516 | validation: 0.31773213817981594]
	TIME [epoch: 10.2 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.301436876025976		[learning rate: 0.005601]
	Learning Rate: 0.00560105
	LOSS [training: 0.301436876025976 | validation: 0.30516249637505044]
	TIME [epoch: 10.2 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3090222928710062		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 0.3090222928710062 | validation: 0.2759362018351094]
	TIME [epoch: 10.2 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.29144987125214783		[learning rate: 0.0055566]
	Learning Rate: 0.00555658
	LOSS [training: 0.29144987125214783 | validation: 0.3088065809209118]
	TIME [epoch: 10.2 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3063861304193592		[learning rate: 0.0055345]
	Learning Rate: 0.00553448
	LOSS [training: 0.3063861304193592 | validation: 0.3079901906787893]
	TIME [epoch: 10.2 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.29252158070692963		[learning rate: 0.0055125]
	Learning Rate: 0.00551247
	LOSS [training: 0.29252158070692963 | validation: 0.3070396638931125]
	TIME [epoch: 10.2 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3570767996264734		[learning rate: 0.0054905]
	Learning Rate: 0.00549054
	LOSS [training: 0.3570767996264734 | validation: 0.3073474905188191]
	TIME [epoch: 10.2 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3241362141924921		[learning rate: 0.0054687]
	Learning Rate: 0.00546871
	LOSS [training: 0.3241362141924921 | validation: 0.28496475391744863]
	TIME [epoch: 10.2 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.343742447513629		[learning rate: 0.005447]
	Learning Rate: 0.00544696
	LOSS [training: 0.343742447513629 | validation: 0.29158435343518574]
	TIME [epoch: 10.2 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.298653451662959		[learning rate: 0.0054253]
	Learning Rate: 0.00542529
	LOSS [training: 0.298653451662959 | validation: 0.3461011697226379]
	TIME [epoch: 10.2 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.33681978571167187		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 0.33681978571167187 | validation: 0.2882517881081089]
	TIME [epoch: 10.2 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.29705102523858495		[learning rate: 0.0053822]
	Learning Rate: 0.00538222
	LOSS [training: 0.29705102523858495 | validation: 0.33197384386077955]
	TIME [epoch: 10.2 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.27321204018789036		[learning rate: 0.0053608]
	Learning Rate: 0.00536081
	LOSS [training: 0.27321204018789036 | validation: 0.3343596136747453]
	TIME [epoch: 10.2 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2899070158257783		[learning rate: 0.0053395]
	Learning Rate: 0.00533949
	LOSS [training: 0.2899070158257783 | validation: 0.2875054865622225]
	TIME [epoch: 10.2 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.28646505219375906		[learning rate: 0.0053183]
	Learning Rate: 0.00531826
	LOSS [training: 0.28646505219375906 | validation: 0.3970472079750458]
	TIME [epoch: 10.2 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.28893326758628823		[learning rate: 0.0052971]
	Learning Rate: 0.0052971
	LOSS [training: 0.28893326758628823 | validation: 0.2903001009217905]
	TIME [epoch: 10.2 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.30231571635529275		[learning rate: 0.005276]
	Learning Rate: 0.00527604
	LOSS [training: 0.30231571635529275 | validation: 0.28971883624369366]
	TIME [epoch: 10.2 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.279624080620779		[learning rate: 0.0052551]
	Learning Rate: 0.00525505
	LOSS [training: 0.279624080620779 | validation: 0.2981393441571384]
	TIME [epoch: 10.2 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.29192481909899265		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 0.29192481909899265 | validation: 0.43619401310071526]
	TIME [epoch: 10.2 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4018928527785318		[learning rate: 0.0052133]
	Learning Rate: 0.00521333
	LOSS [training: 0.4018928527785318 | validation: 0.2866713369113604]
	TIME [epoch: 10.2 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.28983870860914807		[learning rate: 0.0051926]
	Learning Rate: 0.0051926
	LOSS [training: 0.28983870860914807 | validation: 0.2756589951789676]
	TIME [epoch: 10.2 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.27581907117900595		[learning rate: 0.0051719]
	Learning Rate: 0.00517194
	LOSS [training: 0.27581907117900595 | validation: 0.28347307609309896]
	TIME [epoch: 10.2 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.27442969454884186		[learning rate: 0.0051514]
	Learning Rate: 0.00515137
	LOSS [training: 0.27442969454884186 | validation: 0.294950126962515]
	TIME [epoch: 10.2 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.271441093287393		[learning rate: 0.0051309]
	Learning Rate: 0.00513089
	LOSS [training: 0.271441093287393 | validation: 0.2835106849667655]
	TIME [epoch: 10.2 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.27152365622908536		[learning rate: 0.0051105]
	Learning Rate: 0.00511048
	LOSS [training: 0.27152365622908536 | validation: 0.28681379817242875]
	TIME [epoch: 10.2 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3298238824925439		[learning rate: 0.0050902]
	Learning Rate: 0.00509015
	LOSS [training: 0.3298238824925439 | validation: 0.2699258360851279]
	TIME [epoch: 10.2 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v10_20240711_153302/states/model_facs_dec1b_2dpca_v10_214.pth
	Model improved!!!
EPOCH 215/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3321392363691205		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 0.3321392363691205 | validation: 0.29153675780929256]
	TIME [epoch: 10.2 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2974736260186443		[learning rate: 0.0050497]
	Learning Rate: 0.00504974
	LOSS [training: 0.2974736260186443 | validation: 0.2755189929366364]
	TIME [epoch: 10.2 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2859082571818648		[learning rate: 0.0050297]
	Learning Rate: 0.00502966
	LOSS [training: 0.2859082571818648 | validation: 0.27211556423564853]
	TIME [epoch: 10.2 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2839027604084704		[learning rate: 0.0050097]
	Learning Rate: 0.00500965
	LOSS [training: 0.2839027604084704 | validation: 0.2840547070207276]
	TIME [epoch: 10.2 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2974619126916379		[learning rate: 0.0049897]
	Learning Rate: 0.00498973
	LOSS [training: 0.2974619126916379 | validation: 0.28893850158869794]
	TIME [epoch: 10.2 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.28783917498113293		[learning rate: 0.0049699]
	Learning Rate: 0.00496988
	LOSS [training: 0.28783917498113293 | validation: 0.29927528868846975]
	TIME [epoch: 10.2 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3193368042067556		[learning rate: 0.0049501]
	Learning Rate: 0.00495012
	LOSS [training: 0.3193368042067556 | validation: 0.3146386094337402]
	TIME [epoch: 10.2 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32308841745446953		[learning rate: 0.0049304]
	Learning Rate: 0.00493043
	LOSS [training: 0.32308841745446953 | validation: 0.28745090286940583]
	TIME [epoch: 10.2 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2809476814142924		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 0.2809476814142924 | validation: 0.27715140746968103]
	TIME [epoch: 10.2 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2893063853400564		[learning rate: 0.0048913]
	Learning Rate: 0.00489129
	LOSS [training: 0.2893063853400564 | validation: 0.2837920669971874]
	TIME [epoch: 10.2 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3049493657846994		[learning rate: 0.0048718]
	Learning Rate: 0.00487183
	LOSS [training: 0.3049493657846994 | validation: 0.27869928595885474]
	TIME [epoch: 10.2 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.30322679501812666		[learning rate: 0.0048525]
	Learning Rate: 0.00485245
	LOSS [training: 0.30322679501812666 | validation: 0.2773634615570228]
	TIME [epoch: 10.2 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2980429631035067		[learning rate: 0.0048332]
	Learning Rate: 0.00483316
	LOSS [training: 0.2980429631035067 | validation: 0.31413856889573405]
	TIME [epoch: 10.2 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.31574396501655194		[learning rate: 0.0048139]
	Learning Rate: 0.00481393
	LOSS [training: 0.31574396501655194 | validation: 0.26886334867158934]
	TIME [epoch: 10.2 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v10_20240711_153302/states/model_facs_dec1b_2dpca_v10_228.pth
	Model improved!!!
EPOCH 229/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2986823241631514		[learning rate: 0.0047948]
	Learning Rate: 0.00479479
	LOSS [training: 0.2986823241631514 | validation: 0.2686069656270637]
	TIME [epoch: 10.2 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v10_20240711_153302/states/model_facs_dec1b_2dpca_v10_229.pth
	Model improved!!!
EPOCH 230/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3079658646264568		[learning rate: 0.0047757]
	Learning Rate: 0.00477572
	LOSS [training: 0.3079658646264568 | validation: 0.3589076132468313]
	TIME [epoch: 10.3 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3865471208808302		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.3865471208808302 | validation: 0.29549725409953165]
	TIME [epoch: 10.3 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.28527618176465336		[learning rate: 0.0047378]
	Learning Rate: 0.0047378
	LOSS [training: 0.28527618176465336 | validation: 0.280599531764127]
	TIME [epoch: 10.2 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.293892662598666		[learning rate: 0.004719]
	Learning Rate: 0.00471896
	LOSS [training: 0.293892662598666 | validation: 0.3027942105827569]
	TIME [epoch: 10.3 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.28535250854171706		[learning rate: 0.0047002]
	Learning Rate: 0.00470019
	LOSS [training: 0.28535250854171706 | validation: 0.29557389998737305]
	TIME [epoch: 10.2 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2678810783166104		[learning rate: 0.0046815]
	Learning Rate: 0.0046815
	LOSS [training: 0.2678810783166104 | validation: 0.2602955802847246]
	TIME [epoch: 10.2 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v10_20240711_153302/states/model_facs_dec1b_2dpca_v10_235.pth
	Model improved!!!
EPOCH 236/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.29673763839292694		[learning rate: 0.0046629]
	Learning Rate: 0.00466288
	LOSS [training: 0.29673763839292694 | validation: 0.301943579999966]
	TIME [epoch: 10.2 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.28202605381778023		[learning rate: 0.0046443]
	Learning Rate: 0.00464433
	LOSS [training: 0.28202605381778023 | validation: 0.27911121249062876]
	TIME [epoch: 10.2 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2802971078139353		[learning rate: 0.0046259]
	Learning Rate: 0.00462586
	LOSS [training: 0.2802971078139353 | validation: 0.2925592696233935]
	TIME [epoch: 10.2 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3092114107963381		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 0.3092114107963381 | validation: 0.2678036077088213]
	TIME [epoch: 10.2 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.29174141889674204		[learning rate: 0.0045891]
	Learning Rate: 0.00458913
	LOSS [training: 0.29174141889674204 | validation: 0.2980004801627718]
	TIME [epoch: 10.2 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.27472212996739737		[learning rate: 0.0045709]
	Learning Rate: 0.00457088
	LOSS [training: 0.27472212996739737 | validation: 0.27436277046505914]
	TIME [epoch: 10.2 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26430778411568223		[learning rate: 0.0045527]
	Learning Rate: 0.0045527
	LOSS [training: 0.26430778411568223 | validation: 0.324705637141995]
	TIME [epoch: 10.2 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2831510303933069		[learning rate: 0.0045346]
	Learning Rate: 0.00453459
	LOSS [training: 0.2831510303933069 | validation: 0.274845149459372]
	TIME [epoch: 10.2 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25592558303300333		[learning rate: 0.0045166]
	Learning Rate: 0.00451656
	LOSS [training: 0.25592558303300333 | validation: 0.28053776867709584]
	TIME [epoch: 10.2 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2759439787401235		[learning rate: 0.0044986]
	Learning Rate: 0.0044986
	LOSS [training: 0.2759439787401235 | validation: 0.2734464107467899]
	TIME [epoch: 10.2 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3057319140594245		[learning rate: 0.0044807]
	Learning Rate: 0.0044807
	LOSS [training: 0.3057319140594245 | validation: 0.30162088985005964]
	TIME [epoch: 10.2 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.28734471875052936		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 0.28734471875052936 | validation: 0.2733221533239065]
	TIME [epoch: 10.2 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3048392199912258		[learning rate: 0.0044451]
	Learning Rate: 0.00444513
	LOSS [training: 0.3048392199912258 | validation: 0.3415286145924278]
	TIME [epoch: 10.2 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3018952871666087		[learning rate: 0.0044275]
	Learning Rate: 0.00442745
	LOSS [training: 0.3018952871666087 | validation: 0.2991604189002605]
	TIME [epoch: 10.2 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.29280502043644596		[learning rate: 0.0044098]
	Learning Rate: 0.00440984
	LOSS [training: 0.29280502043644596 | validation: 0.2639009034396661]
	TIME [epoch: 10.2 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.31825351200457397		[learning rate: 0.0043923]
	Learning Rate: 0.0043923
	LOSS [training: 0.31825351200457397 | validation: 0.37301305260812506]
	TIME [epoch: 10.2 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.31071600289807755		[learning rate: 0.0043748]
	Learning Rate: 0.00437483
	LOSS [training: 0.31071600289807755 | validation: 0.31211089196618397]
	TIME [epoch: 10.2 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2949653582885706		[learning rate: 0.0043574]
	Learning Rate: 0.00435743
	LOSS [training: 0.2949653582885706 | validation: 0.3127284341868218]
	TIME [epoch: 10.2 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2799015963338865		[learning rate: 0.0043401]
	Learning Rate: 0.0043401
	LOSS [training: 0.2799015963338865 | validation: 0.28930479059846814]
	TIME [epoch: 10.2 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2806953190442221		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 0.2806953190442221 | validation: 0.33984722616390306]
	TIME [epoch: 10.2 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2845215430643862		[learning rate: 0.0043056]
	Learning Rate: 0.00430565
	LOSS [training: 0.2845215430643862 | validation: 0.2754564495440147]
	TIME [epoch: 10.2 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26151957086318156		[learning rate: 0.0042885]
	Learning Rate: 0.00428852
	LOSS [training: 0.26151957086318156 | validation: 0.28420713542222437]
	TIME [epoch: 10.2 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26903512211915914		[learning rate: 0.0042715]
	Learning Rate: 0.00427147
	LOSS [training: 0.26903512211915914 | validation: 0.2711199486503865]
	TIME [epoch: 10.2 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.272721357946353		[learning rate: 0.0042545]
	Learning Rate: 0.00425448
	LOSS [training: 0.272721357946353 | validation: 0.30012216965674676]
	TIME [epoch: 10.2 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26195682525769914		[learning rate: 0.0042376]
	Learning Rate: 0.00423756
	LOSS [training: 0.26195682525769914 | validation: 0.32911192981262716]
	TIME [epoch: 10.3 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.29472415678308983		[learning rate: 0.0042207]
	Learning Rate: 0.0042207
	LOSS [training: 0.29472415678308983 | validation: 0.2690567912063034]
	TIME [epoch: 10.2 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26165107212138977		[learning rate: 0.0042039]
	Learning Rate: 0.00420391
	LOSS [training: 0.26165107212138977 | validation: 0.3041447492629341]
	TIME [epoch: 10.2 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26690545535455223		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 0.26690545535455223 | validation: 0.2613180778989368]
	TIME [epoch: 10.2 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.266336846140635		[learning rate: 0.0041705]
	Learning Rate: 0.00417054
	LOSS [training: 0.266336846140635 | validation: 0.2746999039238455]
	TIME [epoch: 10.2 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2865917735910222		[learning rate: 0.004154]
	Learning Rate: 0.00415395
	LOSS [training: 0.2865917735910222 | validation: 0.26334804075198365]
	TIME [epoch: 10.2 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.27017686591281453		[learning rate: 0.0041374]
	Learning Rate: 0.00413743
	LOSS [training: 0.27017686591281453 | validation: 0.2666675545735634]
	TIME [epoch: 10.2 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2822908180168053		[learning rate: 0.004121]
	Learning Rate: 0.00412098
	LOSS [training: 0.2822908180168053 | validation: 0.27494421898246746]
	TIME [epoch: 10.2 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3410266704030961		[learning rate: 0.0041046]
	Learning Rate: 0.00410458
	LOSS [training: 0.3410266704030961 | validation: 0.28428636281357134]
	TIME [epoch: 10.2 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2717954047904875		[learning rate: 0.0040883]
	Learning Rate: 0.00408826
	LOSS [training: 0.2717954047904875 | validation: 0.2642167581044764]
	TIME [epoch: 10.2 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2720435728998742		[learning rate: 0.004072]
	Learning Rate: 0.004072
	LOSS [training: 0.2720435728998742 | validation: 0.2585425429925235]
	TIME [epoch: 10.2 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v10_20240711_153302/states/model_facs_dec1b_2dpca_v10_270.pth
	Model improved!!!
EPOCH 271/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3029324723869945		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.3029324723869945 | validation: 0.2724909717686545]
	TIME [epoch: 10.2 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3491693888645059		[learning rate: 0.0040397]
	Learning Rate: 0.00403967
	LOSS [training: 0.3491693888645059 | validation: 0.3737173816028011]
	TIME [epoch: 10.2 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.38198426010513026		[learning rate: 0.0040236]
	Learning Rate: 0.00402361
	LOSS [training: 0.38198426010513026 | validation: 0.2766728361865645]
	TIME [epoch: 10.2 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.27605448083139905		[learning rate: 0.0040076]
	Learning Rate: 0.0040076
	LOSS [training: 0.27605448083139905 | validation: 0.26844108771063857]
	TIME [epoch: 10.2 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2769687317883552		[learning rate: 0.0039917]
	Learning Rate: 0.00399166
	LOSS [training: 0.2769687317883552 | validation: 0.2949196141111146]
	TIME [epoch: 10.2 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.27738344198186		[learning rate: 0.0039758]
	Learning Rate: 0.00397579
	LOSS [training: 0.27738344198186 | validation: 0.28668360188362063]
	TIME [epoch: 10.2 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.29886611606228924		[learning rate: 0.00396]
	Learning Rate: 0.00395997
	LOSS [training: 0.29886611606228924 | validation: 0.282711313984804]
	TIME [epoch: 10.2 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.29510443469055775		[learning rate: 0.0039442]
	Learning Rate: 0.00394422
	LOSS [training: 0.29510443469055775 | validation: 0.2898348317554145]
	TIME [epoch: 10.2 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2833421578328723		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 0.2833421578328723 | validation: 0.2588796033087243]
	TIME [epoch: 10.2 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2957846676937775		[learning rate: 0.0039129]
	Learning Rate: 0.00391291
	LOSS [training: 0.2957846676937775 | validation: 0.2840529675256994]
	TIME [epoch: 10.2 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2604470620728121		[learning rate: 0.0038973]
	Learning Rate: 0.00389735
	LOSS [training: 0.2604470620728121 | validation: 0.2661433116360353]
	TIME [epoch: 10.2 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2800434051373019		[learning rate: 0.0038818]
	Learning Rate: 0.00388185
	LOSS [training: 0.2800434051373019 | validation: 0.2808878159392965]
	TIME [epoch: 10.2 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2605553281898968		[learning rate: 0.0038664]
	Learning Rate: 0.00386641
	LOSS [training: 0.2605553281898968 | validation: 0.3004192849721953]
	TIME [epoch: 10.2 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2759203118312116		[learning rate: 0.003851]
	Learning Rate: 0.00385103
	LOSS [training: 0.2759203118312116 | validation: 0.2871665222666442]
	TIME [epoch: 10.2 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2952507020555507		[learning rate: 0.0038357]
	Learning Rate: 0.00383571
	LOSS [training: 0.2952507020555507 | validation: 0.3008900622957807]
	TIME [epoch: 10.2 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3026278873274373		[learning rate: 0.0038205]
	Learning Rate: 0.00382046
	LOSS [training: 0.3026278873274373 | validation: 0.2873100228606541]
	TIME [epoch: 10.3 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2765841224056829		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 0.2765841224056829 | validation: 0.28088003588118216]
	TIME [epoch: 10.2 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.27882321900627005		[learning rate: 0.0037901]
	Learning Rate: 0.00379013
	LOSS [training: 0.27882321900627005 | validation: 0.2916508831608199]
	TIME [epoch: 10.2 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2741392432949837		[learning rate: 0.0037751]
	Learning Rate: 0.00377505
	LOSS [training: 0.2741392432949837 | validation: 0.2643908207501346]
	TIME [epoch: 10.2 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26195015058580584		[learning rate: 0.00376]
	Learning Rate: 0.00376004
	LOSS [training: 0.26195015058580584 | validation: 0.2969214828981494]
	TIME [epoch: 10.2 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2664415823555681		[learning rate: 0.0037451]
	Learning Rate: 0.00374508
	LOSS [training: 0.2664415823555681 | validation: 0.2604184722475763]
	TIME [epoch: 10.2 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.27444169584592326		[learning rate: 0.0037302]
	Learning Rate: 0.00373019
	LOSS [training: 0.27444169584592326 | validation: 0.27608866464803267]
	TIME [epoch: 10.2 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2426203569721866		[learning rate: 0.0037154]
	Learning Rate: 0.00371535
	LOSS [training: 0.2426203569721866 | validation: 0.26522025342822125]
	TIME [epoch: 10.2 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25641950862333796		[learning rate: 0.0037006]
	Learning Rate: 0.00370058
	LOSS [training: 0.25641950862333796 | validation: 0.2852781648479607]
	TIME [epoch: 10.2 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2657786726010507		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 0.2657786726010507 | validation: 0.30661355866104856]
	TIME [epoch: 10.2 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.27918672980738396		[learning rate: 0.0036712]
	Learning Rate: 0.0036712
	LOSS [training: 0.27918672980738396 | validation: 0.2790849756866379]
	TIME [epoch: 10.2 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2652824479208031		[learning rate: 0.0036566]
	Learning Rate: 0.0036566
	LOSS [training: 0.2652824479208031 | validation: 0.27734690379418814]
	TIME [epoch: 10.2 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.255405890931979		[learning rate: 0.0036421]
	Learning Rate: 0.00364205
	LOSS [training: 0.255405890931979 | validation: 0.26029076256299455]
	TIME [epoch: 10.2 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2675117256366415		[learning rate: 0.0036276]
	Learning Rate: 0.00362757
	LOSS [training: 0.2675117256366415 | validation: 0.2862059866977491]
	TIME [epoch: 10.2 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2759098351505218		[learning rate: 0.0036131]
	Learning Rate: 0.00361314
	LOSS [training: 0.2759098351505218 | validation: 0.25660791116464576]
	TIME [epoch: 10.2 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v10_20240711_153302/states/model_facs_dec1b_2dpca_v10_300.pth
	Model improved!!!
EPOCH 301/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.261656026105355		[learning rate: 0.0035988]
	Learning Rate: 0.00359877
	LOSS [training: 0.261656026105355 | validation: 0.26005473210244767]
	TIME [epoch: 10.2 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2706057175904385		[learning rate: 0.0035845]
	Learning Rate: 0.00358445
	LOSS [training: 0.2706057175904385 | validation: 0.27259609979345195]
	TIME [epoch: 10.2 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2722744606448859		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 0.2722744606448859 | validation: 0.25772314576289856]
	TIME [epoch: 10.2 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26472838464146164		[learning rate: 0.003556]
	Learning Rate: 0.003556
	LOSS [training: 0.26472838464146164 | validation: 0.27241206490700853]
	TIME [epoch: 10.3 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2645126221175068		[learning rate: 0.0035419]
	Learning Rate: 0.00354185
	LOSS [training: 0.2645126221175068 | validation: 0.28787496877622126]
	TIME [epoch: 10.2 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2817816716754092		[learning rate: 0.0035278]
	Learning Rate: 0.00352777
	LOSS [training: 0.2817816716754092 | validation: 0.2793293524341988]
	TIME [epoch: 10.2 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.254029644530473		[learning rate: 0.0035137]
	Learning Rate: 0.00351374
	LOSS [training: 0.254029644530473 | validation: 0.28260253841940663]
	TIME [epoch: 10.2 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2592702730737417		[learning rate: 0.0034998]
	Learning Rate: 0.00349976
	LOSS [training: 0.2592702730737417 | validation: 0.2656940200609049]
	TIME [epoch: 10.2 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2713569621643557		[learning rate: 0.0034858]
	Learning Rate: 0.00348584
	LOSS [training: 0.2713569621643557 | validation: 0.2810700796072148]
	TIME [epoch: 10.2 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25620072159722357		[learning rate: 0.003472]
	Learning Rate: 0.00347198
	LOSS [training: 0.25620072159722357 | validation: 0.2594864835322916]
	TIME [epoch: 10.2 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2558302991552821		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.2558302991552821 | validation: 0.2818713695408837]
	TIME [epoch: 10.2 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2501988541513493		[learning rate: 0.0034444]
	Learning Rate: 0.00344441
	LOSS [training: 0.2501988541513493 | validation: 0.24841065789772848]
	TIME [epoch: 10.2 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v10_20240711_153302/states/model_facs_dec1b_2dpca_v10_312.pth
	Model improved!!!
EPOCH 313/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25665560335074583		[learning rate: 0.0034307]
	Learning Rate: 0.00343071
	LOSS [training: 0.25665560335074583 | validation: 0.2573276656528495]
	TIME [epoch: 10.2 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26697558959897677		[learning rate: 0.0034171]
	Learning Rate: 0.00341707
	LOSS [training: 0.26697558959897677 | validation: 0.2644484349574666]
	TIME [epoch: 10.2 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2646379286207922		[learning rate: 0.0034035]
	Learning Rate: 0.00340348
	LOSS [training: 0.2646379286207922 | validation: 0.25238382333708886]
	TIME [epoch: 10.2 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2500877279211483		[learning rate: 0.0033899]
	Learning Rate: 0.00338994
	LOSS [training: 0.2500877279211483 | validation: 0.2613980708371691]
	TIME [epoch: 10.2 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2816299424531056		[learning rate: 0.0033765]
	Learning Rate: 0.00337646
	LOSS [training: 0.2816299424531056 | validation: 0.27177055832067554]
	TIME [epoch: 10.2 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.28371518476609453		[learning rate: 0.003363]
	Learning Rate: 0.00336303
	LOSS [training: 0.28371518476609453 | validation: 0.26485967467651783]
	TIME [epoch: 10.2 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26941047132302554		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 0.26941047132302554 | validation: 0.25743828227305526]
	TIME [epoch: 10.2 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25584622003428925		[learning rate: 0.0033363]
	Learning Rate: 0.00333633
	LOSS [training: 0.25584622003428925 | validation: 0.2549303641468464]
	TIME [epoch: 10.2 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2703293372205101		[learning rate: 0.0033231]
	Learning Rate: 0.00332306
	LOSS [training: 0.2703293372205101 | validation: 0.2747067873729373]
	TIME [epoch: 10.2 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2591229759229399		[learning rate: 0.0033098]
	Learning Rate: 0.00330985
	LOSS [training: 0.2591229759229399 | validation: 0.25743122764194054]
	TIME [epoch: 10.2 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.29539304807606914		[learning rate: 0.0032967]
	Learning Rate: 0.00329668
	LOSS [training: 0.29539304807606914 | validation: 0.25815038262307954]
	TIME [epoch: 10.2 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25640522361977314		[learning rate: 0.0032836]
	Learning Rate: 0.00328357
	LOSS [training: 0.25640522361977314 | validation: 0.2629059485830104]
	TIME [epoch: 10.2 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2690902246006344		[learning rate: 0.0032705]
	Learning Rate: 0.00327051
	LOSS [training: 0.2690902246006344 | validation: 0.2866830977286584]
	TIME [epoch: 10.2 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26579816316072835		[learning rate: 0.0032575]
	Learning Rate: 0.0032575
	LOSS [training: 0.26579816316072835 | validation: 0.2564382574288739]
	TIME [epoch: 10.2 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2609373160288946		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 0.2609373160288946 | validation: 0.26872858550908224]
	TIME [epoch: 10.2 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26686651546136547		[learning rate: 0.0032316]
	Learning Rate: 0.00323164
	LOSS [training: 0.26686651546136547 | validation: 0.29142501558632966]
	TIME [epoch: 10.2 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.35012852519056525		[learning rate: 0.0032188]
	Learning Rate: 0.00321879
	LOSS [training: 0.35012852519056525 | validation: 0.2744033268857111]
	TIME [epoch: 10.2 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.29415664478496		[learning rate: 0.003206]
	Learning Rate: 0.00320599
	LOSS [training: 0.29415664478496 | validation: 0.26514571859584246]
	TIME [epoch: 10.2 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25911652708482763		[learning rate: 0.0031932]
	Learning Rate: 0.00319323
	LOSS [training: 0.25911652708482763 | validation: 0.2636580337495799]
	TIME [epoch: 10.2 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26679617707296194		[learning rate: 0.0031805]
	Learning Rate: 0.00318053
	LOSS [training: 0.26679617707296194 | validation: 0.2603678066268281]
	TIME [epoch: 10.2 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26734525341666965		[learning rate: 0.0031679]
	Learning Rate: 0.00316788
	LOSS [training: 0.26734525341666965 | validation: 0.2719523287808415]
	TIME [epoch: 10.2 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2723427762786284		[learning rate: 0.0031553]
	Learning Rate: 0.00315528
	LOSS [training: 0.2723427762786284 | validation: 0.26338889872482457]
	TIME [epoch: 10.2 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25010949701044627		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 0.25010949701044627 | validation: 0.26789680118593595]
	TIME [epoch: 10.2 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2852577013849671		[learning rate: 0.0031302]
	Learning Rate: 0.00313023
	LOSS [training: 0.2852577013849671 | validation: 0.26004281141086955]
	TIME [epoch: 10.2 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25621582548021044		[learning rate: 0.0031178]
	Learning Rate: 0.00311779
	LOSS [training: 0.25621582548021044 | validation: 0.2535269798643811]
	TIME [epoch: 10.2 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2533496158914068		[learning rate: 0.0031054]
	Learning Rate: 0.00310538
	LOSS [training: 0.2533496158914068 | validation: 0.2739161977409009]
	TIME [epoch: 10.2 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25936598988606163		[learning rate: 0.003093]
	Learning Rate: 0.00309303
	LOSS [training: 0.25936598988606163 | validation: 0.26799919814262985]
	TIME [epoch: 10.2 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.28224657591594365		[learning rate: 0.0030807]
	Learning Rate: 0.00308073
	LOSS [training: 0.28224657591594365 | validation: 0.27307875204911586]
	TIME [epoch: 10.2 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25350255364112306		[learning rate: 0.0030685]
	Learning Rate: 0.00306848
	LOSS [training: 0.25350255364112306 | validation: 0.27367519250948863]
	TIME [epoch: 10.2 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24705855243435534		[learning rate: 0.0030563]
	Learning Rate: 0.00305627
	LOSS [training: 0.24705855243435534 | validation: 0.26504202978084473]
	TIME [epoch: 10.2 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2687101784578141		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 0.2687101784578141 | validation: 0.26569255449644724]
	TIME [epoch: 10.2 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2748709689225317		[learning rate: 0.003032]
	Learning Rate: 0.00303201
	LOSS [training: 0.2748709689225317 | validation: 0.30891014387359517]
	TIME [epoch: 10.2 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.27232615837396823		[learning rate: 0.00302]
	Learning Rate: 0.00301995
	LOSS [training: 0.27232615837396823 | validation: 0.27673144245166814]
	TIME [epoch: 10.2 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2675861537174404		[learning rate: 0.0030079]
	Learning Rate: 0.00300794
	LOSS [training: 0.2675861537174404 | validation: 0.26644989579307676]
	TIME [epoch: 10.2 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.27037762758809103		[learning rate: 0.002996]
	Learning Rate: 0.00299598
	LOSS [training: 0.27037762758809103 | validation: 0.2583859450190037]
	TIME [epoch: 10.2 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26192384032218585		[learning rate: 0.0029841]
	Learning Rate: 0.00298406
	LOSS [training: 0.26192384032218585 | validation: 0.25725101931906674]
	TIME [epoch: 10.2 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2625184163024223		[learning rate: 0.0029722]
	Learning Rate: 0.00297219
	LOSS [training: 0.2625184163024223 | validation: 0.254566291032543]
	TIME [epoch: 10.2 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25757293836439504		[learning rate: 0.0029604]
	Learning Rate: 0.00296037
	LOSS [training: 0.25757293836439504 | validation: 0.26564925184351984]
	TIME [epoch: 10.2 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.27883971814325226		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.27883971814325226 | validation: 0.2848754265134489]
	TIME [epoch: 10.2 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2713059554068557		[learning rate: 0.0029369]
	Learning Rate: 0.00293687
	LOSS [training: 0.2713059554068557 | validation: 0.27005366279130155]
	TIME [epoch: 10.2 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24568151895624077		[learning rate: 0.0029252]
	Learning Rate: 0.00292519
	LOSS [training: 0.24568151895624077 | validation: 0.255015843124787]
	TIME [epoch: 10.2 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24290910617893122		[learning rate: 0.0029136]
	Learning Rate: 0.00291355
	LOSS [training: 0.24290910617893122 | validation: 0.25450129260090437]
	TIME [epoch: 10.2 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2718331337938319		[learning rate: 0.002902]
	Learning Rate: 0.00290197
	LOSS [training: 0.2718331337938319 | validation: 0.30011187560114716]
	TIME [epoch: 10.2 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.27553441375832577		[learning rate: 0.0028904]
	Learning Rate: 0.00289042
	LOSS [training: 0.27553441375832577 | validation: 0.26688404916289776]
	TIME [epoch: 10.2 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25874769315502		[learning rate: 0.0028789]
	Learning Rate: 0.00287893
	LOSS [training: 0.25874769315502 | validation: 0.26254986167923644]
	TIME [epoch: 10.2 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2675274965918639		[learning rate: 0.0028675]
	Learning Rate: 0.00286748
	LOSS [training: 0.2675274965918639 | validation: 0.29625717308731864]
	TIME [epoch: 10.2 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26007642355466587		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 0.26007642355466587 | validation: 0.26475901414667524]
	TIME [epoch: 10.2 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2492865988314115		[learning rate: 0.0028447]
	Learning Rate: 0.00284471
	LOSS [training: 0.2492865988314115 | validation: 0.2587162839575608]
	TIME [epoch: 10.2 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24446319589073598		[learning rate: 0.0028334]
	Learning Rate: 0.0028334
	LOSS [training: 0.24446319589073598 | validation: 0.2623813826322608]
	TIME [epoch: 10.2 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2482798315910785		[learning rate: 0.0028221]
	Learning Rate: 0.00282213
	LOSS [training: 0.2482798315910785 | validation: 0.25490151828842134]
	TIME [epoch: 10.2 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25017486144944806		[learning rate: 0.0028109]
	Learning Rate: 0.00281091
	LOSS [training: 0.25017486144944806 | validation: 0.2687275663654466]
	TIME [epoch: 10.2 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25234381368236697		[learning rate: 0.0027997]
	Learning Rate: 0.00279973
	LOSS [training: 0.25234381368236697 | validation: 0.2602713991256423]
	TIME [epoch: 10.2 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.248613090285929		[learning rate: 0.0027886]
	Learning Rate: 0.00278859
	LOSS [training: 0.248613090285929 | validation: 0.2697826782782232]
	TIME [epoch: 10.2 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.27966062607514125		[learning rate: 0.0027775]
	Learning Rate: 0.0027775
	LOSS [training: 0.27966062607514125 | validation: 0.2894903594812352]
	TIME [epoch: 10.2 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25351615146288764		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 0.25351615146288764 | validation: 0.26570291174127253]
	TIME [epoch: 10.2 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2465579034088542		[learning rate: 0.0027554]
	Learning Rate: 0.00275545
	LOSS [training: 0.2465579034088542 | validation: 0.2550917707019499]
	TIME [epoch: 10.2 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2573453182787359		[learning rate: 0.0027445]
	Learning Rate: 0.00274449
	LOSS [training: 0.2573453182787359 | validation: 0.2569083326772668]
	TIME [epoch: 10.2 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25535770171062		[learning rate: 0.0027336]
	Learning Rate: 0.00273357
	LOSS [training: 0.25535770171062 | validation: 0.2564851646207137]
	TIME [epoch: 10.2 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.252257219285752		[learning rate: 0.0027227]
	Learning Rate: 0.0027227
	LOSS [training: 0.252257219285752 | validation: 0.274617202088658]
	TIME [epoch: 10.2 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2661515136151699		[learning rate: 0.0027119]
	Learning Rate: 0.00271187
	LOSS [training: 0.2661515136151699 | validation: 0.2544063981502833]
	TIME [epoch: 10.2 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.27869854655346954		[learning rate: 0.0027011]
	Learning Rate: 0.00270109
	LOSS [training: 0.27869854655346954 | validation: 0.27463931871454406]
	TIME [epoch: 10.2 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25364463433896506		[learning rate: 0.0026903]
	Learning Rate: 0.00269034
	LOSS [training: 0.25364463433896506 | validation: 0.2664701097138793]
	TIME [epoch: 10.2 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24582481117284086		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 0.24582481117284086 | validation: 0.25458645714858597]
	TIME [epoch: 10.3 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24473551756692968		[learning rate: 0.002669]
	Learning Rate: 0.00266899
	LOSS [training: 0.24473551756692968 | validation: 0.2647765611398736]
	TIME [epoch: 10.2 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2627225559868583		[learning rate: 0.0026584]
	Learning Rate: 0.00265837
	LOSS [training: 0.2627225559868583 | validation: 0.2677091129100318]
	TIME [epoch: 10.2 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24074326543276003		[learning rate: 0.0026478]
	Learning Rate: 0.0026478
	LOSS [training: 0.24074326543276003 | validation: 0.2684922950855656]
	TIME [epoch: 10.2 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24780423351521907		[learning rate: 0.0026373]
	Learning Rate: 0.00263727
	LOSS [training: 0.24780423351521907 | validation: 0.24875166988315928]
	TIME [epoch: 10.2 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2372141549588766		[learning rate: 0.0026268]
	Learning Rate: 0.00262678
	LOSS [training: 0.2372141549588766 | validation: 0.2531279225194819]
	TIME [epoch: 10.2 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2560281374091887		[learning rate: 0.0026163]
	Learning Rate: 0.00261633
	LOSS [training: 0.2560281374091887 | validation: 0.250522423784028]
	TIME [epoch: 10.3 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23888068331762838		[learning rate: 0.0026059]
	Learning Rate: 0.00260592
	LOSS [training: 0.23888068331762838 | validation: 0.2517822814557039]
	TIME [epoch: 10.3 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23901738233402542		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 0.23901738233402542 | validation: 0.26104641687132335]
	TIME [epoch: 10.2 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24534745762928908		[learning rate: 0.0025852]
	Learning Rate: 0.00258523
	LOSS [training: 0.24534745762928908 | validation: 0.28182013600235895]
	TIME [epoch: 10.2 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2595417495883234		[learning rate: 0.002575]
	Learning Rate: 0.00257495
	LOSS [training: 0.2595417495883234 | validation: 0.25899198664417333]
	TIME [epoch: 10.2 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2531097291704839		[learning rate: 0.0025647]
	Learning Rate: 0.00256471
	LOSS [training: 0.2531097291704839 | validation: 0.2538530630135649]
	TIME [epoch: 10.2 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25914854574394597		[learning rate: 0.0025545]
	Learning Rate: 0.00255451
	LOSS [training: 0.25914854574394597 | validation: 0.26343042135850653]
	TIME [epoch: 10.2 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2402619740693498		[learning rate: 0.0025444]
	Learning Rate: 0.00254435
	LOSS [training: 0.2402619740693498 | validation: 0.25650456297472074]
	TIME [epoch: 10.2 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2418745284391392		[learning rate: 0.0025342]
	Learning Rate: 0.00253423
	LOSS [training: 0.2418745284391392 | validation: 0.25318516041396183]
	TIME [epoch: 10.2 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2457410265111134		[learning rate: 0.0025242]
	Learning Rate: 0.00252415
	LOSS [training: 0.2457410265111134 | validation: 0.25064893238266395]
	TIME [epoch: 10.2 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23819104245116535		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.23819104245116535 | validation: 0.26699563596569975]
	TIME [epoch: 10.2 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2483422734988843		[learning rate: 0.0025041]
	Learning Rate: 0.00250411
	LOSS [training: 0.2483422734988843 | validation: 0.26290470973171576]
	TIME [epoch: 10.2 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24273156056507686		[learning rate: 0.0024942]
	Learning Rate: 0.00249415
	LOSS [training: 0.24273156056507686 | validation: 0.2575409821364747]
	TIME [epoch: 10.2 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23753876549153474		[learning rate: 0.0024842]
	Learning Rate: 0.00248423
	LOSS [training: 0.23753876549153474 | validation: 0.3858813011521165]
	TIME [epoch: 10.2 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.31464563811021273		[learning rate: 0.0024744]
	Learning Rate: 0.00247435
	LOSS [training: 0.31464563811021273 | validation: 0.2630778650686386]
	TIME [epoch: 10.2 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25735165650087716		[learning rate: 0.0024645]
	Learning Rate: 0.00246451
	LOSS [training: 0.25735165650087716 | validation: 0.25355511401823233]
	TIME [epoch: 10.2 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2530110837645519		[learning rate: 0.0024547]
	Learning Rate: 0.00245471
	LOSS [training: 0.2530110837645519 | validation: 0.2642534915777003]
	TIME [epoch: 10.2 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26244125720857897		[learning rate: 0.0024449]
	Learning Rate: 0.00244495
	LOSS [training: 0.26244125720857897 | validation: 0.26954683377378386]
	TIME [epoch: 10.2 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2463877698125662		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 0.2463877698125662 | validation: 0.25114698646750633]
	TIME [epoch: 10.2 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24630306383119877		[learning rate: 0.0024255]
	Learning Rate: 0.00242554
	LOSS [training: 0.24630306383119877 | validation: 0.25476285948286176]
	TIME [epoch: 10.2 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24137969597733677		[learning rate: 0.0024159]
	Learning Rate: 0.00241589
	LOSS [training: 0.24137969597733677 | validation: 0.2543128415674652]
	TIME [epoch: 10.2 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2469393969092056		[learning rate: 0.0024063]
	Learning Rate: 0.00240628
	LOSS [training: 0.2469393969092056 | validation: 0.26914499966269056]
	TIME [epoch: 10.2 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2361586411773732		[learning rate: 0.0023967]
	Learning Rate: 0.00239671
	LOSS [training: 0.2361586411773732 | validation: 0.25236793551774195]
	TIME [epoch: 10.2 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2426523644127034		[learning rate: 0.0023872]
	Learning Rate: 0.00238718
	LOSS [training: 0.2426523644127034 | validation: 0.2700552030115734]
	TIME [epoch: 10.2 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23853936222966565		[learning rate: 0.0023777]
	Learning Rate: 0.00237768
	LOSS [training: 0.23853936222966565 | validation: 0.2623361925467935]
	TIME [epoch: 10.2 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2510730309461296		[learning rate: 0.0023682]
	Learning Rate: 0.00236823
	LOSS [training: 0.2510730309461296 | validation: 0.2572724929519575]
	TIME [epoch: 10.2 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23540426094159367		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 0.23540426094159367 | validation: 0.2553001931795714]
	TIME [epoch: 10.2 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24209208344896702		[learning rate: 0.0023494]
	Learning Rate: 0.00234942
	LOSS [training: 0.24209208344896702 | validation: 0.2845588929052162]
	TIME [epoch: 10.2 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2527350790913823		[learning rate: 0.0023401]
	Learning Rate: 0.00234008
	LOSS [training: 0.2527350790913823 | validation: 0.24876534229845987]
	TIME [epoch: 10.2 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24424281765172642		[learning rate: 0.0023308]
	Learning Rate: 0.00233077
	LOSS [training: 0.24424281765172642 | validation: 0.25641196130044785]
	TIME [epoch: 10.2 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2529233410548075		[learning rate: 0.0023215]
	Learning Rate: 0.0023215
	LOSS [training: 0.2529233410548075 | validation: 0.2504581051586086]
	TIME [epoch: 10.2 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24085432054572273		[learning rate: 0.0023123]
	Learning Rate: 0.00231227
	LOSS [training: 0.24085432054572273 | validation: 0.24648148744950413]
	TIME [epoch: 10.2 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v10_20240711_153302/states/model_facs_dec1b_2dpca_v10_412.pth
	Model improved!!!
EPOCH 413/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23532885256005143		[learning rate: 0.0023031]
	Learning Rate: 0.00230307
	LOSS [training: 0.23532885256005143 | validation: 0.24984565906916795]
	TIME [epoch: 10.2 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2546062646683513		[learning rate: 0.0022939]
	Learning Rate: 0.00229391
	LOSS [training: 0.2546062646683513 | validation: 0.26384492863290027]
	TIME [epoch: 10.2 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23655172870093966		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 0.23655172870093966 | validation: 0.2527906967787243]
	TIME [epoch: 10.2 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24150855694727735		[learning rate: 0.0022757]
	Learning Rate: 0.0022757
	LOSS [training: 0.24150855694727735 | validation: 0.26825354658567513]
	TIME [epoch: 10.2 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2414210582079049		[learning rate: 0.0022667]
	Learning Rate: 0.00226665
	LOSS [training: 0.2414210582079049 | validation: 0.24602936938932102]
	TIME [epoch: 10.2 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v10_20240711_153302/states/model_facs_dec1b_2dpca_v10_417.pth
	Model improved!!!
EPOCH 418/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.256747930458507		[learning rate: 0.0022576]
	Learning Rate: 0.00225764
	LOSS [training: 0.256747930458507 | validation: 0.260070305409822]
	TIME [epoch: 10.2 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23569599762092652		[learning rate: 0.0022487]
	Learning Rate: 0.00224866
	LOSS [training: 0.23569599762092652 | validation: 0.2505819242460841]
	TIME [epoch: 10.2 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2360394177821773		[learning rate: 0.0022397]
	Learning Rate: 0.00223971
	LOSS [training: 0.2360394177821773 | validation: 0.25529262439263745]
	TIME [epoch: 10.2 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23550970185581888		[learning rate: 0.0022308]
	Learning Rate: 0.0022308
	LOSS [training: 0.23550970185581888 | validation: 0.26159841379698234]
	TIME [epoch: 10.2 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23974276449386178		[learning rate: 0.0022219]
	Learning Rate: 0.00222193
	LOSS [training: 0.23974276449386178 | validation: 0.2767116003552951]
	TIME [epoch: 10.3 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2494430256406125		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.2494430256406125 | validation: 0.25616881089057914]
	TIME [epoch: 10.3 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24439701790290988		[learning rate: 0.0022043]
	Learning Rate: 0.00220429
	LOSS [training: 0.24439701790290988 | validation: 0.2513830181871797]
	TIME [epoch: 10.2 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23270390220408455		[learning rate: 0.0021955]
	Learning Rate: 0.00219553
	LOSS [training: 0.23270390220408455 | validation: 0.2614727755592493]
	TIME [epoch: 10.2 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23997722948570172		[learning rate: 0.0021868]
	Learning Rate: 0.00218679
	LOSS [training: 0.23997722948570172 | validation: 0.25723777512598434]
	TIME [epoch: 10.2 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23991923835225692		[learning rate: 0.0021781]
	Learning Rate: 0.0021781
	LOSS [training: 0.23991923835225692 | validation: 0.2521943981352049]
	TIME [epoch: 10.2 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24902148385677586		[learning rate: 0.0021694]
	Learning Rate: 0.00216943
	LOSS [training: 0.24902148385677586 | validation: 0.25997057359889747]
	TIME [epoch: 10.2 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24400724468982654		[learning rate: 0.0021608]
	Learning Rate: 0.0021608
	LOSS [training: 0.24400724468982654 | validation: 0.25296818350880607]
	TIME [epoch: 10.2 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23862695538079348		[learning rate: 0.0021522]
	Learning Rate: 0.00215221
	LOSS [training: 0.23862695538079348 | validation: 0.25765764060041385]
	TIME [epoch: 10.2 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24036630695197245		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.24036630695197245 | validation: 0.25956892741420723]
	TIME [epoch: 10.2 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2574761661040522		[learning rate: 0.0021351]
	Learning Rate: 0.00213512
	LOSS [training: 0.2574761661040522 | validation: 0.24950904015332753]
	TIME [epoch: 10.2 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2585111680340534		[learning rate: 0.0021266]
	Learning Rate: 0.00212663
	LOSS [training: 0.2585111680340534 | validation: 0.2708620784349719]
	TIME [epoch: 10.2 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23844900509733216		[learning rate: 0.0021182]
	Learning Rate: 0.00211817
	LOSS [training: 0.23844900509733216 | validation: 0.24864651200781976]
	TIME [epoch: 10.2 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24325665364589577		[learning rate: 0.0021097]
	Learning Rate: 0.00210975
	LOSS [training: 0.24325665364589577 | validation: 0.25311622101048115]
	TIME [epoch: 10.2 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.250306553751389		[learning rate: 0.0021014]
	Learning Rate: 0.00210136
	LOSS [training: 0.250306553751389 | validation: 0.2972866609338079]
	TIME [epoch: 10.2 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2554377468108546		[learning rate: 0.002093]
	Learning Rate: 0.002093
	LOSS [training: 0.2554377468108546 | validation: 0.2689089673063078]
	TIME [epoch: 10.2 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2534078526733107		[learning rate: 0.0020847]
	Learning Rate: 0.00208468
	LOSS [training: 0.2534078526733107 | validation: 0.26432268878587156]
	TIME [epoch: 10.2 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2391740074301866		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.2391740074301866 | validation: 0.2555025886151483]
	TIME [epoch: 10.2 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23316918448130158		[learning rate: 0.0020681]
	Learning Rate: 0.00206813
	LOSS [training: 0.23316918448130158 | validation: 0.24935965953133601]
	TIME [epoch: 10.2 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24048075934609858		[learning rate: 0.0020599]
	Learning Rate: 0.0020599
	LOSS [training: 0.24048075934609858 | validation: 0.2707492001430446]
	TIME [epoch: 10.2 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23815957869209547		[learning rate: 0.0020517]
	Learning Rate: 0.00205171
	LOSS [training: 0.23815957869209547 | validation: 0.24592869234753598]
	TIME [epoch: 10.2 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v10_20240711_153302/states/model_facs_dec1b_2dpca_v10_442.pth
	Model improved!!!
EPOCH 443/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25299185872963		[learning rate: 0.0020435]
	Learning Rate: 0.00204355
	LOSS [training: 0.25299185872963 | validation: 0.25369626430843395]
	TIME [epoch: 10.2 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23689016105726543		[learning rate: 0.0020354]
	Learning Rate: 0.00203542
	LOSS [training: 0.23689016105726543 | validation: 0.25509258708751703]
	TIME [epoch: 10.2 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24241507124556375		[learning rate: 0.0020273]
	Learning Rate: 0.00202732
	LOSS [training: 0.24241507124556375 | validation: 0.25097631408530907]
	TIME [epoch: 10.2 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23816501061635284		[learning rate: 0.0020193]
	Learning Rate: 0.00201926
	LOSS [training: 0.23816501061635284 | validation: 0.24985220477835587]
	TIME [epoch: 10.2 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23772873538120745		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 0.23772873538120745 | validation: 0.24839014649628832]
	TIME [epoch: 10.2 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2571749403826097		[learning rate: 0.0020032]
	Learning Rate: 0.00200323
	LOSS [training: 0.2571749403826097 | validation: 0.26583728280500285]
	TIME [epoch: 10.2 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24122090849130448		[learning rate: 0.0019953]
	Learning Rate: 0.00199526
	LOSS [training: 0.24122090849130448 | validation: 0.24968047549601544]
	TIME [epoch: 10.2 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2451617912609434		[learning rate: 0.0019873]
	Learning Rate: 0.00198733
	LOSS [training: 0.2451617912609434 | validation: 0.24846412964727707]
	TIME [epoch: 10.2 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25182935205988716		[learning rate: 0.0019794]
	Learning Rate: 0.00197942
	LOSS [training: 0.25182935205988716 | validation: 0.2740424984937477]
	TIME [epoch: 10.2 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23355766260403577		[learning rate: 0.0019715]
	Learning Rate: 0.00197155
	LOSS [training: 0.23355766260403577 | validation: 0.2483492497296132]
	TIME [epoch: 10.2 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23988721130815266		[learning rate: 0.0019637]
	Learning Rate: 0.00196371
	LOSS [training: 0.23988721130815266 | validation: 0.2547112687136365]
	TIME [epoch: 10.2 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23096664118972812		[learning rate: 0.0019559]
	Learning Rate: 0.0019559
	LOSS [training: 0.23096664118972812 | validation: 0.25536427855642474]
	TIME [epoch: 10.2 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23198767204319123		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 0.23198767204319123 | validation: 0.24350009944249643]
	TIME [epoch: 10.2 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v10_20240711_153302/states/model_facs_dec1b_2dpca_v10_455.pth
	Model improved!!!
EPOCH 456/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23242732287483692		[learning rate: 0.0019404]
	Learning Rate: 0.00194037
	LOSS [training: 0.23242732287483692 | validation: 0.25123745528789654]
	TIME [epoch: 10.2 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2304074677123736		[learning rate: 0.0019327]
	Learning Rate: 0.00193265
	LOSS [training: 0.2304074677123736 | validation: 0.2528435967781478]
	TIME [epoch: 10.2 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23267148272528232		[learning rate: 0.001925]
	Learning Rate: 0.00192497
	LOSS [training: 0.23267148272528232 | validation: 0.25013079147802014]
	TIME [epoch: 10.2 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23305567331650068		[learning rate: 0.0019173]
	Learning Rate: 0.00191731
	LOSS [training: 0.23305567331650068 | validation: 0.2461523487450057]
	TIME [epoch: 10.2 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23161036409542074		[learning rate: 0.0019097]
	Learning Rate: 0.00190968
	LOSS [training: 0.23161036409542074 | validation: 0.26834483100084155]
	TIME [epoch: 10.2 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2388351083596463		[learning rate: 0.0019021]
	Learning Rate: 0.00190209
	LOSS [training: 0.2388351083596463 | validation: 0.2573994944378327]
	TIME [epoch: 10.2 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23387802205731306		[learning rate: 0.0018945]
	Learning Rate: 0.00189452
	LOSS [training: 0.23387802205731306 | validation: 0.2507251143071492]
	TIME [epoch: 10.2 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2311668954540627		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.2311668954540627 | validation: 0.2434688299732862]
	TIME [epoch: 10.2 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v10_20240711_153302/states/model_facs_dec1b_2dpca_v10_463.pth
	Model improved!!!
EPOCH 464/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22974269256800633		[learning rate: 0.0018795]
	Learning Rate: 0.00187948
	LOSS [training: 0.22974269256800633 | validation: 0.25459014256960666]
	TIME [epoch: 10.2 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23730448077807567		[learning rate: 0.001872]
	Learning Rate: 0.00187201
	LOSS [training: 0.23730448077807567 | validation: 0.2573100272567403]
	TIME [epoch: 10.2 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24565999101080202		[learning rate: 0.0018646]
	Learning Rate: 0.00186456
	LOSS [training: 0.24565999101080202 | validation: 0.2576331265327382]
	TIME [epoch: 10.2 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23040975098269062		[learning rate: 0.0018571]
	Learning Rate: 0.00185715
	LOSS [training: 0.23040975098269062 | validation: 0.25064093234035695]
	TIME [epoch: 10.2 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23487990379737733		[learning rate: 0.0018498]
	Learning Rate: 0.00184976
	LOSS [training: 0.23487990379737733 | validation: 0.260361230071868]
	TIME [epoch: 10.2 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24020903744707015		[learning rate: 0.0018424]
	Learning Rate: 0.0018424
	LOSS [training: 0.24020903744707015 | validation: 0.252013801687592]
	TIME [epoch: 10.2 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22946419018599165		[learning rate: 0.0018351]
	Learning Rate: 0.00183508
	LOSS [training: 0.22946419018599165 | validation: 0.24402322415441874]
	TIME [epoch: 10.2 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23055420110716376		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.23055420110716376 | validation: 0.27677553354293016]
	TIME [epoch: 10.2 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23714803680563737		[learning rate: 0.0018205]
	Learning Rate: 0.00182051
	LOSS [training: 0.23714803680563737 | validation: 0.24848742433340973]
	TIME [epoch: 10.2 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2334338745610969		[learning rate: 0.0018133]
	Learning Rate: 0.00181327
	LOSS [training: 0.2334338745610969 | validation: 0.2556157536121229]
	TIME [epoch: 10.2 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22940550571470503		[learning rate: 0.0018061]
	Learning Rate: 0.00180605
	LOSS [training: 0.22940550571470503 | validation: 0.2546695243069186]
	TIME [epoch: 10.2 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2328944981152963		[learning rate: 0.0017989]
	Learning Rate: 0.00179887
	LOSS [training: 0.2328944981152963 | validation: 0.2678753229006036]
	TIME [epoch: 10.2 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23971593539579836		[learning rate: 0.0017917]
	Learning Rate: 0.00179172
	LOSS [training: 0.23971593539579836 | validation: 0.250172020948499]
	TIME [epoch: 10.2 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24521524684895205		[learning rate: 0.0017846]
	Learning Rate: 0.00178459
	LOSS [training: 0.24521524684895205 | validation: 0.24420561167502025]
	TIME [epoch: 10.2 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23130612901699202		[learning rate: 0.0017775]
	Learning Rate: 0.00177749
	LOSS [training: 0.23130612901699202 | validation: 0.2620517552104358]
	TIME [epoch: 10.2 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23413376536168462		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.23413376536168462 | validation: 0.2421021507939356]
	TIME [epoch: 10.2 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v10_20240711_153302/states/model_facs_dec1b_2dpca_v10_479.pth
	Model improved!!!
EPOCH 480/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.229156989018341		[learning rate: 0.0017634]
	Learning Rate: 0.00176338
	LOSS [training: 0.229156989018341 | validation: 0.2537563504224488]
	TIME [epoch: 10.2 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25010947996354627		[learning rate: 0.0017564]
	Learning Rate: 0.00175637
	LOSS [training: 0.25010947996354627 | validation: 0.2563210257783707]
	TIME [epoch: 10.2 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.252036201799616		[learning rate: 0.0017494]
	Learning Rate: 0.00174938
	LOSS [training: 0.252036201799616 | validation: 0.25036829352879203]
	TIME [epoch: 10.2 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2340978423838989		[learning rate: 0.0017424]
	Learning Rate: 0.00174242
	LOSS [training: 0.2340978423838989 | validation: 0.28352905978156956]
	TIME [epoch: 10.2 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23680871911791412		[learning rate: 0.0017355]
	Learning Rate: 0.00173549
	LOSS [training: 0.23680871911791412 | validation: 0.2474312062990624]
	TIME [epoch: 10.2 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23027402596798063		[learning rate: 0.0017286]
	Learning Rate: 0.00172859
	LOSS [training: 0.23027402596798063 | validation: 0.2406941267351729]
	TIME [epoch: 10.2 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v10_20240711_153302/states/model_facs_dec1b_2dpca_v10_485.pth
	Model improved!!!
EPOCH 486/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23319425761868928		[learning rate: 0.0017217]
	Learning Rate: 0.00172172
	LOSS [training: 0.23319425761868928 | validation: 0.2466651754731716]
	TIME [epoch: 10.2 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23549869748279054		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 0.23549869748279054 | validation: 0.24027373091940155]
	TIME [epoch: 10.2 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v10_20240711_153302/states/model_facs_dec1b_2dpca_v10_487.pth
	Model improved!!!
EPOCH 488/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23500281891146008		[learning rate: 0.001708]
	Learning Rate: 0.00170805
	LOSS [training: 0.23500281891146008 | validation: 0.2745038787677959]
	TIME [epoch: 10.2 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24870954506584353		[learning rate: 0.0017013]
	Learning Rate: 0.00170125
	LOSS [training: 0.24870954506584353 | validation: 0.2702588746054054]
	TIME [epoch: 10.2 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23544652863607704		[learning rate: 0.0016945]
	Learning Rate: 0.00169449
	LOSS [training: 0.23544652863607704 | validation: 0.2350062011705088]
	TIME [epoch: 10.2 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v10_20240711_153302/states/model_facs_dec1b_2dpca_v10_490.pth
	Model improved!!!
EPOCH 491/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23048588864001202		[learning rate: 0.0016877]
	Learning Rate: 0.00168775
	LOSS [training: 0.23048588864001202 | validation: 0.251003381090509]
	TIME [epoch: 10.5 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2303392473278162		[learning rate: 0.001681]
	Learning Rate: 0.00168104
	LOSS [training: 0.2303392473278162 | validation: 0.2519415042630758]
	TIME [epoch: 10.2 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23148660298282409		[learning rate: 0.0016743]
	Learning Rate: 0.00167435
	LOSS [training: 0.23148660298282409 | validation: 0.25573742765895247]
	TIME [epoch: 10.3 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23426959524924865		[learning rate: 0.0016677]
	Learning Rate: 0.00166769
	LOSS [training: 0.23426959524924865 | validation: 0.24623941092122834]
	TIME [epoch: 10.2 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23165152889913937		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.23165152889913937 | validation: 0.25568298427501585]
	TIME [epoch: 10.2 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24123980224972724		[learning rate: 0.0016545]
	Learning Rate: 0.00165445
	LOSS [training: 0.24123980224972724 | validation: 0.2617177365488523]
	TIME [epoch: 10.2 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22958513909169462		[learning rate: 0.0016479]
	Learning Rate: 0.00164787
	LOSS [training: 0.22958513909169462 | validation: 0.2540133581419551]
	TIME [epoch: 10.2 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22543049414332827		[learning rate: 0.0016413]
	Learning Rate: 0.00164132
	LOSS [training: 0.22543049414332827 | validation: 0.25213597830475426]
	TIME [epoch: 10.2 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2444609253171821		[learning rate: 0.0016348]
	Learning Rate: 0.00163479
	LOSS [training: 0.2444609253171821 | validation: 0.23994368976432198]
	TIME [epoch: 10.2 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23477418411965909		[learning rate: 0.0016283]
	Learning Rate: 0.00162829
	LOSS [training: 0.23477418411965909 | validation: 0.24417086123190285]
	TIME [epoch: 10.2 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23038900676107843		[learning rate: 0.0016218]
	Learning Rate: 0.00162181
	LOSS [training: 0.23038900676107843 | validation: 0.24655985325710317]
	TIME [epoch: 40.9 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2238995944811856		[learning rate: 0.0016154]
	Learning Rate: 0.00161536
	LOSS [training: 0.2238995944811856 | validation: 0.23908186543719717]
	TIME [epoch: 19.8 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22998973460377037		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 0.22998973460377037 | validation: 0.24950118482945777]
	TIME [epoch: 19.8 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22893486065795857		[learning rate: 0.0016025]
	Learning Rate: 0.00160254
	LOSS [training: 0.22893486065795857 | validation: 0.2347211742373228]
	TIME [epoch: 19.8 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v10_20240711_153302/states/model_facs_dec1b_2dpca_v10_504.pth
	Model improved!!!
EPOCH 505/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22900440748513295		[learning rate: 0.0015962]
	Learning Rate: 0.00159616
	LOSS [training: 0.22900440748513295 | validation: 0.2567929021566677]
	TIME [epoch: 19.8 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23947508303902268		[learning rate: 0.0015898]
	Learning Rate: 0.00158981
	LOSS [training: 0.23947508303902268 | validation: 0.23997534688372063]
	TIME [epoch: 19.8 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23214515807517921		[learning rate: 0.0015835]
	Learning Rate: 0.00158349
	LOSS [training: 0.23214515807517921 | validation: 0.23898453651031387]
	TIME [epoch: 19.8 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2532911051083848		[learning rate: 0.0015772]
	Learning Rate: 0.00157719
	LOSS [training: 0.2532911051083848 | validation: 0.29715722914257553]
	TIME [epoch: 19.8 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.28682621142492365		[learning rate: 0.0015709]
	Learning Rate: 0.00157092
	LOSS [training: 0.28682621142492365 | validation: 0.2638725713546993]
	TIME [epoch: 19.8 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24913216902665633		[learning rate: 0.0015647]
	Learning Rate: 0.00156467
	LOSS [training: 0.24913216902665633 | validation: 0.24409840050675177]
	TIME [epoch: 19.8 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23162042258723836		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.23162042258723836 | validation: 0.23962302584532144]
	TIME [epoch: 19.8 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23294061101896243		[learning rate: 0.0015522]
	Learning Rate: 0.00155225
	LOSS [training: 0.23294061101896243 | validation: 0.2587031856209355]
	TIME [epoch: 19.8 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23241315927824965		[learning rate: 0.0015461]
	Learning Rate: 0.00154608
	LOSS [training: 0.23241315927824965 | validation: 0.24883535116109595]
	TIME [epoch: 19.8 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23525240529062608		[learning rate: 0.0015399]
	Learning Rate: 0.00153993
	LOSS [training: 0.23525240529062608 | validation: 0.24778158557284718]
	TIME [epoch: 19.8 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23444652401715174		[learning rate: 0.0015338]
	Learning Rate: 0.0015338
	LOSS [training: 0.23444652401715174 | validation: 0.24476515561573065]
	TIME [epoch: 19.8 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2316663583819125		[learning rate: 0.0015277]
	Learning Rate: 0.0015277
	LOSS [training: 0.2316663583819125 | validation: 0.2394871462517048]
	TIME [epoch: 19.8 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23230374889116684		[learning rate: 0.0015216]
	Learning Rate: 0.00152163
	LOSS [training: 0.23230374889116684 | validation: 0.23868651783892275]
	TIME [epoch: 19.8 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23026049736070092		[learning rate: 0.0015156]
	Learning Rate: 0.00151557
	LOSS [training: 0.23026049736070092 | validation: 0.2369781777852511]
	TIME [epoch: 19.8 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2334704982691433		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.2334704982691433 | validation: 0.23624621105606117]
	TIME [epoch: 19.8 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23227443292247393		[learning rate: 0.0015035]
	Learning Rate: 0.00150354
	LOSS [training: 0.23227443292247393 | validation: 0.2480866034299846]
	TIME [epoch: 19.8 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24567963342007745		[learning rate: 0.0014976]
	Learning Rate: 0.00149756
	LOSS [training: 0.24567963342007745 | validation: 0.25811882231037064]
	TIME [epoch: 19.8 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25177688432723744		[learning rate: 0.0014916]
	Learning Rate: 0.00149161
	LOSS [training: 0.25177688432723744 | validation: 0.26181314391426314]
	TIME [epoch: 19.8 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2362561020560724		[learning rate: 0.0014857]
	Learning Rate: 0.00148567
	LOSS [training: 0.2362561020560724 | validation: 0.2575654239851993]
	TIME [epoch: 19.8 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23801392866355306		[learning rate: 0.0014798]
	Learning Rate: 0.00147976
	LOSS [training: 0.23801392866355306 | validation: 0.2443438585898817]
	TIME [epoch: 19.8 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24630965167003716		[learning rate: 0.0014739]
	Learning Rate: 0.00147388
	LOSS [training: 0.24630965167003716 | validation: 0.24422701113654957]
	TIME [epoch: 19.8 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24289524905636745		[learning rate: 0.001468]
	Learning Rate: 0.00146802
	LOSS [training: 0.24289524905636745 | validation: 0.2340172903288086]
	TIME [epoch: 19.8 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v10_20240711_153302/states/model_facs_dec1b_2dpca_v10_526.pth
	Model improved!!!
EPOCH 527/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23251290072080247		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.23251290072080247 | validation: 0.25948375333011797]
	TIME [epoch: 19.8 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2325268343880881		[learning rate: 0.0014564]
	Learning Rate: 0.00145636
	LOSS [training: 0.2325268343880881 | validation: 0.2374284302134387]
	TIME [epoch: 19.8 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2264785948776803		[learning rate: 0.0014506]
	Learning Rate: 0.00145057
	LOSS [training: 0.2264785948776803 | validation: 0.24269497469703444]
	TIME [epoch: 19.8 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22683712079170862		[learning rate: 0.0014448]
	Learning Rate: 0.0014448
	LOSS [training: 0.22683712079170862 | validation: 0.23647836807426695]
	TIME [epoch: 19.8 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23111105955913036		[learning rate: 0.0014391]
	Learning Rate: 0.00143905
	LOSS [training: 0.23111105955913036 | validation: 0.2586004139205399]
	TIME [epoch: 19.9 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23127067584523633		[learning rate: 0.0014333]
	Learning Rate: 0.00143333
	LOSS [training: 0.23127067584523633 | validation: 0.2506536386987058]
	TIME [epoch: 19.8 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23253944865028034		[learning rate: 0.0014276]
	Learning Rate: 0.00142763
	LOSS [training: 0.23253944865028034 | validation: 0.24206216389058194]
	TIME [epoch: 19.8 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23068820139007457		[learning rate: 0.001422]
	Learning Rate: 0.00142195
	LOSS [training: 0.23068820139007457 | validation: 0.27735029381435206]
	TIME [epoch: 19.8 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2562341501565584		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.2562341501565584 | validation: 0.24580250007898563]
	TIME [epoch: 19.8 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23360259612261622		[learning rate: 0.0014107]
	Learning Rate: 0.00141066
	LOSS [training: 0.23360259612261622 | validation: 0.24977840589198386]
	TIME [epoch: 19.8 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2262354906741343		[learning rate: 0.0014051]
	Learning Rate: 0.00140505
	LOSS [training: 0.2262354906741343 | validation: 0.2401626436478888]
	TIME [epoch: 19.8 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22358822214502483		[learning rate: 0.0013995]
	Learning Rate: 0.00139946
	LOSS [training: 0.22358822214502483 | validation: 0.24123205190220834]
	TIME [epoch: 19.8 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23108673938778013		[learning rate: 0.0013939]
	Learning Rate: 0.0013939
	LOSS [training: 0.23108673938778013 | validation: 0.24014958693033753]
	TIME [epoch: 19.8 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.234247235415591		[learning rate: 0.0013884]
	Learning Rate: 0.00138835
	LOSS [training: 0.234247235415591 | validation: 0.24265797299733144]
	TIME [epoch: 19.8 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23171523330486257		[learning rate: 0.0013828]
	Learning Rate: 0.00138283
	LOSS [training: 0.23171523330486257 | validation: 0.24195614937810137]
	TIME [epoch: 19.8 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24935465948581895		[learning rate: 0.0013773]
	Learning Rate: 0.00137733
	LOSS [training: 0.24935465948581895 | validation: 0.2662393643734929]
	TIME [epoch: 19.8 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24375987149338352		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 0.24375987149338352 | validation: 0.250587673744895]
	TIME [epoch: 19.8 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23910973313160883		[learning rate: 0.0013664]
	Learning Rate: 0.0013664
	LOSS [training: 0.23910973313160883 | validation: 0.24891517310530742]
	TIME [epoch: 19.8 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23086127800767942		[learning rate: 0.001361]
	Learning Rate: 0.00136096
	LOSS [training: 0.23086127800767942 | validation: 0.23722669460004725]
	TIME [epoch: 19.8 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22333257491385894		[learning rate: 0.0013555]
	Learning Rate: 0.00135555
	LOSS [training: 0.22333257491385894 | validation: 0.25790281081413396]
	TIME [epoch: 19.8 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23983879427716356		[learning rate: 0.0013502]
	Learning Rate: 0.00135016
	LOSS [training: 0.23983879427716356 | validation: 0.2545836650698115]
	TIME [epoch: 19.8 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2309867022188906		[learning rate: 0.0013448]
	Learning Rate: 0.00134479
	LOSS [training: 0.2309867022188906 | validation: 0.2592117763241372]
	TIME [epoch: 19.8 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.244814116381943		[learning rate: 0.0013394]
	Learning Rate: 0.00133944
	LOSS [training: 0.244814116381943 | validation: 0.24730892926257061]
	TIME [epoch: 19.8 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22723672906931597		[learning rate: 0.0013341]
	Learning Rate: 0.00133411
	LOSS [training: 0.22723672906931597 | validation: 0.23802594759855622]
	TIME [epoch: 19.8 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23179274620025048		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.23179274620025048 | validation: 0.2500288091888295]
	TIME [epoch: 19.8 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22650920880690173		[learning rate: 0.0013235]
	Learning Rate: 0.00132352
	LOSS [training: 0.22650920880690173 | validation: 0.26063132619251755]
	TIME [epoch: 19.8 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23675290261183018		[learning rate: 0.0013183]
	Learning Rate: 0.00131826
	LOSS [training: 0.23675290261183018 | validation: 0.24032748104222787]
	TIME [epoch: 19.8 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22819380398985675		[learning rate: 0.001313]
	Learning Rate: 0.00131301
	LOSS [training: 0.22819380398985675 | validation: 0.2483239197407082]
	TIME [epoch: 19.8 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23235136864363126		[learning rate: 0.0013078]
	Learning Rate: 0.00130779
	LOSS [training: 0.23235136864363126 | validation: 0.2579842297380447]
	TIME [epoch: 19.8 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2269786318632561		[learning rate: 0.0013026]
	Learning Rate: 0.00130259
	LOSS [training: 0.2269786318632561 | validation: 0.24397705579428383]
	TIME [epoch: 19.8 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22426745676797216		[learning rate: 0.0012974]
	Learning Rate: 0.00129741
	LOSS [training: 0.22426745676797216 | validation: 0.24464882533693152]
	TIME [epoch: 19.8 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24285626428311613		[learning rate: 0.0012922]
	Learning Rate: 0.00129225
	LOSS [training: 0.24285626428311613 | validation: 0.24270792785384648]
	TIME [epoch: 19.8 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23170951688776073		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 0.23170951688776073 | validation: 0.24606758862134734]
	TIME [epoch: 19.8 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2305378615449374		[learning rate: 0.001282]
	Learning Rate: 0.00128199
	LOSS [training: 0.2305378615449374 | validation: 0.24858033363979373]
	TIME [epoch: 19.8 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23162672367427609		[learning rate: 0.0012769]
	Learning Rate: 0.00127689
	LOSS [training: 0.23162672367427609 | validation: 0.24333170551454214]
	TIME [epoch: 19.8 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22313076727020092		[learning rate: 0.0012718]
	Learning Rate: 0.00127181
	LOSS [training: 0.22313076727020092 | validation: 0.23616704925129867]
	TIME [epoch: 19.8 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22854285512520356		[learning rate: 0.0012668]
	Learning Rate: 0.00126675
	LOSS [training: 0.22854285512520356 | validation: 0.23738502000364936]
	TIME [epoch: 19.8 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23057570871092892		[learning rate: 0.0012617]
	Learning Rate: 0.00126172
	LOSS [training: 0.23057570871092892 | validation: 0.24601404771334073]
	TIME [epoch: 19.8 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2291990494709783		[learning rate: 0.0012567]
	Learning Rate: 0.0012567
	LOSS [training: 0.2291990494709783 | validation: 0.2817207153990681]
	TIME [epoch: 19.8 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23476994835721815		[learning rate: 0.0012517]
	Learning Rate: 0.0012517
	LOSS [training: 0.23476994835721815 | validation: 0.2430639563844536]
	TIME [epoch: 19.8 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22667863140073552		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 0.22667863140073552 | validation: 0.24120632998506872]
	TIME [epoch: 19.8 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24209016566156963		[learning rate: 0.0012418]
	Learning Rate: 0.00124176
	LOSS [training: 0.24209016566156963 | validation: 0.24830600692853788]
	TIME [epoch: 19.8 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2500390587128169		[learning rate: 0.0012368]
	Learning Rate: 0.00123682
	LOSS [training: 0.2500390587128169 | validation: 0.2532464938214739]
	TIME [epoch: 19.8 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23703140161201575		[learning rate: 0.0012319]
	Learning Rate: 0.0012319
	LOSS [training: 0.23703140161201575 | validation: 0.24371364299283185]
	TIME [epoch: 19.8 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22603282483659737		[learning rate: 0.001227]
	Learning Rate: 0.001227
	LOSS [training: 0.22603282483659737 | validation: 0.2667287719839463]
	TIME [epoch: 19.8 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23221254414311313		[learning rate: 0.0012221]
	Learning Rate: 0.00122212
	LOSS [training: 0.23221254414311313 | validation: 0.23345202136706694]
	TIME [epoch: 19.8 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v10_20240711_153302/states/model_facs_dec1b_2dpca_v10_572.pth
	Model improved!!!
EPOCH 573/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.21801554213498323		[learning rate: 0.0012173]
	Learning Rate: 0.00121726
	LOSS [training: 0.21801554213498323 | validation: 0.2352516606129103]
	TIME [epoch: 19.8 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2231849843258444		[learning rate: 0.0012124]
	Learning Rate: 0.00121242
	LOSS [training: 0.2231849843258444 | validation: 0.23530922828726125]
	TIME [epoch: 19.8 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2240388974458362		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 0.2240388974458362 | validation: 0.2500358899768876]
	TIME [epoch: 19.8 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23257255649044709		[learning rate: 0.0012028]
	Learning Rate: 0.0012028
	LOSS [training: 0.23257255649044709 | validation: 0.23184881682966024]
	TIME [epoch: 19.8 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v10_20240711_153302/states/model_facs_dec1b_2dpca_v10_576.pth
	Model improved!!!
EPOCH 577/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2258931344797903		[learning rate: 0.001198]
	Learning Rate: 0.00119801
	LOSS [training: 0.2258931344797903 | validation: 0.24741820752227867]
	TIME [epoch: 19.8 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24584233975880812		[learning rate: 0.0011932]
	Learning Rate: 0.00119325
	LOSS [training: 0.24584233975880812 | validation: 0.2629025692214423]
	TIME [epoch: 19.8 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2547312619783699		[learning rate: 0.0011885]
	Learning Rate: 0.0011885
	LOSS [training: 0.2547312619783699 | validation: 0.23396045865365714]
	TIME [epoch: 19.8 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2306429498480202		[learning rate: 0.0011838]
	Learning Rate: 0.00118378
	LOSS [training: 0.2306429498480202 | validation: 0.23378811568864508]
	TIME [epoch: 19.8 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22572774724607925		[learning rate: 0.0011791]
	Learning Rate: 0.00117907
	LOSS [training: 0.22572774724607925 | validation: 0.23680387276947998]
	TIME [epoch: 19.8 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23160956507628339		[learning rate: 0.0011744]
	Learning Rate: 0.00117438
	LOSS [training: 0.23160956507628339 | validation: 0.24149365273614626]
	TIME [epoch: 19.8 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2282783839125807		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 0.2282783839125807 | validation: 0.2482174335633554]
	TIME [epoch: 19.8 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22840575685689032		[learning rate: 0.0011651]
	Learning Rate: 0.00116505
	LOSS [training: 0.22840575685689032 | validation: 0.23665991246344592]
	TIME [epoch: 19.8 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22784603024777134		[learning rate: 0.0011604]
	Learning Rate: 0.00116042
	LOSS [training: 0.22784603024777134 | validation: 0.24512309714703817]
	TIME [epoch: 19.8 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22633811757273353		[learning rate: 0.0011558]
	Learning Rate: 0.00115581
	LOSS [training: 0.22633811757273353 | validation: 0.24573331763087172]
	TIME [epoch: 19.8 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23588676605503978		[learning rate: 0.0011512]
	Learning Rate: 0.00115121
	LOSS [training: 0.23588676605503978 | validation: 0.24817315430469566]
	TIME [epoch: 19.8 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2644396547851661		[learning rate: 0.0011466]
	Learning Rate: 0.00114663
	LOSS [training: 0.2644396547851661 | validation: 0.2341875020519058]
	TIME [epoch: 19.9 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22727669587575383		[learning rate: 0.0011421]
	Learning Rate: 0.00114207
	LOSS [training: 0.22727669587575383 | validation: 0.2418901240050439]
	TIME [epoch: 19.9 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22508232360471384		[learning rate: 0.0011375]
	Learning Rate: 0.00113753
	LOSS [training: 0.22508232360471384 | validation: 0.23639501581904532]
	TIME [epoch: 19.8 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2200075053188975		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.2200075053188975 | validation: 0.2348192357546255]
	TIME [epoch: 19.8 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2359197844352346		[learning rate: 0.0011285]
	Learning Rate: 0.0011285
	LOSS [training: 0.2359197844352346 | validation: 0.24485505879798525]
	TIME [epoch: 19.8 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22600796048901317		[learning rate: 0.001124]
	Learning Rate: 0.00112401
	LOSS [training: 0.22600796048901317 | validation: 0.23389687876498844]
	TIME [epoch: 19.8 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2294001437012826		[learning rate: 0.0011195]
	Learning Rate: 0.00111954
	LOSS [training: 0.2294001437012826 | validation: 0.2359016908565797]
	TIME [epoch: 19.8 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23643906070100001		[learning rate: 0.0011151]
	Learning Rate: 0.00111508
	LOSS [training: 0.23643906070100001 | validation: 0.23770075840488625]
	TIME [epoch: 19.8 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22821201231256444		[learning rate: 0.0011106]
	Learning Rate: 0.00111065
	LOSS [training: 0.22821201231256444 | validation: 0.22843417853244255]
	TIME [epoch: 19.8 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v10_20240711_153302/states/model_facs_dec1b_2dpca_v10_596.pth
	Model improved!!!
EPOCH 597/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22401734158411138		[learning rate: 0.0011062]
	Learning Rate: 0.00110623
	LOSS [training: 0.22401734158411138 | validation: 0.2361382697557331]
	TIME [epoch: 19.8 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2510418441069887		[learning rate: 0.0011018]
	Learning Rate: 0.00110183
	LOSS [training: 0.2510418441069887 | validation: 0.28241842886104473]
	TIME [epoch: 19.8 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2618172995395498		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 0.2618172995395498 | validation: 0.2658060910756425]
	TIME [epoch: 19.8 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25306639174969514		[learning rate: 0.0010931]
	Learning Rate: 0.00109309
	LOSS [training: 0.25306639174969514 | validation: 0.29107353129920177]
	TIME [epoch: 19.8 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25762470457360237		[learning rate: 0.0010887]
	Learning Rate: 0.00108874
	LOSS [training: 0.25762470457360237 | validation: 0.25395682028505934]
	TIME [epoch: 19.8 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2676893214912233		[learning rate: 0.0010844]
	Learning Rate: 0.00108441
	LOSS [training: 0.2676893214912233 | validation: 0.2592010053471637]
	TIME [epoch: 19.8 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26059094269744787		[learning rate: 0.0010801]
	Learning Rate: 0.00108009
	LOSS [training: 0.26059094269744787 | validation: 0.23734719343698624]
	TIME [epoch: 19.8 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23504893701664997		[learning rate: 0.0010758]
	Learning Rate: 0.0010758
	LOSS [training: 0.23504893701664997 | validation: 0.2271002814313356]
	TIME [epoch: 19.8 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v10_20240711_153302/states/model_facs_dec1b_2dpca_v10_604.pth
	Model improved!!!
EPOCH 605/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23478946281152618		[learning rate: 0.0010715]
	Learning Rate: 0.00107152
	LOSS [training: 0.23478946281152618 | validation: 0.2420392294380894]
	TIME [epoch: 19.9 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23291392627314622		[learning rate: 0.0010673]
	Learning Rate: 0.00106726
	LOSS [training: 0.23291392627314622 | validation: 0.2325556552417633]
	TIME [epoch: 19.8 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23029054882396732		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 0.23029054882396732 | validation: 0.23171711424329838]
	TIME [epoch: 19.9 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22560155935207313		[learning rate: 0.0010588]
	Learning Rate: 0.00105878
	LOSS [training: 0.22560155935207313 | validation: 0.2401503010568001]
	TIME [epoch: 19.8 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22944693393321902		[learning rate: 0.0010546]
	Learning Rate: 0.00105457
	LOSS [training: 0.22944693393321902 | validation: 0.2350130720146975]
	TIME [epoch: 19.8 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22291387672206606		[learning rate: 0.0010504]
	Learning Rate: 0.00105038
	LOSS [training: 0.22291387672206606 | validation: 0.2277871856723516]
	TIME [epoch: 19.8 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22957375215774758		[learning rate: 0.0010462]
	Learning Rate: 0.0010462
	LOSS [training: 0.22957375215774758 | validation: 0.23166810361261017]
	TIME [epoch: 19.8 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23182372908952745		[learning rate: 0.001042]
	Learning Rate: 0.00104204
	LOSS [training: 0.23182372908952745 | validation: 0.2351166287446477]
	TIME [epoch: 19.8 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23896355765624153		[learning rate: 0.0010379]
	Learning Rate: 0.0010379
	LOSS [training: 0.23896355765624153 | validation: 0.23599773690541329]
	TIME [epoch: 19.8 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22683577156649604		[learning rate: 0.0010338]
	Learning Rate: 0.00103377
	LOSS [training: 0.22683577156649604 | validation: 0.2320934029524008]
	TIME [epoch: 19.8 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22733506768474404		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 0.22733506768474404 | validation: 0.2617336692309638]
	TIME [epoch: 19.8 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24019825742171255		[learning rate: 0.0010256]
	Learning Rate: 0.00102556
	LOSS [training: 0.24019825742171255 | validation: 0.23602376968988587]
	TIME [epoch: 19.8 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23574255065676578		[learning rate: 0.0010215]
	Learning Rate: 0.00102148
	LOSS [training: 0.23574255065676578 | validation: 0.23043576555722298]
	TIME [epoch: 19.8 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2253989909250883		[learning rate: 0.0010174]
	Learning Rate: 0.00101742
	LOSS [training: 0.2253989909250883 | validation: 0.233092931249893]
	TIME [epoch: 19.8 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24110687203730585		[learning rate: 0.0010134]
	Learning Rate: 0.00101337
	LOSS [training: 0.24110687203730585 | validation: 0.23972114600767463]
	TIME [epoch: 19.8 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22287687975359274		[learning rate: 0.0010093]
	Learning Rate: 0.00100934
	LOSS [training: 0.22287687975359274 | validation: 0.23283523412148094]
	TIME [epoch: 19.8 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22401299008850095		[learning rate: 0.0010053]
	Learning Rate: 0.00100533
	LOSS [training: 0.22401299008850095 | validation: 0.23078255665276762]
	TIME [epoch: 19.8 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23283085553618005		[learning rate: 0.0010013]
	Learning Rate: 0.00100133
	LOSS [training: 0.23283085553618005 | validation: 0.23149052129851394]
	TIME [epoch: 19.9 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2201429675464931		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 0.2201429675464931 | validation: 0.2307138494727578]
	TIME [epoch: 19.8 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2562705151791065		[learning rate: 0.00099338]
	Learning Rate: 0.00099338
	LOSS [training: 0.2562705151791065 | validation: 0.2366159603829941]
	TIME [epoch: 19.8 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23435198894837184		[learning rate: 0.00098943]
	Learning Rate: 0.000989429
	LOSS [training: 0.23435198894837184 | validation: 0.23061937748881708]
	TIME [epoch: 19.8 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2304344999442132		[learning rate: 0.00098549]
	Learning Rate: 0.000985494
	LOSS [training: 0.2304344999442132 | validation: 0.23732738414896248]
	TIME [epoch: 19.8 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22667734153181873		[learning rate: 0.00098157]
	Learning Rate: 0.000981574
	LOSS [training: 0.22667734153181873 | validation: 0.23151675752091933]
	TIME [epoch: 19.8 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.21821733969771934		[learning rate: 0.00097767]
	Learning Rate: 0.00097767
	LOSS [training: 0.21821733969771934 | validation: 0.2355849743470019]
	TIME [epoch: 19.8 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23008638986166474		[learning rate: 0.00097378]
	Learning Rate: 0.000973782
	LOSS [training: 0.23008638986166474 | validation: 0.27577733378076147]
	TIME [epoch: 19.8 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.33950173166257397		[learning rate: 0.00096991]
	Learning Rate: 0.000969909
	LOSS [training: 0.33950173166257397 | validation: 0.35435080991339474]
	TIME [epoch: 19.8 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32314733673859186		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.32314733673859186 | validation: 0.2992485367216549]
	TIME [epoch: 19.8 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.27807693213641094		[learning rate: 0.00096221]
	Learning Rate: 0.000962209
	LOSS [training: 0.27807693213641094 | validation: 0.2743258065865968]
	TIME [epoch: 19.8 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2505512696166967		[learning rate: 0.00095838]
	Learning Rate: 0.000958382
	LOSS [training: 0.2505512696166967 | validation: 0.2621396477241904]
	TIME [epoch: 19.8 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24931232080630406		[learning rate: 0.00095457]
	Learning Rate: 0.00095457
	LOSS [training: 0.24931232080630406 | validation: 0.25209673566732976]
	TIME [epoch: 19.8 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24420086292458182		[learning rate: 0.00095077]
	Learning Rate: 0.000950773
	LOSS [training: 0.24420086292458182 | validation: 0.2492866545848748]
	TIME [epoch: 19.8 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23833176482941065		[learning rate: 0.00094699]
	Learning Rate: 0.000946992
	LOSS [training: 0.23833176482941065 | validation: 0.26027883905041194]
	TIME [epoch: 19.8 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24168456808925054		[learning rate: 0.00094323]
	Learning Rate: 0.000943225
	LOSS [training: 0.24168456808925054 | validation: 0.2520202668008909]
	TIME [epoch: 19.8 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23528562435552416		[learning rate: 0.00093947]
	Learning Rate: 0.000939474
	LOSS [training: 0.23528562435552416 | validation: 0.2492131922530533]
	TIME [epoch: 19.8 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23212799685622784		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.23212799685622784 | validation: 0.2618284048609544]
	TIME [epoch: 19.8 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24364179688227694		[learning rate: 0.00093202]
	Learning Rate: 0.000932015
	LOSS [training: 0.24364179688227694 | validation: 0.25314189554895006]
	TIME [epoch: 19.8 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2394270521230345		[learning rate: 0.00092831]
	Learning Rate: 0.000928309
	LOSS [training: 0.2394270521230345 | validation: 0.2626670552364617]
	TIME [epoch: 19.8 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23544327498316753		[learning rate: 0.00092462]
	Learning Rate: 0.000924616
	LOSS [training: 0.23544327498316753 | validation: 0.24147047441360944]
	TIME [epoch: 19.8 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23548297141961705		[learning rate: 0.00092094]
	Learning Rate: 0.000920939
	LOSS [training: 0.23548297141961705 | validation: 0.2870010876853863]
	TIME [epoch: 19.8 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2515260122492984		[learning rate: 0.00091728]
	Learning Rate: 0.000917276
	LOSS [training: 0.2515260122492984 | validation: 0.24962428040030896]
	TIME [epoch: 19.8 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2309312443836807		[learning rate: 0.00091363]
	Learning Rate: 0.000913628
	LOSS [training: 0.2309312443836807 | validation: 0.24283217033665805]
	TIME [epoch: 19.8 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22738057827139452		[learning rate: 0.00090999]
	Learning Rate: 0.000909994
	LOSS [training: 0.22738057827139452 | validation: 0.2589982383606038]
	TIME [epoch: 19.8 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24042748079137757		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.24042748079137757 | validation: 0.23768203768188578]
	TIME [epoch: 19.8 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22520449925445224		[learning rate: 0.00090277]
	Learning Rate: 0.00090277
	LOSS [training: 0.22520449925445224 | validation: 0.22738724131773497]
	TIME [epoch: 19.8 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22693013825128025		[learning rate: 0.00089918]
	Learning Rate: 0.000899179
	LOSS [training: 0.22693013825128025 | validation: 0.26138967738215096]
	TIME [epoch: 19.9 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2318285293431886		[learning rate: 0.0008956]
	Learning Rate: 0.000895603
	LOSS [training: 0.2318285293431886 | validation: 0.23464373879235598]
	TIME [epoch: 19.8 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.21768594374850078		[learning rate: 0.00089204]
	Learning Rate: 0.000892041
	LOSS [training: 0.21768594374850078 | validation: 0.22903958528064403]
	TIME [epoch: 19.9 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.21869997248731374		[learning rate: 0.00088849]
	Learning Rate: 0.000888493
	LOSS [training: 0.21869997248731374 | validation: 0.23456927540263955]
	TIME [epoch: 19.8 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2177656086083779		[learning rate: 0.00088496]
	Learning Rate: 0.000884959
	LOSS [training: 0.2177656086083779 | validation: 0.23686862163252315]
	TIME [epoch: 19.8 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2274241097917994		[learning rate: 0.00088144]
	Learning Rate: 0.000881439
	LOSS [training: 0.2274241097917994 | validation: 0.22840327162342383]
	TIME [epoch: 19.8 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2133612752378683		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 0.2133612752378683 | validation: 0.22431560065642656]
	TIME [epoch: 19.8 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v10_20240711_153302/states/model_facs_dec1b_2dpca_v10_655.pth
	Model improved!!!
EPOCH 656/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.21569305489422708		[learning rate: 0.00087444]
	Learning Rate: 0.000874441
	LOSS [training: 0.21569305489422708 | validation: 0.23605517684168217]
	TIME [epoch: 19.8 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.21691261066048634		[learning rate: 0.00087096]
	Learning Rate: 0.000870964
	LOSS [training: 0.21691261066048634 | validation: 0.22605586382959553]
	TIME [epoch: 19.8 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.21940911961283996		[learning rate: 0.0008675]
	Learning Rate: 0.0008675
	LOSS [training: 0.21940911961283996 | validation: 0.2291561283040629]
	TIME [epoch: 19.8 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22028444259212676		[learning rate: 0.00086405]
	Learning Rate: 0.000864049
	LOSS [training: 0.22028444259212676 | validation: 0.2374891355113225]
	TIME [epoch: 19.8 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22044487933596024		[learning rate: 0.00086061]
	Learning Rate: 0.000860613
	LOSS [training: 0.22044487933596024 | validation: 0.23567389689974072]
	TIME [epoch: 19.8 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22715319493221564		[learning rate: 0.00085719]
	Learning Rate: 0.00085719
	LOSS [training: 0.22715319493221564 | validation: 0.23108060208793962]
	TIME [epoch: 19.8 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22135776495058254		[learning rate: 0.00085378]
	Learning Rate: 0.00085378
	LOSS [training: 0.22135776495058254 | validation: 0.2258085310695705]
	TIME [epoch: 19.8 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22459408270945166		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 0.22459408270945166 | validation: 0.24651083853868547]
	TIME [epoch: 19.8 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23026535015205038		[learning rate: 0.000847]
	Learning Rate: 0.000847002
	LOSS [training: 0.23026535015205038 | validation: 0.23227551598645904]
	TIME [epoch: 19.8 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22023184855848854		[learning rate: 0.00084363]
	Learning Rate: 0.000843634
	LOSS [training: 0.22023184855848854 | validation: 0.2230320657866554]
	TIME [epoch: 19.8 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v10_20240711_153302/states/model_facs_dec1b_2dpca_v10_665.pth
	Model improved!!!
EPOCH 666/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.21753248527036934		[learning rate: 0.00084028]
	Learning Rate: 0.000840278
	LOSS [training: 0.21753248527036934 | validation: 0.23989117557287426]
	TIME [epoch: 19.8 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2262606201720724		[learning rate: 0.00083694]
	Learning Rate: 0.000836936
	LOSS [training: 0.2262606201720724 | validation: 0.24025170525471262]
	TIME [epoch: 19.8 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2270069743505383		[learning rate: 0.00083361]
	Learning Rate: 0.000833608
	LOSS [training: 0.2270069743505383 | validation: 0.23285085273986988]
	TIME [epoch: 19.8 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2222644346423931		[learning rate: 0.00083029]
	Learning Rate: 0.000830292
	LOSS [training: 0.2222644346423931 | validation: 0.22823217231653312]
	TIME [epoch: 19.8 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24445447185303923		[learning rate: 0.00082699]
	Learning Rate: 0.00082699
	LOSS [training: 0.24445447185303923 | validation: 0.29339644369793905]
	TIME [epoch: 19.8 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2781555531540477		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.2781555531540477 | validation: 0.27303758353405766]
	TIME [epoch: 19.8 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25603627192705736		[learning rate: 0.00082042]
	Learning Rate: 0.000820424
	LOSS [training: 0.25603627192705736 | validation: 0.2656818389258819]
	TIME [epoch: 19.8 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24651310161211418		[learning rate: 0.00081716]
	Learning Rate: 0.000817161
	LOSS [training: 0.24651310161211418 | validation: 0.26070289173720074]
	TIME [epoch: 19.8 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23632163139695964		[learning rate: 0.00081391]
	Learning Rate: 0.000813911
	LOSS [training: 0.23632163139695964 | validation: 0.24752395404820984]
	TIME [epoch: 19.8 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2450181633798283		[learning rate: 0.00081067]
	Learning Rate: 0.000810674
	LOSS [training: 0.2450181633798283 | validation: 0.2616233905308135]
	TIME [epoch: 19.8 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2567182627550182		[learning rate: 0.00080745]
	Learning Rate: 0.00080745
	LOSS [training: 0.2567182627550182 | validation: 0.27485252229285695]
	TIME [epoch: 19.8 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2456401160976448		[learning rate: 0.00080424]
	Learning Rate: 0.000804238
	LOSS [training: 0.2456401160976448 | validation: 0.26142607831943604]
	TIME [epoch: 19.8 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2454894251618439		[learning rate: 0.00080104]
	Learning Rate: 0.000801039
	LOSS [training: 0.2454894251618439 | validation: 0.27899364435430474]
	TIME [epoch: 19.8 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3185701636591117		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 0.3185701636591117 | validation: 0.29567905539215145]
	TIME [epoch: 19.8 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.28068614003313175		[learning rate: 0.00079468]
	Learning Rate: 0.00079468
	LOSS [training: 0.28068614003313175 | validation: 0.2760367524466938]
	TIME [epoch: 19.8 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2624988632228488		[learning rate: 0.00079152]
	Learning Rate: 0.000791519
	LOSS [training: 0.2624988632228488 | validation: 0.2717284314508025]
	TIME [epoch: 19.8 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25875782577816453		[learning rate: 0.00078837]
	Learning Rate: 0.000788371
	LOSS [training: 0.25875782577816453 | validation: 0.2679481808006735]
	TIME [epoch: 19.8 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25426977362232656		[learning rate: 0.00078524]
	Learning Rate: 0.000785236
	LOSS [training: 0.25426977362232656 | validation: 0.25730478806250956]
	TIME [epoch: 19.8 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24540839833267458		[learning rate: 0.00078211]
	Learning Rate: 0.000782113
	LOSS [training: 0.24540839833267458 | validation: 0.2580702296627796]
	TIME [epoch: 19.8 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24296729704763098		[learning rate: 0.000779]
	Learning Rate: 0.000779002
	LOSS [training: 0.24296729704763098 | validation: 0.253727801589241]
	TIME [epoch: 19.8 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24146504773556407		[learning rate: 0.0007759]
	Learning Rate: 0.000775904
	LOSS [training: 0.24146504773556407 | validation: 0.25319888325765205]
	TIME [epoch: 19.8 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23426041207006554		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 0.23426041207006554 | validation: 0.24516452751468223]
	TIME [epoch: 19.8 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2282438962945489		[learning rate: 0.00076974]
	Learning Rate: 0.000769744
	LOSS [training: 0.2282438962945489 | validation: 0.2445986054148539]
	TIME [epoch: 19.8 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22892193626720983		[learning rate: 0.00076668]
	Learning Rate: 0.000766682
	LOSS [training: 0.22892193626720983 | validation: 0.24763411921763506]
	TIME [epoch: 19.8 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23102603810206135		[learning rate: 0.00076363]
	Learning Rate: 0.000763633
	LOSS [training: 0.23102603810206135 | validation: 0.2631320820762403]
	TIME [epoch: 19.8 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24254157610742316		[learning rate: 0.0007606]
	Learning Rate: 0.000760596
	LOSS [training: 0.24254157610742316 | validation: 0.25398898098037803]
	TIME [epoch: 19.8 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23514848600249716		[learning rate: 0.00075757]
	Learning Rate: 0.000757571
	LOSS [training: 0.23514848600249716 | validation: 0.24124900076021566]
	TIME [epoch: 19.8 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23961548637026725		[learning rate: 0.00075456]
	Learning Rate: 0.000754557
	LOSS [training: 0.23961548637026725 | validation: 0.24775508266371205]
	TIME [epoch: 19.8 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23593583525799738		[learning rate: 0.00075156]
	Learning Rate: 0.000751556
	LOSS [training: 0.23593583525799738 | validation: 0.251485610409823]
	TIME [epoch: 19.8 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23075766222316252		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 0.23075766222316252 | validation: 0.25459974092751525]
	TIME [epoch: 19.8 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23609404547507268		[learning rate: 0.00074559]
	Learning Rate: 0.00074559
	LOSS [training: 0.23609404547507268 | validation: 0.2506713927347285]
	TIME [epoch: 19.8 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23521100294858086		[learning rate: 0.00074262]
	Learning Rate: 0.000742624
	LOSS [training: 0.23521100294858086 | validation: 0.24851717426124723]
	TIME [epoch: 19.8 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23130406327999292		[learning rate: 0.00073967]
	Learning Rate: 0.000739671
	LOSS [training: 0.23130406327999292 | validation: 0.25168075774690263]
	TIME [epoch: 19.8 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23664935882697208		[learning rate: 0.00073673]
	Learning Rate: 0.000736729
	LOSS [training: 0.23664935882697208 | validation: 0.249623522717591]
	TIME [epoch: 19.8 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2267333542549288		[learning rate: 0.0007338]
	Learning Rate: 0.000733799
	LOSS [training: 0.2267333542549288 | validation: 0.23891818902417472]
	TIME [epoch: 19.8 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22449239971865578		[learning rate: 0.00073088]
	Learning Rate: 0.00073088
	LOSS [training: 0.22449239971865578 | validation: 0.23886144135402013]
	TIME [epoch: 19.8 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22411988411832054		[learning rate: 0.00072797]
	Learning Rate: 0.000727973
	LOSS [training: 0.22411988411832054 | validation: 0.2475999313764373]
	TIME [epoch: 19.8 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23090742493056007		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 0.23090742493056007 | validation: 0.2389512011120151]
	TIME [epoch: 19.8 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2380290257646653		[learning rate: 0.00072219]
	Learning Rate: 0.000722194
	LOSS [training: 0.2380290257646653 | validation: 0.24376092375358666]
	TIME [epoch: 19.8 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23227817433844264		[learning rate: 0.00071932]
	Learning Rate: 0.000719322
	LOSS [training: 0.23227817433844264 | validation: 0.24137572502666566]
	TIME [epoch: 19.8 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22552340855860475		[learning rate: 0.00071646]
	Learning Rate: 0.000716461
	LOSS [training: 0.22552340855860475 | validation: 0.23970675791577226]
	TIME [epoch: 19.8 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22745268824597098		[learning rate: 0.00071361]
	Learning Rate: 0.000713611
	LOSS [training: 0.22745268824597098 | validation: 0.25175240137616806]
	TIME [epoch: 19.8 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2319041254756869		[learning rate: 0.00071077]
	Learning Rate: 0.000710773
	LOSS [training: 0.2319041254756869 | validation: 0.24200767087159702]
	TIME [epoch: 19.8 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22130558070626438		[learning rate: 0.00070795]
	Learning Rate: 0.000707946
	LOSS [training: 0.22130558070626438 | validation: 0.2369097605784704]
	TIME [epoch: 19.8 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2278991109385351		[learning rate: 0.00070513]
	Learning Rate: 0.00070513
	LOSS [training: 0.2278991109385351 | validation: 0.24399618355810135]
	TIME [epoch: 19.8 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23322735737526182		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.23322735737526182 | validation: 0.24506588074630323]
	TIME [epoch: 19.8 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2443465577042813		[learning rate: 0.00069953]
	Learning Rate: 0.000699532
	LOSS [training: 0.2443465577042813 | validation: 0.2442278183792852]
	TIME [epoch: 19.8 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2503565078992555		[learning rate: 0.00069675]
	Learning Rate: 0.00069675
	LOSS [training: 0.2503565078992555 | validation: 0.2685866620411152]
	TIME [epoch: 19.8 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25019978159551404		[learning rate: 0.00069398]
	Learning Rate: 0.000693979
	LOSS [training: 0.25019978159551404 | validation: 0.25505455884288425]
	TIME [epoch: 19.8 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2398383816569354		[learning rate: 0.00069122]
	Learning Rate: 0.000691219
	LOSS [training: 0.2398383816569354 | validation: 0.26687992284676726]
	TIME [epoch: 19.8 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.28151218891530366		[learning rate: 0.00068847]
	Learning Rate: 0.000688469
	LOSS [training: 0.28151218891530366 | validation: 0.3106959475062975]
	TIME [epoch: 19.8 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.35770065429194786		[learning rate: 0.00068573]
	Learning Rate: 0.000685731
	LOSS [training: 0.35770065429194786 | validation: 0.47263070617023634]
	TIME [epoch: 19.8 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3570904094175818		[learning rate: 0.000683]
	Learning Rate: 0.000683004
	LOSS [training: 0.3570904094175818 | validation: 0.32651594576520876]
	TIME [epoch: 19.8 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.30744860506861843		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 0.30744860506861843 | validation: 0.32688890649281055]
	TIME [epoch: 19.8 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.34626159945764745		[learning rate: 0.00067758]
	Learning Rate: 0.000677582
	LOSS [training: 0.34626159945764745 | validation: 0.42285141313232044]
	TIME [epoch: 19.8 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.39538878526297006		[learning rate: 0.00067489]
	Learning Rate: 0.000674887
	LOSS [training: 0.39538878526297006 | validation: 0.3555528081004911]
	TIME [epoch: 19.8 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.39793994425166024		[learning rate: 0.0006722]
	Learning Rate: 0.000672202
	LOSS [training: 0.39793994425166024 | validation: 0.44855356957753756]
	TIME [epoch: 19.8 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.38582680247532697		[learning rate: 0.00066953]
	Learning Rate: 0.000669529
	LOSS [training: 0.38582680247532697 | validation: 0.35996686219137747]
	TIME [epoch: 19.8 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4027222632192031		[learning rate: 0.00066687]
	Learning Rate: 0.000666866
	LOSS [training: 0.4027222632192031 | validation: 0.46698335056050444]
	TIME [epoch: 19.8 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.39979146921358627		[learning rate: 0.00066421]
	Learning Rate: 0.000664213
	LOSS [training: 0.39979146921358627 | validation: 0.3858593696685415]
	TIME [epoch: 19.8 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.33268195632866765		[learning rate: 0.00066157]
	Learning Rate: 0.000661572
	LOSS [training: 0.33268195632866765 | validation: 0.3035811701052028]
	TIME [epoch: 19.8 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.34447430329682466		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 0.34447430329682466 | validation: 0.4418698752227369]
	TIME [epoch: 19.8 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.39694730578760384		[learning rate: 0.00065632]
	Learning Rate: 0.00065632
	LOSS [training: 0.39694730578760384 | validation: 0.3907103035258265]
	TIME [epoch: 19.8 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3567829892683748		[learning rate: 0.00065371]
	Learning Rate: 0.000653709
	LOSS [training: 0.3567829892683748 | validation: 0.29795502946637364]
	TIME [epoch: 19.8 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.33674236120391426		[learning rate: 0.00065111]
	Learning Rate: 0.000651109
	LOSS [training: 0.33674236120391426 | validation: 0.3940729256621525]
	TIME [epoch: 19.8 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.43538071769155606		[learning rate: 0.00064852]
	Learning Rate: 0.00064852
	LOSS [training: 0.43538071769155606 | validation: 0.4955282129282613]
	TIME [epoch: 19.8 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.37737614198470315		[learning rate: 0.00064594]
	Learning Rate: 0.00064594
	LOSS [training: 0.37737614198470315 | validation: 0.38841043368195244]
	TIME [epoch: 19.8 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.36775695419295673		[learning rate: 0.00064337]
	Learning Rate: 0.000643371
	LOSS [training: 0.36775695419295673 | validation: 0.3125447106481757]
	TIME [epoch: 19.8 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3423335753087167		[learning rate: 0.00064081]
	Learning Rate: 0.000640812
	LOSS [training: 0.3423335753087167 | validation: 0.3322009711654692]
	TIME [epoch: 19.8 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4423854243373924		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 0.4423854243373924 | validation: 0.41624471916051176]
	TIME [epoch: 19.8 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.48404019042866014		[learning rate: 0.00063572]
	Learning Rate: 0.000635725
	LOSS [training: 0.48404019042866014 | validation: 0.5131393924001534]
	TIME [epoch: 19.8 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5830501785348852		[learning rate: 0.0006332]
	Learning Rate: 0.000633196
	LOSS [training: 0.5830501785348852 | validation: 0.5567857418794022]
	TIME [epoch: 19.8 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6383650937244414		[learning rate: 0.00063068]
	Learning Rate: 0.000630678
	LOSS [training: 0.6383650937244414 | validation: 0.6883710325527106]
	TIME [epoch: 19.8 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6930429906200514		[learning rate: 0.00062817]
	Learning Rate: 0.00062817
	LOSS [training: 0.6930429906200514 | validation: 0.7705032179788751]
	TIME [epoch: 19.8 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7420930394044825		[learning rate: 0.00062567]
	Learning Rate: 0.000625671
	LOSS [training: 0.7420930394044825 | validation: 0.6504415979876993]
	TIME [epoch: 19.8 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6024507289232964		[learning rate: 0.00062318]
	Learning Rate: 0.000623183
	LOSS [training: 0.6024507289232964 | validation: 0.5709569727641989]
	TIME [epoch: 19.8 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6950944220946914		[learning rate: 0.0006207]
	Learning Rate: 0.000620704
	LOSS [training: 0.6950944220946914 | validation: 0.6789353527851353]
	TIME [epoch: 19.8 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6144042399217287		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 0.6144042399217287 | validation: 0.5455642516447587]
	TIME [epoch: 19.8 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5613369340661309		[learning rate: 0.00061578]
	Learning Rate: 0.000615777
	LOSS [training: 0.5613369340661309 | validation: 0.4970676737202996]
	TIME [epoch: 19.8 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4942479814872683		[learning rate: 0.00061333]
	Learning Rate: 0.000613327
	LOSS [training: 0.4942479814872683 | validation: 0.42253149815668456]
	TIME [epoch: 19.8 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4699497278076746		[learning rate: 0.00061089]
	Learning Rate: 0.000610888
	LOSS [training: 0.4699497278076746 | validation: 0.44656772907266085]
	TIME [epoch: 19.8 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.44521583676008575		[learning rate: 0.00060846]
	Learning Rate: 0.000608458
	LOSS [training: 0.44521583676008575 | validation: 0.4327695845031457]
	TIME [epoch: 19.8 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4402703600629096		[learning rate: 0.00060604]
	Learning Rate: 0.000606038
	LOSS [training: 0.4402703600629096 | validation: 0.4229807195018882]
	TIME [epoch: 19.8 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.40821082300232214		[learning rate: 0.00060363]
	Learning Rate: 0.000603628
	LOSS [training: 0.40821082300232214 | validation: 0.3616255956541759]
	TIME [epoch: 19.8 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4555350555772638		[learning rate: 0.00060123]
	Learning Rate: 0.000601227
	LOSS [training: 0.4555350555772638 | validation: 0.44682004571534134]
	TIME [epoch: 19.8 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.515300338251133		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.515300338251133 | validation: 0.46739338219200166]
	TIME [epoch: 19.8 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.49158170317511096		[learning rate: 0.00059645]
	Learning Rate: 0.000596454
	LOSS [training: 0.49158170317511096 | validation: 0.5338832707592884]
	TIME [epoch: 19.8 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6181846646400468		[learning rate: 0.00059408]
	Learning Rate: 0.000594082
	LOSS [training: 0.6181846646400468 | validation: 0.6815692033570852]
	TIME [epoch: 19.8 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6314527575279099		[learning rate: 0.00059172]
	Learning Rate: 0.000591719
	LOSS [training: 0.6314527575279099 | validation: 0.6848811970632062]
	TIME [epoch: 19.8 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6982371375286444		[learning rate: 0.00058937]
	Learning Rate: 0.000589365
	LOSS [training: 0.6982371375286444 | validation: 0.7993986316835038]
	TIME [epoch: 19.8 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7108303319371536		[learning rate: 0.00058702]
	Learning Rate: 0.000587021
	LOSS [training: 0.7108303319371536 | validation: 0.7067708525013778]
	TIME [epoch: 19.8 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6574080331651532		[learning rate: 0.00058469]
	Learning Rate: 0.000584687
	LOSS [training: 0.6574080331651532 | validation: 0.7110266360622627]
	TIME [epoch: 19.8 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.705186083010751		[learning rate: 0.00058236]
	Learning Rate: 0.000582361
	LOSS [training: 0.705186083010751 | validation: 0.667035359052777]
	TIME [epoch: 19.8 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.609494144771453		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 0.609494144771453 | validation: 0.6010429871921479]
	TIME [epoch: 19.8 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5499825847809758		[learning rate: 0.00057774]
	Learning Rate: 0.000577738
	LOSS [training: 0.5499825847809758 | validation: 0.5359993169653655]
	TIME [epoch: 19.8 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5147356012340247		[learning rate: 0.00057544]
	Learning Rate: 0.00057544
	LOSS [training: 0.5147356012340247 | validation: 0.5593362504300646]
	TIME [epoch: 19.8 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5437533750539734		[learning rate: 0.00057315]
	Learning Rate: 0.000573151
	LOSS [training: 0.5437533750539734 | validation: 0.5827332722239662]
	TIME [epoch: 19.8 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5149275968217913		[learning rate: 0.00057087]
	Learning Rate: 0.000570872
	LOSS [training: 0.5149275968217913 | validation: 0.5186229319750505]
	TIME [epoch: 19.8 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.503899798275626		[learning rate: 0.0005686]
	Learning Rate: 0.000568601
	LOSS [training: 0.503899798275626 | validation: 0.5171719432760508]
	TIME [epoch: 19.8 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5083434365289428		[learning rate: 0.00056634]
	Learning Rate: 0.00056634
	LOSS [training: 0.5083434365289428 | validation: 0.531381131193048]
	TIME [epoch: 19.8 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5183382378904875		[learning rate: 0.00056409]
	Learning Rate: 0.000564087
	LOSS [training: 0.5183382378904875 | validation: 0.5056718603620274]
	TIME [epoch: 19.8 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5121276784082138		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 0.5121276784082138 | validation: 0.5014636262137662]
	TIME [epoch: 19.8 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5099960537506886		[learning rate: 0.00055961]
	Learning Rate: 0.000559609
	LOSS [training: 0.5099960537506886 | validation: 0.5110364335082489]
	TIME [epoch: 19.8 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.47723306298046947		[learning rate: 0.00055738]
	Learning Rate: 0.000557383
	LOSS [training: 0.47723306298046947 | validation: 0.5380663848451734]
	TIME [epoch: 19.8 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4898392975378241		[learning rate: 0.00055517]
	Learning Rate: 0.000555166
	LOSS [training: 0.4898392975378241 | validation: 0.5336064260346782]
	TIME [epoch: 19.8 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4881008965404632		[learning rate: 0.00055296]
	Learning Rate: 0.000552958
	LOSS [training: 0.4881008965404632 | validation: 0.5356689910609489]
	TIME [epoch: 19.8 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4818148718328355		[learning rate: 0.00055076]
	Learning Rate: 0.000550759
	LOSS [training: 0.4818148718328355 | validation: 0.49532613315737634]
	TIME [epoch: 19.8 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4966099905363444		[learning rate: 0.00054857]
	Learning Rate: 0.000548568
	LOSS [training: 0.4966099905363444 | validation: 0.4976968410345954]
	TIME [epoch: 19.8 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5338174473675663		[learning rate: 0.00054639]
	Learning Rate: 0.000546387
	LOSS [training: 0.5338174473675663 | validation: 0.5112466214980579]
	TIME [epoch: 19.8 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5156712062674038		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 0.5156712062674038 | validation: 0.5012996782342827]
	TIME [epoch: 19.8 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5091378342445613		[learning rate: 0.00054205]
	Learning Rate: 0.000542049
	LOSS [training: 0.5091378342445613 | validation: 0.5136717633072253]
	TIME [epoch: 19.8 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.49658636440190357		[learning rate: 0.00053989]
	Learning Rate: 0.000539893
	LOSS [training: 0.49658636440190357 | validation: 0.5138840407335371]
	TIME [epoch: 19.8 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5030264397755682		[learning rate: 0.00053775]
	Learning Rate: 0.000537746
	LOSS [training: 0.5030264397755682 | validation: 0.4987412233436454]
	TIME [epoch: 19.8 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.48255494422303813		[learning rate: 0.00053561]
	Learning Rate: 0.000535607
	LOSS [training: 0.48255494422303813 | validation: 0.474407964915458]
	TIME [epoch: 19.8 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.46686598613675023		[learning rate: 0.00053348]
	Learning Rate: 0.000533477
	LOSS [training: 0.46686598613675023 | validation: 0.48708139706228276]
	TIME [epoch: 19.8 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.47753711478292105		[learning rate: 0.00053135]
	Learning Rate: 0.000531355
	LOSS [training: 0.47753711478292105 | validation: 0.4950361600132605]
	TIME [epoch: 19.8 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4925528361604262		[learning rate: 0.00052924]
	Learning Rate: 0.000529241
	LOSS [training: 0.4925528361604262 | validation: 0.5382755884737203]
	TIME [epoch: 19.8 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5262587111582964		[learning rate: 0.00052714]
	Learning Rate: 0.000527136
	LOSS [training: 0.5262587111582964 | validation: 0.5609297954932537]
	TIME [epoch: 19.8 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.550463895614309		[learning rate: 0.00052504]
	Learning Rate: 0.00052504
	LOSS [training: 0.550463895614309 | validation: 0.5886311643804852]
	TIME [epoch: 19.8 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5795279276806208		[learning rate: 0.00052295]
	Learning Rate: 0.000522952
	LOSS [training: 0.5795279276806208 | validation: 0.5907459309935341]
	TIME [epoch: 19.8 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.548689288236698		[learning rate: 0.00052087]
	Learning Rate: 0.000520872
	LOSS [training: 0.548689288236698 | validation: 0.582303072429858]
	TIME [epoch: 19.8 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.551599479195306		[learning rate: 0.0005188]
	Learning Rate: 0.0005188
	LOSS [training: 0.551599479195306 | validation: 0.6250772214855125]
	TIME [epoch: 19.8 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5720930083696079		[learning rate: 0.00051674]
	Learning Rate: 0.000516737
	LOSS [training: 0.5720930083696079 | validation: 0.6754042325505678]
	TIME [epoch: 19.8 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5873315105116416		[learning rate: 0.00051468]
	Learning Rate: 0.000514681
	LOSS [training: 0.5873315105116416 | validation: 0.716797887032065]
	TIME [epoch: 19.8 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6034564728446766		[learning rate: 0.00051263]
	Learning Rate: 0.000512634
	LOSS [training: 0.6034564728446766 | validation: 0.634032679095412]
	TIME [epoch: 19.8 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5968346408074425		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 0.5968346408074425 | validation: 0.6488237341902394]
	TIME [epoch: 19.8 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6197183389774913		[learning rate: 0.00050856]
	Learning Rate: 0.000508565
	LOSS [training: 0.6197183389774913 | validation: 0.6317999973543931]
	TIME [epoch: 19.8 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6204342692507651		[learning rate: 0.00050654]
	Learning Rate: 0.000506542
	LOSS [training: 0.6204342692507651 | validation: 0.6264877923596562]
	TIME [epoch: 19.8 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6003766764020809		[learning rate: 0.00050453]
	Learning Rate: 0.000504527
	LOSS [training: 0.6003766764020809 | validation: 0.5605551637240194]
	TIME [epoch: 19.8 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5353958355411713		[learning rate: 0.00050252]
	Learning Rate: 0.000502521
	LOSS [training: 0.5353958355411713 | validation: 0.5401599777672905]
	TIME [epoch: 19.8 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5277406939927849		[learning rate: 0.00050052]
	Learning Rate: 0.000500522
	LOSS [training: 0.5277406939927849 | validation: 0.5273979412380324]
	TIME [epoch: 19.8 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5022403627824075		[learning rate: 0.00049853]
	Learning Rate: 0.000498531
	LOSS [training: 0.5022403627824075 | validation: 0.5078479985047688]
	TIME [epoch: 19.8 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4989526212492529		[learning rate: 0.00049655]
	Learning Rate: 0.000496548
	LOSS [training: 0.4989526212492529 | validation: 0.4971622506576508]
	TIME [epoch: 19.8 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4854440512157173		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 0.4854440512157173 | validation: 0.48607862658892326]
	TIME [epoch: 19.8 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.47802910289411193		[learning rate: 0.00049261]
	Learning Rate: 0.000492606
	LOSS [training: 0.47802910289411193 | validation: 0.49837774563131526]
	TIME [epoch: 19.8 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5051814075512715		[learning rate: 0.00049065]
	Learning Rate: 0.000490647
	LOSS [training: 0.5051814075512715 | validation: 0.5319217265175434]
	TIME [epoch: 19.8 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5022016320886772		[learning rate: 0.0004887]
	Learning Rate: 0.000488696
	LOSS [training: 0.5022016320886772 | validation: 0.5164979746981642]
	TIME [epoch: 19.8 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4828353958582298		[learning rate: 0.00048675]
	Learning Rate: 0.000486752
	LOSS [training: 0.4828353958582298 | validation: 0.5259022026274779]
	TIME [epoch: 19.8 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4946964349926782		[learning rate: 0.00048482]
	Learning Rate: 0.000484816
	LOSS [training: 0.4946964349926782 | validation: 0.5548728872405094]
	TIME [epoch: 19.8 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5125812715595901		[learning rate: 0.00048289]
	Learning Rate: 0.000482888
	LOSS [training: 0.5125812715595901 | validation: 0.5518053446850921]
	TIME [epoch: 19.8 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5061331862598158		[learning rate: 0.00048097]
	Learning Rate: 0.000480967
	LOSS [training: 0.5061331862598158 | validation: 0.5252577423727642]
	TIME [epoch: 19.8 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.502104143984515		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 0.502104143984515 | validation: 0.5329197395980692]
	TIME [epoch: 19.8 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5188527564132754		[learning rate: 0.00047715]
	Learning Rate: 0.000477149
	LOSS [training: 0.5188527564132754 | validation: 0.5421369945212511]
	TIME [epoch: 19.8 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5077222165150187		[learning rate: 0.00047525]
	Learning Rate: 0.000475251
	LOSS [training: 0.5077222165150187 | validation: 0.5155098991680696]
	TIME [epoch: 19.8 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5142884844880283		[learning rate: 0.00047336]
	Learning Rate: 0.000473361
	LOSS [training: 0.5142884844880283 | validation: 0.5158455620854914]
	TIME [epoch: 19.8 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5006646543236022		[learning rate: 0.00047148]
	Learning Rate: 0.000471478
	LOSS [training: 0.5006646543236022 | validation: 0.49165328831427946]
	TIME [epoch: 19.8 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4928546171134847		[learning rate: 0.0004696]
	Learning Rate: 0.000469603
	LOSS [training: 0.4928546171134847 | validation: 0.47242120078422867]
	TIME [epoch: 19.8 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4757821079452033		[learning rate: 0.00046774]
	Learning Rate: 0.000467735
	LOSS [training: 0.4757821079452033 | validation: 0.4715760696875521]
	TIME [epoch: 19.8 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.47873183946667175		[learning rate: 0.00046587]
	Learning Rate: 0.000465875
	LOSS [training: 0.47873183946667175 | validation: 0.44757886772928873]
	TIME [epoch: 19.8 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4317596128964604		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 0.4317596128964604 | validation: 0.42547926756799886]
	TIME [epoch: 19.8 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4238395433217074		[learning rate: 0.00046218]
	Learning Rate: 0.000462176
	LOSS [training: 0.4238395433217074 | validation: 0.43217517971969743]
	TIME [epoch: 19.8 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.42103309211758977		[learning rate: 0.00046034]
	Learning Rate: 0.000460338
	LOSS [training: 0.42103309211758977 | validation: 0.4376426431735518]
	TIME [epoch: 19.8 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.44433755646851947		[learning rate: 0.00045851]
	Learning Rate: 0.000458507
	LOSS [training: 0.44433755646851947 | validation: 0.44893111376633277]
	TIME [epoch: 19.8 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4438837371313149		[learning rate: 0.00045668]
	Learning Rate: 0.000456684
	LOSS [training: 0.4438837371313149 | validation: 0.47632658739216127]
	TIME [epoch: 19.8 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.46047055711332097		[learning rate: 0.00045487]
	Learning Rate: 0.000454867
	LOSS [training: 0.46047055711332097 | validation: 0.4942521768997783]
	TIME [epoch: 19.8 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4431704042154197		[learning rate: 0.00045306]
	Learning Rate: 0.000453058
	LOSS [training: 0.4431704042154197 | validation: 0.4357557504513331]
	TIME [epoch: 19.8 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4200395727331146		[learning rate: 0.00045126]
	Learning Rate: 0.000451256
	LOSS [training: 0.4200395727331146 | validation: 0.4293755868057728]
	TIME [epoch: 19.8 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4243773477026637		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 0.4243773477026637 | validation: 0.46023622507208006]
	TIME [epoch: 19.8 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.42903541290452396		[learning rate: 0.00044767]
	Learning Rate: 0.000447674
	LOSS [training: 0.42903541290452396 | validation: 0.43378270492189214]
	TIME [epoch: 19.8 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4184702685347842		[learning rate: 0.00044589]
	Learning Rate: 0.000445893
	LOSS [training: 0.4184702685347842 | validation: 0.41441292410541664]
	TIME [epoch: 19.8 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.38899577586714895		[learning rate: 0.00044412]
	Learning Rate: 0.00044412
	LOSS [training: 0.38899577586714895 | validation: 0.38823361920531474]
	TIME [epoch: 19.8 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.38013379083076854		[learning rate: 0.00044235]
	Learning Rate: 0.000442353
	LOSS [training: 0.38013379083076854 | validation: 0.36353790981239537]
	TIME [epoch: 19.8 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.34934700349642445		[learning rate: 0.00044059]
	Learning Rate: 0.000440594
	LOSS [training: 0.34934700349642445 | validation: 0.35148404339723804]
	TIME [epoch: 19.8 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.33728453786329804		[learning rate: 0.00043884]
	Learning Rate: 0.000438842
	LOSS [training: 0.33728453786329804 | validation: 0.3514279117994215]
	TIME [epoch: 19.8 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3454766551492927		[learning rate: 0.0004371]
	Learning Rate: 0.000437096
	LOSS [training: 0.3454766551492927 | validation: 0.3472602339042668]
	TIME [epoch: 19.8 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.33950843175513856		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 0.33950843175513856 | validation: 0.3458018529611655]
	TIME [epoch: 19.8 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3484673601883283		[learning rate: 0.00043363]
	Learning Rate: 0.000433626
	LOSS [training: 0.3484673601883283 | validation: 0.3586136362936881]
	TIME [epoch: 19.8 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3564660756716667		[learning rate: 0.0004319]
	Learning Rate: 0.000431901
	LOSS [training: 0.3564660756716667 | validation: 0.35612760071563637]
	TIME [epoch: 19.8 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3550694272781247		[learning rate: 0.00043018]
	Learning Rate: 0.000430184
	LOSS [training: 0.3550694272781247 | validation: 0.3429541493184214]
	TIME [epoch: 19.8 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3467002522772532		[learning rate: 0.00042847]
	Learning Rate: 0.000428473
	LOSS [training: 0.3467002522772532 | validation: 0.3326181884093143]
	TIME [epoch: 19.8 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.33774005106826		[learning rate: 0.00042677]
	Learning Rate: 0.000426768
	LOSS [training: 0.33774005106826 | validation: 0.3365315050041696]
	TIME [epoch: 19.8 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32028465766087194		[learning rate: 0.00042507]
	Learning Rate: 0.000425071
	LOSS [training: 0.32028465766087194 | validation: 0.31766200544240064]
	TIME [epoch: 19.8 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3162023064495595		[learning rate: 0.00042338]
	Learning Rate: 0.00042338
	LOSS [training: 0.3162023064495595 | validation: 0.31878086320293253]
	TIME [epoch: 19.8 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3301189688492391		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 0.3301189688492391 | validation: 0.38012136074167724]
	TIME [epoch: 19.8 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3659836680724934		[learning rate: 0.00042002]
	Learning Rate: 0.000420019
	LOSS [training: 0.3659836680724934 | validation: 0.35491187824607284]
	TIME [epoch: 19.8 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3509252917714078		[learning rate: 0.00041835]
	Learning Rate: 0.000418349
	LOSS [training: 0.3509252917714078 | validation: 0.35348955601209553]
	TIME [epoch: 19.8 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.334617319273018		[learning rate: 0.00041668]
	Learning Rate: 0.000416685
	LOSS [training: 0.334617319273018 | validation: 0.3390706004988486]
	TIME [epoch: 19.8 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.33379275581377166		[learning rate: 0.00041503]
	Learning Rate: 0.000415028
	LOSS [training: 0.33379275581377166 | validation: 0.3313067598833198]
	TIME [epoch: 19.8 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32868075871171715		[learning rate: 0.00041338]
	Learning Rate: 0.000413377
	LOSS [training: 0.32868075871171715 | validation: 0.3320465993467585]
	TIME [epoch: 19.8 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.31821014832504946		[learning rate: 0.00041173]
	Learning Rate: 0.000411733
	LOSS [training: 0.31821014832504946 | validation: 0.32147801638857526]
	TIME [epoch: 19.8 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.31254179349690436		[learning rate: 0.0004101]
	Learning Rate: 0.000410095
	LOSS [training: 0.31254179349690436 | validation: 0.3148438104574366]
	TIME [epoch: 19.8 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3059677100003391		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 0.3059677100003391 | validation: 0.321950845121249]
	TIME [epoch: 19.8 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.31158105822300075		[learning rate: 0.00040684]
	Learning Rate: 0.00040684
	LOSS [training: 0.31158105822300075 | validation: 0.31410011007256045]
	TIME [epoch: 19.8 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3092561548036651		[learning rate: 0.00040522]
	Learning Rate: 0.000405221
	LOSS [training: 0.3092561548036651 | validation: 0.3166914786069713]
	TIME [epoch: 19.8 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.34846604993047664		[learning rate: 0.00040361]
	Learning Rate: 0.00040361
	LOSS [training: 0.34846604993047664 | validation: 0.40759458581046176]
	TIME [epoch: 19.8 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3957265794741462		[learning rate: 0.000402]
	Learning Rate: 0.000402004
	LOSS [training: 0.3957265794741462 | validation: 0.466680354893784]
	TIME [epoch: 19.8 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4693491953934653		[learning rate: 0.00040041]
	Learning Rate: 0.000400406
	LOSS [training: 0.4693491953934653 | validation: 0.4819650444719604]
	TIME [epoch: 19.8 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4675379004062121		[learning rate: 0.00039881]
	Learning Rate: 0.000398813
	LOSS [training: 0.4675379004062121 | validation: 0.43699810892754104]
	TIME [epoch: 19.8 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.42821529551725		[learning rate: 0.00039723]
	Learning Rate: 0.000397227
	LOSS [training: 0.42821529551725 | validation: 0.3997573248064696]
	TIME [epoch: 19.8 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.34259342791838054		[learning rate: 0.00039565]
	Learning Rate: 0.000395647
	LOSS [training: 0.34259342791838054 | validation: 0.3266185281225209]
	TIME [epoch: 19.8 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.30621303501529074		[learning rate: 0.00039407]
	Learning Rate: 0.000394073
	LOSS [training: 0.30621303501529074 | validation: 0.3204526548150347]
	TIME [epoch: 19.8 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.33302347253118036		[learning rate: 0.00039251]
	Learning Rate: 0.000392506
	LOSS [training: 0.33302347253118036 | validation: 0.3771527750893499]
	TIME [epoch: 19.8 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.42445544957044024		[learning rate: 0.00039094]
	Learning Rate: 0.000390945
	LOSS [training: 0.42445544957044024 | validation: 0.492579333740972]
	TIME [epoch: 19.8 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4385207062942928		[learning rate: 0.00038939]
	Learning Rate: 0.00038939
	LOSS [training: 0.4385207062942928 | validation: 0.43999077869850495]
	TIME [epoch: 19.8 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.41382696654863643		[learning rate: 0.00038784]
	Learning Rate: 0.000387841
	LOSS [training: 0.41382696654863643 | validation: 0.435864467354851]
	TIME [epoch: 19.8 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.41568051779838805		[learning rate: 0.0003863]
	Learning Rate: 0.000386299
	LOSS [training: 0.41568051779838805 | validation: 0.41625338991300814]
	TIME [epoch: 19.8 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.37519635089067843		[learning rate: 0.00038476]
	Learning Rate: 0.000384762
	LOSS [training: 0.37519635089067843 | validation: 0.34571059789778935]
	TIME [epoch: 19.8 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.33800338081167475		[learning rate: 0.00038323]
	Learning Rate: 0.000383232
	LOSS [training: 0.33800338081167475 | validation: 0.3384840793409499]
	TIME [epoch: 19.8 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3264827541012853		[learning rate: 0.00038171]
	Learning Rate: 0.000381708
	LOSS [training: 0.3264827541012853 | validation: 0.3286565188143309]
	TIME [epoch: 19.8 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32112934902441403		[learning rate: 0.00038019]
	Learning Rate: 0.000380189
	LOSS [training: 0.32112934902441403 | validation: 0.317787183797573]
	TIME [epoch: 19.8 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.30173942073708976		[learning rate: 0.00037868]
	Learning Rate: 0.000378677
	LOSS [training: 0.30173942073708976 | validation: 0.32119049889564677]
	TIME [epoch: 19.8 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v10_20240711_153302/states/model_facs_dec1b_2dpca_v10_866.pth
Halted early. No improvement in validation loss for 200 epochs.
Finished training in 12489.363 seconds.
