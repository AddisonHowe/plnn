Args:
Namespace(name='model_facs_dec1b_2dpca_v1', outdir='out/model_training/model_facs_dec1b_2dpca_v1', training_data='data/training_data/facs/pca/dec1_fitonsubset/transition1_subset_epi_tr_ce_an_pc12/training', validation_data='data/training_data/facs/pca/dec1_fitonsubset/transition1_subset_epi_tr_ce_an_pc12/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=5, patience=200, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, dt=0.001, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 1081702820

Training model...

Saving initial model state to: out/model_training/model_facs_dec1b_2dpca_v1_20240624_133245/states/model_facs_dec1b_2dpca_v1_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7414366809780143		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7414366809780143 | validation: 0.6364336659770122]
	TIME [epoch: 65.5 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v1_20240624_133245/states/model_facs_dec1b_2dpca_v1_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6786236878443658		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6786236878443658 | validation: 0.6174498694864607]
	TIME [epoch: 36.6 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v1_20240624_133245/states/model_facs_dec1b_2dpca_v1_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6922083611075378		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6922083611075378 | validation: 0.5997669510589614]
	TIME [epoch: 36.6 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v1_20240624_133245/states/model_facs_dec1b_2dpca_v1_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6299194781222328		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6299194781222328 | validation: 0.5632558380674028]
	TIME [epoch: 36.6 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v1_20240624_133245/states/model_facs_dec1b_2dpca_v1_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5859604476633542		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5859604476633542 | validation: 0.5542339271234545]
	TIME [epoch: 36.7 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v1_20240624_133245/states/model_facs_dec1b_2dpca_v1_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.647516298919095		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.647516298919095 | validation: 0.5218418973475126]
	TIME [epoch: 36.6 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v1_20240624_133245/states/model_facs_dec1b_2dpca_v1_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6057645152842792		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6057645152842792 | validation: 0.5194842453917828]
	TIME [epoch: 36.6 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v1_20240624_133245/states/model_facs_dec1b_2dpca_v1_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6013938357349499		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6013938357349499 | validation: 0.5027587209354644]
	TIME [epoch: 36.6 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v1_20240624_133245/states/model_facs_dec1b_2dpca_v1_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5226119746422442		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5226119746422442 | validation: 0.4527858927271149]
	TIME [epoch: 36.7 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v1_20240624_133245/states/model_facs_dec1b_2dpca_v1_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.48662754305404604		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.48662754305404604 | validation: 0.45291985076165]
	TIME [epoch: 36.7 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4810776635149815		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4810776635149815 | validation: 0.37332769093932355]
	TIME [epoch: 36.7 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v1_20240624_133245/states/model_facs_dec1b_2dpca_v1_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.40727789808020404		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.40727789808020404 | validation: 0.315411986359964]
	TIME [epoch: 36.6 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v1_20240624_133245/states/model_facs_dec1b_2dpca_v1_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3906801327015682		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3906801327015682 | validation: 0.3052881260358859]
	TIME [epoch: 36.6 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v1_20240624_133245/states/model_facs_dec1b_2dpca_v1_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3528503245220378		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3528503245220378 | validation: 0.283805947861047]
	TIME [epoch: 36.6 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v1_20240624_133245/states/model_facs_dec1b_2dpca_v1_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.31344161954232624		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.31344161954232624 | validation: 0.2563010186758587]
	TIME [epoch: 36.7 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v1_20240624_133245/states/model_facs_dec1b_2dpca_v1_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.30863378782268946		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.30863378782268946 | validation: 0.24209310350974483]
	TIME [epoch: 36.7 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v1_20240624_133245/states/model_facs_dec1b_2dpca_v1_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2782340797897833		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2782340797897833 | validation: 0.224044368925858]
	TIME [epoch: 36.7 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v1_20240624_133245/states/model_facs_dec1b_2dpca_v1_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25231232527805714		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.25231232527805714 | validation: 0.2040210833696628]
	TIME [epoch: 36.7 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v1_20240624_133245/states/model_facs_dec1b_2dpca_v1_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2574229923651881		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2574229923651881 | validation: 0.20609968268703813]
	TIME [epoch: 36.6 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2538912971032845		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2538912971032845 | validation: 0.18366614144814813]
	TIME [epoch: 36.7 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v1_20240624_133245/states/model_facs_dec1b_2dpca_v1_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23702319935030916		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23702319935030916 | validation: 0.31629114777472767]
	TIME [epoch: 36.7 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24496151284507567		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24496151284507567 | validation: 0.18482110035376978]
	TIME [epoch: 36.6 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.21771963401368227		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.21771963401368227 | validation: 0.1681011085321103]
	TIME [epoch: 36.7 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v1_20240624_133245/states/model_facs_dec1b_2dpca_v1_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1879329184023516		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1879329184023516 | validation: 0.14495010470996614]
	TIME [epoch: 36.7 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v1_20240624_133245/states/model_facs_dec1b_2dpca_v1_24.pth
	Model improved!!!
EPOCH 25/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23129217826604487		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23129217826604487 | validation: 0.15930285595879773]
	TIME [epoch: 36.7 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.19560517754555765		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.19560517754555765 | validation: 0.1916700927173493]
	TIME [epoch: 36.7 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.21955492198758753		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.21955492198758753 | validation: 0.1761394626194234]
	TIME [epoch: 36.7 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.18734225124668763		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18734225124668763 | validation: 0.1538107628260763]
	TIME [epoch: 36.6 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.19284153998209488		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.19284153998209488 | validation: 0.1901534997905475]
	TIME [epoch: 36.6 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.19101094501310767		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.19101094501310767 | validation: 0.1537626041996328]
	TIME [epoch: 36.6 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.21571557956550663		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.21571557956550663 | validation: 0.15173903034275565]
	TIME [epoch: 36.6 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.18018117088008445		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18018117088008445 | validation: 0.1544734515710599]
	TIME [epoch: 36.6 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.18739411248902982		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18739411248902982 | validation: 0.1673302321306433]
	TIME [epoch: 36.6 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.18636073635108558		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18636073635108558 | validation: 0.148806067644766]
	TIME [epoch: 36.7 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.19080278495192948		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.19080278495192948 | validation: 0.1856246453507326]
	TIME [epoch: 36.7 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.18343872487080826		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18343872487080826 | validation: 0.14741373178288514]
	TIME [epoch: 36.7 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17023350455707942		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17023350455707942 | validation: 0.14528824159743997]
	TIME [epoch: 36.6 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16566732477676954		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16566732477676954 | validation: 0.14861372406830503]
	TIME [epoch: 36.6 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17082418788071338		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17082418788071338 | validation: 0.1318836481272665]
	TIME [epoch: 36.7 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v1_20240624_133245/states/model_facs_dec1b_2dpca_v1_39.pth
	Model improved!!!
EPOCH 40/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1645611455083884		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1645611455083884 | validation: 0.13438686930899607]
	TIME [epoch: 36.6 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17593775380787166		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17593775380787166 | validation: 0.13195691250987018]
	TIME [epoch: 36.6 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17772671890898936		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17772671890898936 | validation: 0.1274777539366871]
	TIME [epoch: 36.6 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v1_20240624_133245/states/model_facs_dec1b_2dpca_v1_42.pth
	Model improved!!!
EPOCH 43/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.175816312120344		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.175816312120344 | validation: 0.1602759351307868]
	TIME [epoch: 36.6 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16824754995608104		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16824754995608104 | validation: 0.1756868938486502]
	TIME [epoch: 36.6 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.19841962904098148		[learning rate: 0.0099823]
	Learning Rate: 0.0099823
	LOSS [training: 0.19841962904098148 | validation: 0.13458816605016236]
	TIME [epoch: 36.6 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17494709086025245		[learning rate: 0.0099426]
	Learning Rate: 0.0099426
	LOSS [training: 0.17494709086025245 | validation: 0.17078651014663065]
	TIME [epoch: 36.6 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17154492767080132		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 0.17154492767080132 | validation: 0.1487906403356015]
	TIME [epoch: 36.6 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17893399361742982		[learning rate: 0.0098637]
	Learning Rate: 0.00986367
	LOSS [training: 0.17893399361742982 | validation: 0.1491294172785984]
	TIME [epoch: 36.7 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16809852103998502		[learning rate: 0.0098244]
	Learning Rate: 0.00982444
	LOSS [training: 0.16809852103998502 | validation: 0.13299495953279106]
	TIME [epoch: 36.7 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1716652279355969		[learning rate: 0.0097854]
	Learning Rate: 0.00978536
	LOSS [training: 0.1716652279355969 | validation: 0.1544992297219534]
	TIME [epoch: 36.7 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15441680210572248		[learning rate: 0.0097464]
	Learning Rate: 0.00974644
	LOSS [training: 0.15441680210572248 | validation: 0.11730934586564476]
	TIME [epoch: 36.6 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v1_20240624_133245/states/model_facs_dec1b_2dpca_v1_51.pth
	Model improved!!!
EPOCH 52/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14260678539720917		[learning rate: 0.0097077]
	Learning Rate: 0.00970768
	LOSS [training: 0.14260678539720917 | validation: 0.14418442756531874]
	TIME [epoch: 36.6 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.173645893180071		[learning rate: 0.0096691]
	Learning Rate: 0.00966907
	LOSS [training: 0.173645893180071 | validation: 0.11669505811422871]
	TIME [epoch: 36.7 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v1_20240624_133245/states/model_facs_dec1b_2dpca_v1_53.pth
	Model improved!!!
EPOCH 54/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1557617319352641		[learning rate: 0.0096306]
	Learning Rate: 0.00963061
	LOSS [training: 0.1557617319352641 | validation: 0.17642791818175868]
	TIME [epoch: 36.6 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16284801400915874		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 0.16284801400915874 | validation: 0.12211899609492785]
	TIME [epoch: 36.6 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16664501860054315		[learning rate: 0.0095542]
	Learning Rate: 0.00955415
	LOSS [training: 0.16664501860054315 | validation: 0.11976718869712974]
	TIME [epoch: 36.6 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15251411631906014		[learning rate: 0.0095162]
	Learning Rate: 0.00951616
	LOSS [training: 0.15251411631906014 | validation: 0.1191055212232939]
	TIME [epoch: 36.7 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1598997951951594		[learning rate: 0.0094783]
	Learning Rate: 0.00947831
	LOSS [training: 0.1598997951951594 | validation: 0.11475058274776821]
	TIME [epoch: 36.7 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v1_20240624_133245/states/model_facs_dec1b_2dpca_v1_58.pth
	Model improved!!!
EPOCH 59/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14662831907044474		[learning rate: 0.0094406]
	Learning Rate: 0.00944061
	LOSS [training: 0.14662831907044474 | validation: 0.11676146309675024]
	TIME [epoch: 36.7 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15059036529152098		[learning rate: 0.0094031]
	Learning Rate: 0.00940306
	LOSS [training: 0.15059036529152098 | validation: 0.11568809739470179]
	TIME [epoch: 36.6 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13935980484392518		[learning rate: 0.0093657]
	Learning Rate: 0.00936566
	LOSS [training: 0.13935980484392518 | validation: 0.16171532301083436]
	TIME [epoch: 36.7 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17189250764724265		[learning rate: 0.0093284]
	Learning Rate: 0.00932841
	LOSS [training: 0.17189250764724265 | validation: 0.11627157752535403]
	TIME [epoch: 36.7 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14270380548818354		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 0.14270380548818354 | validation: 0.14679765592942176]
	TIME [epoch: 36.6 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16583346581395755		[learning rate: 0.0092544]
	Learning Rate: 0.00925435
	LOSS [training: 0.16583346581395755 | validation: 0.12152293845106517]
	TIME [epoch: 36.7 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14583904175349088		[learning rate: 0.0092175]
	Learning Rate: 0.00921755
	LOSS [training: 0.14583904175349088 | validation: 0.12061892373812917]
	TIME [epoch: 36.6 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15026278402969917		[learning rate: 0.0091809]
	Learning Rate: 0.00918089
	LOSS [training: 0.15026278402969917 | validation: 0.12546557453093793]
	TIME [epoch: 36.6 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14506168707355904		[learning rate: 0.0091444]
	Learning Rate: 0.00914437
	LOSS [training: 0.14506168707355904 | validation: 0.12343186559369437]
	TIME [epoch: 36.7 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16250324600331936		[learning rate: 0.009108]
	Learning Rate: 0.009108
	LOSS [training: 0.16250324600331936 | validation: 0.109787856532895]
	TIME [epoch: 36.7 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v1_20240624_133245/states/model_facs_dec1b_2dpca_v1_68.pth
	Model improved!!!
EPOCH 69/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14933666958398464		[learning rate: 0.0090718]
	Learning Rate: 0.00907178
	LOSS [training: 0.14933666958398464 | validation: 0.1092967021243767]
	TIME [epoch: 36.6 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v1_20240624_133245/states/model_facs_dec1b_2dpca_v1_69.pth
	Model improved!!!
EPOCH 70/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14148748955880588		[learning rate: 0.0090357]
	Learning Rate: 0.00903569
	LOSS [training: 0.14148748955880588 | validation: 0.11826187691696946]
	TIME [epoch: 36.6 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1422851348586007		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 0.1422851348586007 | validation: 0.12251243529842393]
	TIME [epoch: 36.7 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.156514994058159		[learning rate: 0.008964]
	Learning Rate: 0.00896396
	LOSS [training: 0.156514994058159 | validation: 0.11370133288243063]
	TIME [epoch: 36.7 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1398914371866327		[learning rate: 0.0089283]
	Learning Rate: 0.00892831
	LOSS [training: 0.1398914371866327 | validation: 0.10598153083093098]
	TIME [epoch: 36.7 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v1_20240624_133245/states/model_facs_dec1b_2dpca_v1_73.pth
	Model improved!!!
EPOCH 74/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14745246979218793		[learning rate: 0.0088928]
	Learning Rate: 0.0088928
	LOSS [training: 0.14745246979218793 | validation: 0.14808514567258632]
	TIME [epoch: 36.7 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15353096638361172		[learning rate: 0.0088574]
	Learning Rate: 0.00885743
	LOSS [training: 0.15353096638361172 | validation: 0.10729622604901404]
	TIME [epoch: 36.6 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1480907741439773		[learning rate: 0.0088222]
	Learning Rate: 0.0088222
	LOSS [training: 0.1480907741439773 | validation: 0.11584250126894832]
	TIME [epoch: 36.6 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1429109438560502		[learning rate: 0.0087871]
	Learning Rate: 0.00878711
	LOSS [training: 0.1429109438560502 | validation: 0.11660419991434164]
	TIME [epoch: 36.7 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13906431039678058		[learning rate: 0.0087522]
	Learning Rate: 0.00875216
	LOSS [training: 0.13906431039678058 | validation: 0.12708101206332617]
	TIME [epoch: 36.7 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13733214911451264		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 0.13733214911451264 | validation: 0.11329790201021703]
	TIME [epoch: 36.7 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1356325751350857		[learning rate: 0.0086827]
	Learning Rate: 0.00868268
	LOSS [training: 0.1356325751350857 | validation: 0.12714942397026463]
	TIME [epoch: 36.7 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15134040553198064		[learning rate: 0.0086481]
	Learning Rate: 0.00864815
	LOSS [training: 0.15134040553198064 | validation: 0.11372932792566373]
	TIME [epoch: 36.7 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14965241505007107		[learning rate: 0.0086138]
	Learning Rate: 0.00861375
	LOSS [training: 0.14965241505007107 | validation: 0.10542498677365461]
	TIME [epoch: 36.7 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v1_20240624_133245/states/model_facs_dec1b_2dpca_v1_82.pth
	Model improved!!!
EPOCH 83/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14321609010068004		[learning rate: 0.0085795]
	Learning Rate: 0.00857949
	LOSS [training: 0.14321609010068004 | validation: 0.11838322752807953]
	TIME [epoch: 36.7 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1325069430176217		[learning rate: 0.0085454]
	Learning Rate: 0.00854537
	LOSS [training: 0.1325069430176217 | validation: 0.13546431017974495]
	TIME [epoch: 36.6 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13056566882666043		[learning rate: 0.0085114]
	Learning Rate: 0.00851138
	LOSS [training: 0.13056566882666043 | validation: 0.10129944697116247]
	TIME [epoch: 36.6 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v1_20240624_133245/states/model_facs_dec1b_2dpca_v1_85.pth
	Model improved!!!
EPOCH 86/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15899118435302195		[learning rate: 0.0084775]
	Learning Rate: 0.00847753
	LOSS [training: 0.15899118435302195 | validation: 0.11214042908145234]
	TIME [epoch: 36.7 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13011873446112934		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 0.13011873446112934 | validation: 0.12083140455826695]
	TIME [epoch: 36.7 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15754125389911047		[learning rate: 0.0084102]
	Learning Rate: 0.00841023
	LOSS [training: 0.15754125389911047 | validation: 0.10823953029080462]
	TIME [epoch: 36.7 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14879011707698744		[learning rate: 0.0083768]
	Learning Rate: 0.00837678
	LOSS [training: 0.14879011707698744 | validation: 0.12270588198723453]
	TIME [epoch: 36.6 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14291432775095428		[learning rate: 0.0083435]
	Learning Rate: 0.00834346
	LOSS [training: 0.14291432775095428 | validation: 0.11429307620334117]
	TIME [epoch: 36.7 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1515806651401551		[learning rate: 0.0083103]
	Learning Rate: 0.00831027
	LOSS [training: 0.1515806651401551 | validation: 0.12020262235419485]
	TIME [epoch: 36.7 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13886950523671285		[learning rate: 0.0082772]
	Learning Rate: 0.00827722
	LOSS [training: 0.13886950523671285 | validation: 0.11205614650075543]
	TIME [epoch: 36.7 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14183104931553825		[learning rate: 0.0082443]
	Learning Rate: 0.0082443
	LOSS [training: 0.14183104931553825 | validation: 0.10110946393355354]
	TIME [epoch: 36.7 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v1_20240624_133245/states/model_facs_dec1b_2dpca_v1_93.pth
	Model improved!!!
EPOCH 94/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13429132387592874		[learning rate: 0.0082115]
	Learning Rate: 0.00821151
	LOSS [training: 0.13429132387592874 | validation: 0.10791653545998688]
	TIME [epoch: 36.7 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1308451876713193		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 0.1308451876713193 | validation: 0.11096207427697125]
	TIME [epoch: 36.6 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15251856139606224		[learning rate: 0.0081463]
	Learning Rate: 0.00814632
	LOSS [training: 0.15251856139606224 | validation: 0.11850841951819995]
	TIME [epoch: 36.6 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15992330001122185		[learning rate: 0.0081139]
	Learning Rate: 0.00811392
	LOSS [training: 0.15992330001122185 | validation: 0.10850388782588874]
	TIME [epoch: 36.7 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13591669877080031		[learning rate: 0.0080816]
	Learning Rate: 0.00808165
	LOSS [training: 0.13591669877080031 | validation: 0.10552681617335888]
	TIME [epoch: 36.7 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14027563977368931		[learning rate: 0.0080495]
	Learning Rate: 0.00804951
	LOSS [training: 0.14027563977368931 | validation: 0.11101943724054526]
	TIME [epoch: 36.7 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13840230074523374		[learning rate: 0.0080175]
	Learning Rate: 0.00801749
	LOSS [training: 0.13840230074523374 | validation: 0.12518905014193207]
	TIME [epoch: 36.7 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1483500620344608		[learning rate: 0.0079856]
	Learning Rate: 0.0079856
	LOSS [training: 0.1483500620344608 | validation: 0.12062367946431163]
	TIME [epoch: 36.7 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1262609723956684		[learning rate: 0.0079538]
	Learning Rate: 0.00795384
	LOSS [training: 0.1262609723956684 | validation: 0.10634506360342333]
	TIME [epoch: 36.7 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14422386182107774		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 0.14422386182107774 | validation: 0.1194160209333162]
	TIME [epoch: 36.7 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1311002001271554		[learning rate: 0.0078907]
	Learning Rate: 0.0078907
	LOSS [training: 0.1311002001271554 | validation: 0.11303923682624162]
	TIME [epoch: 36.7 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13997758611037373		[learning rate: 0.0078593]
	Learning Rate: 0.00785931
	LOSS [training: 0.13997758611037373 | validation: 0.11899868744605946]
	TIME [epoch: 36.7 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13797221381172406		[learning rate: 0.0078281]
	Learning Rate: 0.00782805
	LOSS [training: 0.13797221381172406 | validation: 0.12098063656118434]
	TIME [epoch: 36.7 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13193801959018736		[learning rate: 0.0077969]
	Learning Rate: 0.00779692
	LOSS [training: 0.13193801959018736 | validation: 0.10769624671037845]
	TIME [epoch: 36.7 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16378237518109406		[learning rate: 0.0077659]
	Learning Rate: 0.00776591
	LOSS [training: 0.16378237518109406 | validation: 0.1116244821948997]
	TIME [epoch: 36.7 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14779578340548646		[learning rate: 0.007735]
	Learning Rate: 0.00773502
	LOSS [training: 0.14779578340548646 | validation: 0.12080652595091038]
	TIME [epoch: 36.7 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1379638526009357		[learning rate: 0.0077043]
	Learning Rate: 0.00770426
	LOSS [training: 0.1379638526009357 | validation: 0.12067777356441375]
	TIME [epoch: 36.7 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14147774880781816		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 0.14147774880781816 | validation: 0.10403805888218302]
	TIME [epoch: 36.7 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1446494831470271		[learning rate: 0.0076431]
	Learning Rate: 0.00764309
	LOSS [training: 0.1446494831470271 | validation: 0.1057907597588879]
	TIME [epoch: 36.7 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13351843835057906		[learning rate: 0.0076127]
	Learning Rate: 0.00761269
	LOSS [training: 0.13351843835057906 | validation: 0.10475763649150002]
	TIME [epoch: 36.7 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1400789917587041		[learning rate: 0.0075824]
	Learning Rate: 0.00758242
	LOSS [training: 0.1400789917587041 | validation: 0.10730227977348891]
	TIME [epoch: 36.7 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13589189431011597		[learning rate: 0.0075523]
	Learning Rate: 0.00755226
	LOSS [training: 0.13589189431011597 | validation: 0.1325047016290213]
	TIME [epoch: 36.7 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13798923752895934		[learning rate: 0.0075222]
	Learning Rate: 0.00752222
	LOSS [training: 0.13798923752895934 | validation: 0.10516779506580878]
	TIME [epoch: 36.7 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11696542670000144		[learning rate: 0.0074923]
	Learning Rate: 0.0074923
	LOSS [training: 0.11696542670000144 | validation: 0.11053472883153306]
	TIME [epoch: 36.7 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14607757818063327		[learning rate: 0.0074625]
	Learning Rate: 0.0074625
	LOSS [training: 0.14607757818063327 | validation: 0.10707633436677821]
	TIME [epoch: 36.7 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13031614779770673		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 0.13031614779770673 | validation: 0.12233160310114859]
	TIME [epoch: 36.7 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12123147447404325		[learning rate: 0.0074033]
	Learning Rate: 0.00740326
	LOSS [training: 0.12123147447404325 | validation: 0.10403322047432532]
	TIME [epoch: 36.7 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1318123951861448		[learning rate: 0.0073738]
	Learning Rate: 0.00737382
	LOSS [training: 0.1318123951861448 | validation: 0.11207081280659066]
	TIME [epoch: 36.7 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13096108773998888		[learning rate: 0.0073445]
	Learning Rate: 0.00734449
	LOSS [training: 0.13096108773998888 | validation: 0.11554443608690909]
	TIME [epoch: 36.7 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13840572683693844		[learning rate: 0.0073153]
	Learning Rate: 0.00731528
	LOSS [training: 0.13840572683693844 | validation: 0.11189265133391554]
	TIME [epoch: 36.7 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13535535011385613		[learning rate: 0.0072862]
	Learning Rate: 0.00728618
	LOSS [training: 0.13535535011385613 | validation: 0.10377804598061013]
	TIME [epoch: 36.7 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13044562533129897		[learning rate: 0.0072572]
	Learning Rate: 0.0072572
	LOSS [training: 0.13044562533129897 | validation: 0.11299960192628282]
	TIME [epoch: 36.6 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13194827068730655		[learning rate: 0.0072283]
	Learning Rate: 0.00722834
	LOSS [training: 0.13194827068730655 | validation: 0.11501421423049707]
	TIME [epoch: 36.7 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12288780813762872		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 0.12288780813762872 | validation: 0.1130479920183608]
	TIME [epoch: 36.6 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1278645885844526		[learning rate: 0.007171]
	Learning Rate: 0.00717095
	LOSS [training: 0.1278645885844526 | validation: 0.11414282275632326]
	TIME [epoch: 36.7 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12404470718543825		[learning rate: 0.0071424]
	Learning Rate: 0.00714243
	LOSS [training: 0.12404470718543825 | validation: 0.10273806338048694]
	TIME [epoch: 36.7 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1394111033723989		[learning rate: 0.007114]
	Learning Rate: 0.00711403
	LOSS [training: 0.1394111033723989 | validation: 0.11534441754828628]
	TIME [epoch: 36.7 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.139132371444512		[learning rate: 0.0070857]
	Learning Rate: 0.00708573
	LOSS [training: 0.139132371444512 | validation: 0.10567087155680295]
	TIME [epoch: 36.7 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13034340642943282		[learning rate: 0.0070575]
	Learning Rate: 0.00705755
	LOSS [training: 0.13034340642943282 | validation: 0.13310331676017223]
	TIME [epoch: 36.7 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13844188058506068		[learning rate: 0.0070295]
	Learning Rate: 0.00702948
	LOSS [training: 0.13844188058506068 | validation: 0.11105383722074366]
	TIME [epoch: 36.6 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1336823077651334		[learning rate: 0.0070015]
	Learning Rate: 0.00700152
	LOSS [training: 0.1336823077651334 | validation: 0.10003285495107672]
	TIME [epoch: 36.7 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v1_20240624_133245/states/model_facs_dec1b_2dpca_v1_134.pth
	Model improved!!!
EPOCH 135/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.128988400660243		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 0.128988400660243 | validation: 0.09793444673731437]
	TIME [epoch: 36.7 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v1_20240624_133245/states/model_facs_dec1b_2dpca_v1_135.pth
	Model improved!!!
EPOCH 136/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12193006435968377		[learning rate: 0.0069459]
	Learning Rate: 0.00694594
	LOSS [training: 0.12193006435968377 | validation: 0.11571959766833025]
	TIME [epoch: 36.7 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13288171085482733		[learning rate: 0.0069183]
	Learning Rate: 0.00691831
	LOSS [training: 0.13288171085482733 | validation: 0.1013113429837027]
	TIME [epoch: 36.7 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12901278239903122		[learning rate: 0.0068908]
	Learning Rate: 0.00689079
	LOSS [training: 0.12901278239903122 | validation: 0.12012067400455954]
	TIME [epoch: 36.7 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13408805911022817		[learning rate: 0.0068634]
	Learning Rate: 0.00686339
	LOSS [training: 0.13408805911022817 | validation: 0.11026967868728513]
	TIME [epoch: 36.7 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12982951995517428		[learning rate: 0.0068361]
	Learning Rate: 0.00683609
	LOSS [training: 0.12982951995517428 | validation: 0.12050882063036697]
	TIME [epoch: 36.7 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13775621871726276		[learning rate: 0.0068089]
	Learning Rate: 0.0068089
	LOSS [training: 0.13775621871726276 | validation: 0.1089016143283206]
	TIME [epoch: 36.7 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1259673547167473		[learning rate: 0.0067818]
	Learning Rate: 0.00678182
	LOSS [training: 0.1259673547167473 | validation: 0.10690862876540139]
	TIME [epoch: 36.7 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1314912852769843		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 0.1314912852769843 | validation: 0.10777487402974884]
	TIME [epoch: 36.7 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12649666301240067		[learning rate: 0.006728]
	Learning Rate: 0.00672798
	LOSS [training: 0.12649666301240067 | validation: 0.1082014628610368]
	TIME [epoch: 36.7 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12782388337488404		[learning rate: 0.0067012]
	Learning Rate: 0.00670122
	LOSS [training: 0.12782388337488404 | validation: 0.10525392091795549]
	TIME [epoch: 36.7 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1478371984211361		[learning rate: 0.0066746]
	Learning Rate: 0.00667457
	LOSS [training: 0.1478371984211361 | validation: 0.09925727007296474]
	TIME [epoch: 36.7 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13082526054488053		[learning rate: 0.006648]
	Learning Rate: 0.00664802
	LOSS [training: 0.13082526054488053 | validation: 0.10158635820780575]
	TIME [epoch: 36.7 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1350302892368372		[learning rate: 0.0066216]
	Learning Rate: 0.00662158
	LOSS [training: 0.1350302892368372 | validation: 0.12562517112412863]
	TIME [epoch: 36.7 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1353800433669633		[learning rate: 0.0065952]
	Learning Rate: 0.00659524
	LOSS [training: 0.1353800433669633 | validation: 0.1057616839872971]
	TIME [epoch: 36.7 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13429494019166552		[learning rate: 0.006569]
	Learning Rate: 0.00656901
	LOSS [training: 0.13429494019166552 | validation: 0.10421227986156659]
	TIME [epoch: 36.7 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13121540367932405		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 0.13121540367932405 | validation: 0.11672689226897137]
	TIME [epoch: 36.6 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13222742974826757		[learning rate: 0.0065169]
	Learning Rate: 0.00651686
	LOSS [training: 0.13222742974826757 | validation: 0.11106181524571399]
	TIME [epoch: 36.7 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12800896690244265		[learning rate: 0.0064909]
	Learning Rate: 0.00649094
	LOSS [training: 0.12800896690244265 | validation: 0.10034715654725672]
	TIME [epoch: 36.7 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12625758881775143		[learning rate: 0.0064651]
	Learning Rate: 0.00646512
	LOSS [training: 0.12625758881775143 | validation: 0.10763849860477348]
	TIME [epoch: 36.7 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12175272128454943		[learning rate: 0.0064394]
	Learning Rate: 0.00643941
	LOSS [training: 0.12175272128454943 | validation: 0.1261147620691958]
	TIME [epoch: 36.7 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13961247089281875		[learning rate: 0.0064138]
	Learning Rate: 0.0064138
	LOSS [training: 0.13961247089281875 | validation: 0.1104120844373923]
	TIME [epoch: 36.7 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1397009869936812		[learning rate: 0.0063883]
	Learning Rate: 0.00638829
	LOSS [training: 0.1397009869936812 | validation: 0.09721970263279274]
	TIME [epoch: 36.7 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v1_20240624_133245/states/model_facs_dec1b_2dpca_v1_157.pth
	Model improved!!!
EPOCH 158/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1429533836171298		[learning rate: 0.0063629]
	Learning Rate: 0.00636288
	LOSS [training: 0.1429533836171298 | validation: 0.09649366909901597]
	TIME [epoch: 36.7 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v1_20240624_133245/states/model_facs_dec1b_2dpca_v1_158.pth
	Model improved!!!
EPOCH 159/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13494664127574843		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 0.13494664127574843 | validation: 0.10132076394917733]
	TIME [epoch: 36.5 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12756314007630168		[learning rate: 0.0063124]
	Learning Rate: 0.00631237
	LOSS [training: 0.12756314007630168 | validation: 0.09678828445971646]
	TIME [epoch: 36.6 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1365038839842118		[learning rate: 0.0062873]
	Learning Rate: 0.00628726
	LOSS [training: 0.1365038839842118 | validation: 0.10281182539904277]
	TIME [epoch: 36.6 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13749421690524036		[learning rate: 0.0062623]
	Learning Rate: 0.00626226
	LOSS [training: 0.13749421690524036 | validation: 0.10702722985630497]
	TIME [epoch: 36.6 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14615725460180848		[learning rate: 0.0062373]
	Learning Rate: 0.00623735
	LOSS [training: 0.14615725460180848 | validation: 0.11336893885074084]
	TIME [epoch: 36.6 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15372614090500486		[learning rate: 0.0062125]
	Learning Rate: 0.00621254
	LOSS [training: 0.15372614090500486 | validation: 0.12958928898749822]
	TIME [epoch: 36.6 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14388031523327294		[learning rate: 0.0061878]
	Learning Rate: 0.00618783
	LOSS [training: 0.14388031523327294 | validation: 0.11551140166461109]
	TIME [epoch: 36.6 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1296147052769757		[learning rate: 0.0061632]
	Learning Rate: 0.00616322
	LOSS [training: 0.1296147052769757 | validation: 0.10508921281507581]
	TIME [epoch: 36.6 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13695135514462364		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 0.13695135514462364 | validation: 0.09790797062659155]
	TIME [epoch: 36.6 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12464468126814479		[learning rate: 0.0061143]
	Learning Rate: 0.00611429
	LOSS [training: 0.12464468126814479 | validation: 0.10729381596835433]
	TIME [epoch: 36.6 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13434005237432742		[learning rate: 0.00609]
	Learning Rate: 0.00608997
	LOSS [training: 0.13434005237432742 | validation: 0.0972095176711441]
	TIME [epoch: 36.6 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12800510415706204		[learning rate: 0.0060658]
	Learning Rate: 0.00606575
	LOSS [training: 0.12800510415706204 | validation: 0.10984767989033055]
	TIME [epoch: 36.6 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12592749742893516		[learning rate: 0.0060416]
	Learning Rate: 0.00604163
	LOSS [training: 0.12592749742893516 | validation: 0.11036435824918947]
	TIME [epoch: 36.6 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13280852801117865		[learning rate: 0.0060176]
	Learning Rate: 0.0060176
	LOSS [training: 0.13280852801117865 | validation: 0.10780785503616268]
	TIME [epoch: 36.7 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1382028099648094		[learning rate: 0.0059937]
	Learning Rate: 0.00599366
	LOSS [training: 0.1382028099648094 | validation: 0.0953709604208937]
	TIME [epoch: 36.6 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v1_20240624_133245/states/model_facs_dec1b_2dpca_v1_173.pth
	Model improved!!!
EPOCH 174/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12934616205355173		[learning rate: 0.0059698]
	Learning Rate: 0.00596982
	LOSS [training: 0.12934616205355173 | validation: 0.1162911464439117]
	TIME [epoch: 36.7 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13864621185678813		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 0.13864621185678813 | validation: 0.12223970238793438]
	TIME [epoch: 36.6 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14255009222704468		[learning rate: 0.0059224]
	Learning Rate: 0.00592243
	LOSS [training: 0.14255009222704468 | validation: 0.10436961652575323]
	TIME [epoch: 36.6 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12037072462986403		[learning rate: 0.0058989]
	Learning Rate: 0.00589888
	LOSS [training: 0.12037072462986403 | validation: 0.11235305659214205]
	TIME [epoch: 36.7 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1417767116456909		[learning rate: 0.0058754]
	Learning Rate: 0.00587541
	LOSS [training: 0.1417767116456909 | validation: 0.1147779667097549]
	TIME [epoch: 36.6 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13112516736484436		[learning rate: 0.005852]
	Learning Rate: 0.00585205
	LOSS [training: 0.13112516736484436 | validation: 0.10731298855853522]
	TIME [epoch: 36.6 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12654624008223467		[learning rate: 0.0058288]
	Learning Rate: 0.00582877
	LOSS [training: 0.12654624008223467 | validation: 0.11138365696837386]
	TIME [epoch: 36.6 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1323280690307643		[learning rate: 0.0058056]
	Learning Rate: 0.00580559
	LOSS [training: 0.1323280690307643 | validation: 0.10707830795923498]
	TIME [epoch: 36.7 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13539537573050314		[learning rate: 0.0057825]
	Learning Rate: 0.0057825
	LOSS [training: 0.13539537573050314 | validation: 0.10151572880944519]
	TIME [epoch: 36.6 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12186032579240018		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 0.12186032579240018 | validation: 0.11708104114091386]
	TIME [epoch: 36.6 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12781015046317384		[learning rate: 0.0057366]
	Learning Rate: 0.00573659
	LOSS [training: 0.12781015046317384 | validation: 0.11391695470847636]
	TIME [epoch: 36.6 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.138172981711575		[learning rate: 0.0057138]
	Learning Rate: 0.00571377
	LOSS [training: 0.138172981711575 | validation: 0.10399125714748687]
	TIME [epoch: 36.6 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12700922983703677		[learning rate: 0.005691]
	Learning Rate: 0.00569105
	LOSS [training: 0.12700922983703677 | validation: 0.09760448240133637]
	TIME [epoch: 36.6 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12968083060093594		[learning rate: 0.0056684]
	Learning Rate: 0.00566841
	LOSS [training: 0.12968083060093594 | validation: 0.10334659540435534]
	TIME [epoch: 36.6 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12267553710649841		[learning rate: 0.0056459]
	Learning Rate: 0.00564587
	LOSS [training: 0.12267553710649841 | validation: 0.10823448550377199]
	TIME [epoch: 36.6 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12098348565801315		[learning rate: 0.0056234]
	Learning Rate: 0.00562341
	LOSS [training: 0.12098348565801315 | validation: 0.10804574165461411]
	TIME [epoch: 36.6 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13464703721806737		[learning rate: 0.005601]
	Learning Rate: 0.00560105
	LOSS [training: 0.13464703721806737 | validation: 0.093544957051722]
	TIME [epoch: 36.6 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v1_20240624_133245/states/model_facs_dec1b_2dpca_v1_190.pth
	Model improved!!!
EPOCH 191/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12084970922102459		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 0.12084970922102459 | validation: 0.10570539103191827]
	TIME [epoch: 36.6 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12070685517732395		[learning rate: 0.0055566]
	Learning Rate: 0.00555658
	LOSS [training: 0.12070685517732395 | validation: 0.09797554385999882]
	TIME [epoch: 36.6 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11307035074835103		[learning rate: 0.0055345]
	Learning Rate: 0.00553448
	LOSS [training: 0.11307035074835103 | validation: 0.11024669233001276]
	TIME [epoch: 36.6 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1402461541853879		[learning rate: 0.0055125]
	Learning Rate: 0.00551247
	LOSS [training: 0.1402461541853879 | validation: 0.11765760420554809]
	TIME [epoch: 36.6 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1326880728596139		[learning rate: 0.0054905]
	Learning Rate: 0.00549054
	LOSS [training: 0.1326880728596139 | validation: 0.11149066976065128]
	TIME [epoch: 36.6 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1443138758280861		[learning rate: 0.0054687]
	Learning Rate: 0.00546871
	LOSS [training: 0.1443138758280861 | validation: 0.10220559037301324]
	TIME [epoch: 36.6 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11658079725648496		[learning rate: 0.005447]
	Learning Rate: 0.00544696
	LOSS [training: 0.11658079725648496 | validation: 0.10096836282867538]
	TIME [epoch: 36.6 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1312464678248036		[learning rate: 0.0054253]
	Learning Rate: 0.00542529
	LOSS [training: 0.1312464678248036 | validation: 0.10647845239027051]
	TIME [epoch: 36.6 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12741291355122566		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 0.12741291355122566 | validation: 0.08999176418081863]
	TIME [epoch: 36.6 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v1_20240624_133245/states/model_facs_dec1b_2dpca_v1_199.pth
	Model improved!!!
EPOCH 200/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11869192657567745		[learning rate: 0.0053822]
	Learning Rate: 0.00538222
	LOSS [training: 0.11869192657567745 | validation: 0.09263284167114878]
	TIME [epoch: 36.6 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11722299859244166		[learning rate: 0.0053608]
	Learning Rate: 0.00536081
	LOSS [training: 0.11722299859244166 | validation: 0.09831854000589975]
	TIME [epoch: 36.6 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13436257587731573		[learning rate: 0.0053395]
	Learning Rate: 0.00533949
	LOSS [training: 0.13436257587731573 | validation: 0.09440102403694231]
	TIME [epoch: 36.6 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14107487381861653		[learning rate: 0.0053183]
	Learning Rate: 0.00531826
	LOSS [training: 0.14107487381861653 | validation: 0.10989142126652048]
	TIME [epoch: 36.6 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12240321738475497		[learning rate: 0.0052971]
	Learning Rate: 0.0052971
	LOSS [training: 0.12240321738475497 | validation: 0.10096907963540573]
	TIME [epoch: 36.6 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1301144591283714		[learning rate: 0.005276]
	Learning Rate: 0.00527604
	LOSS [training: 0.1301144591283714 | validation: 0.1007822276488211]
	TIME [epoch: 36.6 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12632214971912112		[learning rate: 0.0052551]
	Learning Rate: 0.00525505
	LOSS [training: 0.12632214971912112 | validation: 0.10899521471543787]
	TIME [epoch: 36.6 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13103440983772552		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 0.13103440983772552 | validation: 0.09637434545401]
	TIME [epoch: 36.6 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12448344700755148		[learning rate: 0.0052133]
	Learning Rate: 0.00521333
	LOSS [training: 0.12448344700755148 | validation: 0.10104816900921634]
	TIME [epoch: 36.6 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1284729612175222		[learning rate: 0.0051926]
	Learning Rate: 0.0051926
	LOSS [training: 0.1284729612175222 | validation: 0.0996767499364309]
	TIME [epoch: 36.6 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12034509781058822		[learning rate: 0.0051719]
	Learning Rate: 0.00517194
	LOSS [training: 0.12034509781058822 | validation: 0.10270322506722618]
	TIME [epoch: 36.6 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12452624609113805		[learning rate: 0.0051514]
	Learning Rate: 0.00515137
	LOSS [training: 0.12452624609113805 | validation: 0.10452184196807071]
	TIME [epoch: 36.6 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1353262282066007		[learning rate: 0.0051309]
	Learning Rate: 0.00513089
	LOSS [training: 0.1353262282066007 | validation: 0.10565188615959405]
	TIME [epoch: 36.6 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13284577940667427		[learning rate: 0.0051105]
	Learning Rate: 0.00511048
	LOSS [training: 0.13284577940667427 | validation: 0.09837096801648341]
	TIME [epoch: 36.6 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13123788888699006		[learning rate: 0.0050902]
	Learning Rate: 0.00509015
	LOSS [training: 0.13123788888699006 | validation: 0.10370639836576864]
	TIME [epoch: 36.6 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11164744611602376		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 0.11164744611602376 | validation: 0.09724168974802835]
	TIME [epoch: 36.6 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12382150279180386		[learning rate: 0.0050497]
	Learning Rate: 0.00504974
	LOSS [training: 0.12382150279180386 | validation: 0.10137052680469641]
	TIME [epoch: 36.6 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12567109036773302		[learning rate: 0.0050297]
	Learning Rate: 0.00502966
	LOSS [training: 0.12567109036773302 | validation: 0.10305644529181443]
	TIME [epoch: 36.6 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12624624633372517		[learning rate: 0.0050097]
	Learning Rate: 0.00500965
	LOSS [training: 0.12624624633372517 | validation: 0.11765366018123853]
	TIME [epoch: 36.6 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1476626237222131		[learning rate: 0.0049897]
	Learning Rate: 0.00498973
	LOSS [training: 0.1476626237222131 | validation: 0.0980772332512492]
	TIME [epoch: 36.6 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13079744097018528		[learning rate: 0.0049699]
	Learning Rate: 0.00496988
	LOSS [training: 0.13079744097018528 | validation: 0.09772263863351152]
	TIME [epoch: 36.6 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12754612933238813		[learning rate: 0.0049501]
	Learning Rate: 0.00495012
	LOSS [training: 0.12754612933238813 | validation: 0.10751527748018501]
	TIME [epoch: 36.6 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13478569417198705		[learning rate: 0.0049304]
	Learning Rate: 0.00493043
	LOSS [training: 0.13478569417198705 | validation: 0.10175312842057524]
	TIME [epoch: 36.6 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12040037770222384		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 0.12040037770222384 | validation: 0.10015865429312562]
	TIME [epoch: 36.6 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1300151451653626		[learning rate: 0.0048913]
	Learning Rate: 0.00489129
	LOSS [training: 0.1300151451653626 | validation: 0.09736558956921237]
	TIME [epoch: 36.6 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12192331304135694		[learning rate: 0.0048718]
	Learning Rate: 0.00487183
	LOSS [training: 0.12192331304135694 | validation: 0.10239475148885997]
	TIME [epoch: 36.6 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12456533534981788		[learning rate: 0.0048525]
	Learning Rate: 0.00485245
	LOSS [training: 0.12456533534981788 | validation: 0.09887458651823576]
	TIME [epoch: 36.6 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12519794680556118		[learning rate: 0.0048332]
	Learning Rate: 0.00483316
	LOSS [training: 0.12519794680556118 | validation: 0.10279334754709243]
	TIME [epoch: 36.6 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11692672079743373		[learning rate: 0.0048139]
	Learning Rate: 0.00481393
	LOSS [training: 0.11692672079743373 | validation: 0.10155187456212586]
	TIME [epoch: 36.6 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1210893689687236		[learning rate: 0.0047948]
	Learning Rate: 0.00479479
	LOSS [training: 0.1210893689687236 | validation: 0.09973660372647694]
	TIME [epoch: 36.6 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1224151014641678		[learning rate: 0.0047757]
	Learning Rate: 0.00477572
	LOSS [training: 0.1224151014641678 | validation: 0.09857515352126738]
	TIME [epoch: 36.6 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12515140273116276		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.12515140273116276 | validation: 0.09329430062205843]
	TIME [epoch: 36.6 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1255631070405031		[learning rate: 0.0047378]
	Learning Rate: 0.0047378
	LOSS [training: 0.1255631070405031 | validation: 0.10003872098595368]
	TIME [epoch: 36.6 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12324691063658401		[learning rate: 0.004719]
	Learning Rate: 0.00471896
	LOSS [training: 0.12324691063658401 | validation: 0.10105109962873415]
	TIME [epoch: 36.6 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12841299557565578		[learning rate: 0.0047002]
	Learning Rate: 0.00470019
	LOSS [training: 0.12841299557565578 | validation: 0.09731474175660237]
	TIME [epoch: 36.6 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12735850416904268		[learning rate: 0.0046815]
	Learning Rate: 0.0046815
	LOSS [training: 0.12735850416904268 | validation: 0.10142203862100296]
	TIME [epoch: 36.6 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13336269582490914		[learning rate: 0.0046629]
	Learning Rate: 0.00466288
	LOSS [training: 0.13336269582490914 | validation: 0.10486893431912023]
	TIME [epoch: 36.6 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13953203232467476		[learning rate: 0.0046443]
	Learning Rate: 0.00464433
	LOSS [training: 0.13953203232467476 | validation: 0.09978581994087399]
	TIME [epoch: 36.6 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11778091444034924		[learning rate: 0.0046259]
	Learning Rate: 0.00462586
	LOSS [training: 0.11778091444034924 | validation: 0.1144574705032944]
	TIME [epoch: 36.6 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11402096194648562		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 0.11402096194648562 | validation: 0.11723712643382567]
	TIME [epoch: 36.6 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1495663654072258		[learning rate: 0.0045891]
	Learning Rate: 0.00458913
	LOSS [training: 0.1495663654072258 | validation: 0.10247464348946685]
	TIME [epoch: 36.6 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1300218313853994		[learning rate: 0.0045709]
	Learning Rate: 0.00457088
	LOSS [training: 0.1300218313853994 | validation: 0.09423813485933252]
	TIME [epoch: 36.6 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12500383712689092		[learning rate: 0.0045527]
	Learning Rate: 0.0045527
	LOSS [training: 0.12500383712689092 | validation: 0.09571354053839223]
	TIME [epoch: 36.6 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11956930101279559		[learning rate: 0.0045346]
	Learning Rate: 0.00453459
	LOSS [training: 0.11956930101279559 | validation: 0.10031895902976498]
	TIME [epoch: 36.6 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12212323358921763		[learning rate: 0.0045166]
	Learning Rate: 0.00451656
	LOSS [training: 0.12212323358921763 | validation: 0.11189692834491483]
	TIME [epoch: 36.6 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12110268457813422		[learning rate: 0.0044986]
	Learning Rate: 0.0044986
	LOSS [training: 0.12110268457813422 | validation: 0.10013314835814457]
	TIME [epoch: 36.6 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11821737171364265		[learning rate: 0.0044807]
	Learning Rate: 0.0044807
	LOSS [training: 0.11821737171364265 | validation: 0.09144097786941371]
	TIME [epoch: 36.6 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12501783810577313		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 0.12501783810577313 | validation: 0.08848941030799307]
	TIME [epoch: 36.6 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v1_20240624_133245/states/model_facs_dec1b_2dpca_v1_247.pth
	Model improved!!!
EPOCH 248/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13861497230362177		[learning rate: 0.0044451]
	Learning Rate: 0.00444513
	LOSS [training: 0.13861497230362177 | validation: 0.09750352799155441]
	TIME [epoch: 36.6 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12557501018107153		[learning rate: 0.0044275]
	Learning Rate: 0.00442745
	LOSS [training: 0.12557501018107153 | validation: 0.09128405461891774]
	TIME [epoch: 36.6 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11725271756805752		[learning rate: 0.0044098]
	Learning Rate: 0.00440984
	LOSS [training: 0.11725271756805752 | validation: 0.10716798662789018]
	TIME [epoch: 36.6 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12351596315123853		[learning rate: 0.0043923]
	Learning Rate: 0.0043923
	LOSS [training: 0.12351596315123853 | validation: 0.10028699635968148]
	TIME [epoch: 36.6 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13503630875464515		[learning rate: 0.0043748]
	Learning Rate: 0.00437483
	LOSS [training: 0.13503630875464515 | validation: 0.11120753827158514]
	TIME [epoch: 36.6 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11784496464823535		[learning rate: 0.0043574]
	Learning Rate: 0.00435743
	LOSS [training: 0.11784496464823535 | validation: 0.10302672122362573]
	TIME [epoch: 36.6 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1316034651933556		[learning rate: 0.0043401]
	Learning Rate: 0.0043401
	LOSS [training: 0.1316034651933556 | validation: 0.10598552800101095]
	TIME [epoch: 36.6 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12550346943517018		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 0.12550346943517018 | validation: 0.09766436438935988]
	TIME [epoch: 36.6 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13255913012841625		[learning rate: 0.0043056]
	Learning Rate: 0.00430565
	LOSS [training: 0.13255913012841625 | validation: 0.10388963638521513]
	TIME [epoch: 36.6 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1228143173508175		[learning rate: 0.0042885]
	Learning Rate: 0.00428852
	LOSS [training: 0.1228143173508175 | validation: 0.0915473798736652]
	TIME [epoch: 36.6 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1228752671086152		[learning rate: 0.0042715]
	Learning Rate: 0.00427147
	LOSS [training: 0.1228752671086152 | validation: 0.10801885086600689]
	TIME [epoch: 36.6 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1157738551925957		[learning rate: 0.0042545]
	Learning Rate: 0.00425448
	LOSS [training: 0.1157738551925957 | validation: 0.0956106606842397]
	TIME [epoch: 36.6 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11124985270262802		[learning rate: 0.0042376]
	Learning Rate: 0.00423756
	LOSS [training: 0.11124985270262802 | validation: 0.10239333278436354]
	TIME [epoch: 36.6 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1280839282602909		[learning rate: 0.0042207]
	Learning Rate: 0.0042207
	LOSS [training: 0.1280839282602909 | validation: 0.10257364089657231]
	TIME [epoch: 36.6 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12144076551770436		[learning rate: 0.0042039]
	Learning Rate: 0.00420391
	LOSS [training: 0.12144076551770436 | validation: 0.09329292499605098]
	TIME [epoch: 36.6 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12021921381568329		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 0.12021921381568329 | validation: 0.10821899019042795]
	TIME [epoch: 36.6 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13084970108659422		[learning rate: 0.0041705]
	Learning Rate: 0.00417054
	LOSS [training: 0.13084970108659422 | validation: 0.09798218265029911]
	TIME [epoch: 36.6 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1367472571628047		[learning rate: 0.004154]
	Learning Rate: 0.00415395
	LOSS [training: 0.1367472571628047 | validation: 0.09607638402963761]
	TIME [epoch: 36.6 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12381343355067494		[learning rate: 0.0041374]
	Learning Rate: 0.00413743
	LOSS [training: 0.12381343355067494 | validation: 0.09867311669635814]
	TIME [epoch: 36.6 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11428664836661882		[learning rate: 0.004121]
	Learning Rate: 0.00412098
	LOSS [training: 0.11428664836661882 | validation: 0.09872453911902794]
	TIME [epoch: 36.6 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1211384958191374		[learning rate: 0.0041046]
	Learning Rate: 0.00410458
	LOSS [training: 0.1211384958191374 | validation: 0.09649061883208485]
	TIME [epoch: 36.6 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11836291249786518		[learning rate: 0.0040883]
	Learning Rate: 0.00408826
	LOSS [training: 0.11836291249786518 | validation: 0.10479066103593267]
	TIME [epoch: 36.6 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13182439847401642		[learning rate: 0.004072]
	Learning Rate: 0.004072
	LOSS [training: 0.13182439847401642 | validation: 0.10128545443095552]
	TIME [epoch: 36.6 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12639098306804528		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.12639098306804528 | validation: 0.09854261432909577]
	TIME [epoch: 36.6 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12009827376797294		[learning rate: 0.0040397]
	Learning Rate: 0.00403967
	LOSS [training: 0.12009827376797294 | validation: 0.09934473208733839]
	TIME [epoch: 36.6 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11612809649923886		[learning rate: 0.0040236]
	Learning Rate: 0.00402361
	LOSS [training: 0.11612809649923886 | validation: 0.09207485806613214]
	TIME [epoch: 36.6 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12648667325846885		[learning rate: 0.0040076]
	Learning Rate: 0.0040076
	LOSS [training: 0.12648667325846885 | validation: 0.09946595699366316]
	TIME [epoch: 36.6 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11334458288457983		[learning rate: 0.0039917]
	Learning Rate: 0.00399166
	LOSS [training: 0.11334458288457983 | validation: 0.10200792707843429]
	TIME [epoch: 36.6 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12482295130194017		[learning rate: 0.0039758]
	Learning Rate: 0.00397579
	LOSS [training: 0.12482295130194017 | validation: 0.10217243158135307]
	TIME [epoch: 36.6 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12463585842157882		[learning rate: 0.00396]
	Learning Rate: 0.00395997
	LOSS [training: 0.12463585842157882 | validation: 0.10136284799425224]
	TIME [epoch: 36.7 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11943877447346796		[learning rate: 0.0039442]
	Learning Rate: 0.00394422
	LOSS [training: 0.11943877447346796 | validation: 0.09648336448359415]
	TIME [epoch: 36.6 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11720892859984472		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 0.11720892859984472 | validation: 0.09479905046884388]
	TIME [epoch: 36.6 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12322453255328354		[learning rate: 0.0039129]
	Learning Rate: 0.00391291
	LOSS [training: 0.12322453255328354 | validation: 0.09836946274076953]
	TIME [epoch: 36.6 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12503386610113465		[learning rate: 0.0038973]
	Learning Rate: 0.00389735
	LOSS [training: 0.12503386610113465 | validation: 0.09429756261500229]
	TIME [epoch: 36.6 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1365591670741422		[learning rate: 0.0038818]
	Learning Rate: 0.00388185
	LOSS [training: 0.1365591670741422 | validation: 0.0953515611066075]
	TIME [epoch: 36.6 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12657419584246535		[learning rate: 0.0038664]
	Learning Rate: 0.00386641
	LOSS [training: 0.12657419584246535 | validation: 0.1053992057986329]
	TIME [epoch: 36.6 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11785453754250597		[learning rate: 0.003851]
	Learning Rate: 0.00385103
	LOSS [training: 0.11785453754250597 | validation: 0.09268265437293974]
	TIME [epoch: 36.6 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12088998859224774		[learning rate: 0.0038357]
	Learning Rate: 0.00383571
	LOSS [training: 0.12088998859224774 | validation: 0.09119518762047743]
	TIME [epoch: 36.6 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12933624608593464		[learning rate: 0.0038205]
	Learning Rate: 0.00382046
	LOSS [training: 0.12933624608593464 | validation: 0.10047952816873618]
	TIME [epoch: 36.6 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11662746071978478		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 0.11662746071978478 | validation: 0.0988922113479966]
	TIME [epoch: 36.6 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11012613972647844		[learning rate: 0.0037901]
	Learning Rate: 0.00379013
	LOSS [training: 0.11012613972647844 | validation: 0.10065842187507681]
	TIME [epoch: 36.6 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12073457113609162		[learning rate: 0.0037751]
	Learning Rate: 0.00377505
	LOSS [training: 0.12073457113609162 | validation: 0.09894798045636559]
	TIME [epoch: 36.6 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11495840507011557		[learning rate: 0.00376]
	Learning Rate: 0.00376004
	LOSS [training: 0.11495840507011557 | validation: 0.101103893441479]
	TIME [epoch: 36.6 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.111741388570685		[learning rate: 0.0037451]
	Learning Rate: 0.00374508
	LOSS [training: 0.111741388570685 | validation: 0.09572260642020367]
	TIME [epoch: 36.6 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13039366507451597		[learning rate: 0.0037302]
	Learning Rate: 0.00373019
	LOSS [training: 0.13039366507451597 | validation: 0.09352162347251705]
	TIME [epoch: 36.7 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1262757354149917		[learning rate: 0.0037154]
	Learning Rate: 0.00371535
	LOSS [training: 0.1262757354149917 | validation: 0.103268924894823]
	TIME [epoch: 36.7 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1528041636370719		[learning rate: 0.0037006]
	Learning Rate: 0.00370058
	LOSS [training: 0.1528041636370719 | validation: 0.1048190893390009]
	TIME [epoch: 36.8 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12524625955912874		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 0.12524625955912874 | validation: 0.09312544861249292]
	TIME [epoch: 36.7 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.129867349805046		[learning rate: 0.0036712]
	Learning Rate: 0.0036712
	LOSS [training: 0.129867349805046 | validation: 0.1025071783656248]
	TIME [epoch: 36.6 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11128476148088651		[learning rate: 0.0036566]
	Learning Rate: 0.0036566
	LOSS [training: 0.11128476148088651 | validation: 0.10017764268464793]
	TIME [epoch: 36.4 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12097431729145362		[learning rate: 0.0036421]
	Learning Rate: 0.00364205
	LOSS [training: 0.12097431729145362 | validation: 0.10395337922065369]
	TIME [epoch: 36.4 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12407791069571328		[learning rate: 0.0036276]
	Learning Rate: 0.00362757
	LOSS [training: 0.12407791069571328 | validation: 0.09382538656704627]
	TIME [epoch: 36.7 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12599249874499818		[learning rate: 0.0036131]
	Learning Rate: 0.00361314
	LOSS [training: 0.12599249874499818 | validation: 0.09645010799139284]
	TIME [epoch: 36.6 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11156458855329429		[learning rate: 0.0035988]
	Learning Rate: 0.00359877
	LOSS [training: 0.11156458855329429 | validation: 0.10059605433936011]
	TIME [epoch: 36.4 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11909830713034471		[learning rate: 0.0035845]
	Learning Rate: 0.00358445
	LOSS [training: 0.11909830713034471 | validation: 0.0923678581381188]
	TIME [epoch: 36.6 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1318172232494245		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 0.1318172232494245 | validation: 0.10560493833390434]
	TIME [epoch: 36.5 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12129979104038828		[learning rate: 0.003556]
	Learning Rate: 0.003556
	LOSS [training: 0.12129979104038828 | validation: 0.10410561717150069]
	TIME [epoch: 36.6 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11331238115210872		[learning rate: 0.0035419]
	Learning Rate: 0.00354185
	LOSS [training: 0.11331238115210872 | validation: 0.0989950154478314]
	TIME [epoch: 36.6 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12599434338791285		[learning rate: 0.0035278]
	Learning Rate: 0.00352777
	LOSS [training: 0.12599434338791285 | validation: 0.09079370448049409]
	TIME [epoch: 36.6 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11559604768136428		[learning rate: 0.0035137]
	Learning Rate: 0.00351374
	LOSS [training: 0.11559604768136428 | validation: 0.09719992929713844]
	TIME [epoch: 36.6 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11910425300728594		[learning rate: 0.0034998]
	Learning Rate: 0.00349976
	LOSS [training: 0.11910425300728594 | validation: 0.10148470692033215]
	TIME [epoch: 36.6 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12361348520628411		[learning rate: 0.0034858]
	Learning Rate: 0.00348584
	LOSS [training: 0.12361348520628411 | validation: 0.09141229002718158]
	TIME [epoch: 36.7 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13257530958825262		[learning rate: 0.003472]
	Learning Rate: 0.00347198
	LOSS [training: 0.13257530958825262 | validation: 0.10138444763950887]
	TIME [epoch: 36.7 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12926307481041685		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.12926307481041685 | validation: 0.0958196080662724]
	TIME [epoch: 36.7 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12879722934500842		[learning rate: 0.0034444]
	Learning Rate: 0.00344441
	LOSS [training: 0.12879722934500842 | validation: 0.09831912605392656]
	TIME [epoch: 36.9 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10957589386135846		[learning rate: 0.0034307]
	Learning Rate: 0.00343071
	LOSS [training: 0.10957589386135846 | validation: 0.0989983095652492]
	TIME [epoch: 36.8 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12307703777323359		[learning rate: 0.0034171]
	Learning Rate: 0.00341707
	LOSS [training: 0.12307703777323359 | validation: 0.10037098741651354]
	TIME [epoch: 36.5 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1254980023955745		[learning rate: 0.0034035]
	Learning Rate: 0.00340348
	LOSS [training: 0.1254980023955745 | validation: 0.09765786200562425]
	TIME [epoch: 36.4 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12349414156888683		[learning rate: 0.0033899]
	Learning Rate: 0.00338994
	LOSS [training: 0.12349414156888683 | validation: 0.10878745878722632]
	TIME [epoch: 36.7 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12767966769248792		[learning rate: 0.0033765]
	Learning Rate: 0.00337646
	LOSS [training: 0.12767966769248792 | validation: 0.10222568233877913]
	TIME [epoch: 36.8 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13228070653636204		[learning rate: 0.003363]
	Learning Rate: 0.00336303
	LOSS [training: 0.13228070653636204 | validation: 0.09830208363454704]
	TIME [epoch: 36.5 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11961743456094304		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 0.11961743456094304 | validation: 0.09468293167200317]
	TIME [epoch: 36.3 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11857533739784411		[learning rate: 0.0033363]
	Learning Rate: 0.00333633
	LOSS [training: 0.11857533739784411 | validation: 0.09798056754974256]
	TIME [epoch: 36.5 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11105219321896627		[learning rate: 0.0033231]
	Learning Rate: 0.00332306
	LOSS [training: 0.11105219321896627 | validation: 0.09801217846682711]
	TIME [epoch: 36.6 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11463076137412864		[learning rate: 0.0033098]
	Learning Rate: 0.00330985
	LOSS [training: 0.11463076137412864 | validation: 0.09910154521481677]
	TIME [epoch: 36.6 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11701800414086419		[learning rate: 0.0032967]
	Learning Rate: 0.00329668
	LOSS [training: 0.11701800414086419 | validation: 0.10741626775825534]
	TIME [epoch: 36.6 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11133915805418829		[learning rate: 0.0032836]
	Learning Rate: 0.00328357
	LOSS [training: 0.11133915805418829 | validation: 0.09835805945710545]
	TIME [epoch: 36.7 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11291118468660949		[learning rate: 0.0032705]
	Learning Rate: 0.00327051
	LOSS [training: 0.11291118468660949 | validation: 0.10111275991706407]
	TIME [epoch: 36.6 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12223870746646741		[learning rate: 0.0032575]
	Learning Rate: 0.0032575
	LOSS [training: 0.12223870746646741 | validation: 0.09956887166834469]
	TIME [epoch: 36.6 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12551075512116291		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 0.12551075512116291 | validation: 0.09913480128134323]
	TIME [epoch: 36.7 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1158776301523304		[learning rate: 0.0032316]
	Learning Rate: 0.00323164
	LOSS [training: 0.1158776301523304 | validation: 0.09080164770801341]
	TIME [epoch: 36.7 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11181077244355538		[learning rate: 0.0032188]
	Learning Rate: 0.00321879
	LOSS [training: 0.11181077244355538 | validation: 0.10251416118635355]
	TIME [epoch: 36.8 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11019183958052912		[learning rate: 0.003206]
	Learning Rate: 0.00320599
	LOSS [training: 0.11019183958052912 | validation: 0.1032704375458611]
	TIME [epoch: 36.8 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12054868596448906		[learning rate: 0.0031932]
	Learning Rate: 0.00319323
	LOSS [training: 0.12054868596448906 | validation: 0.09846941917403111]
	TIME [epoch: 36.9 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11993386198046815		[learning rate: 0.0031805]
	Learning Rate: 0.00318053
	LOSS [training: 0.11993386198046815 | validation: 0.09951988647360822]
	TIME [epoch: 36.8 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11658977547208758		[learning rate: 0.0031679]
	Learning Rate: 0.00316788
	LOSS [training: 0.11658977547208758 | validation: 0.08975288415193941]
	TIME [epoch: 36.7 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12087993097982849		[learning rate: 0.0031553]
	Learning Rate: 0.00315528
	LOSS [training: 0.12087993097982849 | validation: 0.09459784206761193]
	TIME [epoch: 36.5 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1174518440180527		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 0.1174518440180527 | validation: 0.0969360760898386]
	TIME [epoch: 36.8 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11696400053473417		[learning rate: 0.0031302]
	Learning Rate: 0.00313023
	LOSS [training: 0.11696400053473417 | validation: 0.09913828396724812]
	TIME [epoch: 36.8 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11195575566579204		[learning rate: 0.0031178]
	Learning Rate: 0.00311779
	LOSS [training: 0.11195575566579204 | validation: 0.1046678921310193]
	TIME [epoch: 36.6 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11052633498541375		[learning rate: 0.0031054]
	Learning Rate: 0.00310538
	LOSS [training: 0.11052633498541375 | validation: 0.10096939854628213]
	TIME [epoch: 36.4 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11577567675280721		[learning rate: 0.003093]
	Learning Rate: 0.00309303
	LOSS [training: 0.11577567675280721 | validation: 0.0999763220418666]
	TIME [epoch: 36.6 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12586065729225776		[learning rate: 0.0030807]
	Learning Rate: 0.00308073
	LOSS [training: 0.12586065729225776 | validation: 0.09335817284669698]
	TIME [epoch: 36.7 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12305772252908159		[learning rate: 0.0030685]
	Learning Rate: 0.00306848
	LOSS [training: 0.12305772252908159 | validation: 0.09377983313201635]
	TIME [epoch: 36.6 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1197213565136551		[learning rate: 0.0030563]
	Learning Rate: 0.00305627
	LOSS [training: 0.1197213565136551 | validation: 0.10383440996148319]
	TIME [epoch: 36.7 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11371160783880331		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 0.11371160783880331 | validation: 0.10293653011762771]
	TIME [epoch: 36.7 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11657805385620115		[learning rate: 0.003032]
	Learning Rate: 0.00303201
	LOSS [training: 0.11657805385620115 | validation: 0.09814694503905952]
	TIME [epoch: 36.7 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12169477897853631		[learning rate: 0.00302]
	Learning Rate: 0.00301995
	LOSS [training: 0.12169477897853631 | validation: 0.103600863840196]
	TIME [epoch: 36.7 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11035918338172664		[learning rate: 0.0030079]
	Learning Rate: 0.00300794
	LOSS [training: 0.11035918338172664 | validation: 0.09643538878704487]
	TIME [epoch: 36.7 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11907454072245639		[learning rate: 0.002996]
	Learning Rate: 0.00299598
	LOSS [training: 0.11907454072245639 | validation: 0.09513510009181811]
	TIME [epoch: 36.7 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12703833131633857		[learning rate: 0.0029841]
	Learning Rate: 0.00298406
	LOSS [training: 0.12703833131633857 | validation: 0.09806167986171754]
	TIME [epoch: 36.8 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1170865217283558		[learning rate: 0.0029722]
	Learning Rate: 0.00297219
	LOSS [training: 0.1170865217283558 | validation: 0.09970438641810923]
	TIME [epoch: 36.9 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11502338044405394		[learning rate: 0.0029604]
	Learning Rate: 0.00296037
	LOSS [training: 0.11502338044405394 | validation: 0.10438265039468446]
	TIME [epoch: 36.8 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11819101582447405		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.11819101582447405 | validation: 0.10320517793930142]
	TIME [epoch: 36.8 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.111774467356685		[learning rate: 0.0029369]
	Learning Rate: 0.00293687
	LOSS [training: 0.111774467356685 | validation: 0.0965803104431968]
	TIME [epoch: 36.5 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11911867208504745		[learning rate: 0.0029252]
	Learning Rate: 0.00292519
	LOSS [training: 0.11911867208504745 | validation: 0.09242038091128853]
	TIME [epoch: 36.6 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12576266120597931		[learning rate: 0.0029136]
	Learning Rate: 0.00291355
	LOSS [training: 0.12576266120597931 | validation: 0.09538910895759951]
	TIME [epoch: 36.8 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12774894209308785		[learning rate: 0.002902]
	Learning Rate: 0.00290197
	LOSS [training: 0.12774894209308785 | validation: 0.09255323660668442]
	TIME [epoch: 36.7 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1307224551981384		[learning rate: 0.0028904]
	Learning Rate: 0.00289042
	LOSS [training: 0.1307224551981384 | validation: 0.09949808036767052]
	TIME [epoch: 36.4 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11182719027102639		[learning rate: 0.0028789]
	Learning Rate: 0.00287893
	LOSS [training: 0.11182719027102639 | validation: 0.09599565054486477]
	TIME [epoch: 36.6 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11502883944705783		[learning rate: 0.0028675]
	Learning Rate: 0.00286748
	LOSS [training: 0.11502883944705783 | validation: 0.10049270379607034]
	TIME [epoch: 36.6 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1158523439330541		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 0.1158523439330541 | validation: 0.10337417099920902]
	TIME [epoch: 36.7 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10853026964044074		[learning rate: 0.0028447]
	Learning Rate: 0.00284471
	LOSS [training: 0.10853026964044074 | validation: 0.09536840198599927]
	TIME [epoch: 36.7 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11897766578240739		[learning rate: 0.0028334]
	Learning Rate: 0.0028334
	LOSS [training: 0.11897766578240739 | validation: 0.10567056522105296]
	TIME [epoch: 36.7 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11306048727934141		[learning rate: 0.0028221]
	Learning Rate: 0.00282213
	LOSS [training: 0.11306048727934141 | validation: 0.09739173022493691]
	TIME [epoch: 36.7 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12429125219663122		[learning rate: 0.0028109]
	Learning Rate: 0.00281091
	LOSS [training: 0.12429125219663122 | validation: 0.09964271231005377]
	TIME [epoch: 36.7 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1236863557268683		[learning rate: 0.0027997]
	Learning Rate: 0.00279973
	LOSS [training: 0.1236863557268683 | validation: 0.09400792386408226]
	TIME [epoch: 36.7 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11731943742114265		[learning rate: 0.0027886]
	Learning Rate: 0.00278859
	LOSS [training: 0.11731943742114265 | validation: 0.10045334492305617]
	TIME [epoch: 36.7 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11917361047749336		[learning rate: 0.0027775]
	Learning Rate: 0.0027775
	LOSS [training: 0.11917361047749336 | validation: 0.10175793238462653]
	TIME [epoch: 36.8 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12087627552415577		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 0.12087627552415577 | validation: 0.09481228909530609]
	TIME [epoch: 36.9 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10887427992564867		[learning rate: 0.0027554]
	Learning Rate: 0.00275545
	LOSS [training: 0.10887427992564867 | validation: 0.09525014704551968]
	TIME [epoch: 36.9 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11661823230183099		[learning rate: 0.0027445]
	Learning Rate: 0.00274449
	LOSS [training: 0.11661823230183099 | validation: 0.09905922266994442]
	TIME [epoch: 36.7 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12582476268391707		[learning rate: 0.0027336]
	Learning Rate: 0.00273357
	LOSS [training: 0.12582476268391707 | validation: 0.09199945648384171]
	TIME [epoch: 36.6 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11733347559343585		[learning rate: 0.0027227]
	Learning Rate: 0.0027227
	LOSS [training: 0.11733347559343585 | validation: 0.09410055935960018]
	TIME [epoch: 36.6 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12600284594206104		[learning rate: 0.0027119]
	Learning Rate: 0.00271187
	LOSS [training: 0.12600284594206104 | validation: 0.09733687884359203]
	TIME [epoch: 36.7 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10942709650018094		[learning rate: 0.0027011]
	Learning Rate: 0.00270109
	LOSS [training: 0.10942709650018094 | validation: 0.09051067560892681]
	TIME [epoch: 36.8 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11973217686469412		[learning rate: 0.0026903]
	Learning Rate: 0.00269034
	LOSS [training: 0.11973217686469412 | validation: 0.09987768804090165]
	TIME [epoch: 36.3 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12044390473815134		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 0.12044390473815134 | validation: 0.09635144676564215]
	TIME [epoch: 36.7 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11925145027185913		[learning rate: 0.002669]
	Learning Rate: 0.00266899
	LOSS [training: 0.11925145027185913 | validation: 0.09358242991549119]
	TIME [epoch: 36.5 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11233742190084099		[learning rate: 0.0026584]
	Learning Rate: 0.00265837
	LOSS [training: 0.11233742190084099 | validation: 0.10064296052610704]
	TIME [epoch: 36.7 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12462358341016357		[learning rate: 0.0026478]
	Learning Rate: 0.0026478
	LOSS [training: 0.12462358341016357 | validation: 0.1051120978302702]
	TIME [epoch: 36.7 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1113253263477105		[learning rate: 0.0026373]
	Learning Rate: 0.00263727
	LOSS [training: 0.1113253263477105 | validation: 0.09999095665272918]
	TIME [epoch: 36.7 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12362515177765492		[learning rate: 0.0026268]
	Learning Rate: 0.00262678
	LOSS [training: 0.12362515177765492 | validation: 0.10524650853455533]
	TIME [epoch: 36.7 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12307752404465577		[learning rate: 0.0026163]
	Learning Rate: 0.00261633
	LOSS [training: 0.12307752404465577 | validation: 0.10331187536748501]
	TIME [epoch: 36.7 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11922277210656154		[learning rate: 0.0026059]
	Learning Rate: 0.00260592
	LOSS [training: 0.11922277210656154 | validation: 0.09913299447635922]
	TIME [epoch: 36.7 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11253065273488962		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 0.11253065273488962 | validation: 0.09506134812919716]
	TIME [epoch: 36.7 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11871357399223958		[learning rate: 0.0025852]
	Learning Rate: 0.00258523
	LOSS [training: 0.11871357399223958 | validation: 0.10311988333344677]
	TIME [epoch: 36.7 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11712463466195538		[learning rate: 0.002575]
	Learning Rate: 0.00257495
	LOSS [training: 0.11712463466195538 | validation: 0.09700313035304864]
	TIME [epoch: 36.8 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11487101857402876		[learning rate: 0.0025647]
	Learning Rate: 0.00256471
	LOSS [training: 0.11487101857402876 | validation: 0.09721055355046546]
	TIME [epoch: 36.9 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.112229527196569		[learning rate: 0.0025545]
	Learning Rate: 0.00255451
	LOSS [training: 0.112229527196569 | validation: 0.09189235666320206]
	TIME [epoch: 36.8 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12684056790998455		[learning rate: 0.0025444]
	Learning Rate: 0.00254435
	LOSS [training: 0.12684056790998455 | validation: 0.09953713161146902]
	TIME [epoch: 36.7 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11827678111766342		[learning rate: 0.0025342]
	Learning Rate: 0.00253423
	LOSS [training: 0.11827678111766342 | validation: 0.09981078898089475]
	TIME [epoch: 36.5 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1164217212309944		[learning rate: 0.0025242]
	Learning Rate: 0.00252415
	LOSS [training: 0.1164217212309944 | validation: 0.09137539751832657]
	TIME [epoch: 36.7 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12002984076333206		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.12002984076333206 | validation: 0.09534551059292849]
	TIME [epoch: 36.8 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1202129438321465		[learning rate: 0.0025041]
	Learning Rate: 0.00250411
	LOSS [training: 0.1202129438321465 | validation: 0.09903240712832773]
	TIME [epoch: 36.7 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11973134440880687		[learning rate: 0.0024942]
	Learning Rate: 0.00249415
	LOSS [training: 0.11973134440880687 | validation: 0.09729168977840028]
	TIME [epoch: 36.5 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12427405393372365		[learning rate: 0.0024842]
	Learning Rate: 0.00248423
	LOSS [training: 0.12427405393372365 | validation: 0.09660198008667836]
	TIME [epoch: 36.4 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11971288741792614		[learning rate: 0.0024744]
	Learning Rate: 0.00247435
	LOSS [training: 0.11971288741792614 | validation: 0.09412444763364432]
	TIME [epoch: 36.7 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1133974242053904		[learning rate: 0.0024645]
	Learning Rate: 0.00246451
	LOSS [training: 0.1133974242053904 | validation: 0.09285911724717885]
	TIME [epoch: 36.7 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11456101535434672		[learning rate: 0.0024547]
	Learning Rate: 0.00245471
	LOSS [training: 0.11456101535434672 | validation: 0.09134563567699538]
	TIME [epoch: 36.7 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11182329016544462		[learning rate: 0.0024449]
	Learning Rate: 0.00244495
	LOSS [training: 0.11182329016544462 | validation: 0.09903847956601715]
	TIME [epoch: 36.7 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11829581847503591		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 0.11829581847503591 | validation: 0.09668661922360437]
	TIME [epoch: 36.7 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13086694022982173		[learning rate: 0.0024255]
	Learning Rate: 0.00242554
	LOSS [training: 0.13086694022982173 | validation: 0.09383366183501407]
	TIME [epoch: 36.7 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11800136013074747		[learning rate: 0.0024159]
	Learning Rate: 0.00241589
	LOSS [training: 0.11800136013074747 | validation: 0.09369223961801675]
	TIME [epoch: 36.7 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12175825398576048		[learning rate: 0.0024063]
	Learning Rate: 0.00240628
	LOSS [training: 0.12175825398576048 | validation: 0.09351556131034307]
	TIME [epoch: 36.7 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11711986439942887		[learning rate: 0.0023967]
	Learning Rate: 0.00239671
	LOSS [training: 0.11711986439942887 | validation: 0.1004296322070034]
	TIME [epoch: 36.8 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12068573265537713		[learning rate: 0.0023872]
	Learning Rate: 0.00238718
	LOSS [training: 0.12068573265537713 | validation: 0.1014475011205965]
	TIME [epoch: 36.9 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11427536425305214		[learning rate: 0.0023777]
	Learning Rate: 0.00237768
	LOSS [training: 0.11427536425305214 | validation: 0.09131490750732532]
	TIME [epoch: 36.8 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11749348867466075		[learning rate: 0.0023682]
	Learning Rate: 0.00236823
	LOSS [training: 0.11749348867466075 | validation: 0.0900323905957701]
	TIME [epoch: 36.5 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11694630026794489		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 0.11694630026794489 | validation: 0.10670112479462823]
	TIME [epoch: 36.5 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11034195963148062		[learning rate: 0.0023494]
	Learning Rate: 0.00234942
	LOSS [training: 0.11034195963148062 | validation: 0.09446846627729073]
	TIME [epoch: 36.7 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11741023956546053		[learning rate: 0.0023401]
	Learning Rate: 0.00234008
	LOSS [training: 0.11741023956546053 | validation: 0.09879485390261304]
	TIME [epoch: 36.8 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12311559399682886		[learning rate: 0.0023308]
	Learning Rate: 0.00233077
	LOSS [training: 0.12311559399682886 | validation: 0.10086945195940344]
	TIME [epoch: 36.7 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1231605799204149		[learning rate: 0.0023215]
	Learning Rate: 0.0023215
	LOSS [training: 0.1231605799204149 | validation: 0.09625181651892613]
	TIME [epoch: 36.7 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11258825598103495		[learning rate: 0.0023123]
	Learning Rate: 0.00231227
	LOSS [training: 0.11258825598103495 | validation: 0.0959541509372069]
	TIME [epoch: 36.7 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11830773545259013		[learning rate: 0.0023031]
	Learning Rate: 0.00230307
	LOSS [training: 0.11830773545259013 | validation: 0.09577769019932088]
	TIME [epoch: 36.6 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11189604214489957		[learning rate: 0.0022939]
	Learning Rate: 0.00229391
	LOSS [training: 0.11189604214489957 | validation: 0.09552658958561326]
	TIME [epoch: 36.7 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11267196228127593		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 0.11267196228127593 | validation: 0.09277169481151519]
	TIME [epoch: 36.7 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11609233712443522		[learning rate: 0.0022757]
	Learning Rate: 0.0022757
	LOSS [training: 0.11609233712443522 | validation: 0.09038693305534957]
	TIME [epoch: 36.7 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11026660945231757		[learning rate: 0.0022667]
	Learning Rate: 0.00226665
	LOSS [training: 0.11026660945231757 | validation: 0.09268995025678867]
	TIME [epoch: 36.7 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13453235936804564		[learning rate: 0.0022576]
	Learning Rate: 0.00225764
	LOSS [training: 0.13453235936804564 | validation: 0.09185700398755392]
	TIME [epoch: 36.7 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11586333751525085		[learning rate: 0.0022487]
	Learning Rate: 0.00224866
	LOSS [training: 0.11586333751525085 | validation: 0.09876572368939325]
	TIME [epoch: 36.7 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12046558414517117		[learning rate: 0.0022397]
	Learning Rate: 0.00223971
	LOSS [training: 0.12046558414517117 | validation: 0.09215532640685087]
	TIME [epoch: 36.7 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11268687036174582		[learning rate: 0.0022308]
	Learning Rate: 0.0022308
	LOSS [training: 0.11268687036174582 | validation: 0.09311081029916626]
	TIME [epoch: 36.8 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10908132567331957		[learning rate: 0.0022219]
	Learning Rate: 0.00222193
	LOSS [training: 0.10908132567331957 | validation: 0.09264497281958728]
	TIME [epoch: 36.8 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1196875315735988		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.1196875315735988 | validation: 0.10143400061854631]
	TIME [epoch: 36.8 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11565146880176304		[learning rate: 0.0022043]
	Learning Rate: 0.00220429
	LOSS [training: 0.11565146880176304 | validation: 0.08967566043823398]
	TIME [epoch: 37 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11064457583484996		[learning rate: 0.0021955]
	Learning Rate: 0.00219553
	LOSS [training: 0.11064457583484996 | validation: 0.09878696655862441]
	TIME [epoch: 36.9 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11371790135420606		[learning rate: 0.0021868]
	Learning Rate: 0.00218679
	LOSS [training: 0.11371790135420606 | validation: 0.09492969215398132]
	TIME [epoch: 36.9 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11722658839961768		[learning rate: 0.0021781]
	Learning Rate: 0.0021781
	LOSS [training: 0.11722658839961768 | validation: 0.09607503877483167]
	TIME [epoch: 36.9 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12143696327493436		[learning rate: 0.0021694]
	Learning Rate: 0.00216943
	LOSS [training: 0.12143696327493436 | validation: 0.10134748686852768]
	TIME [epoch: 36.9 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12466491015517435		[learning rate: 0.0021608]
	Learning Rate: 0.0021608
	LOSS [training: 0.12466491015517435 | validation: 0.10516115537188338]
	TIME [epoch: 36.8 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1194917229240781		[learning rate: 0.0021522]
	Learning Rate: 0.00215221
	LOSS [training: 0.1194917229240781 | validation: 0.09310668315127009]
	TIME [epoch: 36.8 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11168427589016298		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.11168427589016298 | validation: 0.09227646232244316]
	TIME [epoch: 36.9 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1284806010264551		[learning rate: 0.0021351]
	Learning Rate: 0.00213512
	LOSS [training: 0.1284806010264551 | validation: 0.0986904944611936]
	TIME [epoch: 36.8 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12412557891773036		[learning rate: 0.0021266]
	Learning Rate: 0.00212663
	LOSS [training: 0.12412557891773036 | validation: 0.10243294430972343]
	TIME [epoch: 36.8 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12398575181877586		[learning rate: 0.0021182]
	Learning Rate: 0.00211817
	LOSS [training: 0.12398575181877586 | validation: 0.09541104047104208]
	TIME [epoch: 36.7 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13095593108098855		[learning rate: 0.0021097]
	Learning Rate: 0.00210975
	LOSS [training: 0.13095593108098855 | validation: 0.09896043757345441]
	TIME [epoch: 36.7 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11316711018585332		[learning rate: 0.0021014]
	Learning Rate: 0.00210136
	LOSS [training: 0.11316711018585332 | validation: 0.09813055982176433]
	TIME [epoch: 36.7 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11925130180890145		[learning rate: 0.002093]
	Learning Rate: 0.002093
	LOSS [training: 0.11925130180890145 | validation: 0.09136107017119115]
	TIME [epoch: 36.7 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11616326071553923		[learning rate: 0.0020847]
	Learning Rate: 0.00208468
	LOSS [training: 0.11616326071553923 | validation: 0.09403265242027795]
	TIME [epoch: 36.7 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12025665628165186		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.12025665628165186 | validation: 0.09678120106649155]
	TIME [epoch: 36.7 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10592646701509005		[learning rate: 0.0020681]
	Learning Rate: 0.00206813
	LOSS [training: 0.10592646701509005 | validation: 0.09887695556215041]
	TIME [epoch: 36.7 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11996674646518413		[learning rate: 0.0020599]
	Learning Rate: 0.0020599
	LOSS [training: 0.11996674646518413 | validation: 0.08847007632701198]
	TIME [epoch: 36.8 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v1_20240624_133245/states/model_facs_dec1b_2dpca_v1_441.pth
	Model improved!!!
EPOCH 442/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11847139659220912		[learning rate: 0.0020517]
	Learning Rate: 0.00205171
	LOSS [training: 0.11847139659220912 | validation: 0.10543052722823631]
	TIME [epoch: 36.8 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1256984347113142		[learning rate: 0.0020435]
	Learning Rate: 0.00204355
	LOSS [training: 0.1256984347113142 | validation: 0.09833812718790176]
	TIME [epoch: 36.8 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11909918053726831		[learning rate: 0.0020354]
	Learning Rate: 0.00203542
	LOSS [training: 0.11909918053726831 | validation: 0.09489358150305413]
	TIME [epoch: 36.9 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10790605349259458		[learning rate: 0.0020273]
	Learning Rate: 0.00202732
	LOSS [training: 0.10790605349259458 | validation: 0.0930679464227688]
	TIME [epoch: 36.8 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11050820929067257		[learning rate: 0.0020193]
	Learning Rate: 0.00201926
	LOSS [training: 0.11050820929067257 | validation: 0.09529408471516627]
	TIME [epoch: 36.9 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11438133689953779		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 0.11438133689953779 | validation: 0.10017516728486872]
	TIME [epoch: 36.9 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11320419294810627		[learning rate: 0.0020032]
	Learning Rate: 0.00200323
	LOSS [training: 0.11320419294810627 | validation: 0.10157843213055957]
	TIME [epoch: 36.8 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1216659190057783		[learning rate: 0.0019953]
	Learning Rate: 0.00199526
	LOSS [training: 0.1216659190057783 | validation: 0.09725959359109891]
	TIME [epoch: 36.9 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11293428912553215		[learning rate: 0.0019873]
	Learning Rate: 0.00198733
	LOSS [training: 0.11293428912553215 | validation: 0.09386283797432977]
	TIME [epoch: 36.8 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12461630894834366		[learning rate: 0.0019794]
	Learning Rate: 0.00197942
	LOSS [training: 0.12461630894834366 | validation: 0.09599896743950205]
	TIME [epoch: 36.8 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12485773199477627		[learning rate: 0.0019715]
	Learning Rate: 0.00197155
	LOSS [training: 0.12485773199477627 | validation: 0.09726466495874522]
	TIME [epoch: 36.8 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13078588992014442		[learning rate: 0.0019637]
	Learning Rate: 0.00196371
	LOSS [training: 0.13078588992014442 | validation: 0.09480836934996974]
	TIME [epoch: 36.8 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1133931283219716		[learning rate: 0.0019559]
	Learning Rate: 0.0019559
	LOSS [training: 0.1133931283219716 | validation: 0.09131897276257102]
	TIME [epoch: 36.7 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10995837437985326		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 0.10995837437985326 | validation: 0.09925162232787661]
	TIME [epoch: 36.7 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12902671947407918		[learning rate: 0.0019404]
	Learning Rate: 0.00194037
	LOSS [training: 0.12902671947407918 | validation: 0.09445832334785109]
	TIME [epoch: 36.7 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12831280686426436		[learning rate: 0.0019327]
	Learning Rate: 0.00193265
	LOSS [training: 0.12831280686426436 | validation: 0.10110028864387059]
	TIME [epoch: 36.7 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1142299485674319		[learning rate: 0.001925]
	Learning Rate: 0.00192497
	LOSS [training: 0.1142299485674319 | validation: 0.10359013703667486]
	TIME [epoch: 36.7 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11729990373087235		[learning rate: 0.0019173]
	Learning Rate: 0.00191731
	LOSS [training: 0.11729990373087235 | validation: 0.1038358987937205]
	TIME [epoch: 36.8 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12498621865248445		[learning rate: 0.0019097]
	Learning Rate: 0.00190968
	LOSS [training: 0.12498621865248445 | validation: 0.09760130568223993]
	TIME [epoch: 36.8 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11402070880976581		[learning rate: 0.0019021]
	Learning Rate: 0.00190209
	LOSS [training: 0.11402070880976581 | validation: 0.09349030985700808]
	TIME [epoch: 36.9 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11357858457359739		[learning rate: 0.0018945]
	Learning Rate: 0.00189452
	LOSS [training: 0.11357858457359739 | validation: 0.08984974797894696]
	TIME [epoch: 36.8 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1190799899816018		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.1190799899816018 | validation: 0.09052888110286156]
	TIME [epoch: 36.8 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1157751410400891		[learning rate: 0.0018795]
	Learning Rate: 0.00187948
	LOSS [training: 0.1157751410400891 | validation: 0.09125839251356349]
	TIME [epoch: 36.9 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11278372518427177		[learning rate: 0.001872]
	Learning Rate: 0.00187201
	LOSS [training: 0.11278372518427177 | validation: 0.09540347167966064]
	TIME [epoch: 36.9 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11759271880494183		[learning rate: 0.0018646]
	Learning Rate: 0.00186456
	LOSS [training: 0.11759271880494183 | validation: 0.09275377638880215]
	TIME [epoch: 36.9 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11607691275162016		[learning rate: 0.0018571]
	Learning Rate: 0.00185715
	LOSS [training: 0.11607691275162016 | validation: 0.09131294929277985]
	TIME [epoch: 36.9 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1206087059622814		[learning rate: 0.0018498]
	Learning Rate: 0.00184976
	LOSS [training: 0.1206087059622814 | validation: 0.09286649964754502]
	TIME [epoch: 36.9 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1174181019845381		[learning rate: 0.0018424]
	Learning Rate: 0.0018424
	LOSS [training: 0.1174181019845381 | validation: 0.10143461410015872]
	TIME [epoch: 36.8 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10802951740260269		[learning rate: 0.0018351]
	Learning Rate: 0.00183508
	LOSS [training: 0.10802951740260269 | validation: 0.09566139597724935]
	TIME [epoch: 36.8 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11110807868706754		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.11110807868706754 | validation: 0.09961582004407088]
	TIME [epoch: 36.8 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1167580163811756		[learning rate: 0.0018205]
	Learning Rate: 0.00182051
	LOSS [training: 0.1167580163811756 | validation: 0.09446661195816287]
	TIME [epoch: 36.8 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11478123024956864		[learning rate: 0.0018133]
	Learning Rate: 0.00181327
	LOSS [training: 0.11478123024956864 | validation: 0.10247577050933283]
	TIME [epoch: 36.8 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12506033786192866		[learning rate: 0.0018061]
	Learning Rate: 0.00180605
	LOSS [training: 0.12506033786192866 | validation: 0.09300164456004822]
	TIME [epoch: 36.8 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11455112951896629		[learning rate: 0.0017989]
	Learning Rate: 0.00179887
	LOSS [training: 0.11455112951896629 | validation: 0.09700108212378855]
	TIME [epoch: 36.7 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1155032069527336		[learning rate: 0.0017917]
	Learning Rate: 0.00179172
	LOSS [training: 0.1155032069527336 | validation: 0.10035232640875433]
	TIME [epoch: 36.7 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1109591969488373		[learning rate: 0.0017846]
	Learning Rate: 0.00178459
	LOSS [training: 0.1109591969488373 | validation: 0.08898918834273678]
	TIME [epoch: 36.7 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11522310925947954		[learning rate: 0.0017775]
	Learning Rate: 0.00177749
	LOSS [training: 0.11522310925947954 | validation: 0.09868852137003861]
	TIME [epoch: 36.8 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.115673431609427		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.115673431609427 | validation: 0.09731998235904585]
	TIME [epoch: 36.8 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1101185012519075		[learning rate: 0.0017634]
	Learning Rate: 0.00176338
	LOSS [training: 0.1101185012519075 | validation: 0.0980620421688366]
	TIME [epoch: 36.8 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11296211879076849		[learning rate: 0.0017564]
	Learning Rate: 0.00175637
	LOSS [training: 0.11296211879076849 | validation: 0.09381628603304532]
	TIME [epoch: 36.8 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11789812211977603		[learning rate: 0.0017494]
	Learning Rate: 0.00174938
	LOSS [training: 0.11789812211977603 | validation: 0.09689006094656644]
	TIME [epoch: 37 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.108123081321069		[learning rate: 0.0017424]
	Learning Rate: 0.00174242
	LOSS [training: 0.108123081321069 | validation: 0.09510264376502306]
	TIME [epoch: 36.8 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11888546529078045		[learning rate: 0.0017355]
	Learning Rate: 0.00173549
	LOSS [training: 0.11888546529078045 | validation: 0.09926233684085092]
	TIME [epoch: 36.9 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12380011073896696		[learning rate: 0.0017286]
	Learning Rate: 0.00172859
	LOSS [training: 0.12380011073896696 | validation: 0.09897982429371088]
	TIME [epoch: 36.9 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11286338269855631		[learning rate: 0.0017217]
	Learning Rate: 0.00172172
	LOSS [training: 0.11286338269855631 | validation: 0.09129411699368564]
	TIME [epoch: 36.9 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1118261066671628		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 0.1118261066671628 | validation: 0.09961288403485354]
	TIME [epoch: 36.8 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11442933365746377		[learning rate: 0.001708]
	Learning Rate: 0.00170805
	LOSS [training: 0.11442933365746377 | validation: 0.10000534658527187]
	TIME [epoch: 36.7 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11131176571667778		[learning rate: 0.0017013]
	Learning Rate: 0.00170125
	LOSS [training: 0.11131176571667778 | validation: 0.09544826443434072]
	TIME [epoch: 36.8 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11316381886633432		[learning rate: 0.0016945]
	Learning Rate: 0.00169449
	LOSS [training: 0.11316381886633432 | validation: 0.09693397310353494]
	TIME [epoch: 36.9 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11361207691656786		[learning rate: 0.0016877]
	Learning Rate: 0.00168775
	LOSS [training: 0.11361207691656786 | validation: 0.09233201706757921]
	TIME [epoch: 36.8 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12430662890806181		[learning rate: 0.001681]
	Learning Rate: 0.00168104
	LOSS [training: 0.12430662890806181 | validation: 0.09579855043708625]
	TIME [epoch: 36.8 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11926185003699269		[learning rate: 0.0016743]
	Learning Rate: 0.00167435
	LOSS [training: 0.11926185003699269 | validation: 0.09681710735985427]
	TIME [epoch: 36.7 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11671795181609863		[learning rate: 0.0016677]
	Learning Rate: 0.00166769
	LOSS [training: 0.11671795181609863 | validation: 0.09484757678952525]
	TIME [epoch: 36.7 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12071727284045679		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.12071727284045679 | validation: 0.0961966787398488]
	TIME [epoch: 36.9 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12545150202721944		[learning rate: 0.0016545]
	Learning Rate: 0.00165445
	LOSS [training: 0.12545150202721944 | validation: 0.08748801160169592]
	TIME [epoch: 36.8 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v1_20240624_133245/states/model_facs_dec1b_2dpca_v1_496.pth
	Model improved!!!
EPOCH 497/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11262952798863518		[learning rate: 0.0016479]
	Learning Rate: 0.00164787
	LOSS [training: 0.11262952798863518 | validation: 0.09264380097252585]
	TIME [epoch: 36.8 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11299409177219452		[learning rate: 0.0016413]
	Learning Rate: 0.00164132
	LOSS [training: 0.11299409177219452 | validation: 0.094782682646244]
	TIME [epoch: 36.9 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12128112423321598		[learning rate: 0.0016348]
	Learning Rate: 0.00163479
	LOSS [training: 0.12128112423321598 | validation: 0.09389422838534292]
	TIME [epoch: 36.8 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10833961828279601		[learning rate: 0.0016283]
	Learning Rate: 0.00162829
	LOSS [training: 0.10833961828279601 | validation: 0.09653403007109794]
	TIME [epoch: 36.8 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11773928435161604		[learning rate: 0.0016218]
	Learning Rate: 0.00162181
	LOSS [training: 0.11773928435161604 | validation: 0.09631622192219334]
	TIME [epoch: 36.8 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11358060419457588		[learning rate: 0.0016154]
	Learning Rate: 0.00161536
	LOSS [training: 0.11358060419457588 | validation: 0.09634631539558283]
	TIME [epoch: 36.9 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11490340926870728		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 0.11490340926870728 | validation: 0.10166531729826649]
	TIME [epoch: 36.8 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11892740614250541		[learning rate: 0.0016025]
	Learning Rate: 0.00160254
	LOSS [training: 0.11892740614250541 | validation: 0.09539782870183461]
	TIME [epoch: 36.9 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10965982184258216		[learning rate: 0.0015962]
	Learning Rate: 0.00159616
	LOSS [training: 0.10965982184258216 | validation: 0.09530075352692273]
	TIME [epoch: 36.9 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11644427985257738		[learning rate: 0.0015898]
	Learning Rate: 0.00158981
	LOSS [training: 0.11644427985257738 | validation: 0.0935390592169819]
	TIME [epoch: 36.9 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11966690469866978		[learning rate: 0.0015835]
	Learning Rate: 0.00158349
	LOSS [training: 0.11966690469866978 | validation: 0.09208046369030813]
	TIME [epoch: 36.8 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12418475129671368		[learning rate: 0.0015772]
	Learning Rate: 0.00157719
	LOSS [training: 0.12418475129671368 | validation: 0.08719588211825788]
	TIME [epoch: 36.8 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v1_20240624_133245/states/model_facs_dec1b_2dpca_v1_508.pth
	Model improved!!!
EPOCH 509/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11712577307040181		[learning rate: 0.0015709]
	Learning Rate: 0.00157092
	LOSS [training: 0.11712577307040181 | validation: 0.09711127056918059]
	TIME [epoch: 36.8 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11794489399091251		[learning rate: 0.0015647]
	Learning Rate: 0.00156467
	LOSS [training: 0.11794489399091251 | validation: 0.09578267773645828]
	TIME [epoch: 36.8 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11916618996076996		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.11916618996076996 | validation: 0.09002517537384867]
	TIME [epoch: 36.8 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11791775853849569		[learning rate: 0.0015522]
	Learning Rate: 0.00155225
	LOSS [training: 0.11791775853849569 | validation: 0.10101360050435018]
	TIME [epoch: 36.7 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10951766546426038		[learning rate: 0.0015461]
	Learning Rate: 0.00154608
	LOSS [training: 0.10951766546426038 | validation: 0.09959992891064337]
	TIME [epoch: 36.7 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11128900408246298		[learning rate: 0.0015399]
	Learning Rate: 0.00153993
	LOSS [training: 0.11128900408246298 | validation: 0.09349600635326247]
	TIME [epoch: 36.8 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11835382477793042		[learning rate: 0.0015338]
	Learning Rate: 0.0015338
	LOSS [training: 0.11835382477793042 | validation: 0.09833085087045457]
	TIME [epoch: 36.8 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12095535849158161		[learning rate: 0.0015277]
	Learning Rate: 0.0015277
	LOSS [training: 0.12095535849158161 | validation: 0.09236445066055801]
	TIME [epoch: 36.9 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1280500055674998		[learning rate: 0.0015216]
	Learning Rate: 0.00152163
	LOSS [training: 0.1280500055674998 | validation: 0.09999928339047592]
	TIME [epoch: 36.9 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11463543982915302		[learning rate: 0.0015156]
	Learning Rate: 0.00151557
	LOSS [training: 0.11463543982915302 | validation: 0.09289649405282438]
	TIME [epoch: 36.8 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12275241420878598		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.12275241420878598 | validation: 0.0958785025829599]
	TIME [epoch: 36.8 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11263672119488095		[learning rate: 0.0015035]
	Learning Rate: 0.00150354
	LOSS [training: 0.11263672119488095 | validation: 0.09852733402870029]
	TIME [epoch: 37 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1097097362879305		[learning rate: 0.0014976]
	Learning Rate: 0.00149756
	LOSS [training: 0.1097097362879305 | validation: 0.09605696091186591]
	TIME [epoch: 36.8 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11350492476402627		[learning rate: 0.0014916]
	Learning Rate: 0.00149161
	LOSS [training: 0.11350492476402627 | validation: 0.10809520543116664]
	TIME [epoch: 36.9 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11359760467708074		[learning rate: 0.0014857]
	Learning Rate: 0.00148567
	LOSS [training: 0.11359760467708074 | validation: 0.09030365733683879]
	TIME [epoch: 36.9 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11009476949738567		[learning rate: 0.0014798]
	Learning Rate: 0.00147976
	LOSS [training: 0.11009476949738567 | validation: 0.09371323338806671]
	TIME [epoch: 36.9 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1116463596477833		[learning rate: 0.0014739]
	Learning Rate: 0.00147388
	LOSS [training: 0.1116463596477833 | validation: 0.09475034217150735]
	TIME [epoch: 36.8 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10968720955963901		[learning rate: 0.001468]
	Learning Rate: 0.00146802
	LOSS [training: 0.10968720955963901 | validation: 0.08911025780381292]
	TIME [epoch: 36.8 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1183837104913556		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.1183837104913556 | validation: 0.09700659027106007]
	TIME [epoch: 36.8 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12285158426040176		[learning rate: 0.0014564]
	Learning Rate: 0.00145636
	LOSS [training: 0.12285158426040176 | validation: 0.09398054507806669]
	TIME [epoch: 36.8 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11314253506539067		[learning rate: 0.0014506]
	Learning Rate: 0.00145057
	LOSS [training: 0.11314253506539067 | validation: 0.09744832076215595]
	TIME [epoch: 36.8 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1154955694496068		[learning rate: 0.0014448]
	Learning Rate: 0.0014448
	LOSS [training: 0.1154955694496068 | validation: 0.09711892119973331]
	TIME [epoch: 36.7 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11884908220592832		[learning rate: 0.0014391]
	Learning Rate: 0.00143905
	LOSS [training: 0.11884908220592832 | validation: 0.09697910761815687]
	TIME [epoch: 36.7 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11742566488148645		[learning rate: 0.0014333]
	Learning Rate: 0.00143333
	LOSS [training: 0.11742566488148645 | validation: 0.10005740851785475]
	TIME [epoch: 36.8 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11791877850321647		[learning rate: 0.0014276]
	Learning Rate: 0.00142763
	LOSS [training: 0.11791877850321647 | validation: 0.09521538224687097]
	TIME [epoch: 36.8 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11545381381802183		[learning rate: 0.001422]
	Learning Rate: 0.00142195
	LOSS [training: 0.11545381381802183 | validation: 0.0999827376179335]
	TIME [epoch: 36.9 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11311469679598682		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.11311469679598682 | validation: 0.09964072860467292]
	TIME [epoch: 36.9 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11895573948004719		[learning rate: 0.0014107]
	Learning Rate: 0.00141066
	LOSS [training: 0.11895573948004719 | validation: 0.09049919999014347]
	TIME [epoch: 36.8 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11139477552404507		[learning rate: 0.0014051]
	Learning Rate: 0.00140505
	LOSS [training: 0.11139477552404507 | validation: 0.09092406526529802]
	TIME [epoch: 36.8 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11639898257657147		[learning rate: 0.0013995]
	Learning Rate: 0.00139946
	LOSS [training: 0.11639898257657147 | validation: 0.09772881029008455]
	TIME [epoch: 36.9 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11121998561893474		[learning rate: 0.0013939]
	Learning Rate: 0.0013939
	LOSS [training: 0.11121998561893474 | validation: 0.09891632837699924]
	TIME [epoch: 36.9 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10875482573527623		[learning rate: 0.0013884]
	Learning Rate: 0.00138835
	LOSS [training: 0.10875482573527623 | validation: 0.09418778988569199]
	TIME [epoch: 36.9 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10580230105484004		[learning rate: 0.0013828]
	Learning Rate: 0.00138283
	LOSS [training: 0.10580230105484004 | validation: 0.09529062872578409]
	TIME [epoch: 36.9 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11276687048137098		[learning rate: 0.0013773]
	Learning Rate: 0.00137733
	LOSS [training: 0.11276687048137098 | validation: 0.09516471062694912]
	TIME [epoch: 36.9 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11758043210161705		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 0.11758043210161705 | validation: 0.09616886356322436]
	TIME [epoch: 36.9 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11060417549683259		[learning rate: 0.0013664]
	Learning Rate: 0.0013664
	LOSS [training: 0.11060417549683259 | validation: 0.09836392083989165]
	TIME [epoch: 36.8 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11207688753053367		[learning rate: 0.001361]
	Learning Rate: 0.00136096
	LOSS [training: 0.11207688753053367 | validation: 0.09217530778265996]
	TIME [epoch: 36.9 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11400281944339044		[learning rate: 0.0013555]
	Learning Rate: 0.00135555
	LOSS [training: 0.11400281944339044 | validation: 0.09100222409194315]
	TIME [epoch: 36.8 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11635538277117233		[learning rate: 0.0013502]
	Learning Rate: 0.00135016
	LOSS [training: 0.11635538277117233 | validation: 0.09775680242196402]
	TIME [epoch: 36.8 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11402979308147729		[learning rate: 0.0013448]
	Learning Rate: 0.00134479
	LOSS [training: 0.11402979308147729 | validation: 0.09914708786584917]
	TIME [epoch: 36.7 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11170986557226999		[learning rate: 0.0013394]
	Learning Rate: 0.00133944
	LOSS [training: 0.11170986557226999 | validation: 0.10154840771704329]
	TIME [epoch: 36.8 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12152260339668795		[learning rate: 0.0013341]
	Learning Rate: 0.00133411
	LOSS [training: 0.12152260339668795 | validation: 0.09243721802930974]
	TIME [epoch: 36.8 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12021963592341162		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.12021963592341162 | validation: 0.09059947240910282]
	TIME [epoch: 36.8 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10547903134196338		[learning rate: 0.0013235]
	Learning Rate: 0.00132352
	LOSS [training: 0.10547903134196338 | validation: 0.09248591131347217]
	TIME [epoch: 36.8 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11057817984368326		[learning rate: 0.0013183]
	Learning Rate: 0.00131826
	LOSS [training: 0.11057817984368326 | validation: 0.09508208973569734]
	TIME [epoch: 36.8 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10472109617582641		[learning rate: 0.001313]
	Learning Rate: 0.00131301
	LOSS [training: 0.10472109617582641 | validation: 0.09941848166018986]
	TIME [epoch: 36.8 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1176801829049957		[learning rate: 0.0013078]
	Learning Rate: 0.00130779
	LOSS [training: 0.1176801829049957 | validation: 0.09350877333576132]
	TIME [epoch: 36.8 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11306475849952946		[learning rate: 0.0013026]
	Learning Rate: 0.00130259
	LOSS [training: 0.11306475849952946 | validation: 0.10408021147885951]
	TIME [epoch: 36.7 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10978971098981288		[learning rate: 0.0012974]
	Learning Rate: 0.00129741
	LOSS [training: 0.10978971098981288 | validation: 0.0995618752744865]
	TIME [epoch: 36.7 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11174789997504263		[learning rate: 0.0012922]
	Learning Rate: 0.00129225
	LOSS [training: 0.11174789997504263 | validation: 0.09150546547796141]
	TIME [epoch: 36.7 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11483406730102473		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 0.11483406730102473 | validation: 0.09689455967283159]
	TIME [epoch: 36.7 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11376434762292124		[learning rate: 0.001282]
	Learning Rate: 0.00128199
	LOSS [training: 0.11376434762292124 | validation: 0.10372317851935567]
	TIME [epoch: 36.7 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11321590912579545		[learning rate: 0.0012769]
	Learning Rate: 0.00127689
	LOSS [training: 0.11321590912579545 | validation: 0.0934140917636626]
	TIME [epoch: 36.7 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12500106833131552		[learning rate: 0.0012718]
	Learning Rate: 0.00127181
	LOSS [training: 0.12500106833131552 | validation: 0.09951369728648943]
	TIME [epoch: 36.7 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11011218620014784		[learning rate: 0.0012668]
	Learning Rate: 0.00126675
	LOSS [training: 0.11011218620014784 | validation: 0.09284104245660921]
	TIME [epoch: 36.7 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10944071591023988		[learning rate: 0.0012617]
	Learning Rate: 0.00126172
	LOSS [training: 0.10944071591023988 | validation: 0.09841525652192015]
	TIME [epoch: 36.7 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10414805169374691		[learning rate: 0.0012567]
	Learning Rate: 0.0012567
	LOSS [training: 0.10414805169374691 | validation: 0.09916211808530219]
	TIME [epoch: 36.7 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1189683890051065		[learning rate: 0.0012517]
	Learning Rate: 0.0012517
	LOSS [training: 0.1189683890051065 | validation: 0.10008592320233714]
	TIME [epoch: 36.7 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12350196295193566		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 0.12350196295193566 | validation: 0.09096084456469251]
	TIME [epoch: 36.7 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11003900440770509		[learning rate: 0.0012418]
	Learning Rate: 0.00124176
	LOSS [training: 0.11003900440770509 | validation: 0.08803723077425711]
	TIME [epoch: 36.7 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12028501228861484		[learning rate: 0.0012368]
	Learning Rate: 0.00123682
	LOSS [training: 0.12028501228861484 | validation: 0.09780520210902913]
	TIME [epoch: 36.7 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1115513052056108		[learning rate: 0.0012319]
	Learning Rate: 0.0012319
	LOSS [training: 0.1115513052056108 | validation: 0.09767746050650294]
	TIME [epoch: 36.7 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11147595813501295		[learning rate: 0.001227]
	Learning Rate: 0.001227
	LOSS [training: 0.11147595813501295 | validation: 0.09364052911937219]
	TIME [epoch: 36.7 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12433360282456309		[learning rate: 0.0012221]
	Learning Rate: 0.00122212
	LOSS [training: 0.12433360282456309 | validation: 0.09763637700051042]
	TIME [epoch: 36.7 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1150517082651567		[learning rate: 0.0012173]
	Learning Rate: 0.00121726
	LOSS [training: 0.1150517082651567 | validation: 0.1000398573741911]
	TIME [epoch: 36.7 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11123486817700155		[learning rate: 0.0012124]
	Learning Rate: 0.00121242
	LOSS [training: 0.11123486817700155 | validation: 0.09633060189837823]
	TIME [epoch: 36.7 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11214879939501765		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 0.11214879939501765 | validation: 0.09195662587010636]
	TIME [epoch: 36.7 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10595595905508907		[learning rate: 0.0012028]
	Learning Rate: 0.0012028
	LOSS [training: 0.10595595905508907 | validation: 0.0928416340931942]
	TIME [epoch: 36.7 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11227240751728153		[learning rate: 0.001198]
	Learning Rate: 0.00119801
	LOSS [training: 0.11227240751728153 | validation: 0.09706742180448893]
	TIME [epoch: 36.7 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11179905545190769		[learning rate: 0.0011932]
	Learning Rate: 0.00119325
	LOSS [training: 0.11179905545190769 | validation: 0.10000226792745756]
	TIME [epoch: 36.7 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11221451507345098		[learning rate: 0.0011885]
	Learning Rate: 0.0011885
	LOSS [training: 0.11221451507345098 | validation: 0.10462310595957942]
	TIME [epoch: 36.7 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12625157354807046		[learning rate: 0.0011838]
	Learning Rate: 0.00118378
	LOSS [training: 0.12625157354807046 | validation: 0.09217443319860971]
	TIME [epoch: 36.7 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10784952614924687		[learning rate: 0.0011791]
	Learning Rate: 0.00117907
	LOSS [training: 0.10784952614924687 | validation: 0.10016904721242781]
	TIME [epoch: 36.7 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13070329711505405		[learning rate: 0.0011744]
	Learning Rate: 0.00117438
	LOSS [training: 0.13070329711505405 | validation: 0.08940823060355485]
	TIME [epoch: 36.7 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11744605748650458		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 0.11744605748650458 | validation: 0.10053399051838349]
	TIME [epoch: 36.7 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1211171527447685		[learning rate: 0.0011651]
	Learning Rate: 0.00116505
	LOSS [training: 0.1211171527447685 | validation: 0.09715757540555067]
	TIME [epoch: 36.7 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10740420307891316		[learning rate: 0.0011604]
	Learning Rate: 0.00116042
	LOSS [training: 0.10740420307891316 | validation: 0.0940673501927847]
	TIME [epoch: 36.7 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11525810054034608		[learning rate: 0.0011558]
	Learning Rate: 0.00115581
	LOSS [training: 0.11525810054034608 | validation: 0.09251241481203952]
	TIME [epoch: 36.7 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11338920590701636		[learning rate: 0.0011512]
	Learning Rate: 0.00115121
	LOSS [training: 0.11338920590701636 | validation: 0.09598721084295461]
	TIME [epoch: 36.7 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10658381932735678		[learning rate: 0.0011466]
	Learning Rate: 0.00114663
	LOSS [training: 0.10658381932735678 | validation: 0.09225942752841225]
	TIME [epoch: 36.7 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1206543354383624		[learning rate: 0.0011421]
	Learning Rate: 0.00114207
	LOSS [training: 0.1206543354383624 | validation: 0.09383433448680847]
	TIME [epoch: 36.7 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11056353585696577		[learning rate: 0.0011375]
	Learning Rate: 0.00113753
	LOSS [training: 0.11056353585696577 | validation: 0.0913934989953333]
	TIME [epoch: 36.7 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11177578884894841		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.11177578884894841 | validation: 0.09255112656981869]
	TIME [epoch: 36.6 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11286177632555934		[learning rate: 0.0011285]
	Learning Rate: 0.0011285
	LOSS [training: 0.11286177632555934 | validation: 0.09848646378101134]
	TIME [epoch: 36.7 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11865186350447339		[learning rate: 0.001124]
	Learning Rate: 0.00112401
	LOSS [training: 0.11865186350447339 | validation: 0.09066835299634485]
	TIME [epoch: 36.7 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10633304466531517		[learning rate: 0.0011195]
	Learning Rate: 0.00111954
	LOSS [training: 0.10633304466531517 | validation: 0.09651938911717933]
	TIME [epoch: 36.7 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12007998515180159		[learning rate: 0.0011151]
	Learning Rate: 0.00111508
	LOSS [training: 0.12007998515180159 | validation: 0.09532572830900699]
	TIME [epoch: 36.7 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1262321905843737		[learning rate: 0.0011106]
	Learning Rate: 0.00111065
	LOSS [training: 0.1262321905843737 | validation: 0.09251474299233202]
	TIME [epoch: 36.8 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11366023000192325		[learning rate: 0.0011062]
	Learning Rate: 0.00110623
	LOSS [training: 0.11366023000192325 | validation: 0.0964892438443065]
	TIME [epoch: 36.7 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1089440981213336		[learning rate: 0.0011018]
	Learning Rate: 0.00110183
	LOSS [training: 0.1089440981213336 | validation: 0.09622773375146605]
	TIME [epoch: 36.7 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1095952076124617		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 0.1095952076124617 | validation: 0.09094998448354324]
	TIME [epoch: 36.7 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11583821882271857		[learning rate: 0.0010931]
	Learning Rate: 0.00109309
	LOSS [training: 0.11583821882271857 | validation: 0.09372947598004576]
	TIME [epoch: 36.7 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11348099593196898		[learning rate: 0.0010887]
	Learning Rate: 0.00108874
	LOSS [training: 0.11348099593196898 | validation: 0.0877299201822505]
	TIME [epoch: 36.7 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11493526947916775		[learning rate: 0.0010844]
	Learning Rate: 0.00108441
	LOSS [training: 0.11493526947916775 | validation: 0.09562019857096346]
	TIME [epoch: 36.7 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11646051594518005		[learning rate: 0.0010801]
	Learning Rate: 0.00108009
	LOSS [training: 0.11646051594518005 | validation: 0.0956246201580001]
	TIME [epoch: 36.7 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11237493836293513		[learning rate: 0.0010758]
	Learning Rate: 0.0010758
	LOSS [training: 0.11237493836293513 | validation: 0.09290482659515278]
	TIME [epoch: 36.7 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11344818440373672		[learning rate: 0.0010715]
	Learning Rate: 0.00107152
	LOSS [training: 0.11344818440373672 | validation: 0.09222694815703425]
	TIME [epoch: 36.7 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11773019603987461		[learning rate: 0.0010673]
	Learning Rate: 0.00106726
	LOSS [training: 0.11773019603987461 | validation: 0.09962063412277243]
	TIME [epoch: 36.7 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10244148150447696		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 0.10244148150447696 | validation: 0.09110008620313736]
	TIME [epoch: 36.7 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1111687891259968		[learning rate: 0.0010588]
	Learning Rate: 0.00105878
	LOSS [training: 0.1111687891259968 | validation: 0.09537324041252175]
	TIME [epoch: 36.7 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1074689774515791		[learning rate: 0.0010546]
	Learning Rate: 0.00105457
	LOSS [training: 0.1074689774515791 | validation: 0.0881259031833207]
	TIME [epoch: 36.8 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11064375944579327		[learning rate: 0.0010504]
	Learning Rate: 0.00105038
	LOSS [training: 0.11064375944579327 | validation: 0.09315119447844264]
	TIME [epoch: 36.7 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10973774077560121		[learning rate: 0.0010462]
	Learning Rate: 0.0010462
	LOSS [training: 0.10973774077560121 | validation: 0.09518152053171015]
	TIME [epoch: 36.7 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10861374080722541		[learning rate: 0.001042]
	Learning Rate: 0.00104204
	LOSS [training: 0.10861374080722541 | validation: 0.08865446449875039]
	TIME [epoch: 36.8 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11711922196559559		[learning rate: 0.0010379]
	Learning Rate: 0.0010379
	LOSS [training: 0.11711922196559559 | validation: 0.09499132756727147]
	TIME [epoch: 36.7 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1155946010475984		[learning rate: 0.0010338]
	Learning Rate: 0.00103377
	LOSS [training: 0.1155946010475984 | validation: 0.09285886155355375]
	TIME [epoch: 36.7 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12070600116575562		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 0.12070600116575562 | validation: 0.09496859716051995]
	TIME [epoch: 36.8 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10870252727783565		[learning rate: 0.0010256]
	Learning Rate: 0.00102556
	LOSS [training: 0.10870252727783565 | validation: 0.09875715088767403]
	TIME [epoch: 36.7 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10986055945138036		[learning rate: 0.0010215]
	Learning Rate: 0.00102148
	LOSS [training: 0.10986055945138036 | validation: 0.0986895880170672]
	TIME [epoch: 36.8 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11181130027956865		[learning rate: 0.0010174]
	Learning Rate: 0.00101742
	LOSS [training: 0.11181130027956865 | validation: 0.0922473101085632]
	TIME [epoch: 36.8 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11246829300448846		[learning rate: 0.0010134]
	Learning Rate: 0.00101337
	LOSS [training: 0.11246829300448846 | validation: 0.094709082271298]
	TIME [epoch: 36.7 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12289167137775049		[learning rate: 0.0010093]
	Learning Rate: 0.00100934
	LOSS [training: 0.12289167137775049 | validation: 0.09677700899282274]
	TIME [epoch: 36.7 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10541409006903867		[learning rate: 0.0010053]
	Learning Rate: 0.00100533
	LOSS [training: 0.10541409006903867 | validation: 0.09677859500191219]
	TIME [epoch: 36.7 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11231722395352163		[learning rate: 0.0010013]
	Learning Rate: 0.00100133
	LOSS [training: 0.11231722395352163 | validation: 0.0939477297619787]
	TIME [epoch: 36.7 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11433887184817748		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 0.11433887184817748 | validation: 0.10132581703217924]
	TIME [epoch: 36.7 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11976645685382185		[learning rate: 0.00099338]
	Learning Rate: 0.00099338
	LOSS [training: 0.11976645685382185 | validation: 0.09982936630012451]
	TIME [epoch: 36.7 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1128022395767469		[learning rate: 0.00098943]
	Learning Rate: 0.000989429
	LOSS [training: 0.1128022395767469 | validation: 0.09559729345973667]
	TIME [epoch: 36.7 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11263477009434864		[learning rate: 0.00098549]
	Learning Rate: 0.000985494
	LOSS [training: 0.11263477009434864 | validation: 0.09705615114314307]
	TIME [epoch: 36.7 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1079211505488675		[learning rate: 0.00098157]
	Learning Rate: 0.000981574
	LOSS [training: 0.1079211505488675 | validation: 0.09427825028791478]
	TIME [epoch: 36.7 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11770707772629871		[learning rate: 0.00097767]
	Learning Rate: 0.00097767
	LOSS [training: 0.11770707772629871 | validation: 0.09476453896559493]
	TIME [epoch: 36.7 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.118046437940463		[learning rate: 0.00097378]
	Learning Rate: 0.000973782
	LOSS [training: 0.118046437940463 | validation: 0.10496238490517576]
	TIME [epoch: 36.7 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11136510386876747		[learning rate: 0.00096991]
	Learning Rate: 0.000969909
	LOSS [training: 0.11136510386876747 | validation: 0.09913461366301454]
	TIME [epoch: 36.7 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1255967813666181		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.1255967813666181 | validation: 0.09598077058268126]
	TIME [epoch: 36.7 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1096034315970113		[learning rate: 0.00096221]
	Learning Rate: 0.000962209
	LOSS [training: 0.1096034315970113 | validation: 0.09507819059504359]
	TIME [epoch: 36.7 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10888272434903545		[learning rate: 0.00095838]
	Learning Rate: 0.000958382
	LOSS [training: 0.10888272434903545 | validation: 0.09001839271212894]
	TIME [epoch: 36.7 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11852399321970856		[learning rate: 0.00095457]
	Learning Rate: 0.00095457
	LOSS [training: 0.11852399321970856 | validation: 0.09467392601122744]
	TIME [epoch: 36.7 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12029167711284061		[learning rate: 0.00095077]
	Learning Rate: 0.000950773
	LOSS [training: 0.12029167711284061 | validation: 0.09390332936772113]
	TIME [epoch: 36.7 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1154300943873692		[learning rate: 0.00094699]
	Learning Rate: 0.000946992
	LOSS [training: 0.1154300943873692 | validation: 0.09404812453137341]
	TIME [epoch: 36.7 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11427143776626619		[learning rate: 0.00094323]
	Learning Rate: 0.000943225
	LOSS [training: 0.11427143776626619 | validation: 0.09490688872333544]
	TIME [epoch: 36.7 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1085630048966887		[learning rate: 0.00093947]
	Learning Rate: 0.000939474
	LOSS [training: 0.1085630048966887 | validation: 0.10080912708172178]
	TIME [epoch: 36.7 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1225777803169353		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.1225777803169353 | validation: 0.09654359434003504]
	TIME [epoch: 36.7 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10678944914645386		[learning rate: 0.00093202]
	Learning Rate: 0.000932015
	LOSS [training: 0.10678944914645386 | validation: 0.09261789156600046]
	TIME [epoch: 36.7 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1159180446786659		[learning rate: 0.00092831]
	Learning Rate: 0.000928309
	LOSS [training: 0.1159180446786659 | validation: 0.09036610462883138]
	TIME [epoch: 36.7 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10722849931235405		[learning rate: 0.00092462]
	Learning Rate: 0.000924616
	LOSS [training: 0.10722849931235405 | validation: 0.09661299401949083]
	TIME [epoch: 36.7 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11246209944156778		[learning rate: 0.00092094]
	Learning Rate: 0.000920939
	LOSS [training: 0.11246209944156778 | validation: 0.09245036684165944]
	TIME [epoch: 36.7 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11289035724048589		[learning rate: 0.00091728]
	Learning Rate: 0.000917276
	LOSS [training: 0.11289035724048589 | validation: 0.09891039293469568]
	TIME [epoch: 36.7 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10661183844163488		[learning rate: 0.00091363]
	Learning Rate: 0.000913628
	LOSS [training: 0.10661183844163488 | validation: 0.0973986869053627]
	TIME [epoch: 36.7 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10775444133097317		[learning rate: 0.00090999]
	Learning Rate: 0.000909994
	LOSS [training: 0.10775444133097317 | validation: 0.09824111809299743]
	TIME [epoch: 36.7 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11873932204558105		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.11873932204558105 | validation: 0.09767577224167082]
	TIME [epoch: 36.7 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11756773835727014		[learning rate: 0.00090277]
	Learning Rate: 0.00090277
	LOSS [training: 0.11756773835727014 | validation: 0.09637302854741639]
	TIME [epoch: 36.7 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10995230371335198		[learning rate: 0.00089918]
	Learning Rate: 0.000899179
	LOSS [training: 0.10995230371335198 | validation: 0.09010724514711745]
	TIME [epoch: 36.7 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11375963013624325		[learning rate: 0.0008956]
	Learning Rate: 0.000895603
	LOSS [training: 0.11375963013624325 | validation: 0.09018979766630468]
	TIME [epoch: 36.7 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11462278801363973		[learning rate: 0.00089204]
	Learning Rate: 0.000892041
	LOSS [training: 0.11462278801363973 | validation: 0.09542163989364308]
	TIME [epoch: 36.7 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10868396928022796		[learning rate: 0.00088849]
	Learning Rate: 0.000888493
	LOSS [training: 0.10868396928022796 | validation: 0.1010825469898254]
	TIME [epoch: 36.7 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11212834279313882		[learning rate: 0.00088496]
	Learning Rate: 0.000884959
	LOSS [training: 0.11212834279313882 | validation: 0.09828836032369172]
	TIME [epoch: 36.6 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11178942709611192		[learning rate: 0.00088144]
	Learning Rate: 0.000881439
	LOSS [training: 0.11178942709611192 | validation: 0.10195799761383058]
	TIME [epoch: 36.7 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10910338832552319		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 0.10910338832552319 | validation: 0.096178099522752]
	TIME [epoch: 36.7 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11292927569236721		[learning rate: 0.00087444]
	Learning Rate: 0.000874441
	LOSS [training: 0.11292927569236721 | validation: 0.09956706496615063]
	TIME [epoch: 36.7 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11132438868367094		[learning rate: 0.00087096]
	Learning Rate: 0.000870964
	LOSS [training: 0.11132438868367094 | validation: 0.09291345088870663]
	TIME [epoch: 36.7 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11070221282727356		[learning rate: 0.0008675]
	Learning Rate: 0.0008675
	LOSS [training: 0.11070221282727356 | validation: 0.09287018466700837]
	TIME [epoch: 36.7 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10704688942545487		[learning rate: 0.00086405]
	Learning Rate: 0.000864049
	LOSS [training: 0.10704688942545487 | validation: 0.09424820856011626]
	TIME [epoch: 36.7 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11237143715254512		[learning rate: 0.00086061]
	Learning Rate: 0.000860613
	LOSS [training: 0.11237143715254512 | validation: 0.09595286381660817]
	TIME [epoch: 36.7 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11255547039427267		[learning rate: 0.00085719]
	Learning Rate: 0.00085719
	LOSS [training: 0.11255547039427267 | validation: 0.08730577230759072]
	TIME [epoch: 36.7 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11114528943795518		[learning rate: 0.00085378]
	Learning Rate: 0.00085378
	LOSS [training: 0.11114528943795518 | validation: 0.09614450090831991]
	TIME [epoch: 36.7 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1125530320204775		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 0.1125530320204775 | validation: 0.09511511637260694]
	TIME [epoch: 36.7 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10980004230776483		[learning rate: 0.000847]
	Learning Rate: 0.000847002
	LOSS [training: 0.10980004230776483 | validation: 0.09270676858832624]
	TIME [epoch: 36.7 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1129162295532215		[learning rate: 0.00084363]
	Learning Rate: 0.000843634
	LOSS [training: 0.1129162295532215 | validation: 0.09464517056556072]
	TIME [epoch: 36.7 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10598889826979074		[learning rate: 0.00084028]
	Learning Rate: 0.000840278
	LOSS [training: 0.10598889826979074 | validation: 0.09326990195125688]
	TIME [epoch: 36.7 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11415545007128063		[learning rate: 0.00083694]
	Learning Rate: 0.000836936
	LOSS [training: 0.11415545007128063 | validation: 0.09621411016415546]
	TIME [epoch: 36.6 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11100474785154371		[learning rate: 0.00083361]
	Learning Rate: 0.000833608
	LOSS [training: 0.11100474785154371 | validation: 0.10223474929784337]
	TIME [epoch: 36.6 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11679143127179421		[learning rate: 0.00083029]
	Learning Rate: 0.000830292
	LOSS [training: 0.11679143127179421 | validation: 0.09842348023673228]
	TIME [epoch: 36.7 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1111565089239292		[learning rate: 0.00082699]
	Learning Rate: 0.00082699
	LOSS [training: 0.1111565089239292 | validation: 0.09506640130856608]
	TIME [epoch: 36.7 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.114511709362114		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.114511709362114 | validation: 0.09676071395832274]
	TIME [epoch: 36.6 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1142824325318246		[learning rate: 0.00082042]
	Learning Rate: 0.000820424
	LOSS [training: 0.1142824325318246 | validation: 0.09136612138141323]
	TIME [epoch: 36.6 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11252578101161825		[learning rate: 0.00081716]
	Learning Rate: 0.000817161
	LOSS [training: 0.11252578101161825 | validation: 0.08982053890158972]
	TIME [epoch: 36.7 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11663306748184372		[learning rate: 0.00081391]
	Learning Rate: 0.000813911
	LOSS [training: 0.11663306748184372 | validation: 0.09777819410779474]
	TIME [epoch: 36.7 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11307432201972725		[learning rate: 0.00081067]
	Learning Rate: 0.000810674
	LOSS [training: 0.11307432201972725 | validation: 0.09386771547484533]
	TIME [epoch: 36.7 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11509645238770307		[learning rate: 0.00080745]
	Learning Rate: 0.00080745
	LOSS [training: 0.11509645238770307 | validation: 0.08985337655527541]
	TIME [epoch: 36.6 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10882232353683928		[learning rate: 0.00080424]
	Learning Rate: 0.000804238
	LOSS [training: 0.10882232353683928 | validation: 0.09358813397550486]
	TIME [epoch: 36.6 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11678298297111425		[learning rate: 0.00080104]
	Learning Rate: 0.000801039
	LOSS [training: 0.11678298297111425 | validation: 0.089669813182477]
	TIME [epoch: 36.6 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12547869348630222		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 0.12547869348630222 | validation: 0.09746652020360975]
	TIME [epoch: 36.6 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11354656545192746		[learning rate: 0.00079468]
	Learning Rate: 0.00079468
	LOSS [training: 0.11354656545192746 | validation: 0.09886041834834962]
	TIME [epoch: 36.7 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12140293626884574		[learning rate: 0.00079152]
	Learning Rate: 0.000791519
	LOSS [training: 0.12140293626884574 | validation: 0.10279640410541672]
	TIME [epoch: 36.7 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11344507419055204		[learning rate: 0.00078837]
	Learning Rate: 0.000788371
	LOSS [training: 0.11344507419055204 | validation: 0.09597062878714037]
	TIME [epoch: 36.7 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10898245688879149		[learning rate: 0.00078524]
	Learning Rate: 0.000785236
	LOSS [training: 0.10898245688879149 | validation: 0.08766116244592762]
	TIME [epoch: 36.7 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10116497070458191		[learning rate: 0.00078211]
	Learning Rate: 0.000782113
	LOSS [training: 0.10116497070458191 | validation: 0.09071450440483585]
	TIME [epoch: 36.7 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10833263512320682		[learning rate: 0.000779]
	Learning Rate: 0.000779002
	LOSS [training: 0.10833263512320682 | validation: 0.09734034035426142]
	TIME [epoch: 36.6 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11032586773110285		[learning rate: 0.0007759]
	Learning Rate: 0.000775904
	LOSS [training: 0.11032586773110285 | validation: 0.09074743328314627]
	TIME [epoch: 36.7 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11429675713075754		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 0.11429675713075754 | validation: 0.09781395970943205]
	TIME [epoch: 36.7 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10494226192483237		[learning rate: 0.00076974]
	Learning Rate: 0.000769744
	LOSS [training: 0.10494226192483237 | validation: 0.09113188024477574]
	TIME [epoch: 36.7 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11181522321581344		[learning rate: 0.00076668]
	Learning Rate: 0.000766682
	LOSS [training: 0.11181522321581344 | validation: 0.09257582063309003]
	TIME [epoch: 36.7 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10365107441170127		[learning rate: 0.00076363]
	Learning Rate: 0.000763633
	LOSS [training: 0.10365107441170127 | validation: 0.09450591512195047]
	TIME [epoch: 36.7 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11984555243642886		[learning rate: 0.0007606]
	Learning Rate: 0.000760596
	LOSS [training: 0.11984555243642886 | validation: 0.09481060356786034]
	TIME [epoch: 36.6 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11167161923126202		[learning rate: 0.00075757]
	Learning Rate: 0.000757571
	LOSS [training: 0.11167161923126202 | validation: 0.09802863193033878]
	TIME [epoch: 36.7 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10292525170967773		[learning rate: 0.00075456]
	Learning Rate: 0.000754557
	LOSS [training: 0.10292525170967773 | validation: 0.09774523217981154]
	TIME [epoch: 36.6 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11057796260543556		[learning rate: 0.00075156]
	Learning Rate: 0.000751556
	LOSS [training: 0.11057796260543556 | validation: 0.0920514986418399]
	TIME [epoch: 36.7 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10792692644218843		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 0.10792692644218843 | validation: 0.09824114574348042]
	TIME [epoch: 36.7 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10877517205100405		[learning rate: 0.00074559]
	Learning Rate: 0.00074559
	LOSS [training: 0.10877517205100405 | validation: 0.09440353439458707]
	TIME [epoch: 36.7 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10732135913176488		[learning rate: 0.00074262]
	Learning Rate: 0.000742624
	LOSS [training: 0.10732135913176488 | validation: 0.09276046827550571]
	TIME [epoch: 36.6 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10902271185735564		[learning rate: 0.00073967]
	Learning Rate: 0.000739671
	LOSS [training: 0.10902271185735564 | validation: 0.10030941712822558]
	TIME [epoch: 36.7 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11670243085576197		[learning rate: 0.00073673]
	Learning Rate: 0.000736729
	LOSS [training: 0.11670243085576197 | validation: 0.09618416430109061]
	TIME [epoch: 36.7 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11092120744141143		[learning rate: 0.0007338]
	Learning Rate: 0.000733799
	LOSS [training: 0.11092120744141143 | validation: 0.08631241333312464]
	TIME [epoch: 36.6 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v1_20240624_133245/states/model_facs_dec1b_2dpca_v1_700.pth
	Model improved!!!
EPOCH 701/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10824501811213463		[learning rate: 0.00073088]
	Learning Rate: 0.00073088
	LOSS [training: 0.10824501811213463 | validation: 0.09749891706540488]
	TIME [epoch: 36.7 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10866842734749646		[learning rate: 0.00072797]
	Learning Rate: 0.000727973
	LOSS [training: 0.10866842734749646 | validation: 0.10016762033481134]
	TIME [epoch: 36.7 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11445956295749005		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 0.11445956295749005 | validation: 0.09659078149063496]
	TIME [epoch: 36.7 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11081340919637844		[learning rate: 0.00072219]
	Learning Rate: 0.000722194
	LOSS [training: 0.11081340919637844 | validation: 0.09438821352320988]
	TIME [epoch: 36.7 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12048196635309488		[learning rate: 0.00071932]
	Learning Rate: 0.000719322
	LOSS [training: 0.12048196635309488 | validation: 0.09383135839255378]
	TIME [epoch: 36.7 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11421372254225953		[learning rate: 0.00071646]
	Learning Rate: 0.000716461
	LOSS [training: 0.11421372254225953 | validation: 0.09605795321856392]
	TIME [epoch: 36.7 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1183727255747486		[learning rate: 0.00071361]
	Learning Rate: 0.000713611
	LOSS [training: 0.1183727255747486 | validation: 0.08821535074282254]
	TIME [epoch: 36.7 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10639115620181717		[learning rate: 0.00071077]
	Learning Rate: 0.000710773
	LOSS [training: 0.10639115620181717 | validation: 0.09379727907990405]
	TIME [epoch: 36.7 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11153606792086733		[learning rate: 0.00070795]
	Learning Rate: 0.000707946
	LOSS [training: 0.11153606792086733 | validation: 0.09643317141020781]
	TIME [epoch: 36.7 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1100738776480467		[learning rate: 0.00070513]
	Learning Rate: 0.00070513
	LOSS [training: 0.1100738776480467 | validation: 0.09852116031132854]
	TIME [epoch: 36.7 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10921558451369845		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.10921558451369845 | validation: 0.09787705470994844]
	TIME [epoch: 36.7 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11016472003367642		[learning rate: 0.00069953]
	Learning Rate: 0.000699532
	LOSS [training: 0.11016472003367642 | validation: 0.09018451016847294]
	TIME [epoch: 36.7 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11014602759674735		[learning rate: 0.00069675]
	Learning Rate: 0.00069675
	LOSS [training: 0.11014602759674735 | validation: 0.1001896080548957]
	TIME [epoch: 36.7 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1120696321808873		[learning rate: 0.00069398]
	Learning Rate: 0.000693979
	LOSS [training: 0.1120696321808873 | validation: 0.10362166894558081]
	TIME [epoch: 36.7 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11115213696110088		[learning rate: 0.00069122]
	Learning Rate: 0.000691219
	LOSS [training: 0.11115213696110088 | validation: 0.09374262357824052]
	TIME [epoch: 36.7 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10859701618649079		[learning rate: 0.00068847]
	Learning Rate: 0.000688469
	LOSS [training: 0.10859701618649079 | validation: 0.09889559257714775]
	TIME [epoch: 36.7 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11269923464460832		[learning rate: 0.00068573]
	Learning Rate: 0.000685731
	LOSS [training: 0.11269923464460832 | validation: 0.09397464107848305]
	TIME [epoch: 36.7 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10837169083436704		[learning rate: 0.000683]
	Learning Rate: 0.000683004
	LOSS [training: 0.10837169083436704 | validation: 0.09398351349897396]
	TIME [epoch: 36.7 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.118041567608346		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 0.118041567608346 | validation: 0.0935393946235833]
	TIME [epoch: 36.7 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12118584278267969		[learning rate: 0.00067758]
	Learning Rate: 0.000677582
	LOSS [training: 0.12118584278267969 | validation: 0.09513397608836785]
	TIME [epoch: 36.7 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11273266525401035		[learning rate: 0.00067489]
	Learning Rate: 0.000674887
	LOSS [training: 0.11273266525401035 | validation: 0.09799869191433086]
	TIME [epoch: 36.6 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10952530663070312		[learning rate: 0.0006722]
	Learning Rate: 0.000672202
	LOSS [training: 0.10952530663070312 | validation: 0.09775239580486676]
	TIME [epoch: 36.6 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12481953261349611		[learning rate: 0.00066953]
	Learning Rate: 0.000669529
	LOSS [training: 0.12481953261349611 | validation: 0.09952808598499083]
	TIME [epoch: 36.7 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10929960978555787		[learning rate: 0.00066687]
	Learning Rate: 0.000666866
	LOSS [training: 0.10929960978555787 | validation: 0.09430856821456154]
	TIME [epoch: 36.6 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11472331585395601		[learning rate: 0.00066421]
	Learning Rate: 0.000664213
	LOSS [training: 0.11472331585395601 | validation: 0.09891784020117159]
	TIME [epoch: 36.7 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1191698738158981		[learning rate: 0.00066157]
	Learning Rate: 0.000661572
	LOSS [training: 0.1191698738158981 | validation: 0.0900581240627725]
	TIME [epoch: 36.7 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1116539734932848		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 0.1116539734932848 | validation: 0.09264701509022848]
	TIME [epoch: 36.7 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10773181264903914		[learning rate: 0.00065632]
	Learning Rate: 0.00065632
	LOSS [training: 0.10773181264903914 | validation: 0.10502944783100554]
	TIME [epoch: 36.7 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10701798590254054		[learning rate: 0.00065371]
	Learning Rate: 0.000653709
	LOSS [training: 0.10701798590254054 | validation: 0.0931392150618991]
	TIME [epoch: 36.7 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11466135512128789		[learning rate: 0.00065111]
	Learning Rate: 0.000651109
	LOSS [training: 0.11466135512128789 | validation: 0.09703732244832217]
	TIME [epoch: 36.6 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11196883147953006		[learning rate: 0.00064852]
	Learning Rate: 0.00064852
	LOSS [training: 0.11196883147953006 | validation: 0.09241884293608367]
	TIME [epoch: 36.7 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11392127636644885		[learning rate: 0.00064594]
	Learning Rate: 0.00064594
	LOSS [training: 0.11392127636644885 | validation: 0.09289678264325979]
	TIME [epoch: 36.7 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11215088627862195		[learning rate: 0.00064337]
	Learning Rate: 0.000643371
	LOSS [training: 0.11215088627862195 | validation: 0.1029242285348327]
	TIME [epoch: 36.7 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11156867292964358		[learning rate: 0.00064081]
	Learning Rate: 0.000640812
	LOSS [training: 0.11156867292964358 | validation: 0.09770025431212995]
	TIME [epoch: 36.6 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10581334791839402		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 0.10581334791839402 | validation: 0.09841396968354388]
	TIME [epoch: 36.7 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11132364635051942		[learning rate: 0.00063572]
	Learning Rate: 0.000635725
	LOSS [training: 0.11132364635051942 | validation: 0.09293031416969175]
	TIME [epoch: 36.6 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.109026481898244		[learning rate: 0.0006332]
	Learning Rate: 0.000633196
	LOSS [training: 0.109026481898244 | validation: 0.09118089193319164]
	TIME [epoch: 36.7 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11388990334709558		[learning rate: 0.00063068]
	Learning Rate: 0.000630678
	LOSS [training: 0.11388990334709558 | validation: 0.09707792297768725]
	TIME [epoch: 36.7 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11026353345319656		[learning rate: 0.00062817]
	Learning Rate: 0.00062817
	LOSS [training: 0.11026353345319656 | validation: 0.09249668369601416]
	TIME [epoch: 36.7 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11011034704405705		[learning rate: 0.00062567]
	Learning Rate: 0.000625671
	LOSS [training: 0.11011034704405705 | validation: 0.0944483864494304]
	TIME [epoch: 36.7 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11322778963005861		[learning rate: 0.00062318]
	Learning Rate: 0.000623183
	LOSS [training: 0.11322778963005861 | validation: 0.09314343483321826]
	TIME [epoch: 36.7 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11007125980189977		[learning rate: 0.0006207]
	Learning Rate: 0.000620704
	LOSS [training: 0.11007125980189977 | validation: 0.1003476450143945]
	TIME [epoch: 36.7 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12007536636799464		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 0.12007536636799464 | validation: 0.092637170522803]
	TIME [epoch: 36.7 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11191840584777572		[learning rate: 0.00061578]
	Learning Rate: 0.000615777
	LOSS [training: 0.11191840584777572 | validation: 0.09217302490987732]
	TIME [epoch: 36.7 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12042411293523357		[learning rate: 0.00061333]
	Learning Rate: 0.000613327
	LOSS [training: 0.12042411293523357 | validation: 0.0961813881182571]
	TIME [epoch: 36.7 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11393833917345694		[learning rate: 0.00061089]
	Learning Rate: 0.000610888
	LOSS [training: 0.11393833917345694 | validation: 0.09738977812136358]
	TIME [epoch: 36.7 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11103653848178865		[learning rate: 0.00060846]
	Learning Rate: 0.000608458
	LOSS [training: 0.11103653848178865 | validation: 0.09476317742422927]
	TIME [epoch: 36.6 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1097469403576519		[learning rate: 0.00060604]
	Learning Rate: 0.000606038
	LOSS [training: 0.1097469403576519 | validation: 0.09485556926657102]
	TIME [epoch: 36.7 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10930109286434297		[learning rate: 0.00060363]
	Learning Rate: 0.000603628
	LOSS [training: 0.10930109286434297 | validation: 0.09557451879164622]
	TIME [epoch: 36.7 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11617897196132468		[learning rate: 0.00060123]
	Learning Rate: 0.000601227
	LOSS [training: 0.11617897196132468 | validation: 0.09223738291654758]
	TIME [epoch: 36.6 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10773162146230919		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.10773162146230919 | validation: 0.0988840643986044]
	TIME [epoch: 36.6 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11391455010527392		[learning rate: 0.00059645]
	Learning Rate: 0.000596454
	LOSS [training: 0.11391455010527392 | validation: 0.09125978822394532]
	TIME [epoch: 36.6 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10776040648317599		[learning rate: 0.00059408]
	Learning Rate: 0.000594082
	LOSS [training: 0.10776040648317599 | validation: 0.09746126389243392]
	TIME [epoch: 36.7 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11691969178191834		[learning rate: 0.00059172]
	Learning Rate: 0.000591719
	LOSS [training: 0.11691969178191834 | validation: 0.0935341253618921]
	TIME [epoch: 36.7 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1065133241763913		[learning rate: 0.00058937]
	Learning Rate: 0.000589365
	LOSS [training: 0.1065133241763913 | validation: 0.09418142949189798]
	TIME [epoch: 36.6 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11766523431109926		[learning rate: 0.00058702]
	Learning Rate: 0.000587021
	LOSS [training: 0.11766523431109926 | validation: 0.09904626850935648]
	TIME [epoch: 36.6 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10569648429828638		[learning rate: 0.00058469]
	Learning Rate: 0.000584687
	LOSS [training: 0.10569648429828638 | validation: 0.0933331084241813]
	TIME [epoch: 36.6 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11142033858059791		[learning rate: 0.00058236]
	Learning Rate: 0.000582361
	LOSS [training: 0.11142033858059791 | validation: 0.09953270881877126]
	TIME [epoch: 36.7 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1084801289560603		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 0.1084801289560603 | validation: 0.09379025229631319]
	TIME [epoch: 36.7 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10629569024451663		[learning rate: 0.00057774]
	Learning Rate: 0.000577738
	LOSS [training: 0.10629569024451663 | validation: 0.09624528792629874]
	TIME [epoch: 36.6 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11412637280239107		[learning rate: 0.00057544]
	Learning Rate: 0.00057544
	LOSS [training: 0.11412637280239107 | validation: 0.09761474870552274]
	TIME [epoch: 36.7 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11282599824201298		[learning rate: 0.00057315]
	Learning Rate: 0.000573151
	LOSS [training: 0.11282599824201298 | validation: 0.09370228592813483]
	TIME [epoch: 36.7 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11269069669310751		[learning rate: 0.00057087]
	Learning Rate: 0.000570872
	LOSS [training: 0.11269069669310751 | validation: 0.09535805423408168]
	TIME [epoch: 36.7 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1096705610917965		[learning rate: 0.0005686]
	Learning Rate: 0.000568601
	LOSS [training: 0.1096705610917965 | validation: 0.09885712498812663]
	TIME [epoch: 36.7 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12008888591144481		[learning rate: 0.00056634]
	Learning Rate: 0.00056634
	LOSS [training: 0.12008888591144481 | validation: 0.08993095791221452]
	TIME [epoch: 36.7 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10547681341079568		[learning rate: 0.00056409]
	Learning Rate: 0.000564087
	LOSS [training: 0.10547681341079568 | validation: 0.09289969739378583]
	TIME [epoch: 36.7 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11229335943774392		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 0.11229335943774392 | validation: 0.09765602051671088]
	TIME [epoch: 36.7 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10779247658411949		[learning rate: 0.00055961]
	Learning Rate: 0.000559609
	LOSS [training: 0.10779247658411949 | validation: 0.09734983152650618]
	TIME [epoch: 36.7 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11614534492002651		[learning rate: 0.00055738]
	Learning Rate: 0.000557383
	LOSS [training: 0.11614534492002651 | validation: 0.0879602775655858]
	TIME [epoch: 36.7 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12620927572855248		[learning rate: 0.00055517]
	Learning Rate: 0.000555166
	LOSS [training: 0.12620927572855248 | validation: 0.09562813668159689]
	TIME [epoch: 36.7 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11230728552431454		[learning rate: 0.00055296]
	Learning Rate: 0.000552958
	LOSS [training: 0.11230728552431454 | validation: 0.09035495273286588]
	TIME [epoch: 36.7 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11248625461644192		[learning rate: 0.00055076]
	Learning Rate: 0.000550759
	LOSS [training: 0.11248625461644192 | validation: 0.10071157142688003]
	TIME [epoch: 36.7 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11131933536581179		[learning rate: 0.00054857]
	Learning Rate: 0.000548568
	LOSS [training: 0.11131933536581179 | validation: 0.09650907926794845]
	TIME [epoch: 36.7 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1194572941022356		[learning rate: 0.00054639]
	Learning Rate: 0.000546387
	LOSS [training: 0.1194572941022356 | validation: 0.08691297400736504]
	TIME [epoch: 36.7 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11012430069614314		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 0.11012430069614314 | validation: 0.09293180391371379]
	TIME [epoch: 36.7 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10318523488940236		[learning rate: 0.00054205]
	Learning Rate: 0.000542049
	LOSS [training: 0.10318523488940236 | validation: 0.09713619334539147]
	TIME [epoch: 36.7 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10909257952576286		[learning rate: 0.00053989]
	Learning Rate: 0.000539893
	LOSS [training: 0.10909257952576286 | validation: 0.09148816424655934]
	TIME [epoch: 36.7 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11287138939298548		[learning rate: 0.00053775]
	Learning Rate: 0.000537746
	LOSS [training: 0.11287138939298548 | validation: 0.09685259742513212]
	TIME [epoch: 36.7 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11262302665855535		[learning rate: 0.00053561]
	Learning Rate: 0.000535607
	LOSS [training: 0.11262302665855535 | validation: 0.09440439182786334]
	TIME [epoch: 36.7 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10816689828773447		[learning rate: 0.00053348]
	Learning Rate: 0.000533477
	LOSS [training: 0.10816689828773447 | validation: 0.08838494994754638]
	TIME [epoch: 36.7 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11505868541497094		[learning rate: 0.00053135]
	Learning Rate: 0.000531355
	LOSS [training: 0.11505868541497094 | validation: 0.09759987155663993]
	TIME [epoch: 36.7 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11752676932573057		[learning rate: 0.00052924]
	Learning Rate: 0.000529241
	LOSS [training: 0.11752676932573057 | validation: 0.0951381319666972]
	TIME [epoch: 36.7 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11083941837547535		[learning rate: 0.00052714]
	Learning Rate: 0.000527136
	LOSS [training: 0.11083941837547535 | validation: 0.10229255375049688]
	TIME [epoch: 36.7 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1205101900498221		[learning rate: 0.00052504]
	Learning Rate: 0.00052504
	LOSS [training: 0.1205101900498221 | validation: 0.08957017726621871]
	TIME [epoch: 36.7 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11122242459384046		[learning rate: 0.00052295]
	Learning Rate: 0.000522952
	LOSS [training: 0.11122242459384046 | validation: 0.09139465852508108]
	TIME [epoch: 36.7 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11436161855304884		[learning rate: 0.00052087]
	Learning Rate: 0.000520872
	LOSS [training: 0.11436161855304884 | validation: 0.10007430549368768]
	TIME [epoch: 36.7 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10674010366059081		[learning rate: 0.0005188]
	Learning Rate: 0.0005188
	LOSS [training: 0.10674010366059081 | validation: 0.09577953975082132]
	TIME [epoch: 36.7 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11236107446614864		[learning rate: 0.00051674]
	Learning Rate: 0.000516737
	LOSS [training: 0.11236107446614864 | validation: 0.09040934595813468]
	TIME [epoch: 36.7 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12416068945717912		[learning rate: 0.00051468]
	Learning Rate: 0.000514681
	LOSS [training: 0.12416068945717912 | validation: 0.09890200153468989]
	TIME [epoch: 36.6 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12274420756706385		[learning rate: 0.00051263]
	Learning Rate: 0.000512634
	LOSS [training: 0.12274420756706385 | validation: 0.09085958701886857]
	TIME [epoch: 36.7 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11158271518766415		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 0.11158271518766415 | validation: 0.09128631107011506]
	TIME [epoch: 36.6 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1107140262154241		[learning rate: 0.00050856]
	Learning Rate: 0.000508565
	LOSS [training: 0.1107140262154241 | validation: 0.0994077242047362]
	TIME [epoch: 36.7 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12156536397118793		[learning rate: 0.00050654]
	Learning Rate: 0.000506542
	LOSS [training: 0.12156536397118793 | validation: 0.09577255221900041]
	TIME [epoch: 36.7 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11586883689841215		[learning rate: 0.00050453]
	Learning Rate: 0.000504527
	LOSS [training: 0.11586883689841215 | validation: 0.10015784144373283]
	TIME [epoch: 36.7 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12655985747816179		[learning rate: 0.00050252]
	Learning Rate: 0.000502521
	LOSS [training: 0.12655985747816179 | validation: 0.09672077767121486]
	TIME [epoch: 36.6 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11455698728268408		[learning rate: 0.00050052]
	Learning Rate: 0.000500522
	LOSS [training: 0.11455698728268408 | validation: 0.09258126889589394]
	TIME [epoch: 36.7 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10814178344280036		[learning rate: 0.00049853]
	Learning Rate: 0.000498531
	LOSS [training: 0.10814178344280036 | validation: 0.09882219522412654]
	TIME [epoch: 36.7 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10685595357453723		[learning rate: 0.00049655]
	Learning Rate: 0.000496548
	LOSS [training: 0.10685595357453723 | validation: 0.09514699825440692]
	TIME [epoch: 36.7 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11657046250563699		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 0.11657046250563699 | validation: 0.09022304302009208]
	TIME [epoch: 36.7 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10758991460349497		[learning rate: 0.00049261]
	Learning Rate: 0.000492606
	LOSS [training: 0.10758991460349497 | validation: 0.09827595946648575]
	TIME [epoch: 36.7 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11312424950811344		[learning rate: 0.00049065]
	Learning Rate: 0.000490647
	LOSS [training: 0.11312424950811344 | validation: 0.09813475280488708]
	TIME [epoch: 36.7 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10865965905277293		[learning rate: 0.0004887]
	Learning Rate: 0.000488696
	LOSS [training: 0.10865965905277293 | validation: 0.08948807939891965]
	TIME [epoch: 36.7 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11064635162429687		[learning rate: 0.00048675]
	Learning Rate: 0.000486752
	LOSS [training: 0.11064635162429687 | validation: 0.0972257408030118]
	TIME [epoch: 36.7 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11422392349192008		[learning rate: 0.00048482]
	Learning Rate: 0.000484816
	LOSS [training: 0.11422392349192008 | validation: 0.09773740236746602]
	TIME [epoch: 36.7 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10133427082432021		[learning rate: 0.00048289]
	Learning Rate: 0.000482888
	LOSS [training: 0.10133427082432021 | validation: 0.09433605850960683]
	TIME [epoch: 36.7 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10910230676535088		[learning rate: 0.00048097]
	Learning Rate: 0.000480967
	LOSS [training: 0.10910230676535088 | validation: 0.09620225399529558]
	TIME [epoch: 36.7 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12373982458122083		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 0.12373982458122083 | validation: 0.09343596103623301]
	TIME [epoch: 36.7 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10568304267574145		[learning rate: 0.00047715]
	Learning Rate: 0.000477149
	LOSS [training: 0.10568304267574145 | validation: 0.09855885795212978]
	TIME [epoch: 36.7 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1090103834470152		[learning rate: 0.00047525]
	Learning Rate: 0.000475251
	LOSS [training: 0.1090103834470152 | validation: 0.09561573615996535]
	TIME [epoch: 36.7 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11570397422893845		[learning rate: 0.00047336]
	Learning Rate: 0.000473361
	LOSS [training: 0.11570397422893845 | validation: 0.09363534099761557]
	TIME [epoch: 36.6 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11937231532250224		[learning rate: 0.00047148]
	Learning Rate: 0.000471478
	LOSS [training: 0.11937231532250224 | validation: 0.09145686161541236]
	TIME [epoch: 36.7 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11047659924673957		[learning rate: 0.0004696]
	Learning Rate: 0.000469603
	LOSS [training: 0.11047659924673957 | validation: 0.09996294174724416]
	TIME [epoch: 36.6 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12144931508625054		[learning rate: 0.00046774]
	Learning Rate: 0.000467735
	LOSS [training: 0.12144931508625054 | validation: 0.09672985100590772]
	TIME [epoch: 36.6 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11278235156048148		[learning rate: 0.00046587]
	Learning Rate: 0.000465875
	LOSS [training: 0.11278235156048148 | validation: 0.08881490385780712]
	TIME [epoch: 36.6 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10742307329631814		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 0.10742307329631814 | validation: 0.10038491298172905]
	TIME [epoch: 36.7 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10617583310417245		[learning rate: 0.00046218]
	Learning Rate: 0.000462176
	LOSS [training: 0.10617583310417245 | validation: 0.09408163521156321]
	TIME [epoch: 36.6 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11717115635675353		[learning rate: 0.00046034]
	Learning Rate: 0.000460338
	LOSS [training: 0.11717115635675353 | validation: 0.0968311301084959]
	TIME [epoch: 36.7 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11528929755018952		[learning rate: 0.00045851]
	Learning Rate: 0.000458507
	LOSS [training: 0.11528929755018952 | validation: 0.09945115939952237]
	TIME [epoch: 36.6 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10768361028782891		[learning rate: 0.00045668]
	Learning Rate: 0.000456684
	LOSS [training: 0.10768361028782891 | validation: 0.08827027251303385]
	TIME [epoch: 36.7 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11499586437461559		[learning rate: 0.00045487]
	Learning Rate: 0.000454867
	LOSS [training: 0.11499586437461559 | validation: 0.09596491891713577]
	TIME [epoch: 36.6 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11628121808648201		[learning rate: 0.00045306]
	Learning Rate: 0.000453058
	LOSS [training: 0.11628121808648201 | validation: 0.09640846287174941]
	TIME [epoch: 36.6 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11242728232537688		[learning rate: 0.00045126]
	Learning Rate: 0.000451256
	LOSS [training: 0.11242728232537688 | validation: 0.09039067263641878]
	TIME [epoch: 36.6 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10466861903697915		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 0.10466861903697915 | validation: 0.09364824871288475]
	TIME [epoch: 36.7 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10555029489623652		[learning rate: 0.00044767]
	Learning Rate: 0.000447674
	LOSS [training: 0.10555029489623652 | validation: 0.09875703032870477]
	TIME [epoch: 36.6 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11488728385665065		[learning rate: 0.00044589]
	Learning Rate: 0.000445893
	LOSS [training: 0.11488728385665065 | validation: 0.09255701943883661]
	TIME [epoch: 36.7 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11953079006282041		[learning rate: 0.00044412]
	Learning Rate: 0.00044412
	LOSS [training: 0.11953079006282041 | validation: 0.08997971474491609]
	TIME [epoch: 36.6 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10847288705004948		[learning rate: 0.00044235]
	Learning Rate: 0.000442353
	LOSS [training: 0.10847288705004948 | validation: 0.09702361707758207]
	TIME [epoch: 36.7 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10944601965442319		[learning rate: 0.00044059]
	Learning Rate: 0.000440594
	LOSS [training: 0.10944601965442319 | validation: 0.0927806308739871]
	TIME [epoch: 36.7 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11132136112467089		[learning rate: 0.00043884]
	Learning Rate: 0.000438842
	LOSS [training: 0.11132136112467089 | validation: 0.093472024180177]
	TIME [epoch: 36.7 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12152933961056421		[learning rate: 0.0004371]
	Learning Rate: 0.000437096
	LOSS [training: 0.12152933961056421 | validation: 0.08725432328970038]
	TIME [epoch: 36.6 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10865699098909205		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 0.10865699098909205 | validation: 0.08796496796973781]
	TIME [epoch: 36.7 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11028427207559649		[learning rate: 0.00043363]
	Learning Rate: 0.000433626
	LOSS [training: 0.11028427207559649 | validation: 0.09527063067678639]
	TIME [epoch: 36.6 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11630363459506693		[learning rate: 0.0004319]
	Learning Rate: 0.000431901
	LOSS [training: 0.11630363459506693 | validation: 0.09746980840935907]
	TIME [epoch: 36.6 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1144308902542021		[learning rate: 0.00043018]
	Learning Rate: 0.000430184
	LOSS [training: 0.1144308902542021 | validation: 0.0973545012909145]
	TIME [epoch: 36.6 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11313159306004719		[learning rate: 0.00042847]
	Learning Rate: 0.000428473
	LOSS [training: 0.11313159306004719 | validation: 0.09430403386237482]
	TIME [epoch: 36.7 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10491730126017237		[learning rate: 0.00042677]
	Learning Rate: 0.000426768
	LOSS [training: 0.10491730126017237 | validation: 0.09599071760298646]
	TIME [epoch: 36.6 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10753869520773496		[learning rate: 0.00042507]
	Learning Rate: 0.000425071
	LOSS [training: 0.10753869520773496 | validation: 0.09512513613451015]
	TIME [epoch: 36.7 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11339129522217534		[learning rate: 0.00042338]
	Learning Rate: 0.00042338
	LOSS [training: 0.11339129522217534 | validation: 0.09400800264661627]
	TIME [epoch: 36.6 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10684236399318366		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 0.10684236399318366 | validation: 0.09781832045970694]
	TIME [epoch: 37.2 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1090394954987486		[learning rate: 0.00042002]
	Learning Rate: 0.000420019
	LOSS [training: 0.1090394954987486 | validation: 0.09321416524919347]
	TIME [epoch: 36.7 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11899112797310989		[learning rate: 0.00041835]
	Learning Rate: 0.000418349
	LOSS [training: 0.11899112797310989 | validation: 0.08733434613846733]
	TIME [epoch: 36.6 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1098163259661111		[learning rate: 0.00041668]
	Learning Rate: 0.000416685
	LOSS [training: 0.1098163259661111 | validation: 0.09455331717727342]
	TIME [epoch: 36.6 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10935356962993421		[learning rate: 0.00041503]
	Learning Rate: 0.000415028
	LOSS [training: 0.10935356962993421 | validation: 0.0987319531833735]
	TIME [epoch: 36.7 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11208943472973631		[learning rate: 0.00041338]
	Learning Rate: 0.000413377
	LOSS [training: 0.11208943472973631 | validation: 0.0958930371435113]
	TIME [epoch: 36.6 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10760507509625628		[learning rate: 0.00041173]
	Learning Rate: 0.000411733
	LOSS [training: 0.10760507509625628 | validation: 0.09008562038206125]
	TIME [epoch: 36.7 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11952477600839423		[learning rate: 0.0004101]
	Learning Rate: 0.000410095
	LOSS [training: 0.11952477600839423 | validation: 0.099454787935603]
	TIME [epoch: 36.6 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1066550158400767		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 0.1066550158400767 | validation: 0.09777257002213782]
	TIME [epoch: 36.6 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10903201472817431		[learning rate: 0.00040684]
	Learning Rate: 0.00040684
	LOSS [training: 0.10903201472817431 | validation: 0.09972907304240479]
	TIME [epoch: 36.7 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11579200264604422		[learning rate: 0.00040522]
	Learning Rate: 0.000405221
	LOSS [training: 0.11579200264604422 | validation: 0.09855030224351742]
	TIME [epoch: 36.7 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10881184252688941		[learning rate: 0.00040361]
	Learning Rate: 0.00040361
	LOSS [training: 0.10881184252688941 | validation: 0.09809975388592385]
	TIME [epoch: 36.6 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1079292546621089		[learning rate: 0.000402]
	Learning Rate: 0.000402004
	LOSS [training: 0.1079292546621089 | validation: 0.09762557555847334]
	TIME [epoch: 36.7 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1114123924045357		[learning rate: 0.00040041]
	Learning Rate: 0.000400406
	LOSS [training: 0.1114123924045357 | validation: 0.09498880110445777]
	TIME [epoch: 36.6 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11535608419363255		[learning rate: 0.00039881]
	Learning Rate: 0.000398813
	LOSS [training: 0.11535608419363255 | validation: 0.09297984392208017]
	TIME [epoch: 36.7 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11160258978045595		[learning rate: 0.00039723]
	Learning Rate: 0.000397227
	LOSS [training: 0.11160258978045595 | validation: 0.10312155264178009]
	TIME [epoch: 36.6 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11297902509428923		[learning rate: 0.00039565]
	Learning Rate: 0.000395647
	LOSS [training: 0.11297902509428923 | validation: 0.0939668877521477]
	TIME [epoch: 36.6 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11209101731185335		[learning rate: 0.00039407]
	Learning Rate: 0.000394073
	LOSS [training: 0.11209101731185335 | validation: 0.09411138819184076]
	TIME [epoch: 36.6 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11179457281254485		[learning rate: 0.00039251]
	Learning Rate: 0.000392506
	LOSS [training: 0.11179457281254485 | validation: 0.09773358587533643]
	TIME [epoch: 36.6 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11134097837798279		[learning rate: 0.00039094]
	Learning Rate: 0.000390945
	LOSS [training: 0.11134097837798279 | validation: 0.09556148257201054]
	TIME [epoch: 36.7 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11285763462992665		[learning rate: 0.00038939]
	Learning Rate: 0.00038939
	LOSS [training: 0.11285763462992665 | validation: 0.09341759934902652]
	TIME [epoch: 36.7 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1077410280352675		[learning rate: 0.00038784]
	Learning Rate: 0.000387841
	LOSS [training: 0.1077410280352675 | validation: 0.09813579852791932]
	TIME [epoch: 36.6 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10707724737103594		[learning rate: 0.0003863]
	Learning Rate: 0.000386299
	LOSS [training: 0.10707724737103594 | validation: 0.09497796728028021]
	TIME [epoch: 36.6 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10603321537967472		[learning rate: 0.00038476]
	Learning Rate: 0.000384762
	LOSS [training: 0.10603321537967472 | validation: 0.09794579692390873]
	TIME [epoch: 36.6 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10840341029351523		[learning rate: 0.00038323]
	Learning Rate: 0.000383232
	LOSS [training: 0.10840341029351523 | validation: 0.09938007129787116]
	TIME [epoch: 36.7 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11362578822985725		[learning rate: 0.00038171]
	Learning Rate: 0.000381708
	LOSS [training: 0.11362578822985725 | validation: 0.09605686706479942]
	TIME [epoch: 36.6 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.110621718268957		[learning rate: 0.00038019]
	Learning Rate: 0.000380189
	LOSS [training: 0.110621718268957 | validation: 0.101682661368764]
	TIME [epoch: 36.7 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.107177875020303		[learning rate: 0.00037868]
	Learning Rate: 0.000378677
	LOSS [training: 0.107177875020303 | validation: 0.0999119239008757]
	TIME [epoch: 36.6 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10742631520020209		[learning rate: 0.00037717]
	Learning Rate: 0.000377171
	LOSS [training: 0.10742631520020209 | validation: 0.09357138297098067]
	TIME [epoch: 36.6 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1079013784681838		[learning rate: 0.00037567]
	Learning Rate: 0.000375671
	LOSS [training: 0.1079013784681838 | validation: 0.09610869284387262]
	TIME [epoch: 36.7 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10844981102906179		[learning rate: 0.00037418]
	Learning Rate: 0.000374177
	LOSS [training: 0.10844981102906179 | validation: 0.10491789533869174]
	TIME [epoch: 36.7 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11488651824697566		[learning rate: 0.00037269]
	Learning Rate: 0.000372689
	LOSS [training: 0.11488651824697566 | validation: 0.09517853791938746]
	TIME [epoch: 36.7 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11559206846123872		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 0.11559206846123872 | validation: 0.08995267480652265]
	TIME [epoch: 36.7 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11527301822245975		[learning rate: 0.00036973]
	Learning Rate: 0.00036973
	LOSS [training: 0.11527301822245975 | validation: 0.09466480405212853]
	TIME [epoch: 36.7 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10995250400281062		[learning rate: 0.00036826]
	Learning Rate: 0.000368259
	LOSS [training: 0.10995250400281062 | validation: 0.0951678341639125]
	TIME [epoch: 36.7 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11320956371938158		[learning rate: 0.00036679]
	Learning Rate: 0.000366795
	LOSS [training: 0.11320956371938158 | validation: 0.0966362540634043]
	TIME [epoch: 36.7 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10357856273880382		[learning rate: 0.00036534]
	Learning Rate: 0.000365336
	LOSS [training: 0.10357856273880382 | validation: 0.10610402858795379]
	TIME [epoch: 36.7 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10783767858669943		[learning rate: 0.00036388]
	Learning Rate: 0.000363883
	LOSS [training: 0.10783767858669943 | validation: 0.09858917677007506]
	TIME [epoch: 36.7 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10774045382504986		[learning rate: 0.00036244]
	Learning Rate: 0.000362436
	LOSS [training: 0.10774045382504986 | validation: 0.09350200106834858]
	TIME [epoch: 36.7 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11611445815798545		[learning rate: 0.00036099]
	Learning Rate: 0.000360994
	LOSS [training: 0.11611445815798545 | validation: 0.0930221433281911]
	TIME [epoch: 36.7 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12038612512770877		[learning rate: 0.00035956]
	Learning Rate: 0.000359558
	LOSS [training: 0.12038612512770877 | validation: 0.09948635000092934]
	TIME [epoch: 36.7 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10650962306790415		[learning rate: 0.00035813]
	Learning Rate: 0.000358128
	LOSS [training: 0.10650962306790415 | validation: 0.09240885338765399]
	TIME [epoch: 36.7 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10955865372433003		[learning rate: 0.0003567]
	Learning Rate: 0.000356704
	LOSS [training: 0.10955865372433003 | validation: 0.09232194552214959]
	TIME [epoch: 36.7 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10914056744514786		[learning rate: 0.00035529]
	Learning Rate: 0.000355285
	LOSS [training: 0.10914056744514786 | validation: 0.09126238112985031]
	TIME [epoch: 36.7 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11271550266931128		[learning rate: 0.00035387]
	Learning Rate: 0.000353872
	LOSS [training: 0.11271550266931128 | validation: 0.09125600998425498]
	TIME [epoch: 36.7 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12727945073890917		[learning rate: 0.00035246]
	Learning Rate: 0.000352465
	LOSS [training: 0.12727945073890917 | validation: 0.098217469568617]
	TIME [epoch: 36.6 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11036114519051103		[learning rate: 0.00035106]
	Learning Rate: 0.000351063
	LOSS [training: 0.11036114519051103 | validation: 0.0969601164705409]
	TIME [epoch: 36.7 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10815895450859024		[learning rate: 0.00034967]
	Learning Rate: 0.000349666
	LOSS [training: 0.10815895450859024 | validation: 0.10104387734428324]
	TIME [epoch: 36.7 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1242034041437299		[learning rate: 0.00034828]
	Learning Rate: 0.000348276
	LOSS [training: 0.1242034041437299 | validation: 0.0943533368671523]
	TIME [epoch: 36.7 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11236113475629805		[learning rate: 0.00034689]
	Learning Rate: 0.000346891
	LOSS [training: 0.11236113475629805 | validation: 0.09034688241918394]
	TIME [epoch: 36.7 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11529135338873957		[learning rate: 0.00034551]
	Learning Rate: 0.000345511
	LOSS [training: 0.11529135338873957 | validation: 0.09679216613373072]
	TIME [epoch: 36.7 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10390385886280822		[learning rate: 0.00034414]
	Learning Rate: 0.000344137
	LOSS [training: 0.10390385886280822 | validation: 0.09652152178078378]
	TIME [epoch: 36.6 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11407751247582966		[learning rate: 0.00034277]
	Learning Rate: 0.000342768
	LOSS [training: 0.11407751247582966 | validation: 0.09816063818727698]
	TIME [epoch: 36.6 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11048426659886317		[learning rate: 0.0003414]
	Learning Rate: 0.000341405
	LOSS [training: 0.11048426659886317 | validation: 0.09360436978705144]
	TIME [epoch: 36.7 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1060790063922085		[learning rate: 0.00034005]
	Learning Rate: 0.000340047
	LOSS [training: 0.1060790063922085 | validation: 0.09420642959977192]
	TIME [epoch: 36.7 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11614735722971517		[learning rate: 0.00033869]
	Learning Rate: 0.000338694
	LOSS [training: 0.11614735722971517 | validation: 0.0893214954174724]
	TIME [epoch: 36.6 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10851190471286411		[learning rate: 0.00033735]
	Learning Rate: 0.000337347
	LOSS [training: 0.10851190471286411 | validation: 0.0970325933217481]
	TIME [epoch: 36.7 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11159051196745813		[learning rate: 0.00033601]
	Learning Rate: 0.000336005
	LOSS [training: 0.11159051196745813 | validation: 0.10052556558112909]
	TIME [epoch: 36.6 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11133876316419292		[learning rate: 0.00033467]
	Learning Rate: 0.000334669
	LOSS [training: 0.11133876316419292 | validation: 0.09631061329697606]
	TIME [epoch: 36.7 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1236782477543574		[learning rate: 0.00033334]
	Learning Rate: 0.000333338
	LOSS [training: 0.1236782477543574 | validation: 0.09965255547832788]
	TIME [epoch: 36.6 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10488839454672329		[learning rate: 0.00033201]
	Learning Rate: 0.000332012
	LOSS [training: 0.10488839454672329 | validation: 0.08555837843886718]
	TIME [epoch: 36.7 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v1_20240624_133245/states/model_facs_dec1b_2dpca_v1_899.pth
	Model improved!!!
EPOCH 900/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10685731636182834		[learning rate: 0.00033069]
	Learning Rate: 0.000330692
	LOSS [training: 0.10685731636182834 | validation: 0.09145528308772972]
	TIME [epoch: 36.7 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11265983612147054		[learning rate: 0.00032938]
	Learning Rate: 0.000329376
	LOSS [training: 0.11265983612147054 | validation: 0.09081031146372373]
	TIME [epoch: 36.6 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10691961830947676		[learning rate: 0.00032807]
	Learning Rate: 0.000328066
	LOSS [training: 0.10691961830947676 | validation: 0.09632869410405084]
	TIME [epoch: 36.6 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10533148585964043		[learning rate: 0.00032676]
	Learning Rate: 0.000326761
	LOSS [training: 0.10533148585964043 | validation: 0.09390276483267464]
	TIME [epoch: 36.6 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1156400213540982		[learning rate: 0.00032546]
	Learning Rate: 0.000325462
	LOSS [training: 0.1156400213540982 | validation: 0.10026687720631071]
	TIME [epoch: 36.6 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10468964557755729		[learning rate: 0.00032417]
	Learning Rate: 0.000324167
	LOSS [training: 0.10468964557755729 | validation: 0.09318465766203224]
	TIME [epoch: 36.7 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11330010647922771		[learning rate: 0.00032288]
	Learning Rate: 0.000322878
	LOSS [training: 0.11330010647922771 | validation: 0.0951856492399201]
	TIME [epoch: 36.6 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11360342196110101		[learning rate: 0.00032159]
	Learning Rate: 0.000321594
	LOSS [training: 0.11360342196110101 | validation: 0.09293446003191538]
	TIME [epoch: 36.7 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11275771066473735		[learning rate: 0.00032031]
	Learning Rate: 0.000320315
	LOSS [training: 0.11275771066473735 | validation: 0.0927181263933067]
	TIME [epoch: 36.6 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11589798995035178		[learning rate: 0.00031904]
	Learning Rate: 0.000319041
	LOSS [training: 0.11589798995035178 | validation: 0.09493382082538201]
	TIME [epoch: 36.6 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11139170462759147		[learning rate: 0.00031777]
	Learning Rate: 0.000317772
	LOSS [training: 0.11139170462759147 | validation: 0.09446940958420916]
	TIME [epoch: 36.6 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1099840743824488		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 0.1099840743824488 | validation: 0.09859782387889407]
	TIME [epoch: 36.6 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1160575904822768		[learning rate: 0.00031525]
	Learning Rate: 0.000315249
	LOSS [training: 0.1160575904822768 | validation: 0.09414847232949797]
	TIME [epoch: 36.6 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10565351298561027		[learning rate: 0.000314]
	Learning Rate: 0.000313995
	LOSS [training: 0.10565351298561027 | validation: 0.09288754582309193]
	TIME [epoch: 36.6 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10942193763037543		[learning rate: 0.00031275]
	Learning Rate: 0.000312746
	LOSS [training: 0.10942193763037543 | validation: 0.09375254500830014]
	TIME [epoch: 36.6 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10988749980672587		[learning rate: 0.0003115]
	Learning Rate: 0.000311503
	LOSS [training: 0.10988749980672587 | validation: 0.09069065327062262]
	TIME [epoch: 36.6 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11277852734690914		[learning rate: 0.00031026]
	Learning Rate: 0.000310264
	LOSS [training: 0.11277852734690914 | validation: 0.08887680921354406]
	TIME [epoch: 36.6 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11889787664189984		[learning rate: 0.00030903]
	Learning Rate: 0.00030903
	LOSS [training: 0.11889787664189984 | validation: 0.1004339286190509]
	TIME [epoch: 36.6 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10368579315671982		[learning rate: 0.0003078]
	Learning Rate: 0.0003078
	LOSS [training: 0.10368579315671982 | validation: 0.09248318550302785]
	TIME [epoch: 36.6 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10872767917288433		[learning rate: 0.00030658]
	Learning Rate: 0.000306576
	LOSS [training: 0.10872767917288433 | validation: 0.0999070626703575]
	TIME [epoch: 36.7 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10941927753557451		[learning rate: 0.00030536]
	Learning Rate: 0.000305357
	LOSS [training: 0.10941927753557451 | validation: 0.08931554319120735]
	TIME [epoch: 36.6 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11061619012699797		[learning rate: 0.00030414]
	Learning Rate: 0.000304142
	LOSS [training: 0.11061619012699797 | validation: 0.09522763758750344]
	TIME [epoch: 36.6 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10706420171401108		[learning rate: 0.00030293]
	Learning Rate: 0.000302933
	LOSS [training: 0.10706420171401108 | validation: 0.09963875621197368]
	TIME [epoch: 36.6 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10976342174326136		[learning rate: 0.00030173]
	Learning Rate: 0.000301728
	LOSS [training: 0.10976342174326136 | validation: 0.08905825567126588]
	TIME [epoch: 36.6 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11275979443460346		[learning rate: 0.00030053]
	Learning Rate: 0.000300528
	LOSS [training: 0.11275979443460346 | validation: 0.09382662493126744]
	TIME [epoch: 36.7 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11508846569026411		[learning rate: 0.00029933]
	Learning Rate: 0.000299333
	LOSS [training: 0.11508846569026411 | validation: 0.09685133205544352]
	TIME [epoch: 36.6 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.09941482216406412		[learning rate: 0.00029814]
	Learning Rate: 0.000298142
	LOSS [training: 0.09941482216406412 | validation: 0.10628735863249254]
	TIME [epoch: 36.6 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10937012578982201		[learning rate: 0.00029696]
	Learning Rate: 0.000296956
	LOSS [training: 0.10937012578982201 | validation: 0.09980240945949097]
	TIME [epoch: 36.6 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10877867687279091		[learning rate: 0.00029578]
	Learning Rate: 0.000295775
	LOSS [training: 0.10877867687279091 | validation: 0.09229172214159738]
	TIME [epoch: 36.6 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12138036260599502		[learning rate: 0.0002946]
	Learning Rate: 0.000294599
	LOSS [training: 0.12138036260599502 | validation: 0.10235142813287856]
	TIME [epoch: 36.6 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1196675066279434		[learning rate: 0.00029343]
	Learning Rate: 0.000293427
	LOSS [training: 0.1196675066279434 | validation: 0.09488400694793678]
	TIME [epoch: 36.6 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10978987627611834		[learning rate: 0.00029226]
	Learning Rate: 0.00029226
	LOSS [training: 0.10978987627611834 | validation: 0.09445970293531813]
	TIME [epoch: 36.7 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10709960216229611		[learning rate: 0.0002911]
	Learning Rate: 0.000291098
	LOSS [training: 0.10709960216229611 | validation: 0.09389694603091618]
	TIME [epoch: 36.6 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10744023392985985		[learning rate: 0.00028994]
	Learning Rate: 0.00028994
	LOSS [training: 0.10744023392985985 | validation: 0.09181585214181429]
	TIME [epoch: 36.6 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11409983425360795		[learning rate: 0.00028879]
	Learning Rate: 0.000288786
	LOSS [training: 0.11409983425360795 | validation: 0.091703533388894]
	TIME [epoch: 36.6 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12001471468696343		[learning rate: 0.00028764]
	Learning Rate: 0.000287638
	LOSS [training: 0.12001471468696343 | validation: 0.09005097012746963]
	TIME [epoch: 36.7 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11157895435182821		[learning rate: 0.00028649]
	Learning Rate: 0.000286494
	LOSS [training: 0.11157895435182821 | validation: 0.1004485194972355]
	TIME [epoch: 36.6 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1061681836029631		[learning rate: 0.00028535]
	Learning Rate: 0.000285354
	LOSS [training: 0.1061681836029631 | validation: 0.09449706808351685]
	TIME [epoch: 36.6 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11471046955621149		[learning rate: 0.00028422]
	Learning Rate: 0.00028422
	LOSS [training: 0.11471046955621149 | validation: 0.09270668978749304]
	TIME [epoch: 36.6 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11256268908864013		[learning rate: 0.00028309]
	Learning Rate: 0.000283089
	LOSS [training: 0.11256268908864013 | validation: 0.09730586203014982]
	TIME [epoch: 36.7 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11084462644229677		[learning rate: 0.00028196]
	Learning Rate: 0.000281963
	LOSS [training: 0.11084462644229677 | validation: 0.09472707776102576]
	TIME [epoch: 36.6 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11282273494356024		[learning rate: 0.00028084]
	Learning Rate: 0.000280842
	LOSS [training: 0.11282273494356024 | validation: 0.09454559732370993]
	TIME [epoch: 36.6 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10292572941151439		[learning rate: 0.00027972]
	Learning Rate: 0.000279725
	LOSS [training: 0.10292572941151439 | validation: 0.09600085041885205]
	TIME [epoch: 36.6 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11604622223712771		[learning rate: 0.00027861]
	Learning Rate: 0.000278612
	LOSS [training: 0.11604622223712771 | validation: 0.09431655583592306]
	TIME [epoch: 36.7 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11644433702293489		[learning rate: 0.0002775]
	Learning Rate: 0.000277504
	LOSS [training: 0.11644433702293489 | validation: 0.09352663781093858]
	TIME [epoch: 36.6 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11733477832431892		[learning rate: 0.0002764]
	Learning Rate: 0.0002764
	LOSS [training: 0.11733477832431892 | validation: 0.0989666427784048]
	TIME [epoch: 36.6 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10772027518276057		[learning rate: 0.0002753]
	Learning Rate: 0.000275301
	LOSS [training: 0.10772027518276057 | validation: 0.09590351532461497]
	TIME [epoch: 36.6 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11264595191820723		[learning rate: 0.00027421]
	Learning Rate: 0.000274206
	LOSS [training: 0.11264595191820723 | validation: 0.0921354823770237]
	TIME [epoch: 36.7 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11674596749030222		[learning rate: 0.00027312]
	Learning Rate: 0.000273115
	LOSS [training: 0.11674596749030222 | validation: 0.08960993870693587]
	TIME [epoch: 36.6 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11175652632459648		[learning rate: 0.00027203]
	Learning Rate: 0.000272029
	LOSS [training: 0.11175652632459648 | validation: 0.09589755376410261]
	TIME [epoch: 36.6 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10921653095931678		[learning rate: 0.00027095]
	Learning Rate: 0.000270947
	LOSS [training: 0.10921653095931678 | validation: 0.09597340873038439]
	TIME [epoch: 36.6 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11114110682831797		[learning rate: 0.00026987]
	Learning Rate: 0.00026987
	LOSS [training: 0.11114110682831797 | validation: 0.10040416280056674]
	TIME [epoch: 36.7 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1102815169261099		[learning rate: 0.0002688]
	Learning Rate: 0.000268796
	LOSS [training: 0.1102815169261099 | validation: 0.09684835890243981]
	TIME [epoch: 36.6 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10886076021361846		[learning rate: 0.00026773]
	Learning Rate: 0.000267727
	LOSS [training: 0.10886076021361846 | validation: 0.09665288485862106]
	TIME [epoch: 36.6 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10751449598771573		[learning rate: 0.00026666]
	Learning Rate: 0.000266662
	LOSS [training: 0.10751449598771573 | validation: 0.0961250210637675]
	TIME [epoch: 36.6 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11157780097371132		[learning rate: 0.0002656]
	Learning Rate: 0.000265602
	LOSS [training: 0.11157780097371132 | validation: 0.09483206955121581]
	TIME [epoch: 36.7 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1118965102285868		[learning rate: 0.00026455]
	Learning Rate: 0.000264545
	LOSS [training: 0.1118965102285868 | validation: 0.09751022611449767]
	TIME [epoch: 36.6 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11064323742855375		[learning rate: 0.00026349]
	Learning Rate: 0.000263493
	LOSS [training: 0.11064323742855375 | validation: 0.09772565790358749]
	TIME [epoch: 36.7 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10377444487546802		[learning rate: 0.00026245]
	Learning Rate: 0.000262445
	LOSS [training: 0.10377444487546802 | validation: 0.09652489643214479]
	TIME [epoch: 36.6 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1088300476599399		[learning rate: 0.0002614]
	Learning Rate: 0.000261401
	LOSS [training: 0.1088300476599399 | validation: 0.09352730487708225]
	TIME [epoch: 36.6 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10931399515148425		[learning rate: 0.00026036]
	Learning Rate: 0.000260362
	LOSS [training: 0.10931399515148425 | validation: 0.0958126876813665]
	TIME [epoch: 36.6 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11415072995807371		[learning rate: 0.00025933]
	Learning Rate: 0.000259326
	LOSS [training: 0.11415072995807371 | validation: 0.0982744620935374]
	TIME [epoch: 36.6 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11696142923305367		[learning rate: 0.00025829]
	Learning Rate: 0.000258295
	LOSS [training: 0.11696142923305367 | validation: 0.09426140719865247]
	TIME [epoch: 36.6 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10266742274514058		[learning rate: 0.00025727]
	Learning Rate: 0.000257267
	LOSS [training: 0.10266742274514058 | validation: 0.09557481317229063]
	TIME [epoch: 36.7 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10476240400538907		[learning rate: 0.00025624]
	Learning Rate: 0.000256244
	LOSS [training: 0.10476240400538907 | validation: 0.09361188826673235]
	TIME [epoch: 36.6 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11034785642541695		[learning rate: 0.00025522]
	Learning Rate: 0.000255225
	LOSS [training: 0.11034785642541695 | validation: 0.0908211938360846]
	TIME [epoch: 36.6 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11314058672013995		[learning rate: 0.00025421]
	Learning Rate: 0.00025421
	LOSS [training: 0.11314058672013995 | validation: 0.08937170840193637]
	TIME [epoch: 36.6 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10980721131692535		[learning rate: 0.0002532]
	Learning Rate: 0.000253199
	LOSS [training: 0.10980721131692535 | validation: 0.09309881488330314]
	TIME [epoch: 36.7 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.107937044914831		[learning rate: 0.00025219]
	Learning Rate: 0.000252192
	LOSS [training: 0.107937044914831 | validation: 0.10105180487256633]
	TIME [epoch: 36.6 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10850952389916474		[learning rate: 0.00025119]
	Learning Rate: 0.000251189
	LOSS [training: 0.10850952389916474 | validation: 0.09825487944212358]
	TIME [epoch: 36.7 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12260415976525103		[learning rate: 0.00025019]
	Learning Rate: 0.00025019
	LOSS [training: 0.12260415976525103 | validation: 0.09181122361793834]
	TIME [epoch: 36.7 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12027391440679258		[learning rate: 0.00024919]
	Learning Rate: 0.000249195
	LOSS [training: 0.12027391440679258 | validation: 0.09506404112862932]
	TIME [epoch: 36.7 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11945295252576066		[learning rate: 0.0002482]
	Learning Rate: 0.000248203
	LOSS [training: 0.11945295252576066 | validation: 0.08924112191432317]
	TIME [epoch: 36.6 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10698636431929812		[learning rate: 0.00024722]
	Learning Rate: 0.000247216
	LOSS [training: 0.10698636431929812 | validation: 0.09589852675892588]
	TIME [epoch: 36.7 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10643711077800681		[learning rate: 0.00024623]
	Learning Rate: 0.000246233
	LOSS [training: 0.10643711077800681 | validation: 0.09250990021676589]
	TIME [epoch: 36.6 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1083212023241602		[learning rate: 0.00024525]
	Learning Rate: 0.000245254
	LOSS [training: 0.1083212023241602 | validation: 0.09843196562443592]
	TIME [epoch: 36.6 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10636483878518102		[learning rate: 0.00024428]
	Learning Rate: 0.000244278
	LOSS [training: 0.10636483878518102 | validation: 0.09685602633157843]
	TIME [epoch: 36.6 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10782419999633269		[learning rate: 0.00024331]
	Learning Rate: 0.000243307
	LOSS [training: 0.10782419999633269 | validation: 0.09412247169289067]
	TIME [epoch: 36.6 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10719223307327737		[learning rate: 0.00024234]
	Learning Rate: 0.000242339
	LOSS [training: 0.10719223307327737 | validation: 0.0934090336465968]
	TIME [epoch: 36.6 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10796260241374402		[learning rate: 0.00024138]
	Learning Rate: 0.000241375
	LOSS [training: 0.10796260241374402 | validation: 0.09221642144382078]
	TIME [epoch: 36.7 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10442048868810895		[learning rate: 0.00024042]
	Learning Rate: 0.000240415
	LOSS [training: 0.10442048868810895 | validation: 0.08933748426232224]
	TIME [epoch: 36.6 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10484246555551119		[learning rate: 0.00023946]
	Learning Rate: 0.000239459
	LOSS [training: 0.10484246555551119 | validation: 0.09386193938683367]
	TIME [epoch: 36.6 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1169220192433328		[learning rate: 0.00023851]
	Learning Rate: 0.000238506
	LOSS [training: 0.1169220192433328 | validation: 0.09284245293363058]
	TIME [epoch: 36.7 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1076916248023186		[learning rate: 0.00023756]
	Learning Rate: 0.000237558
	LOSS [training: 0.1076916248023186 | validation: 0.09606008231940913]
	TIME [epoch: 36.6 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11524858466211316		[learning rate: 0.00023661]
	Learning Rate: 0.000236613
	LOSS [training: 0.11524858466211316 | validation: 0.09646748460952992]
	TIME [epoch: 36.6 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1100065943223951		[learning rate: 0.00023567]
	Learning Rate: 0.000235672
	LOSS [training: 0.1100065943223951 | validation: 0.09333763601768949]
	TIME [epoch: 36.6 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10937771771458803		[learning rate: 0.00023473]
	Learning Rate: 0.000234735
	LOSS [training: 0.10937771771458803 | validation: 0.09672826040385599]
	TIME [epoch: 36.6 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10814775677604076		[learning rate: 0.0002338]
	Learning Rate: 0.000233801
	LOSS [training: 0.10814775677604076 | validation: 0.10054970899248387]
	TIME [epoch: 36.7 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11407005306670051		[learning rate: 0.00023287]
	Learning Rate: 0.000232871
	LOSS [training: 0.11407005306670051 | validation: 0.09144693163414674]
	TIME [epoch: 36.6 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11002173394472409		[learning rate: 0.00023194]
	Learning Rate: 0.000231945
	LOSS [training: 0.11002173394472409 | validation: 0.08997075381605993]
	TIME [epoch: 36.6 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11096401770894931		[learning rate: 0.00023102]
	Learning Rate: 0.000231022
	LOSS [training: 0.11096401770894931 | validation: 0.09726953345735542]
	TIME [epoch: 36.6 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11595419430459011		[learning rate: 0.0002301]
	Learning Rate: 0.000230103
	LOSS [training: 0.11595419430459011 | validation: 0.0907388163810813]
	TIME [epoch: 36.6 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11189922401395484		[learning rate: 0.00022919]
	Learning Rate: 0.000229188
	LOSS [training: 0.11189922401395484 | validation: 0.08977800368057853]
	TIME [epoch: 36.7 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11967225393192314		[learning rate: 0.00022828]
	Learning Rate: 0.000228277
	LOSS [training: 0.11967225393192314 | validation: 0.09853402518208584]
	TIME [epoch: 36.6 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10331953781072879		[learning rate: 0.00022737]
	Learning Rate: 0.000227369
	LOSS [training: 0.10331953781072879 | validation: 0.09412264952436475]
	TIME [epoch: 36.6 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10350655163874312		[learning rate: 0.00022646]
	Learning Rate: 0.000226464
	LOSS [training: 0.10350655163874312 | validation: 0.08797913631323065]
	TIME [epoch: 36.6 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11352342059135406		[learning rate: 0.00022556]
	Learning Rate: 0.000225564
	LOSS [training: 0.11352342059135406 | validation: 0.08595796985040552]
	TIME [epoch: 36.6 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11296560531791333		[learning rate: 0.00022467]
	Learning Rate: 0.000224667
	LOSS [training: 0.11296560531791333 | validation: 0.09012579044984273]
	TIME [epoch: 36.6 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10820877412356443		[learning rate: 0.00022377]
	Learning Rate: 0.000223773
	LOSS [training: 0.10820877412356443 | validation: 0.08842401342077502]
	TIME [epoch: 36.6 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10487753505342645		[learning rate: 0.00022288]
	Learning Rate: 0.000222883
	LOSS [training: 0.10487753505342645 | validation: 0.09792478997435694]
	TIME [epoch: 36.6 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10940724763628315		[learning rate: 0.000222]
	Learning Rate: 0.000221997
	LOSS [training: 0.10940724763628315 | validation: 0.0988651645224923]
	TIME [epoch: 36.7 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11808527611978459		[learning rate: 0.00022111]
	Learning Rate: 0.000221114
	LOSS [training: 0.11808527611978459 | validation: 0.09524342787389369]
	TIME [epoch: 36.7 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11514448709476371		[learning rate: 0.00022023]
	Learning Rate: 0.000220234
	LOSS [training: 0.11514448709476371 | validation: 0.09745675779081782]
	TIME [epoch: 36.6 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11234014025299609		[learning rate: 0.00021936]
	Learning Rate: 0.000219358
	LOSS [training: 0.11234014025299609 | validation: 0.0992637489147582]
	TIME [epoch: 36.6 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11134603057631172		[learning rate: 0.00021849]
	Learning Rate: 0.000218486
	LOSS [training: 0.11134603057631172 | validation: 0.0952303894158728]
	TIME [epoch: 36.6 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11844140343704737		[learning rate: 0.00021762]
	Learning Rate: 0.000217617
	LOSS [training: 0.11844140343704737 | validation: 0.0951663718681098]
	TIME [epoch: 36.7 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10907159151640844		[learning rate: 0.00021675]
	Learning Rate: 0.000216751
	LOSS [training: 0.10907159151640844 | validation: 0.0990730310172446]
	TIME [epoch: 36.6 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11042383945630393		[learning rate: 0.00021589]
	Learning Rate: 0.000215889
	LOSS [training: 0.11042383945630393 | validation: 0.08757906383976388]
	TIME [epoch: 36.6 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10797714180523445		[learning rate: 0.00021503]
	Learning Rate: 0.00021503
	LOSS [training: 0.10797714180523445 | validation: 0.09112879182273237]
	TIME [epoch: 36.6 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11995824807056721		[learning rate: 0.00021418]
	Learning Rate: 0.000214175
	LOSS [training: 0.11995824807056721 | validation: 0.10230801446519129]
	TIME [epoch: 36.7 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11740134834626804		[learning rate: 0.00021332]
	Learning Rate: 0.000213323
	LOSS [training: 0.11740134834626804 | validation: 0.0924272338740931]
	TIME [epoch: 36.6 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11770448150503382		[learning rate: 0.00021247]
	Learning Rate: 0.000212475
	LOSS [training: 0.11770448150503382 | validation: 0.09190494368886126]
	TIME [epoch: 36.6 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1050763156531683		[learning rate: 0.00021163]
	Learning Rate: 0.00021163
	LOSS [training: 0.1050763156531683 | validation: 0.10077381703124359]
	TIME [epoch: 36.6 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11311311602647597		[learning rate: 0.00021079]
	Learning Rate: 0.000210788
	LOSS [training: 0.11311311602647597 | validation: 0.09934586691405456]
	TIME [epoch: 36.6 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10758900760420881		[learning rate: 0.00020995]
	Learning Rate: 0.00020995
	LOSS [training: 0.10758900760420881 | validation: 0.09168772549726513]
	TIME [epoch: 36.6 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10477521494108794		[learning rate: 0.00020911]
	Learning Rate: 0.000209115
	LOSS [training: 0.10477521494108794 | validation: 0.09909828676276386]
	TIME [epoch: 36.6 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11738316717222894		[learning rate: 0.00020828]
	Learning Rate: 0.000208283
	LOSS [training: 0.11738316717222894 | validation: 0.09603529519948173]
	TIME [epoch: 36.6 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10955776774525562		[learning rate: 0.00020745]
	Learning Rate: 0.000207455
	LOSS [training: 0.10955776774525562 | validation: 0.09112991247319477]
	TIME [epoch: 36.6 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11831992377868354		[learning rate: 0.00020663]
	Learning Rate: 0.00020663
	LOSS [training: 0.11831992377868354 | validation: 0.0942724941807153]
	TIME [epoch: 36.6 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11251737421662646		[learning rate: 0.00020581]
	Learning Rate: 0.000205808
	LOSS [training: 0.11251737421662646 | validation: 0.09404842036670868]
	TIME [epoch: 36.7 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10803245253900409		[learning rate: 0.00020499]
	Learning Rate: 0.000204989
	LOSS [training: 0.10803245253900409 | validation: 0.09639432931359951]
	TIME [epoch: 36.6 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11575644869334026		[learning rate: 0.00020417]
	Learning Rate: 0.000204174
	LOSS [training: 0.11575644869334026 | validation: 0.09296898174067751]
	TIME [epoch: 36.6 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10508335715241052		[learning rate: 0.00020336]
	Learning Rate: 0.000203362
	LOSS [training: 0.10508335715241052 | validation: 0.10006380431656932]
	TIME [epoch: 36.6 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10338243808909071		[learning rate: 0.00020255]
	Learning Rate: 0.000202553
	LOSS [training: 0.10338243808909071 | validation: 0.10013142795502764]
	TIME [epoch: 36.6 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11288539821494527		[learning rate: 0.00020175]
	Learning Rate: 0.000201747
	LOSS [training: 0.11288539821494527 | validation: 0.10099460208817039]
	TIME [epoch: 36.6 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11022956887172002		[learning rate: 0.00020094]
	Learning Rate: 0.000200945
	LOSS [training: 0.11022956887172002 | validation: 0.09486460332885245]
	TIME [epoch: 36.6 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10697751695670774		[learning rate: 0.00020015]
	Learning Rate: 0.000200146
	LOSS [training: 0.10697751695670774 | validation: 0.09430883717086913]
	TIME [epoch: 36.6 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11603942164963356		[learning rate: 0.00019935]
	Learning Rate: 0.00019935
	LOSS [training: 0.11603942164963356 | validation: 0.09288554867395199]
	TIME [epoch: 36.6 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10746907090778876		[learning rate: 0.00019856]
	Learning Rate: 0.000198557
	LOSS [training: 0.10746907090778876 | validation: 0.09412300523989395]
	TIME [epoch: 36.6 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10548448781005021		[learning rate: 0.00019777]
	Learning Rate: 0.000197767
	LOSS [training: 0.10548448781005021 | validation: 0.08993730182447633]
	TIME [epoch: 36.7 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10909317814117651		[learning rate: 0.00019698]
	Learning Rate: 0.00019698
	LOSS [training: 0.10909317814117651 | validation: 0.09285170758032503]
	TIME [epoch: 36.6 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11414986021371584		[learning rate: 0.0001962]
	Learning Rate: 0.000196197
	LOSS [training: 0.11414986021371584 | validation: 0.09700612184542137]
	TIME [epoch: 36.6 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10534442523442417		[learning rate: 0.00019542]
	Learning Rate: 0.000195417
	LOSS [training: 0.10534442523442417 | validation: 0.09487544827070124]
	TIME [epoch: 36.6 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1171082486630474		[learning rate: 0.00019464]
	Learning Rate: 0.000194639
	LOSS [training: 0.1171082486630474 | validation: 0.08224023074360096]
	TIME [epoch: 36.7 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v1_20240624_133245/states/model_facs_dec1b_2dpca_v1_1033.pth
	Model improved!!!
EPOCH 1034/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10686621084829112		[learning rate: 0.00019387]
	Learning Rate: 0.000193865
	LOSS [training: 0.10686621084829112 | validation: 0.08999609752509655]
	TIME [epoch: 36.7 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1139274083847538		[learning rate: 0.00019309]
	Learning Rate: 0.000193094
	LOSS [training: 0.1139274083847538 | validation: 0.0908134957226853]
	TIME [epoch: 36.6 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10967808170271928		[learning rate: 0.00019233]
	Learning Rate: 0.000192326
	LOSS [training: 0.10967808170271928 | validation: 0.09631686411865273]
	TIME [epoch: 36.6 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10872429049812772		[learning rate: 0.00019156]
	Learning Rate: 0.000191561
	LOSS [training: 0.10872429049812772 | validation: 0.09767666784647284]
	TIME [epoch: 36.6 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10728235753188071		[learning rate: 0.0001908]
	Learning Rate: 0.000190799
	LOSS [training: 0.10728235753188071 | validation: 0.0958382723959533]
	TIME [epoch: 36.6 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10488754272685447		[learning rate: 0.00019004]
	Learning Rate: 0.00019004
	LOSS [training: 0.10488754272685447 | validation: 0.09507873343800413]
	TIME [epoch: 36.7 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10254025412124396		[learning rate: 0.00018928]
	Learning Rate: 0.000189285
	LOSS [training: 0.10254025412124396 | validation: 0.09096045999642868]
	TIME [epoch: 36.6 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10498095735320508		[learning rate: 0.00018853]
	Learning Rate: 0.000188532
	LOSS [training: 0.10498095735320508 | validation: 0.09824841005764398]
	TIME [epoch: 36.6 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10914386403378702		[learning rate: 0.00018778]
	Learning Rate: 0.000187782
	LOSS [training: 0.10914386403378702 | validation: 0.09947066945074093]
	TIME [epoch: 36.7 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12414862193555634		[learning rate: 0.00018704]
	Learning Rate: 0.000187035
	LOSS [training: 0.12414862193555634 | validation: 0.10150817426869567]
	TIME [epoch: 36.7 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11302937597093761		[learning rate: 0.00018629]
	Learning Rate: 0.000186291
	LOSS [training: 0.11302937597093761 | validation: 0.09564940148006981]
	TIME [epoch: 36.7 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10249358990415271		[learning rate: 0.00018555]
	Learning Rate: 0.00018555
	LOSS [training: 0.10249358990415271 | validation: 0.09222592867943949]
	TIME [epoch: 36.6 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10400858604179841		[learning rate: 0.00018481]
	Learning Rate: 0.000184812
	LOSS [training: 0.10400858604179841 | validation: 0.09536803297870462]
	TIME [epoch: 36.6 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10429963400497282		[learning rate: 0.00018408]
	Learning Rate: 0.000184077
	LOSS [training: 0.10429963400497282 | validation: 0.09099042095637738]
	TIME [epoch: 36.7 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10992430874386122		[learning rate: 0.00018335]
	Learning Rate: 0.000183345
	LOSS [training: 0.10992430874386122 | validation: 0.0894960465423016]
	TIME [epoch: 36.6 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11701262628276037		[learning rate: 0.00018262]
	Learning Rate: 0.000182616
	LOSS [training: 0.11701262628276037 | validation: 0.09091625810600708]
	TIME [epoch: 36.6 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1290480825978412		[learning rate: 0.00018189]
	Learning Rate: 0.00018189
	LOSS [training: 0.1290480825978412 | validation: 0.09361363226416694]
	TIME [epoch: 36.7 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10890559756593632		[learning rate: 0.00018117]
	Learning Rate: 0.000181166
	LOSS [training: 0.10890559756593632 | validation: 0.09677002152557884]
	TIME [epoch: 36.7 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1078075208930154		[learning rate: 0.00018045]
	Learning Rate: 0.000180446
	LOSS [training: 0.1078075208930154 | validation: 0.09263613963718398]
	TIME [epoch: 36.7 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1058941523722585		[learning rate: 0.00017973]
	Learning Rate: 0.000179728
	LOSS [training: 0.1058941523722585 | validation: 0.08816037289710629]
	TIME [epoch: 36.6 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10932041206790027		[learning rate: 0.00017901]
	Learning Rate: 0.000179013
	LOSS [training: 0.10932041206790027 | validation: 0.09543980037442774]
	TIME [epoch: 36.6 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11692603688516698		[learning rate: 0.0001783]
	Learning Rate: 0.000178301
	LOSS [training: 0.11692603688516698 | validation: 0.09435253944270279]
	TIME [epoch: 36.6 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11062857194943833		[learning rate: 0.00017759]
	Learning Rate: 0.000177592
	LOSS [training: 0.11062857194943833 | validation: 0.09240145771099292]
	TIME [epoch: 36.7 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1023241818474797		[learning rate: 0.00017689]
	Learning Rate: 0.000176886
	LOSS [training: 0.1023241818474797 | validation: 0.09927270430739027]
	TIME [epoch: 36.7 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12424634420598532		[learning rate: 0.00017618]
	Learning Rate: 0.000176182
	LOSS [training: 0.12424634420598532 | validation: 0.08891434705705528]
	TIME [epoch: 36.7 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11880359154693027		[learning rate: 0.00017548]
	Learning Rate: 0.000175481
	LOSS [training: 0.11880359154693027 | validation: 0.09190206962184613]
	TIME [epoch: 36.7 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11655655253826216		[learning rate: 0.00017478]
	Learning Rate: 0.000174783
	LOSS [training: 0.11655655253826216 | validation: 0.09365394348307929]
	TIME [epoch: 36.7 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12093131490064543		[learning rate: 0.00017409]
	Learning Rate: 0.000174088
	LOSS [training: 0.12093131490064543 | validation: 0.0969463172379649]
	TIME [epoch: 36.7 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11722046648410396		[learning rate: 0.0001734]
	Learning Rate: 0.000173396
	LOSS [training: 0.11722046648410396 | validation: 0.08938154007046248]
	TIME [epoch: 36.6 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10930413238129949		[learning rate: 0.00017271]
	Learning Rate: 0.000172706
	LOSS [training: 0.10930413238129949 | validation: 0.097365832537303]
	TIME [epoch: 36.6 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10594044408650166		[learning rate: 0.00017202]
	Learning Rate: 0.000172019
	LOSS [training: 0.10594044408650166 | validation: 0.09776018092297704]
	TIME [epoch: 36.6 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11107731284220852		[learning rate: 0.00017134]
	Learning Rate: 0.000171335
	LOSS [training: 0.11107731284220852 | validation: 0.09144586423728436]
	TIME [epoch: 36.6 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11044836579690694		[learning rate: 0.00017065]
	Learning Rate: 0.000170654
	LOSS [training: 0.11044836579690694 | validation: 0.09507081909419361]
	TIME [epoch: 36.6 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11266576542346504		[learning rate: 0.00016997]
	Learning Rate: 0.000169975
	LOSS [training: 0.11266576542346504 | validation: 0.10504452501954291]
	TIME [epoch: 36.6 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10229674645155812		[learning rate: 0.0001693]
	Learning Rate: 0.000169299
	LOSS [training: 0.10229674645155812 | validation: 0.09474590347523523]
	TIME [epoch: 36.6 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10867107409427909		[learning rate: 0.00016863]
	Learning Rate: 0.000168625
	LOSS [training: 0.10867107409427909 | validation: 0.09805516643493922]
	TIME [epoch: 36.6 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11035732127065584		[learning rate: 0.00016795]
	Learning Rate: 0.000167955
	LOSS [training: 0.11035732127065584 | validation: 0.09768122823292122]
	TIME [epoch: 36.6 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11839647304128609		[learning rate: 0.00016729]
	Learning Rate: 0.000167287
	LOSS [training: 0.11839647304128609 | validation: 0.09817799372779443]
	TIME [epoch: 36.7 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10502661922310019		[learning rate: 0.00016662]
	Learning Rate: 0.000166621
	LOSS [training: 0.10502661922310019 | validation: 0.10170897501072593]
	TIME [epoch: 36.6 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11812208993239522		[learning rate: 0.00016596]
	Learning Rate: 0.000165959
	LOSS [training: 0.11812208993239522 | validation: 0.09507548883998138]
	TIME [epoch: 36.6 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11269387278239816		[learning rate: 0.0001653]
	Learning Rate: 0.000165299
	LOSS [training: 0.11269387278239816 | validation: 0.09038829178060458]
	TIME [epoch: 36.6 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11347049776449467		[learning rate: 0.00016464]
	Learning Rate: 0.000164641
	LOSS [training: 0.11347049776449467 | validation: 0.09448253768248302]
	TIME [epoch: 36.7 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10736493203833336		[learning rate: 0.00016399]
	Learning Rate: 0.000163986
	LOSS [training: 0.10736493203833336 | validation: 0.09392002194884772]
	TIME [epoch: 36.6 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10565750557919651		[learning rate: 0.00016333]
	Learning Rate: 0.000163334
	LOSS [training: 0.10565750557919651 | validation: 0.09511947960187224]
	TIME [epoch: 36.6 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11394085955957135		[learning rate: 0.00016268]
	Learning Rate: 0.000162685
	LOSS [training: 0.11394085955957135 | validation: 0.09870168093925948]
	TIME [epoch: 36.6 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1232130684627147		[learning rate: 0.00016204]
	Learning Rate: 0.000162037
	LOSS [training: 0.1232130684627147 | validation: 0.09423385876564178]
	TIME [epoch: 36.7 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1078366344228865		[learning rate: 0.00016139]
	Learning Rate: 0.000161393
	LOSS [training: 0.1078366344228865 | validation: 0.09511728825198447]
	TIME [epoch: 36.6 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10830120826596595		[learning rate: 0.00016075]
	Learning Rate: 0.000160751
	LOSS [training: 0.10830120826596595 | validation: 0.09864092838235679]
	TIME [epoch: 36.6 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1176182844755658		[learning rate: 0.00016011]
	Learning Rate: 0.000160112
	LOSS [training: 0.1176182844755658 | validation: 0.09198694051468877]
	TIME [epoch: 36.6 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11942689234869215		[learning rate: 0.00015947]
	Learning Rate: 0.000159475
	LOSS [training: 0.11942689234869215 | validation: 0.09966873794106627]
	TIME [epoch: 36.6 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11445403105085306		[learning rate: 0.00015884]
	Learning Rate: 0.000158841
	LOSS [training: 0.11445403105085306 | validation: 0.09768453866176698]
	TIME [epoch: 36.6 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1118794829890352		[learning rate: 0.00015821]
	Learning Rate: 0.000158209
	LOSS [training: 0.1118794829890352 | validation: 0.09348670170827876]
	TIME [epoch: 36.6 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1140186197886986		[learning rate: 0.00015758]
	Learning Rate: 0.00015758
	LOSS [training: 0.1140186197886986 | validation: 0.10095521868252004]
	TIME [epoch: 36.7 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10934414962638217		[learning rate: 0.00015695]
	Learning Rate: 0.000156953
	LOSS [training: 0.10934414962638217 | validation: 0.09538755395800862]
	TIME [epoch: 36.6 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10588765832474967		[learning rate: 0.00015633]
	Learning Rate: 0.000156329
	LOSS [training: 0.10588765832474967 | validation: 0.09522267980372315]
	TIME [epoch: 36.7 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1124977200252322		[learning rate: 0.00015571]
	Learning Rate: 0.000155707
	LOSS [training: 0.1124977200252322 | validation: 0.09661771395901322]
	TIME [epoch: 36.6 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10698138627023795		[learning rate: 0.00015509]
	Learning Rate: 0.000155088
	LOSS [training: 0.10698138627023795 | validation: 0.09576262053111884]
	TIME [epoch: 36.7 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10778064074714616		[learning rate: 0.00015447]
	Learning Rate: 0.000154471
	LOSS [training: 0.10778064074714616 | validation: 0.09972560379601392]
	TIME [epoch: 36.7 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10272902762477684		[learning rate: 0.00015386]
	Learning Rate: 0.000153856
	LOSS [training: 0.10272902762477684 | validation: 0.09660700013289329]
	TIME [epoch: 36.7 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1045413947969833		[learning rate: 0.00015324]
	Learning Rate: 0.000153244
	LOSS [training: 0.1045413947969833 | validation: 0.09166451646453451]
	TIME [epoch: 36.7 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11517506686297269		[learning rate: 0.00015263]
	Learning Rate: 0.000152635
	LOSS [training: 0.11517506686297269 | validation: 0.09288177112010634]
	TIME [epoch: 36.7 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11319345363896709		[learning rate: 0.00015203]
	Learning Rate: 0.000152028
	LOSS [training: 0.11319345363896709 | validation: 0.09967312348097566]
	TIME [epoch: 36.7 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11702532712210442		[learning rate: 0.00015142]
	Learning Rate: 0.000151423
	LOSS [training: 0.11702532712210442 | validation: 0.09489698308807971]
	TIME [epoch: 36.7 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10381714632315589		[learning rate: 0.00015082]
	Learning Rate: 0.000150821
	LOSS [training: 0.10381714632315589 | validation: 0.09711636107882554]
	TIME [epoch: 36.6 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10804479164301327		[learning rate: 0.00015022]
	Learning Rate: 0.000150221
	LOSS [training: 0.10804479164301327 | validation: 0.09822000769842357]
	TIME [epoch: 36.7 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11104585796855074		[learning rate: 0.00014962]
	Learning Rate: 0.000149624
	LOSS [training: 0.11104585796855074 | validation: 0.0967724736390658]
	TIME [epoch: 36.7 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10782227393886504		[learning rate: 0.00014903]
	Learning Rate: 0.000149028
	LOSS [training: 0.10782227393886504 | validation: 0.09580402700758173]
	TIME [epoch: 36.6 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10738546641716266		[learning rate: 0.00014844]
	Learning Rate: 0.000148436
	LOSS [training: 0.10738546641716266 | validation: 0.09090780297388738]
	TIME [epoch: 36.7 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10690364852457408		[learning rate: 0.00014785]
	Learning Rate: 0.000147845
	LOSS [training: 0.10690364852457408 | validation: 0.09746374571042364]
	TIME [epoch: 36.6 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11388474837890598		[learning rate: 0.00014726]
	Learning Rate: 0.000147257
	LOSS [training: 0.11388474837890598 | validation: 0.09481453170254407]
	TIME [epoch: 36.6 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10595783837831622		[learning rate: 0.00014667]
	Learning Rate: 0.000146672
	LOSS [training: 0.10595783837831622 | validation: 0.09136411216791454]
	TIME [epoch: 36.6 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10716097212003635		[learning rate: 0.00014609]
	Learning Rate: 0.000146088
	LOSS [training: 0.10716097212003635 | validation: 0.09790402132891982]
	TIME [epoch: 36.7 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11263081651242568		[learning rate: 0.00014551]
	Learning Rate: 0.000145507
	LOSS [training: 0.11263081651242568 | validation: 0.08781602581374004]
	TIME [epoch: 36.6 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10791700642511845		[learning rate: 0.00014493]
	Learning Rate: 0.000144929
	LOSS [training: 0.10791700642511845 | validation: 0.09701265626902746]
	TIME [epoch: 36.6 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1196080868227153		[learning rate: 0.00014435]
	Learning Rate: 0.000144352
	LOSS [training: 0.1196080868227153 | validation: 0.09426389001054417]
	TIME [epoch: 36.7 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11725077500760842		[learning rate: 0.00014378]
	Learning Rate: 0.000143778
	LOSS [training: 0.11725077500760842 | validation: 0.09578875073859074]
	TIME [epoch: 36.7 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10631372497061009		[learning rate: 0.00014321]
	Learning Rate: 0.000143206
	LOSS [training: 0.10631372497061009 | validation: 0.09877789082590833]
	TIME [epoch: 36.7 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10276268098408396		[learning rate: 0.00014264]
	Learning Rate: 0.000142637
	LOSS [training: 0.10276268098408396 | validation: 0.09396964172395017]
	TIME [epoch: 36.6 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10845746288192172		[learning rate: 0.00014207]
	Learning Rate: 0.000142069
	LOSS [training: 0.10845746288192172 | validation: 0.09109666872685263]
	TIME [epoch: 36.6 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10596617547261247		[learning rate: 0.0001415]
	Learning Rate: 0.000141504
	LOSS [training: 0.10596617547261247 | validation: 0.0995594420280819]
	TIME [epoch: 36.7 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10430733929794142		[learning rate: 0.00014094]
	Learning Rate: 0.000140941
	LOSS [training: 0.10430733929794142 | validation: 0.09398897185240003]
	TIME [epoch: 36.6 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10618926174629513		[learning rate: 0.00014038]
	Learning Rate: 0.000140381
	LOSS [training: 0.10618926174629513 | validation: 0.09424077195390534]
	TIME [epoch: 36.7 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11492839053933131		[learning rate: 0.00013982]
	Learning Rate: 0.000139822
	LOSS [training: 0.11492839053933131 | validation: 0.09198146714403466]
	TIME [epoch: 36.6 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10431508937250775		[learning rate: 0.00013927]
	Learning Rate: 0.000139266
	LOSS [training: 0.10431508937250775 | validation: 0.10004090001702517]
	TIME [epoch: 36.7 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.119092152799082		[learning rate: 0.00013871]
	Learning Rate: 0.000138712
	LOSS [training: 0.119092152799082 | validation: 0.09946393793112121]
	TIME [epoch: 36.7 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1010502518152096		[learning rate: 0.00013816]
	Learning Rate: 0.000138161
	LOSS [training: 0.1010502518152096 | validation: 0.09400793259678977]
	TIME [epoch: 36.6 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11729093155663728		[learning rate: 0.00013761]
	Learning Rate: 0.000137611
	LOSS [training: 0.11729093155663728 | validation: 0.10111755604868193]
	TIME [epoch: 36.6 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10838391501714423		[learning rate: 0.00013706]
	Learning Rate: 0.000137064
	LOSS [training: 0.10838391501714423 | validation: 0.08866595992099956]
	TIME [epoch: 36.7 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1028965138506835		[learning rate: 0.00013652]
	Learning Rate: 0.000136519
	LOSS [training: 0.1028965138506835 | validation: 0.09612857636347738]
	TIME [epoch: 36.6 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11253140335152041		[learning rate: 0.00013598]
	Learning Rate: 0.000135976
	LOSS [training: 0.11253140335152041 | validation: 0.09167198249567492]
	TIME [epoch: 36.6 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1084891017598361		[learning rate: 0.00013543]
	Learning Rate: 0.000135435
	LOSS [training: 0.1084891017598361 | validation: 0.09630600379198694]
	TIME [epoch: 36.6 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11237653487659248		[learning rate: 0.0001349]
	Learning Rate: 0.000134896
	LOSS [training: 0.11237653487659248 | validation: 0.0936893615817692]
	TIME [epoch: 36.6 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12256286959443502		[learning rate: 0.00013436]
	Learning Rate: 0.00013436
	LOSS [training: 0.12256286959443502 | validation: 0.09142358974740158]
	TIME [epoch: 36.7 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1059418195223033		[learning rate: 0.00013383]
	Learning Rate: 0.000133825
	LOSS [training: 0.1059418195223033 | validation: 0.09789996027030243]
	TIME [epoch: 36.6 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10892927207278459		[learning rate: 0.00013329]
	Learning Rate: 0.000133293
	LOSS [training: 0.10892927207278459 | validation: 0.09721239082946517]
	TIME [epoch: 36.7 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11403629012463308		[learning rate: 0.00013276]
	Learning Rate: 0.000132763
	LOSS [training: 0.11403629012463308 | validation: 0.09528348954889951]
	TIME [epoch: 36.7 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10613802401041926		[learning rate: 0.00013223]
	Learning Rate: 0.000132235
	LOSS [training: 0.10613802401041926 | validation: 0.09559163562972743]
	TIME [epoch: 36.7 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10590833071635586		[learning rate: 0.00013171]
	Learning Rate: 0.000131709
	LOSS [training: 0.10590833071635586 | validation: 0.08950279381140795]
	TIME [epoch: 36.7 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12160036350313162		[learning rate: 0.00013119]
	Learning Rate: 0.000131185
	LOSS [training: 0.12160036350313162 | validation: 0.09630210640294035]
	TIME [epoch: 36.6 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11945822295126361		[learning rate: 0.00013066]
	Learning Rate: 0.000130663
	LOSS [training: 0.11945822295126361 | validation: 0.0950238100171378]
	TIME [epoch: 36.7 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10783389300437912		[learning rate: 0.00013014]
	Learning Rate: 0.000130144
	LOSS [training: 0.10783389300437912 | validation: 0.10073540949601738]
	TIME [epoch: 36.6 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11456516415259507		[learning rate: 0.00012963]
	Learning Rate: 0.000129626
	LOSS [training: 0.11456516415259507 | validation: 0.100283939840529]
	TIME [epoch: 36.6 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10796467225583085		[learning rate: 0.00012911]
	Learning Rate: 0.000129111
	LOSS [training: 0.10796467225583085 | validation: 0.0970487990355993]
	TIME [epoch: 36.7 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10387966835723478		[learning rate: 0.0001286]
	Learning Rate: 0.000128597
	LOSS [training: 0.10387966835723478 | validation: 0.09656735927029794]
	TIME [epoch: 36.6 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11320014910254679		[learning rate: 0.00012809]
	Learning Rate: 0.000128086
	LOSS [training: 0.11320014910254679 | validation: 0.09159575054128448]
	TIME [epoch: 36.6 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11187758939400275		[learning rate: 0.00012758]
	Learning Rate: 0.000127576
	LOSS [training: 0.11187758939400275 | validation: 0.10219431979226226]
	TIME [epoch: 36.6 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10917264719747206		[learning rate: 0.00012707]
	Learning Rate: 0.000127069
	LOSS [training: 0.10917264719747206 | validation: 0.09288025789686263]
	TIME [epoch: 36.7 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11157634578755395		[learning rate: 0.00012656]
	Learning Rate: 0.000126563
	LOSS [training: 0.11157634578755395 | validation: 0.09155102428210564]
	TIME [epoch: 36.7 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.105258503802614		[learning rate: 0.00012606]
	Learning Rate: 0.00012606
	LOSS [training: 0.105258503802614 | validation: 0.09629767490731153]
	TIME [epoch: 36.6 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11148726702926605		[learning rate: 0.00012556]
	Learning Rate: 0.000125559
	LOSS [training: 0.11148726702926605 | validation: 0.0931235419535215]
	TIME [epoch: 36.6 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10665992842496852		[learning rate: 0.00012506]
	Learning Rate: 0.000125059
	LOSS [training: 0.10665992842496852 | validation: 0.0932825454376656]
	TIME [epoch: 36.6 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10983654562305557		[learning rate: 0.00012456]
	Learning Rate: 0.000124562
	LOSS [training: 0.10983654562305557 | validation: 0.09185245433748881]
	TIME [epoch: 36.6 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10814583119025332		[learning rate: 0.00012407]
	Learning Rate: 0.000124066
	LOSS [training: 0.10814583119025332 | validation: 0.09281804397677315]
	TIME [epoch: 36.6 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10380103696943979		[learning rate: 0.00012357]
	Learning Rate: 0.000123573
	LOSS [training: 0.10380103696943979 | validation: 0.09052291437877866]
	TIME [epoch: 36.6 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10219269444578795		[learning rate: 0.00012308]
	Learning Rate: 0.000123081
	LOSS [training: 0.10219269444578795 | validation: 0.0971211642469145]
	TIME [epoch: 36.6 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10505872733455923		[learning rate: 0.00012259]
	Learning Rate: 0.000122592
	LOSS [training: 0.10505872733455923 | validation: 0.09489041822466239]
	TIME [epoch: 36.6 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11814454838201367		[learning rate: 0.0001221]
	Learning Rate: 0.000122104
	LOSS [training: 0.11814454838201367 | validation: 0.09508017835455203]
	TIME [epoch: 36.6 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11558637200812287		[learning rate: 0.00012162]
	Learning Rate: 0.000121619
	LOSS [training: 0.11558637200812287 | validation: 0.09419700488955726]
	TIME [epoch: 36.7 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11119914288914308		[learning rate: 0.00012113]
	Learning Rate: 0.000121135
	LOSS [training: 0.11119914288914308 | validation: 0.09479595588607473]
	TIME [epoch: 36.6 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1080483283931684		[learning rate: 0.00012065]
	Learning Rate: 0.000120653
	LOSS [training: 0.1080483283931684 | validation: 0.09049740644107722]
	TIME [epoch: 36.6 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10796117070916608		[learning rate: 0.00012017]
	Learning Rate: 0.000120173
	LOSS [training: 0.10796117070916608 | validation: 0.08924260637734122]
	TIME [epoch: 36.6 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11896588025603205		[learning rate: 0.0001197]
	Learning Rate: 0.000119695
	LOSS [training: 0.11896588025603205 | validation: 0.1047022349149966]
	TIME [epoch: 36.6 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11296372540156213		[learning rate: 0.00011922]
	Learning Rate: 0.000119219
	LOSS [training: 0.11296372540156213 | validation: 0.09566300042376268]
	TIME [epoch: 36.6 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10777881643013809		[learning rate: 0.00011875]
	Learning Rate: 0.000118745
	LOSS [training: 0.10777881643013809 | validation: 0.09615713375782105]
	TIME [epoch: 36.7 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11209461088967447		[learning rate: 0.00011827]
	Learning Rate: 0.000118273
	LOSS [training: 0.11209461088967447 | validation: 0.08399960237242175]
	TIME [epoch: 36.6 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1089169868153441		[learning rate: 0.0001178]
	Learning Rate: 0.000117802
	LOSS [training: 0.1089169868153441 | validation: 0.09901211529640715]
	TIME [epoch: 36.6 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10728142019156849		[learning rate: 0.00011733]
	Learning Rate: 0.000117334
	LOSS [training: 0.10728142019156849 | validation: 0.0952893059200399]
	TIME [epoch: 36.6 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10114169059628722		[learning rate: 0.00011687]
	Learning Rate: 0.000116867
	LOSS [training: 0.10114169059628722 | validation: 0.09534609744903702]
	TIME [epoch: 36.6 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11000172303829975		[learning rate: 0.0001164]
	Learning Rate: 0.000116402
	LOSS [training: 0.11000172303829975 | validation: 0.09598368819683463]
	TIME [epoch: 36.6 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11339954629901995		[learning rate: 0.00011594]
	Learning Rate: 0.000115939
	LOSS [training: 0.11339954629901995 | validation: 0.09634749983248307]
	TIME [epoch: 36.6 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1139069444251727		[learning rate: 0.00011548]
	Learning Rate: 0.000115478
	LOSS [training: 0.1139069444251727 | validation: 0.08760656646073171]
	TIME [epoch: 36.6 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10395364032185314		[learning rate: 0.00011502]
	Learning Rate: 0.000115019
	LOSS [training: 0.10395364032185314 | validation: 0.09516073333809369]
	TIME [epoch: 36.7 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10994619642507956		[learning rate: 0.00011456]
	Learning Rate: 0.000114561
	LOSS [training: 0.10994619642507956 | validation: 0.09339455450975977]
	TIME [epoch: 36.6 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10860924410754118		[learning rate: 0.00011411]
	Learning Rate: 0.000114106
	LOSS [training: 0.10860924410754118 | validation: 0.10013853787001596]
	TIME [epoch: 36.6 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.09943840703076776		[learning rate: 0.00011365]
	Learning Rate: 0.000113652
	LOSS [training: 0.09943840703076776 | validation: 0.09636688371961057]
	TIME [epoch: 36.6 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.107938285930812		[learning rate: 0.0001132]
	Learning Rate: 0.0001132
	LOSS [training: 0.107938285930812 | validation: 0.08977283284091242]
	TIME [epoch: 36.7 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.121087673319513		[learning rate: 0.00011275]
	Learning Rate: 0.00011275
	LOSS [training: 0.121087673319513 | validation: 0.09892250805859812]
	TIME [epoch: 36.6 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10586685275500077		[learning rate: 0.0001123]
	Learning Rate: 0.000112301
	LOSS [training: 0.10586685275500077 | validation: 0.09650962332875032]
	TIME [epoch: 36.7 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11103023972002252		[learning rate: 0.00011185]
	Learning Rate: 0.000111855
	LOSS [training: 0.11103023972002252 | validation: 0.09096589724295948]
	TIME [epoch: 36.7 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10627303786346878		[learning rate: 0.00011141]
	Learning Rate: 0.00011141
	LOSS [training: 0.10627303786346878 | validation: 0.09516553188306853]
	TIME [epoch: 36.7 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1110549453812469		[learning rate: 0.00011097]
