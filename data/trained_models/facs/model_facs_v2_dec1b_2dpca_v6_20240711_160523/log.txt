Args:
Namespace(name='model_facs_v2_dec1b_2dpca_v6', outdir='out/model_training/model_facs_v2_dec1b_2dpca_v6', training_data='data/training_data/facs_v2/pca/dec1_fitonsubset/transition1_subset_epi_tr_ce_an_pc12/training', validation_data='data/training_data/facs_v2/pca/dec1_fitonsubset/transition1_subset_epi_tr_ce_an_pc12/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=10, batch_size=50, patience=200, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, quadratic_a=1.0, quadratic_b=1.0, ndims=2, nparams=2, nsigs=2, ncells=100, ncells_sample=100, model_do_sample=False, dt=0.005, dt_schedule='stepped', dt_schedule_bounds=[500, 1000, 1500], dt_schedule_scales=[0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=True, sigma=0.02, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', kernel='multiscale', bw_range=[0.2, 0.5, 0.9, 1.1, 1.3, 1.5, 2.0], optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 3741064795

Training model...

Saving initial model state to: out/model_training/model_facs_v2_dec1b_2dpca_v6_20240711_160523/states/model_facs_v2_dec1b_2dpca_v6_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.3460987364661852		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3460987364661852 | validation: 1.2528952636502446]
	TIME [epoch: 41.9 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v6_20240711_160523/states/model_facs_v2_dec1b_2dpca_v6_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.2418651796010294		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2418651796010294 | validation: 1.1301157581864922]
	TIME [epoch: 7.11 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v6_20240711_160523/states/model_facs_v2_dec1b_2dpca_v6_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.146532390683179		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.146532390683179 | validation: 1.120920613380661]
	TIME [epoch: 7.11 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v6_20240711_160523/states/model_facs_v2_dec1b_2dpca_v6_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.1098277619907473		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1098277619907473 | validation: 0.9868228617551799]
	TIME [epoch: 7.13 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v6_20240711_160523/states/model_facs_v2_dec1b_2dpca_v6_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.0696658047549548		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0696658047549548 | validation: 0.9347412495066786]
	TIME [epoch: 7.11 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v6_20240711_160523/states/model_facs_v2_dec1b_2dpca_v6_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.0095847999497183		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0095847999497183 | validation: 0.8161056142243156]
	TIME [epoch: 7.11 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v6_20240711_160523/states/model_facs_v2_dec1b_2dpca_v6_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.9369463327000853		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9369463327000853 | validation: 0.847706836030634]
	TIME [epoch: 7.1 sec]
EPOCH 8/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.8951705842975434		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8951705842975434 | validation: 0.722488489616491]
	TIME [epoch: 7.11 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v6_20240711_160523/states/model_facs_v2_dec1b_2dpca_v6_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.8638305925111628		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8638305925111628 | validation: 0.7260217314254723]
	TIME [epoch: 7.12 sec]
EPOCH 10/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.8596561737589143		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8596561737589143 | validation: 0.7424711919541427]
	TIME [epoch: 7.11 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.830826333241513		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.830826333241513 | validation: 0.7358360910297359]
	TIME [epoch: 7.1 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7798941495229944		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7798941495229944 | validation: 0.7730634252221226]
	TIME [epoch: 7.11 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7724362562963695		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7724362562963695 | validation: 0.648567092994143]
	TIME [epoch: 7.11 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v6_20240711_160523/states/model_facs_v2_dec1b_2dpca_v6_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.758307240018699		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.758307240018699 | validation: 0.7194045854798413]
	TIME [epoch: 7.45 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6692556310987385		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6692556310987385 | validation: 0.6647375662634221]
	TIME [epoch: 7.1 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6282521096140312		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6282521096140312 | validation: 0.5696905986165078]
	TIME [epoch: 7.11 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v6_20240711_160523/states/model_facs_v2_dec1b_2dpca_v6_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6393587412380577		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6393587412380577 | validation: 0.6984165897142548]
	TIME [epoch: 7.11 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5916291864474287		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5916291864474287 | validation: 0.6563640046273771]
	TIME [epoch: 7.12 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5430838250988296		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5430838250988296 | validation: 0.5550857328052233]
	TIME [epoch: 7.1 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v6_20240711_160523/states/model_facs_v2_dec1b_2dpca_v6_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5651135120590738		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5651135120590738 | validation: 0.5802443321950486]
	TIME [epoch: 7.11 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4734139132817746		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4734139132817746 | validation: 0.4707202279479966]
	TIME [epoch: 7.11 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v6_20240711_160523/states/model_facs_v2_dec1b_2dpca_v6_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5551271918261693		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5551271918261693 | validation: 0.5229918604020865]
	TIME [epoch: 7.1 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5496769427785511		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5496769427785511 | validation: 0.46059856881113886]
	TIME [epoch: 7.12 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v6_20240711_160523/states/model_facs_v2_dec1b_2dpca_v6_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.45149146559809633		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.45149146559809633 | validation: 0.5502301020096958]
	TIME [epoch: 7.1 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5235813096642341		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5235813096642341 | validation: 0.49141273501250093]
	TIME [epoch: 7.09 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4544571843690515		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4544571843690515 | validation: 0.4425749934422484]
	TIME [epoch: 7.1 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v6_20240711_160523/states/model_facs_v2_dec1b_2dpca_v6_26.pth
	Model improved!!!
EPOCH 27/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5171836566829638		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5171836566829638 | validation: 0.5898066569437238]
	TIME [epoch: 7.1 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5054193423833246		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5054193423833246 | validation: 0.4231665109983804]
	TIME [epoch: 7.13 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v6_20240711_160523/states/model_facs_v2_dec1b_2dpca_v6_28.pth
	Model improved!!!
EPOCH 29/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.46157504515962994		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.46157504515962994 | validation: 0.4605411704542937]
	TIME [epoch: 7.11 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4510074546282891		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4510074546282891 | validation: 0.4700692878610962]
	TIME [epoch: 7.11 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4665670040772886		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4665670040772886 | validation: 0.42986788113389085]
	TIME [epoch: 7.11 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.48696447848808305		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.48696447848808305 | validation: 0.45514142350135617]
	TIME [epoch: 7.11 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4588627687895001		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4588627687895001 | validation: 0.4215538751393419]
	TIME [epoch: 7.13 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v6_20240711_160523/states/model_facs_v2_dec1b_2dpca_v6_33.pth
	Model improved!!!
EPOCH 34/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4331996241394398		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4331996241394398 | validation: 0.4154245147865696]
	TIME [epoch: 7.11 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v6_20240711_160523/states/model_facs_v2_dec1b_2dpca_v6_34.pth
	Model improved!!!
EPOCH 35/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4212794535169359		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4212794535169359 | validation: 0.4057411243041524]
	TIME [epoch: 7.11 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v6_20240711_160523/states/model_facs_v2_dec1b_2dpca_v6_35.pth
	Model improved!!!
EPOCH 36/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4468221078410003		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4468221078410003 | validation: 0.5243904091749785]
	TIME [epoch: 7.11 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5039045867821446		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5039045867821446 | validation: 0.4525649216631754]
	TIME [epoch: 7.12 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4018795420500447		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4018795420500447 | validation: 0.42691690610763705]
	TIME [epoch: 7.13 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.44415775872517005		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.44415775872517005 | validation: 0.40769495640121073]
	TIME [epoch: 7.11 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4001842754970612		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4001842754970612 | validation: 0.3898008325718386]
	TIME [epoch: 7.12 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v6_20240711_160523/states/model_facs_v2_dec1b_2dpca_v6_40.pth
	Model improved!!!
EPOCH 41/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3932316470860099		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3932316470860099 | validation: 0.43269638951625733]
	TIME [epoch: 7.11 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.43843301490351466		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.43843301490351466 | validation: 0.5027817927470452]
	TIME [epoch: 7.12 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4442687778964045		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4442687778964045 | validation: 0.44130708971300053]
	TIME [epoch: 7.11 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.391856522283132		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.391856522283132 | validation: 0.4303198274757321]
	TIME [epoch: 7.1 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4239858771535668		[learning rate: 0.0099823]
	Learning Rate: 0.0099823
	LOSS [training: 0.4239858771535668 | validation: 0.4092197958691398]
	TIME [epoch: 7.1 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.39679286589457974		[learning rate: 0.0099426]
	Learning Rate: 0.0099426
	LOSS [training: 0.39679286589457974 | validation: 0.387400262928146]
	TIME [epoch: 7.11 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v6_20240711_160523/states/model_facs_v2_dec1b_2dpca_v6_46.pth
	Model improved!!!
EPOCH 47/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3764599979296016		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 0.3764599979296016 | validation: 0.3920093027224804]
	TIME [epoch: 7.12 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4351762725636355		[learning rate: 0.0098637]
	Learning Rate: 0.00986367
	LOSS [training: 0.4351762725636355 | validation: 0.41520647001245264]
	TIME [epoch: 7.11 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.39208253881161526		[learning rate: 0.0098244]
	Learning Rate: 0.00982444
	LOSS [training: 0.39208253881161526 | validation: 0.4827048217198275]
	TIME [epoch: 7.1 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.41009835958107127		[learning rate: 0.0097854]
	Learning Rate: 0.00978536
	LOSS [training: 0.41009835958107127 | validation: 0.3814157853664745]
	TIME [epoch: 7.09 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v6_20240711_160523/states/model_facs_v2_dec1b_2dpca_v6_50.pth
	Model improved!!!
EPOCH 51/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.390001412477466		[learning rate: 0.0097464]
	Learning Rate: 0.00974644
	LOSS [training: 0.390001412477466 | validation: 0.4098863607504913]
	TIME [epoch: 7.11 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.43928256320506054		[learning rate: 0.0097077]
	Learning Rate: 0.00970768
	LOSS [training: 0.43928256320506054 | validation: 0.369236303707489]
	TIME [epoch: 7.1 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v6_20240711_160523/states/model_facs_v2_dec1b_2dpca_v6_52.pth
	Model improved!!!
EPOCH 53/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.38190114593611224		[learning rate: 0.0096691]
	Learning Rate: 0.00966907
	LOSS [training: 0.38190114593611224 | validation: 0.38613784776149396]
	TIME [epoch: 7.12 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3943009760051078		[learning rate: 0.0096306]
	Learning Rate: 0.00963061
	LOSS [training: 0.3943009760051078 | validation: 0.39398222797575966]
	TIME [epoch: 7.11 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.392508878061568		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 0.392508878061568 | validation: 0.3592383750258068]
	TIME [epoch: 7.1 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v6_20240711_160523/states/model_facs_v2_dec1b_2dpca_v6_55.pth
	Model improved!!!
EPOCH 56/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4119629523344918		[learning rate: 0.0095542]
	Learning Rate: 0.00955415
	LOSS [training: 0.4119629523344918 | validation: 0.38425361948067704]
	TIME [epoch: 7.1 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.35771602087197046		[learning rate: 0.0095162]
	Learning Rate: 0.00951616
	LOSS [training: 0.35771602087197046 | validation: 0.35557338705596725]
	TIME [epoch: 7.11 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v6_20240711_160523/states/model_facs_v2_dec1b_2dpca_v6_57.pth
	Model improved!!!
EPOCH 58/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.38943845918030207		[learning rate: 0.0094783]
	Learning Rate: 0.00947831
	LOSS [training: 0.38943845918030207 | validation: 0.4954282371054178]
	TIME [epoch: 7.12 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.42513440804658764		[learning rate: 0.0094406]
	Learning Rate: 0.00944061
	LOSS [training: 0.42513440804658764 | validation: 0.3670531289043309]
	TIME [epoch: 7.11 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3913815240665046		[learning rate: 0.0094031]
	Learning Rate: 0.00940306
	LOSS [training: 0.3913815240665046 | validation: 0.40579096076033905]
	TIME [epoch: 7.11 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3782918692680116		[learning rate: 0.0093657]
	Learning Rate: 0.00936566
	LOSS [training: 0.3782918692680116 | validation: 0.3946120307985258]
	TIME [epoch: 7.11 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3752200555564463		[learning rate: 0.0093284]
	Learning Rate: 0.00932841
	LOSS [training: 0.3752200555564463 | validation: 0.35422573687083764]
	TIME [epoch: 7.12 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v6_20240711_160523/states/model_facs_v2_dec1b_2dpca_v6_62.pth
	Model improved!!!
EPOCH 63/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3817009838974578		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 0.3817009838974578 | validation: 0.3875389644851655]
	TIME [epoch: 7.11 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.37940879107138603		[learning rate: 0.0092544]
	Learning Rate: 0.00925435
	LOSS [training: 0.37940879107138603 | validation: 0.3674103069389193]
	TIME [epoch: 7.11 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.36803973569339526		[learning rate: 0.0092175]
	Learning Rate: 0.00921755
	LOSS [training: 0.36803973569339526 | validation: 0.3485167087127784]
	TIME [epoch: 7.11 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v6_20240711_160523/states/model_facs_v2_dec1b_2dpca_v6_65.pth
	Model improved!!!
EPOCH 66/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3714945038291296		[learning rate: 0.0091809]
	Learning Rate: 0.00918089
	LOSS [training: 0.3714945038291296 | validation: 0.4209159759660849]
	TIME [epoch: 7.11 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.39057877658279117		[learning rate: 0.0091444]
	Learning Rate: 0.00914437
	LOSS [training: 0.39057877658279117 | validation: 0.4319582591098494]
	TIME [epoch: 7.12 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3770760487518486		[learning rate: 0.009108]
	Learning Rate: 0.009108
	LOSS [training: 0.3770760487518486 | validation: 0.35852703153023646]
	TIME [epoch: 7.11 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3770632532105048		[learning rate: 0.0090718]
	Learning Rate: 0.00907178
	LOSS [training: 0.3770632532105048 | validation: 0.4248874780605747]
	TIME [epoch: 7.1 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.38699021320346344		[learning rate: 0.0090357]
	Learning Rate: 0.00903569
	LOSS [training: 0.38699021320346344 | validation: 0.39159275726161136]
	TIME [epoch: 7.11 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3411475902120195		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 0.3411475902120195 | validation: 0.44226011519204944]
	TIME [epoch: 7.1 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3747762628224465		[learning rate: 0.008964]
	Learning Rate: 0.00896396
	LOSS [training: 0.3747762628224465 | validation: 0.38850235696606916]
	TIME [epoch: 7.12 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3704899476359264		[learning rate: 0.0089283]
	Learning Rate: 0.00892831
	LOSS [training: 0.3704899476359264 | validation: 0.3584766027638821]
	TIME [epoch: 7.11 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3727538630441184		[learning rate: 0.0088928]
	Learning Rate: 0.0088928
	LOSS [training: 0.3727538630441184 | validation: 0.4094160032398638]
	TIME [epoch: 7.11 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3920291691683006		[learning rate: 0.0088574]
	Learning Rate: 0.00885743
	LOSS [training: 0.3920291691683006 | validation: 0.3672853825449851]
	TIME [epoch: 7.1 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3624566094918678		[learning rate: 0.0088222]
	Learning Rate: 0.0088222
	LOSS [training: 0.3624566094918678 | validation: 0.37670543822112756]
	TIME [epoch: 7.1 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.37484366615626097		[learning rate: 0.0087871]
	Learning Rate: 0.00878711
	LOSS [training: 0.37484366615626097 | validation: 0.3650171008066847]
	TIME [epoch: 7.13 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.350272930884139		[learning rate: 0.0087522]
	Learning Rate: 0.00875216
	LOSS [training: 0.350272930884139 | validation: 0.38493938997396826]
	TIME [epoch: 7.11 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.36103737522491475		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 0.36103737522491475 | validation: 0.3910927586253298]
	TIME [epoch: 7.11 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.37873062653580825		[learning rate: 0.0086827]
	Learning Rate: 0.00868268
	LOSS [training: 0.37873062653580825 | validation: 0.4023823217338364]
	TIME [epoch: 7.1 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.39107371989969786		[learning rate: 0.0086481]
	Learning Rate: 0.00864815
	LOSS [training: 0.39107371989969786 | validation: 0.34078115111732166]
	TIME [epoch: 7.1 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v6_20240711_160523/states/model_facs_v2_dec1b_2dpca_v6_81.pth
	Model improved!!!
EPOCH 82/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.35967329901422407		[learning rate: 0.0086138]
	Learning Rate: 0.00861375
	LOSS [training: 0.35967329901422407 | validation: 0.35474671969188]
	TIME [epoch: 7.11 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.35363217605746794		[learning rate: 0.0085795]
	Learning Rate: 0.00857949
	LOSS [training: 0.35363217605746794 | validation: 0.3600205314409455]
	TIME [epoch: 7.1 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.35319184061832976		[learning rate: 0.0085454]
	Learning Rate: 0.00854537
	LOSS [training: 0.35319184061832976 | validation: 0.3757647859888024]
	TIME [epoch: 7.1 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3768232505278997		[learning rate: 0.0085114]
	Learning Rate: 0.00851138
	LOSS [training: 0.3768232505278997 | validation: 0.4041630428249496]
	TIME [epoch: 7.11 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.37337808586039545		[learning rate: 0.0084775]
	Learning Rate: 0.00847753
	LOSS [training: 0.37337808586039545 | validation: 0.33008080746252405]
	TIME [epoch: 7.1 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v6_20240711_160523/states/model_facs_v2_dec1b_2dpca_v6_86.pth
	Model improved!!!
EPOCH 87/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.42435352319151115		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 0.42435352319151115 | validation: 0.42836812364839194]
	TIME [epoch: 7.13 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3866695129841921		[learning rate: 0.0084102]
	Learning Rate: 0.00841023
	LOSS [training: 0.3866695129841921 | validation: 0.34344035939828255]
	TIME [epoch: 7.11 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.37602245860156913		[learning rate: 0.0083768]
	Learning Rate: 0.00837678
	LOSS [training: 0.37602245860156913 | validation: 0.4722357467283637]
	TIME [epoch: 7.1 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.38383272597069057		[learning rate: 0.0083435]
	Learning Rate: 0.00834346
	LOSS [training: 0.38383272597069057 | validation: 0.40644645523039147]
	TIME [epoch: 7.11 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.37460668854495854		[learning rate: 0.0083103]
	Learning Rate: 0.00831027
	LOSS [training: 0.37460668854495854 | validation: 0.3654056326859646]
	TIME [epoch: 7.1 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.36113062004535273		[learning rate: 0.0082772]
	Learning Rate: 0.00827722
	LOSS [training: 0.36113062004535273 | validation: 0.35882552468359513]
	TIME [epoch: 7.12 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.35931290436345154		[learning rate: 0.0082443]
	Learning Rate: 0.0082443
	LOSS [training: 0.35931290436345154 | validation: 0.32966978353112564]
	TIME [epoch: 7.09 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v6_20240711_160523/states/model_facs_v2_dec1b_2dpca_v6_93.pth
	Model improved!!!
EPOCH 94/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.36577347629828905		[learning rate: 0.0082115]
	Learning Rate: 0.00821151
	LOSS [training: 0.36577347629828905 | validation: 0.3705634584512397]
	TIME [epoch: 7.1 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3459648605802141		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 0.3459648605802141 | validation: 0.4008726731025957]
	TIME [epoch: 7.09 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.36588991056260106		[learning rate: 0.0081463]
	Learning Rate: 0.00814632
	LOSS [training: 0.36588991056260106 | validation: 0.36082824488154125]
	TIME [epoch: 7.1 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.34839821775663343		[learning rate: 0.0081139]
	Learning Rate: 0.00811392
	LOSS [training: 0.34839821775663343 | validation: 0.36957586611976756]
	TIME [epoch: 7.13 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.38201761329685957		[learning rate: 0.0080816]
	Learning Rate: 0.00808165
	LOSS [training: 0.38201761329685957 | validation: 0.3681750754993053]
	TIME [epoch: 7.1 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.340835278272316		[learning rate: 0.0080495]
	Learning Rate: 0.00804951
	LOSS [training: 0.340835278272316 | validation: 0.3579475450089672]
	TIME [epoch: 7.09 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3509905034699376		[learning rate: 0.0080175]
	Learning Rate: 0.00801749
	LOSS [training: 0.3509905034699376 | validation: 0.35515610551345994]
	TIME [epoch: 7.1 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3425882595200611		[learning rate: 0.0079856]
	Learning Rate: 0.0079856
	LOSS [training: 0.3425882595200611 | validation: 0.39845079039991005]
	TIME [epoch: 7.1 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3527467534029731		[learning rate: 0.0079538]
	Learning Rate: 0.00795384
	LOSS [training: 0.3527467534029731 | validation: 0.332983625044235]
	TIME [epoch: 7.11 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3558357432431964		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 0.3558357432431964 | validation: 0.36269621231621463]
	TIME [epoch: 7.1 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.35247195492070527		[learning rate: 0.0078907]
	Learning Rate: 0.0078907
	LOSS [training: 0.35247195492070527 | validation: 0.3258739914637558]
	TIME [epoch: 7.1 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v6_20240711_160523/states/model_facs_v2_dec1b_2dpca_v6_104.pth
	Model improved!!!
EPOCH 105/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.33354658886901223		[learning rate: 0.0078593]
	Learning Rate: 0.00785931
	LOSS [training: 0.33354658886901223 | validation: 0.322160927658562]
	TIME [epoch: 7.1 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v6_20240711_160523/states/model_facs_v2_dec1b_2dpca_v6_105.pth
	Model improved!!!
EPOCH 106/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.37614775016450736		[learning rate: 0.0078281]
	Learning Rate: 0.00782805
	LOSS [training: 0.37614775016450736 | validation: 0.37309408778538466]
	TIME [epoch: 7.11 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3453027219335001		[learning rate: 0.0077969]
	Learning Rate: 0.00779692
	LOSS [training: 0.3453027219335001 | validation: 0.368870825480295]
	TIME [epoch: 7.12 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.34912698056262087		[learning rate: 0.0077659]
	Learning Rate: 0.00776591
	LOSS [training: 0.34912698056262087 | validation: 0.3552883541771775]
	TIME [epoch: 7.09 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.34509821658432044		[learning rate: 0.007735]
	Learning Rate: 0.00773502
	LOSS [training: 0.34509821658432044 | validation: 0.35229622530105525]
	TIME [epoch: 7.11 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3418064976347128		[learning rate: 0.0077043]
	Learning Rate: 0.00770426
	LOSS [training: 0.3418064976347128 | validation: 0.44958742809032615]
	TIME [epoch: 7.11 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4117464403854239		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 0.4117464403854239 | validation: 0.36479329054522475]
	TIME [epoch: 7.11 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3863457275748324		[learning rate: 0.0076431]
	Learning Rate: 0.00764309
	LOSS [training: 0.3863457275748324 | validation: 0.34476130239994296]
	TIME [epoch: 7.12 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.35668826304515927		[learning rate: 0.0076127]
	Learning Rate: 0.00761269
	LOSS [training: 0.35668826304515927 | validation: 0.3684420911356587]
	TIME [epoch: 7.11 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.35611777527752153		[learning rate: 0.0075824]
	Learning Rate: 0.00758242
	LOSS [training: 0.35611777527752153 | validation: 0.3826981414730706]
	TIME [epoch: 7.11 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.34045027694399743		[learning rate: 0.0075523]
	Learning Rate: 0.00755226
	LOSS [training: 0.34045027694399743 | validation: 0.3462076861622514]
	TIME [epoch: 7.11 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.35520506797703016		[learning rate: 0.0075222]
	Learning Rate: 0.00752222
	LOSS [training: 0.35520506797703016 | validation: 0.3489221323261407]
	TIME [epoch: 7.12 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.34548991468009277		[learning rate: 0.0074923]
	Learning Rate: 0.0074923
	LOSS [training: 0.34548991468009277 | validation: 0.38813048068740896]
	TIME [epoch: 7.12 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.35264626862630005		[learning rate: 0.0074625]
	Learning Rate: 0.0074625
	LOSS [training: 0.35264626862630005 | validation: 0.3661255775924498]
	TIME [epoch: 7.1 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.36112883246699307		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 0.36112883246699307 | validation: 0.3362004253715559]
	TIME [epoch: 7.1 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3809359191801879		[learning rate: 0.0074033]
	Learning Rate: 0.00740326
	LOSS [training: 0.3809359191801879 | validation: 0.34116303024993855]
	TIME [epoch: 7.11 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.36413561429976604		[learning rate: 0.0073738]
	Learning Rate: 0.00737382
	LOSS [training: 0.36413561429976604 | validation: 0.3678738653008155]
	TIME [epoch: 7.11 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3721001938856467		[learning rate: 0.0073445]
	Learning Rate: 0.00734449
	LOSS [training: 0.3721001938856467 | validation: 0.3816849330303275]
	TIME [epoch: 7.13 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3577501032948758		[learning rate: 0.0073153]
	Learning Rate: 0.00731528
	LOSS [training: 0.3577501032948758 | validation: 0.3307813044018003]
	TIME [epoch: 7.1 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3366098231697036		[learning rate: 0.0072862]
	Learning Rate: 0.00728618
	LOSS [training: 0.3366098231697036 | validation: 0.35213503011009967]
	TIME [epoch: 7.11 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3520342784491399		[learning rate: 0.0072572]
	Learning Rate: 0.0072572
	LOSS [training: 0.3520342784491399 | validation: 0.38746424673309277]
	TIME [epoch: 7.1 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3598493428493208		[learning rate: 0.0072283]
	Learning Rate: 0.00722834
	LOSS [training: 0.3598493428493208 | validation: 0.3919785627109239]
	TIME [epoch: 7.11 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3515114141836664		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 0.3515114141836664 | validation: 0.3205772785154958]
	TIME [epoch: 7.12 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v6_20240711_160523/states/model_facs_v2_dec1b_2dpca_v6_127.pth
	Model improved!!!
EPOCH 128/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3370733586816755		[learning rate: 0.007171]
	Learning Rate: 0.00717095
	LOSS [training: 0.3370733586816755 | validation: 0.39310595608227394]
	TIME [epoch: 7.14 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3643494622343104		[learning rate: 0.0071424]
	Learning Rate: 0.00714243
	LOSS [training: 0.3643494622343104 | validation: 0.37920059372010523]
	TIME [epoch: 7.11 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3455800567722053		[learning rate: 0.007114]
	Learning Rate: 0.00711403
	LOSS [training: 0.3455800567722053 | validation: 0.3310336685850223]
	TIME [epoch: 7.1 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.34102162221409127		[learning rate: 0.0070857]
	Learning Rate: 0.00708573
	LOSS [training: 0.34102162221409127 | validation: 0.33447759707428054]
	TIME [epoch: 7.1 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3423035768654896		[learning rate: 0.0070575]
	Learning Rate: 0.00705755
	LOSS [training: 0.3423035768654896 | validation: 0.4055387078162613]
	TIME [epoch: 7.12 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.36329943058080205		[learning rate: 0.0070295]
	Learning Rate: 0.00702948
	LOSS [training: 0.36329943058080205 | validation: 0.37321955758020076]
	TIME [epoch: 7.1 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3398049423566616		[learning rate: 0.0070015]
	Learning Rate: 0.00700152
	LOSS [training: 0.3398049423566616 | validation: 0.3389910165212626]
	TIME [epoch: 7.12 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3361627127066857		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 0.3361627127066857 | validation: 0.333400096775089]
	TIME [epoch: 7.11 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.34041980738738953		[learning rate: 0.0069459]
	Learning Rate: 0.00694594
	LOSS [training: 0.34041980738738953 | validation: 0.401797079304529]
	TIME [epoch: 7.11 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.33351267827167275		[learning rate: 0.0069183]
	Learning Rate: 0.00691831
	LOSS [training: 0.33351267827167275 | validation: 0.41857482708882543]
	TIME [epoch: 7.13 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.34564174976960405		[learning rate: 0.0068908]
	Learning Rate: 0.00689079
	LOSS [training: 0.34564174976960405 | validation: 0.32958683064091804]
	TIME [epoch: 7.11 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3355220073071668		[learning rate: 0.0068634]
	Learning Rate: 0.00686339
	LOSS [training: 0.3355220073071668 | validation: 0.3304341050087681]
	TIME [epoch: 7.11 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3458217260675554		[learning rate: 0.0068361]
	Learning Rate: 0.00683609
	LOSS [training: 0.3458217260675554 | validation: 0.35816784712992555]
	TIME [epoch: 7.11 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3568678985919398		[learning rate: 0.0068089]
	Learning Rate: 0.0068089
	LOSS [training: 0.3568678985919398 | validation: 0.3440759468417813]
	TIME [epoch: 7.11 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.31760386998836204		[learning rate: 0.0067818]
	Learning Rate: 0.00678182
	LOSS [training: 0.31760386998836204 | validation: 0.3276803366154817]
	TIME [epoch: 7.12 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3233539985430493		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 0.3233539985430493 | validation: 0.34920998749185383]
	TIME [epoch: 7.11 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.34399040295341954		[learning rate: 0.006728]
	Learning Rate: 0.00672798
	LOSS [training: 0.34399040295341954 | validation: 0.379907695033982]
	TIME [epoch: 7.11 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.33989013567851595		[learning rate: 0.0067012]
	Learning Rate: 0.00670122
	LOSS [training: 0.33989013567851595 | validation: 0.3844258372106243]
	TIME [epoch: 7.11 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.327212072191054		[learning rate: 0.0066746]
	Learning Rate: 0.00667457
	LOSS [training: 0.327212072191054 | validation: 0.3588346063313212]
	TIME [epoch: 7.11 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.31962353403823984		[learning rate: 0.006648]
	Learning Rate: 0.00664802
	LOSS [training: 0.31962353403823984 | validation: 0.38538583699708556]
	TIME [epoch: 7.13 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.34260071563771927		[learning rate: 0.0066216]
	Learning Rate: 0.00662158
	LOSS [training: 0.34260071563771927 | validation: 0.3391724854155998]
	TIME [epoch: 7.1 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3201018016719949		[learning rate: 0.0065952]
	Learning Rate: 0.00659524
	LOSS [training: 0.3201018016719949 | validation: 0.3950586582087251]
	TIME [epoch: 7.11 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4196228624899104		[learning rate: 0.006569]
	Learning Rate: 0.00656901
	LOSS [training: 0.4196228624899104 | validation: 0.34282891745825433]
	TIME [epoch: 7.11 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3348581814797034		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 0.3348581814797034 | validation: 0.3319483070504658]
	TIME [epoch: 7.11 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.36416239454906635		[learning rate: 0.0065169]
	Learning Rate: 0.00651686
	LOSS [training: 0.36416239454906635 | validation: 0.3616460129286951]
	TIME [epoch: 7.12 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.33951500402874846		[learning rate: 0.0064909]
	Learning Rate: 0.00649094
	LOSS [training: 0.33951500402874846 | validation: 0.3493889054761329]
	TIME [epoch: 7.11 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32464562034244976		[learning rate: 0.0064651]
	Learning Rate: 0.00646512
	LOSS [training: 0.32464562034244976 | validation: 0.35739266965870514]
	TIME [epoch: 7.11 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3235940157331616		[learning rate: 0.0064394]
	Learning Rate: 0.00643941
	LOSS [training: 0.3235940157331616 | validation: 0.3477714505873368]
	TIME [epoch: 7.11 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.34555280386261233		[learning rate: 0.0064138]
	Learning Rate: 0.0064138
	LOSS [training: 0.34555280386261233 | validation: 0.314125402607195]
	TIME [epoch: 7.1 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v6_20240711_160523/states/model_facs_v2_dec1b_2dpca_v6_156.pth
	Model improved!!!
EPOCH 157/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3629033114748636		[learning rate: 0.0063883]
	Learning Rate: 0.00638829
	LOSS [training: 0.3629033114748636 | validation: 0.3726570098072536]
	TIME [epoch: 7.12 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3312905101416701		[learning rate: 0.0063629]
	Learning Rate: 0.00636288
	LOSS [training: 0.3312905101416701 | validation: 0.34274264729901793]
	TIME [epoch: 7.11 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3505384456037792		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 0.3505384456037792 | validation: 0.32655527273283613]
	TIME [epoch: 7.12 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3291905474330462		[learning rate: 0.0063124]
	Learning Rate: 0.00631237
	LOSS [training: 0.3291905474330462 | validation: 0.35211599873606414]
	TIME [epoch: 7.1 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3194533608997012		[learning rate: 0.0062873]
	Learning Rate: 0.00628726
	LOSS [training: 0.3194533608997012 | validation: 0.3211614598505729]
	TIME [epoch: 7.11 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.33367174387620346		[learning rate: 0.0062623]
	Learning Rate: 0.00626226
	LOSS [training: 0.33367174387620346 | validation: 0.31140797733622333]
	TIME [epoch: 7.12 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v6_20240711_160523/states/model_facs_v2_dec1b_2dpca_v6_162.pth
	Model improved!!!
EPOCH 163/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32807880006608525		[learning rate: 0.0062373]
	Learning Rate: 0.00623735
	LOSS [training: 0.32807880006608525 | validation: 0.3317277455588824]
	TIME [epoch: 7.1 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32614601197527415		[learning rate: 0.0062125]
	Learning Rate: 0.00621254
	LOSS [training: 0.32614601197527415 | validation: 0.3182464345106216]
	TIME [epoch: 7.12 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3170004660687782		[learning rate: 0.0061878]
	Learning Rate: 0.00618783
	LOSS [training: 0.3170004660687782 | validation: 0.37080631604272096]
	TIME [epoch: 7.11 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.35455460355999585		[learning rate: 0.0061632]
	Learning Rate: 0.00616322
	LOSS [training: 0.35455460355999585 | validation: 0.4277826285038901]
	TIME [epoch: 7.11 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.37575568297148654		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 0.37575568297148654 | validation: 0.3583767114513614]
	TIME [epoch: 7.13 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32972732828055495		[learning rate: 0.0061143]
	Learning Rate: 0.00611429
	LOSS [training: 0.32972732828055495 | validation: 0.39056429898960554]
	TIME [epoch: 7.1 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3358347772147396		[learning rate: 0.00609]
	Learning Rate: 0.00608997
	LOSS [training: 0.3358347772147396 | validation: 0.3884432819222809]
	TIME [epoch: 7.1 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.35212061729862976		[learning rate: 0.0060658]
	Learning Rate: 0.00606575
	LOSS [training: 0.35212061729862976 | validation: 0.3418562735403874]
	TIME [epoch: 7.09 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3250300942048987		[learning rate: 0.0060416]
	Learning Rate: 0.00604163
	LOSS [training: 0.3250300942048987 | validation: 0.359741668152702]
	TIME [epoch: 7.11 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3279375788127115		[learning rate: 0.0060176]
	Learning Rate: 0.0060176
	LOSS [training: 0.3279375788127115 | validation: 0.3744780547106225]
	TIME [epoch: 7.13 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3171564003451264		[learning rate: 0.0059937]
	Learning Rate: 0.00599366
	LOSS [training: 0.3171564003451264 | validation: 0.3152826836299032]
	TIME [epoch: 7.11 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.31242153031412084		[learning rate: 0.0059698]
	Learning Rate: 0.00596982
	LOSS [training: 0.31242153031412084 | validation: 0.3190214989935884]
	TIME [epoch: 7.11 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.344530190990894		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 0.344530190990894 | validation: 0.356979856054242]
	TIME [epoch: 7.1 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3221832258665007		[learning rate: 0.0059224]
	Learning Rate: 0.00592243
	LOSS [training: 0.3221832258665007 | validation: 0.3052444984192759]
	TIME [epoch: 7.11 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v6_20240711_160523/states/model_facs_v2_dec1b_2dpca_v6_176.pth
	Model improved!!!
EPOCH 177/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32049270530562723		[learning rate: 0.0058989]
	Learning Rate: 0.00589888
	LOSS [training: 0.32049270530562723 | validation: 0.3400925610553513]
	TIME [epoch: 7.12 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3246734878039212		[learning rate: 0.0058754]
	Learning Rate: 0.00587541
	LOSS [training: 0.3246734878039212 | validation: 0.4097355596137476]
	TIME [epoch: 7.11 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3556122880480287		[learning rate: 0.005852]
	Learning Rate: 0.00585205
	LOSS [training: 0.3556122880480287 | validation: 0.3484181813935552]
	TIME [epoch: 7.12 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3267557849572158		[learning rate: 0.0058288]
	Learning Rate: 0.00582877
	LOSS [training: 0.3267557849572158 | validation: 0.36714155378102664]
	TIME [epoch: 7.11 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.33477243847674687		[learning rate: 0.0058056]
	Learning Rate: 0.00580559
	LOSS [training: 0.33477243847674687 | validation: 0.40092207614458564]
	TIME [epoch: 7.12 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32522289992241216		[learning rate: 0.0057825]
	Learning Rate: 0.0057825
	LOSS [training: 0.32522289992241216 | validation: 0.36854223658088525]
	TIME [epoch: 7.13 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3157510997183509		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 0.3157510997183509 | validation: 0.3490306590658433]
	TIME [epoch: 7.12 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32983100116822495		[learning rate: 0.0057366]
	Learning Rate: 0.00573659
	LOSS [training: 0.32983100116822495 | validation: 0.32378827833126544]
	TIME [epoch: 7.12 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3284141362517069		[learning rate: 0.0057138]
	Learning Rate: 0.00571377
	LOSS [training: 0.3284141362517069 | validation: 0.3461821422110072]
	TIME [epoch: 7.12 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3211445744168402		[learning rate: 0.005691]
	Learning Rate: 0.00569105
	LOSS [training: 0.3211445744168402 | validation: 0.32392972185337093]
	TIME [epoch: 7.11 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.35888191742938175		[learning rate: 0.0056684]
	Learning Rate: 0.00566841
	LOSS [training: 0.35888191742938175 | validation: 0.40960311933350607]
	TIME [epoch: 7.13 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3674380878294414		[learning rate: 0.0056459]
	Learning Rate: 0.00564587
	LOSS [training: 0.3674380878294414 | validation: 0.36497588147459215]
	TIME [epoch: 7.11 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3169364819902786		[learning rate: 0.0056234]
	Learning Rate: 0.00562341
	LOSS [training: 0.3169364819902786 | validation: 0.3220977387199716]
	TIME [epoch: 7.1 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3130893987129015		[learning rate: 0.005601]
	Learning Rate: 0.00560105
	LOSS [training: 0.3130893987129015 | validation: 0.3103291196496641]
	TIME [epoch: 7.12 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3541212715476586		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 0.3541212715476586 | validation: 1.0229323835573085]
	TIME [epoch: 7.12 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4645299260284156		[learning rate: 0.0055566]
	Learning Rate: 0.00555658
	LOSS [training: 0.4645299260284156 | validation: 0.38070857979333445]
	TIME [epoch: 7.13 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4851575413429791		[learning rate: 0.0055345]
	Learning Rate: 0.00553448
	LOSS [training: 0.4851575413429791 | validation: 0.44592439380810545]
	TIME [epoch: 7.12 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4123524226016133		[learning rate: 0.0055125]
	Learning Rate: 0.00551247
	LOSS [training: 0.4123524226016133 | validation: 0.6060466974736489]
	TIME [epoch: 7.11 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4557675674788109		[learning rate: 0.0054905]
	Learning Rate: 0.00549054
	LOSS [training: 0.4557675674788109 | validation: 0.3990416996066709]
	TIME [epoch: 7.11 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3793017243675133		[learning rate: 0.0054687]
	Learning Rate: 0.00546871
	LOSS [training: 0.3793017243675133 | validation: 0.34282320410124373]
	TIME [epoch: 7.11 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.36740266709769936		[learning rate: 0.005447]
	Learning Rate: 0.00544696
	LOSS [training: 0.36740266709769936 | validation: 0.3773946162204066]
	TIME [epoch: 7.13 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3548045325004107		[learning rate: 0.0054253]
	Learning Rate: 0.00542529
	LOSS [training: 0.3548045325004107 | validation: 0.44963479011572033]
	TIME [epoch: 7.12 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3726018887426031		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 0.3726018887426031 | validation: 0.3524726477606527]
	TIME [epoch: 7.11 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3047085798063494		[learning rate: 0.0053822]
	Learning Rate: 0.00538222
	LOSS [training: 0.3047085798063494 | validation: 0.34659516454434713]
	TIME [epoch: 7.12 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3164359111038426		[learning rate: 0.0053608]
	Learning Rate: 0.00536081
	LOSS [training: 0.3164359111038426 | validation: 0.3440705941653331]
	TIME [epoch: 7.11 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32737117682841704		[learning rate: 0.0053395]
	Learning Rate: 0.00533949
	LOSS [training: 0.32737117682841704 | validation: 0.351443188505647]
	TIME [epoch: 7.12 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.318090288372137		[learning rate: 0.0053183]
	Learning Rate: 0.00531826
	LOSS [training: 0.318090288372137 | validation: 0.3313234600916971]
	TIME [epoch: 7.11 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3150871338642509		[learning rate: 0.0052971]
	Learning Rate: 0.0052971
	LOSS [training: 0.3150871338642509 | validation: 0.32749106369624625]
	TIME [epoch: 7.12 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6136131601544538		[learning rate: 0.005276]
	Learning Rate: 0.00527604
	LOSS [training: 0.6136131601544538 | validation: 2.183703032267675]
	TIME [epoch: 7.12 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 9/9] avg loss: 3.9498492011339263		[learning rate: 0.0052551]
	Learning Rate: 0.00525505
	LOSS [training: 3.9498492011339263 | validation: 4.604861094639498]
	TIME [epoch: 7.12 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 9/9] avg loss: 3.6289066715631932		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 3.6289066715631932 | validation: 2.259184599130786]
	TIME [epoch: 7.14 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.8295737841114286		[learning rate: 0.0052133]
	Learning Rate: 0.00521333
	LOSS [training: 1.8295737841114286 | validation: 2.241086949891114]
	TIME [epoch: 7.12 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 9/9] avg loss: 2.97104731334876		[learning rate: 0.0051926]
	Learning Rate: 0.0051926
	LOSS [training: 2.97104731334876 | validation: 2.8652196846834097]
	TIME [epoch: 7.11 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 9/9] avg loss: 3.036094767192141		[learning rate: 0.0051719]
	Learning Rate: 0.00517194
	LOSS [training: 3.036094767192141 | validation: 2.402569327900011]
	TIME [epoch: 7.09 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 9/9] avg loss: 2.0655608313924247		[learning rate: 0.0051514]
	Learning Rate: 0.00515137
	LOSS [training: 2.0655608313924247 | validation: 1.790115209340621]
	TIME [epoch: 7.08 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.382832983789443		[learning rate: 0.0051309]
	Learning Rate: 0.00513089
	LOSS [training: 1.382832983789443 | validation: 1.0539187637136922]
	TIME [epoch: 7.09 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.2485995255040891		[learning rate: 0.0051105]
	Learning Rate: 0.00511048
	LOSS [training: 1.2485995255040891 | validation: 1.4845774154778102]
	TIME [epoch: 7.09 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.120499711257442		[learning rate: 0.0050902]
	Learning Rate: 0.00509015
	LOSS [training: 1.120499711257442 | validation: 1.2914567346034063]
	TIME [epoch: 7.09 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.2513304897949167		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 1.2513304897949167 | validation: 1.2049442361388438]
	TIME [epoch: 7.09 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.4263046806408128		[learning rate: 0.0050497]
	Learning Rate: 0.00504974
	LOSS [training: 1.4263046806408128 | validation: 1.8653522336632988]
	TIME [epoch: 7.09 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.493251219496391		[learning rate: 0.0050297]
	Learning Rate: 0.00502966
	LOSS [training: 1.493251219496391 | validation: 1.285761729883407]
	TIME [epoch: 7.11 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.3102682143688558		[learning rate: 0.0050097]
	Learning Rate: 0.00500965
	LOSS [training: 1.3102682143688558 | validation: 1.4415265298554283]
	TIME [epoch: 7.09 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.2443745079092645		[learning rate: 0.0049897]
	Learning Rate: 0.00498973
	LOSS [training: 1.2443745079092645 | validation: 1.2332329919801646]
	TIME [epoch: 7.1 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.3636111680357677		[learning rate: 0.0049699]
	Learning Rate: 0.00496988
	LOSS [training: 1.3636111680357677 | validation: 1.4582497640203775]
	TIME [epoch: 7.09 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.4416378595300903		[learning rate: 0.0049501]
	Learning Rate: 0.00495012
	LOSS [training: 1.4416378595300903 | validation: 1.4031963544958017]
	TIME [epoch: 7.1 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.2167491302340396		[learning rate: 0.0049304]
	Learning Rate: 0.00493043
	LOSS [training: 1.2167491302340396 | validation: 2.824685554873509]
	TIME [epoch: 7.1 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.6983881099863922		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 1.6983881099863922 | validation: 1.2275243979032513]
	TIME [epoch: 7.09 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.198562972086779		[learning rate: 0.0048913]
	Learning Rate: 0.00489129
	LOSS [training: 1.198562972086779 | validation: 1.299982492611248]
	TIME [epoch: 7.09 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.7510760128621752		[learning rate: 0.0048718]
	Learning Rate: 0.00487183
	LOSS [training: 1.7510760128621752 | validation: 2.280332104096705]
	TIME [epoch: 7.09 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 9/9] avg loss: 2.10993265416669		[learning rate: 0.0048525]
	Learning Rate: 0.00485245
	LOSS [training: 2.10993265416669 | validation: 2.213979526641016]
	TIME [epoch: 7.09 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 9/9] avg loss: 2.3557970945241546		[learning rate: 0.0048332]
	Learning Rate: 0.00483316
	LOSS [training: 2.3557970945241546 | validation: 2.428416825218157]
	TIME [epoch: 7.08 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 9/9] avg loss: 2.1767936116001447		[learning rate: 0.0048139]
	Learning Rate: 0.00481393
	LOSS [training: 2.1767936116001447 | validation: 1.3308121684872312]
	TIME [epoch: 7.07 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.1065219044299974		[learning rate: 0.0047948]
	Learning Rate: 0.00479479
	LOSS [training: 1.1065219044299974 | validation: 0.82480438844754]
	TIME [epoch: 7.07 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7705486417245003		[learning rate: 0.0047757]
	Learning Rate: 0.00477572
	LOSS [training: 0.7705486417245003 | validation: 0.6460665078221494]
	TIME [epoch: 7.06 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6429465745425942		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.6429465745425942 | validation: 0.8989783613060846]
	TIME [epoch: 7.07 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7066840107739527		[learning rate: 0.0047378]
	Learning Rate: 0.0047378
	LOSS [training: 0.7066840107739527 | validation: 0.6653645246144981]
	TIME [epoch: 7.08 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5842098475944559		[learning rate: 0.004719]
	Learning Rate: 0.00471896
	LOSS [training: 0.5842098475944559 | validation: 0.5967478234198476]
	TIME [epoch: 7.07 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5430986654750412		[learning rate: 0.0047002]
	Learning Rate: 0.00470019
	LOSS [training: 0.5430986654750412 | validation: 0.6380737663691927]
	TIME [epoch: 7.07 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5352068256078419		[learning rate: 0.0046815]
	Learning Rate: 0.0046815
	LOSS [training: 0.5352068256078419 | validation: 0.5635468090721487]
	TIME [epoch: 7.07 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5029435294124343		[learning rate: 0.0046629]
	Learning Rate: 0.00466288
	LOSS [training: 0.5029435294124343 | validation: 0.6248925361568921]
	TIME [epoch: 7.07 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.45864049010816693		[learning rate: 0.0046443]
	Learning Rate: 0.00464433
	LOSS [training: 0.45864049010816693 | validation: 0.4529977462183784]
	TIME [epoch: 7.09 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.42114161601993394		[learning rate: 0.0046259]
	Learning Rate: 0.00462586
	LOSS [training: 0.42114161601993394 | validation: 0.43265058477671187]
	TIME [epoch: 7.11 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.414653876444786		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 0.414653876444786 | validation: 0.43567880665680275]
	TIME [epoch: 7.1 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.42400611426459506		[learning rate: 0.0045891]
	Learning Rate: 0.00458913
	LOSS [training: 0.42400611426459506 | validation: 0.41380583780072777]
	TIME [epoch: 7.09 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.47608632519843447		[learning rate: 0.0045709]
	Learning Rate: 0.00457088
	LOSS [training: 0.47608632519843447 | validation: 0.5418878431798826]
	TIME [epoch: 7.09 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.43910794477062576		[learning rate: 0.0045527]
	Learning Rate: 0.0045527
	LOSS [training: 0.43910794477062576 | validation: 0.4252539723289768]
	TIME [epoch: 7.1 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4203920458570151		[learning rate: 0.0045346]
	Learning Rate: 0.00453459
	LOSS [training: 0.4203920458570151 | validation: 0.5053767009205121]
	TIME [epoch: 7.08 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4018844904879742		[learning rate: 0.0045166]
	Learning Rate: 0.00451656
	LOSS [training: 0.4018844904879742 | validation: 0.4335128517789391]
	TIME [epoch: 7.09 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4082827000125341		[learning rate: 0.0044986]
	Learning Rate: 0.0044986
	LOSS [training: 0.4082827000125341 | validation: 0.4173419126458522]
	TIME [epoch: 7.1 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.43133840101993676		[learning rate: 0.0044807]
	Learning Rate: 0.0044807
	LOSS [training: 0.43133840101993676 | validation: 0.4621212451074313]
	TIME [epoch: 7.08 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4034328245918555		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 0.4034328245918555 | validation: 0.40111117742653235]
	TIME [epoch: 7.08 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3867226872961172		[learning rate: 0.0044451]
	Learning Rate: 0.00444513
	LOSS [training: 0.3867226872961172 | validation: 0.4160429238423188]
	TIME [epoch: 7.08 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.36927858651158396		[learning rate: 0.0044275]
	Learning Rate: 0.00442745
	LOSS [training: 0.36927858651158396 | validation: 0.3465896992905204]
	TIME [epoch: 7.08 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3723393599033		[learning rate: 0.0044098]
	Learning Rate: 0.00440984
	LOSS [training: 0.3723393599033 | validation: 0.3462596830005052]
	TIME [epoch: 7.07 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4120939470100253		[learning rate: 0.0043923]
	Learning Rate: 0.0043923
	LOSS [training: 0.4120939470100253 | validation: 0.37773943509510777]
	TIME [epoch: 7.08 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.48804690687318913		[learning rate: 0.0043748]
	Learning Rate: 0.00437483
	LOSS [training: 0.48804690687318913 | validation: 1.6157962506271673]
	TIME [epoch: 7.08 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.3689852749961324		[learning rate: 0.0043574]
	Learning Rate: 0.00435743
	LOSS [training: 1.3689852749961324 | validation: 1.2809876181353956]
	TIME [epoch: 7.08 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.9064362028169626		[learning rate: 0.0043401]
	Learning Rate: 0.0043401
	LOSS [training: 0.9064362028169626 | validation: 0.5570051062014952]
	TIME [epoch: 7.07 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5191439722331702		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 0.5191439722331702 | validation: 0.43817755703492195]
	TIME [epoch: 7.07 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.41491201983058396		[learning rate: 0.0043056]
	Learning Rate: 0.00430565
	LOSS [training: 0.41491201983058396 | validation: 0.39700557742275555]
	TIME [epoch: 7.06 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.38508271203412664		[learning rate: 0.0042885]
	Learning Rate: 0.00428852
	LOSS [training: 0.38508271203412664 | validation: 0.34564947036501176]
	TIME [epoch: 7.08 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.35455032156590993		[learning rate: 0.0042715]
	Learning Rate: 0.00427147
	LOSS [training: 0.35455032156590993 | validation: 0.3557702898266481]
	TIME [epoch: 7.08 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3386674918206868		[learning rate: 0.0042545]
	Learning Rate: 0.00425448
	LOSS [training: 0.3386674918206868 | validation: 0.41872678111689837]
	TIME [epoch: 7.07 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3441813362516547		[learning rate: 0.0042376]
	Learning Rate: 0.00423756
	LOSS [training: 0.3441813362516547 | validation: 0.3364764494819691]
	TIME [epoch: 7.07 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.348238358730936		[learning rate: 0.0042207]
	Learning Rate: 0.0042207
	LOSS [training: 0.348238358730936 | validation: 0.33921581975229465]
	TIME [epoch: 7.07 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.41158102894222		[learning rate: 0.0042039]
	Learning Rate: 0.00420391
	LOSS [training: 0.41158102894222 | validation: 0.34118704947813655]
	TIME [epoch: 7.07 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4278318372026327		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 0.4278318372026327 | validation: 0.37158703934867915]
	TIME [epoch: 7.08 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.42606346765873704		[learning rate: 0.0041705]
	Learning Rate: 0.00417054
	LOSS [training: 0.42606346765873704 | validation: 0.3355912944910323]
	TIME [epoch: 7.07 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3535489105224297		[learning rate: 0.004154]
	Learning Rate: 0.00415395
	LOSS [training: 0.3535489105224297 | validation: 0.3330111595942439]
	TIME [epoch: 7.07 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3407431451691774		[learning rate: 0.0041374]
	Learning Rate: 0.00413743
	LOSS [training: 0.3407431451691774 | validation: 0.3182594805064022]
	TIME [epoch: 7.07 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.34414339945192746		[learning rate: 0.004121]
	Learning Rate: 0.00412098
	LOSS [training: 0.34414339945192746 | validation: 0.34421463524148416]
	TIME [epoch: 7.08 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.38996483455376274		[learning rate: 0.0041046]
	Learning Rate: 0.00410458
	LOSS [training: 0.38996483455376274 | validation: 0.3283963336121315]
	TIME [epoch: 7.08 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3870033498423698		[learning rate: 0.0040883]
	Learning Rate: 0.00408826
	LOSS [training: 0.3870033498423698 | validation: 0.4262832136253617]
	TIME [epoch: 7.06 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.40744685242989176		[learning rate: 0.004072]
	Learning Rate: 0.004072
	LOSS [training: 0.40744685242989176 | validation: 0.3770206003484037]
	TIME [epoch: 7.07 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3674723546748846		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.3674723546748846 | validation: 0.3507543676971184]
	TIME [epoch: 7.07 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.35036591715794363		[learning rate: 0.0040397]
	Learning Rate: 0.00403967
	LOSS [training: 0.35036591715794363 | validation: 0.33983447645588705]
	TIME [epoch: 7.07 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3376828398134519		[learning rate: 0.0040236]
	Learning Rate: 0.00402361
	LOSS [training: 0.3376828398134519 | validation: 0.3516779983027337]
	TIME [epoch: 7.08 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3940434242483774		[learning rate: 0.0040076]
	Learning Rate: 0.0040076
	LOSS [training: 0.3940434242483774 | validation: 0.38829287605296453]
	TIME [epoch: 7.07 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3924987960717467		[learning rate: 0.0039917]
	Learning Rate: 0.00399166
	LOSS [training: 0.3924987960717467 | validation: 0.3674686020539616]
	TIME [epoch: 7.07 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.36311778020156865		[learning rate: 0.0039758]
	Learning Rate: 0.00397579
	LOSS [training: 0.36311778020156865 | validation: 0.35860323290476426]
	TIME [epoch: 7.07 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.359335661279768		[learning rate: 0.00396]
	Learning Rate: 0.00395997
	LOSS [training: 0.359335661279768 | validation: 0.33074111895626535]
	TIME [epoch: 7.07 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3444016473560559		[learning rate: 0.0039442]
	Learning Rate: 0.00394422
	LOSS [training: 0.3444016473560559 | validation: 0.3418740754947881]
	TIME [epoch: 7.09 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.35808955157279726		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 0.35808955157279726 | validation: 0.3631826449476304]
	TIME [epoch: 7.07 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3696083633879888		[learning rate: 0.0039129]
	Learning Rate: 0.00391291
	LOSS [training: 0.3696083633879888 | validation: 0.33972162484984075]
	TIME [epoch: 7.06 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3525535188583668		[learning rate: 0.0038973]
	Learning Rate: 0.00389735
	LOSS [training: 0.3525535188583668 | validation: 0.3415007008542065]
	TIME [epoch: 7.07 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4029438498461797		[learning rate: 0.0038818]
	Learning Rate: 0.00388185
	LOSS [training: 0.4029438498461797 | validation: 0.38314920630703325]
	TIME [epoch: 7.07 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3478491753869808		[learning rate: 0.0038664]
	Learning Rate: 0.00386641
	LOSS [training: 0.3478491753869808 | validation: 0.3347671993441347]
	TIME [epoch: 7.09 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3431483078189383		[learning rate: 0.003851]
	Learning Rate: 0.00385103
	LOSS [training: 0.3431483078189383 | validation: 0.33224943403648743]
	TIME [epoch: 7.07 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3360794934642116		[learning rate: 0.0038357]
	Learning Rate: 0.00383571
	LOSS [training: 0.3360794934642116 | validation: 0.3292093052177518]
	TIME [epoch: 7.07 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.361359949277318		[learning rate: 0.0038205]
	Learning Rate: 0.00382046
	LOSS [training: 0.361359949277318 | validation: 0.3524712620658981]
	TIME [epoch: 7.06 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3445648099108042		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 0.3445648099108042 | validation: 0.32591159080239873]
	TIME [epoch: 7.07 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.34349050640973705		[learning rate: 0.0037901]
	Learning Rate: 0.00379013
	LOSS [training: 0.34349050640973705 | validation: 0.35780862066612085]
	TIME [epoch: 7.08 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.34431615726662085		[learning rate: 0.0037751]
	Learning Rate: 0.00377505
	LOSS [training: 0.34431615726662085 | validation: 0.3206115224054228]
	TIME [epoch: 7.06 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3382486382099318		[learning rate: 0.00376]
	Learning Rate: 0.00376004
	LOSS [training: 0.3382486382099318 | validation: 0.5350137130385828]
	TIME [epoch: 7.06 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3734424448132031		[learning rate: 0.0037451]
	Learning Rate: 0.00374508
	LOSS [training: 0.3734424448132031 | validation: 0.3664016887910755]
	TIME [epoch: 7.07 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5325955151262697		[learning rate: 0.0037302]
	Learning Rate: 0.00373019
	LOSS [training: 0.5325955151262697 | validation: 0.5314993148440113]
	TIME [epoch: 7.06 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.45191424331192565		[learning rate: 0.0037154]
	Learning Rate: 0.00371535
	LOSS [training: 0.45191424331192565 | validation: 0.39720249645417927]
	TIME [epoch: 7.08 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.36298457297624753		[learning rate: 0.0037006]
	Learning Rate: 0.00370058
	LOSS [training: 0.36298457297624753 | validation: 0.36289745671599394]
	TIME [epoch: 7.06 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3432579334013646		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 0.3432579334013646 | validation: 0.3519577119136964]
	TIME [epoch: 7.06 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.33964227178833234		[learning rate: 0.0036712]
	Learning Rate: 0.0036712
	LOSS [training: 0.33964227178833234 | validation: 0.3324209496124854]
	TIME [epoch: 7.06 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3257922583825701		[learning rate: 0.0036566]
	Learning Rate: 0.0036566
	LOSS [training: 0.3257922583825701 | validation: 0.3445121731454869]
	TIME [epoch: 7.06 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.33335567508440733		[learning rate: 0.0036421]
	Learning Rate: 0.00364205
	LOSS [training: 0.33335567508440733 | validation: 0.3229998488343954]
	TIME [epoch: 7.08 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32672792559286573		[learning rate: 0.0036276]
	Learning Rate: 0.00362757
	LOSS [training: 0.32672792559286573 | validation: 0.3832592739601622]
	TIME [epoch: 7.07 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3339906220070478		[learning rate: 0.0036131]
	Learning Rate: 0.00361314
	LOSS [training: 0.3339906220070478 | validation: 0.35692206103311697]
	TIME [epoch: 7.07 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.34007724832942493		[learning rate: 0.0035988]
	Learning Rate: 0.00359877
	LOSS [training: 0.34007724832942493 | validation: 0.35963327746033646]
	TIME [epoch: 7.07 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.37849705329162286		[learning rate: 0.0035845]
	Learning Rate: 0.00358445
	LOSS [training: 0.37849705329162286 | validation: 0.48719312534841197]
	TIME [epoch: 7.07 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6699334750889422		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 0.6699334750889422 | validation: 0.40821050733686715]
	TIME [epoch: 7.08 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3712867590978292		[learning rate: 0.003556]
	Learning Rate: 0.003556
	LOSS [training: 0.3712867590978292 | validation: 0.3527529241879558]
	TIME [epoch: 7.06 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3728268406005347		[learning rate: 0.0035419]
	Learning Rate: 0.00354185
	LOSS [training: 0.3728268406005347 | validation: 0.34101932608403807]
	TIME [epoch: 7.07 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.40119593891558764		[learning rate: 0.0035278]
	Learning Rate: 0.00352777
	LOSS [training: 0.40119593891558764 | validation: 0.4660142396235659]
	TIME [epoch: 7.07 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.38364919440839756		[learning rate: 0.0035137]
	Learning Rate: 0.00351374
	LOSS [training: 0.38364919440839756 | validation: 0.40346624965997935]
	TIME [epoch: 7.06 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3410935201581536		[learning rate: 0.0034998]
	Learning Rate: 0.00349976
	LOSS [training: 0.3410935201581536 | validation: 0.34195157962550515]
	TIME [epoch: 7.08 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3401734448834172		[learning rate: 0.0034858]
	Learning Rate: 0.00348584
	LOSS [training: 0.3401734448834172 | validation: 0.45727904910373096]
	TIME [epoch: 7.07 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.38126320761327326		[learning rate: 0.003472]
	Learning Rate: 0.00347198
	LOSS [training: 0.38126320761327326 | validation: 0.3564488068756523]
	TIME [epoch: 7.06 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3437899030223441		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.3437899030223441 | validation: 0.3452831893642625]
	TIME [epoch: 7.07 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.34036510949117943		[learning rate: 0.0034444]
	Learning Rate: 0.00344441
	LOSS [training: 0.34036510949117943 | validation: 0.3662477400620592]
	TIME [epoch: 7.06 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.33463215032317967		[learning rate: 0.0034307]
	Learning Rate: 0.00343071
	LOSS [training: 0.33463215032317967 | validation: 0.3770943513574937]
	TIME [epoch: 7.08 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3412266448043487		[learning rate: 0.0034171]
	Learning Rate: 0.00341707
	LOSS [training: 0.3412266448043487 | validation: 0.313723239836243]
	TIME [epoch: 7.07 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3216869018406308		[learning rate: 0.0034035]
	Learning Rate: 0.00340348
	LOSS [training: 0.3216869018406308 | validation: 0.34031739618317725]
	TIME [epoch: 7.07 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3265165455587353		[learning rate: 0.0033899]
	Learning Rate: 0.00338994
	LOSS [training: 0.3265165455587353 | validation: 0.34020418723745455]
	TIME [epoch: 7.06 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32651186587333014		[learning rate: 0.0033765]
	Learning Rate: 0.00337646
	LOSS [training: 0.32651186587333014 | validation: 0.32580108769095895]
	TIME [epoch: 7.07 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3182201916851266		[learning rate: 0.003363]
	Learning Rate: 0.00336303
	LOSS [training: 0.3182201916851266 | validation: 0.377241476508281]
	TIME [epoch: 7.08 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3340864487871869		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 0.3340864487871869 | validation: 0.37451035718820425]
	TIME [epoch: 7.07 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32324096843155214		[learning rate: 0.0033363]
	Learning Rate: 0.00333633
	LOSS [training: 0.32324096843155214 | validation: 0.2957167237513869]
	TIME [epoch: 7.07 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v6_20240711_160523/states/model_facs_v2_dec1b_2dpca_v6_320.pth
	Model improved!!!
EPOCH 321/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.31795230245574124		[learning rate: 0.0033231]
	Learning Rate: 0.00332306
	LOSS [training: 0.31795230245574124 | validation: 0.3083885795696514]
	TIME [epoch: 7.07 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3260382229252204		[learning rate: 0.0033098]
	Learning Rate: 0.00330985
	LOSS [training: 0.3260382229252204 | validation: 0.32058015661947464]
	TIME [epoch: 7.07 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3224481386363682		[learning rate: 0.0032967]
	Learning Rate: 0.00329668
	LOSS [training: 0.3224481386363682 | validation: 0.32547284250195674]
	TIME [epoch: 7.09 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32780865798067277		[learning rate: 0.0032836]
	Learning Rate: 0.00328357
	LOSS [training: 0.32780865798067277 | validation: 0.36836628421893824]
	TIME [epoch: 7.08 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.316520842867876		[learning rate: 0.0032705]
	Learning Rate: 0.00327051
	LOSS [training: 0.316520842867876 | validation: 0.30656293021437736]
	TIME [epoch: 7.07 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3087713266530273		[learning rate: 0.0032575]
	Learning Rate: 0.0032575
	LOSS [training: 0.3087713266530273 | validation: 0.3094989221802424]
	TIME [epoch: 7.07 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32139983232289837		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 0.32139983232289837 | validation: 0.40505944224637425]
	TIME [epoch: 7.07 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3286823176623635		[learning rate: 0.0032316]
	Learning Rate: 0.00323164
	LOSS [training: 0.3286823176623635 | validation: 0.34235160091752076]
	TIME [epoch: 7.09 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3240291098558174		[learning rate: 0.0032188]
	Learning Rate: 0.00321879
	LOSS [training: 0.3240291098558174 | validation: 0.32388925035064353]
	TIME [epoch: 7.07 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3070286028677324		[learning rate: 0.003206]
	Learning Rate: 0.00320599
	LOSS [training: 0.3070286028677324 | validation: 0.3155919858956913]
	TIME [epoch: 7.08 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.31146057662844373		[learning rate: 0.0031932]
	Learning Rate: 0.00319323
	LOSS [training: 0.31146057662844373 | validation: 0.31861913466917424]
	TIME [epoch: 7.07 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.30601286245246934		[learning rate: 0.0031805]
	Learning Rate: 0.00318053
	LOSS [training: 0.30601286245246934 | validation: 0.2993992709420648]
	TIME [epoch: 7.07 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3004119736596549		[learning rate: 0.0031679]
	Learning Rate: 0.00316788
	LOSS [training: 0.3004119736596549 | validation: 0.35587247711760395]
	TIME [epoch: 7.08 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.324623871252714		[learning rate: 0.0031553]
	Learning Rate: 0.00315528
	LOSS [training: 0.324623871252714 | validation: 0.33665518598529875]
	TIME [epoch: 7.07 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3121841355848946		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 0.3121841355848946 | validation: 0.3031848520705681]
	TIME [epoch: 7.07 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.305463692320186		[learning rate: 0.0031302]
	Learning Rate: 0.00313023
	LOSS [training: 0.305463692320186 | validation: 0.294006161329322]
	TIME [epoch: 7.07 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v6_20240711_160523/states/model_facs_v2_dec1b_2dpca_v6_336.pth
	Model improved!!!
EPOCH 337/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.30284148638257563		[learning rate: 0.0031178]
	Learning Rate: 0.00311779
	LOSS [training: 0.30284148638257563 | validation: 0.30926791393750397]
	TIME [epoch: 7.06 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3030727962454377		[learning rate: 0.0031054]
	Learning Rate: 0.00310538
	LOSS [training: 0.3030727962454377 | validation: 0.31406349820883933]
	TIME [epoch: 7.08 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3467951249925977		[learning rate: 0.003093]
	Learning Rate: 0.00309303
	LOSS [training: 0.3467951249925977 | validation: 0.3317348992104242]
	TIME [epoch: 7.07 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.907547488324475		[learning rate: 0.0030807]
	Learning Rate: 0.00308073
	LOSS [training: 0.907547488324475 | validation: 1.9682705100199889]
	TIME [epoch: 7.07 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.9646822485654332		[learning rate: 0.0030685]
	Learning Rate: 0.00306848
	LOSS [training: 1.9646822485654332 | validation: 1.2210044267942792]
	TIME [epoch: 7.07 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.614000289328438		[learning rate: 0.0030563]
	Learning Rate: 0.00305627
	LOSS [training: 1.614000289328438 | validation: 1.8538844808246764]
	TIME [epoch: 7.07 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 9/9] avg loss: 2.115080787140684		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 2.115080787140684 | validation: 2.64339060114967]
	TIME [epoch: 7.08 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 9/9] avg loss: 2.4729980876987034		[learning rate: 0.003032]
	Learning Rate: 0.00303201
	LOSS [training: 2.4729980876987034 | validation: 2.8260836086803836]
	TIME [epoch: 7.07 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 9/9] avg loss: 2.5303242009019886		[learning rate: 0.00302]
	Learning Rate: 0.00301995
	LOSS [training: 2.5303242009019886 | validation: 2.770255875873773]
	TIME [epoch: 7.07 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 9/9] avg loss: 3.0775928689447856		[learning rate: 0.0030079]
	Learning Rate: 0.00300794
	LOSS [training: 3.0775928689447856 | validation: 3.887743531070261]
	TIME [epoch: 7.07 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 9/9] avg loss: 3.88902230691148		[learning rate: 0.002996]
	Learning Rate: 0.00299598
	LOSS [training: 3.88902230691148 | validation: 4.047688815577809]
	TIME [epoch: 7.06 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 9/9] avg loss: 4.156228482268795		[learning rate: 0.0029841]
	Learning Rate: 0.00298406
	LOSS [training: 4.156228482268795 | validation: 4.638987503540949]
	TIME [epoch: 7.08 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 9/9] avg loss: 4.559010747875053		[learning rate: 0.0029722]
	Learning Rate: 0.00297219
	LOSS [training: 4.559010747875053 | validation: 4.540813421905993]
	TIME [epoch: 7.07 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 9/9] avg loss: 4.752392626565066		[learning rate: 0.0029604]
	Learning Rate: 0.00296037
	LOSS [training: 4.752392626565066 | validation: 4.957169945394456]
	TIME [epoch: 7.06 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 9/9] avg loss: 5.050712319943263		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 5.050712319943263 | validation: 5.050516872267399]
	TIME [epoch: 7.06 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 9/9] avg loss: 4.938745294002457		[learning rate: 0.0029369]
	Learning Rate: 0.00293687
	LOSS [training: 4.938745294002457 | validation: 4.763259944979327]
	TIME [epoch: 7.07 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 9/9] avg loss: 4.730004287382759		[learning rate: 0.0029252]
	Learning Rate: 0.00292519
	LOSS [training: 4.730004287382759 | validation: 4.621632125797969]
	TIME [epoch: 7.08 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 9/9] avg loss: 4.7061474543945465		[learning rate: 0.0029136]
	Learning Rate: 0.00291355
	LOSS [training: 4.7061474543945465 | validation: 4.903475438866208]
	TIME [epoch: 7.07 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 9/9] avg loss: 4.876300311326967		[learning rate: 0.002902]
	Learning Rate: 0.00290197
	LOSS [training: 4.876300311326967 | validation: 4.962236249247193]
	TIME [epoch: 7.07 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 9/9] avg loss: 5.16590792511016		[learning rate: 0.0028904]
	Learning Rate: 0.00289042
	LOSS [training: 5.16590792511016 | validation: 5.187242436945387]
	TIME [epoch: 7.07 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 9/9] avg loss: 5.028556384498437		[learning rate: 0.0028789]
	Learning Rate: 0.00287893
	LOSS [training: 5.028556384498437 | validation: 4.8629582798850155]
	TIME [epoch: 7.06 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 9/9] avg loss: 4.543430605259542		[learning rate: 0.0028675]
	Learning Rate: 0.00286748
	LOSS [training: 4.543430605259542 | validation: 4.288882217446755]
	TIME [epoch: 7.08 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 9/9] avg loss: 4.277790341588921		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 4.277790341588921 | validation: 4.19559576588738]
	TIME [epoch: 7.07 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 9/9] avg loss: 4.264465882344163		[learning rate: 0.0028447]
	Learning Rate: 0.00284471
	LOSS [training: 4.264465882344163 | validation: 4.152908973732652]
	TIME [epoch: 7.07 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 9/9] avg loss: 4.084188722483378		[learning rate: 0.0028334]
	Learning Rate: 0.0028334
	LOSS [training: 4.084188722483378 | validation: 3.911417866282469]
	TIME [epoch: 7.06 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 9/9] avg loss: 3.993648349358932		[learning rate: 0.0028221]
	Learning Rate: 0.00282213
	LOSS [training: 3.993648349358932 | validation: 3.7806276823431246]
	TIME [epoch: 7.06 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 9/9] avg loss: 3.7801385498147733		[learning rate: 0.0028109]
	Learning Rate: 0.00281091
	LOSS [training: 3.7801385498147733 | validation: 3.70533924776315]
	TIME [epoch: 7.08 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 9/9] avg loss: 3.8669992640294564		[learning rate: 0.0027997]
	Learning Rate: 0.00279973
	LOSS [training: 3.8669992640294564 | validation: 4.399055307173029]
	TIME [epoch: 7.07 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 9/9] avg loss: 4.572247256520551		[learning rate: 0.0027886]
	Learning Rate: 0.00278859
	LOSS [training: 4.572247256520551 | validation: 3.811326799805073]
	TIME [epoch: 7.06 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 9/9] avg loss: 4.064851448436028		[learning rate: 0.0027775]
	Learning Rate: 0.0027775
	LOSS [training: 4.064851448436028 | validation: 4.096126047232886]
	TIME [epoch: 7.07 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 9/9] avg loss: 4.220187165268538		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 4.220187165268538 | validation: 4.365533002886922]
	TIME [epoch: 7.07 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 9/9] avg loss: 4.368931805131655		[learning rate: 0.0027554]
	Learning Rate: 0.00275545
	LOSS [training: 4.368931805131655 | validation: 4.2840253618976805]
	TIME [epoch: 7.07 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 9/9] avg loss: 4.470899372169097		[learning rate: 0.0027445]
	Learning Rate: 0.00274449
	LOSS [training: 4.470899372169097 | validation: 3.713124653893659]
	TIME [epoch: 7.08 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 9/9] avg loss: 3.6489254717907005		[learning rate: 0.0027336]
	Learning Rate: 0.00273357
	LOSS [training: 3.6489254717907005 | validation: 3.301579112205066]
	TIME [epoch: 7.07 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 9/9] avg loss: 3.6038245297308333		[learning rate: 0.0027227]
	Learning Rate: 0.0027227
	LOSS [training: 3.6038245297308333 | validation: 3.5059020495816013]
	TIME [epoch: 7.07 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 9/9] avg loss: 4.165663488387004		[learning rate: 0.0027119]
	Learning Rate: 0.00271187
	LOSS [training: 4.165663488387004 | validation: 3.635471678757407]
	TIME [epoch: 7.07 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 9/9] avg loss: 3.5848639439443186		[learning rate: 0.0027011]
	Learning Rate: 0.00270109
	LOSS [training: 3.5848639439443186 | validation: 3.044514995477168]
	TIME [epoch: 7.08 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 9/9] avg loss: 3.0872266620318305		[learning rate: 0.0026903]
	Learning Rate: 0.00269034
	LOSS [training: 3.0872266620318305 | validation: 2.8414007851056953]
	TIME [epoch: 7.08 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 9/9] avg loss: 2.84984993669646		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 2.84984993669646 | validation: 2.760112433183182]
	TIME [epoch: 7.07 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 9/9] avg loss: 2.9658149623252776		[learning rate: 0.002669]
	Learning Rate: 0.00266899
	LOSS [training: 2.9658149623252776 | validation: 3.1312644369911835]
	TIME [epoch: 7.07 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 9/9] avg loss: 3.2366858292515204		[learning rate: 0.0026584]
	Learning Rate: 0.00265837
	LOSS [training: 3.2366858292515204 | validation: 3.156169312981257]
	TIME [epoch: 7.07 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 9/9] avg loss: 3.538045044121677		[learning rate: 0.0026478]
	Learning Rate: 0.0026478
	LOSS [training: 3.538045044121677 | validation: 3.529777367342585]
	TIME [epoch: 7.07 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 9/9] avg loss: 3.4266937521518783		[learning rate: 0.0026373]
	Learning Rate: 0.00263727
	LOSS [training: 3.4266937521518783 | validation: 3.0219425459056124]
	TIME [epoch: 7.08 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 9/9] avg loss: 3.120233547998133		[learning rate: 0.0026268]
	Learning Rate: 0.00262678
	LOSS [training: 3.120233547998133 | validation: 2.722329444343612]
	TIME [epoch: 7.07 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 9/9] avg loss: 2.8088696190620275		[learning rate: 0.0026163]
	Learning Rate: 0.00261633
	LOSS [training: 2.8088696190620275 | validation: 2.792373260065574]
	TIME [epoch: 7.07 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 9/9] avg loss: 2.9581256514621415		[learning rate: 0.0026059]
	Learning Rate: 0.00260592
	LOSS [training: 2.9581256514621415 | validation: 3.136866958945386]
	TIME [epoch: 7.07 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 9/9] avg loss: 3.3608043893431105		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 3.3608043893431105 | validation: 3.786818442177922]
	TIME [epoch: 7.07 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 9/9] avg loss: 4.414377321646476		[learning rate: 0.0025852]
	Learning Rate: 0.00258523
	LOSS [training: 4.414377321646476 | validation: 4.485984893271153]
	TIME [epoch: 7.08 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 9/9] avg loss: 4.590093561106154		[learning rate: 0.002575]
	Learning Rate: 0.00257495
	LOSS [training: 4.590093561106154 | validation: 3.9594728015771365]
	TIME [epoch: 7.07 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 9/9] avg loss: 4.302236480627901		[learning rate: 0.0025647]
	Learning Rate: 0.00256471
	LOSS [training: 4.302236480627901 | validation: 4.2957544751729335]
	TIME [epoch: 7.07 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 9/9] avg loss: 4.584529694971304		[learning rate: 0.0025545]
	Learning Rate: 0.00255451
	LOSS [training: 4.584529694971304 | validation: 4.816074006487588]
	TIME [epoch: 7.06 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 9/9] avg loss: 4.8848336010935425		[learning rate: 0.0025444]
	Learning Rate: 0.00254435
	LOSS [training: 4.8848336010935425 | validation: 4.905493460095309]
	TIME [epoch: 7.07 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 9/9] avg loss: 4.751453237693226		[learning rate: 0.0025342]
	Learning Rate: 0.00253423
	LOSS [training: 4.751453237693226 | validation: 4.4758692895251855]
	TIME [epoch: 7.08 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 9/9] avg loss: 4.391143407720048		[learning rate: 0.0025242]
	Learning Rate: 0.00252415
	LOSS [training: 4.391143407720048 | validation: 4.087928854987404]
	TIME [epoch: 7.06 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 9/9] avg loss: 4.366323041206937		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 4.366323041206937 | validation: 4.511418616805218]
	TIME [epoch: 7.06 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 9/9] avg loss: 4.819260611006422		[learning rate: 0.0025041]
	Learning Rate: 0.00250411
	LOSS [training: 4.819260611006422 | validation: 5.322540236934653]
	TIME [epoch: 7.06 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 9/9] avg loss: 5.2946845132773985		[learning rate: 0.0024942]
	Learning Rate: 0.00249415
	LOSS [training: 5.2946845132773985 | validation: 5.364980942280211]
	TIME [epoch: 7.06 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 9/9] avg loss: 5.415737530084673		[learning rate: 0.0024842]
	Learning Rate: 0.00248423
	LOSS [training: 5.415737530084673 | validation: 4.908875102455212]
	TIME [epoch: 7.08 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 9/9] avg loss: 5.004613048980482		[learning rate: 0.0024744]
	Learning Rate: 0.00247435
	LOSS [training: 5.004613048980482 | validation: 4.357440415813203]
	TIME [epoch: 7.06 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 9/9] avg loss: 4.168407571632497		[learning rate: 0.0024645]
	Learning Rate: 0.00246451
	LOSS [training: 4.168407571632497 | validation: 3.7264223280401367]
	TIME [epoch: 7.06 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 9/9] avg loss: 3.7315362167347965		[learning rate: 0.0024547]
	Learning Rate: 0.00245471
	LOSS [training: 3.7315362167347965 | validation: 3.59581842770388]
	TIME [epoch: 7.07 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 9/9] avg loss: 3.608128139460036		[learning rate: 0.0024449]
	Learning Rate: 0.00244495
	LOSS [training: 3.608128139460036 | validation: 3.1763031512653495]
	TIME [epoch: 7.06 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 9/9] avg loss: 3.7906430584985435		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 3.7906430584985435 | validation: 3.791454147942841]
	TIME [epoch: 7.08 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 9/9] avg loss: 4.117695175159399		[learning rate: 0.0024255]
	Learning Rate: 0.00242554
	LOSS [training: 4.117695175159399 | validation: 4.085707860030791]
	TIME [epoch: 7.06 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 9/9] avg loss: 4.864446782351507		[learning rate: 0.0024159]
	Learning Rate: 0.00241589
	LOSS [training: 4.864446782351507 | validation: 6.0271998538093055]
	TIME [epoch: 7.06 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 9/9] avg loss: 5.2575351437799		[learning rate: 0.0024063]
	Learning Rate: 0.00240628
	LOSS [training: 5.2575351437799 | validation: 5.407449441519317]
	TIME [epoch: 7.07 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 9/9] avg loss: 5.214081966963746		[learning rate: 0.0023967]
	Learning Rate: 0.00239671
	LOSS [training: 5.214081966963746 | validation: 5.153664570212268]
	TIME [epoch: 7.07 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 9/9] avg loss: 4.823893650880285		[learning rate: 0.0023872]
	Learning Rate: 0.00238718
	LOSS [training: 4.823893650880285 | validation: 4.753783090037106]
	TIME [epoch: 7.08 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 9/9] avg loss: 4.636587254551625		[learning rate: 0.0023777]
	Learning Rate: 0.00237768
	LOSS [training: 4.636587254551625 | validation: 3.8731155278333476]
	TIME [epoch: 7.06 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 9/9] avg loss: 3.724940220248857		[learning rate: 0.0023682]
	Learning Rate: 0.00236823
	LOSS [training: 3.724940220248857 | validation: 3.365909844978714]
	TIME [epoch: 7.06 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 9/9] avg loss: 3.496557283726284		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 3.496557283726284 | validation: 2.98025984875557]
	TIME [epoch: 7.06 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 9/9] avg loss: 3.1223921620074773		[learning rate: 0.0023494]
	Learning Rate: 0.00234942
	LOSS [training: 3.1223921620074773 | validation: 3.4831639852765]
	TIME [epoch: 7.06 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 9/9] avg loss: 3.1221554678999706		[learning rate: 0.0023401]
	Learning Rate: 0.00234008
	LOSS [training: 3.1221554678999706 | validation: 3.2884461664666604]
	TIME [epoch: 7.07 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 9/9] avg loss: 2.864436546375328		[learning rate: 0.0023308]
	Learning Rate: 0.00233077
	LOSS [training: 2.864436546375328 | validation: 3.009765252721911]
	TIME [epoch: 7.06 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 9/9] avg loss: 3.704136045755746		[learning rate: 0.0023215]
	Learning Rate: 0.0023215
	LOSS [training: 3.704136045755746 | validation: 4.55026690132295]
	TIME [epoch: 7.06 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 9/9] avg loss: 3.499591093670409		[learning rate: 0.0023123]
	Learning Rate: 0.00231227
	LOSS [training: 3.499591093670409 | validation: 2.9884946331393]
	TIME [epoch: 7.06 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 9/9] avg loss: 2.4076608572249594		[learning rate: 0.0023031]
	Learning Rate: 0.00230307
	LOSS [training: 2.4076608572249594 | validation: 1.8450955876593906]
	TIME [epoch: 7.06 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.5023977562254602		[learning rate: 0.0022939]
	Learning Rate: 0.00229391
	LOSS [training: 1.5023977562254602 | validation: 0.985193945453118]
	TIME [epoch: 7.08 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.9432600144673672		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 0.9432600144673672 | validation: 0.7965782772759755]
	TIME [epoch: 7.06 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.81209644808967		[learning rate: 0.0022757]
	Learning Rate: 0.0022757
	LOSS [training: 0.81209644808967 | validation: 0.7221933671468733]
	TIME [epoch: 7.06 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7634343513660053		[learning rate: 0.0022667]
	Learning Rate: 0.00226665
	LOSS [training: 0.7634343513660053 | validation: 0.6345555448543501]
	TIME [epoch: 7.06 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.595389261014756		[learning rate: 0.0022576]
	Learning Rate: 0.00225764
	LOSS [training: 0.595389261014756 | validation: 0.5219911030837581]
	TIME [epoch: 7.06 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5471303851100602		[learning rate: 0.0022487]
	Learning Rate: 0.00224866
	LOSS [training: 0.5471303851100602 | validation: 0.5252683222809861]
	TIME [epoch: 7.08 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5079591008705847		[learning rate: 0.0022397]
	Learning Rate: 0.00223971
	LOSS [training: 0.5079591008705847 | validation: 0.44856259767142087]
	TIME [epoch: 7.06 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4624705219443941		[learning rate: 0.0022308]
	Learning Rate: 0.0022308
	LOSS [training: 0.4624705219443941 | validation: 0.4167362670996108]
	TIME [epoch: 7.06 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4457047963249192		[learning rate: 0.0022219]
	Learning Rate: 0.00222193
	LOSS [training: 0.4457047963249192 | validation: 0.4802110056503529]
	TIME [epoch: 7.06 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.44811415815456346		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.44811415815456346 | validation: 0.4190727948009757]
	TIME [epoch: 7.06 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4031837073174991		[learning rate: 0.0022043]
	Learning Rate: 0.00220429
	LOSS [training: 0.4031837073174991 | validation: 0.38324695799721287]
	TIME [epoch: 7.08 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4607082086996806		[learning rate: 0.0021955]
	Learning Rate: 0.00219553
	LOSS [training: 0.4607082086996806 | validation: 0.40392461336334484]
	TIME [epoch: 7.07 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3842131304517723		[learning rate: 0.0021868]
	Learning Rate: 0.00218679
	LOSS [training: 0.3842131304517723 | validation: 0.39204466164645363]
	TIME [epoch: 7.06 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.38269723184416166		[learning rate: 0.0021781]
	Learning Rate: 0.0021781
	LOSS [training: 0.38269723184416166 | validation: 0.39820300039401674]
	TIME [epoch: 7.06 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.36467675761505153		[learning rate: 0.0021694]
	Learning Rate: 0.00216943
	LOSS [training: 0.36467675761505153 | validation: 0.363781111570732]
	TIME [epoch: 7.06 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3681001791465007		[learning rate: 0.0021608]
	Learning Rate: 0.0021608
	LOSS [training: 0.3681001791465007 | validation: 0.3402577770199294]
	TIME [epoch: 7.08 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.36317867153549854		[learning rate: 0.0021522]
	Learning Rate: 0.00215221
	LOSS [training: 0.36317867153549854 | validation: 0.3937623674269456]
	TIME [epoch: 7.07 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.35810025044813504		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.35810025044813504 | validation: 0.3454518818674194]
	TIME [epoch: 7.06 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.330361023225969		[learning rate: 0.0021351]
	Learning Rate: 0.00213512
	LOSS [training: 0.330361023225969 | validation: 0.3433083770609292]
	TIME [epoch: 7.06 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.33600493990567376		[learning rate: 0.0021266]
	Learning Rate: 0.00212663
	LOSS [training: 0.33600493990567376 | validation: 0.37140195648035446]
	TIME [epoch: 7.06 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3341536503379191		[learning rate: 0.0021182]
	Learning Rate: 0.00211817
	LOSS [training: 0.3341536503379191 | validation: 0.365231814355689]
	TIME [epoch: 7.08 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3345053775612321		[learning rate: 0.0021097]
	Learning Rate: 0.00210975
	LOSS [training: 0.3345053775612321 | validation: 0.32781752946055587]
	TIME [epoch: 7.07 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3255391550620532		[learning rate: 0.0021014]
	Learning Rate: 0.00210136
	LOSS [training: 0.3255391550620532 | validation: 0.36883239506353716]
	TIME [epoch: 7.06 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32676650980556554		[learning rate: 0.002093]
	Learning Rate: 0.002093
	LOSS [training: 0.32676650980556554 | validation: 0.33881792173262404]
	TIME [epoch: 7.07 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3185469884544985		[learning rate: 0.0020847]
	Learning Rate: 0.00208468
	LOSS [training: 0.3185469884544985 | validation: 0.3570168136833137]
	TIME [epoch: 7.07 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32768502983066516		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.32768502983066516 | validation: 0.37297877132679513]
	TIME [epoch: 7.08 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.33477823022156405		[learning rate: 0.0020681]
	Learning Rate: 0.00206813
	LOSS [training: 0.33477823022156405 | validation: 0.35614779724450163]
	TIME [epoch: 7.07 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.41044745148599604		[learning rate: 0.0020599]
	Learning Rate: 0.0020599
	LOSS [training: 0.41044745148599604 | validation: 0.39512891267143757]
	TIME [epoch: 7.06 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3865150061961651		[learning rate: 0.0020517]
	Learning Rate: 0.00205171
	LOSS [training: 0.3865150061961651 | validation: 0.34941021550572293]
	TIME [epoch: 7.06 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3371337899448921		[learning rate: 0.0020435]
	Learning Rate: 0.00204355
	LOSS [training: 0.3371337899448921 | validation: 0.3392870342873585]
	TIME [epoch: 7.06 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.33555373212387407		[learning rate: 0.0020354]
	Learning Rate: 0.00203542
	LOSS [training: 0.33555373212387407 | validation: 0.3376518998819399]
	TIME [epoch: 7.08 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3267526748220486		[learning rate: 0.0020273]
	Learning Rate: 0.00202732
	LOSS [training: 0.3267526748220486 | validation: 0.3334749126390525]
	TIME [epoch: 7.07 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.31953190630125783		[learning rate: 0.0020193]
	Learning Rate: 0.00201926
	LOSS [training: 0.31953190630125783 | validation: 0.3483136085053567]
	TIME [epoch: 7.06 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3442857369928378		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 0.3442857369928378 | validation: 0.34795564618173713]
	TIME [epoch: 7.06 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.31792141078806363		[learning rate: 0.0020032]
	Learning Rate: 0.00200323
	LOSS [training: 0.31792141078806363 | validation: 0.34665529770138576]
	TIME [epoch: 7.06 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.31522135702032145		[learning rate: 0.0019953]
	Learning Rate: 0.00199526
	LOSS [training: 0.31522135702032145 | validation: 0.3281586763220755]
	TIME [epoch: 7.08 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3156681206429669		[learning rate: 0.0019873]
	Learning Rate: 0.00198733
	LOSS [training: 0.3156681206429669 | validation: 0.3285203074670291]
	TIME [epoch: 7.07 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.31190448696078676		[learning rate: 0.0019794]
	Learning Rate: 0.00197942
	LOSS [training: 0.31190448696078676 | validation: 0.3325858046508464]
	TIME [epoch: 7.06 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3061848245362231		[learning rate: 0.0019715]
	Learning Rate: 0.00197155
	LOSS [training: 0.3061848245362231 | validation: 0.33670814329142207]
	TIME [epoch: 7.06 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3172860174863651		[learning rate: 0.0019637]
	Learning Rate: 0.00196371
	LOSS [training: 0.3172860174863651 | validation: 0.32925248074083757]
	TIME [epoch: 7.07 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3196582099060655		[learning rate: 0.0019559]
	Learning Rate: 0.0019559
	LOSS [training: 0.3196582099060655 | validation: 0.3464489606927574]
	TIME [epoch: 7.08 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.33517909737969986		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 0.33517909737969986 | validation: 0.3867751535429925]
	TIME [epoch: 7.07 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.34457521801530805		[learning rate: 0.0019404]
	Learning Rate: 0.00194037
	LOSS [training: 0.34457521801530805 | validation: 0.33856452941583326]
	TIME [epoch: 7.06 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.31482910599902336		[learning rate: 0.0019327]
	Learning Rate: 0.00193265
	LOSS [training: 0.31482910599902336 | validation: 0.34282229150843035]
	TIME [epoch: 7.07 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.33946744902181886		[learning rate: 0.001925]
	Learning Rate: 0.00192497
	LOSS [training: 0.33946744902181886 | validation: 0.34980572129416065]
	TIME [epoch: 7.06 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32603985398356605		[learning rate: 0.0019173]
	Learning Rate: 0.00191731
	LOSS [training: 0.32603985398356605 | validation: 0.3552146002761903]
	TIME [epoch: 7.08 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2944425702227449		[learning rate: 0.0019097]
	Learning Rate: 0.00190968
	LOSS [training: 0.2944425702227449 | validation: 0.33288020677311786]
	TIME [epoch: 7.07 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.30871105873985677		[learning rate: 0.0019021]
	Learning Rate: 0.00190209
	LOSS [training: 0.30871105873985677 | validation: 0.3235146175617776]
	TIME [epoch: 7.12 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.29633850795165717		[learning rate: 0.0018945]
	Learning Rate: 0.00189452
	LOSS [training: 0.29633850795165717 | validation: 0.332754748874497]
	TIME [epoch: 7.06 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.30312293989863676		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.30312293989863676 | validation: 0.3111440551092117]
	TIME [epoch: 7.06 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3426689609152517		[learning rate: 0.0018795]
	Learning Rate: 0.00187948
	LOSS [training: 0.3426689609152517 | validation: 0.3577317644611382]
	TIME [epoch: 7.07 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.43376841475386807		[learning rate: 0.001872]
	Learning Rate: 0.00187201
	LOSS [training: 0.43376841475386807 | validation: 0.4917216696788792]
	TIME [epoch: 7.07 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6385133238297688		[learning rate: 0.0018646]
	Learning Rate: 0.00186456
	LOSS [training: 0.6385133238297688 | validation: 0.7543669251889631]
	TIME [epoch: 7.06 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7216889304811782		[learning rate: 0.0018571]
	Learning Rate: 0.00185715
	LOSS [training: 0.7216889304811782 | validation: 0.5195940933602313]
	TIME [epoch: 7.06 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5609848308095728		[learning rate: 0.0018498]
	Learning Rate: 0.00184976
	LOSS [training: 0.5609848308095728 | validation: 0.5020728153607423]
	TIME [epoch: 7.06 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5601887668451799		[learning rate: 0.0018424]
	Learning Rate: 0.0018424
	LOSS [training: 0.5601887668451799 | validation: 0.567082855308174]
	TIME [epoch: 7.07 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6018396422058642		[learning rate: 0.0018351]
	Learning Rate: 0.00183508
	LOSS [training: 0.6018396422058642 | validation: 0.554067808662491]
	TIME [epoch: 7.07 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6233215633349696		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.6233215633349696 | validation: 0.6313309249591491]
	TIME [epoch: 7.06 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6315590456319928		[learning rate: 0.0018205]
	Learning Rate: 0.00182051
	LOSS [training: 0.6315590456319928 | validation: 0.6302494405289993]
	TIME [epoch: 7.06 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5968151602450377		[learning rate: 0.0018133]
	Learning Rate: 0.00181327
	LOSS [training: 0.5968151602450377 | validation: 0.5577526700078916]
	TIME [epoch: 7.06 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6095661944765884		[learning rate: 0.0018061]
	Learning Rate: 0.00180605
	LOSS [training: 0.6095661944765884 | validation: 0.6086721219777299]
	TIME [epoch: 7.06 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6591470955742804		[learning rate: 0.0017989]
	Learning Rate: 0.00179887
	LOSS [training: 0.6591470955742804 | validation: 0.4992170330907282]
	TIME [epoch: 7.07 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.46233859319884985		[learning rate: 0.0017917]
	Learning Rate: 0.00179172
	LOSS [training: 0.46233859319884985 | validation: 0.4061974631875843]
	TIME [epoch: 7.06 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.370628613340806		[learning rate: 0.0017846]
	Learning Rate: 0.00178459
	LOSS [training: 0.370628613340806 | validation: 0.36516648323469225]
	TIME [epoch: 7.07 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3541800724394374		[learning rate: 0.0017775]
	Learning Rate: 0.00177749
	LOSS [training: 0.3541800724394374 | validation: 0.35343265689416453]
	TIME [epoch: 7.06 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32495680377326086		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.32495680377326086 | validation: 0.333964112797734]
	TIME [epoch: 7.07 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3228203849947136		[learning rate: 0.0017634]
	Learning Rate: 0.00176338
	LOSS [training: 0.3228203849947136 | validation: 0.3281464480353566]
	TIME [epoch: 7.08 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3174928509219011		[learning rate: 0.0017564]
	Learning Rate: 0.00175637
	LOSS [training: 0.3174928509219011 | validation: 0.3712556070147066]
	TIME [epoch: 7.06 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.38630196882272183		[learning rate: 0.0017494]
	Learning Rate: 0.00174938
	LOSS [training: 0.38630196882272183 | validation: 0.42499290940988405]
	TIME [epoch: 7.06 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.45247676567546613		[learning rate: 0.0017424]
	Learning Rate: 0.00174242
	LOSS [training: 0.45247676567546613 | validation: 0.4457526690280538]
	TIME [epoch: 7.06 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.541454541835737		[learning rate: 0.0017355]
	Learning Rate: 0.00173549
	LOSS [training: 0.541454541835737 | validation: 0.503605460141061]
	TIME [epoch: 7.06 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7683382585596871		[learning rate: 0.0017286]
	Learning Rate: 0.00172859
	LOSS [training: 0.7683382585596871 | validation: 0.8333467210063461]
	TIME [epoch: 7.08 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7400310406766147		[learning rate: 0.0017217]
	Learning Rate: 0.00172172
	LOSS [training: 0.7400310406766147 | validation: 0.614867236129643]
	TIME [epoch: 7.06 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6227791565536561		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 0.6227791565536561 | validation: 0.6817053282574062]
	TIME [epoch: 7.07 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7829640831025009		[learning rate: 0.001708]
	Learning Rate: 0.00170805
	LOSS [training: 0.7829640831025009 | validation: 0.7114117648024612]
	TIME [epoch: 7.06 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.0156021797877024		[learning rate: 0.0017013]
	Learning Rate: 0.00170125
	LOSS [training: 1.0156021797877024 | validation: 1.6329368846399983]
	TIME [epoch: 7.06 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.888205322853779		[learning rate: 0.0016945]
	Learning Rate: 0.00169449
	LOSS [training: 1.888205322853779 | validation: 1.9421135452344533]
	TIME [epoch: 7.07 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 9/9] avg loss: 2.0286195526919304		[learning rate: 0.0016877]
	Learning Rate: 0.00168775
	LOSS [training: 2.0286195526919304 | validation: 1.7733223813284777]
	TIME [epoch: 7.06 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.7841849017974363		[learning rate: 0.001681]
	Learning Rate: 0.00168104
	LOSS [training: 1.7841849017974363 | validation: 1.039560494112281]
	TIME [epoch: 7.06 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.602331098516495		[learning rate: 0.0016743]
	Learning Rate: 0.00167435
	LOSS [training: 1.602331098516495 | validation: 1.8265850718050487]
	TIME [epoch: 7.06 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 9/9] avg loss: 2.676453231271586		[learning rate: 0.0016677]
	Learning Rate: 0.00166769
	LOSS [training: 2.676453231271586 | validation: 2.7517861764653304]
	TIME [epoch: 7.06 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 9/9] avg loss: 3.1132304945956273		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 3.1132304945956273 | validation: 3.2651875895785936]
	TIME [epoch: 7.07 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 9/9] avg loss: 3.3559445991097054		[learning rate: 0.0016545]
	Learning Rate: 0.00165445
	LOSS [training: 3.3559445991097054 | validation: 3.4162030197337763]
	TIME [epoch: 7.06 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 9/9] avg loss: 3.627422822338226		[learning rate: 0.0016479]
	Learning Rate: 0.00164787
	LOSS [training: 3.627422822338226 | validation: 3.4266031616655597]
	TIME [epoch: 7.06 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 9/9] avg loss: 3.5127866458502193		[learning rate: 0.0016413]
	Learning Rate: 0.00164132
	LOSS [training: 3.5127866458502193 | validation: 3.638333469590509]
	TIME [epoch: 7.05 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 9/9] avg loss: 3.6215464516864153		[learning rate: 0.0016348]
	Learning Rate: 0.00163479
	LOSS [training: 3.6215464516864153 | validation: 3.6180740696402696]
	TIME [epoch: 7.06 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 9/9] avg loss: 3.7245801762269446		[learning rate: 0.0016283]
	Learning Rate: 0.00162829
	LOSS [training: 3.7245801762269446 | validation: 4.071073821798486]
	TIME [epoch: 7.07 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 9/9] avg loss: 3.558575209153179		[learning rate: 0.0016218]
	Learning Rate: 0.00162181
	LOSS [training: 3.558575209153179 | validation: 2.9526682533429414]
	TIME [epoch: 37.3 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 9/9] avg loss: 3.327932808654142		[learning rate: 0.0016154]
	Learning Rate: 0.00161536
	LOSS [training: 3.327932808654142 | validation: 3.5143441204633916]
	TIME [epoch: 13.6 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 9/9] avg loss: 2.9917113076605446		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 2.9917113076605446 | validation: 1.4931121617572631]
	TIME [epoch: 13.5 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.090738020600847		[learning rate: 0.0016025]
	Learning Rate: 0.00160254
	LOSS [training: 1.090738020600847 | validation: 0.6656519540737593]
	TIME [epoch: 13.6 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.604614975133528		[learning rate: 0.0015962]
	Learning Rate: 0.00159616
	LOSS [training: 0.604614975133528 | validation: 0.42335762608059646]
	TIME [epoch: 13.6 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3994988849370607		[learning rate: 0.0015898]
	Learning Rate: 0.00158981
	LOSS [training: 0.3994988849370607 | validation: 0.34591144099170407]
	TIME [epoch: 13.5 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3857259780281368		[learning rate: 0.0015835]
	Learning Rate: 0.00158349
	LOSS [training: 0.3857259780281368 | validation: 0.3423108479782523]
	TIME [epoch: 13.6 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.37853362692013587		[learning rate: 0.0015772]
	Learning Rate: 0.00157719
	LOSS [training: 0.37853362692013587 | validation: 0.3380337272768664]
	TIME [epoch: 13.5 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.35304314252110447		[learning rate: 0.0015709]
	Learning Rate: 0.00157092
	LOSS [training: 0.35304314252110447 | validation: 0.35037618467303583]
	TIME [epoch: 13.5 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3747270790018341		[learning rate: 0.0015647]
	Learning Rate: 0.00156467
	LOSS [training: 0.3747270790018341 | validation: 0.33228526308398565]
	TIME [epoch: 13.6 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.33284612689136905		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.33284612689136905 | validation: 0.32390882440683233]
	TIME [epoch: 13.5 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.33975093245084625		[learning rate: 0.0015522]
	Learning Rate: 0.00155225
	LOSS [training: 0.33975093245084625 | validation: 0.33202283492694684]
	TIME [epoch: 13.5 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32251175963099427		[learning rate: 0.0015461]
	Learning Rate: 0.00154608
	LOSS [training: 0.32251175963099427 | validation: 0.34450686227082417]
	TIME [epoch: 13.6 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.43088544638620024		[learning rate: 0.0015399]
	Learning Rate: 0.00153993
	LOSS [training: 0.43088544638620024 | validation: 0.45399149840440733]
	TIME [epoch: 13.5 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.38040943138222966		[learning rate: 0.0015338]
	Learning Rate: 0.0015338
	LOSS [training: 0.38040943138222966 | validation: 0.369149655892817]
	TIME [epoch: 13.6 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3573872613228311		[learning rate: 0.0015277]
	Learning Rate: 0.0015277
	LOSS [training: 0.3573872613228311 | validation: 0.3515254633494911]
	TIME [epoch: 13.5 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.36341091780493096		[learning rate: 0.0015216]
	Learning Rate: 0.00152163
	LOSS [training: 0.36341091780493096 | validation: 0.3452911629762063]
	TIME [epoch: 13.5 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3866766906943028		[learning rate: 0.0015156]
	Learning Rate: 0.00151557
	LOSS [training: 0.3866766906943028 | validation: 0.4240303315244763]
	TIME [epoch: 13.6 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4544409817369108		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.4544409817369108 | validation: 0.38093988824378566]
	TIME [epoch: 13.5 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3823887367965294		[learning rate: 0.0015035]
	Learning Rate: 0.00150354
	LOSS [training: 0.3823887367965294 | validation: 0.38855181357501983]
	TIME [epoch: 13.5 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4532965118311785		[learning rate: 0.0014976]
	Learning Rate: 0.00149756
	LOSS [training: 0.4532965118311785 | validation: 0.4795478025718709]
	TIME [epoch: 13.6 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4626259420425243		[learning rate: 0.0014916]
	Learning Rate: 0.00149161
	LOSS [training: 0.4626259420425243 | validation: 0.5024642048748122]
	TIME [epoch: 13.5 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.8507404294115939		[learning rate: 0.0014857]
	Learning Rate: 0.00148567
	LOSS [training: 0.8507404294115939 | validation: 0.8577129625337475]
	TIME [epoch: 13.5 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.0984704091116118		[learning rate: 0.0014798]
	Learning Rate: 0.00147976
	LOSS [training: 1.0984704091116118 | validation: 1.2395374525262293]
	TIME [epoch: 13.6 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.5893428250075952		[learning rate: 0.0014739]
	Learning Rate: 0.00147388
	LOSS [training: 1.5893428250075952 | validation: 1.5013838867171225]
	TIME [epoch: 13.5 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.2842565369579255		[learning rate: 0.001468]
	Learning Rate: 0.00146802
	LOSS [training: 1.2842565369579255 | validation: 1.0215758897060856]
	TIME [epoch: 13.5 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7726579049361224		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.7726579049361224 | validation: 0.47635132768603244]
	TIME [epoch: 13.6 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4405683411539159		[learning rate: 0.0014564]
	Learning Rate: 0.00145636
	LOSS [training: 0.4405683411539159 | validation: 0.45753023015391114]
	TIME [epoch: 13.5 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4062526687360824		[learning rate: 0.0014506]
	Learning Rate: 0.00145057
	LOSS [training: 0.4062526687360824 | validation: 0.38448931328275315]
	TIME [epoch: 13.5 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4372043458652462		[learning rate: 0.0014448]
	Learning Rate: 0.0014448
	LOSS [training: 0.4372043458652462 | validation: 0.4110215618010777]
	TIME [epoch: 13.6 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.384911158432505		[learning rate: 0.0014391]
	Learning Rate: 0.00143905
	LOSS [training: 0.384911158432505 | validation: 0.3849143474495834]
	TIME [epoch: 13.5 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.37408695828159155		[learning rate: 0.0014333]
	Learning Rate: 0.00143333
	LOSS [training: 0.37408695828159155 | validation: 0.36941399213262394]
	TIME [epoch: 13.5 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3739454532526843		[learning rate: 0.0014276]
	Learning Rate: 0.00142763
	LOSS [training: 0.3739454532526843 | validation: 0.38402708999544133]
	TIME [epoch: 13.6 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.35881526632743876		[learning rate: 0.001422]
	Learning Rate: 0.00142195
	LOSS [training: 0.35881526632743876 | validation: 0.3895977189134162]
	TIME [epoch: 13.5 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.35913090143787335		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.35913090143787335 | validation: 0.35246918516411807]
	TIME [epoch: 13.6 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3515839451494866		[learning rate: 0.0014107]
	Learning Rate: 0.00141066
	LOSS [training: 0.3515839451494866 | validation: 0.35130432767597397]
	TIME [epoch: 13.5 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.33667812755826204		[learning rate: 0.0014051]
	Learning Rate: 0.00140505
	LOSS [training: 0.33667812755826204 | validation: 0.33636557240205134]
	TIME [epoch: 13.5 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v6_20240711_160523/states/model_facs_v2_dec1b_2dpca_v6_537.pth
Halted early. No improvement in validation loss for 200 epochs.
Finished training in 4143.843 seconds.
