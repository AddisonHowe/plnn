Args:
Namespace(name='model_facs_v2_dec2b_2dpca_v11', outdir='out/model_training/model_facs_v2_dec2b_2dpca_v11', training_data='data/training_data/facs_v2/pca/dec2_fitonsubset/transition2_subset_ce_pn_m_pc12/training', validation_data='data/training_data/facs_v2/pca/dec2_fitonsubset/transition2_subset_ce_pn_m_pc12/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=10, batch_size=50, patience=200, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, quadratic_a=1.0, quadratic_b=1.0, ndims=2, nparams=2, nsigs=2, ncells=400, ncells_sample=400, model_do_sample=False, dt=0.005, dt_schedule='stepped', dt_schedule_bounds=[500, 1000, 1500], dt_schedule_scales=[0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=True, sigma=0.8, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', kernel='multiscale', bw_range=[0.2, 0.5, 0.9, 1.1, 1.3, 1.5, 2.0], optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 854571674

Training model...

Saving initial model state to: out/model_training/model_facs_v2_dec2b_2dpca_v11_20240712_140902/states/model_facs_v2_dec2b_2dpca_v11_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6033382881441258		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6033382881441258 | validation: 0.6969489637313708]
	TIME [epoch: 35.6 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v11_20240712_140902/states/model_facs_v2_dec2b_2dpca_v11_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.49094911604174757		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.49094911604174757 | validation: 0.6288487240043532]
	TIME [epoch: 5.89 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v11_20240712_140902/states/model_facs_v2_dec2b_2dpca_v11_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46272395877190736		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.46272395877190736 | validation: 0.6125592354549934]
	TIME [epoch: 5.9 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v11_20240712_140902/states/model_facs_v2_dec2b_2dpca_v11_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4559335714093547		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4559335714093547 | validation: 0.6032387554616696]
	TIME [epoch: 5.89 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v11_20240712_140902/states/model_facs_v2_dec2b_2dpca_v11_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4153055480676489		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4153055480676489 | validation: 0.5414838951505148]
	TIME [epoch: 5.9 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v11_20240712_140902/states/model_facs_v2_dec2b_2dpca_v11_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.393731869206043		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.393731869206043 | validation: 0.5537849769702498]
	TIME [epoch: 5.9 sec]
EPOCH 7/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3794548719328549		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3794548719328549 | validation: 0.49401703345678066]
	TIME [epoch: 5.89 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v11_20240712_140902/states/model_facs_v2_dec2b_2dpca_v11_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33094568008821523		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.33094568008821523 | validation: 0.4848284990711019]
	TIME [epoch: 5.88 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v11_20240712_140902/states/model_facs_v2_dec2b_2dpca_v11_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34402084520102305		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.34402084520102305 | validation: 0.47764826174939523]
	TIME [epoch: 5.91 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v11_20240712_140902/states/model_facs_v2_dec2b_2dpca_v11_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30745748561972286		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.30745748561972286 | validation: 0.47449032862006757]
	TIME [epoch: 5.9 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v11_20240712_140902/states/model_facs_v2_dec2b_2dpca_v11_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3518345591610367		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3518345591610367 | validation: 0.5140942101039109]
	TIME [epoch: 5.91 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32142489765591126		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.32142489765591126 | validation: 0.4264286349785969]
	TIME [epoch: 5.89 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v11_20240712_140902/states/model_facs_v2_dec2b_2dpca_v11_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3228317391318826		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3228317391318826 | validation: 0.4468623882701349]
	TIME [epoch: 5.9 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2950355575927336		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2950355575927336 | validation: 0.4546200641704815]
	TIME [epoch: 5.9 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31245667517022835		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.31245667517022835 | validation: 0.43827860913785327]
	TIME [epoch: 5.89 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29924824011138856		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.29924824011138856 | validation: 0.4807721775374816]
	TIME [epoch: 5.89 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2845843898350255		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2845843898350255 | validation: 0.4082287600554062]
	TIME [epoch: 5.89 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v11_20240712_140902/states/model_facs_v2_dec2b_2dpca_v11_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3064152817748537		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3064152817748537 | validation: 0.4604812799410852]
	TIME [epoch: 5.87 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29526651017288535		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.29526651017288535 | validation: 0.4297264394945366]
	TIME [epoch: 5.89 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2807169244706637		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2807169244706637 | validation: 0.42339709057671215]
	TIME [epoch: 5.89 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3058467867487614		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3058467867487614 | validation: 0.48414927720301193]
	TIME [epoch: 5.91 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2955326702363029		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2955326702363029 | validation: 0.41290473846315034]
	TIME [epoch: 5.9 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27452078665398616		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.27452078665398616 | validation: 0.4267672604180656]
	TIME [epoch: 5.9 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2822170168249856		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2822170168249856 | validation: 0.435274403081937]
	TIME [epoch: 5.88 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2959823048942877		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2959823048942877 | validation: 0.4714758056897646]
	TIME [epoch: 5.89 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29090233543711436		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.29090233543711436 | validation: 0.4068864440762495]
	TIME [epoch: 5.89 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v11_20240712_140902/states/model_facs_v2_dec2b_2dpca_v11_26.pth
	Model improved!!!
EPOCH 27/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2925398271217001		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2925398271217001 | validation: 0.46808735782843186]
	TIME [epoch: 5.89 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28414703496623933		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.28414703496623933 | validation: 0.44471493096345066]
	TIME [epoch: 5.88 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28622998610817335		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.28622998610817335 | validation: 0.38528326860980305]
	TIME [epoch: 5.9 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v11_20240712_140902/states/model_facs_v2_dec2b_2dpca_v11_29.pth
	Model improved!!!
EPOCH 30/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26811584086736023		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.26811584086736023 | validation: 0.47200910629814563]
	TIME [epoch: 5.89 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2928121104737822		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2928121104737822 | validation: 0.4012890224777639]
	TIME [epoch: 5.88 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2812671930411511		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2812671930411511 | validation: 0.4378728331867354]
	TIME [epoch: 5.88 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29943526578254953		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.29943526578254953 | validation: 0.4178934747471337]
	TIME [epoch: 5.88 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2885720168877349		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2885720168877349 | validation: 0.40177926789193263]
	TIME [epoch: 5.88 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2619718404881429		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2619718404881429 | validation: 0.40824257825785193]
	TIME [epoch: 5.88 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2705640438383031		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2705640438383031 | validation: 0.40339003442520577]
	TIME [epoch: 5.89 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2860240919624849		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2860240919624849 | validation: 0.38649536337954005]
	TIME [epoch: 5.89 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.255432770224367		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.255432770224367 | validation: 0.3869859670925082]
	TIME [epoch: 5.88 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2817799776344269		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2817799776344269 | validation: 0.3931752242984127]
	TIME [epoch: 5.88 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.267461757998522		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.267461757998522 | validation: 0.4152099934723004]
	TIME [epoch: 5.88 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26632037724889435		[learning rate: 0.0099646]
	Learning Rate: 0.00996464
	LOSS [training: 0.26632037724889435 | validation: 0.3832729277357925]
	TIME [epoch: 5.88 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v11_20240712_140902/states/model_facs_v2_dec2b_2dpca_v11_41.pth
	Model improved!!!
EPOCH 42/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2562523442066523		[learning rate: 0.0099206]
	Learning Rate: 0.00992061
	LOSS [training: 0.2562523442066523 | validation: 0.47459563784492514]
	TIME [epoch: 5.87 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2846481669094671		[learning rate: 0.0098768]
	Learning Rate: 0.00987678
	LOSS [training: 0.2846481669094671 | validation: 0.3772739897181407]
	TIME [epoch: 5.87 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v11_20240712_140902/states/model_facs_v2_dec2b_2dpca_v11_43.pth
	Model improved!!!
EPOCH 44/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26888530563586716		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 0.26888530563586716 | validation: 0.36475366722122765]
	TIME [epoch: 5.89 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v11_20240712_140902/states/model_facs_v2_dec2b_2dpca_v11_44.pth
	Model improved!!!
EPOCH 45/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.253874648900963		[learning rate: 0.0097897]
	Learning Rate: 0.0097897
	LOSS [training: 0.253874648900963 | validation: 0.35920276794522]
	TIME [epoch: 5.89 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v11_20240712_140902/states/model_facs_v2_dec2b_2dpca_v11_45.pth
	Model improved!!!
EPOCH 46/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2844235115328175		[learning rate: 0.0097464]
	Learning Rate: 0.00974644
	LOSS [training: 0.2844235115328175 | validation: 0.4049051903206351]
	TIME [epoch: 5.88 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27665690612956007		[learning rate: 0.0097034]
	Learning Rate: 0.00970338
	LOSS [training: 0.27665690612956007 | validation: 0.3790575810900717]
	TIME [epoch: 5.89 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2539929755019404		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 0.2539929755019404 | validation: 0.4047492195572416]
	TIME [epoch: 5.88 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.261882951752138		[learning rate: 0.0096178]
	Learning Rate: 0.00961783
	LOSS [training: 0.261882951752138 | validation: 0.38204755063108176]
	TIME [epoch: 5.89 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23712449965857157		[learning rate: 0.0095753]
	Learning Rate: 0.00957533
	LOSS [training: 0.23712449965857157 | validation: 0.36002653798906503]
	TIME [epoch: 5.88 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27682713190493974		[learning rate: 0.009533]
	Learning Rate: 0.00953303
	LOSS [training: 0.27682713190493974 | validation: 0.36969333280863503]
	TIME [epoch: 5.89 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22562269076338395		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 0.22562269076338395 | validation: 0.36562659964972744]
	TIME [epoch: 5.89 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2506301091231223		[learning rate: 0.009449]
	Learning Rate: 0.00944897
	LOSS [training: 0.2506301091231223 | validation: 0.3900472159596746]
	TIME [epoch: 5.89 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2965397248726055		[learning rate: 0.0094072]
	Learning Rate: 0.00940722
	LOSS [training: 0.2965397248726055 | validation: 0.36969797174998703]
	TIME [epoch: 5.88 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22885371821666203		[learning rate: 0.0093657]
	Learning Rate: 0.00936566
	LOSS [training: 0.22885371821666203 | validation: 0.3501174828939284]
	TIME [epoch: 5.89 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v11_20240712_140902/states/model_facs_v2_dec2b_2dpca_v11_55.pth
	Model improved!!!
EPOCH 56/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23119655503562847		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 0.23119655503562847 | validation: 0.3488395839625811]
	TIME [epoch: 5.89 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v11_20240712_140902/states/model_facs_v2_dec2b_2dpca_v11_56.pth
	Model improved!!!
EPOCH 57/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22377818638749614		[learning rate: 0.0092831]
	Learning Rate: 0.00928308
	LOSS [training: 0.22377818638749614 | validation: 0.37000182019065864]
	TIME [epoch: 5.88 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2480002353470699		[learning rate: 0.0092421]
	Learning Rate: 0.00924207
	LOSS [training: 0.2480002353470699 | validation: 0.37173977806050446]
	TIME [epoch: 5.9 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2537868181109134		[learning rate: 0.0092012]
	Learning Rate: 0.00920124
	LOSS [training: 0.2537868181109134 | validation: 0.3613896930865318]
	TIME [epoch: 5.9 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.232212203218994		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 0.232212203218994 | validation: 0.3698652017201687]
	TIME [epoch: 5.89 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2746776155190957		[learning rate: 0.0091201]
	Learning Rate: 0.00912011
	LOSS [training: 0.2746776155190957 | validation: 0.3534709375459289]
	TIME [epoch: 5.88 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22775657882744235		[learning rate: 0.0090798]
	Learning Rate: 0.00907981
	LOSS [training: 0.22775657882744235 | validation: 0.34054324849519035]
	TIME [epoch: 5.89 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v11_20240712_140902/states/model_facs_v2_dec2b_2dpca_v11_62.pth
	Model improved!!!
EPOCH 63/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22085729945587645		[learning rate: 0.0090397]
	Learning Rate: 0.0090397
	LOSS [training: 0.22085729945587645 | validation: 0.33214267121716634]
	TIME [epoch: 5.87 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v11_20240712_140902/states/model_facs_v2_dec2b_2dpca_v11_63.pth
	Model improved!!!
EPOCH 64/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2349923783613756		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 0.2349923783613756 | validation: 0.36166400122086784]
	TIME [epoch: 5.88 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21036378654612134		[learning rate: 0.00896]
	Learning Rate: 0.00895999
	LOSS [training: 0.21036378654612134 | validation: 0.3464595576913704]
	TIME [epoch: 5.89 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23608099651093667		[learning rate: 0.0089204]
	Learning Rate: 0.00892041
	LOSS [training: 0.23608099651093667 | validation: 0.3448964813203553]
	TIME [epoch: 5.89 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22959213807688564		[learning rate: 0.008881]
	Learning Rate: 0.00888099
	LOSS [training: 0.22959213807688564 | validation: 0.3222269052904481]
	TIME [epoch: 5.9 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v11_20240712_140902/states/model_facs_v2_dec2b_2dpca_v11_67.pth
	Model improved!!!
EPOCH 68/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2110430163944974		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 0.2110430163944974 | validation: 0.3518611602722072]
	TIME [epoch: 5.88 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21646684280885026		[learning rate: 0.0088027]
	Learning Rate: 0.00880269
	LOSS [training: 0.21646684280885026 | validation: 0.35223296146400396]
	TIME [epoch: 5.89 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2280265263340234		[learning rate: 0.0087638]
	Learning Rate: 0.0087638
	LOSS [training: 0.2280265263340234 | validation: 0.35272065609079684]
	TIME [epoch: 5.88 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24199027427303044		[learning rate: 0.0087251]
	Learning Rate: 0.00872508
	LOSS [training: 0.24199027427303044 | validation: 0.46496145831529806]
	TIME [epoch: 5.88 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2693158394380234		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 0.2693158394380234 | validation: 0.3616782101233614]
	TIME [epoch: 5.88 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20492033346100696		[learning rate: 0.0086481]
	Learning Rate: 0.00864815
	LOSS [training: 0.20492033346100696 | validation: 0.3255628767878145]
	TIME [epoch: 5.89 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2300675888773304		[learning rate: 0.0086099]
	Learning Rate: 0.00860994
	LOSS [training: 0.2300675888773304 | validation: 0.43968162210089756]
	TIME [epoch: 5.9 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2799040182447352		[learning rate: 0.0085719]
	Learning Rate: 0.0085719
	LOSS [training: 0.2799040182447352 | validation: 0.3330446049386159]
	TIME [epoch: 5.88 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21734724456583962		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 0.21734724456583962 | validation: 0.32399070526201307]
	TIME [epoch: 5.88 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2257441446955319		[learning rate: 0.0084963]
	Learning Rate: 0.00849632
	LOSS [training: 0.2257441446955319 | validation: 0.3339547609095359]
	TIME [epoch: 5.89 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21358368580452222		[learning rate: 0.0084588]
	Learning Rate: 0.00845878
	LOSS [training: 0.21358368580452222 | validation: 0.30335457916285224]
	TIME [epoch: 5.88 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v11_20240712_140902/states/model_facs_v2_dec2b_2dpca_v11_78.pth
	Model improved!!!
EPOCH 79/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20212300996028093		[learning rate: 0.0084214]
	Learning Rate: 0.00842141
	LOSS [training: 0.20212300996028093 | validation: 0.3922626021486352]
	TIME [epoch: 5.88 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2289295075337517		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 0.2289295075337517 | validation: 0.3870548302952903]
	TIME [epoch: 6.17 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19934358899376817		[learning rate: 0.0083472]
	Learning Rate: 0.00834715
	LOSS [training: 0.19934358899376817 | validation: 0.3378632013569264]
	TIME [epoch: 5.9 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2172522945047783		[learning rate: 0.0083103]
	Learning Rate: 0.00831027
	LOSS [training: 0.2172522945047783 | validation: 0.36574595414237754]
	TIME [epoch: 5.9 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21393283560111542		[learning rate: 0.0082736]
	Learning Rate: 0.00827356
	LOSS [training: 0.21393283560111542 | validation: 0.3129965482329412]
	TIME [epoch: 5.89 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21086704357122224		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 0.21086704357122224 | validation: 0.3332827963173086]
	TIME [epoch: 5.89 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27150829666979537		[learning rate: 0.0082006]
	Learning Rate: 0.00820061
	LOSS [training: 0.27150829666979537 | validation: 0.3552317436603757]
	TIME [epoch: 5.89 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24045489849507345		[learning rate: 0.0081644]
	Learning Rate: 0.00816438
	LOSS [training: 0.24045489849507345 | validation: 0.3136126396191057]
	TIME [epoch: 5.89 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21480400435767227		[learning rate: 0.0081283]
	Learning Rate: 0.0081283
	LOSS [training: 0.21480400435767227 | validation: 0.2994586698318495]
	TIME [epoch: 5.89 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v11_20240712_140902/states/model_facs_v2_dec2b_2dpca_v11_87.pth
	Model improved!!!
EPOCH 88/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1947710314176683		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 0.1947710314176683 | validation: 0.29009277042063863]
	TIME [epoch: 5.89 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v11_20240712_140902/states/model_facs_v2_dec2b_2dpca_v11_88.pth
	Model improved!!!
EPOCH 89/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1982370531419197		[learning rate: 0.0080566]
	Learning Rate: 0.00805664
	LOSS [training: 0.1982370531419197 | validation: 0.33828176815772565]
	TIME [epoch: 5.91 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3361563660831747		[learning rate: 0.008021]
	Learning Rate: 0.00802104
	LOSS [training: 0.3361563660831747 | validation: 0.3097317572581292]
	TIME [epoch: 5.89 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20381629684983033		[learning rate: 0.0079856]
	Learning Rate: 0.0079856
	LOSS [training: 0.20381629684983033 | validation: 0.34070677164290664]
	TIME [epoch: 5.89 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21922539517398887		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 0.21922539517398887 | validation: 0.370371175696315]
	TIME [epoch: 5.89 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22452414681415184		[learning rate: 0.0079152]
	Learning Rate: 0.00791519
	LOSS [training: 0.22452414681415184 | validation: 0.3039239921827353]
	TIME [epoch: 5.89 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2101558819784791		[learning rate: 0.0078802]
	Learning Rate: 0.00788022
	LOSS [training: 0.2101558819784791 | validation: 0.37788068900301697]
	TIME [epoch: 5.89 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23870996899459856		[learning rate: 0.0078454]
	Learning Rate: 0.00784541
	LOSS [training: 0.23870996899459856 | validation: 0.4027325020172105]
	TIME [epoch: 5.91 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21849134191592184		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 0.21849134191592184 | validation: 0.32287024380118806]
	TIME [epoch: 5.89 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21744866173751584		[learning rate: 0.0077762]
	Learning Rate: 0.00777623
	LOSS [training: 0.21744866173751584 | validation: 0.3672508406361717]
	TIME [epoch: 5.9 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20907334210663642		[learning rate: 0.0077419]
	Learning Rate: 0.00774188
	LOSS [training: 0.20907334210663642 | validation: 0.297840753838131]
	TIME [epoch: 5.89 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21335662347988552		[learning rate: 0.0077077]
	Learning Rate: 0.00770767
	LOSS [training: 0.21335662347988552 | validation: 0.3034470506833604]
	TIME [epoch: 5.89 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21290484769348178		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 0.21290484769348178 | validation: 0.4152472339372765]
	TIME [epoch: 5.89 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22324636440233578		[learning rate: 0.0076397]
	Learning Rate: 0.00763971
	LOSS [training: 0.22324636440233578 | validation: 0.3502357248797915]
	TIME [epoch: 5.89 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2070412142803096		[learning rate: 0.007606]
	Learning Rate: 0.00760596
	LOSS [training: 0.2070412142803096 | validation: 0.3225314905296898]
	TIME [epoch: 5.89 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20230172782364225		[learning rate: 0.0075724]
	Learning Rate: 0.00757235
	LOSS [training: 0.20230172782364225 | validation: 0.32291512935301653]
	TIME [epoch: 5.9 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20698531893580382		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 0.20698531893580382 | validation: 0.34698411668229867]
	TIME [epoch: 5.91 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2272896414448112		[learning rate: 0.0075056]
	Learning Rate: 0.00750559
	LOSS [training: 0.2272896414448112 | validation: 0.3399385249228838]
	TIME [epoch: 5.9 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20428673210951728		[learning rate: 0.0074724]
	Learning Rate: 0.00747242
	LOSS [training: 0.20428673210951728 | validation: 0.38663859417149704]
	TIME [epoch: 5.89 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23141639594131663		[learning rate: 0.0074394]
	Learning Rate: 0.00743941
	LOSS [training: 0.23141639594131663 | validation: 0.3190132717906484]
	TIME [epoch: 5.89 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.213331549500187		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 0.213331549500187 | validation: 0.3284419148286486]
	TIME [epoch: 5.9 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20009601150343306		[learning rate: 0.0073738]
	Learning Rate: 0.00737382
	LOSS [training: 0.20009601150343306 | validation: 0.34060677898034075]
	TIME [epoch: 5.89 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2091622168360266		[learning rate: 0.0073412]
	Learning Rate: 0.00734124
	LOSS [training: 0.2091622168360266 | validation: 0.2910227824594615]
	TIME [epoch: 5.89 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.202043188730531		[learning rate: 0.0073088]
	Learning Rate: 0.0073088
	LOSS [training: 0.202043188730531 | validation: 0.30019732860835163]
	TIME [epoch: 5.89 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19790540275036547		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 0.19790540275036547 | validation: 0.29752389669221724]
	TIME [epoch: 5.9 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2198789175046441		[learning rate: 0.0072444]
	Learning Rate: 0.00724436
	LOSS [training: 0.2198789175046441 | validation: 0.2938514678172522]
	TIME [epoch: 5.9 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20253900465456		[learning rate: 0.0072124]
	Learning Rate: 0.00721235
	LOSS [training: 0.20253900465456 | validation: 0.3207516722885812]
	TIME [epoch: 5.89 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21682742150678602		[learning rate: 0.0071805]
	Learning Rate: 0.00718049
	LOSS [training: 0.21682742150678602 | validation: 0.315373733296654]
	TIME [epoch: 5.89 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2072574401719312		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 0.2072574401719312 | validation: 0.31858187207340716]
	TIME [epoch: 5.89 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21687934713211043		[learning rate: 0.0071172]
	Learning Rate: 0.00711718
	LOSS [training: 0.21687934713211043 | validation: 0.3241092438848238]
	TIME [epoch: 5.89 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21090629570103614		[learning rate: 0.0070857]
	Learning Rate: 0.00708573
	LOSS [training: 0.21090629570103614 | validation: 0.29087754994383813]
	TIME [epoch: 5.89 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2021979748960677		[learning rate: 0.0070544]
	Learning Rate: 0.00705442
	LOSS [training: 0.2021979748960677 | validation: 0.3341733366349057]
	TIME [epoch: 5.9 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2182246228261892		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 0.2182246228261892 | validation: 0.3626558257562117]
	TIME [epoch: 5.91 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2190917199519266		[learning rate: 0.0069922]
	Learning Rate: 0.00699222
	LOSS [training: 0.2190917199519266 | validation: 0.3016205489343831]
	TIME [epoch: 5.9 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21394920634352044		[learning rate: 0.0069613]
	Learning Rate: 0.00696133
	LOSS [training: 0.21394920634352044 | validation: 0.3237825976520311]
	TIME [epoch: 5.89 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.195166108459596		[learning rate: 0.0069306]
	Learning Rate: 0.00693057
	LOSS [training: 0.195166108459596 | validation: 0.32808853736201]
	TIME [epoch: 5.89 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2029660423890593		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 0.2029660423890593 | validation: 0.3337285955988987]
	TIME [epoch: 5.89 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21489139781070005		[learning rate: 0.0068695]
	Learning Rate: 0.00686947
	LOSS [training: 0.21489139781070005 | validation: 0.3706132210908724]
	TIME [epoch: 5.9 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20308194821365316		[learning rate: 0.0068391]
	Learning Rate: 0.00683912
	LOSS [training: 0.20308194821365316 | validation: 0.3645429494954432]
	TIME [epoch: 5.9 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2084592277786971		[learning rate: 0.0068089]
	Learning Rate: 0.0068089
	LOSS [training: 0.2084592277786971 | validation: 0.2951776602695029]
	TIME [epoch: 5.91 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20530764889531		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 0.20530764889531 | validation: 0.332587513685046]
	TIME [epoch: 5.9 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19630164880910575		[learning rate: 0.0067489]
	Learning Rate: 0.00674887
	LOSS [training: 0.19630164880910575 | validation: 0.2816439268605303]
	TIME [epoch: 5.89 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v11_20240712_140902/states/model_facs_v2_dec2b_2dpca_v11_129.pth
	Model improved!!!
EPOCH 130/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1963228785304316		[learning rate: 0.006719]
	Learning Rate: 0.00671905
	LOSS [training: 0.1963228785304316 | validation: 0.31396058298624274]
	TIME [epoch: 5.9 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2013985174749764		[learning rate: 0.0066894]
	Learning Rate: 0.00668936
	LOSS [training: 0.2013985174749764 | validation: 0.33198131422121613]
	TIME [epoch: 5.9 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21292847139394455		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 0.21292847139394455 | validation: 0.32768627183543164]
	TIME [epoch: 5.9 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19357124013950538		[learning rate: 0.0066304]
	Learning Rate: 0.00663038
	LOSS [training: 0.19357124013950538 | validation: 0.35768946539655166]
	TIME [epoch: 5.9 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22418004222015933		[learning rate: 0.0066011]
	Learning Rate: 0.00660109
	LOSS [training: 0.22418004222015933 | validation: 0.3610250660723525]
	TIME [epoch: 5.9 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2276197211822281		[learning rate: 0.0065719]
	Learning Rate: 0.00657192
	LOSS [training: 0.2276197211822281 | validation: 0.30696145717980367]
	TIME [epoch: 5.91 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19459777285207		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 0.19459777285207 | validation: 0.32529812428681526]
	TIME [epoch: 5.9 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19087398892705826		[learning rate: 0.006514]
	Learning Rate: 0.00651398
	LOSS [training: 0.19087398892705826 | validation: 0.31021828773849086]
	TIME [epoch: 5.9 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19410887039524885		[learning rate: 0.0064852]
	Learning Rate: 0.00648519
	LOSS [training: 0.19410887039524885 | validation: 0.3010637261204381]
	TIME [epoch: 5.9 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.190721867941212		[learning rate: 0.0064565]
	Learning Rate: 0.00645654
	LOSS [training: 0.190721867941212 | validation: 0.28512242115821007]
	TIME [epoch: 5.89 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19574204712753168		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 0.19574204712753168 | validation: 0.3031835689240924]
	TIME [epoch: 5.9 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20640495035253165		[learning rate: 0.0063996]
	Learning Rate: 0.00639961
	LOSS [training: 0.20640495035253165 | validation: 0.3057117592616479]
	TIME [epoch: 5.9 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2000019437199061		[learning rate: 0.0063713]
	Learning Rate: 0.00637134
	LOSS [training: 0.2000019437199061 | validation: 0.3488134327585475]
	TIME [epoch: 5.9 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2332275883907542		[learning rate: 0.0063432]
	Learning Rate: 0.00634319
	LOSS [training: 0.2332275883907542 | validation: 0.3298297573735536]
	TIME [epoch: 5.9 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20105729507122705		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 0.20105729507122705 | validation: 0.31369733910754793]
	TIME [epoch: 5.9 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1929031988379888		[learning rate: 0.0062873]
	Learning Rate: 0.00628726
	LOSS [training: 0.1929031988379888 | validation: 0.311670952499378]
	TIME [epoch: 5.9 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19865793821473385		[learning rate: 0.0062595]
	Learning Rate: 0.00625948
	LOSS [training: 0.19865793821473385 | validation: 0.32158138361620026]
	TIME [epoch: 5.9 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19378677158880347		[learning rate: 0.0062318]
	Learning Rate: 0.00623183
	LOSS [training: 0.19378677158880347 | validation: 0.34672242453115387]
	TIME [epoch: 5.9 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20581845004708094		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 0.20581845004708094 | validation: 0.31076312053873006]
	TIME [epoch: 5.9 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2014909671072913		[learning rate: 0.0061769]
	Learning Rate: 0.00617688
	LOSS [training: 0.2014909671072913 | validation: 0.3071574240697292]
	TIME [epoch: 5.9 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19392865935278775		[learning rate: 0.0061496]
	Learning Rate: 0.00614959
	LOSS [training: 0.19392865935278775 | validation: 0.29801020014728263]
	TIME [epoch: 5.91 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19903511335339757		[learning rate: 0.0061224]
	Learning Rate: 0.00612242
	LOSS [training: 0.19903511335339757 | validation: 0.31974206795207016]
	TIME [epoch: 5.9 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19727107476667438		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 0.19727107476667438 | validation: 0.2957745665336672]
	TIME [epoch: 5.9 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1873210546250402		[learning rate: 0.0060684]
	Learning Rate: 0.00606844
	LOSS [training: 0.1873210546250402 | validation: 0.39058667688850546]
	TIME [epoch: 5.9 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.241202679908641		[learning rate: 0.0060416]
	Learning Rate: 0.00604163
	LOSS [training: 0.241202679908641 | validation: 0.5867413841647473]
	TIME [epoch: 5.9 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4265134176867491		[learning rate: 0.0060149]
	Learning Rate: 0.00601493
	LOSS [training: 0.4265134176867491 | validation: 0.3967918417831614]
	TIME [epoch: 5.9 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2477961741121421		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 0.2477961741121421 | validation: 0.35993359130449676]
	TIME [epoch: 5.9 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22715521689060827		[learning rate: 0.0059619]
	Learning Rate: 0.0059619
	LOSS [training: 0.22715521689060827 | validation: 0.3356796200291957]
	TIME [epoch: 5.9 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2228548070623919		[learning rate: 0.0059356]
	Learning Rate: 0.00593556
	LOSS [training: 0.2228548070623919 | validation: 0.3460221206329295]
	TIME [epoch: 5.91 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21229460643207418		[learning rate: 0.0059093]
	Learning Rate: 0.00590933
	LOSS [training: 0.21229460643207418 | validation: 0.34403934455528173]
	TIME [epoch: 5.9 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2087145037697155		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 0.2087145037697155 | validation: 0.3470213386950666]
	TIME [epoch: 5.89 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20643373104722693		[learning rate: 0.0058572]
	Learning Rate: 0.00585723
	LOSS [training: 0.20643373104722693 | validation: 0.3407691202686845]
	TIME [epoch: 5.89 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21337491570763514		[learning rate: 0.0058314]
	Learning Rate: 0.00583135
	LOSS [training: 0.21337491570763514 | validation: 0.3442276395882255]
	TIME [epoch: 5.89 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20895145652823627		[learning rate: 0.0058056]
	Learning Rate: 0.00580559
	LOSS [training: 0.20895145652823627 | validation: 0.32446414241347704]
	TIME [epoch: 5.89 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20174524963730417		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 0.20174524963730417 | validation: 0.3026230142363487]
	TIME [epoch: 5.89 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19964444298804734		[learning rate: 0.0057544]
	Learning Rate: 0.0057544
	LOSS [training: 0.19964444298804734 | validation: 0.3048680593590222]
	TIME [epoch: 5.9 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19372328257130658		[learning rate: 0.005729]
	Learning Rate: 0.00572897
	LOSS [training: 0.19372328257130658 | validation: 0.3525345223227915]
	TIME [epoch: 5.9 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18084314818863118		[learning rate: 0.0057037]
	Learning Rate: 0.00570366
	LOSS [training: 0.18084314818863118 | validation: 0.29494678433925464]
	TIME [epoch: 5.9 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19896407599038893		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 0.19896407599038893 | validation: 0.2879353368233338]
	TIME [epoch: 5.9 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20370937209231962		[learning rate: 0.0056534]
	Learning Rate: 0.00565337
	LOSS [training: 0.20370937209231962 | validation: 0.29747301628589273]
	TIME [epoch: 5.89 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18210764407282032		[learning rate: 0.0056284]
	Learning Rate: 0.0056284
	LOSS [training: 0.18210764407282032 | validation: 0.34044580093834786]
	TIME [epoch: 5.9 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18830030560305505		[learning rate: 0.0056035]
	Learning Rate: 0.00560353
	LOSS [training: 0.18830030560305505 | validation: 0.28501838659897166]
	TIME [epoch: 5.89 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19984554256513298		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 0.19984554256513298 | validation: 0.33414748758611446]
	TIME [epoch: 5.89 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22351788425960115		[learning rate: 0.0055541]
	Learning Rate: 0.00555412
	LOSS [training: 0.22351788425960115 | validation: 0.3210345553979295]
	TIME [epoch: 5.9 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19490840663692238		[learning rate: 0.0055296]
	Learning Rate: 0.00552958
	LOSS [training: 0.19490840663692238 | validation: 0.29141699742134797]
	TIME [epoch: 5.89 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1999213155138863		[learning rate: 0.0055052]
	Learning Rate: 0.00550515
	LOSS [training: 0.1999213155138863 | validation: 0.2862143484000148]
	TIME [epoch: 5.89 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19242591677410573		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 0.19242591677410573 | validation: 0.2908486620685043]
	TIME [epoch: 5.89 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19766691866488445		[learning rate: 0.0054566]
	Learning Rate: 0.00545661
	LOSS [training: 0.19766691866488445 | validation: 0.3067662161619061]
	TIME [epoch: 5.89 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19464566912195752		[learning rate: 0.0054325]
	Learning Rate: 0.0054325
	LOSS [training: 0.19464566912195752 | validation: 0.30607234810123984]
	TIME [epoch: 5.89 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19345998697315503		[learning rate: 0.0054085]
	Learning Rate: 0.0054085
	LOSS [training: 0.19345998697315503 | validation: 0.28672863108713353]
	TIME [epoch: 5.89 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1878593124190821		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 0.1878593124190821 | validation: 0.29720885596690794]
	TIME [epoch: 5.89 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18785571441137885		[learning rate: 0.0053608]
	Learning Rate: 0.00536081
	LOSS [training: 0.18785571441137885 | validation: 0.2989921191623519]
	TIME [epoch: 5.9 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1850766376162398		[learning rate: 0.0053371]
	Learning Rate: 0.00533713
	LOSS [training: 0.1850766376162398 | validation: 0.27929071656964205]
	TIME [epoch: 5.89 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v11_20240712_140902/states/model_facs_v2_dec2b_2dpca_v11_182.pth
	Model improved!!!
EPOCH 183/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1906767540035726		[learning rate: 0.0053135]
	Learning Rate: 0.00531355
	LOSS [training: 0.1906767540035726 | validation: 0.28309872551188503]
	TIME [epoch: 5.89 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18264742941531203		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 0.18264742941531203 | validation: 0.35093465066114854]
	TIME [epoch: 5.88 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2074245515295611		[learning rate: 0.0052667]
	Learning Rate: 0.0052667
	LOSS [training: 0.2074245515295611 | validation: 0.34609780690180536]
	TIME [epoch: 5.89 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19677030746895047		[learning rate: 0.0052434]
	Learning Rate: 0.00524343
	LOSS [training: 0.19677030746895047 | validation: 0.3426056427998462]
	TIME [epoch: 5.91 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19599011730458102		[learning rate: 0.0052203]
	Learning Rate: 0.00522026
	LOSS [training: 0.19599011730458102 | validation: 0.2839079574395419]
	TIME [epoch: 5.89 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19181366871302657		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 0.19181366871302657 | validation: 0.2765297914883209]
	TIME [epoch: 5.9 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v11_20240712_140902/states/model_facs_v2_dec2b_2dpca_v11_188.pth
	Model improved!!!
EPOCH 189/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1912790512724308		[learning rate: 0.0051742]
	Learning Rate: 0.00517423
	LOSS [training: 0.1912790512724308 | validation: 0.29597994558264124]
	TIME [epoch: 5.9 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1884532587955287		[learning rate: 0.0051514]
	Learning Rate: 0.00515137
	LOSS [training: 0.1884532587955287 | validation: 0.3749036076439181]
	TIME [epoch: 5.88 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2050983935228813		[learning rate: 0.0051286]
	Learning Rate: 0.00512861
	LOSS [training: 0.2050983935228813 | validation: 0.33699364525844216]
	TIME [epoch: 5.89 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18331943148039415		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 0.18331943148039415 | validation: 0.30443354818158935]
	TIME [epoch: 5.89 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23181157962002735		[learning rate: 0.0050834]
	Learning Rate: 0.00508339
	LOSS [training: 0.23181157962002735 | validation: 0.35929140408100335]
	TIME [epoch: 5.89 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21920193640382454		[learning rate: 0.0050609]
	Learning Rate: 0.00506093
	LOSS [training: 0.21920193640382454 | validation: 0.3505916333177441]
	TIME [epoch: 5.89 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2034379121007932		[learning rate: 0.0050386]
	Learning Rate: 0.00503857
	LOSS [training: 0.2034379121007932 | validation: 0.32365599805875944]
	TIME [epoch: 5.89 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20650941404273188		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 0.20650941404273188 | validation: 0.3227473650918072]
	TIME [epoch: 5.9 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19101976967508383		[learning rate: 0.0049941]
	Learning Rate: 0.00499415
	LOSS [training: 0.19101976967508383 | validation: 0.3210248138174587]
	TIME [epoch: 5.89 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1990202827345527		[learning rate: 0.0049721]
	Learning Rate: 0.00497208
	LOSS [training: 0.1990202827345527 | validation: 0.29148836698732683]
	TIME [epoch: 5.89 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.189147687178674		[learning rate: 0.0049501]
	Learning Rate: 0.00495012
	LOSS [training: 0.189147687178674 | validation: 0.3016411758905536]
	TIME [epoch: 5.89 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2052619714766371		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 0.2052619714766371 | validation: 0.2890248064684704]
	TIME [epoch: 5.89 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1934516310387909		[learning rate: 0.0049065]
	Learning Rate: 0.00490647
	LOSS [training: 0.1934516310387909 | validation: 0.3144259321048428]
	TIME [epoch: 5.89 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19055657174891713		[learning rate: 0.0048848]
	Learning Rate: 0.00488479
	LOSS [training: 0.19055657174891713 | validation: 0.3307953832150651]
	TIME [epoch: 5.89 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18238041849694628		[learning rate: 0.0048632]
	Learning Rate: 0.00486321
	LOSS [training: 0.18238041849694628 | validation: 0.29763664618347785]
	TIME [epoch: 5.89 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19616520124939024		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 0.19616520124939024 | validation: 0.3114102538387707]
	TIME [epoch: 5.89 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1849557525250234		[learning rate: 0.0048203]
	Learning Rate: 0.00482033
	LOSS [training: 0.1849557525250234 | validation: 0.29838545401187444]
	TIME [epoch: 5.88 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19253129650479367		[learning rate: 0.004799]
	Learning Rate: 0.00479903
	LOSS [training: 0.19253129650479367 | validation: 0.30282113085518875]
	TIME [epoch: 5.89 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1816292983729522		[learning rate: 0.0047778]
	Learning Rate: 0.00477783
	LOSS [training: 0.1816292983729522 | validation: 0.2767830912168634]
	TIME [epoch: 5.88 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19448543014492092		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.19448543014492092 | validation: 0.28745986610276475]
	TIME [epoch: 5.88 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19364842986566771		[learning rate: 0.0047357]
	Learning Rate: 0.0047357
	LOSS [training: 0.19364842986566771 | validation: 0.3040209267164]
	TIME [epoch: 5.88 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1929443045694424		[learning rate: 0.0047148]
	Learning Rate: 0.00471478
	LOSS [training: 0.1929443045694424 | validation: 0.31653963077658537]
	TIME [epoch: 5.88 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1838632970795504		[learning rate: 0.0046939]
	Learning Rate: 0.00469395
	LOSS [training: 0.1838632970795504 | validation: 0.3282926336632615]
	TIME [epoch: 5.89 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19236909817688988		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 0.19236909817688988 | validation: 0.27876570765235376]
	TIME [epoch: 5.88 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19566988475984376		[learning rate: 0.0046526]
	Learning Rate: 0.00465256
	LOSS [training: 0.19566988475984376 | validation: 0.2884677688228309]
	TIME [epoch: 5.86 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1946805055006404		[learning rate: 0.004632]
	Learning Rate: 0.00463201
	LOSS [training: 0.1946805055006404 | validation: 0.3238570536096366]
	TIME [epoch: 5.88 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19061431322983743		[learning rate: 0.0046115]
	Learning Rate: 0.00461154
	LOSS [training: 0.19061431322983743 | validation: 0.32755920893219226]
	TIME [epoch: 5.86 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20327957221252002		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 0.20327957221252002 | validation: 0.30548180098289585]
	TIME [epoch: 5.86 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18607250558389796		[learning rate: 0.0045709]
	Learning Rate: 0.00457088
	LOSS [training: 0.18607250558389796 | validation: 0.3272485349055473]
	TIME [epoch: 5.86 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19994198994727183		[learning rate: 0.0045507]
	Learning Rate: 0.00455069
	LOSS [training: 0.19994198994727183 | validation: 0.2998868074885202]
	TIME [epoch: 5.86 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19274233574109445		[learning rate: 0.0045306]
	Learning Rate: 0.00453058
	LOSS [training: 0.19274233574109445 | validation: 0.32211688328306287]
	TIME [epoch: 5.87 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19897458823890188		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 0.19897458823890188 | validation: 0.3063844239059298]
	TIME [epoch: 5.87 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18469722392907412		[learning rate: 0.0044906]
	Learning Rate: 0.00449063
	LOSS [training: 0.18469722392907412 | validation: 0.31812169860924416]
	TIME [epoch: 5.87 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17848134635952806		[learning rate: 0.0044708]
	Learning Rate: 0.00447079
	LOSS [training: 0.17848134635952806 | validation: 0.2982259954623893]
	TIME [epoch: 5.87 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19324385297586583		[learning rate: 0.004451]
	Learning Rate: 0.00445104
	LOSS [training: 0.19324385297586583 | validation: 0.3138434313738869]
	TIME [epoch: 5.87 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1965236222886457		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 0.1965236222886457 | validation: 0.29418322458784507]
	TIME [epoch: 5.87 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18075441093795178		[learning rate: 0.0044118]
	Learning Rate: 0.0044118
	LOSS [training: 0.18075441093795178 | validation: 0.3038534409639194]
	TIME [epoch: 5.87 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1884184936710674		[learning rate: 0.0043923]
	Learning Rate: 0.0043923
	LOSS [training: 0.1884184936710674 | validation: 0.3147953547073564]
	TIME [epoch: 5.86 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18626311975178284		[learning rate: 0.0043729]
	Learning Rate: 0.0043729
	LOSS [training: 0.18626311975178284 | validation: 0.3224384248564662]
	TIME [epoch: 5.87 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19423817860908113		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 0.19423817860908113 | validation: 0.3113161969823784]
	TIME [epoch: 5.86 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18936657470317558		[learning rate: 0.0043343]
	Learning Rate: 0.00433434
	LOSS [training: 0.18936657470317558 | validation: 0.3057825774469762]
	TIME [epoch: 5.87 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19494016270834183		[learning rate: 0.0043152]
	Learning Rate: 0.00431519
	LOSS [training: 0.19494016270834183 | validation: 0.30317078263000763]
	TIME [epoch: 5.87 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19797028925543475		[learning rate: 0.0042961]
	Learning Rate: 0.00429612
	LOSS [training: 0.19797028925543475 | validation: 0.32725355825604635]
	TIME [epoch: 5.87 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20495032426360843		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 0.20495032426360843 | validation: 0.31354361668525155]
	TIME [epoch: 5.87 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1884967202227324		[learning rate: 0.0042582]
	Learning Rate: 0.00425825
	LOSS [training: 0.1884967202227324 | validation: 0.3119817317633517]
	TIME [epoch: 5.86 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19895471223155536		[learning rate: 0.0042394]
	Learning Rate: 0.00423943
	LOSS [training: 0.19895471223155536 | validation: 0.3221671624636027]
	TIME [epoch: 5.87 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18923810624864187		[learning rate: 0.0042207]
	Learning Rate: 0.0042207
	LOSS [training: 0.18923810624864187 | validation: 0.29965655302108457]
	TIME [epoch: 5.88 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18097193003966128		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 0.18097193003966128 | validation: 0.3102589024993181]
	TIME [epoch: 5.87 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17986715029992595		[learning rate: 0.0041835]
	Learning Rate: 0.00418349
	LOSS [training: 0.17986715029992595 | validation: 0.29325733269709964]
	TIME [epoch: 5.87 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19262788009753223		[learning rate: 0.004165]
	Learning Rate: 0.004165
	LOSS [training: 0.19262788009753223 | validation: 0.3062534839134763]
	TIME [epoch: 5.87 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18993353478491945		[learning rate: 0.0041466]
	Learning Rate: 0.0041466
	LOSS [training: 0.18993353478491945 | validation: 0.3067278244232143]
	TIME [epoch: 5.87 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1814176969848362		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 0.1814176969848362 | validation: 0.3024694457322312]
	TIME [epoch: 5.87 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18178314514380453		[learning rate: 0.00411]
	Learning Rate: 0.00411004
	LOSS [training: 0.18178314514380453 | validation: 0.3216988216829844]
	TIME [epoch: 5.87 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18665473265567942		[learning rate: 0.0040919]
	Learning Rate: 0.00409188
	LOSS [training: 0.18665473265567942 | validation: 0.3109234216236278]
	TIME [epoch: 5.89 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1885548789924258		[learning rate: 0.0040738]
	Learning Rate: 0.0040738
	LOSS [training: 0.1885548789924258 | validation: 0.32814185531474066]
	TIME [epoch: 5.88 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19454237378314407		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.19454237378314407 | validation: 0.28972621745616806]
	TIME [epoch: 5.87 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1815709434076996		[learning rate: 0.0040379]
	Learning Rate: 0.00403788
	LOSS [training: 0.1815709434076996 | validation: 0.297377526053865]
	TIME [epoch: 5.87 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1895656908870317		[learning rate: 0.00402]
	Learning Rate: 0.00402004
	LOSS [training: 0.1895656908870317 | validation: 0.4147881431082104]
	TIME [epoch: 5.87 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19334410742598113		[learning rate: 0.0040023]
	Learning Rate: 0.00400228
	LOSS [training: 0.19334410742598113 | validation: 0.32291468542436036]
	TIME [epoch: 5.87 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1763814671786125		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 0.1763814671786125 | validation: 0.3009440905005332]
	TIME [epoch: 5.87 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17862499453793973		[learning rate: 0.003967]
	Learning Rate: 0.00396699
	LOSS [training: 0.17862499453793973 | validation: 0.2929877063615684]
	TIME [epoch: 5.87 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1900965832815009		[learning rate: 0.0039495]
	Learning Rate: 0.00394947
	LOSS [training: 0.1900965832815009 | validation: 0.2765581658275762]
	TIME [epoch: 5.89 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18565375011050028		[learning rate: 0.003932]
	Learning Rate: 0.00393202
	LOSS [training: 0.18565375011050028 | validation: 0.31611688893304984]
	TIME [epoch: 5.87 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1741023823108202		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 0.1741023823108202 | validation: 0.29807441649763394]
	TIME [epoch: 5.87 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18221518890612498		[learning rate: 0.0038973]
	Learning Rate: 0.00389735
	LOSS [training: 0.18221518890612498 | validation: 0.38639028821372523]
	TIME [epoch: 5.86 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19796761066275553		[learning rate: 0.0038801]
	Learning Rate: 0.00388013
	LOSS [training: 0.19796761066275553 | validation: 0.3568014965956482]
	TIME [epoch: 5.87 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1915452872936864		[learning rate: 0.003863]
	Learning Rate: 0.00386299
	LOSS [training: 0.1915452872936864 | validation: 0.30098373066107376]
	TIME [epoch: 5.87 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.185830128461056		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 0.185830128461056 | validation: 0.31402775744902744]
	TIME [epoch: 5.88 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19087329038062967		[learning rate: 0.0038289]
	Learning Rate: 0.00382893
	LOSS [training: 0.19087329038062967 | validation: 0.2963224875522582]
	TIME [epoch: 5.88 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17918005913876162		[learning rate: 0.003812]
	Learning Rate: 0.00381201
	LOSS [training: 0.17918005913876162 | validation: 0.2839317589083705]
	TIME [epoch: 5.88 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17922760461563994		[learning rate: 0.0037952]
	Learning Rate: 0.00379517
	LOSS [training: 0.17922760461563994 | validation: 0.28501945428366443]
	TIME [epoch: 5.86 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18886990583767538		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 0.18886990583767538 | validation: 0.2853752860682281]
	TIME [epoch: 5.88 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17896128557710797		[learning rate: 0.0037617]
	Learning Rate: 0.0037617
	LOSS [training: 0.17896128557710797 | validation: 0.306275767543041]
	TIME [epoch: 5.87 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18938319524292288		[learning rate: 0.0037451]
	Learning Rate: 0.00374508
	LOSS [training: 0.18938319524292288 | validation: 0.29658045373891007]
	TIME [epoch: 5.88 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2018627733629086		[learning rate: 0.0037285]
	Learning Rate: 0.00372854
	LOSS [training: 0.2018627733629086 | validation: 0.311573086447124]
	TIME [epoch: 5.87 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18573074332759826		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 0.18573074332759826 | validation: 0.28628743863562206]
	TIME [epoch: 5.87 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1798723824913783		[learning rate: 0.0036957]
	Learning Rate: 0.00369566
	LOSS [training: 0.1798723824913783 | validation: 0.30119297531202915]
	TIME [epoch: 5.88 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18450201095716584		[learning rate: 0.0036793]
	Learning Rate: 0.00367933
	LOSS [training: 0.18450201095716584 | validation: 0.2970243983055454]
	TIME [epoch: 5.87 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17739256635308412		[learning rate: 0.0036631]
	Learning Rate: 0.00366308
	LOSS [training: 0.17739256635308412 | validation: 0.33763244633505757]
	TIME [epoch: 5.87 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18796953520748408		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 0.18796953520748408 | validation: 0.29761284355955386]
	TIME [epoch: 5.87 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17177917885954336		[learning rate: 0.0036308]
	Learning Rate: 0.00363078
	LOSS [training: 0.17177917885954336 | validation: 0.29461764002998986]
	TIME [epoch: 5.86 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17524823741272116		[learning rate: 0.0036147]
	Learning Rate: 0.00361474
	LOSS [training: 0.17524823741272116 | validation: 0.3355286326993993]
	TIME [epoch: 5.88 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1868441810627451		[learning rate: 0.0035988]
	Learning Rate: 0.00359877
	LOSS [training: 0.1868441810627451 | validation: 0.30436152533858674]
	TIME [epoch: 5.87 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17794057496249271		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 0.17794057496249271 | validation: 0.28471182904892994]
	TIME [epoch: 5.88 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1757157801199466		[learning rate: 0.003567]
	Learning Rate: 0.00356704
	LOSS [training: 0.1757157801199466 | validation: 0.2977138891639252]
	TIME [epoch: 5.88 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17338854248824204		[learning rate: 0.0035513]
	Learning Rate: 0.00355128
	LOSS [training: 0.17338854248824204 | validation: 0.2842876489996578]
	TIME [epoch: 5.88 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.177535277914615		[learning rate: 0.0035356]
	Learning Rate: 0.00353559
	LOSS [training: 0.177535277914615 | validation: 0.2942228921046407]
	TIME [epoch: 5.87 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.191247147926146		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 0.191247147926146 | validation: 0.2913656111532723]
	TIME [epoch: 5.87 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1795097952181215		[learning rate: 0.0035044]
	Learning Rate: 0.00350441
	LOSS [training: 0.1795097952181215 | validation: 0.2907388178046527]
	TIME [epoch: 5.88 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1732207470135489		[learning rate: 0.0034889]
	Learning Rate: 0.00348893
	LOSS [training: 0.1732207470135489 | validation: 0.28812232514770364]
	TIME [epoch: 5.87 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18307865039837246		[learning rate: 0.0034735]
	Learning Rate: 0.00347352
	LOSS [training: 0.18307865039837246 | validation: 0.289795873642051]
	TIME [epoch: 5.88 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18099176300600534		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.18099176300600534 | validation: 0.2886605604989386]
	TIME [epoch: 5.88 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18485482017650365		[learning rate: 0.0034429]
	Learning Rate: 0.00344289
	LOSS [training: 0.18485482017650365 | validation: 0.28566459053467036]
	TIME [epoch: 5.89 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1819149715441848		[learning rate: 0.0034277]
	Learning Rate: 0.00342768
	LOSS [training: 0.1819149715441848 | validation: 0.290042705491826]
	TIME [epoch: 5.87 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16705585396437855		[learning rate: 0.0034125]
	Learning Rate: 0.00341253
	LOSS [training: 0.16705585396437855 | validation: 0.2925907501910923]
	TIME [epoch: 5.88 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18202511571876911		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 0.18202511571876911 | validation: 0.2868904707697336]
	TIME [epoch: 5.88 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1753387942811321		[learning rate: 0.0033824]
	Learning Rate: 0.00338245
	LOSS [training: 0.1753387942811321 | validation: 0.28874707885228124]
	TIME [epoch: 5.87 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17439200520507975		[learning rate: 0.0033675]
	Learning Rate: 0.0033675
	LOSS [training: 0.17439200520507975 | validation: 0.2992652479047032]
	TIME [epoch: 5.89 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18464974124366218		[learning rate: 0.0033526]
	Learning Rate: 0.00335262
	LOSS [training: 0.18464974124366218 | validation: 0.3030110429913284]
	TIME [epoch: 5.87 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17570646353294647		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 0.17570646353294647 | validation: 0.2826341783033496]
	TIME [epoch: 5.89 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18719985971942082		[learning rate: 0.0033231]
	Learning Rate: 0.00332306
	LOSS [training: 0.18719985971942082 | validation: 0.2927158735257161]
	TIME [epoch: 5.88 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18384216562086886		[learning rate: 0.0033084]
	Learning Rate: 0.00330838
	LOSS [training: 0.18384216562086886 | validation: 0.2816001454143206]
	TIME [epoch: 5.87 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1741883776608704		[learning rate: 0.0032938]
	Learning Rate: 0.00329376
	LOSS [training: 0.1741883776608704 | validation: 0.3007836587279445]
	TIME [epoch: 5.87 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17618064353407992		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 0.17618064353407992 | validation: 0.30850754101659006]
	TIME [epoch: 5.87 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17416839684523916		[learning rate: 0.0032647]
	Learning Rate: 0.00326472
	LOSS [training: 0.17416839684523916 | validation: 0.28945107747437104]
	TIME [epoch: 5.87 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17600278585582305		[learning rate: 0.0032503]
	Learning Rate: 0.0032503
	LOSS [training: 0.17600278585582305 | validation: 0.275802481762273]
	TIME [epoch: 5.87 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v11_20240712_140902/states/model_facs_v2_dec2b_2dpca_v11_294.pth
	Model improved!!!
EPOCH 295/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1799866512611276		[learning rate: 0.0032359]
	Learning Rate: 0.00323594
	LOSS [training: 0.1799866512611276 | validation: 0.26864241898946356]
	TIME [epoch: 5.88 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v11_20240712_140902/states/model_facs_v2_dec2b_2dpca_v11_295.pth
	Model improved!!!
EPOCH 296/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17963504620307602		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 0.17963504620307602 | validation: 0.2953383780949656]
	TIME [epoch: 5.89 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17751135182935363		[learning rate: 0.0032074]
	Learning Rate: 0.00320741
	LOSS [training: 0.17751135182935363 | validation: 0.2761101004408814]
	TIME [epoch: 5.88 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17270630520746183		[learning rate: 0.0031932]
	Learning Rate: 0.00319323
	LOSS [training: 0.17270630520746183 | validation: 0.3503450744327189]
	TIME [epoch: 5.88 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18651221050012393		[learning rate: 0.0031791]
	Learning Rate: 0.00317913
	LOSS [training: 0.18651221050012393 | validation: 0.3041496078164861]
	TIME [epoch: 5.9 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18236466084877284		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 0.18236466084877284 | validation: 0.3015040129496306]
	TIME [epoch: 5.88 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18489925826598794		[learning rate: 0.0031511]
	Learning Rate: 0.0031511
	LOSS [training: 0.18489925826598794 | validation: 0.3171255555561076]
	TIME [epoch: 5.88 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17741398853531345		[learning rate: 0.0031372]
	Learning Rate: 0.00313717
	LOSS [training: 0.17741398853531345 | validation: 0.29704971815866565]
	TIME [epoch: 5.87 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1762112251222545		[learning rate: 0.0031233]
	Learning Rate: 0.00312331
	LOSS [training: 0.1762112251222545 | validation: 0.2919256625939211]
	TIME [epoch: 5.88 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.169802165617613		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 0.169802165617613 | validation: 0.3099398303291208]
	TIME [epoch: 5.87 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18305627660530085		[learning rate: 0.0030958]
	Learning Rate: 0.00309577
	LOSS [training: 0.18305627660530085 | validation: 0.28251739486838595]
	TIME [epoch: 5.87 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18358911120875687		[learning rate: 0.0030821]
	Learning Rate: 0.0030821
	LOSS [training: 0.18358911120875687 | validation: 0.2968135625110739]
	TIME [epoch: 5.87 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18389355212034114		[learning rate: 0.0030685]
	Learning Rate: 0.00306848
	LOSS [training: 0.18389355212034114 | validation: 0.281960334535908]
	TIME [epoch: 5.87 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18906858537057275		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 0.18906858537057275 | validation: 0.3062248918881985]
	TIME [epoch: 5.87 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18506969659187578		[learning rate: 0.0030414]
	Learning Rate: 0.00304142
	LOSS [training: 0.18506969659187578 | validation: 0.3276691670092226]
	TIME [epoch: 5.87 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17274574126761305		[learning rate: 0.003028]
	Learning Rate: 0.00302799
	LOSS [training: 0.17274574126761305 | validation: 0.2777889544071004]
	TIME [epoch: 5.87 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17736995358994223		[learning rate: 0.0030146]
	Learning Rate: 0.00301461
	LOSS [training: 0.17736995358994223 | validation: 0.28393530490550867]
	TIME [epoch: 5.89 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17438500858302008		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 0.17438500858302008 | validation: 0.2972435411363599]
	TIME [epoch: 5.87 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18908402485140527		[learning rate: 0.002988]
	Learning Rate: 0.00298803
	LOSS [training: 0.18908402485140527 | validation: 0.35382217916059355]
	TIME [epoch: 5.88 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2158725066279473		[learning rate: 0.0029748]
	Learning Rate: 0.00297483
	LOSS [training: 0.2158725066279473 | validation: 0.29446022432892593]
	TIME [epoch: 5.87 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17522728142298236		[learning rate: 0.0029617]
	Learning Rate: 0.00296168
	LOSS [training: 0.17522728142298236 | validation: 0.29278796123451134]
	TIME [epoch: 5.88 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.175050217070793		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.175050217070793 | validation: 0.31648781412629307]
	TIME [epoch: 5.87 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17193166114980374		[learning rate: 0.0029356]
	Learning Rate: 0.00293557
	LOSS [training: 0.17193166114980374 | validation: 0.29985694304178045]
	TIME [epoch: 5.88 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18682185190419107		[learning rate: 0.0029226]
	Learning Rate: 0.0029226
	LOSS [training: 0.18682185190419107 | validation: 0.2920620512098046]
	TIME [epoch: 5.88 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17302994607969202		[learning rate: 0.0029097]
	Learning Rate: 0.00290969
	LOSS [training: 0.17302994607969202 | validation: 0.30563306267279844]
	TIME [epoch: 5.89 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17216765923432992		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 0.17216765923432992 | validation: 0.280868596014378]
	TIME [epoch: 5.88 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1723627770160915		[learning rate: 0.002884]
	Learning Rate: 0.00288403
	LOSS [training: 0.1723627770160915 | validation: 0.27455350773459236]
	TIME [epoch: 5.94 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19431705536687505		[learning rate: 0.0028713]
	Learning Rate: 0.00287129
	LOSS [training: 0.19431705536687505 | validation: 0.2955082801232784]
	TIME [epoch: 5.87 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1867603679658633		[learning rate: 0.0028586]
	Learning Rate: 0.0028586
	LOSS [training: 0.1867603679658633 | validation: 0.29653587269529763]
	TIME [epoch: 5.89 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17004451262772585		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 0.17004451262772585 | validation: 0.2879243421431492]
	TIME [epoch: 5.88 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1828148570626774		[learning rate: 0.0028334]
	Learning Rate: 0.0028334
	LOSS [training: 0.1828148570626774 | validation: 0.29340114374577875]
	TIME [epoch: 5.88 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17247189399699164		[learning rate: 0.0028209]
	Learning Rate: 0.00282088
	LOSS [training: 0.17247189399699164 | validation: 0.30502244798968836]
	TIME [epoch: 5.88 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17021944394798513		[learning rate: 0.0028084]
	Learning Rate: 0.00280842
	LOSS [training: 0.17021944394798513 | validation: 0.2777235526827045]
	TIME [epoch: 5.89 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17612625014376782		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 0.17612625014376782 | validation: 0.29069641522038014]
	TIME [epoch: 5.87 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17956973293161857		[learning rate: 0.0027837]
	Learning Rate: 0.00278366
	LOSS [training: 0.17956973293161857 | validation: 0.2999455309349389]
	TIME [epoch: 5.88 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17449540367769412		[learning rate: 0.0027714]
	Learning Rate: 0.00277136
	LOSS [training: 0.17449540367769412 | validation: 0.30719457549032386]
	TIME [epoch: 5.87 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17393656147159997		[learning rate: 0.0027591]
	Learning Rate: 0.00275911
	LOSS [training: 0.17393656147159997 | validation: 0.28246386950520475]
	TIME [epoch: 5.88 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17413132865356373		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 0.17413132865356373 | validation: 0.2993676231655973]
	TIME [epoch: 5.87 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.172097024705736		[learning rate: 0.0027348]
	Learning Rate: 0.00273478
	LOSS [training: 0.172097024705736 | validation: 0.2853253359768788]
	TIME [epoch: 5.88 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18010731102142685		[learning rate: 0.0027227]
	Learning Rate: 0.0027227
	LOSS [training: 0.18010731102142685 | validation: 0.29668165083246695]
	TIME [epoch: 5.88 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18152424835982278		[learning rate: 0.0027107]
	Learning Rate: 0.00271067
	LOSS [training: 0.18152424835982278 | validation: 0.31732149636457707]
	TIME [epoch: 5.88 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17802295900123988		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 0.17802295900123988 | validation: 0.29221958406432585]
	TIME [epoch: 5.87 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17019438006270748		[learning rate: 0.0026868]
	Learning Rate: 0.00268677
	LOSS [training: 0.17019438006270748 | validation: 0.29024444828285834]
	TIME [epoch: 5.87 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18038061139120984		[learning rate: 0.0026749]
	Learning Rate: 0.0026749
	LOSS [training: 0.18038061139120984 | validation: 0.29679362137357573]
	TIME [epoch: 5.88 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17351118003632604		[learning rate: 0.0026631]
	Learning Rate: 0.00266308
	LOSS [training: 0.17351118003632604 | validation: 0.2899462548986937]
	TIME [epoch: 5.88 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1675869443916049		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 0.1675869443916049 | validation: 0.28221073802931956]
	TIME [epoch: 5.88 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1818189496344535		[learning rate: 0.0026396]
	Learning Rate: 0.0026396
	LOSS [training: 0.1818189496344535 | validation: 0.2822798713334764]
	TIME [epoch: 5.87 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17598684099297937		[learning rate: 0.0026279]
	Learning Rate: 0.00262794
	LOSS [training: 0.17598684099297937 | validation: 0.275356854054385]
	TIME [epoch: 5.88 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17225543906133606		[learning rate: 0.0026163]
	Learning Rate: 0.00261633
	LOSS [training: 0.17225543906133606 | validation: 0.2842066098863873]
	TIME [epoch: 5.88 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17006629620416192		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 0.17006629620416192 | validation: 0.2955455837023194]
	TIME [epoch: 5.87 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17869750695095704		[learning rate: 0.0025933]
	Learning Rate: 0.00259326
	LOSS [training: 0.17869750695095704 | validation: 0.3195630671043889]
	TIME [epoch: 5.87 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1680215678982809		[learning rate: 0.0025818]
	Learning Rate: 0.0025818
	LOSS [training: 0.1680215678982809 | validation: 0.2865667812923849]
	TIME [epoch: 5.87 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17129099156413044		[learning rate: 0.0025704]
	Learning Rate: 0.0025704
	LOSS [training: 0.17129099156413044 | validation: 0.2864377963723241]
	TIME [epoch: 5.88 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1723212944155658		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.1723212944155658 | validation: 0.2766724355063643]
	TIME [epoch: 5.87 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18590573168191235		[learning rate: 0.0025477]
	Learning Rate: 0.00254773
	LOSS [training: 0.18590573168191235 | validation: 0.2816168766498858]
	TIME [epoch: 5.88 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21860827925274876		[learning rate: 0.0025365]
	Learning Rate: 0.00253648
	LOSS [training: 0.21860827925274876 | validation: 0.3027186480563472]
	TIME [epoch: 5.87 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17706399689895927		[learning rate: 0.0025253]
	Learning Rate: 0.00252527
	LOSS [training: 0.17706399689895927 | validation: 0.29164607673951387]
	TIME [epoch: 5.87 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16743411416313686		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.16743411416313686 | validation: 0.29265495918897344]
	TIME [epoch: 5.87 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16644554204333026		[learning rate: 0.002503]
	Learning Rate: 0.002503
	LOSS [training: 0.16644554204333026 | validation: 0.2994844546521741]
	TIME [epoch: 5.87 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16884951061166098		[learning rate: 0.0024919]
	Learning Rate: 0.00249194
	LOSS [training: 0.16884951061166098 | validation: 0.29347763442320174]
	TIME [epoch: 5.87 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17774338224119152		[learning rate: 0.0024809]
	Learning Rate: 0.00248093
	LOSS [training: 0.17774338224119152 | validation: 0.2820068915212578]
	TIME [epoch: 5.88 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16897548284421862		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 0.16897548284421862 | validation: 0.2873783793429226]
	TIME [epoch: 5.87 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.166200653828591		[learning rate: 0.0024591]
	Learning Rate: 0.00245906
	LOSS [training: 0.166200653828591 | validation: 0.31191392903082593]
	TIME [epoch: 5.89 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1768684895458664		[learning rate: 0.0024482]
	Learning Rate: 0.0024482
	LOSS [training: 0.1768684895458664 | validation: 0.3092905657064891]
	TIME [epoch: 5.89 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16444392708406166		[learning rate: 0.0024374]
	Learning Rate: 0.00243738
	LOSS [training: 0.16444392708406166 | validation: 0.2835551681610399]
	TIME [epoch: 5.88 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17045861930194348		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.17045861930194348 | validation: 0.3291971882482823]
	TIME [epoch: 5.87 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17608572884004403		[learning rate: 0.0024159]
	Learning Rate: 0.00241589
	LOSS [training: 0.17608572884004403 | validation: 0.28451107991855984]
	TIME [epoch: 5.88 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16945881993614045		[learning rate: 0.0024052]
	Learning Rate: 0.00240521
	LOSS [training: 0.16945881993614045 | validation: 0.27613774792484364]
	TIME [epoch: 5.88 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1761799448191187		[learning rate: 0.0023946]
	Learning Rate: 0.00239459
	LOSS [training: 0.1761799448191187 | validation: 0.31347785948458273]
	TIME [epoch: 5.87 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17782520966298893		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 0.17782520966298893 | validation: 0.29271911548344726]
	TIME [epoch: 5.88 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17511543897735152		[learning rate: 0.0023735]
	Learning Rate: 0.00237347
	LOSS [training: 0.17511543897735152 | validation: 0.29068196296963467]
	TIME [epoch: 5.88 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17468700675314588		[learning rate: 0.002363]
	Learning Rate: 0.00236299
	LOSS [training: 0.17468700675314588 | validation: 0.28418234728420816]
	TIME [epoch: 5.87 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16775163825465125		[learning rate: 0.0023525]
	Learning Rate: 0.00235255
	LOSS [training: 0.16775163825465125 | validation: 0.30638921430669885]
	TIME [epoch: 5.87 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17399506573301882		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.17399506573301882 | validation: 0.26983933278889755]
	TIME [epoch: 5.87 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18750787402653568		[learning rate: 0.0023318]
	Learning Rate: 0.00233181
	LOSS [training: 0.18750787402653568 | validation: 0.30311754939485125]
	TIME [epoch: 5.88 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17029603650746497		[learning rate: 0.0023215]
	Learning Rate: 0.0023215
	LOSS [training: 0.17029603650746497 | validation: 0.2766636116029594]
	TIME [epoch: 5.87 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17422693500405068		[learning rate: 0.0023112]
	Learning Rate: 0.00231125
	LOSS [training: 0.17422693500405068 | validation: 0.2822285197426228]
	TIME [epoch: 5.87 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16906328631205453		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.16906328631205453 | validation: 0.2970895257717876]
	TIME [epoch: 5.88 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16932128517750583		[learning rate: 0.0022909]
	Learning Rate: 0.00229087
	LOSS [training: 0.16932128517750583 | validation: 0.2938171916463225]
	TIME [epoch: 5.88 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16524065988542058		[learning rate: 0.0022807]
	Learning Rate: 0.00228075
	LOSS [training: 0.16524065988542058 | validation: 0.30193686930617186]
	TIME [epoch: 5.88 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17721429627878754		[learning rate: 0.0022707]
	Learning Rate: 0.00227067
	LOSS [training: 0.17721429627878754 | validation: 0.324542289865606]
	TIME [epoch: 5.88 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16944145501435268		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.16944145501435268 | validation: 0.31223428863800545]
	TIME [epoch: 5.87 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17091918726776928		[learning rate: 0.0022506]
	Learning Rate: 0.00225065
	LOSS [training: 0.17091918726776928 | validation: 0.30147330196526223]
	TIME [epoch: 5.88 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16962401686785805		[learning rate: 0.0022407]
	Learning Rate: 0.0022407
	LOSS [training: 0.16962401686785805 | validation: 0.2943286523777705]
	TIME [epoch: 5.88 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16647901552491745		[learning rate: 0.0022308]
	Learning Rate: 0.0022308
	LOSS [training: 0.16647901552491745 | validation: 0.2892227989469432]
	TIME [epoch: 5.87 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17991421963141813		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.17991421963141813 | validation: 0.3080063802974688]
	TIME [epoch: 5.88 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17928445604168985		[learning rate: 0.0022111]
	Learning Rate: 0.00221114
	LOSS [training: 0.17928445604168985 | validation: 0.38736159071769133]
	TIME [epoch: 5.89 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17042849895476375		[learning rate: 0.0022014]
	Learning Rate: 0.00220137
	LOSS [training: 0.17042849895476375 | validation: 0.296748246598994]
	TIME [epoch: 5.87 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17056376832118503		[learning rate: 0.0021916]
	Learning Rate: 0.00219164
	LOSS [training: 0.17056376832118503 | validation: 0.291348180445897]
	TIME [epoch: 5.88 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16698902390571146		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.16698902390571146 | validation: 0.3139096574372592]
	TIME [epoch: 5.87 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1692253958576002		[learning rate: 0.0021723]
	Learning Rate: 0.00217232
	LOSS [training: 0.1692253958576002 | validation: 0.30297903441277835]
	TIME [epoch: 5.88 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16933485172903526		[learning rate: 0.0021627]
	Learning Rate: 0.00216272
	LOSS [training: 0.16933485172903526 | validation: 0.2837236410865643]
	TIME [epoch: 5.87 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17306412725894568		[learning rate: 0.0021532]
	Learning Rate: 0.00215316
	LOSS [training: 0.17306412725894568 | validation: 0.277169619193661]
	TIME [epoch: 5.88 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1712839999483758		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.1712839999483758 | validation: 0.276519383857556]
	TIME [epoch: 5.89 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17040792095318127		[learning rate: 0.0021342]
	Learning Rate: 0.00213418
	LOSS [training: 0.17040792095318127 | validation: 0.28816763321725913]
	TIME [epoch: 5.89 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16645520434300384		[learning rate: 0.0021247]
	Learning Rate: 0.00212475
	LOSS [training: 0.16645520434300384 | validation: 0.28623156979667813]
	TIME [epoch: 5.87 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17340518052512355		[learning rate: 0.0021154]
	Learning Rate: 0.00211536
	LOSS [training: 0.17340518052512355 | validation: 0.2890401370224174]
	TIME [epoch: 5.88 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16442333632742595		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.16442333632742595 | validation: 0.2969428999089927]
	TIME [epoch: 5.88 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17418364872195702		[learning rate: 0.0020967]
	Learning Rate: 0.00209671
	LOSS [training: 0.17418364872195702 | validation: 0.3318231457962347]
	TIME [epoch: 5.88 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16853571081874905		[learning rate: 0.0020874]
	Learning Rate: 0.00208745
	LOSS [training: 0.16853571081874905 | validation: 0.31187579009564165]
	TIME [epoch: 5.87 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17563580688670402		[learning rate: 0.0020782]
	Learning Rate: 0.00207822
	LOSS [training: 0.17563580688670402 | validation: 0.29656593518141683]
	TIME [epoch: 5.88 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17015526549094967		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.17015526549094967 | validation: 0.2968566239106642]
	TIME [epoch: 5.88 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1757727872911275		[learning rate: 0.0020599]
	Learning Rate: 0.0020599
	LOSS [training: 0.1757727872911275 | validation: 0.33781925763374343]
	TIME [epoch: 5.88 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1717461977319409		[learning rate: 0.0020508]
	Learning Rate: 0.0020508
	LOSS [training: 0.1717461977319409 | validation: 0.3041588341561535]
	TIME [epoch: 5.87 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17017656774280324		[learning rate: 0.0020417]
	Learning Rate: 0.00204174
	LOSS [training: 0.17017656774280324 | validation: 0.2763887031660387]
	TIME [epoch: 5.88 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17380423447001325		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.17380423447001325 | validation: 0.2820673973499406]
	TIME [epoch: 5.87 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1703132655895861		[learning rate: 0.0020237]
	Learning Rate: 0.00202374
	LOSS [training: 0.1703132655895861 | validation: 0.2948612476412439]
	TIME [epoch: 5.88 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16928396241866567		[learning rate: 0.0020148]
	Learning Rate: 0.00201479
	LOSS [training: 0.16928396241866567 | validation: 0.31023250832127547]
	TIME [epoch: 5.88 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17735872203535957		[learning rate: 0.0020059]
	Learning Rate: 0.00200589
	LOSS [training: 0.17735872203535957 | validation: 0.28899869205030004]
	TIME [epoch: 5.9 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16405822410578585		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.16405822410578585 | validation: 0.29613590900004455]
	TIME [epoch: 5.89 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16750480249139355		[learning rate: 0.0019882]
	Learning Rate: 0.00198821
	LOSS [training: 0.16750480249139355 | validation: 0.30831349769858324]
	TIME [epoch: 5.88 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17165576152036252		[learning rate: 0.0019794]
	Learning Rate: 0.00197942
	LOSS [training: 0.17165576152036252 | validation: 0.3065065958209417]
	TIME [epoch: 5.89 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16349415183646354		[learning rate: 0.0019707]
	Learning Rate: 0.00197068
	LOSS [training: 0.16349415183646354 | validation: 0.28184014077056274]
	TIME [epoch: 5.88 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16621827639761053		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.16621827639761053 | validation: 0.2738418230515153]
	TIME [epoch: 5.88 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1682892018651602		[learning rate: 0.0019533]
	Learning Rate: 0.0019533
	LOSS [training: 0.1682892018651602 | validation: 0.28424575778383]
	TIME [epoch: 5.88 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17574298432117708		[learning rate: 0.0019447]
	Learning Rate: 0.00194467
	LOSS [training: 0.17574298432117708 | validation: 0.3002756516268428]
	TIME [epoch: 5.88 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18048860436113123		[learning rate: 0.0019361]
	Learning Rate: 0.00193608
	LOSS [training: 0.18048860436113123 | validation: 0.30705485276890676]
	TIME [epoch: 5.89 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16855566583162532		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.16855566583162532 | validation: 0.29755856459963237]
	TIME [epoch: 5.88 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17783647479422848		[learning rate: 0.001919]
	Learning Rate: 0.00191901
	LOSS [training: 0.17783647479422848 | validation: 0.27683026313633435]
	TIME [epoch: 5.88 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1668568324088288		[learning rate: 0.0019105]
	Learning Rate: 0.00191053
	LOSS [training: 0.1668568324088288 | validation: 0.285559854304206]
	TIME [epoch: 5.88 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16660113673438834		[learning rate: 0.0019021]
	Learning Rate: 0.00190209
	LOSS [training: 0.16660113673438834 | validation: 0.2720111127140421]
	TIME [epoch: 5.88 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1687505782577102		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.1687505782577102 | validation: 0.27688219997838703]
	TIME [epoch: 5.88 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17621858214528022		[learning rate: 0.0018853]
	Learning Rate: 0.00188532
	LOSS [training: 0.17621858214528022 | validation: 0.2842195825781507]
	TIME [epoch: 5.88 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16912005370570188		[learning rate: 0.001877]
	Learning Rate: 0.00187699
	LOSS [training: 0.16912005370570188 | validation: 0.29107028604988494]
	TIME [epoch: 5.89 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16683308840390615		[learning rate: 0.0018687]
	Learning Rate: 0.0018687
	LOSS [training: 0.16683308840390615 | validation: 0.26158673280413375]
	TIME [epoch: 5.89 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v11_20240712_140902/states/model_facs_v2_dec2b_2dpca_v11_419.pth
	Model improved!!!
EPOCH 420/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16616848996036823		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.16616848996036823 | validation: 0.2837785417765842]
	TIME [epoch: 5.88 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16761474492043177		[learning rate: 0.0018522]
	Learning Rate: 0.00185222
	LOSS [training: 0.16761474492043177 | validation: 0.2871840915051266]
	TIME [epoch: 5.89 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1666321682695115		[learning rate: 0.001844]
	Learning Rate: 0.00184404
	LOSS [training: 0.1666321682695115 | validation: 0.2831571889881383]
	TIME [epoch: 5.88 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16708090511960322		[learning rate: 0.0018359]
	Learning Rate: 0.00183589
	LOSS [training: 0.16708090511960322 | validation: 0.2710844595568189]
	TIME [epoch: 5.88 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16907134343561966		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.16907134343561966 | validation: 0.28282328058454276]
	TIME [epoch: 5.88 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1750870401584105		[learning rate: 0.0018197]
	Learning Rate: 0.0018197
	LOSS [training: 0.1750870401584105 | validation: 0.2846965855672222]
	TIME [epoch: 5.88 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17504855864400704		[learning rate: 0.0018117]
	Learning Rate: 0.00181166
	LOSS [training: 0.17504855864400704 | validation: 0.2761371899981123]
	TIME [epoch: 5.89 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16683164998868044		[learning rate: 0.0018037]
	Learning Rate: 0.00180366
	LOSS [training: 0.16683164998868044 | validation: 0.29013371183226555]
	TIME [epoch: 5.89 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17050730960584154		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.17050730960584154 | validation: 0.28898302328871794]
	TIME [epoch: 5.88 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17001130091292935		[learning rate: 0.0017878]
	Learning Rate: 0.00178775
	LOSS [training: 0.17001130091292935 | validation: 0.2929736061909845]
	TIME [epoch: 5.88 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1715306895310817		[learning rate: 0.0017799]
	Learning Rate: 0.00177985
	LOSS [training: 0.1715306895310817 | validation: 0.2904043532874855]
	TIME [epoch: 5.89 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.168785332626037		[learning rate: 0.001772]
	Learning Rate: 0.00177199
	LOSS [training: 0.168785332626037 | validation: 0.28166286323047784]
	TIME [epoch: 5.88 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1724419606030895		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.1724419606030895 | validation: 0.2880934538283276]
	TIME [epoch: 5.88 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17212066631261008		[learning rate: 0.0017564]
	Learning Rate: 0.00175637
	LOSS [training: 0.17212066631261008 | validation: 0.28145034437219824]
	TIME [epoch: 5.88 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16399995844534257		[learning rate: 0.0017486]
	Learning Rate: 0.00174861
	LOSS [training: 0.16399995844534257 | validation: 0.2824729928249842]
	TIME [epoch: 5.89 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16527572895875559		[learning rate: 0.0017409]
	Learning Rate: 0.00174088
	LOSS [training: 0.16527572895875559 | validation: 0.293639919244755]
	TIME [epoch: 5.88 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16973426207181352		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.16973426207181352 | validation: 0.2772223408914545]
	TIME [epoch: 5.88 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16711736361053564		[learning rate: 0.0017255]
	Learning Rate: 0.00172553
	LOSS [training: 0.16711736361053564 | validation: 0.27181138623248075]
	TIME [epoch: 5.88 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16608869785319277		[learning rate: 0.0017179]
	Learning Rate: 0.00171791
	LOSS [training: 0.16608869785319277 | validation: 0.2868829447633502]
	TIME [epoch: 5.88 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17217447087020452		[learning rate: 0.0017103]
	Learning Rate: 0.00171032
	LOSS [training: 0.17217447087020452 | validation: 0.28806951754001964]
	TIME [epoch: 5.88 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17072411294336937		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.17072411294336937 | validation: 0.2972931064717949]
	TIME [epoch: 5.88 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16400561885618056		[learning rate: 0.0016952]
	Learning Rate: 0.00169524
	LOSS [training: 0.16400561885618056 | validation: 0.2875471009609223]
	TIME [epoch: 5.89 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16824221134020972		[learning rate: 0.0016877]
	Learning Rate: 0.00168775
	LOSS [training: 0.16824221134020972 | validation: 0.29762118740014115]
	TIME [epoch: 5.88 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1706920404511457		[learning rate: 0.0016803]
	Learning Rate: 0.00168029
	LOSS [training: 0.1706920404511457 | validation: 0.27055535621780746]
	TIME [epoch: 5.88 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1690466250309999		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.1690466250309999 | validation: 0.3006256749167518]
	TIME [epoch: 5.88 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16536513539760925		[learning rate: 0.0016655]
	Learning Rate: 0.00166548
	LOSS [training: 0.16536513539760925 | validation: 0.2794181450067805]
	TIME [epoch: 5.88 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16621645544453328		[learning rate: 0.0016581]
	Learning Rate: 0.00165812
	LOSS [training: 0.16621645544453328 | validation: 0.28665623102372445]
	TIME [epoch: 5.88 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1762434720626541		[learning rate: 0.0016508]
	Learning Rate: 0.00165079
	LOSS [training: 0.1762434720626541 | validation: 0.2776611822242991]
	TIME [epoch: 5.88 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16026166144050202		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.16026166144050202 | validation: 0.271188941047461]
	TIME [epoch: 5.88 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16489317816820054		[learning rate: 0.0016362]
	Learning Rate: 0.00163624
	LOSS [training: 0.16489317816820054 | validation: 0.2720143496414849]
	TIME [epoch: 5.89 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1651775090129824		[learning rate: 0.001629]
	Learning Rate: 0.00162901
	LOSS [training: 0.1651775090129824 | validation: 0.29169475292165037]
	TIME [epoch: 5.88 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16823605220801627		[learning rate: 0.0016218]
	Learning Rate: 0.00162181
	LOSS [training: 0.16823605220801627 | validation: 0.32672419210249737]
	TIME [epoch: 5.88 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1711540838462982		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.1711540838462982 | validation: 0.28664802988841903]
	TIME [epoch: 5.87 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16373549389427655		[learning rate: 0.0016075]
	Learning Rate: 0.00160751
	LOSS [training: 0.16373549389427655 | validation: 0.2796071498586011]
	TIME [epoch: 5.87 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17074746389626805		[learning rate: 0.0016004]
	Learning Rate: 0.00160041
	LOSS [training: 0.17074746389626805 | validation: 0.28559933741493215]
	TIME [epoch: 5.87 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18564368522058539		[learning rate: 0.0015933]
	Learning Rate: 0.00159334
	LOSS [training: 0.18564368522058539 | validation: 0.313734732226454]
	TIME [epoch: 5.87 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18611942498748973		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.18611942498748973 | validation: 0.29585515315786803]
	TIME [epoch: 5.88 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17796066993267765		[learning rate: 0.0015793]
	Learning Rate: 0.00157929
	LOSS [training: 0.17796066993267765 | validation: 0.2838591065086759]
	TIME [epoch: 5.88 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17253731633164096		[learning rate: 0.0015723]
	Learning Rate: 0.00157231
	LOSS [training: 0.17253731633164096 | validation: 0.28222245175762506]
	TIME [epoch: 5.88 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1689214503948977		[learning rate: 0.0015654]
	Learning Rate: 0.00156536
	LOSS [training: 0.1689214503948977 | validation: 0.30388431081991457]
	TIME [epoch: 5.87 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16827897962524624		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.16827897962524624 | validation: 0.2871218218629972]
	TIME [epoch: 5.87 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17227021427186323		[learning rate: 0.0015516]
	Learning Rate: 0.00155156
	LOSS [training: 0.17227021427186323 | validation: 0.25913664128933955]
	TIME [epoch: 5.88 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v11_20240712_140902/states/model_facs_v2_dec2b_2dpca_v11_461.pth
	Model improved!!!
EPOCH 462/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16944999481327325		[learning rate: 0.0015447]
	Learning Rate: 0.00154471
	LOSS [training: 0.16944999481327325 | validation: 0.26207417300618036]
	TIME [epoch: 5.89 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1637308939689933		[learning rate: 0.0015379]
	Learning Rate: 0.00153788
	LOSS [training: 0.1637308939689933 | validation: 0.2697190691729624]
	TIME [epoch: 5.87 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1668114230195314		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.1668114230195314 | validation: 0.280725353757022]
	TIME [epoch: 5.89 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16331851876780232		[learning rate: 0.0015243]
	Learning Rate: 0.00152432
	LOSS [training: 0.16331851876780232 | validation: 0.28527127763825877]
	TIME [epoch: 5.89 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17122886763182044		[learning rate: 0.0015176]
	Learning Rate: 0.00151759
	LOSS [training: 0.17122886763182044 | validation: 0.2719854735804963]
	TIME [epoch: 5.88 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17188410454827235		[learning rate: 0.0015109]
	Learning Rate: 0.00151088
	LOSS [training: 0.17188410454827235 | validation: 0.29836253673432445]
	TIME [epoch: 5.87 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16795812465123217		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.16795812465123217 | validation: 0.2992528858395314]
	TIME [epoch: 5.88 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1676163835009839		[learning rate: 0.0014976]
	Learning Rate: 0.00149756
	LOSS [training: 0.1676163835009839 | validation: 0.27457282481726614]
	TIME [epoch: 5.88 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17033005921613004		[learning rate: 0.0014909]
	Learning Rate: 0.00149094
	LOSS [training: 0.17033005921613004 | validation: 0.2919268674627924]
	TIME [epoch: 5.88 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1658076059441232		[learning rate: 0.0014844]
	Learning Rate: 0.00148436
	LOSS [training: 0.1658076059441232 | validation: 0.2750316127153725]
	TIME [epoch: 5.87 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16773537217812606		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.16773537217812606 | validation: 0.2680951488417882]
	TIME [epoch: 5.89 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1675977804367355		[learning rate: 0.0014713]
	Learning Rate: 0.00147127
	LOSS [training: 0.1675977804367355 | validation: 0.2859142818344506]
	TIME [epoch: 5.88 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1692910235501491		[learning rate: 0.0014648]
	Learning Rate: 0.00146477
	LOSS [training: 0.1692910235501491 | validation: 0.3048229421925668]
	TIME [epoch: 5.87 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16949395938446815		[learning rate: 0.0014583]
	Learning Rate: 0.0014583
	LOSS [training: 0.16949395938446815 | validation: 0.29421791063976066]
	TIME [epoch: 5.87 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16775427749123525		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.16775427749123525 | validation: 0.2923135719983712]
	TIME [epoch: 5.88 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16667663885292017		[learning rate: 0.0014454]
	Learning Rate: 0.00144544
	LOSS [training: 0.16667663885292017 | validation: 0.286060781421269]
	TIME [epoch: 5.87 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16862652513605547		[learning rate: 0.0014391]
	Learning Rate: 0.00143905
	LOSS [training: 0.16862652513605547 | validation: 0.29007113273179946]
	TIME [epoch: 5.87 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17050957741065498		[learning rate: 0.0014327]
	Learning Rate: 0.0014327
	LOSS [training: 0.17050957741065498 | validation: 0.29112165399379725]
	TIME [epoch: 5.88 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16516086817193934		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.16516086817193934 | validation: 0.29025548361263526]
	TIME [epoch: 5.88 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16517403362279465		[learning rate: 0.0014201]
	Learning Rate: 0.00142006
	LOSS [training: 0.16517403362279465 | validation: 0.28393560893537845]
	TIME [epoch: 5.88 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17090802660780754		[learning rate: 0.0014138]
	Learning Rate: 0.00141379
	LOSS [training: 0.17090802660780754 | validation: 0.267873562328029]
	TIME [epoch: 5.87 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16772510401120228		[learning rate: 0.0014075]
	Learning Rate: 0.00140754
	LOSS [training: 0.16772510401120228 | validation: 0.29277988283762096]
	TIME [epoch: 5.88 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1639700805603918		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.1639700805603918 | validation: 0.29352815580346564]
	TIME [epoch: 5.88 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16684093485929072		[learning rate: 0.0013951]
	Learning Rate: 0.00139513
	LOSS [training: 0.16684093485929072 | validation: 0.28087709592849935]
	TIME [epoch: 5.88 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17239186151092262		[learning rate: 0.001389]
	Learning Rate: 0.00138897
	LOSS [training: 0.17239186151092262 | validation: 0.2735780933266425]
	TIME [epoch: 5.87 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15927252651627893		[learning rate: 0.0013828]
	Learning Rate: 0.00138283
	LOSS [training: 0.15927252651627893 | validation: 0.2898094960814985]
	TIME [epoch: 5.89 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16065844643631838		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.16065844643631838 | validation: 0.2899407517426629]
	TIME [epoch: 5.88 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1702975958475118		[learning rate: 0.0013706]
	Learning Rate: 0.00137064
	LOSS [training: 0.1702975958475118 | validation: 0.2826638970030956]
	TIME [epoch: 5.88 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16743562101481146		[learning rate: 0.0013646]
	Learning Rate: 0.00136458
	LOSS [training: 0.16743562101481146 | validation: 0.28144167378951207]
	TIME [epoch: 5.87 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16708413069810707		[learning rate: 0.0013586]
	Learning Rate: 0.00135855
	LOSS [training: 0.16708413069810707 | validation: 0.27186134756965497]
	TIME [epoch: 5.88 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16224005631457364		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.16224005631457364 | validation: 0.28452461711448795]
	TIME [epoch: 5.88 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16336708804305275		[learning rate: 0.0013466]
	Learning Rate: 0.00134658
	LOSS [training: 0.16336708804305275 | validation: 0.2658035125395499]
	TIME [epoch: 5.88 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1657917165621094		[learning rate: 0.0013406]
	Learning Rate: 0.00134063
	LOSS [training: 0.1657917165621094 | validation: 0.28367687489796717]
	TIME [epoch: 5.88 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16247624463006963		[learning rate: 0.0013347]
	Learning Rate: 0.0013347
	LOSS [training: 0.16247624463006963 | validation: 0.2972476809631159]
	TIME [epoch: 5.89 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16476682077762317		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.16476682077762317 | validation: 0.3100169658809975]
	TIME [epoch: 5.89 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17552744786690705		[learning rate: 0.0013229]
	Learning Rate: 0.00132293
	LOSS [training: 0.17552744786690705 | validation: 0.2684713006355163]
	TIME [epoch: 5.88 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16255809780233493		[learning rate: 0.0013171]
	Learning Rate: 0.00131709
	LOSS [training: 0.16255809780233493 | validation: 0.31392140357330556]
	TIME [epoch: 5.88 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17467063887148232		[learning rate: 0.0013113]
	Learning Rate: 0.00131127
	LOSS [training: 0.17467063887148232 | validation: 0.2709195777276308]
	TIME [epoch: 5.87 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17720271529409917		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.17720271529409917 | validation: 0.28520526912039124]
	TIME [epoch: 5.88 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16731613562946235		[learning rate: 0.0012997]
	Learning Rate: 0.00129971
	LOSS [training: 0.16731613562946235 | validation: 0.27973664318951996]
	TIME [epoch: 32.9 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16802899232889876		[learning rate: 0.001294]
	Learning Rate: 0.00129397
	LOSS [training: 0.16802899232889876 | validation: 0.2678573682642583]
	TIME [epoch: 11.4 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16546604927925745		[learning rate: 0.0012882]
	Learning Rate: 0.00128825
	LOSS [training: 0.16546604927925745 | validation: 0.2776633403315128]
	TIME [epoch: 11.3 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17835203857599577		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.17835203857599577 | validation: 0.31392454578942]
	TIME [epoch: 11.4 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17156296188503078		[learning rate: 0.0012769]
	Learning Rate: 0.00127689
	LOSS [training: 0.17156296188503078 | validation: 0.2858380083971796]
	TIME [epoch: 11.4 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16249639250097864		[learning rate: 0.0012712]
	Learning Rate: 0.00127125
	LOSS [training: 0.16249639250097864 | validation: 0.28929643975725594]
	TIME [epoch: 11.4 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16063893027178333		[learning rate: 0.0012656]
	Learning Rate: 0.00126563
	LOSS [training: 0.16063893027178333 | validation: 0.27831964660342556]
	TIME [epoch: 11.3 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16835517417303253		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.16835517417303253 | validation: 0.27393789770725024]
	TIME [epoch: 11.3 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15909641545152195		[learning rate: 0.0012545]
	Learning Rate: 0.00125447
	LOSS [training: 0.15909641545152195 | validation: 0.2795580122461857]
	TIME [epoch: 11.4 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16161640654366755		[learning rate: 0.0012489]
	Learning Rate: 0.00124893
	LOSS [training: 0.16161640654366755 | validation: 0.2798453464258737]
	TIME [epoch: 11.4 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16244431621302297		[learning rate: 0.0012434]
	Learning Rate: 0.00124341
	LOSS [training: 0.16244431621302297 | validation: 0.29399070926394505]
	TIME [epoch: 11.3 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16241505537267525		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.16241505537267525 | validation: 0.27715940641465353]
	TIME [epoch: 11.3 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16326103718455517		[learning rate: 0.0012324]
	Learning Rate: 0.00123245
	LOSS [training: 0.16326103718455517 | validation: 0.29110463117572966]
	TIME [epoch: 11.3 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16400794157271256		[learning rate: 0.001227]
	Learning Rate: 0.001227
	LOSS [training: 0.16400794157271256 | validation: 0.2872446116630568]
	TIME [epoch: 11.3 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17242595059644067		[learning rate: 0.0012216]
	Learning Rate: 0.00122158
	LOSS [training: 0.17242595059644067 | validation: 0.27514233105089747]
	TIME [epoch: 11.3 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16500752620041226		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.16500752620041226 | validation: 0.27475705523714633]
	TIME [epoch: 11.4 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17066690875600565		[learning rate: 0.0012108]
	Learning Rate: 0.00121081
	LOSS [training: 0.17066690875600565 | validation: 0.2667399772027635]
	TIME [epoch: 11.4 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16246464550834175		[learning rate: 0.0012055]
	Learning Rate: 0.00120546
	LOSS [training: 0.16246464550834175 | validation: 0.2785480619038074]
	TIME [epoch: 11.3 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1682728617904594		[learning rate: 0.0012001]
	Learning Rate: 0.00120014
	LOSS [training: 0.1682728617904594 | validation: 0.28991977276820624]
	TIME [epoch: 11.3 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16372159228916391		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.16372159228916391 | validation: 0.27200929520279954]
	TIME [epoch: 11.4 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16225357906563675		[learning rate: 0.0011896]
	Learning Rate: 0.00118956
	LOSS [training: 0.16225357906563675 | validation: 0.2692691854450412]
	TIME [epoch: 11.4 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1624114500145422		[learning rate: 0.0011843]
	Learning Rate: 0.0011843
	LOSS [training: 0.1624114500145422 | validation: 0.27025833058591037]
	TIME [epoch: 11.3 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16272639791543503		[learning rate: 0.0011791]
	Learning Rate: 0.00117907
	LOSS [training: 0.16272639791543503 | validation: 0.28138526547015746]
	TIME [epoch: 11.3 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16180033189459533		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.16180033189459533 | validation: 0.2680190528730122]
	TIME [epoch: 11.3 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16614512221467365		[learning rate: 0.0011687]
	Learning Rate: 0.00116867
	LOSS [training: 0.16614512221467365 | validation: 0.27693479380348224]
	TIME [epoch: 11.4 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16847338612727514		[learning rate: 0.0011635]
	Learning Rate: 0.00116351
	LOSS [training: 0.16847338612727514 | validation: 0.28983432310411783]
	TIME [epoch: 11.3 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16565504327389297		[learning rate: 0.0011584]
	Learning Rate: 0.00115837
	LOSS [training: 0.16565504327389297 | validation: 0.2808519973817289]
	TIME [epoch: 11.3 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17251386779355976		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.17251386779355976 | validation: 0.2916069958590428]
	TIME [epoch: 11.4 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17823289397859657		[learning rate: 0.0011482]
	Learning Rate: 0.00114815
	LOSS [training: 0.17823289397859657 | validation: 0.2974844079854374]
	TIME [epoch: 11.3 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17834894936240825		[learning rate: 0.0011431]
	Learning Rate: 0.00114308
	LOSS [training: 0.17834894936240825 | validation: 0.27647978700620135]
	TIME [epoch: 11.3 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1743897406829389		[learning rate: 0.001138]
	Learning Rate: 0.00113803
	LOSS [training: 0.1743897406829389 | validation: 0.28731538473994295]
	TIME [epoch: 11.3 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16314347398794732		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.16314347398794732 | validation: 0.27728347322162533]
	TIME [epoch: 11.3 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.163403241775442		[learning rate: 0.001128]
	Learning Rate: 0.001128
	LOSS [training: 0.163403241775442 | validation: 0.2819441574423315]
	TIME [epoch: 11.4 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16098437129775076		[learning rate: 0.001123]
	Learning Rate: 0.00112301
	LOSS [training: 0.16098437129775076 | validation: 0.26799010103349863]
	TIME [epoch: 11.4 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16506135809801684		[learning rate: 0.0011181]
	Learning Rate: 0.00111805
	LOSS [training: 0.16506135809801684 | validation: 0.27273347900714856]
	TIME [epoch: 11.4 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16740897630089652		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.16740897630089652 | validation: 0.2714813180945241]
	TIME [epoch: 11.3 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16738293530295537		[learning rate: 0.0011082]
	Learning Rate: 0.00110819
	LOSS [training: 0.16738293530295537 | validation: 0.27910083736223606]
	TIME [epoch: 11.3 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16359781463297401		[learning rate: 0.0011033]
	Learning Rate: 0.0011033
	LOSS [training: 0.16359781463297401 | validation: 0.2958689491350581]
	TIME [epoch: 11.3 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16199950765332083		[learning rate: 0.0010984]
	Learning Rate: 0.00109842
	LOSS [training: 0.16199950765332083 | validation: 0.2872084626082258]
	TIME [epoch: 11.3 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15883146201486245		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.15883146201486245 | validation: 0.2955397131689789]
	TIME [epoch: 11.3 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16622070639137898		[learning rate: 0.0010887]
	Learning Rate: 0.00108874
	LOSS [training: 0.16622070639137898 | validation: 0.28361004881797297]
	TIME [epoch: 11.3 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16833276352260182		[learning rate: 0.0010839]
	Learning Rate: 0.00108393
	LOSS [training: 0.16833276352260182 | validation: 0.27599726705849836]
	TIME [epoch: 11.3 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1633433603385624		[learning rate: 0.0010791]
	Learning Rate: 0.00107914
	LOSS [training: 0.1633433603385624 | validation: 0.2763245930498781]
	TIME [epoch: 11.3 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16187424309240167		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.16187424309240167 | validation: 0.27299968587438833]
	TIME [epoch: 11.3 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1636039860519245		[learning rate: 0.0010696]
	Learning Rate: 0.00106962
	LOSS [training: 0.1636039860519245 | validation: 0.27480395189398765]
	TIME [epoch: 11.3 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16625713324698568		[learning rate: 0.0010649]
	Learning Rate: 0.0010649
	LOSS [training: 0.16625713324698568 | validation: 0.29004329560141023]
	TIME [epoch: 11.4 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16525225946220998		[learning rate: 0.0010602]
	Learning Rate: 0.00106019
	LOSS [training: 0.16525225946220998 | validation: 0.26918430348794253]
	TIME [epoch: 11.3 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16108254789035142		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.16108254789035142 | validation: 0.27936714453827083]
	TIME [epoch: 11.3 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16350295693374586		[learning rate: 0.0010508]
	Learning Rate: 0.00105084
	LOSS [training: 0.16350295693374586 | validation: 0.28917916177324665]
	TIME [epoch: 11.3 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1645242956168293		[learning rate: 0.0010462]
	Learning Rate: 0.0010462
	LOSS [training: 0.1645242956168293 | validation: 0.2710466242116376]
	TIME [epoch: 11.3 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16477060907579374		[learning rate: 0.0010416]
	Learning Rate: 0.00104158
	LOSS [training: 0.16477060907579374 | validation: 0.28196490729633483]
	TIME [epoch: 11.3 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1650123535301447		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.1650123535301447 | validation: 0.2779051241596342]
	TIME [epoch: 11.3 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16832873422432337		[learning rate: 0.0010324]
	Learning Rate: 0.0010324
	LOSS [training: 0.16832873422432337 | validation: 0.2733656328402837]
	TIME [epoch: 11.4 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16424075867782567		[learning rate: 0.0010278]
	Learning Rate: 0.00102783
	LOSS [training: 0.16424075867782567 | validation: 0.2713518650969333]
	TIME [epoch: 11.3 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1620270008718228		[learning rate: 0.0010233]
	Learning Rate: 0.00102329
	LOSS [training: 0.1620270008718228 | validation: 0.2658795703237494]
	TIME [epoch: 11.3 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15788835205063084		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.15788835205063084 | validation: 0.27777878797017586]
	TIME [epoch: 11.4 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16380351448658823		[learning rate: 0.0010143]
	Learning Rate: 0.00101427
	LOSS [training: 0.16380351448658823 | validation: 0.29391791146109175]
	TIME [epoch: 11.3 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16604498322101477		[learning rate: 0.0010098]
	Learning Rate: 0.00100979
	LOSS [training: 0.16604498322101477 | validation: 0.2772054803290636]
	TIME [epoch: 11.4 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1622618537524121		[learning rate: 0.0010053]
	Learning Rate: 0.00100533
	LOSS [training: 0.1622618537524121 | validation: 0.26902652448150094]
	TIME [epoch: 11.3 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16498884773979972		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.16498884773979972 | validation: 0.2729318138998947]
	TIME [epoch: 11.4 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1610681132216397		[learning rate: 0.00099646]
	Learning Rate: 0.000996464
	LOSS [training: 0.1610681132216397 | validation: 0.26988480725860237]
	TIME [epoch: 11.3 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16459691587664277		[learning rate: 0.00099206]
	Learning Rate: 0.000992061
	LOSS [training: 0.16459691587664277 | validation: 0.2766614464066235]
	TIME [epoch: 11.4 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15970154687707386		[learning rate: 0.00098768]
	Learning Rate: 0.000987678
	LOSS [training: 0.15970154687707386 | validation: 0.2770534435487305]
	TIME [epoch: 11.3 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16528946467029568		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.16528946467029568 | validation: 0.2734897700908238]
	TIME [epoch: 11.3 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16110323931661358		[learning rate: 0.00097897]
	Learning Rate: 0.00097897
	LOSS [training: 0.16110323931661358 | validation: 0.27664984447790586]
	TIME [epoch: 11.4 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16760945355737641		[learning rate: 0.00097464]
	Learning Rate: 0.000974644
	LOSS [training: 0.16760945355737641 | validation: 0.2677682242247174]
	TIME [epoch: 11.4 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16460145862265838		[learning rate: 0.00097034]
	Learning Rate: 0.000970338
	LOSS [training: 0.16460145862265838 | validation: 0.268250375587343]
	TIME [epoch: 11.3 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16792156983731413		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.16792156983731413 | validation: 0.2736426516179151]
	TIME [epoch: 11.4 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1701617693177627		[learning rate: 0.00096178]
	Learning Rate: 0.000961783
	LOSS [training: 0.1701617693177627 | validation: 0.28214906876926027]
	TIME [epoch: 11.3 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16965055337366053		[learning rate: 0.00095753]
	Learning Rate: 0.000957533
	LOSS [training: 0.16965055337366053 | validation: 0.28557297675167015]
	TIME [epoch: 11.4 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1639573285939166		[learning rate: 0.0009533]
	Learning Rate: 0.000953303
	LOSS [training: 0.1639573285939166 | validation: 0.28806713395467676]
	TIME [epoch: 11.3 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16139618097334987		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.16139618097334987 | validation: 0.27853040306388677]
	TIME [epoch: 11.3 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15652485363186078		[learning rate: 0.0009449]
	Learning Rate: 0.000944897
	LOSS [training: 0.15652485363186078 | validation: 0.2679699930811501]
	TIME [epoch: 11.3 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15758715383132257		[learning rate: 0.00094072]
	Learning Rate: 0.000940723
	LOSS [training: 0.15758715383132257 | validation: 0.2755665617584951]
	TIME [epoch: 11.3 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17005883436884597		[learning rate: 0.00093657]
	Learning Rate: 0.000936566
	LOSS [training: 0.17005883436884597 | validation: 0.28534013179865864]
	TIME [epoch: 11.3 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16008655274154418		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.16008655274154418 | validation: 0.2765967639564284]
	TIME [epoch: 11.3 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16020612027608155		[learning rate: 0.00092831]
	Learning Rate: 0.000928309
	LOSS [training: 0.16020612027608155 | validation: 0.27720912656736657]
	TIME [epoch: 11.3 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16908242703102458		[learning rate: 0.00092421]
	Learning Rate: 0.000924207
	LOSS [training: 0.16908242703102458 | validation: 0.2861096062053515]
	TIME [epoch: 11.4 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16966351220602846		[learning rate: 0.00092012]
	Learning Rate: 0.000920124
	LOSS [training: 0.16966351220602846 | validation: 0.2964838232875052]
	TIME [epoch: 11.3 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1666836486507361		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.1666836486507361 | validation: 0.26982674177337435]
	TIME [epoch: 11.4 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16277073252436833		[learning rate: 0.00091201]
	Learning Rate: 0.000912011
	LOSS [training: 0.16277073252436833 | validation: 0.2909467287045185]
	TIME [epoch: 11.3 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17512930854543224		[learning rate: 0.00090798]
	Learning Rate: 0.000907981
	LOSS [training: 0.17512930854543224 | validation: 0.2901600799903606]
	TIME [epoch: 11.4 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1680957971317164		[learning rate: 0.00090397]
	Learning Rate: 0.00090397
	LOSS [training: 0.1680957971317164 | validation: 0.2805859658103473]
	TIME [epoch: 11.3 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16668138347305758		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.16668138347305758 | validation: 0.276129361274595]
	TIME [epoch: 11.4 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1605519712923515		[learning rate: 0.000896]
	Learning Rate: 0.000895999
	LOSS [training: 0.1605519712923515 | validation: 0.2771782745341605]
	TIME [epoch: 11.4 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17068498157643575		[learning rate: 0.00089204]
	Learning Rate: 0.000892041
	LOSS [training: 0.17068498157643575 | validation: 0.29327590978441465]
	TIME [epoch: 11.4 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16445668268853383		[learning rate: 0.0008881]
	Learning Rate: 0.000888099
	LOSS [training: 0.16445668268853383 | validation: 0.27295770547090337]
	TIME [epoch: 11.3 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1619654112766734		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.1619654112766734 | validation: 0.2796770492855437]
	TIME [epoch: 11.3 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1648261306623455		[learning rate: 0.00088027]
	Learning Rate: 0.000880269
	LOSS [training: 0.1648261306623455 | validation: 0.27103186384037725]
	TIME [epoch: 11.3 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16398338229592604		[learning rate: 0.00087638]
	Learning Rate: 0.00087638
	LOSS [training: 0.16398338229592604 | validation: 0.278792479345123]
	TIME [epoch: 11.4 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15951183824053888		[learning rate: 0.00087251]
	Learning Rate: 0.000872508
	LOSS [training: 0.15951183824053888 | validation: 0.2697558555937733]
	TIME [epoch: 11.3 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16629177843901016		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.16629177843901016 | validation: 0.2774119172279508]
	TIME [epoch: 11.4 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.169107217156884		[learning rate: 0.00086481]
	Learning Rate: 0.000864815
	LOSS [training: 0.169107217156884 | validation: 0.268894035509336]
	TIME [epoch: 11.3 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15636080636273095		[learning rate: 0.00086099]
	Learning Rate: 0.000860994
	LOSS [training: 0.15636080636273095 | validation: 0.27855521623048474]
	TIME [epoch: 11.4 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1671537501337599		[learning rate: 0.00085719]
	Learning Rate: 0.00085719
	LOSS [training: 0.1671537501337599 | validation: 0.28026852338072245]
	TIME [epoch: 11.3 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16083779445041615		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.16083779445041615 | validation: 0.281600635591245]
	TIME [epoch: 11.3 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1619555037017662		[learning rate: 0.00084963]
	Learning Rate: 0.000849632
	LOSS [training: 0.1619555037017662 | validation: 0.28189973406960406]
	TIME [epoch: 11.3 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16270451212443404		[learning rate: 0.00084588]
	Learning Rate: 0.000845878
	LOSS [training: 0.16270451212443404 | validation: 0.2702383031797225]
	TIME [epoch: 11.4 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16695133042743698		[learning rate: 0.00084214]
	Learning Rate: 0.000842141
	LOSS [training: 0.16695133042743698 | validation: 0.290133599471013]
	TIME [epoch: 11.3 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1676845171388912		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.1676845171388912 | validation: 0.2935470379528875]
	TIME [epoch: 11.3 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1682850894099403		[learning rate: 0.00083472]
	Learning Rate: 0.000834715
	LOSS [training: 0.1682850894099403 | validation: 0.2736379496122856]
	TIME [epoch: 11.4 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15954642614208134		[learning rate: 0.00083103]
	Learning Rate: 0.000831028
	LOSS [training: 0.15954642614208134 | validation: 0.28006151678095326]
	TIME [epoch: 11.4 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1597679923883574		[learning rate: 0.00082736]
	Learning Rate: 0.000827356
	LOSS [training: 0.1597679923883574 | validation: 0.2831320514904232]
	TIME [epoch: 11.4 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16086986884899507		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.16086986884899507 | validation: 0.267236533258947]
	TIME [epoch: 11.4 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15847034601802037		[learning rate: 0.00082006]
	Learning Rate: 0.000820061
	LOSS [training: 0.15847034601802037 | validation: 0.2806525473290075]
	TIME [epoch: 11.4 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1628131962820782		[learning rate: 0.00081644]
	Learning Rate: 0.000816438
	LOSS [training: 0.1628131962820782 | validation: 0.2641599703054015]
	TIME [epoch: 11.4 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1674431592960886		[learning rate: 0.00081283]
	Learning Rate: 0.000812831
	LOSS [training: 0.1674431592960886 | validation: 0.29606906375068825]
	TIME [epoch: 11.4 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16678053627317496		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.16678053627317496 | validation: 0.2715462850626243]
	TIME [epoch: 11.4 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16421427920609025		[learning rate: 0.00080566]
	Learning Rate: 0.000805664
	LOSS [training: 0.16421427920609025 | validation: 0.2848205008796717]
	TIME [epoch: 11.4 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1640733710309422		[learning rate: 0.0008021]
	Learning Rate: 0.000802104
	LOSS [training: 0.1640733710309422 | validation: 0.28864350375940045]
	TIME [epoch: 11.4 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17464833230742705		[learning rate: 0.00079856]
	Learning Rate: 0.00079856
	LOSS [training: 0.17464833230742705 | validation: 0.27870678996855697]
	TIME [epoch: 11.4 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16346468200774983		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.16346468200774983 | validation: 0.2870995194701341]
	TIME [epoch: 11.4 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1596854182181821		[learning rate: 0.00079152]
	Learning Rate: 0.000791519
	LOSS [training: 0.1596854182181821 | validation: 0.28176709274894307]
	TIME [epoch: 11.4 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16145889653388223		[learning rate: 0.00078802]
	Learning Rate: 0.000788022
	LOSS [training: 0.16145889653388223 | validation: 0.2676872545453272]
	TIME [epoch: 11.4 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16372812878429027		[learning rate: 0.00078454]
	Learning Rate: 0.000784541
	LOSS [training: 0.16372812878429027 | validation: 0.26787559704867925]
	TIME [epoch: 11.4 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16257735821956384		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.16257735821956384 | validation: 0.2765530817907495]
	TIME [epoch: 11.4 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16472575479200677		[learning rate: 0.00077762]
	Learning Rate: 0.000777623
	LOSS [training: 0.16472575479200677 | validation: 0.28687160814251256]
	TIME [epoch: 11.4 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1600348317260875		[learning rate: 0.00077419]
	Learning Rate: 0.000774188
	LOSS [training: 0.1600348317260875 | validation: 0.2838504587932831]
	TIME [epoch: 11.4 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16065348678681018		[learning rate: 0.00077077]
	Learning Rate: 0.000770767
	LOSS [training: 0.16065348678681018 | validation: 0.2759039872643612]
	TIME [epoch: 11.4 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1606702446815936		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.1606702446815936 | validation: 0.2723856960546994]
	TIME [epoch: 11.4 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16894447370345173		[learning rate: 0.00076397]
	Learning Rate: 0.000763971
	LOSS [training: 0.16894447370345173 | validation: 0.292994956543069]
	TIME [epoch: 11.4 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16019691011692927		[learning rate: 0.0007606]
	Learning Rate: 0.000760596
	LOSS [training: 0.16019691011692927 | validation: 0.2753554777386619]
	TIME [epoch: 11.4 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1625325119570272		[learning rate: 0.00075724]
	Learning Rate: 0.000757235
	LOSS [training: 0.1625325119570272 | validation: 0.27527232612659813]
	TIME [epoch: 11.4 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16233820731626097		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.16233820731626097 | validation: 0.2739855906344119]
	TIME [epoch: 11.4 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16758922920563893		[learning rate: 0.00075056]
	Learning Rate: 0.000750559
	LOSS [training: 0.16758922920563893 | validation: 0.29023861400015194]
	TIME [epoch: 11.4 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1621910985202037		[learning rate: 0.00074724]
	Learning Rate: 0.000747242
	LOSS [training: 0.1621910985202037 | validation: 0.2872695393919805]
	TIME [epoch: 11.4 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16416416232808023		[learning rate: 0.00074394]
	Learning Rate: 0.000743941
	LOSS [training: 0.16416416232808023 | validation: 0.27379780537832543]
	TIME [epoch: 11.4 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16394928553015425		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.16394928553015425 | validation: 0.2744216551105841]
	TIME [epoch: 11.4 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16452083440773707		[learning rate: 0.00073738]
	Learning Rate: 0.000737382
	LOSS [training: 0.16452083440773707 | validation: 0.2848916380358896]
	TIME [epoch: 11.4 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16446246748482998		[learning rate: 0.00073412]
	Learning Rate: 0.000734124
	LOSS [training: 0.16446246748482998 | validation: 0.2825771304980108]
	TIME [epoch: 11.4 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16205538967252558		[learning rate: 0.00073088]
	Learning Rate: 0.00073088
	LOSS [training: 0.16205538967252558 | validation: 0.27018826158719406]
	TIME [epoch: 11.4 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16543599057986388		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 0.16543599057986388 | validation: 0.2784853854544926]
	TIME [epoch: 11.4 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15701999311525316		[learning rate: 0.00072444]
	Learning Rate: 0.000724436
	LOSS [training: 0.15701999311525316 | validation: 0.2803700718577851]
	TIME [epoch: 11.4 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16111824095503918		[learning rate: 0.00072124]
	Learning Rate: 0.000721235
	LOSS [training: 0.16111824095503918 | validation: 0.27796372430049876]
	TIME [epoch: 11.4 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16427930825275872		[learning rate: 0.00071805]
	Learning Rate: 0.000718049
	LOSS [training: 0.16427930825275872 | validation: 0.26886451055034855]
	TIME [epoch: 11.4 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15823645171726736		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.15823645171726736 | validation: 0.2688742212556918]
	TIME [epoch: 11.4 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1641858852117387		[learning rate: 0.00071172]
	Learning Rate: 0.000711718
	LOSS [training: 0.1641858852117387 | validation: 0.2836361676313886]
	TIME [epoch: 11.4 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16611530528902832		[learning rate: 0.00070857]
	Learning Rate: 0.000708573
	LOSS [training: 0.16611530528902832 | validation: 0.2835726556596955]
	TIME [epoch: 11.4 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1651050616392581		[learning rate: 0.00070544]
	Learning Rate: 0.000705442
	LOSS [training: 0.1651050616392581 | validation: 0.2699890189085916]
	TIME [epoch: 11.4 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16714329033730357		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.16714329033730357 | validation: 0.2809985854012729]
	TIME [epoch: 11.4 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16250932545370284		[learning rate: 0.00069922]
	Learning Rate: 0.000699222
	LOSS [training: 0.16250932545370284 | validation: 0.27353347048846033]
	TIME [epoch: 11.4 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16234690077083014		[learning rate: 0.00069613]
	Learning Rate: 0.000696133
	LOSS [training: 0.16234690077083014 | validation: 0.2822155622748144]
	TIME [epoch: 11.4 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16050789625556433		[learning rate: 0.00069306]
	Learning Rate: 0.000693058
	LOSS [training: 0.16050789625556433 | validation: 0.2742149930879396]
	TIME [epoch: 11.4 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1562054616384359		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 0.1562054616384359 | validation: 0.2781506517762614]
	TIME [epoch: 11.4 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16262317508510832		[learning rate: 0.00068695]
	Learning Rate: 0.000686947
	LOSS [training: 0.16262317508510832 | validation: 0.2738453482847195]
	TIME [epoch: 11.4 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1588390393753622		[learning rate: 0.00068391]
	Learning Rate: 0.000683912
	LOSS [training: 0.1588390393753622 | validation: 0.2929171593419998]
	TIME [epoch: 11.4 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16355681642398875		[learning rate: 0.00068089]
	Learning Rate: 0.00068089
	LOSS [training: 0.16355681642398875 | validation: 0.27115450664757346]
	TIME [epoch: 11.4 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1564860926020913		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 0.1564860926020913 | validation: 0.2781028745295933]
	TIME [epoch: 11.4 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15800575177862364		[learning rate: 0.00067489]
	Learning Rate: 0.000674887
	LOSS [training: 0.15800575177862364 | validation: 0.2691202111033242]
	TIME [epoch: 11.4 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16584260429688724		[learning rate: 0.0006719]
	Learning Rate: 0.000671905
	LOSS [training: 0.16584260429688724 | validation: 0.2824038666761539]
	TIME [epoch: 11.4 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16376119993603744		[learning rate: 0.00066894]
	Learning Rate: 0.000668936
	LOSS [training: 0.16376119993603744 | validation: 0.27583525842602546]
	TIME [epoch: 11.4 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16083562467049314		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 0.16083562467049314 | validation: 0.2772843174715733]
	TIME [epoch: 11.4 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16173587012028165		[learning rate: 0.00066304]
	Learning Rate: 0.000663038
	LOSS [training: 0.16173587012028165 | validation: 0.2703240014832102]
	TIME [epoch: 11.4 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15709180774062573		[learning rate: 0.00066011]
	Learning Rate: 0.000660109
	LOSS [training: 0.15709180774062573 | validation: 0.27245619895939893]
	TIME [epoch: 11.4 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15833283979266682		[learning rate: 0.00065719]
	Learning Rate: 0.000657192
	LOSS [training: 0.15833283979266682 | validation: 0.28382467665847066]
	TIME [epoch: 11.4 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1618624237640089		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 0.1618624237640089 | validation: 0.2708382714453182]
	TIME [epoch: 11.4 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16247665895896996		[learning rate: 0.0006514]
	Learning Rate: 0.000651398
	LOSS [training: 0.16247665895896996 | validation: 0.27671810120760476]
	TIME [epoch: 11.4 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15981846338612204		[learning rate: 0.00064852]
	Learning Rate: 0.00064852
	LOSS [training: 0.15981846338612204 | validation: 0.2764909925445757]
	TIME [epoch: 11.4 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16798668641119038		[learning rate: 0.00064565]
	Learning Rate: 0.000645654
	LOSS [training: 0.16798668641119038 | validation: 0.2724110532784957]
	TIME [epoch: 11.4 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16529106711815061		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 0.16529106711815061 | validation: 0.26681130768421485]
	TIME [epoch: 11.4 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1612422600008282		[learning rate: 0.00063996]
	Learning Rate: 0.000639962
	LOSS [training: 0.1612422600008282 | validation: 0.2786533710518451]
	TIME [epoch: 11.4 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16091674939948036		[learning rate: 0.00063713]
	Learning Rate: 0.000637134
	LOSS [training: 0.16091674939948036 | validation: 0.27542447539382464]
	TIME [epoch: 11.4 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v11_20240712_140902/states/model_facs_v2_dec2b_2dpca_v11_662.pth
Halted early. No improvement in validation loss for 200 epochs.
Finished training in 4869.194 seconds.
