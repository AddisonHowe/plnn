Args:
Namespace(name='model_facs_v2_dec1b_2dpca_v13b', outdir='out/model_training/model_facs_v2_dec1b_2dpca_v13b', training_data='data/training_data/facs_v2/pca/dec1_fitonsubset/transition1_subset_epi_tr_ce_an_pc12/training', validation_data='data/training_data/facs_v2/pca/dec1_fitonsubset/transition1_subset_epi_tr_ce_an_pc12/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=10, batch_size=50, patience=200, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, quadratic_a=1.0, quadratic_b=1.0, ndims=2, nparams=2, nsigs=2, ncells=400, ncells_sample=400, model_do_sample=False, dt=0.005, dt_schedule='stepped', dt_schedule_bounds=[50, 100, 200, 300], dt_schedule_scales=[0.5, 0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', kernel='multiscale', bw_range=[0.2, 0.5, 0.9, 1.1, 1.3, 1.5, 2.0], optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 410407372

Training model...

Saving initial model state to: out/model_training/model_facs_v2_dec1b_2dpca_v13b_20240716_161953/states/model_facs_v2_dec1b_2dpca_v13b_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.5281266030677392		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5281266030677392 | validation: 1.290776370604482]
	TIME [epoch: 37.4 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v13b_20240716_161953/states/model_facs_v2_dec1b_2dpca_v13b_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.2980312862598804		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2980312862598804 | validation: 1.2357886213565155]
	TIME [epoch: 9.58 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v13b_20240716_161953/states/model_facs_v2_dec1b_2dpca_v13b_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.2635362474504257		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2635362474504257 | validation: 1.1509361021344737]
	TIME [epoch: 9.55 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v13b_20240716_161953/states/model_facs_v2_dec1b_2dpca_v13b_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.1902413846546855		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1902413846546855 | validation: 1.0708259737433514]
	TIME [epoch: 9.56 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v13b_20240716_161953/states/model_facs_v2_dec1b_2dpca_v13b_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.1197342642065427		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1197342642065427 | validation: 1.0198306998615334]
	TIME [epoch: 9.54 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v13b_20240716_161953/states/model_facs_v2_dec1b_2dpca_v13b_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.0851979854781315		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0851979854781315 | validation: 0.9462284113939955]
	TIME [epoch: 9.53 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v13b_20240716_161953/states/model_facs_v2_dec1b_2dpca_v13b_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.9974421615861088		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9974421615861088 | validation: 0.8935053980759091]
	TIME [epoch: 9.55 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v13b_20240716_161953/states/model_facs_v2_dec1b_2dpca_v13b_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.9226854994585865		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9226854994585865 | validation: 0.829299849888461]
	TIME [epoch: 9.54 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v13b_20240716_161953/states/model_facs_v2_dec1b_2dpca_v13b_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.8208706458616714		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8208706458616714 | validation: 0.7948806752545738]
	TIME [epoch: 9.52 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v13b_20240716_161953/states/model_facs_v2_dec1b_2dpca_v13b_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7226074486898367		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7226074486898367 | validation: 0.8678967379675875]
	TIME [epoch: 9.54 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7369559985479932		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7369559985479932 | validation: 0.592580347442874]
	TIME [epoch: 9.53 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v13b_20240716_161953/states/model_facs_v2_dec1b_2dpca_v13b_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5503569157992048		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5503569157992048 | validation: 0.5238290931813793]
	TIME [epoch: 9.53 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v13b_20240716_161953/states/model_facs_v2_dec1b_2dpca_v13b_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5149150222428045		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5149150222428045 | validation: 0.4410397760884185]
	TIME [epoch: 9.52 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v13b_20240716_161953/states/model_facs_v2_dec1b_2dpca_v13b_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4492613492924259		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4492613492924259 | validation: 0.40836205736058523]
	TIME [epoch: 9.54 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v13b_20240716_161953/states/model_facs_v2_dec1b_2dpca_v13b_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.43297830566615375		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.43297830566615375 | validation: 0.3824841576147405]
	TIME [epoch: 9.53 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v13b_20240716_161953/states/model_facs_v2_dec1b_2dpca_v13b_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.43066657668786085		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.43066657668786085 | validation: 0.46539950044683864]
	TIME [epoch: 9.53 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.43834720647352005		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.43834720647352005 | validation: 0.3647823602587404]
	TIME [epoch: 9.53 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v13b_20240716_161953/states/model_facs_v2_dec1b_2dpca_v13b_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.40028325627022887		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.40028325627022887 | validation: 0.3847010670492965]
	TIME [epoch: 9.54 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3978636089458767		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3978636089458767 | validation: 0.345793863242826]
	TIME [epoch: 9.52 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v13b_20240716_161953/states/model_facs_v2_dec1b_2dpca_v13b_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.38922074393034856		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.38922074393034856 | validation: 0.3241683819039553]
	TIME [epoch: 9.56 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v13b_20240716_161953/states/model_facs_v2_dec1b_2dpca_v13b_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3675668061793084		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3675668061793084 | validation: 0.3568634076250147]
	TIME [epoch: 9.57 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3575269443583517		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3575269443583517 | validation: 0.3220439920789385]
	TIME [epoch: 9.56 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v13b_20240716_161953/states/model_facs_v2_dec1b_2dpca_v13b_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3393549529550996		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3393549529550996 | validation: 0.3214569494158866]
	TIME [epoch: 9.55 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v13b_20240716_161953/states/model_facs_v2_dec1b_2dpca_v13b_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.34893142818415396		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.34893142818415396 | validation: 0.35323189638551533]
	TIME [epoch: 9.55 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3426120415216889		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3426120415216889 | validation: 0.2895176679044377]
	TIME [epoch: 9.56 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v13b_20240716_161953/states/model_facs_v2_dec1b_2dpca_v13b_25.pth
	Model improved!!!
EPOCH 26/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3223914709738745		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3223914709738745 | validation: 0.3565593202580487]
	TIME [epoch: 9.54 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.34299733553880646		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.34299733553880646 | validation: 0.2887642943509367]
	TIME [epoch: 9.54 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v13b_20240716_161953/states/model_facs_v2_dec1b_2dpca_v13b_27.pth
	Model improved!!!
EPOCH 28/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3119476698374401		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3119476698374401 | validation: 0.27016520603050864]
	TIME [epoch: 9.55 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v13b_20240716_161953/states/model_facs_v2_dec1b_2dpca_v13b_28.pth
	Model improved!!!
EPOCH 29/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32560070037025274		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.32560070037025274 | validation: 0.29010085214954373]
	TIME [epoch: 9.54 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.30535334916719276		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.30535334916719276 | validation: 0.2560806606271685]
	TIME [epoch: 9.53 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v13b_20240716_161953/states/model_facs_v2_dec1b_2dpca_v13b_30.pth
	Model improved!!!
EPOCH 31/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3060322977209273		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3060322977209273 | validation: 0.26071741786349206]
	TIME [epoch: 9.53 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3227710333003644		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3227710333003644 | validation: 0.23740302709444183]
	TIME [epoch: 9.57 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v13b_20240716_161953/states/model_facs_v2_dec1b_2dpca_v13b_32.pth
	Model improved!!!
EPOCH 33/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2940918054107437		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2940918054107437 | validation: 0.2432184122336991]
	TIME [epoch: 9.56 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.29641276940259076		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.29641276940259076 | validation: 0.2722408921503766]
	TIME [epoch: 9.54 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3041102453257739		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3041102453257739 | validation: 0.24727845341901808]
	TIME [epoch: 9.56 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.293276567696936		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.293276567696936 | validation: 0.2508990579909795]
	TIME [epoch: 9.56 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2934008713290235		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2934008713290235 | validation: 0.25211153474653447]
	TIME [epoch: 9.55 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2978278795139177		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2978278795139177 | validation: 0.25661879385132547]
	TIME [epoch: 9.54 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.28880246958749617		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.28880246958749617 | validation: 0.2424679110264985]
	TIME [epoch: 9.55 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2747217144549761		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2747217144549761 | validation: 0.23131652528604119]
	TIME [epoch: 9.56 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v13b_20240716_161953/states/model_facs_v2_dec1b_2dpca_v13b_40.pth
	Model improved!!!
EPOCH 41/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.27876409271688424		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.27876409271688424 | validation: 0.2671143329983078]
	TIME [epoch: 9.52 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.31032303921438703		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.31032303921438703 | validation: 0.28290561631974553]
	TIME [epoch: 9.53 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2881566581376376		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2881566581376376 | validation: 0.23347906495522358]
	TIME [epoch: 9.54 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2693112600266946		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2693112600266946 | validation: 0.22256968463659516]
	TIME [epoch: 9.53 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v13b_20240716_161953/states/model_facs_v2_dec1b_2dpca_v13b_44.pth
	Model improved!!!
EPOCH 45/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2819810695138789		[learning rate: 0.0099823]
	Learning Rate: 0.0099823
	LOSS [training: 0.2819810695138789 | validation: 0.23802967697236452]
	TIME [epoch: 9.54 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2751901141050171		[learning rate: 0.0099426]
	Learning Rate: 0.0099426
	LOSS [training: 0.2751901141050171 | validation: 0.22895307181334396]
	TIME [epoch: 9.55 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.28088096779839117		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 0.28088096779839117 | validation: 0.22626994579324652]
	TIME [epoch: 9.55 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.27019699951381115		[learning rate: 0.0098637]
	Learning Rate: 0.00986367
	LOSS [training: 0.27019699951381115 | validation: 0.22920610069573172]
	TIME [epoch: 9.54 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26945162103592035		[learning rate: 0.0098244]
	Learning Rate: 0.00982444
	LOSS [training: 0.26945162103592035 | validation: 0.2657441773953782]
	TIME [epoch: 9.52 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2816586713571733		[learning rate: 0.0097854]
	Learning Rate: 0.00978536
	LOSS [training: 0.2816586713571733 | validation: 0.2641645410840371]
	TIME [epoch: 9.53 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2674956675768271		[learning rate: 0.0097464]
	Learning Rate: 0.00974644
	LOSS [training: 0.2674956675768271 | validation: 0.2408318059059093]
	TIME [epoch: 44 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2810578655204384		[learning rate: 0.0097077]
	Learning Rate: 0.00970768
	LOSS [training: 0.2810578655204384 | validation: 0.23270320816348705]
	TIME [epoch: 18.5 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.27215313527389434		[learning rate: 0.0096691]
	Learning Rate: 0.00966907
	LOSS [training: 0.27215313527389434 | validation: 0.23695561799686957]
	TIME [epoch: 18.5 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.27398858939855497		[learning rate: 0.0096306]
	Learning Rate: 0.00963061
	LOSS [training: 0.27398858939855497 | validation: 0.22788531461065803]
	TIME [epoch: 18.5 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.269043858280511		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 0.269043858280511 | validation: 0.2188250090322394]
	TIME [epoch: 18.5 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v13b_20240716_161953/states/model_facs_v2_dec1b_2dpca_v13b_55.pth
	Model improved!!!
EPOCH 56/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26955666414278157		[learning rate: 0.0095542]
	Learning Rate: 0.00955415
	LOSS [training: 0.26955666414278157 | validation: 0.2305398943391046]
	TIME [epoch: 18.5 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.28065518003036716		[learning rate: 0.0095162]
	Learning Rate: 0.00951616
	LOSS [training: 0.28065518003036716 | validation: 0.23559689487079288]
	TIME [epoch: 18.5 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2718990636926987		[learning rate: 0.0094783]
	Learning Rate: 0.00947831
	LOSS [training: 0.2718990636926987 | validation: 0.227313567250836]
	TIME [epoch: 18.5 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26592461698580666		[learning rate: 0.0094406]
	Learning Rate: 0.00944061
	LOSS [training: 0.26592461698580666 | validation: 0.23075011480920385]
	TIME [epoch: 18.5 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2750025015647177		[learning rate: 0.0094031]
	Learning Rate: 0.00940306
	LOSS [training: 0.2750025015647177 | validation: 0.2238328764167667]
	TIME [epoch: 18.5 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25720429629315256		[learning rate: 0.0093657]
	Learning Rate: 0.00936566
	LOSS [training: 0.25720429629315256 | validation: 0.20736729810937554]
	TIME [epoch: 18.5 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v13b_20240716_161953/states/model_facs_v2_dec1b_2dpca_v13b_61.pth
	Model improved!!!
EPOCH 62/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26090581959910825		[learning rate: 0.0093284]
	Learning Rate: 0.00932841
	LOSS [training: 0.26090581959910825 | validation: 0.2975236105380094]
	TIME [epoch: 18.5 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2807206161261172		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 0.2807206161261172 | validation: 0.22563143706098074]
	TIME [epoch: 18.5 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25648612404003673		[learning rate: 0.0092544]
	Learning Rate: 0.00925435
	LOSS [training: 0.25648612404003673 | validation: 0.2257078138991541]
	TIME [epoch: 18.5 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2598861850392932		[learning rate: 0.0092175]
	Learning Rate: 0.00921755
	LOSS [training: 0.2598861850392932 | validation: 0.22728124484610154]
	TIME [epoch: 18.5 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26355488674222305		[learning rate: 0.0091809]
	Learning Rate: 0.00918089
	LOSS [training: 0.26355488674222305 | validation: 0.22020161663774268]
	TIME [epoch: 18.5 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2611002829595619		[learning rate: 0.0091444]
	Learning Rate: 0.00914437
	LOSS [training: 0.2611002829595619 | validation: 0.2141150303778872]
	TIME [epoch: 18.5 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2673050231852978		[learning rate: 0.009108]
	Learning Rate: 0.009108
	LOSS [training: 0.2673050231852978 | validation: 0.21634020184068578]
	TIME [epoch: 18.5 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26043184949267373		[learning rate: 0.0090718]
	Learning Rate: 0.00907178
	LOSS [training: 0.26043184949267373 | validation: 0.2056102531376701]
	TIME [epoch: 18.5 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v13b_20240716_161953/states/model_facs_v2_dec1b_2dpca_v13b_69.pth
	Model improved!!!
EPOCH 70/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2651103507942939		[learning rate: 0.0090357]
	Learning Rate: 0.00903569
	LOSS [training: 0.2651103507942939 | validation: 0.21049342717863118]
	TIME [epoch: 18.5 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2589229907446307		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 0.2589229907446307 | validation: 0.22230568079674748]
	TIME [epoch: 18.5 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2545193855109789		[learning rate: 0.008964]
	Learning Rate: 0.00896396
	LOSS [training: 0.2545193855109789 | validation: 0.22044219007546034]
	TIME [epoch: 18.5 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2634599825034505		[learning rate: 0.0089283]
	Learning Rate: 0.00892831
	LOSS [training: 0.2634599825034505 | validation: 0.20989260060173906]
	TIME [epoch: 18.5 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25392223711912787		[learning rate: 0.0088928]
	Learning Rate: 0.0088928
	LOSS [training: 0.25392223711912787 | validation: 0.23927497696852623]
	TIME [epoch: 18.5 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2692948687368588		[learning rate: 0.0088574]
	Learning Rate: 0.00885743
	LOSS [training: 0.2692948687368588 | validation: 0.24770840673312272]
	TIME [epoch: 18.5 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2600417023634255		[learning rate: 0.0088222]
	Learning Rate: 0.0088222
	LOSS [training: 0.2600417023634255 | validation: 0.20627807900986536]
	TIME [epoch: 18.5 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.263705425718193		[learning rate: 0.0087871]
	Learning Rate: 0.00878711
	LOSS [training: 0.263705425718193 | validation: 0.22635292991897762]
	TIME [epoch: 18.5 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2527389647346358		[learning rate: 0.0087522]
	Learning Rate: 0.00875216
	LOSS [training: 0.2527389647346358 | validation: 0.22062085539863913]
	TIME [epoch: 18.5 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.261195650313508		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 0.261195650313508 | validation: 0.23140998533407126]
	TIME [epoch: 18.5 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25738167238218135		[learning rate: 0.0086827]
	Learning Rate: 0.00868268
	LOSS [training: 0.25738167238218135 | validation: 0.21132161509009678]
	TIME [epoch: 18.5 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26081250832488134		[learning rate: 0.0086481]
	Learning Rate: 0.00864815
	LOSS [training: 0.26081250832488134 | validation: 0.20798009499229336]
	TIME [epoch: 18.5 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2547888764350804		[learning rate: 0.0086138]
	Learning Rate: 0.00861375
	LOSS [training: 0.2547888764350804 | validation: 0.2174387046802233]
	TIME [epoch: 18.5 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2705245436361286		[learning rate: 0.0085795]
	Learning Rate: 0.00857949
	LOSS [training: 0.2705245436361286 | validation: 0.23688827240543162]
	TIME [epoch: 18.5 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25827060991841866		[learning rate: 0.0085454]
	Learning Rate: 0.00854537
	LOSS [training: 0.25827060991841866 | validation: 0.22609704574170034]
	TIME [epoch: 18.5 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26289106715138905		[learning rate: 0.0085114]
	Learning Rate: 0.00851138
	LOSS [training: 0.26289106715138905 | validation: 0.2120442288904898]
	TIME [epoch: 18.5 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25085030553251436		[learning rate: 0.0084775]
	Learning Rate: 0.00847753
	LOSS [training: 0.25085030553251436 | validation: 0.2111381760437719]
	TIME [epoch: 18.5 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2610658922399326		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 0.2610658922399326 | validation: 0.20784901911808365]
	TIME [epoch: 18.5 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.250235364348143		[learning rate: 0.0084102]
	Learning Rate: 0.00841023
	LOSS [training: 0.250235364348143 | validation: 0.22445988518910812]
	TIME [epoch: 18.5 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2703930447256961		[learning rate: 0.0083768]
	Learning Rate: 0.00837678
	LOSS [training: 0.2703930447256961 | validation: 0.20236597323182134]
	TIME [epoch: 18.5 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v13b_20240716_161953/states/model_facs_v2_dec1b_2dpca_v13b_89.pth
	Model improved!!!
EPOCH 90/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24491379654991347		[learning rate: 0.0083435]
	Learning Rate: 0.00834346
	LOSS [training: 0.24491379654991347 | validation: 0.24824817548947697]
	TIME [epoch: 18.5 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26687110869345687		[learning rate: 0.0083103]
	Learning Rate: 0.00831027
	LOSS [training: 0.26687110869345687 | validation: 0.21341193665374364]
	TIME [epoch: 18.5 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24922287646017482		[learning rate: 0.0082772]
	Learning Rate: 0.00827722
	LOSS [training: 0.24922287646017482 | validation: 0.2019224009619406]
	TIME [epoch: 18.5 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v13b_20240716_161953/states/model_facs_v2_dec1b_2dpca_v13b_92.pth
	Model improved!!!
EPOCH 93/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2563713401742191		[learning rate: 0.0082443]
	Learning Rate: 0.0082443
	LOSS [training: 0.2563713401742191 | validation: 0.22842149577672685]
	TIME [epoch: 18.5 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25308880709685705		[learning rate: 0.0082115]
	Learning Rate: 0.00821151
	LOSS [training: 0.25308880709685705 | validation: 0.23828715236302359]
	TIME [epoch: 18.5 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25306638078300536		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 0.25306638078300536 | validation: 0.20287123783189093]
	TIME [epoch: 18.5 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25257173168918573		[learning rate: 0.0081463]
	Learning Rate: 0.00814632
	LOSS [training: 0.25257173168918573 | validation: 0.23142775585812947]
	TIME [epoch: 18.5 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26954278487013394		[learning rate: 0.0081139]
	Learning Rate: 0.00811392
	LOSS [training: 0.26954278487013394 | validation: 0.24136150932560377]
	TIME [epoch: 18.5 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2493801873439745		[learning rate: 0.0080816]
	Learning Rate: 0.00808165
	LOSS [training: 0.2493801873439745 | validation: 0.20888330291845753]
	TIME [epoch: 18.5 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2391727971076455		[learning rate: 0.0080495]
	Learning Rate: 0.00804951
	LOSS [training: 0.2391727971076455 | validation: 0.20498834516603806]
	TIME [epoch: 18.5 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2574614445016883		[learning rate: 0.0080175]
	Learning Rate: 0.00801749
	LOSS [training: 0.2574614445016883 | validation: 0.22756558456809275]
	TIME [epoch: 18.5 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25485157414710075		[learning rate: 0.0079856]
	Learning Rate: 0.0079856
	LOSS [training: 0.25485157414710075 | validation: 0.21162786424313973]
	TIME [epoch: 65.6 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24704312870488193		[learning rate: 0.0079538]
	Learning Rate: 0.00795384
	LOSS [training: 0.24704312870488193 | validation: 0.24605305107254782]
	TIME [epoch: 40.1 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26924655956457944		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 0.26924655956457944 | validation: 0.2005391607898384]
	TIME [epoch: 40.1 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v13b_20240716_161953/states/model_facs_v2_dec1b_2dpca_v13b_103.pth
	Model improved!!!
EPOCH 104/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2638369786036193		[learning rate: 0.0078907]
	Learning Rate: 0.0078907
	LOSS [training: 0.2638369786036193 | validation: 0.22008502933613666]
	TIME [epoch: 40.1 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24620394147801783		[learning rate: 0.0078593]
	Learning Rate: 0.00785931
	LOSS [training: 0.24620394147801783 | validation: 0.2033037655420598]
	TIME [epoch: 40.1 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24164831224607047		[learning rate: 0.0078281]
	Learning Rate: 0.00782805
	LOSS [training: 0.24164831224607047 | validation: 0.20548049376996116]
	TIME [epoch: 40.1 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2533458891200925		[learning rate: 0.0077969]
	Learning Rate: 0.00779692
	LOSS [training: 0.2533458891200925 | validation: 0.20916927586990958]
	TIME [epoch: 40.1 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2489559047817712		[learning rate: 0.0077659]
	Learning Rate: 0.00776591
	LOSS [training: 0.2489559047817712 | validation: 0.2056808018869]
	TIME [epoch: 40.1 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2497926055741437		[learning rate: 0.007735]
	Learning Rate: 0.00773502
	LOSS [training: 0.2497926055741437 | validation: 0.19561604770774663]
	TIME [epoch: 40.1 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v13b_20240716_161953/states/model_facs_v2_dec1b_2dpca_v13b_109.pth
	Model improved!!!
EPOCH 110/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24847204374139498		[learning rate: 0.0077043]
	Learning Rate: 0.00770426
	LOSS [training: 0.24847204374139498 | validation: 0.20378663895458687]
	TIME [epoch: 40 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24942004548711058		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 0.24942004548711058 | validation: 0.22032268543990852]
	TIME [epoch: 40.1 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24784213622834983		[learning rate: 0.0076431]
	Learning Rate: 0.00764309
	LOSS [training: 0.24784213622834983 | validation: 0.19679408456879877]
	TIME [epoch: 40.1 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2428080278151924		[learning rate: 0.0076127]
	Learning Rate: 0.00761269
	LOSS [training: 0.2428080278151924 | validation: 0.22810402980812627]
	TIME [epoch: 40.1 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26462841573306106		[learning rate: 0.0075824]
	Learning Rate: 0.00758242
	LOSS [training: 0.26462841573306106 | validation: 0.2019411334233927]
	TIME [epoch: 40.1 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24993090087449765		[learning rate: 0.0075523]
	Learning Rate: 0.00755226
	LOSS [training: 0.24993090087449765 | validation: 0.19933931132636265]
	TIME [epoch: 40.1 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24669231721949958		[learning rate: 0.0075222]
	Learning Rate: 0.00752222
	LOSS [training: 0.24669231721949958 | validation: 0.20685817768656295]
	TIME [epoch: 40.1 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2551713015536818		[learning rate: 0.0074923]
	Learning Rate: 0.0074923
	LOSS [training: 0.2551713015536818 | validation: 0.19715880535949132]
	TIME [epoch: 40.1 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2450334919135416		[learning rate: 0.0074625]
	Learning Rate: 0.0074625
	LOSS [training: 0.2450334919135416 | validation: 0.22157992105631252]
	TIME [epoch: 40.1 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2446294817889407		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 0.2446294817889407 | validation: 0.20201362724564526]
	TIME [epoch: 40.1 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25182351892467114		[learning rate: 0.0074033]
	Learning Rate: 0.00740326
	LOSS [training: 0.25182351892467114 | validation: 0.212267380610973]
	TIME [epoch: 40.1 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24331596522469537		[learning rate: 0.0073738]
	Learning Rate: 0.00737382
	LOSS [training: 0.24331596522469537 | validation: 0.2115993073462125]
	TIME [epoch: 40.1 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24290100154441296		[learning rate: 0.0073445]
	Learning Rate: 0.00734449
	LOSS [training: 0.24290100154441296 | validation: 0.21025624320889819]
	TIME [epoch: 40.1 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2566185773721838		[learning rate: 0.0073153]
	Learning Rate: 0.00731528
	LOSS [training: 0.2566185773721838 | validation: 0.19937900071743708]
	TIME [epoch: 40.1 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24122873253355204		[learning rate: 0.0072862]
	Learning Rate: 0.00728618
	LOSS [training: 0.24122873253355204 | validation: 0.2226309406574348]
	TIME [epoch: 40.1 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2484438544976207		[learning rate: 0.0072572]
	Learning Rate: 0.0072572
	LOSS [training: 0.2484438544976207 | validation: 0.20216724563507218]
	TIME [epoch: 40.1 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24628067181656124		[learning rate: 0.0072283]
	Learning Rate: 0.00722834
	LOSS [training: 0.24628067181656124 | validation: 0.1984165670747875]
	TIME [epoch: 40.1 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24150648223789606		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 0.24150648223789606 | validation: 0.21687247485303685]
	TIME [epoch: 40.1 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24663062415930476		[learning rate: 0.007171]
	Learning Rate: 0.00717095
	LOSS [training: 0.24663062415930476 | validation: 0.21449759803458357]
	TIME [epoch: 40.1 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24662191389839658		[learning rate: 0.0071424]
	Learning Rate: 0.00714243
	LOSS [training: 0.24662191389839658 | validation: 0.20457217925395135]
	TIME [epoch: 40.1 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25512397409545323		[learning rate: 0.007114]
	Learning Rate: 0.00711403
	LOSS [training: 0.25512397409545323 | validation: 0.19591047893887364]
	TIME [epoch: 40.1 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24003109676373408		[learning rate: 0.0070857]
	Learning Rate: 0.00708573
	LOSS [training: 0.24003109676373408 | validation: 0.20417549069373847]
	TIME [epoch: 40.1 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24721319834567973		[learning rate: 0.0070575]
	Learning Rate: 0.00705755
	LOSS [training: 0.24721319834567973 | validation: 0.19792356202953926]
	TIME [epoch: 40.1 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23929127311502077		[learning rate: 0.0070295]
	Learning Rate: 0.00702948
	LOSS [training: 0.23929127311502077 | validation: 0.2056548009610763]
	TIME [epoch: 40.1 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24408970141238914		[learning rate: 0.0070015]
	Learning Rate: 0.00700152
	LOSS [training: 0.24408970141238914 | validation: 0.21596123625440894]
	TIME [epoch: 40.1 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25693658170557826		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 0.25693658170557826 | validation: 0.2031283152863445]
	TIME [epoch: 40.1 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23937677005102945		[learning rate: 0.0069459]
	Learning Rate: 0.00694594
	LOSS [training: 0.23937677005102945 | validation: 0.22143494642173284]
	TIME [epoch: 40.1 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25789252785890904		[learning rate: 0.0069183]
	Learning Rate: 0.00691831
	LOSS [training: 0.25789252785890904 | validation: 0.20151706329969993]
	TIME [epoch: 40.1 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24024718370806625		[learning rate: 0.0068908]
	Learning Rate: 0.00689079
	LOSS [training: 0.24024718370806625 | validation: 0.20455811781371708]
	TIME [epoch: 40.1 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24029216203221473		[learning rate: 0.0068634]
	Learning Rate: 0.00686339
	LOSS [training: 0.24029216203221473 | validation: 0.20049605625764083]
	TIME [epoch: 40.1 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24463000663605852		[learning rate: 0.0068361]
	Learning Rate: 0.00683609
	LOSS [training: 0.24463000663605852 | validation: 0.2016540177268263]
	TIME [epoch: 40.1 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26099542309750556		[learning rate: 0.0068089]
	Learning Rate: 0.0068089
	LOSS [training: 0.26099542309750556 | validation: 0.2044090395939393]
	TIME [epoch: 40.1 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24151944539674494		[learning rate: 0.0067818]
	Learning Rate: 0.00678182
	LOSS [training: 0.24151944539674494 | validation: 0.2052233307961356]
	TIME [epoch: 40.1 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2415062110480241		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 0.2415062110480241 | validation: 0.21033509751553675]
	TIME [epoch: 40.1 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25289312048485074		[learning rate: 0.006728]
	Learning Rate: 0.00672798
	LOSS [training: 0.25289312048485074 | validation: 0.20013282561158388]
	TIME [epoch: 40.1 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24124162320684578		[learning rate: 0.0067012]
	Learning Rate: 0.00670122
	LOSS [training: 0.24124162320684578 | validation: 0.2009189067640774]
	TIME [epoch: 40.1 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24240712829183975		[learning rate: 0.0066746]
	Learning Rate: 0.00667457
	LOSS [training: 0.24240712829183975 | validation: 0.20226209005578727]
	TIME [epoch: 40.1 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2414572154765665		[learning rate: 0.006648]
	Learning Rate: 0.00664802
	LOSS [training: 0.2414572154765665 | validation: 0.20507796941086753]
	TIME [epoch: 40.1 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24170880372303807		[learning rate: 0.0066216]
	Learning Rate: 0.00662158
	LOSS [training: 0.24170880372303807 | validation: 0.2076627974532197]
	TIME [epoch: 40.1 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24376668097121923		[learning rate: 0.0065952]
	Learning Rate: 0.00659524
	LOSS [training: 0.24376668097121923 | validation: 0.20726377962948175]
	TIME [epoch: 40.1 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23513314661586637		[learning rate: 0.006569]
	Learning Rate: 0.00656901
	LOSS [training: 0.23513314661586637 | validation: 0.22230961358182538]
	TIME [epoch: 40.1 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2502420803191183		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 0.2502420803191183 | validation: 0.20392632006550868]
	TIME [epoch: 40.1 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24314806546131676		[learning rate: 0.0065169]
	Learning Rate: 0.00651686
	LOSS [training: 0.24314806546131676 | validation: 0.21714452293648617]
	TIME [epoch: 40.1 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24409000884310583		[learning rate: 0.0064909]
	Learning Rate: 0.00649094
	LOSS [training: 0.24409000884310583 | validation: 0.20336567608472933]
	TIME [epoch: 40.1 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24653238463088892		[learning rate: 0.0064651]
	Learning Rate: 0.00646512
	LOSS [training: 0.24653238463088892 | validation: 0.21759302035549544]
	TIME [epoch: 40.1 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.253877257184198		[learning rate: 0.0064394]
	Learning Rate: 0.00643941
	LOSS [training: 0.253877257184198 | validation: 0.2044080421428744]
	TIME [epoch: 40 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23626710185729818		[learning rate: 0.0064138]
	Learning Rate: 0.0064138
	LOSS [training: 0.23626710185729818 | validation: 0.2229110375598598]
	TIME [epoch: 40.1 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24292365668161903		[learning rate: 0.0063883]
	Learning Rate: 0.00638829
	LOSS [training: 0.24292365668161903 | validation: 0.2136784644103599]
	TIME [epoch: 40 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25963795680736207		[learning rate: 0.0063629]
	Learning Rate: 0.00636288
	LOSS [training: 0.25963795680736207 | validation: 0.21787430463778645]
	TIME [epoch: 40.1 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23589223917184		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 0.23589223917184 | validation: 0.2250146107218669]
	TIME [epoch: 40.1 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24523565119371846		[learning rate: 0.0063124]
	Learning Rate: 0.00631237
	LOSS [training: 0.24523565119371846 | validation: 0.2048687140339312]
	TIME [epoch: 40.1 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24025385156694432		[learning rate: 0.0062873]
	Learning Rate: 0.00628726
	LOSS [training: 0.24025385156694432 | validation: 0.21078841438220958]
	TIME [epoch: 40.1 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2431924657889398		[learning rate: 0.0062623]
	Learning Rate: 0.00626226
	LOSS [training: 0.2431924657889398 | validation: 0.2020576884571584]
	TIME [epoch: 40.1 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24263181762784067		[learning rate: 0.0062373]
	Learning Rate: 0.00623735
	LOSS [training: 0.24263181762784067 | validation: 0.21167813414152686]
	TIME [epoch: 40.1 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24544698525438044		[learning rate: 0.0062125]
	Learning Rate: 0.00621254
	LOSS [training: 0.24544698525438044 | validation: 0.19747987090938288]
	TIME [epoch: 40.1 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24049445153018598		[learning rate: 0.0061878]
	Learning Rate: 0.00618783
	LOSS [training: 0.24049445153018598 | validation: 0.1926156375101457]
	TIME [epoch: 40.1 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v13b_20240716_161953/states/model_facs_v2_dec1b_2dpca_v13b_165.pth
	Model improved!!!
EPOCH 166/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2442782708867185		[learning rate: 0.0061632]
	Learning Rate: 0.00616322
	LOSS [training: 0.2442782708867185 | validation: 0.21190803860669855]
	TIME [epoch: 40 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24678919395811214		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 0.24678919395811214 | validation: 0.2083384446344799]
	TIME [epoch: 40 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23670381914801078		[learning rate: 0.0061143]
	Learning Rate: 0.00611429
	LOSS [training: 0.23670381914801078 | validation: 0.22083824573180239]
	TIME [epoch: 40 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23738871199845532		[learning rate: 0.00609]
	Learning Rate: 0.00608997
	LOSS [training: 0.23738871199845532 | validation: 0.21290552106727598]
	TIME [epoch: 40 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24600925413606398		[learning rate: 0.0060658]
	Learning Rate: 0.00606575
	LOSS [training: 0.24600925413606398 | validation: 0.20112405218524537]
	TIME [epoch: 40 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23774922444606933		[learning rate: 0.0060416]
	Learning Rate: 0.00604163
	LOSS [training: 0.23774922444606933 | validation: 0.20016761873639335]
	TIME [epoch: 40.1 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23994966337263213		[learning rate: 0.0060176]
	Learning Rate: 0.0060176
	LOSS [training: 0.23994966337263213 | validation: 0.21541319270062295]
	TIME [epoch: 40.1 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24632098635804406		[learning rate: 0.0059937]
	Learning Rate: 0.00599366
	LOSS [training: 0.24632098635804406 | validation: 0.20691408683980667]
	TIME [epoch: 40.1 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24378079831418661		[learning rate: 0.0059698]
	Learning Rate: 0.00596982
	LOSS [training: 0.24378079831418661 | validation: 0.20206944473707927]
	TIME [epoch: 40.1 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24050725544041146		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 0.24050725544041146 | validation: 0.20399207449425188]
	TIME [epoch: 40.1 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24658353857825885		[learning rate: 0.0059224]
	Learning Rate: 0.00592243
	LOSS [training: 0.24658353857825885 | validation: 0.21117356836057227]
	TIME [epoch: 40.1 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23379905863488717		[learning rate: 0.0058989]
	Learning Rate: 0.00589888
	LOSS [training: 0.23379905863488717 | validation: 0.19084396809535326]
	TIME [epoch: 40.1 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v13b_20240716_161953/states/model_facs_v2_dec1b_2dpca_v13b_177.pth
	Model improved!!!
EPOCH 178/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23889832464649072		[learning rate: 0.0058754]
	Learning Rate: 0.00587541
	LOSS [training: 0.23889832464649072 | validation: 0.19824633982514692]
	TIME [epoch: 40 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23591956712088402		[learning rate: 0.005852]
	Learning Rate: 0.00585205
	LOSS [training: 0.23591956712088402 | validation: 0.20471756143914027]
	TIME [epoch: 40 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23690559615112183		[learning rate: 0.0058288]
	Learning Rate: 0.00582877
	LOSS [training: 0.23690559615112183 | validation: 0.19508399533267223]
	TIME [epoch: 40.1 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23838950248552435		[learning rate: 0.0058056]
	Learning Rate: 0.00580559
	LOSS [training: 0.23838950248552435 | validation: 0.19430555431662785]
	TIME [epoch: 40.1 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23901060707145458		[learning rate: 0.0057825]
	Learning Rate: 0.0057825
	LOSS [training: 0.23901060707145458 | validation: 0.20066464684216584]
	TIME [epoch: 40.1 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24321921993116322		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 0.24321921993116322 | validation: 0.20027978404552846]
	TIME [epoch: 40.1 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24361486173839683		[learning rate: 0.0057366]
	Learning Rate: 0.00573659
	LOSS [training: 0.24361486173839683 | validation: 0.20231853377964287]
	TIME [epoch: 40.1 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23570028796919582		[learning rate: 0.0057138]
	Learning Rate: 0.00571377
	LOSS [training: 0.23570028796919582 | validation: 0.1959336468305161]
	TIME [epoch: 40.1 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24016202021234628		[learning rate: 0.005691]
	Learning Rate: 0.00569105
	LOSS [training: 0.24016202021234628 | validation: 0.20882477009961525]
	TIME [epoch: 40.1 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24181789381327004		[learning rate: 0.0056684]
	Learning Rate: 0.00566841
	LOSS [training: 0.24181789381327004 | validation: 0.22266932710348747]
	TIME [epoch: 40.1 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23840293405370858		[learning rate: 0.0056459]
	Learning Rate: 0.00564587
	LOSS [training: 0.23840293405370858 | validation: 0.19942856934376124]
	TIME [epoch: 40.1 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24136436263733854		[learning rate: 0.0056234]
	Learning Rate: 0.00562341
	LOSS [training: 0.24136436263733854 | validation: 0.20478474962168183]
	TIME [epoch: 40 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2386479437661979		[learning rate: 0.005601]
	Learning Rate: 0.00560105
	LOSS [training: 0.2386479437661979 | validation: 0.20552023868460054]
	TIME [epoch: 40.1 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2439929039127699		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 0.2439929039127699 | validation: 0.2121322600757372]
	TIME [epoch: 40.1 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23430761660469773		[learning rate: 0.0055566]
	Learning Rate: 0.00555658
	LOSS [training: 0.23430761660469773 | validation: 0.20097609705555036]
	TIME [epoch: 40.1 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23311944606268012		[learning rate: 0.0055345]
	Learning Rate: 0.00553448
	LOSS [training: 0.23311944606268012 | validation: 0.19316700842693704]
	TIME [epoch: 40.1 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2462943916307904		[learning rate: 0.0055125]
	Learning Rate: 0.00551247
	LOSS [training: 0.2462943916307904 | validation: 0.2035949758120828]
	TIME [epoch: 40.1 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23517421456315624		[learning rate: 0.0054905]
	Learning Rate: 0.00549054
	LOSS [training: 0.23517421456315624 | validation: 0.19962962048886607]
	TIME [epoch: 40.1 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24081557449546617		[learning rate: 0.0054687]
	Learning Rate: 0.00546871
	LOSS [training: 0.24081557449546617 | validation: 0.19926274581696696]
	TIME [epoch: 40.1 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24265243679757528		[learning rate: 0.005447]
	Learning Rate: 0.00544696
	LOSS [training: 0.24265243679757528 | validation: 0.19404094076092243]
	TIME [epoch: 40.1 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24587836145145076		[learning rate: 0.0054253]
	Learning Rate: 0.00542529
	LOSS [training: 0.24587836145145076 | validation: 0.20862057956164692]
	TIME [epoch: 40.1 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2318385698733132		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 0.2318385698733132 | validation: 0.2079173278445378]
	TIME [epoch: 40.1 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24187276517574854		[learning rate: 0.0053822]
	Learning Rate: 0.00538222
	LOSS [training: 0.24187276517574854 | validation: 0.2095285417364079]
	TIME [epoch: 40.1 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2353276775544296		[learning rate: 0.0053608]
	Learning Rate: 0.00536081
	LOSS [training: 0.2353276775544296 | validation: 0.20612634441740765]
	TIME [epoch: 111 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2433956513318557		[learning rate: 0.0053395]
	Learning Rate: 0.00533949
	LOSS [training: 0.2433956513318557 | validation: 0.19823562907478698]
	TIME [epoch: 86.2 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2317817498252703		[learning rate: 0.0053183]
	Learning Rate: 0.00531826
	LOSS [training: 0.2317817498252703 | validation: 0.19803767216285473]
	TIME [epoch: 86.1 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23266367846206634		[learning rate: 0.0052971]
	Learning Rate: 0.0052971
	LOSS [training: 0.23266367846206634 | validation: 0.2048084061281518]
	TIME [epoch: 86.1 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23165340177085397		[learning rate: 0.005276]
	Learning Rate: 0.00527604
	LOSS [training: 0.23165340177085397 | validation: 0.20039570880045443]
	TIME [epoch: 86.1 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23036233420936558		[learning rate: 0.0052551]
	Learning Rate: 0.00525505
	LOSS [training: 0.23036233420936558 | validation: 0.19907692487787515]
	TIME [epoch: 86.1 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23723307196588955		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 0.23723307196588955 | validation: 0.20468504601073145]
	TIME [epoch: 86.1 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2379943968414771		[learning rate: 0.0052133]
	Learning Rate: 0.00521333
	LOSS [training: 0.2379943968414771 | validation: 0.19617176707612125]
	TIME [epoch: 86.1 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24196453167145682		[learning rate: 0.0051926]
	Learning Rate: 0.0051926
	LOSS [training: 0.24196453167145682 | validation: 0.2003853095942782]
	TIME [epoch: 86.1 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2351595059058537		[learning rate: 0.0051719]
	Learning Rate: 0.00517194
	LOSS [training: 0.2351595059058537 | validation: 0.20695941577365967]
	TIME [epoch: 86.2 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2354483140128908		[learning rate: 0.0051514]
	Learning Rate: 0.00515137
	LOSS [training: 0.2354483140128908 | validation: 0.1951078925125061]
	TIME [epoch: 86.2 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.228663036815045		[learning rate: 0.0051309]
	Learning Rate: 0.00513089
	LOSS [training: 0.228663036815045 | validation: 0.20495135452659036]
	TIME [epoch: 86.2 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23274630354726464		[learning rate: 0.0051105]
	Learning Rate: 0.00511048
	LOSS [training: 0.23274630354726464 | validation: 0.19571448537946587]
	TIME [epoch: 86.2 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2342255824646776		[learning rate: 0.0050902]
	Learning Rate: 0.00509015
	LOSS [training: 0.2342255824646776 | validation: 0.2006463932582938]
	TIME [epoch: 86.2 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23578681398055976		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 0.23578681398055976 | validation: 0.19356226822474262]
	TIME [epoch: 86.2 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2407445052666383		[learning rate: 0.0050497]
	Learning Rate: 0.00504974
	LOSS [training: 0.2407445052666383 | validation: 0.19361543332286102]
	TIME [epoch: 86.2 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23917498239206805		[learning rate: 0.0050297]
	Learning Rate: 0.00502966
	LOSS [training: 0.23917498239206805 | validation: 0.19308613883054768]
	TIME [epoch: 86.2 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2395532826783615		[learning rate: 0.0050097]
	Learning Rate: 0.00500965
	LOSS [training: 0.2395532826783615 | validation: 0.2013911094343514]
	TIME [epoch: 86.2 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2331269971805948		[learning rate: 0.0049897]
	Learning Rate: 0.00498973
	LOSS [training: 0.2331269971805948 | validation: 0.19515352495800187]
	TIME [epoch: 86.2 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23577032830267802		[learning rate: 0.0049699]
	Learning Rate: 0.00496988
	LOSS [training: 0.23577032830267802 | validation: 0.19752826374609686]
	TIME [epoch: 86.2 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23838629524767604		[learning rate: 0.0049501]
	Learning Rate: 0.00495012
	LOSS [training: 0.23838629524767604 | validation: 0.18790666996525593]
	TIME [epoch: 86.2 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v13b_20240716_161953/states/model_facs_v2_dec1b_2dpca_v13b_221.pth
	Model improved!!!
EPOCH 222/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24122844000512325		[learning rate: 0.0049304]
	Learning Rate: 0.00493043
	LOSS [training: 0.24122844000512325 | validation: 0.19424929121183437]
	TIME [epoch: 86.2 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24127577172985534		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 0.24127577172985534 | validation: 0.19727914258358037]
	TIME [epoch: 86.2 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2346285125189367		[learning rate: 0.0048913]
	Learning Rate: 0.00489129
	LOSS [training: 0.2346285125189367 | validation: 0.19174351851583749]
	TIME [epoch: 86.2 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22789610588269074		[learning rate: 0.0048718]
	Learning Rate: 0.00487183
	LOSS [training: 0.22789610588269074 | validation: 0.19656802273213794]
	TIME [epoch: 86.2 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2321363172363141		[learning rate: 0.0048525]
	Learning Rate: 0.00485245
	LOSS [training: 0.2321363172363141 | validation: 0.19927982514810239]
	TIME [epoch: 86.2 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23429413067574634		[learning rate: 0.0048332]
	Learning Rate: 0.00483316
	LOSS [training: 0.23429413067574634 | validation: 0.1942009542114638]
	TIME [epoch: 86.2 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23640162135324358		[learning rate: 0.0048139]
	Learning Rate: 0.00481393
	LOSS [training: 0.23640162135324358 | validation: 0.21172073997945398]
	TIME [epoch: 86.2 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24696171751771112		[learning rate: 0.0047948]
	Learning Rate: 0.00479479
	LOSS [training: 0.24696171751771112 | validation: 0.19073769834439896]
	TIME [epoch: 86.2 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2326222827283725		[learning rate: 0.0047757]
	Learning Rate: 0.00477572
	LOSS [training: 0.2326222827283725 | validation: 0.19487103661253058]
	TIME [epoch: 86.2 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2370086048386581		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.2370086048386581 | validation: 0.20031738208117256]
	TIME [epoch: 86.2 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22825989596950869		[learning rate: 0.0047378]
	Learning Rate: 0.0047378
	LOSS [training: 0.22825989596950869 | validation: 0.19374159828784931]
	TIME [epoch: 86.2 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23748361671717916		[learning rate: 0.004719]
	Learning Rate: 0.00471896
	LOSS [training: 0.23748361671717916 | validation: 0.2002794705167429]
	TIME [epoch: 86.2 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23195038339938787		[learning rate: 0.0047002]
	Learning Rate: 0.00470019
	LOSS [training: 0.23195038339938787 | validation: 0.2031357419569248]
	TIME [epoch: 86.2 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24212189687262178		[learning rate: 0.0046815]
	Learning Rate: 0.0046815
	LOSS [training: 0.24212189687262178 | validation: 0.18958488197025197]
	TIME [epoch: 86.2 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23880300213965164		[learning rate: 0.0046629]
	Learning Rate: 0.00466288
	LOSS [training: 0.23880300213965164 | validation: 0.21764774706777318]
	TIME [epoch: 86.2 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24038857126165672		[learning rate: 0.0046443]
	Learning Rate: 0.00464433
	LOSS [training: 0.24038857126165672 | validation: 0.19223163548152924]
	TIME [epoch: 86.2 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22817627016610198		[learning rate: 0.0046259]
	Learning Rate: 0.00462586
	LOSS [training: 0.22817627016610198 | validation: 0.1926131050461554]
	TIME [epoch: 86.2 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2354679927637876		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 0.2354679927637876 | validation: 0.1968090946479785]
	TIME [epoch: 86.1 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2395037301406054		[learning rate: 0.0045891]
	Learning Rate: 0.00458913
	LOSS [training: 0.2395037301406054 | validation: 0.20320721568517147]
	TIME [epoch: 86.2 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2330575093437529		[learning rate: 0.0045709]
	Learning Rate: 0.00457088
	LOSS [training: 0.2330575093437529 | validation: 0.1946327267861415]
	TIME [epoch: 86.2 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23632171102694421		[learning rate: 0.0045527]
	Learning Rate: 0.0045527
	LOSS [training: 0.23632171102694421 | validation: 0.19400803385928503]
	TIME [epoch: 86.2 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23643270035532707		[learning rate: 0.0045346]
	Learning Rate: 0.00453459
	LOSS [training: 0.23643270035532707 | validation: 0.20390763477763688]
	TIME [epoch: 86.2 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2370665156998484		[learning rate: 0.0045166]
	Learning Rate: 0.00451656
	LOSS [training: 0.2370665156998484 | validation: 0.1944636825883829]
	TIME [epoch: 86.2 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24211420934383052		[learning rate: 0.0044986]
	Learning Rate: 0.0044986
	LOSS [training: 0.24211420934383052 | validation: 0.21164813665866689]
	TIME [epoch: 86.2 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23670864864825644		[learning rate: 0.0044807]
	Learning Rate: 0.0044807
	LOSS [training: 0.23670864864825644 | validation: 0.2021450907079292]
	TIME [epoch: 86.2 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2302019559589792		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 0.2302019559589792 | validation: 0.20388291271601977]
	TIME [epoch: 86.2 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23100205841332727		[learning rate: 0.0044451]
	Learning Rate: 0.00444513
	LOSS [training: 0.23100205841332727 | validation: 0.1922044004968288]
	TIME [epoch: 86.2 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23560102220230425		[learning rate: 0.0044275]
	Learning Rate: 0.00442745
	LOSS [training: 0.23560102220230425 | validation: 0.19780405092981754]
	TIME [epoch: 86.2 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23184645725166433		[learning rate: 0.0044098]
	Learning Rate: 0.00440984
	LOSS [training: 0.23184645725166433 | validation: 0.21097998037058185]
	TIME [epoch: 86.2 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23373286482888225		[learning rate: 0.0043923]
	Learning Rate: 0.0043923
	LOSS [training: 0.23373286482888225 | validation: 0.19271220684256807]
	TIME [epoch: 86.2 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2297221414778891		[learning rate: 0.0043748]
	Learning Rate: 0.00437483
	LOSS [training: 0.2297221414778891 | validation: 0.20258382112044218]
	TIME [epoch: 86.2 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23806047183466145		[learning rate: 0.0043574]
	Learning Rate: 0.00435743
	LOSS [training: 0.23806047183466145 | validation: 0.1989254691726384]
	TIME [epoch: 86.2 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2372933174425058		[learning rate: 0.0043401]
	Learning Rate: 0.0043401
	LOSS [training: 0.2372933174425058 | validation: 0.20053716624748458]
	TIME [epoch: 86.2 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23320455479785634		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 0.23320455479785634 | validation: 0.19087328470281342]
	TIME [epoch: 86.2 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.238270177893625		[learning rate: 0.0043056]
	Learning Rate: 0.00430565
	LOSS [training: 0.238270177893625 | validation: 0.19246418093417383]
	TIME [epoch: 86.2 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2343173013863381		[learning rate: 0.0042885]
	Learning Rate: 0.00428852
	LOSS [training: 0.2343173013863381 | validation: 0.19909683533827316]
	TIME [epoch: 86.2 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23847528458786282		[learning rate: 0.0042715]
	Learning Rate: 0.00427147
	LOSS [training: 0.23847528458786282 | validation: 0.20049275437080696]
	TIME [epoch: 86.2 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23047843706921212		[learning rate: 0.0042545]
	Learning Rate: 0.00425448
	LOSS [training: 0.23047843706921212 | validation: 0.1994733550900481]
	TIME [epoch: 86.2 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23372070479921486		[learning rate: 0.0042376]
	Learning Rate: 0.00423756
	LOSS [training: 0.23372070479921486 | validation: 0.19512853616100273]
	TIME [epoch: 86.1 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23617395094383692		[learning rate: 0.0042207]
	Learning Rate: 0.0042207
	LOSS [training: 0.23617395094383692 | validation: 0.19504113794668324]
	TIME [epoch: 86.2 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23598747733341863		[learning rate: 0.0042039]
	Learning Rate: 0.00420391
	LOSS [training: 0.23598747733341863 | validation: 0.19384436474856667]
	TIME [epoch: 86.2 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2413253193687953		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 0.2413253193687953 | validation: 0.1903549432564438]
	TIME [epoch: 86.2 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2339069961248969		[learning rate: 0.0041705]
	Learning Rate: 0.00417054
	LOSS [training: 0.2339069961248969 | validation: 0.18648756926815008]
	TIME [epoch: 86.2 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v13b_20240716_161953/states/model_facs_v2_dec1b_2dpca_v13b_264.pth
	Model improved!!!
EPOCH 265/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23496930478437283		[learning rate: 0.004154]
	Learning Rate: 0.00415395
	LOSS [training: 0.23496930478437283 | validation: 0.20436852138536374]
	TIME [epoch: 86.1 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23771648692464348		[learning rate: 0.0041374]
	Learning Rate: 0.00413743
	LOSS [training: 0.23771648692464348 | validation: 0.2077587057077046]
	TIME [epoch: 86.1 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2342371090486095		[learning rate: 0.004121]
	Learning Rate: 0.00412098
	LOSS [training: 0.2342371090486095 | validation: 0.19885521410460674]
	TIME [epoch: 86.1 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23493093202008394		[learning rate: 0.0041046]
	Learning Rate: 0.00410458
	LOSS [training: 0.23493093202008394 | validation: 0.18633871465861407]
	TIME [epoch: 86.1 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v13b_20240716_161953/states/model_facs_v2_dec1b_2dpca_v13b_268.pth
	Model improved!!!
EPOCH 269/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23352799223638288		[learning rate: 0.0040883]
	Learning Rate: 0.00408826
	LOSS [training: 0.23352799223638288 | validation: 0.19701721539908307]
	TIME [epoch: 86 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2367797336375287		[learning rate: 0.004072]
	Learning Rate: 0.004072
	LOSS [training: 0.2367797336375287 | validation: 0.20089048688417305]
	TIME [epoch: 86.1 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23311879017548293		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.23311879017548293 | validation: 0.19505228785214307]
	TIME [epoch: 86.1 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23370391768313917		[learning rate: 0.0040397]
	Learning Rate: 0.00403967
	LOSS [training: 0.23370391768313917 | validation: 0.20874258628932205]
	TIME [epoch: 86.1 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23525815761029367		[learning rate: 0.0040236]
	Learning Rate: 0.00402361
	LOSS [training: 0.23525815761029367 | validation: 0.18989054163907718]
	TIME [epoch: 86.1 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2317875475177154		[learning rate: 0.0040076]
	Learning Rate: 0.0040076
	LOSS [training: 0.2317875475177154 | validation: 0.21163068018578074]
	TIME [epoch: 86.1 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24024702633737607		[learning rate: 0.0039917]
	Learning Rate: 0.00399166
	LOSS [training: 0.24024702633737607 | validation: 0.18884929897371083]
	TIME [epoch: 85.9 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22826873769288328		[learning rate: 0.0039758]
	Learning Rate: 0.00397579
	LOSS [training: 0.22826873769288328 | validation: 0.2011675510524523]
	TIME [epoch: 86 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23637706010693174		[learning rate: 0.00396]
	Learning Rate: 0.00395997
	LOSS [training: 0.23637706010693174 | validation: 0.19794541255404088]
	TIME [epoch: 86 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2300154444133602		[learning rate: 0.0039442]
	Learning Rate: 0.00394422
	LOSS [training: 0.2300154444133602 | validation: 0.1897450290557341]
	TIME [epoch: 86.1 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24167827537330228		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 0.24167827537330228 | validation: 0.19481170003069123]
	TIME [epoch: 86.1 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24046902898034617		[learning rate: 0.0039129]
	Learning Rate: 0.00391291
	LOSS [training: 0.24046902898034617 | validation: 0.19534903583085544]
	TIME [epoch: 86.1 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.230049702393326		[learning rate: 0.0038973]
	Learning Rate: 0.00389735
	LOSS [training: 0.230049702393326 | validation: 0.1964769785820377]
	TIME [epoch: 86 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22636684586543054		[learning rate: 0.0038818]
	Learning Rate: 0.00388185
	LOSS [training: 0.22636684586543054 | validation: 0.19654880215054588]
	TIME [epoch: 86 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24814537664259037		[learning rate: 0.0038664]
	Learning Rate: 0.00386641
	LOSS [training: 0.24814537664259037 | validation: 0.18941307559308682]
	TIME [epoch: 86 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23163907562108785		[learning rate: 0.003851]
	Learning Rate: 0.00385103
	LOSS [training: 0.23163907562108785 | validation: 0.19030620998157424]
	TIME [epoch: 86.1 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23355038375420753		[learning rate: 0.0038357]
	Learning Rate: 0.00383571
	LOSS [training: 0.23355038375420753 | validation: 0.1994929239356335]
	TIME [epoch: 86 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23205786214098145		[learning rate: 0.0038205]
	Learning Rate: 0.00382046
	LOSS [training: 0.23205786214098145 | validation: 0.1923292444466564]
	TIME [epoch: 86.1 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23361589356412985		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 0.23361589356412985 | validation: 0.18883281118040046]
	TIME [epoch: 86 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23400156422570126		[learning rate: 0.0037901]
	Learning Rate: 0.00379013
	LOSS [training: 0.23400156422570126 | validation: 0.19862063237041397]
	TIME [epoch: 86.2 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23701390403797587		[learning rate: 0.0037751]
	Learning Rate: 0.00377505
	LOSS [training: 0.23701390403797587 | validation: 0.18978047425206868]
	TIME [epoch: 86 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22919037478432566		[learning rate: 0.00376]
	Learning Rate: 0.00376004
	LOSS [training: 0.22919037478432566 | validation: 0.1972208749538269]
	TIME [epoch: 85.9 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23949064815996618		[learning rate: 0.0037451]
	Learning Rate: 0.00374508
	LOSS [training: 0.23949064815996618 | validation: 0.18830529792882977]
	TIME [epoch: 86.1 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23451723252863857		[learning rate: 0.0037302]
	Learning Rate: 0.00373019
	LOSS [training: 0.23451723252863857 | validation: 0.2043593530280417]
	TIME [epoch: 86.1 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23154337564163965		[learning rate: 0.0037154]
	Learning Rate: 0.00371535
	LOSS [training: 0.23154337564163965 | validation: 0.19784887009227592]
	TIME [epoch: 86 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2348275893633628		[learning rate: 0.0037006]
	Learning Rate: 0.00370058
	LOSS [training: 0.2348275893633628 | validation: 0.18858385764702273]
	TIME [epoch: 86 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2280796180702834		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 0.2280796180702834 | validation: 0.19107587518810332]
	TIME [epoch: 86 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23920275949695244		[learning rate: 0.0036712]
	Learning Rate: 0.0036712
	LOSS [training: 0.23920275949695244 | validation: 0.2062998126686087]
	TIME [epoch: 86 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23356612718502756		[learning rate: 0.0036566]
	Learning Rate: 0.0036566
	LOSS [training: 0.23356612718502756 | validation: 0.1994554782155546]
	TIME [epoch: 86 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2357282638645651		[learning rate: 0.0036421]
	Learning Rate: 0.00364205
	LOSS [training: 0.2357282638645651 | validation: 0.19789699105970765]
	TIME [epoch: 86 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23484380940904626		[learning rate: 0.0036276]
	Learning Rate: 0.00362757
	LOSS [training: 0.23484380940904626 | validation: 0.19605782324970167]
	TIME [epoch: 86.1 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2344813438368097		[learning rate: 0.0036131]
	Learning Rate: 0.00361314
	LOSS [training: 0.2344813438368097 | validation: 0.19441038461358695]
	TIME [epoch: 86 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.227514156191703		[learning rate: 0.0035988]
	Learning Rate: 0.00359877
	LOSS [training: 0.227514156191703 | validation: 0.1985020179620434]
	TIME [epoch: 204 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2346427499780027		[learning rate: 0.0035845]
	Learning Rate: 0.00358445
	LOSS [training: 0.2346427499780027 | validation: 0.20529305186621033]
	TIME [epoch: 179 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23003164082287267		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 0.23003164082287267 | validation: 0.19367219829088184]
	TIME [epoch: 179 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23030822535515144		[learning rate: 0.003556]
	Learning Rate: 0.003556
	LOSS [training: 0.23030822535515144 | validation: 0.19463644608515215]
	TIME [epoch: 178 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22950893929594457		[learning rate: 0.0035419]
	Learning Rate: 0.00354185
	LOSS [training: 0.22950893929594457 | validation: 0.18937475088962133]
	TIME [epoch: 179 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23110251532135273		[learning rate: 0.0035278]
	Learning Rate: 0.00352777
	LOSS [training: 0.23110251532135273 | validation: 0.19381833938326815]
	TIME [epoch: 179 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23055819752391007		[learning rate: 0.0035137]
	Learning Rate: 0.00351374
	LOSS [training: 0.23055819752391007 | validation: 0.18698556208222777]
	TIME [epoch: 179 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22660231861958394		[learning rate: 0.0034998]
	Learning Rate: 0.00349976
	LOSS [training: 0.22660231861958394 | validation: 0.1894800063047728]
	TIME [epoch: 179 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22406578145716866		[learning rate: 0.0034858]
	Learning Rate: 0.00348584
	LOSS [training: 0.22406578145716866 | validation: 0.19558331899117362]
	TIME [epoch: 179 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23352443513433307		[learning rate: 0.003472]
	Learning Rate: 0.00347198
	LOSS [training: 0.23352443513433307 | validation: 0.19201289431111673]
	TIME [epoch: 179 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23185828686256857		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.23185828686256857 | validation: 0.1980820427856546]
	TIME [epoch: 179 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2323155177316752		[learning rate: 0.0034444]
	Learning Rate: 0.00344441
	LOSS [training: 0.2323155177316752 | validation: 0.19826266756994443]
	TIME [epoch: 179 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2280747732714783		[learning rate: 0.0034307]
	Learning Rate: 0.00343071
	LOSS [training: 0.2280747732714783 | validation: 0.1883230085144775]
	TIME [epoch: 179 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22768402315009625		[learning rate: 0.0034171]
	Learning Rate: 0.00341707
	LOSS [training: 0.22768402315009625 | validation: 0.19431459883486638]
	TIME [epoch: 179 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23260031036603668		[learning rate: 0.0034035]
	Learning Rate: 0.00340348
	LOSS [training: 0.23260031036603668 | validation: 0.2066452760008129]
	TIME [epoch: 179 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23728644938610088		[learning rate: 0.0033899]
	Learning Rate: 0.00338994
	LOSS [training: 0.23728644938610088 | validation: 0.18795099420758282]
	TIME [epoch: 179 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23179675632991995		[learning rate: 0.0033765]
	Learning Rate: 0.00337646
	LOSS [training: 0.23179675632991995 | validation: 0.1956051742042082]
	TIME [epoch: 179 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23386713400998438		[learning rate: 0.003363]
	Learning Rate: 0.00336303
	LOSS [training: 0.23386713400998438 | validation: 0.1887415998999678]
	TIME [epoch: 179 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22664754389397446		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 0.22664754389397446 | validation: 0.18970463810697666]
	TIME [epoch: 179 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22705154636813507		[learning rate: 0.0033363]
	Learning Rate: 0.00333633
	LOSS [training: 0.22705154636813507 | validation: 0.19273598363460928]
	TIME [epoch: 179 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23990818253098714		[learning rate: 0.0033231]
	Learning Rate: 0.00332306
	LOSS [training: 0.23990818253098714 | validation: 0.2034141698702708]
	TIME [epoch: 179 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22860316712211803		[learning rate: 0.0033098]
	Learning Rate: 0.00330985
	LOSS [training: 0.22860316712211803 | validation: 0.19354747178133946]
	TIME [epoch: 179 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22367581143222587		[learning rate: 0.0032967]
	Learning Rate: 0.00329668
	LOSS [training: 0.22367581143222587 | validation: 0.1887128643935943]
	TIME [epoch: 179 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.228319066892085		[learning rate: 0.0032836]
	Learning Rate: 0.00328357
	LOSS [training: 0.228319066892085 | validation: 0.18859408177879478]
	TIME [epoch: 179 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22669684620955813		[learning rate: 0.0032705]
	Learning Rate: 0.00327051
	LOSS [training: 0.22669684620955813 | validation: 0.19070201583775706]
	TIME [epoch: 179 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23208456535725772		[learning rate: 0.0032575]
	Learning Rate: 0.0032575
	LOSS [training: 0.23208456535725772 | validation: 0.1953770948592612]
	TIME [epoch: 179 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23782773750329017		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 0.23782773750329017 | validation: 0.18621453107260405]
	TIME [epoch: 179 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v13b_20240716_161953/states/model_facs_v2_dec1b_2dpca_v13b_327.pth
	Model improved!!!
EPOCH 328/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23006903790234073		[learning rate: 0.0032316]
	Learning Rate: 0.00323164
	LOSS [training: 0.23006903790234073 | validation: 0.18875371137907582]
	TIME [epoch: 179 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22648713873850332		[learning rate: 0.0032188]
	Learning Rate: 0.00321879
	LOSS [training: 0.22648713873850332 | validation: 0.20125308288724764]
	TIME [epoch: 178 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2303164541884266		[learning rate: 0.003206]
	Learning Rate: 0.00320599
	LOSS [training: 0.2303164541884266 | validation: 0.18821427094916884]
	TIME [epoch: 179 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24148839098468367		[learning rate: 0.0031932]
	Learning Rate: 0.00319323
	LOSS [training: 0.24148839098468367 | validation: 0.19553575996046652]
	TIME [epoch: 179 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23488007226940047		[learning rate: 0.0031805]
	Learning Rate: 0.00318053
	LOSS [training: 0.23488007226940047 | validation: 0.1937938380730955]
	TIME [epoch: 179 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23292970531337265		[learning rate: 0.0031679]
	Learning Rate: 0.00316788
	LOSS [training: 0.23292970531337265 | validation: 0.19236659656496982]
	TIME [epoch: 179 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23645527790275475		[learning rate: 0.0031553]
	Learning Rate: 0.00315528
	LOSS [training: 0.23645527790275475 | validation: 0.1884557452388259]
	TIME [epoch: 179 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23446602904703123		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 0.23446602904703123 | validation: 0.20467886867437599]
	TIME [epoch: 179 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23873339781203196		[learning rate: 0.0031302]
	Learning Rate: 0.00313023
	LOSS [training: 0.23873339781203196 | validation: 0.1899729009140525]
	TIME [epoch: 179 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2267987359189749		[learning rate: 0.0031178]
	Learning Rate: 0.00311779
	LOSS [training: 0.2267987359189749 | validation: 0.19349634830754442]
	TIME [epoch: 179 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23359695632835167		[learning rate: 0.0031054]
	Learning Rate: 0.00310538
	LOSS [training: 0.23359695632835167 | validation: 0.19059915837786776]
	TIME [epoch: 179 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22990848491394728		[learning rate: 0.003093]
	Learning Rate: 0.00309303
	LOSS [training: 0.22990848491394728 | validation: 0.192189038260061]
	TIME [epoch: 179 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22962002191205036		[learning rate: 0.0030807]
	Learning Rate: 0.00308073
	LOSS [training: 0.22962002191205036 | validation: 0.19352805481728544]
	TIME [epoch: 179 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2377263299898434		[learning rate: 0.0030685]
	Learning Rate: 0.00306848
	LOSS [training: 0.2377263299898434 | validation: 0.20723586227468643]
	TIME [epoch: 179 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2330214455399557		[learning rate: 0.0030563]
	Learning Rate: 0.00305627
	LOSS [training: 0.2330214455399557 | validation: 0.18958960189731539]
	TIME [epoch: 179 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22339422048846705		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 0.22339422048846705 | validation: 0.1884809134981456]
	TIME [epoch: 179 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23139194158761744		[learning rate: 0.003032]
	Learning Rate: 0.00303201
	LOSS [training: 0.23139194158761744 | validation: 0.20372666348509738]
	TIME [epoch: 179 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23044856310308756		[learning rate: 0.00302]
	Learning Rate: 0.00301995
	LOSS [training: 0.23044856310308756 | validation: 0.19797514593777857]
	TIME [epoch: 179 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2312247256272309		[learning rate: 0.0030079]
	Learning Rate: 0.00300794
	LOSS [training: 0.2312247256272309 | validation: 0.18660868738422232]
	TIME [epoch: 179 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.223288487792622		[learning rate: 0.002996]
	Learning Rate: 0.00299598
	LOSS [training: 0.223288487792622 | validation: 0.19765423728669793]
	TIME [epoch: 179 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23102386582664425		[learning rate: 0.0029841]
	Learning Rate: 0.00298406
	LOSS [training: 0.23102386582664425 | validation: 0.19755599724227313]
	TIME [epoch: 179 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22894040971319912		[learning rate: 0.0029722]
	Learning Rate: 0.00297219
	LOSS [training: 0.22894040971319912 | validation: 0.18740059308681878]
	TIME [epoch: 179 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22923741276095827		[learning rate: 0.0029604]
	Learning Rate: 0.00296037
	LOSS [training: 0.22923741276095827 | validation: 0.18371620209793618]
	TIME [epoch: 179 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v13b_20240716_161953/states/model_facs_v2_dec1b_2dpca_v13b_350.pth
	Model improved!!!
EPOCH 351/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23715585723955535		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.23715585723955535 | validation: 0.19522079641281898]
	TIME [epoch: 179 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23244870326295577		[learning rate: 0.0029369]
	Learning Rate: 0.00293687
	LOSS [training: 0.23244870326295577 | validation: 0.19261619036018623]
	TIME [epoch: 179 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2327804513382966		[learning rate: 0.0029252]
	Learning Rate: 0.00292519
	LOSS [training: 0.2327804513382966 | validation: 0.18903872205093372]
	TIME [epoch: 178 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2238388444147677		[learning rate: 0.0029136]
	Learning Rate: 0.00291355
	LOSS [training: 0.2238388444147677 | validation: 0.19057292971674292]
	TIME [epoch: 179 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22540426051603163		[learning rate: 0.002902]
	Learning Rate: 0.00290197
	LOSS [training: 0.22540426051603163 | validation: 0.1939946734341183]
	TIME [epoch: 179 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23702255140472633		[learning rate: 0.0028904]
	Learning Rate: 0.00289042
	LOSS [training: 0.23702255140472633 | validation: 0.19366342133769027]
	TIME [epoch: 179 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23472576302078801		[learning rate: 0.0028789]
	Learning Rate: 0.00287893
	LOSS [training: 0.23472576302078801 | validation: 0.18168085607155554]
	TIME [epoch: 179 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v13b_20240716_161953/states/model_facs_v2_dec1b_2dpca_v13b_357.pth
	Model improved!!!
EPOCH 358/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23226343656779658		[learning rate: 0.0028675]
	Learning Rate: 0.00286748
	LOSS [training: 0.23226343656779658 | validation: 0.1847103595234218]
	TIME [epoch: 179 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22962969033325148		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 0.22962969033325148 | validation: 0.18719423314877917]
	TIME [epoch: 178 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23549070752382922		[learning rate: 0.0028447]
	Learning Rate: 0.00284471
	LOSS [training: 0.23549070752382922 | validation: 0.18657041380273715]
	TIME [epoch: 179 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22287456112737505		[learning rate: 0.0028334]
	Learning Rate: 0.0028334
	LOSS [training: 0.22287456112737505 | validation: 0.19579201510206867]
	TIME [epoch: 178 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22564642806141835		[learning rate: 0.0028221]
	Learning Rate: 0.00282213
	LOSS [training: 0.22564642806141835 | validation: 0.1861872412493607]
	TIME [epoch: 178 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23003238344792823		[learning rate: 0.0028109]
	Learning Rate: 0.00281091
	LOSS [training: 0.23003238344792823 | validation: 0.1880343257366783]
	TIME [epoch: 178 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22999681609907688		[learning rate: 0.0027997]
	Learning Rate: 0.00279973
	LOSS [training: 0.22999681609907688 | validation: 0.18897341836109446]
	TIME [epoch: 178 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22907194900647335		[learning rate: 0.0027886]
	Learning Rate: 0.00278859
	LOSS [training: 0.22907194900647335 | validation: 0.1912475831010863]
	TIME [epoch: 178 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2261353214881862		[learning rate: 0.0027775]
	Learning Rate: 0.0027775
	LOSS [training: 0.2261353214881862 | validation: 0.18732226943977193]
	TIME [epoch: 179 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22152649291616827		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 0.22152649291616827 | validation: 0.18956816637032517]
	TIME [epoch: 178 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22884277571548195		[learning rate: 0.0027554]
	Learning Rate: 0.00275545
	LOSS [training: 0.22884277571548195 | validation: 0.1928497880655929]
	TIME [epoch: 179 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24317399202203654		[learning rate: 0.0027445]
	Learning Rate: 0.00274449
	LOSS [training: 0.24317399202203654 | validation: 0.20231322122575496]
	TIME [epoch: 178 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24469061416454968		[learning rate: 0.0027336]
	Learning Rate: 0.00273357
	LOSS [training: 0.24469061416454968 | validation: 0.19420198335522013]
	TIME [epoch: 179 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2285853529569684		[learning rate: 0.0027227]
	Learning Rate: 0.0027227
	LOSS [training: 0.2285853529569684 | validation: 0.19487539689133215]
	TIME [epoch: 178 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23183902875392626		[learning rate: 0.0027119]
	Learning Rate: 0.00271187
	LOSS [training: 0.23183902875392626 | validation: 0.1917026771438209]
	TIME [epoch: 179 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22634720851037762		[learning rate: 0.0027011]
	Learning Rate: 0.00270109
	LOSS [training: 0.22634720851037762 | validation: 0.18524931886266233]
	TIME [epoch: 178 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2349069549365098		[learning rate: 0.0026903]
	Learning Rate: 0.00269034
	LOSS [training: 0.2349069549365098 | validation: 0.18787863704819485]
	TIME [epoch: 179 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2349609724055064		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 0.2349609724055064 | validation: 0.18861462648018718]
	TIME [epoch: 178 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22933526074037858		[learning rate: 0.002669]
	Learning Rate: 0.00266899
	LOSS [training: 0.22933526074037858 | validation: 0.18898053466184267]
	TIME [epoch: 178 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23629496110707338		[learning rate: 0.0026584]
	Learning Rate: 0.00265837
	LOSS [training: 0.23629496110707338 | validation: 0.19191430342301943]
	TIME [epoch: 179 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2357632428631487		[learning rate: 0.0026478]
	Learning Rate: 0.0026478
	LOSS [training: 0.2357632428631487 | validation: 0.1876760928125979]
	TIME [epoch: 179 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22920288260060895		[learning rate: 0.0026373]
	Learning Rate: 0.00263727
	LOSS [training: 0.22920288260060895 | validation: 0.18799294404503444]
	TIME [epoch: 179 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2280368370438802		[learning rate: 0.0026268]
	Learning Rate: 0.00262678
	LOSS [training: 0.2280368370438802 | validation: 0.19345622117947495]
	TIME [epoch: 179 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23363128893406143		[learning rate: 0.0026163]
	Learning Rate: 0.00261633
	LOSS [training: 0.23363128893406143 | validation: 0.18938591766976556]
	TIME [epoch: 179 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22938960164171895		[learning rate: 0.0026059]
	Learning Rate: 0.00260592
	LOSS [training: 0.22938960164171895 | validation: 0.1869431922066936]
	TIME [epoch: 178 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2329401726859347		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 0.2329401726859347 | validation: 0.1873104911479848]
	TIME [epoch: 179 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23517419253815255		[learning rate: 0.0025852]
	Learning Rate: 0.00258523
	LOSS [training: 0.23517419253815255 | validation: 0.19099317933620114]
	TIME [epoch: 179 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22758850290635152		[learning rate: 0.002575]
	Learning Rate: 0.00257495
	LOSS [training: 0.22758850290635152 | validation: 0.18364759067725694]
	TIME [epoch: 179 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23089631498285357		[learning rate: 0.0025647]
	Learning Rate: 0.00256471
	LOSS [training: 0.23089631498285357 | validation: 0.19238300848207462]
	TIME [epoch: 179 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2393145928482992		[learning rate: 0.0025545]
	Learning Rate: 0.00255451
	LOSS [training: 0.2393145928482992 | validation: 0.18504730547794665]
	TIME [epoch: 179 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23233890084860376		[learning rate: 0.0025444]
	Learning Rate: 0.00254435
	LOSS [training: 0.23233890084860376 | validation: 0.18699551753639324]
	TIME [epoch: 179 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23209660171278987		[learning rate: 0.0025342]
	Learning Rate: 0.00253423
	LOSS [training: 0.23209660171278987 | validation: 0.19812018215743238]
	TIME [epoch: 179 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23028410577301928		[learning rate: 0.0025242]
	Learning Rate: 0.00252415
	LOSS [training: 0.23028410577301928 | validation: 0.19245169475012663]
	TIME [epoch: 179 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22530325967904932		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.22530325967904932 | validation: 0.19609164194310785]
	TIME [epoch: 179 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2312766026755565		[learning rate: 0.0025041]
	Learning Rate: 0.00250411
	LOSS [training: 0.2312766026755565 | validation: 0.18545775472511397]
	TIME [epoch: 179 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22979863623039698		[learning rate: 0.0024942]
	Learning Rate: 0.00249415
	LOSS [training: 0.22979863623039698 | validation: 0.18913188295410074]
	TIME [epoch: 179 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22061804548613964		[learning rate: 0.0024842]
	Learning Rate: 0.00248423
	LOSS [training: 0.22061804548613964 | validation: 0.18505527507352326]
	TIME [epoch: 179 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22374664160126892		[learning rate: 0.0024744]
	Learning Rate: 0.00247435
	LOSS [training: 0.22374664160126892 | validation: 0.18836059924201237]
	TIME [epoch: 179 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23399327156435495		[learning rate: 0.0024645]
	Learning Rate: 0.00246451
	LOSS [training: 0.23399327156435495 | validation: 0.18000879163763953]
	TIME [epoch: 179 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v13b_20240716_161953/states/model_facs_v2_dec1b_2dpca_v13b_396.pth
	Model improved!!!
EPOCH 397/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23008753826184694		[learning rate: 0.0024547]
	Learning Rate: 0.00245471
	LOSS [training: 0.23008753826184694 | validation: 0.1900615957290722]
	TIME [epoch: 179 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23244408733858435		[learning rate: 0.0024449]
	Learning Rate: 0.00244495
	LOSS [training: 0.23244408733858435 | validation: 0.1897402387559762]
	TIME [epoch: 178 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22496920553703445		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 0.22496920553703445 | validation: 0.1883572803723299]
	TIME [epoch: 178 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23361780803314666		[learning rate: 0.0024255]
	Learning Rate: 0.00242554
	LOSS [training: 0.23361780803314666 | validation: 0.18837328441695972]
	TIME [epoch: 178 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22461311562290692		[learning rate: 0.0024159]
	Learning Rate: 0.00241589
	LOSS [training: 0.22461311562290692 | validation: 0.18432905062804977]
	TIME [epoch: 178 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22296957920462074		[learning rate: 0.0024063]
	Learning Rate: 0.00240628
	LOSS [training: 0.22296957920462074 | validation: 0.19086810125852327]
	TIME [epoch: 178 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23047208170388955		[learning rate: 0.0023967]
	Learning Rate: 0.00239671
	LOSS [training: 0.23047208170388955 | validation: 0.18419235684928448]
	TIME [epoch: 178 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2273379987247385		[learning rate: 0.0023872]
	Learning Rate: 0.00238718
	LOSS [training: 0.2273379987247385 | validation: 0.19519703756845458]
	TIME [epoch: 179 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.230879122246434		[learning rate: 0.0023777]
	Learning Rate: 0.00237768
	LOSS [training: 0.230879122246434 | validation: 0.1923529858252532]
	TIME [epoch: 179 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22932180131827154		[learning rate: 0.0023682]
	Learning Rate: 0.00236823
	LOSS [training: 0.22932180131827154 | validation: 0.1915551358814601]
	TIME [epoch: 179 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22182407567743506		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 0.22182407567743506 | validation: 0.18815021105306168]
	TIME [epoch: 178 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2276068613623831		[learning rate: 0.0023494]
	Learning Rate: 0.00234942
	LOSS [training: 0.2276068613623831 | validation: 0.18433386197957974]
	TIME [epoch: 178 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22909757075827558		[learning rate: 0.0023401]
	Learning Rate: 0.00234008
	LOSS [training: 0.22909757075827558 | validation: 0.1866826610663609]
	TIME [epoch: 179 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2317391546396182		[learning rate: 0.0023308]
	Learning Rate: 0.00233077
	LOSS [training: 0.2317391546396182 | validation: 0.18735907084750744]
	TIME [epoch: 179 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22533736933690596		[learning rate: 0.0023215]
	Learning Rate: 0.0023215
	LOSS [training: 0.22533736933690596 | validation: 0.18998066567023653]
	TIME [epoch: 178 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22854837698425035		[learning rate: 0.0023123]
	Learning Rate: 0.00231227
	LOSS [training: 0.22854837698425035 | validation: 0.1921559801431208]
	TIME [epoch: 179 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23049467687997513		[learning rate: 0.0023031]
	Learning Rate: 0.00230307
	LOSS [training: 0.23049467687997513 | validation: 0.19499532426487082]
	TIME [epoch: 178 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2322813186692122		[learning rate: 0.0022939]
	Learning Rate: 0.00229391
	LOSS [training: 0.2322813186692122 | validation: 0.17745144227277226]
	TIME [epoch: 179 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v13b_20240716_161953/states/model_facs_v2_dec1b_2dpca_v13b_414.pth
	Model improved!!!
EPOCH 415/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22707235269552267		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 0.22707235269552267 | validation: 0.18913903100458002]
	TIME [epoch: 179 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23597762070021558		[learning rate: 0.0022757]
	Learning Rate: 0.0022757
	LOSS [training: 0.23597762070021558 | validation: 0.19277754035377892]
	TIME [epoch: 179 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2294227647976396		[learning rate: 0.0022667]
	Learning Rate: 0.00226665
	LOSS [training: 0.2294227647976396 | validation: 0.1923917319130681]
	TIME [epoch: 179 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2290574345352556		[learning rate: 0.0022576]
	Learning Rate: 0.00225764
	LOSS [training: 0.2290574345352556 | validation: 0.18870856923737622]
	TIME [epoch: 179 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22498821987028395		[learning rate: 0.0022487]
	Learning Rate: 0.00224866
	LOSS [training: 0.22498821987028395 | validation: 0.19358035589471284]
	TIME [epoch: 178 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2271903832572961		[learning rate: 0.0022397]
	Learning Rate: 0.00223971
	LOSS [training: 0.2271903832572961 | validation: 0.1924996242416472]
	TIME [epoch: 179 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22085229267336262		[learning rate: 0.0022308]
	Learning Rate: 0.0022308
	LOSS [training: 0.22085229267336262 | validation: 0.1873809810660454]
	TIME [epoch: 178 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22425507143063264		[learning rate: 0.0022219]
	Learning Rate: 0.00222193
	LOSS [training: 0.22425507143063264 | validation: 0.1854250045836526]
	TIME [epoch: 179 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23255423877143835		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.23255423877143835 | validation: 0.18603708584954332]
	TIME [epoch: 179 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22723696458016793		[learning rate: 0.0022043]
	Learning Rate: 0.00220429
	LOSS [training: 0.22723696458016793 | validation: 0.18859350265409733]
	TIME [epoch: 179 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23103832967710236		[learning rate: 0.0021955]
	Learning Rate: 0.00219553
	LOSS [training: 0.23103832967710236 | validation: 0.18933721120189814]
	TIME [epoch: 179 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2348592572760454		[learning rate: 0.0021868]
	Learning Rate: 0.00218679
	LOSS [training: 0.2348592572760454 | validation: 0.18988974711537382]
	TIME [epoch: 179 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23220406011122563		[learning rate: 0.0021781]
	Learning Rate: 0.0021781
	LOSS [training: 0.23220406011122563 | validation: 0.191784063127607]
	TIME [epoch: 179 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23218156477192142		[learning rate: 0.0021694]
	Learning Rate: 0.00216943
	LOSS [training: 0.23218156477192142 | validation: 0.18795018737882527]
	TIME [epoch: 179 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23415820131331447		[learning rate: 0.0021608]
	Learning Rate: 0.0021608
	LOSS [training: 0.23415820131331447 | validation: 0.18952211466729488]
	TIME [epoch: 179 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22711713987782403		[learning rate: 0.0021522]
	Learning Rate: 0.00215221
	LOSS [training: 0.22711713987782403 | validation: 0.18665889687749448]
	TIME [epoch: 178 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2312262030579316		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.2312262030579316 | validation: 0.18745470101793854]
	TIME [epoch: 179 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22651046985953224		[learning rate: 0.0021351]
	Learning Rate: 0.00213512
	LOSS [training: 0.22651046985953224 | validation: 0.18749116485351028]
	TIME [epoch: 178 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22646128542552063		[learning rate: 0.0021266]
	Learning Rate: 0.00212663
	LOSS [training: 0.22646128542552063 | validation: 0.18583964028034397]
	TIME [epoch: 178 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2287384893758528		[learning rate: 0.0021182]
	Learning Rate: 0.00211817
	LOSS [training: 0.2287384893758528 | validation: 0.18799408847395122]
	TIME [epoch: 179 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2286831288954022		[learning rate: 0.0021097]
	Learning Rate: 0.00210975
	LOSS [training: 0.2286831288954022 | validation: 0.1880745881407814]
	TIME [epoch: 179 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22913462556675132		[learning rate: 0.0021014]
	Learning Rate: 0.00210136
	LOSS [training: 0.22913462556675132 | validation: 0.19316271588112643]
	TIME [epoch: 179 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22895161583573673		[learning rate: 0.002093]
	Learning Rate: 0.002093
	LOSS [training: 0.22895161583573673 | validation: 0.1895352942111534]
	TIME [epoch: 178 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22877386305901043		[learning rate: 0.0020847]
	Learning Rate: 0.00208468
	LOSS [training: 0.22877386305901043 | validation: 0.18755197355854308]
	TIME [epoch: 179 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23390930365862428		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.23390930365862428 | validation: 0.18876343132964774]
	TIME [epoch: 179 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2276327304635236		[learning rate: 0.0020681]
	Learning Rate: 0.00206813
	LOSS [training: 0.2276327304635236 | validation: 0.1966697991587252]
	TIME [epoch: 179 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22634142431861878		[learning rate: 0.0020599]
	Learning Rate: 0.0020599
	LOSS [training: 0.22634142431861878 | validation: 0.18890222483061478]
	TIME [epoch: 179 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22979782326910472		[learning rate: 0.0020517]
	Learning Rate: 0.00205171
	LOSS [training: 0.22979782326910472 | validation: 0.1886803685206838]
	TIME [epoch: 179 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.230140515819806		[learning rate: 0.0020435]
	Learning Rate: 0.00204355
	LOSS [training: 0.230140515819806 | validation: 0.18214222105859307]
	TIME [epoch: 178 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23082883571302018		[learning rate: 0.0020354]
	Learning Rate: 0.00203542
	LOSS [training: 0.23082883571302018 | validation: 0.1853103205479767]
	TIME [epoch: 179 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.236580189982343		[learning rate: 0.0020273]
	Learning Rate: 0.00202732
	LOSS [training: 0.236580189982343 | validation: 0.1891173128161435]
	TIME [epoch: 179 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22579192641662837		[learning rate: 0.0020193]
	Learning Rate: 0.00201926
	LOSS [training: 0.22579192641662837 | validation: 0.18392692702375948]
	TIME [epoch: 178 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22884292199210193		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 0.22884292199210193 | validation: 0.19183481752197845]
	TIME [epoch: 179 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2319752790788178		[learning rate: 0.0020032]
	Learning Rate: 0.00200323
	LOSS [training: 0.2319752790788178 | validation: 0.19293364284862058]
	TIME [epoch: 178 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23046240793238304		[learning rate: 0.0019953]
	Learning Rate: 0.00199526
	LOSS [training: 0.23046240793238304 | validation: 0.18353265683573622]
	TIME [epoch: 178 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2216884810290853		[learning rate: 0.0019873]
	Learning Rate: 0.00198733
	LOSS [training: 0.2216884810290853 | validation: 0.18873735430759586]
	TIME [epoch: 179 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2262107075222577		[learning rate: 0.0019794]
	Learning Rate: 0.00197942
	LOSS [training: 0.2262107075222577 | validation: 0.187888422372717]
	TIME [epoch: 179 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2312439761192167		[learning rate: 0.0019715]
	Learning Rate: 0.00197155
	LOSS [training: 0.2312439761192167 | validation: 0.18983078081881136]
	TIME [epoch: 179 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22239343951398974		[learning rate: 0.0019637]
	Learning Rate: 0.00196371
	LOSS [training: 0.22239343951398974 | validation: 0.18440768642456012]
	TIME [epoch: 178 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22180045244960594		[learning rate: 0.0019559]
	Learning Rate: 0.0019559
	LOSS [training: 0.22180045244960594 | validation: 0.1854176346529211]
	TIME [epoch: 179 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2254734694658669		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 0.2254734694658669 | validation: 0.19004743815292627]
	TIME [epoch: 179 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22553589610053842		[learning rate: 0.0019404]
	Learning Rate: 0.00194037
	LOSS [training: 0.22553589610053842 | validation: 0.1842185311137853]
	TIME [epoch: 179 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2248634949195011		[learning rate: 0.0019327]
	Learning Rate: 0.00193265
	LOSS [training: 0.2248634949195011 | validation: 0.18882182638373318]
	TIME [epoch: 178 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22631677414180196		[learning rate: 0.001925]
	Learning Rate: 0.00192497
	LOSS [training: 0.22631677414180196 | validation: 0.19141087715401864]
	TIME [epoch: 178 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23319904806315092		[learning rate: 0.0019173]
	Learning Rate: 0.00191731
	LOSS [training: 0.23319904806315092 | validation: 0.18781425389999867]
	TIME [epoch: 178 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2279298409105005		[learning rate: 0.0019097]
	Learning Rate: 0.00190968
	LOSS [training: 0.2279298409105005 | validation: 0.18493029008915843]
	TIME [epoch: 178 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22823226454178216		[learning rate: 0.0019021]
	Learning Rate: 0.00190209
	LOSS [training: 0.22823226454178216 | validation: 0.18612079070825155]
	TIME [epoch: 178 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22058270943256586		[learning rate: 0.0018945]
	Learning Rate: 0.00189452
	LOSS [training: 0.22058270943256586 | validation: 0.1919259371535033]
	TIME [epoch: 178 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22930239720777731		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.22930239720777731 | validation: 0.19082073718008777]
	TIME [epoch: 179 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23526402585080744		[learning rate: 0.0018795]
	Learning Rate: 0.00187948
	LOSS [training: 0.23526402585080744 | validation: 0.19618092620247832]
	TIME [epoch: 178 sec]
EPOCH 465/2000:
	Training over batches...
