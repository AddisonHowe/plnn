Args:
Namespace(name='model_facs_v2_dec1b_2dpca_v7', outdir='out/model_training/model_facs_v2_dec1b_2dpca_v7', training_data='data/training_data/facs_v2/pca/dec1_fitonsubset/transition1_subset_epi_tr_ce_an_pc12/training', validation_data='data/training_data/facs_v2/pca/dec1_fitonsubset/transition1_subset_epi_tr_ce_an_pc12/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=10, batch_size=50, patience=200, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, quadratic_a=1.0, quadratic_b=1.0, ndims=2, nparams=2, nsigs=2, ncells=200, ncells_sample=200, model_do_sample=False, dt=0.005, dt_schedule='stepped', dt_schedule_bounds=[500, 1000, 1500], dt_schedule_scales=[0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=True, sigma=0.02, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', kernel='multiscale', bw_range=[0.2, 0.5, 0.9, 1.1, 1.3, 1.5, 2.0], optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 1356876436

Training model...

Saving initial model state to: out/model_training/model_facs_v2_dec1b_2dpca_v7_20240711_163535/states/model_facs_v2_dec1b_2dpca_v7_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.352816874727247		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.352816874727247 | validation: 1.2442619772670873]
	TIME [epoch: 37.5 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v7_20240711_163535/states/model_facs_v2_dec1b_2dpca_v7_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.2424216460881425		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2424216460881425 | validation: 1.1272148565228597]
	TIME [epoch: 7.93 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v7_20240711_163535/states/model_facs_v2_dec1b_2dpca_v7_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.0932262986228363		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0932262986228363 | validation: 1.042619246334493]
	TIME [epoch: 7.89 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v7_20240711_163535/states/model_facs_v2_dec1b_2dpca_v7_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.0455581839035275		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0455581839035275 | validation: 0.9785549633129401]
	TIME [epoch: 7.89 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v7_20240711_163535/states/model_facs_v2_dec1b_2dpca_v7_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.0223368398217012		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0223368398217012 | validation: 1.0198836045332715]
	TIME [epoch: 7.91 sec]
EPOCH 6/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.9625698694028824		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9625698694028824 | validation: 0.9137917164937347]
	TIME [epoch: 7.89 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v7_20240711_163535/states/model_facs_v2_dec1b_2dpca_v7_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.9038783510632425		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9038783510632425 | validation: 0.8325986932439602]
	TIME [epoch: 7.89 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v7_20240711_163535/states/model_facs_v2_dec1b_2dpca_v7_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.9093544206605535		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9093544206605535 | validation: 0.7744236771233031]
	TIME [epoch: 7.89 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v7_20240711_163535/states/model_facs_v2_dec1b_2dpca_v7_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.8163693811810724		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8163693811810724 | validation: 0.7596305565971966]
	TIME [epoch: 7.89 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v7_20240711_163535/states/model_facs_v2_dec1b_2dpca_v7_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7461792445629252		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7461792445629252 | validation: 0.7286922268611825]
	TIME [epoch: 7.93 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v7_20240711_163535/states/model_facs_v2_dec1b_2dpca_v7_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7141529117589838		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7141529117589838 | validation: 0.7454650854764224]
	TIME [epoch: 7.93 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6836409857515579		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6836409857515579 | validation: 0.6463503123446882]
	TIME [epoch: 7.98 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v7_20240711_163535/states/model_facs_v2_dec1b_2dpca_v7_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6780501611435814		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6780501611435814 | validation: 0.6196350643482587]
	TIME [epoch: 7.96 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v7_20240711_163535/states/model_facs_v2_dec1b_2dpca_v7_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6597312774806744		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6597312774806744 | validation: 0.5581668568001431]
	TIME [epoch: 7.91 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v7_20240711_163535/states/model_facs_v2_dec1b_2dpca_v7_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6268803394909593		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6268803394909593 | validation: 0.570550927153876]
	TIME [epoch: 7.92 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5738179429284904		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5738179429284904 | validation: 1.083800233915219]
	TIME [epoch: 7.93 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6400770388537018		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6400770388537018 | validation: 0.5379623128863609]
	TIME [epoch: 8 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v7_20240711_163535/states/model_facs_v2_dec1b_2dpca_v7_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5780146612779116		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5780146612779116 | validation: 0.9316200429530108]
	TIME [epoch: 7.91 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6743757419097925		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6743757419097925 | validation: 0.5788532991212658]
	TIME [epoch: 7.95 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6052554230255078		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6052554230255078 | validation: 0.5877533420091805]
	TIME [epoch: 7.95 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5520997999779893		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5520997999779893 | validation: 0.763135485126102]
	TIME [epoch: 7.93 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6347549299208836		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6347549299208836 | validation: 0.5374969421869796]
	TIME [epoch: 7.9 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v7_20240711_163535/states/model_facs_v2_dec1b_2dpca_v7_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5257991467763778		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5257991467763778 | validation: 0.5242869620948591]
	TIME [epoch: 7.98 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v7_20240711_163535/states/model_facs_v2_dec1b_2dpca_v7_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5523932197090999		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5523932197090999 | validation: 0.7102828196942774]
	TIME [epoch: 7.96 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5653431628869415		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5653431628869415 | validation: 0.5075459430031708]
	TIME [epoch: 7.98 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v7_20240711_163535/states/model_facs_v2_dec1b_2dpca_v7_25.pth
	Model improved!!!
EPOCH 26/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5055867274344721		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5055867274344721 | validation: 0.4959659313527169]
	TIME [epoch: 7.93 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v7_20240711_163535/states/model_facs_v2_dec1b_2dpca_v7_26.pth
	Model improved!!!
EPOCH 27/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5871293237875989		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5871293237875989 | validation: 0.48210453642373663]
	TIME [epoch: 7.93 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v7_20240711_163535/states/model_facs_v2_dec1b_2dpca_v7_27.pth
	Model improved!!!
EPOCH 28/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.47944580366573786		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.47944580366573786 | validation: 0.5197961451186425]
	TIME [epoch: 7.95 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.51485922109229		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.51485922109229 | validation: 0.4729093334805784]
	TIME [epoch: 7.92 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v7_20240711_163535/states/model_facs_v2_dec1b_2dpca_v7_29.pth
	Model improved!!!
EPOCH 30/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4409442453867053		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4409442453867053 | validation: 0.436862442666179]
	TIME [epoch: 7.96 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v7_20240711_163535/states/model_facs_v2_dec1b_2dpca_v7_30.pth
	Model improved!!!
EPOCH 31/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5175774505827871		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5175774505827871 | validation: 0.540114468037139]
	TIME [epoch: 7.96 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5613879328507452		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5613879328507452 | validation: 0.5357228468231868]
	TIME [epoch: 7.96 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5325737860747359		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5325737860747359 | validation: 0.5148536220797152]
	TIME [epoch: 7.88 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.48604549392125196		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.48604549392125196 | validation: 0.527017921500706]
	TIME [epoch: 7.97 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4901469549735521		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4901469549735521 | validation: 0.5224973801688778]
	TIME [epoch: 7.97 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4866597478379801		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4866597478379801 | validation: 0.5579573671414014]
	TIME [epoch: 7.92 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4616714849230321		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4616714849230321 | validation: 0.5110259586327475]
	TIME [epoch: 7.95 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5309376390536209		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5309376390536209 | validation: 0.5383341793982851]
	TIME [epoch: 7.93 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.47091692558589915		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.47091692558589915 | validation: 0.4959300998997307]
	TIME [epoch: 7.98 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.542062377777158		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.542062377777158 | validation: 0.5880060629721293]
	TIME [epoch: 7.93 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4542299933039784		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4542299933039784 | validation: 0.4913290299708882]
	TIME [epoch: 7.89 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5556596393478475		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5556596393478475 | validation: 0.6102969698409744]
	TIME [epoch: 7.88 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.468083838995909		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.468083838995909 | validation: 0.5158304400223314]
	TIME [epoch: 7.88 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6019912517686798		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6019912517686798 | validation: 0.48324444532974625]
	TIME [epoch: 7.9 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5164605484771272		[learning rate: 0.0099823]
	Learning Rate: 0.0099823
	LOSS [training: 0.5164605484771272 | validation: 0.4205281164170446]
	TIME [epoch: 7.95 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v7_20240711_163535/states/model_facs_v2_dec1b_2dpca_v7_45.pth
	Model improved!!!
EPOCH 46/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.46310101758707906		[learning rate: 0.0099426]
	Learning Rate: 0.0099426
	LOSS [training: 0.46310101758707906 | validation: 0.49026057931763967]
	TIME [epoch: 7.96 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.49445083859179806		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 0.49445083859179806 | validation: 0.4171275519672523]
	TIME [epoch: 8.01 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v7_20240711_163535/states/model_facs_v2_dec1b_2dpca_v7_47.pth
	Model improved!!!
EPOCH 48/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4680727442406795		[learning rate: 0.0098637]
	Learning Rate: 0.00986367
	LOSS [training: 0.4680727442406795 | validation: 0.44736095205115084]
	TIME [epoch: 7.88 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.49620949116150015		[learning rate: 0.0098244]
	Learning Rate: 0.00982444
	LOSS [training: 0.49620949116150015 | validation: 0.4860323280206254]
	TIME [epoch: 7.97 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4813497569459489		[learning rate: 0.0097854]
	Learning Rate: 0.00978536
	LOSS [training: 0.4813497569459489 | validation: 0.42622530074317044]
	TIME [epoch: 7.97 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4393554444310616		[learning rate: 0.0097464]
	Learning Rate: 0.00974644
	LOSS [training: 0.4393554444310616 | validation: 0.4281183531934446]
	TIME [epoch: 7.95 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4717090170417536		[learning rate: 0.0097077]
	Learning Rate: 0.00970768
	LOSS [training: 0.4717090170417536 | validation: 0.3976784039990935]
	TIME [epoch: 7.91 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v7_20240711_163535/states/model_facs_v2_dec1b_2dpca_v7_52.pth
	Model improved!!!
EPOCH 53/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.42845436146081883		[learning rate: 0.0096691]
	Learning Rate: 0.00966907
	LOSS [training: 0.42845436146081883 | validation: 0.4632022207771341]
	TIME [epoch: 7.94 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.466312812251763		[learning rate: 0.0096306]
	Learning Rate: 0.00963061
	LOSS [training: 0.466312812251763 | validation: 0.4759895479361469]
	TIME [epoch: 7.97 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.42376977516302244		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 0.42376977516302244 | validation: 0.49249635035346506]
	TIME [epoch: 7.91 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.46557126379634123		[learning rate: 0.0095542]
	Learning Rate: 0.00955415
	LOSS [training: 0.46557126379634123 | validation: 0.40068477686602133]
	TIME [epoch: 7.94 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.435975462021371		[learning rate: 0.0095162]
	Learning Rate: 0.00951616
	LOSS [training: 0.435975462021371 | validation: 0.38517647757971374]
	TIME [epoch: 7.95 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v7_20240711_163535/states/model_facs_v2_dec1b_2dpca_v7_57.pth
	Model improved!!!
EPOCH 58/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4413737149352474		[learning rate: 0.0094783]
	Learning Rate: 0.00947831
	LOSS [training: 0.4413737149352474 | validation: 0.40742970110624366]
	TIME [epoch: 7.95 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.45316523877003934		[learning rate: 0.0094406]
	Learning Rate: 0.00944061
	LOSS [training: 0.45316523877003934 | validation: 0.5167953290054002]
	TIME [epoch: 7.92 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4521903093893719		[learning rate: 0.0094031]
	Learning Rate: 0.00940306
	LOSS [training: 0.4521903093893719 | validation: 0.4928335512546571]
	TIME [epoch: 7.97 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.42625446693842384		[learning rate: 0.0093657]
	Learning Rate: 0.00936566
	LOSS [training: 0.42625446693842384 | validation: 0.43946052916251677]
	TIME [epoch: 7.97 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3949184822808376		[learning rate: 0.0093284]
	Learning Rate: 0.00932841
	LOSS [training: 0.3949184822808376 | validation: 0.3681901219070566]
	TIME [epoch: 7.99 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v7_20240711_163535/states/model_facs_v2_dec1b_2dpca_v7_62.pth
	Model improved!!!
EPOCH 63/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.42700816471344827		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 0.42700816471344827 | validation: 0.4013255667027235]
	TIME [epoch: 7.91 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3986554826998146		[learning rate: 0.0092544]
	Learning Rate: 0.00925435
	LOSS [training: 0.3986554826998146 | validation: 0.45469816274842556]
	TIME [epoch: 7.96 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4173860914847564		[learning rate: 0.0092175]
	Learning Rate: 0.00921755
	LOSS [training: 0.4173860914847564 | validation: 0.3920734353065357]
	TIME [epoch: 8 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.39329604800343454		[learning rate: 0.0091809]
	Learning Rate: 0.00918089
	LOSS [training: 0.39329604800343454 | validation: 0.4075259250547874]
	TIME [epoch: 7.94 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4062883732735039		[learning rate: 0.0091444]
	Learning Rate: 0.00914437
	LOSS [training: 0.4062883732735039 | validation: 0.39874071954560547]
	TIME [epoch: 7.93 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4155132863421326		[learning rate: 0.009108]
	Learning Rate: 0.009108
	LOSS [training: 0.4155132863421326 | validation: 0.38773966304675994]
	TIME [epoch: 7.95 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.42194665175040014		[learning rate: 0.0090718]
	Learning Rate: 0.00907178
	LOSS [training: 0.42194665175040014 | validation: 0.4709526819399007]
	TIME [epoch: 8 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4255873249839126		[learning rate: 0.0090357]
	Learning Rate: 0.00903569
	LOSS [training: 0.4255873249839126 | validation: 0.4034783890834685]
	TIME [epoch: 7.92 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4002993473488068		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 0.4002993473488068 | validation: 0.4169915094635838]
	TIME [epoch: 7.98 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4175916138543148		[learning rate: 0.008964]
	Learning Rate: 0.00896396
	LOSS [training: 0.4175916138543148 | validation: 0.3691205116471941]
	TIME [epoch: 7.96 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.38669027183813204		[learning rate: 0.0089283]
	Learning Rate: 0.00892831
	LOSS [training: 0.38669027183813204 | validation: 0.38333715649517447]
	TIME [epoch: 7.93 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.43856628476652204		[learning rate: 0.0088928]
	Learning Rate: 0.0088928
	LOSS [training: 0.43856628476652204 | validation: 0.3459273233558372]
	TIME [epoch: 7.89 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v7_20240711_163535/states/model_facs_v2_dec1b_2dpca_v7_74.pth
	Model improved!!!
EPOCH 75/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3978333291357648		[learning rate: 0.0088574]
	Learning Rate: 0.00885743
	LOSS [training: 0.3978333291357648 | validation: 0.377465467227939]
	TIME [epoch: 7.91 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.39906724460393284		[learning rate: 0.0088222]
	Learning Rate: 0.0088222
	LOSS [training: 0.39906724460393284 | validation: 0.3740718620052744]
	TIME [epoch: 7.95 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.396496293084286		[learning rate: 0.0087871]
	Learning Rate: 0.00878711
	LOSS [training: 0.396496293084286 | validation: 0.3833650924445142]
	TIME [epoch: 7.98 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3907925048008129		[learning rate: 0.0087522]
	Learning Rate: 0.00875216
	LOSS [training: 0.3907925048008129 | validation: 0.3662393684475077]
	TIME [epoch: 7.9 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3706463742509391		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 0.3706463742509391 | validation: 0.3891632899921153]
	TIME [epoch: 7.96 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4161789062496419		[learning rate: 0.0086827]
	Learning Rate: 0.00868268
	LOSS [training: 0.4161789062496419 | validation: 0.38859904124203964]
	TIME [epoch: 7.98 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.37953441092467144		[learning rate: 0.0086481]
	Learning Rate: 0.00864815
	LOSS [training: 0.37953441092467144 | validation: 0.46469121516170536]
	TIME [epoch: 7.93 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4169103450040843		[learning rate: 0.0086138]
	Learning Rate: 0.00861375
	LOSS [training: 0.4169103450040843 | validation: 0.45381584961550514]
	TIME [epoch: 7.93 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4205906727420341		[learning rate: 0.0085795]
	Learning Rate: 0.00857949
	LOSS [training: 0.4205906727420341 | validation: 0.4444954612333338]
	TIME [epoch: 7.96 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.37940900463760113		[learning rate: 0.0085454]
	Learning Rate: 0.00854537
	LOSS [training: 0.37940900463760113 | validation: 0.3886678653897345]
	TIME [epoch: 7.97 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3849336310432741		[learning rate: 0.0085114]
	Learning Rate: 0.00851138
	LOSS [training: 0.3849336310432741 | validation: 0.35139643971991114]
	TIME [epoch: 7.9 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3825838621326445		[learning rate: 0.0084775]
	Learning Rate: 0.00847753
	LOSS [training: 0.3825838621326445 | validation: 0.457978428795899]
	TIME [epoch: 7.95 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4371758833806932		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 0.4371758833806932 | validation: 0.5277749351040224]
	TIME [epoch: 7.94 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.46546394120624524		[learning rate: 0.0084102]
	Learning Rate: 0.00841023
	LOSS [training: 0.46546394120624524 | validation: 0.37525258301247627]
	TIME [epoch: 7.98 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3917713611582565		[learning rate: 0.0083768]
	Learning Rate: 0.00837678
	LOSS [training: 0.3917713611582565 | validation: 0.42255336971191937]
	TIME [epoch: 7.91 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4416008110034392		[learning rate: 0.0083435]
	Learning Rate: 0.00834346
	LOSS [training: 0.4416008110034392 | validation: 0.3774973509043948]
	TIME [epoch: 7.94 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3894353608498474		[learning rate: 0.0083103]
	Learning Rate: 0.00831027
	LOSS [training: 0.3894353608498474 | validation: 0.4466734567918043]
	TIME [epoch: 7.94 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3966417264783846		[learning rate: 0.0082772]
	Learning Rate: 0.00827722
	LOSS [training: 0.3966417264783846 | validation: 0.38263336813872567]
	TIME [epoch: 7.94 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.38396221244935824		[learning rate: 0.0082443]
	Learning Rate: 0.0082443
	LOSS [training: 0.38396221244935824 | validation: 0.38369721715380134]
	TIME [epoch: 7.88 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3675072813058563		[learning rate: 0.0082115]
	Learning Rate: 0.00821151
	LOSS [training: 0.3675072813058563 | validation: 0.37704953776180566]
	TIME [epoch: 7.97 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.37045312861010515		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 0.37045312861010515 | validation: 0.38166349232313923]
	TIME [epoch: 7.97 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.38269461414858896		[learning rate: 0.0081463]
	Learning Rate: 0.00814632
	LOSS [training: 0.38269461414858896 | validation: 0.37510585400302554]
	TIME [epoch: 7.96 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4030329498567047		[learning rate: 0.0081139]
	Learning Rate: 0.00811392
	LOSS [training: 0.4030329498567047 | validation: 0.4630200234855252]
	TIME [epoch: 7.91 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3856956763571296		[learning rate: 0.0080816]
	Learning Rate: 0.00808165
	LOSS [training: 0.3856956763571296 | validation: 0.3652365822317638]
	TIME [epoch: 7.94 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.38476025297516225		[learning rate: 0.0080495]
	Learning Rate: 0.00804951
	LOSS [training: 0.38476025297516225 | validation: 0.4911991628179533]
	TIME [epoch: 7.97 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4079736824389646		[learning rate: 0.0080175]
	Learning Rate: 0.00801749
	LOSS [training: 0.4079736824389646 | validation: 0.3567852936283885]
	TIME [epoch: 7.9 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.37231287296797305		[learning rate: 0.0079856]
	Learning Rate: 0.0079856
	LOSS [training: 0.37231287296797305 | validation: 0.3555571209042863]
	TIME [epoch: 7.95 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.35370317099842397		[learning rate: 0.0079538]
	Learning Rate: 0.00795384
	LOSS [training: 0.35370317099842397 | validation: 0.36029018353102005]
	TIME [epoch: 7.94 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.41517479700813337		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 0.41517479700813337 | validation: 0.42590265381094616]
	TIME [epoch: 7.96 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.37296190054636436		[learning rate: 0.0078907]
	Learning Rate: 0.0078907
	LOSS [training: 0.37296190054636436 | validation: 0.42114376342502524]
	TIME [epoch: 7.9 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.37163134358771255		[learning rate: 0.0078593]
	Learning Rate: 0.00785931
	LOSS [training: 0.37163134358771255 | validation: 0.3344470935862341]
	TIME [epoch: 7.97 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v7_20240711_163535/states/model_facs_v2_dec1b_2dpca_v7_105.pth
	Model improved!!!
EPOCH 106/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3823416194998725		[learning rate: 0.0078281]
	Learning Rate: 0.00782805
	LOSS [training: 0.3823416194998725 | validation: 0.36777352103984023]
	TIME [epoch: 7.96 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.38451656510758603		[learning rate: 0.0077969]
	Learning Rate: 0.00779692
	LOSS [training: 0.38451656510758603 | validation: 0.4263748613580917]
	TIME [epoch: 7.95 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.392651931536138		[learning rate: 0.0077659]
	Learning Rate: 0.00776591
	LOSS [training: 0.392651931536138 | validation: 0.40759200728176725]
	TIME [epoch: 7.87 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3755182156482715		[learning rate: 0.007735]
	Learning Rate: 0.00773502
	LOSS [training: 0.3755182156482715 | validation: 0.33984076589120876]
	TIME [epoch: 7.94 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.35662264960732515		[learning rate: 0.0077043]
	Learning Rate: 0.00770426
	LOSS [training: 0.35662264960732515 | validation: 0.38008206359233837]
	TIME [epoch: 7.93 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.36518148075062773		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 0.36518148075062773 | validation: 0.41998734528669723]
	TIME [epoch: 7.88 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4399092800009262		[learning rate: 0.0076431]
	Learning Rate: 0.00764309
	LOSS [training: 0.4399092800009262 | validation: 0.3821666568450304]
	TIME [epoch: 7.92 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3569272173809831		[learning rate: 0.0076127]
	Learning Rate: 0.00761269
	LOSS [training: 0.3569272173809831 | validation: 0.37707160736026063]
	TIME [epoch: 7.93 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3590801143586842		[learning rate: 0.0075824]
	Learning Rate: 0.00758242
	LOSS [training: 0.3590801143586842 | validation: 0.3698890498011437]
	TIME [epoch: 7.98 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.36926058414989027		[learning rate: 0.0075523]
	Learning Rate: 0.00755226
	LOSS [training: 0.36926058414989027 | validation: 0.37066494567366626]
	TIME [epoch: 7.92 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.406138113542078		[learning rate: 0.0075222]
	Learning Rate: 0.00752222
	LOSS [training: 0.406138113542078 | validation: 0.3596045874560182]
	TIME [epoch: 7.94 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3672047249121007		[learning rate: 0.0074923]
	Learning Rate: 0.0074923
	LOSS [training: 0.3672047249121007 | validation: 0.4044238580193572]
	TIME [epoch: 7.94 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.360364485251117		[learning rate: 0.0074625]
	Learning Rate: 0.0074625
	LOSS [training: 0.360364485251117 | validation: 0.35015479876292865]
	TIME [epoch: 7.99 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.33391722609053365		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 0.33391722609053365 | validation: 0.3535017717218663]
	TIME [epoch: 7.92 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3359347324052888		[learning rate: 0.0074033]
	Learning Rate: 0.00740326
	LOSS [training: 0.3359347324052888 | validation: 0.35384073639855895]
	TIME [epoch: 7.95 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.35149105376854667		[learning rate: 0.0073738]
	Learning Rate: 0.00737382
	LOSS [training: 0.35149105376854667 | validation: 0.3723112486964314]
	TIME [epoch: 7.93 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.37299389253096915		[learning rate: 0.0073445]
	Learning Rate: 0.00734449
	LOSS [training: 0.37299389253096915 | validation: 0.35087664014194814]
	TIME [epoch: 7.95 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.34369534752980513		[learning rate: 0.0073153]
	Learning Rate: 0.00731528
	LOSS [training: 0.34369534752980513 | validation: 0.39843457537606325]
	TIME [epoch: 7.91 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3642567953907624		[learning rate: 0.0072862]
	Learning Rate: 0.00728618
	LOSS [training: 0.3642567953907624 | validation: 0.3488914362891551]
	TIME [epoch: 7.98 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3516826912763043		[learning rate: 0.0072572]
	Learning Rate: 0.0072572
	LOSS [training: 0.3516826912763043 | validation: 0.3570904006519654]
	TIME [epoch: 7.99 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3548997896978776		[learning rate: 0.0072283]
	Learning Rate: 0.00722834
	LOSS [training: 0.3548997896978776 | validation: 0.3358148514806557]
	TIME [epoch: 7.94 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3394637252459487		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 0.3394637252459487 | validation: 0.341835253682209]
	TIME [epoch: 7.92 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.34357258830994164		[learning rate: 0.007171]
	Learning Rate: 0.00717095
	LOSS [training: 0.34357258830994164 | validation: 0.3486579274397064]
	TIME [epoch: 7.92 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.35225628005331927		[learning rate: 0.0071424]
	Learning Rate: 0.00714243
	LOSS [training: 0.35225628005331927 | validation: 0.33646102074959694]
	TIME [epoch: 7.99 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3478999145065764		[learning rate: 0.007114]
	Learning Rate: 0.00711403
	LOSS [training: 0.3478999145065764 | validation: 0.38130041525955016]
	TIME [epoch: 7.94 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3707596388804977		[learning rate: 0.0070857]
	Learning Rate: 0.00708573
	LOSS [training: 0.3707596388804977 | validation: 0.343598227945255]
	TIME [epoch: 7.93 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3495275655329315		[learning rate: 0.0070575]
	Learning Rate: 0.00705755
	LOSS [training: 0.3495275655329315 | validation: 0.36677952244090617]
	TIME [epoch: 7.93 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3495293652088661		[learning rate: 0.0070295]
	Learning Rate: 0.00702948
	LOSS [training: 0.3495293652088661 | validation: 0.34045364586272936]
	TIME [epoch: 7.98 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.339793664142537		[learning rate: 0.0070015]
	Learning Rate: 0.00700152
	LOSS [training: 0.339793664142537 | validation: 0.3611767191485025]
	TIME [epoch: 7.91 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.33147618556764413		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 0.33147618556764413 | validation: 0.3605756023153044]
	TIME [epoch: 7.95 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.36160374303807047		[learning rate: 0.0069459]
	Learning Rate: 0.00694594
	LOSS [training: 0.36160374303807047 | validation: 0.36293613552760445]
	TIME [epoch: 7.92 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3427566596789582		[learning rate: 0.0069183]
	Learning Rate: 0.00691831
	LOSS [training: 0.3427566596789582 | validation: 0.3687758588323242]
	TIME [epoch: 7.94 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3360343851611059		[learning rate: 0.0068908]
	Learning Rate: 0.00689079
	LOSS [training: 0.3360343851611059 | validation: 0.3388915719125409]
	TIME [epoch: 7.89 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3535673986601266		[learning rate: 0.0068634]
	Learning Rate: 0.00686339
	LOSS [training: 0.3535673986601266 | validation: 0.35068103136920137]
	TIME [epoch: 7.88 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3272588146062166		[learning rate: 0.0068361]
	Learning Rate: 0.00683609
	LOSS [training: 0.3272588146062166 | validation: 0.36033990777788716]
	TIME [epoch: 7.94 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.33925095717809506		[learning rate: 0.0068089]
	Learning Rate: 0.0068089
	LOSS [training: 0.33925095717809506 | validation: 0.32013941092263526]
	TIME [epoch: 7.96 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v7_20240711_163535/states/model_facs_v2_dec1b_2dpca_v7_141.pth
	Model improved!!!
EPOCH 142/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3411666985797233		[learning rate: 0.0067818]
	Learning Rate: 0.00678182
	LOSS [training: 0.3411666985797233 | validation: 0.39622533299535895]
	TIME [epoch: 7.89 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.33295064587977624		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 0.33295064587977624 | validation: 0.31433901246487367]
	TIME [epoch: 7.92 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v7_20240711_163535/states/model_facs_v2_dec1b_2dpca_v7_143.pth
	Model improved!!!
EPOCH 144/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.34633599073662213		[learning rate: 0.006728]
	Learning Rate: 0.00672798
	LOSS [training: 0.34633599073662213 | validation: 0.32927504125525614]
	TIME [epoch: 7.9 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.336482443367482		[learning rate: 0.0067012]
	Learning Rate: 0.00670122
	LOSS [training: 0.336482443367482 | validation: 0.3287816408159499]
	TIME [epoch: 7.93 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.34960271357574535		[learning rate: 0.0066746]
	Learning Rate: 0.00667457
	LOSS [training: 0.34960271357574535 | validation: 0.36480805567016683]
	TIME [epoch: 7.93 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3283329189642435		[learning rate: 0.006648]
	Learning Rate: 0.00664802
	LOSS [training: 0.3283329189642435 | validation: 0.3434350798868053]
	TIME [epoch: 7.94 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3480126766903211		[learning rate: 0.0066216]
	Learning Rate: 0.00662158
	LOSS [training: 0.3480126766903211 | validation: 0.38543557945215023]
	TIME [epoch: 7.92 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.35257813717835007		[learning rate: 0.0065952]
	Learning Rate: 0.00659524
	LOSS [training: 0.35257813717835007 | validation: 0.3680678534712658]
	TIME [epoch: 7.91 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.33909943332682435		[learning rate: 0.006569]
	Learning Rate: 0.00656901
	LOSS [training: 0.33909943332682435 | validation: 0.35336811427202186]
	TIME [epoch: 7.89 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3380039400550181		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 0.3380039400550181 | validation: 0.3257357662648547]
	TIME [epoch: 7.93 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3298731614436411		[learning rate: 0.0065169]
	Learning Rate: 0.00651686
	LOSS [training: 0.3298731614436411 | validation: 0.4197278123986569]
	TIME [epoch: 8 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.353179566983781		[learning rate: 0.0064909]
	Learning Rate: 0.00649094
	LOSS [training: 0.353179566983781 | validation: 0.41418935754964126]
	TIME [epoch: 7.9 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3432088193692376		[learning rate: 0.0064651]
	Learning Rate: 0.00646512
	LOSS [training: 0.3432088193692376 | validation: 0.3463210899046298]
	TIME [epoch: 7.9 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3230585352922785		[learning rate: 0.0064394]
	Learning Rate: 0.00643941
	LOSS [training: 0.3230585352922785 | validation: 0.3516090289500133]
	TIME [epoch: 7.95 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.34000807210159123		[learning rate: 0.0064138]
	Learning Rate: 0.0064138
	LOSS [training: 0.34000807210159123 | validation: 0.3344727067091149]
	TIME [epoch: 7.96 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.33979227756324487		[learning rate: 0.0063883]
	Learning Rate: 0.00638829
	LOSS [training: 0.33979227756324487 | validation: 0.3204248491178389]
	TIME [epoch: 7.87 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3352793448786933		[learning rate: 0.0063629]
	Learning Rate: 0.00636288
	LOSS [training: 0.3352793448786933 | validation: 0.46756326726659997]
	TIME [epoch: 7.89 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3413594713010718		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 0.3413594713010718 | validation: 0.3359723117720346]
	TIME [epoch: 7.99 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3243187547396972		[learning rate: 0.0063124]
	Learning Rate: 0.00631237
	LOSS [training: 0.3243187547396972 | validation: 0.32169089279333346]
	TIME [epoch: 7.89 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.321954392600685		[learning rate: 0.0062873]
	Learning Rate: 0.00628726
	LOSS [training: 0.321954392600685 | validation: 0.3767911936996987]
	TIME [epoch: 7.88 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3477493460290066		[learning rate: 0.0062623]
	Learning Rate: 0.00626226
	LOSS [training: 0.3477493460290066 | validation: 0.36114511889825907]
	TIME [epoch: 7.88 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3432954422933827		[learning rate: 0.0062373]
	Learning Rate: 0.00623735
	LOSS [training: 0.3432954422933827 | validation: 0.32559410840947284]
	TIME [epoch: 7.98 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3281079009243884		[learning rate: 0.0062125]
	Learning Rate: 0.00621254
	LOSS [training: 0.3281079009243884 | validation: 0.3245990368691729]
	TIME [epoch: 7.9 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3266590689225257		[learning rate: 0.0061878]
	Learning Rate: 0.00618783
	LOSS [training: 0.3266590689225257 | validation: 0.32268700726948557]
	TIME [epoch: 7.91 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.37152894084640153		[learning rate: 0.0061632]
	Learning Rate: 0.00616322
	LOSS [training: 0.37152894084640153 | validation: 0.3437256670851204]
	TIME [epoch: 7.91 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3290151479356271		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 0.3290151479356271 | validation: 0.3435804519340043]
	TIME [epoch: 7.93 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3223463465662846		[learning rate: 0.0061143]
	Learning Rate: 0.00611429
	LOSS [training: 0.3223463465662846 | validation: 0.3588996437677885]
	TIME [epoch: 7.9 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3333523144330442		[learning rate: 0.00609]
	Learning Rate: 0.00608997
	LOSS [training: 0.3333523144330442 | validation: 0.32234965685456557]
	TIME [epoch: 7.88 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3247815362932742		[learning rate: 0.0060658]
	Learning Rate: 0.00606575
	LOSS [training: 0.3247815362932742 | validation: 0.31723691525548836]
	TIME [epoch: 7.95 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3940422073818066		[learning rate: 0.0060416]
	Learning Rate: 0.00604163
	LOSS [training: 0.3940422073818066 | validation: 0.3836883322839063]
	TIME [epoch: 7.96 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4246093983124207		[learning rate: 0.0060176]
	Learning Rate: 0.0060176
	LOSS [training: 0.4246093983124207 | validation: 0.3474832110895192]
	TIME [epoch: 7.9 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4136409149696036		[learning rate: 0.0059937]
	Learning Rate: 0.00599366
	LOSS [training: 0.4136409149696036 | validation: 0.33811584119231985]
	TIME [epoch: 7.88 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.39851624066066776		[learning rate: 0.0059698]
	Learning Rate: 0.00596982
	LOSS [training: 0.39851624066066776 | validation: 0.36595638163128724]
	TIME [epoch: 7.95 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.42204574983982546		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 0.42204574983982546 | validation: 0.35176059135168086]
	TIME [epoch: 7.96 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.37699955705662985		[learning rate: 0.0059224]
	Learning Rate: 0.00592243
	LOSS [training: 0.37699955705662985 | validation: 0.3430091358810008]
	TIME [epoch: 7.92 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3467630991217724		[learning rate: 0.0058989]
	Learning Rate: 0.00589888
	LOSS [training: 0.3467630991217724 | validation: 0.3416691646934344]
	TIME [epoch: 7.88 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4478030154073719		[learning rate: 0.0058754]
	Learning Rate: 0.00587541
	LOSS [training: 0.4478030154073719 | validation: 0.4153388457803239]
	TIME [epoch: 7.97 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4978528141697454		[learning rate: 0.005852]
	Learning Rate: 0.00585205
	LOSS [training: 0.4978528141697454 | validation: 0.387954318837055]
	TIME [epoch: 7.93 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4816713742439151		[learning rate: 0.0058288]
	Learning Rate: 0.00582877
	LOSS [training: 0.4816713742439151 | validation: 0.3755987572115596]
	TIME [epoch: 7.88 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.41524839121521295		[learning rate: 0.0058056]
	Learning Rate: 0.00580559
	LOSS [training: 0.41524839121521295 | validation: 0.32887179166591285]
	TIME [epoch: 7.88 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3354629703421142		[learning rate: 0.0057825]
	Learning Rate: 0.0057825
	LOSS [training: 0.3354629703421142 | validation: 0.327425196953813]
	TIME [epoch: 8 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3709116924497		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 0.3709116924497 | validation: 0.34525210427791764]
	TIME [epoch: 7.91 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.35427341466473794		[learning rate: 0.0057366]
	Learning Rate: 0.00573659
	LOSS [training: 0.35427341466473794 | validation: 0.3524776727563891]
	TIME [epoch: 7.88 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3801783396475629		[learning rate: 0.0057138]
	Learning Rate: 0.00571377
	LOSS [training: 0.3801783396475629 | validation: 0.3321203158892254]
	TIME [epoch: 7.91 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3735937220148895		[learning rate: 0.005691]
	Learning Rate: 0.00569105
	LOSS [training: 0.3735937220148895 | validation: 0.3452209878018643]
	TIME [epoch: 8 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3612921996571883		[learning rate: 0.0056684]
	Learning Rate: 0.00566841
	LOSS [training: 0.3612921996571883 | validation: 0.33774394297184795]
	TIME [epoch: 7.92 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.36173724579875643		[learning rate: 0.0056459]
	Learning Rate: 0.00564587
	LOSS [training: 0.36173724579875643 | validation: 0.3460217555307409]
	TIME [epoch: 7.89 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3978291140317485		[learning rate: 0.0056234]
	Learning Rate: 0.00562341
	LOSS [training: 0.3978291140317485 | validation: 0.3619976131872964]
	TIME [epoch: 7.93 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4097848762611951		[learning rate: 0.005601]
	Learning Rate: 0.00560105
	LOSS [training: 0.4097848762611951 | validation: 0.3528273479129956]
	TIME [epoch: 7.97 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3796784923353499		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 0.3796784923353499 | validation: 0.356696852990351]
	TIME [epoch: 7.87 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.39094865246929633		[learning rate: 0.0055566]
	Learning Rate: 0.00555658
	LOSS [training: 0.39094865246929633 | validation: 0.42325963206712336]
	TIME [epoch: 7.88 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6046462309627518		[learning rate: 0.0055345]
	Learning Rate: 0.00553448
	LOSS [training: 0.6046462309627518 | validation: 0.4456214970658303]
	TIME [epoch: 7.95 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.44738913872176866		[learning rate: 0.0055125]
	Learning Rate: 0.00551247
	LOSS [training: 0.44738913872176866 | validation: 0.3965283986195848]
	TIME [epoch: 7.95 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4243317288647802		[learning rate: 0.0054905]
	Learning Rate: 0.00549054
	LOSS [training: 0.4243317288647802 | validation: 0.41005234660597356]
	TIME [epoch: 7.88 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.39431377042229443		[learning rate: 0.0054687]
	Learning Rate: 0.00546871
	LOSS [training: 0.39431377042229443 | validation: 0.3674849086385189]
	TIME [epoch: 7.87 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.39412350521344686		[learning rate: 0.005447]
	Learning Rate: 0.00544696
	LOSS [training: 0.39412350521344686 | validation: 0.39140500336495415]
	TIME [epoch: 7.97 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.8620890507079328		[learning rate: 0.0054253]
	Learning Rate: 0.00542529
	LOSS [training: 0.8620890507079328 | validation: 0.6081219814049819]
	TIME [epoch: 7.96 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.8721599430179747		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 0.8721599430179747 | validation: 0.5513276430555274]
	TIME [epoch: 7.89 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.73896364310947		[learning rate: 0.0053822]
	Learning Rate: 0.00538222
	LOSS [training: 0.73896364310947 | validation: 0.47836869737312365]
	TIME [epoch: 7.88 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7469727036172448		[learning rate: 0.0053608]
	Learning Rate: 0.00536081
	LOSS [training: 0.7469727036172448 | validation: 0.7348373278927994]
	TIME [epoch: 8.04 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5919795166683658		[learning rate: 0.0053395]
	Learning Rate: 0.00533949
	LOSS [training: 0.5919795166683658 | validation: 0.46899234868309786]
	TIME [epoch: 8.03 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5296168066548159		[learning rate: 0.0053183]
	Learning Rate: 0.00531826
	LOSS [training: 0.5296168066548159 | validation: 0.6181399497906865]
	TIME [epoch: 7.94 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6608915306341456		[learning rate: 0.0052971]
	Learning Rate: 0.0052971
	LOSS [training: 0.6608915306341456 | validation: 0.5485864589679641]
	TIME [epoch: 7.96 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5894500101969786		[learning rate: 0.005276]
	Learning Rate: 0.00527604
	LOSS [training: 0.5894500101969786 | validation: 0.661044332981052]
	TIME [epoch: 7.97 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5901333726854233		[learning rate: 0.0052551]
	Learning Rate: 0.00525505
	LOSS [training: 0.5901333726854233 | validation: 0.4468552477064042]
	TIME [epoch: 7.94 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4728286883072812		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 0.4728286883072812 | validation: 0.412580920000304]
	TIME [epoch: 7.9 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4590208437514105		[learning rate: 0.0052133]
	Learning Rate: 0.00521333
	LOSS [training: 0.4590208437514105 | validation: 0.430846481945249]
	TIME [epoch: 7.98 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5436594153615167		[learning rate: 0.0051926]
	Learning Rate: 0.0051926
	LOSS [training: 0.5436594153615167 | validation: 0.4792603669533686]
	TIME [epoch: 7.98 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5607901933216033		[learning rate: 0.0051719]
	Learning Rate: 0.00517194
	LOSS [training: 0.5607901933216033 | validation: 0.47881897281522673]
	TIME [epoch: 8 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5230270447534848		[learning rate: 0.0051514]
	Learning Rate: 0.00515137
	LOSS [training: 0.5230270447534848 | validation: 0.4378756531967153]
	TIME [epoch: 7.9 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5077306056810624		[learning rate: 0.0051309]
	Learning Rate: 0.00513089
	LOSS [training: 0.5077306056810624 | validation: 0.4434478381059007]
	TIME [epoch: 8.01 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.8119515993699097		[learning rate: 0.0051105]
	Learning Rate: 0.00511048
	LOSS [training: 0.8119515993699097 | validation: 0.6744765988385425]
	TIME [epoch: 8.01 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7657915557449779		[learning rate: 0.0050902]
	Learning Rate: 0.00509015
	LOSS [training: 0.7657915557449779 | validation: 0.6143920814774972]
	TIME [epoch: 7.98 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7149231968868175		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 0.7149231968868175 | validation: 0.5861356701856051]
	TIME [epoch: 7.91 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6253340396596614		[learning rate: 0.0050497]
	Learning Rate: 0.00504974
	LOSS [training: 0.6253340396596614 | validation: 0.5514747967465194]
	TIME [epoch: 8.02 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5910960071304513		[learning rate: 0.0050297]
	Learning Rate: 0.00502966
	LOSS [training: 0.5910960071304513 | validation: 0.5437815623256735]
	TIME [epoch: 8 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5761134020067286		[learning rate: 0.0050097]
	Learning Rate: 0.00500965
	LOSS [training: 0.5761134020067286 | validation: 0.5103301364222173]
	TIME [epoch: 7.89 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5431650106220243		[learning rate: 0.0049897]
	Learning Rate: 0.00498973
	LOSS [training: 0.5431650106220243 | validation: 0.47829711515895823]
	TIME [epoch: 7.93 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5502639375740638		[learning rate: 0.0049699]
	Learning Rate: 0.00496988
	LOSS [training: 0.5502639375740638 | validation: 0.5639671881291157]
	TIME [epoch: 7.94 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6291970472239584		[learning rate: 0.0049501]
	Learning Rate: 0.00495012
	LOSS [training: 0.6291970472239584 | validation: 0.5851834248960214]
	TIME [epoch: 8.01 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6153140285898265		[learning rate: 0.0049304]
	Learning Rate: 0.00493043
	LOSS [training: 0.6153140285898265 | validation: 0.5336291039364149]
	TIME [epoch: 7.93 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5739706638461196		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 0.5739706638461196 | validation: 0.5118594502540239]
	TIME [epoch: 7.94 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5491612213941254		[learning rate: 0.0048913]
	Learning Rate: 0.00489129
	LOSS [training: 0.5491612213941254 | validation: 0.46900922012917823]
	TIME [epoch: 7.93 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5147560077165002		[learning rate: 0.0048718]
	Learning Rate: 0.00487183
	LOSS [training: 0.5147560077165002 | validation: 0.45796226004490165]
	TIME [epoch: 8 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4842824008872449		[learning rate: 0.0048525]
	Learning Rate: 0.00485245
	LOSS [training: 0.4842824008872449 | validation: 0.4613867467817682]
	TIME [epoch: 7.89 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.477544859762985		[learning rate: 0.0048332]
	Learning Rate: 0.00483316
	LOSS [training: 0.477544859762985 | validation: 0.40444468964299995]
	TIME [epoch: 7.97 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.457538535531948		[learning rate: 0.0048139]
	Learning Rate: 0.00481393
	LOSS [training: 0.457538535531948 | validation: 0.41671986606736855]
	TIME [epoch: 7.97 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4466962817582368		[learning rate: 0.0047948]
	Learning Rate: 0.00479479
	LOSS [training: 0.4466962817582368 | validation: 0.46387962294660146]
	TIME [epoch: 7.94 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6244287018539256		[learning rate: 0.0047757]
	Learning Rate: 0.00477572
	LOSS [training: 0.6244287018539256 | validation: 1.1187611548232161]
	TIME [epoch: 7.89 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.7958784342013194		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 1.7958784342013194 | validation: 1.3351059780065184]
	TIME [epoch: 8.01 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.5564379587304844		[learning rate: 0.0047378]
	Learning Rate: 0.0047378
	LOSS [training: 1.5564379587304844 | validation: 1.0625534963886003]
	TIME [epoch: 7.98 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.6762424087591994		[learning rate: 0.004719]
	Learning Rate: 0.00471896
	LOSS [training: 1.6762424087591994 | validation: 1.6819598954532722]
	TIME [epoch: 7.91 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 9/9] avg loss: 2.069438011404145		[learning rate: 0.0047002]
	Learning Rate: 0.00470019
	LOSS [training: 2.069438011404145 | validation: 1.5947520521591798]
	TIME [epoch: 7.95 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.9643271062485281		[learning rate: 0.0046815]
	Learning Rate: 0.0046815
	LOSS [training: 1.9643271062485281 | validation: 1.5328013575709414]
	TIME [epoch: 7.95 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.9084482790322777		[learning rate: 0.0046629]
	Learning Rate: 0.00466288
	LOSS [training: 1.9084482790322777 | validation: 1.1025607349992552]
	TIME [epoch: 8.02 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 9/9] avg loss: 2.179134291347578		[learning rate: 0.0046443]
	Learning Rate: 0.00464433
	LOSS [training: 2.179134291347578 | validation: 1.5516617887799504]
	TIME [epoch: 7.94 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.793375051364137		[learning rate: 0.0046259]
	Learning Rate: 0.00462586
	LOSS [training: 1.793375051364137 | validation: 1.1851352359557779]
	TIME [epoch: 7.96 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.4962254136147113		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 1.4962254136147113 | validation: 1.7212341387402144]
	TIME [epoch: 8 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.3837794947173778		[learning rate: 0.0045891]
	Learning Rate: 0.00458913
	LOSS [training: 1.3837794947173778 | validation: 1.1009610238751903]
	TIME [epoch: 8.01 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.2335235953588588		[learning rate: 0.0045709]
	Learning Rate: 0.00457088
	LOSS [training: 1.2335235953588588 | validation: 1.2431101937650886]
	TIME [epoch: 7.9 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.3553659841055725		[learning rate: 0.0045527]
	Learning Rate: 0.0045527
	LOSS [training: 1.3553659841055725 | validation: 0.9658606469314573]
	TIME [epoch: 7.97 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.7744426997410065		[learning rate: 0.0045346]
	Learning Rate: 0.00453459
	LOSS [training: 1.7744426997410065 | validation: 1.9148653348464866]
	TIME [epoch: 7.95 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.9042397843223542		[learning rate: 0.0045166]
	Learning Rate: 0.00451656
	LOSS [training: 1.9042397843223542 | validation: 2.054516534191933]
	TIME [epoch: 7.9 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 9/9] avg loss: 2.597846566898259		[learning rate: 0.0044986]
	Learning Rate: 0.0044986
	LOSS [training: 2.597846566898259 | validation: 2.5490552182159307]
	TIME [epoch: 7.9 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 9/9] avg loss: 2.8065966040703993		[learning rate: 0.0044807]
	Learning Rate: 0.0044807
	LOSS [training: 2.8065966040703993 | validation: 2.4942009063756045]
	TIME [epoch: 7.96 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 9/9] avg loss: 2.4262083489057553		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 2.4262083489057553 | validation: 1.8252130540372935]
	TIME [epoch: 7.98 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.9586940092152514		[learning rate: 0.0044451]
	Learning Rate: 0.00444513
	LOSS [training: 1.9586940092152514 | validation: 1.521163104634551]
	TIME [epoch: 7.95 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.584902624789194		[learning rate: 0.0044275]
	Learning Rate: 0.00442745
	LOSS [training: 1.584902624789194 | validation: 1.3163319853763766]
	TIME [epoch: 7.92 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.3171013092566337		[learning rate: 0.0044098]
	Learning Rate: 0.00440984
	LOSS [training: 1.3171013092566337 | validation: 1.1321692587206158]
	TIME [epoch: 7.95 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.193803368255123		[learning rate: 0.0043923]
	Learning Rate: 0.0043923
	LOSS [training: 1.193803368255123 | validation: 0.9936768301861001]
	TIME [epoch: 7.95 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.1180938791686628		[learning rate: 0.0043748]
	Learning Rate: 0.00437483
	LOSS [training: 1.1180938791686628 | validation: 0.900747861843832]
	TIME [epoch: 7.91 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.0456406765861628		[learning rate: 0.0043574]
	Learning Rate: 0.00435743
	LOSS [training: 1.0456406765861628 | validation: 0.8529105679718484]
	TIME [epoch: 7.93 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.0192370918702376		[learning rate: 0.0043401]
	Learning Rate: 0.0043401
	LOSS [training: 1.0192370918702376 | validation: 0.90301707818652]
	TIME [epoch: 7.96 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.0843474985916284		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 1.0843474985916284 | validation: 1.0081206247781362]
	TIME [epoch: 7.92 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.087590485991647		[learning rate: 0.0043056]
	Learning Rate: 0.00430565
	LOSS [training: 1.087590485991647 | validation: 0.8677538582647164]
	TIME [epoch: 7.9 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.0135951603917581		[learning rate: 0.0042885]
	Learning Rate: 0.00428852
	LOSS [training: 1.0135951603917581 | validation: 0.8162821319069696]
	TIME [epoch: 7.96 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.3477375179438986		[learning rate: 0.0042715]
	Learning Rate: 0.00427147
	LOSS [training: 1.3477375179438986 | validation: 0.9603581426644758]
	TIME [epoch: 7.94 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.3319133223190822		[learning rate: 0.0042545]
	Learning Rate: 0.00425448
	LOSS [training: 1.3319133223190822 | validation: 0.9280227243375319]
	TIME [epoch: 7.91 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.2445694498832771		[learning rate: 0.0042376]
	Learning Rate: 0.00423756
	LOSS [training: 1.2445694498832771 | validation: 0.9228377421115406]
	TIME [epoch: 7.88 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.121834551246178		[learning rate: 0.0042207]
	Learning Rate: 0.0042207
	LOSS [training: 1.121834551246178 | validation: 0.6900397955271338]
	TIME [epoch: 7.92 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.9791890548876676		[learning rate: 0.0042039]
	Learning Rate: 0.00420391
	LOSS [training: 0.9791890548876676 | validation: 0.7709040372431165]
	TIME [epoch: 7.96 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.0724829965959555		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 1.0724829965959555 | validation: 0.7627645923723018]
	TIME [epoch: 7.89 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.8844568763618351		[learning rate: 0.0041705]
	Learning Rate: 0.00417054
	LOSS [training: 0.8844568763618351 | validation: 0.6318134868609666]
	TIME [epoch: 7.88 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.8493762534227477		[learning rate: 0.004154]
	Learning Rate: 0.00415395
	LOSS [training: 0.8493762534227477 | validation: 0.7098295563264175]
	TIME [epoch: 7.95 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.8508055783835258		[learning rate: 0.0041374]
	Learning Rate: 0.00413743
	LOSS [training: 0.8508055783835258 | validation: 0.6319663827166422]
	TIME [epoch: 7.92 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.9595053776571467		[learning rate: 0.004121]
	Learning Rate: 0.00412098
	LOSS [training: 0.9595053776571467 | validation: 1.0051626319577394]
	TIME [epoch: 7.89 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.291027754619338		[learning rate: 0.0041046]
	Learning Rate: 0.00410458
	LOSS [training: 1.291027754619338 | validation: 1.2834177422050812]
	TIME [epoch: 7.94 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.4041756998230588		[learning rate: 0.0040883]
	Learning Rate: 0.00408826
	LOSS [training: 1.4041756998230588 | validation: 1.4352453972030648]
	TIME [epoch: 7.93 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.3193588155982419		[learning rate: 0.004072]
	Learning Rate: 0.004072
	LOSS [training: 1.3193588155982419 | validation: 0.8691577879712306]
	TIME [epoch: 7.93 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.9154133753821108		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.9154133753821108 | validation: 0.6830885863522556]
	TIME [epoch: 7.89 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7784358224484993		[learning rate: 0.0040397]
	Learning Rate: 0.00403967
	LOSS [training: 0.7784358224484993 | validation: 0.646809738313453]
	TIME [epoch: 7.9 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7552183363610199		[learning rate: 0.0040236]
	Learning Rate: 0.00402361
	LOSS [training: 0.7552183363610199 | validation: 0.6144034379090846]
	TIME [epoch: 7.92 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.78355917054885		[learning rate: 0.0040076]
	Learning Rate: 0.0040076
	LOSS [training: 0.78355917054885 | validation: 0.6018784867859754]
	TIME [epoch: 7.92 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7064910904794431		[learning rate: 0.0039917]
	Learning Rate: 0.00399166
	LOSS [training: 0.7064910904794431 | validation: 0.575481480770589]
	TIME [epoch: 7.89 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7679805889000014		[learning rate: 0.0039758]
	Learning Rate: 0.00397579
	LOSS [training: 0.7679805889000014 | validation: 0.7241698352591663]
	TIME [epoch: 7.99 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7773401325385639		[learning rate: 0.00396]
	Learning Rate: 0.00395997
	LOSS [training: 0.7773401325385639 | validation: 0.586833933686511]
	TIME [epoch: 7.94 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7212446753322916		[learning rate: 0.0039442]
	Learning Rate: 0.00394422
	LOSS [training: 0.7212446753322916 | validation: 0.5750705047924258]
	TIME [epoch: 7.9 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6811570847034183		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 0.6811570847034183 | validation: 0.606909757317486]
	TIME [epoch: 7.89 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6862736790388123		[learning rate: 0.0039129]
	Learning Rate: 0.00391291
	LOSS [training: 0.6862736790388123 | validation: 0.5154593241855382]
	TIME [epoch: 7.95 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6529606116638681		[learning rate: 0.0038973]
	Learning Rate: 0.00389735
	LOSS [training: 0.6529606116638681 | validation: 0.49873971343765405]
	TIME [epoch: 7.93 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.619342304875182		[learning rate: 0.0038818]
	Learning Rate: 0.00388185
	LOSS [training: 0.619342304875182 | validation: 0.5228165741451701]
	TIME [epoch: 7.89 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6266829303971174		[learning rate: 0.0038664]
	Learning Rate: 0.00386641
	LOSS [training: 0.6266829303971174 | validation: 0.5397719953382003]
	TIME [epoch: 7.89 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7433507715474482		[learning rate: 0.003851]
	Learning Rate: 0.00385103
	LOSS [training: 0.7433507715474482 | validation: 0.5892333277714681]
	TIME [epoch: 7.92 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7260858218374322		[learning rate: 0.0038357]
	Learning Rate: 0.00383571
	LOSS [training: 0.7260858218374322 | validation: 0.5550539993493019]
	TIME [epoch: 7.95 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6708101576327008		[learning rate: 0.0038205]
	Learning Rate: 0.00382046
	LOSS [training: 0.6708101576327008 | validation: 0.5039425640773668]
	TIME [epoch: 7.89 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6613418465193338		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 0.6613418465193338 | validation: 0.6346156348789784]
	TIME [epoch: 7.92 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7451544701372487		[learning rate: 0.0037901]
	Learning Rate: 0.00379013
	LOSS [training: 0.7451544701372487 | validation: 0.5176476853955275]
	TIME [epoch: 7.92 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6062786098994093		[learning rate: 0.0037751]
	Learning Rate: 0.00377505
	LOSS [training: 0.6062786098994093 | validation: 0.45998182309397206]
	TIME [epoch: 7.92 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5849678971542159		[learning rate: 0.00376]
	Learning Rate: 0.00376004
	LOSS [training: 0.5849678971542159 | validation: 0.4484298986266378]
	TIME [epoch: 7.89 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6481077460374953		[learning rate: 0.0037451]
	Learning Rate: 0.00374508
	LOSS [training: 0.6481077460374953 | validation: 0.546132957540343]
	TIME [epoch: 7.95 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6240052781470345		[learning rate: 0.0037302]
	Learning Rate: 0.00373019
	LOSS [training: 0.6240052781470345 | validation: 0.466369012743667]
	TIME [epoch: 7.94 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5365710134947818		[learning rate: 0.0037154]
	Learning Rate: 0.00371535
	LOSS [training: 0.5365710134947818 | validation: 0.4486670084315348]
	TIME [epoch: 7.91 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5195676151858774		[learning rate: 0.0037006]
	Learning Rate: 0.00370058
	LOSS [training: 0.5195676151858774 | validation: 0.43039880209624737]
	TIME [epoch: 7.89 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.930627941385478		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 0.930627941385478 | validation: 1.2095069115445054]
	TIME [epoch: 7.95 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.3808030377806473		[learning rate: 0.0036712]
	Learning Rate: 0.0036712
	LOSS [training: 1.3808030377806473 | validation: 1.2788433797612462]
	TIME [epoch: 7.95 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.1723648392511938		[learning rate: 0.0036566]
	Learning Rate: 0.0036566
	LOSS [training: 1.1723648392511938 | validation: 0.7861266413822331]
	TIME [epoch: 7.91 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.8732642977485692		[learning rate: 0.0036421]
	Learning Rate: 0.00364205
	LOSS [training: 0.8732642977485692 | validation: 0.6507651557243888]
	TIME [epoch: 7.88 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7631470053608609		[learning rate: 0.0036276]
	Learning Rate: 0.00362757
	LOSS [training: 0.7631470053608609 | validation: 0.5733524254827664]
	TIME [epoch: 7.95 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7014928238901992		[learning rate: 0.0036131]
	Learning Rate: 0.00361314
	LOSS [training: 0.7014928238901992 | validation: 0.5579873106816291]
	TIME [epoch: 7.94 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6696543767665281		[learning rate: 0.0035988]
	Learning Rate: 0.00359877
	LOSS [training: 0.6696543767665281 | validation: 0.5268036268314247]
	TIME [epoch: 7.89 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6902444390412562		[learning rate: 0.0035845]
	Learning Rate: 0.00358445
	LOSS [training: 0.6902444390412562 | validation: 0.8103575616334222]
	TIME [epoch: 7.92 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6674097093231612		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 0.6674097093231612 | validation: 0.4820211529568789]
	TIME [epoch: 7.92 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6069839274040807		[learning rate: 0.003556]
	Learning Rate: 0.003556
	LOSS [training: 0.6069839274040807 | validation: 0.4891753229074748]
	TIME [epoch: 7.93 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5886244639473482		[learning rate: 0.0035419]
	Learning Rate: 0.00354185
	LOSS [training: 0.5886244639473482 | validation: 0.5105685533085089]
	TIME [epoch: 7.89 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5398629679206416		[learning rate: 0.0035278]
	Learning Rate: 0.00352777
	LOSS [training: 0.5398629679206416 | validation: 0.48808487994714034]
	TIME [epoch: 7.98 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5394305991547094		[learning rate: 0.0035137]
	Learning Rate: 0.00351374
	LOSS [training: 0.5394305991547094 | validation: 0.4371749071036334]
	TIME [epoch: 7.95 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.47707209821379365		[learning rate: 0.0034998]
	Learning Rate: 0.00349976
	LOSS [training: 0.47707209821379365 | validation: 0.44866030154836745]
	TIME [epoch: 7.92 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4567811647181092		[learning rate: 0.0034858]
	Learning Rate: 0.00348584
	LOSS [training: 0.4567811647181092 | validation: 0.4227271779290559]
	TIME [epoch: 7.89 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4581089019818651		[learning rate: 0.003472]
	Learning Rate: 0.00347198
	LOSS [training: 0.4581089019818651 | validation: 0.4794180975006749]
	TIME [epoch: 7.95 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4786887943244927		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.4786887943244927 | validation: 0.452079846807249]
	TIME [epoch: 7.98 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.43933676009428935		[learning rate: 0.0034444]
	Learning Rate: 0.00344441
	LOSS [training: 0.43933676009428935 | validation: 0.4613584564580771]
	TIME [epoch: 7.9 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.424055362033783		[learning rate: 0.0034307]
	Learning Rate: 0.00343071
	LOSS [training: 0.424055362033783 | validation: 0.39971051428587556]
	TIME [epoch: 7.88 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.41474054509891967		[learning rate: 0.0034171]
	Learning Rate: 0.00341707
	LOSS [training: 0.41474054509891967 | validation: 0.4096991490867425]
	TIME [epoch: 7.96 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4109687737007034		[learning rate: 0.0034035]
	Learning Rate: 0.00340348
	LOSS [training: 0.4109687737007034 | validation: 0.4004070703558208]
	TIME [epoch: 7.94 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4081894791728301		[learning rate: 0.0033899]
	Learning Rate: 0.00338994
	LOSS [training: 0.4081894791728301 | validation: 0.4015379292538494]
	TIME [epoch: 7.89 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.41223865041291624		[learning rate: 0.0033765]
	Learning Rate: 0.00337646
	LOSS [training: 0.41223865041291624 | validation: 0.38820816960112053]
	TIME [epoch: 7.9 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4070812918482016		[learning rate: 0.003363]
	Learning Rate: 0.00336303
	LOSS [training: 0.4070812918482016 | validation: 0.4059751517814081]
	TIME [epoch: 7.93 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4030212452043744		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 0.4030212452043744 | validation: 0.3674892436096262]
	TIME [epoch: 7.93 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4041495084538766		[learning rate: 0.0033363]
	Learning Rate: 0.00333633
	LOSS [training: 0.4041495084538766 | validation: 0.38734813365634446]
	TIME [epoch: 7.9 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.39389740116879907		[learning rate: 0.0033231]
	Learning Rate: 0.00332306
	LOSS [training: 0.39389740116879907 | validation: 0.4650140201203795]
	TIME [epoch: 7.92 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4170466856598774		[learning rate: 0.0033098]
	Learning Rate: 0.00330985
	LOSS [training: 0.4170466856598774 | validation: 0.3805920724484252]
	TIME [epoch: 7.93 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.390703353794983		[learning rate: 0.0032967]
	Learning Rate: 0.00329668
	LOSS [training: 0.390703353794983 | validation: 0.38297588485630346]
	TIME [epoch: 7.93 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3881057038299045		[learning rate: 0.0032836]
	Learning Rate: 0.00328357
	LOSS [training: 0.3881057038299045 | validation: 0.3828337950725628]
	TIME [epoch: 7.9 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.39563585212780666		[learning rate: 0.0032705]
	Learning Rate: 0.00327051
	LOSS [training: 0.39563585212780666 | validation: 0.3786668907598524]
	TIME [epoch: 7.95 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4128558024802029		[learning rate: 0.0032575]
	Learning Rate: 0.0032575
	LOSS [training: 0.4128558024802029 | validation: 0.45161823674464097]
	TIME [epoch: 7.94 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.38300081789389356		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 0.38300081789389356 | validation: 0.359676871411141]
	TIME [epoch: 7.9 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.36997525294396705		[learning rate: 0.0032316]
	Learning Rate: 0.00323164
	LOSS [training: 0.36997525294396705 | validation: 0.3531172058578319]
	TIME [epoch: 7.88 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.357224219878604		[learning rate: 0.0032188]
	Learning Rate: 0.00321879
	LOSS [training: 0.357224219878604 | validation: 0.3525837329763865]
	TIME [epoch: 7.96 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.35569655500404274		[learning rate: 0.003206]
	Learning Rate: 0.00320599
	LOSS [training: 0.35569655500404274 | validation: 0.35422698012125886]
	TIME [epoch: 7.94 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3655815049618594		[learning rate: 0.0031932]
	Learning Rate: 0.00319323
	LOSS [training: 0.3655815049618594 | validation: 0.36502193380589254]
	TIME [epoch: 7.9 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3802145635791392		[learning rate: 0.0031805]
	Learning Rate: 0.00318053
	LOSS [training: 0.3802145635791392 | validation: 0.3421920813884326]
	TIME [epoch: 7.88 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3536462473616013		[learning rate: 0.0031679]
	Learning Rate: 0.00316788
	LOSS [training: 0.3536462473616013 | validation: 0.34916840665520016]
	TIME [epoch: 7.95 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3569539297790172		[learning rate: 0.0031553]
	Learning Rate: 0.00315528
	LOSS [training: 0.3569539297790172 | validation: 0.510233133706009]
	TIME [epoch: 7.93 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5519030349086166		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 0.5519030349086166 | validation: 0.46278947038500784]
	TIME [epoch: 7.89 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5938972872943952		[learning rate: 0.0031302]
	Learning Rate: 0.00313023
	LOSS [training: 0.5938972872943952 | validation: 0.5366453779001608]
	TIME [epoch: 7.91 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7425910261352429		[learning rate: 0.0031178]
	Learning Rate: 0.00311779
	LOSS [training: 0.7425910261352429 | validation: 0.5298621567174086]
	TIME [epoch: 7.95 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.66369467407		[learning rate: 0.0031054]
	Learning Rate: 0.00310538
	LOSS [training: 0.66369467407 | validation: 0.4743080409600566]
	TIME [epoch: 7.94 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5890399513947724		[learning rate: 0.003093]
	Learning Rate: 0.00309303
	LOSS [training: 0.5890399513947724 | validation: 0.4611378694747863]
	TIME [epoch: 7.91 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6210939847039612		[learning rate: 0.0030807]
	Learning Rate: 0.00308073
	LOSS [training: 0.6210939847039612 | validation: 0.506457769642709]
	TIME [epoch: 7.93 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.576195525150037		[learning rate: 0.0030685]
	Learning Rate: 0.00306848
	LOSS [training: 0.576195525150037 | validation: 0.43970152639663074]
	TIME [epoch: 7.92 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5185152794644444		[learning rate: 0.0030563]
	Learning Rate: 0.00305627
	LOSS [training: 0.5185152794644444 | validation: 0.36958760856508616]
	TIME [epoch: 7.92 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.38949438093706973		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 0.38949438093706973 | validation: 0.35599902540182515]
	TIME [epoch: 7.9 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.398197697838918		[learning rate: 0.003032]
	Learning Rate: 0.00303201
	LOSS [training: 0.398197697838918 | validation: 0.3720052818416687]
	TIME [epoch: 7.95 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v7_20240711_163535/states/model_facs_v2_dec1b_2dpca_v7_344.pth
Halted early. No improvement in validation loss for 200 epochs.
Finished training in 2786.786 seconds.
