Args:
Namespace(name='model_facs_v2_dec1b_2dpca_v13', outdir='out/model_training/model_facs_v2_dec1b_2dpca_v13', training_data='data/training_data/facs_v2/pca/dec1_fitonsubset/transition1_subset_epi_tr_ce_an_pc12/training', validation_data='data/training_data/facs_v2/pca/dec1_fitonsubset/transition1_subset_epi_tr_ce_an_pc12/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=10, batch_size=50, patience=200, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, quadratic_a=1.0, quadratic_b=1.0, ndims=2, nparams=2, nsigs=2, ncells=400, ncells_sample=400, model_do_sample=False, dt=0.005, dt_schedule='stepped', dt_schedule_bounds=[50, 500, 1000], dt_schedule_scales=[0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', kernel='multiscale', bw_range=[0.2, 0.5, 0.9, 1.1, 1.3, 1.5, 2.0], optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 1771295851

Training model...

Saving initial model state to: out/model_training/model_facs_v2_dec1b_2dpca_v13_20240716_142646/states/model_facs_v2_dec1b_2dpca_v13_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.9377099943373406		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9377099943373406 | validation: 1.2971066513508585]
	TIME [epoch: 37.9 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v13_20240716_142646/states/model_facs_v2_dec1b_2dpca_v13_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.3045537335716182		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3045537335716182 | validation: 1.147101840526066]
	TIME [epoch: 9.8 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v13_20240716_142646/states/model_facs_v2_dec1b_2dpca_v13_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.250046287644577		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.250046287644577 | validation: 1.1100836798346805]
	TIME [epoch: 9.77 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v13_20240716_142646/states/model_facs_v2_dec1b_2dpca_v13_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.1641930298991796		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1641930298991796 | validation: 1.1972986774882384]
	TIME [epoch: 9.77 sec]
EPOCH 5/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.1759959072643102		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1759959072643102 | validation: 0.9745638586317232]
	TIME [epoch: 9.74 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v13_20240716_142646/states/model_facs_v2_dec1b_2dpca_v13_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.1097494937086503		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1097494937086503 | validation: 1.0171160388494358]
	TIME [epoch: 9.77 sec]
EPOCH 7/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.0630421299266972		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0630421299266972 | validation: 0.8933534442602703]
	TIME [epoch: 9.78 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v13_20240716_142646/states/model_facs_v2_dec1b_2dpca_v13_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.0240846970166357		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0240846970166357 | validation: 0.8452205721056123]
	TIME [epoch: 9.75 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v13_20240716_142646/states/model_facs_v2_dec1b_2dpca_v13_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.9537774152976655		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9537774152976655 | validation: 0.8192872909949738]
	TIME [epoch: 9.78 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v13_20240716_142646/states/model_facs_v2_dec1b_2dpca_v13_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.9293997487462384		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9293997487462384 | validation: 0.7633985461402399]
	TIME [epoch: 9.79 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v13_20240716_142646/states/model_facs_v2_dec1b_2dpca_v13_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.8018024670297721		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8018024670297721 | validation: 0.7842703280261605]
	TIME [epoch: 9.79 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7770125693816219		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7770125693816219 | validation: 0.5910656918159988]
	TIME [epoch: 9.77 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v13_20240716_142646/states/model_facs_v2_dec1b_2dpca_v13_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6801837469398004		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6801837469398004 | validation: 0.5275170965097962]
	TIME [epoch: 9.78 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v13_20240716_142646/states/model_facs_v2_dec1b_2dpca_v13_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6483710611520029		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6483710611520029 | validation: 0.48010421826656546]
	TIME [epoch: 9.8 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v13_20240716_142646/states/model_facs_v2_dec1b_2dpca_v13_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5724152602316106		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5724152602316106 | validation: 0.41136019895791287]
	TIME [epoch: 9.77 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v13_20240716_142646/states/model_facs_v2_dec1b_2dpca_v13_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5310006220358303		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5310006220358303 | validation: 0.4668485966966677]
	TIME [epoch: 9.75 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.46806461283211803		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.46806461283211803 | validation: 0.33171913714333934]
	TIME [epoch: 9.75 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v13_20240716_142646/states/model_facs_v2_dec1b_2dpca_v13_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4206070875690948		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4206070875690948 | validation: 0.3253309268213836]
	TIME [epoch: 9.78 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v13_20240716_142646/states/model_facs_v2_dec1b_2dpca_v13_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3779786072573075		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3779786072573075 | validation: 0.2914387599694195]
	TIME [epoch: 9.75 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v13_20240716_142646/states/model_facs_v2_dec1b_2dpca_v13_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3294739584117672		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3294739584117672 | validation: 0.32547273887847505]
	TIME [epoch: 9.77 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3412096026383161		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3412096026383161 | validation: 0.2777496204791637]
	TIME [epoch: 9.78 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v13_20240716_142646/states/model_facs_v2_dec1b_2dpca_v13_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32718082508226026		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.32718082508226026 | validation: 0.28679978535179973]
	TIME [epoch: 9.78 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32846254908198447		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.32846254908198447 | validation: 0.2594187648887419]
	TIME [epoch: 9.77 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v13_20240716_142646/states/model_facs_v2_dec1b_2dpca_v13_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.30894902736142554		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.30894902736142554 | validation: 0.27734342837033055]
	TIME [epoch: 9.78 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.31588281540988467		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.31588281540988467 | validation: 0.2578199174214618]
	TIME [epoch: 9.79 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v13_20240716_142646/states/model_facs_v2_dec1b_2dpca_v13_25.pth
	Model improved!!!
EPOCH 26/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.33191025938084007		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.33191025938084007 | validation: 0.25565816401693514]
	TIME [epoch: 9.76 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v13_20240716_142646/states/model_facs_v2_dec1b_2dpca_v13_26.pth
	Model improved!!!
EPOCH 27/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2944868462147494		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2944868462147494 | validation: 0.24819463186290536]
	TIME [epoch: 9.75 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v13_20240716_142646/states/model_facs_v2_dec1b_2dpca_v13_27.pth
	Model improved!!!
EPOCH 28/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.28188783028109854		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.28188783028109854 | validation: 0.2809277205981052]
	TIME [epoch: 9.77 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2954628910260653		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2954628910260653 | validation: 0.24572990030474745]
	TIME [epoch: 9.76 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v13_20240716_142646/states/model_facs_v2_dec1b_2dpca_v13_29.pth
	Model improved!!!
EPOCH 30/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.29274733407233694		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.29274733407233694 | validation: 0.2775444825479815]
	TIME [epoch: 9.78 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2890612386010409		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2890612386010409 | validation: 0.23575430498999647]
	TIME [epoch: 9.78 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v13_20240716_142646/states/model_facs_v2_dec1b_2dpca_v13_31.pth
	Model improved!!!
EPOCH 32/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2955704322838698		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2955704322838698 | validation: 0.2550391367975196]
	TIME [epoch: 9.79 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2926864631924826		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2926864631924826 | validation: 0.24896453369423716]
	TIME [epoch: 9.77 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.28794968185056474		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.28794968185056474 | validation: 0.2565836140852682]
	TIME [epoch: 9.76 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2806228109677226		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2806228109677226 | validation: 0.26016046078285726]
	TIME [epoch: 10.1 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2822784594663665		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2822784594663665 | validation: 0.2412723540344261]
	TIME [epoch: 9.76 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.27557650868699674		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.27557650868699674 | validation: 0.24843081013759796]
	TIME [epoch: 9.77 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26838317242732407		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.26838317242732407 | validation: 0.22316718829075474]
	TIME [epoch: 9.76 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v13_20240716_142646/states/model_facs_v2_dec1b_2dpca_v13_38.pth
	Model improved!!!
EPOCH 39/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.27712958553465633		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.27712958553465633 | validation: 0.2339886770702681]
	TIME [epoch: 9.76 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2846116282979867		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2846116282979867 | validation: 0.22356018374259698]
	TIME [epoch: 9.74 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2814545406934208		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2814545406934208 | validation: 0.25406948680050523]
	TIME [epoch: 9.74 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.27233363085884005		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.27233363085884005 | validation: 0.22931618089385042]
	TIME [epoch: 9.76 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2713093671651984		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2713093671651984 | validation: 0.23111608429948496]
	TIME [epoch: 9.75 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2616093102606851		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2616093102606851 | validation: 0.2581109624310701]
	TIME [epoch: 9.75 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2780068097786219		[learning rate: 0.0099823]
	Learning Rate: 0.0099823
	LOSS [training: 0.2780068097786219 | validation: 0.2422404470883254]
	TIME [epoch: 9.74 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25296881385426934		[learning rate: 0.0099426]
	Learning Rate: 0.0099426
	LOSS [training: 0.25296881385426934 | validation: 0.2229965189639786]
	TIME [epoch: 9.76 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v13_20240716_142646/states/model_facs_v2_dec1b_2dpca_v13_46.pth
	Model improved!!!
EPOCH 47/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2663609955420352		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 0.2663609955420352 | validation: 0.23114060880934734]
	TIME [epoch: 9.78 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.27479168604338267		[learning rate: 0.0098637]
	Learning Rate: 0.00986367
	LOSS [training: 0.27479168604338267 | validation: 0.2637515817886306]
	TIME [epoch: 9.77 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.27270164929900614		[learning rate: 0.0098244]
	Learning Rate: 0.00982444
	LOSS [training: 0.27270164929900614 | validation: 0.2185494471752587]
	TIME [epoch: 9.77 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v13_20240716_142646/states/model_facs_v2_dec1b_2dpca_v13_49.pth
	Model improved!!!
EPOCH 50/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2566743473413349		[learning rate: 0.0097854]
	Learning Rate: 0.00978536
	LOSS [training: 0.2566743473413349 | validation: 0.20106820512324863]
	TIME [epoch: 9.79 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v13_20240716_142646/states/model_facs_v2_dec1b_2dpca_v13_50.pth
	Model improved!!!
EPOCH 51/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25991366493498363		[learning rate: 0.0097464]
	Learning Rate: 0.00974644
	LOSS [training: 0.25991366493498363 | validation: 0.22183408864100018]
	TIME [epoch: 44.6 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2629618391737354		[learning rate: 0.0097077]
	Learning Rate: 0.00970768
	LOSS [training: 0.2629618391737354 | validation: 0.22668984687876576]
	TIME [epoch: 18.9 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2660285926397183		[learning rate: 0.0096691]
	Learning Rate: 0.00966907
	LOSS [training: 0.2660285926397183 | validation: 0.22601133333373075]
	TIME [epoch: 18.9 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2648392814837812		[learning rate: 0.0096306]
	Learning Rate: 0.00963061
	LOSS [training: 0.2648392814837812 | validation: 0.24548710933036108]
	TIME [epoch: 18.9 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26662532751911355		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 0.26662532751911355 | validation: 0.25168340337458844]
	TIME [epoch: 18.9 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2691140720587165		[learning rate: 0.0095542]
	Learning Rate: 0.00955415
	LOSS [training: 0.2691140720587165 | validation: 0.23226917965778915]
	TIME [epoch: 18.9 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2730992883951156		[learning rate: 0.0095162]
	Learning Rate: 0.00951616
	LOSS [training: 0.2730992883951156 | validation: 0.24847545298899024]
	TIME [epoch: 18.9 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2696229215091608		[learning rate: 0.0094783]
	Learning Rate: 0.00947831
	LOSS [training: 0.2696229215091608 | validation: 0.2441968072256271]
	TIME [epoch: 18.9 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26032548137352773		[learning rate: 0.0094406]
	Learning Rate: 0.00944061
	LOSS [training: 0.26032548137352773 | validation: 0.20730872141252438]
	TIME [epoch: 18.9 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2614088883720475		[learning rate: 0.0094031]
	Learning Rate: 0.00940306
	LOSS [training: 0.2614088883720475 | validation: 0.2119809500513318]
	TIME [epoch: 18.9 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2552072652414304		[learning rate: 0.0093657]
	Learning Rate: 0.00936566
	LOSS [training: 0.2552072652414304 | validation: 0.237004383589204]
	TIME [epoch: 18.9 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25640872636800277		[learning rate: 0.0093284]
	Learning Rate: 0.00932841
	LOSS [training: 0.25640872636800277 | validation: 0.20986084841844885]
	TIME [epoch: 18.9 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2508504636454363		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 0.2508504636454363 | validation: 0.26591499272104796]
	TIME [epoch: 18.9 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2799450124578017		[learning rate: 0.0092544]
	Learning Rate: 0.00925435
	LOSS [training: 0.2799450124578017 | validation: 0.21105254203425355]
	TIME [epoch: 18.9 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2681206373135611		[learning rate: 0.0092175]
	Learning Rate: 0.00921755
	LOSS [training: 0.2681206373135611 | validation: 0.21754809930621768]
	TIME [epoch: 18.9 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25330568397811404		[learning rate: 0.0091809]
	Learning Rate: 0.00918089
	LOSS [training: 0.25330568397811404 | validation: 0.22655392742397948]
	TIME [epoch: 18.9 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25170132503543047		[learning rate: 0.0091444]
	Learning Rate: 0.00914437
	LOSS [training: 0.25170132503543047 | validation: 0.23890033132336214]
	TIME [epoch: 18.9 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2607734103067132		[learning rate: 0.009108]
	Learning Rate: 0.009108
	LOSS [training: 0.2607734103067132 | validation: 0.21051987513062462]
	TIME [epoch: 18.9 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25333054394820426		[learning rate: 0.0090718]
	Learning Rate: 0.00907178
	LOSS [training: 0.25333054394820426 | validation: 0.2182385231089563]
	TIME [epoch: 18.9 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2624892107314807		[learning rate: 0.0090357]
	Learning Rate: 0.00903569
	LOSS [training: 0.2624892107314807 | validation: 0.2050801029640968]
	TIME [epoch: 18.9 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2537529241309288		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 0.2537529241309288 | validation: 0.2149339914117741]
	TIME [epoch: 18.9 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24783952553258348		[learning rate: 0.008964]
	Learning Rate: 0.00896396
	LOSS [training: 0.24783952553258348 | validation: 0.21568846445724618]
	TIME [epoch: 18.9 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.249089410095608		[learning rate: 0.0089283]
	Learning Rate: 0.00892831
	LOSS [training: 0.249089410095608 | validation: 0.2141168970641147]
	TIME [epoch: 18.9 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.27175586587432843		[learning rate: 0.0088928]
	Learning Rate: 0.0088928
	LOSS [training: 0.27175586587432843 | validation: 0.22776559952957748]
	TIME [epoch: 18.9 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.27581601770578185		[learning rate: 0.0088574]
	Learning Rate: 0.00885743
	LOSS [training: 0.27581601770578185 | validation: 0.20830423746546814]
	TIME [epoch: 18.9 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.27911012752086206		[learning rate: 0.0088222]
	Learning Rate: 0.0088222
	LOSS [training: 0.27911012752086206 | validation: 0.21981841111586337]
	TIME [epoch: 18.9 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.27211584253604204		[learning rate: 0.0087871]
	Learning Rate: 0.00878711
	LOSS [training: 0.27211584253604204 | validation: 0.23484271087872396]
	TIME [epoch: 18.9 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.277773165661722		[learning rate: 0.0087522]
	Learning Rate: 0.00875216
	LOSS [training: 0.277773165661722 | validation: 0.2028053817225377]
	TIME [epoch: 18.9 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26676204168817313		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 0.26676204168817313 | validation: 0.21818538132101004]
	TIME [epoch: 18.9 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26218081603931565		[learning rate: 0.0086827]
	Learning Rate: 0.00868268
	LOSS [training: 0.26218081603931565 | validation: 0.21323386842434763]
	TIME [epoch: 18.9 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2596242591114917		[learning rate: 0.0086481]
	Learning Rate: 0.00864815
	LOSS [training: 0.2596242591114917 | validation: 0.21437912097167597]
	TIME [epoch: 18.9 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26160449279812653		[learning rate: 0.0086138]
	Learning Rate: 0.00861375
	LOSS [training: 0.26160449279812653 | validation: 0.21082371407144723]
	TIME [epoch: 18.9 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2731232953095157		[learning rate: 0.0085795]
	Learning Rate: 0.00857949
	LOSS [training: 0.2731232953095157 | validation: 0.25692402407240433]
	TIME [epoch: 18.9 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26118113129416587		[learning rate: 0.0085454]
	Learning Rate: 0.00854537
	LOSS [training: 0.26118113129416587 | validation: 0.22403489357517387]
	TIME [epoch: 18.9 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2501875359193833		[learning rate: 0.0085114]
	Learning Rate: 0.00851138
	LOSS [training: 0.2501875359193833 | validation: 0.21006534249031414]
	TIME [epoch: 18.9 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2604136957360217		[learning rate: 0.0084775]
	Learning Rate: 0.00847753
	LOSS [training: 0.2604136957360217 | validation: 0.20198226167576605]
	TIME [epoch: 18.9 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24856782743929312		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 0.24856782743929312 | validation: 0.22514298255599824]
	TIME [epoch: 18.9 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25925857272437663		[learning rate: 0.0084102]
	Learning Rate: 0.00841023
	LOSS [training: 0.25925857272437663 | validation: 0.20724700458672302]
	TIME [epoch: 18.9 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2639752581131389		[learning rate: 0.0083768]
	Learning Rate: 0.00837678
	LOSS [training: 0.2639752581131389 | validation: 0.20102057039079754]
	TIME [epoch: 18.9 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v13_20240716_142646/states/model_facs_v2_dec1b_2dpca_v13_89.pth
	Model improved!!!
EPOCH 90/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2506696685316822		[learning rate: 0.0083435]
	Learning Rate: 0.00834346
	LOSS [training: 0.2506696685316822 | validation: 0.20910429750392673]
	TIME [epoch: 18.8 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24691423374532975		[learning rate: 0.0083103]
	Learning Rate: 0.00831027
	LOSS [training: 0.24691423374532975 | validation: 0.20011243927188377]
	TIME [epoch: 18.8 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v13_20240716_142646/states/model_facs_v2_dec1b_2dpca_v13_91.pth
	Model improved!!!
EPOCH 92/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2634231128943422		[learning rate: 0.0082772]
	Learning Rate: 0.00827722
	LOSS [training: 0.2634231128943422 | validation: 0.21226081704119576]
	TIME [epoch: 18.9 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24768715273662106		[learning rate: 0.0082443]
	Learning Rate: 0.0082443
	LOSS [training: 0.24768715273662106 | validation: 0.2130212949495552]
	TIME [epoch: 18.8 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24489329742519525		[learning rate: 0.0082115]
	Learning Rate: 0.00821151
	LOSS [training: 0.24489329742519525 | validation: 0.20858393444547021]
	TIME [epoch: 18.8 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24647719290930936		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 0.24647719290930936 | validation: 0.22461996768471618]
	TIME [epoch: 18.9 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26255093963024145		[learning rate: 0.0081463]
	Learning Rate: 0.00814632
	LOSS [training: 0.26255093963024145 | validation: 0.19893080173328598]
	TIME [epoch: 18.9 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v13_20240716_142646/states/model_facs_v2_dec1b_2dpca_v13_96.pth
	Model improved!!!
EPOCH 97/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2515545524284916		[learning rate: 0.0081139]
	Learning Rate: 0.00811392
	LOSS [training: 0.2515545524284916 | validation: 0.2199639740794037]
	TIME [epoch: 18.9 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2570845312092765		[learning rate: 0.0080816]
	Learning Rate: 0.00808165
	LOSS [training: 0.2570845312092765 | validation: 0.2113917065753092]
	TIME [epoch: 18.8 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25906472196755936		[learning rate: 0.0080495]
	Learning Rate: 0.00804951
	LOSS [training: 0.25906472196755936 | validation: 0.20502649282893115]
	TIME [epoch: 18.9 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24404815887692533		[learning rate: 0.0080175]
	Learning Rate: 0.00801749
	LOSS [training: 0.24404815887692533 | validation: 0.19837370233087182]
	TIME [epoch: 18.8 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v13_20240716_142646/states/model_facs_v2_dec1b_2dpca_v13_100.pth
	Model improved!!!
EPOCH 101/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2531706318252641		[learning rate: 0.0079856]
	Learning Rate: 0.0079856
	LOSS [training: 0.2531706318252641 | validation: 0.20534292682419003]
	TIME [epoch: 18.9 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25355241012372776		[learning rate: 0.0079538]
	Learning Rate: 0.00795384
	LOSS [training: 0.25355241012372776 | validation: 0.19274641801902154]
	TIME [epoch: 18.9 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v13_20240716_142646/states/model_facs_v2_dec1b_2dpca_v13_102.pth
	Model improved!!!
EPOCH 103/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2470778579541021		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 0.2470778579541021 | validation: 0.21177097149237972]
	TIME [epoch: 18.9 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.262521966767077		[learning rate: 0.0078907]
	Learning Rate: 0.0078907
	LOSS [training: 0.262521966767077 | validation: 0.20064145707668507]
	TIME [epoch: 18.9 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23989086429701714		[learning rate: 0.0078593]
	Learning Rate: 0.00785931
	LOSS [training: 0.23989086429701714 | validation: 0.20207839462292454]
	TIME [epoch: 18.9 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24705325652920587		[learning rate: 0.0078281]
	Learning Rate: 0.00782805
	LOSS [training: 0.24705325652920587 | validation: 0.21130165661646286]
	TIME [epoch: 18.9 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2499336908301457		[learning rate: 0.0077969]
	Learning Rate: 0.00779692
	LOSS [training: 0.2499336908301457 | validation: 0.2266650096934927]
	TIME [epoch: 18.9 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2544218881311284		[learning rate: 0.0077659]
	Learning Rate: 0.00776591
	LOSS [training: 0.2544218881311284 | validation: 0.206266307462268]
	TIME [epoch: 18.9 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25800401360268244		[learning rate: 0.007735]
	Learning Rate: 0.00773502
	LOSS [training: 0.25800401360268244 | validation: 0.2374026699235594]
	TIME [epoch: 18.9 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2690933095990378		[learning rate: 0.0077043]
	Learning Rate: 0.00770426
	LOSS [training: 0.2690933095990378 | validation: 0.24121966749706242]
	TIME [epoch: 18.9 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26276531201664194		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 0.26276531201664194 | validation: 0.2129137057982687]
	TIME [epoch: 18.9 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2539111110750486		[learning rate: 0.0076431]
	Learning Rate: 0.00764309
	LOSS [training: 0.2539111110750486 | validation: 0.210899332369093]
	TIME [epoch: 18.9 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24609338442742004		[learning rate: 0.0076127]
	Learning Rate: 0.00761269
	LOSS [training: 0.24609338442742004 | validation: 0.19367679363311]
	TIME [epoch: 18.9 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.253536989811751		[learning rate: 0.0075824]
	Learning Rate: 0.00758242
	LOSS [training: 0.253536989811751 | validation: 0.21622776544865457]
	TIME [epoch: 18.9 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24742668844367893		[learning rate: 0.0075523]
	Learning Rate: 0.00755226
	LOSS [training: 0.24742668844367893 | validation: 0.19794544877884732]
	TIME [epoch: 18.9 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2418842108957216		[learning rate: 0.0075222]
	Learning Rate: 0.00752222
	LOSS [training: 0.2418842108957216 | validation: 0.23041048578787912]
	TIME [epoch: 18.9 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24777566670670137		[learning rate: 0.0074923]
	Learning Rate: 0.0074923
	LOSS [training: 0.24777566670670137 | validation: 0.1999943060467399]
	TIME [epoch: 18.9 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24536427461928095		[learning rate: 0.0074625]
	Learning Rate: 0.0074625
	LOSS [training: 0.24536427461928095 | validation: 0.20912607336084582]
	TIME [epoch: 18.9 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.240969355304403		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 0.240969355304403 | validation: 0.21653914091482518]
	TIME [epoch: 18.9 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24925505906805734		[learning rate: 0.0074033]
	Learning Rate: 0.00740326
	LOSS [training: 0.24925505906805734 | validation: 0.19772779157589465]
	TIME [epoch: 18.9 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.245301468859166		[learning rate: 0.0073738]
	Learning Rate: 0.00737382
	LOSS [training: 0.245301468859166 | validation: 0.20163434755777332]
	TIME [epoch: 18.9 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24615619054212556		[learning rate: 0.0073445]
	Learning Rate: 0.00734449
	LOSS [training: 0.24615619054212556 | validation: 0.209080854283405]
	TIME [epoch: 18.9 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2506687027982082		[learning rate: 0.0073153]
	Learning Rate: 0.00731528
	LOSS [training: 0.2506687027982082 | validation: 0.21649514457149915]
	TIME [epoch: 18.9 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2594076783412826		[learning rate: 0.0072862]
	Learning Rate: 0.00728618
	LOSS [training: 0.2594076783412826 | validation: 0.2021358111611319]
	TIME [epoch: 18.9 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24648653296009698		[learning rate: 0.0072572]
	Learning Rate: 0.0072572
	LOSS [training: 0.24648653296009698 | validation: 0.19959808930281378]
	TIME [epoch: 18.9 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24293372345275405		[learning rate: 0.0072283]
	Learning Rate: 0.00722834
	LOSS [training: 0.24293372345275405 | validation: 0.2178815644781779]
	TIME [epoch: 18.9 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24799186377618515		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 0.24799186377618515 | validation: 0.20583548828138828]
	TIME [epoch: 18.9 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25078633178929727		[learning rate: 0.007171]
	Learning Rate: 0.00717095
	LOSS [training: 0.25078633178929727 | validation: 0.20084080341940283]
	TIME [epoch: 18.9 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2454570696057982		[learning rate: 0.0071424]
	Learning Rate: 0.00714243
	LOSS [training: 0.2454570696057982 | validation: 0.2134316299508135]
	TIME [epoch: 18.9 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24549055050095958		[learning rate: 0.007114]
	Learning Rate: 0.00711403
	LOSS [training: 0.24549055050095958 | validation: 0.21428305489594787]
	TIME [epoch: 18.9 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24847620110606997		[learning rate: 0.0070857]
	Learning Rate: 0.00708573
	LOSS [training: 0.24847620110606997 | validation: 0.21653715925825728]
	TIME [epoch: 18.9 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24819179691597684		[learning rate: 0.0070575]
	Learning Rate: 0.00705755
	LOSS [training: 0.24819179691597684 | validation: 0.2002854536514528]
	TIME [epoch: 18.9 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24571461815719114		[learning rate: 0.0070295]
	Learning Rate: 0.00702948
	LOSS [training: 0.24571461815719114 | validation: 0.19878127542663357]
	TIME [epoch: 18.9 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2417719487541507		[learning rate: 0.0070015]
	Learning Rate: 0.00700152
	LOSS [training: 0.2417719487541507 | validation: 0.20406293578300866]
	TIME [epoch: 18.9 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2417223808022273		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 0.2417223808022273 | validation: 0.2003130529191822]
	TIME [epoch: 18.9 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25202260745059657		[learning rate: 0.0069459]
	Learning Rate: 0.00694594
	LOSS [training: 0.25202260745059657 | validation: 0.19727686111330328]
	TIME [epoch: 18.9 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2433554115647604		[learning rate: 0.0069183]
	Learning Rate: 0.00691831
	LOSS [training: 0.2433554115647604 | validation: 0.1970827623831351]
	TIME [epoch: 18.9 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2486071214514596		[learning rate: 0.0068908]
	Learning Rate: 0.00689079
	LOSS [training: 0.2486071214514596 | validation: 0.19435943688794846]
	TIME [epoch: 18.9 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24471973769445812		[learning rate: 0.0068634]
	Learning Rate: 0.00686339
	LOSS [training: 0.24471973769445812 | validation: 0.1954809697275294]
	TIME [epoch: 18.9 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24048684073142393		[learning rate: 0.0068361]
	Learning Rate: 0.00683609
	LOSS [training: 0.24048684073142393 | validation: 0.20001443105460393]
	TIME [epoch: 18.9 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2373620042236641		[learning rate: 0.0068089]
	Learning Rate: 0.0068089
	LOSS [training: 0.2373620042236641 | validation: 0.2035680684411641]
	TIME [epoch: 18.9 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23585514761135937		[learning rate: 0.0067818]
	Learning Rate: 0.00678182
	LOSS [training: 0.23585514761135937 | validation: 0.20442408961136774]
	TIME [epoch: 18.9 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24502007195235695		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 0.24502007195235695 | validation: 0.1980644191600918]
	TIME [epoch: 18.9 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24352769699075946		[learning rate: 0.006728]
	Learning Rate: 0.00672798
	LOSS [training: 0.24352769699075946 | validation: 0.2024751581175106]
	TIME [epoch: 18.9 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23969090136233312		[learning rate: 0.0067012]
	Learning Rate: 0.00670122
	LOSS [training: 0.23969090136233312 | validation: 0.20543751073465932]
	TIME [epoch: 18.9 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2429378604148834		[learning rate: 0.0066746]
	Learning Rate: 0.00667457
	LOSS [training: 0.2429378604148834 | validation: 0.2020928612252332]
	TIME [epoch: 18.9 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24296313012244936		[learning rate: 0.006648]
	Learning Rate: 0.00664802
	LOSS [training: 0.24296313012244936 | validation: 0.20679871309551148]
	TIME [epoch: 18.9 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24775628794292276		[learning rate: 0.0066216]
	Learning Rate: 0.00662158
	LOSS [training: 0.24775628794292276 | validation: 0.20292345541543616]
	TIME [epoch: 18.9 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23670821625017563		[learning rate: 0.0065952]
	Learning Rate: 0.00659524
	LOSS [training: 0.23670821625017563 | validation: 0.22818646136303053]
	TIME [epoch: 18.9 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23951601494611494		[learning rate: 0.006569]
	Learning Rate: 0.00656901
	LOSS [training: 0.23951601494611494 | validation: 0.20519854201407756]
	TIME [epoch: 18.9 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24945384575712323		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 0.24945384575712323 | validation: 0.20241581064349354]
	TIME [epoch: 18.9 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25097933906314124		[learning rate: 0.0065169]
	Learning Rate: 0.00651686
	LOSS [training: 0.25097933906314124 | validation: 0.19834799045688395]
	TIME [epoch: 18.9 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2450035962542921		[learning rate: 0.0064909]
	Learning Rate: 0.00649094
	LOSS [training: 0.2450035962542921 | validation: 0.20568684647719704]
	TIME [epoch: 18.9 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23932389883388508		[learning rate: 0.0064651]
	Learning Rate: 0.00646512
	LOSS [training: 0.23932389883388508 | validation: 0.20451060814769534]
	TIME [epoch: 18.9 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23513306601161504		[learning rate: 0.0064394]
	Learning Rate: 0.00643941
	LOSS [training: 0.23513306601161504 | validation: 0.19876239068804386]
	TIME [epoch: 18.9 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2499859038716908		[learning rate: 0.0064138]
	Learning Rate: 0.0064138
	LOSS [training: 0.2499859038716908 | validation: 0.20637648636892608]
	TIME [epoch: 18.9 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25352665451074174		[learning rate: 0.0063883]
	Learning Rate: 0.00638829
	LOSS [training: 0.25352665451074174 | validation: 0.2014728694600762]
	TIME [epoch: 18.9 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2406778821545471		[learning rate: 0.0063629]
	Learning Rate: 0.00636288
	LOSS [training: 0.2406778821545471 | validation: 0.23018137620471216]
	TIME [epoch: 18.9 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2451769507438612		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 0.2451769507438612 | validation: 0.19699963650661656]
	TIME [epoch: 18.9 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2375233990352047		[learning rate: 0.0063124]
	Learning Rate: 0.00631237
	LOSS [training: 0.2375233990352047 | validation: 0.19942686140796123]
	TIME [epoch: 18.9 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2453187212097938		[learning rate: 0.0062873]
	Learning Rate: 0.00628726
	LOSS [training: 0.2453187212097938 | validation: 0.1938125776093997]
	TIME [epoch: 18.9 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2433912600932334		[learning rate: 0.0062623]
	Learning Rate: 0.00626226
	LOSS [training: 0.2433912600932334 | validation: 0.20589512532261875]
	TIME [epoch: 18.9 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25572548314794463		[learning rate: 0.0062373]
	Learning Rate: 0.00623735
	LOSS [training: 0.25572548314794463 | validation: 0.21190541242650265]
	TIME [epoch: 18.9 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24929755119365574		[learning rate: 0.0062125]
	Learning Rate: 0.00621254
	LOSS [training: 0.24929755119365574 | validation: 0.2051526318726545]
	TIME [epoch: 18.9 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24530363424273086		[learning rate: 0.0061878]
	Learning Rate: 0.00618783
	LOSS [training: 0.24530363424273086 | validation: 0.20147333320165858]
	TIME [epoch: 18.9 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24528268943030718		[learning rate: 0.0061632]
	Learning Rate: 0.00616322
	LOSS [training: 0.24528268943030718 | validation: 0.20566552227413198]
	TIME [epoch: 18.9 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24731595586601474		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 0.24731595586601474 | validation: 0.20403843379767758]
	TIME [epoch: 18.9 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23408402388786836		[learning rate: 0.0061143]
	Learning Rate: 0.00611429
	LOSS [training: 0.23408402388786836 | validation: 0.2057638862171815]
	TIME [epoch: 18.9 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24297468784106402		[learning rate: 0.00609]
	Learning Rate: 0.00608997
	LOSS [training: 0.24297468784106402 | validation: 0.20071831107693097]
	TIME [epoch: 18.9 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23824851591203666		[learning rate: 0.0060658]
	Learning Rate: 0.00606575
	LOSS [training: 0.23824851591203666 | validation: 0.2001575640116821]
	TIME [epoch: 18.9 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24098060957277237		[learning rate: 0.0060416]
	Learning Rate: 0.00604163
	LOSS [training: 0.24098060957277237 | validation: 0.19951851898150866]
	TIME [epoch: 18.9 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23938424136823658		[learning rate: 0.0060176]
	Learning Rate: 0.0060176
	LOSS [training: 0.23938424136823658 | validation: 0.20891848717588318]
	TIME [epoch: 18.9 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24748666554763904		[learning rate: 0.0059937]
	Learning Rate: 0.00599366
	LOSS [training: 0.24748666554763904 | validation: 0.1910088663338628]
	TIME [epoch: 18.9 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v13_20240716_142646/states/model_facs_v2_dec1b_2dpca_v13_173.pth
	Model improved!!!
EPOCH 174/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23551902616521841		[learning rate: 0.0059698]
	Learning Rate: 0.00596982
	LOSS [training: 0.23551902616521841 | validation: 0.22120938800835055]
	TIME [epoch: 18.9 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24122211885650163		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 0.24122211885650163 | validation: 0.19669483928442394]
	TIME [epoch: 18.9 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2486713575979867		[learning rate: 0.0059224]
	Learning Rate: 0.00592243
	LOSS [training: 0.2486713575979867 | validation: 0.22458704311499167]
	TIME [epoch: 18.9 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23991921843058694		[learning rate: 0.0058989]
	Learning Rate: 0.00589888
	LOSS [training: 0.23991921843058694 | validation: 0.1995945424008934]
	TIME [epoch: 18.9 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24289888187759645		[learning rate: 0.0058754]
	Learning Rate: 0.00587541
	LOSS [training: 0.24289888187759645 | validation: 0.20786819234764886]
	TIME [epoch: 18.9 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24598391319514468		[learning rate: 0.005852]
	Learning Rate: 0.00585205
	LOSS [training: 0.24598391319514468 | validation: 0.19845474175815808]
	TIME [epoch: 18.9 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2469584177434683		[learning rate: 0.0058288]
	Learning Rate: 0.00582877
	LOSS [training: 0.2469584177434683 | validation: 0.20369738908848198]
	TIME [epoch: 18.9 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24483783319608213		[learning rate: 0.0058056]
	Learning Rate: 0.00580559
	LOSS [training: 0.24483783319608213 | validation: 0.20774642303663526]
	TIME [epoch: 18.9 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.236922340104753		[learning rate: 0.0057825]
	Learning Rate: 0.0057825
	LOSS [training: 0.236922340104753 | validation: 0.20017464541554847]
	TIME [epoch: 18.9 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23462231939057876		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 0.23462231939057876 | validation: 0.21006838044458293]
	TIME [epoch: 18.9 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24068171921640172		[learning rate: 0.0057366]
	Learning Rate: 0.00573659
	LOSS [training: 0.24068171921640172 | validation: 0.1958883378183684]
	TIME [epoch: 18.9 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2426902860290418		[learning rate: 0.0057138]
	Learning Rate: 0.00571377
	LOSS [training: 0.2426902860290418 | validation: 0.20388001406721373]
	TIME [epoch: 19 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2406019397206515		[learning rate: 0.005691]
	Learning Rate: 0.00569105
	LOSS [training: 0.2406019397206515 | validation: 0.19557422143060613]
	TIME [epoch: 18.9 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2430280680301354		[learning rate: 0.0056684]
	Learning Rate: 0.00566841
	LOSS [training: 0.2430280680301354 | validation: 0.2110606707287988]
	TIME [epoch: 18.9 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24033289953192208		[learning rate: 0.0056459]
	Learning Rate: 0.00564587
	LOSS [training: 0.24033289953192208 | validation: 0.20179009351965682]
	TIME [epoch: 18.9 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23527813341602474		[learning rate: 0.0056234]
	Learning Rate: 0.00562341
	LOSS [training: 0.23527813341602474 | validation: 0.1976318750403733]
	TIME [epoch: 18.9 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23584886484004977		[learning rate: 0.005601]
	Learning Rate: 0.00560105
	LOSS [training: 0.23584886484004977 | validation: 0.19664449246049492]
	TIME [epoch: 18.9 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23452097059526927		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 0.23452097059526927 | validation: 0.198021339228153]
	TIME [epoch: 18.9 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23428811698733978		[learning rate: 0.0055566]
	Learning Rate: 0.00555658
	LOSS [training: 0.23428811698733978 | validation: 0.20876327194142333]
	TIME [epoch: 18.9 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.260216888847385		[learning rate: 0.0055345]
	Learning Rate: 0.00553448
	LOSS [training: 0.260216888847385 | validation: 0.21105221628347123]
	TIME [epoch: 18.9 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24349066046410112		[learning rate: 0.0055125]
	Learning Rate: 0.00551247
	LOSS [training: 0.24349066046410112 | validation: 0.20200691000031173]
	TIME [epoch: 18.9 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23432787560724255		[learning rate: 0.0054905]
	Learning Rate: 0.00549054
	LOSS [training: 0.23432787560724255 | validation: 0.19564846798619367]
	TIME [epoch: 18.9 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24496417738532456		[learning rate: 0.0054687]
	Learning Rate: 0.00546871
	LOSS [training: 0.24496417738532456 | validation: 0.1977461108927805]
	TIME [epoch: 18.9 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24169121146583405		[learning rate: 0.005447]
	Learning Rate: 0.00544696
	LOSS [training: 0.24169121146583405 | validation: 0.19846887825739995]
	TIME [epoch: 18.9 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23680474586984454		[learning rate: 0.0054253]
	Learning Rate: 0.00542529
	LOSS [training: 0.23680474586984454 | validation: 0.19569510153850456]
	TIME [epoch: 18.9 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24901283216040693		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 0.24901283216040693 | validation: 0.1927534149025804]
	TIME [epoch: 18.9 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2440747236454042		[learning rate: 0.0053822]
	Learning Rate: 0.00538222
	LOSS [training: 0.2440747236454042 | validation: 0.19674982053951634]
	TIME [epoch: 18.9 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24745320920402777		[learning rate: 0.0053608]
	Learning Rate: 0.00536081
	LOSS [training: 0.24745320920402777 | validation: 0.20334861964953146]
	TIME [epoch: 18.9 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24399138730852396		[learning rate: 0.0053395]
	Learning Rate: 0.00533949
	LOSS [training: 0.24399138730852396 | validation: 0.19782616599118982]
	TIME [epoch: 18.9 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23933464571463217		[learning rate: 0.0053183]
	Learning Rate: 0.00531826
	LOSS [training: 0.23933464571463217 | validation: 0.19866472711073002]
	TIME [epoch: 18.9 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23981640120958383		[learning rate: 0.0052971]
	Learning Rate: 0.0052971
	LOSS [training: 0.23981640120958383 | validation: 0.20790645511346253]
	TIME [epoch: 18.9 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24136412131088056		[learning rate: 0.005276]
	Learning Rate: 0.00527604
	LOSS [training: 0.24136412131088056 | validation: 0.19158630897441511]
	TIME [epoch: 18.9 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2347064866371587		[learning rate: 0.0052551]
	Learning Rate: 0.00525505
	LOSS [training: 0.2347064866371587 | validation: 0.2046886869732336]
	TIME [epoch: 18.9 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24831358498388736		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 0.24831358498388736 | validation: 0.20330338225858302]
	TIME [epoch: 18.9 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2377422579670445		[learning rate: 0.0052133]
	Learning Rate: 0.00521333
	LOSS [training: 0.2377422579670445 | validation: 0.19926700243981704]
	TIME [epoch: 18.9 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2377676178182515		[learning rate: 0.0051926]
	Learning Rate: 0.0051926
	LOSS [training: 0.2377676178182515 | validation: 0.1899347861410184]
	TIME [epoch: 18.9 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v13_20240716_142646/states/model_facs_v2_dec1b_2dpca_v13_209.pth
	Model improved!!!
EPOCH 210/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23769873844394646		[learning rate: 0.0051719]
	Learning Rate: 0.00517194
	LOSS [training: 0.23769873844394646 | validation: 0.2030877401253821]
	TIME [epoch: 18.8 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2343734568449015		[learning rate: 0.0051514]
	Learning Rate: 0.00515137
	LOSS [training: 0.2343734568449015 | validation: 0.19076459640571916]
	TIME [epoch: 18.9 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2345906662310634		[learning rate: 0.0051309]
	Learning Rate: 0.00513089
	LOSS [training: 0.2345906662310634 | validation: 0.19321918294077597]
	TIME [epoch: 18.9 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23733379537192809		[learning rate: 0.0051105]
	Learning Rate: 0.00511048
	LOSS [training: 0.23733379537192809 | validation: 0.20212938629522653]
	TIME [epoch: 18.9 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24077701980136945		[learning rate: 0.0050902]
	Learning Rate: 0.00509015
	LOSS [training: 0.24077701980136945 | validation: 0.1918020564936016]
	TIME [epoch: 18.9 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23658785959328632		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 0.23658785959328632 | validation: 0.20735913823025304]
	TIME [epoch: 18.9 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2397732391663359		[learning rate: 0.0050497]
	Learning Rate: 0.00504974
	LOSS [training: 0.2397732391663359 | validation: 0.20752376573336145]
	TIME [epoch: 18.9 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23724793109158426		[learning rate: 0.0050297]
	Learning Rate: 0.00502966
	LOSS [training: 0.23724793109158426 | validation: 0.19888884514051575]
	TIME [epoch: 18.9 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23248712589717244		[learning rate: 0.0050097]
	Learning Rate: 0.00500965
	LOSS [training: 0.23248712589717244 | validation: 0.20829868994924788]
	TIME [epoch: 18.9 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.240453047735269		[learning rate: 0.0049897]
	Learning Rate: 0.00498973
	LOSS [training: 0.240453047735269 | validation: 0.1985366916901]
	TIME [epoch: 18.9 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.236556818672969		[learning rate: 0.0049699]
	Learning Rate: 0.00496988
	LOSS [training: 0.236556818672969 | validation: 0.19781456586027296]
	TIME [epoch: 18.9 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23968396347889506		[learning rate: 0.0049501]
	Learning Rate: 0.00495012
	LOSS [training: 0.23968396347889506 | validation: 0.19300181208149053]
	TIME [epoch: 18.9 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23841575555963576		[learning rate: 0.0049304]
	Learning Rate: 0.00493043
	LOSS [training: 0.23841575555963576 | validation: 0.1959232796707091]
	TIME [epoch: 18.9 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23808027499139406		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 0.23808027499139406 | validation: 0.1959042619160461]
	TIME [epoch: 18.9 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2426628674487552		[learning rate: 0.0048913]
	Learning Rate: 0.00489129
	LOSS [training: 0.2426628674487552 | validation: 0.20284535742635743]
	TIME [epoch: 18.9 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24049918037790233		[learning rate: 0.0048718]
	Learning Rate: 0.00487183
	LOSS [training: 0.24049918037790233 | validation: 0.19412753335605665]
	TIME [epoch: 18.9 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23722327727757764		[learning rate: 0.0048525]
	Learning Rate: 0.00485245
	LOSS [training: 0.23722327727757764 | validation: 0.19464406217369984]
	TIME [epoch: 18.9 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23718724131454527		[learning rate: 0.0048332]
	Learning Rate: 0.00483316
	LOSS [training: 0.23718724131454527 | validation: 0.2155674919898775]
	TIME [epoch: 18.9 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23747009860303933		[learning rate: 0.0048139]
	Learning Rate: 0.00481393
	LOSS [training: 0.23747009860303933 | validation: 0.1976759271794099]
	TIME [epoch: 18.9 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23649597761448002		[learning rate: 0.0047948]
	Learning Rate: 0.00479479
	LOSS [training: 0.23649597761448002 | validation: 0.19511673307854857]
	TIME [epoch: 18.9 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23569828905772847		[learning rate: 0.0047757]
	Learning Rate: 0.00477572
	LOSS [training: 0.23569828905772847 | validation: 0.19698249727501962]
	TIME [epoch: 18.9 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23652693817905623		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.23652693817905623 | validation: 0.199202345905333]
	TIME [epoch: 18.9 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23637128990570716		[learning rate: 0.0047378]
	Learning Rate: 0.0047378
	LOSS [training: 0.23637128990570716 | validation: 0.19684126492455595]
	TIME [epoch: 18.9 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23581945172798577		[learning rate: 0.004719]
	Learning Rate: 0.00471896
	LOSS [training: 0.23581945172798577 | validation: 0.19827253653035024]
	TIME [epoch: 18.9 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2335493547194035		[learning rate: 0.0047002]
	Learning Rate: 0.00470019
	LOSS [training: 0.2335493547194035 | validation: 0.20165060653818007]
	TIME [epoch: 18.9 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24044868883224055		[learning rate: 0.0046815]
	Learning Rate: 0.0046815
	LOSS [training: 0.24044868883224055 | validation: 0.20269275084711408]
	TIME [epoch: 18.9 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24385100164418333		[learning rate: 0.0046629]
	Learning Rate: 0.00466288
	LOSS [training: 0.24385100164418333 | validation: 0.1897725682626554]
	TIME [epoch: 18.9 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v13_20240716_142646/states/model_facs_v2_dec1b_2dpca_v13_236.pth
	Model improved!!!
EPOCH 237/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2329311726018095		[learning rate: 0.0046443]
	Learning Rate: 0.00464433
	LOSS [training: 0.2329311726018095 | validation: 0.20346935739013866]
	TIME [epoch: 18.9 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2381995200472781		[learning rate: 0.0046259]
	Learning Rate: 0.00462586
	LOSS [training: 0.2381995200472781 | validation: 0.1919448530876673]
	TIME [epoch: 18.9 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23680314321685497		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 0.23680314321685497 | validation: 0.1970291720945983]
	TIME [epoch: 18.9 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23220816950340112		[learning rate: 0.0045891]
	Learning Rate: 0.00458913
	LOSS [training: 0.23220816950340112 | validation: 0.20505792275428464]
	TIME [epoch: 18.9 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24030835256865313		[learning rate: 0.0045709]
	Learning Rate: 0.00457088
	LOSS [training: 0.24030835256865313 | validation: 0.1937747384068932]
	TIME [epoch: 18.9 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23846225282230524		[learning rate: 0.0045527]
	Learning Rate: 0.0045527
	LOSS [training: 0.23846225282230524 | validation: 0.19132333122602885]
	TIME [epoch: 18.9 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22790489307122755		[learning rate: 0.0045346]
	Learning Rate: 0.00453459
	LOSS [training: 0.22790489307122755 | validation: 0.197119466278947]
	TIME [epoch: 18.9 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23835573676106542		[learning rate: 0.0045166]
	Learning Rate: 0.00451656
	LOSS [training: 0.23835573676106542 | validation: 0.1977379585958875]
	TIME [epoch: 18.9 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23210237685707902		[learning rate: 0.0044986]
	Learning Rate: 0.0044986
	LOSS [training: 0.23210237685707902 | validation: 0.20083667570106462]
	TIME [epoch: 18.9 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23540172253926636		[learning rate: 0.0044807]
	Learning Rate: 0.0044807
	LOSS [training: 0.23540172253926636 | validation: 0.2103428557982448]
	TIME [epoch: 18.9 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23799529965083727		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 0.23799529965083727 | validation: 0.19536709605030864]
	TIME [epoch: 18.9 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23890655162496507		[learning rate: 0.0044451]
	Learning Rate: 0.00444513
	LOSS [training: 0.23890655162496507 | validation: 0.19971052585025104]
	TIME [epoch: 18.9 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23448132353122844		[learning rate: 0.0044275]
	Learning Rate: 0.00442745
	LOSS [training: 0.23448132353122844 | validation: 0.19422269352607618]
	TIME [epoch: 18.9 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2423899103759709		[learning rate: 0.0044098]
	Learning Rate: 0.00440984
	LOSS [training: 0.2423899103759709 | validation: 0.1977106407828189]
	TIME [epoch: 18.9 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24249449660189665		[learning rate: 0.0043923]
	Learning Rate: 0.0043923
	LOSS [training: 0.24249449660189665 | validation: 0.20955119306967435]
	TIME [epoch: 18.9 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23974111163149528		[learning rate: 0.0043748]
	Learning Rate: 0.00437483
	LOSS [training: 0.23974111163149528 | validation: 0.19122389357072378]
	TIME [epoch: 18.9 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23765025366061096		[learning rate: 0.0043574]
	Learning Rate: 0.00435743
	LOSS [training: 0.23765025366061096 | validation: 0.19936846548675174]
	TIME [epoch: 18.9 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23725873874340422		[learning rate: 0.0043401]
	Learning Rate: 0.0043401
	LOSS [training: 0.23725873874340422 | validation: 0.21025458969185268]
	TIME [epoch: 18.9 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2316413607394856		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 0.2316413607394856 | validation: 0.20001631720853896]
	TIME [epoch: 18.9 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24171934075150978		[learning rate: 0.0043056]
	Learning Rate: 0.00430565
	LOSS [training: 0.24171934075150978 | validation: 0.20424683907815444]
	TIME [epoch: 18.9 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2324718206211356		[learning rate: 0.0042885]
	Learning Rate: 0.00428852
	LOSS [training: 0.2324718206211356 | validation: 0.19606779419123213]
	TIME [epoch: 18.9 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23616719962056384		[learning rate: 0.0042715]
	Learning Rate: 0.00427147
	LOSS [training: 0.23616719962056384 | validation: 0.19706495217592848]
	TIME [epoch: 18.9 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23113800880940166		[learning rate: 0.0042545]
	Learning Rate: 0.00425448
	LOSS [training: 0.23113800880940166 | validation: 0.20133735940430775]
	TIME [epoch: 18.9 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2406232115598302		[learning rate: 0.0042376]
	Learning Rate: 0.00423756
	LOSS [training: 0.2406232115598302 | validation: 0.19844668593668208]
	TIME [epoch: 18.9 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23436337293710455		[learning rate: 0.0042207]
	Learning Rate: 0.0042207
	LOSS [training: 0.23436337293710455 | validation: 0.19305652572251278]
	TIME [epoch: 18.9 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23699297904614625		[learning rate: 0.0042039]
	Learning Rate: 0.00420391
	LOSS [training: 0.23699297904614625 | validation: 0.19980590545481886]
	TIME [epoch: 18.9 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23238190789987684		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 0.23238190789987684 | validation: 0.19247624936355742]
	TIME [epoch: 18.9 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22625823272728335		[learning rate: 0.0041705]
	Learning Rate: 0.00417054
	LOSS [training: 0.22625823272728335 | validation: 0.20271209460725972]
	TIME [epoch: 18.9 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23359894297266445		[learning rate: 0.004154]
	Learning Rate: 0.00415395
	LOSS [training: 0.23359894297266445 | validation: 0.2014467071085808]
	TIME [epoch: 18.9 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24246420570933452		[learning rate: 0.0041374]
	Learning Rate: 0.00413743
	LOSS [training: 0.24246420570933452 | validation: 0.20329836790380967]
	TIME [epoch: 18.9 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23673672507997268		[learning rate: 0.004121]
	Learning Rate: 0.00412098
	LOSS [training: 0.23673672507997268 | validation: 0.19562280907938007]
	TIME [epoch: 18.9 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23401427298930644		[learning rate: 0.0041046]
	Learning Rate: 0.00410458
	LOSS [training: 0.23401427298930644 | validation: 0.19683899875756605]
	TIME [epoch: 18.9 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2363466075637738		[learning rate: 0.0040883]
	Learning Rate: 0.00408826
	LOSS [training: 0.2363466075637738 | validation: 0.19187074743469146]
	TIME [epoch: 18.9 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22943228631547777		[learning rate: 0.004072]
	Learning Rate: 0.004072
	LOSS [training: 0.22943228631547777 | validation: 0.20540780119541804]
	TIME [epoch: 18.9 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2403517173059443		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.2403517173059443 | validation: 0.19277109111442017]
	TIME [epoch: 18.9 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23527074824820257		[learning rate: 0.0040397]
	Learning Rate: 0.00403967
	LOSS [training: 0.23527074824820257 | validation: 0.20068254869205596]
	TIME [epoch: 18.9 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23633109923616707		[learning rate: 0.0040236]
	Learning Rate: 0.00402361
	LOSS [training: 0.23633109923616707 | validation: 0.20323050444175533]
	TIME [epoch: 18.9 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2594911803441308		[learning rate: 0.0040076]
	Learning Rate: 0.0040076
	LOSS [training: 0.2594911803441308 | validation: 0.1995409659763013]
	TIME [epoch: 18.9 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23512029406741		[learning rate: 0.0039917]
	Learning Rate: 0.00399166
	LOSS [training: 0.23512029406741 | validation: 0.1988007811044335]
	TIME [epoch: 18.9 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22989901133979723		[learning rate: 0.0039758]
	Learning Rate: 0.00397579
	LOSS [training: 0.22989901133979723 | validation: 0.19709451726952065]
	TIME [epoch: 18.9 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2331318423200388		[learning rate: 0.00396]
	Learning Rate: 0.00395997
	LOSS [training: 0.2331318423200388 | validation: 0.21152519191820174]
	TIME [epoch: 18.9 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23196497468939883		[learning rate: 0.0039442]
	Learning Rate: 0.00394422
	LOSS [training: 0.23196497468939883 | validation: 0.21247748968533386]
	TIME [epoch: 18.9 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24043261750649803		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 0.24043261750649803 | validation: 0.20274660831745464]
	TIME [epoch: 18.9 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23430286051116578		[learning rate: 0.0039129]
	Learning Rate: 0.00391291
	LOSS [training: 0.23430286051116578 | validation: 0.19291149163513194]
	TIME [epoch: 18.9 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24043203510580025		[learning rate: 0.0038973]
	Learning Rate: 0.00389735
	LOSS [training: 0.24043203510580025 | validation: 0.19350945354367277]
	TIME [epoch: 18.9 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23597811309331704		[learning rate: 0.0038818]
	Learning Rate: 0.00388185
	LOSS [training: 0.23597811309331704 | validation: 0.1987353051332612]
	TIME [epoch: 18.9 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24102950877547136		[learning rate: 0.0038664]
	Learning Rate: 0.00386641
	LOSS [training: 0.24102950877547136 | validation: 0.19236360520182325]
	TIME [epoch: 18.9 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22928061570657354		[learning rate: 0.003851]
	Learning Rate: 0.00385103
	LOSS [training: 0.22928061570657354 | validation: 0.21205137990905962]
	TIME [epoch: 18.9 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2319545470033656		[learning rate: 0.0038357]
	Learning Rate: 0.00383571
	LOSS [training: 0.2319545470033656 | validation: 0.19359257032937255]
	TIME [epoch: 18.9 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22802127175060186		[learning rate: 0.0038205]
	Learning Rate: 0.00382046
	LOSS [training: 0.22802127175060186 | validation: 0.19087482261556682]
	TIME [epoch: 18.9 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24131176222949613		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 0.24131176222949613 | validation: 0.19714889125065793]
	TIME [epoch: 18.9 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23538144099542985		[learning rate: 0.0037901]
	Learning Rate: 0.00379013
	LOSS [training: 0.23538144099542985 | validation: 0.1916799579087876]
	TIME [epoch: 18.9 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23573444897307722		[learning rate: 0.0037751]
	Learning Rate: 0.00377505
	LOSS [training: 0.23573444897307722 | validation: 0.19708781965141606]
	TIME [epoch: 18.9 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22621954220521928		[learning rate: 0.00376]
	Learning Rate: 0.00376004
	LOSS [training: 0.22621954220521928 | validation: 0.19531335498117222]
	TIME [epoch: 18.9 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22878933431709797		[learning rate: 0.0037451]
	Learning Rate: 0.00374508
	LOSS [training: 0.22878933431709797 | validation: 0.1988546593111673]
	TIME [epoch: 18.9 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2386399292008766		[learning rate: 0.0037302]
	Learning Rate: 0.00373019
	LOSS [training: 0.2386399292008766 | validation: 0.19663293141434285]
	TIME [epoch: 18.9 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2387562886914131		[learning rate: 0.0037154]
	Learning Rate: 0.00371535
	LOSS [training: 0.2387562886914131 | validation: 0.18739520833870105]
	TIME [epoch: 18.9 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v13_20240716_142646/states/model_facs_v2_dec1b_2dpca_v13_293.pth
	Model improved!!!
EPOCH 294/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2355138894322281		[learning rate: 0.0037006]
	Learning Rate: 0.00370058
	LOSS [training: 0.2355138894322281 | validation: 0.1929671610697888]
	TIME [epoch: 18.9 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23346753203591142		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 0.23346753203591142 | validation: 0.20206745381136226]
	TIME [epoch: 18.9 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23319241187790057		[learning rate: 0.0036712]
	Learning Rate: 0.0036712
	LOSS [training: 0.23319241187790057 | validation: 0.19440488071953274]
	TIME [epoch: 18.9 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23918621730395342		[learning rate: 0.0036566]
	Learning Rate: 0.0036566
	LOSS [training: 0.23918621730395342 | validation: 0.21151387876666616]
	TIME [epoch: 18.9 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2357356351449309		[learning rate: 0.0036421]
	Learning Rate: 0.00364205
	LOSS [training: 0.2357356351449309 | validation: 0.20094285500054143]
	TIME [epoch: 18.9 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2430267773500363		[learning rate: 0.0036276]
	Learning Rate: 0.00362757
	LOSS [training: 0.2430267773500363 | validation: 0.20070767404355533]
	TIME [epoch: 18.9 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23828906327225555		[learning rate: 0.0036131]
	Learning Rate: 0.00361314
	LOSS [training: 0.23828906327225555 | validation: 0.19005473279380306]
	TIME [epoch: 18.9 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22939508946483148		[learning rate: 0.0035988]
	Learning Rate: 0.00359877
	LOSS [training: 0.22939508946483148 | validation: 0.18887334962191232]
	TIME [epoch: 18.9 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23180650487348098		[learning rate: 0.0035845]
	Learning Rate: 0.00358445
	LOSS [training: 0.23180650487348098 | validation: 0.2040306514597793]
	TIME [epoch: 18.9 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24173711359600678		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 0.24173711359600678 | validation: 0.19956696501413726]
	TIME [epoch: 18.9 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2338672564966019		[learning rate: 0.003556]
	Learning Rate: 0.003556
	LOSS [training: 0.2338672564966019 | validation: 0.1935314523987163]
	TIME [epoch: 18.9 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23652306803776119		[learning rate: 0.0035419]
	Learning Rate: 0.00354185
	LOSS [training: 0.23652306803776119 | validation: 0.19387374660808215]
	TIME [epoch: 18.9 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23246825066281046		[learning rate: 0.0035278]
	Learning Rate: 0.00352777
	LOSS [training: 0.23246825066281046 | validation: 0.18728438486586127]
	TIME [epoch: 18.9 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v13_20240716_142646/states/model_facs_v2_dec1b_2dpca_v13_306.pth
	Model improved!!!
EPOCH 307/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2269835320288374		[learning rate: 0.0035137]
	Learning Rate: 0.00351374
	LOSS [training: 0.2269835320288374 | validation: 0.19435841818657304]
	TIME [epoch: 18.9 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22839026002784232		[learning rate: 0.0034998]
	Learning Rate: 0.00349976
	LOSS [training: 0.22839026002784232 | validation: 0.19561190653146393]
	TIME [epoch: 18.9 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23889225305105447		[learning rate: 0.0034858]
	Learning Rate: 0.00348584
	LOSS [training: 0.23889225305105447 | validation: 0.1866404106680289]
	TIME [epoch: 18.9 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v13_20240716_142646/states/model_facs_v2_dec1b_2dpca_v13_309.pth
	Model improved!!!
EPOCH 310/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23672519864877162		[learning rate: 0.003472]
	Learning Rate: 0.00347198
	LOSS [training: 0.23672519864877162 | validation: 0.1958104916430216]
	TIME [epoch: 18.9 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22983261003900024		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.22983261003900024 | validation: 0.18764248313479454]
	TIME [epoch: 18.9 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23699148952984628		[learning rate: 0.0034444]
	Learning Rate: 0.00344441
	LOSS [training: 0.23699148952984628 | validation: 0.1865402965903411]
	TIME [epoch: 18.9 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v13_20240716_142646/states/model_facs_v2_dec1b_2dpca_v13_312.pth
	Model improved!!!
EPOCH 313/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2322418597925141		[learning rate: 0.0034307]
	Learning Rate: 0.00343071
	LOSS [training: 0.2322418597925141 | validation: 0.19211836814400193]
	TIME [epoch: 18.8 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2334872248807123		[learning rate: 0.0034171]
	Learning Rate: 0.00341707
	LOSS [training: 0.2334872248807123 | validation: 0.1955581583646857]
	TIME [epoch: 18.9 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2369245229063104		[learning rate: 0.0034035]
	Learning Rate: 0.00340348
	LOSS [training: 0.2369245229063104 | validation: 0.19905098491057452]
	TIME [epoch: 18.9 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2367238340631998		[learning rate: 0.0033899]
	Learning Rate: 0.00338994
	LOSS [training: 0.2367238340631998 | validation: 0.18994747307647425]
	TIME [epoch: 18.9 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23286942958916595		[learning rate: 0.0033765]
	Learning Rate: 0.00337646
	LOSS [training: 0.23286942958916595 | validation: 0.1991911812454601]
	TIME [epoch: 18.9 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23691380235468695		[learning rate: 0.003363]
	Learning Rate: 0.00336303
	LOSS [training: 0.23691380235468695 | validation: 0.19429758223537066]
	TIME [epoch: 18.9 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22969909994866555		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 0.22969909994866555 | validation: 0.19308637461831107]
	TIME [epoch: 18.9 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2367786332675007		[learning rate: 0.0033363]
	Learning Rate: 0.00333633
	LOSS [training: 0.2367786332675007 | validation: 0.19042586119036797]
	TIME [epoch: 18.9 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.232644535388516		[learning rate: 0.0033231]
	Learning Rate: 0.00332306
	LOSS [training: 0.232644535388516 | validation: 0.1959366962146775]
	TIME [epoch: 18.9 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23026044274948798		[learning rate: 0.0033098]
	Learning Rate: 0.00330985
	LOSS [training: 0.23026044274948798 | validation: 0.1986437418068361]
	TIME [epoch: 18.9 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23850107067556633		[learning rate: 0.0032967]
	Learning Rate: 0.00329668
	LOSS [training: 0.23850107067556633 | validation: 0.20981285556104465]
	TIME [epoch: 18.9 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2430725380261374		[learning rate: 0.0032836]
	Learning Rate: 0.00328357
	LOSS [training: 0.2430725380261374 | validation: 0.19318704434954087]
	TIME [epoch: 18.9 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23677411170052873		[learning rate: 0.0032705]
	Learning Rate: 0.00327051
	LOSS [training: 0.23677411170052873 | validation: 0.20756462173917622]
	TIME [epoch: 18.9 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25514016874851597		[learning rate: 0.0032575]
	Learning Rate: 0.0032575
	LOSS [training: 0.25514016874851597 | validation: 0.1972676394616139]
	TIME [epoch: 18.9 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2361231418581068		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 0.2361231418581068 | validation: 0.19104301150378075]
	TIME [epoch: 18.9 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23203384836547944		[learning rate: 0.0032316]
	Learning Rate: 0.00323164
	LOSS [training: 0.23203384836547944 | validation: 0.19190207988800395]
	TIME [epoch: 18.9 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2273128693868912		[learning rate: 0.0032188]
	Learning Rate: 0.00321879
	LOSS [training: 0.2273128693868912 | validation: 0.19705989694746612]
	TIME [epoch: 18.9 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2310706381348682		[learning rate: 0.003206]
	Learning Rate: 0.00320599
	LOSS [training: 0.2310706381348682 | validation: 0.1901071132273248]
	TIME [epoch: 18.9 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24085310332713034		[learning rate: 0.0031932]
	Learning Rate: 0.00319323
	LOSS [training: 0.24085310332713034 | validation: 0.18845694727714862]
	TIME [epoch: 18.9 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2538272929209777		[learning rate: 0.0031805]
	Learning Rate: 0.00318053
	LOSS [training: 0.2538272929209777 | validation: 0.19843371523263834]
	TIME [epoch: 18.9 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2298611687714455		[learning rate: 0.0031679]
	Learning Rate: 0.00316788
	LOSS [training: 0.2298611687714455 | validation: 0.18606140466016324]
	TIME [epoch: 18.9 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v13_20240716_142646/states/model_facs_v2_dec1b_2dpca_v13_333.pth
	Model improved!!!
EPOCH 334/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22578394354604076		[learning rate: 0.0031553]
	Learning Rate: 0.00315528
	LOSS [training: 0.22578394354604076 | validation: 0.18864098040447552]
	TIME [epoch: 18.9 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23816301664175032		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 0.23816301664175032 | validation: 0.19199651526302347]
	TIME [epoch: 18.9 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23131314508530743		[learning rate: 0.0031302]
	Learning Rate: 0.00313023
	LOSS [training: 0.23131314508530743 | validation: 0.19552997507081746]
	TIME [epoch: 18.9 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23312682260353965		[learning rate: 0.0031178]
	Learning Rate: 0.00311779
	LOSS [training: 0.23312682260353965 | validation: 0.19239551753385203]
	TIME [epoch: 18.9 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23217167005950426		[learning rate: 0.0031054]
	Learning Rate: 0.00310538
	LOSS [training: 0.23217167005950426 | validation: 0.19742909553405288]
	TIME [epoch: 18.9 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22683511530766762		[learning rate: 0.003093]
	Learning Rate: 0.00309303
	LOSS [training: 0.22683511530766762 | validation: 0.18804037732687404]
	TIME [epoch: 18.9 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22375663417325592		[learning rate: 0.0030807]
	Learning Rate: 0.00308073
	LOSS [training: 0.22375663417325592 | validation: 0.19330451798910597]
	TIME [epoch: 18.9 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23248387772067833		[learning rate: 0.0030685]
	Learning Rate: 0.00306848
	LOSS [training: 0.23248387772067833 | validation: 0.19254942690792692]
	TIME [epoch: 18.9 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23661799377123138		[learning rate: 0.0030563]
	Learning Rate: 0.00305627
	LOSS [training: 0.23661799377123138 | validation: 0.1893789628541705]
	TIME [epoch: 18.9 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2283799329666012		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 0.2283799329666012 | validation: 0.19347853688970956]
	TIME [epoch: 18.9 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22663871264348665		[learning rate: 0.003032]
	Learning Rate: 0.00303201
	LOSS [training: 0.22663871264348665 | validation: 0.1913437299951741]
	TIME [epoch: 18.9 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23312161409401227		[learning rate: 0.00302]
	Learning Rate: 0.00301995
	LOSS [training: 0.23312161409401227 | validation: 0.18944382769549373]
	TIME [epoch: 18.9 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2332888486329002		[learning rate: 0.0030079]
	Learning Rate: 0.00300794
	LOSS [training: 0.2332888486329002 | validation: 0.19083185225088845]
	TIME [epoch: 18.9 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22768064045074535		[learning rate: 0.002996]
	Learning Rate: 0.00299598
	LOSS [training: 0.22768064045074535 | validation: 0.18705867367869258]
	TIME [epoch: 18.9 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22718892411862518		[learning rate: 0.0029841]
	Learning Rate: 0.00298406
	LOSS [training: 0.22718892411862518 | validation: 0.1941669366340612]
	TIME [epoch: 18.9 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23268264106792566		[learning rate: 0.0029722]
	Learning Rate: 0.00297219
	LOSS [training: 0.23268264106792566 | validation: 0.19374428612054947]
	TIME [epoch: 18.9 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23653760131439336		[learning rate: 0.0029604]
	Learning Rate: 0.00296037
	LOSS [training: 0.23653760131439336 | validation: 0.18510675899338436]
	TIME [epoch: 18.9 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v13_20240716_142646/states/model_facs_v2_dec1b_2dpca_v13_350.pth
	Model improved!!!
EPOCH 351/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22934654480002495		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.22934654480002495 | validation: 0.1905910966699335]
	TIME [epoch: 18.9 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2241838678964992		[learning rate: 0.0029369]
	Learning Rate: 0.00293687
	LOSS [training: 0.2241838678964992 | validation: 0.19002016974925667]
	TIME [epoch: 18.9 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2395636805246047		[learning rate: 0.0029252]
	Learning Rate: 0.00292519
	LOSS [training: 0.2395636805246047 | validation: 0.19310632911401548]
	TIME [epoch: 18.8 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2341425676906693		[learning rate: 0.0029136]
	Learning Rate: 0.00291355
	LOSS [training: 0.2341425676906693 | validation: 0.19590440294398534]
	TIME [epoch: 18.9 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23150915599481647		[learning rate: 0.002902]
	Learning Rate: 0.00290197
	LOSS [training: 0.23150915599481647 | validation: 0.19362853413455436]
	TIME [epoch: 18.9 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22876756304156456		[learning rate: 0.0028904]
	Learning Rate: 0.00289042
	LOSS [training: 0.22876756304156456 | validation: 0.19642665943050044]
	TIME [epoch: 18.9 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23829796188353317		[learning rate: 0.0028789]
	Learning Rate: 0.00287893
	LOSS [training: 0.23829796188353317 | validation: 0.19401607334980836]
	TIME [epoch: 18.9 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23517968840141806		[learning rate: 0.0028675]
	Learning Rate: 0.00286748
	LOSS [training: 0.23517968840141806 | validation: 0.19250945534626393]
	TIME [epoch: 18.9 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23707138624561497		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 0.23707138624561497 | validation: 0.20089092338583608]
	TIME [epoch: 18.9 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23193598697779766		[learning rate: 0.0028447]
	Learning Rate: 0.00284471
	LOSS [training: 0.23193598697779766 | validation: 0.19271465302108753]
	TIME [epoch: 18.9 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23960904948401204		[learning rate: 0.0028334]
	Learning Rate: 0.0028334
	LOSS [training: 0.23960904948401204 | validation: 0.19297413085461695]
	TIME [epoch: 18.9 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25110701931817325		[learning rate: 0.0028221]
	Learning Rate: 0.00282213
	LOSS [training: 0.25110701931817325 | validation: 0.19357262921070856]
	TIME [epoch: 18.9 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22878708373570733		[learning rate: 0.0028109]
	Learning Rate: 0.00281091
	LOSS [training: 0.22878708373570733 | validation: 0.1927693042835209]
	TIME [epoch: 18.9 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22635661160784812		[learning rate: 0.0027997]
	Learning Rate: 0.00279973
	LOSS [training: 0.22635661160784812 | validation: 0.19764753434850282]
	TIME [epoch: 18.9 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23144725095619606		[learning rate: 0.0027886]
	Learning Rate: 0.00278859
	LOSS [training: 0.23144725095619606 | validation: 0.19443196438021554]
	TIME [epoch: 18.9 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22922296325906194		[learning rate: 0.0027775]
	Learning Rate: 0.0027775
	LOSS [training: 0.22922296325906194 | validation: 0.1929680851082512]
	TIME [epoch: 18.9 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22918705060995215		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 0.22918705060995215 | validation: 0.19417638223050268]
	TIME [epoch: 18.9 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23251593590982042		[learning rate: 0.0027554]
	Learning Rate: 0.00275545
	LOSS [training: 0.23251593590982042 | validation: 0.19032405441219788]
	TIME [epoch: 18.9 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23184777868639106		[learning rate: 0.0027445]
	Learning Rate: 0.00274449
	LOSS [training: 0.23184777868639106 | validation: 0.19030578357164535]
	TIME [epoch: 18.9 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2305839053063855		[learning rate: 0.0027336]
	Learning Rate: 0.00273357
	LOSS [training: 0.2305839053063855 | validation: 0.18562736214715828]
	TIME [epoch: 18.9 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2383161105159851		[learning rate: 0.0027227]
	Learning Rate: 0.0027227
	LOSS [training: 0.2383161105159851 | validation: 0.19852633529082617]
	TIME [epoch: 18.9 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22844055304284255		[learning rate: 0.0027119]
	Learning Rate: 0.00271187
	LOSS [training: 0.22844055304284255 | validation: 0.19055195830290264]
	TIME [epoch: 18.9 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2423375808729743		[learning rate: 0.0027011]
	Learning Rate: 0.00270109
	LOSS [training: 0.2423375808729743 | validation: 0.19306561881900858]
	TIME [epoch: 18.9 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2318177594023415		[learning rate: 0.0026903]
	Learning Rate: 0.00269034
	LOSS [training: 0.2318177594023415 | validation: 0.1939564024511856]
	TIME [epoch: 18.9 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2319196785283035		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 0.2319196785283035 | validation: 0.1996555093191821]
	TIME [epoch: 18.9 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23152381915126588		[learning rate: 0.002669]
	Learning Rate: 0.00266899
	LOSS [training: 0.23152381915126588 | validation: 0.1993432223209335]
	TIME [epoch: 18.9 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2363963950161689		[learning rate: 0.0026584]
	Learning Rate: 0.00265837
	LOSS [training: 0.2363963950161689 | validation: 0.19518997404782085]
	TIME [epoch: 18.9 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23068574090669594		[learning rate: 0.0026478]
	Learning Rate: 0.0026478
	LOSS [training: 0.23068574090669594 | validation: 0.19420377505732964]
	TIME [epoch: 18.9 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22603411047941233		[learning rate: 0.0026373]
	Learning Rate: 0.00263727
	LOSS [training: 0.22603411047941233 | validation: 0.1922905063583195]
	TIME [epoch: 18.9 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22702946019591286		[learning rate: 0.0026268]
	Learning Rate: 0.00262678
	LOSS [training: 0.22702946019591286 | validation: 0.19197709291304874]
	TIME [epoch: 18.9 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22807521178325596		[learning rate: 0.0026163]
	Learning Rate: 0.00261633
	LOSS [training: 0.22807521178325596 | validation: 0.1963842700181879]
	TIME [epoch: 18.9 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2319444921566365		[learning rate: 0.0026059]
	Learning Rate: 0.00260592
	LOSS [training: 0.2319444921566365 | validation: 0.19010807899812027]
	TIME [epoch: 18.9 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22901561954767635		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 0.22901561954767635 | validation: 0.1935817846173759]
	TIME [epoch: 18.9 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23737035202468526		[learning rate: 0.0025852]
	Learning Rate: 0.00258523
	LOSS [training: 0.23737035202468526 | validation: 0.19307043889661654]
	TIME [epoch: 18.9 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23072957288514725		[learning rate: 0.002575]
	Learning Rate: 0.00257495
	LOSS [training: 0.23072957288514725 | validation: 0.18869830445100416]
	TIME [epoch: 18.9 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22618372052159158		[learning rate: 0.0025647]
	Learning Rate: 0.00256471
	LOSS [training: 0.22618372052159158 | validation: 0.1923784299301339]
	TIME [epoch: 18.9 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22148497112620433		[learning rate: 0.0025545]
	Learning Rate: 0.00255451
	LOSS [training: 0.22148497112620433 | validation: 0.19329599269766834]
	TIME [epoch: 18.9 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22630280627686958		[learning rate: 0.0025444]
	Learning Rate: 0.00254435
	LOSS [training: 0.22630280627686958 | validation: 0.18420822485582972]
	TIME [epoch: 18.9 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v13_20240716_142646/states/model_facs_v2_dec1b_2dpca_v13_388.pth
	Model improved!!!
EPOCH 389/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22926785912710804		[learning rate: 0.0025342]
	Learning Rate: 0.00253423
	LOSS [training: 0.22926785912710804 | validation: 0.19385069229220694]
	TIME [epoch: 18.9 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23434312603588806		[learning rate: 0.0025242]
	Learning Rate: 0.00252415
	LOSS [training: 0.23434312603588806 | validation: 0.1963557591875526]
	TIME [epoch: 18.9 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24224381936112835		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.24224381936112835 | validation: 0.18754426296611365]
	TIME [epoch: 18.9 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23086883830260424		[learning rate: 0.0025041]
	Learning Rate: 0.00250411
	LOSS [training: 0.23086883830260424 | validation: 0.19140886772397242]
	TIME [epoch: 18.9 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23214272780461734		[learning rate: 0.0024942]
	Learning Rate: 0.00249415
	LOSS [training: 0.23214272780461734 | validation: 0.19486125499139534]
	TIME [epoch: 18.9 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2266645112667243		[learning rate: 0.0024842]
	Learning Rate: 0.00248423
	LOSS [training: 0.2266645112667243 | validation: 0.1898656565960124]
	TIME [epoch: 18.9 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2325557317905823		[learning rate: 0.0024744]
	Learning Rate: 0.00247435
	LOSS [training: 0.2325557317905823 | validation: 0.18747640858461959]
	TIME [epoch: 18.9 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22637557510374678		[learning rate: 0.0024645]
	Learning Rate: 0.00246451
	LOSS [training: 0.22637557510374678 | validation: 0.19363976098650115]
	TIME [epoch: 18.9 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23773185855669826		[learning rate: 0.0024547]
	Learning Rate: 0.00245471
	LOSS [training: 0.23773185855669826 | validation: 0.18906424871886157]
	TIME [epoch: 18.9 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23201126700488775		[learning rate: 0.0024449]
	Learning Rate: 0.00244495
	LOSS [training: 0.23201126700488775 | validation: 0.1950311895340206]
	TIME [epoch: 18.9 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.228772025775663		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 0.228772025775663 | validation: 0.1887636426775098]
	TIME [epoch: 18.9 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2254313576162936		[learning rate: 0.0024255]
	Learning Rate: 0.00242554
	LOSS [training: 0.2254313576162936 | validation: 0.189508660558678]
	TIME [epoch: 18.9 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2295400117380142		[learning rate: 0.0024159]
	Learning Rate: 0.00241589
	LOSS [training: 0.2295400117380142 | validation: 0.19150405981238408]
	TIME [epoch: 18.9 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22710210389794472		[learning rate: 0.0024063]
	Learning Rate: 0.00240628
	LOSS [training: 0.22710210389794472 | validation: 0.19574875935911118]
	TIME [epoch: 18.9 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22976508916365518		[learning rate: 0.0023967]
	Learning Rate: 0.00239671
	LOSS [training: 0.22976508916365518 | validation: 0.18944100793321533]
	TIME [epoch: 18.9 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22674118540785		[learning rate: 0.0023872]
	Learning Rate: 0.00238718
	LOSS [training: 0.22674118540785 | validation: 0.1903841156260826]
	TIME [epoch: 18.9 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2337887154869895		[learning rate: 0.0023777]
	Learning Rate: 0.00237768
	LOSS [training: 0.2337887154869895 | validation: 0.20136672768065025]
	TIME [epoch: 18.9 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23076060541703314		[learning rate: 0.0023682]
	Learning Rate: 0.00236823
	LOSS [training: 0.23076060541703314 | validation: 0.1890741697971767]
	TIME [epoch: 18.9 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22626867538203013		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 0.22626867538203013 | validation: 0.18802549288835568]
	TIME [epoch: 18.8 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2271700024920152		[learning rate: 0.0023494]
	Learning Rate: 0.00234942
	LOSS [training: 0.2271700024920152 | validation: 0.1881512550739522]
	TIME [epoch: 18.9 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2271865745902324		[learning rate: 0.0023401]
	Learning Rate: 0.00234008
	LOSS [training: 0.2271865745902324 | validation: 0.18906594352852263]
	TIME [epoch: 18.8 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2357550677242522		[learning rate: 0.0023308]
	Learning Rate: 0.00233077
	LOSS [training: 0.2357550677242522 | validation: 0.19455532919895926]
	TIME [epoch: 18.9 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23716089101864116		[learning rate: 0.0023215]
	Learning Rate: 0.0023215
	LOSS [training: 0.23716089101864116 | validation: 0.1859808483444889]
	TIME [epoch: 18.9 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22976301290919166		[learning rate: 0.0023123]
	Learning Rate: 0.00231227
	LOSS [training: 0.22976301290919166 | validation: 0.19094542792005847]
	TIME [epoch: 18.9 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23006945076238747		[learning rate: 0.0023031]
	Learning Rate: 0.00230307
	LOSS [training: 0.23006945076238747 | validation: 0.18765832686138295]
	TIME [epoch: 18.9 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.21877144860922787		[learning rate: 0.0022939]
	Learning Rate: 0.00229391
	LOSS [training: 0.21877144860922787 | validation: 0.19307796106012123]
	TIME [epoch: 18.9 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22360465242303126		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 0.22360465242303126 | validation: 0.18166433399269546]
	TIME [epoch: 18.9 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v13_20240716_142646/states/model_facs_v2_dec1b_2dpca_v13_415.pth
	Model improved!!!
EPOCH 416/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.233469496814113		[learning rate: 0.0022757]
	Learning Rate: 0.0022757
	LOSS [training: 0.233469496814113 | validation: 0.19199974656211635]
	TIME [epoch: 18.9 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2291459858665202		[learning rate: 0.0022667]
	Learning Rate: 0.00226665
	LOSS [training: 0.2291459858665202 | validation: 0.19146394240665104]
	TIME [epoch: 18.8 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23081759939159094		[learning rate: 0.0022576]
	Learning Rate: 0.00225764
	LOSS [training: 0.23081759939159094 | validation: 0.18980578033462178]
	TIME [epoch: 18.9 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23142612837611143		[learning rate: 0.0022487]
	Learning Rate: 0.00224866
	LOSS [training: 0.23142612837611143 | validation: 0.19178266162628915]
	TIME [epoch: 18.9 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22378522914590565		[learning rate: 0.0022397]
	Learning Rate: 0.00223971
	LOSS [training: 0.22378522914590565 | validation: 0.18710103505897296]
	TIME [epoch: 18.9 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23172156159977492		[learning rate: 0.0022308]
	Learning Rate: 0.0022308
	LOSS [training: 0.23172156159977492 | validation: 0.1929971801027213]
	TIME [epoch: 18.9 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2294318892509568		[learning rate: 0.0022219]
	Learning Rate: 0.00222193
	LOSS [training: 0.2294318892509568 | validation: 0.19198251386949047]
	TIME [epoch: 18.9 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23072538153840721		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.23072538153840721 | validation: 0.1962160604087846]
	TIME [epoch: 18.9 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.230033655963977		[learning rate: 0.0022043]
	Learning Rate: 0.00220429
	LOSS [training: 0.230033655963977 | validation: 0.18681021816915913]
	TIME [epoch: 18.9 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23555611734065776		[learning rate: 0.0021955]
	Learning Rate: 0.00219553
	LOSS [training: 0.23555611734065776 | validation: 0.18910841043826312]
	TIME [epoch: 18.9 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22526328477059115		[learning rate: 0.0021868]
	Learning Rate: 0.00218679
	LOSS [training: 0.22526328477059115 | validation: 0.19623958280447942]
	TIME [epoch: 18.9 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23304259881443234		[learning rate: 0.0021781]
	Learning Rate: 0.0021781
	LOSS [training: 0.23304259881443234 | validation: 0.1913752450394223]
	TIME [epoch: 18.9 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22943679654937743		[learning rate: 0.0021694]
	Learning Rate: 0.00216943
	LOSS [training: 0.22943679654937743 | validation: 0.19066515490365263]
	TIME [epoch: 18.9 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22367768203758795		[learning rate: 0.0021608]
	Learning Rate: 0.0021608
	LOSS [training: 0.22367768203758795 | validation: 0.19310745270626928]
	TIME [epoch: 18.9 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23146956136035815		[learning rate: 0.0021522]
	Learning Rate: 0.00215221
	LOSS [training: 0.23146956136035815 | validation: 0.193661020432927]
	TIME [epoch: 18.9 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23185458922659835		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.23185458922659835 | validation: 0.20800228038227245]
	TIME [epoch: 18.9 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24806337924504054		[learning rate: 0.0021351]
	Learning Rate: 0.00213512
	LOSS [training: 0.24806337924504054 | validation: 0.1837716988908683]
	TIME [epoch: 18.9 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2333348096444772		[learning rate: 0.0021266]
	Learning Rate: 0.00212663
	LOSS [training: 0.2333348096444772 | validation: 0.19087714117246962]
	TIME [epoch: 18.9 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2263198503386762		[learning rate: 0.0021182]
	Learning Rate: 0.00211817
	LOSS [training: 0.2263198503386762 | validation: 0.18952218259201078]
	TIME [epoch: 18.9 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23230009778427935		[learning rate: 0.0021097]
	Learning Rate: 0.00210975
	LOSS [training: 0.23230009778427935 | validation: 0.19015627266672844]
	TIME [epoch: 18.9 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2250559644996311		[learning rate: 0.0021014]
	Learning Rate: 0.00210136
	LOSS [training: 0.2250559644996311 | validation: 0.18570906277863547]
	TIME [epoch: 18.9 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22521857315750124		[learning rate: 0.002093]
	Learning Rate: 0.002093
	LOSS [training: 0.22521857315750124 | validation: 0.18511667294856035]
	TIME [epoch: 18.9 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22785445475619673		[learning rate: 0.0020847]
	Learning Rate: 0.00208468
	LOSS [training: 0.22785445475619673 | validation: 0.18809464907552456]
	TIME [epoch: 18.9 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22886295878733234		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.22886295878733234 | validation: 0.19125577487171813]
	TIME [epoch: 18.9 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22794899029286686		[learning rate: 0.0020681]
	Learning Rate: 0.00206813
	LOSS [training: 0.22794899029286686 | validation: 0.19263050144982133]
	TIME [epoch: 18.9 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23093423055567155		[learning rate: 0.0020599]
	Learning Rate: 0.0020599
	LOSS [training: 0.23093423055567155 | validation: 0.18742562775338353]
	TIME [epoch: 18.9 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2396326627994435		[learning rate: 0.0020517]
	Learning Rate: 0.00205171
	LOSS [training: 0.2396326627994435 | validation: 0.19054563821196951]
	TIME [epoch: 18.9 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23568150118074588		[learning rate: 0.0020435]
	Learning Rate: 0.00204355
	LOSS [training: 0.23568150118074588 | validation: 0.19826961771411153]
	TIME [epoch: 18.9 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2272597780106145		[learning rate: 0.0020354]
	Learning Rate: 0.00203542
	LOSS [training: 0.2272597780106145 | validation: 0.18967680579450627]
	TIME [epoch: 18.9 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23271918882345732		[learning rate: 0.0020273]
	Learning Rate: 0.00202732
	LOSS [training: 0.23271918882345732 | validation: 0.19019227072784792]
	TIME [epoch: 18.9 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2329636978207717		[learning rate: 0.0020193]
	Learning Rate: 0.00201926
	LOSS [training: 0.2329636978207717 | validation: 0.19080425393033779]
	TIME [epoch: 18.9 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2241861364651371		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 0.2241861364651371 | validation: 0.1941495557654028]
	TIME [epoch: 18.9 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22799062999365255		[learning rate: 0.0020032]
	Learning Rate: 0.00200323
	LOSS [training: 0.22799062999365255 | validation: 0.19954745047824018]
	TIME [epoch: 18.9 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23057485713513984		[learning rate: 0.0019953]
	Learning Rate: 0.00199526
	LOSS [training: 0.23057485713513984 | validation: 0.1949209574675299]
	TIME [epoch: 18.9 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23078926641962305		[learning rate: 0.0019873]
	Learning Rate: 0.00198733
	LOSS [training: 0.23078926641962305 | validation: 0.19007254029233167]
	TIME [epoch: 18.9 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23128731188191887		[learning rate: 0.0019794]
	Learning Rate: 0.00197942
	LOSS [training: 0.23128731188191887 | validation: 0.19248169208841087]
	TIME [epoch: 18.9 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23238551806448188		[learning rate: 0.0019715]
	Learning Rate: 0.00197155
	LOSS [training: 0.23238551806448188 | validation: 0.1881273564857976]
	TIME [epoch: 18.9 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2335468599122411		[learning rate: 0.0019637]
	Learning Rate: 0.00196371
	LOSS [training: 0.2335468599122411 | validation: 0.18728956841570304]
	TIME [epoch: 18.9 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22276138608913035		[learning rate: 0.0019559]
	Learning Rate: 0.0019559
	LOSS [training: 0.22276138608913035 | validation: 0.19190006095650616]
	TIME [epoch: 18.9 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23025616512035343		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 0.23025616512035343 | validation: 0.19362974415724424]
	TIME [epoch: 18.9 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2321987040783496		[learning rate: 0.0019404]
	Learning Rate: 0.00194037
	LOSS [training: 0.2321987040783496 | validation: 0.19080115655353203]
	TIME [epoch: 18.9 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23255098486791675		[learning rate: 0.0019327]
	Learning Rate: 0.00193265
	LOSS [training: 0.23255098486791675 | validation: 0.19401399203521524]
	TIME [epoch: 18.9 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23015714756347577		[learning rate: 0.001925]
	Learning Rate: 0.00192497
	LOSS [training: 0.23015714756347577 | validation: 0.1919664228771148]
	TIME [epoch: 18.9 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22462991114601896		[learning rate: 0.0019173]
	Learning Rate: 0.00191731
	LOSS [training: 0.22462991114601896 | validation: 0.19739813965014238]
	TIME [epoch: 18.9 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22695077367056468		[learning rate: 0.0019097]
	Learning Rate: 0.00190968
	LOSS [training: 0.22695077367056468 | validation: 0.19786488208725486]
	TIME [epoch: 18.9 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23149012422580442		[learning rate: 0.0019021]
	Learning Rate: 0.00190209
	LOSS [training: 0.23149012422580442 | validation: 0.188408222145012]
	TIME [epoch: 19 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23218519887400005		[learning rate: 0.0018945]
	Learning Rate: 0.00189452
	LOSS [training: 0.23218519887400005 | validation: 0.1872158217936893]
	TIME [epoch: 18.9 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2239823942506659		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.2239823942506659 | validation: 0.19246549987255007]
	TIME [epoch: 18.9 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23591784968018623		[learning rate: 0.0018795]
	Learning Rate: 0.00187948
	LOSS [training: 0.23591784968018623 | validation: 0.18599988487631966]
	TIME [epoch: 18.9 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22247399779493116		[learning rate: 0.001872]
	Learning Rate: 0.00187201
	LOSS [training: 0.22247399779493116 | validation: 0.18638594280150406]
	TIME [epoch: 18.9 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22171283795729513		[learning rate: 0.0018646]
	Learning Rate: 0.00186456
	LOSS [training: 0.22171283795729513 | validation: 0.19063687994469924]
	TIME [epoch: 18.9 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22164673741175975		[learning rate: 0.0018571]
	Learning Rate: 0.00185715
	LOSS [training: 0.22164673741175975 | validation: 0.1866732762701831]
	TIME [epoch: 18.9 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23128496766630052		[learning rate: 0.0018498]
	Learning Rate: 0.00184976
	LOSS [training: 0.23128496766630052 | validation: 0.18371912690127604]
	TIME [epoch: 18.9 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23855565964572087		[learning rate: 0.0018424]
	Learning Rate: 0.0018424
	LOSS [training: 0.23855565964572087 | validation: 0.19474215594874034]
	TIME [epoch: 18.9 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22978274982643285		[learning rate: 0.0018351]
	Learning Rate: 0.00183508
	LOSS [training: 0.22978274982643285 | validation: 0.18919539413186323]
	TIME [epoch: 18.9 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22940137405733463		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.22940137405733463 | validation: 0.1956715543472167]
	TIME [epoch: 18.9 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23015761148315278		[learning rate: 0.0018205]
	Learning Rate: 0.00182051
	LOSS [training: 0.23015761148315278 | validation: 0.18821887733559114]
	TIME [epoch: 18.9 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22826411480907924		[learning rate: 0.0018133]
	Learning Rate: 0.00181327
	LOSS [training: 0.22826411480907924 | validation: 0.19285965531806393]
	TIME [epoch: 18.9 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22506557447531528		[learning rate: 0.0018061]
	Learning Rate: 0.00180605
	LOSS [training: 0.22506557447531528 | validation: 0.1855510044629774]
	TIME [epoch: 18.9 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2243798100021958		[learning rate: 0.0017989]
	Learning Rate: 0.00179887
	LOSS [training: 0.2243798100021958 | validation: 0.1932550766143955]
	TIME [epoch: 18.9 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22981338765896966		[learning rate: 0.0017917]
	Learning Rate: 0.00179172
	LOSS [training: 0.22981338765896966 | validation: 0.18848159260924024]
	TIME [epoch: 18.9 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2342522620656047		[learning rate: 0.0017846]
	Learning Rate: 0.00178459
	LOSS [training: 0.2342522620656047 | validation: 0.18919362485603608]
	TIME [epoch: 18.9 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2250244843889675		[learning rate: 0.0017775]
	Learning Rate: 0.00177749
	LOSS [training: 0.2250244843889675 | validation: 0.19168064458306316]
	TIME [epoch: 18.9 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22053066995158133		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.22053066995158133 | validation: 0.18926480321694988]
	TIME [epoch: 18.9 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23494247357839854		[learning rate: 0.0017634]
	Learning Rate: 0.00176338
	LOSS [training: 0.23494247357839854 | validation: 0.19325868921927836]
	TIME [epoch: 18.9 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2305826512265287		[learning rate: 0.0017564]
	Learning Rate: 0.00175637
	LOSS [training: 0.2305826512265287 | validation: 0.18870168751654032]
	TIME [epoch: 18.9 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22640045147645152		[learning rate: 0.0017494]
	Learning Rate: 0.00174938
	LOSS [training: 0.22640045147645152 | validation: 0.1932095118486091]
	TIME [epoch: 18.9 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22634164019997893		[learning rate: 0.0017424]
	Learning Rate: 0.00174242
	LOSS [training: 0.22634164019997893 | validation: 0.194061705998614]
	TIME [epoch: 18.9 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2235503921358036		[learning rate: 0.0017355]
	Learning Rate: 0.00173549
	LOSS [training: 0.2235503921358036 | validation: 0.18691628945494396]
	TIME [epoch: 18.9 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2238207849910038		[learning rate: 0.0017286]
	Learning Rate: 0.00172859
	LOSS [training: 0.2238207849910038 | validation: 0.18851860543814986]
	TIME [epoch: 18.9 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22244128319524448		[learning rate: 0.0017217]
	Learning Rate: 0.00172172
	LOSS [training: 0.22244128319524448 | validation: 0.1959447330927721]
	TIME [epoch: 18.9 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22887513245816088		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 0.22887513245816088 | validation: 0.18962517176956678]
	TIME [epoch: 18.9 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23087425232704575		[learning rate: 0.001708]
	Learning Rate: 0.00170805
	LOSS [training: 0.23087425232704575 | validation: 0.1881182841174835]
	TIME [epoch: 18.9 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22572620067376548		[learning rate: 0.0017013]
	Learning Rate: 0.00170125
	LOSS [training: 0.22572620067376548 | validation: 0.19610701264851899]
	TIME [epoch: 18.9 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22473883862703373		[learning rate: 0.0016945]
	Learning Rate: 0.00169449
	LOSS [training: 0.22473883862703373 | validation: 0.19299695948458223]
	TIME [epoch: 18.9 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22814088898092846		[learning rate: 0.0016877]
	Learning Rate: 0.00168775
	LOSS [training: 0.22814088898092846 | validation: 0.18528037961320093]
	TIME [epoch: 18.9 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22713894509825755		[learning rate: 0.001681]
	Learning Rate: 0.00168104
	LOSS [training: 0.22713894509825755 | validation: 0.18616963117434987]
	TIME [epoch: 18.9 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23191607948533133		[learning rate: 0.0016743]
	Learning Rate: 0.00167435
	LOSS [training: 0.23191607948533133 | validation: 0.1912141007272537]
	TIME [epoch: 18.9 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23351677218503036		[learning rate: 0.0016677]
	Learning Rate: 0.00166769
	LOSS [training: 0.23351677218503036 | validation: 0.19727734998748775]
	TIME [epoch: 18.9 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22928632269347635		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.22928632269347635 | validation: 0.18935039290690775]
	TIME [epoch: 18.9 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22515919324131495		[learning rate: 0.0016545]
	Learning Rate: 0.00165445
	LOSS [training: 0.22515919324131495 | validation: 0.18792642950459834]
	TIME [epoch: 18.9 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22830798670224534		[learning rate: 0.0016479]
	Learning Rate: 0.00164787
	LOSS [training: 0.22830798670224534 | validation: 0.19435326566292369]
	TIME [epoch: 18.9 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22689445378869952		[learning rate: 0.0016413]
	Learning Rate: 0.00164132
	LOSS [training: 0.22689445378869952 | validation: 0.1867490330599973]
	TIME [epoch: 18.9 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22878490823925698		[learning rate: 0.0016348]
	Learning Rate: 0.00163479
	LOSS [training: 0.22878490823925698 | validation: 0.19472589453843572]
	TIME [epoch: 18.9 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2307502306011271		[learning rate: 0.0016283]
	Learning Rate: 0.00162829
	LOSS [training: 0.2307502306011271 | validation: 0.19026689065351027]
	TIME [epoch: 18.9 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22110726377537718		[learning rate: 0.0016218]
	Learning Rate: 0.00162181
	LOSS [training: 0.22110726377537718 | validation: 0.19449047011298468]
	TIME [epoch: 66.5 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23433432041717023		[learning rate: 0.0016154]
	Learning Rate: 0.00161536
	LOSS [training: 0.23433432041717023 | validation: 0.1913277726537421]
	TIME [epoch: 41 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22100898044565018		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 0.22100898044565018 | validation: 0.19331668577045696]
	TIME [epoch: 41 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22707900681512047		[learning rate: 0.0016025]
	Learning Rate: 0.00160254
	LOSS [training: 0.22707900681512047 | validation: 0.19478423200262784]
	TIME [epoch: 41 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2305098018754536		[learning rate: 0.0015962]
	Learning Rate: 0.00159616
	LOSS [training: 0.2305098018754536 | validation: 0.19174587305215113]
	TIME [epoch: 41 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23022283939000443		[learning rate: 0.0015898]
	Learning Rate: 0.00158981
	LOSS [training: 0.23022283939000443 | validation: 0.18910880736630017]
	TIME [epoch: 41 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2295810211843916		[learning rate: 0.0015835]
	Learning Rate: 0.00158349
	LOSS [training: 0.2295810211843916 | validation: 0.1878226744351635]
	TIME [epoch: 41 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22819261029625026		[learning rate: 0.0015772]
	Learning Rate: 0.00157719
	LOSS [training: 0.22819261029625026 | validation: 0.1880299983349753]
	TIME [epoch: 41 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23489917789363135		[learning rate: 0.0015709]
	Learning Rate: 0.00157092
	LOSS [training: 0.23489917789363135 | validation: 0.18822246714910668]
	TIME [epoch: 41 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2260051550673061		[learning rate: 0.0015647]
	Learning Rate: 0.00156467
	LOSS [training: 0.2260051550673061 | validation: 0.18432286781121734]
	TIME [epoch: 41 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23482947520909217		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.23482947520909217 | validation: 0.18634734535219769]
	TIME [epoch: 41 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2318264157562043		[learning rate: 0.0015522]
	Learning Rate: 0.00155225
	LOSS [training: 0.2318264157562043 | validation: 0.1888583607196738]
	TIME [epoch: 41 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22980669043264237		[learning rate: 0.0015461]
	Learning Rate: 0.00154608
	LOSS [training: 0.22980669043264237 | validation: 0.1934151367870183]
	TIME [epoch: 41 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22538524551286443		[learning rate: 0.0015399]
	Learning Rate: 0.00153993
	LOSS [training: 0.22538524551286443 | validation: 0.18691626131411948]
	TIME [epoch: 41 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2204868289924553		[learning rate: 0.0015338]
	Learning Rate: 0.0015338
	LOSS [training: 0.2204868289924553 | validation: 0.1892287919370112]
	TIME [epoch: 41 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22384928935332088		[learning rate: 0.0015277]
	Learning Rate: 0.0015277
	LOSS [training: 0.22384928935332088 | validation: 0.18631491901921587]
	TIME [epoch: 41 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23252230160191312		[learning rate: 0.0015216]
	Learning Rate: 0.00152163
	LOSS [training: 0.23252230160191312 | validation: 0.18871243570735027]
	TIME [epoch: 41 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2278371548745136		[learning rate: 0.0015156]
	Learning Rate: 0.00151557
	LOSS [training: 0.2278371548745136 | validation: 0.19114784675224666]
	TIME [epoch: 41 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23001582615049326		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.23001582615049326 | validation: 0.1971301458085977]
	TIME [epoch: 41 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2308712958342457		[learning rate: 0.0015035]
	Learning Rate: 0.00150354
	LOSS [training: 0.2308712958342457 | validation: 0.18842909387083268]
	TIME [epoch: 41 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2301639228167689		[learning rate: 0.0014976]
	Learning Rate: 0.00149756
	LOSS [training: 0.2301639228167689 | validation: 0.1984257044043191]
	TIME [epoch: 41 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.21914917722642435		[learning rate: 0.0014916]
	Learning Rate: 0.00149161
	LOSS [training: 0.21914917722642435 | validation: 0.18831721627771011]
	TIME [epoch: 41 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2276697284155924		[learning rate: 0.0014857]
	Learning Rate: 0.00148567
	LOSS [training: 0.2276697284155924 | validation: 0.1849399924195403]
	TIME [epoch: 41 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2350032148451959		[learning rate: 0.0014798]
	Learning Rate: 0.00147976
	LOSS [training: 0.2350032148451959 | validation: 0.19411384409685697]
	TIME [epoch: 41.1 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22285366380397997		[learning rate: 0.0014739]
	Learning Rate: 0.00147388
	LOSS [training: 0.22285366380397997 | validation: 0.18929033669845338]
	TIME [epoch: 41 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23016014682008715		[learning rate: 0.001468]
	Learning Rate: 0.00146802
	LOSS [training: 0.23016014682008715 | validation: 0.19005524169622395]
	TIME [epoch: 41 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22152757965638348		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.22152757965638348 | validation: 0.18940852556286877]
	TIME [epoch: 41 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2220761585029869		[learning rate: 0.0014564]
	Learning Rate: 0.00145636
	LOSS [training: 0.2220761585029869 | validation: 0.188017583044148]
	TIME [epoch: 41 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2374754881263648		[learning rate: 0.0014506]
	Learning Rate: 0.00145057
	LOSS [training: 0.2374754881263648 | validation: 0.18829408268570466]
	TIME [epoch: 41 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22603382846840978		[learning rate: 0.0014448]
	Learning Rate: 0.0014448
	LOSS [training: 0.22603382846840978 | validation: 0.18850435562598652]
	TIME [epoch: 41 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22638969955387442		[learning rate: 0.0014391]
	Learning Rate: 0.00143905
	LOSS [training: 0.22638969955387442 | validation: 0.19027548285798568]
	TIME [epoch: 41 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22365792922022948		[learning rate: 0.0014333]
	Learning Rate: 0.00143333
	LOSS [training: 0.22365792922022948 | validation: 0.1917842549663453]
	TIME [epoch: 41 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22474051926601543		[learning rate: 0.0014276]
	Learning Rate: 0.00142763
	LOSS [training: 0.22474051926601543 | validation: 0.18957354361016007]
	TIME [epoch: 41 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23274725371353128		[learning rate: 0.001422]
	Learning Rate: 0.00142195
	LOSS [training: 0.23274725371353128 | validation: 0.18470093580793728]
	TIME [epoch: 41 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2282290936975434		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.2282290936975434 | validation: 0.18984623640425516]
	TIME [epoch: 41 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22693077680518703		[learning rate: 0.0014107]
	Learning Rate: 0.00141066
	LOSS [training: 0.22693077680518703 | validation: 0.1883220427270999]
	TIME [epoch: 41 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23173960855232434		[learning rate: 0.0014051]
	Learning Rate: 0.00140505
	LOSS [training: 0.23173960855232434 | validation: 0.19221044343595184]
	TIME [epoch: 41 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23040096036988367		[learning rate: 0.0013995]
	Learning Rate: 0.00139946
	LOSS [training: 0.23040096036988367 | validation: 0.19386036921950958]
	TIME [epoch: 41 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2230032608767353		[learning rate: 0.0013939]
	Learning Rate: 0.0013939
	LOSS [training: 0.2230032608767353 | validation: 0.1894243307191586]
	TIME [epoch: 41 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.21829900882475922		[learning rate: 0.0013884]
	Learning Rate: 0.00138835
	LOSS [training: 0.21829900882475922 | validation: 0.19382487423621084]
	TIME [epoch: 41 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23451671832256826		[learning rate: 0.0013828]
	Learning Rate: 0.00138283
	LOSS [training: 0.23451671832256826 | validation: 0.1917987123732882]
	TIME [epoch: 41 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23942938695183516		[learning rate: 0.0013773]
	Learning Rate: 0.00137733
	LOSS [training: 0.23942938695183516 | validation: 0.1897930758609589]
	TIME [epoch: 41 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23311286789448385		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 0.23311286789448385 | validation: 0.1925389316286321]
	TIME [epoch: 41 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22580285040414066		[learning rate: 0.0013664]
	Learning Rate: 0.0013664
	LOSS [training: 0.22580285040414066 | validation: 0.18991451814700056]
	TIME [epoch: 41 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22331205403969545		[learning rate: 0.001361]
	Learning Rate: 0.00136096
	LOSS [training: 0.22331205403969545 | validation: 0.19125276573386613]
	TIME [epoch: 41 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23569242684897976		[learning rate: 0.0013555]
	Learning Rate: 0.00135555
	LOSS [training: 0.23569242684897976 | validation: 0.1913010139463705]
	TIME [epoch: 41 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23105096923387952		[learning rate: 0.0013502]
	Learning Rate: 0.00135016
	LOSS [training: 0.23105096923387952 | validation: 0.18733603686111933]
	TIME [epoch: 41 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2286789826989959		[learning rate: 0.0013448]
	Learning Rate: 0.00134479
	LOSS [training: 0.2286789826989959 | validation: 0.19294380563970887]
	TIME [epoch: 41 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22729851467679194		[learning rate: 0.0013394]
	Learning Rate: 0.00133944
	LOSS [training: 0.22729851467679194 | validation: 0.1891009075015067]
	TIME [epoch: 41 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22802204414592828		[learning rate: 0.0013341]
	Learning Rate: 0.00133411
	LOSS [training: 0.22802204414592828 | validation: 0.19148662782785927]
	TIME [epoch: 41 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2239458172480123		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.2239458172480123 | validation: 0.18800957245073419]
	TIME [epoch: 41 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22632530780986274		[learning rate: 0.0013235]
	Learning Rate: 0.00132352
	LOSS [training: 0.22632530780986274 | validation: 0.19169040117909178]
	TIME [epoch: 41 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2266267958292203		[learning rate: 0.0013183]
	Learning Rate: 0.00131826
	LOSS [training: 0.2266267958292203 | validation: 0.1864562501625393]
	TIME [epoch: 41 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22698628964581927		[learning rate: 0.001313]
	Learning Rate: 0.00131301
	LOSS [training: 0.22698628964581927 | validation: 0.19255775955965462]
	TIME [epoch: 41 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22991894649188285		[learning rate: 0.0013078]
	Learning Rate: 0.00130779
	LOSS [training: 0.22991894649188285 | validation: 0.19150976410047107]
	TIME [epoch: 41 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22569655934841754		[learning rate: 0.0013026]
	Learning Rate: 0.00130259
	LOSS [training: 0.22569655934841754 | validation: 0.19088306937414995]
	TIME [epoch: 41 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22877065416133543		[learning rate: 0.0012974]
	Learning Rate: 0.00129741
	LOSS [training: 0.22877065416133543 | validation: 0.19183339870095378]
	TIME [epoch: 41 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22529525679821483		[learning rate: 0.0012922]
	Learning Rate: 0.00129225
	LOSS [training: 0.22529525679821483 | validation: 0.18703050750437272]
	TIME [epoch: 41 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2287849439178692		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 0.2287849439178692 | validation: 0.19955494562000461]
	TIME [epoch: 41 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2275892467719098		[learning rate: 0.001282]
	Learning Rate: 0.00128199
	LOSS [training: 0.2275892467719098 | validation: 0.18946638602334015]
	TIME [epoch: 41 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22763757189780487		[learning rate: 0.0012769]
	Learning Rate: 0.00127689
	LOSS [training: 0.22763757189780487 | validation: 0.18817049198785368]
	TIME [epoch: 41 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.21908818217456075		[learning rate: 0.0012718]
	Learning Rate: 0.00127181
	LOSS [training: 0.21908818217456075 | validation: 0.1909929620172678]
	TIME [epoch: 41 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22177288106496718		[learning rate: 0.0012668]
	Learning Rate: 0.00126675
	LOSS [training: 0.22177288106496718 | validation: 0.18889674642793844]
	TIME [epoch: 41 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22659348279869798		[learning rate: 0.0012617]
	Learning Rate: 0.00126172
	LOSS [training: 0.22659348279869798 | validation: 0.18393933548474115]
	TIME [epoch: 41 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22336240529050874		[learning rate: 0.0012567]
	Learning Rate: 0.0012567
	LOSS [training: 0.22336240529050874 | validation: 0.18911326629273276]
	TIME [epoch: 41 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22711800572531005		[learning rate: 0.0012517]
	Learning Rate: 0.0012517
	LOSS [training: 0.22711800572531005 | validation: 0.18615649990487756]
	TIME [epoch: 41 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22877776457263568		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 0.22877776457263568 | validation: 0.18650227658975477]
	TIME [epoch: 41 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22545202688279195		[learning rate: 0.0012418]
	Learning Rate: 0.00124176
	LOSS [training: 0.22545202688279195 | validation: 0.18598872288750423]
	TIME [epoch: 41 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22959803908723497		[learning rate: 0.0012368]
	Learning Rate: 0.00123682
	LOSS [training: 0.22959803908723497 | validation: 0.19211905331749296]
	TIME [epoch: 41 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22585900040579843		[learning rate: 0.0012319]
	Learning Rate: 0.0012319
	LOSS [training: 0.22585900040579843 | validation: 0.1896019187527235]
	TIME [epoch: 41 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23233236139922406		[learning rate: 0.001227]
	Learning Rate: 0.001227
	LOSS [training: 0.23233236139922406 | validation: 0.19437445320961655]
	TIME [epoch: 41 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22009096087626748		[learning rate: 0.0012221]
	Learning Rate: 0.00122212
	LOSS [training: 0.22009096087626748 | validation: 0.18801622613355176]
	TIME [epoch: 41 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22495978447140852		[learning rate: 0.0012173]
	Learning Rate: 0.00121726
	LOSS [training: 0.22495978447140852 | validation: 0.18556829285484208]
	TIME [epoch: 41 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23443477015340944		[learning rate: 0.0012124]
	Learning Rate: 0.00121242
	LOSS [training: 0.23443477015340944 | validation: 0.18908045941031368]
	TIME [epoch: 41 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22471328600000787		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 0.22471328600000787 | validation: 0.19024548763393825]
	TIME [epoch: 41 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2258354230437848		[learning rate: 0.0012028]
	Learning Rate: 0.0012028
	LOSS [training: 0.2258354230437848 | validation: 0.19322853044409607]
	TIME [epoch: 41 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2279426788185458		[learning rate: 0.001198]
	Learning Rate: 0.00119801
	LOSS [training: 0.2279426788185458 | validation: 0.19041798662970166]
	TIME [epoch: 41 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22566101193099922		[learning rate: 0.0011932]
	Learning Rate: 0.00119325
	LOSS [training: 0.22566101193099922 | validation: 0.19330706355279115]
	TIME [epoch: 41 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22371515720154664		[learning rate: 0.0011885]
	Learning Rate: 0.0011885
	LOSS [training: 0.22371515720154664 | validation: 0.18946687937651394]
	TIME [epoch: 41 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22746737700500608		[learning rate: 0.0011838]
	Learning Rate: 0.00118378
	LOSS [training: 0.22746737700500608 | validation: 0.19164352431055817]
	TIME [epoch: 41 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2198081030772242		[learning rate: 0.0011791]
	Learning Rate: 0.00117907
	LOSS [training: 0.2198081030772242 | validation: 0.19008428339025008]
	TIME [epoch: 41 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22733191155708374		[learning rate: 0.0011744]
	Learning Rate: 0.00117438
	LOSS [training: 0.22733191155708374 | validation: 0.1923323480859552]
	TIME [epoch: 41 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22930879671866858		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 0.22930879671866858 | validation: 0.19049005689135123]
	TIME [epoch: 41 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22268329875799375		[learning rate: 0.0011651]
	Learning Rate: 0.00116505
	LOSS [training: 0.22268329875799375 | validation: 0.19257286503116142]
	TIME [epoch: 41 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.21775051208730123		[learning rate: 0.0011604]
	Learning Rate: 0.00116042
	LOSS [training: 0.21775051208730123 | validation: 0.18716834308173905]
	TIME [epoch: 41 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23013797735166758		[learning rate: 0.0011558]
	Learning Rate: 0.00115581
	LOSS [training: 0.23013797735166758 | validation: 0.18608036083962298]
	TIME [epoch: 41 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22307253083740408		[learning rate: 0.0011512]
	Learning Rate: 0.00115121
	LOSS [training: 0.22307253083740408 | validation: 0.18576426202031887]
	TIME [epoch: 41 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23255689167008034		[learning rate: 0.0011466]
	Learning Rate: 0.00114663
	LOSS [training: 0.23255689167008034 | validation: 0.19101522353099687]
	TIME [epoch: 41 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23013412832984903		[learning rate: 0.0011421]
	Learning Rate: 0.00114207
	LOSS [training: 0.23013412832984903 | validation: 0.1968939602995912]
	TIME [epoch: 41 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23048450212629648		[learning rate: 0.0011375]
	Learning Rate: 0.00113753
	LOSS [training: 0.23048450212629648 | validation: 0.19353337187728137]
	TIME [epoch: 41 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22632886461528898		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.22632886461528898 | validation: 0.19176386004144932]
	TIME [epoch: 41 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23292512574771726		[learning rate: 0.0011285]
	Learning Rate: 0.0011285
	LOSS [training: 0.23292512574771726 | validation: 0.19124421448085663]
	TIME [epoch: 41 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23841333147258625		[learning rate: 0.001124]
	Learning Rate: 0.00112401
	LOSS [training: 0.23841333147258625 | validation: 0.18552969509977482]
	TIME [epoch: 41 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22861885603607904		[learning rate: 0.0011195]
	Learning Rate: 0.00111954
	LOSS [training: 0.22861885603607904 | validation: 0.18957821808879044]
	TIME [epoch: 41 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23034797940506216		[learning rate: 0.0011151]
	Learning Rate: 0.00111508
	LOSS [training: 0.23034797940506216 | validation: 0.19428715591761456]
	TIME [epoch: 41 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23086023354966073		[learning rate: 0.0011106]
	Learning Rate: 0.00111065
	LOSS [training: 0.23086023354966073 | validation: 0.1864616090493853]
	TIME [epoch: 41 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22938534288583373		[learning rate: 0.0011062]
	Learning Rate: 0.00110623
	LOSS [training: 0.22938534288583373 | validation: 0.1907097431244244]
	TIME [epoch: 41 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22177241406281284		[learning rate: 0.0011018]
	Learning Rate: 0.00110183
	LOSS [training: 0.22177241406281284 | validation: 0.18651332919987643]
	TIME [epoch: 41 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22700504232673036		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 0.22700504232673036 | validation: 0.19017750141264705]
	TIME [epoch: 41 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23128217273635596		[learning rate: 0.0010931]
	Learning Rate: 0.00109309
	LOSS [training: 0.23128217273635596 | validation: 0.19103986873885886]
	TIME [epoch: 41 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22036298000526727		[learning rate: 0.0010887]
	Learning Rate: 0.00108874
	LOSS [training: 0.22036298000526727 | validation: 0.1920220003528599]
	TIME [epoch: 40.9 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2225668992346906		[learning rate: 0.0010844]
	Learning Rate: 0.00108441
	LOSS [training: 0.2225668992346906 | validation: 0.18772110992401375]
	TIME [epoch: 40.9 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22920310422666748		[learning rate: 0.0010801]
	Learning Rate: 0.00108009
	LOSS [training: 0.22920310422666748 | validation: 0.19070709896595]
	TIME [epoch: 40.9 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2245446328325747		[learning rate: 0.0010758]
	Learning Rate: 0.0010758
	LOSS [training: 0.2245446328325747 | validation: 0.19531849879518015]
	TIME [epoch: 40.9 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22071623085852887		[learning rate: 0.0010715]
	Learning Rate: 0.00107152
	LOSS [training: 0.22071623085852887 | validation: 0.1879274086954387]
	TIME [epoch: 40.9 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22383215137845028		[learning rate: 0.0010673]
	Learning Rate: 0.00106726
	LOSS [training: 0.22383215137845028 | validation: 0.18722246149833205]
	TIME [epoch: 40.9 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22942394287774498		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 0.22942394287774498 | validation: 0.18941993099650098]
	TIME [epoch: 40.9 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22819072045446165		[learning rate: 0.0010588]
	Learning Rate: 0.00105878
	LOSS [training: 0.22819072045446165 | validation: 0.18089677496105094]
	TIME [epoch: 40.9 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v13_20240716_142646/states/model_facs_v2_dec1b_2dpca_v13_608.pth
	Model improved!!!
EPOCH 609/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22808215488178693		[learning rate: 0.0010546]
	Learning Rate: 0.00105457
	LOSS [training: 0.22808215488178693 | validation: 0.19083303170918073]
	TIME [epoch: 41 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2248021482648736		[learning rate: 0.0010504]
	Learning Rate: 0.00105038
	LOSS [training: 0.2248021482648736 | validation: 0.188825770465282]
	TIME [epoch: 41 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22827863644767485		[learning rate: 0.0010462]
	Learning Rate: 0.0010462
	LOSS [training: 0.22827863644767485 | validation: 0.1853032104434424]
	TIME [epoch: 41 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22339765297823633		[learning rate: 0.001042]
	Learning Rate: 0.00104204
	LOSS [training: 0.22339765297823633 | validation: 0.1900279113462707]
	TIME [epoch: 41 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22851149044574123		[learning rate: 0.0010379]
	Learning Rate: 0.0010379
	LOSS [training: 0.22851149044574123 | validation: 0.1911599043676281]
	TIME [epoch: 41 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2250902156998357		[learning rate: 0.0010338]
	Learning Rate: 0.00103377
	LOSS [training: 0.2250902156998357 | validation: 0.1894953773827261]
	TIME [epoch: 41 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2262973598115719		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 0.2262973598115719 | validation: 0.18956199322698006]
	TIME [epoch: 41 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23050642752914596		[learning rate: 0.0010256]
	Learning Rate: 0.00102556
	LOSS [training: 0.23050642752914596 | validation: 0.19129809449204668]
	TIME [epoch: 41 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22359169661292697		[learning rate: 0.0010215]
	Learning Rate: 0.00102148
	LOSS [training: 0.22359169661292697 | validation: 0.18758779231407274]
	TIME [epoch: 41 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22718696448301257		[learning rate: 0.0010174]
	Learning Rate: 0.00101742
	LOSS [training: 0.22718696448301257 | validation: 0.18469284423564444]
	TIME [epoch: 41 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22725418801644745		[learning rate: 0.0010134]
	Learning Rate: 0.00101337
	LOSS [training: 0.22725418801644745 | validation: 0.19241927865146574]
	TIME [epoch: 41 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2258259373826055		[learning rate: 0.0010093]
	Learning Rate: 0.00100934
	LOSS [training: 0.2258259373826055 | validation: 0.1873359122711673]
	TIME [epoch: 41 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2290811969691039		[learning rate: 0.0010053]
	Learning Rate: 0.00100533
	LOSS [training: 0.2290811969691039 | validation: 0.19142596076600954]
	TIME [epoch: 41 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22287022073085705		[learning rate: 0.0010013]
	Learning Rate: 0.00100133
	LOSS [training: 0.22287022073085705 | validation: 0.18561499500685336]
	TIME [epoch: 41 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22412686860572728		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 0.22412686860572728 | validation: 0.185522517057643]
	TIME [epoch: 41 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2306291504320657		[learning rate: 0.00099338]
	Learning Rate: 0.00099338
	LOSS [training: 0.2306291504320657 | validation: 0.1839678693371447]
	TIME [epoch: 41 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22912093236669792		[learning rate: 0.00098943]
	Learning Rate: 0.000989429
	LOSS [training: 0.22912093236669792 | validation: 0.18898371353209203]
	TIME [epoch: 41 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2239301149573455		[learning rate: 0.00098549]
	Learning Rate: 0.000985494
	LOSS [training: 0.2239301149573455 | validation: 0.19149680389309168]
	TIME [epoch: 41 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22887120106339628		[learning rate: 0.00098157]
	Learning Rate: 0.000981574
	LOSS [training: 0.22887120106339628 | validation: 0.18987226758519388]
	TIME [epoch: 41 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2239917895605578		[learning rate: 0.00097767]
	Learning Rate: 0.00097767
	LOSS [training: 0.2239917895605578 | validation: 0.19237782013887184]
	TIME [epoch: 41 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23074036685930105		[learning rate: 0.00097378]
	Learning Rate: 0.000973782
	LOSS [training: 0.23074036685930105 | validation: 0.18598936520824022]
	TIME [epoch: 41 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2179764084631648		[learning rate: 0.00096991]
	Learning Rate: 0.000969909
	LOSS [training: 0.2179764084631648 | validation: 0.18765185367324635]
	TIME [epoch: 41 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2278851938680836		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.2278851938680836 | validation: 0.18899273788380666]
	TIME [epoch: 41 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2298626558631539		[learning rate: 0.00096221]
	Learning Rate: 0.000962209
	LOSS [training: 0.2298626558631539 | validation: 0.18725359785171328]
	TIME [epoch: 41 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2243414633087224		[learning rate: 0.00095838]
	Learning Rate: 0.000958382
	LOSS [training: 0.2243414633087224 | validation: 0.18668011390313147]
	TIME [epoch: 41 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2244806194584321		[learning rate: 0.00095457]
	Learning Rate: 0.00095457
	LOSS [training: 0.2244806194584321 | validation: 0.18849123817539976]
	TIME [epoch: 41 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22606740693127256		[learning rate: 0.00095077]
	Learning Rate: 0.000950773
	LOSS [training: 0.22606740693127256 | validation: 0.1866522417274535]
	TIME [epoch: 40.9 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22233708734283977		[learning rate: 0.00094699]
	Learning Rate: 0.000946992
	LOSS [training: 0.22233708734283977 | validation: 0.18844033737051977]
	TIME [epoch: 41 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22714291068373235		[learning rate: 0.00094323]
	Learning Rate: 0.000943225
	LOSS [training: 0.22714291068373235 | validation: 0.18614058942891906]
	TIME [epoch: 41 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23269251270433294		[learning rate: 0.00093947]
	Learning Rate: 0.000939474
	LOSS [training: 0.23269251270433294 | validation: 0.18760323317113292]
	TIME [epoch: 41 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23009727503032926		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.23009727503032926 | validation: 0.19310817064363578]
	TIME [epoch: 41 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22870637958572157		[learning rate: 0.00093202]
	Learning Rate: 0.000932015
	LOSS [training: 0.22870637958572157 | validation: 0.1909139261363258]
	TIME [epoch: 41 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23002226561605374		[learning rate: 0.00092831]
	Learning Rate: 0.000928309
	LOSS [training: 0.23002226561605374 | validation: 0.1931051657605079]
	TIME [epoch: 41 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2206397952711814		[learning rate: 0.00092462]
	Learning Rate: 0.000924616
	LOSS [training: 0.2206397952711814 | validation: 0.1845971261514444]
	TIME [epoch: 40.9 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2269308620770659		[learning rate: 0.00092094]
	Learning Rate: 0.000920939
	LOSS [training: 0.2269308620770659 | validation: 0.19136185128233532]
	TIME [epoch: 41 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22135817323679768		[learning rate: 0.00091728]
	Learning Rate: 0.000917276
	LOSS [training: 0.22135817323679768 | validation: 0.19545840766316255]
	TIME [epoch: 41 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2292424738428445		[learning rate: 0.00091363]
	Learning Rate: 0.000913628
	LOSS [training: 0.2292424738428445 | validation: 0.19295980986930839]
	TIME [epoch: 41 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2265060558331421		[learning rate: 0.00090999]
	Learning Rate: 0.000909994
	LOSS [training: 0.2265060558331421 | validation: 0.19340019905245237]
	TIME [epoch: 41 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23082412433871705		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.23082412433871705 | validation: 0.19268431551721737]
	TIME [epoch: 41 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22377857442804164		[learning rate: 0.00090277]
	Learning Rate: 0.00090277
	LOSS [training: 0.22377857442804164 | validation: 0.18711842924658054]
	TIME [epoch: 41 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22991396058183255		[learning rate: 0.00089918]
	Learning Rate: 0.000899179
	LOSS [training: 0.22991396058183255 | validation: 0.18994332749863796]
	TIME [epoch: 40.9 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22445296923511812		[learning rate: 0.0008956]
	Learning Rate: 0.000895603
	LOSS [training: 0.22445296923511812 | validation: 0.19392784316352496]
	TIME [epoch: 41 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22908291359502087		[learning rate: 0.00089204]
	Learning Rate: 0.000892041
	LOSS [training: 0.22908291359502087 | validation: 0.18796629760105182]
	TIME [epoch: 41 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2232150080819443		[learning rate: 0.00088849]
	Learning Rate: 0.000888493
	LOSS [training: 0.2232150080819443 | validation: 0.19263601280995796]
	TIME [epoch: 41 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22655746132714402		[learning rate: 0.00088496]
	Learning Rate: 0.000884959
	LOSS [training: 0.22655746132714402 | validation: 0.19635509951908506]
	TIME [epoch: 41 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22800229305196623		[learning rate: 0.00088144]
	Learning Rate: 0.000881439
	LOSS [training: 0.22800229305196623 | validation: 0.18639336024421715]
	TIME [epoch: 41 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22120417538269457		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 0.22120417538269457 | validation: 0.19281130757584988]
	TIME [epoch: 41 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22544623047696336		[learning rate: 0.00087444]
	Learning Rate: 0.000874441
	LOSS [training: 0.22544623047696336 | validation: 0.190160117757663]
	TIME [epoch: 41 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2241283408022866		[learning rate: 0.00087096]
	Learning Rate: 0.000870964
	LOSS [training: 0.2241283408022866 | validation: 0.18631270800074376]
	TIME [epoch: 41 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23020234343669602		[learning rate: 0.0008675]
	Learning Rate: 0.0008675
	LOSS [training: 0.23020234343669602 | validation: 0.18166037765760906]
	TIME [epoch: 40.9 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22437175756939798		[learning rate: 0.00086405]
	Learning Rate: 0.000864049
	LOSS [training: 0.22437175756939798 | validation: 0.18791480745471817]
	TIME [epoch: 41 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22499293001006254		[learning rate: 0.00086061]
	Learning Rate: 0.000860613
	LOSS [training: 0.22499293001006254 | validation: 0.19031288488196013]
	TIME [epoch: 41 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22179019968552766		[learning rate: 0.00085719]
	Learning Rate: 0.00085719
	LOSS [training: 0.22179019968552766 | validation: 0.19339256339654398]
	TIME [epoch: 40.9 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22839662820789608		[learning rate: 0.00085378]
	Learning Rate: 0.00085378
	LOSS [training: 0.22839662820789608 | validation: 0.1899152047951184]
	TIME [epoch: 41 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22233920369020094		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 0.22233920369020094 | validation: 0.19441881009312045]
	TIME [epoch: 41 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23073644152075412		[learning rate: 0.000847]
	Learning Rate: 0.000847002
	LOSS [training: 0.23073644152075412 | validation: 0.19716769192717506]
	TIME [epoch: 41 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22836888258844304		[learning rate: 0.00084363]
	Learning Rate: 0.000843634
	LOSS [training: 0.22836888258844304 | validation: 0.19738335070552154]
	TIME [epoch: 41 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22528227948982638		[learning rate: 0.00084028]
	Learning Rate: 0.000840278
	LOSS [training: 0.22528227948982638 | validation: 0.1892262844319854]
	TIME [epoch: 41 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22396017697973983		[learning rate: 0.00083694]
	Learning Rate: 0.000836936
	LOSS [training: 0.22396017697973983 | validation: 0.19240668399419697]
	TIME [epoch: 41 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22531822109506738		[learning rate: 0.00083361]
	Learning Rate: 0.000833608
	LOSS [training: 0.22531822109506738 | validation: 0.19265968613549284]
	TIME [epoch: 41 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2225758292729226		[learning rate: 0.00083029]
	Learning Rate: 0.000830292
	LOSS [training: 0.2225758292729226 | validation: 0.1819200274724811]
	TIME [epoch: 40.9 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22700847624440693		[learning rate: 0.00082699]
	Learning Rate: 0.00082699
	LOSS [training: 0.22700847624440693 | validation: 0.18878686799106587]
	TIME [epoch: 41 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22126194739232904		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.22126194739232904 | validation: 0.19293310348581844]
	TIME [epoch: 41 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22394809213773278		[learning rate: 0.00082042]
	Learning Rate: 0.000820424
	LOSS [training: 0.22394809213773278 | validation: 0.19441159003354053]
	TIME [epoch: 41 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22121986757309806		[learning rate: 0.00081716]
	Learning Rate: 0.000817161
	LOSS [training: 0.22121986757309806 | validation: 0.190604030959703]
	TIME [epoch: 41 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22225604301025786		[learning rate: 0.00081391]
	Learning Rate: 0.000813911
	LOSS [training: 0.22225604301025786 | validation: 0.1884481644410208]
	TIME [epoch: 41 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22756820296383967		[learning rate: 0.00081067]
	Learning Rate: 0.000810674
	LOSS [training: 0.22756820296383967 | validation: 0.19283404870940643]
	TIME [epoch: 41 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2268248801237207		[learning rate: 0.00080745]
	Learning Rate: 0.00080745
	LOSS [training: 0.2268248801237207 | validation: 0.1881584571171018]
	TIME [epoch: 41 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22179595852740278		[learning rate: 0.00080424]
	Learning Rate: 0.000804238
	LOSS [training: 0.22179595852740278 | validation: 0.19030040089069877]
	TIME [epoch: 41 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22264924074704254		[learning rate: 0.00080104]
	Learning Rate: 0.000801039
	LOSS [training: 0.22264924074704254 | validation: 0.18894810931757122]
	TIME [epoch: 41 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22058997062058838		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 0.22058997062058838 | validation: 0.1883364831867803]
	TIME [epoch: 40.9 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22303336195478918		[learning rate: 0.00079468]
	Learning Rate: 0.00079468
	LOSS [training: 0.22303336195478918 | validation: 0.18915315179245779]
	TIME [epoch: 41 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23020957673473275		[learning rate: 0.00079152]
	Learning Rate: 0.000791519
	LOSS [training: 0.23020957673473275 | validation: 0.18823097761131913]
	TIME [epoch: 40.9 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22816794305560123		[learning rate: 0.00078837]
	Learning Rate: 0.000788371
	LOSS [training: 0.22816794305560123 | validation: 0.196410290750544]
	TIME [epoch: 41 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2287644126322963		[learning rate: 0.00078524]
	Learning Rate: 0.000785236
	LOSS [training: 0.2287644126322963 | validation: 0.18704025555178155]
	TIME [epoch: 41 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.21911180548131975		[learning rate: 0.00078211]
	Learning Rate: 0.000782113
	LOSS [training: 0.21911180548131975 | validation: 0.18927730365879653]
	TIME [epoch: 41 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22935988134537302		[learning rate: 0.000779]
	Learning Rate: 0.000779002
	LOSS [training: 0.22935988134537302 | validation: 0.18888269601860558]
	TIME [epoch: 41 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.21921434223154634		[learning rate: 0.0007759]
	Learning Rate: 0.000775904
	LOSS [training: 0.21921434223154634 | validation: 0.18840748874528737]
	TIME [epoch: 41 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2249321216395462		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 0.2249321216395462 | validation: 0.1856909207476921]
	TIME [epoch: 41 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2348889800292272		[learning rate: 0.00076974]
	Learning Rate: 0.000769744
	LOSS [training: 0.2348889800292272 | validation: 0.18833032902050933]
	TIME [epoch: 41 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23021845611948485		[learning rate: 0.00076668]
	Learning Rate: 0.000766682
	LOSS [training: 0.23021845611948485 | validation: 0.1948798526564784]
	TIME [epoch: 41 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23002960065061856		[learning rate: 0.00076363]
	Learning Rate: 0.000763633
	LOSS [training: 0.23002960065061856 | validation: 0.18562748698764783]
	TIME [epoch: 41 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22347263414546933		[learning rate: 0.0007606]
	Learning Rate: 0.000760596
	LOSS [training: 0.22347263414546933 | validation: 0.1871348682010865]
	TIME [epoch: 40.9 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.230501087566955		[learning rate: 0.00075757]
	Learning Rate: 0.000757571
	LOSS [training: 0.230501087566955 | validation: 0.19154206492357378]
	TIME [epoch: 41 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2216295060040012		[learning rate: 0.00075456]
	Learning Rate: 0.000754557
	LOSS [training: 0.2216295060040012 | validation: 0.18676804493614635]
	TIME [epoch: 41 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2236483613515814		[learning rate: 0.00075156]
	Learning Rate: 0.000751556
	LOSS [training: 0.2236483613515814 | validation: 0.1882137976942615]
	TIME [epoch: 40.9 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22697573752552178		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 0.22697573752552178 | validation: 0.19003528660435623]
	TIME [epoch: 41 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2214934398080332		[learning rate: 0.00074559]
	Learning Rate: 0.00074559
	LOSS [training: 0.2214934398080332 | validation: 0.18450516664630026]
	TIME [epoch: 40.9 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22824704854335062		[learning rate: 0.00074262]
	Learning Rate: 0.000742624
	LOSS [training: 0.22824704854335062 | validation: 0.1882434146911513]
	TIME [epoch: 41 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22650534912510864		[learning rate: 0.00073967]
	Learning Rate: 0.000739671
	LOSS [training: 0.22650534912510864 | validation: 0.18705012059045772]
	TIME [epoch: 41 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22314767041862626		[learning rate: 0.00073673]
	Learning Rate: 0.000736729
	LOSS [training: 0.22314767041862626 | validation: 0.18503585545141074]
	TIME [epoch: 41 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22866931072214916		[learning rate: 0.0007338]
	Learning Rate: 0.000733799
	LOSS [training: 0.22866931072214916 | validation: 0.18876823034421805]
	TIME [epoch: 41 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23179508582474062		[learning rate: 0.00073088]
	Learning Rate: 0.00073088
	LOSS [training: 0.23179508582474062 | validation: 0.18679717156037037]
	TIME [epoch: 41 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2235178796861485		[learning rate: 0.00072797]
	Learning Rate: 0.000727973
	LOSS [training: 0.2235178796861485 | validation: 0.18719501675020744]
	TIME [epoch: 41 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22420225949718325		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 0.22420225949718325 | validation: 0.1878950185453388]
	TIME [epoch: 41 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22249388702135567		[learning rate: 0.00072219]
	Learning Rate: 0.000722194
	LOSS [training: 0.22249388702135567 | validation: 0.19344242104900725]
	TIME [epoch: 41 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23064224607836112		[learning rate: 0.00071932]
	Learning Rate: 0.000719322
	LOSS [training: 0.23064224607836112 | validation: 0.18686941320081493]
	TIME [epoch: 41 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22801939765852763		[learning rate: 0.00071646]
	Learning Rate: 0.000716461
	LOSS [training: 0.22801939765852763 | validation: 0.18552727871608604]
	TIME [epoch: 41 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22746144494914844		[learning rate: 0.00071361]
	Learning Rate: 0.000713611
	LOSS [training: 0.22746144494914844 | validation: 0.1852935229305813]
	TIME [epoch: 41 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22675363337942864		[learning rate: 0.00071077]
	Learning Rate: 0.000710773
	LOSS [training: 0.22675363337942864 | validation: 0.18705693154848504]
	TIME [epoch: 41 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22574645404226		[learning rate: 0.00070795]
	Learning Rate: 0.000707946
	LOSS [training: 0.22574645404226 | validation: 0.1869136070691163]
	TIME [epoch: 41 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22956405466577604		[learning rate: 0.00070513]
	Learning Rate: 0.00070513
	LOSS [training: 0.22956405466577604 | validation: 0.1891949653363363]
	TIME [epoch: 41 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22609779977624772		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.22609779977624772 | validation: 0.18776944512865137]
	TIME [epoch: 41 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22698121100115223		[learning rate: 0.00069953]
	Learning Rate: 0.000699532
	LOSS [training: 0.22698121100115223 | validation: 0.18588771180412295]
	TIME [epoch: 41 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22548550662764624		[learning rate: 0.00069675]
	Learning Rate: 0.00069675
	LOSS [training: 0.22548550662764624 | validation: 0.18913164710917124]
	TIME [epoch: 41 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22331447909998203		[learning rate: 0.00069398]
	Learning Rate: 0.000693979
	LOSS [training: 0.22331447909998203 | validation: 0.18274748388559775]
	TIME [epoch: 41 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23516329441758987		[learning rate: 0.00069122]
	Learning Rate: 0.000691219
	LOSS [training: 0.23516329441758987 | validation: 0.19144535283439007]
	TIME [epoch: 41 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22259770765966488		[learning rate: 0.00068847]
	Learning Rate: 0.000688469
	LOSS [training: 0.22259770765966488 | validation: 0.19434430215444048]
	TIME [epoch: 41 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22658746653060316		[learning rate: 0.00068573]
	Learning Rate: 0.000685731
	LOSS [training: 0.22658746653060316 | validation: 0.18735406647738875]
	TIME [epoch: 40.9 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2191318229059504		[learning rate: 0.000683]
	Learning Rate: 0.000683004
	LOSS [training: 0.2191318229059504 | validation: 0.18627376333972628]
	TIME [epoch: 41 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22436815419780126		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 0.22436815419780126 | validation: 0.1937442356399644]
	TIME [epoch: 41 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22939973097804986		[learning rate: 0.00067758]
	Learning Rate: 0.000677582
	LOSS [training: 0.22939973097804986 | validation: 0.19093630437784437]
	TIME [epoch: 41 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23681867009648686		[learning rate: 0.00067489]
	Learning Rate: 0.000674887
	LOSS [training: 0.23681867009648686 | validation: 0.18819411084665072]
	TIME [epoch: 41 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22178840617171353		[learning rate: 0.0006722]
	Learning Rate: 0.000672202
	LOSS [training: 0.22178840617171353 | validation: 0.1847078963484333]
	TIME [epoch: 41 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22182824041263455		[learning rate: 0.00066953]
	Learning Rate: 0.000669529
	LOSS [training: 0.22182824041263455 | validation: 0.1854545364391986]
	TIME [epoch: 41 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2256583539240284		[learning rate: 0.00066687]
	Learning Rate: 0.000666866
	LOSS [training: 0.2256583539240284 | validation: 0.19056721046114786]
	TIME [epoch: 41 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22440463916820605		[learning rate: 0.00066421]
	Learning Rate: 0.000664213
	LOSS [training: 0.22440463916820605 | validation: 0.18804456553099808]
	TIME [epoch: 41 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22660263152106414		[learning rate: 0.00066157]
	Learning Rate: 0.000661572
	LOSS [training: 0.22660263152106414 | validation: 0.1842099914346886]
	TIME [epoch: 41 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22433321851447097		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 0.22433321851447097 | validation: 0.19094109556442795]
	TIME [epoch: 41 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22481793737131017		[learning rate: 0.00065632]
	Learning Rate: 0.00065632
	LOSS [training: 0.22481793737131017 | validation: 0.18713072959863042]
	TIME [epoch: 41 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22452301340790382		[learning rate: 0.00065371]
	Learning Rate: 0.000653709
	LOSS [training: 0.22452301340790382 | validation: 0.19143112486962807]
	TIME [epoch: 41 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22605329058172682		[learning rate: 0.00065111]
	Learning Rate: 0.000651109
	LOSS [training: 0.22605329058172682 | validation: 0.19186915012803157]
	TIME [epoch: 41 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22969564484035432		[learning rate: 0.00064852]
	Learning Rate: 0.00064852
	LOSS [training: 0.22969564484035432 | validation: 0.19116576687294165]
	TIME [epoch: 41 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23175805518447604		[learning rate: 0.00064594]
	Learning Rate: 0.00064594
	LOSS [training: 0.23175805518447604 | validation: 0.18649640368321257]
	TIME [epoch: 41 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22473500514046885		[learning rate: 0.00064337]
	Learning Rate: 0.000643371
	LOSS [training: 0.22473500514046885 | validation: 0.19065319491729246]
	TIME [epoch: 41 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22762910021912694		[learning rate: 0.00064081]
	Learning Rate: 0.000640812
	LOSS [training: 0.22762910021912694 | validation: 0.1866216495983184]
	TIME [epoch: 41 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22170561854334433		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 0.22170561854334433 | validation: 0.18061376984235666]
	TIME [epoch: 41 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v13_20240716_142646/states/model_facs_v2_dec1b_2dpca_v13_735.pth
	Model improved!!!
EPOCH 736/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22890265789266534		[learning rate: 0.00063572]
	Learning Rate: 0.000635725
	LOSS [training: 0.22890265789266534 | validation: 0.1870150815968319]
	TIME [epoch: 41 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22106585091823014		[learning rate: 0.0006332]
	Learning Rate: 0.000633196
	LOSS [training: 0.22106585091823014 | validation: 0.18660119726374252]
	TIME [epoch: 41 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2297958820885381		[learning rate: 0.00063068]
	Learning Rate: 0.000630678
	LOSS [training: 0.2297958820885381 | validation: 0.18716288028042202]
	TIME [epoch: 41 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22372068867367975		[learning rate: 0.00062817]
	Learning Rate: 0.00062817
	LOSS [training: 0.22372068867367975 | validation: 0.191995315394298]
	TIME [epoch: 41 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22626190373597246		[learning rate: 0.00062567]
	Learning Rate: 0.000625671
	LOSS [training: 0.22626190373597246 | validation: 0.18160697979644133]
	TIME [epoch: 41.1 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22095353828335876		[learning rate: 0.00062318]
	Learning Rate: 0.000623183
	LOSS [training: 0.22095353828335876 | validation: 0.1941278588086769]
	TIME [epoch: 41 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22981678072710401		[learning rate: 0.0006207]
	Learning Rate: 0.000620704
	LOSS [training: 0.22981678072710401 | validation: 0.19357529429831644]
	TIME [epoch: 41 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22525269949566695		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 0.22525269949566695 | validation: 0.18714714339172686]
	TIME [epoch: 41 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22257831649661597		[learning rate: 0.00061578]
	Learning Rate: 0.000615777
	LOSS [training: 0.22257831649661597 | validation: 0.19096022058506262]
	TIME [epoch: 41 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22437946190858696		[learning rate: 0.00061333]
	Learning Rate: 0.000613327
	LOSS [training: 0.22437946190858696 | validation: 0.19033634365023785]
	TIME [epoch: 41 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2294808871714088		[learning rate: 0.00061089]
	Learning Rate: 0.000610888
	LOSS [training: 0.2294808871714088 | validation: 0.18675536158506928]
	TIME [epoch: 41 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22211703231744054		[learning rate: 0.00060846]
	Learning Rate: 0.000608458
	LOSS [training: 0.22211703231744054 | validation: 0.1850227177499046]
	TIME [epoch: 40.9 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2214310269959791		[learning rate: 0.00060604]
	Learning Rate: 0.000606038
	LOSS [training: 0.2214310269959791 | validation: 0.1872699805186791]
	TIME [epoch: 41 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22527995985407204		[learning rate: 0.00060363]
	Learning Rate: 0.000603628
	LOSS [training: 0.22527995985407204 | validation: 0.18807207054958758]
	TIME [epoch: 41 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2208155990822062		[learning rate: 0.00060123]
	Learning Rate: 0.000601227
	LOSS [training: 0.2208155990822062 | validation: 0.18981592462945435]
	TIME [epoch: 41 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22871418425382048		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.22871418425382048 | validation: 0.19099319108411084]
	TIME [epoch: 41.1 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22269074275047837		[learning rate: 0.00059645]
	Learning Rate: 0.000596454
	LOSS [training: 0.22269074275047837 | validation: 0.18005139255874428]
	TIME [epoch: 41 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v13_20240716_142646/states/model_facs_v2_dec1b_2dpca_v13_752.pth
	Model improved!!!
EPOCH 753/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22805229016854373		[learning rate: 0.00059408]
	Learning Rate: 0.000594082
	LOSS [training: 0.22805229016854373 | validation: 0.18949788143210372]
	TIME [epoch: 41 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23017441208423747		[learning rate: 0.00059172]
	Learning Rate: 0.000591719
	LOSS [training: 0.23017441208423747 | validation: 0.19158110315727925]
	TIME [epoch: 41 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22021237996061988		[learning rate: 0.00058937]
	Learning Rate: 0.000589365
	LOSS [training: 0.22021237996061988 | validation: 0.18906125659954187]
	TIME [epoch: 41 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22479747798668562		[learning rate: 0.00058702]
	Learning Rate: 0.000587021
	LOSS [training: 0.22479747798668562 | validation: 0.19112959985967914]
	TIME [epoch: 41 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22573455643336693		[learning rate: 0.00058469]
	Learning Rate: 0.000584687
	LOSS [training: 0.22573455643336693 | validation: 0.19024994099593406]
	TIME [epoch: 41 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22774636979667914		[learning rate: 0.00058236]
	Learning Rate: 0.000582361
	LOSS [training: 0.22774636979667914 | validation: 0.1910990291436598]
	TIME [epoch: 41 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22423106011976118		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 0.22423106011976118 | validation: 0.19046372393679767]
	TIME [epoch: 41 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2244184843535083		[learning rate: 0.00057774]
	Learning Rate: 0.000577738
	LOSS [training: 0.2244184843535083 | validation: 0.18745420611875255]
	TIME [epoch: 41 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2225510700005499		[learning rate: 0.00057544]
	Learning Rate: 0.00057544
	LOSS [training: 0.2225510700005499 | validation: 0.1851163213006568]
	TIME [epoch: 41 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2195856859530805		[learning rate: 0.00057315]
	Learning Rate: 0.000573151
	LOSS [training: 0.2195856859530805 | validation: 0.1875411903029905]
	TIME [epoch: 41 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2287952500365864		[learning rate: 0.00057087]
	Learning Rate: 0.000570872
	LOSS [training: 0.2287952500365864 | validation: 0.18511512155737284]
	TIME [epoch: 41 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22101297044764376		[learning rate: 0.0005686]
	Learning Rate: 0.000568601
	LOSS [training: 0.22101297044764376 | validation: 0.19156025682709982]
	TIME [epoch: 41 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2238055558768618		[learning rate: 0.00056634]
	Learning Rate: 0.00056634
	LOSS [training: 0.2238055558768618 | validation: 0.18982309342438247]
	TIME [epoch: 41 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22801820035961923		[learning rate: 0.00056409]
	Learning Rate: 0.000564087
	LOSS [training: 0.22801820035961923 | validation: 0.18474837272956726]
	TIME [epoch: 41 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22617836522614942		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 0.22617836522614942 | validation: 0.19014831225176101]
	TIME [epoch: 41 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22428895839760868		[learning rate: 0.00055961]
	Learning Rate: 0.000559609
	LOSS [training: 0.22428895839760868 | validation: 0.18403337913186807]
	TIME [epoch: 41 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22601882909646262		[learning rate: 0.00055738]
	Learning Rate: 0.000557383
	LOSS [training: 0.22601882909646262 | validation: 0.18293136809856242]
	TIME [epoch: 41 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22649961577582786		[learning rate: 0.00055517]
	Learning Rate: 0.000555166
	LOSS [training: 0.22649961577582786 | validation: 0.19053443264633554]
	TIME [epoch: 41 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.21792639669698957		[learning rate: 0.00055296]
	Learning Rate: 0.000552958
	LOSS [training: 0.21792639669698957 | validation: 0.18478868908985285]
	TIME [epoch: 41 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23539818662558198		[learning rate: 0.00055076]
	Learning Rate: 0.000550759
	LOSS [training: 0.23539818662558198 | validation: 0.18741023410361662]
	TIME [epoch: 41 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2209499077717327		[learning rate: 0.00054857]
	Learning Rate: 0.000548568
	LOSS [training: 0.2209499077717327 | validation: 0.19648650710631044]
	TIME [epoch: 41 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22321577220060362		[learning rate: 0.00054639]
	Learning Rate: 0.000546387
	LOSS [training: 0.22321577220060362 | validation: 0.18925590917058868]
	TIME [epoch: 41 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.21978562573822746		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 0.21978562573822746 | validation: 0.19018006276400837]
	TIME [epoch: 40.9 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22537090802457144		[learning rate: 0.00054205]
	Learning Rate: 0.000542049
	LOSS [training: 0.22537090802457144 | validation: 0.18874264510110958]
	TIME [epoch: 41 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2200631102114844		[learning rate: 0.00053989]
	Learning Rate: 0.000539893
	LOSS [training: 0.2200631102114844 | validation: 0.18333265041905805]
	TIME [epoch: 41 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2242892773744318		[learning rate: 0.00053775]
	Learning Rate: 0.000537746
	LOSS [training: 0.2242892773744318 | validation: 0.1882313082956481]
	TIME [epoch: 41 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22118519674999745		[learning rate: 0.00053561]
	Learning Rate: 0.000535607
	LOSS [training: 0.22118519674999745 | validation: 0.1891651876880477]
	TIME [epoch: 41 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22137864695519377		[learning rate: 0.00053348]
	Learning Rate: 0.000533477
	LOSS [training: 0.22137864695519377 | validation: 0.1872021239782429]
	TIME [epoch: 41 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2232119846130734		[learning rate: 0.00053135]
	Learning Rate: 0.000531355
	LOSS [training: 0.2232119846130734 | validation: 0.1847268599608783]
	TIME [epoch: 41 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22301571910200257		[learning rate: 0.00052924]
	Learning Rate: 0.000529241
	LOSS [training: 0.22301571910200257 | validation: 0.18111925813466717]
	TIME [epoch: 41 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22007504392836766		[learning rate: 0.00052714]
	Learning Rate: 0.000527136
	LOSS [training: 0.22007504392836766 | validation: 0.18702246514205867]
	TIME [epoch: 41 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2221641294947628		[learning rate: 0.00052504]
	Learning Rate: 0.00052504
	LOSS [training: 0.2221641294947628 | validation: 0.186996985687163]
	TIME [epoch: 41 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2237901252277027		[learning rate: 0.00052295]
	Learning Rate: 0.000522952
	LOSS [training: 0.2237901252277027 | validation: 0.1903172422244619]
	TIME [epoch: 41 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22392312193547767		[learning rate: 0.00052087]
	Learning Rate: 0.000520872
	LOSS [training: 0.22392312193547767 | validation: 0.1897333635245073]
	TIME [epoch: 41 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22004660239568985		[learning rate: 0.0005188]
	Learning Rate: 0.0005188
	LOSS [training: 0.22004660239568985 | validation: 0.18730131812470865]
	TIME [epoch: 41 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2209941187277969		[learning rate: 0.00051674]
	Learning Rate: 0.000516737
	LOSS [training: 0.2209941187277969 | validation: 0.18719575990187037]
	TIME [epoch: 41 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22188131224647253		[learning rate: 0.00051468]
	Learning Rate: 0.000514681
	LOSS [training: 0.22188131224647253 | validation: 0.18847717526614086]
	TIME [epoch: 41 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22444710981141267		[learning rate: 0.00051263]
	Learning Rate: 0.000512634
	LOSS [training: 0.22444710981141267 | validation: 0.18790428861781255]
	TIME [epoch: 41 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2251942896132485		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 0.2251942896132485 | validation: 0.1866623013937598]
	TIME [epoch: 41 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22364124597317847		[learning rate: 0.00050856]
	Learning Rate: 0.000508565
	LOSS [training: 0.22364124597317847 | validation: 0.18616249380941965]
	TIME [epoch: 41 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22433864527346595		[learning rate: 0.00050654]
	Learning Rate: 0.000506542
	LOSS [training: 0.22433864527346595 | validation: 0.18609805532450532]
	TIME [epoch: 41 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22943366238742247		[learning rate: 0.00050453]
	Learning Rate: 0.000504527
	LOSS [training: 0.22943366238742247 | validation: 0.18571883502323167]
	TIME [epoch: 41 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2307381631596527		[learning rate: 0.00050252]
	Learning Rate: 0.000502521
	LOSS [training: 0.2307381631596527 | validation: 0.18538133181823585]
	TIME [epoch: 41 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2249697648841953		[learning rate: 0.00050052]
	Learning Rate: 0.000500522
	LOSS [training: 0.2249697648841953 | validation: 0.1810976469397239]
	TIME [epoch: 41 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22276520334234012		[learning rate: 0.00049853]
	Learning Rate: 0.000498531
	LOSS [training: 0.22276520334234012 | validation: 0.19147260958917472]
	TIME [epoch: 41 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23079031873891237		[learning rate: 0.00049655]
	Learning Rate: 0.000496548
	LOSS [training: 0.23079031873891237 | validation: 0.18881135887661307]
	TIME [epoch: 41 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2236711673738522		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 0.2236711673738522 | validation: 0.18704747109781067]
	TIME [epoch: 41 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2265591356162498		[learning rate: 0.00049261]
	Learning Rate: 0.000492606
	LOSS [training: 0.2265591356162498 | validation: 0.18856237161255723]
	TIME [epoch: 41 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22640581750689887		[learning rate: 0.00049065]
	Learning Rate: 0.000490647
	LOSS [training: 0.22640581750689887 | validation: 0.1860845972624697]
	TIME [epoch: 41 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22817458020657877		[learning rate: 0.0004887]
	Learning Rate: 0.000488696
	LOSS [training: 0.22817458020657877 | validation: 0.1877608919053167]
	TIME [epoch: 41 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.21859661766279156		[learning rate: 0.00048675]
	Learning Rate: 0.000486752
	LOSS [training: 0.21859661766279156 | validation: 0.1839217831330685]
	TIME [epoch: 41 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22905530322662285		[learning rate: 0.00048482]
	Learning Rate: 0.000484816
	LOSS [training: 0.22905530322662285 | validation: 0.18968578231076913]
	TIME [epoch: 41 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2186246581511647		[learning rate: 0.00048289]
	Learning Rate: 0.000482888
	LOSS [training: 0.2186246581511647 | validation: 0.1885760391466791]
	TIME [epoch: 41 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2236613257499917		[learning rate: 0.00048097]
	Learning Rate: 0.000480967
	LOSS [training: 0.2236613257499917 | validation: 0.18751484074715163]
	TIME [epoch: 41 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22377420283625893		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 0.22377420283625893 | validation: 0.1868865011778592]
	TIME [epoch: 41 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22854913081170924		[learning rate: 0.00047715]
	Learning Rate: 0.000477149
	LOSS [training: 0.22854913081170924 | validation: 0.18405605391070912]
	TIME [epoch: 41 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22301708548614518		[learning rate: 0.00047525]
	Learning Rate: 0.000475251
	LOSS [training: 0.22301708548614518 | validation: 0.19210411397257124]
	TIME [epoch: 41 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22345500843471747		[learning rate: 0.00047336]
	Learning Rate: 0.000473361
	LOSS [training: 0.22345500843471747 | validation: 0.18880972776915544]
	TIME [epoch: 40.9 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22110792515231661		[learning rate: 0.00047148]
	Learning Rate: 0.000471478
	LOSS [training: 0.22110792515231661 | validation: 0.19412594290419422]
	TIME [epoch: 41 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22739711043257868		[learning rate: 0.0004696]
	Learning Rate: 0.000469603
	LOSS [training: 0.22739711043257868 | validation: 0.1870941250313347]
	TIME [epoch: 40.9 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22593398944456883		[learning rate: 0.00046774]
	Learning Rate: 0.000467735
	LOSS [training: 0.22593398944456883 | validation: 0.1865905250667542]
	TIME [epoch: 40.9 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2235388068182726		[learning rate: 0.00046587]
	Learning Rate: 0.000465875
	LOSS [training: 0.2235388068182726 | validation: 0.1893988171009613]
	TIME [epoch: 40.9 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22319307401527347		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 0.22319307401527347 | validation: 0.18390263617339195]
	TIME [epoch: 41 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22036709227167192		[learning rate: 0.00046218]
	Learning Rate: 0.000462176
	LOSS [training: 0.22036709227167192 | validation: 0.18620916747378258]
	TIME [epoch: 41 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22552350901455093		[learning rate: 0.00046034]
	Learning Rate: 0.000460338
	LOSS [training: 0.22552350901455093 | validation: 0.18802739698437979]
	TIME [epoch: 41 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22529882661403627		[learning rate: 0.00045851]
	Learning Rate: 0.000458507
	LOSS [training: 0.22529882661403627 | validation: 0.188388438908825]
	TIME [epoch: 41 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22690695949732398		[learning rate: 0.00045668]
	Learning Rate: 0.000456684
	LOSS [training: 0.22690695949732398 | validation: 0.18463836936669403]
	TIME [epoch: 41 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22562203260273594		[learning rate: 0.00045487]
	Learning Rate: 0.000454867
	LOSS [training: 0.22562203260273594 | validation: 0.1916141800156505]
	TIME [epoch: 41 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22677820330479964		[learning rate: 0.00045306]
	Learning Rate: 0.000453058
	LOSS [training: 0.22677820330479964 | validation: 0.18765051753195894]
	TIME [epoch: 40.9 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22171101990607275		[learning rate: 0.00045126]
	Learning Rate: 0.000451256
	LOSS [training: 0.22171101990607275 | validation: 0.18923666571004089]
	TIME [epoch: 41 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2285832887749054		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 0.2285832887749054 | validation: 0.1921059434919729]
	TIME [epoch: 40.9 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22852576528707125		[learning rate: 0.00044767]
	Learning Rate: 0.000447674
	LOSS [training: 0.22852576528707125 | validation: 0.18787512727763817]
	TIME [epoch: 41 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.21350238379148062		[learning rate: 0.00044589]
	Learning Rate: 0.000445893
	LOSS [training: 0.21350238379148062 | validation: 0.18858215770029294]
	TIME [epoch: 41 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22159672415002818		[learning rate: 0.00044412]
	Learning Rate: 0.00044412
	LOSS [training: 0.22159672415002818 | validation: 0.1881156911853763]
	TIME [epoch: 41 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.21813597438726143		[learning rate: 0.00044235]
	Learning Rate: 0.000442353
	LOSS [training: 0.21813597438726143 | validation: 0.19211424280766515]
	TIME [epoch: 41 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22196311063469104		[learning rate: 0.00044059]
	Learning Rate: 0.000440594
	LOSS [training: 0.22196311063469104 | validation: 0.18482200451033293]
	TIME [epoch: 41 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22539813418628116		[learning rate: 0.00043884]
	Learning Rate: 0.000438842
	LOSS [training: 0.22539813418628116 | validation: 0.187067489421194]
	TIME [epoch: 40.9 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2219879836697665		[learning rate: 0.0004371]
	Learning Rate: 0.000437096
	LOSS [training: 0.2219879836697665 | validation: 0.1887981256743253]
	TIME [epoch: 41 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22015596397959042		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 0.22015596397959042 | validation: 0.1854637478191146]
	TIME [epoch: 40.9 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22590894939173684		[learning rate: 0.00043363]
	Learning Rate: 0.000433626
	LOSS [training: 0.22590894939173684 | validation: 0.18632594488814821]
	TIME [epoch: 40.9 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22181616635044935		[learning rate: 0.0004319]
	Learning Rate: 0.000431901
	LOSS [training: 0.22181616635044935 | validation: 0.18916727985377152]
	TIME [epoch: 40.9 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22292007401987915		[learning rate: 0.00043018]
	Learning Rate: 0.000430184
	LOSS [training: 0.22292007401987915 | validation: 0.19198450825668223]
	TIME [epoch: 41 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2251958964809552		[learning rate: 0.00042847]
	Learning Rate: 0.000428473
	LOSS [training: 0.2251958964809552 | validation: 0.18562571016841978]
	TIME [epoch: 41 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22709114330278643		[learning rate: 0.00042677]
	Learning Rate: 0.000426768
	LOSS [training: 0.22709114330278643 | validation: 0.1902203844538242]
	TIME [epoch: 41 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22438384348297497		[learning rate: 0.00042507]
	Learning Rate: 0.000425071
	LOSS [training: 0.22438384348297497 | validation: 0.19393182635212708]
	TIME [epoch: 41 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22631597023228472		[learning rate: 0.00042338]
	Learning Rate: 0.00042338
	LOSS [training: 0.22631597023228472 | validation: 0.1863720472095774]
	TIME [epoch: 41 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2231979749691598		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 0.2231979749691598 | validation: 0.1924518730065123]
	TIME [epoch: 41 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22132999030761424		[learning rate: 0.00042002]
	Learning Rate: 0.000420019
	LOSS [training: 0.22132999030761424 | validation: 0.19541053400594688]
	TIME [epoch: 41 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22423617152355113		[learning rate: 0.00041835]
	Learning Rate: 0.000418349
	LOSS [training: 0.22423617152355113 | validation: 0.18799300659587187]
	TIME [epoch: 40.9 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22505069826661991		[learning rate: 0.00041668]
	Learning Rate: 0.000416685
	LOSS [training: 0.22505069826661991 | validation: 0.1949077225754726]
	TIME [epoch: 41 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22233389247571855		[learning rate: 0.00041503]
	Learning Rate: 0.000415028
	LOSS [training: 0.22233389247571855 | validation: 0.1875629830123507]
	TIME [epoch: 41 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22827546222185077		[learning rate: 0.00041338]
	Learning Rate: 0.000413377
	LOSS [training: 0.22827546222185077 | validation: 0.1907513136226399]
	TIME [epoch: 41 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22688411755868218		[learning rate: 0.00041173]
	Learning Rate: 0.000411733
	LOSS [training: 0.22688411755868218 | validation: 0.18585114283671209]
	TIME [epoch: 41 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22645291785389057		[learning rate: 0.0004101]
	Learning Rate: 0.000410095
	LOSS [training: 0.22645291785389057 | validation: 0.18846203203274786]
	TIME [epoch: 41 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22462494914315892		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 0.22462494914315892 | validation: 0.19246278595584596]
	TIME [epoch: 41 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2237631818224961		[learning rate: 0.00040684]
	Learning Rate: 0.00040684
	LOSS [training: 0.2237631818224961 | validation: 0.19344376150963208]
	TIME [epoch: 41 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22388570379706962		[learning rate: 0.00040522]
	Learning Rate: 0.000405221
	LOSS [training: 0.22388570379706962 | validation: 0.1897989935991078]
	TIME [epoch: 41.1 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22746927367627467		[learning rate: 0.00040361]
	Learning Rate: 0.00040361
	LOSS [training: 0.22746927367627467 | validation: 0.19173032817578717]
	TIME [epoch: 41 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22237356979062733		[learning rate: 0.000402]
	Learning Rate: 0.000402004
	LOSS [training: 0.22237356979062733 | validation: 0.19232477961775765]
	TIME [epoch: 41.1 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22149421851931375		[learning rate: 0.00040041]
	Learning Rate: 0.000400406
	LOSS [training: 0.22149421851931375 | validation: 0.1861532299098481]
	TIME [epoch: 41 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22725059011791635		[learning rate: 0.00039881]
	Learning Rate: 0.000398813
	LOSS [training: 0.22725059011791635 | validation: 0.1897608533012532]
	TIME [epoch: 41 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.21965707339207943		[learning rate: 0.00039723]
	Learning Rate: 0.000397227
	LOSS [training: 0.21965707339207943 | validation: 0.19007173418579484]
	TIME [epoch: 41 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22714127802665496		[learning rate: 0.00039565]
	Learning Rate: 0.000395647
	LOSS [training: 0.22714127802665496 | validation: 0.19495338912153143]
	TIME [epoch: 41 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22891022081046442		[learning rate: 0.00039407]
	Learning Rate: 0.000394073
	LOSS [training: 0.22891022081046442 | validation: 0.18883863920395214]
	TIME [epoch: 41.1 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22712963490598836		[learning rate: 0.00039251]
	Learning Rate: 0.000392506
	LOSS [training: 0.22712963490598836 | validation: 0.18970075046400323]
	TIME [epoch: 41 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2263193043257074		[learning rate: 0.00039094]
	Learning Rate: 0.000390945
	LOSS [training: 0.2263193043257074 | validation: 0.18886738016347765]
	TIME [epoch: 41 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.221081783103512		[learning rate: 0.00038939]
	Learning Rate: 0.00038939
	LOSS [training: 0.221081783103512 | validation: 0.18991057852663157]
	TIME [epoch: 41 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22669442137897672		[learning rate: 0.00038784]
	Learning Rate: 0.000387841
	LOSS [training: 0.22669442137897672 | validation: 0.1885113364173832]
	TIME [epoch: 41 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22310922512552192		[learning rate: 0.0003863]
	Learning Rate: 0.000386299
	LOSS [training: 0.22310922512552192 | validation: 0.18943418378091495]
	TIME [epoch: 41 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22468571304209128		[learning rate: 0.00038476]
	Learning Rate: 0.000384762
	LOSS [training: 0.22468571304209128 | validation: 0.1885163359231083]
	TIME [epoch: 41 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2241349448432683		[learning rate: 0.00038323]
	Learning Rate: 0.000383232
	LOSS [training: 0.2241349448432683 | validation: 0.18993509514599732]
	TIME [epoch: 41.1 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.21826604730462454		[learning rate: 0.00038171]
	Learning Rate: 0.000381708
	LOSS [training: 0.21826604730462454 | validation: 0.18661058643259143]
	TIME [epoch: 41.1 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2256527108910237		[learning rate: 0.00038019]
	Learning Rate: 0.000380189
	LOSS [training: 0.2256527108910237 | validation: 0.19173359121421327]
	TIME [epoch: 41 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22124751503031537		[learning rate: 0.00037868]
	Learning Rate: 0.000378677
	LOSS [training: 0.22124751503031537 | validation: 0.187384379510749]
	TIME [epoch: 41.1 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22734848081906925		[learning rate: 0.00037717]
	Learning Rate: 0.000377171
	LOSS [training: 0.22734848081906925 | validation: 0.1861629780141138]
	TIME [epoch: 41.1 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22570469744304977		[learning rate: 0.00037567]
	Learning Rate: 0.000375671
	LOSS [training: 0.22570469744304977 | validation: 0.18994811001293302]
	TIME [epoch: 41.1 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.21984288801666158		[learning rate: 0.00037418]
	Learning Rate: 0.000374177
	LOSS [training: 0.21984288801666158 | validation: 0.1866508686594467]
	TIME [epoch: 41 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22604530711634593		[learning rate: 0.00037269]
	Learning Rate: 0.000372689
	LOSS [training: 0.22604530711634593 | validation: 0.188484721012535]
	TIME [epoch: 41.1 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2227913566002152		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 0.2227913566002152 | validation: 0.18781876220036023]
	TIME [epoch: 41.1 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22563805142884164		[learning rate: 0.00036973]
	Learning Rate: 0.00036973
	LOSS [training: 0.22563805142884164 | validation: 0.18981970002757703]
	TIME [epoch: 41.1 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2231533037694506		[learning rate: 0.00036826]
	Learning Rate: 0.000368259
	LOSS [training: 0.2231533037694506 | validation: 0.18732349693139352]
	TIME [epoch: 41.1 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2231822089964501		[learning rate: 0.00036679]
	Learning Rate: 0.000366795
	LOSS [training: 0.2231822089964501 | validation: 0.19548725810283143]
	TIME [epoch: 41.1 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22867893461936242		[learning rate: 0.00036534]
	Learning Rate: 0.000365336
	LOSS [training: 0.22867893461936242 | validation: 0.1905149120554423]
	TIME [epoch: 41 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22580518825537144		[learning rate: 0.00036388]
	Learning Rate: 0.000363883
	LOSS [training: 0.22580518825537144 | validation: 0.18683990066724374]
	TIME [epoch: 41.1 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2266662717538201		[learning rate: 0.00036244]
	Learning Rate: 0.000362436
	LOSS [training: 0.2266662717538201 | validation: 0.1892155898767426]
	TIME [epoch: 41.1 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22567415439563765		[learning rate: 0.00036099]
	Learning Rate: 0.000360994
	LOSS [training: 0.22567415439563765 | validation: 0.19241979567916023]
	TIME [epoch: 41.1 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2263881658505785		[learning rate: 0.00035956]
	Learning Rate: 0.000359558
	LOSS [training: 0.2263881658505785 | validation: 0.1905045376324842]
	TIME [epoch: 41.1 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.221872518891164		[learning rate: 0.00035813]
	Learning Rate: 0.000358128
	LOSS [training: 0.221872518891164 | validation: 0.19296898434313642]
	TIME [epoch: 41.1 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2203586905254736		[learning rate: 0.0003567]
	Learning Rate: 0.000356704
	LOSS [training: 0.2203586905254736 | validation: 0.18661106741454384]
	TIME [epoch: 41.1 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2205724098487022		[learning rate: 0.00035529]
	Learning Rate: 0.000355285
	LOSS [training: 0.2205724098487022 | validation: 0.1971624732255363]
	TIME [epoch: 41.1 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22444362804532186		[learning rate: 0.00035387]
	Learning Rate: 0.000353872
	LOSS [training: 0.22444362804532186 | validation: 0.18909771966682004]
	TIME [epoch: 41 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2312969625737606		[learning rate: 0.00035246]
	Learning Rate: 0.000352465
	LOSS [training: 0.2312969625737606 | validation: 0.18879474224619852]
	TIME [epoch: 41.1 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23277386299336364		[learning rate: 0.00035106]
	Learning Rate: 0.000351063
	LOSS [training: 0.23277386299336364 | validation: 0.19247824212265247]
	TIME [epoch: 41 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22334187863184102		[learning rate: 0.00034967]
	Learning Rate: 0.000349666
	LOSS [training: 0.22334187863184102 | validation: 0.18278903496079324]
	TIME [epoch: 41 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22536839744699286		[learning rate: 0.00034828]
	Learning Rate: 0.000348276
	LOSS [training: 0.22536839744699286 | validation: 0.1857127049411036]
	TIME [epoch: 41 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22474873761944186		[learning rate: 0.00034689]
	Learning Rate: 0.000346891
	LOSS [training: 0.22474873761944186 | validation: 0.19044717917596207]
	TIME [epoch: 41.1 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22802313325765855		[learning rate: 0.00034551]
	Learning Rate: 0.000345511
	LOSS [training: 0.22802313325765855 | validation: 0.1849044031648971]
	TIME [epoch: 41 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22617169068164422		[learning rate: 0.00034414]
	Learning Rate: 0.000344137
	LOSS [training: 0.22617169068164422 | validation: 0.1870329970424033]
	TIME [epoch: 41 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22249382559700295		[learning rate: 0.00034277]
	Learning Rate: 0.000342768
	LOSS [training: 0.22249382559700295 | validation: 0.18898692152817115]
	TIME [epoch: 41 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22158451758381154		[learning rate: 0.0003414]
	Learning Rate: 0.000341405
	LOSS [training: 0.22158451758381154 | validation: 0.18615541165583763]
	TIME [epoch: 41.1 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2224060719624992		[learning rate: 0.00034005]
	Learning Rate: 0.000340047
	LOSS [training: 0.2224060719624992 | validation: 0.19028082429815188]
	TIME [epoch: 41.1 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2235742197148899		[learning rate: 0.00033869]
	Learning Rate: 0.000338694
	LOSS [training: 0.2235742197148899 | validation: 0.1916879424276516]
	TIME [epoch: 41.1 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22557614292513614		[learning rate: 0.00033735]
	Learning Rate: 0.000337347
	LOSS [training: 0.22557614292513614 | validation: 0.1891522135966937]
	TIME [epoch: 41 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22258508585129652		[learning rate: 0.00033601]
	Learning Rate: 0.000336005
	LOSS [training: 0.22258508585129652 | validation: 0.18950337834415368]
	TIME [epoch: 41.1 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.221636058699435		[learning rate: 0.00033467]
	Learning Rate: 0.000334669
	LOSS [training: 0.221636058699435 | validation: 0.1936352254705914]
	TIME [epoch: 41 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2143084837015224		[learning rate: 0.00033334]
	Learning Rate: 0.000333338
	LOSS [training: 0.2143084837015224 | validation: 0.18942310878223959]
	TIME [epoch: 41.1 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22194565172552957		[learning rate: 0.00033201]
	Learning Rate: 0.000332012
	LOSS [training: 0.22194565172552957 | validation: 0.1895866662789229]
	TIME [epoch: 41 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22640925987065078		[learning rate: 0.00033069]
	Learning Rate: 0.000330692
	LOSS [training: 0.22640925987065078 | validation: 0.18686116017611049]
	TIME [epoch: 41.1 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.21929360468579037		[learning rate: 0.00032938]
	Learning Rate: 0.000329376
	LOSS [training: 0.21929360468579037 | validation: 0.19297386930423266]
	TIME [epoch: 41 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2208395496912008		[learning rate: 0.00032807]
	Learning Rate: 0.000328066
	LOSS [training: 0.2208395496912008 | validation: 0.18483061122973937]
	TIME [epoch: 41 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22962406946872996		[learning rate: 0.00032676]
	Learning Rate: 0.000326761
	LOSS [training: 0.22962406946872996 | validation: 0.1896544892307667]
	TIME [epoch: 41 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22258299104190218		[learning rate: 0.00032546]
	Learning Rate: 0.000325462
	LOSS [training: 0.22258299104190218 | validation: 0.1881977765276348]
	TIME [epoch: 41 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22626483179261525		[learning rate: 0.00032417]
	Learning Rate: 0.000324167
	LOSS [training: 0.22626483179261525 | validation: 0.18582193613003356]
	TIME [epoch: 41 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22535257247431817		[learning rate: 0.00032288]
	Learning Rate: 0.000322878
	LOSS [training: 0.22535257247431817 | validation: 0.18468927016378248]
	TIME [epoch: 41 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22317013391100582		[learning rate: 0.00032159]
	Learning Rate: 0.000321594
	LOSS [training: 0.22317013391100582 | validation: 0.18628899342445637]
	TIME [epoch: 41 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22079987433728623		[learning rate: 0.00032031]
	Learning Rate: 0.000320315
	LOSS [training: 0.22079987433728623 | validation: 0.19349213503665796]
	TIME [epoch: 41.1 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.21927776341835553		[learning rate: 0.00031904]
	Learning Rate: 0.000319041
	LOSS [training: 0.21927776341835553 | validation: 0.18790202072209197]
	TIME [epoch: 41 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2258904614624784		[learning rate: 0.00031777]
	Learning Rate: 0.000317772
	LOSS [training: 0.2258904614624784 | validation: 0.18996163739104532]
	TIME [epoch: 41.1 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22112517430054696		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 0.22112517430054696 | validation: 0.19211858890869515]
	TIME [epoch: 41 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22226079412080488		[learning rate: 0.00031525]
	Learning Rate: 0.000315249
	LOSS [training: 0.22226079412080488 | validation: 0.19139617583166274]
	TIME [epoch: 41 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22351109403576286		[learning rate: 0.000314]
	Learning Rate: 0.000313995
	LOSS [training: 0.22351109403576286 | validation: 0.18573207596827204]
	TIME [epoch: 41 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.21992135162722015		[learning rate: 0.00031275]
	Learning Rate: 0.000312746
	LOSS [training: 0.21992135162722015 | validation: 0.19438935608777141]
	TIME [epoch: 41 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.21816917716003353		[learning rate: 0.0003115]
	Learning Rate: 0.000311503
	LOSS [training: 0.21816917716003353 | validation: 0.18517382409362443]
	TIME [epoch: 41 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22667062290396758		[learning rate: 0.00031026]
	Learning Rate: 0.000310264
	LOSS [training: 0.22667062290396758 | validation: 0.19053277786567974]
	TIME [epoch: 41 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22367010955482647		[learning rate: 0.00030903]
	Learning Rate: 0.00030903
	LOSS [training: 0.22367010955482647 | validation: 0.1900962500210701]
	TIME [epoch: 41 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.21990459895113446		[learning rate: 0.0003078]
	Learning Rate: 0.0003078
	LOSS [training: 0.21990459895113446 | validation: 0.19006148955233854]
	TIME [epoch: 41.1 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22241821602378467		[learning rate: 0.00030658]
	Learning Rate: 0.000306576
	LOSS [training: 0.22241821602378467 | validation: 0.19202536591709218]
	TIME [epoch: 41 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2172284500632861		[learning rate: 0.00030536]
	Learning Rate: 0.000305357
	LOSS [training: 0.2172284500632861 | validation: 0.19769780275248586]
	TIME [epoch: 41 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22697282814920433		[learning rate: 0.00030414]
	Learning Rate: 0.000304142
	LOSS [training: 0.22697282814920433 | validation: 0.18997989273561586]
	TIME [epoch: 41 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22360534579325972		[learning rate: 0.00030293]
	Learning Rate: 0.000302933
	LOSS [training: 0.22360534579325972 | validation: 0.1927962745417092]
	TIME [epoch: 41.1 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22576921246699788		[learning rate: 0.00030173]
	Learning Rate: 0.000301728
	LOSS [training: 0.22576921246699788 | validation: 0.18829423470256407]
	TIME [epoch: 41 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22544034244222733		[learning rate: 0.00030053]
	Learning Rate: 0.000300528
	LOSS [training: 0.22544034244222733 | validation: 0.18602222012663133]
	TIME [epoch: 41.1 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2243738423684385		[learning rate: 0.00029933]
	Learning Rate: 0.000299333
	LOSS [training: 0.2243738423684385 | validation: 0.19040596986801778]
	TIME [epoch: 41.1 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22308097346296638		[learning rate: 0.00029814]
	Learning Rate: 0.000298142
	LOSS [training: 0.22308097346296638 | validation: 0.18786707566042957]
	TIME [epoch: 41 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22339945325149702		[learning rate: 0.00029696]
	Learning Rate: 0.000296956
	LOSS [training: 0.22339945325149702 | validation: 0.18679841711477466]
	TIME [epoch: 41.1 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2226440434469026		[learning rate: 0.00029578]
	Learning Rate: 0.000295775
	LOSS [training: 0.2226440434469026 | validation: 0.18492320952834637]
	TIME [epoch: 41 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22453005234233847		[learning rate: 0.0002946]
	Learning Rate: 0.000294599
	LOSS [training: 0.22453005234233847 | validation: 0.1895184686156074]
	TIME [epoch: 41 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2248354525212439		[learning rate: 0.00029343]
	Learning Rate: 0.000293427
	LOSS [training: 0.2248354525212439 | validation: 0.18834028448500637]
	TIME [epoch: 41 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2210960217790118		[learning rate: 0.00029226]
	Learning Rate: 0.00029226
	LOSS [training: 0.2210960217790118 | validation: 0.1882941607906547]
	TIME [epoch: 41 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22440590971931204		[learning rate: 0.0002911]
	Learning Rate: 0.000291098
	LOSS [training: 0.22440590971931204 | validation: 0.18501555367067352]
	TIME [epoch: 41 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22370323117906019		[learning rate: 0.00028994]
	Learning Rate: 0.00028994
	LOSS [training: 0.22370323117906019 | validation: 0.18524174712507746]
	TIME [epoch: 41 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22113082317628174		[learning rate: 0.00028879]
	Learning Rate: 0.000288786
	LOSS [training: 0.22113082317628174 | validation: 0.18460667942660958]
	TIME [epoch: 41.1 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2243086155051927		[learning rate: 0.00028764]
	Learning Rate: 0.000287638
	LOSS [training: 0.2243086155051927 | validation: 0.19321243494077509]
	TIME [epoch: 41 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2195089674420612		[learning rate: 0.00028649]
	Learning Rate: 0.000286494
	LOSS [training: 0.2195089674420612 | validation: 0.18826783054287302]
	TIME [epoch: 41.1 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22560602713235978		[learning rate: 0.00028535]
	Learning Rate: 0.000285354
	LOSS [training: 0.22560602713235978 | validation: 0.18875187495023954]
	TIME [epoch: 41 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22715319506398413		[learning rate: 0.00028422]
	Learning Rate: 0.00028422
	LOSS [training: 0.22715319506398413 | validation: 0.18876963796864935]
	TIME [epoch: 41.1 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22923047880144054		[learning rate: 0.00028309]
	Learning Rate: 0.000283089
	LOSS [training: 0.22923047880144054 | validation: 0.18963024303377612]
	TIME [epoch: 41 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22175892100662992		[learning rate: 0.00028196]
	Learning Rate: 0.000281963
	LOSS [training: 0.22175892100662992 | validation: 0.19039914802431646]
	TIME [epoch: 41.1 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22436389613082033		[learning rate: 0.00028084]
	Learning Rate: 0.000280842
	LOSS [training: 0.22436389613082033 | validation: 0.19343419701639353]
	TIME [epoch: 41.1 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2201859392644464		[learning rate: 0.00027972]
	Learning Rate: 0.000279725
	LOSS [training: 0.2201859392644464 | validation: 0.1886321525998488]
	TIME [epoch: 41 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22847321662209236		[learning rate: 0.00027861]
	Learning Rate: 0.000278612
	LOSS [training: 0.22847321662209236 | validation: 0.1893039331353379]
	TIME [epoch: 41.1 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.227739966370403		[learning rate: 0.0002775]
	Learning Rate: 0.000277504
	LOSS [training: 0.227739966370403 | validation: 0.18636952138221918]
	TIME [epoch: 41.1 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2218346349669805		[learning rate: 0.0002764]
	Learning Rate: 0.0002764
	LOSS [training: 0.2218346349669805 | validation: 0.189159853950137]
	TIME [epoch: 41 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22324729499228096		[learning rate: 0.0002753]
	Learning Rate: 0.000275301
	LOSS [training: 0.22324729499228096 | validation: 0.1894826757371128]
	TIME [epoch: 41.1 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.21887736235764418		[learning rate: 0.00027421]
	Learning Rate: 0.000274206
	LOSS [training: 0.21887736235764418 | validation: 0.18938085437505417]
	TIME [epoch: 41 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.21944081129376813		[learning rate: 0.00027312]
	Learning Rate: 0.000273115
	LOSS [training: 0.21944081129376813 | validation: 0.1906693253390822]
	TIME [epoch: 41.1 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2217310784831601		[learning rate: 0.00027203]
	Learning Rate: 0.000272029
	LOSS [training: 0.2217310784831601 | validation: 0.18656597211893852]
	TIME [epoch: 41.1 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2212067707646162		[learning rate: 0.00027095]
	Learning Rate: 0.000270947
	LOSS [training: 0.2212067707646162 | validation: 0.1882959584149521]
	TIME [epoch: 41.1 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2264852004364205		[learning rate: 0.00026987]
	Learning Rate: 0.00026987
	LOSS [training: 0.2264852004364205 | validation: 0.18669076033585674]
	TIME [epoch: 41.1 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22301782940890635		[learning rate: 0.0002688]
	Learning Rate: 0.000268796
	LOSS [training: 0.22301782940890635 | validation: 0.19233930666089816]
	TIME [epoch: 41 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22514146010107597		[learning rate: 0.00026773]
	Learning Rate: 0.000267727
	LOSS [training: 0.22514146010107597 | validation: 0.1883521922043213]
	TIME [epoch: 41 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v13_20240716_142646/states/model_facs_v2_dec1b_2dpca_v13_953.pth
Halted early. No improvement in validation loss for 200 epochs.
Finished training in 27757.469 seconds.
