Args:
Namespace(name='model_facs_dec1b_2dpca_v2', outdir='out/model_training/model_facs_dec1b_2dpca_v2', training_data='data/training_data/facs/pca/dec1_fitonsubset/transition1_subset_epi_tr_ce_an_pc12/training', validation_data='data/training_data/facs/pca/dec1_fitonsubset/transition1_subset_epi_tr_ce_an_pc12/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=10, batch_size=50, patience=200, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=2000, ncells_sample=2000, model_do_sample=False, dt=0.001, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 770546760

Training model...

Saving initial model state to: out/model_training/model_facs_dec1b_2dpca_v2_20240627_193058/states/model_facs_dec1b_2dpca_v2_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7733154611077562		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7733154611077562 | validation: 0.6673284254131484]
	TIME [epoch: 170 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v2_20240627_193058/states/model_facs_dec1b_2dpca_v2_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6695573611940713		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6695573611940713 | validation: 0.623787449155523]
	TIME [epoch: 142 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v2_20240627_193058/states/model_facs_dec1b_2dpca_v2_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6447457278124126		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6447457278124126 | validation: 0.5911254456760895]
	TIME [epoch: 142 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v2_20240627_193058/states/model_facs_dec1b_2dpca_v2_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6255540481731683		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6255540481731683 | validation: 0.5930020641423104]
	TIME [epoch: 143 sec]
EPOCH 5/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5808492644229417		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5808492644229417 | validation: 0.5603210846523481]
	TIME [epoch: 143 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v2_20240627_193058/states/model_facs_dec1b_2dpca_v2_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5417133016390241		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5417133016390241 | validation: 0.5135365093917126]
	TIME [epoch: 143 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v2_20240627_193058/states/model_facs_dec1b_2dpca_v2_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5270774216362668		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5270774216362668 | validation: 0.46778506257301744]
	TIME [epoch: 143 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v2_20240627_193058/states/model_facs_dec1b_2dpca_v2_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.46658083521551574		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.46658083521551574 | validation: 0.4297553067232883]
	TIME [epoch: 143 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v2_20240627_193058/states/model_facs_dec1b_2dpca_v2_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4404651669931434		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4404651669931434 | validation: 0.33517583031419224]
	TIME [epoch: 143 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v2_20240627_193058/states/model_facs_dec1b_2dpca_v2_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3706294258515686		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3706294258515686 | validation: 0.2940660564527003]
	TIME [epoch: 143 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v2_20240627_193058/states/model_facs_dec1b_2dpca_v2_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.33003149806528176		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.33003149806528176 | validation: 0.3003652076772418]
	TIME [epoch: 143 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2664020710520074		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2664020710520074 | validation: 0.23762675298972652]
	TIME [epoch: 143 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v2_20240627_193058/states/model_facs_dec1b_2dpca_v2_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2564566194931992		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2564566194931992 | validation: 0.2591704445396997]
	TIME [epoch: 143 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22627078040624912		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22627078040624912 | validation: 0.197516703353345]
	TIME [epoch: 143 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v2_20240627_193058/states/model_facs_dec1b_2dpca_v2_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2257266343073972		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2257266343073972 | validation: 0.19841674881202154]
	TIME [epoch: 143 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.20231109400203742		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20231109400203742 | validation: 0.17655310022790718]
	TIME [epoch: 143 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v2_20240627_193058/states/model_facs_dec1b_2dpca_v2_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.21748491149277469		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.21748491149277469 | validation: 0.2226517091027908]
	TIME [epoch: 143 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.19230581142772965		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.19230581142772965 | validation: 0.16761420855771766]
	TIME [epoch: 142 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v2_20240627_193058/states/model_facs_dec1b_2dpca_v2_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1860018325016435		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1860018325016435 | validation: 0.17524133028862454]
	TIME [epoch: 143 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.18578632781552584		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18578632781552584 | validation: 0.17141561438513503]
	TIME [epoch: 143 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1651571874682264		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1651571874682264 | validation: 0.14233727436850946]
	TIME [epoch: 143 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v2_20240627_193058/states/model_facs_dec1b_2dpca_v2_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16467581975585327		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16467581975585327 | validation: 0.14681692564106733]
	TIME [epoch: 142 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15727894671440312		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15727894671440312 | validation: 0.1423889750967246]
	TIME [epoch: 142 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16177344551971232		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16177344551971232 | validation: 0.14515468023791075]
	TIME [epoch: 143 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15347519692671968		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15347519692671968 | validation: 0.1503143307058576]
	TIME [epoch: 142 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15318997893885442		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15318997893885442 | validation: 0.13979404831155004]
	TIME [epoch: 142 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v2_20240627_193058/states/model_facs_dec1b_2dpca_v2_26.pth
	Model improved!!!
EPOCH 27/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15391497199675158		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15391497199675158 | validation: 0.13024076940271628]
	TIME [epoch: 142 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v2_20240627_193058/states/model_facs_dec1b_2dpca_v2_27.pth
	Model improved!!!
EPOCH 28/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14554384950608615		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14554384950608615 | validation: 0.1386113640098174]
	TIME [epoch: 143 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16661924717748383		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16661924717748383 | validation: 0.13353685822513586]
	TIME [epoch: 142 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14413415048051756		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14413415048051756 | validation: 0.13637568413621315]
	TIME [epoch: 143 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15550443382540935		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15550443382540935 | validation: 0.13356295010923114]
	TIME [epoch: 143 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14280905203802463		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14280905203802463 | validation: 0.16518957366126813]
	TIME [epoch: 143 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1406853702343112		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1406853702343112 | validation: 0.12624579661978003]
	TIME [epoch: 143 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v2_20240627_193058/states/model_facs_dec1b_2dpca_v2_33.pth
	Model improved!!!
EPOCH 34/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14366347893749387		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14366347893749387 | validation: 0.1407788148348478]
	TIME [epoch: 143 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1392366930248232		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1392366930248232 | validation: 0.13036914416897635]
	TIME [epoch: 142 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14421097635187893		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14421097635187893 | validation: 0.153962935897126]
	TIME [epoch: 143 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1396938299493484		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1396938299493484 | validation: 0.13393974794024804]
	TIME [epoch: 142 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13274667930858736		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13274667930858736 | validation: 0.11965296668819118]
	TIME [epoch: 143 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v2_20240627_193058/states/model_facs_dec1b_2dpca_v2_38.pth
	Model improved!!!
EPOCH 39/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13887374410975561		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13887374410975561 | validation: 0.11978835040928928]
	TIME [epoch: 142 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13707214721161118		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13707214721161118 | validation: 0.11867535030652188]
	TIME [epoch: 143 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v2_20240627_193058/states/model_facs_dec1b_2dpca_v2_40.pth
	Model improved!!!
EPOCH 41/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12952854668706382		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12952854668706382 | validation: 0.11799269864554134]
	TIME [epoch: 142 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v2_20240627_193058/states/model_facs_dec1b_2dpca_v2_41.pth
	Model improved!!!
EPOCH 42/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13595294860193888		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13595294860193888 | validation: 0.1123991243880739]
	TIME [epoch: 142 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v2_20240627_193058/states/model_facs_dec1b_2dpca_v2_42.pth
	Model improved!!!
EPOCH 43/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12966421963955221		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12966421963955221 | validation: 0.12452840215799202]
	TIME [epoch: 142 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13530951372581035		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13530951372581035 | validation: 0.1171530470778345]
	TIME [epoch: 143 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12721068303530292		[learning rate: 0.0099823]
	Learning Rate: 0.0099823
	LOSS [training: 0.12721068303530292 | validation: 0.124565520310658]
	TIME [epoch: 142 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12525386352763285		[learning rate: 0.0099426]
	Learning Rate: 0.0099426
	LOSS [training: 0.12525386352763285 | validation: 0.11363100584622536]
	TIME [epoch: 143 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13254423625224845		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 0.13254423625224845 | validation: 0.12739539922502638]
	TIME [epoch: 142 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1393135416130934		[learning rate: 0.0098637]
	Learning Rate: 0.00986367
	LOSS [training: 0.1393135416130934 | validation: 0.11582695060273554]
	TIME [epoch: 142 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12753784033597476		[learning rate: 0.0098244]
	Learning Rate: 0.00982444
	LOSS [training: 0.12753784033597476 | validation: 0.12447748109492673]
	TIME [epoch: 142 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12820638649082558		[learning rate: 0.0097854]
	Learning Rate: 0.00978536
	LOSS [training: 0.12820638649082558 | validation: 0.12227600914800005]
	TIME [epoch: 142 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13208080570461844		[learning rate: 0.0097464]
	Learning Rate: 0.00974644
	LOSS [training: 0.13208080570461844 | validation: 0.14276564949571033]
	TIME [epoch: 143 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12760031979668857		[learning rate: 0.0097077]
	Learning Rate: 0.00970768
	LOSS [training: 0.12760031979668857 | validation: 0.1045193173694233]
	TIME [epoch: 143 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v2_20240627_193058/states/model_facs_dec1b_2dpca_v2_52.pth
	Model improved!!!
EPOCH 53/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13583184558883354		[learning rate: 0.0096691]
	Learning Rate: 0.00966907
	LOSS [training: 0.13583184558883354 | validation: 0.1200456166029709]
	TIME [epoch: 142 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13751173077344359		[learning rate: 0.0096306]
	Learning Rate: 0.00963061
	LOSS [training: 0.13751173077344359 | validation: 0.10802311365999204]
	TIME [epoch: 143 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12417810374114542		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 0.12417810374114542 | validation: 0.11377494051437735]
	TIME [epoch: 143 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1291015924700306		[learning rate: 0.0095542]
	Learning Rate: 0.00955415
	LOSS [training: 0.1291015924700306 | validation: 0.10445159007332902]
	TIME [epoch: 143 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v2_20240627_193058/states/model_facs_dec1b_2dpca_v2_56.pth
	Model improved!!!
EPOCH 57/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12137733960468096		[learning rate: 0.0095162]
	Learning Rate: 0.00951616
	LOSS [training: 0.12137733960468096 | validation: 0.13110953488968993]
	TIME [epoch: 143 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12746341277215592		[learning rate: 0.0094783]
	Learning Rate: 0.00947831
	LOSS [training: 0.12746341277215592 | validation: 0.1105195919368365]
	TIME [epoch: 143 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1223676657464746		[learning rate: 0.0094406]
	Learning Rate: 0.00944061
	LOSS [training: 0.1223676657464746 | validation: 0.10718109768124995]
	TIME [epoch: 143 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1271841782368359		[learning rate: 0.0094031]
	Learning Rate: 0.00940306
	LOSS [training: 0.1271841782368359 | validation: 0.10926793397535481]
	TIME [epoch: 143 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12964908458812097		[learning rate: 0.0093657]
	Learning Rate: 0.00936566
	LOSS [training: 0.12964908458812097 | validation: 0.11872788305503006]
	TIME [epoch: 143 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12161361067525618		[learning rate: 0.0093284]
	Learning Rate: 0.00932841
	LOSS [training: 0.12161361067525618 | validation: 0.09990758020953024]
	TIME [epoch: 143 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v2_20240627_193058/states/model_facs_dec1b_2dpca_v2_62.pth
	Model improved!!!
EPOCH 63/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1235092292807586		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 0.1235092292807586 | validation: 0.1014881270661326]
	TIME [epoch: 143 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1260777155835446		[learning rate: 0.0092544]
	Learning Rate: 0.00925435
	LOSS [training: 0.1260777155835446 | validation: 0.1046370120707431]
	TIME [epoch: 143 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12624003689016852		[learning rate: 0.0092175]
	Learning Rate: 0.00921755
	LOSS [training: 0.12624003689016852 | validation: 0.10585440418922569]
	TIME [epoch: 143 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12832822273881467		[learning rate: 0.0091809]
	Learning Rate: 0.00918089
	LOSS [training: 0.12832822273881467 | validation: 0.12317411889520466]
	TIME [epoch: 143 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12091823120104903		[learning rate: 0.0091444]
	Learning Rate: 0.00914437
	LOSS [training: 0.12091823120104903 | validation: 0.10546274904936111]
	TIME [epoch: 143 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11925088877617782		[learning rate: 0.009108]
	Learning Rate: 0.009108
	LOSS [training: 0.11925088877617782 | validation: 0.10392944505796502]
	TIME [epoch: 143 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12358780594291405		[learning rate: 0.0090718]
	Learning Rate: 0.00907178
	LOSS [training: 0.12358780594291405 | validation: 0.10346502982233703]
	TIME [epoch: 143 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1206424059560222		[learning rate: 0.0090357]
	Learning Rate: 0.00903569
	LOSS [training: 0.1206424059560222 | validation: 0.11821698889500812]
	TIME [epoch: 143 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1334098792832766		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 0.1334098792832766 | validation: 0.10780736229981336]
	TIME [epoch: 143 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12054586002357559		[learning rate: 0.008964]
	Learning Rate: 0.00896396
	LOSS [training: 0.12054586002357559 | validation: 0.10095303224513393]
	TIME [epoch: 143 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1195602824986168		[learning rate: 0.0089283]
	Learning Rate: 0.00892831
	LOSS [training: 0.1195602824986168 | validation: 0.10475623652177705]
	TIME [epoch: 143 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12434706350684571		[learning rate: 0.0088928]
	Learning Rate: 0.0088928
	LOSS [training: 0.12434706350684571 | validation: 0.10019856349368331]
	TIME [epoch: 143 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12434390173439142		[learning rate: 0.0088574]
	Learning Rate: 0.00885743
	LOSS [training: 0.12434390173439142 | validation: 0.10913408858569451]
	TIME [epoch: 143 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11985930211673534		[learning rate: 0.0088222]
	Learning Rate: 0.0088222
	LOSS [training: 0.11985930211673534 | validation: 0.10277138812322668]
	TIME [epoch: 143 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12125414454047559		[learning rate: 0.0087871]
	Learning Rate: 0.00878711
	LOSS [training: 0.12125414454047559 | validation: 0.10406441808794868]
	TIME [epoch: 143 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11927161599210831		[learning rate: 0.0087522]
	Learning Rate: 0.00875216
	LOSS [training: 0.11927161599210831 | validation: 0.09907251920454035]
	TIME [epoch: 143 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v2_20240627_193058/states/model_facs_dec1b_2dpca_v2_78.pth
	Model improved!!!
EPOCH 79/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12288892686292902		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 0.12288892686292902 | validation: 0.10006947007146712]
	TIME [epoch: 142 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12157951083385171		[learning rate: 0.0086827]
	Learning Rate: 0.00868268
	LOSS [training: 0.12157951083385171 | validation: 0.10276778903040466]
	TIME [epoch: 142 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11992036837812475		[learning rate: 0.0086481]
	Learning Rate: 0.00864815
	LOSS [training: 0.11992036837812475 | validation: 0.10862748611713516]
	TIME [epoch: 143 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1190353821030165		[learning rate: 0.0086138]
	Learning Rate: 0.00861375
	LOSS [training: 0.1190353821030165 | validation: 0.09993885987373052]
	TIME [epoch: 143 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11964096820627261		[learning rate: 0.0085795]
	Learning Rate: 0.00857949
	LOSS [training: 0.11964096820627261 | validation: 0.09947342216714121]
	TIME [epoch: 142 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1179052465681271		[learning rate: 0.0085454]
	Learning Rate: 0.00854537
	LOSS [training: 0.1179052465681271 | validation: 0.09943194518502953]
	TIME [epoch: 143 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1234443520758639		[learning rate: 0.0085114]
	Learning Rate: 0.00851138
	LOSS [training: 0.1234443520758639 | validation: 0.10719791650342811]
	TIME [epoch: 142 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12155805940956761		[learning rate: 0.0084775]
	Learning Rate: 0.00847753
	LOSS [training: 0.12155805940956761 | validation: 0.1027106184674265]
	TIME [epoch: 143 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1171869601965257		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 0.1171869601965257 | validation: 0.10099147233637247]
	TIME [epoch: 143 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11656705198812405		[learning rate: 0.0084102]
	Learning Rate: 0.00841023
	LOSS [training: 0.11656705198812405 | validation: 0.11453740968016898]
	TIME [epoch: 143 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12301874122413922		[learning rate: 0.0083768]
	Learning Rate: 0.00837678
	LOSS [training: 0.12301874122413922 | validation: 0.10113475487789605]
	TIME [epoch: 143 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11683944629353157		[learning rate: 0.0083435]
	Learning Rate: 0.00834346
	LOSS [training: 0.11683944629353157 | validation: 0.09770136528378955]
	TIME [epoch: 143 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v2_20240627_193058/states/model_facs_dec1b_2dpca_v2_90.pth
	Model improved!!!
EPOCH 91/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12153767165796439		[learning rate: 0.0083103]
	Learning Rate: 0.00831027
	LOSS [training: 0.12153767165796439 | validation: 0.10365815545072032]
	TIME [epoch: 142 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12305119102112931		[learning rate: 0.0082772]
	Learning Rate: 0.00827722
	LOSS [training: 0.12305119102112931 | validation: 0.09789063411540325]
	TIME [epoch: 143 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12446500758351872		[learning rate: 0.0082443]
	Learning Rate: 0.0082443
	LOSS [training: 0.12446500758351872 | validation: 0.1035802494791064]
	TIME [epoch: 143 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11881498214503977		[learning rate: 0.0082115]
	Learning Rate: 0.00821151
	LOSS [training: 0.11881498214503977 | validation: 0.09699177883601823]
	TIME [epoch: 143 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v2_20240627_193058/states/model_facs_dec1b_2dpca_v2_94.pth
	Model improved!!!
EPOCH 95/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11757416287604282		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 0.11757416287604282 | validation: 0.09983457112742669]
	TIME [epoch: 143 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11512160133932703		[learning rate: 0.0081463]
	Learning Rate: 0.00814632
	LOSS [training: 0.11512160133932703 | validation: 0.10162438812540986]
	TIME [epoch: 143 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12561864236067688		[learning rate: 0.0081139]
	Learning Rate: 0.00811392
	LOSS [training: 0.12561864236067688 | validation: 0.11131877788306718]
	TIME [epoch: 143 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12377040155706914		[learning rate: 0.0080816]
	Learning Rate: 0.00808165
	LOSS [training: 0.12377040155706914 | validation: 0.11747129149859495]
	TIME [epoch: 143 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11933523158141535		[learning rate: 0.0080495]
	Learning Rate: 0.00804951
	LOSS [training: 0.11933523158141535 | validation: 0.10491778815399003]
	TIME [epoch: 143 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1184155371429337		[learning rate: 0.0080175]
	Learning Rate: 0.00801749
	LOSS [training: 0.1184155371429337 | validation: 0.10215781784812294]
	TIME [epoch: 143 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.122464991176777		[learning rate: 0.0079856]
	Learning Rate: 0.0079856
	LOSS [training: 0.122464991176777 | validation: 0.12087544020711241]
	TIME [epoch: 143 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12450143786035055		[learning rate: 0.0079538]
	Learning Rate: 0.00795384
	LOSS [training: 0.12450143786035055 | validation: 0.10775092051435661]
	TIME [epoch: 143 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11554860365276502		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 0.11554860365276502 | validation: 0.09910539721577553]
	TIME [epoch: 143 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12189206436258579		[learning rate: 0.0078907]
	Learning Rate: 0.0078907
	LOSS [training: 0.12189206436258579 | validation: 0.11499098881435257]
	TIME [epoch: 143 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11907501065207343		[learning rate: 0.0078593]
	Learning Rate: 0.00785931
	LOSS [training: 0.11907501065207343 | validation: 0.10331334983581131]
	TIME [epoch: 143 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11553946952465585		[learning rate: 0.0078281]
	Learning Rate: 0.00782805
	LOSS [training: 0.11553946952465585 | validation: 0.09994182094003694]
	TIME [epoch: 143 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.113782521848629		[learning rate: 0.0077969]
	Learning Rate: 0.00779692
	LOSS [training: 0.113782521848629 | validation: 0.0996349487351463]
	TIME [epoch: 143 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11552659258974485		[learning rate: 0.0077659]
	Learning Rate: 0.00776591
	LOSS [training: 0.11552659258974485 | validation: 0.10445949518949896]
	TIME [epoch: 143 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12040411973950274		[learning rate: 0.007735]
	Learning Rate: 0.00773502
	LOSS [training: 0.12040411973950274 | validation: 0.107967241197786]
	TIME [epoch: 143 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11857136739928892		[learning rate: 0.0077043]
	Learning Rate: 0.00770426
	LOSS [training: 0.11857136739928892 | validation: 0.09842931727331469]
	TIME [epoch: 143 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11612159038044093		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 0.11612159038044093 | validation: 0.10973343911199777]
	TIME [epoch: 143 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11934853929466754		[learning rate: 0.0076431]
	Learning Rate: 0.00764309
	LOSS [training: 0.11934853929466754 | validation: 0.1028017533364618]
	TIME [epoch: 143 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11574543554208416		[learning rate: 0.0076127]
	Learning Rate: 0.00761269
	LOSS [training: 0.11574543554208416 | validation: 0.1128055071408021]
	TIME [epoch: 143 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12360194499857144		[learning rate: 0.0075824]
	Learning Rate: 0.00758242
	LOSS [training: 0.12360194499857144 | validation: 0.09939274707846403]
	TIME [epoch: 143 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1198352688988486		[learning rate: 0.0075523]
	Learning Rate: 0.00755226
	LOSS [training: 0.1198352688988486 | validation: 0.10270242263253808]
	TIME [epoch: 143 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12067423463757161		[learning rate: 0.0075222]
	Learning Rate: 0.00752222
	LOSS [training: 0.12067423463757161 | validation: 0.10136969133366007]
	TIME [epoch: 143 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12158851822900885		[learning rate: 0.0074923]
	Learning Rate: 0.0074923
	LOSS [training: 0.12158851822900885 | validation: 0.0976997177900899]
	TIME [epoch: 143 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11391436888524901		[learning rate: 0.0074625]
	Learning Rate: 0.0074625
	LOSS [training: 0.11391436888524901 | validation: 0.11578247293655046]
	TIME [epoch: 143 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1257496091528512		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 0.1257496091528512 | validation: 0.09880786473604468]
	TIME [epoch: 143 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11556921188861054		[learning rate: 0.0074033]
	Learning Rate: 0.00740326
	LOSS [training: 0.11556921188861054 | validation: 0.10673957128871633]
	TIME [epoch: 143 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12095102304152282		[learning rate: 0.0073738]
	Learning Rate: 0.00737382
	LOSS [training: 0.12095102304152282 | validation: 0.10498028130548134]
	TIME [epoch: 143 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11928923650859773		[learning rate: 0.0073445]
	Learning Rate: 0.00734449
	LOSS [training: 0.11928923650859773 | validation: 0.1250051280413646]
	TIME [epoch: 143 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12436000236989614		[learning rate: 0.0073153]
	Learning Rate: 0.00731528
	LOSS [training: 0.12436000236989614 | validation: 0.09713188415987035]
	TIME [epoch: 143 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11563182497857499		[learning rate: 0.0072862]
	Learning Rate: 0.00728618
	LOSS [training: 0.11563182497857499 | validation: 0.0956068948302773]
	TIME [epoch: 143 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v2_20240627_193058/states/model_facs_dec1b_2dpca_v2_124.pth
	Model improved!!!
EPOCH 125/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11954831530240269		[learning rate: 0.0072572]
	Learning Rate: 0.0072572
	LOSS [training: 0.11954831530240269 | validation: 0.09651406690410383]
	TIME [epoch: 143 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11264901554021993		[learning rate: 0.0072283]
	Learning Rate: 0.00722834
	LOSS [training: 0.11264901554021993 | validation: 0.10347473365167281]
	TIME [epoch: 143 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11659907523479024		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 0.11659907523479024 | validation: 0.09977612987687247]
	TIME [epoch: 143 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11782183425120873		[learning rate: 0.007171]
	Learning Rate: 0.00717095
	LOSS [training: 0.11782183425120873 | validation: 0.11223538410317416]
	TIME [epoch: 143 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11993222351321167		[learning rate: 0.0071424]
	Learning Rate: 0.00714243
	LOSS [training: 0.11993222351321167 | validation: 0.10745034654840473]
	TIME [epoch: 143 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11694184842359354		[learning rate: 0.007114]
	Learning Rate: 0.00711403
	LOSS [training: 0.11694184842359354 | validation: 0.11130531778813353]
	TIME [epoch: 143 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12038400537497464		[learning rate: 0.0070857]
	Learning Rate: 0.00708573
	LOSS [training: 0.12038400537497464 | validation: 0.09603829858831521]
	TIME [epoch: 143 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11629198518278505		[learning rate: 0.0070575]
	Learning Rate: 0.00705755
	LOSS [training: 0.11629198518278505 | validation: 0.11634767726303155]
	TIME [epoch: 143 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11436226192380877		[learning rate: 0.0070295]
	Learning Rate: 0.00702948
	LOSS [training: 0.11436226192380877 | validation: 0.10113290957451074]
	TIME [epoch: 143 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11745953091343579		[learning rate: 0.0070015]
	Learning Rate: 0.00700152
	LOSS [training: 0.11745953091343579 | validation: 0.10815791180128868]
	TIME [epoch: 143 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11864501039949824		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 0.11864501039949824 | validation: 0.10141818880565263]
	TIME [epoch: 143 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12539602658095703		[learning rate: 0.0069459]
	Learning Rate: 0.00694594
	LOSS [training: 0.12539602658095703 | validation: 0.10346181715283449]
	TIME [epoch: 143 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11690148042861573		[learning rate: 0.0069183]
	Learning Rate: 0.00691831
	LOSS [training: 0.11690148042861573 | validation: 0.1015340434517095]
	TIME [epoch: 143 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1166608459184022		[learning rate: 0.0068908]
	Learning Rate: 0.00689079
	LOSS [training: 0.1166608459184022 | validation: 0.10255884271956242]
	TIME [epoch: 143 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11742825786074196		[learning rate: 0.0068634]
	Learning Rate: 0.00686339
	LOSS [training: 0.11742825786074196 | validation: 0.10485974975026865]
	TIME [epoch: 143 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11857506213112974		[learning rate: 0.0068361]
	Learning Rate: 0.00683609
	LOSS [training: 0.11857506213112974 | validation: 0.09726879778756951]
	TIME [epoch: 143 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11575767706579046		[learning rate: 0.0068089]
	Learning Rate: 0.0068089
	LOSS [training: 0.11575767706579046 | validation: 0.1013253594847268]
	TIME [epoch: 143 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11582263490341765		[learning rate: 0.0067818]
	Learning Rate: 0.00678182
	LOSS [training: 0.11582263490341765 | validation: 0.09638911784735846]
	TIME [epoch: 143 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1173860570004372		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 0.1173860570004372 | validation: 0.09865388853646104]
	TIME [epoch: 143 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12044806492796765		[learning rate: 0.006728]
	Learning Rate: 0.00672798
	LOSS [training: 0.12044806492796765 | validation: 0.0958249320967939]
	TIME [epoch: 143 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11679659842235382		[learning rate: 0.0067012]
	Learning Rate: 0.00670122
	LOSS [training: 0.11679659842235382 | validation: 0.09791411032082034]
	TIME [epoch: 143 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11923029622916673		[learning rate: 0.0066746]
	Learning Rate: 0.00667457
	LOSS [training: 0.11923029622916673 | validation: 0.09760784990971709]
	TIME [epoch: 143 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11318325234549345		[learning rate: 0.006648]
	Learning Rate: 0.00664802
	LOSS [training: 0.11318325234549345 | validation: 0.10242132012998788]
	TIME [epoch: 143 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12014929861963826		[learning rate: 0.0066216]
	Learning Rate: 0.00662158
	LOSS [training: 0.12014929861963826 | validation: 0.10083510994161518]
	TIME [epoch: 143 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11417202031172866		[learning rate: 0.0065952]
	Learning Rate: 0.00659524
	LOSS [training: 0.11417202031172866 | validation: 0.10495827428092877]
	TIME [epoch: 143 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11588588351822798		[learning rate: 0.006569]
	Learning Rate: 0.00656901
	LOSS [training: 0.11588588351822798 | validation: 0.09694384505105055]
	TIME [epoch: 143 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11634030716575545		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 0.11634030716575545 | validation: 0.10054947337392928]
	TIME [epoch: 143 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11442149862977485		[learning rate: 0.0065169]
	Learning Rate: 0.00651686
	LOSS [training: 0.11442149862977485 | validation: 0.09920601751909695]
	TIME [epoch: 143 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11792821872626275		[learning rate: 0.0064909]
	Learning Rate: 0.00649094
	LOSS [training: 0.11792821872626275 | validation: 0.09847999070250046]
	TIME [epoch: 143 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11469368055037527		[learning rate: 0.0064651]
	Learning Rate: 0.00646512
	LOSS [training: 0.11469368055037527 | validation: 0.09660452732433714]
	TIME [epoch: 143 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11606768148871859		[learning rate: 0.0064394]
	Learning Rate: 0.00643941
	LOSS [training: 0.11606768148871859 | validation: 0.09674153630167415]
	TIME [epoch: 143 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11452021960675594		[learning rate: 0.0064138]
	Learning Rate: 0.0064138
	LOSS [training: 0.11452021960675594 | validation: 0.09604097446549303]
	TIME [epoch: 142 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11389662102185533		[learning rate: 0.0063883]
	Learning Rate: 0.00638829
	LOSS [training: 0.11389662102185533 | validation: 0.11858195368348401]
	TIME [epoch: 143 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12423994178850657		[learning rate: 0.0063629]
	Learning Rate: 0.00636288
	LOSS [training: 0.12423994178850657 | validation: 0.09546120602026147]
	TIME [epoch: 143 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v2_20240627_193058/states/model_facs_dec1b_2dpca_v2_158.pth
	Model improved!!!
EPOCH 159/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1158828219141676		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 0.1158828219141676 | validation: 0.09582751482335511]
	TIME [epoch: 142 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11628257094455087		[learning rate: 0.0063124]
	Learning Rate: 0.00631237
	LOSS [training: 0.11628257094455087 | validation: 0.10607381415486514]
	TIME [epoch: 142 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11685964984463373		[learning rate: 0.0062873]
	Learning Rate: 0.00628726
	LOSS [training: 0.11685964984463373 | validation: 0.09798564462490134]
	TIME [epoch: 142 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11842430800340807		[learning rate: 0.0062623]
	Learning Rate: 0.00626226
	LOSS [training: 0.11842430800340807 | validation: 0.09747543816956586]
	TIME [epoch: 142 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11362326930253903		[learning rate: 0.0062373]
	Learning Rate: 0.00623735
	LOSS [training: 0.11362326930253903 | validation: 0.0981637655918903]
	TIME [epoch: 143 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11466199656038076		[learning rate: 0.0062125]
	Learning Rate: 0.00621254
	LOSS [training: 0.11466199656038076 | validation: 0.09594254649294062]
	TIME [epoch: 143 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11488496951781915		[learning rate: 0.0061878]
	Learning Rate: 0.00618783
	LOSS [training: 0.11488496951781915 | validation: 0.0969297993389412]
	TIME [epoch: 142 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1126705762737989		[learning rate: 0.0061632]
	Learning Rate: 0.00616322
	LOSS [training: 0.1126705762737989 | validation: 0.10300014151943819]
	TIME [epoch: 143 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11569956424086215		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 0.11569956424086215 | validation: 0.09943736178258734]
	TIME [epoch: 142 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12015012541630002		[learning rate: 0.0061143]
	Learning Rate: 0.00611429
	LOSS [training: 0.12015012541630002 | validation: 0.0952067209948185]
	TIME [epoch: 142 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v2_20240627_193058/states/model_facs_dec1b_2dpca_v2_168.pth
	Model improved!!!
EPOCH 169/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11306554794755128		[learning rate: 0.00609]
	Learning Rate: 0.00608997
	LOSS [training: 0.11306554794755128 | validation: 0.09500194920484663]
	TIME [epoch: 142 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v2_20240627_193058/states/model_facs_dec1b_2dpca_v2_169.pth
	Model improved!!!
EPOCH 170/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1161693596908919		[learning rate: 0.0060658]
	Learning Rate: 0.00606575
	LOSS [training: 0.1161693596908919 | validation: 0.0980341359003112]
	TIME [epoch: 142 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11521940916723523		[learning rate: 0.0060416]
	Learning Rate: 0.00604163
	LOSS [training: 0.11521940916723523 | validation: 0.10088071745116992]
	TIME [epoch: 142 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1163582794155688		[learning rate: 0.0060176]
	Learning Rate: 0.0060176
	LOSS [training: 0.1163582794155688 | validation: 0.09630725797489767]
	TIME [epoch: 142 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11453421150873883		[learning rate: 0.0059937]
	Learning Rate: 0.00599366
	LOSS [training: 0.11453421150873883 | validation: 0.09538219017401747]
	TIME [epoch: 142 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11523087015945009		[learning rate: 0.0059698]
	Learning Rate: 0.00596982
	LOSS [training: 0.11523087015945009 | validation: 0.0966258601548259]
	TIME [epoch: 142 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11421479549118126		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 0.11421479549118126 | validation: 0.09804629029699603]
	TIME [epoch: 142 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11387892763514468		[learning rate: 0.0059224]
	Learning Rate: 0.00592243
	LOSS [training: 0.11387892763514468 | validation: 0.09879684564880516]
	TIME [epoch: 143 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1169993724836842		[learning rate: 0.0058989]
	Learning Rate: 0.00589888
	LOSS [training: 0.1169993724836842 | validation: 0.10034045224685932]
	TIME [epoch: 142 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11421045292846631		[learning rate: 0.0058754]
	Learning Rate: 0.00587541
	LOSS [training: 0.11421045292846631 | validation: 0.09801177667717305]
	TIME [epoch: 142 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11731879636479804		[learning rate: 0.005852]
	Learning Rate: 0.00585205
	LOSS [training: 0.11731879636479804 | validation: 0.09759622469657281]
	TIME [epoch: 142 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1134403106526453		[learning rate: 0.0058288]
	Learning Rate: 0.00582877
	LOSS [training: 0.1134403106526453 | validation: 0.09835809762840278]
	TIME [epoch: 143 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11440959676291292		[learning rate: 0.0058056]
	Learning Rate: 0.00580559
	LOSS [training: 0.11440959676291292 | validation: 0.09836530684006825]
	TIME [epoch: 142 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11333625601803085		[learning rate: 0.0057825]
	Learning Rate: 0.0057825
	LOSS [training: 0.11333625601803085 | validation: 0.11205608201620362]
	TIME [epoch: 142 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1189713743559449		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 0.1189713743559449 | validation: 0.09586543515828781]
	TIME [epoch: 142 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.115049642267001		[learning rate: 0.0057366]
	Learning Rate: 0.00573659
	LOSS [training: 0.115049642267001 | validation: 0.10135375723567355]
	TIME [epoch: 142 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11327960091339076		[learning rate: 0.0057138]
	Learning Rate: 0.00571377
	LOSS [training: 0.11327960091339076 | validation: 0.09621048163461535]
	TIME [epoch: 142 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11452227609509039		[learning rate: 0.005691]
	Learning Rate: 0.00569105
	LOSS [training: 0.11452227609509039 | validation: 0.09689316978910767]
	TIME [epoch: 142 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11581981458452446		[learning rate: 0.0056684]
	Learning Rate: 0.00566841
	LOSS [training: 0.11581981458452446 | validation: 0.09517112324900512]
	TIME [epoch: 142 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11462003039630586		[learning rate: 0.0056459]
	Learning Rate: 0.00564587
	LOSS [training: 0.11462003039630586 | validation: 0.09822280745733873]
	TIME [epoch: 142 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11229845880398798		[learning rate: 0.0056234]
	Learning Rate: 0.00562341
	LOSS [training: 0.11229845880398798 | validation: 0.09920368889350609]
	TIME [epoch: 142 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10981690197726536		[learning rate: 0.005601]
	Learning Rate: 0.00560105
	LOSS [training: 0.10981690197726536 | validation: 0.1025003441118314]
	TIME [epoch: 142 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11770052865378923		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 0.11770052865378923 | validation: 0.10053338421098368]
	TIME [epoch: 142 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11407257992872472		[learning rate: 0.0055566]
	Learning Rate: 0.00555658
	LOSS [training: 0.11407257992872472 | validation: 0.09948060383562903]
	TIME [epoch: 142 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11457090124834715		[learning rate: 0.0055345]
	Learning Rate: 0.00553448
	LOSS [training: 0.11457090124834715 | validation: 0.10036746108861228]
	TIME [epoch: 142 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11560181920058168		[learning rate: 0.0055125]
	Learning Rate: 0.00551247
	LOSS [training: 0.11560181920058168 | validation: 0.09417740609620988]
	TIME [epoch: 142 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v2_20240627_193058/states/model_facs_dec1b_2dpca_v2_194.pth
	Model improved!!!
EPOCH 195/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11563107456508091		[learning rate: 0.0054905]
	Learning Rate: 0.00549054
	LOSS [training: 0.11563107456508091 | validation: 0.09764722573209061]
	TIME [epoch: 142 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12059278678195026		[learning rate: 0.0054687]
	Learning Rate: 0.00546871
	LOSS [training: 0.12059278678195026 | validation: 0.09679714345003951]
	TIME [epoch: 142 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11290317974694959		[learning rate: 0.005447]
	Learning Rate: 0.00544696
	LOSS [training: 0.11290317974694959 | validation: 0.09797616709095483]
	TIME [epoch: 142 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11128058721850513		[learning rate: 0.0054253]
	Learning Rate: 0.00542529
	LOSS [training: 0.11128058721850513 | validation: 0.09608677259097728]
	TIME [epoch: 142 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1141557518681789		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 0.1141557518681789 | validation: 0.09495491081849529]
	TIME [epoch: 142 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11262975685367126		[learning rate: 0.0053822]
	Learning Rate: 0.00538222
	LOSS [training: 0.11262975685367126 | validation: 0.09653293200120734]
	TIME [epoch: 142 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11421302068345465		[learning rate: 0.0053608]
	Learning Rate: 0.00536081
	LOSS [training: 0.11421302068345465 | validation: 0.09668556114117469]
	TIME [epoch: 142 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11286910824282424		[learning rate: 0.0053395]
	Learning Rate: 0.00533949
	LOSS [training: 0.11286910824282424 | validation: 0.09840157778724157]
	TIME [epoch: 142 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11443139590259475		[learning rate: 0.0053183]
	Learning Rate: 0.00531826
	LOSS [training: 0.11443139590259475 | validation: 0.09663038178946538]
	TIME [epoch: 142 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11449223274097858		[learning rate: 0.0052971]
	Learning Rate: 0.0052971
	LOSS [training: 0.11449223274097858 | validation: 0.09970396679386567]
	TIME [epoch: 142 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11646819605116487		[learning rate: 0.005276]
	Learning Rate: 0.00527604
	LOSS [training: 0.11646819605116487 | validation: 0.09605264100006634]
	TIME [epoch: 142 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11335887732441474		[learning rate: 0.0052551]
	Learning Rate: 0.00525505
	LOSS [training: 0.11335887732441474 | validation: 0.0960282382343329]
	TIME [epoch: 142 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11316009166928856		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 0.11316009166928856 | validation: 0.09530046334699613]
	TIME [epoch: 142 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11128775187261757		[learning rate: 0.0052133]
	Learning Rate: 0.00521333
	LOSS [training: 0.11128775187261757 | validation: 0.09814977758787244]
	TIME [epoch: 142 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11583253232759712		[learning rate: 0.0051926]
	Learning Rate: 0.0051926
	LOSS [training: 0.11583253232759712 | validation: 0.09489496116794102]
	TIME [epoch: 142 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11212166570411533		[learning rate: 0.0051719]
	Learning Rate: 0.00517194
	LOSS [training: 0.11212166570411533 | validation: 0.09326890086841598]
	TIME [epoch: 142 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v2_20240627_193058/states/model_facs_dec1b_2dpca_v2_210.pth
	Model improved!!!
EPOCH 211/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11483240436388033		[learning rate: 0.0051514]
	Learning Rate: 0.00515137
	LOSS [training: 0.11483240436388033 | validation: 0.09607722734846758]
	TIME [epoch: 142 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11665320766651366		[learning rate: 0.0051309]
	Learning Rate: 0.00513089
	LOSS [training: 0.11665320766651366 | validation: 0.0991229975518558]
	TIME [epoch: 142 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1111270160305012		[learning rate: 0.0051105]
	Learning Rate: 0.00511048
	LOSS [training: 0.1111270160305012 | validation: 0.10145245586497013]
	TIME [epoch: 142 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11474604572960032		[learning rate: 0.0050902]
	Learning Rate: 0.00509015
	LOSS [training: 0.11474604572960032 | validation: 0.09472788604427451]
	TIME [epoch: 142 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11478860284778508		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 0.11478860284778508 | validation: 0.10175449154983111]
	TIME [epoch: 143 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11313068665690262		[learning rate: 0.0050497]
	Learning Rate: 0.00504974
	LOSS [training: 0.11313068665690262 | validation: 0.09431686484830931]
	TIME [epoch: 142 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11312724340310715		[learning rate: 0.0050297]
	Learning Rate: 0.00502966
	LOSS [training: 0.11312724340310715 | validation: 0.09649258846856842]
	TIME [epoch: 142 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11333381533236432		[learning rate: 0.0050097]
	Learning Rate: 0.00500965
	LOSS [training: 0.11333381533236432 | validation: 0.0952921583074072]
	TIME [epoch: 142 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11561802914008958		[learning rate: 0.0049897]
	Learning Rate: 0.00498973
	LOSS [training: 0.11561802914008958 | validation: 0.09764219401461724]
	TIME [epoch: 142 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11763644571598797		[learning rate: 0.0049699]
	Learning Rate: 0.00496988
	LOSS [training: 0.11763644571598797 | validation: 0.09951291828491597]
	TIME [epoch: 142 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11415853926694883		[learning rate: 0.0049501]
	Learning Rate: 0.00495012
	LOSS [training: 0.11415853926694883 | validation: 0.09575122374240405]
	TIME [epoch: 142 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1116988942154032		[learning rate: 0.0049304]
	Learning Rate: 0.00493043
	LOSS [training: 0.1116988942154032 | validation: 0.09798680332678675]
	TIME [epoch: 142 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11148798576658277		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 0.11148798576658277 | validation: 0.10598440800039051]
	TIME [epoch: 142 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11442504399208829		[learning rate: 0.0048913]
	Learning Rate: 0.00489129
	LOSS [training: 0.11442504399208829 | validation: 0.09480695669111784]
	TIME [epoch: 142 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11266097023079721		[learning rate: 0.0048718]
	Learning Rate: 0.00487183
	LOSS [training: 0.11266097023079721 | validation: 0.10278373762211301]
	TIME [epoch: 142 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11253078264220534		[learning rate: 0.0048525]
	Learning Rate: 0.00485245
	LOSS [training: 0.11253078264220534 | validation: 0.0948269873240706]
	TIME [epoch: 142 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11511245710064208		[learning rate: 0.0048332]
	Learning Rate: 0.00483316
	LOSS [training: 0.11511245710064208 | validation: 0.09483277942393101]
	TIME [epoch: 142 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10981452434687505		[learning rate: 0.0048139]
	Learning Rate: 0.00481393
	LOSS [training: 0.10981452434687505 | validation: 0.09434699592778845]
	TIME [epoch: 142 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11424429544440537		[learning rate: 0.0047948]
	Learning Rate: 0.00479479
	LOSS [training: 0.11424429544440537 | validation: 0.09698481511424609]
	TIME [epoch: 142 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11196927528577534		[learning rate: 0.0047757]
	Learning Rate: 0.00477572
	LOSS [training: 0.11196927528577534 | validation: 0.10181493139371896]
	TIME [epoch: 142 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11409000059423688		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.11409000059423688 | validation: 0.09606153127069281]
	TIME [epoch: 142 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11512379806249677		[learning rate: 0.0047378]
	Learning Rate: 0.0047378
	LOSS [training: 0.11512379806249677 | validation: 0.09530533047621953]
	TIME [epoch: 142 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1162649880000771		[learning rate: 0.004719]
	Learning Rate: 0.00471896
	LOSS [training: 0.1162649880000771 | validation: 0.09762828969210724]
	TIME [epoch: 142 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11097388076708872		[learning rate: 0.0047002]
	Learning Rate: 0.00470019
	LOSS [training: 0.11097388076708872 | validation: 0.09557983265506867]
	TIME [epoch: 142 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11410504019042483		[learning rate: 0.0046815]
	Learning Rate: 0.0046815
	LOSS [training: 0.11410504019042483 | validation: 0.09378465364017449]
	TIME [epoch: 142 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11294734021853833		[learning rate: 0.0046629]
	Learning Rate: 0.00466288
	LOSS [training: 0.11294734021853833 | validation: 0.09621021239680808]
	TIME [epoch: 143 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11437979662022846		[learning rate: 0.0046443]
	Learning Rate: 0.00464433
	LOSS [training: 0.11437979662022846 | validation: 0.0940100928828775]
	TIME [epoch: 143 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10975424550471813		[learning rate: 0.0046259]
	Learning Rate: 0.00462586
	LOSS [training: 0.10975424550471813 | validation: 0.10467674547581204]
	TIME [epoch: 142 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11509843173003761		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 0.11509843173003761 | validation: 0.09553731948067991]
	TIME [epoch: 142 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11149296675996473		[learning rate: 0.0045891]
	Learning Rate: 0.00458913
	LOSS [training: 0.11149296675996473 | validation: 0.09507198926743246]
	TIME [epoch: 142 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11564561656819827		[learning rate: 0.0045709]
	Learning Rate: 0.00457088
	LOSS [training: 0.11564561656819827 | validation: 0.09710575344915956]
	TIME [epoch: 142 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11276139222827648		[learning rate: 0.0045527]
	Learning Rate: 0.0045527
	LOSS [training: 0.11276139222827648 | validation: 0.09376251942173633]
	TIME [epoch: 142 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11488874831900746		[learning rate: 0.0045346]
	Learning Rate: 0.00453459
	LOSS [training: 0.11488874831900746 | validation: 0.09852594287016855]
	TIME [epoch: 142 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11196443590142907		[learning rate: 0.0045166]
	Learning Rate: 0.00451656
	LOSS [training: 0.11196443590142907 | validation: 0.09624100122170297]
	TIME [epoch: 142 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11233076542920704		[learning rate: 0.0044986]
	Learning Rate: 0.0044986
	LOSS [training: 0.11233076542920704 | validation: 0.09633159568579233]
	TIME [epoch: 142 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11302963105267873		[learning rate: 0.0044807]
	Learning Rate: 0.0044807
	LOSS [training: 0.11302963105267873 | validation: 0.09813509920029291]
	TIME [epoch: 143 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1128447947036683		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 0.1128447947036683 | validation: 0.0949208590889278]
	TIME [epoch: 142 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11403431300062487		[learning rate: 0.0044451]
	Learning Rate: 0.00444513
	LOSS [training: 0.11403431300062487 | validation: 0.09819052550581685]
	TIME [epoch: 142 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11319042717427331		[learning rate: 0.0044275]
	Learning Rate: 0.00442745
	LOSS [training: 0.11319042717427331 | validation: 0.10080967105158481]
	TIME [epoch: 143 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11277712419205607		[learning rate: 0.0044098]
	Learning Rate: 0.00440984
	LOSS [training: 0.11277712419205607 | validation: 0.0961575758565]
	TIME [epoch: 143 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11081517210678138		[learning rate: 0.0043923]
	Learning Rate: 0.0043923
	LOSS [training: 0.11081517210678138 | validation: 0.09972241687843862]
	TIME [epoch: 143 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11232331640997227		[learning rate: 0.0043748]
	Learning Rate: 0.00437483
	LOSS [training: 0.11232331640997227 | validation: 0.10161170804024874]
	TIME [epoch: 143 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11302084470060206		[learning rate: 0.0043574]
	Learning Rate: 0.00435743
	LOSS [training: 0.11302084470060206 | validation: 0.09619317630224135]
	TIME [epoch: 143 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11298452830630662		[learning rate: 0.0043401]
	Learning Rate: 0.0043401
	LOSS [training: 0.11298452830630662 | validation: 0.09485625789360329]
	TIME [epoch: 143 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11273487739458796		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 0.11273487739458796 | validation: 0.0996742564129786]
	TIME [epoch: 143 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11579166205818986		[learning rate: 0.0043056]
	Learning Rate: 0.00430565
	LOSS [training: 0.11579166205818986 | validation: 0.09518612075095491]
	TIME [epoch: 143 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11116241938905354		[learning rate: 0.0042885]
	Learning Rate: 0.00428852
	LOSS [training: 0.11116241938905354 | validation: 0.0941428186095177]
	TIME [epoch: 142 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11282013358402627		[learning rate: 0.0042715]
	Learning Rate: 0.00427147
	LOSS [training: 0.11282013358402627 | validation: 0.09547980982105994]
	TIME [epoch: 143 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11428427510479928		[learning rate: 0.0042545]
	Learning Rate: 0.00425448
	LOSS [training: 0.11428427510479928 | validation: 0.09577980904720725]
	TIME [epoch: 143 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11392963461199823		[learning rate: 0.0042376]
	Learning Rate: 0.00423756
	LOSS [training: 0.11392963461199823 | validation: 0.1025129023185954]
	TIME [epoch: 143 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11202367576205938		[learning rate: 0.0042207]
	Learning Rate: 0.0042207
	LOSS [training: 0.11202367576205938 | validation: 0.09526911733572876]
	TIME [epoch: 143 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11107183148607495		[learning rate: 0.0042039]
	Learning Rate: 0.00420391
	LOSS [training: 0.11107183148607495 | validation: 0.09314820435035515]
	TIME [epoch: 143 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v2_20240627_193058/states/model_facs_dec1b_2dpca_v2_262.pth
	Model improved!!!
EPOCH 263/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10929308809029685		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 0.10929308809029685 | validation: 0.09543696769669721]
	TIME [epoch: 143 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11472220725526941		[learning rate: 0.0041705]
	Learning Rate: 0.00417054
	LOSS [training: 0.11472220725526941 | validation: 0.09752501478166489]
	TIME [epoch: 143 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11130529231714832		[learning rate: 0.004154]
	Learning Rate: 0.00415395
	LOSS [training: 0.11130529231714832 | validation: 0.09405925344623547]
	TIME [epoch: 143 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11345380419612927		[learning rate: 0.0041374]
	Learning Rate: 0.00413743
	LOSS [training: 0.11345380419612927 | validation: 0.10003355603071262]
	TIME [epoch: 143 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11206547080401087		[learning rate: 0.004121]
	Learning Rate: 0.00412098
	LOSS [training: 0.11206547080401087 | validation: 0.0982502969196732]
	TIME [epoch: 143 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11273594352075872		[learning rate: 0.0041046]
	Learning Rate: 0.00410458
	LOSS [training: 0.11273594352075872 | validation: 0.09410428901949117]
	TIME [epoch: 143 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1128233534773111		[learning rate: 0.0040883]
	Learning Rate: 0.00408826
	LOSS [training: 0.1128233534773111 | validation: 0.097036070122999]
	TIME [epoch: 143 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1128914487430049		[learning rate: 0.004072]
	Learning Rate: 0.004072
	LOSS [training: 0.1128914487430049 | validation: 0.09547367831126721]
	TIME [epoch: 143 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11347061766700087		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.11347061766700087 | validation: 0.09585194911524189]
	TIME [epoch: 143 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1130770970293698		[learning rate: 0.0040397]
	Learning Rate: 0.00403967
	LOSS [training: 0.1130770970293698 | validation: 0.095760169691393]
	TIME [epoch: 143 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1115655424564686		[learning rate: 0.0040236]
	Learning Rate: 0.00402361
	LOSS [training: 0.1115655424564686 | validation: 0.09597931356528151]
	TIME [epoch: 143 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11204442387197755		[learning rate: 0.0040076]
	Learning Rate: 0.0040076
	LOSS [training: 0.11204442387197755 | validation: 0.09526373890931758]
	TIME [epoch: 143 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11216036082744352		[learning rate: 0.0039917]
	Learning Rate: 0.00399166
	LOSS [training: 0.11216036082744352 | validation: 0.09582970258365689]
	TIME [epoch: 143 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11082342275348717		[learning rate: 0.0039758]
	Learning Rate: 0.00397579
	LOSS [training: 0.11082342275348717 | validation: 0.0942186680291821]
	TIME [epoch: 143 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1098981954338569		[learning rate: 0.00396]
	Learning Rate: 0.00395997
	LOSS [training: 0.1098981954338569 | validation: 0.09566967524528044]
	TIME [epoch: 143 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11314293080323977		[learning rate: 0.0039442]
	Learning Rate: 0.00394422
	LOSS [training: 0.11314293080323977 | validation: 0.09515008567343505]
	TIME [epoch: 143 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11543314870332885		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 0.11543314870332885 | validation: 0.0921053995771241]
	TIME [epoch: 143 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v2_20240627_193058/states/model_facs_dec1b_2dpca_v2_279.pth
	Model improved!!!
EPOCH 280/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10895789965894907		[learning rate: 0.0039129]
	Learning Rate: 0.00391291
	LOSS [training: 0.10895789965894907 | validation: 0.09537741623327908]
	TIME [epoch: 143 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1116823381911322		[learning rate: 0.0038973]
	Learning Rate: 0.00389735
	LOSS [training: 0.1116823381911322 | validation: 0.09407193448256926]
	TIME [epoch: 143 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11148630789753715		[learning rate: 0.0038818]
	Learning Rate: 0.00388185
	LOSS [training: 0.11148630789753715 | validation: 0.09597540480244623]
	TIME [epoch: 143 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11230147397430226		[learning rate: 0.0038664]
	Learning Rate: 0.00386641
	LOSS [training: 0.11230147397430226 | validation: 0.09390203320183321]
	TIME [epoch: 143 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11099704181192417		[learning rate: 0.003851]
	Learning Rate: 0.00385103
	LOSS [training: 0.11099704181192417 | validation: 0.09884916362905907]
	TIME [epoch: 143 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1121170392751155		[learning rate: 0.0038357]
	Learning Rate: 0.00383571
	LOSS [training: 0.1121170392751155 | validation: 0.09351839857988684]
	TIME [epoch: 143 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11003884845298662		[learning rate: 0.0038205]
	Learning Rate: 0.00382046
	LOSS [training: 0.11003884845298662 | validation: 0.09517230238044383]
	TIME [epoch: 143 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11070000516724934		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 0.11070000516724934 | validation: 0.09641086451302788]
	TIME [epoch: 143 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11448776982529092		[learning rate: 0.0037901]
	Learning Rate: 0.00379013
	LOSS [training: 0.11448776982529092 | validation: 0.1009118873877464]
	TIME [epoch: 143 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11314065169032579		[learning rate: 0.0037751]
	Learning Rate: 0.00377505
	LOSS [training: 0.11314065169032579 | validation: 0.09698571211387534]
	TIME [epoch: 143 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11096639151788525		[learning rate: 0.00376]
	Learning Rate: 0.00376004
	LOSS [training: 0.11096639151788525 | validation: 0.0977554947688258]
	TIME [epoch: 143 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11039453454155847		[learning rate: 0.0037451]
	Learning Rate: 0.00374508
	LOSS [training: 0.11039453454155847 | validation: 0.09686139907786775]
	TIME [epoch: 143 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11499456992674756		[learning rate: 0.0037302]
	Learning Rate: 0.00373019
	LOSS [training: 0.11499456992674756 | validation: 0.09568022971398074]
	TIME [epoch: 143 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11059367441803955		[learning rate: 0.0037154]
	Learning Rate: 0.00371535
	LOSS [training: 0.11059367441803955 | validation: 0.09813085004418284]
	TIME [epoch: 143 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11188973742736764		[learning rate: 0.0037006]
	Learning Rate: 0.00370058
	LOSS [training: 0.11188973742736764 | validation: 0.09552815455360163]
	TIME [epoch: 143 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10966480427307032		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 0.10966480427307032 | validation: 0.09668738913094835]
	TIME [epoch: 143 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11523528046853963		[learning rate: 0.0036712]
	Learning Rate: 0.0036712
	LOSS [training: 0.11523528046853963 | validation: 0.09381714822395912]
	TIME [epoch: 143 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11334726578920525		[learning rate: 0.0036566]
	Learning Rate: 0.0036566
	LOSS [training: 0.11334726578920525 | validation: 0.09426067127125401]
	TIME [epoch: 143 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11206940168207231		[learning rate: 0.0036421]
	Learning Rate: 0.00364205
	LOSS [training: 0.11206940168207231 | validation: 0.09570898599909329]
	TIME [epoch: 143 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11260113572623519		[learning rate: 0.0036276]
	Learning Rate: 0.00362757
	LOSS [training: 0.11260113572623519 | validation: 0.09561955558963184]
	TIME [epoch: 143 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11379464694709464		[learning rate: 0.0036131]
	Learning Rate: 0.00361314
	LOSS [training: 0.11379464694709464 | validation: 0.09501394308921082]
	TIME [epoch: 143 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1102005893416273		[learning rate: 0.0035988]
	Learning Rate: 0.00359877
	LOSS [training: 0.1102005893416273 | validation: 0.09498035029001044]
	TIME [epoch: 143 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11258217252983707		[learning rate: 0.0035845]
	Learning Rate: 0.00358445
	LOSS [training: 0.11258217252983707 | validation: 0.09927167448283798]
	TIME [epoch: 143 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11389682042759684		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 0.11389682042759684 | validation: 0.09524968723066901]
	TIME [epoch: 143 sec]
EPOCH 304/2000:
	Training over batches...
