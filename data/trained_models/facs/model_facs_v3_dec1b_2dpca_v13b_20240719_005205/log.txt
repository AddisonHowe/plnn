Args:
Namespace(name='model_facs_v3_dec1b_2dpca_v13b', outdir='out/model_training/model_facs_v3_dec1b_2dpca_v13b', training_data='data/training_data/facs_v3/pca/dec1_fitonsubset/transition1_subset_epi_tr_ce_an_pc12/training', validation_data='data/training_data/facs_v3/pca/dec1_fitonsubset/transition1_subset_epi_tr_ce_an_pc12/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=10, batch_size=50, patience=200, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, quadratic_a=1.0, quadratic_b=1.0, ndims=2, nparams=2, nsigs=2, ncells=400, ncells_sample=400, model_do_sample=False, dt=0.005, dt_schedule='stepped', dt_schedule_bounds=[50, 100, 200, 300], dt_schedule_scales=[0.5, 0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', kernel='multiscale', bw_range=[0.2, 0.5, 0.9, 1.1, 1.3, 1.5, 2.0], optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 3564525507

Training model...

Saving initial model state to: out/model_training/model_facs_v3_dec1b_2dpca_v13b_20240719_005205/states/model_facs_v3_dec1b_2dpca_v13b_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.318213390765919		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.318213390765919 | validation: 1.1589644150764524]
	TIME [epoch: 23.2 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13b_20240719_005205/states/model_facs_v3_dec1b_2dpca_v13b_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.2199735801069027		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2199735801069027 | validation: 1.067313344187305]
	TIME [epoch: 7.33 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13b_20240719_005205/states/model_facs_v3_dec1b_2dpca_v13b_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.1964928268868196		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1964928268868196 | validation: 1.0764015607849777]
	TIME [epoch: 7.35 sec]
EPOCH 4/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.180801118879468		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.180801118879468 | validation: 1.0516852166724617]
	TIME [epoch: 7.32 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13b_20240719_005205/states/model_facs_v3_dec1b_2dpca_v13b_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.1737192486069146		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1737192486069146 | validation: 1.0105969460477402]
	TIME [epoch: 7.31 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13b_20240719_005205/states/model_facs_v3_dec1b_2dpca_v13b_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.135895452829691		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.135895452829691 | validation: 0.9984511294404015]
	TIME [epoch: 7.33 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13b_20240719_005205/states/model_facs_v3_dec1b_2dpca_v13b_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.1117603371734537		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1117603371734537 | validation: 0.9722274854772965]
	TIME [epoch: 7.35 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13b_20240719_005205/states/model_facs_v3_dec1b_2dpca_v13b_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.0939285469521816		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0939285469521816 | validation: 0.9413963271810644]
	TIME [epoch: 7.38 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13b_20240719_005205/states/model_facs_v3_dec1b_2dpca_v13b_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.0358277798607711		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0358277798607711 | validation: 0.8468949363197218]
	TIME [epoch: 7.36 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13b_20240719_005205/states/model_facs_v3_dec1b_2dpca_v13b_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.9871792862789621		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9871792862789621 | validation: 0.8071193260261046]
	TIME [epoch: 7.38 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13b_20240719_005205/states/model_facs_v3_dec1b_2dpca_v13b_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.9149440967511073		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9149440967511073 | validation: 0.7846118678515713]
	TIME [epoch: 7.34 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13b_20240719_005205/states/model_facs_v3_dec1b_2dpca_v13b_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.851365605250724		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.851365605250724 | validation: 0.8115561965970732]
	TIME [epoch: 7.38 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.7832092780841026		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7832092780841026 | validation: 0.7380666677564959]
	TIME [epoch: 7.36 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13b_20240719_005205/states/model_facs_v3_dec1b_2dpca_v13b_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.7132524140158027		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7132524140158027 | validation: 0.6192652182356259]
	TIME [epoch: 7.29 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13b_20240719_005205/states/model_facs_v3_dec1b_2dpca_v13b_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.7027561238261808		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7027561238261808 | validation: 0.5990167542702347]
	TIME [epoch: 7.37 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13b_20240719_005205/states/model_facs_v3_dec1b_2dpca_v13b_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5999644186925002		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5999644186925002 | validation: 0.5154312568269463]
	TIME [epoch: 7.32 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13b_20240719_005205/states/model_facs_v3_dec1b_2dpca_v13b_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5071622690901177		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5071622690901177 | validation: 0.5183292368673541]
	TIME [epoch: 7.28 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.469163043363415		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.469163043363415 | validation: 0.43774927429259414]
	TIME [epoch: 7.33 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13b_20240719_005205/states/model_facs_v3_dec1b_2dpca_v13b_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5500167960187855		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5500167960187855 | validation: 0.481063243061499]
	TIME [epoch: 7.33 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4551658034273352		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4551658034273352 | validation: 0.3926041688101164]
	TIME [epoch: 7.36 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13b_20240719_005205/states/model_facs_v3_dec1b_2dpca_v13b_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.410078668499039		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.410078668499039 | validation: 0.39460864052563405]
	TIME [epoch: 7.33 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.45091057764073744		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.45091057764073744 | validation: 0.4793902473506275]
	TIME [epoch: 7.35 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.43784562411967554		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.43784562411967554 | validation: 0.369813300636963]
	TIME [epoch: 7.38 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13b_20240719_005205/states/model_facs_v3_dec1b_2dpca_v13b_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3945131493661352		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3945131493661352 | validation: 0.341085920626755]
	TIME [epoch: 7.31 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13b_20240719_005205/states/model_facs_v3_dec1b_2dpca_v13b_24.pth
	Model improved!!!
EPOCH 25/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4814770815644942		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4814770815644942 | validation: 0.42363281519741935]
	TIME [epoch: 7.36 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4187608769654187		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4187608769654187 | validation: 0.33199779233222326]
	TIME [epoch: 7.37 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13b_20240719_005205/states/model_facs_v3_dec1b_2dpca_v13b_26.pth
	Model improved!!!
EPOCH 27/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3645855569454208		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3645855569454208 | validation: 0.3337411822729196]
	TIME [epoch: 7.34 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.40199897683793706		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.40199897683793706 | validation: 0.32268929445041833]
	TIME [epoch: 7.36 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13b_20240719_005205/states/model_facs_v3_dec1b_2dpca_v13b_28.pth
	Model improved!!!
EPOCH 29/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3584863507057991		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3584863507057991 | validation: 0.3392867681513288]
	TIME [epoch: 7.34 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4053242791949097		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4053242791949097 | validation: 0.3088108025683407]
	TIME [epoch: 7.33 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13b_20240719_005205/states/model_facs_v3_dec1b_2dpca_v13b_30.pth
	Model improved!!!
EPOCH 31/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.34786207908840533		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.34786207908840533 | validation: 0.3165812624582724]
	TIME [epoch: 7.35 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3508384234643657		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3508384234643657 | validation: 0.2980966261968391]
	TIME [epoch: 7.33 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13b_20240719_005205/states/model_facs_v3_dec1b_2dpca_v13b_32.pth
	Model improved!!!
EPOCH 33/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3888316013594901		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3888316013594901 | validation: 0.2986575385852993]
	TIME [epoch: 7.34 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.34417147303958756		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.34417147303958756 | validation: 0.28741513358012727]
	TIME [epoch: 7.34 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13b_20240719_005205/states/model_facs_v3_dec1b_2dpca_v13b_34.pth
	Model improved!!!
EPOCH 35/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.34124725652273674		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.34124725652273674 | validation: 0.2970408394574465]
	TIME [epoch: 7.33 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3256696881938982		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3256696881938982 | validation: 0.29120423795828054]
	TIME [epoch: 7.34 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.31305886429337737		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.31305886429337737 | validation: 0.2751932445993977]
	TIME [epoch: 7.34 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13b_20240719_005205/states/model_facs_v3_dec1b_2dpca_v13b_37.pth
	Model improved!!!
EPOCH 38/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.33334972443422206		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.33334972443422206 | validation: 0.34354421134931973]
	TIME [epoch: 7.35 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3458137438228454		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3458137438228454 | validation: 0.2790268854847412]
	TIME [epoch: 7.36 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.37183752271844134		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.37183752271844134 | validation: 0.28092577197543384]
	TIME [epoch: 7.34 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3253264454810771		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3253264454810771 | validation: 0.27337147981409554]
	TIME [epoch: 7.33 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13b_20240719_005205/states/model_facs_v3_dec1b_2dpca_v13b_41.pth
	Model improved!!!
EPOCH 42/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3143650656521579		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3143650656521579 | validation: 0.29648652599016084]
	TIME [epoch: 7.34 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3529623841277378		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3529623841277378 | validation: 0.27535741167808236]
	TIME [epoch: 7.35 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3245039496607776		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3245039496607776 | validation: 0.25732430632659026]
	TIME [epoch: 7.33 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13b_20240719_005205/states/model_facs_v3_dec1b_2dpca_v13b_44.pth
	Model improved!!!
EPOCH 45/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.31255869748409176		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.31255869748409176 | validation: 0.31010309835384814]
	TIME [epoch: 7.35 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3179311559553779		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3179311559553779 | validation: 0.3080587510870089]
	TIME [epoch: 7.34 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3162364355510607		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3162364355510607 | validation: 0.25456854546351954]
	TIME [epoch: 7.36 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13b_20240719_005205/states/model_facs_v3_dec1b_2dpca_v13b_47.pth
	Model improved!!!
EPOCH 48/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.31893428265796037		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.31893428265796037 | validation: 0.26228845195232653]
	TIME [epoch: 7.35 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.31639592511833337		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.31639592511833337 | validation: 0.25261952695070455]
	TIME [epoch: 7.35 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13b_20240719_005205/states/model_facs_v3_dec1b_2dpca_v13b_49.pth
	Model improved!!!
EPOCH 50/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.31089084839111897		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.31089084839111897 | validation: 0.2594837442039971]
	TIME [epoch: 7.31 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3113898200086945		[learning rate: 0.0099705]
	Learning Rate: 0.00997052
	LOSS [training: 0.3113898200086945 | validation: 0.2410152282516222]
	TIME [epoch: 27.9 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13b_20240719_005205/states/model_facs_v3_dec1b_2dpca_v13b_51.pth
	Model improved!!!
EPOCH 52/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3337221132669135		[learning rate: 0.0099353]
	Learning Rate: 0.00993527
	LOSS [training: 0.3337221132669135 | validation: 0.2682301157648147]
	TIME [epoch: 14.1 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3098075012481432		[learning rate: 0.0099001]
	Learning Rate: 0.00990013
	LOSS [training: 0.3098075012481432 | validation: 0.25239641861696527]
	TIME [epoch: 14.2 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2973035322295757		[learning rate: 0.0098651]
	Learning Rate: 0.00986512
	LOSS [training: 0.2973035322295757 | validation: 0.249542143575876]
	TIME [epoch: 14.1 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3274132308424145		[learning rate: 0.0098302]
	Learning Rate: 0.00983024
	LOSS [training: 0.3274132308424145 | validation: 0.24811995178349297]
	TIME [epoch: 14.2 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.32290321266940425		[learning rate: 0.0097955]
	Learning Rate: 0.00979548
	LOSS [training: 0.32290321266940425 | validation: 0.24464668057427116]
	TIME [epoch: 14.2 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29314881078498084		[learning rate: 0.0097608]
	Learning Rate: 0.00976084
	LOSS [training: 0.29314881078498084 | validation: 0.24309760177895162]
	TIME [epoch: 14.2 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2893353638518014		[learning rate: 0.0097263]
	Learning Rate: 0.00972632
	LOSS [training: 0.2893353638518014 | validation: 0.2512628095626788]
	TIME [epoch: 14.1 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2986306571850672		[learning rate: 0.0096919]
	Learning Rate: 0.00969193
	LOSS [training: 0.2986306571850672 | validation: 0.2393919069933388]
	TIME [epoch: 14.1 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13b_20240719_005205/states/model_facs_v3_dec1b_2dpca_v13b_59.pth
	Model improved!!!
EPOCH 60/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28911479601016427		[learning rate: 0.0096577]
	Learning Rate: 0.00965766
	LOSS [training: 0.28911479601016427 | validation: 0.23882913075614615]
	TIME [epoch: 14.1 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13b_20240719_005205/states/model_facs_v3_dec1b_2dpca_v13b_60.pth
	Model improved!!!
EPOCH 61/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.303731087018081		[learning rate: 0.0096235]
	Learning Rate: 0.00962351
	LOSS [training: 0.303731087018081 | validation: 0.23390811390384708]
	TIME [epoch: 14.1 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13b_20240719_005205/states/model_facs_v3_dec1b_2dpca_v13b_61.pth
	Model improved!!!
EPOCH 62/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2951521997939639		[learning rate: 0.0095895]
	Learning Rate: 0.00958948
	LOSS [training: 0.2951521997939639 | validation: 0.2575958461396094]
	TIME [epoch: 14.1 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3260304190258068		[learning rate: 0.0095556]
	Learning Rate: 0.00955557
	LOSS [training: 0.3260304190258068 | validation: 0.26556538123127027]
	TIME [epoch: 14.1 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2966694116964681		[learning rate: 0.0095218]
	Learning Rate: 0.00952177
	LOSS [training: 0.2966694116964681 | validation: 0.2405068558688693]
	TIME [epoch: 14.1 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2996762629118069		[learning rate: 0.0094881]
	Learning Rate: 0.0094881
	LOSS [training: 0.2996762629118069 | validation: 0.23540782794746487]
	TIME [epoch: 14.1 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28265536324085394		[learning rate: 0.0094546]
	Learning Rate: 0.00945455
	LOSS [training: 0.28265536324085394 | validation: 0.23530639047571805]
	TIME [epoch: 14.2 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27627036716529246		[learning rate: 0.0094211]
	Learning Rate: 0.00942112
	LOSS [training: 0.27627036716529246 | validation: 0.27049294930132595]
	TIME [epoch: 14.2 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2874810466283283		[learning rate: 0.0093878]
	Learning Rate: 0.00938781
	LOSS [training: 0.2874810466283283 | validation: 0.24510597931905012]
	TIME [epoch: 14.1 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.293249703607305		[learning rate: 0.0093546]
	Learning Rate: 0.00935461
	LOSS [training: 0.293249703607305 | validation: 0.2268272414327178]
	TIME [epoch: 14.1 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13b_20240719_005205/states/model_facs_v3_dec1b_2dpca_v13b_69.pth
	Model improved!!!
EPOCH 70/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28821964640064274		[learning rate: 0.0093215]
	Learning Rate: 0.00932153
	LOSS [training: 0.28821964640064274 | validation: 0.24034185533756874]
	TIME [epoch: 14.1 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29879418909429717		[learning rate: 0.0092886]
	Learning Rate: 0.00928857
	LOSS [training: 0.29879418909429717 | validation: 0.24862342787938657]
	TIME [epoch: 14.1 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2817310048477916		[learning rate: 0.0092557]
	Learning Rate: 0.00925572
	LOSS [training: 0.2817310048477916 | validation: 0.23616841475123845]
	TIME [epoch: 14.1 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27906934728564		[learning rate: 0.009223]
	Learning Rate: 0.00922299
	LOSS [training: 0.27906934728564 | validation: 0.23021423305902156]
	TIME [epoch: 14.1 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2863863194971666		[learning rate: 0.0091904]
	Learning Rate: 0.00919038
	LOSS [training: 0.2863863194971666 | validation: 0.23024106996166321]
	TIME [epoch: 14.1 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2940178431316359		[learning rate: 0.0091579]
	Learning Rate: 0.00915788
	LOSS [training: 0.2940178431316359 | validation: 0.23042249781689073]
	TIME [epoch: 14.1 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2855555758760941		[learning rate: 0.0091255]
	Learning Rate: 0.00912549
	LOSS [training: 0.2855555758760941 | validation: 0.22791927265975614]
	TIME [epoch: 14.1 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27574069193997025		[learning rate: 0.0090932]
	Learning Rate: 0.00909323
	LOSS [training: 0.27574069193997025 | validation: 0.2234692032298998]
	TIME [epoch: 14.2 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13b_20240719_005205/states/model_facs_v3_dec1b_2dpca_v13b_77.pth
	Model improved!!!
EPOCH 78/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27215461339591984		[learning rate: 0.0090611]
	Learning Rate: 0.00906107
	LOSS [training: 0.27215461339591984 | validation: 0.23871710559076936]
	TIME [epoch: 14.1 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.298217147881767		[learning rate: 0.009029]
	Learning Rate: 0.00902903
	LOSS [training: 0.298217147881767 | validation: 0.23002528849936388]
	TIME [epoch: 14.1 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28034989105411445		[learning rate: 0.0089971]
	Learning Rate: 0.0089971
	LOSS [training: 0.28034989105411445 | validation: 0.2263829235921344]
	TIME [epoch: 14.1 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2859372432317468		[learning rate: 0.0089653]
	Learning Rate: 0.00896528
	LOSS [training: 0.2859372432317468 | validation: 0.22733076907203875]
	TIME [epoch: 14.1 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.283706613304066		[learning rate: 0.0089336]
	Learning Rate: 0.00893358
	LOSS [training: 0.283706613304066 | validation: 0.22136483841338847]
	TIME [epoch: 14.1 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13b_20240719_005205/states/model_facs_v3_dec1b_2dpca_v13b_82.pth
	Model improved!!!
EPOCH 83/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2677863709226866		[learning rate: 0.008902]
	Learning Rate: 0.00890199
	LOSS [training: 0.2677863709226866 | validation: 0.23937992334223512]
	TIME [epoch: 14.1 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27192972751889644		[learning rate: 0.0088705]
	Learning Rate: 0.00887051
	LOSS [training: 0.27192972751889644 | validation: 0.22902877308695074]
	TIME [epoch: 14.1 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2916597101080925		[learning rate: 0.0088391]
	Learning Rate: 0.00883914
	LOSS [training: 0.2916597101080925 | validation: 0.2314091385380784]
	TIME [epoch: 14.2 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2674585995155186		[learning rate: 0.0088079]
	Learning Rate: 0.00880789
	LOSS [training: 0.2674585995155186 | validation: 0.24134893086581388]
	TIME [epoch: 14.2 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27653558476119655		[learning rate: 0.0087767]
	Learning Rate: 0.00877674
	LOSS [training: 0.27653558476119655 | validation: 0.22961576962009134]
	TIME [epoch: 14.1 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28134536341069316		[learning rate: 0.0087457]
	Learning Rate: 0.00874571
	LOSS [training: 0.28134536341069316 | validation: 0.2634761952962539]
	TIME [epoch: 14.2 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2853143444029906		[learning rate: 0.0087148]
	Learning Rate: 0.00871478
	LOSS [training: 0.2853143444029906 | validation: 0.22807387515004077]
	TIME [epoch: 14.2 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2919182128379934		[learning rate: 0.008684]
	Learning Rate: 0.00868396
	LOSS [training: 0.2919182128379934 | validation: 0.2229212765567174]
	TIME [epoch: 14.2 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26322780579083244		[learning rate: 0.0086533]
	Learning Rate: 0.00865326
	LOSS [training: 0.26322780579083244 | validation: 0.23786128829641534]
	TIME [epoch: 14.2 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26425802179009783		[learning rate: 0.0086227]
	Learning Rate: 0.00862265
	LOSS [training: 0.26425802179009783 | validation: 0.22054052338827584]
	TIME [epoch: 14.2 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13b_20240719_005205/states/model_facs_v3_dec1b_2dpca_v13b_92.pth
	Model improved!!!
EPOCH 93/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2763871573863084		[learning rate: 0.0085922]
	Learning Rate: 0.00859216
	LOSS [training: 0.2763871573863084 | validation: 0.22363052292184693]
	TIME [epoch: 14.1 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28230020826959706		[learning rate: 0.0085618]
	Learning Rate: 0.00856178
	LOSS [training: 0.28230020826959706 | validation: 0.22979870366667035]
	TIME [epoch: 14.1 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2821378668302302		[learning rate: 0.0085315]
	Learning Rate: 0.0085315
	LOSS [training: 0.2821378668302302 | validation: 0.2271483565114961]
	TIME [epoch: 14.2 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28365992466455014		[learning rate: 0.0085013]
	Learning Rate: 0.00850134
	LOSS [training: 0.28365992466455014 | validation: 0.22072918470386194]
	TIME [epoch: 14.1 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2693939176410651		[learning rate: 0.0084713]
	Learning Rate: 0.00847127
	LOSS [training: 0.2693939176410651 | validation: 0.22051380954483904]
	TIME [epoch: 14.1 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13b_20240719_005205/states/model_facs_v3_dec1b_2dpca_v13b_97.pth
	Model improved!!!
EPOCH 98/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27070051065334094		[learning rate: 0.0084413]
	Learning Rate: 0.00844132
	LOSS [training: 0.27070051065334094 | validation: 0.22233478449385213]
	TIME [epoch: 14.2 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26268674491373767		[learning rate: 0.0084115]
	Learning Rate: 0.00841147
	LOSS [training: 0.26268674491373767 | validation: 0.22091639564242715]
	TIME [epoch: 14.2 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28441797977006084		[learning rate: 0.0083817]
	Learning Rate: 0.00838172
	LOSS [training: 0.28441797977006084 | validation: 0.22542531908303123]
	TIME [epoch: 14.2 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27399748097051563		[learning rate: 0.0083521]
	Learning Rate: 0.00835208
	LOSS [training: 0.27399748097051563 | validation: 0.2208089681946328]
	TIME [epoch: 44.2 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2728704062943828		[learning rate: 0.0083225]
	Learning Rate: 0.00832255
	LOSS [training: 0.2728704062943828 | validation: 0.22254347429232837]
	TIME [epoch: 30.5 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2863813479710938		[learning rate: 0.0082931]
	Learning Rate: 0.00829312
	LOSS [training: 0.2863813479710938 | validation: 0.22841585018069513]
	TIME [epoch: 30.6 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2717822487477364		[learning rate: 0.0082638]
	Learning Rate: 0.00826379
	LOSS [training: 0.2717822487477364 | validation: 0.22758079590265895]
	TIME [epoch: 30.5 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26856631205887954		[learning rate: 0.0082346]
	Learning Rate: 0.00823457
	LOSS [training: 0.26856631205887954 | validation: 0.21416591761237508]
	TIME [epoch: 30.6 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13b_20240719_005205/states/model_facs_v3_dec1b_2dpca_v13b_105.pth
	Model improved!!!
EPOCH 106/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26938161316731124		[learning rate: 0.0082055]
	Learning Rate: 0.00820545
	LOSS [training: 0.26938161316731124 | validation: 0.21644104213166143]
	TIME [epoch: 30.5 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28299942808808143		[learning rate: 0.0081764]
	Learning Rate: 0.00817644
	LOSS [training: 0.28299942808808143 | validation: 0.23241855081710705]
	TIME [epoch: 30.5 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27629388653255144		[learning rate: 0.0081475]
	Learning Rate: 0.00814752
	LOSS [training: 0.27629388653255144 | validation: 0.21474326929395926]
	TIME [epoch: 30.5 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25577680446838874		[learning rate: 0.0081187]
	Learning Rate: 0.00811871
	LOSS [training: 0.25577680446838874 | validation: 0.2278665383555824]
	TIME [epoch: 30.6 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27723532625708275		[learning rate: 0.00809]
	Learning Rate: 0.00809
	LOSS [training: 0.27723532625708275 | validation: 0.21674414177792092]
	TIME [epoch: 30.5 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2699752630149624		[learning rate: 0.0080614]
	Learning Rate: 0.0080614
	LOSS [training: 0.2699752630149624 | validation: 0.21664159909560018]
	TIME [epoch: 30.6 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2654276421962774		[learning rate: 0.0080329]
	Learning Rate: 0.00803289
	LOSS [training: 0.2654276421962774 | validation: 0.22551800660841578]
	TIME [epoch: 30.5 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26999787467344816		[learning rate: 0.0080045]
	Learning Rate: 0.00800448
	LOSS [training: 0.26999787467344816 | validation: 0.23634257823272115]
	TIME [epoch: 30.5 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27776647168232443		[learning rate: 0.0079762]
	Learning Rate: 0.00797618
	LOSS [training: 0.27776647168232443 | validation: 0.22275685092703398]
	TIME [epoch: 30.5 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2696844136094619		[learning rate: 0.007948]
	Learning Rate: 0.00794797
	LOSS [training: 0.2696844136094619 | validation: 0.2291800662720828]
	TIME [epoch: 30.5 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27677340063890893		[learning rate: 0.0079199]
	Learning Rate: 0.00791987
	LOSS [training: 0.27677340063890893 | validation: 0.2222373679845635]
	TIME [epoch: 30.5 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26970593440417334		[learning rate: 0.0078919]
	Learning Rate: 0.00789186
	LOSS [training: 0.26970593440417334 | validation: 0.21721136780736838]
	TIME [epoch: 30.4 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26297211203392584		[learning rate: 0.007864]
	Learning Rate: 0.00786395
	LOSS [training: 0.26297211203392584 | validation: 0.2258815743156693]
	TIME [epoch: 30.4 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26916023529064736		[learning rate: 0.0078361]
	Learning Rate: 0.00783615
	LOSS [training: 0.26916023529064736 | validation: 0.2242697170834281]
	TIME [epoch: 30.5 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25836456597838753		[learning rate: 0.0078084]
	Learning Rate: 0.00780844
	LOSS [training: 0.25836456597838753 | validation: 0.2252241263074184]
	TIME [epoch: 30.5 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27227561656087024		[learning rate: 0.0077808]
	Learning Rate: 0.00778083
	LOSS [training: 0.27227561656087024 | validation: 0.21164731269612785]
	TIME [epoch: 30.5 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13b_20240719_005205/states/model_facs_v3_dec1b_2dpca_v13b_121.pth
	Model improved!!!
EPOCH 122/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.269984261669378		[learning rate: 0.0077533]
	Learning Rate: 0.00775331
	LOSS [training: 0.269984261669378 | validation: 0.2201429334796464]
	TIME [epoch: 30.6 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2590403648324801		[learning rate: 0.0077259]
	Learning Rate: 0.00772589
	LOSS [training: 0.2590403648324801 | validation: 0.21711190102607572]
	TIME [epoch: 30.5 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26948009438668574		[learning rate: 0.0076986]
	Learning Rate: 0.00769857
	LOSS [training: 0.26948009438668574 | validation: 0.21813976409809044]
	TIME [epoch: 30.5 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2669116781887928		[learning rate: 0.0076714]
	Learning Rate: 0.00767135
	LOSS [training: 0.2669116781887928 | validation: 0.22722170392273194]
	TIME [epoch: 30.5 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26878377475775306		[learning rate: 0.0076442]
	Learning Rate: 0.00764422
	LOSS [training: 0.26878377475775306 | validation: 0.2158567797396361]
	TIME [epoch: 30.5 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26488639660291396		[learning rate: 0.0076172]
	Learning Rate: 0.00761719
	LOSS [training: 0.26488639660291396 | validation: 0.2154793383251073]
	TIME [epoch: 30.5 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26038432560905245		[learning rate: 0.0075903]
	Learning Rate: 0.00759025
	LOSS [training: 0.26038432560905245 | validation: 0.2218206347353952]
	TIME [epoch: 30.5 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2756502743693812		[learning rate: 0.0075634]
	Learning Rate: 0.00756341
	LOSS [training: 0.2756502743693812 | validation: 0.2142835057994085]
	TIME [epoch: 30.5 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2557512803935253		[learning rate: 0.0075367]
	Learning Rate: 0.00753667
	LOSS [training: 0.2557512803935253 | validation: 0.21515051294668514]
	TIME [epoch: 30.5 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27013414660305096		[learning rate: 0.00751]
	Learning Rate: 0.00751002
	LOSS [training: 0.27013414660305096 | validation: 0.22032643451655884]
	TIME [epoch: 30.5 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2678797894406329		[learning rate: 0.0074835]
	Learning Rate: 0.00748346
	LOSS [training: 0.2678797894406329 | validation: 0.21830245171677648]
	TIME [epoch: 30.5 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26299320405229926		[learning rate: 0.007457]
	Learning Rate: 0.007457
	LOSS [training: 0.26299320405229926 | validation: 0.22534842344992895]
	TIME [epoch: 30.6 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2681773427868206		[learning rate: 0.0074306]
	Learning Rate: 0.00743063
	LOSS [training: 0.2681773427868206 | validation: 0.22118292494848077]
	TIME [epoch: 30.6 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2616112674574113		[learning rate: 0.0074044]
	Learning Rate: 0.00740435
	LOSS [training: 0.2616112674574113 | validation: 0.21972568667300219]
	TIME [epoch: 30.6 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26867251867057945		[learning rate: 0.0073782]
	Learning Rate: 0.00737817
	LOSS [training: 0.26867251867057945 | validation: 0.2292999509045755]
	TIME [epoch: 30.6 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26225555623048735		[learning rate: 0.0073521]
	Learning Rate: 0.00735208
	LOSS [training: 0.26225555623048735 | validation: 0.22037743789702402]
	TIME [epoch: 30.5 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2664712935322597		[learning rate: 0.0073261]
	Learning Rate: 0.00732608
	LOSS [training: 0.2664712935322597 | validation: 0.2166403204326774]
	TIME [epoch: 30.5 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25343555556427744		[learning rate: 0.0073002]
	Learning Rate: 0.00730018
	LOSS [training: 0.25343555556427744 | validation: 0.21552993756242406]
	TIME [epoch: 30.5 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2647085078340484		[learning rate: 0.0072744]
	Learning Rate: 0.00727436
	LOSS [training: 0.2647085078340484 | validation: 0.22526997758964118]
	TIME [epoch: 30.5 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.262914090015193		[learning rate: 0.0072486]
	Learning Rate: 0.00724864
	LOSS [training: 0.262914090015193 | validation: 0.23395413390404657]
	TIME [epoch: 30.5 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26801329697635023		[learning rate: 0.007223]
	Learning Rate: 0.007223
	LOSS [training: 0.26801329697635023 | validation: 0.215778557446487]
	TIME [epoch: 30.5 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25953056537712105		[learning rate: 0.0071975]
	Learning Rate: 0.00719746
	LOSS [training: 0.25953056537712105 | validation: 0.21972445121812495]
	TIME [epoch: 30.6 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27447475802179505		[learning rate: 0.007172]
	Learning Rate: 0.00717201
	LOSS [training: 0.27447475802179505 | validation: 0.21983501885863124]
	TIME [epoch: 30.6 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26627087034092006		[learning rate: 0.0071467]
	Learning Rate: 0.00714665
	LOSS [training: 0.26627087034092006 | validation: 0.22463239540527818]
	TIME [epoch: 30.6 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2683246374113514		[learning rate: 0.0071214]
	Learning Rate: 0.00712138
	LOSS [training: 0.2683246374113514 | validation: 0.21365550840642408]
	TIME [epoch: 30.5 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25450565346858783		[learning rate: 0.0070962]
	Learning Rate: 0.0070962
	LOSS [training: 0.25450565346858783 | validation: 0.20804005893762367]
	TIME [epoch: 30.6 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13b_20240719_005205/states/model_facs_v3_dec1b_2dpca_v13b_147.pth
	Model improved!!!
EPOCH 148/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2543495308842673		[learning rate: 0.0070711]
	Learning Rate: 0.0070711
	LOSS [training: 0.2543495308842673 | validation: 0.21906981129886427]
	TIME [epoch: 30.5 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25993783557494105		[learning rate: 0.0070461]
	Learning Rate: 0.0070461
	LOSS [training: 0.25993783557494105 | validation: 0.21535486552687882]
	TIME [epoch: 30.5 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.265689852219581		[learning rate: 0.0070212]
	Learning Rate: 0.00702118
	LOSS [training: 0.265689852219581 | validation: 0.21737623584875698]
	TIME [epoch: 30.5 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25762397877686055		[learning rate: 0.0069964]
	Learning Rate: 0.00699635
	LOSS [training: 0.25762397877686055 | validation: 0.2128177093580293]
	TIME [epoch: 30.3 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27347230408029116		[learning rate: 0.0069716]
	Learning Rate: 0.00697161
	LOSS [training: 0.27347230408029116 | validation: 0.21238834381874697]
	TIME [epoch: 30.6 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2604981724157773		[learning rate: 0.006947]
	Learning Rate: 0.00694696
	LOSS [training: 0.2604981724157773 | validation: 0.21737669484941208]
	TIME [epoch: 30.4 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25432950201113513		[learning rate: 0.0069224]
	Learning Rate: 0.00692239
	LOSS [training: 0.25432950201113513 | validation: 0.22128312980958437]
	TIME [epoch: 30.6 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25300534604200703		[learning rate: 0.0068979]
	Learning Rate: 0.00689792
	LOSS [training: 0.25300534604200703 | validation: 0.21471564371723165]
	TIME [epoch: 30.6 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2656589077958042		[learning rate: 0.0068735]
	Learning Rate: 0.00687352
	LOSS [training: 0.2656589077958042 | validation: 0.21515365595094327]
	TIME [epoch: 30.6 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.266468661812782		[learning rate: 0.0068492]
	Learning Rate: 0.00684922
	LOSS [training: 0.266468661812782 | validation: 0.21521859047876557]
	TIME [epoch: 30.5 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27015743252651697		[learning rate: 0.006825]
	Learning Rate: 0.006825
	LOSS [training: 0.27015743252651697 | validation: 0.23010552613010882]
	TIME [epoch: 30.6 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26598680473517505		[learning rate: 0.0068009]
	Learning Rate: 0.00680086
	LOSS [training: 0.26598680473517505 | validation: 0.21174081200411882]
	TIME [epoch: 30.5 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.265772263834596		[learning rate: 0.0067768]
	Learning Rate: 0.00677681
	LOSS [training: 0.265772263834596 | validation: 0.2099723022757151]
	TIME [epoch: 30.6 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.255876151793754		[learning rate: 0.0067529]
	Learning Rate: 0.00675285
	LOSS [training: 0.255876151793754 | validation: 0.2251297313139508]
	TIME [epoch: 30.5 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2679923809612104		[learning rate: 0.006729]
	Learning Rate: 0.00672897
	LOSS [training: 0.2679923809612104 | validation: 0.21019520778040893]
	TIME [epoch: 30.5 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25241841180555175		[learning rate: 0.0067052]
	Learning Rate: 0.00670518
	LOSS [training: 0.25241841180555175 | validation: 0.21246802901353928]
	TIME [epoch: 30.5 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2579281571683138		[learning rate: 0.0066815]
	Learning Rate: 0.00668147
	LOSS [training: 0.2579281571683138 | validation: 0.221077817720235]
	TIME [epoch: 30.6 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26324474041108326		[learning rate: 0.0066578]
	Learning Rate: 0.00665784
	LOSS [training: 0.26324474041108326 | validation: 0.21786221411383141]
	TIME [epoch: 30.5 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26175457260802865		[learning rate: 0.0066343]
	Learning Rate: 0.0066343
	LOSS [training: 0.26175457260802865 | validation: 0.20947376770859333]
	TIME [epoch: 30.5 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25967001000552176		[learning rate: 0.0066108]
	Learning Rate: 0.00661084
	LOSS [training: 0.25967001000552176 | validation: 0.2110318451241497]
	TIME [epoch: 30.5 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2624157230271252		[learning rate: 0.0065875]
	Learning Rate: 0.00658746
	LOSS [training: 0.2624157230271252 | validation: 0.21842354845726622]
	TIME [epoch: 30.6 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2571618466124144		[learning rate: 0.0065642]
	Learning Rate: 0.00656416
	LOSS [training: 0.2571618466124144 | validation: 0.22377216193649385]
	TIME [epoch: 30.5 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26187397248818683		[learning rate: 0.006541]
	Learning Rate: 0.00654095
	LOSS [training: 0.26187397248818683 | validation: 0.2070402823178637]
	TIME [epoch: 30.5 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13b_20240719_005205/states/model_facs_v3_dec1b_2dpca_v13b_170.pth
	Model improved!!!
EPOCH 171/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.261008683402593		[learning rate: 0.0065178]
	Learning Rate: 0.00651782
	LOSS [training: 0.261008683402593 | validation: 0.2110414128463856]
	TIME [epoch: 30.5 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25877879620593763		[learning rate: 0.0064948]
	Learning Rate: 0.00649477
	LOSS [training: 0.25877879620593763 | validation: 0.21419548115517406]
	TIME [epoch: 30.6 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2632300663813241		[learning rate: 0.0064718]
	Learning Rate: 0.00647181
	LOSS [training: 0.2632300663813241 | validation: 0.2140286579076645]
	TIME [epoch: 30.6 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24962243802328413		[learning rate: 0.0064489]
	Learning Rate: 0.00644892
	LOSS [training: 0.24962243802328413 | validation: 0.21565745038626574]
	TIME [epoch: 30.6 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2615704550140861		[learning rate: 0.0064261]
	Learning Rate: 0.00642612
	LOSS [training: 0.2615704550140861 | validation: 0.21379157761406767]
	TIME [epoch: 30.6 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26192092917962223		[learning rate: 0.0064034]
	Learning Rate: 0.00640339
	LOSS [training: 0.26192092917962223 | validation: 0.21441535257468597]
	TIME [epoch: 30.5 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25977611519520527		[learning rate: 0.0063808]
	Learning Rate: 0.00638075
	LOSS [training: 0.25977611519520527 | validation: 0.21655999399634332]
	TIME [epoch: 30.5 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26116230203831436		[learning rate: 0.0063582]
	Learning Rate: 0.00635819
	LOSS [training: 0.26116230203831436 | validation: 0.21686592257890847]
	TIME [epoch: 30.5 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25283398720286415		[learning rate: 0.0063357]
	Learning Rate: 0.0063357
	LOSS [training: 0.25283398720286415 | validation: 0.21448717810916146]
	TIME [epoch: 30.6 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2626362999148337		[learning rate: 0.0063133]
	Learning Rate: 0.0063133
	LOSS [training: 0.2626362999148337 | validation: 0.213430392182566]
	TIME [epoch: 30.5 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2641850246510594		[learning rate: 0.006291]
	Learning Rate: 0.00629097
	LOSS [training: 0.2641850246510594 | validation: 0.21728565394310645]
	TIME [epoch: 30.5 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2572541530991354		[learning rate: 0.0062687]
	Learning Rate: 0.00626873
	LOSS [training: 0.2572541530991354 | validation: 0.2113406177209241]
	TIME [epoch: 30.5 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2583072346347871		[learning rate: 0.0062466]
	Learning Rate: 0.00624656
	LOSS [training: 0.2583072346347871 | validation: 0.2291811885064349]
	TIME [epoch: 30.5 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27383363201399996		[learning rate: 0.0062245]
	Learning Rate: 0.00622447
	LOSS [training: 0.27383363201399996 | validation: 0.2153249210417683]
	TIME [epoch: 30.5 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25645263664396006		[learning rate: 0.0062025]
	Learning Rate: 0.00620246
	LOSS [training: 0.25645263664396006 | validation: 0.21550073812512718]
	TIME [epoch: 30.6 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2527234772516736		[learning rate: 0.0061805]
	Learning Rate: 0.00618053
	LOSS [training: 0.2527234772516736 | validation: 0.21404800242601726]
	TIME [epoch: 30.5 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25711386445309464		[learning rate: 0.0061587]
	Learning Rate: 0.00615867
	LOSS [training: 0.25711386445309464 | validation: 0.2159128035166554]
	TIME [epoch: 30.6 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2613812926961449		[learning rate: 0.0061369]
	Learning Rate: 0.00613689
	LOSS [training: 0.2613812926961449 | validation: 0.2198950623109813]
	TIME [epoch: 30.5 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2579822752762537		[learning rate: 0.0061152]
	Learning Rate: 0.00611519
	LOSS [training: 0.2579822752762537 | validation: 0.21558263939208572]
	TIME [epoch: 30.5 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2556730281138971		[learning rate: 0.0060936]
	Learning Rate: 0.00609357
	LOSS [training: 0.2556730281138971 | validation: 0.2162992699847079]
	TIME [epoch: 30.5 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25659939501236656		[learning rate: 0.006072]
	Learning Rate: 0.00607202
	LOSS [training: 0.25659939501236656 | validation: 0.21311217338286575]
	TIME [epoch: 30.5 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25034993567780384		[learning rate: 0.0060505]
	Learning Rate: 0.00605055
	LOSS [training: 0.25034993567780384 | validation: 0.2140172491257874]
	TIME [epoch: 30.5 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2590624889258431		[learning rate: 0.0060292]
	Learning Rate: 0.00602915
	LOSS [training: 0.2590624889258431 | validation: 0.21435046757116355]
	TIME [epoch: 30.6 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25337014159869614		[learning rate: 0.0060078]
	Learning Rate: 0.00600783
	LOSS [training: 0.25337014159869614 | validation: 0.21980246013363827]
	TIME [epoch: 30.6 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25863698923324024		[learning rate: 0.0059866]
	Learning Rate: 0.00598659
	LOSS [training: 0.25863698923324024 | validation: 0.21462004532655024]
	TIME [epoch: 30.6 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2553605054865418		[learning rate: 0.0059654]
	Learning Rate: 0.00596542
	LOSS [training: 0.2553605054865418 | validation: 0.212903566201744]
	TIME [epoch: 30.5 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2522618009545426		[learning rate: 0.0059443]
	Learning Rate: 0.00594433
	LOSS [training: 0.2522618009545426 | validation: 0.2235959988091974]
	TIME [epoch: 30.6 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25534550234497383		[learning rate: 0.0059233]
	Learning Rate: 0.0059233
	LOSS [training: 0.25534550234497383 | validation: 0.21535214406799824]
	TIME [epoch: 30.5 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25240665469163354		[learning rate: 0.0059024]
	Learning Rate: 0.00590236
	LOSS [training: 0.25240665469163354 | validation: 0.21211276979453492]
	TIME [epoch: 30.5 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2692352438461669		[learning rate: 0.0058815]
	Learning Rate: 0.00588149
	LOSS [training: 0.2692352438461669 | validation: 0.2165355325040476]
	TIME [epoch: 30.5 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25648371826276234		[learning rate: 0.0058607]
	Learning Rate: 0.00586069
	LOSS [training: 0.25648371826276234 | validation: 0.20849381978073162]
	TIME [epoch: 78.7 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2585756927504373		[learning rate: 0.00584]
	Learning Rate: 0.00583996
	LOSS [training: 0.2585756927504373 | validation: 0.21619900792842248]
	TIME [epoch: 65 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26408391820898425		[learning rate: 0.0058193]
	Learning Rate: 0.00581931
	LOSS [training: 0.26408391820898425 | validation: 0.20833479455804219]
	TIME [epoch: 65.3 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25618569290876825		[learning rate: 0.0057987]
	Learning Rate: 0.00579874
	LOSS [training: 0.25618569290876825 | validation: 0.21187341312165042]
	TIME [epoch: 65.1 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24395200471301237		[learning rate: 0.0057782]
	Learning Rate: 0.00577823
	LOSS [training: 0.24395200471301237 | validation: 0.22206884618416717]
	TIME [epoch: 65.3 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24953521003727078		[learning rate: 0.0057578]
	Learning Rate: 0.0057578
	LOSS [training: 0.24953521003727078 | validation: 0.21958515215711802]
	TIME [epoch: 65.2 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25125067727825184		[learning rate: 0.0057374]
	Learning Rate: 0.00573744
	LOSS [training: 0.25125067727825184 | validation: 0.21756768187437353]
	TIME [epoch: 65.3 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2581716461767105		[learning rate: 0.0057171]
	Learning Rate: 0.00571715
	LOSS [training: 0.2581716461767105 | validation: 0.2346538194397517]
	TIME [epoch: 65.2 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2754157225952877		[learning rate: 0.0056969]
	Learning Rate: 0.00569693
	LOSS [training: 0.2754157225952877 | validation: 0.22383539136155867]
	TIME [epoch: 65.3 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2534035850015586		[learning rate: 0.0056768]
	Learning Rate: 0.00567679
	LOSS [training: 0.2534035850015586 | validation: 0.21089083400143127]
	TIME [epoch: 65 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2601552169843089		[learning rate: 0.0056567]
	Learning Rate: 0.00565671
	LOSS [training: 0.2601552169843089 | validation: 0.21486141898349978]
	TIME [epoch: 65.2 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24894356897757394		[learning rate: 0.0056367]
	Learning Rate: 0.00563671
	LOSS [training: 0.24894356897757394 | validation: 0.21112652228662454]
	TIME [epoch: 65.1 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2580694211862102		[learning rate: 0.0056168]
	Learning Rate: 0.00561678
	LOSS [training: 0.2580694211862102 | validation: 0.2159996724913345]
	TIME [epoch: 65.3 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2465577972894225		[learning rate: 0.0055969]
	Learning Rate: 0.00559691
	LOSS [training: 0.2465577972894225 | validation: 0.2184397814097109]
	TIME [epoch: 65.1 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24988187110040325		[learning rate: 0.0055771]
	Learning Rate: 0.00557712
	LOSS [training: 0.24988187110040325 | validation: 0.2175462397535947]
	TIME [epoch: 65.2 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25684477831017777		[learning rate: 0.0055574]
	Learning Rate: 0.0055574
	LOSS [training: 0.25684477831017777 | validation: 0.22139514245691508]
	TIME [epoch: 65.1 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25225863012905775		[learning rate: 0.0055378]
	Learning Rate: 0.00553775
	LOSS [training: 0.25225863012905775 | validation: 0.205505861700515]
	TIME [epoch: 65.2 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13b_20240719_005205/states/model_facs_v3_dec1b_2dpca_v13b_217.pth
	Model improved!!!
EPOCH 218/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2573525628382607		[learning rate: 0.0055182]
	Learning Rate: 0.00551817
	LOSS [training: 0.2573525628382607 | validation: 0.21304240250459477]
	TIME [epoch: 65.1 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.262285190083347		[learning rate: 0.0054987]
	Learning Rate: 0.00549865
	LOSS [training: 0.262285190083347 | validation: 0.2155548898596679]
	TIME [epoch: 65.1 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2601000243078287		[learning rate: 0.0054792]
	Learning Rate: 0.00547921
	LOSS [training: 0.2601000243078287 | validation: 0.209958593836842]
	TIME [epoch: 65.1 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.250790084296916		[learning rate: 0.0054598]
	Learning Rate: 0.00545983
	LOSS [training: 0.250790084296916 | validation: 0.21049426048263103]
	TIME [epoch: 65.2 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24930111169432764		[learning rate: 0.0054405]
	Learning Rate: 0.00544053
	LOSS [training: 0.24930111169432764 | validation: 0.21185475217062436]
	TIME [epoch: 65.2 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2577691969794258		[learning rate: 0.0054213]
	Learning Rate: 0.00542129
	LOSS [training: 0.2577691969794258 | validation: 0.21552168785718046]
	TIME [epoch: 65.3 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25884046109209286		[learning rate: 0.0054021]
	Learning Rate: 0.00540212
	LOSS [training: 0.25884046109209286 | validation: 0.22078551155281537]
	TIME [epoch: 65.2 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2638646867367077		[learning rate: 0.005383]
	Learning Rate: 0.00538302
	LOSS [training: 0.2638646867367077 | validation: 0.20519280169542453]
	TIME [epoch: 65.2 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13b_20240719_005205/states/model_facs_v3_dec1b_2dpca_v13b_225.pth
	Model improved!!!
EPOCH 226/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2516461026474658		[learning rate: 0.005364]
	Learning Rate: 0.00536398
	LOSS [training: 0.2516461026474658 | validation: 0.20742264944108085]
	TIME [epoch: 65 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2614471900658686		[learning rate: 0.005345]
	Learning Rate: 0.00534501
	LOSS [training: 0.2614471900658686 | validation: 0.22281810505999539]
	TIME [epoch: 65.1 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2640366174556458		[learning rate: 0.0053261]
	Learning Rate: 0.00532611
	LOSS [training: 0.2640366174556458 | validation: 0.21112292461145196]
	TIME [epoch: 65 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2555789146538696		[learning rate: 0.0053073]
	Learning Rate: 0.00530728
	LOSS [training: 0.2555789146538696 | validation: 0.21521941947147222]
	TIME [epoch: 65.2 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25705930044381997		[learning rate: 0.0052885]
	Learning Rate: 0.00528851
	LOSS [training: 0.25705930044381997 | validation: 0.2135437163910828]
	TIME [epoch: 65.2 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2542436358976205		[learning rate: 0.0052698]
	Learning Rate: 0.00526981
	LOSS [training: 0.2542436358976205 | validation: 0.21009821170833454]
	TIME [epoch: 65.1 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24949713771088536		[learning rate: 0.0052512]
	Learning Rate: 0.00525117
	LOSS [training: 0.24949713771088536 | validation: 0.21104096749343187]
	TIME [epoch: 65 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24790222309180676		[learning rate: 0.0052326]
	Learning Rate: 0.0052326
	LOSS [training: 0.24790222309180676 | validation: 0.21025664139824923]
	TIME [epoch: 65.1 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2563740322264275		[learning rate: 0.0052141]
	Learning Rate: 0.0052141
	LOSS [training: 0.2563740322264275 | validation: 0.2158325542242006]
	TIME [epoch: 65 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25302450708511953		[learning rate: 0.0051957]
	Learning Rate: 0.00519566
	LOSS [training: 0.25302450708511953 | validation: 0.21514516176341908]
	TIME [epoch: 65.1 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2510922102235143		[learning rate: 0.0051773]
	Learning Rate: 0.00517729
	LOSS [training: 0.2510922102235143 | validation: 0.21790758436573898]
	TIME [epoch: 65 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25101247860756554		[learning rate: 0.005159]
	Learning Rate: 0.00515898
	LOSS [training: 0.25101247860756554 | validation: 0.21337596768594383]
	TIME [epoch: 65.1 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2527265836298643		[learning rate: 0.0051407]
	Learning Rate: 0.00514074
	LOSS [training: 0.2527265836298643 | validation: 0.21145095475785963]
	TIME [epoch: 65 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2511487408839271		[learning rate: 0.0051226]
	Learning Rate: 0.00512256
	LOSS [training: 0.2511487408839271 | validation: 0.21990725964545305]
	TIME [epoch: 65.1 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2579099164423673		[learning rate: 0.0051044]
	Learning Rate: 0.00510445
	LOSS [training: 0.2579099164423673 | validation: 0.21264178075036902]
	TIME [epoch: 65.1 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2464471872853717		[learning rate: 0.0050864]
	Learning Rate: 0.0050864
	LOSS [training: 0.2464471872853717 | validation: 0.21751011656394303]
	TIME [epoch: 65 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25537081849232734		[learning rate: 0.0050684]
	Learning Rate: 0.00506841
	LOSS [training: 0.25537081849232734 | validation: 0.2165284869012029]
	TIME [epoch: 65.1 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2551190602902494		[learning rate: 0.0050505]
	Learning Rate: 0.00505049
	LOSS [training: 0.2551190602902494 | validation: 0.21351243284812488]
	TIME [epoch: 65.1 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2533154365444629		[learning rate: 0.0050326]
	Learning Rate: 0.00503263
	LOSS [training: 0.2533154365444629 | validation: 0.214340312156503]
	TIME [epoch: 65.1 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25257747052157625		[learning rate: 0.0050148]
	Learning Rate: 0.00501483
	LOSS [training: 0.25257747052157625 | validation: 0.21740817174112048]
	TIME [epoch: 65.1 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2516531696764716		[learning rate: 0.0049971]
	Learning Rate: 0.0049971
	LOSS [training: 0.2516531696764716 | validation: 0.20749313941858794]
	TIME [epoch: 65 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25426177637688274		[learning rate: 0.0049794]
	Learning Rate: 0.00497943
	LOSS [training: 0.25426177637688274 | validation: 0.22055821784698454]
	TIME [epoch: 65.1 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24852595049176776		[learning rate: 0.0049618]
	Learning Rate: 0.00496182
	LOSS [training: 0.24852595049176776 | validation: 0.21230474721310405]
	TIME [epoch: 65.1 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25935320023407954		[learning rate: 0.0049443]
	Learning Rate: 0.00494427
	LOSS [training: 0.25935320023407954 | validation: 0.2149892519323267]
	TIME [epoch: 65 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2502167601921684		[learning rate: 0.0049268]
	Learning Rate: 0.00492679
	LOSS [training: 0.2502167601921684 | validation: 0.2131408272576479]
	TIME [epoch: 65 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25277545723512357		[learning rate: 0.0049094]
	Learning Rate: 0.00490937
	LOSS [training: 0.25277545723512357 | validation: 0.21163970966240112]
	TIME [epoch: 65.1 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2581425662248007		[learning rate: 0.004892]
	Learning Rate: 0.00489201
	LOSS [training: 0.2581425662248007 | validation: 0.21086259957134548]
	TIME [epoch: 65.1 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24529791134534973		[learning rate: 0.0048747]
	Learning Rate: 0.00487471
	LOSS [training: 0.24529791134534973 | validation: 0.2037989616702885]
	TIME [epoch: 65 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13b_20240719_005205/states/model_facs_v3_dec1b_2dpca_v13b_253.pth
	Model improved!!!
EPOCH 254/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25122819611763053		[learning rate: 0.0048575]
	Learning Rate: 0.00485747
	LOSS [training: 0.25122819611763053 | validation: 0.20830045130456282]
	TIME [epoch: 64.7 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2613949762451646		[learning rate: 0.0048403]
	Learning Rate: 0.00484029
	LOSS [training: 0.2613949762451646 | validation: 0.20705209153892837]
	TIME [epoch: 65 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25418097582003113		[learning rate: 0.0048232]
	Learning Rate: 0.00482318
	LOSS [training: 0.25418097582003113 | validation: 0.20630396561798917]
	TIME [epoch: 65 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24656965669951494		[learning rate: 0.0048061]
	Learning Rate: 0.00480612
	LOSS [training: 0.24656965669951494 | validation: 0.21173355997817858]
	TIME [epoch: 65.1 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2574099853192858		[learning rate: 0.0047891]
	Learning Rate: 0.00478913
	LOSS [training: 0.2574099853192858 | validation: 0.20914243322561915]
	TIME [epoch: 64.9 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2580539668632302		[learning rate: 0.0047722]
	Learning Rate: 0.00477219
	LOSS [training: 0.2580539668632302 | validation: 0.20780706788723396]
	TIME [epoch: 65.1 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24709874096992535		[learning rate: 0.0047553]
	Learning Rate: 0.00475532
	LOSS [training: 0.24709874096992535 | validation: 0.20992487942696192]
	TIME [epoch: 65.1 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.252610822898623		[learning rate: 0.0047385]
	Learning Rate: 0.0047385
	LOSS [training: 0.252610822898623 | validation: 0.2119602110145137]
	TIME [epoch: 65.1 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25983541034773855		[learning rate: 0.0047217]
	Learning Rate: 0.00472175
	LOSS [training: 0.25983541034773855 | validation: 0.2145719373452319]
	TIME [epoch: 65.1 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2508219260631935		[learning rate: 0.004705]
	Learning Rate: 0.00470505
	LOSS [training: 0.2508219260631935 | validation: 0.2122912992020874]
	TIME [epoch: 65.1 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2522054108800968		[learning rate: 0.0046884]
	Learning Rate: 0.00468841
	LOSS [training: 0.2522054108800968 | validation: 0.21496866099568068]
	TIME [epoch: 65.2 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2504291083485584		[learning rate: 0.0046718]
	Learning Rate: 0.00467183
	LOSS [training: 0.2504291083485584 | validation: 0.2196409826990294]
	TIME [epoch: 65.2 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2573729970908225		[learning rate: 0.0046553]
	Learning Rate: 0.00465531
	LOSS [training: 0.2573729970908225 | validation: 0.21290639574828618]
	TIME [epoch: 65 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2537442761411925		[learning rate: 0.0046388]
	Learning Rate: 0.00463885
	LOSS [training: 0.2537442761411925 | validation: 0.20877928160045273]
	TIME [epoch: 65.1 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24700664285829532		[learning rate: 0.0046224]
	Learning Rate: 0.00462245
	LOSS [training: 0.24700664285829532 | validation: 0.20876994932591733]
	TIME [epoch: 65 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2564584718812111		[learning rate: 0.0046061]
	Learning Rate: 0.0046061
	LOSS [training: 0.2564584718812111 | validation: 0.2139053350653078]
	TIME [epoch: 65 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2505757132308616		[learning rate: 0.0045898]
	Learning Rate: 0.00458981
	LOSS [training: 0.2505757132308616 | validation: 0.20698644557036996]
	TIME [epoch: 65.1 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2550789287833914		[learning rate: 0.0045736]
	Learning Rate: 0.00457358
	LOSS [training: 0.2550789287833914 | validation: 0.20541037507732166]
	TIME [epoch: 64.8 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24913959150666798		[learning rate: 0.0045574]
	Learning Rate: 0.00455741
	LOSS [training: 0.24913959150666798 | validation: 0.21228239469170532]
	TIME [epoch: 65.1 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25474786863134596		[learning rate: 0.0045413]
	Learning Rate: 0.00454129
	LOSS [training: 0.25474786863134596 | validation: 0.2078320419145691]
	TIME [epoch: 64.9 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24394814252032407		[learning rate: 0.0045252]
	Learning Rate: 0.00452523
	LOSS [training: 0.24394814252032407 | validation: 0.22051846413936177]
	TIME [epoch: 65 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2560323746700584		[learning rate: 0.0045092]
	Learning Rate: 0.00450923
	LOSS [training: 0.2560323746700584 | validation: 0.21095037110495668]
	TIME [epoch: 65.1 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2431444898190008		[learning rate: 0.0044933]
	Learning Rate: 0.00449329
	LOSS [training: 0.2431444898190008 | validation: 0.20718925233641255]
	TIME [epoch: 65 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25024314826882094		[learning rate: 0.0044774]
	Learning Rate: 0.0044774
	LOSS [training: 0.25024314826882094 | validation: 0.21402049423464048]
	TIME [epoch: 65 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2464447207322248		[learning rate: 0.0044616]
	Learning Rate: 0.00446156
	LOSS [training: 0.2464447207322248 | validation: 0.20601729303619543]
	TIME [epoch: 65 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2562682844874644		[learning rate: 0.0044458]
	Learning Rate: 0.00444579
	LOSS [training: 0.2562682844874644 | validation: 0.20947940470833357]
	TIME [epoch: 65.1 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25639908797209304		[learning rate: 0.0044301]
	Learning Rate: 0.00443007
	LOSS [training: 0.25639908797209304 | validation: 0.21025877189415693]
	TIME [epoch: 65.1 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25096274692792253		[learning rate: 0.0044144]
	Learning Rate: 0.0044144
	LOSS [training: 0.25096274692792253 | validation: 0.21441733459355872]
	TIME [epoch: 65 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2510782638875866		[learning rate: 0.0043988]
	Learning Rate: 0.00439879
	LOSS [training: 0.2510782638875866 | validation: 0.207783809541617]
	TIME [epoch: 65.1 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2531240244560196		[learning rate: 0.0043832]
	Learning Rate: 0.00438324
	LOSS [training: 0.2531240244560196 | validation: 0.20726855728247076]
	TIME [epoch: 65.1 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24904035792977577		[learning rate: 0.0043677]
	Learning Rate: 0.00436774
	LOSS [training: 0.24904035792977577 | validation: 0.20512500654028779]
	TIME [epoch: 65 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.252292611578756		[learning rate: 0.0043523]
	Learning Rate: 0.00435229
	LOSS [training: 0.252292611578756 | validation: 0.20923640265277546]
	TIME [epoch: 65.1 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2551609202385851		[learning rate: 0.0043369]
	Learning Rate: 0.0043369
	LOSS [training: 0.2551609202385851 | validation: 0.21249097141511983]
	TIME [epoch: 65 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2487765922074836		[learning rate: 0.0043216]
	Learning Rate: 0.00432156
	LOSS [training: 0.2487765922074836 | validation: 0.22334762317803483]
	TIME [epoch: 65 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25378330696001716		[learning rate: 0.0043063]
	Learning Rate: 0.00430628
	LOSS [training: 0.25378330696001716 | validation: 0.21124577029363953]
	TIME [epoch: 65 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2519240764604668		[learning rate: 0.0042911]
	Learning Rate: 0.00429106
	LOSS [training: 0.2519240764604668 | validation: 0.21321531538003885]
	TIME [epoch: 65 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2516809536032849		[learning rate: 0.0042759]
	Learning Rate: 0.00427588
	LOSS [training: 0.2516809536032849 | validation: 0.2151203527809514]
	TIME [epoch: 65.2 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25235551849285714		[learning rate: 0.0042608]
	Learning Rate: 0.00426076
	LOSS [training: 0.25235551849285714 | validation: 0.21651018738897165]
	TIME [epoch: 64.9 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24855101629037937		[learning rate: 0.0042457]
	Learning Rate: 0.00424569
	LOSS [training: 0.24855101629037937 | validation: 0.21307326662917517]
	TIME [epoch: 65 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24592777784340633		[learning rate: 0.0042307]
	Learning Rate: 0.00423068
	LOSS [training: 0.24592777784340633 | validation: 0.2085815475338202]
	TIME [epoch: 65 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24932017060600645		[learning rate: 0.0042157]
	Learning Rate: 0.00421572
	LOSS [training: 0.24932017060600645 | validation: 0.2188035722577964]
	TIME [epoch: 65.1 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24589014031999631		[learning rate: 0.0042008]
	Learning Rate: 0.00420081
	LOSS [training: 0.24589014031999631 | validation: 0.20791017741742]
	TIME [epoch: 65 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2532415641368389		[learning rate: 0.004186]
	Learning Rate: 0.00418596
	LOSS [training: 0.2532415641368389 | validation: 0.21120900833418652]
	TIME [epoch: 65.1 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25114966475869		[learning rate: 0.0041712]
	Learning Rate: 0.00417116
	LOSS [training: 0.25114966475869 | validation: 0.2067537139076645]
	TIME [epoch: 65 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2538215129272505		[learning rate: 0.0041564]
	Learning Rate: 0.00415641
	LOSS [training: 0.2538215129272505 | validation: 0.20605775115804467]
	TIME [epoch: 64.9 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2521190735652654		[learning rate: 0.0041417]
	Learning Rate: 0.00414171
	LOSS [training: 0.2521190735652654 | validation: 0.2103539127245039]
	TIME [epoch: 64.9 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24899927616840245		[learning rate: 0.0041271]
	Learning Rate: 0.00412706
	LOSS [training: 0.24899927616840245 | validation: 0.2089936010553041]
	TIME [epoch: 65.1 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24770547594253697		[learning rate: 0.0041125]
	Learning Rate: 0.00411247
	LOSS [training: 0.24770547594253697 | validation: 0.21518608709516754]
	TIME [epoch: 149 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2519543557225526		[learning rate: 0.0040979]
	Learning Rate: 0.00409793
	LOSS [training: 0.2519543557225526 | validation: 0.21588524265691325]
	TIME [epoch: 134 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24838438877303715		[learning rate: 0.0040834]
	Learning Rate: 0.00408344
	LOSS [training: 0.24838438877303715 | validation: 0.21087259503181627]
	TIME [epoch: 135 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24724119716851192		[learning rate: 0.004069]
	Learning Rate: 0.004069
	LOSS [training: 0.24724119716851192 | validation: 0.21184730000850052]
	TIME [epoch: 134 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24886694026952053		[learning rate: 0.0040546]
	Learning Rate: 0.00405461
	LOSS [training: 0.24886694026952053 | validation: 0.2032770483344149]
	TIME [epoch: 135 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13b_20240719_005205/states/model_facs_v3_dec1b_2dpca_v13b_305.pth
	Model improved!!!
EPOCH 306/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2565029633500719		[learning rate: 0.0040403]
	Learning Rate: 0.00404027
	LOSS [training: 0.2565029633500719 | validation: 0.20952386717274968]
	TIME [epoch: 134 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24786228561489812		[learning rate: 0.004026]
	Learning Rate: 0.00402598
	LOSS [training: 0.24786228561489812 | validation: 0.21068422032571404]
	TIME [epoch: 134 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2493678511432975		[learning rate: 0.0040117]
	Learning Rate: 0.00401175
	LOSS [training: 0.2493678511432975 | validation: 0.2124892529457406]
	TIME [epoch: 134 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24637134396058724		[learning rate: 0.0039976]
	Learning Rate: 0.00399756
	LOSS [training: 0.24637134396058724 | validation: 0.21607819675616668]
	TIME [epoch: 135 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.252939280920127		[learning rate: 0.0039834]
	Learning Rate: 0.00398342
	LOSS [training: 0.252939280920127 | validation: 0.21715698617896498]
	TIME [epoch: 134 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24839064776894848		[learning rate: 0.0039693]
	Learning Rate: 0.00396934
	LOSS [training: 0.24839064776894848 | validation: 0.210108904605876]
	TIME [epoch: 134 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25372389618141195		[learning rate: 0.0039553]
	Learning Rate: 0.0039553
	LOSS [training: 0.25372389618141195 | validation: 0.2129143533495433]
	TIME [epoch: 134 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24466109420487		[learning rate: 0.0039413]
	Learning Rate: 0.00394131
	LOSS [training: 0.24466109420487 | validation: 0.2131322389194159]
	TIME [epoch: 135 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25327594408369675		[learning rate: 0.0039274]
	Learning Rate: 0.00392738
	LOSS [training: 0.25327594408369675 | validation: 0.20393401563917637]
	TIME [epoch: 135 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24605723953420586		[learning rate: 0.0039135]
	Learning Rate: 0.00391349
	LOSS [training: 0.24605723953420586 | validation: 0.21828481178823766]
	TIME [epoch: 134 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2476088072979871		[learning rate: 0.0038997]
	Learning Rate: 0.00389965
	LOSS [training: 0.2476088072979871 | validation: 0.21179606853888341]
	TIME [epoch: 134 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24496704257500843		[learning rate: 0.0038859]
	Learning Rate: 0.00388586
	LOSS [training: 0.24496704257500843 | validation: 0.2094617195709913]
	TIME [epoch: 135 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2575232826599692		[learning rate: 0.0038721]
	Learning Rate: 0.00387212
	LOSS [training: 0.2575232826599692 | validation: 0.20575199330206134]
	TIME [epoch: 134 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25449854122733184		[learning rate: 0.0038584]
	Learning Rate: 0.00385843
	LOSS [training: 0.25449854122733184 | validation: 0.21163156495057187]
	TIME [epoch: 134 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2500196162530564		[learning rate: 0.0038448]
	Learning Rate: 0.00384478
	LOSS [training: 0.2500196162530564 | validation: 0.2101184093314762]
	TIME [epoch: 134 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25129839016053984		[learning rate: 0.0038312]
	Learning Rate: 0.00383119
	LOSS [training: 0.25129839016053984 | validation: 0.20885073343615362]
	TIME [epoch: 134 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25308123123248677		[learning rate: 0.0038176]
	Learning Rate: 0.00381764
	LOSS [training: 0.25308123123248677 | validation: 0.2104360435534308]
	TIME [epoch: 134 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25442177648460923		[learning rate: 0.0038041]
	Learning Rate: 0.00380414
	LOSS [training: 0.25442177648460923 | validation: 0.2124488313106927]
	TIME [epoch: 134 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24790034761342916		[learning rate: 0.0037907]
	Learning Rate: 0.00379069
	LOSS [training: 0.24790034761342916 | validation: 0.213836047366568]
	TIME [epoch: 134 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25564313030312663		[learning rate: 0.0037773]
	Learning Rate: 0.00377728
	LOSS [training: 0.25564313030312663 | validation: 0.20278500277467515]
	TIME [epoch: 134 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13b_20240719_005205/states/model_facs_v3_dec1b_2dpca_v13b_325.pth
	Model improved!!!
EPOCH 326/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2523096824965004		[learning rate: 0.0037639]
	Learning Rate: 0.00376393
	LOSS [training: 0.2523096824965004 | validation: 0.21773390537479081]
	TIME [epoch: 134 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24830785422990662		[learning rate: 0.0037506]
	Learning Rate: 0.00375062
	LOSS [training: 0.24830785422990662 | validation: 0.21097127213950712]
	TIME [epoch: 134 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2580096025925586		[learning rate: 0.0037374]
	Learning Rate: 0.00373735
	LOSS [training: 0.2580096025925586 | validation: 0.222150936344731]
	TIME [epoch: 134 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25222756939082625		[learning rate: 0.0037241]
	Learning Rate: 0.00372414
	LOSS [training: 0.25222756939082625 | validation: 0.2174541843095846]
	TIME [epoch: 134 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.258226131870469		[learning rate: 0.003711]
	Learning Rate: 0.00371097
	LOSS [training: 0.258226131870469 | validation: 0.22167177597686485]
	TIME [epoch: 134 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25091905459276687		[learning rate: 0.0036978]
	Learning Rate: 0.00369785
	LOSS [training: 0.25091905459276687 | validation: 0.21748751005453365]
	TIME [epoch: 135 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2571217120026197		[learning rate: 0.0036848]
	Learning Rate: 0.00368477
	LOSS [training: 0.2571217120026197 | validation: 0.22084353254257233]
	TIME [epoch: 134 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2450560826004842		[learning rate: 0.0036717]
	Learning Rate: 0.00367174
	LOSS [training: 0.2450560826004842 | validation: 0.20962042223938204]
	TIME [epoch: 134 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24776841423980045		[learning rate: 0.0036588]
	Learning Rate: 0.00365875
	LOSS [training: 0.24776841423980045 | validation: 0.21148305207332868]
	TIME [epoch: 135 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25097226831545855		[learning rate: 0.0036458]
	Learning Rate: 0.00364582
	LOSS [training: 0.25097226831545855 | validation: 0.21866539245733038]
	TIME [epoch: 134 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2545368657095353		[learning rate: 0.0036329]
	Learning Rate: 0.00363292
	LOSS [training: 0.2545368657095353 | validation: 0.21354864275329968]
	TIME [epoch: 135 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2457379631629403		[learning rate: 0.0036201]
	Learning Rate: 0.00362008
	LOSS [training: 0.2457379631629403 | validation: 0.2071211178422821]
	TIME [epoch: 134 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.257271276217888		[learning rate: 0.0036073]
	Learning Rate: 0.00360728
	LOSS [training: 0.257271276217888 | validation: 0.21898965883563487]
	TIME [epoch: 134 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24856371775057376		[learning rate: 0.0035945]
	Learning Rate: 0.00359452
	LOSS [training: 0.24856371775057376 | validation: 0.21581167670544774]
	TIME [epoch: 135 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24806653239423893		[learning rate: 0.0035818]
	Learning Rate: 0.00358181
	LOSS [training: 0.24806653239423893 | validation: 0.2047656994249436]
	TIME [epoch: 134 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24307225056657314		[learning rate: 0.0035691]
	Learning Rate: 0.00356914
	LOSS [training: 0.24307225056657314 | validation: 0.21037374542061923]
	TIME [epoch: 134 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24879179565488022		[learning rate: 0.0035565]
	Learning Rate: 0.00355652
	LOSS [training: 0.24879179565488022 | validation: 0.2087445934450925]
	TIME [epoch: 134 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24701339161447444		[learning rate: 0.0035439]
	Learning Rate: 0.00354395
	LOSS [training: 0.24701339161447444 | validation: 0.20962159477178405]
	TIME [epoch: 135 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24876108846653797		[learning rate: 0.0035314]
	Learning Rate: 0.00353141
	LOSS [training: 0.24876108846653797 | validation: 0.21330514215052884]
	TIME [epoch: 134 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24674908101586182		[learning rate: 0.0035189]
	Learning Rate: 0.00351893
	LOSS [training: 0.24674908101586182 | validation: 0.21063676033072695]
	TIME [epoch: 134 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2541083552612385		[learning rate: 0.0035065]
	Learning Rate: 0.00350648
	LOSS [training: 0.2541083552612385 | validation: 0.2054420123425889]
	TIME [epoch: 134 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24673614856127346		[learning rate: 0.0034941]
	Learning Rate: 0.00349408
	LOSS [training: 0.24673614856127346 | validation: 0.22234838029150533]
	TIME [epoch: 134 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24867156676242508		[learning rate: 0.0034817]
	Learning Rate: 0.00348173
	LOSS [training: 0.24867156676242508 | validation: 0.2176935617535968]
	TIME [epoch: 134 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2487162056652947		[learning rate: 0.0034694]
	Learning Rate: 0.00346942
	LOSS [training: 0.2487162056652947 | validation: 0.22034187529348853]
	TIME [epoch: 134 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25353689211611263		[learning rate: 0.0034571]
	Learning Rate: 0.00345715
	LOSS [training: 0.25353689211611263 | validation: 0.20762535957100078]
	TIME [epoch: 134 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24600178459893962		[learning rate: 0.0034449]
	Learning Rate: 0.00344492
	LOSS [training: 0.24600178459893962 | validation: 0.21364953563396485]
	TIME [epoch: 134 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24202461298624542		[learning rate: 0.0034327]
	Learning Rate: 0.00343274
	LOSS [training: 0.24202461298624542 | validation: 0.20943724936661196]
	TIME [epoch: 134 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2503922029079839		[learning rate: 0.0034206]
	Learning Rate: 0.0034206
	LOSS [training: 0.2503922029079839 | validation: 0.21198501483557916]
	TIME [epoch: 134 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24695338174204504		[learning rate: 0.0034085]
	Learning Rate: 0.00340851
	LOSS [training: 0.24695338174204504 | validation: 0.21269448141861597]
	TIME [epoch: 134 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24261005428138294		[learning rate: 0.0033965]
	Learning Rate: 0.00339645
	LOSS [training: 0.24261005428138294 | validation: 0.2128304012572722]
	TIME [epoch: 135 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2469361639613549		[learning rate: 0.0033844]
	Learning Rate: 0.00338444
	LOSS [training: 0.2469361639613549 | validation: 0.21564217718810888]
	TIME [epoch: 134 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24890956232776995		[learning rate: 0.0033725]
	Learning Rate: 0.00337247
	LOSS [training: 0.24890956232776995 | validation: 0.20614883236922257]
	TIME [epoch: 134 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24835587814020899		[learning rate: 0.0033605]
	Learning Rate: 0.00336055
	LOSS [training: 0.24835587814020899 | validation: 0.2143890172593533]
	TIME [epoch: 134 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2489748573932902		[learning rate: 0.0033487]
	Learning Rate: 0.00334867
	LOSS [training: 0.2489748573932902 | validation: 0.20568413722604792]
	TIME [epoch: 134 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2505484235380923		[learning rate: 0.0033368]
	Learning Rate: 0.00333682
	LOSS [training: 0.2505484235380923 | validation: 0.21086663518852147]
	TIME [epoch: 134 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2509915629981896		[learning rate: 0.003325]
	Learning Rate: 0.00332502
	LOSS [training: 0.2509915629981896 | validation: 0.21133455867736622]
	TIME [epoch: 134 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2418714928284775		[learning rate: 0.0033133]
	Learning Rate: 0.00331327
	LOSS [training: 0.2418714928284775 | validation: 0.20890209839888058]
	TIME [epoch: 134 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2505925869169939		[learning rate: 0.0033016]
	Learning Rate: 0.00330155
	LOSS [training: 0.2505925869169939 | validation: 0.20883844902347892]
	TIME [epoch: 134 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24255263890441126		[learning rate: 0.0032899]
	Learning Rate: 0.00328988
	LOSS [training: 0.24255263890441126 | validation: 0.21209204517240812]
	TIME [epoch: 134 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2428600855595632		[learning rate: 0.0032782]
	Learning Rate: 0.00327824
	LOSS [training: 0.2428600855595632 | validation: 0.21296177108609626]
	TIME [epoch: 135 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24892832861968683		[learning rate: 0.0032666]
	Learning Rate: 0.00326665
	LOSS [training: 0.24892832861968683 | validation: 0.20934740314544475]
	TIME [epoch: 134 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24986345736481144		[learning rate: 0.0032551]
	Learning Rate: 0.0032551
	LOSS [training: 0.24986345736481144 | validation: 0.2108105591240536]
	TIME [epoch: 134 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24691592249866232		[learning rate: 0.0032436]
	Learning Rate: 0.00324359
	LOSS [training: 0.24691592249866232 | validation: 0.21260657848673037]
	TIME [epoch: 134 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25425991732946823		[learning rate: 0.0032321]
	Learning Rate: 0.00323212
	LOSS [training: 0.25425991732946823 | validation: 0.20821932852500558]
	TIME [epoch: 134 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.248181856978728		[learning rate: 0.0032207]
	Learning Rate: 0.00322069
	LOSS [training: 0.248181856978728 | validation: 0.20280853245903502]
	TIME [epoch: 134 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24224374875059496		[learning rate: 0.0032093]
	Learning Rate: 0.0032093
	LOSS [training: 0.24224374875059496 | validation: 0.21220522750753057]
	TIME [epoch: 134 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24347611722300888		[learning rate: 0.003198]
	Learning Rate: 0.00319795
	LOSS [training: 0.24347611722300888 | validation: 0.20905852519556758]
	TIME [epoch: 134 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2521846114099227		[learning rate: 0.0031866]
	Learning Rate: 0.00318664
	LOSS [training: 0.2521846114099227 | validation: 0.21769765960810722]
	TIME [epoch: 134 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24973453193488315		[learning rate: 0.0031754]
	Learning Rate: 0.00317537
	LOSS [training: 0.24973453193488315 | validation: 0.20260531178565327]
	TIME [epoch: 134 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13b_20240719_005205/states/model_facs_v3_dec1b_2dpca_v13b_374.pth
	Model improved!!!
EPOCH 375/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24560676160833247		[learning rate: 0.0031641]
	Learning Rate: 0.00316415
	LOSS [training: 0.24560676160833247 | validation: 0.2099351064129797]
	TIME [epoch: 133 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.248263020137935		[learning rate: 0.003153]
	Learning Rate: 0.00315296
	LOSS [training: 0.248263020137935 | validation: 0.20131067551883128]
	TIME [epoch: 133 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13b_20240719_005205/states/model_facs_v3_dec1b_2dpca_v13b_376.pth
	Model improved!!!
EPOCH 377/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25100247920975716		[learning rate: 0.0031418]
	Learning Rate: 0.00314181
	LOSS [training: 0.25100247920975716 | validation: 0.21283424728994751]
	TIME [epoch: 133 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2459547244659468		[learning rate: 0.0031307]
	Learning Rate: 0.0031307
	LOSS [training: 0.2459547244659468 | validation: 0.21275124159999229]
	TIME [epoch: 133 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2509046016641787		[learning rate: 0.0031196]
	Learning Rate: 0.00311963
	LOSS [training: 0.2509046016641787 | validation: 0.21457014125237944]
	TIME [epoch: 133 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24903920226477028		[learning rate: 0.0031086]
	Learning Rate: 0.00310859
	LOSS [training: 0.24903920226477028 | validation: 0.2139589860552802]
	TIME [epoch: 133 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24904271891946683		[learning rate: 0.0030976]
	Learning Rate: 0.0030976
	LOSS [training: 0.24904271891946683 | validation: 0.20852795529020476]
	TIME [epoch: 133 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24360731972767555		[learning rate: 0.0030866]
	Learning Rate: 0.00308665
	LOSS [training: 0.24360731972767555 | validation: 0.20864317497980278]
	TIME [epoch: 133 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2436594544150351		[learning rate: 0.0030757]
	Learning Rate: 0.00307573
	LOSS [training: 0.2436594544150351 | validation: 0.2101208141501488]
	TIME [epoch: 133 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24837632345836713		[learning rate: 0.0030649]
	Learning Rate: 0.00306486
	LOSS [training: 0.24837632345836713 | validation: 0.20548420596800726]
	TIME [epoch: 133 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25244823172873304		[learning rate: 0.003054]
	Learning Rate: 0.00305402
	LOSS [training: 0.25244823172873304 | validation: 0.20422214106835845]
	TIME [epoch: 133 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2506600741669742		[learning rate: 0.0030432]
	Learning Rate: 0.00304322
	LOSS [training: 0.2506600741669742 | validation: 0.20694734453248578]
	TIME [epoch: 133 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24494246171415401		[learning rate: 0.0030325]
	Learning Rate: 0.00303246
	LOSS [training: 0.24494246171415401 | validation: 0.21012147018066352]
	TIME [epoch: 133 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24895100185666727		[learning rate: 0.0030217]
	Learning Rate: 0.00302174
	LOSS [training: 0.24895100185666727 | validation: 0.2048052717706743]
	TIME [epoch: 133 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24892363943616505		[learning rate: 0.003011]
	Learning Rate: 0.00301105
	LOSS [training: 0.24892363943616505 | validation: 0.20833003543247797]
	TIME [epoch: 133 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24733699555833133		[learning rate: 0.0030004]
	Learning Rate: 0.0030004
	LOSS [training: 0.24733699555833133 | validation: 0.21592571190892187]
	TIME [epoch: 134 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24689265631758958		[learning rate: 0.0029898]
	Learning Rate: 0.00298979
	LOSS [training: 0.24689265631758958 | validation: 0.21444770619165845]
	TIME [epoch: 134 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25145379232478887		[learning rate: 0.0029792]
	Learning Rate: 0.00297922
	LOSS [training: 0.25145379232478887 | validation: 0.20844434448178878]
	TIME [epoch: 134 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2533483802587907		[learning rate: 0.0029687]
	Learning Rate: 0.00296869
	LOSS [training: 0.2533483802587907 | validation: 0.20539221580718667]
	TIME [epoch: 134 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24673595046540334		[learning rate: 0.0029582]
	Learning Rate: 0.00295819
	LOSS [training: 0.24673595046540334 | validation: 0.2062321531844044]
	TIME [epoch: 134 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24727413450673064		[learning rate: 0.0029477]
	Learning Rate: 0.00294773
	LOSS [training: 0.24727413450673064 | validation: 0.20778253077590958]
	TIME [epoch: 134 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24166696425881773		[learning rate: 0.0029373]
	Learning Rate: 0.0029373
	LOSS [training: 0.24166696425881773 | validation: 0.20889705135417577]
	TIME [epoch: 134 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2506040028229264		[learning rate: 0.0029269]
	Learning Rate: 0.00292692
	LOSS [training: 0.2506040028229264 | validation: 0.20768384915985422]
	TIME [epoch: 134 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24892704738697669		[learning rate: 0.0029166]
	Learning Rate: 0.00291657
	LOSS [training: 0.24892704738697669 | validation: 0.21268833252966993]
	TIME [epoch: 134 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2512421493404326		[learning rate: 0.0029063]
	Learning Rate: 0.00290625
	LOSS [training: 0.2512421493404326 | validation: 0.20818274739228074]
	TIME [epoch: 134 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.244127090920219		[learning rate: 0.002896]
	Learning Rate: 0.00289598
	LOSS [training: 0.244127090920219 | validation: 0.206524949870397]
	TIME [epoch: 134 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24970037440125284		[learning rate: 0.0028857]
	Learning Rate: 0.00288573
	LOSS [training: 0.24970037440125284 | validation: 0.21152666817795795]
	TIME [epoch: 133 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2460766782403004		[learning rate: 0.0028755]
	Learning Rate: 0.00287553
	LOSS [training: 0.2460766782403004 | validation: 0.21105286187126912]
	TIME [epoch: 133 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24862107655374963		[learning rate: 0.0028654]
	Learning Rate: 0.00286536
	LOSS [training: 0.24862107655374963 | validation: 0.20906979518466642]
	TIME [epoch: 134 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24656330703422122		[learning rate: 0.0028552]
	Learning Rate: 0.00285523
	LOSS [training: 0.24656330703422122 | validation: 0.20766298344645517]
	TIME [epoch: 134 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2427247838778427		[learning rate: 0.0028451]
	Learning Rate: 0.00284513
	LOSS [training: 0.2427247838778427 | validation: 0.211347186935193]
	TIME [epoch: 134 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24190141146716604		[learning rate: 0.0028351]
	Learning Rate: 0.00283507
	LOSS [training: 0.24190141146716604 | validation: 0.21377349164520823]
	TIME [epoch: 134 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2439083652052878		[learning rate: 0.002825]
	Learning Rate: 0.00282505
	LOSS [training: 0.2439083652052878 | validation: 0.20955992725789652]
	TIME [epoch: 134 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24833197678898847		[learning rate: 0.0028151]
	Learning Rate: 0.00281506
	LOSS [training: 0.24833197678898847 | validation: 0.20973190590261245]
	TIME [epoch: 134 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24612617521254312		[learning rate: 0.0028051]
	Learning Rate: 0.0028051
	LOSS [training: 0.24612617521254312 | validation: 0.213102795121894]
	TIME [epoch: 134 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2523267292176891		[learning rate: 0.0027952]
	Learning Rate: 0.00279518
	LOSS [training: 0.2523267292176891 | validation: 0.21130692885771946]
	TIME [epoch: 134 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24763115813504297		[learning rate: 0.0027853]
	Learning Rate: 0.0027853
	LOSS [training: 0.24763115813504297 | validation: 0.20954884091053624]
	TIME [epoch: 134 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24812454740742687		[learning rate: 0.0027754]
	Learning Rate: 0.00277545
	LOSS [training: 0.24812454740742687 | validation: 0.2134593723090843]
	TIME [epoch: 134 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24785714916941204		[learning rate: 0.0027656]
	Learning Rate: 0.00276564
	LOSS [training: 0.24785714916941204 | validation: 0.2138377084945236]
	TIME [epoch: 134 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2545147568629315		[learning rate: 0.0027559]
	Learning Rate: 0.00275586
	LOSS [training: 0.2545147568629315 | validation: 0.21679449966803627]
	TIME [epoch: 134 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24857788961689042		[learning rate: 0.0027461]
	Learning Rate: 0.00274611
	LOSS [training: 0.24857788961689042 | validation: 0.21083131212995337]
	TIME [epoch: 134 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24732375335820497		[learning rate: 0.0027364]
	Learning Rate: 0.0027364
	LOSS [training: 0.24732375335820497 | validation: 0.20027514214541825]
	TIME [epoch: 134 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13b_20240719_005205/states/model_facs_v3_dec1b_2dpca_v13b_416.pth
	Model improved!!!
EPOCH 417/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24598029378165806		[learning rate: 0.0027267]
	Learning Rate: 0.00272672
	LOSS [training: 0.24598029378165806 | validation: 0.20879240624990456]
	TIME [epoch: 133 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24097380668812476		[learning rate: 0.0027171]
	Learning Rate: 0.00271708
	LOSS [training: 0.24097380668812476 | validation: 0.21087525996601664]
	TIME [epoch: 134 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24348015811702675		[learning rate: 0.0027075]
	Learning Rate: 0.00270747
	LOSS [training: 0.24348015811702675 | validation: 0.21737590061838752]
	TIME [epoch: 134 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2538515489252818		[learning rate: 0.0026979]
	Learning Rate: 0.0026979
	LOSS [training: 0.2538515489252818 | validation: 0.2115991859464085]
	TIME [epoch: 134 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24599790629292695		[learning rate: 0.0026884]
	Learning Rate: 0.00268836
	LOSS [training: 0.24599790629292695 | validation: 0.2183904800612276]
	TIME [epoch: 134 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24516906182358478		[learning rate: 0.0026789]
	Learning Rate: 0.00267885
	LOSS [training: 0.24516906182358478 | validation: 0.20818119218589587]
	TIME [epoch: 135 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24325452371404074		[learning rate: 0.0026694]
	Learning Rate: 0.00266938
	LOSS [training: 0.24325452371404074 | validation: 0.21381832321379957]
	TIME [epoch: 134 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24655759653743317		[learning rate: 0.0026599]
	Learning Rate: 0.00265994
	LOSS [training: 0.24655759653743317 | validation: 0.21094468676282915]
	TIME [epoch: 134 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2552532389939603		[learning rate: 0.0026505]
	Learning Rate: 0.00265053
	LOSS [training: 0.2552532389939603 | validation: 0.22282322839777283]
	TIME [epoch: 134 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2548088132996431		[learning rate: 0.0026412]
	Learning Rate: 0.00264116
	LOSS [training: 0.2548088132996431 | validation: 0.21017799740528634]
	TIME [epoch: 134 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24470521419732827		[learning rate: 0.0026318]
	Learning Rate: 0.00263182
	LOSS [training: 0.24470521419732827 | validation: 0.21349940088620936]
	TIME [epoch: 134 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.252846604315117		[learning rate: 0.0026225]
	Learning Rate: 0.00262251
	LOSS [training: 0.252846604315117 | validation: 0.2189262246285028]
	TIME [epoch: 134 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24981992052856591		[learning rate: 0.0026132]
	Learning Rate: 0.00261324
	LOSS [training: 0.24981992052856591 | validation: 0.21145819939416274]
	TIME [epoch: 134 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2542549391148034		[learning rate: 0.002604]
	Learning Rate: 0.002604
	LOSS [training: 0.2542549391148034 | validation: 0.21071662220088797]
	TIME [epoch: 134 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2488764621342391		[learning rate: 0.0025948]
	Learning Rate: 0.00259479
	LOSS [training: 0.2488764621342391 | validation: 0.20572126128502485]
	TIME [epoch: 134 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2525470373336516		[learning rate: 0.0025856]
	Learning Rate: 0.00258562
	LOSS [training: 0.2525470373336516 | validation: 0.20904754381958704]
	TIME [epoch: 134 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24618501573793747		[learning rate: 0.0025765]
	Learning Rate: 0.00257647
	LOSS [training: 0.24618501573793747 | validation: 0.20445091225314735]
	TIME [epoch: 134 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24430371253048125		[learning rate: 0.0025674]
	Learning Rate: 0.00256736
	LOSS [training: 0.24430371253048125 | validation: 0.20984040476248128]
	TIME [epoch: 134 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2400888537510276		[learning rate: 0.0025583]
	Learning Rate: 0.00255828
	LOSS [training: 0.2400888537510276 | validation: 0.21139900110203952]
	TIME [epoch: 134 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24556751110041833		[learning rate: 0.0025492]
	Learning Rate: 0.00254924
	LOSS [training: 0.24556751110041833 | validation: 0.2121485392606266]
	TIME [epoch: 134 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2515125803047591		[learning rate: 0.0025402]
	Learning Rate: 0.00254022
	LOSS [training: 0.2515125803047591 | validation: 0.22233700358805158]
	TIME [epoch: 134 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24634124240416597		[learning rate: 0.0025312]
	Learning Rate: 0.00253124
	LOSS [training: 0.24634124240416597 | validation: 0.2284561905225424]
	TIME [epoch: 134 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2627102555791659		[learning rate: 0.0025223]
	Learning Rate: 0.00252229
	LOSS [training: 0.2627102555791659 | validation: 0.24385108455470914]
	TIME [epoch: 134 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2552259517365075		[learning rate: 0.0025134]
	Learning Rate: 0.00251337
	LOSS [training: 0.2552259517365075 | validation: 0.23222590311375085]
	TIME [epoch: 134 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24786706290190916		[learning rate: 0.0025045]
	Learning Rate: 0.00250448
	LOSS [training: 0.24786706290190916 | validation: 0.21901990773271382]
	TIME [epoch: 134 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2480240426207864		[learning rate: 0.0024956]
	Learning Rate: 0.00249563
	LOSS [training: 0.2480240426207864 | validation: 0.22181970187590583]
	TIME [epoch: 134 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2435015253360672		[learning rate: 0.0024868]
	Learning Rate: 0.0024868
	LOSS [training: 0.2435015253360672 | validation: 0.2169112221995642]
	TIME [epoch: 134 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24521715104733918		[learning rate: 0.002478]
	Learning Rate: 0.00247801
	LOSS [training: 0.24521715104733918 | validation: 0.21583263736802735]
	TIME [epoch: 134 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24706839190741936		[learning rate: 0.0024692]
	Learning Rate: 0.00246924
	LOSS [training: 0.24706839190741936 | validation: 0.2141419751364504]
	TIME [epoch: 134 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2483213406031847		[learning rate: 0.0024605]
	Learning Rate: 0.00246051
	LOSS [training: 0.2483213406031847 | validation: 0.21862244408836423]
	TIME [epoch: 134 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24476668798740153		[learning rate: 0.0024518]
	Learning Rate: 0.00245181
	LOSS [training: 0.24476668798740153 | validation: 0.21913407223833037]
	TIME [epoch: 134 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24408867714084312		[learning rate: 0.0024431]
	Learning Rate: 0.00244314
	LOSS [training: 0.24408867714084312 | validation: 0.21768119947901865]
	TIME [epoch: 134 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24065507172673017		[learning rate: 0.0024345]
	Learning Rate: 0.0024345
	LOSS [training: 0.24065507172673017 | validation: 0.20728687075769492]
	TIME [epoch: 134 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24617170189557724		[learning rate: 0.0024259]
	Learning Rate: 0.00242589
	LOSS [training: 0.24617170189557724 | validation: 0.2119143399814294]
	TIME [epoch: 134 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24486825691815017		[learning rate: 0.0024173]
	Learning Rate: 0.00241732
	LOSS [training: 0.24486825691815017 | validation: 0.2142447023375888]
	TIME [epoch: 134 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2403632628473895		[learning rate: 0.0024088]
	Learning Rate: 0.00240877
	LOSS [training: 0.2403632628473895 | validation: 0.21478914543217184]
	TIME [epoch: 134 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24961183876090035		[learning rate: 0.0024002]
	Learning Rate: 0.00240025
	LOSS [training: 0.24961183876090035 | validation: 0.20850777771876236]
	TIME [epoch: 134 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24100343923418102		[learning rate: 0.0023918]
	Learning Rate: 0.00239176
	LOSS [training: 0.24100343923418102 | validation: 0.21318094510518631]
	TIME [epoch: 134 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2440217653209161		[learning rate: 0.0023833]
	Learning Rate: 0.0023833
	LOSS [training: 0.2440217653209161 | validation: 0.21247063183912512]
	TIME [epoch: 134 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24732885786366202		[learning rate: 0.0023749]
	Learning Rate: 0.00237488
	LOSS [training: 0.24732885786366202 | validation: 0.20735922152409714]
	TIME [epoch: 133 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2452378946798454		[learning rate: 0.0023665]
	Learning Rate: 0.00236648
	LOSS [training: 0.2452378946798454 | validation: 0.2034840736082848]
	TIME [epoch: 134 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2447755596124798		[learning rate: 0.0023581]
	Learning Rate: 0.00235811
	LOSS [training: 0.2447755596124798 | validation: 0.21887035599201282]
	TIME [epoch: 133 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25380412247348993		[learning rate: 0.0023498]
	Learning Rate: 0.00234977
	LOSS [training: 0.25380412247348993 | validation: 0.21407892640089682]
	TIME [epoch: 133 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2484098479502923		[learning rate: 0.0023415]
	Learning Rate: 0.00234146
	LOSS [training: 0.2484098479502923 | validation: 0.21890572675887404]
	TIME [epoch: 133 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2482048847032909		[learning rate: 0.0023332]
	Learning Rate: 0.00233318
	LOSS [training: 0.2482048847032909 | validation: 0.21121748009196512]
	TIME [epoch: 133 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24922909280554226		[learning rate: 0.0023249]
	Learning Rate: 0.00232493
	LOSS [training: 0.24922909280554226 | validation: 0.2102805123722519]
	TIME [epoch: 133 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23936289448985856		[learning rate: 0.0023167]
	Learning Rate: 0.00231671
	LOSS [training: 0.23936289448985856 | validation: 0.21459419110987485]
	TIME [epoch: 134 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24961320950497823		[learning rate: 0.0023085]
	Learning Rate: 0.00230852
	LOSS [training: 0.24961320950497823 | validation: 0.2091503349569507]
	TIME [epoch: 133 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24723585448732352		[learning rate: 0.0023004]
	Learning Rate: 0.00230035
	LOSS [training: 0.24723585448732352 | validation: 0.21183199830265803]
	TIME [epoch: 133 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24473413523495224		[learning rate: 0.0022922]
	Learning Rate: 0.00229222
	LOSS [training: 0.24473413523495224 | validation: 0.21138942875877867]
	TIME [epoch: 134 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24538748205687497		[learning rate: 0.0022841]
	Learning Rate: 0.00228411
	LOSS [training: 0.24538748205687497 | validation: 0.20744028513593143]
	TIME [epoch: 134 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2424277588764433		[learning rate: 0.002276]
	Learning Rate: 0.00227604
	LOSS [training: 0.2424277588764433 | validation: 0.2109363970689841]
	TIME [epoch: 133 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24348107160067112		[learning rate: 0.002268]
	Learning Rate: 0.00226799
	LOSS [training: 0.24348107160067112 | validation: 0.20735937381065211]
	TIME [epoch: 133 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2531861381718803		[learning rate: 0.00226]
	Learning Rate: 0.00225997
	LOSS [training: 0.2531861381718803 | validation: 0.21150388797032615]
	TIME [epoch: 133 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24381132637762826		[learning rate: 0.002252]
	Learning Rate: 0.00225198
	LOSS [training: 0.24381132637762826 | validation: 0.21006309019514427]
	TIME [epoch: 134 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24562846477259417		[learning rate: 0.002244]
	Learning Rate: 0.00224401
	LOSS [training: 0.24562846477259417 | validation: 0.2133763745292257]
	TIME [epoch: 134 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24975544617327772		[learning rate: 0.0022361]
	Learning Rate: 0.00223608
	LOSS [training: 0.24975544617327772 | validation: 0.20546716199189322]
	TIME [epoch: 134 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24481946035267396		[learning rate: 0.0022282]
	Learning Rate: 0.00222817
	LOSS [training: 0.24481946035267396 | validation: 0.20988632575818728]
	TIME [epoch: 133 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24546820328821425		[learning rate: 0.0022203]
	Learning Rate: 0.00222029
	LOSS [training: 0.24546820328821425 | validation: 0.2154507435670944]
	TIME [epoch: 134 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2440078929427217		[learning rate: 0.0022124]
	Learning Rate: 0.00221244
	LOSS [training: 0.2440078929427217 | validation: 0.20160931976038876]
	TIME [epoch: 134 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24754431615376946		[learning rate: 0.0022046]
	Learning Rate: 0.00220462
	LOSS [training: 0.24754431615376946 | validation: 0.21055506297051707]
	TIME [epoch: 134 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24825422668934663		[learning rate: 0.0021968]
	Learning Rate: 0.00219682
	LOSS [training: 0.24825422668934663 | validation: 0.20996173250344624]
	TIME [epoch: 134 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24600388936657439		[learning rate: 0.0021891]
	Learning Rate: 0.00218905
	LOSS [training: 0.24600388936657439 | validation: 0.20369958854027032]
	TIME [epoch: 134 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2426637309227969		[learning rate: 0.0021813]
	Learning Rate: 0.00218131
	LOSS [training: 0.2426637309227969 | validation: 0.2071876701665266]
	TIME [epoch: 134 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23886221473434574		[learning rate: 0.0021736]
	Learning Rate: 0.0021736
	LOSS [training: 0.23886221473434574 | validation: 0.20479761141943414]
	TIME [epoch: 134 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24683313403314075		[learning rate: 0.0021659]
	Learning Rate: 0.00216591
	LOSS [training: 0.24683313403314075 | validation: 0.21132921042085712]
	TIME [epoch: 133 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24780974037407014		[learning rate: 0.0021583]
	Learning Rate: 0.00215825
	LOSS [training: 0.24780974037407014 | validation: 0.21400575151855872]
	TIME [epoch: 134 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2459345002108891		[learning rate: 0.0021506]
	Learning Rate: 0.00215062
	LOSS [training: 0.2459345002108891 | validation: 0.21275073360862087]
	TIME [epoch: 134 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2473465747847531		[learning rate: 0.002143]
	Learning Rate: 0.00214302
	LOSS [training: 0.2473465747847531 | validation: 0.2102250509700335]
	TIME [epoch: 133 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2409174132124038		[learning rate: 0.0021354]
	Learning Rate: 0.00213544
	LOSS [training: 0.2409174132124038 | validation: 0.21293289198097462]
	TIME [epoch: 133 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24390348912805696		[learning rate: 0.0021279]
	Learning Rate: 0.00212789
	LOSS [training: 0.24390348912805696 | validation: 0.20490439873220812]
	TIME [epoch: 134 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24473742347147173		[learning rate: 0.0021204]
	Learning Rate: 0.00212036
	LOSS [training: 0.24473742347147173 | validation: 0.21467258610155643]
	TIME [epoch: 133 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24123718782266082		[learning rate: 0.0021129]
	Learning Rate: 0.00211287
	LOSS [training: 0.24123718782266082 | validation: 0.21280847069511366]
	TIME [epoch: 134 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24816252005396075		[learning rate: 0.0021054]
	Learning Rate: 0.00210539
	LOSS [training: 0.24816252005396075 | validation: 0.20982345778938988]
	TIME [epoch: 133 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23917503210780278		[learning rate: 0.0020979]
	Learning Rate: 0.00209795
	LOSS [training: 0.23917503210780278 | validation: 0.2079848742971298]
	TIME [epoch: 133 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24545307055438015		[learning rate: 0.0020905]
	Learning Rate: 0.00209053
	LOSS [training: 0.24545307055438015 | validation: 0.20543924752643888]
	TIME [epoch: 133 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24476345523005727		[learning rate: 0.0020831]
	Learning Rate: 0.00208314
	LOSS [training: 0.24476345523005727 | validation: 0.2103027754844981]
	TIME [epoch: 133 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24459857794200235		[learning rate: 0.0020758]
	Learning Rate: 0.00207577
	LOSS [training: 0.24459857794200235 | validation: 0.21499921185946264]
	TIME [epoch: 134 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25114616678175783		[learning rate: 0.0020684]
	Learning Rate: 0.00206843
	LOSS [training: 0.25114616678175783 | validation: 0.20614740393008435]
	TIME [epoch: 133 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24708902778628083		[learning rate: 0.0020611]
	Learning Rate: 0.00206112
	LOSS [training: 0.24708902778628083 | validation: 0.20575257596090651]
	TIME [epoch: 134 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2397371528926399		[learning rate: 0.0020538]
	Learning Rate: 0.00205383
	LOSS [training: 0.2397371528926399 | validation: 0.2059727541503611]
	TIME [epoch: 134 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2449051978639237		[learning rate: 0.0020466]
	Learning Rate: 0.00204657
	LOSS [training: 0.2449051978639237 | validation: 0.20801289804210255]
	TIME [epoch: 133 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24638670572282362		[learning rate: 0.0020393]
	Learning Rate: 0.00203933
	LOSS [training: 0.24638670572282362 | validation: 0.20617486499948168]
	TIME [epoch: 134 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2416996819720888		[learning rate: 0.0020321]
	Learning Rate: 0.00203212
	LOSS [training: 0.2416996819720888 | validation: 0.21227152339535404]
	TIME [epoch: 134 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25001926235957483		[learning rate: 0.0020249]
	Learning Rate: 0.00202493
	LOSS [training: 0.25001926235957483 | validation: 0.22019202197129664]
	TIME [epoch: 133 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2570392803847308		[learning rate: 0.0020178]
	Learning Rate: 0.00201777
	LOSS [training: 0.2570392803847308 | validation: 0.2143946230466046]
	TIME [epoch: 133 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24456045383599587		[learning rate: 0.0020106]
	Learning Rate: 0.00201064
	LOSS [training: 0.24456045383599587 | validation: 0.21854416108510608]
	TIME [epoch: 133 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25209060467959726		[learning rate: 0.0020035]
	Learning Rate: 0.00200353
	LOSS [training: 0.25209060467959726 | validation: 0.21435499399600708]
	TIME [epoch: 133 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23743949113083204		[learning rate: 0.0019964]
	Learning Rate: 0.00199644
	LOSS [training: 0.23743949113083204 | validation: 0.21902467719748211]
	TIME [epoch: 133 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24353056497626577		[learning rate: 0.0019894]
	Learning Rate: 0.00198938
	LOSS [training: 0.24353056497626577 | validation: 0.20699474983108476]
	TIME [epoch: 134 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2432898689515328		[learning rate: 0.0019823]
	Learning Rate: 0.00198235
	LOSS [training: 0.2432898689515328 | validation: 0.21238652674030326]
	TIME [epoch: 134 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24245528152859042		[learning rate: 0.0019753]
	Learning Rate: 0.00197534
	LOSS [training: 0.24245528152859042 | validation: 0.2097133906631285]
	TIME [epoch: 133 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24371881998212677		[learning rate: 0.0019684]
	Learning Rate: 0.00196835
	LOSS [training: 0.24371881998212677 | validation: 0.20689464650207046]
	TIME [epoch: 133 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24212906359350042		[learning rate: 0.0019614]
	Learning Rate: 0.00196139
	LOSS [training: 0.24212906359350042 | validation: 0.20884252901292127]
	TIME [epoch: 133 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24388128054564692		[learning rate: 0.0019545]
	Learning Rate: 0.00195445
	LOSS [training: 0.24388128054564692 | validation: 0.2105951240186629]
	TIME [epoch: 133 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24107774199991852		[learning rate: 0.0019475]
	Learning Rate: 0.00194754
	LOSS [training: 0.24107774199991852 | validation: 0.21022095503484267]
	TIME [epoch: 134 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24590064237281886		[learning rate: 0.0019407]
	Learning Rate: 0.00194066
	LOSS [training: 0.24590064237281886 | validation: 0.213830014433883]
	TIME [epoch: 134 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24421152060175197		[learning rate: 0.0019338]
	Learning Rate: 0.00193379
	LOSS [training: 0.24421152060175197 | validation: 0.2085714794184106]
	TIME [epoch: 134 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24614525891491681		[learning rate: 0.001927]
	Learning Rate: 0.00192696
	LOSS [training: 0.24614525891491681 | validation: 0.21354811036454519]
	TIME [epoch: 134 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24188095244512878		[learning rate: 0.0019201]
	Learning Rate: 0.00192014
	LOSS [training: 0.24188095244512878 | validation: 0.20722446208292608]
	TIME [epoch: 133 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24589319998334966		[learning rate: 0.0019134]
	Learning Rate: 0.00191335
	LOSS [training: 0.24589319998334966 | validation: 0.2149757340906302]
	TIME [epoch: 133 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2434144533609256		[learning rate: 0.0019066]
	Learning Rate: 0.00190659
	LOSS [training: 0.2434144533609256 | validation: 0.20648660729579035]
	TIME [epoch: 134 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24573846006751385		[learning rate: 0.0018998]
	Learning Rate: 0.00189984
	LOSS [training: 0.24573846006751385 | validation: 0.21365806145381344]
	TIME [epoch: 134 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2436175510551355		[learning rate: 0.0018931]
	Learning Rate: 0.00189313
	LOSS [training: 0.2436175510551355 | validation: 0.20948151731073925]
	TIME [epoch: 134 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24672246275634802		[learning rate: 0.0018864]
	Learning Rate: 0.00188643
	LOSS [training: 0.24672246275634802 | validation: 0.2054591291608669]
	TIME [epoch: 134 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2449214771060421		[learning rate: 0.0018798]
	Learning Rate: 0.00187976
	LOSS [training: 0.2449214771060421 | validation: 0.20542087335098844]
	TIME [epoch: 133 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24824374018632975		[learning rate: 0.0018731]
	Learning Rate: 0.00187311
	LOSS [training: 0.24824374018632975 | validation: 0.20754596837455752]
	TIME [epoch: 134 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24832160344038215		[learning rate: 0.0018665]
	Learning Rate: 0.00186649
	LOSS [training: 0.24832160344038215 | validation: 0.20447029305556835]
	TIME [epoch: 133 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24238304740755198		[learning rate: 0.0018599]
	Learning Rate: 0.00185989
	LOSS [training: 0.24238304740755198 | validation: 0.21058719716419666]
	TIME [epoch: 134 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24846092977111875		[learning rate: 0.0018533]
	Learning Rate: 0.00185331
	LOSS [training: 0.24846092977111875 | validation: 0.2063418399663261]
	TIME [epoch: 133 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24437938148040472		[learning rate: 0.0018468]
	Learning Rate: 0.00184676
	LOSS [training: 0.24437938148040472 | validation: 0.20458870200634535]
	TIME [epoch: 134 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24178525910493065		[learning rate: 0.0018402]
	Learning Rate: 0.00184023
	LOSS [training: 0.24178525910493065 | validation: 0.20710461569568936]
	TIME [epoch: 133 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24589662572060075		[learning rate: 0.0018337]
	Learning Rate: 0.00183372
	LOSS [training: 0.24589662572060075 | validation: 0.20880976502911347]
	TIME [epoch: 134 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2462727513081854		[learning rate: 0.0018272]
	Learning Rate: 0.00182724
	LOSS [training: 0.2462727513081854 | validation: 0.20822117966790293]
	TIME [epoch: 133 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2512635270835108		[learning rate: 0.0018208]
	Learning Rate: 0.00182078
	LOSS [training: 0.2512635270835108 | validation: 0.2138703766699736]
	TIME [epoch: 134 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24020683601896964		[learning rate: 0.0018143]
	Learning Rate: 0.00181434
	LOSS [training: 0.24020683601896964 | validation: 0.20538921207601096]
	TIME [epoch: 133 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24003162501298358		[learning rate: 0.0018079]
	Learning Rate: 0.00180792
	LOSS [training: 0.24003162501298358 | validation: 0.20868365305163797]
	TIME [epoch: 134 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24370402952844902		[learning rate: 0.0018015]
	Learning Rate: 0.00180153
	LOSS [training: 0.24370402952844902 | validation: 0.20564529447079094]
	TIME [epoch: 133 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2428235552184731		[learning rate: 0.0017952]
	Learning Rate: 0.00179516
	LOSS [training: 0.2428235552184731 | validation: 0.19713182931624496]
	TIME [epoch: 134 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13b_20240719_005205/states/model_facs_v3_dec1b_2dpca_v13b_535.pth
	Model improved!!!
EPOCH 536/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24031014441160667		[learning rate: 0.0017888]
	Learning Rate: 0.00178881
	LOSS [training: 0.24031014441160667 | validation: 0.21167222911929073]
	TIME [epoch: 134 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2413439798692307		[learning rate: 0.0017825]
	Learning Rate: 0.00178248
	LOSS [training: 0.2413439798692307 | validation: 0.2048305627529828]
	TIME [epoch: 134 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24378083880435328		[learning rate: 0.0017762]
	Learning Rate: 0.00177618
	LOSS [training: 0.24378083880435328 | validation: 0.21535463694303783]
	TIME [epoch: 134 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.243667897457978		[learning rate: 0.0017699]
	Learning Rate: 0.0017699
	LOSS [training: 0.243667897457978 | validation: 0.20706238685475808]
	TIME [epoch: 134 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24396219055510027		[learning rate: 0.0017636]
	Learning Rate: 0.00176364
	LOSS [training: 0.24396219055510027 | validation: 0.2078477510035822]
	TIME [epoch: 133 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24360685643219324		[learning rate: 0.0017574]
	Learning Rate: 0.0017574
	LOSS [training: 0.24360685643219324 | validation: 0.20868755257884097]
	TIME [epoch: 134 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24085028358254404		[learning rate: 0.0017512]
	Learning Rate: 0.00175119
	LOSS [training: 0.24085028358254404 | validation: 0.20804406514150048]
	TIME [epoch: 134 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2444068428335171		[learning rate: 0.001745]
	Learning Rate: 0.001745
	LOSS [training: 0.2444068428335171 | validation: 0.20812622658272462]
	TIME [epoch: 134 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24371900606975816		[learning rate: 0.0017388]
	Learning Rate: 0.00173883
	LOSS [training: 0.24371900606975816 | validation: 0.21104097417943915]
	TIME [epoch: 134 sec]
EPOCH 545/2000:
	Training over batches...
