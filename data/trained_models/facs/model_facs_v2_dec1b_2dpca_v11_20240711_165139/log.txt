Args:
Namespace(name='model_facs_v2_dec1b_2dpca_v11', outdir='out/model_training/model_facs_v2_dec1b_2dpca_v11', training_data='data/training_data/facs_v2/pca/dec1_fitonsubset/transition1_subset_epi_tr_ce_an_pc12/training', validation_data='data/training_data/facs_v2/pca/dec1_fitonsubset/transition1_subset_epi_tr_ce_an_pc12/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=10, batch_size=50, patience=200, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, quadratic_a=1.0, quadratic_b=1.0, ndims=2, nparams=2, nsigs=2, ncells=400, ncells_sample=400, model_do_sample=False, dt=0.005, dt_schedule='stepped', dt_schedule_bounds=[500, 1000, 1500], dt_schedule_scales=[0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=True, sigma=0.8, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', kernel='multiscale', bw_range=[0.2, 0.5, 0.9, 1.1, 1.3, 1.5, 2.0], optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 3669337163

Training model...

Saving initial model state to: out/model_training/model_facs_v2_dec1b_2dpca_v11_20240711_165139/states/model_facs_v2_dec1b_2dpca_v11_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.8406598224107378		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8406598224107378 | validation: 0.7030581210945137]
	TIME [epoch: 44.5 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v11_20240711_165139/states/model_facs_v2_dec1b_2dpca_v11_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.8030349233131221		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8030349233131221 | validation: 0.675888717496368]
	TIME [epoch: 9.81 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v11_20240711_165139/states/model_facs_v2_dec1b_2dpca_v11_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7599210655321054		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7599210655321054 | validation: 0.6187647904631908]
	TIME [epoch: 9.81 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v11_20240711_165139/states/model_facs_v2_dec1b_2dpca_v11_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7138751626720476		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7138751626720476 | validation: 0.558029801699006]
	TIME [epoch: 9.79 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v11_20240711_165139/states/model_facs_v2_dec1b_2dpca_v11_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6559490598092157		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6559490598092157 | validation: 0.5298686004521213]
	TIME [epoch: 9.79 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v11_20240711_165139/states/model_facs_v2_dec1b_2dpca_v11_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5907797867460806		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5907797867460806 | validation: 0.4894922693163898]
	TIME [epoch: 9.79 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v11_20240711_165139/states/model_facs_v2_dec1b_2dpca_v11_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5578827334040517		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5578827334040517 | validation: 0.5025984407481039]
	TIME [epoch: 9.8 sec]
EPOCH 8/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5381981864481117		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5381981864481117 | validation: 0.47215126723152706]
	TIME [epoch: 9.78 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v11_20240711_165139/states/model_facs_v2_dec1b_2dpca_v11_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5501393447993261		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5501393447993261 | validation: 0.424624466971696]
	TIME [epoch: 9.8 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v11_20240711_165139/states/model_facs_v2_dec1b_2dpca_v11_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.51529758391815		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.51529758391815 | validation: 0.514657635791343]
	TIME [epoch: 9.81 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.47327080624092815		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.47327080624092815 | validation: 0.5284433341838535]
	TIME [epoch: 9.79 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5587883358255161		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5587883358255161 | validation: 0.4385087345375707]
	TIME [epoch: 9.78 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4766747130419955		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4766747130419955 | validation: 0.43193729503830103]
	TIME [epoch: 9.79 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4500630068320885		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4500630068320885 | validation: 0.49069154007620225]
	TIME [epoch: 9.79 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.654184868226794		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.654184868226794 | validation: 0.49509027420427343]
	TIME [epoch: 9.79 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5631479055905183		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5631479055905183 | validation: 0.42727092282679935]
	TIME [epoch: 9.78 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5196588736444817		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5196588736444817 | validation: 0.41708050988839035]
	TIME [epoch: 9.8 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v11_20240711_165139/states/model_facs_v2_dec1b_2dpca_v11_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4516555098867723		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4516555098867723 | validation: 0.5847765728350447]
	TIME [epoch: 9.79 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.458146722835		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.458146722835 | validation: 0.4052257474306599]
	TIME [epoch: 9.79 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v11_20240711_165139/states/model_facs_v2_dec1b_2dpca_v11_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.49942593356001524		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.49942593356001524 | validation: 0.40003879590018887]
	TIME [epoch: 9.79 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v11_20240711_165139/states/model_facs_v2_dec1b_2dpca_v11_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.44543516328504157		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.44543516328504157 | validation: 0.39739614242973065]
	TIME [epoch: 9.8 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v11_20240711_165139/states/model_facs_v2_dec1b_2dpca_v11_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4211555911138707		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4211555911138707 | validation: 0.4503982147776645]
	TIME [epoch: 9.79 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4131625325795851		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4131625325795851 | validation: 0.39588423262720535]
	TIME [epoch: 9.78 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v11_20240711_165139/states/model_facs_v2_dec1b_2dpca_v11_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4587848572632831		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4587848572632831 | validation: 0.3986196404020888]
	TIME [epoch: 9.81 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4052682508470307		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4052682508470307 | validation: 0.4271064660186564]
	TIME [epoch: 9.79 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.45359924891783915		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.45359924891783915 | validation: 0.38504485366184965]
	TIME [epoch: 9.79 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v11_20240711_165139/states/model_facs_v2_dec1b_2dpca_v11_26.pth
	Model improved!!!
EPOCH 27/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3884773593236513		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3884773593236513 | validation: 0.4010868482003498]
	TIME [epoch: 9.8 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4429424626101254		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4429424626101254 | validation: 0.43044973499676287]
	TIME [epoch: 9.8 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.42752833767334386		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.42752833767334386 | validation: 0.39082147966954905]
	TIME [epoch: 9.79 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.43085741098525515		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.43085741098525515 | validation: 0.385442471878155]
	TIME [epoch: 9.78 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4095521857164595		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4095521857164595 | validation: 0.45065790566820996]
	TIME [epoch: 9.81 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.43599994382099777		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.43599994382099777 | validation: 0.36123735354421466]
	TIME [epoch: 9.8 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v11_20240711_165139/states/model_facs_v2_dec1b_2dpca_v11_32.pth
	Model improved!!!
EPOCH 33/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3967942919649624		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3967942919649624 | validation: 0.35496738150167084]
	TIME [epoch: 9.78 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v11_20240711_165139/states/model_facs_v2_dec1b_2dpca_v11_33.pth
	Model improved!!!
EPOCH 34/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.41275869749004324		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.41275869749004324 | validation: 0.5283686242961487]
	TIME [epoch: 9.79 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4465048036621725		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4465048036621725 | validation: 0.36770255757413517]
	TIME [epoch: 9.81 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.37590573134027483		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.37590573134027483 | validation: 0.3603869957932473]
	TIME [epoch: 9.79 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4153251384179556		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4153251384179556 | validation: 0.4370512078455702]
	TIME [epoch: 9.78 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4044004993966264		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4044004993966264 | validation: 0.3682116216545748]
	TIME [epoch: 9.8 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4267818407406706		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4267818407406706 | validation: 0.5909565958261627]
	TIME [epoch: 9.79 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4336606074016032		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4336606074016032 | validation: 0.37621320607792874]
	TIME [epoch: 9.79 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3963430257451986		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3963430257451986 | validation: 0.6297107466437237]
	TIME [epoch: 9.79 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5351693054785515		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5351693054785515 | validation: 0.36457232188450056]
	TIME [epoch: 9.81 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.49275741018817065		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.49275741018817065 | validation: 0.37781093299289753]
	TIME [epoch: 9.8 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.42719629125351044		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.42719629125351044 | validation: 0.35635357329069084]
	TIME [epoch: 9.8 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4049090197568391		[learning rate: 0.0099823]
	Learning Rate: 0.0099823
	LOSS [training: 0.4049090197568391 | validation: 0.35212869006983044]
	TIME [epoch: 9.8 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v11_20240711_165139/states/model_facs_v2_dec1b_2dpca_v11_45.pth
	Model improved!!!
EPOCH 46/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.40360615998973043		[learning rate: 0.0099426]
	Learning Rate: 0.0099426
	LOSS [training: 0.40360615998973043 | validation: 0.3950245188802685]
	TIME [epoch: 9.81 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4183658894105094		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 0.4183658894105094 | validation: 0.36271260245943826]
	TIME [epoch: 9.8 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3708638229998702		[learning rate: 0.0098637]
	Learning Rate: 0.00986367
	LOSS [training: 0.3708638229998702 | validation: 0.39909083936822987]
	TIME [epoch: 9.79 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.36979385609566556		[learning rate: 0.0098244]
	Learning Rate: 0.00982444
	LOSS [training: 0.36979385609566556 | validation: 0.38105006520691054]
	TIME [epoch: 9.81 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4563245369473573		[learning rate: 0.0097854]
	Learning Rate: 0.00978536
	LOSS [training: 0.4563245369473573 | validation: 0.33948226915438445]
	TIME [epoch: 9.79 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v11_20240711_165139/states/model_facs_v2_dec1b_2dpca_v11_50.pth
	Model improved!!!
EPOCH 51/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3558928467378383		[learning rate: 0.0097464]
	Learning Rate: 0.00974644
	LOSS [training: 0.3558928467378383 | validation: 0.3468379731320106]
	TIME [epoch: 9.8 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3934210454190867		[learning rate: 0.0097077]
	Learning Rate: 0.00970768
	LOSS [training: 0.3934210454190867 | validation: 0.3723076468309554]
	TIME [epoch: 9.8 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3789801804093107		[learning rate: 0.0096691]
	Learning Rate: 0.00966907
	LOSS [training: 0.3789801804093107 | validation: 0.32380418695376756]
	TIME [epoch: 9.81 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v11_20240711_165139/states/model_facs_v2_dec1b_2dpca_v11_53.pth
	Model improved!!!
EPOCH 54/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.36612463928448796		[learning rate: 0.0096306]
	Learning Rate: 0.00963061
	LOSS [training: 0.36612463928448796 | validation: 0.3692072258066158]
	TIME [epoch: 9.8 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.37251423194745686		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 0.37251423194745686 | validation: 0.4051801692089826]
	TIME [epoch: 9.8 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3977260914672045		[learning rate: 0.0095542]
	Learning Rate: 0.00955415
	LOSS [training: 0.3977260914672045 | validation: 0.33657401881714694]
	TIME [epoch: 9.81 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3674041035997315		[learning rate: 0.0095162]
	Learning Rate: 0.00951616
	LOSS [training: 0.3674041035997315 | validation: 0.32009843583433784]
	TIME [epoch: 9.8 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v11_20240711_165139/states/model_facs_v2_dec1b_2dpca_v11_57.pth
	Model improved!!!
EPOCH 58/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.36711745689495956		[learning rate: 0.0094783]
	Learning Rate: 0.00947831
	LOSS [training: 0.36711745689495956 | validation: 0.3819163754746546]
	TIME [epoch: 9.8 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3751021321420886		[learning rate: 0.0094406]
	Learning Rate: 0.00944061
	LOSS [training: 0.3751021321420886 | validation: 0.3309797389785412]
	TIME [epoch: 9.8 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3548708849455362		[learning rate: 0.0094031]
	Learning Rate: 0.00940306
	LOSS [training: 0.3548708849455362 | validation: 0.3387931041881644]
	TIME [epoch: 9.8 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.36982810405643		[learning rate: 0.0093657]
	Learning Rate: 0.00936566
	LOSS [training: 0.36982810405643 | validation: 0.4405409471663157]
	TIME [epoch: 9.79 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3700822697593152		[learning rate: 0.0093284]
	Learning Rate: 0.00932841
	LOSS [training: 0.3700822697593152 | validation: 0.39939915059257963]
	TIME [epoch: 9.79 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3556912378946515		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 0.3556912378946515 | validation: 0.3494327543365941]
	TIME [epoch: 9.8 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3867829295039475		[learning rate: 0.0092544]
	Learning Rate: 0.00925435
	LOSS [training: 0.3867829295039475 | validation: 0.3469539098295734]
	TIME [epoch: 9.8 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.35941281644603773		[learning rate: 0.0092175]
	Learning Rate: 0.00921755
	LOSS [training: 0.35941281644603773 | validation: 0.3080661367222793]
	TIME [epoch: 9.79 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v11_20240711_165139/states/model_facs_v2_dec1b_2dpca_v11_65.pth
	Model improved!!!
EPOCH 66/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3709232130081351		[learning rate: 0.0091809]
	Learning Rate: 0.00918089
	LOSS [training: 0.3709232130081351 | validation: 0.39552475142723714]
	TIME [epoch: 9.78 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.36307736039515337		[learning rate: 0.0091444]
	Learning Rate: 0.00914437
	LOSS [training: 0.36307736039515337 | validation: 0.37119676325852297]
	TIME [epoch: 9.81 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.33928439084012885		[learning rate: 0.009108]
	Learning Rate: 0.009108
	LOSS [training: 0.33928439084012885 | validation: 0.33957640793962174]
	TIME [epoch: 9.79 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.38240826744134165		[learning rate: 0.0090718]
	Learning Rate: 0.00907178
	LOSS [training: 0.38240826744134165 | validation: 0.3499161305646348]
	TIME [epoch: 9.8 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.33437073606512274		[learning rate: 0.0090357]
	Learning Rate: 0.00903569
	LOSS [training: 0.33437073606512274 | validation: 0.32612429291642747]
	TIME [epoch: 9.79 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.33740605489980136		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 0.33740605489980136 | validation: 0.3304940024549016]
	TIME [epoch: 9.81 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.35019617485365734		[learning rate: 0.008964]
	Learning Rate: 0.00896396
	LOSS [training: 0.35019617485365734 | validation: 0.3417943834351824]
	TIME [epoch: 9.79 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.34571809677478177		[learning rate: 0.0089283]
	Learning Rate: 0.00892831
	LOSS [training: 0.34571809677478177 | validation: 0.30909038524449506]
	TIME [epoch: 9.79 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.34202041336732564		[learning rate: 0.0088928]
	Learning Rate: 0.0088928
	LOSS [training: 0.34202041336732564 | validation: 0.3392805972543658]
	TIME [epoch: 9.8 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3578105299988492		[learning rate: 0.0088574]
	Learning Rate: 0.00885743
	LOSS [training: 0.3578105299988492 | validation: 0.37009451915238223]
	TIME [epoch: 9.8 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.35925460528664743		[learning rate: 0.0088222]
	Learning Rate: 0.0088222
	LOSS [training: 0.35925460528664743 | validation: 0.34296702608111873]
	TIME [epoch: 9.79 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.352225657493624		[learning rate: 0.0087871]
	Learning Rate: 0.00878711
	LOSS [training: 0.352225657493624 | validation: 0.3697650779854348]
	TIME [epoch: 9.79 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.34884884682861933		[learning rate: 0.0087522]
	Learning Rate: 0.00875216
	LOSS [training: 0.34884884682861933 | validation: 0.29883931998385155]
	TIME [epoch: 9.81 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v11_20240711_165139/states/model_facs_v2_dec1b_2dpca_v11_78.pth
	Model improved!!!
EPOCH 79/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.38883556552324805		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 0.38883556552324805 | validation: 0.3720604577435034]
	TIME [epoch: 9.79 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3914964982325837		[learning rate: 0.0086827]
	Learning Rate: 0.00868268
	LOSS [training: 0.3914964982325837 | validation: 0.32180565118736987]
	TIME [epoch: 9.77 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3364832267218771		[learning rate: 0.0086481]
	Learning Rate: 0.00864815
	LOSS [training: 0.3364832267218771 | validation: 0.3456263116822651]
	TIME [epoch: 9.78 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3485964598430322		[learning rate: 0.0086138]
	Learning Rate: 0.00861375
	LOSS [training: 0.3485964598430322 | validation: 0.31071174202654833]
	TIME [epoch: 9.78 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3129953758235359		[learning rate: 0.0085795]
	Learning Rate: 0.00857949
	LOSS [training: 0.3129953758235359 | validation: 0.3196747093603289]
	TIME [epoch: 9.77 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3281903364995322		[learning rate: 0.0085454]
	Learning Rate: 0.00854537
	LOSS [training: 0.3281903364995322 | validation: 0.30058471022564714]
	TIME [epoch: 9.77 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3273935574550645		[learning rate: 0.0085114]
	Learning Rate: 0.00851138
	LOSS [training: 0.3273935574550645 | validation: 0.2952881713997707]
	TIME [epoch: 9.79 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v11_20240711_165139/states/model_facs_v2_dec1b_2dpca_v11_85.pth
	Model improved!!!
EPOCH 86/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3501407483957558		[learning rate: 0.0084775]
	Learning Rate: 0.00847753
	LOSS [training: 0.3501407483957558 | validation: 0.33949428127694425]
	TIME [epoch: 9.79 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3384680732532901		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 0.3384680732532901 | validation: 0.32783175464706465]
	TIME [epoch: 9.79 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3333027411114773		[learning rate: 0.0084102]
	Learning Rate: 0.00841023
	LOSS [training: 0.3333027411114773 | validation: 0.3289025682915706]
	TIME [epoch: 9.8 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3606146586816401		[learning rate: 0.0083768]
	Learning Rate: 0.00837678
	LOSS [training: 0.3606146586816401 | validation: 0.3130172708953999]
	TIME [epoch: 9.82 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.33109726936862743		[learning rate: 0.0083435]
	Learning Rate: 0.00834346
	LOSS [training: 0.33109726936862743 | validation: 0.2963442126185337]
	TIME [epoch: 9.8 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32512805558964825		[learning rate: 0.0083103]
	Learning Rate: 0.00831027
	LOSS [training: 0.32512805558964825 | validation: 0.32035433979073746]
	TIME [epoch: 9.8 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32972242803131707		[learning rate: 0.0082772]
	Learning Rate: 0.00827722
	LOSS [training: 0.32972242803131707 | validation: 0.34656910029555543]
	TIME [epoch: 9.81 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.33266270628366257		[learning rate: 0.0082443]
	Learning Rate: 0.0082443
	LOSS [training: 0.33266270628366257 | validation: 0.317643152193171]
	TIME [epoch: 9.81 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.307040118812608		[learning rate: 0.0082115]
	Learning Rate: 0.00821151
	LOSS [training: 0.307040118812608 | validation: 0.2944179815974158]
	TIME [epoch: 9.8 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v11_20240711_165139/states/model_facs_v2_dec1b_2dpca_v11_94.pth
	Model improved!!!
EPOCH 95/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.33250249445307717		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 0.33250249445307717 | validation: 0.33325072662841015]
	TIME [epoch: 9.8 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3263565383350392		[learning rate: 0.0081463]
	Learning Rate: 0.00814632
	LOSS [training: 0.3263565383350392 | validation: 0.2986709842670471]
	TIME [epoch: 9.81 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.31382057280296616		[learning rate: 0.0081139]
	Learning Rate: 0.00811392
	LOSS [training: 0.31382057280296616 | validation: 0.28596749204837013]
	TIME [epoch: 9.79 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v11_20240711_165139/states/model_facs_v2_dec1b_2dpca_v11_97.pth
	Model improved!!!
EPOCH 98/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3008372427734438		[learning rate: 0.0080816]
	Learning Rate: 0.00808165
	LOSS [training: 0.3008372427734438 | validation: 0.30699908091344125]
	TIME [epoch: 9.8 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3265046700427044		[learning rate: 0.0080495]
	Learning Rate: 0.00804951
	LOSS [training: 0.3265046700427044 | validation: 0.30863367363157795]
	TIME [epoch: 9.8 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3083153472580624		[learning rate: 0.0080175]
	Learning Rate: 0.00801749
	LOSS [training: 0.3083153472580624 | validation: 0.3182592985918341]
	TIME [epoch: 9.8 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3231124422007233		[learning rate: 0.0079856]
	Learning Rate: 0.0079856
	LOSS [training: 0.3231124422007233 | validation: 0.36125871639456325]
	TIME [epoch: 9.8 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4239666054152398		[learning rate: 0.0079538]
	Learning Rate: 0.00795384
	LOSS [training: 0.4239666054152398 | validation: 0.32169330373300764]
	TIME [epoch: 9.8 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3433493317825554		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 0.3433493317825554 | validation: 0.32188209906198806]
	TIME [epoch: 9.81 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3295151666398596		[learning rate: 0.0078907]
	Learning Rate: 0.0078907
	LOSS [training: 0.3295151666398596 | validation: 0.3176502133019524]
	TIME [epoch: 9.8 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3189573212893934		[learning rate: 0.0078593]
	Learning Rate: 0.00785931
	LOSS [training: 0.3189573212893934 | validation: 0.3174577002751492]
	TIME [epoch: 9.79 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.302978700738021		[learning rate: 0.0078281]
	Learning Rate: 0.00782805
	LOSS [training: 0.302978700738021 | validation: 0.2961215565451221]
	TIME [epoch: 9.8 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4082639231214781		[learning rate: 0.0077969]
	Learning Rate: 0.00779692
	LOSS [training: 0.4082639231214781 | validation: 0.8355793677163744]
	TIME [epoch: 9.81 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7526817886243176		[learning rate: 0.0077659]
	Learning Rate: 0.00776591
	LOSS [training: 0.7526817886243176 | validation: 0.4170464021614883]
	TIME [epoch: 9.79 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5621851756091399		[learning rate: 0.007735]
	Learning Rate: 0.00773502
	LOSS [training: 0.5621851756091399 | validation: 0.41600059434099723]
	TIME [epoch: 9.79 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5924281361358233		[learning rate: 0.0077043]
	Learning Rate: 0.00770426
	LOSS [training: 0.5924281361358233 | validation: 0.43685145835204386]
	TIME [epoch: 9.8 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6095122024158383		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 0.6095122024158383 | validation: 0.39586066195252306]
	TIME [epoch: 9.79 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5792860352940311		[learning rate: 0.0076431]
	Learning Rate: 0.00764309
	LOSS [training: 0.5792860352940311 | validation: 0.4076460788758588]
	TIME [epoch: 9.79 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5643480318141093		[learning rate: 0.0076127]
	Learning Rate: 0.00761269
	LOSS [training: 0.5643480318141093 | validation: 0.39851426955530245]
	TIME [epoch: 9.79 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.48887710222131353		[learning rate: 0.0075824]
	Learning Rate: 0.00758242
	LOSS [training: 0.48887710222131353 | validation: 0.38432159189549053]
	TIME [epoch: 9.81 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3600074982507804		[learning rate: 0.0075523]
	Learning Rate: 0.00755226
	LOSS [training: 0.3600074982507804 | validation: 0.3401081454649828]
	TIME [epoch: 9.79 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.35586675268786583		[learning rate: 0.0075222]
	Learning Rate: 0.00752222
	LOSS [training: 0.35586675268786583 | validation: 0.3165248060199441]
	TIME [epoch: 9.8 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.35399024324482553		[learning rate: 0.0074923]
	Learning Rate: 0.0074923
	LOSS [training: 0.35399024324482553 | validation: 0.3391330710140389]
	TIME [epoch: 9.8 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32630505800978526		[learning rate: 0.0074625]
	Learning Rate: 0.0074625
	LOSS [training: 0.32630505800978526 | validation: 0.28383227059334803]
	TIME [epoch: 9.81 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v11_20240711_165139/states/model_facs_v2_dec1b_2dpca_v11_118.pth
	Model improved!!!
EPOCH 119/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2995647286640126		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 0.2995647286640126 | validation: 0.29607487561086093]
	TIME [epoch: 9.8 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32737679931895464		[learning rate: 0.0074033]
	Learning Rate: 0.00740326
	LOSS [training: 0.32737679931895464 | validation: 0.29654678087879016]
	TIME [epoch: 9.8 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2976237298352977		[learning rate: 0.0073738]
	Learning Rate: 0.00737382
	LOSS [training: 0.2976237298352977 | validation: 0.2852996535799346]
	TIME [epoch: 9.81 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.30257578692134923		[learning rate: 0.0073445]
	Learning Rate: 0.00734449
	LOSS [training: 0.30257578692134923 | validation: 0.3512195282646091]
	TIME [epoch: 9.8 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2946741585059773		[learning rate: 0.0073153]
	Learning Rate: 0.00731528
	LOSS [training: 0.2946741585059773 | validation: 0.29386256324472676]
	TIME [epoch: 9.8 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2935049563800266		[learning rate: 0.0072862]
	Learning Rate: 0.00728618
	LOSS [training: 0.2935049563800266 | validation: 0.2816789495019133]
	TIME [epoch: 9.8 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v11_20240711_165139/states/model_facs_v2_dec1b_2dpca_v11_124.pth
	Model improved!!!
EPOCH 125/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.31426288564614663		[learning rate: 0.0072572]
	Learning Rate: 0.0072572
	LOSS [training: 0.31426288564614663 | validation: 0.2866944296846189]
	TIME [epoch: 9.81 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.28959526403693875		[learning rate: 0.0072283]
	Learning Rate: 0.00722834
	LOSS [training: 0.28959526403693875 | validation: 0.2836674525085408]
	TIME [epoch: 9.79 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2938055122137491		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 0.2938055122137491 | validation: 0.30049006497961334]
	TIME [epoch: 9.8 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3089263372136249		[learning rate: 0.007171]
	Learning Rate: 0.00717095
	LOSS [training: 0.3089263372136249 | validation: 0.2799742244413458]
	TIME [epoch: 9.8 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v11_20240711_165139/states/model_facs_v2_dec1b_2dpca_v11_128.pth
	Model improved!!!
EPOCH 129/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.31109579166891266		[learning rate: 0.0071424]
	Learning Rate: 0.00714243
	LOSS [training: 0.31109579166891266 | validation: 0.30940769362908455]
	TIME [epoch: 9.8 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3110531649680743		[learning rate: 0.007114]
	Learning Rate: 0.00711403
	LOSS [training: 0.3110531649680743 | validation: 0.2934737386920225]
	TIME [epoch: 9.79 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.30165519713472266		[learning rate: 0.0070857]
	Learning Rate: 0.00708573
	LOSS [training: 0.30165519713472266 | validation: 0.29643503282949035]
	TIME [epoch: 9.79 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.279865261727263		[learning rate: 0.0070575]
	Learning Rate: 0.00705755
	LOSS [training: 0.279865261727263 | validation: 0.2823504552027295]
	TIME [epoch: 9.81 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2961393516600405		[learning rate: 0.0070295]
	Learning Rate: 0.00702948
	LOSS [training: 0.2961393516600405 | validation: 0.2864871509996232]
	TIME [epoch: 9.79 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3130245082648557		[learning rate: 0.0070015]
	Learning Rate: 0.00700152
	LOSS [training: 0.3130245082648557 | validation: 0.3237646262697179]
	TIME [epoch: 9.79 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3062999055171882		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 0.3062999055171882 | validation: 0.2689698656676156]
	TIME [epoch: 9.8 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v11_20240711_165139/states/model_facs_v2_dec1b_2dpca_v11_135.pth
	Model improved!!!
EPOCH 136/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2929098394878186		[learning rate: 0.0069459]
	Learning Rate: 0.00694594
	LOSS [training: 0.2929098394878186 | validation: 0.27761924041265307]
	TIME [epoch: 9.8 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2910130050792713		[learning rate: 0.0069183]
	Learning Rate: 0.00691831
	LOSS [training: 0.2910130050792713 | validation: 0.3120981957417561]
	TIME [epoch: 9.79 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2946105169705486		[learning rate: 0.0068908]
	Learning Rate: 0.00689079
	LOSS [training: 0.2946105169705486 | validation: 0.2793816524698276]
	TIME [epoch: 9.79 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2817257814197678		[learning rate: 0.0068634]
	Learning Rate: 0.00686339
	LOSS [training: 0.2817257814197678 | validation: 0.3022966590889626]
	TIME [epoch: 9.81 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.308872342437755		[learning rate: 0.0068361]
	Learning Rate: 0.00683609
	LOSS [training: 0.308872342437755 | validation: 0.28258454940241723]
	TIME [epoch: 9.79 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.28465983716224424		[learning rate: 0.0068089]
	Learning Rate: 0.0068089
	LOSS [training: 0.28465983716224424 | validation: 0.2924458979464114]
	TIME [epoch: 9.79 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2646765944460276		[learning rate: 0.0067818]
	Learning Rate: 0.00678182
	LOSS [training: 0.2646765944460276 | validation: 0.2841836278771107]
	TIME [epoch: 9.8 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2912156723375381		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 0.2912156723375381 | validation: 0.27420306746382483]
	TIME [epoch: 9.81 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.28358666851688213		[learning rate: 0.006728]
	Learning Rate: 0.00672798
	LOSS [training: 0.28358666851688213 | validation: 0.26000803662200916]
	TIME [epoch: 9.79 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v11_20240711_165139/states/model_facs_v2_dec1b_2dpca_v11_144.pth
	Model improved!!!
EPOCH 145/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2874541974510043		[learning rate: 0.0067012]
	Learning Rate: 0.00670122
	LOSS [training: 0.2874541974510043 | validation: 0.29632251029255113]
	TIME [epoch: 9.81 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2961477504029089		[learning rate: 0.0066746]
	Learning Rate: 0.00667457
	LOSS [training: 0.2961477504029089 | validation: 0.2973132759492587]
	TIME [epoch: 9.82 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3016677683635643		[learning rate: 0.006648]
	Learning Rate: 0.00664802
	LOSS [training: 0.3016677683635643 | validation: 0.298878655008961]
	TIME [epoch: 9.8 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2912775671164993		[learning rate: 0.0066216]
	Learning Rate: 0.00662158
	LOSS [training: 0.2912775671164993 | validation: 0.2664025209613106]
	TIME [epoch: 9.8 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.30522647972235323		[learning rate: 0.0065952]
	Learning Rate: 0.00659524
	LOSS [training: 0.30522647972235323 | validation: 0.2773386368776783]
	TIME [epoch: 9.8 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.29927281800662087		[learning rate: 0.006569]
	Learning Rate: 0.00656901
	LOSS [training: 0.29927281800662087 | validation: 0.26530415796162277]
	TIME [epoch: 9.82 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2852067496918137		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 0.2852067496918137 | validation: 0.2565749724946115]
	TIME [epoch: 9.8 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v11_20240711_165139/states/model_facs_v2_dec1b_2dpca_v11_151.pth
	Model improved!!!
EPOCH 152/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2885361395527861		[learning rate: 0.0065169]
	Learning Rate: 0.00651686
	LOSS [training: 0.2885361395527861 | validation: 0.3352646952430587]
	TIME [epoch: 9.8 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.31526969809785466		[learning rate: 0.0064909]
	Learning Rate: 0.00649094
	LOSS [training: 0.31526969809785466 | validation: 0.2912458664426846]
	TIME [epoch: 9.81 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.28515032433601095		[learning rate: 0.0064651]
	Learning Rate: 0.00646512
	LOSS [training: 0.28515032433601095 | validation: 0.25959629772579135]
	TIME [epoch: 9.81 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.29228052728073634		[learning rate: 0.0064394]
	Learning Rate: 0.00643941
	LOSS [training: 0.29228052728073634 | validation: 0.2891216019293997]
	TIME [epoch: 9.8 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2984537637688514		[learning rate: 0.0064138]
	Learning Rate: 0.0064138
	LOSS [training: 0.2984537637688514 | validation: 0.26479026311767634]
	TIME [epoch: 9.8 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.27147246015031956		[learning rate: 0.0063883]
	Learning Rate: 0.00638829
	LOSS [training: 0.27147246015031956 | validation: 0.26696725122793363]
	TIME [epoch: 9.82 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.30914604397404344		[learning rate: 0.0063629]
	Learning Rate: 0.00636288
	LOSS [training: 0.30914604397404344 | validation: 0.26519547760201556]
	TIME [epoch: 9.8 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2802940182864663		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 0.2802940182864663 | validation: 0.290712413969474]
	TIME [epoch: 9.8 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.29840344087499243		[learning rate: 0.0063124]
	Learning Rate: 0.00631237
	LOSS [training: 0.29840344087499243 | validation: 0.3078049519111382]
	TIME [epoch: 9.8 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.29729185251478446		[learning rate: 0.0062873]
	Learning Rate: 0.00628726
	LOSS [training: 0.29729185251478446 | validation: 0.2800471640334087]
	TIME [epoch: 9.81 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2770574181285244		[learning rate: 0.0062623]
	Learning Rate: 0.00626226
	LOSS [training: 0.2770574181285244 | validation: 0.27351571475413955]
	TIME [epoch: 9.79 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2987750688671589		[learning rate: 0.0062373]
	Learning Rate: 0.00623735
	LOSS [training: 0.2987750688671589 | validation: 0.2533533250160951]
	TIME [epoch: 9.79 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v11_20240711_165139/states/model_facs_v2_dec1b_2dpca_v11_163.pth
	Model improved!!!
EPOCH 164/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.28038477418868607		[learning rate: 0.0062125]
	Learning Rate: 0.00621254
	LOSS [training: 0.28038477418868607 | validation: 0.2674411716704002]
	TIME [epoch: 9.81 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3141739728201195		[learning rate: 0.0061878]
	Learning Rate: 0.00618783
	LOSS [training: 0.3141739728201195 | validation: 0.2666926891118887]
	TIME [epoch: 9.8 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.284269286701687		[learning rate: 0.0061632]
	Learning Rate: 0.00616322
	LOSS [training: 0.284269286701687 | validation: 0.2719349239079616]
	TIME [epoch: 9.8 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.31724142311892484		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 0.31724142311892484 | validation: 0.2778895826473276]
	TIME [epoch: 9.8 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.28658134644579153		[learning rate: 0.0061143]
	Learning Rate: 0.00611429
	LOSS [training: 0.28658134644579153 | validation: 0.274513322238532]
	TIME [epoch: 9.81 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.299359562679711		[learning rate: 0.00609]
	Learning Rate: 0.00608997
	LOSS [training: 0.299359562679711 | validation: 0.2942302510844459]
	TIME [epoch: 9.79 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3187240917739225		[learning rate: 0.0060658]
	Learning Rate: 0.00606575
	LOSS [training: 0.3187240917739225 | validation: 0.29415575512209735]
	TIME [epoch: 9.79 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3043362859729241		[learning rate: 0.0060416]
	Learning Rate: 0.00604163
	LOSS [training: 0.3043362859729241 | validation: 0.2766010225400638]
	TIME [epoch: 9.8 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.30350420992502186		[learning rate: 0.0060176]
	Learning Rate: 0.0060176
	LOSS [training: 0.30350420992502186 | validation: 0.30075381256222444]
	TIME [epoch: 9.8 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32244479591941044		[learning rate: 0.0059937]
	Learning Rate: 0.00599366
	LOSS [training: 0.32244479591941044 | validation: 0.3137731423804003]
	TIME [epoch: 9.79 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3493537617216998		[learning rate: 0.0059698]
	Learning Rate: 0.00596982
	LOSS [training: 0.3493537617216998 | validation: 0.3045872020953548]
	TIME [epoch: 9.79 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3683238760364631		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 0.3683238760364631 | validation: 0.3114399435932119]
	TIME [epoch: 9.81 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3056062442194023		[learning rate: 0.0059224]
	Learning Rate: 0.00592243
	LOSS [training: 0.3056062442194023 | validation: 0.29029649324938506]
	TIME [epoch: 9.8 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.40048812365278647		[learning rate: 0.0058989]
	Learning Rate: 0.00589888
	LOSS [training: 0.40048812365278647 | validation: 0.39710791470788587]
	TIME [epoch: 9.79 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.39099535338488317		[learning rate: 0.0058754]
	Learning Rate: 0.00587541
	LOSS [training: 0.39099535338488317 | validation: 0.30375532422931595]
	TIME [epoch: 9.8 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3671853086781737		[learning rate: 0.005852]
	Learning Rate: 0.00585205
	LOSS [training: 0.3671853086781737 | validation: 0.3050269027900283]
	TIME [epoch: 9.81 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3365736593046955		[learning rate: 0.0058288]
	Learning Rate: 0.00582877
	LOSS [training: 0.3365736593046955 | validation: 0.2960104562300711]
	TIME [epoch: 9.8 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3157895649645585		[learning rate: 0.0058056]
	Learning Rate: 0.00580559
	LOSS [training: 0.3157895649645585 | validation: 0.3350745330013362]
	TIME [epoch: 9.8 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3162513162945613		[learning rate: 0.0057825]
	Learning Rate: 0.0057825
	LOSS [training: 0.3162513162945613 | validation: 0.28662200015420997]
	TIME [epoch: 9.82 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.35369610226374104		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 0.35369610226374104 | validation: 0.2944491567489306]
	TIME [epoch: 9.8 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3103468916387178		[learning rate: 0.0057366]
	Learning Rate: 0.00573659
	LOSS [training: 0.3103468916387178 | validation: 0.2789124948718638]
	TIME [epoch: 9.8 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3103585851638051		[learning rate: 0.0057138]
	Learning Rate: 0.00571377
	LOSS [training: 0.3103585851638051 | validation: 0.3243714126255295]
	TIME [epoch: 9.79 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3365780122899929		[learning rate: 0.005691]
	Learning Rate: 0.00569105
	LOSS [training: 0.3365780122899929 | validation: 0.2860376783504563]
	TIME [epoch: 9.81 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3289464910029351		[learning rate: 0.0056684]
	Learning Rate: 0.00566841
	LOSS [training: 0.3289464910029351 | validation: 0.3594207677084129]
	TIME [epoch: 9.79 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.38095162390563186		[learning rate: 0.0056459]
	Learning Rate: 0.00564587
	LOSS [training: 0.38095162390563186 | validation: 0.28971335265265036]
	TIME [epoch: 9.79 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3301510445316092		[learning rate: 0.0056234]
	Learning Rate: 0.00562341
	LOSS [training: 0.3301510445316092 | validation: 0.2736829482700321]
	TIME [epoch: 9.8 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2891453994863393		[learning rate: 0.005601]
	Learning Rate: 0.00560105
	LOSS [training: 0.2891453994863393 | validation: 0.29999656492842597]
	TIME [epoch: 9.81 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.30130434194345274		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 0.30130434194345274 | validation: 0.3213105002853164]
	TIME [epoch: 9.8 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3058950063347661		[learning rate: 0.0055566]
	Learning Rate: 0.00555658
	LOSS [training: 0.3058950063347661 | validation: 0.46404949601394757]
	TIME [epoch: 9.79 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3007041741584837		[learning rate: 0.0055345]
	Learning Rate: 0.00553448
	LOSS [training: 0.3007041741584837 | validation: 0.304820917712812]
	TIME [epoch: 9.81 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3044387064473569		[learning rate: 0.0055125]
	Learning Rate: 0.00551247
	LOSS [training: 0.3044387064473569 | validation: 0.29667556238782267]
	TIME [epoch: 9.8 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3046071214939857		[learning rate: 0.0054905]
	Learning Rate: 0.00549054
	LOSS [training: 0.3046071214939857 | validation: 0.2792501210792887]
	TIME [epoch: 9.79 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.31731298072592634		[learning rate: 0.0054687]
	Learning Rate: 0.00546871
	LOSS [training: 0.31731298072592634 | validation: 0.2796436502259095]
	TIME [epoch: 9.79 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2896179466685906		[learning rate: 0.005447]
	Learning Rate: 0.00544696
	LOSS [training: 0.2896179466685906 | validation: 0.26224091498470814]
	TIME [epoch: 9.81 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.27233253228069865		[learning rate: 0.0054253]
	Learning Rate: 0.00542529
	LOSS [training: 0.27233253228069865 | validation: 0.2670349871788023]
	TIME [epoch: 9.79 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.28815160670367757		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 0.28815160670367757 | validation: 0.39236418246973626]
	TIME [epoch: 9.79 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.30922708240266433		[learning rate: 0.0053822]
	Learning Rate: 0.00538222
	LOSS [training: 0.30922708240266433 | validation: 0.2693603304985013]
	TIME [epoch: 9.81 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.28436725174506106		[learning rate: 0.0053608]
	Learning Rate: 0.00536081
	LOSS [training: 0.28436725174506106 | validation: 0.27695612869180486]
	TIME [epoch: 9.81 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2982439276460783		[learning rate: 0.0053395]
	Learning Rate: 0.00533949
	LOSS [training: 0.2982439276460783 | validation: 0.2680668168546849]
	TIME [epoch: 9.79 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.27546855433311995		[learning rate: 0.0053183]
	Learning Rate: 0.00531826
	LOSS [training: 0.27546855433311995 | validation: 0.27543044283373475]
	TIME [epoch: 9.79 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2806020059865373		[learning rate: 0.0052971]
	Learning Rate: 0.0052971
	LOSS [training: 0.2806020059865373 | validation: 0.25689029690377385]
	TIME [epoch: 9.81 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.30962583093405144		[learning rate: 0.005276]
	Learning Rate: 0.00527604
	LOSS [training: 0.30962583093405144 | validation: 0.3004562650943487]
	TIME [epoch: 9.79 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2979457126645121		[learning rate: 0.0052551]
	Learning Rate: 0.00525505
	LOSS [training: 0.2979457126645121 | validation: 0.29847081121523383]
	TIME [epoch: 9.79 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3074804080808371		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 0.3074804080808371 | validation: 0.3039557178755864]
	TIME [epoch: 9.79 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.29272281168781		[learning rate: 0.0052133]
	Learning Rate: 0.00521333
	LOSS [training: 0.29272281168781 | validation: 0.33498228203507774]
	TIME [epoch: 9.81 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.318051811121695		[learning rate: 0.0051926]
	Learning Rate: 0.0051926
	LOSS [training: 0.318051811121695 | validation: 0.3545468847792542]
	TIME [epoch: 9.79 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3259180860475477		[learning rate: 0.0051719]
	Learning Rate: 0.00517194
	LOSS [training: 0.3259180860475477 | validation: 0.2524511687539882]
	TIME [epoch: 9.8 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v11_20240711_165139/states/model_facs_v2_dec1b_2dpca_v11_210.pth
	Model improved!!!
EPOCH 211/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.29235232698086183		[learning rate: 0.0051514]
	Learning Rate: 0.00515137
	LOSS [training: 0.29235232698086183 | validation: 0.2825082036741261]
	TIME [epoch: 9.8 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.280741960748371		[learning rate: 0.0051309]
	Learning Rate: 0.00513089
	LOSS [training: 0.280741960748371 | validation: 0.3456016248894487]
	TIME [epoch: 9.79 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2933919981605883		[learning rate: 0.0051105]
	Learning Rate: 0.00511048
	LOSS [training: 0.2933919981605883 | validation: 0.25633521075507637]
	TIME [epoch: 9.79 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.27054702807656433		[learning rate: 0.0050902]
	Learning Rate: 0.00509015
	LOSS [training: 0.27054702807656433 | validation: 0.26274664682461885]
	TIME [epoch: 9.8 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2808288225213531		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 0.2808288225213531 | validation: 0.3039035524547156]
	TIME [epoch: 9.81 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.31316819743479735		[learning rate: 0.0050497]
	Learning Rate: 0.00504974
	LOSS [training: 0.31316819743479735 | validation: 0.269347403831511]
	TIME [epoch: 9.79 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.306895093981783		[learning rate: 0.0050297]
	Learning Rate: 0.00502966
	LOSS [training: 0.306895093981783 | validation: 0.34018791577538615]
	TIME [epoch: 9.79 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32553821337093003		[learning rate: 0.0050097]
	Learning Rate: 0.00500965
	LOSS [training: 0.32553821337093003 | validation: 0.32797627466870294]
	TIME [epoch: 9.8 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3007749215196285		[learning rate: 0.0049897]
	Learning Rate: 0.00498973
	LOSS [training: 0.3007749215196285 | validation: 0.28515632649102496]
	TIME [epoch: 9.8 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3137941100696564		[learning rate: 0.0049699]
	Learning Rate: 0.00496988
	LOSS [training: 0.3137941100696564 | validation: 0.28624249533200236]
	TIME [epoch: 9.79 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2979175249797557		[learning rate: 0.0049501]
	Learning Rate: 0.00495012
	LOSS [training: 0.2979175249797557 | validation: 0.27362630320152703]
	TIME [epoch: 9.8 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.29347834502373366		[learning rate: 0.0049304]
	Learning Rate: 0.00493043
	LOSS [training: 0.29347834502373366 | validation: 0.2668030502861214]
	TIME [epoch: 9.81 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2784186074830493		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 0.2784186074830493 | validation: 0.2594033706477302]
	TIME [epoch: 9.8 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2926108357845523		[learning rate: 0.0048913]
	Learning Rate: 0.00489129
	LOSS [training: 0.2926108357845523 | validation: 0.27632348884182223]
	TIME [epoch: 9.79 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.28103677528604765		[learning rate: 0.0048718]
	Learning Rate: 0.00487183
	LOSS [training: 0.28103677528604765 | validation: 0.3223704374029459]
	TIME [epoch: 9.79 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.28447963630012757		[learning rate: 0.0048525]
	Learning Rate: 0.00485245
	LOSS [training: 0.28447963630012757 | validation: 0.2624827542348053]
	TIME [epoch: 9.81 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2833704050527001		[learning rate: 0.0048332]
	Learning Rate: 0.00483316
	LOSS [training: 0.2833704050527001 | validation: 0.2702956179489589]
	TIME [epoch: 9.79 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.296059786664481		[learning rate: 0.0048139]
	Learning Rate: 0.00481393
	LOSS [training: 0.296059786664481 | validation: 0.28350645852747414]
	TIME [epoch: 9.79 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.30757562282420486		[learning rate: 0.0047948]
	Learning Rate: 0.00479479
	LOSS [training: 0.30757562282420486 | validation: 0.2664608065941812]
	TIME [epoch: 9.8 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.28644530015831754		[learning rate: 0.0047757]
	Learning Rate: 0.00477572
	LOSS [training: 0.28644530015831754 | validation: 0.2757536618986429]
	TIME [epoch: 9.8 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.27579939567786993		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.27579939567786993 | validation: 0.2943418870381441]
	TIME [epoch: 9.79 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2861012095111555		[learning rate: 0.0047378]
	Learning Rate: 0.0047378
	LOSS [training: 0.2861012095111555 | validation: 0.31271070207794605]
	TIME [epoch: 9.79 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.30283151531291364		[learning rate: 0.004719]
	Learning Rate: 0.00471896
	LOSS [training: 0.30283151531291364 | validation: 0.2942882258733779]
	TIME [epoch: 9.8 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2844522032456596		[learning rate: 0.0047002]
	Learning Rate: 0.00470019
	LOSS [training: 0.2844522032456596 | validation: 0.27173751969006876]
	TIME [epoch: 9.79 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.29480809836188626		[learning rate: 0.0046815]
	Learning Rate: 0.0046815
	LOSS [training: 0.29480809836188626 | validation: 0.3124995584110043]
	TIME [epoch: 9.79 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.29025635910209546		[learning rate: 0.0046629]
	Learning Rate: 0.00466288
	LOSS [training: 0.29025635910209546 | validation: 0.2784802493644158]
	TIME [epoch: 9.79 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2921634416713188		[learning rate: 0.0046443]
	Learning Rate: 0.00464433
	LOSS [training: 0.2921634416713188 | validation: 0.276875248174531]
	TIME [epoch: 9.8 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2896792936630422		[learning rate: 0.0046259]
	Learning Rate: 0.00462586
	LOSS [training: 0.2896792936630422 | validation: 0.26930508268650666]
	TIME [epoch: 9.79 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.29150144457755		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 0.29150144457755 | validation: 0.25481432464263126]
	TIME [epoch: 9.79 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5189181586673108		[learning rate: 0.0045891]
	Learning Rate: 0.00458913
	LOSS [training: 0.5189181586673108 | validation: 0.32636033628495725]
	TIME [epoch: 9.8 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32514842125972016		[learning rate: 0.0045709]
	Learning Rate: 0.00457088
	LOSS [training: 0.32514842125972016 | validation: 0.32553261161642794]
	TIME [epoch: 9.79 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.30608781050078876		[learning rate: 0.0045527]
	Learning Rate: 0.0045527
	LOSS [training: 0.30608781050078876 | validation: 0.2929064877339058]
	TIME [epoch: 9.79 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.296726630904569		[learning rate: 0.0045346]
	Learning Rate: 0.00453459
	LOSS [training: 0.296726630904569 | validation: 0.2663320446285099]
	TIME [epoch: 9.79 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2958339513215328		[learning rate: 0.0045166]
	Learning Rate: 0.00451656
	LOSS [training: 0.2958339513215328 | validation: 0.26751309099480935]
	TIME [epoch: 9.81 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.28473562708059824		[learning rate: 0.0044986]
	Learning Rate: 0.0044986
	LOSS [training: 0.28473562708059824 | validation: 0.25639960480721624]
	TIME [epoch: 9.79 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.28055834164881505		[learning rate: 0.0044807]
	Learning Rate: 0.0044807
	LOSS [training: 0.28055834164881505 | validation: 0.2557451882235747]
	TIME [epoch: 9.79 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2865880317926871		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 0.2865880317926871 | validation: 0.26520487587265434]
	TIME [epoch: 9.79 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3282012905799211		[learning rate: 0.0044451]
	Learning Rate: 0.00444513
	LOSS [training: 0.3282012905799211 | validation: 0.3139503840542932]
	TIME [epoch: 9.79 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.30431158612924303		[learning rate: 0.0044275]
	Learning Rate: 0.00442745
	LOSS [training: 0.30431158612924303 | validation: 0.3181289228721953]
	TIME [epoch: 9.78 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3110648001854361		[learning rate: 0.0044098]
	Learning Rate: 0.00440984
	LOSS [training: 0.3110648001854361 | validation: 0.32522658215205]
	TIME [epoch: 9.79 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3985370789067523		[learning rate: 0.0043923]
	Learning Rate: 0.0043923
	LOSS [training: 0.3985370789067523 | validation: 0.3313037492722164]
	TIME [epoch: 9.8 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3228701413788067		[learning rate: 0.0043748]
	Learning Rate: 0.00437483
	LOSS [training: 0.3228701413788067 | validation: 0.2804505463771402]
	TIME [epoch: 9.79 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.28733063358535127		[learning rate: 0.0043574]
	Learning Rate: 0.00435743
	LOSS [training: 0.28733063358535127 | validation: 0.25234640936153213]
	TIME [epoch: 9.79 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v11_20240711_165139/states/model_facs_v2_dec1b_2dpca_v11_253.pth
	Model improved!!!
EPOCH 254/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2736907522193496		[learning rate: 0.0043401]
	Learning Rate: 0.0043401
	LOSS [training: 0.2736907522193496 | validation: 0.2711782571842411]
	TIME [epoch: 9.79 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2888250749981666		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 0.2888250749981666 | validation: 0.2743068463942309]
	TIME [epoch: 9.8 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.28272129353025416		[learning rate: 0.0043056]
	Learning Rate: 0.00430565
	LOSS [training: 0.28272129353025416 | validation: 0.274381452949027]
	TIME [epoch: 9.79 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.29487716006126763		[learning rate: 0.0042885]
	Learning Rate: 0.00428852
	LOSS [training: 0.29487716006126763 | validation: 0.2678701423691399]
	TIME [epoch: 9.78 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2869641132182442		[learning rate: 0.0042715]
	Learning Rate: 0.00427147
	LOSS [training: 0.2869641132182442 | validation: 0.2634663539507087]
	TIME [epoch: 9.79 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.28757287668946585		[learning rate: 0.0042545]
	Learning Rate: 0.00425448
	LOSS [training: 0.28757287668946585 | validation: 0.2895767024030507]
	TIME [epoch: 9.79 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2819766855203235		[learning rate: 0.0042376]
	Learning Rate: 0.00423756
	LOSS [training: 0.2819766855203235 | validation: 0.24819328960973594]
	TIME [epoch: 9.78 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v11_20240711_165139/states/model_facs_v2_dec1b_2dpca_v11_260.pth
	Model improved!!!
EPOCH 261/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.29123276082417693		[learning rate: 0.0042207]
	Learning Rate: 0.0042207
	LOSS [training: 0.29123276082417693 | validation: 0.27257228921849946]
	TIME [epoch: 9.79 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.28347783836545415		[learning rate: 0.0042039]
	Learning Rate: 0.00420391
	LOSS [training: 0.28347783836545415 | validation: 0.25368886666509516]
	TIME [epoch: 9.8 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2900977555221283		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 0.2900977555221283 | validation: 0.26892181221477623]
	TIME [epoch: 9.87 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.27186364129941387		[learning rate: 0.0041705]
	Learning Rate: 0.00417054
	LOSS [training: 0.27186364129941387 | validation: 0.2599119320548645]
	TIME [epoch: 9.79 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2865122507578807		[learning rate: 0.004154]
	Learning Rate: 0.00415395
	LOSS [training: 0.2865122507578807 | validation: 0.26858820016428264]
	TIME [epoch: 9.79 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2876613459006132		[learning rate: 0.0041374]
	Learning Rate: 0.00413743
	LOSS [training: 0.2876613459006132 | validation: 0.27740898042021783]
	TIME [epoch: 9.79 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.28410542747663814		[learning rate: 0.004121]
	Learning Rate: 0.00412098
	LOSS [training: 0.28410542747663814 | validation: 0.2668466779027759]
	TIME [epoch: 9.79 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2821641851044448		[learning rate: 0.0041046]
	Learning Rate: 0.00410458
	LOSS [training: 0.2821641851044448 | validation: 0.27934931771623017]
	TIME [epoch: 9.78 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.36940036168945295		[learning rate: 0.0040883]
	Learning Rate: 0.00408826
	LOSS [training: 0.36940036168945295 | validation: 0.2765079921691435]
	TIME [epoch: 9.8 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3192895162147448		[learning rate: 0.004072]
	Learning Rate: 0.004072
	LOSS [training: 0.3192895162147448 | validation: 0.2736266202894695]
	TIME [epoch: 9.78 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.29443167001452203		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.29443167001452203 | validation: 0.2772057949470065]
	TIME [epoch: 9.79 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.28022668809611156		[learning rate: 0.0040397]
	Learning Rate: 0.00403967
	LOSS [training: 0.28022668809611156 | validation: 0.25980461605329086]
	TIME [epoch: 9.78 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.28490960230147216		[learning rate: 0.0040236]
	Learning Rate: 0.00402361
	LOSS [training: 0.28490960230147216 | validation: 0.2638632957698996]
	TIME [epoch: 9.8 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2947620788012807		[learning rate: 0.0040076]
	Learning Rate: 0.0040076
	LOSS [training: 0.2947620788012807 | validation: 0.267333636588156]
	TIME [epoch: 9.79 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2829587905382718		[learning rate: 0.0039917]
	Learning Rate: 0.00399166
	LOSS [training: 0.2829587905382718 | validation: 0.25929818909672453]
	TIME [epoch: 9.79 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2794170758087969		[learning rate: 0.0039758]
	Learning Rate: 0.00397579
	LOSS [training: 0.2794170758087969 | validation: 0.2845061391786345]
	TIME [epoch: 9.79 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2944916959140525		[learning rate: 0.00396]
	Learning Rate: 0.00395997
	LOSS [training: 0.2944916959140525 | validation: 0.2934835301040112]
	TIME [epoch: 9.8 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2793666640963072		[learning rate: 0.0039442]
	Learning Rate: 0.00394422
	LOSS [training: 0.2793666640963072 | validation: 0.24957209522378765]
	TIME [epoch: 9.79 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2855764096308301		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 0.2855764096308301 | validation: 0.3043712359160665]
	TIME [epoch: 9.79 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.29780339674296136		[learning rate: 0.0039129]
	Learning Rate: 0.00391291
	LOSS [training: 0.29780339674296136 | validation: 0.2525840505733229]
	TIME [epoch: 9.8 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.29035892343689174		[learning rate: 0.0038973]
	Learning Rate: 0.00389735
	LOSS [training: 0.29035892343689174 | validation: 0.26560747160936893]
	TIME [epoch: 9.79 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2854309581955692		[learning rate: 0.0038818]
	Learning Rate: 0.00388185
	LOSS [training: 0.2854309581955692 | validation: 0.255768781186673]
	TIME [epoch: 9.79 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.28557094311541065		[learning rate: 0.0038664]
	Learning Rate: 0.00386641
	LOSS [training: 0.28557094311541065 | validation: 0.2649083001636636]
	TIME [epoch: 9.79 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.27867339613735265		[learning rate: 0.003851]
	Learning Rate: 0.00385103
	LOSS [training: 0.27867339613735265 | validation: 0.2664179017642412]
	TIME [epoch: 9.8 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3031112902825318		[learning rate: 0.0038357]
	Learning Rate: 0.00383571
	LOSS [training: 0.3031112902825318 | validation: 0.2889971082844517]
	TIME [epoch: 9.79 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2886668802078368		[learning rate: 0.0038205]
	Learning Rate: 0.00382046
	LOSS [training: 0.2886668802078368 | validation: 0.24988136397084376]
	TIME [epoch: 9.78 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2703828977653685		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 0.2703828977653685 | validation: 0.26481509236171635]
	TIME [epoch: 9.8 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2778214878603429		[learning rate: 0.0037901]
	Learning Rate: 0.00379013
	LOSS [training: 0.2778214878603429 | validation: 0.2473510139813409]
	TIME [epoch: 9.79 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v11_20240711_165139/states/model_facs_v2_dec1b_2dpca_v11_288.pth
	Model improved!!!
EPOCH 289/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26847840837443837		[learning rate: 0.0037751]
	Learning Rate: 0.00377505
	LOSS [training: 0.26847840837443837 | validation: 0.2601148278311646]
	TIME [epoch: 9.79 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2789141877080391		[learning rate: 0.00376]
	Learning Rate: 0.00376004
	LOSS [training: 0.2789141877080391 | validation: 0.26106693803914965]
	TIME [epoch: 9.78 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.28132884892209176		[learning rate: 0.0037451]
	Learning Rate: 0.00374508
	LOSS [training: 0.28132884892209176 | validation: 0.2542222553053481]
	TIME [epoch: 9.79 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26083420924965195		[learning rate: 0.0037302]
	Learning Rate: 0.00373019
	LOSS [training: 0.26083420924965195 | validation: 0.24276785617451072]
	TIME [epoch: 9.78 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v11_20240711_165139/states/model_facs_v2_dec1b_2dpca_v11_292.pth
	Model improved!!!
EPOCH 293/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.266347955691139		[learning rate: 0.0037154]
	Learning Rate: 0.00371535
	LOSS [training: 0.266347955691139 | validation: 0.2936577420492384]
	TIME [epoch: 9.79 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.27388222834794557		[learning rate: 0.0037006]
	Learning Rate: 0.00370058
	LOSS [training: 0.27388222834794557 | validation: 0.24182357180059705]
	TIME [epoch: 9.79 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v11_20240711_165139/states/model_facs_v2_dec1b_2dpca_v11_294.pth
	Model improved!!!
EPOCH 295/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2622152059306831		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 0.2622152059306831 | validation: 0.24905734184558934]
	TIME [epoch: 9.79 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2934201976366592		[learning rate: 0.0036712]
	Learning Rate: 0.0036712
	LOSS [training: 0.2934201976366592 | validation: 0.25827154433495003]
	TIME [epoch: 9.77 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2760094313796768		[learning rate: 0.0036566]
	Learning Rate: 0.0036566
	LOSS [training: 0.2760094313796768 | validation: 0.2642437776822716]
	TIME [epoch: 9.78 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.27149811178392685		[learning rate: 0.0036421]
	Learning Rate: 0.00364205
	LOSS [training: 0.27149811178392685 | validation: 0.24490314983396283]
	TIME [epoch: 9.8 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26477042649670235		[learning rate: 0.0036276]
	Learning Rate: 0.00362757
	LOSS [training: 0.26477042649670235 | validation: 0.27574456493738364]
	TIME [epoch: 9.78 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2701752214218606		[learning rate: 0.0036131]
	Learning Rate: 0.00361314
	LOSS [training: 0.2701752214218606 | validation: 0.2675245383322824]
	TIME [epoch: 9.78 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2633019921858135		[learning rate: 0.0035988]
	Learning Rate: 0.00359877
	LOSS [training: 0.2633019921858135 | validation: 0.2814570409145829]
	TIME [epoch: 9.78 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26162635093221437		[learning rate: 0.0035845]
	Learning Rate: 0.00358445
	LOSS [training: 0.26162635093221437 | validation: 0.2741759261480525]
	TIME [epoch: 9.79 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26346104631734096		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 0.26346104631734096 | validation: 0.25146578065629094]
	TIME [epoch: 9.78 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3448693781336426		[learning rate: 0.003556]
	Learning Rate: 0.003556
	LOSS [training: 0.3448693781336426 | validation: 0.2804687595749625]
	TIME [epoch: 9.77 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3175682047602099		[learning rate: 0.0035419]
	Learning Rate: 0.00354185
	LOSS [training: 0.3175682047602099 | validation: 0.26549762431591767]
	TIME [epoch: 9.78 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.317438225538476		[learning rate: 0.0035278]
	Learning Rate: 0.00352777
	LOSS [training: 0.317438225538476 | validation: 0.2788580456594241]
	TIME [epoch: 9.78 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3164219804758156		[learning rate: 0.0035137]
	Learning Rate: 0.00351374
	LOSS [training: 0.3164219804758156 | validation: 0.27772976667132027]
	TIME [epoch: 9.77 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.30371140297151084		[learning rate: 0.0034998]
	Learning Rate: 0.00349976
	LOSS [training: 0.30371140297151084 | validation: 0.2533134583992625]
	TIME [epoch: 9.77 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3047722609644819		[learning rate: 0.0034858]
	Learning Rate: 0.00348584
	LOSS [training: 0.3047722609644819 | validation: 0.2475633434081474]
	TIME [epoch: 9.79 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.309552268148762		[learning rate: 0.003472]
	Learning Rate: 0.00347198
	LOSS [training: 0.309552268148762 | validation: 0.2742605366327222]
	TIME [epoch: 9.78 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.31118746723822066		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.31118746723822066 | validation: 0.28099461213123467]
	TIME [epoch: 9.77 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.29285409000596924		[learning rate: 0.0034444]
	Learning Rate: 0.00344441
	LOSS [training: 0.29285409000596924 | validation: 0.25124652702206607]
	TIME [epoch: 9.79 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2833448348708939		[learning rate: 0.0034307]
	Learning Rate: 0.00343071
	LOSS [training: 0.2833448348708939 | validation: 0.25673969400319246]
	TIME [epoch: 9.78 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.28885409622841907		[learning rate: 0.0034171]
	Learning Rate: 0.00341707
	LOSS [training: 0.28885409622841907 | validation: 0.2820220464789734]
	TIME [epoch: 9.77 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2808173988919393		[learning rate: 0.0034035]
	Learning Rate: 0.00340348
	LOSS [training: 0.2808173988919393 | validation: 0.26461836068732364]
	TIME [epoch: 9.77 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2946279512827554		[learning rate: 0.0033899]
	Learning Rate: 0.00338994
	LOSS [training: 0.2946279512827554 | validation: 0.25189195130153225]
	TIME [epoch: 9.79 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.28192859316124924		[learning rate: 0.0033765]
	Learning Rate: 0.00337646
	LOSS [training: 0.28192859316124924 | validation: 0.25248782755951177]
	TIME [epoch: 9.78 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2772407627140954		[learning rate: 0.003363]
	Learning Rate: 0.00336303
	LOSS [training: 0.2772407627140954 | validation: 0.25320551928054535]
	TIME [epoch: 9.78 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2850067570111846		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 0.2850067570111846 | validation: 0.2686698330234196]
	TIME [epoch: 9.78 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.29385742836718043		[learning rate: 0.0033363]
	Learning Rate: 0.00333633
	LOSS [training: 0.29385742836718043 | validation: 0.2742113015914847]
	TIME [epoch: 9.79 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2851169471825119		[learning rate: 0.0033231]
	Learning Rate: 0.00332306
	LOSS [training: 0.2851169471825119 | validation: 0.260757978204737]
	TIME [epoch: 9.77 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.29058835390120047		[learning rate: 0.0033098]
	Learning Rate: 0.00330985
	LOSS [training: 0.29058835390120047 | validation: 0.24365505975669546]
	TIME [epoch: 9.78 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.30209585992511695		[learning rate: 0.0032967]
	Learning Rate: 0.00329668
	LOSS [training: 0.30209585992511695 | validation: 0.24632903282669485]
	TIME [epoch: 9.79 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2634311268538862		[learning rate: 0.0032836]
	Learning Rate: 0.00328357
	LOSS [training: 0.2634311268538862 | validation: 0.24199036943656474]
	TIME [epoch: 9.78 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26455683289146514		[learning rate: 0.0032705]
	Learning Rate: 0.00327051
	LOSS [training: 0.26455683289146514 | validation: 0.2409308108842841]
	TIME [epoch: 9.78 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v11_20240711_165139/states/model_facs_v2_dec1b_2dpca_v11_325.pth
	Model improved!!!
EPOCH 326/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2782644806300945		[learning rate: 0.0032575]
	Learning Rate: 0.0032575
	LOSS [training: 0.2782644806300945 | validation: 0.24147622872926214]
	TIME [epoch: 9.78 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2658153195040469		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 0.2658153195040469 | validation: 0.24685146302081265]
	TIME [epoch: 9.79 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2584168372066102		[learning rate: 0.0032316]
	Learning Rate: 0.00323164
	LOSS [training: 0.2584168372066102 | validation: 0.23761093687693347]
	TIME [epoch: 9.78 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v11_20240711_165139/states/model_facs_v2_dec1b_2dpca_v11_328.pth
	Model improved!!!
EPOCH 329/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2668440047972751		[learning rate: 0.0032188]
	Learning Rate: 0.00321879
	LOSS [training: 0.2668440047972751 | validation: 0.239040621411802]
	TIME [epoch: 9.78 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2830564875583136		[learning rate: 0.003206]
	Learning Rate: 0.00320599
	LOSS [training: 0.2830564875583136 | validation: 0.2633864913792373]
	TIME [epoch: 9.79 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2902637903619772		[learning rate: 0.0031932]
	Learning Rate: 0.00319323
	LOSS [training: 0.2902637903619772 | validation: 0.25473968847946765]
	TIME [epoch: 9.79 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.270198346645607		[learning rate: 0.0031805]
	Learning Rate: 0.00318053
	LOSS [training: 0.270198346645607 | validation: 0.272683412984945]
	TIME [epoch: 9.78 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26952705539470184		[learning rate: 0.0031679]
	Learning Rate: 0.00316788
	LOSS [training: 0.26952705539470184 | validation: 0.24953294890527258]
	TIME [epoch: 9.77 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2587454020412376		[learning rate: 0.0031553]
	Learning Rate: 0.00315528
	LOSS [training: 0.2587454020412376 | validation: 0.23661645963196695]
	TIME [epoch: 9.79 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v11_20240711_165139/states/model_facs_v2_dec1b_2dpca_v11_334.pth
	Model improved!!!
EPOCH 335/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26194695790593125		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 0.26194695790593125 | validation: 0.2501001398606063]
	TIME [epoch: 9.78 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26400626661001125		[learning rate: 0.0031302]
	Learning Rate: 0.00313023
	LOSS [training: 0.26400626661001125 | validation: 0.2618319589981473]
	TIME [epoch: 9.78 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2558262178932409		[learning rate: 0.0031178]
	Learning Rate: 0.00311779
	LOSS [training: 0.2558262178932409 | validation: 0.23942323552063413]
	TIME [epoch: 9.78 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2507456462965607		[learning rate: 0.0031054]
	Learning Rate: 0.00310538
	LOSS [training: 0.2507456462965607 | validation: 0.24870291514165083]
	TIME [epoch: 9.79 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2583028130727235		[learning rate: 0.003093]
	Learning Rate: 0.00309303
	LOSS [training: 0.2583028130727235 | validation: 0.24236419399617906]
	TIME [epoch: 9.77 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2637361404189395		[learning rate: 0.0030807]
	Learning Rate: 0.00308073
	LOSS [training: 0.2637361404189395 | validation: 0.25383666671615973]
	TIME [epoch: 9.78 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2649338513039797		[learning rate: 0.0030685]
	Learning Rate: 0.00306848
	LOSS [training: 0.2649338513039797 | validation: 0.24747495128295688]
	TIME [epoch: 9.79 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25833829042854867		[learning rate: 0.0030563]
	Learning Rate: 0.00305627
	LOSS [training: 0.25833829042854867 | validation: 0.23974828096675221]
	TIME [epoch: 9.78 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2551456188660318		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 0.2551456188660318 | validation: 0.24797754104697778]
	TIME [epoch: 9.77 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2810626803871802		[learning rate: 0.003032]
	Learning Rate: 0.00303201
	LOSS [training: 0.2810626803871802 | validation: 0.2831181911520906]
	TIME [epoch: 9.78 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.30452098707820624		[learning rate: 0.00302]
	Learning Rate: 0.00301995
	LOSS [training: 0.30452098707820624 | validation: 0.25703090863832173]
	TIME [epoch: 9.8 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.27038877564102864		[learning rate: 0.0030079]
	Learning Rate: 0.00300794
	LOSS [training: 0.27038877564102864 | validation: 0.2502439890469275]
	TIME [epoch: 9.78 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2621333079761081		[learning rate: 0.002996]
	Learning Rate: 0.00299598
	LOSS [training: 0.2621333079761081 | validation: 0.24899114488883106]
	TIME [epoch: 9.78 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26956772523876976		[learning rate: 0.0029841]
	Learning Rate: 0.00298406
	LOSS [training: 0.26956772523876976 | validation: 0.2629917504164416]
	TIME [epoch: 9.78 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.27839315486840804		[learning rate: 0.0029722]
	Learning Rate: 0.00297219
	LOSS [training: 0.27839315486840804 | validation: 0.25853255976321216]
	TIME [epoch: 9.79 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2658027490742478		[learning rate: 0.0029604]
	Learning Rate: 0.00296037
	LOSS [training: 0.2658027490742478 | validation: 0.2408605712141322]
	TIME [epoch: 9.78 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2622468664725098		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.2622468664725098 | validation: 0.2875315662384155]
	TIME [epoch: 9.77 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2976264561987029		[learning rate: 0.0029369]
	Learning Rate: 0.00293687
	LOSS [training: 0.2976264561987029 | validation: 0.2695446725001064]
	TIME [epoch: 9.79 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26718971239406497		[learning rate: 0.0029252]
	Learning Rate: 0.00292519
	LOSS [training: 0.26718971239406497 | validation: 0.25416351179386015]
	TIME [epoch: 9.77 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2610926074825316		[learning rate: 0.0029136]
	Learning Rate: 0.00291355
	LOSS [training: 0.2610926074825316 | validation: 0.25414994895854925]
	TIME [epoch: 9.78 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2561050485352758		[learning rate: 0.002902]
	Learning Rate: 0.00290197
	LOSS [training: 0.2561050485352758 | validation: 0.24512031984590804]
	TIME [epoch: 9.78 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.28261998780030817		[learning rate: 0.0028904]
	Learning Rate: 0.00289042
	LOSS [training: 0.28261998780030817 | validation: 0.29177927301492407]
	TIME [epoch: 9.8 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.278666847908226		[learning rate: 0.0028789]
	Learning Rate: 0.00287893
	LOSS [training: 0.278666847908226 | validation: 0.2579148548189765]
	TIME [epoch: 9.78 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.27311762954278823		[learning rate: 0.0028675]
	Learning Rate: 0.00286748
	LOSS [training: 0.27311762954278823 | validation: 0.26656027626240164]
	TIME [epoch: 9.78 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2769895654432582		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 0.2769895654432582 | validation: 0.26878410937728564]
	TIME [epoch: 9.78 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2614214192959719		[learning rate: 0.0028447]
	Learning Rate: 0.00284471
	LOSS [training: 0.2614214192959719 | validation: 0.24224491812599097]
	TIME [epoch: 9.79 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.27365038715695167		[learning rate: 0.0028334]
	Learning Rate: 0.0028334
	LOSS [training: 0.27365038715695167 | validation: 0.23968785828605413]
	TIME [epoch: 9.78 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2536446147446173		[learning rate: 0.0028221]
	Learning Rate: 0.00282213
	LOSS [training: 0.2536446147446173 | validation: 0.24161087333504633]
	TIME [epoch: 9.78 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2889277908054444		[learning rate: 0.0028109]
	Learning Rate: 0.00281091
	LOSS [training: 0.2889277908054444 | validation: 0.30023833910554915]
	TIME [epoch: 9.79 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2921316046180701		[learning rate: 0.0027997]
	Learning Rate: 0.00279973
	LOSS [training: 0.2921316046180701 | validation: 0.27126329009629047]
	TIME [epoch: 9.78 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2850246223897547		[learning rate: 0.0027886]
	Learning Rate: 0.00278859
	LOSS [training: 0.2850246223897547 | validation: 0.2928762621405576]
	TIME [epoch: 9.77 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2916625882428037		[learning rate: 0.0027775]
	Learning Rate: 0.0027775
	LOSS [training: 0.2916625882428037 | validation: 0.2704274916360069]
	TIME [epoch: 9.78 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.27972799268708587		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 0.27972799268708587 | validation: 0.2775875755455476]
	TIME [epoch: 9.79 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.40144383059893873		[learning rate: 0.0027554]
	Learning Rate: 0.00275545
	LOSS [training: 0.40144383059893873 | validation: 0.5926888659234829]
	TIME [epoch: 9.78 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.9034502486753486		[learning rate: 0.0027445]
	Learning Rate: 0.00274449
	LOSS [training: 0.9034502486753486 | validation: 0.7596536672799097]
	TIME [epoch: 9.77 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.2846982993424376		[learning rate: 0.0027336]
	Learning Rate: 0.00273357
	LOSS [training: 1.2846982993424376 | validation: 1.4331074888468094]
	TIME [epoch: 9.79 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.9970812940368314		[learning rate: 0.0027227]
	Learning Rate: 0.0027227
	LOSS [training: 1.9970812940368314 | validation: 1.797302385056484]
	TIME [epoch: 9.78 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 9/9] avg loss: 2.5482323723941027		[learning rate: 0.0027119]
	Learning Rate: 0.00271187
	LOSS [training: 2.5482323723941027 | validation: 1.634819378843627]
	TIME [epoch: 9.78 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.4446078699718699		[learning rate: 0.0027011]
	Learning Rate: 0.00270109
	LOSS [training: 1.4446078699718699 | validation: 1.0248815803151312]
	TIME [epoch: 9.77 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.3360294406882751		[learning rate: 0.0026903]
	Learning Rate: 0.00269034
	LOSS [training: 1.3360294406882751 | validation: 1.2746495900970503]
	TIME [epoch: 9.79 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.7516731628013629		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 1.7516731628013629 | validation: 1.3813853654801]
	TIME [epoch: 9.78 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.4809889863240622		[learning rate: 0.002669]
	Learning Rate: 0.00266899
	LOSS [training: 1.4809889863240622 | validation: 1.1575386753314938]
	TIME [epoch: 9.78 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.3191914898714145		[learning rate: 0.0026584]
	Learning Rate: 0.00265837
	LOSS [training: 1.3191914898714145 | validation: 1.2167043388294487]
	TIME [epoch: 9.77 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.9713890633852047		[learning rate: 0.0026478]
	Learning Rate: 0.0026478
	LOSS [training: 1.9713890633852047 | validation: 1.8618758572859577]
	TIME [epoch: 9.79 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 9/9] avg loss: 2.4540815680665835		[learning rate: 0.0026373]
	Learning Rate: 0.00263727
	LOSS [training: 2.4540815680665835 | validation: 2.003309864264239]
	TIME [epoch: 9.77 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 9/9] avg loss: 2.536265013799159		[learning rate: 0.0026268]
	Learning Rate: 0.00262678
	LOSS [training: 2.536265013799159 | validation: 2.2688408181260145]
	TIME [epoch: 9.77 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 9/9] avg loss: 2.303764487975331		[learning rate: 0.0026163]
	Learning Rate: 0.00261633
	LOSS [training: 2.303764487975331 | validation: 2.1567677748470926]
	TIME [epoch: 9.78 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 9/9] avg loss: 2.6601421620575474		[learning rate: 0.0026059]
	Learning Rate: 0.00260592
	LOSS [training: 2.6601421620575474 | validation: 2.559164872318195]
	TIME [epoch: 9.78 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 9/9] avg loss: 3.491598396985132		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 3.491598396985132 | validation: 3.0061910966800562]
	TIME [epoch: 9.77 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 9/9] avg loss: 2.466720246137586		[learning rate: 0.0025852]
	Learning Rate: 0.00258523
	LOSS [training: 2.466720246137586 | validation: 1.982366754266181]
	TIME [epoch: 9.77 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 9/9] avg loss: 2.5883227848320605		[learning rate: 0.002575]
	Learning Rate: 0.00257495
	LOSS [training: 2.5883227848320605 | validation: 2.3344919808191813]
	TIME [epoch: 9.79 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 9/9] avg loss: 3.339830677671876		[learning rate: 0.0025647]
	Learning Rate: 0.00256471
	LOSS [training: 3.339830677671876 | validation: 2.1029145569931]
	TIME [epoch: 9.78 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 9/9] avg loss: 2.122234981134698		[learning rate: 0.0025545]
	Learning Rate: 0.00255451
	LOSS [training: 2.122234981134698 | validation: 1.48935535006023]
	TIME [epoch: 9.77 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 9/9] avg loss: 2.0534421742542803		[learning rate: 0.0025444]
	Learning Rate: 0.00254435
	LOSS [training: 2.0534421742542803 | validation: 2.5263562413213005]
	TIME [epoch: 9.78 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 9/9] avg loss: 3.7636188175018983		[learning rate: 0.0025342]
	Learning Rate: 0.00253423
	LOSS [training: 3.7636188175018983 | validation: 3.093003652928794]
	TIME [epoch: 9.78 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 9/9] avg loss: 4.603707084190443		[learning rate: 0.0025242]
	Learning Rate: 0.00252415
	LOSS [training: 4.603707084190443 | validation: 5.1439827285757005]
	TIME [epoch: 9.77 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 9/9] avg loss: 6.050008075946987		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 6.050008075946987 | validation: 4.883256066551074]
	TIME [epoch: 9.77 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 9/9] avg loss: 5.435329540564687		[learning rate: 0.0025041]
	Learning Rate: 0.00250411
	LOSS [training: 5.435329540564687 | validation: 4.8287785270456665]
	TIME [epoch: 9.79 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 9/9] avg loss: 5.884404537504174		[learning rate: 0.0024942]
	Learning Rate: 0.00249415
	LOSS [training: 5.884404537504174 | validation: 4.903623020799967]
	TIME [epoch: 9.77 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 9/9] avg loss: 5.225102275876357		[learning rate: 0.0024842]
	Learning Rate: 0.00248423
	LOSS [training: 5.225102275876357 | validation: 3.3748621531873924]
	TIME [epoch: 9.77 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 9/9] avg loss: 2.602859082232193		[learning rate: 0.0024744]
	Learning Rate: 0.00247435
	LOSS [training: 2.602859082232193 | validation: 1.6518200020695435]
	TIME [epoch: 9.77 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 9/9] avg loss: 2.0657860455077546		[learning rate: 0.0024645]
	Learning Rate: 0.00246451
	LOSS [training: 2.0657860455077546 | validation: 1.7884544027986777]
	TIME [epoch: 9.79 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 9/9] avg loss: 2.3451890927641332		[learning rate: 0.0024547]
	Learning Rate: 0.00245471
	LOSS [training: 2.3451890927641332 | validation: 2.3283758394136065]
	TIME [epoch: 9.78 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 9/9] avg loss: 3.562774802084199		[learning rate: 0.0024449]
	Learning Rate: 0.00244495
	LOSS [training: 3.562774802084199 | validation: 3.84437993653921]
	TIME [epoch: 9.78 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 9/9] avg loss: 4.504503903856757		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 4.504503903856757 | validation: 3.7035901902148276]
	TIME [epoch: 9.78 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 9/9] avg loss: 4.626936213206282		[learning rate: 0.0024255]
	Learning Rate: 0.00242554
	LOSS [training: 4.626936213206282 | validation: 4.919864136387269]
	TIME [epoch: 9.78 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 9/9] avg loss: 5.9544338762152025		[learning rate: 0.0024159]
	Learning Rate: 0.00241589
	LOSS [training: 5.9544338762152025 | validation: 5.095515887268638]
	TIME [epoch: 9.78 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 9/9] avg loss: 4.589580495336701		[learning rate: 0.0024063]
	Learning Rate: 0.00240628
	LOSS [training: 4.589580495336701 | validation: 2.676940432393893]
	TIME [epoch: 9.78 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 9/9] avg loss: 2.7300140397796926		[learning rate: 0.0023967]
	Learning Rate: 0.00239671
	LOSS [training: 2.7300140397796926 | validation: 2.0772838180283792]
	TIME [epoch: 9.79 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 9/9] avg loss: 2.344770210329329		[learning rate: 0.0023872]
	Learning Rate: 0.00238718
	LOSS [training: 2.344770210329329 | validation: 1.8425506417977175]
	TIME [epoch: 9.77 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 9/9] avg loss: 2.037940588471606		[learning rate: 0.0023777]
	Learning Rate: 0.00237768
	LOSS [training: 2.037940588471606 | validation: 1.7986960682315352]
	TIME [epoch: 9.77 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 9/9] avg loss: 2.170236244487097		[learning rate: 0.0023682]
	Learning Rate: 0.00236823
	LOSS [training: 2.170236244487097 | validation: 2.0027728444079163]
	TIME [epoch: 9.78 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 9/9] avg loss: 2.502637496399437		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 2.502637496399437 | validation: 2.501651362705632]
	TIME [epoch: 9.79 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 9/9] avg loss: 2.909236575978124		[learning rate: 0.0023494]
	Learning Rate: 0.00234942
	LOSS [training: 2.909236575978124 | validation: 2.0466038357436522]
	TIME [epoch: 9.77 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 9/9] avg loss: 2.524144457368282		[learning rate: 0.0023401]
	Learning Rate: 0.00234008
	LOSS [training: 2.524144457368282 | validation: 2.2167267680471667]
	TIME [epoch: 9.77 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 9/9] avg loss: 2.9671771685104997		[learning rate: 0.0023308]
	Learning Rate: 0.00233077
	LOSS [training: 2.9671771685104997 | validation: 2.552376703323051]
	TIME [epoch: 9.79 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 9/9] avg loss: 2.636853821710014		[learning rate: 0.0023215]
	Learning Rate: 0.0023215
	LOSS [training: 2.636853821710014 | validation: 2.264039775694784]
	TIME [epoch: 9.78 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 9/9] avg loss: 2.984880038628094		[learning rate: 0.0023123]
	Learning Rate: 0.00231227
	LOSS [training: 2.984880038628094 | validation: 2.5612735510612454]
	TIME [epoch: 9.77 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 9/9] avg loss: 3.2211159604604696		[learning rate: 0.0023031]
	Learning Rate: 0.00230307
	LOSS [training: 3.2211159604604696 | validation: 2.4498761564566296]
	TIME [epoch: 9.77 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 9/9] avg loss: 3.5740870432695635		[learning rate: 0.0022939]
	Learning Rate: 0.00229391
	LOSS [training: 3.5740870432695635 | validation: 3.262510894378311]
	TIME [epoch: 9.79 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 9/9] avg loss: 3.864426778858149		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 3.864426778858149 | validation: 2.4649746925619604]
	TIME [epoch: 9.77 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 9/9] avg loss: 4.25641836577713		[learning rate: 0.0022757]
	Learning Rate: 0.0022757
	LOSS [training: 4.25641836577713 | validation: 4.140301987834169]
	TIME [epoch: 9.78 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 9/9] avg loss: 5.356157275980674		[learning rate: 0.0022667]
	Learning Rate: 0.00226665
	LOSS [training: 5.356157275980674 | validation: 4.997457972009423]
	TIME [epoch: 9.78 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 9/9] avg loss: 5.745514091921195		[learning rate: 0.0022576]
	Learning Rate: 0.00225764
	LOSS [training: 5.745514091921195 | validation: 4.976833052985554]
	TIME [epoch: 9.79 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 9/9] avg loss: 5.666619587442121		[learning rate: 0.0022487]
	Learning Rate: 0.00224866
	LOSS [training: 5.666619587442121 | validation: 4.808818643177469]
	TIME [epoch: 9.77 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 9/9] avg loss: 5.314690990464774		[learning rate: 0.0022397]
	Learning Rate: 0.00223971
	LOSS [training: 5.314690990464774 | validation: 4.317651944585987]
	TIME [epoch: 9.77 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 9/9] avg loss: 4.643117584460969		[learning rate: 0.0022308]
	Learning Rate: 0.0022308
	LOSS [training: 4.643117584460969 | validation: 3.4093143390500438]
	TIME [epoch: 9.79 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 9/9] avg loss: 4.764614354619081		[learning rate: 0.0022219]
	Learning Rate: 0.00222193
	LOSS [training: 4.764614354619081 | validation: 4.382089684048951]
	TIME [epoch: 9.78 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 9/9] avg loss: 5.630891759978491		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 5.630891759978491 | validation: 5.728751000228282]
	TIME [epoch: 9.78 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 9/9] avg loss: 6.586203226810671		[learning rate: 0.0022043]
	Learning Rate: 0.00220429
	LOSS [training: 6.586203226810671 | validation: 6.011320013780972]
	TIME [epoch: 9.77 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 9/9] avg loss: 6.290309814134324		[learning rate: 0.0021955]
	Learning Rate: 0.00219553
	LOSS [training: 6.290309814134324 | validation: 5.31684996227413]
	TIME [epoch: 9.79 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 9/9] avg loss: 5.729353688255852		[learning rate: 0.0021868]
	Learning Rate: 0.00218679
	LOSS [training: 5.729353688255852 | validation: 4.932449832519626]
	TIME [epoch: 9.78 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 9/9] avg loss: 5.765774912248703		[learning rate: 0.0021781]
	Learning Rate: 0.0021781
	LOSS [training: 5.765774912248703 | validation: 5.009815413854699]
	TIME [epoch: 9.77 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 9/9] avg loss: 4.939888735857078		[learning rate: 0.0021694]
	Learning Rate: 0.00216943
	LOSS [training: 4.939888735857078 | validation: 3.5551703218527515]
	TIME [epoch: 9.78 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 9/9] avg loss: 4.1306157876731975		[learning rate: 0.0021608]
	Learning Rate: 0.0021608
	LOSS [training: 4.1306157876731975 | validation: 2.208632180376653]
	TIME [epoch: 9.78 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 9/9] avg loss: 2.0671019892937195		[learning rate: 0.0021522]
	Learning Rate: 0.00215221
	LOSS [training: 2.0671019892937195 | validation: 1.1633096424554439]
	TIME [epoch: 9.77 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.4457109729239823		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 1.4457109729239823 | validation: 1.0091225347276365]
	TIME [epoch: 9.78 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.1350570483083233		[learning rate: 0.0021351]
	Learning Rate: 0.00213512
	LOSS [training: 1.1350570483083233 | validation: 0.7194802983920591]
	TIME [epoch: 9.79 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.8543537113522433		[learning rate: 0.0021266]
	Learning Rate: 0.00212663
	LOSS [training: 0.8543537113522433 | validation: 0.5789302189202828]
	TIME [epoch: 9.78 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7271053174605709		[learning rate: 0.0021182]
	Learning Rate: 0.00211817
	LOSS [training: 0.7271053174605709 | validation: 0.512771277601611]
	TIME [epoch: 9.78 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6684137133726514		[learning rate: 0.0021097]
	Learning Rate: 0.00210975
	LOSS [training: 0.6684137133726514 | validation: 0.48803445548058183]
	TIME [epoch: 9.78 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6625053165255619		[learning rate: 0.0021014]
	Learning Rate: 0.00210136
	LOSS [training: 0.6625053165255619 | validation: 0.4725438220949387]
	TIME [epoch: 9.79 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6470547059112348		[learning rate: 0.002093]
	Learning Rate: 0.002093
	LOSS [training: 0.6470547059112348 | validation: 0.4432902491747558]
	TIME [epoch: 9.78 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6088169979958229		[learning rate: 0.0020847]
	Learning Rate: 0.00208468
	LOSS [training: 0.6088169979958229 | validation: 0.4226108210836843]
	TIME [epoch: 9.78 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5683542441347181		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.5683542441347181 | validation: 0.40349531402328986]
	TIME [epoch: 9.79 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5894156915311489		[learning rate: 0.0020681]
	Learning Rate: 0.00206813
	LOSS [training: 0.5894156915311489 | validation: 0.4223988406736822]
	TIME [epoch: 9.78 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5471612763500074		[learning rate: 0.0020599]
	Learning Rate: 0.0020599
	LOSS [training: 0.5471612763500074 | validation: 0.39456017674124777]
	TIME [epoch: 9.77 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5340037197716708		[learning rate: 0.0020517]
	Learning Rate: 0.00205171
	LOSS [training: 0.5340037197716708 | validation: 0.39462885617859966]
	TIME [epoch: 9.77 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5107444051898082		[learning rate: 0.0020435]
	Learning Rate: 0.00204355
	LOSS [training: 0.5107444051898082 | validation: 0.3846709821921379]
	TIME [epoch: 9.8 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5244086125106038		[learning rate: 0.0020354]
	Learning Rate: 0.00203542
	LOSS [training: 0.5244086125106038 | validation: 0.3798121340680825]
	TIME [epoch: 9.77 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.49025663159347993		[learning rate: 0.0020273]
	Learning Rate: 0.00202732
	LOSS [training: 0.49025663159347993 | validation: 0.3668574327614178]
	TIME [epoch: 9.77 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.513214705707336		[learning rate: 0.0020193]
	Learning Rate: 0.00201926
	LOSS [training: 0.513214705707336 | validation: 0.703789133229258]
	TIME [epoch: 9.78 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.589986140787473		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 0.589986140787473 | validation: 0.44954519243531266]
	TIME [epoch: 9.79 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6358073010222981		[learning rate: 0.0020032]
	Learning Rate: 0.00200323
	LOSS [training: 0.6358073010222981 | validation: 0.5331391695169999]
	TIME [epoch: 9.77 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.59704439191245		[learning rate: 0.0019953]
	Learning Rate: 0.00199526
	LOSS [training: 0.59704439191245 | validation: 0.46085807529594963]
	TIME [epoch: 9.78 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7833759259459667		[learning rate: 0.0019873]
	Learning Rate: 0.00198733
	LOSS [training: 0.7833759259459667 | validation: 0.6370884053605682]
	TIME [epoch: 9.79 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.608420411718668		[learning rate: 0.0019794]
	Learning Rate: 0.00197942
	LOSS [training: 0.608420411718668 | validation: 0.45004101709096006]
	TIME [epoch: 9.78 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5859760280200634		[learning rate: 0.0019715]
	Learning Rate: 0.00197155
	LOSS [training: 0.5859760280200634 | validation: 0.41399363685384544]
	TIME [epoch: 9.77 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5669522954157332		[learning rate: 0.0019637]
	Learning Rate: 0.00196371
	LOSS [training: 0.5669522954157332 | validation: 0.41388970410697856]
	TIME [epoch: 9.78 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5350484019686426		[learning rate: 0.0019559]
	Learning Rate: 0.0019559
	LOSS [training: 0.5350484019686426 | validation: 0.41823245892069905]
	TIME [epoch: 9.79 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5317723555565436		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 0.5317723555565436 | validation: 0.3815839822746871]
	TIME [epoch: 9.78 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.48731469329234056		[learning rate: 0.0019404]
	Learning Rate: 0.00194037
	LOSS [training: 0.48731469329234056 | validation: 0.37110654514651087]
	TIME [epoch: 9.77 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.48352195116368724		[learning rate: 0.0019327]
	Learning Rate: 0.00193265
	LOSS [training: 0.48352195116368724 | validation: 0.37188620859687027]
	TIME [epoch: 9.78 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4715580274137664		[learning rate: 0.001925]
	Learning Rate: 0.00192497
	LOSS [training: 0.4715580274137664 | validation: 0.3647434607158658]
	TIME [epoch: 9.78 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.47991220466362655		[learning rate: 0.0019173]
	Learning Rate: 0.00191731
	LOSS [training: 0.47991220466362655 | validation: 0.3645266879119389]
	TIME [epoch: 9.77 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4614228760147073		[learning rate: 0.0019097]
	Learning Rate: 0.00190968
	LOSS [training: 0.4614228760147073 | validation: 0.3539549062693971]
	TIME [epoch: 9.77 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.46306772168316446		[learning rate: 0.0019021]
	Learning Rate: 0.00190209
	LOSS [training: 0.46306772168316446 | validation: 0.37734589709298866]
	TIME [epoch: 9.79 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4497420543018627		[learning rate: 0.0018945]
	Learning Rate: 0.00189452
	LOSS [training: 0.4497420543018627 | validation: 0.35128365328852035]
	TIME [epoch: 9.78 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.45463893466363786		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.45463893466363786 | validation: 0.41868885834572306]
	TIME [epoch: 9.78 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5230633225375594		[learning rate: 0.0018795]
	Learning Rate: 0.00187948
	LOSS [training: 0.5230633225375594 | validation: 0.43890306013577146]
	TIME [epoch: 9.77 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4775737778220183		[learning rate: 0.001872]
	Learning Rate: 0.00187201
	LOSS [training: 0.4775737778220183 | validation: 0.4152217087265999]
	TIME [epoch: 9.79 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.471077598159373		[learning rate: 0.0018646]
	Learning Rate: 0.00186456
	LOSS [training: 0.471077598159373 | validation: 0.40108851076925295]
	TIME [epoch: 9.78 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.44239616186267494		[learning rate: 0.0018571]
	Learning Rate: 0.00185715
	LOSS [training: 0.44239616186267494 | validation: 0.3719894521972416]
	TIME [epoch: 9.77 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4414553189288977		[learning rate: 0.0018498]
	Learning Rate: 0.00184976
	LOSS [training: 0.4414553189288977 | validation: 0.37480077598647943]
	TIME [epoch: 9.78 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4306327520505433		[learning rate: 0.0018424]
	Learning Rate: 0.0018424
	LOSS [training: 0.4306327520505433 | validation: 0.36131629978602914]
	TIME [epoch: 9.78 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.37402077818368923		[learning rate: 0.0018351]
	Learning Rate: 0.00183508
	LOSS [training: 0.37402077818368923 | validation: 0.3307371882600925]
	TIME [epoch: 9.77 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.34914348856242594		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.34914348856242594 | validation: 0.34128359341641923]
	TIME [epoch: 9.78 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3545395272832944		[learning rate: 0.0018205]
	Learning Rate: 0.00182051
	LOSS [training: 0.3545395272832944 | validation: 0.3312299106877111]
	TIME [epoch: 9.79 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.346772227831748		[learning rate: 0.0018133]
	Learning Rate: 0.00181327
	LOSS [training: 0.346772227831748 | validation: 0.3253253022771473]
	TIME [epoch: 9.78 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3406077374071647		[learning rate: 0.0018061]
	Learning Rate: 0.00180605
	LOSS [training: 0.3406077374071647 | validation: 0.3386144866100994]
	TIME [epoch: 9.78 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.34496005973230415		[learning rate: 0.0017989]
	Learning Rate: 0.00179887
	LOSS [training: 0.34496005973230415 | validation: 0.32928928879736225]
	TIME [epoch: 9.78 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3351575502649074		[learning rate: 0.0017917]
	Learning Rate: 0.00179172
	LOSS [training: 0.3351575502649074 | validation: 0.31393369764610923]
	TIME [epoch: 9.79 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.33386185551862874		[learning rate: 0.0017846]
	Learning Rate: 0.00178459
	LOSS [training: 0.33386185551862874 | validation: 0.31730402940462865]
	TIME [epoch: 9.78 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32479857959474523		[learning rate: 0.0017775]
	Learning Rate: 0.00177749
	LOSS [training: 0.32479857959474523 | validation: 0.3137392920522113]
	TIME [epoch: 9.77 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.36586635231033804		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.36586635231033804 | validation: 0.3193667432540728]
	TIME [epoch: 9.79 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.33273251929187814		[learning rate: 0.0017634]
	Learning Rate: 0.00176338
	LOSS [training: 0.33273251929187814 | validation: 0.30548237292059655]
	TIME [epoch: 9.78 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3284759653092117		[learning rate: 0.0017564]
	Learning Rate: 0.00175637
	LOSS [training: 0.3284759653092117 | validation: 0.32041303851439434]
	TIME [epoch: 9.77 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.34629727524984016		[learning rate: 0.0017494]
	Learning Rate: 0.00174938
	LOSS [training: 0.34629727524984016 | validation: 0.317308287497839]
	TIME [epoch: 9.77 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3231097145527666		[learning rate: 0.0017424]
	Learning Rate: 0.00174242
	LOSS [training: 0.3231097145527666 | validation: 0.3096538809394688]
	TIME [epoch: 9.8 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32368679528107025		[learning rate: 0.0017355]
	Learning Rate: 0.00173549
	LOSS [training: 0.32368679528107025 | validation: 0.3228430237140977]
	TIME [epoch: 9.78 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32629984688165986		[learning rate: 0.0017286]
	Learning Rate: 0.00172859
	LOSS [training: 0.32629984688165986 | validation: 0.30376903003026834]
	TIME [epoch: 9.78 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3246010107238955		[learning rate: 0.0017217]
	Learning Rate: 0.00172172
	LOSS [training: 0.3246010107238955 | validation: 0.3198798639659673]
	TIME [epoch: 9.78 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3285084747892533		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 0.3285084747892533 | validation: 0.314887330279064]
	TIME [epoch: 9.79 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32578487185156124		[learning rate: 0.001708]
	Learning Rate: 0.00170805
	LOSS [training: 0.32578487185156124 | validation: 0.30048303004915666]
	TIME [epoch: 9.77 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3205248967026934		[learning rate: 0.0017013]
	Learning Rate: 0.00170125
	LOSS [training: 0.3205248967026934 | validation: 0.3095633378171823]
	TIME [epoch: 9.77 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3249048206531906		[learning rate: 0.0016945]
	Learning Rate: 0.00169449
	LOSS [training: 0.3249048206531906 | validation: 0.30423042199771944]
	TIME [epoch: 9.78 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.31700396920038537		[learning rate: 0.0016877]
	Learning Rate: 0.00168775
	LOSS [training: 0.31700396920038537 | validation: 0.2964681870141782]
	TIME [epoch: 9.78 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3140222809236085		[learning rate: 0.001681]
	Learning Rate: 0.00168104
	LOSS [training: 0.3140222809236085 | validation: 0.3047636470775267]
	TIME [epoch: 9.77 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.31498758614022315		[learning rate: 0.0016743]
	Learning Rate: 0.00167435
	LOSS [training: 0.31498758614022315 | validation: 0.30872799452338995]
	TIME [epoch: 9.77 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.31391574774841646		[learning rate: 0.0016677]
	Learning Rate: 0.00166769
	LOSS [training: 0.31391574774841646 | validation: 0.31228649814464665]
	TIME [epoch: 9.79 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3254649260931194		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.3254649260931194 | validation: 0.29958692945523924]
	TIME [epoch: 9.78 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3155035798561043		[learning rate: 0.0016545]
	Learning Rate: 0.00165445
	LOSS [training: 0.3155035798561043 | validation: 0.298110222200043]
	TIME [epoch: 9.77 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32441972594097246		[learning rate: 0.0016479]
	Learning Rate: 0.00164787
	LOSS [training: 0.32441972594097246 | validation: 0.30369474185847833]
	TIME [epoch: 9.78 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.31376893341302076		[learning rate: 0.0016413]
	Learning Rate: 0.00164132
	LOSS [training: 0.31376893341302076 | validation: 0.29990182878820393]
	TIME [epoch: 9.78 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3055021952638906		[learning rate: 0.0016348]
	Learning Rate: 0.00163479
	LOSS [training: 0.3055021952638906 | validation: 0.30028530997724034]
	TIME [epoch: 9.77 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3118294353118114		[learning rate: 0.0016283]
	Learning Rate: 0.00162829
	LOSS [training: 0.3118294353118114 | validation: 0.29653836605500455]
	TIME [epoch: 9.77 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.30040891575302		[learning rate: 0.0016218]
	Learning Rate: 0.00162181
	LOSS [training: 0.30040891575302 | validation: 0.2961325384800353]
	TIME [epoch: 44.1 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3152585998221603		[learning rate: 0.0016154]
	Learning Rate: 0.00161536
	LOSS [training: 0.3152585998221603 | validation: 0.3001724344381914]
	TIME [epoch: 18.9 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3110610046125587		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 0.3110610046125587 | validation: 0.29889955350077624]
	TIME [epoch: 18.9 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3102532571431136		[learning rate: 0.0016025]
	Learning Rate: 0.00160254
	LOSS [training: 0.3102532571431136 | validation: 0.29197679367014034]
	TIME [epoch: 18.9 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3055143698777876		[learning rate: 0.0015962]
	Learning Rate: 0.00159616
	LOSS [training: 0.3055143698777876 | validation: 0.2883827724514171]
	TIME [epoch: 18.9 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2993346311832854		[learning rate: 0.0015898]
	Learning Rate: 0.00158981
	LOSS [training: 0.2993346311832854 | validation: 0.28486007347173203]
	TIME [epoch: 18.9 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3044124326512591		[learning rate: 0.0015835]
	Learning Rate: 0.00158349
	LOSS [training: 0.3044124326512591 | validation: 0.2951493565233994]
	TIME [epoch: 18.9 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.30926822775957497		[learning rate: 0.0015772]
	Learning Rate: 0.00157719
	LOSS [training: 0.30926822775957497 | validation: 0.30532556727449306]
	TIME [epoch: 18.9 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.29710948593567543		[learning rate: 0.0015709]
	Learning Rate: 0.00157092
	LOSS [training: 0.29710948593567543 | validation: 0.27807664476630706]
	TIME [epoch: 18.9 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.30784272774028726		[learning rate: 0.0015647]
	Learning Rate: 0.00156467
	LOSS [training: 0.30784272774028726 | validation: 0.3235404562668923]
	TIME [epoch: 18.9 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32476168131437355		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.32476168131437355 | validation: 0.289996856359395]
	TIME [epoch: 18.9 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.303051320204589		[learning rate: 0.0015522]
	Learning Rate: 0.00155225
	LOSS [training: 0.303051320204589 | validation: 0.29010670711024683]
	TIME [epoch: 18.9 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3054385081123285		[learning rate: 0.0015461]
	Learning Rate: 0.00154608
	LOSS [training: 0.3054385081123285 | validation: 0.2960580793215406]
	TIME [epoch: 18.9 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.29625020281976316		[learning rate: 0.0015399]
	Learning Rate: 0.00153993
	LOSS [training: 0.29625020281976316 | validation: 0.28494287324752576]
	TIME [epoch: 18.9 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3128998732365059		[learning rate: 0.0015338]
	Learning Rate: 0.0015338
	LOSS [training: 0.3128998732365059 | validation: 0.27978044349860526]
	TIME [epoch: 18.9 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2955803444596532		[learning rate: 0.0015277]
	Learning Rate: 0.0015277
	LOSS [training: 0.2955803444596532 | validation: 0.2845915301797634]
	TIME [epoch: 18.9 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.28888483562585		[learning rate: 0.0015216]
	Learning Rate: 0.00152163
	LOSS [training: 0.28888483562585 | validation: 0.27997647539367876]
	TIME [epoch: 18.9 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2910095573009523		[learning rate: 0.0015156]
	Learning Rate: 0.00151557
	LOSS [training: 0.2910095573009523 | validation: 0.28640791888092887]
	TIME [epoch: 18.9 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.29121175091361995		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.29121175091361995 | validation: 0.2761851459035036]
	TIME [epoch: 18.9 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2903965816402214		[learning rate: 0.0015035]
	Learning Rate: 0.00150354
	LOSS [training: 0.2903965816402214 | validation: 0.26835716997938874]
	TIME [epoch: 18.9 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.28017093162584567		[learning rate: 0.0014976]
	Learning Rate: 0.00149756
	LOSS [training: 0.28017093162584567 | validation: 0.27783892672464433]
	TIME [epoch: 18.9 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2868077580098065		[learning rate: 0.0014916]
	Learning Rate: 0.00149161
	LOSS [training: 0.2868077580098065 | validation: 0.2761339852885658]
	TIME [epoch: 18.9 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2800029395507345		[learning rate: 0.0014857]
	Learning Rate: 0.00148567
	LOSS [training: 0.2800029395507345 | validation: 0.27705528048603123]
	TIME [epoch: 18.9 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.28985031433263314		[learning rate: 0.0014798]
	Learning Rate: 0.00147976
	LOSS [training: 0.28985031433263314 | validation: 0.27409252256192795]
	TIME [epoch: 18.9 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.30096635916809406		[learning rate: 0.0014739]
	Learning Rate: 0.00147388
	LOSS [training: 0.30096635916809406 | validation: 0.2669082704462699]
	TIME [epoch: 18.9 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2906756070554429		[learning rate: 0.001468]
	Learning Rate: 0.00146802
	LOSS [training: 0.2906756070554429 | validation: 0.27901999118332776]
	TIME [epoch: 18.9 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2857023877217602		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.2857023877217602 | validation: 0.2738503754799704]
	TIME [epoch: 18.9 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2768512231055685		[learning rate: 0.0014564]
	Learning Rate: 0.00145636
	LOSS [training: 0.2768512231055685 | validation: 0.30038317379849244]
	TIME [epoch: 18.9 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2859312492432257		[learning rate: 0.0014506]
	Learning Rate: 0.00145057
	LOSS [training: 0.2859312492432257 | validation: 0.27090417436309017]
	TIME [epoch: 18.9 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2809588029080358		[learning rate: 0.0014448]
	Learning Rate: 0.0014448
	LOSS [training: 0.2809588029080358 | validation: 0.3734339218664061]
	TIME [epoch: 18.9 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.304055036049969		[learning rate: 0.0014391]
	Learning Rate: 0.00143905
	LOSS [training: 0.304055036049969 | validation: 0.27365007863300955]
	TIME [epoch: 18.9 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2840608975990632		[learning rate: 0.0014333]
	Learning Rate: 0.00143333
	LOSS [training: 0.2840608975990632 | validation: 0.27500290418774276]
	TIME [epoch: 18.9 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2811939418300592		[learning rate: 0.0014276]
	Learning Rate: 0.00142763
	LOSS [training: 0.2811939418300592 | validation: 0.2727077171239706]
	TIME [epoch: 18.9 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.28297054311612885		[learning rate: 0.001422]
	Learning Rate: 0.00142195
	LOSS [training: 0.28297054311612885 | validation: 0.2766683047156643]
	TIME [epoch: 18.9 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.27361889639618436		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.27361889639618436 | validation: 0.26378459595030124]
	TIME [epoch: 18.9 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v11_20240711_165139/states/model_facs_v2_dec1b_2dpca_v11_535.pth
Halted early. No improvement in validation loss for 200 epochs.
Finished training in 5657.540 seconds.
