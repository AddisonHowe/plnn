Args:
Namespace(name='model_facs_dec2a_2d_v1', outdir='out/model_training/model_facs_dec2a_2d_v1', training_data='data/training_data/facs/dec2/transition2_subset_ce_pn_m_pc12/training', validation_data='data/training_data/facs/dec2/transition2_subset_ce_pn_m_pc12/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=5, patience=200, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, dt=0.001, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 1132906947

Training model...

Saving initial model state to: out/model_training/model_facs_dec2a_2d_v1_20240622_095511/states/model_facs_dec2a_2d_v1_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6063602600869132		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6063602600869132 | validation: 0.4160863557047884]
	TIME [epoch: 45 sec]
	Saving model to: out/model_training/model_facs_dec2a_2d_v1_20240622_095511/states/model_facs_dec2a_2d_v1_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3422122980430586		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3422122980430586 | validation: 0.3713332139424339]
	TIME [epoch: 20.9 sec]
	Saving model to: out/model_training/model_facs_dec2a_2d_v1_20240622_095511/states/model_facs_dec2a_2d_v1_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30669153273287353		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.30669153273287353 | validation: 0.36509267537739026]
	TIME [epoch: 20.9 sec]
	Saving model to: out/model_training/model_facs_dec2a_2d_v1_20240622_095511/states/model_facs_dec2a_2d_v1_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26598810157185176		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.26598810157185176 | validation: 0.36836236387859544]
	TIME [epoch: 20.8 sec]
EPOCH 5/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2803423945410336		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2803423945410336 | validation: 0.35392950090574005]
	TIME [epoch: 20.9 sec]
	Saving model to: out/model_training/model_facs_dec2a_2d_v1_20240622_095511/states/model_facs_dec2a_2d_v1_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2660096991610785		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2660096991610785 | validation: 0.340989285261543]
	TIME [epoch: 20.8 sec]
	Saving model to: out/model_training/model_facs_dec2a_2d_v1_20240622_095511/states/model_facs_dec2a_2d_v1_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25254695568113295		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.25254695568113295 | validation: 0.31317195791329705]
	TIME [epoch: 20.8 sec]
	Saving model to: out/model_training/model_facs_dec2a_2d_v1_20240622_095511/states/model_facs_dec2a_2d_v1_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24185197098894165		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24185197098894165 | validation: 0.3396250970131355]
	TIME [epoch: 20.9 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2922759330470329		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2922759330470329 | validation: 0.316089016757089]
	TIME [epoch: 21 sec]
EPOCH 10/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24274355430555547		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24274355430555547 | validation: 0.33213083318400066]
	TIME [epoch: 21 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2387748498100672		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2387748498100672 | validation: 0.33640740519239004]
	TIME [epoch: 21 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2501167448196345		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2501167448196345 | validation: 0.31986578354115514]
	TIME [epoch: 21.1 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23423202149226202		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23423202149226202 | validation: 0.2989363398103452]
	TIME [epoch: 21 sec]
	Saving model to: out/model_training/model_facs_dec2a_2d_v1_20240622_095511/states/model_facs_dec2a_2d_v1_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2181621426676556		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2181621426676556 | validation: 0.2916465015467983]
	TIME [epoch: 21 sec]
	Saving model to: out/model_training/model_facs_dec2a_2d_v1_20240622_095511/states/model_facs_dec2a_2d_v1_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2153888311676143		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2153888311676143 | validation: 0.29471134360721357]
	TIME [epoch: 21 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.214565923761792		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.214565923761792 | validation: 0.2767380021349725]
	TIME [epoch: 21 sec]
	Saving model to: out/model_training/model_facs_dec2a_2d_v1_20240622_095511/states/model_facs_dec2a_2d_v1_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20820081778116578		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20820081778116578 | validation: 0.2705205916597017]
	TIME [epoch: 20.9 sec]
	Saving model to: out/model_training/model_facs_dec2a_2d_v1_20240622_095511/states/model_facs_dec2a_2d_v1_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2084779498459129		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2084779498459129 | validation: 0.2533953891218649]
	TIME [epoch: 21 sec]
	Saving model to: out/model_training/model_facs_dec2a_2d_v1_20240622_095511/states/model_facs_dec2a_2d_v1_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18309854213150498		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18309854213150498 | validation: 0.27968553740688956]
	TIME [epoch: 21 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1940721337526474		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1940721337526474 | validation: 0.2600513322942479]
	TIME [epoch: 21 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18328232634294128		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18328232634294128 | validation: 0.2728511700523317]
	TIME [epoch: 21 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17811713215490507		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17811713215490507 | validation: 0.24780195195398175]
	TIME [epoch: 21 sec]
	Saving model to: out/model_training/model_facs_dec2a_2d_v1_20240622_095511/states/model_facs_dec2a_2d_v1_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17716548458379516		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17716548458379516 | validation: 0.24519118548565286]
	TIME [epoch: 21 sec]
	Saving model to: out/model_training/model_facs_dec2a_2d_v1_20240622_095511/states/model_facs_dec2a_2d_v1_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1701919046694264		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1701919046694264 | validation: 0.28752612442966347]
	TIME [epoch: 20.9 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2174797265747353		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2174797265747353 | validation: 0.24141609197545716]
	TIME [epoch: 20.9 sec]
	Saving model to: out/model_training/model_facs_dec2a_2d_v1_20240622_095511/states/model_facs_dec2a_2d_v1_25.pth
	Model improved!!!
EPOCH 26/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1582506689142773		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1582506689142773 | validation: 0.23353847990044002]
	TIME [epoch: 21.3 sec]
	Saving model to: out/model_training/model_facs_dec2a_2d_v1_20240622_095511/states/model_facs_dec2a_2d_v1_26.pth
	Model improved!!!
EPOCH 27/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16094398931423984		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16094398931423984 | validation: 0.25102826108149745]
	TIME [epoch: 20.8 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.186367741376879		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.186367741376879 | validation: 0.256238542298767]
	TIME [epoch: 20.8 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1771735374479318		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1771735374479318 | validation: 0.2280507100472531]
	TIME [epoch: 20.8 sec]
	Saving model to: out/model_training/model_facs_dec2a_2d_v1_20240622_095511/states/model_facs_dec2a_2d_v1_29.pth
	Model improved!!!
EPOCH 30/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16739079987619832		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16739079987619832 | validation: 0.2424140365636409]
	TIME [epoch: 20.8 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17490422922655918		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17490422922655918 | validation: 0.24190901839347706]
	TIME [epoch: 20.8 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16245832147987108		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16245832147987108 | validation: 0.2406987697427038]
	TIME [epoch: 20.8 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.157701317576703		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.157701317576703 | validation: 0.21256948216001764]
	TIME [epoch: 20.8 sec]
	Saving model to: out/model_training/model_facs_dec2a_2d_v1_20240622_095511/states/model_facs_dec2a_2d_v1_33.pth
	Model improved!!!
EPOCH 34/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.154806567735222		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.154806567735222 | validation: 0.2346428854981539]
	TIME [epoch: 20.8 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16372864515103988		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16372864515103988 | validation: 0.24928676040576755]
	TIME [epoch: 20.8 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17799643581344476		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17799643581344476 | validation: 0.22083032191506402]
	TIME [epoch: 20.8 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15952792238503777		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15952792238503777 | validation: 0.22585302866388487]
	TIME [epoch: 20.8 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15296753680588565		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15296753680588565 | validation: 0.25215737984840125]
	TIME [epoch: 20.9 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15909223311209608		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15909223311209608 | validation: 0.24189596195996235]
	TIME [epoch: 20.8 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15068805236440092		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15068805236440092 | validation: 0.22888695639580636]
	TIME [epoch: 20.8 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1457410453743374		[learning rate: 0.0099646]
	Learning Rate: 0.00996464
	LOSS [training: 0.1457410453743374 | validation: 0.23854507558614518]
	TIME [epoch: 20.8 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16563370711162412		[learning rate: 0.0099206]
	Learning Rate: 0.00992061
	LOSS [training: 0.16563370711162412 | validation: 0.25139735749639064]
	TIME [epoch: 20.8 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1483106569400497		[learning rate: 0.0098768]
	Learning Rate: 0.00987678
	LOSS [training: 0.1483106569400497 | validation: 0.2713096221666393]
	TIME [epoch: 20.8 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16710887604862065		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 0.16710887604862065 | validation: 0.21456589150680977]
	TIME [epoch: 20.8 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1489818428255385		[learning rate: 0.0097897]
	Learning Rate: 0.0097897
	LOSS [training: 0.1489818428255385 | validation: 0.2132371836161544]
	TIME [epoch: 20.8 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15437510845182198		[learning rate: 0.0097464]
	Learning Rate: 0.00974644
	LOSS [training: 0.15437510845182198 | validation: 0.2223239796979007]
	TIME [epoch: 20.8 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1699834640395719		[learning rate: 0.0097034]
	Learning Rate: 0.00970338
	LOSS [training: 0.1699834640395719 | validation: 0.21099226462474474]
	TIME [epoch: 20.8 sec]
	Saving model to: out/model_training/model_facs_dec2a_2d_v1_20240622_095511/states/model_facs_dec2a_2d_v1_47.pth
	Model improved!!!
EPOCH 48/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1492207066968187		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 0.1492207066968187 | validation: 0.21816743377187814]
	TIME [epoch: 20.8 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15271947174163433		[learning rate: 0.0096178]
	Learning Rate: 0.00961783
	LOSS [training: 0.15271947174163433 | validation: 0.2180456948589476]
	TIME [epoch: 20.8 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13691259073094164		[learning rate: 0.0095753]
	Learning Rate: 0.00957533
	LOSS [training: 0.13691259073094164 | validation: 0.2187302888342552]
	TIME [epoch: 20.8 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13656580030983187		[learning rate: 0.009533]
	Learning Rate: 0.00953303
	LOSS [training: 0.13656580030983187 | validation: 0.25468252944750847]
	TIME [epoch: 20.8 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15033562453091123		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 0.15033562453091123 | validation: 0.19521267915930568]
	TIME [epoch: 20.8 sec]
	Saving model to: out/model_training/model_facs_dec2a_2d_v1_20240622_095511/states/model_facs_dec2a_2d_v1_52.pth
	Model improved!!!
EPOCH 53/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13841496753897298		[learning rate: 0.009449]
	Learning Rate: 0.00944897
	LOSS [training: 0.13841496753897298 | validation: 0.25369760361302723]
	TIME [epoch: 20.8 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13572442965444376		[learning rate: 0.0094072]
	Learning Rate: 0.00940722
	LOSS [training: 0.13572442965444376 | validation: 0.21510445088779923]
	TIME [epoch: 20.8 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16199608830014184		[learning rate: 0.0093657]
	Learning Rate: 0.00936566
	LOSS [training: 0.16199608830014184 | validation: 0.22432309804943995]
	TIME [epoch: 20.8 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13772051063789092		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 0.13772051063789092 | validation: 0.26615697810741135]
	TIME [epoch: 20.8 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13971675209786713		[learning rate: 0.0092831]
	Learning Rate: 0.00928308
	LOSS [training: 0.13971675209786713 | validation: 0.20224432397904152]
	TIME [epoch: 20.8 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13536925264675778		[learning rate: 0.0092421]
	Learning Rate: 0.00924207
	LOSS [training: 0.13536925264675778 | validation: 0.21358322591924395]
	TIME [epoch: 20.8 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12687487129116065		[learning rate: 0.0092012]
	Learning Rate: 0.00920124
	LOSS [training: 0.12687487129116065 | validation: 0.19548359018175837]
	TIME [epoch: 20.8 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1390260003305721		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 0.1390260003305721 | validation: 0.20444571547087964]
	TIME [epoch: 20.8 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1238846362250428		[learning rate: 0.0091201]
	Learning Rate: 0.00912011
	LOSS [training: 0.1238846362250428 | validation: 0.19713250520001846]
	TIME [epoch: 20.8 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13313649437653347		[learning rate: 0.0090798]
	Learning Rate: 0.00907981
	LOSS [training: 0.13313649437653347 | validation: 0.25756894406572484]
	TIME [epoch: 20.8 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10930307335625618		[learning rate: 0.0090397]
	Learning Rate: 0.0090397
	LOSS [training: 0.10930307335625618 | validation: 0.23033071414012768]
	TIME [epoch: 20.8 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16441184436303533		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 0.16441184436303533 | validation: 0.2224991701000832]
	TIME [epoch: 20.8 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14335664860942027		[learning rate: 0.00896]
	Learning Rate: 0.00895999
	LOSS [training: 0.14335664860942027 | validation: 0.1923022104249956]
	TIME [epoch: 20.8 sec]
	Saving model to: out/model_training/model_facs_dec2a_2d_v1_20240622_095511/states/model_facs_dec2a_2d_v1_65.pth
	Model improved!!!
EPOCH 66/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12228683585625093		[learning rate: 0.0089204]
	Learning Rate: 0.00892041
	LOSS [training: 0.12228683585625093 | validation: 0.1944266595474675]
	TIME [epoch: 20.8 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13357488283552016		[learning rate: 0.008881]
	Learning Rate: 0.00888099
	LOSS [training: 0.13357488283552016 | validation: 0.1915798830547848]
	TIME [epoch: 20.8 sec]
	Saving model to: out/model_training/model_facs_dec2a_2d_v1_20240622_095511/states/model_facs_dec2a_2d_v1_67.pth
	Model improved!!!
EPOCH 68/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11816407621383714		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 0.11816407621383714 | validation: 0.2086529584164415]
	TIME [epoch: 20.8 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11023837041400016		[learning rate: 0.0088027]
	Learning Rate: 0.00880269
	LOSS [training: 0.11023837041400016 | validation: 0.21970922172332025]
	TIME [epoch: 20.8 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1363548263334498		[learning rate: 0.0087638]
	Learning Rate: 0.0087638
	LOSS [training: 0.1363548263334498 | validation: 0.1889249543255182]
	TIME [epoch: 20.8 sec]
	Saving model to: out/model_training/model_facs_dec2a_2d_v1_20240622_095511/states/model_facs_dec2a_2d_v1_70.pth
	Model improved!!!
EPOCH 71/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13092580891130026		[learning rate: 0.0087251]
	Learning Rate: 0.00872508
	LOSS [training: 0.13092580891130026 | validation: 0.21749551795748223]
	TIME [epoch: 20.8 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12547725708395033		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 0.12547725708395033 | validation: 0.18062409620049313]
	TIME [epoch: 20.8 sec]
	Saving model to: out/model_training/model_facs_dec2a_2d_v1_20240622_095511/states/model_facs_dec2a_2d_v1_72.pth
	Model improved!!!
EPOCH 73/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11864332189406446		[learning rate: 0.0086481]
	Learning Rate: 0.00864815
	LOSS [training: 0.11864332189406446 | validation: 0.23423830551614028]
	TIME [epoch: 20.8 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13846808495507912		[learning rate: 0.0086099]
	Learning Rate: 0.00860994
	LOSS [training: 0.13846808495507912 | validation: 0.19078229791615106]
	TIME [epoch: 20.9 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12511650969962007		[learning rate: 0.0085719]
	Learning Rate: 0.0085719
	LOSS [training: 0.12511650969962007 | validation: 0.186088702339666]
	TIME [epoch: 21 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1175183680509471		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 0.1175183680509471 | validation: 0.206744452856153]
	TIME [epoch: 21 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10373596568527202		[learning rate: 0.0084963]
	Learning Rate: 0.00849632
	LOSS [training: 0.10373596568527202 | validation: 0.1958813302488333]
	TIME [epoch: 20.9 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14168935958282064		[learning rate: 0.0084588]
	Learning Rate: 0.00845878
	LOSS [training: 0.14168935958282064 | validation: 0.1707200877203614]
	TIME [epoch: 21 sec]
	Saving model to: out/model_training/model_facs_dec2a_2d_v1_20240622_095511/states/model_facs_dec2a_2d_v1_78.pth
	Model improved!!!
EPOCH 79/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11984450821251816		[learning rate: 0.0084214]
	Learning Rate: 0.00842141
	LOSS [training: 0.11984450821251816 | validation: 0.21752086554096628]
	TIME [epoch: 21 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13149211960453372		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 0.13149211960453372 | validation: 0.18177391017386085]
	TIME [epoch: 20.9 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11152276924218527		[learning rate: 0.0083472]
	Learning Rate: 0.00834715
	LOSS [training: 0.11152276924218527 | validation: 0.17839920138345108]
	TIME [epoch: 21 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12174161018434197		[learning rate: 0.0083103]
	Learning Rate: 0.00831027
	LOSS [training: 0.12174161018434197 | validation: 0.17615584421301458]
	TIME [epoch: 21 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1110425654662927		[learning rate: 0.0082736]
	Learning Rate: 0.00827356
	LOSS [training: 0.1110425654662927 | validation: 0.24670226384426233]
	TIME [epoch: 20.9 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11111906195140872		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 0.11111906195140872 | validation: 0.1770399716905893]
	TIME [epoch: 20.9 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13222051496585502		[learning rate: 0.0082006]
	Learning Rate: 0.00820061
	LOSS [training: 0.13222051496585502 | validation: 0.2005807345309825]
	TIME [epoch: 20.9 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1488014617137508		[learning rate: 0.0081644]
	Learning Rate: 0.00816438
	LOSS [training: 0.1488014617137508 | validation: 0.20327261126701482]
	TIME [epoch: 21 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11911503550533084		[learning rate: 0.0081283]
	Learning Rate: 0.0081283
	LOSS [training: 0.11911503550533084 | validation: 0.21142841758060166]
	TIME [epoch: 21 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12512501805194845		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 0.12512501805194845 | validation: 0.21222986168614014]
	TIME [epoch: 21 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1372707354533766		[learning rate: 0.0080566]
	Learning Rate: 0.00805664
	LOSS [training: 0.1372707354533766 | validation: 0.18556784992380057]
	TIME [epoch: 21 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11030164203764045		[learning rate: 0.008021]
	Learning Rate: 0.00802104
	LOSS [training: 0.11030164203764045 | validation: 0.1799053501706877]
	TIME [epoch: 21 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1148743443830003		[learning rate: 0.0079856]
	Learning Rate: 0.0079856
	LOSS [training: 0.1148743443830003 | validation: 0.18778240419821576]
	TIME [epoch: 21.1 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1266343927318548		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 0.1266343927318548 | validation: 0.1960967274986641]
	TIME [epoch: 21 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11677006176075835		[learning rate: 0.0079152]
	Learning Rate: 0.00791519
	LOSS [training: 0.11677006176075835 | validation: 0.24650128940854385]
	TIME [epoch: 21 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12605895711431664		[learning rate: 0.0078802]
	Learning Rate: 0.00788022
	LOSS [training: 0.12605895711431664 | validation: 0.19392825712813166]
	TIME [epoch: 21 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11804314278703357		[learning rate: 0.0078454]
	Learning Rate: 0.00784541
	LOSS [training: 0.11804314278703357 | validation: 0.16000762202643515]
	TIME [epoch: 21 sec]
	Saving model to: out/model_training/model_facs_dec2a_2d_v1_20240622_095511/states/model_facs_dec2a_2d_v1_95.pth
	Model improved!!!
EPOCH 96/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11048677781807878		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 0.11048677781807878 | validation: 0.19106660962719993]
	TIME [epoch: 21 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.121755794982275		[learning rate: 0.0077762]
	Learning Rate: 0.00777623
	LOSS [training: 0.121755794982275 | validation: 0.18258191937660342]
	TIME [epoch: 21 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12327624901404755		[learning rate: 0.0077419]
	Learning Rate: 0.00774188
	LOSS [training: 0.12327624901404755 | validation: 0.20837614672621474]
	TIME [epoch: 21 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11936454819275552		[learning rate: 0.0077077]
	Learning Rate: 0.00770767
	LOSS [training: 0.11936454819275552 | validation: 0.1973469034628052]
	TIME [epoch: 21 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12000337945124447		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 0.12000337945124447 | validation: 0.18219148713508782]
	TIME [epoch: 20.9 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11416413083929625		[learning rate: 0.0076397]
	Learning Rate: 0.00763971
	LOSS [training: 0.11416413083929625 | validation: 0.18926147069963128]
	TIME [epoch: 21 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11890507304830837		[learning rate: 0.007606]
	Learning Rate: 0.00760596
	LOSS [training: 0.11890507304830837 | validation: 0.19834125531116228]
	TIME [epoch: 20.9 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12676706361423545		[learning rate: 0.0075724]
	Learning Rate: 0.00757235
	LOSS [training: 0.12676706361423545 | validation: 0.1827094802501308]
	TIME [epoch: 20.8 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11837068411782689		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 0.11837068411782689 | validation: 0.2847754351276329]
	TIME [epoch: 20.8 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12586772970842747		[learning rate: 0.0075056]
	Learning Rate: 0.00750559
	LOSS [training: 0.12586772970842747 | validation: 0.18601739646773968]
	TIME [epoch: 20.8 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1196418913169883		[learning rate: 0.0074724]
	Learning Rate: 0.00747242
	LOSS [training: 0.1196418913169883 | validation: 0.18215823291587283]
	TIME [epoch: 20.8 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11965654899336206		[learning rate: 0.0074394]
	Learning Rate: 0.00743941
	LOSS [training: 0.11965654899336206 | validation: 0.22301316404780147]
	TIME [epoch: 20.9 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11743491903905098		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 0.11743491903905098 | validation: 0.1751044353046891]
	TIME [epoch: 21 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10805927605500547		[learning rate: 0.0073738]
	Learning Rate: 0.00737382
	LOSS [training: 0.10805927605500547 | validation: 0.27637109531063075]
	TIME [epoch: 21 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10991488288208369		[learning rate: 0.0073412]
	Learning Rate: 0.00734124
	LOSS [training: 0.10991488288208369 | validation: 0.19145201800405823]
	TIME [epoch: 21 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12295064831661033		[learning rate: 0.0073088]
	Learning Rate: 0.0073088
	LOSS [training: 0.12295064831661033 | validation: 0.17366400652221697]
	TIME [epoch: 21 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.117000169945264		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 0.117000169945264 | validation: 0.1673950674820368]
	TIME [epoch: 21 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10224853139351578		[learning rate: 0.0072444]
	Learning Rate: 0.00724436
	LOSS [training: 0.10224853139351578 | validation: 0.18038358541843372]
	TIME [epoch: 21 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09928232794932859		[learning rate: 0.0072124]
	Learning Rate: 0.00721235
	LOSS [training: 0.09928232794932859 | validation: 0.19774528784751622]
	TIME [epoch: 21 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10704118351188581		[learning rate: 0.0071805]
	Learning Rate: 0.00718049
	LOSS [training: 0.10704118351188581 | validation: 0.19743024141402243]
	TIME [epoch: 21 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11702195441115204		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 0.11702195441115204 | validation: 0.18919245289988645]
	TIME [epoch: 21 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12453831850328201		[learning rate: 0.0071172]
	Learning Rate: 0.00711718
	LOSS [training: 0.12453831850328201 | validation: 0.2071925247713176]
	TIME [epoch: 21 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11423239094589946		[learning rate: 0.0070857]
	Learning Rate: 0.00708573
	LOSS [training: 0.11423239094589946 | validation: 0.1776655426261358]
	TIME [epoch: 21 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10932593288958807		[learning rate: 0.0070544]
	Learning Rate: 0.00705442
	LOSS [training: 0.10932593288958807 | validation: 0.22930913379862078]
	TIME [epoch: 21 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11264877999400583		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 0.11264877999400583 | validation: 0.16441126670569567]
	TIME [epoch: 21 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11677578791216425		[learning rate: 0.0069922]
	Learning Rate: 0.00699222
	LOSS [training: 0.11677578791216425 | validation: 0.17934863855921637]
	TIME [epoch: 21 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11930405321712412		[learning rate: 0.0069613]
	Learning Rate: 0.00696133
	LOSS [training: 0.11930405321712412 | validation: 0.20484999315610783]
	TIME [epoch: 21 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10208984218161107		[learning rate: 0.0069306]
	Learning Rate: 0.00693057
	LOSS [training: 0.10208984218161107 | validation: 0.18215001825185412]
	TIME [epoch: 21 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10904046253659774		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 0.10904046253659774 | validation: 0.1699962060062984]
	TIME [epoch: 21 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12021049873442764		[learning rate: 0.0068695]
	Learning Rate: 0.00686947
	LOSS [training: 0.12021049873442764 | validation: 0.3273068787836136]
	TIME [epoch: 21 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12043388227864135		[learning rate: 0.0068391]
	Learning Rate: 0.00683912
	LOSS [training: 0.12043388227864135 | validation: 0.1705837206527625]
	TIME [epoch: 20.9 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10524575450750262		[learning rate: 0.0068089]
	Learning Rate: 0.0068089
	LOSS [training: 0.10524575450750262 | validation: 0.2108825817709531]
	TIME [epoch: 20.8 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1198876192117512		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 0.1198876192117512 | validation: 0.19604779703960953]
	TIME [epoch: 20.8 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1066158793623957		[learning rate: 0.0067489]
	Learning Rate: 0.00674887
	LOSS [training: 0.1066158793623957 | validation: 0.17076799849010732]
	TIME [epoch: 20.8 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10842441857176359		[learning rate: 0.006719]
	Learning Rate: 0.00671905
	LOSS [training: 0.10842441857176359 | validation: 0.1553291010831118]
	TIME [epoch: 20.8 sec]
	Saving model to: out/model_training/model_facs_dec2a_2d_v1_20240622_095511/states/model_facs_dec2a_2d_v1_130.pth
	Model improved!!!
EPOCH 131/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10742820487795243		[learning rate: 0.0066894]
	Learning Rate: 0.00668936
	LOSS [training: 0.10742820487795243 | validation: 0.18130376557816882]
	TIME [epoch: 20.8 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10068749277980979		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 0.10068749277980979 | validation: 0.18231483046189656]
	TIME [epoch: 20.9 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11695421163244872		[learning rate: 0.0066304]
	Learning Rate: 0.00663038
	LOSS [training: 0.11695421163244872 | validation: 0.16909703129255652]
	TIME [epoch: 21 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10435214977661378		[learning rate: 0.0066011]
	Learning Rate: 0.00660109
	LOSS [training: 0.10435214977661378 | validation: 0.19331432170199014]
	TIME [epoch: 21 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11690475476584376		[learning rate: 0.0065719]
	Learning Rate: 0.00657192
	LOSS [training: 0.11690475476584376 | validation: 0.1670432959348935]
	TIME [epoch: 21 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10782748862933053		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 0.10782748862933053 | validation: 0.20938236932579002]
	TIME [epoch: 21 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10796152785392106		[learning rate: 0.006514]
	Learning Rate: 0.00651398
	LOSS [training: 0.10796152785392106 | validation: 0.1906034224178619]
	TIME [epoch: 21 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11450358516062283		[learning rate: 0.0064852]
	Learning Rate: 0.00648519
	LOSS [training: 0.11450358516062283 | validation: 0.17897774731292804]
	TIME [epoch: 21 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10222453789167804		[learning rate: 0.0064565]
	Learning Rate: 0.00645654
	LOSS [training: 0.10222453789167804 | validation: 0.20272587203796882]
	TIME [epoch: 21 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09945470442261414		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 0.09945470442261414 | validation: 0.18328136181084342]
	TIME [epoch: 20.9 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11794244251642098		[learning rate: 0.0063996]
	Learning Rate: 0.00639961
	LOSS [training: 0.11794244251642098 | validation: 0.25921759091489505]
	TIME [epoch: 21 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13005118958500533		[learning rate: 0.0063713]
	Learning Rate: 0.00637134
	LOSS [training: 0.13005118958500533 | validation: 0.15933660159279436]
	TIME [epoch: 21 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1327983785944771		[learning rate: 0.0063432]
	Learning Rate: 0.00634319
	LOSS [training: 0.1327983785944771 | validation: 0.175713116674236]
	TIME [epoch: 21 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11276716928415331		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 0.11276716928415331 | validation: 0.16605582686052675]
	TIME [epoch: 21 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10382169187286468		[learning rate: 0.0062873]
	Learning Rate: 0.00628726
	LOSS [training: 0.10382169187286468 | validation: 0.17906754967263272]
	TIME [epoch: 20.9 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10891656144444		[learning rate: 0.0062595]
	Learning Rate: 0.00625948
	LOSS [training: 0.10891656144444 | validation: 0.19313594318574828]
	TIME [epoch: 21 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10743968889402526		[learning rate: 0.0062318]
	Learning Rate: 0.00623183
	LOSS [training: 0.10743968889402526 | validation: 0.18046840942997863]
	TIME [epoch: 21 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10427516511612489		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 0.10427516511612489 | validation: 0.19047993426063617]
	TIME [epoch: 21 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11871073941262536		[learning rate: 0.0061769]
	Learning Rate: 0.00617688
	LOSS [training: 0.11871073941262536 | validation: 0.17246838238283846]
	TIME [epoch: 20.9 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10803711667857034		[learning rate: 0.0061496]
	Learning Rate: 0.00614959
	LOSS [training: 0.10803711667857034 | validation: 0.1826340668911529]
	TIME [epoch: 21 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1099678922684331		[learning rate: 0.0061224]
	Learning Rate: 0.00612242
	LOSS [training: 0.1099678922684331 | validation: 0.16384691704961576]
	TIME [epoch: 21 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11534904983711278		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 0.11534904983711278 | validation: 0.19158137787826765]
	TIME [epoch: 20.9 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11073635064206178		[learning rate: 0.0060684]
	Learning Rate: 0.00606844
	LOSS [training: 0.11073635064206178 | validation: 0.16523638753332676]
	TIME [epoch: 21 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10342086777218089		[learning rate: 0.0060416]
	Learning Rate: 0.00604163
	LOSS [training: 0.10342086777218089 | validation: 0.19161082818165523]
	TIME [epoch: 21 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12353927459035612		[learning rate: 0.0060149]
	Learning Rate: 0.00601493
	LOSS [training: 0.12353927459035612 | validation: 0.18448123915328163]
	TIME [epoch: 20.9 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10345800529930076		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 0.10345800529930076 | validation: 0.22516224594180495]
	TIME [epoch: 21 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11727974191776527		[learning rate: 0.0059619]
	Learning Rate: 0.0059619
	LOSS [training: 0.11727974191776527 | validation: 0.17676351698822287]
	TIME [epoch: 21 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11500861345363969		[learning rate: 0.0059356]
	Learning Rate: 0.00593556
	LOSS [training: 0.11500861345363969 | validation: 0.16517032974031218]
	TIME [epoch: 21 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10472418526098874		[learning rate: 0.0059093]
	Learning Rate: 0.00590933
	LOSS [training: 0.10472418526098874 | validation: 0.18763732593860002]
	TIME [epoch: 21 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1043671788562562		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 0.1043671788562562 | validation: 0.1660715876368228]
	TIME [epoch: 21 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09998585602017666		[learning rate: 0.0058572]
	Learning Rate: 0.00585723
	LOSS [training: 0.09998585602017666 | validation: 0.17839029812394652]
	TIME [epoch: 21 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12074763447387575		[learning rate: 0.0058314]
	Learning Rate: 0.00583135
	LOSS [training: 0.12074763447387575 | validation: 0.21344704850069485]
	TIME [epoch: 20.9 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09570025444285221		[learning rate: 0.0058056]
	Learning Rate: 0.00580559
	LOSS [training: 0.09570025444285221 | validation: 0.16493298875121068]
	TIME [epoch: 21 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11234716330191272		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 0.11234716330191272 | validation: 0.17591609956635657]
	TIME [epoch: 21 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10898980157174762		[learning rate: 0.0057544]
	Learning Rate: 0.0057544
	LOSS [training: 0.10898980157174762 | validation: 0.20571050138608224]
	TIME [epoch: 21 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10570990387517978		[learning rate: 0.005729]
	Learning Rate: 0.00572897
	LOSS [training: 0.10570990387517978 | validation: 0.176833427069506]
	TIME [epoch: 21 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11547790413129824		[learning rate: 0.0057037]
	Learning Rate: 0.00570366
	LOSS [training: 0.11547790413129824 | validation: 0.17715767910246205]
	TIME [epoch: 21 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10655741882721795		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 0.10655741882721795 | validation: 0.17504293814516247]
	TIME [epoch: 21 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10100664150256651		[learning rate: 0.0056534]
	Learning Rate: 0.00565337
	LOSS [training: 0.10100664150256651 | validation: 0.19433062046260632]
	TIME [epoch: 20.9 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1178781057241602		[learning rate: 0.0056284]
	Learning Rate: 0.0056284
	LOSS [training: 0.1178781057241602 | validation: 0.19637654151471343]
	TIME [epoch: 20.9 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09959595411043291		[learning rate: 0.0056035]
	Learning Rate: 0.00560353
	LOSS [training: 0.09959595411043291 | validation: 0.16187530974876246]
	TIME [epoch: 21 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09762054370100301		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 0.09762054370100301 | validation: 0.20858239657827313]
	TIME [epoch: 20.9 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1104745971215344		[learning rate: 0.0055541]
	Learning Rate: 0.00555412
	LOSS [training: 0.1104745971215344 | validation: 0.1700804694524378]
	TIME [epoch: 21 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09816323619856764		[learning rate: 0.0055296]
	Learning Rate: 0.00552958
	LOSS [training: 0.09816323619856764 | validation: 0.2223148323834421]
	TIME [epoch: 21 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10919211966723208		[learning rate: 0.0055052]
	Learning Rate: 0.00550515
	LOSS [training: 0.10919211966723208 | validation: 0.1777295765079502]
	TIME [epoch: 20.9 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11610320813302129		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 0.11610320813302129 | validation: 0.167915767911897]
	TIME [epoch: 21 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11168044843044944		[learning rate: 0.0054566]
	Learning Rate: 0.00545661
	LOSS [training: 0.11168044843044944 | validation: 0.19440640670039738]
	TIME [epoch: 21 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10681284255706305		[learning rate: 0.0054325]
	Learning Rate: 0.0054325
	LOSS [training: 0.10681284255706305 | validation: 0.1761934240295107]
	TIME [epoch: 20.9 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09570326213734363		[learning rate: 0.0054085]
	Learning Rate: 0.0054085
	LOSS [training: 0.09570326213734363 | validation: 0.1695266436529588]
	TIME [epoch: 20.9 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09866513075971468		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 0.09866513075971468 | validation: 0.16578048422316724]
	TIME [epoch: 21 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11245828202070877		[learning rate: 0.0053608]
	Learning Rate: 0.00536081
	LOSS [training: 0.11245828202070877 | validation: 0.19772450256062957]
	TIME [epoch: 21 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10044048888560164		[learning rate: 0.0053371]
	Learning Rate: 0.00533713
	LOSS [training: 0.10044048888560164 | validation: 0.17870052366025496]
	TIME [epoch: 20.9 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08970137564711622		[learning rate: 0.0053135]
	Learning Rate: 0.00531355
	LOSS [training: 0.08970137564711622 | validation: 0.15347847329206793]
	TIME [epoch: 20.9 sec]
	Saving model to: out/model_training/model_facs_dec2a_2d_v1_20240622_095511/states/model_facs_dec2a_2d_v1_183.pth
	Model improved!!!
EPOCH 184/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11094404989016723		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 0.11094404989016723 | validation: 0.19363214185890637]
	TIME [epoch: 21 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10611143869271907		[learning rate: 0.0052667]
	Learning Rate: 0.0052667
	LOSS [training: 0.10611143869271907 | validation: 0.18417430762679782]
	TIME [epoch: 20.9 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1133812406163223		[learning rate: 0.0052434]
	Learning Rate: 0.00524343
	LOSS [training: 0.1133812406163223 | validation: 0.17690513376255637]
	TIME [epoch: 20.8 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11867151640641187		[learning rate: 0.0052203]
	Learning Rate: 0.00522026
	LOSS [training: 0.11867151640641187 | validation: 0.17001555244925082]
	TIME [epoch: 20.8 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09958450364766584		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 0.09958450364766584 | validation: 0.20769596591158979]
	TIME [epoch: 20.8 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10872499153868878		[learning rate: 0.0051742]
	Learning Rate: 0.00517423
	LOSS [training: 0.10872499153868878 | validation: 0.17215187200974613]
	TIME [epoch: 20.8 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10887186495723503		[learning rate: 0.0051514]
	Learning Rate: 0.00515137
	LOSS [training: 0.10887186495723503 | validation: 0.1835946506720153]
	TIME [epoch: 20.8 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11101082293159763		[learning rate: 0.0051286]
	Learning Rate: 0.00512861
	LOSS [training: 0.11101082293159763 | validation: 0.16190618253253122]
	TIME [epoch: 20.8 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11292789428470877		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 0.11292789428470877 | validation: 0.16874226404511483]
	TIME [epoch: 20.8 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10310173358136447		[learning rate: 0.0050834]
	Learning Rate: 0.00508339
	LOSS [training: 0.10310173358136447 | validation: 0.1939189131869392]
	TIME [epoch: 20.8 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10219447259573688		[learning rate: 0.0050609]
	Learning Rate: 0.00506093
	LOSS [training: 0.10219447259573688 | validation: 0.181503931270331]
	TIME [epoch: 21 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11301017296146498		[learning rate: 0.0050386]
	Learning Rate: 0.00503857
	LOSS [training: 0.11301017296146498 | validation: 0.1581703380435348]
	TIME [epoch: 20.9 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09582994657532948		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 0.09582994657532948 | validation: 0.18335955190594672]
	TIME [epoch: 21 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09410940965166235		[learning rate: 0.0049941]
	Learning Rate: 0.00499415
	LOSS [training: 0.09410940965166235 | validation: 0.17299667227419926]
	TIME [epoch: 21 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11227073414290371		[learning rate: 0.0049721]
	Learning Rate: 0.00497208
	LOSS [training: 0.11227073414290371 | validation: 0.15091852997789837]
	TIME [epoch: 20.9 sec]
	Saving model to: out/model_training/model_facs_dec2a_2d_v1_20240622_095511/states/model_facs_dec2a_2d_v1_198.pth
	Model improved!!!
EPOCH 199/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10405457290742519		[learning rate: 0.0049501]
	Learning Rate: 0.00495012
	LOSS [training: 0.10405457290742519 | validation: 0.18415821550581876]
	TIME [epoch: 21 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10356789815656517		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 0.10356789815656517 | validation: 0.17622486618662686]
	TIME [epoch: 21 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10159313966814842		[learning rate: 0.0049065]
	Learning Rate: 0.00490647
	LOSS [training: 0.10159313966814842 | validation: 0.15546383815709217]
	TIME [epoch: 21 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1115020476106627		[learning rate: 0.0048848]
	Learning Rate: 0.00488479
	LOSS [training: 0.1115020476106627 | validation: 0.15393133031232023]
	TIME [epoch: 20.9 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10906772640239275		[learning rate: 0.0048632]
	Learning Rate: 0.00486321
	LOSS [training: 0.10906772640239275 | validation: 0.1673210518477487]
	TIME [epoch: 21 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.100684659364729		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 0.100684659364729 | validation: 0.1576800663675495]
	TIME [epoch: 21 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10607627730071492		[learning rate: 0.0048203]
	Learning Rate: 0.00482033
	LOSS [training: 0.10607627730071492 | validation: 0.15979454867886125]
	TIME [epoch: 21 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10716686691637531		[learning rate: 0.004799]
	Learning Rate: 0.00479903
	LOSS [training: 0.10716686691637531 | validation: 0.2031233611954108]
	TIME [epoch: 21 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10359201368397111		[learning rate: 0.0047778]
	Learning Rate: 0.00477783
	LOSS [training: 0.10359201368397111 | validation: 0.1749513153527387]
	TIME [epoch: 21 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10823803735563123		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.10823803735563123 | validation: 0.20027356125302262]
	TIME [epoch: 21 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10564632037718535		[learning rate: 0.0047357]
	Learning Rate: 0.0047357
	LOSS [training: 0.10564632037718535 | validation: 0.17075465074427484]
	TIME [epoch: 21 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08983769145298104		[learning rate: 0.0047148]
	Learning Rate: 0.00471478
	LOSS [training: 0.08983769145298104 | validation: 0.17114341792345225]
	TIME [epoch: 21 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09441084124445114		[learning rate: 0.0046939]
	Learning Rate: 0.00469395
	LOSS [training: 0.09441084124445114 | validation: 0.16201633332834292]
	TIME [epoch: 21 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09531488532897853		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 0.09531488532897853 | validation: 0.1698121660463905]
	TIME [epoch: 20.9 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10517886694606526		[learning rate: 0.0046526]
	Learning Rate: 0.00465256
	LOSS [training: 0.10517886694606526 | validation: 0.1990299678338693]
	TIME [epoch: 21 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10113234255826206		[learning rate: 0.004632]
	Learning Rate: 0.00463201
	LOSS [training: 0.10113234255826206 | validation: 0.1759952076018952]
	TIME [epoch: 21 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10377123776644556		[learning rate: 0.0046115]
	Learning Rate: 0.00461154
	LOSS [training: 0.10377123776644556 | validation: 0.1745487805641758]
	TIME [epoch: 21 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08926999822553619		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 0.08926999822553619 | validation: 0.18738412068487725]
	TIME [epoch: 21 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11310951327495618		[learning rate: 0.0045709]
	Learning Rate: 0.00457088
	LOSS [training: 0.11310951327495618 | validation: 0.16694385920038482]
	TIME [epoch: 21 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10544547050577938		[learning rate: 0.0045507]
	Learning Rate: 0.00455069
	LOSS [training: 0.10544547050577938 | validation: 0.1721083148271758]
	TIME [epoch: 21 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0987121814627697		[learning rate: 0.0045306]
	Learning Rate: 0.00453058
	LOSS [training: 0.0987121814627697 | validation: 0.16235742027712782]
	TIME [epoch: 21 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10372456423373813		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 0.10372456423373813 | validation: 0.17452987441057485]
	TIME [epoch: 21 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10042878708309103		[learning rate: 0.0044906]
	Learning Rate: 0.00449063
	LOSS [training: 0.10042878708309103 | validation: 0.15657385234194424]
	TIME [epoch: 21 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10157447170072045		[learning rate: 0.0044708]
	Learning Rate: 0.00447079
	LOSS [training: 0.10157447170072045 | validation: 0.19291905663212663]
	TIME [epoch: 20.9 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10949706454745083		[learning rate: 0.004451]
	Learning Rate: 0.00445104
	LOSS [training: 0.10949706454745083 | validation: 0.15337151218189804]
	TIME [epoch: 20.9 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10323020849971314		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 0.10323020849971314 | validation: 0.17153690987647055]
	TIME [epoch: 21 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10429927143014553		[learning rate: 0.0044118]
	Learning Rate: 0.0044118
	LOSS [training: 0.10429927143014553 | validation: 0.15945513114365106]
	TIME [epoch: 20.9 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09941589535335998		[learning rate: 0.0043923]
	Learning Rate: 0.0043923
	LOSS [training: 0.09941589535335998 | validation: 0.15488577019535832]
	TIME [epoch: 21 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10659434231076839		[learning rate: 0.0043729]
	Learning Rate: 0.0043729
	LOSS [training: 0.10659434231076839 | validation: 0.16083002206973604]
	TIME [epoch: 21 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1056654708805119		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 0.1056654708805119 | validation: 0.16757903126497173]
	TIME [epoch: 21 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10602125711299097		[learning rate: 0.0043343]
	Learning Rate: 0.00433434
	LOSS [training: 0.10602125711299097 | validation: 0.16083376049004094]
	TIME [epoch: 21 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1007842320283517		[learning rate: 0.0043152]
	Learning Rate: 0.00431519
	LOSS [training: 0.1007842320283517 | validation: 0.15394781831715035]
	TIME [epoch: 21 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09986880661740076		[learning rate: 0.0042961]
	Learning Rate: 0.00429612
	LOSS [training: 0.09986880661740076 | validation: 0.17208732177961494]
	TIME [epoch: 21 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10055489858138492		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 0.10055489858138492 | validation: 0.16932264724435506]
	TIME [epoch: 21 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10463299516518258		[learning rate: 0.0042582]
	Learning Rate: 0.00425825
	LOSS [training: 0.10463299516518258 | validation: 0.16612008399154982]
	TIME [epoch: 21 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10173004530253775		[learning rate: 0.0042394]
	Learning Rate: 0.00423943
	LOSS [training: 0.10173004530253775 | validation: 0.15808722585750912]
	TIME [epoch: 21 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09947186311542919		[learning rate: 0.0042207]
	Learning Rate: 0.0042207
	LOSS [training: 0.09947186311542919 | validation: 0.16165576551816307]
	TIME [epoch: 20.9 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10518258291373547		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 0.10518258291373547 | validation: 0.15983379065746045]
	TIME [epoch: 21 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09883952412742292		[learning rate: 0.0041835]
	Learning Rate: 0.00418349
	LOSS [training: 0.09883952412742292 | validation: 0.1658185347670486]
	TIME [epoch: 21 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10289035838388541		[learning rate: 0.004165]
	Learning Rate: 0.004165
	LOSS [training: 0.10289035838388541 | validation: 0.16703088367295318]
	TIME [epoch: 21 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09763464610715801		[learning rate: 0.0041466]
	Learning Rate: 0.0041466
	LOSS [training: 0.09763464610715801 | validation: 0.17670260897599788]
	TIME [epoch: 21 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09435629437551445		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 0.09435629437551445 | validation: 0.16250387931526336]
	TIME [epoch: 21 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10278020470029747		[learning rate: 0.00411]
	Learning Rate: 0.00411004
	LOSS [training: 0.10278020470029747 | validation: 0.1711763109891425]
	TIME [epoch: 21 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09353318312329426		[learning rate: 0.0040919]
	Learning Rate: 0.00409188
	LOSS [training: 0.09353318312329426 | validation: 0.15509332802051287]
	TIME [epoch: 20.9 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10610837385174968		[learning rate: 0.0040738]
	Learning Rate: 0.0040738
	LOSS [training: 0.10610837385174968 | validation: 0.16834188804931044]
	TIME [epoch: 20.9 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09710583776889962		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.09710583776889962 | validation: 0.16391849126482277]
	TIME [epoch: 21 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09864257840651876		[learning rate: 0.0040379]
	Learning Rate: 0.00403788
	LOSS [training: 0.09864257840651876 | validation: 0.17194310541086755]
	TIME [epoch: 20.9 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1058636914601578		[learning rate: 0.00402]
	Learning Rate: 0.00402004
	LOSS [training: 0.1058636914601578 | validation: 0.17080227023941885]
	TIME [epoch: 21 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08872293430150534		[learning rate: 0.0040023]
	Learning Rate: 0.00400228
	LOSS [training: 0.08872293430150534 | validation: 0.1738134823014486]
	TIME [epoch: 21 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09610859693169696		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 0.09610859693169696 | validation: 0.15841751590972328]
	TIME [epoch: 21 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10846901544255627		[learning rate: 0.003967]
	Learning Rate: 0.00396699
	LOSS [training: 0.10846901544255627 | validation: 0.1593493082114267]
	TIME [epoch: 21 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10197123000936274		[learning rate: 0.0039495]
	Learning Rate: 0.00394947
	LOSS [training: 0.10197123000936274 | validation: 0.1623266845980215]
	TIME [epoch: 21 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09805575910550943		[learning rate: 0.003932]
	Learning Rate: 0.00393202
	LOSS [training: 0.09805575910550943 | validation: 0.15795749005397636]
	TIME [epoch: 21 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.104069850214461		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 0.104069850214461 | validation: 0.15836397949773123]
	TIME [epoch: 20.9 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09840657788354987		[learning rate: 0.0038973]
	Learning Rate: 0.00389735
	LOSS [training: 0.09840657788354987 | validation: 0.1643527370121244]
	TIME [epoch: 21 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08593961256852944		[learning rate: 0.0038801]
	Learning Rate: 0.00388013
	LOSS [training: 0.08593961256852944 | validation: 0.16310722831800936]
	TIME [epoch: 21 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10624769989301386		[learning rate: 0.003863]
	Learning Rate: 0.00386299
	LOSS [training: 0.10624769989301386 | validation: 0.15898486922975408]
	TIME [epoch: 20.9 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10237851524522715		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 0.10237851524522715 | validation: 0.17067513583375415]
	TIME [epoch: 21 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09581063924013834		[learning rate: 0.0038289]
	Learning Rate: 0.00382893
	LOSS [training: 0.09581063924013834 | validation: 0.16825665074752288]
	TIME [epoch: 21 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10413393235676091		[learning rate: 0.003812]
	Learning Rate: 0.00381201
	LOSS [training: 0.10413393235676091 | validation: 0.21776611272984125]
	TIME [epoch: 20.9 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10306586930275803		[learning rate: 0.0037952]
	Learning Rate: 0.00379517
	LOSS [training: 0.10306586930275803 | validation: 0.1580917254599762]
	TIME [epoch: 21 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10062764515463818		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 0.10062764515463818 | validation: 0.18969564152296656]
	TIME [epoch: 21 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0958503857383387		[learning rate: 0.0037617]
	Learning Rate: 0.0037617
	LOSS [training: 0.0958503857383387 | validation: 0.15566384687972643]
	TIME [epoch: 20.9 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09810771886206363		[learning rate: 0.0037451]
	Learning Rate: 0.00374508
	LOSS [training: 0.09810771886206363 | validation: 0.1785846780736791]
	TIME [epoch: 20.9 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09983896048206811		[learning rate: 0.0037285]
	Learning Rate: 0.00372854
	LOSS [training: 0.09983896048206811 | validation: 0.15321471391918998]
	TIME [epoch: 21 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10216347520231972		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 0.10216347520231972 | validation: 0.20985095307502455]
	TIME [epoch: 21 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09932376776572842		[learning rate: 0.0036957]
	Learning Rate: 0.00369566
	LOSS [training: 0.09932376776572842 | validation: 0.1489532591343706]
	TIME [epoch: 20.9 sec]
	Saving model to: out/model_training/model_facs_dec2a_2d_v1_20240622_095511/states/model_facs_dec2a_2d_v1_265.pth
	Model improved!!!
EPOCH 266/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10120123230564841		[learning rate: 0.0036793]
	Learning Rate: 0.00367933
	LOSS [training: 0.10120123230564841 | validation: 0.20155433485090354]
	TIME [epoch: 20.9 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09353162009400298		[learning rate: 0.0036631]
	Learning Rate: 0.00366308
	LOSS [training: 0.09353162009400298 | validation: 0.15833290091648297]
	TIME [epoch: 21 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09504480182639369		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 0.09504480182639369 | validation: 0.14987177277999983]
	TIME [epoch: 20.9 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0986926244320385		[learning rate: 0.0036308]
	Learning Rate: 0.00363078
	LOSS [training: 0.0986926244320385 | validation: 0.1532362335908501]
	TIME [epoch: 20.9 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09053510520822912		[learning rate: 0.0036147]
	Learning Rate: 0.00361474
	LOSS [training: 0.09053510520822912 | validation: 0.15768608284193353]
	TIME [epoch: 21 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09941934300176115		[learning rate: 0.0035988]
	Learning Rate: 0.00359877
	LOSS [training: 0.09941934300176115 | validation: 0.16624280582443468]
	TIME [epoch: 20.9 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09647217413176093		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 0.09647217413176093 | validation: 0.16103894961377857]
	TIME [epoch: 20.9 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09573359875460123		[learning rate: 0.003567]
	Learning Rate: 0.00356704
	LOSS [training: 0.09573359875460123 | validation: 0.17692731890356622]
	TIME [epoch: 20.9 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10295485961398712		[learning rate: 0.0035513]
	Learning Rate: 0.00355128
	LOSS [training: 0.10295485961398712 | validation: 0.1800159080605363]
	TIME [epoch: 21 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10025750628213168		[learning rate: 0.0035356]
	Learning Rate: 0.00353559
	LOSS [training: 0.10025750628213168 | validation: 0.16091509275373897]
	TIME [epoch: 20.9 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09837923036425593		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 0.09837923036425593 | validation: 0.18962657542857222]
	TIME [epoch: 21 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10207804825761065		[learning rate: 0.0035044]
	Learning Rate: 0.00350441
	LOSS [training: 0.10207804825761065 | validation: 0.15501476007767218]
	TIME [epoch: 21 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09653558591871907		[learning rate: 0.0034889]
	Learning Rate: 0.00348893
	LOSS [training: 0.09653558591871907 | validation: 0.1677236741922457]
	TIME [epoch: 20.9 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09766444605729789		[learning rate: 0.0034735]
	Learning Rate: 0.00347352
	LOSS [training: 0.09766444605729789 | validation: 0.16834619785909452]
	TIME [epoch: 21 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09148183635711406		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.09148183635711406 | validation: 0.166347105963851]
	TIME [epoch: 21 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1018198830394584		[learning rate: 0.0034429]
	Learning Rate: 0.00344289
	LOSS [training: 0.1018198830394584 | validation: 0.16644076353433362]
	TIME [epoch: 21 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10491170623966337		[learning rate: 0.0034277]
	Learning Rate: 0.00342768
	LOSS [training: 0.10491170623966337 | validation: 0.15780670139558395]
	TIME [epoch: 20.9 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09468726753558006		[learning rate: 0.0034125]
	Learning Rate: 0.00341253
	LOSS [training: 0.09468726753558006 | validation: 0.19305926912505228]
	TIME [epoch: 21 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09788060436342316		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 0.09788060436342316 | validation: 0.1557719565033879]
	TIME [epoch: 20.9 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10215523401234847		[learning rate: 0.0033824]
	Learning Rate: 0.00338245
	LOSS [training: 0.10215523401234847 | validation: 0.22494689932006903]
	TIME [epoch: 20.9 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09469025469932232		[learning rate: 0.0033675]
	Learning Rate: 0.0033675
	LOSS [training: 0.09469025469932232 | validation: 0.16550704879850545]
	TIME [epoch: 20.9 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08982431458211622		[learning rate: 0.0033526]
	Learning Rate: 0.00335262
	LOSS [training: 0.08982431458211622 | validation: 0.17009505179040565]
	TIME [epoch: 20.9 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10112632603481475		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 0.10112632603481475 | validation: 0.1658168670078658]
	TIME [epoch: 20.9 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1000203761553808		[learning rate: 0.0033231]
	Learning Rate: 0.00332306
	LOSS [training: 0.1000203761553808 | validation: 0.15279028910104364]
	TIME [epoch: 20.9 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10035460780667402		[learning rate: 0.0033084]
	Learning Rate: 0.00330838
	LOSS [training: 0.10035460780667402 | validation: 0.20100305074552433]
	TIME [epoch: 20.9 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09273314570711035		[learning rate: 0.0032938]
	Learning Rate: 0.00329376
	LOSS [training: 0.09273314570711035 | validation: 0.15882001054895356]
	TIME [epoch: 20.9 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09890765756407432		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 0.09890765756407432 | validation: 0.15917549852356425]
	TIME [epoch: 20.9 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09539352577830722		[learning rate: 0.0032647]
	Learning Rate: 0.00326472
	LOSS [training: 0.09539352577830722 | validation: 0.16234090970543508]
	TIME [epoch: 20.8 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09475409742762067		[learning rate: 0.0032503]
	Learning Rate: 0.0032503
	LOSS [training: 0.09475409742762067 | validation: 0.16833975282615324]
	TIME [epoch: 20.9 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09902468849793088		[learning rate: 0.0032359]
	Learning Rate: 0.00323594
	LOSS [training: 0.09902468849793088 | validation: 0.17154710293429878]
	TIME [epoch: 20.9 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09947173746582313		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 0.09947173746582313 | validation: 0.18138929552882954]
	TIME [epoch: 20.9 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09798493653416915		[learning rate: 0.0032074]
	Learning Rate: 0.00320741
	LOSS [training: 0.09798493653416915 | validation: 0.17139851733750472]
	TIME [epoch: 20.9 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08689195535351864		[learning rate: 0.0031932]
	Learning Rate: 0.00319323
	LOSS [training: 0.08689195535351864 | validation: 0.17875213286990926]
	TIME [epoch: 20.9 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09376839788932356		[learning rate: 0.0031791]
	Learning Rate: 0.00317913
	LOSS [training: 0.09376839788932356 | validation: 0.161124662961384]
	TIME [epoch: 20.8 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09731612445120422		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 0.09731612445120422 | validation: 0.17106781141307775]
	TIME [epoch: 20.9 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09407534284464521		[learning rate: 0.0031511]
	Learning Rate: 0.0031511
	LOSS [training: 0.09407534284464521 | validation: 0.15441409519301486]
	TIME [epoch: 20.9 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09938936910330382		[learning rate: 0.0031372]
	Learning Rate: 0.00313717
	LOSS [training: 0.09938936910330382 | validation: 0.16243571955788838]
	TIME [epoch: 21 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09684768117951358		[learning rate: 0.0031233]
	Learning Rate: 0.00312331
	LOSS [training: 0.09684768117951358 | validation: 0.1711066246176101]
	TIME [epoch: 20.9 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10138576978770772		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 0.10138576978770772 | validation: 0.186970552948832]
	TIME [epoch: 21 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0855644118062388		[learning rate: 0.0030958]
	Learning Rate: 0.00309577
	LOSS [training: 0.0855644118062388 | validation: 0.15822019245095942]
	TIME [epoch: 21 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09901531992523376		[learning rate: 0.0030821]
	Learning Rate: 0.0030821
	LOSS [training: 0.09901531992523376 | validation: 0.18745029723734763]
	TIME [epoch: 20.9 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0964035848103171		[learning rate: 0.0030685]
	Learning Rate: 0.00306848
	LOSS [training: 0.0964035848103171 | validation: 0.16991360665649835]
	TIME [epoch: 20.9 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10775952712773831		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 0.10775952712773831 | validation: 0.14630179548091019]
	TIME [epoch: 21 sec]
	Saving model to: out/model_training/model_facs_dec2a_2d_v1_20240622_095511/states/model_facs_dec2a_2d_v1_308.pth
	Model improved!!!
EPOCH 309/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09488030754150482		[learning rate: 0.0030414]
	Learning Rate: 0.00304142
	LOSS [training: 0.09488030754150482 | validation: 0.19333814299248359]
	TIME [epoch: 20.9 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09424870964664615		[learning rate: 0.003028]
	Learning Rate: 0.00302799
	LOSS [training: 0.09424870964664615 | validation: 0.15106592598395321]
	TIME [epoch: 20.9 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10178993566864251		[learning rate: 0.0030146]
	Learning Rate: 0.00301461
	LOSS [training: 0.10178993566864251 | validation: 0.1658662043597581]
	TIME [epoch: 21 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09331037229433192		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 0.09331037229433192 | validation: 0.16215761575917303]
	TIME [epoch: 21 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08901256462099857		[learning rate: 0.002988]
	Learning Rate: 0.00298803
	LOSS [training: 0.08901256462099857 | validation: 0.17121927818195626]
	TIME [epoch: 20.9 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10483381389687632		[learning rate: 0.0029748]
	Learning Rate: 0.00297483
	LOSS [training: 0.10483381389687632 | validation: 0.14109441085360871]
	TIME [epoch: 20.9 sec]
	Saving model to: out/model_training/model_facs_dec2a_2d_v1_20240622_095511/states/model_facs_dec2a_2d_v1_314.pth
	Model improved!!!
EPOCH 315/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08887511159141184		[learning rate: 0.0029617]
	Learning Rate: 0.00296168
	LOSS [training: 0.08887511159141184 | validation: 0.21488514125505484]
	TIME [epoch: 21 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09966898611071434		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.09966898611071434 | validation: 0.14649544840307313]
	TIME [epoch: 20.9 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08987751783811497		[learning rate: 0.0029356]
	Learning Rate: 0.00293557
	LOSS [training: 0.08987751783811497 | validation: 0.15524653520636503]
	TIME [epoch: 20.9 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09454506814320562		[learning rate: 0.0029226]
	Learning Rate: 0.0029226
	LOSS [training: 0.09454506814320562 | validation: 0.16184002227065902]
	TIME [epoch: 21 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09790713695923357		[learning rate: 0.0029097]
	Learning Rate: 0.00290969
	LOSS [training: 0.09790713695923357 | validation: 0.1688982129443769]
	TIME [epoch: 20.9 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09947817541533985		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 0.09947817541533985 | validation: 0.1659741769193717]
	TIME [epoch: 20.9 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09665998251438782		[learning rate: 0.002884]
	Learning Rate: 0.00288403
	LOSS [training: 0.09665998251438782 | validation: 0.15368134267854058]
	TIME [epoch: 21 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09574146172693641		[learning rate: 0.0028713]
	Learning Rate: 0.00287129
	LOSS [training: 0.09574146172693641 | validation: 0.16636969381130284]
	TIME [epoch: 21 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10056805031015018		[learning rate: 0.0028586]
	Learning Rate: 0.0028586
	LOSS [training: 0.10056805031015018 | validation: 0.16152415093773614]
	TIME [epoch: 20.9 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10001772135884077		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 0.10001772135884077 | validation: 0.1622982898792495]
	TIME [epoch: 20.9 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10084930643022401		[learning rate: 0.0028334]
	Learning Rate: 0.0028334
	LOSS [training: 0.10084930643022401 | validation: 0.18543727759144144]
	TIME [epoch: 21 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1058344327490931		[learning rate: 0.0028209]
	Learning Rate: 0.00282088
	LOSS [training: 0.1058344327490931 | validation: 0.1467818086884094]
	TIME [epoch: 20.9 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0991059837512391		[learning rate: 0.0028084]
	Learning Rate: 0.00280842
	LOSS [training: 0.0991059837512391 | validation: 0.17340898707738883]
	TIME [epoch: 20.9 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10152417914722452		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 0.10152417914722452 | validation: 0.16414296425893568]
	TIME [epoch: 20.9 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10190941692101636		[learning rate: 0.0027837]
	Learning Rate: 0.00278366
	LOSS [training: 0.10190941692101636 | validation: 0.15149108646927317]
	TIME [epoch: 21 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08789647290264715		[learning rate: 0.0027714]
	Learning Rate: 0.00277136
	LOSS [training: 0.08789647290264715 | validation: 0.17054234580576436]
	TIME [epoch: 20.9 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08771254200949943		[learning rate: 0.0027591]
	Learning Rate: 0.00275911
	LOSS [training: 0.08771254200949943 | validation: 0.16107597062061535]
	TIME [epoch: 21 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09488107126410601		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 0.09488107126410601 | validation: 0.15375098328960818]
	TIME [epoch: 21 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09488981895623927		[learning rate: 0.0027348]
	Learning Rate: 0.00273478
	LOSS [training: 0.09488981895623927 | validation: 0.17109623413462682]
	TIME [epoch: 20.9 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10480034462409196		[learning rate: 0.0027227]
	Learning Rate: 0.0027227
	LOSS [training: 0.10480034462409196 | validation: 0.14388112501996164]
	TIME [epoch: 20.9 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0990877678342715		[learning rate: 0.0027107]
	Learning Rate: 0.00271067
	LOSS [training: 0.0990877678342715 | validation: 0.17674782015061347]
	TIME [epoch: 21 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09125142628946704		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 0.09125142628946704 | validation: 0.15437001012126148]
	TIME [epoch: 20.9 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08476662856002046		[learning rate: 0.0026868]
	Learning Rate: 0.00268677
	LOSS [training: 0.08476662856002046 | validation: 0.1639242290638476]
	TIME [epoch: 20.9 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10221966022671913		[learning rate: 0.0026749]
	Learning Rate: 0.0026749
	LOSS [training: 0.10221966022671913 | validation: 0.18504524061842795]
	TIME [epoch: 21 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09663982236316356		[learning rate: 0.0026631]
	Learning Rate: 0.00266308
	LOSS [training: 0.09663982236316356 | validation: 0.16287961297772838]
	TIME [epoch: 20.9 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09917612122952586		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 0.09917612122952586 | validation: 0.1683130507572395]
	TIME [epoch: 20.9 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.102172310623081		[learning rate: 0.0026396]
	Learning Rate: 0.0026396
	LOSS [training: 0.102172310623081 | validation: 0.1640589150657897]
	TIME [epoch: 21 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09636096064207657		[learning rate: 0.0026279]
	Learning Rate: 0.00262794
	LOSS [training: 0.09636096064207657 | validation: 0.16749805341604693]
	TIME [epoch: 20.9 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09769821474585282		[learning rate: 0.0026163]
	Learning Rate: 0.00261633
	LOSS [training: 0.09769821474585282 | validation: 0.16323033000102427]
	TIME [epoch: 20.9 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09746227096290097		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 0.09746227096290097 | validation: 0.20082994199325868]
	TIME [epoch: 21 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0990831802052472		[learning rate: 0.0025933]
	Learning Rate: 0.00259326
	LOSS [training: 0.0990831802052472 | validation: 0.15716170105247165]
	TIME [epoch: 20.9 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09450057247996525		[learning rate: 0.0025818]
	Learning Rate: 0.0025818
	LOSS [training: 0.09450057247996525 | validation: 0.1586042292657997]
	TIME [epoch: 20.9 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09377153821953088		[learning rate: 0.0025704]
	Learning Rate: 0.0025704
	LOSS [training: 0.09377153821953088 | validation: 0.17923246708498186]
	TIME [epoch: 20.9 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09578405919159141		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.09578405919159141 | validation: 0.15662123761691488]
	TIME [epoch: 20.9 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09971492175205247		[learning rate: 0.0025477]
	Learning Rate: 0.00254773
	LOSS [training: 0.09971492175205247 | validation: 0.19166374071459352]
	TIME [epoch: 20.9 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10452432623869894		[learning rate: 0.0025365]
	Learning Rate: 0.00253648
	LOSS [training: 0.10452432623869894 | validation: 0.15363815294824842]
	TIME [epoch: 20.9 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10264967288272264		[learning rate: 0.0025253]
	Learning Rate: 0.00252527
	LOSS [training: 0.10264967288272264 | validation: 0.1678351212511313]
	TIME [epoch: 20.9 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0883397903693999		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.0883397903693999 | validation: 0.15176046792005654]
	TIME [epoch: 20.9 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09350126542775548		[learning rate: 0.002503]
	Learning Rate: 0.002503
	LOSS [training: 0.09350126542775548 | validation: 0.15376914315318962]
	TIME [epoch: 20.9 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0934798198717666		[learning rate: 0.0024919]
	Learning Rate: 0.00249194
	LOSS [training: 0.0934798198717666 | validation: 0.1542522995294924]
	TIME [epoch: 21 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0932385351207003		[learning rate: 0.0024809]
	Learning Rate: 0.00248093
	LOSS [training: 0.0932385351207003 | validation: 0.15421013123532354]
	TIME [epoch: 21 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0925910492786316		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 0.0925910492786316 | validation: 0.1498483434494306]
	TIME [epoch: 20.9 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09733274573748496		[learning rate: 0.0024591]
	Learning Rate: 0.00245906
	LOSS [training: 0.09733274573748496 | validation: 0.15610068557098689]
	TIME [epoch: 20.9 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10504103587092391		[learning rate: 0.0024482]
	Learning Rate: 0.0024482
	LOSS [training: 0.10504103587092391 | validation: 0.19315258491145573]
	TIME [epoch: 21 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09951069086217776		[learning rate: 0.0024374]
	Learning Rate: 0.00243738
	LOSS [training: 0.09951069086217776 | validation: 0.16612703703439893]
	TIME [epoch: 20.9 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10357746887473673		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.10357746887473673 | validation: 0.15865743774005153]
	TIME [epoch: 20.8 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10511110822490947		[learning rate: 0.0024159]
	Learning Rate: 0.00241589
	LOSS [training: 0.10511110822490947 | validation: 0.15065447150227082]
	TIME [epoch: 21 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10207974703847991		[learning rate: 0.0024052]
	Learning Rate: 0.00240521
	LOSS [training: 0.10207974703847991 | validation: 0.1736648041659805]
	TIME [epoch: 20.9 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10189906572898895		[learning rate: 0.0023946]
	Learning Rate: 0.00239459
	LOSS [training: 0.10189906572898895 | validation: 0.16989504598387595]
	TIME [epoch: 20.9 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09980188991384839		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 0.09980188991384839 | validation: 0.14788634545015386]
	TIME [epoch: 21 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09672501474270807		[learning rate: 0.0023735]
	Learning Rate: 0.00237347
	LOSS [training: 0.09672501474270807 | validation: 0.16869830467427102]
	TIME [epoch: 21 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08850337227533418		[learning rate: 0.002363]
	Learning Rate: 0.00236299
	LOSS [training: 0.08850337227533418 | validation: 0.16319552511515248]
	TIME [epoch: 20.9 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09159691830138261		[learning rate: 0.0023525]
	Learning Rate: 0.00235255
	LOSS [training: 0.09159691830138261 | validation: 0.1593477289376421]
	TIME [epoch: 21 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09851229361781058		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.09851229361781058 | validation: 0.1592768954472461]
	TIME [epoch: 20.9 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09925423933754893		[learning rate: 0.0023318]
	Learning Rate: 0.00233181
	LOSS [training: 0.09925423933754893 | validation: 0.1534045457805319]
	TIME [epoch: 20.9 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09778698545930914		[learning rate: 0.0023215]
	Learning Rate: 0.0023215
	LOSS [training: 0.09778698545930914 | validation: 0.1763877259132947]
	TIME [epoch: 20.9 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10239014845363739		[learning rate: 0.0023112]
	Learning Rate: 0.00231125
	LOSS [training: 0.10239014845363739 | validation: 0.15683668886082555]
	TIME [epoch: 20.9 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09364969168476105		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.09364969168476105 | validation: 0.15730769898758645]
	TIME [epoch: 21 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0952622280994807		[learning rate: 0.0022909]
	Learning Rate: 0.00229087
	LOSS [training: 0.0952622280994807 | validation: 0.16106514643631864]
	TIME [epoch: 20.9 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09644038250026755		[learning rate: 0.0022807]
	Learning Rate: 0.00228075
	LOSS [training: 0.09644038250026755 | validation: 0.15341716396631008]
	TIME [epoch: 21 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09728939134828028		[learning rate: 0.0022707]
	Learning Rate: 0.00227067
	LOSS [training: 0.09728939134828028 | validation: 0.1539180727775101]
	TIME [epoch: 20.9 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09025599115231982		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.09025599115231982 | validation: 0.16494098367015786]
	TIME [epoch: 20.9 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09523601376940209		[learning rate: 0.0022506]
	Learning Rate: 0.00225065
	LOSS [training: 0.09523601376940209 | validation: 0.16207109038240797]
	TIME [epoch: 20.9 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09694769249563831		[learning rate: 0.0022407]
	Learning Rate: 0.0022407
	LOSS [training: 0.09694769249563831 | validation: 0.1543282889410786]
	TIME [epoch: 21 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09374257435367439		[learning rate: 0.0022308]
	Learning Rate: 0.0022308
	LOSS [training: 0.09374257435367439 | validation: 0.17162246901032008]
	TIME [epoch: 20.9 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1004480924511443		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.1004480924511443 | validation: 0.14195139337888169]
	TIME [epoch: 20.9 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09945986249964808		[learning rate: 0.0022111]
	Learning Rate: 0.00221114
	LOSS [training: 0.09945986249964808 | validation: 0.16389568093116494]
	TIME [epoch: 20.9 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09482850826296194		[learning rate: 0.0022014]
	Learning Rate: 0.00220137
	LOSS [training: 0.09482850826296194 | validation: 0.15347217354622283]
	TIME [epoch: 20.8 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09467231517277126		[learning rate: 0.0021916]
	Learning Rate: 0.00219164
	LOSS [training: 0.09467231517277126 | validation: 0.15426741704115568]
	TIME [epoch: 20.8 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09642266615040596		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.09642266615040596 | validation: 0.17268584024771277]
	TIME [epoch: 20.8 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09090348522477057		[learning rate: 0.0021723]
	Learning Rate: 0.00217232
	LOSS [training: 0.09090348522477057 | validation: 0.16247412716922416]
	TIME [epoch: 20.8 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09523807025708675		[learning rate: 0.0021627]
	Learning Rate: 0.00216272
	LOSS [training: 0.09523807025708675 | validation: 0.1628909154171176]
	TIME [epoch: 20.9 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09203917185768382		[learning rate: 0.0021532]
	Learning Rate: 0.00215316
	LOSS [training: 0.09203917185768382 | validation: 0.14815989684175082]
	TIME [epoch: 20.8 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09913634244545215		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.09913634244545215 | validation: 0.1673712515312745]
	TIME [epoch: 20.9 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09828486479597873		[learning rate: 0.0021342]
	Learning Rate: 0.00213418
	LOSS [training: 0.09828486479597873 | validation: 0.1506892535763266]
	TIME [epoch: 20.9 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09683062996699678		[learning rate: 0.0021247]
	Learning Rate: 0.00212475
	LOSS [training: 0.09683062996699678 | validation: 0.15844490990822327]
	TIME [epoch: 20.9 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.090264672305267		[learning rate: 0.0021154]
	Learning Rate: 0.00211536
	LOSS [training: 0.090264672305267 | validation: 0.1549910968899629]
	TIME [epoch: 20.9 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08932639906143311		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.08932639906143311 | validation: 0.15818161743537412]
	TIME [epoch: 20.9 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08908942345138907		[learning rate: 0.0020967]
	Learning Rate: 0.00209671
	LOSS [training: 0.08908942345138907 | validation: 0.14590542590364192]
	TIME [epoch: 20.9 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08693801317837475		[learning rate: 0.0020874]
	Learning Rate: 0.00208745
	LOSS [training: 0.08693801317837475 | validation: 0.15468078744532524]
	TIME [epoch: 21 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0892979810211212		[learning rate: 0.0020782]
	Learning Rate: 0.00207822
	LOSS [training: 0.0892979810211212 | validation: 0.1730291217845225]
	TIME [epoch: 20.9 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09775371496551709		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.09775371496551709 | validation: 0.15298760575619044]
	TIME [epoch: 20.9 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09094547317114318		[learning rate: 0.0020599]
	Learning Rate: 0.0020599
	LOSS [training: 0.09094547317114318 | validation: 0.1486131412269841]
	TIME [epoch: 21 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09642027983930822		[learning rate: 0.0020508]
	Learning Rate: 0.0020508
	LOSS [training: 0.09642027983930822 | validation: 0.14829330377182987]
	TIME [epoch: 21 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09028263629106827		[learning rate: 0.0020417]
	Learning Rate: 0.00204174
	LOSS [training: 0.09028263629106827 | validation: 0.169922141049827]
	TIME [epoch: 20.9 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09203481542147315		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.09203481542147315 | validation: 0.15536216636889527]
	TIME [epoch: 20.9 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09801009308937073		[learning rate: 0.0020237]
	Learning Rate: 0.00202374
	LOSS [training: 0.09801009308937073 | validation: 0.16167034613061007]
	TIME [epoch: 21 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09140314327988908		[learning rate: 0.0020148]
	Learning Rate: 0.00201479
	LOSS [training: 0.09140314327988908 | validation: 0.16980910688936937]
	TIME [epoch: 20.9 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09061124525956613		[learning rate: 0.0020059]
	Learning Rate: 0.00200589
	LOSS [training: 0.09061124525956613 | validation: 0.1484015874742997]
	TIME [epoch: 20.9 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10707257631559175		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.10707257631559175 | validation: 0.16136676977759393]
	TIME [epoch: 21 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09808453365111776		[learning rate: 0.0019882]
	Learning Rate: 0.00198821
	LOSS [training: 0.09808453365111776 | validation: 0.14558506954274408]
	TIME [epoch: 20.9 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08945549399479961		[learning rate: 0.0019794]
	Learning Rate: 0.00197942
	LOSS [training: 0.08945549399479961 | validation: 0.15993094067959313]
	TIME [epoch: 20.9 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08968304017341408		[learning rate: 0.0019707]
	Learning Rate: 0.00197068
	LOSS [training: 0.08968304017341408 | validation: 0.15714646237601299]
	TIME [epoch: 21 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09578161809856275		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.09578161809856275 | validation: 0.1642023123783672]
	TIME [epoch: 20.9 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10245485645912211		[learning rate: 0.0019533]
	Learning Rate: 0.0019533
	LOSS [training: 0.10245485645912211 | validation: 0.18012995892015407]
	TIME [epoch: 20.9 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09301607680186301		[learning rate: 0.0019447]
	Learning Rate: 0.00194467
	LOSS [training: 0.09301607680186301 | validation: 0.16269767288351555]
	TIME [epoch: 20.9 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09075689945615026		[learning rate: 0.0019361]
	Learning Rate: 0.00193608
	LOSS [training: 0.09075689945615026 | validation: 0.17776004019125516]
	TIME [epoch: 20.9 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09336733098166175		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.09336733098166175 | validation: 0.16852859418472216]
	TIME [epoch: 20.9 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09031405011624202		[learning rate: 0.001919]
	Learning Rate: 0.00191901
	LOSS [training: 0.09031405011624202 | validation: 0.17940249404570746]
	TIME [epoch: 20.9 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09701036068158482		[learning rate: 0.0019105]
	Learning Rate: 0.00191053
	LOSS [training: 0.09701036068158482 | validation: 0.17384315979232798]
	TIME [epoch: 20.9 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09503000325813962		[learning rate: 0.0019021]
	Learning Rate: 0.00190209
	LOSS [training: 0.09503000325813962 | validation: 0.1646230620343804]
	TIME [epoch: 20.9 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09339743830576902		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.09339743830576902 | validation: 0.15771107966812448]
	TIME [epoch: 20.9 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0956619466140205		[learning rate: 0.0018853]
	Learning Rate: 0.00188532
	LOSS [training: 0.0956619466140205 | validation: 0.16108595986893387]
	TIME [epoch: 21 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1024408565821036		[learning rate: 0.001877]
	Learning Rate: 0.00187699
	LOSS [training: 0.1024408565821036 | validation: 0.15586636417795136]
	TIME [epoch: 20.9 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10164194972245158		[learning rate: 0.0018687]
	Learning Rate: 0.0018687
	LOSS [training: 0.10164194972245158 | validation: 0.15443564481128294]
	TIME [epoch: 20.9 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09660325706711945		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.09660325706711945 | validation: 0.15527503439423182]
	TIME [epoch: 21 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08884232998604942		[learning rate: 0.0018522]
	Learning Rate: 0.00185222
	LOSS [training: 0.08884232998604942 | validation: 0.1645514767398202]
	TIME [epoch: 20.9 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09852947162252075		[learning rate: 0.001844]
	Learning Rate: 0.00184404
	LOSS [training: 0.09852947162252075 | validation: 0.1619077225783086]
	TIME [epoch: 20.9 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09199054231602825		[learning rate: 0.0018359]
	Learning Rate: 0.00183589
	LOSS [training: 0.09199054231602825 | validation: 0.16636853753610434]
	TIME [epoch: 20.9 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09645599345838055		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.09645599345838055 | validation: 0.15495274137375042]
	TIME [epoch: 20.9 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09535204647666191		[learning rate: 0.0018197]
	Learning Rate: 0.0018197
	LOSS [training: 0.09535204647666191 | validation: 0.15828469561295863]
	TIME [epoch: 20.9 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09191063846036401		[learning rate: 0.0018117]
	Learning Rate: 0.00181166
	LOSS [training: 0.09191063846036401 | validation: 0.14796040581621245]
	TIME [epoch: 20.9 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09810011364272145		[learning rate: 0.0018037]
	Learning Rate: 0.00180366
	LOSS [training: 0.09810011364272145 | validation: 0.16391072115568692]
	TIME [epoch: 21 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09577239266405499		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.09577239266405499 | validation: 0.15623819543396308]
	TIME [epoch: 20.9 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10131996299782928		[learning rate: 0.0017878]
	Learning Rate: 0.00178775
	LOSS [training: 0.10131996299782928 | validation: 0.17776085326746663]
	TIME [epoch: 20.9 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08948560527814		[learning rate: 0.0017799]
	Learning Rate: 0.00177985
	LOSS [training: 0.08948560527814 | validation: 0.1639394244159065]
	TIME [epoch: 20.9 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09475976119169893		[learning rate: 0.001772]
	Learning Rate: 0.00177199
	LOSS [training: 0.09475976119169893 | validation: 0.15580276570345392]
	TIME [epoch: 20.9 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09522199497416131		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.09522199497416131 | validation: 0.16359972163927972]
	TIME [epoch: 20.9 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09572144640087911		[learning rate: 0.0017564]
	Learning Rate: 0.00175637
	LOSS [training: 0.09572144640087911 | validation: 0.17290358109792006]
	TIME [epoch: 20.9 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08712045824740901		[learning rate: 0.0017486]
	Learning Rate: 0.00174861
	LOSS [training: 0.08712045824740901 | validation: 0.16491952565648318]
	TIME [epoch: 20.9 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09095129742007683		[learning rate: 0.0017409]
	Learning Rate: 0.00174088
	LOSS [training: 0.09095129742007683 | validation: 0.17599716713156946]
	TIME [epoch: 20.9 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09316767735467683		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.09316767735467683 | validation: 0.1533225936450665]
	TIME [epoch: 20.9 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09334747070814478		[learning rate: 0.0017255]
	Learning Rate: 0.00172553
	LOSS [training: 0.09334747070814478 | validation: 0.1605780572812895]
	TIME [epoch: 20.9 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09248993706811871		[learning rate: 0.0017179]
	Learning Rate: 0.00171791
	LOSS [training: 0.09248993706811871 | validation: 0.17208062362644044]
	TIME [epoch: 20.9 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09591408152049721		[learning rate: 0.0017103]
	Learning Rate: 0.00171032
	LOSS [training: 0.09591408152049721 | validation: 0.15994153879325074]
	TIME [epoch: 20.9 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09492698111567366		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.09492698111567366 | validation: 0.16424325017977823]
	TIME [epoch: 21 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09730062505820877		[learning rate: 0.0016952]
	Learning Rate: 0.00169524
	LOSS [training: 0.09730062505820877 | validation: 0.1454229473142962]
	TIME [epoch: 20.9 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09224894330150432		[learning rate: 0.0016877]
	Learning Rate: 0.00168775
	LOSS [training: 0.09224894330150432 | validation: 0.16556258999122087]
	TIME [epoch: 20.9 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08518271886971109		[learning rate: 0.0016803]
	Learning Rate: 0.00168029
	LOSS [training: 0.08518271886971109 | validation: 0.16434585632833415]
	TIME [epoch: 20.9 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0936260134530893		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.0936260134530893 | validation: 0.15906106188613714]
	TIME [epoch: 20.9 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09709445774545467		[learning rate: 0.0016655]
	Learning Rate: 0.00166548
	LOSS [training: 0.09709445774545467 | validation: 0.1541923991719992]
	TIME [epoch: 20.9 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09708740791035841		[learning rate: 0.0016581]
	Learning Rate: 0.00165812
	LOSS [training: 0.09708740791035841 | validation: 0.1510266779324991]
	TIME [epoch: 20.9 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09295815760013951		[learning rate: 0.0016508]
	Learning Rate: 0.00165079
	LOSS [training: 0.09295815760013951 | validation: 0.1560659150786777]
	TIME [epoch: 20.9 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08987467115858742		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.08987467115858742 | validation: 0.15939798345217626]
	TIME [epoch: 20.9 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09739215086786188		[learning rate: 0.0016362]
	Learning Rate: 0.00163624
	LOSS [training: 0.09739215086786188 | validation: 0.16496741338347276]
	TIME [epoch: 20.8 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08365544380823775		[learning rate: 0.001629]
	Learning Rate: 0.00162901
	LOSS [training: 0.08365544380823775 | validation: 0.16590695566059352]
	TIME [epoch: 20.8 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0898444479555424		[learning rate: 0.0016218]
	Learning Rate: 0.00162181
	LOSS [training: 0.0898444479555424 | validation: 0.15437435644287867]
	TIME [epoch: 20.9 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09760959915521925		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.09760959915521925 | validation: 0.14271753291173647]
	TIME [epoch: 20.9 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09364425445827165		[learning rate: 0.0016075]
	Learning Rate: 0.00160751
	LOSS [training: 0.09364425445827165 | validation: 0.14586930637241324]
	TIME [epoch: 20.9 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0908210699142091		[learning rate: 0.0016004]
	Learning Rate: 0.00160041
	LOSS [training: 0.0908210699142091 | validation: 0.17035630732235488]
	TIME [epoch: 20.9 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09272561210846866		[learning rate: 0.0015933]
	Learning Rate: 0.00159334
	LOSS [training: 0.09272561210846866 | validation: 0.1439163534240833]
	TIME [epoch: 20.9 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08824840843753805		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.08824840843753805 | validation: 0.15221534802096523]
	TIME [epoch: 20.9 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09255831300879167		[learning rate: 0.0015793]
	Learning Rate: 0.00157929
	LOSS [training: 0.09255831300879167 | validation: 0.14927808285865554]
	TIME [epoch: 20.9 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09833326770777903		[learning rate: 0.0015723]
	Learning Rate: 0.00157231
	LOSS [training: 0.09833326770777903 | validation: 0.1434680403287601]
	TIME [epoch: 20.9 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09800616813626091		[learning rate: 0.0015654]
	Learning Rate: 0.00156536
	LOSS [training: 0.09800616813626091 | validation: 0.17556683564579467]
	TIME [epoch: 20.9 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09215588497463456		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.09215588497463456 | validation: 0.15580476028182802]
	TIME [epoch: 21 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08736800429811381		[learning rate: 0.0015516]
	Learning Rate: 0.00155156
	LOSS [training: 0.08736800429811381 | validation: 0.16470308957085994]
	TIME [epoch: 20.9 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09895067925424705		[learning rate: 0.0015447]
	Learning Rate: 0.00154471
	LOSS [training: 0.09895067925424705 | validation: 0.16834759865843144]
	TIME [epoch: 20.9 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0880934563117628		[learning rate: 0.0015379]
	Learning Rate: 0.00153788
	LOSS [training: 0.0880934563117628 | validation: 0.15870551689566065]
	TIME [epoch: 21 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09564357929779572		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.09564357929779572 | validation: 0.1652657049407368]
	TIME [epoch: 21 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08809466646853144		[learning rate: 0.0015243]
	Learning Rate: 0.00152432
	LOSS [training: 0.08809466646853144 | validation: 0.15548137406443105]
	TIME [epoch: 20.9 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09548854978589544		[learning rate: 0.0015176]
	Learning Rate: 0.00151759
	LOSS [training: 0.09548854978589544 | validation: 0.15497985796171118]
	TIME [epoch: 20.9 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09919947111433183		[learning rate: 0.0015109]
	Learning Rate: 0.00151088
	LOSS [training: 0.09919947111433183 | validation: 0.1626987811064785]
	TIME [epoch: 20.9 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09043534247859762		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.09043534247859762 | validation: 0.1697999349651927]
	TIME [epoch: 20.9 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10173416813522689		[learning rate: 0.0014976]
	Learning Rate: 0.00149756
	LOSS [training: 0.10173416813522689 | validation: 0.15074041414054004]
	TIME [epoch: 20.9 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09250303929603765		[learning rate: 0.0014909]
	Learning Rate: 0.00149094
	LOSS [training: 0.09250303929603765 | validation: 0.15710747227938143]
	TIME [epoch: 20.9 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09244140632491152		[learning rate: 0.0014844]
	Learning Rate: 0.00148436
	LOSS [training: 0.09244140632491152 | validation: 0.16232334366026588]
	TIME [epoch: 20.9 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10525961877282856		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.10525961877282856 | validation: 0.1403515887254966]
	TIME [epoch: 20.9 sec]
	Saving model to: out/model_training/model_facs_dec2a_2d_v1_20240622_095511/states/model_facs_dec2a_2d_v1_472.pth
	Model improved!!!
EPOCH 473/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09809012593666253		[learning rate: 0.0014713]
	Learning Rate: 0.00147127
	LOSS [training: 0.09809012593666253 | validation: 0.15411555948560157]
	TIME [epoch: 21 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0919483067099458		[learning rate: 0.0014648]
	Learning Rate: 0.00146477
	LOSS [training: 0.0919483067099458 | validation: 0.16114113766911406]
	TIME [epoch: 20.9 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09161781064536749		[learning rate: 0.0014583]
	Learning Rate: 0.0014583
	LOSS [training: 0.09161781064536749 | validation: 0.14747785464465946]
	TIME [epoch: 20.9 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09457818689192304		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.09457818689192304 | validation: 0.14812268688682126]
	TIME [epoch: 20.9 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10054490416880775		[learning rate: 0.0014454]
	Learning Rate: 0.00144544
	LOSS [training: 0.10054490416880775 | validation: 0.14839641041454937]
	TIME [epoch: 20.9 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11120019686510547		[learning rate: 0.0014391]
	Learning Rate: 0.00143905
	LOSS [training: 0.11120019686510547 | validation: 0.151763808496616]
	TIME [epoch: 20.9 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09367543170811823		[learning rate: 0.0014327]
	Learning Rate: 0.0014327
	LOSS [training: 0.09367543170811823 | validation: 0.1589301919800178]
	TIME [epoch: 20.9 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0836423803950408		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.0836423803950408 | validation: 0.15897028061534196]
	TIME [epoch: 20.9 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08752350322248621		[learning rate: 0.0014201]
	Learning Rate: 0.00142006
	LOSS [training: 0.08752350322248621 | validation: 0.15984015301668691]
	TIME [epoch: 20.9 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09873453429150851		[learning rate: 0.0014138]
	Learning Rate: 0.00141379
	LOSS [training: 0.09873453429150851 | validation: 0.15669618158591844]
	TIME [epoch: 20.9 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09182626463757401		[learning rate: 0.0014075]
	Learning Rate: 0.00140754
	LOSS [training: 0.09182626463757401 | validation: 0.15110642942423727]
	TIME [epoch: 21 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08636030177293835		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.08636030177293835 | validation: 0.15350227963775417]
	TIME [epoch: 20.9 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09419869734921527		[learning rate: 0.0013951]
	Learning Rate: 0.00139513
	LOSS [training: 0.09419869734921527 | validation: 0.15947112839899247]
	TIME [epoch: 20.9 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09112767646677392		[learning rate: 0.001389]
	Learning Rate: 0.00138897
	LOSS [training: 0.09112767646677392 | validation: 0.16506364634372894]
	TIME [epoch: 20.9 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09646549141026672		[learning rate: 0.0013828]
	Learning Rate: 0.00138283
	LOSS [training: 0.09646549141026672 | validation: 0.15690917046182573]
	TIME [epoch: 20.9 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09563858357533205		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.09563858357533205 | validation: 0.15658001717209732]
	TIME [epoch: 20.9 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09663244500040356		[learning rate: 0.0013706]
	Learning Rate: 0.00137064
	LOSS [training: 0.09663244500040356 | validation: 0.15415211229449988]
	TIME [epoch: 20.9 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09105064597277723		[learning rate: 0.0013646]
	Learning Rate: 0.00136458
	LOSS [training: 0.09105064597277723 | validation: 0.1575241135096236]
	TIME [epoch: 20.9 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09938818716879053		[learning rate: 0.0013586]
	Learning Rate: 0.00135855
	LOSS [training: 0.09938818716879053 | validation: 0.1486754465586247]
	TIME [epoch: 20.8 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09674071381523741		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.09674071381523741 | validation: 0.15109248395655786]
	TIME [epoch: 20.8 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09382281556481098		[learning rate: 0.0013466]
	Learning Rate: 0.00134658
	LOSS [training: 0.09382281556481098 | validation: 0.1569152219899495]
	TIME [epoch: 20.8 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09087515590311104		[learning rate: 0.0013406]
	Learning Rate: 0.00134063
	LOSS [training: 0.09087515590311104 | validation: 0.15833718118361387]
	TIME [epoch: 20.8 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09755608214239656		[learning rate: 0.0013347]
	Learning Rate: 0.0013347
	LOSS [training: 0.09755608214239656 | validation: 0.16326786342034594]
	TIME [epoch: 20.8 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09092618703708123		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.09092618703708123 | validation: 0.1579946366797999]
	TIME [epoch: 20.8 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09174995663221985		[learning rate: 0.0013229]
	Learning Rate: 0.00132293
	LOSS [training: 0.09174995663221985 | validation: 0.15533867596578485]
	TIME [epoch: 20.8 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09815284472001408		[learning rate: 0.0013171]
	Learning Rate: 0.00131709
	LOSS [training: 0.09815284472001408 | validation: 0.16199916514356005]
	TIME [epoch: 20.8 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09035249735319872		[learning rate: 0.0013113]
	Learning Rate: 0.00131127
	LOSS [training: 0.09035249735319872 | validation: 0.1590835744700151]
	TIME [epoch: 20.8 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09013455352114799		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.09013455352114799 | validation: 0.1503804585968967]
	TIME [epoch: 20.9 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09576901911453903		[learning rate: 0.0012997]
	Learning Rate: 0.00129971
	LOSS [training: 0.09576901911453903 | validation: 0.16062059318897817]
	TIME [epoch: 20.9 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08875788501695796		[learning rate: 0.001294]
	Learning Rate: 0.00129397
	LOSS [training: 0.08875788501695796 | validation: 0.16240873357123897]
	TIME [epoch: 20.9 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09672221667760028		[learning rate: 0.0012882]
	Learning Rate: 0.00128825
	LOSS [training: 0.09672221667760028 | validation: 0.1518347182768897]
	TIME [epoch: 20.9 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09227282061394396		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.09227282061394396 | validation: 0.14254058679006767]
	TIME [epoch: 20.9 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08849396315552956		[learning rate: 0.0012769]
	Learning Rate: 0.00127689
	LOSS [training: 0.08849396315552956 | validation: 0.17214492682020177]
	TIME [epoch: 20.9 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09424359940771328		[learning rate: 0.0012712]
	Learning Rate: 0.00127125
	LOSS [training: 0.09424359940771328 | validation: 0.15678821666315665]
	TIME [epoch: 20.9 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09577719961322431		[learning rate: 0.0012656]
	Learning Rate: 0.00126563
	LOSS [training: 0.09577719961322431 | validation: 0.15401715243683864]
	TIME [epoch: 20.9 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0958679708532599		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.0958679708532599 | validation: 0.16342600715178743]
	TIME [epoch: 20.9 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0860781045194047		[learning rate: 0.0012545]
	Learning Rate: 0.00125447
	LOSS [training: 0.0860781045194047 | validation: 0.15145324075123942]
	TIME [epoch: 20.8 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09396605289772383		[learning rate: 0.0012489]
	Learning Rate: 0.00124893
	LOSS [training: 0.09396605289772383 | validation: 0.16073635929594535]
	TIME [epoch: 20.9 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09726767940075051		[learning rate: 0.0012434]
	Learning Rate: 0.00124341
	LOSS [training: 0.09726767940075051 | validation: 0.15937422903343634]
	TIME [epoch: 20.9 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09757045131078294		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.09757045131078294 | validation: 0.1495129099026532]
	TIME [epoch: 20.9 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09192108227734526		[learning rate: 0.0012324]
	Learning Rate: 0.00123245
	LOSS [training: 0.09192108227734526 | validation: 0.1683190589930106]
	TIME [epoch: 20.9 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09345947259232659		[learning rate: 0.001227]
	Learning Rate: 0.001227
	LOSS [training: 0.09345947259232659 | validation: 0.1515505239626462]
	TIME [epoch: 20.9 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08884163265734049		[learning rate: 0.0012216]
	Learning Rate: 0.00122158
	LOSS [training: 0.08884163265734049 | validation: 0.15810568851533946]
	TIME [epoch: 20.9 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09036557971123027		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.09036557971123027 | validation: 0.16445115987689649]
	TIME [epoch: 20.9 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09133915613569618		[learning rate: 0.0012108]
	Learning Rate: 0.00121081
	LOSS [training: 0.09133915613569618 | validation: 0.1631114731295466]
	TIME [epoch: 20.9 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09103053515942153		[learning rate: 0.0012055]
	Learning Rate: 0.00120546
	LOSS [training: 0.09103053515942153 | validation: 0.15264218971784915]
	TIME [epoch: 20.9 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09090222706552778		[learning rate: 0.0012001]
	Learning Rate: 0.00120014
	LOSS [training: 0.09090222706552778 | validation: 0.15428973088081813]
	TIME [epoch: 20.9 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08984575302655684		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.08984575302655684 | validation: 0.1501396025821387]
	TIME [epoch: 20.9 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09124364970622797		[learning rate: 0.0011896]
	Learning Rate: 0.00118956
	LOSS [training: 0.09124364970622797 | validation: 0.1625590238925693]
	TIME [epoch: 20.9 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0904987647654147		[learning rate: 0.0011843]
	Learning Rate: 0.0011843
	LOSS [training: 0.0904987647654147 | validation: 0.15851516251079695]
	TIME [epoch: 20.8 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09244983062832342		[learning rate: 0.0011791]
	Learning Rate: 0.00117907
	LOSS [training: 0.09244983062832342 | validation: 0.1567546205337412]
	TIME [epoch: 20.9 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09629669558189222		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.09629669558189222 | validation: 0.16418450653908861]
	TIME [epoch: 20.9 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10232638456674925		[learning rate: 0.0011687]
	Learning Rate: 0.00116867
	LOSS [training: 0.10232638456674925 | validation: 0.15205618624787737]
	TIME [epoch: 20.8 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08913659909007159		[learning rate: 0.0011635]
	Learning Rate: 0.00116351
	LOSS [training: 0.08913659909007159 | validation: 0.15421477059581232]
	TIME [epoch: 20.9 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09084094382236596		[learning rate: 0.0011584]
	Learning Rate: 0.00115837
	LOSS [training: 0.09084094382236596 | validation: 0.15547739398420624]
	TIME [epoch: 20.9 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10283224108720797		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.10283224108720797 | validation: 0.16045226600743395]
	TIME [epoch: 20.9 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08578905272114164		[learning rate: 0.0011482]
	Learning Rate: 0.00114815
	LOSS [training: 0.08578905272114164 | validation: 0.15455172916748736]
	TIME [epoch: 20.9 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09020927030191343		[learning rate: 0.0011431]
	Learning Rate: 0.00114308
	LOSS [training: 0.09020927030191343 | validation: 0.16870452600162913]
	TIME [epoch: 20.9 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08783452687525758		[learning rate: 0.001138]
	Learning Rate: 0.00113803
	LOSS [training: 0.08783452687525758 | validation: 0.15905518738744678]
	TIME [epoch: 20.9 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09308109394007784		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.09308109394007784 | validation: 0.15955604236579227]
	TIME [epoch: 20.8 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08563224888646301		[learning rate: 0.001128]
	Learning Rate: 0.001128
	LOSS [training: 0.08563224888646301 | validation: 0.14577028399848743]
	TIME [epoch: 20.9 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09963521694794372		[learning rate: 0.001123]
	Learning Rate: 0.00112301
	LOSS [training: 0.09963521694794372 | validation: 0.1665712843422661]
	TIME [epoch: 20.9 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10354219358449664		[learning rate: 0.0011181]
	Learning Rate: 0.00111805
	LOSS [training: 0.10354219358449664 | validation: 0.1569378418953871]
	TIME [epoch: 20.9 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09681839689579345		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.09681839689579345 | validation: 0.16098236529489354]
	TIME [epoch: 20.9 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09789424511816446		[learning rate: 0.0011082]
	Learning Rate: 0.00110819
	LOSS [training: 0.09789424511816446 | validation: 0.15993557761269797]
	TIME [epoch: 20.9 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0915451525955983		[learning rate: 0.0011033]
	Learning Rate: 0.0011033
	LOSS [training: 0.0915451525955983 | validation: 0.15923256826132523]
	TIME [epoch: 20.9 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09545887989663253		[learning rate: 0.0010984]
	Learning Rate: 0.00109842
	LOSS [training: 0.09545887989663253 | validation: 0.16983321511553917]
	TIME [epoch: 20.9 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09204062383103426		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.09204062383103426 | validation: 0.16213222229911914]
	TIME [epoch: 20.9 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09936890665926552		[learning rate: 0.0010887]
	Learning Rate: 0.00108874
	LOSS [training: 0.09936890665926552 | validation: 0.16374945932442847]
	TIME [epoch: 20.9 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08586537857281022		[learning rate: 0.0010839]
	Learning Rate: 0.00108393
	LOSS [training: 0.08586537857281022 | validation: 0.15449291945072458]
	TIME [epoch: 20.9 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08984784470950363		[learning rate: 0.0010791]
	Learning Rate: 0.00107914
	LOSS [training: 0.08984784470950363 | validation: 0.1530321332208898]
	TIME [epoch: 20.9 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09178989258749208		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.09178989258749208 | validation: 0.15799860105622915]
	TIME [epoch: 20.9 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09048668641897835		[learning rate: 0.0010696]
	Learning Rate: 0.00106962
	LOSS [training: 0.09048668641897835 | validation: 0.1485838257852143]
	TIME [epoch: 20.9 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09350031057221254		[learning rate: 0.0010649]
	Learning Rate: 0.0010649
	LOSS [training: 0.09350031057221254 | validation: 0.15417377232592713]
	TIME [epoch: 20.9 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08860031623084981		[learning rate: 0.0010602]
	Learning Rate: 0.00106019
	LOSS [training: 0.08860031623084981 | validation: 0.157289603335527]
	TIME [epoch: 20.9 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09465079507359583		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.09465079507359583 | validation: 0.16080580369986086]
	TIME [epoch: 20.8 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09133159029355327		[learning rate: 0.0010508]
	Learning Rate: 0.00105084
	LOSS [training: 0.09133159029355327 | validation: 0.14905524128516814]
	TIME [epoch: 20.9 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0971419904333158		[learning rate: 0.0010462]
	Learning Rate: 0.0010462
	LOSS [training: 0.0971419904333158 | validation: 0.16448332337602486]
	TIME [epoch: 20.9 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09131937191316794		[learning rate: 0.0010416]
	Learning Rate: 0.00104158
	LOSS [training: 0.09131937191316794 | validation: 0.16231812709112928]
	TIME [epoch: 20.9 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09860037248469684		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.09860037248469684 | validation: 0.16334251106215253]
	TIME [epoch: 20.8 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0942683107567378		[learning rate: 0.0010324]
	Learning Rate: 0.0010324
	LOSS [training: 0.0942683107567378 | validation: 0.15588644849901884]
	TIME [epoch: 20.9 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08302314540867438		[learning rate: 0.0010278]
	Learning Rate: 0.00102783
	LOSS [training: 0.08302314540867438 | validation: 0.15608072421069452]
	TIME [epoch: 20.9 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0942869357471405		[learning rate: 0.0010233]
	Learning Rate: 0.00102329
	LOSS [training: 0.0942869357471405 | validation: 0.1491798651662306]
	TIME [epoch: 20.8 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10121725083808533		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.10121725083808533 | validation: 0.1464384007142766]
	TIME [epoch: 20.9 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09467431598752671		[learning rate: 0.0010143]
	Learning Rate: 0.00101427
	LOSS [training: 0.09467431598752671 | validation: 0.14827664775327143]
	TIME [epoch: 20.9 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09773374132118136		[learning rate: 0.0010098]
	Learning Rate: 0.00100979
	LOSS [training: 0.09773374132118136 | validation: 0.15088263091669954]
	TIME [epoch: 20.9 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09425356178166837		[learning rate: 0.0010053]
	Learning Rate: 0.00100533
	LOSS [training: 0.09425356178166837 | validation: 0.16548626010704742]
	TIME [epoch: 20.9 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10075996796791231		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.10075996796791231 | validation: 0.15066270192632342]
	TIME [epoch: 20.9 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09105882682979587		[learning rate: 0.00099646]
	Learning Rate: 0.000996464
	LOSS [training: 0.09105882682979587 | validation: 0.15137154404205683]
	TIME [epoch: 20.9 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09049482446304537		[learning rate: 0.00099206]
	Learning Rate: 0.000992061
	LOSS [training: 0.09049482446304537 | validation: 0.1572135556466236]
	TIME [epoch: 21 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09087644242963792		[learning rate: 0.00098768]
	Learning Rate: 0.000987678
	LOSS [training: 0.09087644242963792 | validation: 0.1433698890974431]
	TIME [epoch: 20.9 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09369802206905878		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.09369802206905878 | validation: 0.1522585005646065]
	TIME [epoch: 20.9 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10167299891334385		[learning rate: 0.00097897]
	Learning Rate: 0.00097897
	LOSS [training: 0.10167299891334385 | validation: 0.15027627390618964]
	TIME [epoch: 20.9 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08702929748458559		[learning rate: 0.00097464]
	Learning Rate: 0.000974644
	LOSS [training: 0.08702929748458559 | validation: 0.14721476316008486]
	TIME [epoch: 20.9 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09708361934819695		[learning rate: 0.00097034]
	Learning Rate: 0.000970338
	LOSS [training: 0.09708361934819695 | validation: 0.15896115028003333]
	TIME [epoch: 20.9 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08767361983899716		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.08767361983899716 | validation: 0.16760325143574623]
	TIME [epoch: 20.9 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08785505601095048		[learning rate: 0.00096178]
	Learning Rate: 0.000961783
	LOSS [training: 0.08785505601095048 | validation: 0.15875961271815356]
	TIME [epoch: 20.9 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09233072522761235		[learning rate: 0.00095753]
	Learning Rate: 0.000957533
	LOSS [training: 0.09233072522761235 | validation: 0.16333406980898474]
	TIME [epoch: 20.9 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09616070057688708		[learning rate: 0.0009533]
	Learning Rate: 0.000953303
	LOSS [training: 0.09616070057688708 | validation: 0.16351480760822026]
	TIME [epoch: 20.9 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09206679690680075		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.09206679690680075 | validation: 0.15841992894243556]
	TIME [epoch: 20.9 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09389150493360715		[learning rate: 0.0009449]
	Learning Rate: 0.000944897
	LOSS [training: 0.09389150493360715 | validation: 0.15930249823989628]
	TIME [epoch: 20.9 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09224193926423374		[learning rate: 0.00094072]
	Learning Rate: 0.000940723
	LOSS [training: 0.09224193926423374 | validation: 0.15622842616763524]
	TIME [epoch: 20.9 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09426581253993836		[learning rate: 0.00093657]
	Learning Rate: 0.000936566
	LOSS [training: 0.09426581253993836 | validation: 0.1461813543497618]
	TIME [epoch: 20.9 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09099243996690305		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.09099243996690305 | validation: 0.1502407178158024]
	TIME [epoch: 20.9 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09244490421993776		[learning rate: 0.00092831]
	Learning Rate: 0.000928309
	LOSS [training: 0.09244490421993776 | validation: 0.14612472506518864]
	TIME [epoch: 20.9 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08768248684346241		[learning rate: 0.00092421]
	Learning Rate: 0.000924207
	LOSS [training: 0.08768248684346241 | validation: 0.15588689339886944]
	TIME [epoch: 20.9 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09080241692354411		[learning rate: 0.00092012]
	Learning Rate: 0.000920124
	LOSS [training: 0.09080241692354411 | validation: 0.15093080256626878]
	TIME [epoch: 20.9 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0882712577084762		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.0882712577084762 | validation: 0.15315997999281517]
	TIME [epoch: 20.9 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08814510677526696		[learning rate: 0.00091201]
	Learning Rate: 0.000912011
	LOSS [training: 0.08814510677526696 | validation: 0.15228667166925203]
	TIME [epoch: 20.9 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08783342485813705		[learning rate: 0.00090798]
	Learning Rate: 0.000907981
	LOSS [training: 0.08783342485813705 | validation: 0.1395530696726395]
	TIME [epoch: 20.9 sec]
	Saving model to: out/model_training/model_facs_dec2a_2d_v1_20240622_095511/states/model_facs_dec2a_2d_v1_582.pth
	Model improved!!!
EPOCH 583/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08582211220717567		[learning rate: 0.00090397]
	Learning Rate: 0.00090397
	LOSS [training: 0.08582211220717567 | validation: 0.1576620812430985]
	TIME [epoch: 21 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09409001239190513		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.09409001239190513 | validation: 0.16112415657492987]
	TIME [epoch: 20.9 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09663571260852874		[learning rate: 0.000896]
	Learning Rate: 0.000895999
	LOSS [training: 0.09663571260852874 | validation: 0.14687877688302658]
	TIME [epoch: 20.9 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08680493778468644		[learning rate: 0.00089204]
	Learning Rate: 0.000892041
	LOSS [training: 0.08680493778468644 | validation: 0.15185827621831666]
	TIME [epoch: 20.9 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08945028089968522		[learning rate: 0.0008881]
	Learning Rate: 0.000888099
	LOSS [training: 0.08945028089968522 | validation: 0.1579638304771681]
	TIME [epoch: 20.9 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08984598351615877		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.08984598351615877 | validation: 0.1599681521795474]
	TIME [epoch: 20.9 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09824993104853008		[learning rate: 0.00088027]
	Learning Rate: 0.000880269
	LOSS [training: 0.09824993104853008 | validation: 0.15697305922603835]
	TIME [epoch: 21 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09158536446866697		[learning rate: 0.00087638]
	Learning Rate: 0.00087638
	LOSS [training: 0.09158536446866697 | validation: 0.15775873787768632]
	TIME [epoch: 20.9 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09146525892792716		[learning rate: 0.00087251]
	Learning Rate: 0.000872508
	LOSS [training: 0.09146525892792716 | validation: 0.1529769668221201]
	TIME [epoch: 21 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09061928216674069		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.09061928216674069 | validation: 0.154007885317499]
	TIME [epoch: 21 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08439713459670409		[learning rate: 0.00086481]
	Learning Rate: 0.000864815
	LOSS [training: 0.08439713459670409 | validation: 0.1500357104825302]
	TIME [epoch: 21 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09472455032568719		[learning rate: 0.00086099]
	Learning Rate: 0.000860994
	LOSS [training: 0.09472455032568719 | validation: 0.15052087768854405]
	TIME [epoch: 21 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08427359907166469		[learning rate: 0.00085719]
	Learning Rate: 0.00085719
	LOSS [training: 0.08427359907166469 | validation: 0.15697489188177918]
	TIME [epoch: 21 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.090708769649783		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.090708769649783 | validation: 0.15510892858763428]
	TIME [epoch: 21 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0871394053918163		[learning rate: 0.00084963]
	Learning Rate: 0.000849632
	LOSS [training: 0.0871394053918163 | validation: 0.15292298293057333]
	TIME [epoch: 21 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08560381972589363		[learning rate: 0.00084588]
	Learning Rate: 0.000845878
	LOSS [training: 0.08560381972589363 | validation: 0.15450973367777726]
	TIME [epoch: 20.9 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09303157193546148		[learning rate: 0.00084214]
	Learning Rate: 0.000842141
	LOSS [training: 0.09303157193546148 | validation: 0.15829485947920247]
	TIME [epoch: 21 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08699357293256404		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.08699357293256404 | validation: 0.15478091865601576]
	TIME [epoch: 21 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08700031861642386		[learning rate: 0.00083472]
	Learning Rate: 0.000834715
	LOSS [training: 0.08700031861642386 | validation: 0.15475744974244113]
	TIME [epoch: 20.9 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09304153086606075		[learning rate: 0.00083103]
	Learning Rate: 0.000831028
	LOSS [training: 0.09304153086606075 | validation: 0.15686805864283593]
	TIME [epoch: 21 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09306236204511373		[learning rate: 0.00082736]
	Learning Rate: 0.000827356
	LOSS [training: 0.09306236204511373 | validation: 0.15935814893175418]
	TIME [epoch: 21 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08576592733596008		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.08576592733596008 | validation: 0.1574858212217502]
	TIME [epoch: 21 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08703031634945571		[learning rate: 0.00082006]
	Learning Rate: 0.000820061
	LOSS [training: 0.08703031634945571 | validation: 0.1546899425301356]
	TIME [epoch: 21 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08942695605028073		[learning rate: 0.00081644]
	Learning Rate: 0.000816438
	LOSS [training: 0.08942695605028073 | validation: 0.15831601462357148]
	TIME [epoch: 21 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08871809203752885		[learning rate: 0.00081283]
	Learning Rate: 0.000812831
	LOSS [training: 0.08871809203752885 | validation: 0.1518648671522579]
	TIME [epoch: 21 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08899407609870207		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.08899407609870207 | validation: 0.15752011729453608]
	TIME [epoch: 21 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08919027257859344		[learning rate: 0.00080566]
	Learning Rate: 0.000805664
	LOSS [training: 0.08919027257859344 | validation: 0.14666492334263354]
	TIME [epoch: 21 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08829705209635502		[learning rate: 0.0008021]
	Learning Rate: 0.000802104
	LOSS [training: 0.08829705209635502 | validation: 0.1600231592204825]
	TIME [epoch: 21 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09146780666733376		[learning rate: 0.00079856]
	Learning Rate: 0.00079856
	LOSS [training: 0.09146780666733376 | validation: 0.15921938247663453]
	TIME [epoch: 21 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09087492046260436		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.09087492046260436 | validation: 0.15794094711494025]
	TIME [epoch: 21.1 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0924209695879876		[learning rate: 0.00079152]
	Learning Rate: 0.000791519
	LOSS [training: 0.0924209695879876 | validation: 0.15075888995961775]
	TIME [epoch: 21 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08639408536189128		[learning rate: 0.00078802]
	Learning Rate: 0.000788022
	LOSS [training: 0.08639408536189128 | validation: 0.16071567441959306]
	TIME [epoch: 21 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08224958890719712		[learning rate: 0.00078454]
	Learning Rate: 0.000784541
	LOSS [training: 0.08224958890719712 | validation: 0.15793876947362698]
	TIME [epoch: 21 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09537170166735758		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.09537170166735758 | validation: 0.1600648405947685]
	TIME [epoch: 21 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0914513779410127		[learning rate: 0.00077762]
	Learning Rate: 0.000777623
	LOSS [training: 0.0914513779410127 | validation: 0.15245446616786673]
	TIME [epoch: 21 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09134207610873211		[learning rate: 0.00077419]
	Learning Rate: 0.000774188
	LOSS [training: 0.09134207610873211 | validation: 0.14863631970588848]
	TIME [epoch: 21 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08925575585348904		[learning rate: 0.00077077]
	Learning Rate: 0.000770767
	LOSS [training: 0.08925575585348904 | validation: 0.15534973400626967]
	TIME [epoch: 21 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09624982982974371		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.09624982982974371 | validation: 0.1609782308499583]
	TIME [epoch: 21 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09109475786517955		[learning rate: 0.00076397]
	Learning Rate: 0.000763971
	LOSS [training: 0.09109475786517955 | validation: 0.15818213840729242]
	TIME [epoch: 21 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09017956743589586		[learning rate: 0.0007606]
	Learning Rate: 0.000760596
	LOSS [training: 0.09017956743589586 | validation: 0.1512381740776127]
	TIME [epoch: 21.1 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09203131625471837		[learning rate: 0.00075724]
	Learning Rate: 0.000757235
	LOSS [training: 0.09203131625471837 | validation: 0.1488895565773945]
	TIME [epoch: 21 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09701540554021923		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.09701540554021923 | validation: 0.14922388557294222]
	TIME [epoch: 21 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08387771425104633		[learning rate: 0.00075056]
	Learning Rate: 0.000750559
	LOSS [training: 0.08387771425104633 | validation: 0.14740999978297403]
	TIME [epoch: 21 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09340534346130416		[learning rate: 0.00074724]
	Learning Rate: 0.000747242
	LOSS [training: 0.09340534346130416 | validation: 0.16011494962750664]
	TIME [epoch: 21 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09077956742688961		[learning rate: 0.00074394]
	Learning Rate: 0.000743941
	LOSS [training: 0.09077956742688961 | validation: 0.15082375947595425]
	TIME [epoch: 21 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09066324637459265		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.09066324637459265 | validation: 0.1452567340566361]
	TIME [epoch: 21 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09252219038959533		[learning rate: 0.00073738]
	Learning Rate: 0.000737382
	LOSS [training: 0.09252219038959533 | validation: 0.15251213115896192]
	TIME [epoch: 21 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08751389814055574		[learning rate: 0.00073412]
	Learning Rate: 0.000734124
	LOSS [training: 0.08751389814055574 | validation: 0.14920595437323447]
	TIME [epoch: 20.9 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10015531055279739		[learning rate: 0.00073088]
	Learning Rate: 0.00073088
	LOSS [training: 0.10015531055279739 | validation: 0.15435744499595866]
	TIME [epoch: 21 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0825626945978292		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 0.0825626945978292 | validation: 0.16847240877090852]
	TIME [epoch: 21 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09062822362053122		[learning rate: 0.00072444]
	Learning Rate: 0.000724436
	LOSS [training: 0.09062822362053122 | validation: 0.1583928997620248]
	TIME [epoch: 21 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08926388719174941		[learning rate: 0.00072124]
	Learning Rate: 0.000721235
	LOSS [training: 0.08926388719174941 | validation: 0.15106123329201887]
	TIME [epoch: 21 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08639747753165979		[learning rate: 0.00071805]
	Learning Rate: 0.000718049
	LOSS [training: 0.08639747753165979 | validation: 0.15273217607984527]
	TIME [epoch: 21 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10088284580217673		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.10088284580217673 | validation: 0.16120600294970755]
	TIME [epoch: 21 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08927359548348271		[learning rate: 0.00071172]
	Learning Rate: 0.000711718
	LOSS [training: 0.08927359548348271 | validation: 0.14852823826644204]
	TIME [epoch: 21 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08730156913339256		[learning rate: 0.00070857]
	Learning Rate: 0.000708573
	LOSS [training: 0.08730156913339256 | validation: 0.14124776071601144]
	TIME [epoch: 20.9 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0855428257008755		[learning rate: 0.00070544]
	Learning Rate: 0.000705442
	LOSS [training: 0.0855428257008755 | validation: 0.1606534661261693]
	TIME [epoch: 21 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09050628564774758		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.09050628564774758 | validation: 0.16795523116082733]
	TIME [epoch: 20.9 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09218344213143746		[learning rate: 0.00069922]
	Learning Rate: 0.000699222
	LOSS [training: 0.09218344213143746 | validation: 0.1577795237850713]
	TIME [epoch: 21 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09535281700989626		[learning rate: 0.00069613]
	Learning Rate: 0.000696133
	LOSS [training: 0.09535281700989626 | validation: 0.15421740263900424]
	TIME [epoch: 21 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10396322750862075		[learning rate: 0.00069306]
	Learning Rate: 0.000693058
	LOSS [training: 0.10396322750862075 | validation: 0.15526529742011105]
	TIME [epoch: 20.9 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09176282172750581		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 0.09176282172750581 | validation: 0.159283811652361]
	TIME [epoch: 21 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08390441452019295		[learning rate: 0.00068695]
	Learning Rate: 0.000686947
	LOSS [training: 0.08390441452019295 | validation: 0.15681723513572238]
	TIME [epoch: 21 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0897645533963922		[learning rate: 0.00068391]
	Learning Rate: 0.000683912
	LOSS [training: 0.0897645533963922 | validation: 0.15824773830811273]
	TIME [epoch: 21 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09878183249876246		[learning rate: 0.00068089]
	Learning Rate: 0.00068089
	LOSS [training: 0.09878183249876246 | validation: 0.15102212036792315]
	TIME [epoch: 20.9 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08767121426240261		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 0.08767121426240261 | validation: 0.16333373009031477]
	TIME [epoch: 21 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0912478675222826		[learning rate: 0.00067489]
	Learning Rate: 0.000674887
	LOSS [training: 0.0912478675222826 | validation: 0.1556998741738621]
	TIME [epoch: 21 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09216930873780615		[learning rate: 0.0006719]
	Learning Rate: 0.000671905
	LOSS [training: 0.09216930873780615 | validation: 0.1454238385571081]
	TIME [epoch: 21 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09305525839745754		[learning rate: 0.00066894]
	Learning Rate: 0.000668936
	LOSS [training: 0.09305525839745754 | validation: 0.1545954636708427]
	TIME [epoch: 21 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08857566512566264		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 0.08857566512566264 | validation: 0.15587234167146258]
	TIME [epoch: 21 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09042180256358183		[learning rate: 0.00066304]
	Learning Rate: 0.000663038
	LOSS [training: 0.09042180256358183 | validation: 0.16208231013202265]
	TIME [epoch: 20.8 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09321708135529701		[learning rate: 0.00066011]
	Learning Rate: 0.000660109
	LOSS [training: 0.09321708135529701 | validation: 0.14216633503174905]
	TIME [epoch: 20.8 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08821631051027991		[learning rate: 0.00065719]
	Learning Rate: 0.000657192
	LOSS [training: 0.08821631051027991 | validation: 0.1545644818387618]
	TIME [epoch: 20.8 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09167232507258352		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 0.09167232507258352 | validation: 0.1567690050205471]
	TIME [epoch: 21 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0877608089992186		[learning rate: 0.0006514]
	Learning Rate: 0.000651398
	LOSS [training: 0.0877608089992186 | validation: 0.16040834866051837]
	TIME [epoch: 21 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08581239185083242		[learning rate: 0.00064852]
	Learning Rate: 0.00064852
	LOSS [training: 0.08581239185083242 | validation: 0.15308650429648427]
	TIME [epoch: 20.9 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08863224667080448		[learning rate: 0.00064565]
	Learning Rate: 0.000645654
	LOSS [training: 0.08863224667080448 | validation: 0.15959222730572842]
	TIME [epoch: 21 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08966543378865954		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 0.08966543378865954 | validation: 0.15756626441436966]
	TIME [epoch: 21 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09318720293414343		[learning rate: 0.00063996]
	Learning Rate: 0.000639962
	LOSS [training: 0.09318720293414343 | validation: 0.15886599943535232]
	TIME [epoch: 21 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08871975057971995		[learning rate: 0.00063713]
	Learning Rate: 0.000637134
	LOSS [training: 0.08871975057971995 | validation: 0.1538628694129508]
	TIME [epoch: 21 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09424085823160562		[learning rate: 0.00063432]
	Learning Rate: 0.000634319
	LOSS [training: 0.09424085823160562 | validation: 0.15122072291532665]
	TIME [epoch: 21 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09148441105392302		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 0.09148441105392302 | validation: 0.15648955680572837]
	TIME [epoch: 21 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0872779285797489		[learning rate: 0.00062873]
	Learning Rate: 0.000628726
	LOSS [training: 0.0872779285797489 | validation: 0.15487405356534176]
	TIME [epoch: 21 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08906277982295924		[learning rate: 0.00062595]
	Learning Rate: 0.000625948
	LOSS [training: 0.08906277982295924 | validation: 0.15427847858672952]
	TIME [epoch: 21 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0928790987319155		[learning rate: 0.00062318]
	Learning Rate: 0.000623183
	LOSS [training: 0.0928790987319155 | validation: 0.15577265170844729]
	TIME [epoch: 21 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08178894340012045		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 0.08178894340012045 | validation: 0.15026789522367093]
	TIME [epoch: 20.9 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08891508134268318		[learning rate: 0.00061769]
	Learning Rate: 0.000617688
	LOSS [training: 0.08891508134268318 | validation: 0.15624551026181022]
	TIME [epoch: 21 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08829419792226044		[learning rate: 0.00061496]
	Learning Rate: 0.000614959
	LOSS [training: 0.08829419792226044 | validation: 0.15372419808943968]
	TIME [epoch: 20.9 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08510274355763436		[learning rate: 0.00061224]
	Learning Rate: 0.000612242
	LOSS [training: 0.08510274355763436 | validation: 0.16192577064631908]
	TIME [epoch: 21 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09545902887772953		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 0.09545902887772953 | validation: 0.14234447626973526]
	TIME [epoch: 21 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0863390100208046		[learning rate: 0.00060684]
	Learning Rate: 0.000606844
	LOSS [training: 0.0863390100208046 | validation: 0.14820351580737265]
	TIME [epoch: 20.9 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08894842091264248		[learning rate: 0.00060416]
	Learning Rate: 0.000604163
	LOSS [training: 0.08894842091264248 | validation: 0.15583072018522365]
	TIME [epoch: 21 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08589848436989636		[learning rate: 0.00060149]
	Learning Rate: 0.000601493
	LOSS [training: 0.08589848436989636 | validation: 0.16125791088556077]
	TIME [epoch: 21 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08935377713680275		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.08935377713680275 | validation: 0.16534086864291897]
	TIME [epoch: 21 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09164877832320298		[learning rate: 0.00059619]
	Learning Rate: 0.00059619
	LOSS [training: 0.09164877832320298 | validation: 0.1445127365358083]
	TIME [epoch: 21 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0872382113536968		[learning rate: 0.00059356]
	Learning Rate: 0.000593556
	LOSS [training: 0.0872382113536968 | validation: 0.16528078912595137]
	TIME [epoch: 21 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0907728331688579		[learning rate: 0.00059093]
	Learning Rate: 0.000590933
	LOSS [training: 0.0907728331688579 | validation: 0.1441182900857957]
	TIME [epoch: 21 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08854599713835958		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 0.08854599713835958 | validation: 0.15496054751227195]
	TIME [epoch: 21 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09596315032037264		[learning rate: 0.00058572]
	Learning Rate: 0.000585723
	LOSS [training: 0.09596315032037264 | validation: 0.15553914143366088]
	TIME [epoch: 20.9 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09044657688431064		[learning rate: 0.00058314]
	Learning Rate: 0.000583135
	LOSS [training: 0.09044657688431064 | validation: 0.1609197314633274]
	TIME [epoch: 21 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09252862481426234		[learning rate: 0.00058056]
	Learning Rate: 0.000580559
	LOSS [training: 0.09252862481426234 | validation: 0.15425746692609313]
	TIME [epoch: 20.9 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09135301603081296		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 0.09135301603081296 | validation: 0.155828568337336]
	TIME [epoch: 21 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09104188021519007		[learning rate: 0.00057544]
	Learning Rate: 0.00057544
	LOSS [training: 0.09104188021519007 | validation: 0.15627118748598093]
	TIME [epoch: 21 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08996702729766345		[learning rate: 0.0005729]
	Learning Rate: 0.000572898
	LOSS [training: 0.08996702729766345 | validation: 0.15413860335186272]
	TIME [epoch: 21 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09048773801169782		[learning rate: 0.00057037]
	Learning Rate: 0.000570366
	LOSS [training: 0.09048773801169782 | validation: 0.15967050245114991]
	TIME [epoch: 20.9 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08732850420331531		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 0.08732850420331531 | validation: 0.15257147769193707]
	TIME [epoch: 21 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09337112634111887		[learning rate: 0.00056534]
	Learning Rate: 0.000565337
	LOSS [training: 0.09337112634111887 | validation: 0.15580383115199198]
	TIME [epoch: 21 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.098022178852509		[learning rate: 0.00056284]
	Learning Rate: 0.00056284
	LOSS [training: 0.098022178852509 | validation: 0.15866137995150587]
	TIME [epoch: 20.9 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0852455624317039		[learning rate: 0.00056035]
	Learning Rate: 0.000560353
	LOSS [training: 0.0852455624317039 | validation: 0.15476233316590993]
	TIME [epoch: 21 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08487707450846287		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 0.08487707450846287 | validation: 0.1572043148647318]
	TIME [epoch: 21 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09357361606695065		[learning rate: 0.00055541]
	Learning Rate: 0.000555412
	LOSS [training: 0.09357361606695065 | validation: 0.1597955834514467]
	TIME [epoch: 20.9 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10090705625294956		[learning rate: 0.00055296]
	Learning Rate: 0.000552958
	LOSS [training: 0.10090705625294956 | validation: 0.16785208167571097]
	TIME [epoch: 21 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09179594610338286		[learning rate: 0.00055052]
	Learning Rate: 0.000550515
	LOSS [training: 0.09179594610338286 | validation: 0.1526439515296497]
	TIME [epoch: 21 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09631935824006846		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 0.09631935824006846 | validation: 0.14467359034689578]
	TIME [epoch: 21 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08937713473351266		[learning rate: 0.00054566]
	Learning Rate: 0.000545661
	LOSS [training: 0.08937713473351266 | validation: 0.14092366454745572]
	TIME [epoch: 21 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09085312516764525		[learning rate: 0.00054325]
	Learning Rate: 0.00054325
	LOSS [training: 0.09085312516764525 | validation: 0.15760188751829507]
	TIME [epoch: 20.9 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0935353517612417		[learning rate: 0.00054085]
	Learning Rate: 0.00054085
	LOSS [training: 0.0935353517612417 | validation: 0.1583235291733995]
	TIME [epoch: 21 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0823159899215574		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 0.0823159899215574 | validation: 0.15108492327880985]
	TIME [epoch: 20.9 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0975201799190572		[learning rate: 0.00053608]
	Learning Rate: 0.000536081
	LOSS [training: 0.0975201799190572 | validation: 0.15109388624359754]
	TIME [epoch: 21 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09176659880025342		[learning rate: 0.00053371]
	Learning Rate: 0.000533713
	LOSS [training: 0.09176659880025342 | validation: 0.15499124122972513]
	TIME [epoch: 21 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09058032429537324		[learning rate: 0.00053135]
	Learning Rate: 0.000531355
	LOSS [training: 0.09058032429537324 | validation: 0.15734540736285924]
	TIME [epoch: 20.8 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09212470033941841		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 0.09212470033941841 | validation: 0.15315558690161835]
	TIME [epoch: 20.8 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08503820298477227		[learning rate: 0.00052667]
	Learning Rate: 0.00052667
	LOSS [training: 0.08503820298477227 | validation: 0.15443550026189928]
	TIME [epoch: 20.8 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09075165971904495		[learning rate: 0.00052434]
	Learning Rate: 0.000524343
	LOSS [training: 0.09075165971904495 | validation: 0.14940972014322387]
	TIME [epoch: 20.8 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09004227125668475		[learning rate: 0.00052203]
	Learning Rate: 0.000522026
	LOSS [training: 0.09004227125668475 | validation: 0.14648049641365682]
	TIME [epoch: 20.8 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09370666621908633		[learning rate: 0.00051972]
	Learning Rate: 0.00051972
	LOSS [training: 0.09370666621908633 | validation: 0.14623075923464388]
	TIME [epoch: 20.8 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0879887961258678		[learning rate: 0.00051742]
	Learning Rate: 0.000517423
	LOSS [training: 0.0879887961258678 | validation: 0.14859006085006649]
	TIME [epoch: 20.8 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09024790786782415		[learning rate: 0.00051514]
	Learning Rate: 0.000515137
	LOSS [training: 0.09024790786782415 | validation: 0.1598844456195382]
	TIME [epoch: 20.8 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08980179307964438		[learning rate: 0.00051286]
	Learning Rate: 0.000512861
	LOSS [training: 0.08980179307964438 | validation: 0.15134927646353827]
	TIME [epoch: 20.8 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08893835667448004		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 0.08893835667448004 | validation: 0.1625697251070558]
	TIME [epoch: 20.8 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08092799125723682		[learning rate: 0.00050834]
	Learning Rate: 0.000508339
	LOSS [training: 0.08092799125723682 | validation: 0.16061069222791594]
	TIME [epoch: 20.9 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09093244062193634		[learning rate: 0.00050609]
	Learning Rate: 0.000506094
	LOSS [training: 0.09093244062193634 | validation: 0.15233140431257547]
	TIME [epoch: 20.9 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08521713607254348		[learning rate: 0.00050386]
	Learning Rate: 0.000503858
	LOSS [training: 0.08521713607254348 | validation: 0.1542666828250328]
	TIME [epoch: 20.8 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09495072370661531		[learning rate: 0.00050163]
	Learning Rate: 0.000501631
	LOSS [training: 0.09495072370661531 | validation: 0.15492769041268328]
	TIME [epoch: 20.8 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09515943361118073		[learning rate: 0.00049941]
	Learning Rate: 0.000499415
	LOSS [training: 0.09515943361118073 | validation: 0.1616873636010416]
	TIME [epoch: 20.8 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09333522059427238		[learning rate: 0.00049721]
	Learning Rate: 0.000497208
	LOSS [training: 0.09333522059427238 | validation: 0.15283470589975934]
	TIME [epoch: 20.8 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09161631288731147		[learning rate: 0.00049501]
	Learning Rate: 0.000495012
	LOSS [training: 0.09161631288731147 | validation: 0.15900106179865955]
	TIME [epoch: 20.8 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09244184216617306		[learning rate: 0.00049282]
	Learning Rate: 0.000492825
	LOSS [training: 0.09244184216617306 | validation: 0.15552684931564567]
	TIME [epoch: 20.9 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08321168015387378		[learning rate: 0.00049065]
	Learning Rate: 0.000490647
	LOSS [training: 0.08321168015387378 | validation: 0.15134000381557453]
	TIME [epoch: 20.8 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08670925396047455		[learning rate: 0.00048848]
	Learning Rate: 0.000488479
	LOSS [training: 0.08670925396047455 | validation: 0.1461927300466799]
	TIME [epoch: 20.8 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08928252545791196		[learning rate: 0.00048632]
	Learning Rate: 0.000486321
	LOSS [training: 0.08928252545791196 | validation: 0.16180993164382723]
	TIME [epoch: 20.9 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08859454678193876		[learning rate: 0.00048417]
	Learning Rate: 0.000484172
	LOSS [training: 0.08859454678193876 | validation: 0.15333119206062937]
	TIME [epoch: 20.8 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09305176757987108		[learning rate: 0.00048203]
	Learning Rate: 0.000482033
	LOSS [training: 0.09305176757987108 | validation: 0.15143691108673812]
	TIME [epoch: 20.8 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08889466523880099		[learning rate: 0.0004799]
	Learning Rate: 0.000479903
	LOSS [training: 0.08889466523880099 | validation: 0.14478039902426584]
	TIME [epoch: 20.8 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09981959402721197		[learning rate: 0.00047778]
	Learning Rate: 0.000477783
	LOSS [training: 0.09981959402721197 | validation: 0.15578548383132454]
	TIME [epoch: 20.8 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09265502286174991		[learning rate: 0.00047567]
	Learning Rate: 0.000475672
	LOSS [training: 0.09265502286174991 | validation: 0.15962384704446644]
	TIME [epoch: 20.8 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09021288182026851		[learning rate: 0.00047357]
	Learning Rate: 0.00047357
	LOSS [training: 0.09021288182026851 | validation: 0.1527092080021586]
	TIME [epoch: 20.8 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09147059700280835		[learning rate: 0.00047148]
	Learning Rate: 0.000471478
	LOSS [training: 0.09147059700280835 | validation: 0.14731840646708627]
	TIME [epoch: 20.8 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09349286950628942		[learning rate: 0.0004694]
	Learning Rate: 0.000469395
	LOSS [training: 0.09349286950628942 | validation: 0.15840164622229563]
	TIME [epoch: 20.8 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08993373926249257		[learning rate: 0.00046732]
	Learning Rate: 0.000467321
	LOSS [training: 0.08993373926249257 | validation: 0.14545561382839597]
	TIME [epoch: 20.8 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08576558575711173		[learning rate: 0.00046526]
	Learning Rate: 0.000465256
	LOSS [training: 0.08576558575711173 | validation: 0.15766901381325157]
	TIME [epoch: 20.8 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09026667618917084		[learning rate: 0.0004632]
	Learning Rate: 0.000463201
	LOSS [training: 0.09026667618917084 | validation: 0.15803900613744587]
	TIME [epoch: 20.8 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08773984677135338		[learning rate: 0.00046115]
	Learning Rate: 0.000461154
	LOSS [training: 0.08773984677135338 | validation: 0.1460124645004528]
	TIME [epoch: 20.8 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09393564963963312		[learning rate: 0.00045912]
	Learning Rate: 0.000459117
	LOSS [training: 0.09393564963963312 | validation: 0.14505086871971762]
	TIME [epoch: 20.8 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09086598802453678		[learning rate: 0.00045709]
	Learning Rate: 0.000457088
	LOSS [training: 0.09086598802453678 | validation: 0.15618462440758726]
	TIME [epoch: 20.9 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09765073166621636		[learning rate: 0.00045507]
	Learning Rate: 0.000455069
	LOSS [training: 0.09765073166621636 | validation: 0.15362352832602702]
	TIME [epoch: 20.8 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08659043415611654		[learning rate: 0.00045306]
	Learning Rate: 0.000453058
	LOSS [training: 0.08659043415611654 | validation: 0.14480719432177583]
	TIME [epoch: 20.8 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0895593236300251		[learning rate: 0.00045106]
	Learning Rate: 0.000451056
	LOSS [training: 0.0895593236300251 | validation: 0.1590583352770409]
	TIME [epoch: 20.8 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07639662942587512		[learning rate: 0.00044906]
	Learning Rate: 0.000449064
	LOSS [training: 0.07639662942587512 | validation: 0.14811014957268412]
	TIME [epoch: 20.8 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09742931776834152		[learning rate: 0.00044708]
	Learning Rate: 0.000447079
	LOSS [training: 0.09742931776834152 | validation: 0.15269936132131448]
	TIME [epoch: 20.8 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09140967603412466		[learning rate: 0.0004451]
	Learning Rate: 0.000445104
	LOSS [training: 0.09140967603412466 | validation: 0.152508034626292]
	TIME [epoch: 20.8 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09017257324841832		[learning rate: 0.00044314]
	Learning Rate: 0.000443138
	LOSS [training: 0.09017257324841832 | validation: 0.1507288880011222]
	TIME [epoch: 20.8 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09078839393287086		[learning rate: 0.00044118]
	Learning Rate: 0.00044118
	LOSS [training: 0.09078839393287086 | validation: 0.15535944304096921]
	TIME [epoch: 20.8 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09186839571493058		[learning rate: 0.00043923]
	Learning Rate: 0.00043923
	LOSS [training: 0.09186839571493058 | validation: 0.14693740558346602]
	TIME [epoch: 20.8 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09623125025710952		[learning rate: 0.00043729]
	Learning Rate: 0.00043729
	LOSS [training: 0.09623125025710952 | validation: 0.1629342468421688]
	TIME [epoch: 20.9 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09360602918008676		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 0.09360602918008676 | validation: 0.1561853627141385]
	TIME [epoch: 20.8 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09133249540914834		[learning rate: 0.00043343]
	Learning Rate: 0.000433434
	LOSS [training: 0.09133249540914834 | validation: 0.15581417656039112]
	TIME [epoch: 20.8 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09222517856116806		[learning rate: 0.00043152]
	Learning Rate: 0.000431519
	LOSS [training: 0.09222517856116806 | validation: 0.14669319854517843]
	TIME [epoch: 20.9 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08465594793123507		[learning rate: 0.00042961]
	Learning Rate: 0.000429613
	LOSS [training: 0.08465594793123507 | validation: 0.151147755043751]
	TIME [epoch: 20.8 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09086662936487556		[learning rate: 0.00042771]
	Learning Rate: 0.000427714
	LOSS [training: 0.09086662936487556 | validation: 0.13993649786103723]
	TIME [epoch: 20.8 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08842043598012035		[learning rate: 0.00042582]
	Learning Rate: 0.000425825
	LOSS [training: 0.08842043598012035 | validation: 0.15043452931152884]
	TIME [epoch: 20.8 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08462198764500264		[learning rate: 0.00042394]
	Learning Rate: 0.000423943
	LOSS [training: 0.08462198764500264 | validation: 0.14636399157904428]
	TIME [epoch: 20.9 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09379012989624655		[learning rate: 0.00042207]
	Learning Rate: 0.00042207
	LOSS [training: 0.09379012989624655 | validation: 0.14990410639514548]
	TIME [epoch: 20.8 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09279842504776084		[learning rate: 0.00042021]
	Learning Rate: 0.000420205
	LOSS [training: 0.09279842504776084 | validation: 0.1504860640800472]
	TIME [epoch: 20.8 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08982415713847143		[learning rate: 0.00041835]
	Learning Rate: 0.000418349
	LOSS [training: 0.08982415713847143 | validation: 0.16079681014738056]
	TIME [epoch: 20.8 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0858906067808498		[learning rate: 0.0004165]
	Learning Rate: 0.0004165
	LOSS [training: 0.0858906067808498 | validation: 0.156641388327721]
	TIME [epoch: 20.8 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09248630246736611		[learning rate: 0.00041466]
	Learning Rate: 0.00041466
	LOSS [training: 0.09248630246736611 | validation: 0.15172660807586796]
	TIME [epoch: 20.9 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09103865100200562		[learning rate: 0.00041283]
	Learning Rate: 0.000412828
	LOSS [training: 0.09103865100200562 | validation: 0.16340143925996076]
	TIME [epoch: 20.9 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08927934612324902		[learning rate: 0.000411]
	Learning Rate: 0.000411004
	LOSS [training: 0.08927934612324902 | validation: 0.14940535104417316]
	TIME [epoch: 20.8 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09038845023650663		[learning rate: 0.00040919]
	Learning Rate: 0.000409188
	LOSS [training: 0.09038845023650663 | validation: 0.15203302901688642]
	TIME [epoch: 20.8 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09151425464233295		[learning rate: 0.00040738]
	Learning Rate: 0.00040738
	LOSS [training: 0.09151425464233295 | validation: 0.1559854909640475]
	TIME [epoch: 20.8 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09213785296928087		[learning rate: 0.00040558]
	Learning Rate: 0.00040558
	LOSS [training: 0.09213785296928087 | validation: 0.14480838372617974]
	TIME [epoch: 20.8 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08961700193036007		[learning rate: 0.00040379]
	Learning Rate: 0.000403788
	LOSS [training: 0.08961700193036007 | validation: 0.1592132827178214]
	TIME [epoch: 20.8 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08986502690581488		[learning rate: 0.000402]
	Learning Rate: 0.000402004
	LOSS [training: 0.08986502690581488 | validation: 0.16676989547797527]
	TIME [epoch: 20.8 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08592664667003116		[learning rate: 0.00040023]
	Learning Rate: 0.000400228
	LOSS [training: 0.08592664667003116 | validation: 0.14978637978597575]
	TIME [epoch: 20.8 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09343158317776452		[learning rate: 0.00039846]
	Learning Rate: 0.00039846
	LOSS [training: 0.09343158317776452 | validation: 0.14955482858870509]
	TIME [epoch: 20.8 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09599868657927665		[learning rate: 0.0003967]
	Learning Rate: 0.000396699
	LOSS [training: 0.09599868657927665 | validation: 0.16491908511684678]
	TIME [epoch: 20.8 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08706778590326357		[learning rate: 0.00039495]
	Learning Rate: 0.000394947
	LOSS [training: 0.08706778590326357 | validation: 0.15085327688696828]
	TIME [epoch: 20.8 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08780172711037607		[learning rate: 0.0003932]
	Learning Rate: 0.000393202
	LOSS [training: 0.08780172711037607 | validation: 0.15548095476517962]
	TIME [epoch: 20.9 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09021746385416766		[learning rate: 0.00039146]
	Learning Rate: 0.000391464
	LOSS [training: 0.09021746385416766 | validation: 0.14491004025491228]
	TIME [epoch: 20.8 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08655148737745307		[learning rate: 0.00038973]
	Learning Rate: 0.000389735
	LOSS [training: 0.08655148737745307 | validation: 0.1602893751339899]
	TIME [epoch: 20.9 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09302967733010406		[learning rate: 0.00038801]
	Learning Rate: 0.000388013
	LOSS [training: 0.09302967733010406 | validation: 0.15293022009300916]
	TIME [epoch: 20.8 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0833466446474895		[learning rate: 0.0003863]
	Learning Rate: 0.000386299
	LOSS [training: 0.0833466446474895 | validation: 0.1447033936722632]
	TIME [epoch: 20.8 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08683926823245175		[learning rate: 0.00038459]
	Learning Rate: 0.000384592
	LOSS [training: 0.08683926823245175 | validation: 0.1534286527651879]
	TIME [epoch: 20.8 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08786487448335127		[learning rate: 0.00038289]
	Learning Rate: 0.000382893
	LOSS [training: 0.08786487448335127 | validation: 0.16460524276926672]
	TIME [epoch: 20.8 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08375778670709681		[learning rate: 0.0003812]
	Learning Rate: 0.000381201
	LOSS [training: 0.08375778670709681 | validation: 0.14160855779785075]
	TIME [epoch: 20.8 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0863739361565075		[learning rate: 0.00037952]
	Learning Rate: 0.000379517
	LOSS [training: 0.0863739361565075 | validation: 0.15225874884707563]
	TIME [epoch: 20.8 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0946861008414294		[learning rate: 0.00037784]
	Learning Rate: 0.00037784
	LOSS [training: 0.0946861008414294 | validation: 0.1677199919079203]
	TIME [epoch: 20.8 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08764668764515508		[learning rate: 0.00037617]
	Learning Rate: 0.00037617
	LOSS [training: 0.08764668764515508 | validation: 0.15577183542604361]
	TIME [epoch: 20.8 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0931479931463838		[learning rate: 0.00037451]
	Learning Rate: 0.000374508
	LOSS [training: 0.0931479931463838 | validation: 0.1487183327292671]
	TIME [epoch: 20.8 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0910564070416652		[learning rate: 0.00037285]
	Learning Rate: 0.000372854
	LOSS [training: 0.0910564070416652 | validation: 0.14983168392800322]
	TIME [epoch: 20.8 sec]
	Saving model to: out/model_training/model_facs_dec2a_2d_v1_20240622_095511/states/model_facs_dec2a_2d_v1_783.pth
Halted early. No improvement in validation loss for 200 epochs.
Finished training in 16448.112 seconds.
