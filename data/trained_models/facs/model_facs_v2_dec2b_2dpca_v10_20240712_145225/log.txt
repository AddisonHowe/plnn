Args:
Namespace(name='model_facs_v2_dec2b_2dpca_v10', outdir='out/model_training/model_facs_v2_dec2b_2dpca_v10', training_data='data/training_data/facs_v2/pca/dec2_fitonsubset/transition2_subset_ce_pn_m_pc12/training', validation_data='data/training_data/facs_v2/pca/dec2_fitonsubset/transition2_subset_ce_pn_m_pc12/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=10, batch_size=50, patience=200, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, quadratic_a=1.0, quadratic_b=1.0, ndims=2, nparams=2, nsigs=2, ncells=400, ncells_sample=400, model_do_sample=False, dt=0.005, dt_schedule='stepped', dt_schedule_bounds=[500, 1000, 1500], dt_schedule_scales=[0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=True, sigma=0.4, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', kernel='multiscale', bw_range=[0.2, 0.5, 0.9, 1.1, 1.3, 1.5, 2.0], optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 243726298

Training model...

Saving initial model state to: out/model_training/model_facs_v2_dec2b_2dpca_v10_20240712_145225/states/model_facs_v2_dec2b_2dpca_v10_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7773180075685515		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7773180075685515 | validation: 0.7055903092925062]
	TIME [epoch: 36.2 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v10_20240712_145225/states/model_facs_v2_dec2b_2dpca_v10_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5626391554301537		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5626391554301537 | validation: 0.6439066144821307]
	TIME [epoch: 6.12 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v10_20240712_145225/states/model_facs_v2_dec2b_2dpca_v10_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.49862746479478937		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.49862746479478937 | validation: 0.6789145028644245]
	TIME [epoch: 6.16 sec]
EPOCH 4/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4838822591569478		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4838822591569478 | validation: 0.5621361528426045]
	TIME [epoch: 6.12 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v10_20240712_145225/states/model_facs_v2_dec2b_2dpca_v10_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42639646681994947		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.42639646681994947 | validation: 0.5308820417882333]
	TIME [epoch: 6.12 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v10_20240712_145225/states/model_facs_v2_dec2b_2dpca_v10_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44771819067417856		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.44771819067417856 | validation: 0.5252248997343518]
	TIME [epoch: 6.11 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v10_20240712_145225/states/model_facs_v2_dec2b_2dpca_v10_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3664708917514966		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3664708917514966 | validation: 0.5036839348578646]
	TIME [epoch: 6.12 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v10_20240712_145225/states/model_facs_v2_dec2b_2dpca_v10_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.331504863902822		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.331504863902822 | validation: 0.5001231537990576]
	TIME [epoch: 6.12 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v10_20240712_145225/states/model_facs_v2_dec2b_2dpca_v10_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4031968032453327		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4031968032453327 | validation: 0.46940905965750096]
	TIME [epoch: 6.12 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v10_20240712_145225/states/model_facs_v2_dec2b_2dpca_v10_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3341522362850332		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3341522362850332 | validation: 0.4635075621127247]
	TIME [epoch: 6.12 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v10_20240712_145225/states/model_facs_v2_dec2b_2dpca_v10_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.338477561069535		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.338477561069535 | validation: 0.4483303696841119]
	TIME [epoch: 6.12 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v10_20240712_145225/states/model_facs_v2_dec2b_2dpca_v10_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3176570410150528		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3176570410150528 | validation: 0.43892337927371133]
	TIME [epoch: 6.12 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v10_20240712_145225/states/model_facs_v2_dec2b_2dpca_v10_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32550754778114577		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.32550754778114577 | validation: 0.4334332088297795]
	TIME [epoch: 6.13 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v10_20240712_145225/states/model_facs_v2_dec2b_2dpca_v10_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28807190143837563		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.28807190143837563 | validation: 0.5435865148898735]
	TIME [epoch: 6.11 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3438148098742474		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3438148098742474 | validation: 0.42951875144733737]
	TIME [epoch: 6.11 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v10_20240712_145225/states/model_facs_v2_dec2b_2dpca_v10_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2816221218510095		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2816221218510095 | validation: 0.4414284569055916]
	TIME [epoch: 6.16 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3079472192351994		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3079472192351994 | validation: 0.4739624683813142]
	TIME [epoch: 6.11 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.313819511019897		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.313819511019897 | validation: 0.4004839235331929]
	TIME [epoch: 6.12 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v10_20240712_145225/states/model_facs_v2_dec2b_2dpca_v10_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32254475200994454		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.32254475200994454 | validation: 0.4270350358844881]
	TIME [epoch: 6.12 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2896744273049344		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2896744273049344 | validation: 0.4395961817089171]
	TIME [epoch: 6.11 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2702239529800956		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2702239529800956 | validation: 0.3758531623665487]
	TIME [epoch: 6.11 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v10_20240712_145225/states/model_facs_v2_dec2b_2dpca_v10_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2895691059592547		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2895691059592547 | validation: 0.38703622625445494]
	TIME [epoch: 6.12 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2947504217300527		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2947504217300527 | validation: 0.3897231373597311]
	TIME [epoch: 6.11 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2625333336848843		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2625333336848843 | validation: 0.3979173377283397]
	TIME [epoch: 6.1 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24434546014337255		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24434546014337255 | validation: 0.4132273270550405]
	TIME [epoch: 6.11 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2989756159225312		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2989756159225312 | validation: 0.4074125792620942]
	TIME [epoch: 6.11 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2832478414784193		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2832478414784193 | validation: 0.42163434641710157]
	TIME [epoch: 6.11 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2565439955601424		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2565439955601424 | validation: 0.42207036414570953]
	TIME [epoch: 6.11 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2581369194443022		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2581369194443022 | validation: 0.4725523634503626]
	TIME [epoch: 6.11 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31496466980138427		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.31496466980138427 | validation: 0.5111169233925695]
	TIME [epoch: 6.11 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32170904410009526		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.32170904410009526 | validation: 0.37029063094739295]
	TIME [epoch: 6.11 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v10_20240712_145225/states/model_facs_v2_dec2b_2dpca_v10_31.pth
	Model improved!!!
EPOCH 32/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2536120154552749		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2536120154552749 | validation: 0.3608326459870398]
	TIME [epoch: 6.12 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v10_20240712_145225/states/model_facs_v2_dec2b_2dpca_v10_32.pth
	Model improved!!!
EPOCH 33/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23526235077479124		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23526235077479124 | validation: 0.41323395773879434]
	TIME [epoch: 6.13 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2710379052701083		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2710379052701083 | validation: 0.38544207682637677]
	TIME [epoch: 6.12 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2770425209836762		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2770425209836762 | validation: 0.3834405295672109]
	TIME [epoch: 6.11 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24478180270436578		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24478180270436578 | validation: 0.3765426208721827]
	TIME [epoch: 6.11 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2574941553924064		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2574941553924064 | validation: 0.5421969004613464]
	TIME [epoch: 6.12 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.268415750813459		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.268415750813459 | validation: 0.5220245741578458]
	TIME [epoch: 6.11 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2896594735637441		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2896594735637441 | validation: 0.4112378077393246]
	TIME [epoch: 6.12 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26016636180247554		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.26016636180247554 | validation: 0.3796557768345586]
	TIME [epoch: 6.12 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25080271798920206		[learning rate: 0.0099646]
	Learning Rate: 0.00996464
	LOSS [training: 0.25080271798920206 | validation: 0.3305554567681861]
	TIME [epoch: 6.11 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v10_20240712_145225/states/model_facs_v2_dec2b_2dpca_v10_41.pth
	Model improved!!!
EPOCH 42/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23077572482465789		[learning rate: 0.0099206]
	Learning Rate: 0.00992061
	LOSS [training: 0.23077572482465789 | validation: 0.3597799124783916]
	TIME [epoch: 6.11 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27154271586744966		[learning rate: 0.0098768]
	Learning Rate: 0.00987678
	LOSS [training: 0.27154271586744966 | validation: 0.4731549109325089]
	TIME [epoch: 6.11 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2663123541658887		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 0.2663123541658887 | validation: 0.4186022440376006]
	TIME [epoch: 6.11 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29095265806054754		[learning rate: 0.0097897]
	Learning Rate: 0.0097897
	LOSS [training: 0.29095265806054754 | validation: 0.3891631079408006]
	TIME [epoch: 6.11 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28505550105247507		[learning rate: 0.0097464]
	Learning Rate: 0.00974644
	LOSS [training: 0.28505550105247507 | validation: 0.39889225258667316]
	TIME [epoch: 6.11 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29461598423682095		[learning rate: 0.0097034]
	Learning Rate: 0.00970338
	LOSS [training: 0.29461598423682095 | validation: 0.41310917904837346]
	TIME [epoch: 6.12 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2540681465795513		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 0.2540681465795513 | validation: 0.408091007502446]
	TIME [epoch: 6.11 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26756838518668563		[learning rate: 0.0096178]
	Learning Rate: 0.00961783
	LOSS [training: 0.26756838518668563 | validation: 0.4770304448422487]
	TIME [epoch: 6.1 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27330486968905543		[learning rate: 0.0095753]
	Learning Rate: 0.00957533
	LOSS [training: 0.27330486968905543 | validation: 0.46880691962537585]
	TIME [epoch: 6.11 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.339042178807972		[learning rate: 0.009533]
	Learning Rate: 0.00953303
	LOSS [training: 0.339042178807972 | validation: 0.4434144554226676]
	TIME [epoch: 6.11 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27603523326183754		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 0.27603523326183754 | validation: 0.3617620289147858]
	TIME [epoch: 6.11 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2702508840937396		[learning rate: 0.009449]
	Learning Rate: 0.00944897
	LOSS [training: 0.2702508840937396 | validation: 0.3649587828230225]
	TIME [epoch: 6.11 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22806724810298445		[learning rate: 0.0094072]
	Learning Rate: 0.00940722
	LOSS [training: 0.22806724810298445 | validation: 0.5004979891106798]
	TIME [epoch: 6.14 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32130351424872355		[learning rate: 0.0093657]
	Learning Rate: 0.00936566
	LOSS [training: 0.32130351424872355 | validation: 0.4506154377270982]
	TIME [epoch: 6.12 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30391088703611474		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 0.30391088703611474 | validation: 0.39604450803092905]
	TIME [epoch: 6.11 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24851107430083647		[learning rate: 0.0092831]
	Learning Rate: 0.00928308
	LOSS [training: 0.24851107430083647 | validation: 0.41256501455975636]
	TIME [epoch: 6.11 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25828997863785613		[learning rate: 0.0092421]
	Learning Rate: 0.00924207
	LOSS [training: 0.25828997863785613 | validation: 0.3874946439459282]
	TIME [epoch: 6.11 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24106680840272735		[learning rate: 0.0092012]
	Learning Rate: 0.00920124
	LOSS [training: 0.24106680840272735 | validation: 0.3849323373626074]
	TIME [epoch: 6.11 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2325407215255862		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 0.2325407215255862 | validation: 0.3735122090139622]
	TIME [epoch: 6.11 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.271344265308522		[learning rate: 0.0091201]
	Learning Rate: 0.00912011
	LOSS [training: 0.271344265308522 | validation: 0.3630319911167681]
	TIME [epoch: 6.11 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2680583197129125		[learning rate: 0.0090798]
	Learning Rate: 0.00907981
	LOSS [training: 0.2680583197129125 | validation: 0.3836797458350096]
	TIME [epoch: 6.12 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2908125089361803		[learning rate: 0.0090397]
	Learning Rate: 0.0090397
	LOSS [training: 0.2908125089361803 | validation: 0.49257564649451097]
	TIME [epoch: 6.11 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.371876787762006		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 0.371876787762006 | validation: 0.442967126774456]
	TIME [epoch: 6.1 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33199102759385274		[learning rate: 0.00896]
	Learning Rate: 0.00895999
	LOSS [training: 0.33199102759385274 | validation: 0.4293561243998748]
	TIME [epoch: 6.11 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28815705790268326		[learning rate: 0.0089204]
	Learning Rate: 0.00892041
	LOSS [training: 0.28815705790268326 | validation: 0.44163745934111964]
	TIME [epoch: 6.11 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2639569919738495		[learning rate: 0.008881]
	Learning Rate: 0.00888099
	LOSS [training: 0.2639569919738495 | validation: 0.36801594171778806]
	TIME [epoch: 6.11 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2574722747322823		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 0.2574722747322823 | validation: 0.4788678703559714]
	TIME [epoch: 6.11 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24599425477110343		[learning rate: 0.0088027]
	Learning Rate: 0.00880269
	LOSS [training: 0.24599425477110343 | validation: 0.3345696503561219]
	TIME [epoch: 6.12 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2224691124355364		[learning rate: 0.0087638]
	Learning Rate: 0.0087638
	LOSS [training: 0.2224691124355364 | validation: 0.585635728390342]
	TIME [epoch: 6.12 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28337528103075527		[learning rate: 0.0087251]
	Learning Rate: 0.00872508
	LOSS [training: 0.28337528103075527 | validation: 0.38395918444791]
	TIME [epoch: 6.11 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25289019735040136		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 0.25289019735040136 | validation: 0.40531750869337796]
	TIME [epoch: 6.11 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2573966646624805		[learning rate: 0.0086481]
	Learning Rate: 0.00864815
	LOSS [training: 0.2573966646624805 | validation: 0.3952041152200645]
	TIME [epoch: 6.1 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2534193848610309		[learning rate: 0.0086099]
	Learning Rate: 0.00860994
	LOSS [training: 0.2534193848610309 | validation: 0.35659914653519426]
	TIME [epoch: 6.11 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21130243870737503		[learning rate: 0.0085719]
	Learning Rate: 0.0085719
	LOSS [training: 0.21130243870737503 | validation: 0.4570095783431578]
	TIME [epoch: 6.11 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2365621141432798		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 0.2365621141432798 | validation: 0.35936030806079056]
	TIME [epoch: 6.11 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22126660074234525		[learning rate: 0.0084963]
	Learning Rate: 0.00849632
	LOSS [training: 0.22126660074234525 | validation: 0.3350145373377031]
	TIME [epoch: 6.12 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20516383988846315		[learning rate: 0.0084588]
	Learning Rate: 0.00845878
	LOSS [training: 0.20516383988846315 | validation: 0.33454574986490254]
	TIME [epoch: 6.11 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19804818926255902		[learning rate: 0.0084214]
	Learning Rate: 0.00842141
	LOSS [training: 0.19804818926255902 | validation: 0.3454995868069263]
	TIME [epoch: 6.11 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1970600760674304		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 0.1970600760674304 | validation: 0.3983641632370786]
	TIME [epoch: 6.11 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26586058999979634		[learning rate: 0.0083472]
	Learning Rate: 0.00834715
	LOSS [training: 0.26586058999979634 | validation: 0.34088017598076537]
	TIME [epoch: 6.14 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2674461612124108		[learning rate: 0.0083103]
	Learning Rate: 0.00831027
	LOSS [training: 0.2674461612124108 | validation: 0.34374134033058423]
	TIME [epoch: 6.14 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21782372804722136		[learning rate: 0.0082736]
	Learning Rate: 0.00827356
	LOSS [training: 0.21782372804722136 | validation: 0.38186320041702115]
	TIME [epoch: 6.11 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1992651968406997		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 0.1992651968406997 | validation: 0.3949179492235514]
	TIME [epoch: 6.12 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2692504484126589		[learning rate: 0.0082006]
	Learning Rate: 0.00820061
	LOSS [training: 0.2692504484126589 | validation: 0.3359871903143373]
	TIME [epoch: 6.11 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2239853643533733		[learning rate: 0.0081644]
	Learning Rate: 0.00816438
	LOSS [training: 0.2239853643533733 | validation: 0.3995794450008036]
	TIME [epoch: 6.11 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1997234892543192		[learning rate: 0.0081283]
	Learning Rate: 0.0081283
	LOSS [training: 0.1997234892543192 | validation: 0.3527936450698448]
	TIME [epoch: 6.11 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20733387300174924		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 0.20733387300174924 | validation: 0.3342050705875495]
	TIME [epoch: 6.11 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22566081630376916		[learning rate: 0.0080566]
	Learning Rate: 0.00805664
	LOSS [training: 0.22566081630376916 | validation: 0.331322330071374]
	TIME [epoch: 6.11 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22254587371953752		[learning rate: 0.008021]
	Learning Rate: 0.00802104
	LOSS [training: 0.22254587371953752 | validation: 0.3396457094265224]
	TIME [epoch: 6.11 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23645012817302535		[learning rate: 0.0079856]
	Learning Rate: 0.0079856
	LOSS [training: 0.23645012817302535 | validation: 0.3245855298341217]
	TIME [epoch: 6.12 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v10_20240712_145225/states/model_facs_v2_dec2b_2dpca_v10_91.pth
	Model improved!!!
EPOCH 92/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21130790075959985		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 0.21130790075959985 | validation: 0.32554336187555266]
	TIME [epoch: 6.12 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24572189159504707		[learning rate: 0.0079152]
	Learning Rate: 0.00791519
	LOSS [training: 0.24572189159504707 | validation: 0.327526362127054]
	TIME [epoch: 6.11 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23163536054644443		[learning rate: 0.0078802]
	Learning Rate: 0.00788022
	LOSS [training: 0.23163536054644443 | validation: 0.3353485017382151]
	TIME [epoch: 6.11 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23302910629732607		[learning rate: 0.0078454]
	Learning Rate: 0.00784541
	LOSS [training: 0.23302910629732607 | validation: 0.4147354455786535]
	TIME [epoch: 6.11 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24356120269884599		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 0.24356120269884599 | validation: 0.3542367853733595]
	TIME [epoch: 6.1 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21564237521866908		[learning rate: 0.0077762]
	Learning Rate: 0.00777623
	LOSS [training: 0.21564237521866908 | validation: 0.3520116910986729]
	TIME [epoch: 6.11 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24703062197383777		[learning rate: 0.0077419]
	Learning Rate: 0.00774188
	LOSS [training: 0.24703062197383777 | validation: 0.34843628485092615]
	TIME [epoch: 6.11 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21443356182930037		[learning rate: 0.0077077]
	Learning Rate: 0.00770767
	LOSS [training: 0.21443356182930037 | validation: 0.4299817859293392]
	TIME [epoch: 6.12 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2247337496502387		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 0.2247337496502387 | validation: 0.3660460164132469]
	TIME [epoch: 6.11 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21543829651954866		[learning rate: 0.0076397]
	Learning Rate: 0.00763971
	LOSS [training: 0.21543829651954866 | validation: 0.3250848836522857]
	TIME [epoch: 6.12 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21479378523219744		[learning rate: 0.007606]
	Learning Rate: 0.00760596
	LOSS [training: 0.21479378523219744 | validation: 0.3339109845983469]
	TIME [epoch: 6.11 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22030030121893046		[learning rate: 0.0075724]
	Learning Rate: 0.00757235
	LOSS [training: 0.22030030121893046 | validation: 0.3707177833420072]
	TIME [epoch: 6.11 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2169072888453297		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 0.2169072888453297 | validation: 0.3705561915043672]
	TIME [epoch: 6.1 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22530986536823386		[learning rate: 0.0075056]
	Learning Rate: 0.00750559
	LOSS [training: 0.22530986536823386 | validation: 0.3483992344041812]
	TIME [epoch: 6.11 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22469211770974687		[learning rate: 0.0074724]
	Learning Rate: 0.00747242
	LOSS [training: 0.22469211770974687 | validation: 0.31910596632152244]
	TIME [epoch: 6.12 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v10_20240712_145225/states/model_facs_v2_dec2b_2dpca_v10_106.pth
	Model improved!!!
EPOCH 107/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2291894173045849		[learning rate: 0.0074394]
	Learning Rate: 0.00743941
	LOSS [training: 0.2291894173045849 | validation: 0.40319634941738824]
	TIME [epoch: 6.11 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24749637005392572		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 0.24749637005392572 | validation: 0.3232632473799383]
	TIME [epoch: 6.11 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23533481972063788		[learning rate: 0.0073738]
	Learning Rate: 0.00737382
	LOSS [training: 0.23533481972063788 | validation: 0.36514443462837504]
	TIME [epoch: 6.11 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21993933065635168		[learning rate: 0.0073412]
	Learning Rate: 0.00734124
	LOSS [training: 0.21993933065635168 | validation: 0.30358653241964356]
	TIME [epoch: 6.11 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v10_20240712_145225/states/model_facs_v2_dec2b_2dpca_v10_110.pth
	Model improved!!!
EPOCH 111/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21891769049169799		[learning rate: 0.0073088]
	Learning Rate: 0.0073088
	LOSS [training: 0.21891769049169799 | validation: 0.3249006270344448]
	TIME [epoch: 6.11 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18576211145545266		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 0.18576211145545266 | validation: 0.34210008066537084]
	TIME [epoch: 6.11 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21414626435704393		[learning rate: 0.0072444]
	Learning Rate: 0.00724436
	LOSS [training: 0.21414626435704393 | validation: 0.3290186269779022]
	TIME [epoch: 6.11 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20877629318570473		[learning rate: 0.0072124]
	Learning Rate: 0.00721235
	LOSS [training: 0.20877629318570473 | validation: 0.3087085284472343]
	TIME [epoch: 6.11 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24453000049653362		[learning rate: 0.0071805]
	Learning Rate: 0.00718049
	LOSS [training: 0.24453000049653362 | validation: 0.32943586511559964]
	TIME [epoch: 6.1 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18378533498316502		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 0.18378533498316502 | validation: 0.3403615429872087]
	TIME [epoch: 6.1 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20955757596697994		[learning rate: 0.0071172]
	Learning Rate: 0.00711718
	LOSS [training: 0.20955757596697994 | validation: 0.3316963535482818]
	TIME [epoch: 6.1 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21100471407129043		[learning rate: 0.0070857]
	Learning Rate: 0.00708573
	LOSS [training: 0.21100471407129043 | validation: 0.30413429013615934]
	TIME [epoch: 6.11 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2183476826968866		[learning rate: 0.0070544]
	Learning Rate: 0.00705442
	LOSS [training: 0.2183476826968866 | validation: 0.3713236409932421]
	TIME [epoch: 6.11 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23410715360363493		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 0.23410715360363493 | validation: 0.34152041842619135]
	TIME [epoch: 6.1 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19657570173783068		[learning rate: 0.0069922]
	Learning Rate: 0.00699222
	LOSS [training: 0.19657570173783068 | validation: 0.3662815430610693]
	TIME [epoch: 6.12 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2048043525453073		[learning rate: 0.0069613]
	Learning Rate: 0.00696133
	LOSS [training: 0.2048043525453073 | validation: 0.3676661960026519]
	TIME [epoch: 6.11 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20194463936078916		[learning rate: 0.0069306]
	Learning Rate: 0.00693057
	LOSS [training: 0.20194463936078916 | validation: 0.33950216542611]
	TIME [epoch: 6.11 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21228362032575016		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 0.21228362032575016 | validation: 0.33879175428694186]
	TIME [epoch: 6.1 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21345315876417081		[learning rate: 0.0068695]
	Learning Rate: 0.00686947
	LOSS [training: 0.21345315876417081 | validation: 0.34239744276606504]
	TIME [epoch: 6.1 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19826689577835327		[learning rate: 0.0068391]
	Learning Rate: 0.00683912
	LOSS [training: 0.19826689577835327 | validation: 0.3199320537372803]
	TIME [epoch: 6.1 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21095476768372076		[learning rate: 0.0068089]
	Learning Rate: 0.0068089
	LOSS [training: 0.21095476768372076 | validation: 0.34544540093103165]
	TIME [epoch: 6.11 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20624426553185024		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 0.20624426553185024 | validation: 0.32111528819224283]
	TIME [epoch: 6.11 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20088094324752043		[learning rate: 0.0067489]
	Learning Rate: 0.00674887
	LOSS [training: 0.20088094324752043 | validation: 0.380621668551679]
	TIME [epoch: 6.11 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21712207946035605		[learning rate: 0.006719]
	Learning Rate: 0.00671905
	LOSS [training: 0.21712207946035605 | validation: 0.3287261100517474]
	TIME [epoch: 6.11 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21252947690861013		[learning rate: 0.0066894]
	Learning Rate: 0.00668936
	LOSS [training: 0.21252947690861013 | validation: 0.35488552191534983]
	TIME [epoch: 6.11 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2037685113770193		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 0.2037685113770193 | validation: 0.3253155851829348]
	TIME [epoch: 6.1 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19453007022538235		[learning rate: 0.0066304]
	Learning Rate: 0.00663038
	LOSS [training: 0.19453007022538235 | validation: 0.33165312792360235]
	TIME [epoch: 6.11 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19220043896788425		[learning rate: 0.0066011]
	Learning Rate: 0.00660109
	LOSS [training: 0.19220043896788425 | validation: 0.37909829161903763]
	TIME [epoch: 6.1 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21410421017540218		[learning rate: 0.0065719]
	Learning Rate: 0.00657192
	LOSS [training: 0.21410421017540218 | validation: 0.4403251302282861]
	TIME [epoch: 6.11 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21791805194476174		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 0.21791805194476174 | validation: 0.3687892081349363]
	TIME [epoch: 6.12 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21646044898776368		[learning rate: 0.006514]
	Learning Rate: 0.00651398
	LOSS [training: 0.21646044898776368 | validation: 0.33212741067940277]
	TIME [epoch: 6.1 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20641199240946792		[learning rate: 0.0064852]
	Learning Rate: 0.00648519
	LOSS [training: 0.20641199240946792 | validation: 0.31946351058356104]
	TIME [epoch: 6.13 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19245754606017496		[learning rate: 0.0064565]
	Learning Rate: 0.00645654
	LOSS [training: 0.19245754606017496 | validation: 0.33115045678575683]
	TIME [epoch: 6.1 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19908960080229493		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 0.19908960080229493 | validation: 0.3644260866453345]
	TIME [epoch: 6.1 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20370933030969055		[learning rate: 0.0063996]
	Learning Rate: 0.00639961
	LOSS [training: 0.20370933030969055 | validation: 0.314778533102613]
	TIME [epoch: 6.12 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2442016801517449		[learning rate: 0.0063713]
	Learning Rate: 0.00637134
	LOSS [training: 0.2442016801517449 | validation: 0.3284662095243348]
	TIME [epoch: 6.11 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22052727968708258		[learning rate: 0.0063432]
	Learning Rate: 0.00634319
	LOSS [training: 0.22052727968708258 | validation: 0.3131445452609462]
	TIME [epoch: 6.12 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18849341031800546		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 0.18849341031800546 | validation: 0.32780655355297283]
	TIME [epoch: 6.1 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19552703356963635		[learning rate: 0.0062873]
	Learning Rate: 0.00628726
	LOSS [training: 0.19552703356963635 | validation: 0.3290201585580994]
	TIME [epoch: 6.11 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2155130415537884		[learning rate: 0.0062595]
	Learning Rate: 0.00625948
	LOSS [training: 0.2155130415537884 | validation: 0.3012987857142503]
	TIME [epoch: 6.11 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v10_20240712_145225/states/model_facs_v2_dec2b_2dpca_v10_146.pth
	Model improved!!!
EPOCH 147/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2026101829902799		[learning rate: 0.0062318]
	Learning Rate: 0.00623183
	LOSS [training: 0.2026101829902799 | validation: 0.2984817305935678]
	TIME [epoch: 6.12 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v10_20240712_145225/states/model_facs_v2_dec2b_2dpca_v10_147.pth
	Model improved!!!
EPOCH 148/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20607132297328618		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 0.20607132297328618 | validation: 0.30675808736859506]
	TIME [epoch: 6.11 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1875530393335101		[learning rate: 0.0061769]
	Learning Rate: 0.00617688
	LOSS [training: 0.1875530393335101 | validation: 0.32234592787159444]
	TIME [epoch: 6.11 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20951907246021362		[learning rate: 0.0061496]
	Learning Rate: 0.00614959
	LOSS [training: 0.20951907246021362 | validation: 0.3220408188962722]
	TIME [epoch: 6.12 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19355064508357728		[learning rate: 0.0061224]
	Learning Rate: 0.00612242
	LOSS [training: 0.19355064508357728 | validation: 0.3371279354679055]
	TIME [epoch: 6.11 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19547405565501763		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 0.19547405565501763 | validation: 0.3427352997524813]
	TIME [epoch: 6.11 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2094049773834452		[learning rate: 0.0060684]
	Learning Rate: 0.00606844
	LOSS [training: 0.2094049773834452 | validation: 0.3239175956311404]
	TIME [epoch: 6.1 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20315018832875978		[learning rate: 0.0060416]
	Learning Rate: 0.00604163
	LOSS [training: 0.20315018832875978 | validation: 0.4154495850909186]
	TIME [epoch: 6.11 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24910337819017778		[learning rate: 0.0060149]
	Learning Rate: 0.00601493
	LOSS [training: 0.24910337819017778 | validation: 0.3913547685812178]
	TIME [epoch: 6.1 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3253466929777976		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 0.3253466929777976 | validation: 0.45659266074112026]
	TIME [epoch: 6.11 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28701860933553136		[learning rate: 0.0059619]
	Learning Rate: 0.0059619
	LOSS [training: 0.28701860933553136 | validation: 0.3652583219668096]
	TIME [epoch: 6.11 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22013486290525744		[learning rate: 0.0059356]
	Learning Rate: 0.00593556
	LOSS [training: 0.22013486290525744 | validation: 0.347331379935597]
	TIME [epoch: 6.12 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19416012925665022		[learning rate: 0.0059093]
	Learning Rate: 0.00590933
	LOSS [training: 0.19416012925665022 | validation: 0.3483578934954382]
	TIME [epoch: 6.11 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20272302557690428		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 0.20272302557690428 | validation: 0.33259689037808593]
	TIME [epoch: 6.11 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19186797683308124		[learning rate: 0.0058572]
	Learning Rate: 0.00585723
	LOSS [training: 0.19186797683308124 | validation: 0.33750748152429416]
	TIME [epoch: 6.1 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20105844946015847		[learning rate: 0.0058314]
	Learning Rate: 0.00583135
	LOSS [training: 0.20105844946015847 | validation: 0.307386046305319]
	TIME [epoch: 6.11 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18949197369838042		[learning rate: 0.0058056]
	Learning Rate: 0.00580559
	LOSS [training: 0.18949197369838042 | validation: 0.31618458320551746]
	TIME [epoch: 6.11 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19278965349837926		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 0.19278965349837926 | validation: 0.35826374983903475]
	TIME [epoch: 6.11 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18338810664985822		[learning rate: 0.0057544]
	Learning Rate: 0.0057544
	LOSS [training: 0.18338810664985822 | validation: 0.3307293240974373]
	TIME [epoch: 6.12 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18763156438678846		[learning rate: 0.005729]
	Learning Rate: 0.00572897
	LOSS [training: 0.18763156438678846 | validation: 0.4050412542128393]
	TIME [epoch: 6.12 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18728745366649177		[learning rate: 0.0057037]
	Learning Rate: 0.00570366
	LOSS [training: 0.18728745366649177 | validation: 0.345764438842799]
	TIME [epoch: 6.11 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19582507969205282		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 0.19582507969205282 | validation: 0.3948614751658685]
	TIME [epoch: 6.11 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19676240171430995		[learning rate: 0.0056534]
	Learning Rate: 0.00565337
	LOSS [training: 0.19676240171430995 | validation: 0.3638150387086496]
	TIME [epoch: 6.1 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20033513093009092		[learning rate: 0.0056284]
	Learning Rate: 0.0056284
	LOSS [training: 0.20033513093009092 | validation: 0.35128100793158845]
	TIME [epoch: 6.11 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21097291579021035		[learning rate: 0.0056035]
	Learning Rate: 0.00560353
	LOSS [training: 0.21097291579021035 | validation: 0.36094603429663624]
	TIME [epoch: 6.11 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2026483418602507		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 0.2026483418602507 | validation: 0.29455720907865346]
	TIME [epoch: 6.12 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v10_20240712_145225/states/model_facs_v2_dec2b_2dpca_v10_172.pth
	Model improved!!!
EPOCH 173/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18357541074809466		[learning rate: 0.0055541]
	Learning Rate: 0.00555412
	LOSS [training: 0.18357541074809466 | validation: 0.3759577046052804]
	TIME [epoch: 6.12 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2046935068287729		[learning rate: 0.0055296]
	Learning Rate: 0.00552958
	LOSS [training: 0.2046935068287729 | validation: 0.29774170833129954]
	TIME [epoch: 6.11 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18025649858604587		[learning rate: 0.0055052]
	Learning Rate: 0.00550515
	LOSS [training: 0.18025649858604587 | validation: 0.3001519132279417]
	TIME [epoch: 6.1 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18663586299692897		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 0.18663586299692897 | validation: 0.3529439656912025]
	TIME [epoch: 6.1 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1913343564915089		[learning rate: 0.0054566]
	Learning Rate: 0.00545661
	LOSS [training: 0.1913343564915089 | validation: 0.38270114298048]
	TIME [epoch: 6.11 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18819651455587585		[learning rate: 0.0054325]
	Learning Rate: 0.0054325
	LOSS [training: 0.18819651455587585 | validation: 0.3007312012189687]
	TIME [epoch: 6.1 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20023852637678813		[learning rate: 0.0054085]
	Learning Rate: 0.0054085
	LOSS [training: 0.20023852637678813 | validation: 0.32029499478605483]
	TIME [epoch: 6.11 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2008763560307023		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 0.2008763560307023 | validation: 0.31743446597583985]
	TIME [epoch: 6.11 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19619251172786129		[learning rate: 0.0053608]
	Learning Rate: 0.00536081
	LOSS [training: 0.19619251172786129 | validation: 0.32243503488360703]
	TIME [epoch: 6.1 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18955251880345		[learning rate: 0.0053371]
	Learning Rate: 0.00533713
	LOSS [training: 0.18955251880345 | validation: 0.2997231779951473]
	TIME [epoch: 6.1 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18544234598810735		[learning rate: 0.0053135]
	Learning Rate: 0.00531355
	LOSS [training: 0.18544234598810735 | validation: 0.3327288045414471]
	TIME [epoch: 6.11 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19827975099224845		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 0.19827975099224845 | validation: 0.32973653541451]
	TIME [epoch: 6.1 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18179991472284707		[learning rate: 0.0052667]
	Learning Rate: 0.0052667
	LOSS [training: 0.18179991472284707 | validation: 0.3374071720738194]
	TIME [epoch: 6.1 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1839445715069994		[learning rate: 0.0052434]
	Learning Rate: 0.00524343
	LOSS [training: 0.1839445715069994 | validation: 0.4197014726695958]
	TIME [epoch: 6.11 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2129498858430753		[learning rate: 0.0052203]
	Learning Rate: 0.00522026
	LOSS [training: 0.2129498858430753 | validation: 0.40940603621093896]
	TIME [epoch: 6.11 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19600187527817642		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 0.19600187527817642 | validation: 0.4179561600245408]
	TIME [epoch: 6.1 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19169153298207167		[learning rate: 0.0051742]
	Learning Rate: 0.00517423
	LOSS [training: 0.19169153298207167 | validation: 0.32536362732202995]
	TIME [epoch: 6.1 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19814885625655823		[learning rate: 0.0051514]
	Learning Rate: 0.00515137
	LOSS [training: 0.19814885625655823 | validation: 0.31044185845305905]
	TIME [epoch: 6.1 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1982306562948985		[learning rate: 0.0051286]
	Learning Rate: 0.00512861
	LOSS [training: 0.1982306562948985 | validation: 0.29133622014648214]
	TIME [epoch: 6.1 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v10_20240712_145225/states/model_facs_v2_dec2b_2dpca_v10_191.pth
	Model improved!!!
EPOCH 192/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17752006521091296		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 0.17752006521091296 | validation: 0.2917347047258333]
	TIME [epoch: 6.11 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18902481993981385		[learning rate: 0.0050834]
	Learning Rate: 0.00508339
	LOSS [training: 0.18902481993981385 | validation: 0.31418474118452616]
	TIME [epoch: 6.1 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17865334289956153		[learning rate: 0.0050609]
	Learning Rate: 0.00506093
	LOSS [training: 0.17865334289956153 | validation: 0.3132870517323237]
	TIME [epoch: 6.12 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18261326467499117		[learning rate: 0.0050386]
	Learning Rate: 0.00503857
	LOSS [training: 0.18261326467499117 | validation: 0.35574505778112897]
	TIME [epoch: 6.1 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22086354180774098		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 0.22086354180774098 | validation: 0.33085762105879946]
	TIME [epoch: 6.1 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18775360073045722		[learning rate: 0.0049941]
	Learning Rate: 0.00499415
	LOSS [training: 0.18775360073045722 | validation: 0.3399827037382643]
	TIME [epoch: 6.1 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1741825770030339		[learning rate: 0.0049721]
	Learning Rate: 0.00497208
	LOSS [training: 0.1741825770030339 | validation: 0.31730300564746833]
	TIME [epoch: 6.11 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17552469242355057		[learning rate: 0.0049501]
	Learning Rate: 0.00495012
	LOSS [training: 0.17552469242355057 | validation: 0.3001539955910614]
	TIME [epoch: 6.1 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18391913057618542		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 0.18391913057618542 | validation: 0.32914512634457915]
	TIME [epoch: 6.1 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1831422292986119		[learning rate: 0.0049065]
	Learning Rate: 0.00490647
	LOSS [training: 0.1831422292986119 | validation: 0.32680937780396463]
	TIME [epoch: 6.11 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17137805658425403		[learning rate: 0.0048848]
	Learning Rate: 0.00488479
	LOSS [training: 0.17137805658425403 | validation: 0.2995758061940696]
	TIME [epoch: 6.11 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18484780211859755		[learning rate: 0.0048632]
	Learning Rate: 0.00486321
	LOSS [training: 0.18484780211859755 | validation: 0.30768727626618714]
	TIME [epoch: 6.1 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17942436422361122		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 0.17942436422361122 | validation: 0.30914476687411496]
	TIME [epoch: 6.11 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18856838319637886		[learning rate: 0.0048203]
	Learning Rate: 0.00482033
	LOSS [training: 0.18856838319637886 | validation: 0.2867563005996081]
	TIME [epoch: 6.11 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v10_20240712_145225/states/model_facs_v2_dec2b_2dpca_v10_205.pth
	Model improved!!!
EPOCH 206/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1805977724950052		[learning rate: 0.004799]
	Learning Rate: 0.00479903
	LOSS [training: 0.1805977724950052 | validation: 0.37546185129753606]
	TIME [epoch: 6.11 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19515462285534785		[learning rate: 0.0047778]
	Learning Rate: 0.00477783
	LOSS [training: 0.19515462285534785 | validation: 0.3011694910444249]
	TIME [epoch: 6.11 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17338752869163906		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.17338752869163906 | validation: 0.3194255067262517]
	TIME [epoch: 6.11 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17308927123936121		[learning rate: 0.0047357]
	Learning Rate: 0.0047357
	LOSS [training: 0.17308927123936121 | validation: 0.33697044017407185]
	TIME [epoch: 6.12 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20160678078930597		[learning rate: 0.0047148]
	Learning Rate: 0.00471478
	LOSS [training: 0.20160678078930597 | validation: 0.31868948485632137]
	TIME [epoch: 6.13 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1881515994736674		[learning rate: 0.0046939]
	Learning Rate: 0.00469395
	LOSS [training: 0.1881515994736674 | validation: 0.297385209124573]
	TIME [epoch: 6.13 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1746630403987328		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 0.1746630403987328 | validation: 0.28391337333434274]
	TIME [epoch: 6.1 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v10_20240712_145225/states/model_facs_v2_dec2b_2dpca_v10_212.pth
	Model improved!!!
EPOCH 213/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16938719767575233		[learning rate: 0.0046526]
	Learning Rate: 0.00465256
	LOSS [training: 0.16938719767575233 | validation: 0.29914102993460134]
	TIME [epoch: 6.11 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18294547725297242		[learning rate: 0.004632]
	Learning Rate: 0.00463201
	LOSS [training: 0.18294547725297242 | validation: 0.2896299445979685]
	TIME [epoch: 6.11 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1815731053691901		[learning rate: 0.0046115]
	Learning Rate: 0.00461154
	LOSS [training: 0.1815731053691901 | validation: 0.290232529794617]
	TIME [epoch: 6.11 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18046476508395956		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 0.18046476508395956 | validation: 0.2973160402215068]
	TIME [epoch: 6.12 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17419783740137412		[learning rate: 0.0045709]
	Learning Rate: 0.00457088
	LOSS [training: 0.17419783740137412 | validation: 0.30499986124617207]
	TIME [epoch: 6.11 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17575756328222736		[learning rate: 0.0045507]
	Learning Rate: 0.00455069
	LOSS [training: 0.17575756328222736 | validation: 0.3529470393963947]
	TIME [epoch: 6.11 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17789875869756672		[learning rate: 0.0045306]
	Learning Rate: 0.00453058
	LOSS [training: 0.17789875869756672 | validation: 0.2991001686377461]
	TIME [epoch: 6.11 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17805143968453005		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 0.17805143968453005 | validation: 0.3130289685364213]
	TIME [epoch: 6.1 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1724764807903471		[learning rate: 0.0044906]
	Learning Rate: 0.00449063
	LOSS [training: 0.1724764807903471 | validation: 0.30312094886700935]
	TIME [epoch: 6.1 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1720649530952198		[learning rate: 0.0044708]
	Learning Rate: 0.00447079
	LOSS [training: 0.1720649530952198 | validation: 0.29210793444140665]
	TIME [epoch: 6.14 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17229273653089447		[learning rate: 0.004451]
	Learning Rate: 0.00445104
	LOSS [training: 0.17229273653089447 | validation: 0.32991169432815165]
	TIME [epoch: 6.12 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21044431228499047		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 0.21044431228499047 | validation: 0.2897674488078088]
	TIME [epoch: 6.11 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19035176733740097		[learning rate: 0.0044118]
	Learning Rate: 0.0044118
	LOSS [training: 0.19035176733740097 | validation: 0.32277689272576765]
	TIME [epoch: 6.11 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1790474730330323		[learning rate: 0.0043923]
	Learning Rate: 0.0043923
	LOSS [training: 0.1790474730330323 | validation: 0.29519720042206404]
	TIME [epoch: 6.11 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17718080205768433		[learning rate: 0.0043729]
	Learning Rate: 0.0043729
	LOSS [training: 0.17718080205768433 | validation: 0.33198922359704486]
	TIME [epoch: 6.1 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1689139867607324		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 0.1689139867607324 | validation: 0.3339350173242901]
	TIME [epoch: 6.1 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18270960268105185		[learning rate: 0.0043343]
	Learning Rate: 0.00433434
	LOSS [training: 0.18270960268105185 | validation: 0.34092448866989106]
	TIME [epoch: 6.1 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17440882801644014		[learning rate: 0.0043152]
	Learning Rate: 0.00431519
	LOSS [training: 0.17440882801644014 | validation: 0.294673723893845]
	TIME [epoch: 6.11 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18153019873432688		[learning rate: 0.0042961]
	Learning Rate: 0.00429612
	LOSS [training: 0.18153019873432688 | validation: 0.28743608078698]
	TIME [epoch: 6.12 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16874151991307956		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 0.16874151991307956 | validation: 0.28725536724144457]
	TIME [epoch: 6.11 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18081018511737815		[learning rate: 0.0042582]
	Learning Rate: 0.00425825
	LOSS [training: 0.18081018511737815 | validation: 0.28999373354858576]
	TIME [epoch: 6.1 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17727778103853545		[learning rate: 0.0042394]
	Learning Rate: 0.00423943
	LOSS [training: 0.17727778103853545 | validation: 0.2915002105691617]
	TIME [epoch: 6.11 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1732690263339975		[learning rate: 0.0042207]
	Learning Rate: 0.0042207
	LOSS [training: 0.1732690263339975 | validation: 0.2887997396691221]
	TIME [epoch: 6.11 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16526514041846113		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 0.16526514041846113 | validation: 0.2976174382105179]
	TIME [epoch: 6.11 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17732326777006271		[learning rate: 0.0041835]
	Learning Rate: 0.00418349
	LOSS [training: 0.17732326777006271 | validation: 0.2908497224292391]
	TIME [epoch: 6.1 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1682772939395671		[learning rate: 0.004165]
	Learning Rate: 0.004165
	LOSS [training: 0.1682772939395671 | validation: 0.33191507809098014]
	TIME [epoch: 6.12 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16738597804386326		[learning rate: 0.0041466]
	Learning Rate: 0.0041466
	LOSS [training: 0.16738597804386326 | validation: 0.3075888623555234]
	TIME [epoch: 6.11 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17161709860163682		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 0.17161709860163682 | validation: 0.2964906317026167]
	TIME [epoch: 6.1 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17257962443642133		[learning rate: 0.00411]
	Learning Rate: 0.00411004
	LOSS [training: 0.17257962443642133 | validation: 0.29686331179980735]
	TIME [epoch: 6.1 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18445914624556234		[learning rate: 0.0040919]
	Learning Rate: 0.00409188
	LOSS [training: 0.18445914624556234 | validation: 0.2883871977113282]
	TIME [epoch: 6.1 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17430780835248474		[learning rate: 0.0040738]
	Learning Rate: 0.0040738
	LOSS [training: 0.17430780835248474 | validation: 0.31816299933299275]
	TIME [epoch: 6.1 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17205002576931355		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.17205002576931355 | validation: 0.3004988912441958]
	TIME [epoch: 6.1 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1732178401921922		[learning rate: 0.0040379]
	Learning Rate: 0.00403788
	LOSS [training: 0.1732178401921922 | validation: 0.3248103633001094]
	TIME [epoch: 6.11 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1856684684284604		[learning rate: 0.00402]
	Learning Rate: 0.00402004
	LOSS [training: 0.1856684684284604 | validation: 0.32272276833275076]
	TIME [epoch: 6.11 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17543829725073612		[learning rate: 0.0040023]
	Learning Rate: 0.00400228
	LOSS [training: 0.17543829725073612 | validation: 0.3244406039761015]
	TIME [epoch: 6.11 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17978065035510196		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 0.17978065035510196 | validation: 0.31306825804847294]
	TIME [epoch: 6.11 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16240477217505325		[learning rate: 0.003967]
	Learning Rate: 0.00396699
	LOSS [training: 0.16240477217505325 | validation: 0.29938367470365035]
	TIME [epoch: 6.11 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1672389826083217		[learning rate: 0.0039495]
	Learning Rate: 0.00394947
	LOSS [training: 0.1672389826083217 | validation: 0.3065530539524579]
	TIME [epoch: 6.11 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17718780626906575		[learning rate: 0.003932]
	Learning Rate: 0.00393202
	LOSS [training: 0.17718780626906575 | validation: 0.30140384506900453]
	TIME [epoch: 6.1 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1718159728640264		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 0.1718159728640264 | validation: 0.29160448695244134]
	TIME [epoch: 6.11 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.169741266748137		[learning rate: 0.0038973]
	Learning Rate: 0.00389735
	LOSS [training: 0.169741266748137 | validation: 0.29879655021912443]
	TIME [epoch: 6.12 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18148821896128922		[learning rate: 0.0038801]
	Learning Rate: 0.00388013
	LOSS [training: 0.18148821896128922 | validation: 0.32880117925094093]
	TIME [epoch: 6.11 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17234300466671354		[learning rate: 0.003863]
	Learning Rate: 0.00386299
	LOSS [training: 0.17234300466671354 | validation: 0.34836103409172076]
	TIME [epoch: 6.11 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16596516996985622		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 0.16596516996985622 | validation: 0.34796868730952035]
	TIME [epoch: 6.1 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17409421665350402		[learning rate: 0.0038289]
	Learning Rate: 0.00382893
	LOSS [training: 0.17409421665350402 | validation: 0.33159449304073385]
	TIME [epoch: 6.1 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18016312834088694		[learning rate: 0.003812]
	Learning Rate: 0.00381201
	LOSS [training: 0.18016312834088694 | validation: 0.33272674289956905]
	TIME [epoch: 6.11 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16771361424086448		[learning rate: 0.0037952]
	Learning Rate: 0.00379517
	LOSS [training: 0.16771361424086448 | validation: 0.29372795822925385]
	TIME [epoch: 6.12 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16990283112250382		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 0.16990283112250382 | validation: 0.27890597235843473]
	TIME [epoch: 6.12 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v10_20240712_145225/states/model_facs_v2_dec2b_2dpca_v10_260.pth
	Model improved!!!
EPOCH 261/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16621383105806695		[learning rate: 0.0037617]
	Learning Rate: 0.0037617
	LOSS [training: 0.16621383105806695 | validation: 0.27338894286291615]
	TIME [epoch: 6.1 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v10_20240712_145225/states/model_facs_v2_dec2b_2dpca_v10_261.pth
	Model improved!!!
EPOCH 262/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1728859851888066		[learning rate: 0.0037451]
	Learning Rate: 0.00374508
	LOSS [training: 0.1728859851888066 | validation: 0.3194645433119477]
	TIME [epoch: 6.13 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1880517442315114		[learning rate: 0.0037285]
	Learning Rate: 0.00372854
	LOSS [training: 0.1880517442315114 | validation: 0.312996339148504]
	TIME [epoch: 6.13 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18065329595133667		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 0.18065329595133667 | validation: 0.2795033498850209]
	TIME [epoch: 6.12 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16341485374418696		[learning rate: 0.0036957]
	Learning Rate: 0.00369566
	LOSS [training: 0.16341485374418696 | validation: 0.27100945488221995]
	TIME [epoch: 6.12 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v10_20240712_145225/states/model_facs_v2_dec2b_2dpca_v10_265.pth
	Model improved!!!
EPOCH 266/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16661757185721468		[learning rate: 0.0036793]
	Learning Rate: 0.00367933
	LOSS [training: 0.16661757185721468 | validation: 0.28273474390154113]
	TIME [epoch: 6.12 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1655040253277119		[learning rate: 0.0036631]
	Learning Rate: 0.00366308
	LOSS [training: 0.1655040253277119 | validation: 0.2950311088881818]
	TIME [epoch: 6.12 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1740545634781568		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 0.1740545634781568 | validation: 0.33169659855896666]
	TIME [epoch: 6.12 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1829829082204414		[learning rate: 0.0036308]
	Learning Rate: 0.00363078
	LOSS [training: 0.1829829082204414 | validation: 0.3235368796133105]
	TIME [epoch: 6.13 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17144212776462733		[learning rate: 0.0036147]
	Learning Rate: 0.00361474
	LOSS [training: 0.17144212776462733 | validation: 0.33415549020350027]
	TIME [epoch: 6.15 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17565918043989465		[learning rate: 0.0035988]
	Learning Rate: 0.00359877
	LOSS [training: 0.17565918043989465 | validation: 0.29974920535079]
	TIME [epoch: 6.12 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16834497265380027		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 0.16834497265380027 | validation: 0.2967056974266298]
	TIME [epoch: 6.12 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18202684986326143		[learning rate: 0.003567]
	Learning Rate: 0.00356704
	LOSS [training: 0.18202684986326143 | validation: 0.34585415428034144]
	TIME [epoch: 6.12 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18654254049241553		[learning rate: 0.0035513]
	Learning Rate: 0.00355128
	LOSS [training: 0.18654254049241553 | validation: 0.33802712108861505]
	TIME [epoch: 6.13 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17486822309608696		[learning rate: 0.0035356]
	Learning Rate: 0.00353559
	LOSS [training: 0.17486822309608696 | validation: 0.2758066446759084]
	TIME [epoch: 6.13 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16756422042558108		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 0.16756422042558108 | validation: 0.29423960337282346]
	TIME [epoch: 6.13 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16466627208820994		[learning rate: 0.0035044]
	Learning Rate: 0.00350441
	LOSS [training: 0.16466627208820994 | validation: 0.3015809929613732]
	TIME [epoch: 6.12 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16463827299371148		[learning rate: 0.0034889]
	Learning Rate: 0.00348893
	LOSS [training: 0.16463827299371148 | validation: 0.29801660946061836]
	TIME [epoch: 6.13 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1614198671459035		[learning rate: 0.0034735]
	Learning Rate: 0.00347352
	LOSS [training: 0.1614198671459035 | validation: 0.30616919965848927]
	TIME [epoch: 6.12 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17352886722631114		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.17352886722631114 | validation: 0.2905038337429219]
	TIME [epoch: 6.12 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16228736393608068		[learning rate: 0.0034429]
	Learning Rate: 0.00344289
	LOSS [training: 0.16228736393608068 | validation: 0.2980583857677606]
	TIME [epoch: 6.12 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16791688597425722		[learning rate: 0.0034277]
	Learning Rate: 0.00342768
	LOSS [training: 0.16791688597425722 | validation: 0.27582908042462856]
	TIME [epoch: 6.12 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16921617945905948		[learning rate: 0.0034125]
	Learning Rate: 0.00341253
	LOSS [training: 0.16921617945905948 | validation: 0.2972737389932404]
	TIME [epoch: 6.13 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1668739572904324		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 0.1668739572904324 | validation: 0.28446606326177404]
	TIME [epoch: 6.13 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1933310421865922		[learning rate: 0.0033824]
	Learning Rate: 0.00338245
	LOSS [training: 0.1933310421865922 | validation: 0.33859514951323966]
	TIME [epoch: 6.12 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21858268200744332		[learning rate: 0.0033675]
	Learning Rate: 0.0033675
	LOSS [training: 0.21858268200744332 | validation: 0.28727569688406296]
	TIME [epoch: 6.12 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17151589499404718		[learning rate: 0.0033526]
	Learning Rate: 0.00335262
	LOSS [training: 0.17151589499404718 | validation: 0.304273397232174]
	TIME [epoch: 6.13 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15399594464751326		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 0.15399594464751326 | validation: 0.2748605887414862]
	TIME [epoch: 6.12 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17573781478140818		[learning rate: 0.0033231]
	Learning Rate: 0.00332306
	LOSS [training: 0.17573781478140818 | validation: 0.29566654612360477]
	TIME [epoch: 6.12 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16392890673974725		[learning rate: 0.0033084]
	Learning Rate: 0.00330838
	LOSS [training: 0.16392890673974725 | validation: 0.29376613226328346]
	TIME [epoch: 6.12 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1869289455099996		[learning rate: 0.0032938]
	Learning Rate: 0.00329376
	LOSS [training: 0.1869289455099996 | validation: 0.3357086999673393]
	TIME [epoch: 6.12 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16318243655417758		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 0.16318243655417758 | validation: 0.2956151452162698]
	TIME [epoch: 6.13 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16714849608251173		[learning rate: 0.0032647]
	Learning Rate: 0.00326472
	LOSS [training: 0.16714849608251173 | validation: 0.29519611833515724]
	TIME [epoch: 6.12 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1711042619268847		[learning rate: 0.0032503]
	Learning Rate: 0.0032503
	LOSS [training: 0.1711042619268847 | validation: 0.2690254863490564]
	TIME [epoch: 6.12 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v10_20240712_145225/states/model_facs_v2_dec2b_2dpca_v10_294.pth
	Model improved!!!
EPOCH 295/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.160051558899896		[learning rate: 0.0032359]
	Learning Rate: 0.00323594
	LOSS [training: 0.160051558899896 | validation: 0.2832914767749798]
	TIME [epoch: 6.12 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1623759395024686		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 0.1623759395024686 | validation: 0.3033920916782165]
	TIME [epoch: 6.11 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1673714264804844		[learning rate: 0.0032074]
	Learning Rate: 0.00320741
	LOSS [training: 0.1673714264804844 | validation: 0.32455552170511304]
	TIME [epoch: 6.12 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15894698840544186		[learning rate: 0.0031932]
	Learning Rate: 0.00319323
	LOSS [training: 0.15894698840544186 | validation: 0.2993154361960873]
	TIME [epoch: 6.12 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16662052600070992		[learning rate: 0.0031791]
	Learning Rate: 0.00317913
	LOSS [training: 0.16662052600070992 | validation: 0.29210739930715657]
	TIME [epoch: 6.13 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1609920516585527		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 0.1609920516585527 | validation: 0.2953362815476812]
	TIME [epoch: 6.12 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16916027046877108		[learning rate: 0.0031511]
	Learning Rate: 0.0031511
	LOSS [training: 0.16916027046877108 | validation: 0.32463603066122937]
	TIME [epoch: 6.11 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1667491656111066		[learning rate: 0.0031372]
	Learning Rate: 0.00313717
	LOSS [training: 0.1667491656111066 | validation: 0.3336988617647227]
	TIME [epoch: 6.11 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17634408322281894		[learning rate: 0.0031233]
	Learning Rate: 0.00312331
	LOSS [training: 0.17634408322281894 | validation: 0.34171043972233905]
	TIME [epoch: 6.11 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17121291045090395		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 0.17121291045090395 | validation: 0.33885388031203334]
	TIME [epoch: 6.11 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1849681348040671		[learning rate: 0.0030958]
	Learning Rate: 0.00309577
	LOSS [training: 0.1849681348040671 | validation: 0.29937068239875964]
	TIME [epoch: 6.11 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16823338489903775		[learning rate: 0.0030821]
	Learning Rate: 0.0030821
	LOSS [training: 0.16823338489903775 | validation: 0.2840365119655429]
	TIME [epoch: 6.11 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18461134207518598		[learning rate: 0.0030685]
	Learning Rate: 0.00306848
	LOSS [training: 0.18461134207518598 | validation: 0.2762421552992067]
	TIME [epoch: 6.13 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.165660405313294		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 0.165660405313294 | validation: 0.2910860263934873]
	TIME [epoch: 6.12 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15619585946070794		[learning rate: 0.0030414]
	Learning Rate: 0.00304142
	LOSS [training: 0.15619585946070794 | validation: 0.28365965269389215]
	TIME [epoch: 6.13 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17387991375198503		[learning rate: 0.003028]
	Learning Rate: 0.00302799
	LOSS [training: 0.17387991375198503 | validation: 0.3412150700788702]
	TIME [epoch: 6.13 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19945452326277838		[learning rate: 0.0030146]
	Learning Rate: 0.00301461
	LOSS [training: 0.19945452326277838 | validation: 0.2939393250573515]
	TIME [epoch: 6.11 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16933444339112397		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 0.16933444339112397 | validation: 0.31667859611326543]
	TIME [epoch: 6.11 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1920882124287513		[learning rate: 0.002988]
	Learning Rate: 0.00298803
	LOSS [training: 0.1920882124287513 | validation: 0.31584111718162067]
	TIME [epoch: 6.11 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16496498106790383		[learning rate: 0.0029748]
	Learning Rate: 0.00297483
	LOSS [training: 0.16496498106790383 | validation: 0.3190319617040085]
	TIME [epoch: 6.11 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16966113792745957		[learning rate: 0.0029617]
	Learning Rate: 0.00296168
	LOSS [training: 0.16966113792745957 | validation: 0.2927771432237154]
	TIME [epoch: 6.13 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1615034169572654		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.1615034169572654 | validation: 0.3015467292415692]
	TIME [epoch: 6.12 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1627656836066676		[learning rate: 0.0029356]
	Learning Rate: 0.00293557
	LOSS [training: 0.1627656836066676 | validation: 0.29864513098225587]
	TIME [epoch: 6.11 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16314526226806997		[learning rate: 0.0029226]
	Learning Rate: 0.0029226
	LOSS [training: 0.16314526226806997 | validation: 0.2830660820200158]
	TIME [epoch: 6.11 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1698359232026615		[learning rate: 0.0029097]
	Learning Rate: 0.00290969
	LOSS [training: 0.1698359232026615 | validation: 0.2880555678775722]
	TIME [epoch: 6.11 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15676482260271402		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 0.15676482260271402 | validation: 0.29981693898446393]
	TIME [epoch: 6.11 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1647800277723255		[learning rate: 0.002884]
	Learning Rate: 0.00288403
	LOSS [training: 0.1647800277723255 | validation: 0.3294159679854336]
	TIME [epoch: 6.11 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17482754092449035		[learning rate: 0.0028713]
	Learning Rate: 0.00287129
	LOSS [training: 0.17482754092449035 | validation: 0.31981982558771993]
	TIME [epoch: 6.12 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16718696531367264		[learning rate: 0.0028586]
	Learning Rate: 0.0028586
	LOSS [training: 0.16718696531367264 | validation: 0.3028333574632471]
	TIME [epoch: 6.13 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1732321356150585		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 0.1732321356150585 | validation: 0.2881939373017441]
	TIME [epoch: 6.11 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16361984582963007		[learning rate: 0.0028334]
	Learning Rate: 0.0028334
	LOSS [training: 0.16361984582963007 | validation: 0.28259926140012137]
	TIME [epoch: 6.11 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15980777896556092		[learning rate: 0.0028209]
	Learning Rate: 0.00282088
	LOSS [training: 0.15980777896556092 | validation: 0.2687854712651083]
	TIME [epoch: 6.11 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v10_20240712_145225/states/model_facs_v2_dec2b_2dpca_v10_326.pth
	Model improved!!!
EPOCH 327/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1639042676600645		[learning rate: 0.0028084]
	Learning Rate: 0.00280842
	LOSS [training: 0.1639042676600645 | validation: 0.2824566159485113]
	TIME [epoch: 6.11 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16390001348706273		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 0.16390001348706273 | validation: 0.2811277848569503]
	TIME [epoch: 6.11 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1668280475831277		[learning rate: 0.0027837]
	Learning Rate: 0.00278366
	LOSS [training: 0.1668280475831277 | validation: 0.2707351486936672]
	TIME [epoch: 6.11 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17140898376081257		[learning rate: 0.0027714]
	Learning Rate: 0.00277136
	LOSS [training: 0.17140898376081257 | validation: 0.27695064852591694]
	TIME [epoch: 6.12 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1637905826697407		[learning rate: 0.0027591]
	Learning Rate: 0.00275911
	LOSS [training: 0.1637905826697407 | validation: 0.28063260112212407]
	TIME [epoch: 6.11 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1707207361005908		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 0.1707207361005908 | validation: 0.2713992469409234]
	TIME [epoch: 6.11 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17457459907404932		[learning rate: 0.0027348]
	Learning Rate: 0.00273478
	LOSS [training: 0.17457459907404932 | validation: 0.2940725854220599]
	TIME [epoch: 6.11 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17053442605283292		[learning rate: 0.0027227]
	Learning Rate: 0.0027227
	LOSS [training: 0.17053442605283292 | validation: 0.2928894386107559]
	TIME [epoch: 6.14 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16084833353731737		[learning rate: 0.0027107]
	Learning Rate: 0.00271067
	LOSS [training: 0.16084833353731737 | validation: 0.27727621913017886]
	TIME [epoch: 6.11 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1619867901007075		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 0.1619867901007075 | validation: 0.28932478715505905]
	TIME [epoch: 6.1 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16586860490647806		[learning rate: 0.0026868]
	Learning Rate: 0.00268677
	LOSS [training: 0.16586860490647806 | validation: 0.3042011934795933]
	TIME [epoch: 6.11 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17157708376300201		[learning rate: 0.0026749]
	Learning Rate: 0.0026749
	LOSS [training: 0.17157708376300201 | validation: 0.2852009736242827]
	TIME [epoch: 6.12 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16757637617461008		[learning rate: 0.0026631]
	Learning Rate: 0.00266308
	LOSS [training: 0.16757637617461008 | validation: 0.2797474208302731]
	TIME [epoch: 6.11 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16224426978795217		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 0.16224426978795217 | validation: 0.29812925619769676]
	TIME [epoch: 6.13 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1669199997555348		[learning rate: 0.0026396]
	Learning Rate: 0.0026396
	LOSS [training: 0.1669199997555348 | validation: 0.31577341504557643]
	TIME [epoch: 6.13 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16097991682506713		[learning rate: 0.0026279]
	Learning Rate: 0.00262794
	LOSS [training: 0.16097991682506713 | validation: 0.30431990170415296]
	TIME [epoch: 6.1 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16364224197581492		[learning rate: 0.0026163]
	Learning Rate: 0.00261633
	LOSS [training: 0.16364224197581492 | validation: 0.3144010314681672]
	TIME [epoch: 6.11 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17040301367906466		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 0.17040301367906466 | validation: 0.29840383769886836]
	TIME [epoch: 6.14 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1656628433981024		[learning rate: 0.0025933]
	Learning Rate: 0.00259326
	LOSS [training: 0.1656628433981024 | validation: 0.29988143717777255]
	TIME [epoch: 6.14 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17012800245760587		[learning rate: 0.0025818]
	Learning Rate: 0.0025818
	LOSS [training: 0.17012800245760587 | validation: 0.2886626953408579]
	TIME [epoch: 6.14 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15584966360064784		[learning rate: 0.0025704]
	Learning Rate: 0.0025704
	LOSS [training: 0.15584966360064784 | validation: 0.29361452207875366]
	TIME [epoch: 6.12 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.158923715281296		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.158923715281296 | validation: 0.2692716189884388]
	TIME [epoch: 6.11 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16700465982288626		[learning rate: 0.0025477]
	Learning Rate: 0.00254773
	LOSS [training: 0.16700465982288626 | validation: 0.283564793379275]
	TIME [epoch: 6.11 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.158986361230685		[learning rate: 0.0025365]
	Learning Rate: 0.00253648
	LOSS [training: 0.158986361230685 | validation: 0.2894139966013585]
	TIME [epoch: 6.11 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17004021184570198		[learning rate: 0.0025253]
	Learning Rate: 0.00252527
	LOSS [training: 0.17004021184570198 | validation: 0.2721117888255126]
	TIME [epoch: 6.11 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15747194853498472		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.15747194853498472 | validation: 0.28295715144316463]
	TIME [epoch: 6.11 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16803261958800944		[learning rate: 0.002503]
	Learning Rate: 0.002503
	LOSS [training: 0.16803261958800944 | validation: 0.28190747450774534]
	TIME [epoch: 6.12 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15929726569150193		[learning rate: 0.0024919]
	Learning Rate: 0.00249194
	LOSS [training: 0.15929726569150193 | validation: 0.2812273432985515]
	TIME [epoch: 6.12 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15470079751735438		[learning rate: 0.0024809]
	Learning Rate: 0.00248093
	LOSS [training: 0.15470079751735438 | validation: 0.2774348150251551]
	TIME [epoch: 6.11 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15382543882766392		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 0.15382543882766392 | validation: 0.2739722551667706]
	TIME [epoch: 6.12 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14909476914849568		[learning rate: 0.0024591]
	Learning Rate: 0.00245906
	LOSS [training: 0.14909476914849568 | validation: 0.2664328873980924]
	TIME [epoch: 6.11 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v10_20240712_145225/states/model_facs_v2_dec2b_2dpca_v10_357.pth
	Model improved!!!
EPOCH 358/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1626237679360223		[learning rate: 0.0024482]
	Learning Rate: 0.0024482
	LOSS [training: 0.1626237679360223 | validation: 0.28824156711021476]
	TIME [epoch: 6.11 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.160459441087889		[learning rate: 0.0024374]
	Learning Rate: 0.00243738
	LOSS [training: 0.160459441087889 | validation: 0.28713422776228287]
	TIME [epoch: 6.11 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16752578127909099		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.16752578127909099 | validation: 0.2830197533603825]
	TIME [epoch: 6.12 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16192962321942597		[learning rate: 0.0024159]
	Learning Rate: 0.00241589
	LOSS [training: 0.16192962321942597 | validation: 0.295886768001654]
	TIME [epoch: 6.11 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16398742136011496		[learning rate: 0.0024052]
	Learning Rate: 0.00240521
	LOSS [training: 0.16398742136011496 | validation: 0.3010246977936109]
	TIME [epoch: 6.11 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15938823860303258		[learning rate: 0.0023946]
	Learning Rate: 0.00239459
	LOSS [training: 0.15938823860303258 | validation: 0.27435809364371494]
	TIME [epoch: 6.1 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15851658232153662		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 0.15851658232153662 | validation: 0.2801055378065933]
	TIME [epoch: 6.11 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16612247596303537		[learning rate: 0.0023735]
	Learning Rate: 0.00237347
	LOSS [training: 0.16612247596303537 | validation: 0.2928839417020637]
	TIME [epoch: 6.11 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17171483686857666		[learning rate: 0.002363]
	Learning Rate: 0.00236299
	LOSS [training: 0.17171483686857666 | validation: 0.31168880566628837]
	TIME [epoch: 6.11 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15921699519047267		[learning rate: 0.0023525]
	Learning Rate: 0.00235255
	LOSS [training: 0.15921699519047267 | validation: 0.2984506482997337]
	TIME [epoch: 6.11 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.162576542663215		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.162576542663215 | validation: 0.2978467683671006]
	TIME [epoch: 6.12 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15340843175961924		[learning rate: 0.0023318]
	Learning Rate: 0.00233181
	LOSS [training: 0.15340843175961924 | validation: 0.28696805952279075]
	TIME [epoch: 6.11 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15959298835414293		[learning rate: 0.0023215]
	Learning Rate: 0.0023215
	LOSS [training: 0.15959298835414293 | validation: 0.280376535757552]
	TIME [epoch: 6.11 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16234936641358502		[learning rate: 0.0023112]
	Learning Rate: 0.00231125
	LOSS [training: 0.16234936641358502 | validation: 0.29654617286931195]
	TIME [epoch: 6.1 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16853639261170447		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.16853639261170447 | validation: 0.2984524211894229]
	TIME [epoch: 6.1 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18060125767105997		[learning rate: 0.0022909]
	Learning Rate: 0.00229087
	LOSS [training: 0.18060125767105997 | validation: 0.28048966254489277]
	TIME [epoch: 6.13 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1632976002428473		[learning rate: 0.0022807]
	Learning Rate: 0.00228075
	LOSS [training: 0.1632976002428473 | validation: 0.28108071509118093]
	TIME [epoch: 6.11 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15823676373638693		[learning rate: 0.0022707]
	Learning Rate: 0.00227067
	LOSS [training: 0.15823676373638693 | validation: 0.2852949256894027]
	TIME [epoch: 6.11 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1562627101607929		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.1562627101607929 | validation: 0.27457538195728504]
	TIME [epoch: 6.11 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16265147642864553		[learning rate: 0.0022506]
	Learning Rate: 0.00225065
	LOSS [training: 0.16265147642864553 | validation: 0.2872732455043785]
	TIME [epoch: 6.11 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15918080783447483		[learning rate: 0.0022407]
	Learning Rate: 0.0022407
	LOSS [training: 0.15918080783447483 | validation: 0.27643568090085685]
	TIME [epoch: 6.1 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16035643339116912		[learning rate: 0.0022308]
	Learning Rate: 0.0022308
	LOSS [training: 0.16035643339116912 | validation: 0.2996670202768244]
	TIME [epoch: 6.1 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16138503600129644		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.16138503600129644 | validation: 0.29606589606805966]
	TIME [epoch: 6.11 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16260090560651796		[learning rate: 0.0022111]
	Learning Rate: 0.00221114
	LOSS [training: 0.16260090560651796 | validation: 0.29677788772121133]
	TIME [epoch: 6.1 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1652853620511332		[learning rate: 0.0022014]
	Learning Rate: 0.00220137
	LOSS [training: 0.1652853620511332 | validation: 0.32429592037168475]
	TIME [epoch: 6.1 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1641491901466699		[learning rate: 0.0021916]
	Learning Rate: 0.00219164
	LOSS [training: 0.1641491901466699 | validation: 0.2763400657175658]
	TIME [epoch: 6.11 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16109624608619216		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.16109624608619216 | validation: 0.2864634686674763]
	TIME [epoch: 6.11 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16075078159910366		[learning rate: 0.0021723]
	Learning Rate: 0.00217232
	LOSS [training: 0.16075078159910366 | validation: 0.2757890980694812]
	TIME [epoch: 6.11 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16375735117931364		[learning rate: 0.0021627]
	Learning Rate: 0.00216272
	LOSS [training: 0.16375735117931364 | validation: 0.30412121710725615]
	TIME [epoch: 6.1 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16564171522059729		[learning rate: 0.0021532]
	Learning Rate: 0.00215316
	LOSS [training: 0.16564171522059729 | validation: 0.3013776020665656]
	TIME [epoch: 6.16 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1622049665338861		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.1622049665338861 | validation: 0.2849663297894233]
	TIME [epoch: 6.11 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15993179731973178		[learning rate: 0.0021342]
	Learning Rate: 0.00213418
	LOSS [training: 0.15993179731973178 | validation: 0.31353091119864906]
	TIME [epoch: 6.11 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1610138825378708		[learning rate: 0.0021247]
	Learning Rate: 0.00212475
	LOSS [training: 0.1610138825378708 | validation: 0.2892235313483398]
	TIME [epoch: 6.1 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1630875859260574		[learning rate: 0.0021154]
	Learning Rate: 0.00211536
	LOSS [training: 0.1630875859260574 | validation: 0.2847575058504709]
	TIME [epoch: 6.1 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15830740339837965		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.15830740339837965 | validation: 0.27334898499772764]
	TIME [epoch: 6.11 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15876078801380575		[learning rate: 0.0020967]
	Learning Rate: 0.00209671
	LOSS [training: 0.15876078801380575 | validation: 0.28601679438355776]
	TIME [epoch: 6.1 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16638389788211375		[learning rate: 0.0020874]
	Learning Rate: 0.00208745
	LOSS [training: 0.16638389788211375 | validation: 0.3063567574001164]
	TIME [epoch: 6.1 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1571135164023005		[learning rate: 0.0020782]
	Learning Rate: 0.00207822
	LOSS [training: 0.1571135164023005 | validation: 0.29935039498107835]
	TIME [epoch: 6.1 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15231818316776943		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.15231818316776943 | validation: 0.29825355936747466]
	TIME [epoch: 6.1 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1522989025451166		[learning rate: 0.0020599]
	Learning Rate: 0.0020599
	LOSS [training: 0.1522989025451166 | validation: 0.2894135405912503]
	TIME [epoch: 6.1 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16281898341102288		[learning rate: 0.0020508]
	Learning Rate: 0.0020508
	LOSS [training: 0.16281898341102288 | validation: 0.30712884054210216]
	TIME [epoch: 6.1 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16586354735125614		[learning rate: 0.0020417]
	Learning Rate: 0.00204174
	LOSS [training: 0.16586354735125614 | validation: 0.28311805800137685]
	TIME [epoch: 6.1 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16573613855772798		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.16573613855772798 | validation: 0.31012158843442483]
	TIME [epoch: 6.11 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16201234558166205		[learning rate: 0.0020237]
	Learning Rate: 0.00202374
	LOSS [training: 0.16201234558166205 | validation: 0.30763221013542014]
	TIME [epoch: 6.11 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16492420327603613		[learning rate: 0.0020148]
	Learning Rate: 0.00201479
	LOSS [training: 0.16492420327603613 | validation: 0.27007281874346156]
	TIME [epoch: 6.1 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1638450106828351		[learning rate: 0.0020059]
	Learning Rate: 0.00200589
	LOSS [training: 0.1638450106828351 | validation: 0.2654290886192984]
	TIME [epoch: 6.1 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v10_20240712_145225/states/model_facs_v2_dec2b_2dpca_v10_403.pth
	Model improved!!!
EPOCH 404/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16278106667664757		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.16278106667664757 | validation: 0.2933278948563014]
	TIME [epoch: 6.12 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1601011414232342		[learning rate: 0.0019882]
	Learning Rate: 0.00198821
	LOSS [training: 0.1601011414232342 | validation: 0.2877934757965694]
	TIME [epoch: 6.11 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15095613907333436		[learning rate: 0.0019794]
	Learning Rate: 0.00197942
	LOSS [training: 0.15095613907333436 | validation: 0.2854778244562429]
	TIME [epoch: 6.12 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16218927765494393		[learning rate: 0.0019707]
	Learning Rate: 0.00197068
	LOSS [training: 0.16218927765494393 | validation: 0.2822982889213036]
	TIME [epoch: 6.12 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15877580976847766		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.15877580976847766 | validation: 0.2874009709292953]
	TIME [epoch: 6.13 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15900286437252048		[learning rate: 0.0019533]
	Learning Rate: 0.0019533
	LOSS [training: 0.15900286437252048 | validation: 0.2669881370763927]
	TIME [epoch: 6.12 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15690071062817018		[learning rate: 0.0019447]
	Learning Rate: 0.00194467
	LOSS [training: 0.15690071062817018 | validation: 0.28648912245502495]
	TIME [epoch: 6.11 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1540680531557735		[learning rate: 0.0019361]
	Learning Rate: 0.00193608
	LOSS [training: 0.1540680531557735 | validation: 0.2909335607691788]
	TIME [epoch: 6.12 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16008301393689864		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.16008301393689864 | validation: 0.2879571237424352]
	TIME [epoch: 6.11 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16242002595541397		[learning rate: 0.001919]
	Learning Rate: 0.00191901
	LOSS [training: 0.16242002595541397 | validation: 0.2702986000181323]
	TIME [epoch: 6.12 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15534635578513276		[learning rate: 0.0019105]
	Learning Rate: 0.00191053
	LOSS [training: 0.15534635578513276 | validation: 0.28752357736534195]
	TIME [epoch: 6.11 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1630483469297693		[learning rate: 0.0019021]
	Learning Rate: 0.00190209
	LOSS [training: 0.1630483469297693 | validation: 0.28175473843342]
	TIME [epoch: 6.12 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16141958679382462		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.16141958679382462 | validation: 0.3011182466297336]
	TIME [epoch: 6.13 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15841910765129436		[learning rate: 0.0018853]
	Learning Rate: 0.00188532
	LOSS [training: 0.15841910765129436 | validation: 0.27574124385857085]
	TIME [epoch: 6.13 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1600106584836377		[learning rate: 0.001877]
	Learning Rate: 0.00187699
	LOSS [training: 0.1600106584836377 | validation: 0.2850208117147067]
	TIME [epoch: 6.11 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16495072779583064		[learning rate: 0.0018687]
	Learning Rate: 0.0018687
	LOSS [training: 0.16495072779583064 | validation: 0.2791529537829205]
	TIME [epoch: 6.12 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1597803433891944		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.1597803433891944 | validation: 0.30101424946927957]
	TIME [epoch: 6.11 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1537717380927755		[learning rate: 0.0018522]
	Learning Rate: 0.00185222
	LOSS [training: 0.1537717380927755 | validation: 0.2801824113247714]
	TIME [epoch: 6.12 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16005708061213822		[learning rate: 0.001844]
	Learning Rate: 0.00184404
	LOSS [training: 0.16005708061213822 | validation: 0.274046601841222]
	TIME [epoch: 6.12 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1588234136328465		[learning rate: 0.0018359]
	Learning Rate: 0.00183589
	LOSS [training: 0.1588234136328465 | validation: 0.28500880820810903]
	TIME [epoch: 6.11 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15877059949071534		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.15877059949071534 | validation: 0.30539547066751416]
	TIME [epoch: 6.12 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15351907269499		[learning rate: 0.0018197]
	Learning Rate: 0.0018197
	LOSS [training: 0.15351907269499 | validation: 0.2978309130251327]
	TIME [epoch: 6.12 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15494794076361718		[learning rate: 0.0018117]
	Learning Rate: 0.00181166
	LOSS [training: 0.15494794076361718 | validation: 0.285827821939139]
	TIME [epoch: 6.11 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17085699455454398		[learning rate: 0.0018037]
	Learning Rate: 0.00180366
	LOSS [training: 0.17085699455454398 | validation: 0.308168437378808]
	TIME [epoch: 6.13 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16913062776314436		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.16913062776314436 | validation: 0.2850716554180497]
	TIME [epoch: 6.11 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15991656076320507		[learning rate: 0.0017878]
	Learning Rate: 0.00178775
	LOSS [training: 0.15991656076320507 | validation: 0.2892241451110055]
	TIME [epoch: 6.11 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15992627326972095		[learning rate: 0.0017799]
	Learning Rate: 0.00177985
	LOSS [training: 0.15992627326972095 | validation: 0.3055549504222677]
	TIME [epoch: 6.11 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16030632644897932		[learning rate: 0.001772]
	Learning Rate: 0.00177199
	LOSS [training: 0.16030632644897932 | validation: 0.27423733137503326]
	TIME [epoch: 6.11 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1615962830720185		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.1615962830720185 | validation: 0.2771170923998556]
	TIME [epoch: 6.12 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1492603051960654		[learning rate: 0.0017564]
	Learning Rate: 0.00175637
	LOSS [training: 0.1492603051960654 | validation: 0.2769151453280029]
	TIME [epoch: 6.11 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16143088786140303		[learning rate: 0.0017486]
	Learning Rate: 0.00174861
	LOSS [training: 0.16143088786140303 | validation: 0.26861251865707175]
	TIME [epoch: 6.11 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15707431615677345		[learning rate: 0.0017409]
	Learning Rate: 0.00174088
	LOSS [training: 0.15707431615677345 | validation: 0.2699395232513177]
	TIME [epoch: 6.11 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1575529920774307		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.1575529920774307 | validation: 0.2925794811576035]
	TIME [epoch: 6.11 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15549413088624045		[learning rate: 0.0017255]
	Learning Rate: 0.00172553
	LOSS [training: 0.15549413088624045 | validation: 0.2900743799063505]
	TIME [epoch: 6.11 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15665865788777164		[learning rate: 0.0017179]
	Learning Rate: 0.00171791
	LOSS [training: 0.15665865788777164 | validation: 0.2909043971883111]
	TIME [epoch: 6.11 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16037150368227676		[learning rate: 0.0017103]
	Learning Rate: 0.00171032
	LOSS [training: 0.16037150368227676 | validation: 0.2722578664377159]
	TIME [epoch: 6.11 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1627018391233907		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.1627018391233907 | validation: 0.26739211074792113]
	TIME [epoch: 6.13 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1511471075082264		[learning rate: 0.0016952]
	Learning Rate: 0.00169524
	LOSS [training: 0.1511471075082264 | validation: 0.2849402242413669]
	TIME [epoch: 6.11 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1556780351669724		[learning rate: 0.0016877]
	Learning Rate: 0.00168775
	LOSS [training: 0.1556780351669724 | validation: 0.28684455768651623]
	TIME [epoch: 6.11 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1549450663314879		[learning rate: 0.0016803]
	Learning Rate: 0.00168029
	LOSS [training: 0.1549450663314879 | validation: 0.2748383380730479]
	TIME [epoch: 6.11 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16125394743290317		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.16125394743290317 | validation: 0.2719296413731992]
	TIME [epoch: 6.11 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1536280774387681		[learning rate: 0.0016655]
	Learning Rate: 0.00166548
	LOSS [training: 0.1536280774387681 | validation: 0.2834585972755216]
	TIME [epoch: 6.11 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15468457515994183		[learning rate: 0.0016581]
	Learning Rate: 0.00165812
	LOSS [training: 0.15468457515994183 | validation: 0.281051838151242]
	TIME [epoch: 6.11 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16118749275114397		[learning rate: 0.0016508]
	Learning Rate: 0.00165079
	LOSS [training: 0.16118749275114397 | validation: 0.2779508519894057]
	TIME [epoch: 6.11 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15612671502872905		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.15612671502872905 | validation: 0.2775664413530505]
	TIME [epoch: 6.12 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15315512517405888		[learning rate: 0.0016362]
	Learning Rate: 0.00163624
	LOSS [training: 0.15315512517405888 | validation: 0.289877126607943]
	TIME [epoch: 6.11 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15659438237855855		[learning rate: 0.001629]
	Learning Rate: 0.00162901
	LOSS [training: 0.15659438237855855 | validation: 0.27711357591194247]
	TIME [epoch: 6.11 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15789996944988519		[learning rate: 0.0016218]
	Learning Rate: 0.00162181
	LOSS [training: 0.15789996944988519 | validation: 0.2827098883729915]
	TIME [epoch: 6.11 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15901887189998865		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.15901887189998865 | validation: 0.294315985448457]
	TIME [epoch: 6.1 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15576479926659073		[learning rate: 0.0016075]
	Learning Rate: 0.00160751
	LOSS [training: 0.15576479926659073 | validation: 0.2759247069306635]
	TIME [epoch: 6.11 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1550713974079742		[learning rate: 0.0016004]
	Learning Rate: 0.00160041
	LOSS [training: 0.1550713974079742 | validation: 0.27015422769021136]
	TIME [epoch: 6.11 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1587921670190103		[learning rate: 0.0015933]
	Learning Rate: 0.00159334
	LOSS [training: 0.1587921670190103 | validation: 0.28312484527263404]
	TIME [epoch: 6.11 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.160485028205052		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.160485028205052 | validation: 0.2764247518442069]
	TIME [epoch: 6.12 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15749245874589318		[learning rate: 0.0015793]
	Learning Rate: 0.00157929
	LOSS [training: 0.15749245874589318 | validation: 0.27706563866550166]
	TIME [epoch: 6.11 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16069917684972476		[learning rate: 0.0015723]
	Learning Rate: 0.00157231
	LOSS [training: 0.16069917684972476 | validation: 0.28366908697201504]
	TIME [epoch: 6.1 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1611353023170213		[learning rate: 0.0015654]
	Learning Rate: 0.00156536
	LOSS [training: 0.1611353023170213 | validation: 0.28482073774989936]
	TIME [epoch: 6.1 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15433908642028982		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.15433908642028982 | validation: 0.30131652116066643]
	TIME [epoch: 6.11 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15260899721995153		[learning rate: 0.0015516]
	Learning Rate: 0.00155156
	LOSS [training: 0.15260899721995153 | validation: 0.2721946053715915]
	TIME [epoch: 6.11 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14914118000558033		[learning rate: 0.0015447]
	Learning Rate: 0.00154471
	LOSS [training: 0.14914118000558033 | validation: 0.2770791564107837]
	TIME [epoch: 6.1 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15346428375056473		[learning rate: 0.0015379]
	Learning Rate: 0.00153788
	LOSS [training: 0.15346428375056473 | validation: 0.2915982670988435]
	TIME [epoch: 6.11 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15452631806874415		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.15452631806874415 | validation: 0.2983993499869246]
	TIME [epoch: 6.12 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15883831480160976		[learning rate: 0.0015243]
	Learning Rate: 0.00152432
	LOSS [training: 0.15883831480160976 | validation: 0.2821176389566437]
	TIME [epoch: 6.11 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1581467664661688		[learning rate: 0.0015176]
	Learning Rate: 0.00151759
	LOSS [training: 0.1581467664661688 | validation: 0.27498801417842544]
	TIME [epoch: 6.1 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15384361605789665		[learning rate: 0.0015109]
	Learning Rate: 0.00151088
	LOSS [training: 0.15384361605789665 | validation: 0.27099934212361626]
	TIME [epoch: 6.1 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16360043250953119		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.16360043250953119 | validation: 0.29297634960003544]
	TIME [epoch: 6.1 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1572868898222464		[learning rate: 0.0014976]
	Learning Rate: 0.00149756
	LOSS [training: 0.1572868898222464 | validation: 0.2786904931053369]
	TIME [epoch: 6.1 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15435155529677141		[learning rate: 0.0014909]
	Learning Rate: 0.00149094
	LOSS [training: 0.15435155529677141 | validation: 0.28375365338678593]
	TIME [epoch: 6.1 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15539151181891936		[learning rate: 0.0014844]
	Learning Rate: 0.00148436
	LOSS [training: 0.15539151181891936 | validation: 0.2740431768898863]
	TIME [epoch: 6.11 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16465309254619592		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.16465309254619592 | validation: 0.2859864921069222]
	TIME [epoch: 6.12 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16222547432810722		[learning rate: 0.0014713]
	Learning Rate: 0.00147127
	LOSS [training: 0.16222547432810722 | validation: 0.27070999222397096]
	TIME [epoch: 6.11 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15630654429988206		[learning rate: 0.0014648]
	Learning Rate: 0.00146477
	LOSS [training: 0.15630654429988206 | validation: 0.28790421174083075]
	TIME [epoch: 6.1 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1690056622586623		[learning rate: 0.0014583]
	Learning Rate: 0.0014583
	LOSS [training: 0.1690056622586623 | validation: 0.2845256091074146]
	TIME [epoch: 6.11 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16404791794292933		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.16404791794292933 | validation: 0.2783623998683122]
	TIME [epoch: 6.1 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15558542545916404		[learning rate: 0.0014454]
	Learning Rate: 0.00144544
	LOSS [training: 0.15558542545916404 | validation: 0.2805961531995578]
	TIME [epoch: 6.1 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15384287476619166		[learning rate: 0.0014391]
	Learning Rate: 0.00143905
	LOSS [training: 0.15384287476619166 | validation: 0.2888061353981939]
	TIME [epoch: 6.1 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15646332410074623		[learning rate: 0.0014327]
	Learning Rate: 0.0014327
	LOSS [training: 0.15646332410074623 | validation: 0.2993079067695867]
	TIME [epoch: 6.1 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1562327970370492		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.1562327970370492 | validation: 0.27318331630450066]
	TIME [epoch: 6.11 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15921685911207295		[learning rate: 0.0014201]
	Learning Rate: 0.00142006
	LOSS [training: 0.15921685911207295 | validation: 0.27832646654239895]
	TIME [epoch: 6.1 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15253160684860573		[learning rate: 0.0014138]
	Learning Rate: 0.00141379
	LOSS [training: 0.15253160684860573 | validation: 0.27127543428228446]
	TIME [epoch: 6.1 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15996120781634596		[learning rate: 0.0014075]
	Learning Rate: 0.00140754
	LOSS [training: 0.15996120781634596 | validation: 0.28796151322179486]
	TIME [epoch: 6.11 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15785557020162636		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.15785557020162636 | validation: 0.2867096824228886]
	TIME [epoch: 6.11 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15740074504532892		[learning rate: 0.0013951]
	Learning Rate: 0.00139513
	LOSS [training: 0.15740074504532892 | validation: 0.28260529288411274]
	TIME [epoch: 6.11 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1515100337149597		[learning rate: 0.001389]
	Learning Rate: 0.00138897
	LOSS [training: 0.1515100337149597 | validation: 0.29829655238769553]
	TIME [epoch: 6.1 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15673837716606348		[learning rate: 0.0013828]
	Learning Rate: 0.00138283
	LOSS [training: 0.15673837716606348 | validation: 0.2854668109035708]
	TIME [epoch: 6.11 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15042162239782603		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.15042162239782603 | validation: 0.3019251867738406]
	TIME [epoch: 6.12 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15489017162417998		[learning rate: 0.0013706]
	Learning Rate: 0.00137064
	LOSS [training: 0.15489017162417998 | validation: 0.26450319882261303]
	TIME [epoch: 6.11 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v10_20240712_145225/states/model_facs_v2_dec2b_2dpca_v10_489.pth
	Model improved!!!
EPOCH 490/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15595082877786676		[learning rate: 0.0013646]
	Learning Rate: 0.00136458
	LOSS [training: 0.15595082877786676 | validation: 0.28676911093167573]
	TIME [epoch: 6.1 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15283299503841521		[learning rate: 0.0013586]
	Learning Rate: 0.00135855
	LOSS [training: 0.15283299503841521 | validation: 0.270746316319903]
	TIME [epoch: 6.11 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15817378881098823		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.15817378881098823 | validation: 0.2888511886774813]
	TIME [epoch: 6.1 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15579067040254788		[learning rate: 0.0013466]
	Learning Rate: 0.00134658
	LOSS [training: 0.15579067040254788 | validation: 0.28076812895729975]
	TIME [epoch: 6.1 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15316569210060038		[learning rate: 0.0013406]
	Learning Rate: 0.00134063
	LOSS [training: 0.15316569210060038 | validation: 0.2778112222886776]
	TIME [epoch: 6.1 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15495220762803927		[learning rate: 0.0013347]
	Learning Rate: 0.0013347
	LOSS [training: 0.15495220762803927 | validation: 0.2937440152722599]
	TIME [epoch: 6.1 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1569106666171521		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.1569106666171521 | validation: 0.278348591477836]
	TIME [epoch: 6.11 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15739901074738774		[learning rate: 0.0013229]
	Learning Rate: 0.00132293
	LOSS [training: 0.15739901074738774 | validation: 0.288719953997461]
	TIME [epoch: 6.1 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1581019431267229		[learning rate: 0.0013171]
	Learning Rate: 0.00131709
	LOSS [training: 0.1581019431267229 | validation: 0.29877474580582175]
	TIME [epoch: 6.1 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.157777307940592		[learning rate: 0.0013113]
	Learning Rate: 0.00131127
	LOSS [training: 0.157777307940592 | validation: 0.28430182478843397]
	TIME [epoch: 6.1 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15109930988310563		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.15109930988310563 | validation: 0.3292648841373976]
	TIME [epoch: 6.1 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15282120136080507		[learning rate: 0.0012997]
	Learning Rate: 0.00129971
	LOSS [training: 0.15282120136080507 | validation: 0.28436492296868376]
	TIME [epoch: 33.3 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1607019165770846		[learning rate: 0.001294]
	Learning Rate: 0.00129397
	LOSS [training: 0.1607019165770846 | validation: 0.28365719832009684]
	TIME [epoch: 11.8 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1535140599970858		[learning rate: 0.0012882]
	Learning Rate: 0.00128825
	LOSS [training: 0.1535140599970858 | validation: 0.2904451124997115]
	TIME [epoch: 11.8 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14931563744205353		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.14931563744205353 | validation: 0.2823886402738789]
	TIME [epoch: 11.8 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15965681896621645		[learning rate: 0.0012769]
	Learning Rate: 0.00127689
	LOSS [training: 0.15965681896621645 | validation: 0.29750655694310546]
	TIME [epoch: 11.8 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15594202171101113		[learning rate: 0.0012712]
	Learning Rate: 0.00127125
	LOSS [training: 0.15594202171101113 | validation: 0.29454444556321707]
	TIME [epoch: 11.8 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15656700057415981		[learning rate: 0.0012656]
	Learning Rate: 0.00126563
	LOSS [training: 0.15656700057415981 | validation: 0.28629133770917126]
	TIME [epoch: 11.8 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15264855743796585		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.15264855743796585 | validation: 0.2832257035136395]
	TIME [epoch: 12.1 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1539124190053345		[learning rate: 0.0012545]
	Learning Rate: 0.00125447
	LOSS [training: 0.1539124190053345 | validation: 0.2945886136723371]
	TIME [epoch: 11.8 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15384376161781602		[learning rate: 0.0012489]
	Learning Rate: 0.00124893
	LOSS [training: 0.15384376161781602 | validation: 0.2699518379045364]
	TIME [epoch: 11.8 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1572322437121096		[learning rate: 0.0012434]
	Learning Rate: 0.00124341
	LOSS [training: 0.1572322437121096 | validation: 0.2807859244462365]
	TIME [epoch: 11.8 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15130583395325953		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.15130583395325953 | validation: 0.3026818621599598]
	TIME [epoch: 11.8 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15900939264645486		[learning rate: 0.0012324]
	Learning Rate: 0.00123245
	LOSS [training: 0.15900939264645486 | validation: 0.28884288755400467]
	TIME [epoch: 11.8 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1543982187855782		[learning rate: 0.001227]
	Learning Rate: 0.001227
	LOSS [training: 0.1543982187855782 | validation: 0.2800673309421865]
	TIME [epoch: 11.8 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16421566716582936		[learning rate: 0.0012216]
	Learning Rate: 0.00122158
	LOSS [training: 0.16421566716582936 | validation: 0.2722013823905588]
	TIME [epoch: 11.8 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1609010441544823		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.1609010441544823 | validation: 0.2802663500648442]
	TIME [epoch: 11.8 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15955439902225335		[learning rate: 0.0012108]
	Learning Rate: 0.00121081
	LOSS [training: 0.15955439902225335 | validation: 0.2869828092789404]
	TIME [epoch: 11.8 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1449461223405169		[learning rate: 0.0012055]
	Learning Rate: 0.00120546
	LOSS [training: 0.1449461223405169 | validation: 0.28125795980626594]
	TIME [epoch: 11.8 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15713085193274415		[learning rate: 0.0012001]
	Learning Rate: 0.00120014
	LOSS [training: 0.15713085193274415 | validation: 0.2632063533165633]
	TIME [epoch: 11.8 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v10_20240712_145225/states/model_facs_v2_dec2b_2dpca_v10_519.pth
	Model improved!!!
EPOCH 520/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15596254045678812		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.15596254045678812 | validation: 0.29812168366217173]
	TIME [epoch: 11.8 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15240152414193053		[learning rate: 0.0011896]
	Learning Rate: 0.00118956
	LOSS [training: 0.15240152414193053 | validation: 0.29110864663104197]
	TIME [epoch: 11.8 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1525275712313258		[learning rate: 0.0011843]
	Learning Rate: 0.0011843
	LOSS [training: 0.1525275712313258 | validation: 0.27703229622180103]
	TIME [epoch: 11.8 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1500444245265598		[learning rate: 0.0011791]
	Learning Rate: 0.00117907
	LOSS [training: 0.1500444245265598 | validation: 0.27794533668836996]
	TIME [epoch: 11.8 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15015796387195404		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.15015796387195404 | validation: 0.2844708341080022]
	TIME [epoch: 11.8 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15529709851271037		[learning rate: 0.0011687]
	Learning Rate: 0.00116867
	LOSS [training: 0.15529709851271037 | validation: 0.29819291293029276]
	TIME [epoch: 11.8 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15864305257212286		[learning rate: 0.0011635]
	Learning Rate: 0.00116351
	LOSS [training: 0.15864305257212286 | validation: 0.29100951281301524]
	TIME [epoch: 11.8 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1566493681982743		[learning rate: 0.0011584]
	Learning Rate: 0.00115837
	LOSS [training: 0.1566493681982743 | validation: 0.2729154816445547]
	TIME [epoch: 11.8 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15351763017909342		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.15351763017909342 | validation: 0.27199663449464795]
	TIME [epoch: 11.8 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15415435652759435		[learning rate: 0.0011482]
	Learning Rate: 0.00114815
	LOSS [training: 0.15415435652759435 | validation: 0.2817890259259866]
	TIME [epoch: 11.8 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15525470120654872		[learning rate: 0.0011431]
	Learning Rate: 0.00114308
	LOSS [training: 0.15525470120654872 | validation: 0.28105035822481667]
	TIME [epoch: 11.8 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1543073180716365		[learning rate: 0.001138]
	Learning Rate: 0.00113803
	LOSS [training: 0.1543073180716365 | validation: 0.2778876712691049]
	TIME [epoch: 11.8 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15226125121011197		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.15226125121011197 | validation: 0.2897141540693525]
	TIME [epoch: 11.8 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15336409303729168		[learning rate: 0.001128]
	Learning Rate: 0.001128
	LOSS [training: 0.15336409303729168 | validation: 0.27613473839209235]
	TIME [epoch: 11.8 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15639793959101558		[learning rate: 0.001123]
	Learning Rate: 0.00112301
	LOSS [training: 0.15639793959101558 | validation: 0.2715073366245978]
	TIME [epoch: 11.8 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1552985250931697		[learning rate: 0.0011181]
	Learning Rate: 0.00111805
	LOSS [training: 0.1552985250931697 | validation: 0.28602485511212133]
	TIME [epoch: 11.8 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15502872463801842		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.15502872463801842 | validation: 0.27675568161674063]
	TIME [epoch: 11.8 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1515896211633985		[learning rate: 0.0011082]
	Learning Rate: 0.00110819
	LOSS [training: 0.1515896211633985 | validation: 0.30320043424472076]
	TIME [epoch: 11.8 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1505686027984166		[learning rate: 0.0011033]
	Learning Rate: 0.0011033
	LOSS [training: 0.1505686027984166 | validation: 0.27558159861103937]
	TIME [epoch: 11.8 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16138671904115093		[learning rate: 0.0010984]
	Learning Rate: 0.00109842
	LOSS [training: 0.16138671904115093 | validation: 0.29238288660346845]
	TIME [epoch: 11.8 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17863857547698386		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.17863857547698386 | validation: 0.2811393692126838]
	TIME [epoch: 11.8 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1544787501499036		[learning rate: 0.0010887]
	Learning Rate: 0.00108874
	LOSS [training: 0.1544787501499036 | validation: 0.2920967928624976]
	TIME [epoch: 11.8 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14912885261901324		[learning rate: 0.0010839]
	Learning Rate: 0.00108393
	LOSS [training: 0.14912885261901324 | validation: 0.27849074584706535]
	TIME [epoch: 11.8 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1552130503006374		[learning rate: 0.0010791]
	Learning Rate: 0.00107914
	LOSS [training: 0.1552130503006374 | validation: 0.2866911581646087]
	TIME [epoch: 11.8 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15073697946535977		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.15073697946535977 | validation: 0.27961685761658883]
	TIME [epoch: 11.8 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.152558113138713		[learning rate: 0.0010696]
	Learning Rate: 0.00106962
	LOSS [training: 0.152558113138713 | validation: 0.29844063181249464]
	TIME [epoch: 11.8 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15311014607562673		[learning rate: 0.0010649]
	Learning Rate: 0.0010649
	LOSS [training: 0.15311014607562673 | validation: 0.2788689414542502]
	TIME [epoch: 11.8 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15581652019233114		[learning rate: 0.0010602]
	Learning Rate: 0.00106019
	LOSS [training: 0.15581652019233114 | validation: 0.27348631507920723]
	TIME [epoch: 11.8 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1527223124434449		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.1527223124434449 | validation: 0.28451119183883766]
	TIME [epoch: 11.8 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15267731743248664		[learning rate: 0.0010508]
	Learning Rate: 0.00105084
	LOSS [training: 0.15267731743248664 | validation: 0.2817989512153175]
	TIME [epoch: 11.8 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1575256445058549		[learning rate: 0.0010462]
	Learning Rate: 0.0010462
	LOSS [training: 0.1575256445058549 | validation: 0.2903841543458877]
	TIME [epoch: 11.8 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15147897921237127		[learning rate: 0.0010416]
	Learning Rate: 0.00104158
	LOSS [training: 0.15147897921237127 | validation: 0.2755044652756953]
	TIME [epoch: 11.8 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15261426972882774		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.15261426972882774 | validation: 0.27278318098427]
	TIME [epoch: 11.8 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16189369402473647		[learning rate: 0.0010324]
	Learning Rate: 0.0010324
	LOSS [training: 0.16189369402473647 | validation: 0.28606037699196835]
	TIME [epoch: 11.8 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1514866939600779		[learning rate: 0.0010278]
	Learning Rate: 0.00102783
	LOSS [training: 0.1514866939600779 | validation: 0.2811964470921459]
	TIME [epoch: 11.8 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1543136014883611		[learning rate: 0.0010233]
	Learning Rate: 0.00102329
	LOSS [training: 0.1543136014883611 | validation: 0.284052034666144]
	TIME [epoch: 11.8 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1543207381861943		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.1543207381861943 | validation: 0.2819606090573752]
	TIME [epoch: 11.8 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.156669626585408		[learning rate: 0.0010143]
	Learning Rate: 0.00101427
	LOSS [training: 0.156669626585408 | validation: 0.278010234127976]
	TIME [epoch: 11.8 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15540152701432847		[learning rate: 0.0010098]
	Learning Rate: 0.00100979
	LOSS [training: 0.15540152701432847 | validation: 0.2750365475542772]
	TIME [epoch: 11.8 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1562906558327708		[learning rate: 0.0010053]
	Learning Rate: 0.00100533
	LOSS [training: 0.1562906558327708 | validation: 0.2751151567120043]
	TIME [epoch: 11.8 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15467909784901465		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.15467909784901465 | validation: 0.2719126709158228]
	TIME [epoch: 11.8 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15291828190036658		[learning rate: 0.00099646]
	Learning Rate: 0.000996464
	LOSS [training: 0.15291828190036658 | validation: 0.27640113052248105]
	TIME [epoch: 11.8 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14891138329933645		[learning rate: 0.00099206]
	Learning Rate: 0.000992061
	LOSS [training: 0.14891138329933645 | validation: 0.27655891312930625]
	TIME [epoch: 11.8 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15670297631392022		[learning rate: 0.00098768]
	Learning Rate: 0.000987678
	LOSS [training: 0.15670297631392022 | validation: 0.289436123606359]
	TIME [epoch: 11.8 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15098414485895156		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.15098414485895156 | validation: 0.28599488784454685]
	TIME [epoch: 11.8 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15652472585431884		[learning rate: 0.00097897]
	Learning Rate: 0.00097897
	LOSS [training: 0.15652472585431884 | validation: 0.2848834712382664]
	TIME [epoch: 11.8 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1570552110025535		[learning rate: 0.00097464]
	Learning Rate: 0.000974644
	LOSS [training: 0.1570552110025535 | validation: 0.26805216043054]
	TIME [epoch: 11.8 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15010017208172183		[learning rate: 0.00097034]
	Learning Rate: 0.000970338
	LOSS [training: 0.15010017208172183 | validation: 0.2746048537489255]
	TIME [epoch: 11.8 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16689716318858971		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.16689716318858971 | validation: 0.29735879690709843]
	TIME [epoch: 11.8 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1590184507935981		[learning rate: 0.00096178]
	Learning Rate: 0.000961783
	LOSS [training: 0.1590184507935981 | validation: 0.2725992187546038]
	TIME [epoch: 11.8 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15078962952975544		[learning rate: 0.00095753]
	Learning Rate: 0.000957533
	LOSS [training: 0.15078962952975544 | validation: 0.2868245297978054]
	TIME [epoch: 11.8 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1584822846676889		[learning rate: 0.0009533]
	Learning Rate: 0.000953303
	LOSS [training: 0.1584822846676889 | validation: 0.27725828082297826]
	TIME [epoch: 11.8 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1530237238829929		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.1530237238829929 | validation: 0.28782043577580885]
	TIME [epoch: 11.8 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.147175635970716		[learning rate: 0.0009449]
	Learning Rate: 0.000944897
	LOSS [training: 0.147175635970716 | validation: 0.28332758987080614]
	TIME [epoch: 11.8 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15457758632136248		[learning rate: 0.00094072]
	Learning Rate: 0.000940723
	LOSS [training: 0.15457758632136248 | validation: 0.28074646014050714]
	TIME [epoch: 11.8 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15215436469950055		[learning rate: 0.00093657]
	Learning Rate: 0.000936566
	LOSS [training: 0.15215436469950055 | validation: 0.27805322234860846]
	TIME [epoch: 11.8 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15753286909463488		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.15753286909463488 | validation: 0.2901259833114219]
	TIME [epoch: 11.8 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15297341291681615		[learning rate: 0.00092831]
	Learning Rate: 0.000928309
	LOSS [training: 0.15297341291681615 | validation: 0.2928869972805418]
	TIME [epoch: 11.8 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1691894000538061		[learning rate: 0.00092421]
	Learning Rate: 0.000924207
	LOSS [training: 0.1691894000538061 | validation: 0.2832053627801257]
	TIME [epoch: 11.8 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15183231476126585		[learning rate: 0.00092012]
	Learning Rate: 0.000920124
	LOSS [training: 0.15183231476126585 | validation: 0.28354388373936845]
	TIME [epoch: 11.8 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15727510649138537		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.15727510649138537 | validation: 0.2869452055400554]
	TIME [epoch: 11.8 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1524459698949868		[learning rate: 0.00091201]
	Learning Rate: 0.000912011
	LOSS [training: 0.1524459698949868 | validation: 0.2872044281843261]
	TIME [epoch: 11.8 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15265542400249205		[learning rate: 0.00090798]
	Learning Rate: 0.000907981
	LOSS [training: 0.15265542400249205 | validation: 0.28040545608390066]
	TIME [epoch: 11.8 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15443723458231814		[learning rate: 0.00090397]
	Learning Rate: 0.00090397
	LOSS [training: 0.15443723458231814 | validation: 0.2818821444442128]
	TIME [epoch: 11.8 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15193977504630243		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.15193977504630243 | validation: 0.28062730388416873]
	TIME [epoch: 11.8 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15239565672512365		[learning rate: 0.000896]
	Learning Rate: 0.000895999
	LOSS [training: 0.15239565672512365 | validation: 0.2765042301684537]
	TIME [epoch: 11.8 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15294312307164418		[learning rate: 0.00089204]
	Learning Rate: 0.000892041
	LOSS [training: 0.15294312307164418 | validation: 0.2903392982955924]
	TIME [epoch: 11.8 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1553008290012699		[learning rate: 0.0008881]
	Learning Rate: 0.000888099
	LOSS [training: 0.1553008290012699 | validation: 0.2851275238963092]
	TIME [epoch: 11.8 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15495397612656298		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.15495397612656298 | validation: 0.2775652932003271]
	TIME [epoch: 11.8 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15321027216551392		[learning rate: 0.00088027]
	Learning Rate: 0.000880269
	LOSS [training: 0.15321027216551392 | validation: 0.2736752090696761]
	TIME [epoch: 11.8 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15588745470750398		[learning rate: 0.00087638]
	Learning Rate: 0.00087638
	LOSS [training: 0.15588745470750398 | validation: 0.2851173463791139]
	TIME [epoch: 11.8 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15469361033719015		[learning rate: 0.00087251]
	Learning Rate: 0.000872508
	LOSS [training: 0.15469361033719015 | validation: 0.2756137239245444]
	TIME [epoch: 11.8 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15415980599730866		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.15415980599730866 | validation: 0.27793194499738627]
	TIME [epoch: 11.8 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15154375682421053		[learning rate: 0.00086481]
	Learning Rate: 0.000864815
	LOSS [training: 0.15154375682421053 | validation: 0.2800596632391119]
	TIME [epoch: 11.8 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15349536499121474		[learning rate: 0.00086099]
	Learning Rate: 0.000860994
	LOSS [training: 0.15349536499121474 | validation: 0.26554015726803204]
	TIME [epoch: 11.8 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1534869310467498		[learning rate: 0.00085719]
	Learning Rate: 0.00085719
	LOSS [training: 0.1534869310467498 | validation: 0.27975368854816146]
	TIME [epoch: 11.8 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1515037316831252		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.1515037316831252 | validation: 0.2904358414618862]
	TIME [epoch: 11.8 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15520495675307197		[learning rate: 0.00084963]
	Learning Rate: 0.000849632
	LOSS [training: 0.15520495675307197 | validation: 0.2788884251402331]
	TIME [epoch: 11.8 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15329479843627572		[learning rate: 0.00084588]
	Learning Rate: 0.000845878
	LOSS [training: 0.15329479843627572 | validation: 0.27512932408480945]
	TIME [epoch: 11.8 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1521364827457131		[learning rate: 0.00084214]
	Learning Rate: 0.000842141
	LOSS [training: 0.1521364827457131 | validation: 0.27233255354504066]
	TIME [epoch: 11.8 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15439099625810312		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.15439099625810312 | validation: 0.2938872315406926]
	TIME [epoch: 11.8 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15354173836571905		[learning rate: 0.00083472]
	Learning Rate: 0.000834715
	LOSS [training: 0.15354173836571905 | validation: 0.27972585661412513]
	TIME [epoch: 11.8 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15671566865027461		[learning rate: 0.00083103]
	Learning Rate: 0.000831028
	LOSS [training: 0.15671566865027461 | validation: 0.2768590832333909]
	TIME [epoch: 11.8 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15872294392556377		[learning rate: 0.00082736]
	Learning Rate: 0.000827356
	LOSS [training: 0.15872294392556377 | validation: 0.2773668861271358]
	TIME [epoch: 11.8 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14687569873917344		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.14687569873917344 | validation: 0.280197805900509]
	TIME [epoch: 11.8 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14930950944219426		[learning rate: 0.00082006]
	Learning Rate: 0.000820061
	LOSS [training: 0.14930950944219426 | validation: 0.27920064338857864]
	TIME [epoch: 11.8 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1495724677820727		[learning rate: 0.00081644]
	Learning Rate: 0.000816438
	LOSS [training: 0.1495724677820727 | validation: 0.290741684879401]
	TIME [epoch: 11.8 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1699392343217326		[learning rate: 0.00081283]
	Learning Rate: 0.000812831
	LOSS [training: 0.1699392343217326 | validation: 0.299419563610985]
	TIME [epoch: 11.8 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1564238957756936		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.1564238957756936 | validation: 0.27923682663023003]
	TIME [epoch: 11.8 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1507336038664809		[learning rate: 0.00080566]
	Learning Rate: 0.000805664
	LOSS [training: 0.1507336038664809 | validation: 0.2809175474265714]
	TIME [epoch: 11.8 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1514587752292993		[learning rate: 0.0008021]
	Learning Rate: 0.000802104
	LOSS [training: 0.1514587752292993 | validation: 0.2854663498649993]
	TIME [epoch: 11.8 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14817594072148796		[learning rate: 0.00079856]
	Learning Rate: 0.00079856
	LOSS [training: 0.14817594072148796 | validation: 0.28108680829269495]
	TIME [epoch: 11.8 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15275494812194218		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.15275494812194218 | validation: 0.27562137715281865]
	TIME [epoch: 11.8 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15843806460594628		[learning rate: 0.00079152]
	Learning Rate: 0.000791519
	LOSS [training: 0.15843806460594628 | validation: 0.28701648805467306]
	TIME [epoch: 11.8 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15311098426446632		[learning rate: 0.00078802]
	Learning Rate: 0.000788022
	LOSS [training: 0.15311098426446632 | validation: 0.2926747961065227]
	TIME [epoch: 11.8 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15255723650844208		[learning rate: 0.00078454]
	Learning Rate: 0.000784541
	LOSS [training: 0.15255723650844208 | validation: 0.27311240518426816]
	TIME [epoch: 11.8 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15658798403418187		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.15658798403418187 | validation: 0.2841978836533097]
	TIME [epoch: 11.8 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15580093205031087		[learning rate: 0.00077762]
	Learning Rate: 0.000777623
	LOSS [training: 0.15580093205031087 | validation: 0.28749191741885866]
	TIME [epoch: 11.8 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15273634452689092		[learning rate: 0.00077419]
	Learning Rate: 0.000774188
	LOSS [training: 0.15273634452689092 | validation: 0.280549432711402]
	TIME [epoch: 11.8 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15079153993169753		[learning rate: 0.00077077]
	Learning Rate: 0.000770767
	LOSS [training: 0.15079153993169753 | validation: 0.28567363650941946]
	TIME [epoch: 11.8 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1516539455175563		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.1516539455175563 | validation: 0.29102937110356253]
	TIME [epoch: 11.8 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14985799373172304		[learning rate: 0.00076397]
	Learning Rate: 0.000763971
	LOSS [training: 0.14985799373172304 | validation: 0.27151379970243467]
	TIME [epoch: 11.8 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15238498533742562		[learning rate: 0.0007606]
	Learning Rate: 0.000760596
	LOSS [training: 0.15238498533742562 | validation: 0.2802124147147858]
	TIME [epoch: 11.8 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14829655899868285		[learning rate: 0.00075724]
	Learning Rate: 0.000757235
	LOSS [training: 0.14829655899868285 | validation: 0.27430450877968277]
	TIME [epoch: 11.8 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15228383114765393		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.15228383114765393 | validation: 0.29030624997335225]
	TIME [epoch: 11.8 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15022566180563815		[learning rate: 0.00075056]
	Learning Rate: 0.000750559
	LOSS [training: 0.15022566180563815 | validation: 0.28471656429785425]
	TIME [epoch: 11.8 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15760318366748022		[learning rate: 0.00074724]
	Learning Rate: 0.000747242
	LOSS [training: 0.15760318366748022 | validation: 0.2770314294335945]
	TIME [epoch: 11.8 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15352442271733802		[learning rate: 0.00074394]
	Learning Rate: 0.000743941
	LOSS [training: 0.15352442271733802 | validation: 0.2855093924789126]
	TIME [epoch: 11.8 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15638742277463763		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.15638742277463763 | validation: 0.29017457050890866]
	TIME [epoch: 11.8 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15065197697883484		[learning rate: 0.00073738]
	Learning Rate: 0.000737382
	LOSS [training: 0.15065197697883484 | validation: 0.2919774255040211]
	TIME [epoch: 11.8 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1570667339923941		[learning rate: 0.00073412]
	Learning Rate: 0.000734124
	LOSS [training: 0.1570667339923941 | validation: 0.29683240151535656]
	TIME [epoch: 11.8 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1521248180261859		[learning rate: 0.00073088]
	Learning Rate: 0.00073088
	LOSS [training: 0.1521248180261859 | validation: 0.27890909664565144]
	TIME [epoch: 11.8 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14762817853343912		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 0.14762817853343912 | validation: 0.2802642957611366]
	TIME [epoch: 11.8 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15249008449796286		[learning rate: 0.00072444]
	Learning Rate: 0.000724436
	LOSS [training: 0.15249008449796286 | validation: 0.2896019967148085]
	TIME [epoch: 11.8 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15752031696220775		[learning rate: 0.00072124]
	Learning Rate: 0.000721235
	LOSS [training: 0.15752031696220775 | validation: 0.288227093345824]
	TIME [epoch: 11.8 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1532982427305024		[learning rate: 0.00071805]
	Learning Rate: 0.000718049
	LOSS [training: 0.1532982427305024 | validation: 0.2878845735347972]
	TIME [epoch: 11.8 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15184465402373315		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.15184465402373315 | validation: 0.28814739776119586]
	TIME [epoch: 11.8 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15483803516209824		[learning rate: 0.00071172]
	Learning Rate: 0.000711718
	LOSS [training: 0.15483803516209824 | validation: 0.2823387922031364]
	TIME [epoch: 11.8 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15330826828317218		[learning rate: 0.00070857]
	Learning Rate: 0.000708573
	LOSS [training: 0.15330826828317218 | validation: 0.2607359669453189]
	TIME [epoch: 11.8 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v10_20240712_145225/states/model_facs_v2_dec2b_2dpca_v10_638.pth
	Model improved!!!
EPOCH 639/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15015573393202417		[learning rate: 0.00070544]
	Learning Rate: 0.000705442
	LOSS [training: 0.15015573393202417 | validation: 0.28266820321769465]
	TIME [epoch: 11.8 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15144292166219714		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.15144292166219714 | validation: 0.26776244820950257]
	TIME [epoch: 11.8 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15070464390163713		[learning rate: 0.00069922]
	Learning Rate: 0.000699222
	LOSS [training: 0.15070464390163713 | validation: 0.27944061755813115]
	TIME [epoch: 11.8 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15524546845073256		[learning rate: 0.00069613]
	Learning Rate: 0.000696133
	LOSS [training: 0.15524546845073256 | validation: 0.28988109275470814]
	TIME [epoch: 11.8 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15041753530222876		[learning rate: 0.00069306]
	Learning Rate: 0.000693058
	LOSS [training: 0.15041753530222876 | validation: 0.2782237293511698]
	TIME [epoch: 11.8 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15235536974956307		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 0.15235536974956307 | validation: 0.282811239709569]
	TIME [epoch: 11.8 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1513093199186424		[learning rate: 0.00068695]
	Learning Rate: 0.000686947
	LOSS [training: 0.1513093199186424 | validation: 0.279386349027065]
	TIME [epoch: 11.8 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1504467882943299		[learning rate: 0.00068391]
	Learning Rate: 0.000683912
	LOSS [training: 0.1504467882943299 | validation: 0.27363424906525713]
	TIME [epoch: 11.8 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1508001255918666		[learning rate: 0.00068089]
	Learning Rate: 0.00068089
	LOSS [training: 0.1508001255918666 | validation: 0.28598807077699984]
	TIME [epoch: 11.8 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14893529845629522		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 0.14893529845629522 | validation: 0.2800687216995404]
	TIME [epoch: 11.8 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15788738502188643		[learning rate: 0.00067489]
	Learning Rate: 0.000674887
	LOSS [training: 0.15788738502188643 | validation: 0.2861561118984211]
	TIME [epoch: 11.8 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15410529811561732		[learning rate: 0.0006719]
	Learning Rate: 0.000671905
	LOSS [training: 0.15410529811561732 | validation: 0.2737351428581877]
	TIME [epoch: 11.8 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15225542913428253		[learning rate: 0.00066894]
	Learning Rate: 0.000668936
	LOSS [training: 0.15225542913428253 | validation: 0.2723382926803815]
	TIME [epoch: 11.8 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1522429156564291		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 0.1522429156564291 | validation: 0.28742298794216925]
	TIME [epoch: 11.8 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14963814702206676		[learning rate: 0.00066304]
	Learning Rate: 0.000663038
	LOSS [training: 0.14963814702206676 | validation: 0.28020083430305043]
	TIME [epoch: 11.8 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1513343516343188		[learning rate: 0.00066011]
	Learning Rate: 0.000660109
	LOSS [training: 0.1513343516343188 | validation: 0.28492068364711703]
	TIME [epoch: 11.8 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15185632020050105		[learning rate: 0.00065719]
	Learning Rate: 0.000657192
	LOSS [training: 0.15185632020050105 | validation: 0.2748489381901097]
	TIME [epoch: 11.8 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1506709034578846		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 0.1506709034578846 | validation: 0.2758796077336895]
	TIME [epoch: 11.8 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1540024932531951		[learning rate: 0.0006514]
	Learning Rate: 0.000651398
	LOSS [training: 0.1540024932531951 | validation: 0.2979943636268814]
	TIME [epoch: 11.8 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15969316324135263		[learning rate: 0.00064852]
	Learning Rate: 0.00064852
	LOSS [training: 0.15969316324135263 | validation: 0.2827825252384945]
	TIME [epoch: 11.8 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14858819196593326		[learning rate: 0.00064565]
	Learning Rate: 0.000645654
	LOSS [training: 0.14858819196593326 | validation: 0.26825580971800533]
	TIME [epoch: 11.8 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15224936813173517		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 0.15224936813173517 | validation: 0.2768424683744223]
	TIME [epoch: 11.8 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15773164360413253		[learning rate: 0.00063996]
	Learning Rate: 0.000639962
	LOSS [training: 0.15773164360413253 | validation: 0.2785337554902911]
	TIME [epoch: 11.8 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15081013519132025		[learning rate: 0.00063713]
	Learning Rate: 0.000637134
	LOSS [training: 0.15081013519132025 | validation: 0.2976435913214417]
	TIME [epoch: 11.8 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15856409974017832		[learning rate: 0.00063432]
	Learning Rate: 0.000634319
	LOSS [training: 0.15856409974017832 | validation: 0.27825803243667974]
	TIME [epoch: 11.8 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15016969790723092		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 0.15016969790723092 | validation: 0.2799221353471474]
	TIME [epoch: 11.8 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1545954863325461		[learning rate: 0.00062873]
	Learning Rate: 0.000628726
	LOSS [training: 0.1545954863325461 | validation: 0.28298554010537147]
	TIME [epoch: 11.8 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15219713343737581		[learning rate: 0.00062595]
	Learning Rate: 0.000625948
	LOSS [training: 0.15219713343737581 | validation: 0.29523579717871223]
	TIME [epoch: 11.8 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15239885685220203		[learning rate: 0.00062318]
	Learning Rate: 0.000623183
	LOSS [training: 0.15239885685220203 | validation: 0.28201918191564534]
	TIME [epoch: 11.8 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15256712988713855		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 0.15256712988713855 | validation: 0.2797213187048042]
	TIME [epoch: 11.8 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15546005263877702		[learning rate: 0.00061769]
	Learning Rate: 0.000617688
	LOSS [training: 0.15546005263877702 | validation: 0.2875099930376933]
	TIME [epoch: 11.8 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15156794172453608		[learning rate: 0.00061496]
	Learning Rate: 0.000614959
	LOSS [training: 0.15156794172453608 | validation: 0.2698250854581473]
	TIME [epoch: 11.8 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14816524791513838		[learning rate: 0.00061224]
	Learning Rate: 0.000612242
	LOSS [training: 0.14816524791513838 | validation: 0.2801708913989881]
	TIME [epoch: 11.8 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15223928375424758		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 0.15223928375424758 | validation: 0.28234190189043246]
	TIME [epoch: 11.8 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1485544246403206		[learning rate: 0.00060684]
	Learning Rate: 0.000606844
	LOSS [training: 0.1485544246403206 | validation: 0.2792000959647552]
	TIME [epoch: 11.8 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1515186613165686		[learning rate: 0.00060416]
	Learning Rate: 0.000604163
	LOSS [training: 0.1515186613165686 | validation: 0.28536307736379485]
	TIME [epoch: 11.8 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14999398896325195		[learning rate: 0.00060149]
	Learning Rate: 0.000601493
	LOSS [training: 0.14999398896325195 | validation: 0.28070730877733985]
	TIME [epoch: 11.8 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14852913914448196		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.14852913914448196 | validation: 0.2825072340635275]
	TIME [epoch: 11.8 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14584370480536787		[learning rate: 0.00059619]
	Learning Rate: 0.00059619
	LOSS [training: 0.14584370480536787 | validation: 0.2844807875308037]
	TIME [epoch: 11.8 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15493159889750102		[learning rate: 0.00059356]
	Learning Rate: 0.000593556
	LOSS [training: 0.15493159889750102 | validation: 0.2873456100493972]
	TIME [epoch: 11.8 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15254792332940162		[learning rate: 0.00059093]
	Learning Rate: 0.000590933
	LOSS [training: 0.15254792332940162 | validation: 0.26853404946858417]
	TIME [epoch: 11.8 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15326944335902443		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 0.15326944335902443 | validation: 0.2791212613566441]
	TIME [epoch: 11.8 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15487058440960202		[learning rate: 0.00058572]
	Learning Rate: 0.000585723
	LOSS [training: 0.15487058440960202 | validation: 0.28424529707060514]
	TIME [epoch: 11.8 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15036085805716898		[learning rate: 0.00058314]
	Learning Rate: 0.000583135
	LOSS [training: 0.15036085805716898 | validation: 0.27498047455766567]
	TIME [epoch: 11.8 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1507548742831086		[learning rate: 0.00058056]
	Learning Rate: 0.000580559
	LOSS [training: 0.1507548742831086 | validation: 0.28258917634630354]
	TIME [epoch: 11.8 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1533286745298965		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 0.1533286745298965 | validation: 0.28610535865084713]
	TIME [epoch: 11.8 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1568763161198562		[learning rate: 0.00057544]
	Learning Rate: 0.00057544
	LOSS [training: 0.1568763161198562 | validation: 0.275724570989376]
	TIME [epoch: 11.8 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14676961740720645		[learning rate: 0.0005729]
	Learning Rate: 0.000572898
	LOSS [training: 0.14676961740720645 | validation: 0.2860933359106389]
	TIME [epoch: 11.8 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1556281531192828		[learning rate: 0.00057037]
	Learning Rate: 0.000570366
	LOSS [training: 0.1556281531192828 | validation: 0.28019490485823384]
	TIME [epoch: 11.8 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14931689914502744		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 0.14931689914502744 | validation: 0.2827447399017083]
	TIME [epoch: 11.8 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14639496045299388		[learning rate: 0.00056534]
	Learning Rate: 0.000565337
	LOSS [training: 0.14639496045299388 | validation: 0.2739368485323123]
	TIME [epoch: 11.8 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15389327066876493		[learning rate: 0.00056284]
	Learning Rate: 0.00056284
	LOSS [training: 0.15389327066876493 | validation: 0.28242102955648957]
	TIME [epoch: 11.8 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15005370619091735		[learning rate: 0.00056035]
	Learning Rate: 0.000560353
	LOSS [training: 0.15005370619091735 | validation: 0.2891709005504195]
	TIME [epoch: 11.8 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14966456399389202		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 0.14966456399389202 | validation: 0.277835229860248]
	TIME [epoch: 11.8 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15401742439324767		[learning rate: 0.00055541]
	Learning Rate: 0.000555412
	LOSS [training: 0.15401742439324767 | validation: 0.2828704547810253]
	TIME [epoch: 11.8 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15931687778244824		[learning rate: 0.00055296]
	Learning Rate: 0.000552958
	LOSS [training: 0.15931687778244824 | validation: 0.2859090668543662]
	TIME [epoch: 11.8 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15052961924996017		[learning rate: 0.00055052]
	Learning Rate: 0.000550515
	LOSS [training: 0.15052961924996017 | validation: 0.2722754879966485]
	TIME [epoch: 11.8 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15262115445997285		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 0.15262115445997285 | validation: 0.2924420704990937]
	TIME [epoch: 11.8 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1458902436811358		[learning rate: 0.00054566]
	Learning Rate: 0.000545661
	LOSS [training: 0.1458902436811358 | validation: 0.27489148720723877]
	TIME [epoch: 11.8 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1502629404802927		[learning rate: 0.00054325]
	Learning Rate: 0.00054325
	LOSS [training: 0.1502629404802927 | validation: 0.28378446268939156]
	TIME [epoch: 11.8 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15035554355746253		[learning rate: 0.00054085]
	Learning Rate: 0.00054085
	LOSS [training: 0.15035554355746253 | validation: 0.2774990487991169]
	TIME [epoch: 11.8 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1489405518867313		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 0.1489405518867313 | validation: 0.2816114083874592]
	TIME [epoch: 11.8 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15315911156492562		[learning rate: 0.00053608]
	Learning Rate: 0.000536081
	LOSS [training: 0.15315911156492562 | validation: 0.284882197394918]
	TIME [epoch: 11.8 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15701830403095954		[learning rate: 0.00053371]
	Learning Rate: 0.000533713
	LOSS [training: 0.15701830403095954 | validation: 0.28511786069371364]
	TIME [epoch: 11.8 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15261057587328933		[learning rate: 0.00053135]
	Learning Rate: 0.000531355
	LOSS [training: 0.15261057587328933 | validation: 0.2825039578747877]
	TIME [epoch: 11.8 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14534482430160886		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 0.14534482430160886 | validation: 0.28636779766597625]
	TIME [epoch: 11.8 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.147110049848578		[learning rate: 0.00052667]
	Learning Rate: 0.00052667
	LOSS [training: 0.147110049848578 | validation: 0.28398592891578706]
	TIME [epoch: 11.8 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15411190802383765		[learning rate: 0.00052434]
	Learning Rate: 0.000524343
	LOSS [training: 0.15411190802383765 | validation: 0.27738648208818734]
	TIME [epoch: 11.8 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15388567873752146		[learning rate: 0.00052203]
	Learning Rate: 0.000522026
	LOSS [training: 0.15388567873752146 | validation: 0.28257856290764266]
	TIME [epoch: 11.8 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14921774488395267		[learning rate: 0.00051972]
	Learning Rate: 0.00051972
	LOSS [training: 0.14921774488395267 | validation: 0.2803414650186192]
	TIME [epoch: 11.8 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1503503689905791		[learning rate: 0.00051742]
	Learning Rate: 0.000517423
	LOSS [training: 0.1503503689905791 | validation: 0.2713372587482084]
	TIME [epoch: 11.8 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1549845509962669		[learning rate: 0.00051514]
	Learning Rate: 0.000515137
	LOSS [training: 0.1549845509962669 | validation: 0.2856208519335046]
	TIME [epoch: 11.8 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15624808777511906		[learning rate: 0.00051286]
	Learning Rate: 0.000512861
	LOSS [training: 0.15624808777511906 | validation: 0.28064473058362116]
	TIME [epoch: 11.8 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15191924869344176		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 0.15191924869344176 | validation: 0.28793651116389735]
	TIME [epoch: 11.8 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15170867496754462		[learning rate: 0.00050834]
	Learning Rate: 0.000508339
	LOSS [training: 0.15170867496754462 | validation: 0.2878643558219889]
	TIME [epoch: 11.8 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15133933261675137		[learning rate: 0.00050609]
	Learning Rate: 0.000506094
	LOSS [training: 0.15133933261675137 | validation: 0.27590129865070073]
	TIME [epoch: 11.8 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1506505796931139		[learning rate: 0.00050386]
	Learning Rate: 0.000503858
	LOSS [training: 0.1506505796931139 | validation: 0.2825684366535885]
	TIME [epoch: 11.8 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1514669005798654		[learning rate: 0.00050163]
	Learning Rate: 0.000501631
	LOSS [training: 0.1514669005798654 | validation: 0.28548998532462255]
	TIME [epoch: 11.8 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15165162083479639		[learning rate: 0.00049941]
	Learning Rate: 0.000499415
	LOSS [training: 0.15165162083479639 | validation: 0.27637522459474284]
	TIME [epoch: 11.8 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14938283479315242		[learning rate: 0.00049721]
	Learning Rate: 0.000497208
	LOSS [training: 0.14938283479315242 | validation: 0.28161654782250156]
	TIME [epoch: 11.8 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1531484449973773		[learning rate: 0.00049501]
	Learning Rate: 0.000495012
	LOSS [training: 0.1531484449973773 | validation: 0.28401087007993436]
	TIME [epoch: 11.8 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15103864781650764		[learning rate: 0.00049282]
	Learning Rate: 0.000492825
	LOSS [training: 0.15103864781650764 | validation: 0.27594831496583816]
	TIME [epoch: 11.8 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15034439004509076		[learning rate: 0.00049065]
	Learning Rate: 0.000490647
	LOSS [training: 0.15034439004509076 | validation: 0.2904148532669662]
	TIME [epoch: 11.8 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1508978816426294		[learning rate: 0.00048848]
	Learning Rate: 0.000488479
	LOSS [training: 0.1508978816426294 | validation: 0.2835102519336193]
	TIME [epoch: 11.8 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15432811372127272		[learning rate: 0.00048632]
	Learning Rate: 0.000486321
	LOSS [training: 0.15432811372127272 | validation: 0.28599919244881183]
	TIME [epoch: 11.8 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14663442704517785		[learning rate: 0.00048417]
	Learning Rate: 0.000484172
	LOSS [training: 0.14663442704517785 | validation: 0.2739076000810171]
	TIME [epoch: 11.8 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15126471768955463		[learning rate: 0.00048203]
	Learning Rate: 0.000482033
	LOSS [training: 0.15126471768955463 | validation: 0.2764183691491824]
	TIME [epoch: 11.8 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15180752467377068		[learning rate: 0.0004799]
	Learning Rate: 0.000479903
	LOSS [training: 0.15180752467377068 | validation: 0.2750194700071288]
	TIME [epoch: 11.8 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15666353418475626		[learning rate: 0.00047778]
	Learning Rate: 0.000477783
	LOSS [training: 0.15666353418475626 | validation: 0.28104399575469]
	TIME [epoch: 11.8 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15028116020150356		[learning rate: 0.00047567]
	Learning Rate: 0.000475672
	LOSS [training: 0.15028116020150356 | validation: 0.287553050237491]
	TIME [epoch: 11.8 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15267042099261258		[learning rate: 0.00047357]
	Learning Rate: 0.00047357
	LOSS [training: 0.15267042099261258 | validation: 0.2789702681249362]
	TIME [epoch: 11.8 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14728272818523233		[learning rate: 0.00047148]
	Learning Rate: 0.000471478
	LOSS [training: 0.14728272818523233 | validation: 0.27747929578089775]
	TIME [epoch: 11.8 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15383941300176487		[learning rate: 0.0004694]
	Learning Rate: 0.000469395
	LOSS [training: 0.15383941300176487 | validation: 0.28797433833213465]
	TIME [epoch: 11.8 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.152124981396297		[learning rate: 0.00046732]
	Learning Rate: 0.000467321
	LOSS [training: 0.152124981396297 | validation: 0.27315563247912134]
	TIME [epoch: 11.8 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15000309108449725		[learning rate: 0.00046526]
	Learning Rate: 0.000465256
	LOSS [training: 0.15000309108449725 | validation: 0.2804152685615083]
	TIME [epoch: 11.8 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15064687387082035		[learning rate: 0.0004632]
	Learning Rate: 0.000463201
	LOSS [training: 0.15064687387082035 | validation: 0.27525706140595635]
	TIME [epoch: 11.8 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15043150196119986		[learning rate: 0.00046115]
	Learning Rate: 0.000461154
	LOSS [training: 0.15043150196119986 | validation: 0.2835550870209514]
	TIME [epoch: 11.8 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15116747018901994		[learning rate: 0.00045912]
	Learning Rate: 0.000459117
	LOSS [training: 0.15116747018901994 | validation: 0.2826101736718427]
	TIME [epoch: 11.8 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15418097988236734		[learning rate: 0.00045709]
	Learning Rate: 0.000457088
	LOSS [training: 0.15418097988236734 | validation: 0.2892963943551015]
	TIME [epoch: 11.8 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15289091671006477		[learning rate: 0.00045507]
	Learning Rate: 0.000455069
	LOSS [training: 0.15289091671006477 | validation: 0.26726183560017464]
	TIME [epoch: 11.8 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1534480311448254		[learning rate: 0.00045306]
	Learning Rate: 0.000453058
	LOSS [training: 0.1534480311448254 | validation: 0.279778906684581]
	TIME [epoch: 11.8 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15639345614205008		[learning rate: 0.00045106]
	Learning Rate: 0.000451056
	LOSS [training: 0.15639345614205008 | validation: 0.28413443012297074]
	TIME [epoch: 11.8 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1521895365752683		[learning rate: 0.00044906]
	Learning Rate: 0.000449064
	LOSS [training: 0.1521895365752683 | validation: 0.27484886296023076]
	TIME [epoch: 11.8 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15312247859727385		[learning rate: 0.00044708]
	Learning Rate: 0.000447079
	LOSS [training: 0.15312247859727385 | validation: 0.2752696925205999]
	TIME [epoch: 11.8 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1511559004828527		[learning rate: 0.0004451]
	Learning Rate: 0.000445104
	LOSS [training: 0.1511559004828527 | validation: 0.29914916852766194]
	TIME [epoch: 11.8 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15138696597616816		[learning rate: 0.00044314]
	Learning Rate: 0.000443138
	LOSS [training: 0.15138696597616816 | validation: 0.28137024996451726]
	TIME [epoch: 11.8 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15548502356852018		[learning rate: 0.00044118]
	Learning Rate: 0.00044118
	LOSS [training: 0.15548502356852018 | validation: 0.27830289273283376]
	TIME [epoch: 11.8 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15482919369183773		[learning rate: 0.00043923]
	Learning Rate: 0.00043923
	LOSS [training: 0.15482919369183773 | validation: 0.2733907530136313]
	TIME [epoch: 11.8 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15290512899393055		[learning rate: 0.00043729]
	Learning Rate: 0.00043729
	LOSS [training: 0.15290512899393055 | validation: 0.28233346114555646]
	TIME [epoch: 11.8 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1521410780640169		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 0.1521410780640169 | validation: 0.2760109820427481]
	TIME [epoch: 11.8 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15476871585626548		[learning rate: 0.00043343]
	Learning Rate: 0.000433434
	LOSS [training: 0.15476871585626548 | validation: 0.28958286600264527]
	TIME [epoch: 11.8 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1534102245516522		[learning rate: 0.00043152]
	Learning Rate: 0.000431519
	LOSS [training: 0.1534102245516522 | validation: 0.27598334770257016]
	TIME [epoch: 11.8 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15232392294249564		[learning rate: 0.00042961]
	Learning Rate: 0.000429613
	LOSS [training: 0.15232392294249564 | validation: 0.27610467430888624]
	TIME [epoch: 11.8 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14685830500091646		[learning rate: 0.00042771]
	Learning Rate: 0.000427714
	LOSS [training: 0.14685830500091646 | validation: 0.2751559311337929]
	TIME [epoch: 11.8 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14811025056452476		[learning rate: 0.00042582]
	Learning Rate: 0.000425825
	LOSS [training: 0.14811025056452476 | validation: 0.28748476481074586]
	TIME [epoch: 11.8 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1478946680100924		[learning rate: 0.00042394]
	Learning Rate: 0.000423943
	LOSS [training: 0.1478946680100924 | validation: 0.27698169686086616]
	TIME [epoch: 11.8 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15154742514982428		[learning rate: 0.00042207]
	Learning Rate: 0.00042207
	LOSS [training: 0.15154742514982428 | validation: 0.2666403134506188]
	TIME [epoch: 11.8 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15027926424225774		[learning rate: 0.00042021]
	Learning Rate: 0.000420205
	LOSS [training: 0.15027926424225774 | validation: 0.2753550515110296]
	TIME [epoch: 11.8 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14902489663017038		[learning rate: 0.00041835]
	Learning Rate: 0.000418349
	LOSS [training: 0.14902489663017038 | validation: 0.28939590962877937]
	TIME [epoch: 11.8 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14871999127030064		[learning rate: 0.0004165]
	Learning Rate: 0.0004165
	LOSS [training: 0.14871999127030064 | validation: 0.2826341339407792]
	TIME [epoch: 11.8 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15294350097095763		[learning rate: 0.00041466]
	Learning Rate: 0.00041466
	LOSS [training: 0.15294350097095763 | validation: 0.2890967049323527]
	TIME [epoch: 11.8 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1494760633556957		[learning rate: 0.00041283]
	Learning Rate: 0.000412828
	LOSS [training: 0.1494760633556957 | validation: 0.28102746194560385]
	TIME [epoch: 11.8 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15111378927435487		[learning rate: 0.000411]
	Learning Rate: 0.000411004
	LOSS [training: 0.15111378927435487 | validation: 0.2914267310286556]
	TIME [epoch: 11.8 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15135904237858103		[learning rate: 0.00040919]
	Learning Rate: 0.000409188
	LOSS [training: 0.15135904237858103 | validation: 0.27950127748403675]
	TIME [epoch: 11.8 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14955455681416463		[learning rate: 0.00040738]
	Learning Rate: 0.00040738
	LOSS [training: 0.14955455681416463 | validation: 0.28276523603294546]
	TIME [epoch: 11.8 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14915891678786145		[learning rate: 0.00040558]
	Learning Rate: 0.00040558
	LOSS [training: 0.14915891678786145 | validation: 0.29210353859120886]
	TIME [epoch: 11.8 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1524839237443442		[learning rate: 0.00040379]
	Learning Rate: 0.000403788
	LOSS [training: 0.1524839237443442 | validation: 0.29414389813086694]
	TIME [epoch: 11.8 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16162639315844665		[learning rate: 0.000402]
	Learning Rate: 0.000402004
	LOSS [training: 0.16162639315844665 | validation: 0.285688411700755]
	TIME [epoch: 11.8 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15126268740799936		[learning rate: 0.00040023]
	Learning Rate: 0.000400228
	LOSS [training: 0.15126268740799936 | validation: 0.294993402535488]
	TIME [epoch: 11.8 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15356616442766755		[learning rate: 0.00039846]
	Learning Rate: 0.00039846
	LOSS [training: 0.15356616442766755 | validation: 0.28780124600872614]
	TIME [epoch: 11.8 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15048783318913403		[learning rate: 0.0003967]
	Learning Rate: 0.000396699
	LOSS [training: 0.15048783318913403 | validation: 0.2816228096773047]
	TIME [epoch: 11.8 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14743031295135176		[learning rate: 0.00039495]
	Learning Rate: 0.000394947
	LOSS [training: 0.14743031295135176 | validation: 0.28433522137963657]
	TIME [epoch: 11.8 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14757526599704396		[learning rate: 0.0003932]
	Learning Rate: 0.000393202
	LOSS [training: 0.14757526599704396 | validation: 0.2789613594185042]
	TIME [epoch: 11.8 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14993142512699248		[learning rate: 0.00039146]
	Learning Rate: 0.000391464
	LOSS [training: 0.14993142512699248 | validation: 0.2799306192973109]
	TIME [epoch: 11.8 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14994193044352738		[learning rate: 0.00038973]
	Learning Rate: 0.000389735
	LOSS [training: 0.14994193044352738 | validation: 0.272929259186722]
	TIME [epoch: 11.8 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14801355767853336		[learning rate: 0.00038801]
	Learning Rate: 0.000388013
	LOSS [training: 0.14801355767853336 | validation: 0.2658881295936447]
	TIME [epoch: 11.8 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15417465876234845		[learning rate: 0.0003863]
	Learning Rate: 0.000386299
	LOSS [training: 0.15417465876234845 | validation: 0.29140544616409286]
	TIME [epoch: 11.8 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14861007272032087		[learning rate: 0.00038459]
	Learning Rate: 0.000384592
	LOSS [training: 0.14861007272032087 | validation: 0.2891236611885586]
	TIME [epoch: 11.8 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15486737026619504		[learning rate: 0.00038289]
	Learning Rate: 0.000382893
	LOSS [training: 0.15486737026619504 | validation: 0.2852605201536604]
	TIME [epoch: 11.8 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14933089119439671		[learning rate: 0.0003812]
	Learning Rate: 0.000381201
	LOSS [training: 0.14933089119439671 | validation: 0.28568094408148953]
	TIME [epoch: 11.8 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14837693935474447		[learning rate: 0.00037952]
	Learning Rate: 0.000379517
	LOSS [training: 0.14837693935474447 | validation: 0.2767539906296045]
	TIME [epoch: 11.8 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15222099800317973		[learning rate: 0.00037784]
	Learning Rate: 0.00037784
	LOSS [training: 0.15222099800317973 | validation: 0.2785701138057687]
	TIME [epoch: 11.8 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1540175465415921		[learning rate: 0.00037617]
	Learning Rate: 0.00037617
	LOSS [training: 0.1540175465415921 | validation: 0.2848686328181632]
	TIME [epoch: 11.8 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1513729410224999		[learning rate: 0.00037451]
	Learning Rate: 0.000374508
	LOSS [training: 0.1513729410224999 | validation: 0.28238573899079905]
	TIME [epoch: 11.9 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14913599648810597		[learning rate: 0.00037285]
	Learning Rate: 0.000372854
	LOSS [training: 0.14913599648810597 | validation: 0.2728989766154227]
	TIME [epoch: 11.8 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14959752854235484		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 0.14959752854235484 | validation: 0.2818235743370766]
	TIME [epoch: 11.8 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1513164593495626		[learning rate: 0.00036957]
	Learning Rate: 0.000369566
	LOSS [training: 0.1513164593495626 | validation: 0.2736662309086094]
	TIME [epoch: 11.9 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15147219826227057		[learning rate: 0.00036793]
	Learning Rate: 0.000367933
	LOSS [training: 0.15147219826227057 | validation: 0.2807059803176806]
	TIME [epoch: 11.8 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15058182729567188		[learning rate: 0.00036631]
	Learning Rate: 0.000366308
	LOSS [training: 0.15058182729567188 | validation: 0.2776504035426183]
	TIME [epoch: 11.8 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15456154287047488		[learning rate: 0.00036469]
	Learning Rate: 0.000364689
	LOSS [training: 0.15456154287047488 | validation: 0.2763472584685087]
	TIME [epoch: 11.8 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15461409340778842		[learning rate: 0.00036308]
	Learning Rate: 0.000363078
	LOSS [training: 0.15461409340778842 | validation: 0.2897715348346043]
	TIME [epoch: 11.8 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15402311429848511		[learning rate: 0.00036147]
	Learning Rate: 0.000361474
	LOSS [training: 0.15402311429848511 | validation: 0.2721872744209352]
	TIME [epoch: 11.9 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1551405108396567		[learning rate: 0.00035988]
	Learning Rate: 0.000359877
	LOSS [training: 0.1551405108396567 | validation: 0.2782229037673037]
	TIME [epoch: 11.8 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1556416139978174		[learning rate: 0.00035829]
	Learning Rate: 0.000358287
	LOSS [training: 0.1556416139978174 | validation: 0.28237449978028223]
	TIME [epoch: 11.8 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14704946850851136		[learning rate: 0.0003567]
	Learning Rate: 0.000356704
	LOSS [training: 0.14704946850851136 | validation: 0.2816203860269277]
	TIME [epoch: 11.8 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15165994401816366		[learning rate: 0.00035513]
	Learning Rate: 0.000355128
	LOSS [training: 0.15165994401816366 | validation: 0.2680757234025117]
	TIME [epoch: 11.8 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14750922939365174		[learning rate: 0.00035356]
	Learning Rate: 0.000353559
	LOSS [training: 0.14750922939365174 | validation: 0.29042378257207047]
	TIME [epoch: 11.8 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1479170936557598		[learning rate: 0.000352]
	Learning Rate: 0.000351997
	LOSS [training: 0.1479170936557598 | validation: 0.28714305388679756]
	TIME [epoch: 11.8 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15244949436498095		[learning rate: 0.00035044]
	Learning Rate: 0.000350441
	LOSS [training: 0.15244949436498095 | validation: 0.28196661064873557]
	TIME [epoch: 11.8 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14828924125123108		[learning rate: 0.00034889]
	Learning Rate: 0.000348893
	LOSS [training: 0.14828924125123108 | validation: 0.2772479968245943]
	TIME [epoch: 11.8 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14996188990713638		[learning rate: 0.00034735]
	Learning Rate: 0.000347352
	LOSS [training: 0.14996188990713638 | validation: 0.28349401208275776]
	TIME [epoch: 11.8 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15096356520243273		[learning rate: 0.00034582]
	Learning Rate: 0.000345817
	LOSS [training: 0.15096356520243273 | validation: 0.277346730640555]
	TIME [epoch: 11.8 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1501065017328592		[learning rate: 0.00034429]
	Learning Rate: 0.000344289
	LOSS [training: 0.1501065017328592 | validation: 0.2755711734856236]
	TIME [epoch: 11.8 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15037492313185857		[learning rate: 0.00034277]
	Learning Rate: 0.000342768
	LOSS [training: 0.15037492313185857 | validation: 0.28030614813173516]
	TIME [epoch: 11.8 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15394445226732906		[learning rate: 0.00034125]
	Learning Rate: 0.000341253
	LOSS [training: 0.15394445226732906 | validation: 0.27989827226727143]
	TIME [epoch: 11.8 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15019372273596626		[learning rate: 0.00033975]
	Learning Rate: 0.000339746
	LOSS [training: 0.15019372273596626 | validation: 0.28175900505171936]
	TIME [epoch: 11.8 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15505431283420795		[learning rate: 0.00033824]
	Learning Rate: 0.000338245
	LOSS [training: 0.15505431283420795 | validation: 0.26995177607053406]
	TIME [epoch: 11.8 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.147807406461526		[learning rate: 0.00033675]
	Learning Rate: 0.00033675
	LOSS [training: 0.147807406461526 | validation: 0.2778050545327884]
	TIME [epoch: 11.8 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15245450198915972		[learning rate: 0.00033526]
	Learning Rate: 0.000335262
	LOSS [training: 0.15245450198915972 | validation: 0.28051798759184887]
	TIME [epoch: 11.8 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14782935854092094		[learning rate: 0.00033378]
	Learning Rate: 0.000333781
	LOSS [training: 0.14782935854092094 | validation: 0.283921820261731]
	TIME [epoch: 11.8 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15504375711073787		[learning rate: 0.00033231]
	Learning Rate: 0.000332306
	LOSS [training: 0.15504375711073787 | validation: 0.2892984387135121]
	TIME [epoch: 11.8 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15400223600080348		[learning rate: 0.00033084]
	Learning Rate: 0.000330838
	LOSS [training: 0.15400223600080348 | validation: 0.28721756180448027]
	TIME [epoch: 11.8 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14927681199981865		[learning rate: 0.00032938]
	Learning Rate: 0.000329376
	LOSS [training: 0.14927681199981865 | validation: 0.2734398593429443]
	TIME [epoch: 11.8 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15095038851720757		[learning rate: 0.00032792]
	Learning Rate: 0.000327921
	LOSS [training: 0.15095038851720757 | validation: 0.2867944228824139]
	TIME [epoch: 11.8 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15332350312995988		[learning rate: 0.00032647]
	Learning Rate: 0.000326472
	LOSS [training: 0.15332350312995988 | validation: 0.2857671240143672]
	TIME [epoch: 11.8 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15227061506633163		[learning rate: 0.00032503]
	Learning Rate: 0.00032503
	LOSS [training: 0.15227061506633163 | validation: 0.28049139045531407]
	TIME [epoch: 11.8 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15340747489624035		[learning rate: 0.00032359]
	Learning Rate: 0.000323594
	LOSS [training: 0.15340747489624035 | validation: 0.2734099238545997]
	TIME [epoch: 11.8 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1524941513137049		[learning rate: 0.00032216]
	Learning Rate: 0.000322164
	LOSS [training: 0.1524941513137049 | validation: 0.27777455193468]
	TIME [epoch: 11.8 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15364101544208078		[learning rate: 0.00032074]
	Learning Rate: 0.000320741
	LOSS [training: 0.15364101544208078 | validation: 0.2749166475992807]
	TIME [epoch: 11.8 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15209716996602854		[learning rate: 0.00031932]
	Learning Rate: 0.000319323
	LOSS [training: 0.15209716996602854 | validation: 0.28049754967222323]
	TIME [epoch: 11.8 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1491536870669353		[learning rate: 0.00031791]
	Learning Rate: 0.000317913
	LOSS [training: 0.1491536870669353 | validation: 0.2804247909528468]
	TIME [epoch: 11.8 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15077122234503454		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 0.15077122234503454 | validation: 0.2804585275518514]
	TIME [epoch: 11.8 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1496152583274762		[learning rate: 0.00031511]
	Learning Rate: 0.00031511
	LOSS [training: 0.1496152583274762 | validation: 0.27713321845318756]
	TIME [epoch: 11.8 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14571879356089898		[learning rate: 0.00031372]
	Learning Rate: 0.000313717
	LOSS [training: 0.14571879356089898 | validation: 0.27208623485765226]
	TIME [epoch: 11.8 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1516267868632482		[learning rate: 0.00031233]
	Learning Rate: 0.000312331
	LOSS [training: 0.1516267868632482 | validation: 0.27428824212927644]
	TIME [epoch: 11.8 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15174091284519226		[learning rate: 0.00031095]
	Learning Rate: 0.000310951
	LOSS [training: 0.15174091284519226 | validation: 0.2730982166038649]
	TIME [epoch: 11.8 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14450700476278938		[learning rate: 0.00030958]
	Learning Rate: 0.000309577
	LOSS [training: 0.14450700476278938 | validation: 0.2832514444318535]
	TIME [epoch: 11.8 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14964967934822024		[learning rate: 0.00030821]
	Learning Rate: 0.00030821
	LOSS [training: 0.14964967934822024 | validation: 0.2768826909884686]
	TIME [epoch: 11.8 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15307342211600472		[learning rate: 0.00030685]
	Learning Rate: 0.000306848
	LOSS [training: 0.15307342211600472 | validation: 0.27718627939336227]
	TIME [epoch: 11.8 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14946648960459		[learning rate: 0.00030549]
	Learning Rate: 0.000305492
	LOSS [training: 0.14946648960459 | validation: 0.28543362243541853]
	TIME [epoch: 11.8 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15656126271064255		[learning rate: 0.00030414]
	Learning Rate: 0.000304142
	LOSS [training: 0.15656126271064255 | validation: 0.27994790001209896]
	TIME [epoch: 11.8 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14747196940147808		[learning rate: 0.0003028]
	Learning Rate: 0.000302799
	LOSS [training: 0.14747196940147808 | validation: 0.27687459389953617]
	TIME [epoch: 11.8 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14969270279402414		[learning rate: 0.00030146]
	Learning Rate: 0.000301461
	LOSS [training: 0.14969270279402414 | validation: 0.28586583715462555]
	TIME [epoch: 11.8 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1471930590728632		[learning rate: 0.00030013]
	Learning Rate: 0.000300129
	LOSS [training: 0.1471930590728632 | validation: 0.2811588259940784]
	TIME [epoch: 11.8 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15286656984369565		[learning rate: 0.0002988]
	Learning Rate: 0.000298803
	LOSS [training: 0.15286656984369565 | validation: 0.2812124614667275]
	TIME [epoch: 11.8 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15153348845260123		[learning rate: 0.00029748]
	Learning Rate: 0.000297483
	LOSS [training: 0.15153348845260123 | validation: 0.28259786796963965]
	TIME [epoch: 11.8 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14872610830752767		[learning rate: 0.00029617]
	Learning Rate: 0.000296168
	LOSS [training: 0.14872610830752767 | validation: 0.28342290492824324]
	TIME [epoch: 11.8 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15601789279225026		[learning rate: 0.00029486]
	Learning Rate: 0.00029486
	LOSS [training: 0.15601789279225026 | validation: 0.27875300105406875]
	TIME [epoch: 11.8 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15579925369259995		[learning rate: 0.00029356]
	Learning Rate: 0.000293557
	LOSS [training: 0.15579925369259995 | validation: 0.2856132146442163]
	TIME [epoch: 11.8 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.152481793410458		[learning rate: 0.00029226]
	Learning Rate: 0.00029226
	LOSS [training: 0.152481793410458 | validation: 0.27460051072749614]
	TIME [epoch: 11.8 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1508428622609992		[learning rate: 0.00029097]
	Learning Rate: 0.000290969
	LOSS [training: 0.1508428622609992 | validation: 0.2846877629323788]
	TIME [epoch: 11.8 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v10_20240712_145225/states/model_facs_v2_dec2b_2dpca_v10_839.pth
Halted early. No improvement in validation loss for 200 epochs.
Finished training in 7154.056 seconds.
