Args:
Namespace(name='model_facs_dec2b_2dpca_v1', outdir='out/model_training/model_facs_dec2b_2dpca_v1', training_data='data/training_data/facs/pca/dec2_fitonsubset/transition2_subset_ce_pn_m_pc12/training', validation_data='data/training_data/facs/pca/dec2_fitonsubset/transition2_subset_ce_pn_m_pc12/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=5, patience=200, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, dt=0.001, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 1934474416

Training model...

Saving initial model state to: out/model_training/model_facs_dec2b_2dpca_v1_20240624_133245/states/model_facs_dec2b_2dpca_v1_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6461291996811257		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6461291996811257 | validation: 0.5964680218101471]
	TIME [epoch: 50.2 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v1_20240624_133245/states/model_facs_dec2b_2dpca_v1_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3905641250183972		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3905641250183972 | validation: 0.3925809157293357]
	TIME [epoch: 21.7 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v1_20240624_133245/states/model_facs_dec2b_2dpca_v1_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35647347736285173		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.35647347736285173 | validation: 0.4184792185901973]
	TIME [epoch: 21.6 sec]
EPOCH 4/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3417890983153876		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3417890983153876 | validation: 0.41407663287102686]
	TIME [epoch: 21.7 sec]
EPOCH 5/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3384079413463915		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3384079413463915 | validation: 0.5293999738049474]
	TIME [epoch: 21.7 sec]
EPOCH 6/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.391004709022238		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.391004709022238 | validation: 0.44109548675582877]
	TIME [epoch: 21.7 sec]
EPOCH 7/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3370861279325124		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3370861279325124 | validation: 0.3766945345444407]
	TIME [epoch: 21.6 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v1_20240624_133245/states/model_facs_dec2b_2dpca_v1_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2935444881384969		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2935444881384969 | validation: 0.4293912990963449]
	TIME [epoch: 21.7 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32386306204736626		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.32386306204736626 | validation: 0.38862622089745985]
	TIME [epoch: 21.7 sec]
EPOCH 10/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29641966792949737		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.29641966792949737 | validation: 0.33805272924492635]
	TIME [epoch: 21.7 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v1_20240624_133245/states/model_facs_dec2b_2dpca_v1_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2702701239291022		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2702701239291022 | validation: 0.3336526074817381]
	TIME [epoch: 21.7 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v1_20240624_133245/states/model_facs_dec2b_2dpca_v1_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2671046976715418		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2671046976715418 | validation: 0.3310232565469868]
	TIME [epoch: 21.7 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v1_20240624_133245/states/model_facs_dec2b_2dpca_v1_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2463424667934139		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2463424667934139 | validation: 0.3378125481389643]
	TIME [epoch: 21.7 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23883552415284517		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23883552415284517 | validation: 0.3212335738947216]
	TIME [epoch: 21.7 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v1_20240624_133245/states/model_facs_dec2b_2dpca_v1_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21797528071794536		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.21797528071794536 | validation: 0.2666407741567764]
	TIME [epoch: 21.7 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v1_20240624_133245/states/model_facs_dec2b_2dpca_v1_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1947703430381548		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1947703430381548 | validation: 0.2566445505432114]
	TIME [epoch: 21.7 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v1_20240624_133245/states/model_facs_dec2b_2dpca_v1_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21811065213062236		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.21811065213062236 | validation: 0.25347544226012253]
	TIME [epoch: 21.7 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v1_20240624_133245/states/model_facs_dec2b_2dpca_v1_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2025203958666138		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2025203958666138 | validation: 0.2755193586719777]
	TIME [epoch: 21.6 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1935247727538892		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1935247727538892 | validation: 0.24118889354153533]
	TIME [epoch: 21.7 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v1_20240624_133245/states/model_facs_dec2b_2dpca_v1_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1872719348550808		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1872719348550808 | validation: 0.24321691458504996]
	TIME [epoch: 21.6 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18568447833688398		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18568447833688398 | validation: 0.245596956644005]
	TIME [epoch: 21.7 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1762086696228134		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1762086696228134 | validation: 0.24019505834237012]
	TIME [epoch: 21.7 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v1_20240624_133245/states/model_facs_dec2b_2dpca_v1_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1775389407643786		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1775389407643786 | validation: 0.24129465136796785]
	TIME [epoch: 21.6 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18568405238675173		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18568405238675173 | validation: 0.2538404003380973]
	TIME [epoch: 21.7 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19568320484243473		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.19568320484243473 | validation: 0.2627241434270136]
	TIME [epoch: 21.6 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1875447165366552		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1875447165366552 | validation: 0.30054731681245805]
	TIME [epoch: 21.7 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16989768694896995		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16989768694896995 | validation: 0.25425902473659223]
	TIME [epoch: 21.7 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1717453539605527		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1717453539605527 | validation: 0.24648464717764398]
	TIME [epoch: 21.7 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16817722266401733		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16817722266401733 | validation: 0.2323266680236039]
	TIME [epoch: 21.7 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v1_20240624_133245/states/model_facs_dec2b_2dpca_v1_29.pth
	Model improved!!!
EPOCH 30/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1736682879705716		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1736682879705716 | validation: 0.2789327315118345]
	TIME [epoch: 21.7 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16004994475971865		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16004994475971865 | validation: 0.22840416978311867]
	TIME [epoch: 21.7 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v1_20240624_133245/states/model_facs_dec2b_2dpca_v1_31.pth
	Model improved!!!
EPOCH 32/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16524457618633556		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16524457618633556 | validation: 0.245017337463728]
	TIME [epoch: 21.6 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17658583273845882		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17658583273845882 | validation: 0.23534926462621397]
	TIME [epoch: 21.7 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17266316977955326		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17266316977955326 | validation: 0.23588406264752163]
	TIME [epoch: 21.7 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16762648742707525		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16762648742707525 | validation: 0.22067124300226929]
	TIME [epoch: 21.6 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v1_20240624_133245/states/model_facs_dec2b_2dpca_v1_35.pth
	Model improved!!!
EPOCH 36/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18439172925016722		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18439172925016722 | validation: 0.23737924815783404]
	TIME [epoch: 21.6 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1590026925903922		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1590026925903922 | validation: 0.23012384383217832]
	TIME [epoch: 21.6 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15612840341628814		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15612840341628814 | validation: 0.2276289511461261]
	TIME [epoch: 21.6 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16351707957492512		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16351707957492512 | validation: 0.23175702010418991]
	TIME [epoch: 21.6 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16874837137757037		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16874837137757037 | validation: 0.24163078891848858]
	TIME [epoch: 21.7 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15950466975052874		[learning rate: 0.0099646]
	Learning Rate: 0.00996464
	LOSS [training: 0.15950466975052874 | validation: 0.25730640155555895]
	TIME [epoch: 21.7 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1613100284406312		[learning rate: 0.0099206]
	Learning Rate: 0.00992061
	LOSS [training: 0.1613100284406312 | validation: 0.237871412028005]
	TIME [epoch: 21.6 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15827487710408178		[learning rate: 0.0098768]
	Learning Rate: 0.00987678
	LOSS [training: 0.15827487710408178 | validation: 0.246791861814551]
	TIME [epoch: 21.7 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17805299399001653		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 0.17805299399001653 | validation: 0.20713020227154033]
	TIME [epoch: 21.7 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v1_20240624_133245/states/model_facs_dec2b_2dpca_v1_44.pth
	Model improved!!!
EPOCH 45/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1571149833814273		[learning rate: 0.0097897]
	Learning Rate: 0.0097897
	LOSS [training: 0.1571149833814273 | validation: 0.22101870843894983]
	TIME [epoch: 21.6 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17538989123241588		[learning rate: 0.0097464]
	Learning Rate: 0.00974644
	LOSS [training: 0.17538989123241588 | validation: 0.2190700309778992]
	TIME [epoch: 21.7 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16172465936078714		[learning rate: 0.0097034]
	Learning Rate: 0.00970338
	LOSS [training: 0.16172465936078714 | validation: 0.23402463802489892]
	TIME [epoch: 21.7 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1634650095757108		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 0.1634650095757108 | validation: 0.2250018392579475]
	TIME [epoch: 21.7 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14064708954523034		[learning rate: 0.0096178]
	Learning Rate: 0.00961783
	LOSS [training: 0.14064708954523034 | validation: 0.21938850672258964]
	TIME [epoch: 21.6 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.140368222772684		[learning rate: 0.0095753]
	Learning Rate: 0.00957533
	LOSS [training: 0.140368222772684 | validation: 0.24478693047753308]
	TIME [epoch: 21.7 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15852484834737637		[learning rate: 0.009533]
	Learning Rate: 0.00953303
	LOSS [training: 0.15852484834737637 | validation: 0.25799504726333766]
	TIME [epoch: 21.7 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17961345562637226		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 0.17961345562637226 | validation: 0.2077478567603619]
	TIME [epoch: 21.6 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15246581293588063		[learning rate: 0.009449]
	Learning Rate: 0.00944897
	LOSS [training: 0.15246581293588063 | validation: 0.23725247275348085]
	TIME [epoch: 21.7 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16906362183782217		[learning rate: 0.0094072]
	Learning Rate: 0.00940722
	LOSS [training: 0.16906362183782217 | validation: 0.2135983419610536]
	TIME [epoch: 21.7 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1481786649814254		[learning rate: 0.0093657]
	Learning Rate: 0.00936566
	LOSS [training: 0.1481786649814254 | validation: 0.2646490716127343]
	TIME [epoch: 21.6 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17567438525875836		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 0.17567438525875836 | validation: 0.24569734515577052]
	TIME [epoch: 21.7 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14211640672762244		[learning rate: 0.0092831]
	Learning Rate: 0.00928308
	LOSS [training: 0.14211640672762244 | validation: 0.19848891008733868]
	TIME [epoch: 21.6 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v1_20240624_133245/states/model_facs_dec2b_2dpca_v1_57.pth
	Model improved!!!
EPOCH 58/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14198246673335846		[learning rate: 0.0092421]
	Learning Rate: 0.00924207
	LOSS [training: 0.14198246673335846 | validation: 0.21220993980159528]
	TIME [epoch: 21.7 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12468860050939531		[learning rate: 0.0092012]
	Learning Rate: 0.00920124
	LOSS [training: 0.12468860050939531 | validation: 0.22769699360288592]
	TIME [epoch: 21.6 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17608362012558473		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 0.17608362012558473 | validation: 0.20349295750275748]
	TIME [epoch: 21.7 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15242362058574682		[learning rate: 0.0091201]
	Learning Rate: 0.00912011
	LOSS [training: 0.15242362058574682 | validation: 0.252637774191858]
	TIME [epoch: 21.6 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17566069812950963		[learning rate: 0.0090798]
	Learning Rate: 0.00907981
	LOSS [training: 0.17566069812950963 | validation: 0.1764962110587926]
	TIME [epoch: 21.7 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v1_20240624_133245/states/model_facs_dec2b_2dpca_v1_62.pth
	Model improved!!!
EPOCH 63/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1331684618621837		[learning rate: 0.0090397]
	Learning Rate: 0.0090397
	LOSS [training: 0.1331684618621837 | validation: 0.21346445792511193]
	TIME [epoch: 21.7 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14523953510113521		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 0.14523953510113521 | validation: 0.18659592655576093]
	TIME [epoch: 21.7 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13359805388684937		[learning rate: 0.00896]
	Learning Rate: 0.00895999
	LOSS [training: 0.13359805388684937 | validation: 0.20959066346021918]
	TIME [epoch: 21.7 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13251194099596245		[learning rate: 0.0089204]
	Learning Rate: 0.00892041
	LOSS [training: 0.13251194099596245 | validation: 0.3169004094465199]
	TIME [epoch: 21.7 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17566096452608396		[learning rate: 0.008881]
	Learning Rate: 0.00888099
	LOSS [training: 0.17566096452608396 | validation: 0.1849090600197173]
	TIME [epoch: 21.7 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13835921821073466		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 0.13835921821073466 | validation: 0.2006662238591743]
	TIME [epoch: 21.7 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1413214790224526		[learning rate: 0.0088027]
	Learning Rate: 0.00880269
	LOSS [training: 0.1413214790224526 | validation: 0.22078740702169203]
	TIME [epoch: 21.7 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15248135894553788		[learning rate: 0.0087638]
	Learning Rate: 0.0087638
	LOSS [training: 0.15248135894553788 | validation: 0.1979142964738011]
	TIME [epoch: 21.7 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1392019263291227		[learning rate: 0.0087251]
	Learning Rate: 0.00872508
	LOSS [training: 0.1392019263291227 | validation: 0.22007902458048995]
	TIME [epoch: 21.7 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13938710343169863		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 0.13938710343169863 | validation: 0.18604839935445028]
	TIME [epoch: 21.7 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15918474441099		[learning rate: 0.0086481]
	Learning Rate: 0.00864815
	LOSS [training: 0.15918474441099 | validation: 0.180356158635217]
	TIME [epoch: 21.7 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13277228891979723		[learning rate: 0.0086099]
	Learning Rate: 0.00860994
	LOSS [training: 0.13277228891979723 | validation: 0.19145634829198416]
	TIME [epoch: 21.7 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13964036039833727		[learning rate: 0.0085719]
	Learning Rate: 0.0085719
	LOSS [training: 0.13964036039833727 | validation: 0.19038975359980095]
	TIME [epoch: 21.7 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12637886389463662		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 0.12637886389463662 | validation: 0.18184282637402172]
	TIME [epoch: 21.7 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11784850109992336		[learning rate: 0.0084963]
	Learning Rate: 0.00849632
	LOSS [training: 0.11784850109992336 | validation: 0.2548551067208984]
	TIME [epoch: 21.7 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14176784175652157		[learning rate: 0.0084588]
	Learning Rate: 0.00845878
	LOSS [training: 0.14176784175652157 | validation: 0.17263558026320086]
	TIME [epoch: 21.7 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v1_20240624_133245/states/model_facs_dec2b_2dpca_v1_78.pth
	Model improved!!!
EPOCH 79/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15280337317591303		[learning rate: 0.0084214]
	Learning Rate: 0.00842141
	LOSS [training: 0.15280337317591303 | validation: 0.19788039034836186]
	TIME [epoch: 21.7 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18098792252120616		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 0.18098792252120616 | validation: 0.1978093072810607]
	TIME [epoch: 21.6 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12666194298310568		[learning rate: 0.0083472]
	Learning Rate: 0.00834715
	LOSS [training: 0.12666194298310568 | validation: 0.17805807943793664]
	TIME [epoch: 21.7 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13641929583686885		[learning rate: 0.0083103]
	Learning Rate: 0.00831027
	LOSS [training: 0.13641929583686885 | validation: 0.20127617100192807]
	TIME [epoch: 21.7 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14244862022411792		[learning rate: 0.0082736]
	Learning Rate: 0.00827356
	LOSS [training: 0.14244862022411792 | validation: 0.1795355276206414]
	TIME [epoch: 21.6 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.143212417861268		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 0.143212417861268 | validation: 0.22134734913096282]
	TIME [epoch: 21.7 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13687621065877117		[learning rate: 0.0082006]
	Learning Rate: 0.00820061
	LOSS [training: 0.13687621065877117 | validation: 0.17993054491184046]
	TIME [epoch: 21.7 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11398381848056074		[learning rate: 0.0081644]
	Learning Rate: 0.00816438
	LOSS [training: 0.11398381848056074 | validation: 0.2274108191800513]
	TIME [epoch: 21.7 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14288591285129298		[learning rate: 0.0081283]
	Learning Rate: 0.0081283
	LOSS [training: 0.14288591285129298 | validation: 0.20376432262629804]
	TIME [epoch: 21.7 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.128429050779831		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 0.128429050779831 | validation: 0.18039617153467807]
	TIME [epoch: 21.7 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12857925877582935		[learning rate: 0.0080566]
	Learning Rate: 0.00805664
	LOSS [training: 0.12857925877582935 | validation: 0.17906529267795016]
	TIME [epoch: 21.7 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11767069825670078		[learning rate: 0.008021]
	Learning Rate: 0.00802104
	LOSS [training: 0.11767069825670078 | validation: 0.19168269715854253]
	TIME [epoch: 21.7 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1232831530550597		[learning rate: 0.0079856]
	Learning Rate: 0.0079856
	LOSS [training: 0.1232831530550597 | validation: 0.24551246979247932]
	TIME [epoch: 21.7 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13906358770571017		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 0.13906358770571017 | validation: 0.188871421299464]
	TIME [epoch: 21.7 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13068615398774824		[learning rate: 0.0079152]
	Learning Rate: 0.00791519
	LOSS [training: 0.13068615398774824 | validation: 0.19429025009946876]
	TIME [epoch: 21.7 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11076766430577974		[learning rate: 0.0078802]
	Learning Rate: 0.00788022
	LOSS [training: 0.11076766430577974 | validation: 0.19233974558227895]
	TIME [epoch: 21.7 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12430560457996113		[learning rate: 0.0078454]
	Learning Rate: 0.00784541
	LOSS [training: 0.12430560457996113 | validation: 0.19469510681920738]
	TIME [epoch: 21.7 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13116601776553488		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 0.13116601776553488 | validation: 0.19081316049401323]
	TIME [epoch: 21.7 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15306858420782923		[learning rate: 0.0077762]
	Learning Rate: 0.00777623
	LOSS [training: 0.15306858420782923 | validation: 0.2018922925640951]
	TIME [epoch: 21.7 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13636175080399207		[learning rate: 0.0077419]
	Learning Rate: 0.00774188
	LOSS [training: 0.13636175080399207 | validation: 0.19301578394020757]
	TIME [epoch: 21.7 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11744499815875362		[learning rate: 0.0077077]
	Learning Rate: 0.00770767
	LOSS [training: 0.11744499815875362 | validation: 0.1551802062847208]
	TIME [epoch: 21.7 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v1_20240624_133245/states/model_facs_dec2b_2dpca_v1_99.pth
	Model improved!!!
EPOCH 100/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12273660576547551		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 0.12273660576547551 | validation: 0.16254654284917758]
	TIME [epoch: 21.7 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.111962009624505		[learning rate: 0.0076397]
	Learning Rate: 0.00763971
	LOSS [training: 0.111962009624505 | validation: 0.17857449135350315]
	TIME [epoch: 21.7 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1141046257898144		[learning rate: 0.007606]
	Learning Rate: 0.00760596
	LOSS [training: 0.1141046257898144 | validation: 0.20568410054325303]
	TIME [epoch: 21.7 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2058434299666701		[learning rate: 0.0075724]
	Learning Rate: 0.00757235
	LOSS [training: 0.2058434299666701 | validation: 0.23667527809242372]
	TIME [epoch: 21.6 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11185184355318276		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 0.11185184355318276 | validation: 0.21519697505560223]
	TIME [epoch: 21.6 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12421400855884442		[learning rate: 0.0075056]
	Learning Rate: 0.00750559
	LOSS [training: 0.12421400855884442 | validation: 0.19858936698171095]
	TIME [epoch: 21.6 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11578288679981368		[learning rate: 0.0074724]
	Learning Rate: 0.00747242
	LOSS [training: 0.11578288679981368 | validation: 0.1972175305639536]
	TIME [epoch: 21.7 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13981307809484908		[learning rate: 0.0074394]
	Learning Rate: 0.00743941
	LOSS [training: 0.13981307809484908 | validation: 0.225295989406744]
	TIME [epoch: 21.7 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15704107982540677		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 0.15704107982540677 | validation: 0.18897588964275408]
	TIME [epoch: 21.7 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1122986788560644		[learning rate: 0.0073738]
	Learning Rate: 0.00737382
	LOSS [training: 0.1122986788560644 | validation: 0.17602134744802914]
	TIME [epoch: 21.7 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10347925817437247		[learning rate: 0.0073412]
	Learning Rate: 0.00734124
	LOSS [training: 0.10347925817437247 | validation: 0.18034260447232173]
	TIME [epoch: 21.7 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15808260092786636		[learning rate: 0.0073088]
	Learning Rate: 0.0073088
	LOSS [training: 0.15808260092786636 | validation: 0.21013957770141842]
	TIME [epoch: 21.7 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12337854229096616		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 0.12337854229096616 | validation: 0.17553438085067044]
	TIME [epoch: 21.7 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12198310293430996		[learning rate: 0.0072444]
	Learning Rate: 0.00724436
	LOSS [training: 0.12198310293430996 | validation: 0.20592148370270147]
	TIME [epoch: 21.7 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1262082089802106		[learning rate: 0.0072124]
	Learning Rate: 0.00721235
	LOSS [training: 0.1262082089802106 | validation: 0.24689611737537348]
	TIME [epoch: 21.7 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1257128909946849		[learning rate: 0.0071805]
	Learning Rate: 0.00718049
	LOSS [training: 0.1257128909946849 | validation: 0.21303746957495645]
	TIME [epoch: 21.6 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12784736739395056		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 0.12784736739395056 | validation: 0.163209471205455]
	TIME [epoch: 21.7 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1165506871689638		[learning rate: 0.0071172]
	Learning Rate: 0.00711718
	LOSS [training: 0.1165506871689638 | validation: 0.1915381521340166]
	TIME [epoch: 21.7 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10320254438686605		[learning rate: 0.0070857]
	Learning Rate: 0.00708573
	LOSS [training: 0.10320254438686605 | validation: 0.2513186039268541]
	TIME [epoch: 21.7 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14814420459510008		[learning rate: 0.0070544]
	Learning Rate: 0.00705442
	LOSS [training: 0.14814420459510008 | validation: 0.17614808465684462]
	TIME [epoch: 21.7 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11569460518442187		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 0.11569460518442187 | validation: 0.16061903052779558]
	TIME [epoch: 21.6 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10248049567898461		[learning rate: 0.0069922]
	Learning Rate: 0.00699222
	LOSS [training: 0.10248049567898461 | validation: 0.19285085111163952]
	TIME [epoch: 21.7 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12407346690530394		[learning rate: 0.0069613]
	Learning Rate: 0.00696133
	LOSS [training: 0.12407346690530394 | validation: 0.1778526940880396]
	TIME [epoch: 21.7 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12278433535989178		[learning rate: 0.0069306]
	Learning Rate: 0.00693057
	LOSS [training: 0.12278433535989178 | validation: 0.2746373403203267]
	TIME [epoch: 21.7 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13927037446633556		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 0.13927037446633556 | validation: 0.17590672423590156]
	TIME [epoch: 21.7 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11085683419771579		[learning rate: 0.0068695]
	Learning Rate: 0.00686947
	LOSS [training: 0.11085683419771579 | validation: 0.18778582731860072]
	TIME [epoch: 21.7 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12248299695894493		[learning rate: 0.0068391]
	Learning Rate: 0.00683912
	LOSS [training: 0.12248299695894493 | validation: 0.17449869441155552]
	TIME [epoch: 21.7 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12161270716252395		[learning rate: 0.0068089]
	Learning Rate: 0.0068089
	LOSS [training: 0.12161270716252395 | validation: 0.1965473421323324]
	TIME [epoch: 21.6 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11754566002635185		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 0.11754566002635185 | validation: 0.20850117954332212]
	TIME [epoch: 21.7 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11852353095511026		[learning rate: 0.0067489]
	Learning Rate: 0.00674887
	LOSS [training: 0.11852353095511026 | validation: 0.1561449185761555]
	TIME [epoch: 21.6 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10545693273717238		[learning rate: 0.006719]
	Learning Rate: 0.00671905
	LOSS [training: 0.10545693273717238 | validation: 0.15577031541422123]
	TIME [epoch: 21.7 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11633932619471384		[learning rate: 0.0066894]
	Learning Rate: 0.00668936
	LOSS [training: 0.11633932619471384 | validation: 0.2202805196928405]
	TIME [epoch: 21.6 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10081448681638042		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 0.10081448681638042 | validation: 0.1902468733449723]
	TIME [epoch: 21.7 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10878462254598453		[learning rate: 0.0066304]
	Learning Rate: 0.00663038
	LOSS [training: 0.10878462254598453 | validation: 0.1764352242102434]
	TIME [epoch: 21.7 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12028788750540172		[learning rate: 0.0066011]
	Learning Rate: 0.00660109
	LOSS [training: 0.12028788750540172 | validation: 0.18879854191295983]
	TIME [epoch: 21.6 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12522097232019794		[learning rate: 0.0065719]
	Learning Rate: 0.00657192
	LOSS [training: 0.12522097232019794 | validation: 0.2277153458400445]
	TIME [epoch: 21.6 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11344086686137893		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 0.11344086686137893 | validation: 0.1888349033158163]
	TIME [epoch: 21.7 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.127802246697548		[learning rate: 0.006514]
	Learning Rate: 0.00651398
	LOSS [training: 0.127802246697548 | validation: 0.17079798773598961]
	TIME [epoch: 21.7 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13212016513264402		[learning rate: 0.0064852]
	Learning Rate: 0.00648519
	LOSS [training: 0.13212016513264402 | validation: 0.1916780429775737]
	TIME [epoch: 21.6 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12715422577343713		[learning rate: 0.0064565]
	Learning Rate: 0.00645654
	LOSS [training: 0.12715422577343713 | validation: 0.17119557814463912]
	TIME [epoch: 21.6 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11497463161279438		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 0.11497463161279438 | validation: 0.17862653221357017]
	TIME [epoch: 21.7 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11922785442533716		[learning rate: 0.0063996]
	Learning Rate: 0.00639961
	LOSS [training: 0.11922785442533716 | validation: 0.17518384449890478]
	TIME [epoch: 21.6 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11259219213200518		[learning rate: 0.0063713]
	Learning Rate: 0.00637134
	LOSS [training: 0.11259219213200518 | validation: 0.20839146323742463]
	TIME [epoch: 21.7 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10165479306658258		[learning rate: 0.0063432]
	Learning Rate: 0.00634319
	LOSS [training: 0.10165479306658258 | validation: 0.16139829720432045]
	TIME [epoch: 21.7 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1169791719000329		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 0.1169791719000329 | validation: 0.15552681544299793]
	TIME [epoch: 21.7 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11431934778988176		[learning rate: 0.0062873]
	Learning Rate: 0.00628726
	LOSS [training: 0.11431934778988176 | validation: 0.16317381219797025]
	TIME [epoch: 21.7 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1014808909573306		[learning rate: 0.0062595]
	Learning Rate: 0.00625948
	LOSS [training: 0.1014808909573306 | validation: 0.20132055035923657]
	TIME [epoch: 21.7 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1349263313694153		[learning rate: 0.0062318]
	Learning Rate: 0.00623183
	LOSS [training: 0.1349263313694153 | validation: 0.16346165407879162]
	TIME [epoch: 21.7 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11644591759570486		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 0.11644591759570486 | validation: 0.19485737077621312]
	TIME [epoch: 21.6 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11560512391228897		[learning rate: 0.0061769]
	Learning Rate: 0.00617688
	LOSS [training: 0.11560512391228897 | validation: 0.17853045407423368]
	TIME [epoch: 21.6 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11056234835340398		[learning rate: 0.0061496]
	Learning Rate: 0.00614959
	LOSS [training: 0.11056234835340398 | validation: 0.20523527364981747]
	TIME [epoch: 21.6 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12178676947680467		[learning rate: 0.0061224]
	Learning Rate: 0.00612242
	LOSS [training: 0.12178676947680467 | validation: 0.1968431690292274]
	TIME [epoch: 21.6 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12591836333082052		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 0.12591836333082052 | validation: 0.31291669705717223]
	TIME [epoch: 21.6 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12497720228569491		[learning rate: 0.0060684]
	Learning Rate: 0.00606844
	LOSS [training: 0.12497720228569491 | validation: 0.16581687084651958]
	TIME [epoch: 21.6 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09945784455088313		[learning rate: 0.0060416]
	Learning Rate: 0.00604163
	LOSS [training: 0.09945784455088313 | validation: 0.1968073158920931]
	TIME [epoch: 21.6 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10503492059378998		[learning rate: 0.0060149]
	Learning Rate: 0.00601493
	LOSS [training: 0.10503492059378998 | validation: 0.16910035019720907]
	TIME [epoch: 21.6 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10335017504180896		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 0.10335017504180896 | validation: 0.23665344431676041]
	TIME [epoch: 21.6 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11989546132729242		[learning rate: 0.0059619]
	Learning Rate: 0.0059619
	LOSS [training: 0.11989546132729242 | validation: 0.15267087352120853]
	TIME [epoch: 21.6 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v1_20240624_133245/states/model_facs_dec2b_2dpca_v1_157.pth
	Model improved!!!
EPOCH 158/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10341317847140874		[learning rate: 0.0059356]
	Learning Rate: 0.00593556
	LOSS [training: 0.10341317847140874 | validation: 0.20618202849439166]
	TIME [epoch: 21.7 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12129701820187053		[learning rate: 0.0059093]
	Learning Rate: 0.00590933
	LOSS [training: 0.12129701820187053 | validation: 0.17288606904441065]
	TIME [epoch: 21.7 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11469054854465739		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 0.11469054854465739 | validation: 0.16002864890011684]
	TIME [epoch: 21.7 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10141820939935994		[learning rate: 0.0058572]
	Learning Rate: 0.00585723
	LOSS [training: 0.10141820939935994 | validation: 0.1743672785432179]
	TIME [epoch: 21.7 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1051549534764212		[learning rate: 0.0058314]
	Learning Rate: 0.00583135
	LOSS [training: 0.1051549534764212 | validation: 0.26578862653385227]
	TIME [epoch: 21.7 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1340501093940798		[learning rate: 0.0058056]
	Learning Rate: 0.00580559
	LOSS [training: 0.1340501093940798 | validation: 0.24466716604167033]
	TIME [epoch: 21.7 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1681619609586238		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 0.1681619609586238 | validation: 0.17081880078592204]
	TIME [epoch: 21.7 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10393912130778146		[learning rate: 0.0057544]
	Learning Rate: 0.0057544
	LOSS [training: 0.10393912130778146 | validation: 0.17203406528078583]
	TIME [epoch: 21.6 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10497653778480934		[learning rate: 0.005729]
	Learning Rate: 0.00572897
	LOSS [training: 0.10497653778480934 | validation: 0.15962237731778764]
	TIME [epoch: 21.7 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11537057064773357		[learning rate: 0.0057037]
	Learning Rate: 0.00570366
	LOSS [training: 0.11537057064773357 | validation: 0.19435762724085212]
	TIME [epoch: 21.6 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1098518728726517		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 0.1098518728726517 | validation: 0.1578046541454877]
	TIME [epoch: 21.7 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10508783681603111		[learning rate: 0.0056534]
	Learning Rate: 0.00565337
	LOSS [training: 0.10508783681603111 | validation: 0.17234140566644712]
	TIME [epoch: 21.7 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11151646993271216		[learning rate: 0.0056284]
	Learning Rate: 0.0056284
	LOSS [training: 0.11151646993271216 | validation: 0.16994428847812687]
	TIME [epoch: 21.7 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1001586808923717		[learning rate: 0.0056035]
	Learning Rate: 0.00560353
	LOSS [training: 0.1001586808923717 | validation: 0.21763078107338238]
	TIME [epoch: 21.6 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11318268709523696		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 0.11318268709523696 | validation: 0.20570330517170582]
	TIME [epoch: 21.7 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.103524193352442		[learning rate: 0.0055541]
	Learning Rate: 0.00555412
	LOSS [training: 0.103524193352442 | validation: 0.15100707840372096]
	TIME [epoch: 21.6 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v1_20240624_133245/states/model_facs_dec2b_2dpca_v1_173.pth
	Model improved!!!
EPOCH 174/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1254902595190118		[learning rate: 0.0055296]
	Learning Rate: 0.00552958
	LOSS [training: 0.1254902595190118 | validation: 0.21373717373966852]
	TIME [epoch: 21.6 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11686115478791151		[learning rate: 0.0055052]
	Learning Rate: 0.00550515
	LOSS [training: 0.11686115478791151 | validation: 0.1759963565871193]
	TIME [epoch: 21.7 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11415645019144922		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 0.11415645019144922 | validation: 0.14746637118779327]
	TIME [epoch: 21.7 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v1_20240624_133245/states/model_facs_dec2b_2dpca_v1_176.pth
	Model improved!!!
EPOCH 177/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10149425927950365		[learning rate: 0.0054566]
	Learning Rate: 0.00545661
	LOSS [training: 0.10149425927950365 | validation: 0.16653733917618466]
	TIME [epoch: 21.7 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10915512931212834		[learning rate: 0.0054325]
	Learning Rate: 0.0054325
	LOSS [training: 0.10915512931212834 | validation: 0.17262093957299623]
	TIME [epoch: 21.7 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11448542149728698		[learning rate: 0.0054085]
	Learning Rate: 0.0054085
	LOSS [training: 0.11448542149728698 | validation: 0.2261160317500587]
	TIME [epoch: 21.7 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1196520244638033		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 0.1196520244638033 | validation: 0.15364573854232721]
	TIME [epoch: 21.7 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10980254034216061		[learning rate: 0.0053608]
	Learning Rate: 0.00536081
	LOSS [training: 0.10980254034216061 | validation: 0.1542537081628822]
	TIME [epoch: 21.7 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10811426045277346		[learning rate: 0.0053371]
	Learning Rate: 0.00533713
	LOSS [training: 0.10811426045277346 | validation: 0.2553525139277771]
	TIME [epoch: 21.7 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12063360446902989		[learning rate: 0.0053135]
	Learning Rate: 0.00531355
	LOSS [training: 0.12063360446902989 | validation: 0.17949787071649878]
	TIME [epoch: 21.7 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1118648598483503		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 0.1118648598483503 | validation: 0.15697660296923865]
	TIME [epoch: 21.7 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10053027967427933		[learning rate: 0.0052667]
	Learning Rate: 0.0052667
	LOSS [training: 0.10053027967427933 | validation: 0.21975649188042218]
	TIME [epoch: 21.7 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11573429675308314		[learning rate: 0.0052434]
	Learning Rate: 0.00524343
	LOSS [training: 0.11573429675308314 | validation: 0.19559906469533406]
	TIME [epoch: 21.7 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11338448759775384		[learning rate: 0.0052203]
	Learning Rate: 0.00522026
	LOSS [training: 0.11338448759775384 | validation: 0.17894174736395416]
	TIME [epoch: 21.7 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.103604530320304		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 0.103604530320304 | validation: 0.16771064311207573]
	TIME [epoch: 21.7 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10181960193394443		[learning rate: 0.0051742]
	Learning Rate: 0.00517423
	LOSS [training: 0.10181960193394443 | validation: 0.18204020705542023]
	TIME [epoch: 21.7 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11534511368889674		[learning rate: 0.0051514]
	Learning Rate: 0.00515137
	LOSS [training: 0.11534511368889674 | validation: 0.18591064096965182]
	TIME [epoch: 21.7 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09798214637533467		[learning rate: 0.0051286]
	Learning Rate: 0.00512861
	LOSS [training: 0.09798214637533467 | validation: 0.1619190279892233]
	TIME [epoch: 21.7 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10011282647152116		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 0.10011282647152116 | validation: 0.19164596072985196]
	TIME [epoch: 21.7 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11807247752406788		[learning rate: 0.0050834]
	Learning Rate: 0.00508339
	LOSS [training: 0.11807247752406788 | validation: 0.1790095188767931]
	TIME [epoch: 21.7 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11193135210140506		[learning rate: 0.0050609]
	Learning Rate: 0.00506093
	LOSS [training: 0.11193135210140506 | validation: 0.2578888914914471]
	TIME [epoch: 21.6 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11104856536672225		[learning rate: 0.0050386]
	Learning Rate: 0.00503857
	LOSS [training: 0.11104856536672225 | validation: 0.17512128787021808]
	TIME [epoch: 21.7 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11995890907274073		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 0.11995890907274073 | validation: 0.21617716803851653]
	TIME [epoch: 21.7 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10746398428588173		[learning rate: 0.0049941]
	Learning Rate: 0.00499415
	LOSS [training: 0.10746398428588173 | validation: 0.16127181766236967]
	TIME [epoch: 21.6 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09714344969172332		[learning rate: 0.0049721]
	Learning Rate: 0.00497208
	LOSS [training: 0.09714344969172332 | validation: 0.1602815573343056]
	TIME [epoch: 21.7 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10574376797582578		[learning rate: 0.0049501]
	Learning Rate: 0.00495012
	LOSS [training: 0.10574376797582578 | validation: 0.16192572509194264]
	TIME [epoch: 21.7 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10717442558242891		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 0.10717442558242891 | validation: 0.16454185808771518]
	TIME [epoch: 21.7 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10693672587041306		[learning rate: 0.0049065]
	Learning Rate: 0.00490647
	LOSS [training: 0.10693672587041306 | validation: 0.17786013991065686]
	TIME [epoch: 21.7 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10304628689238364		[learning rate: 0.0048848]
	Learning Rate: 0.00488479
	LOSS [training: 0.10304628689238364 | validation: 0.15560085012488503]
	TIME [epoch: 21.7 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10317971210302894		[learning rate: 0.0048632]
	Learning Rate: 0.00486321
	LOSS [training: 0.10317971210302894 | validation: 0.16296451036064494]
	TIME [epoch: 21.6 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09735700637399744		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 0.09735700637399744 | validation: 0.16149727529014046]
	TIME [epoch: 21.7 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10720897125483622		[learning rate: 0.0048203]
	Learning Rate: 0.00482033
	LOSS [training: 0.10720897125483622 | validation: 0.17627769150008432]
	TIME [epoch: 21.7 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10209927912979119		[learning rate: 0.004799]
	Learning Rate: 0.00479903
	LOSS [training: 0.10209927912979119 | validation: 0.15657726597004537]
	TIME [epoch: 21.7 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10607945578010254		[learning rate: 0.0047778]
	Learning Rate: 0.00477783
	LOSS [training: 0.10607945578010254 | validation: 0.21917043487014878]
	TIME [epoch: 21.6 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10449348115380538		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.10449348115380538 | validation: 0.17807785546823163]
	TIME [epoch: 21.7 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11029283402262044		[learning rate: 0.0047357]
	Learning Rate: 0.0047357
	LOSS [training: 0.11029283402262044 | validation: 0.2107144446333814]
	TIME [epoch: 21.7 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10291286461946866		[learning rate: 0.0047148]
	Learning Rate: 0.00471478
	LOSS [training: 0.10291286461946866 | validation: 0.18115295762504427]
	TIME [epoch: 21.7 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10999333724832923		[learning rate: 0.0046939]
	Learning Rate: 0.00469395
	LOSS [training: 0.10999333724832923 | validation: 0.15915253585215805]
	TIME [epoch: 21.7 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10844639715677365		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 0.10844639715677365 | validation: 0.18271074898400533]
	TIME [epoch: 21.7 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1040360391061591		[learning rate: 0.0046526]
	Learning Rate: 0.00465256
	LOSS [training: 0.1040360391061591 | validation: 0.18764059199968353]
	TIME [epoch: 21.7 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10498968289130617		[learning rate: 0.004632]
	Learning Rate: 0.00463201
	LOSS [training: 0.10498968289130617 | validation: 0.1680507704447807]
	TIME [epoch: 21.7 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12073605358191916		[learning rate: 0.0046115]
	Learning Rate: 0.00461154
	LOSS [training: 0.12073605358191916 | validation: 0.20889923693965526]
	TIME [epoch: 21.7 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11961784125929661		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 0.11961784125929661 | validation: 0.16276866083261798]
	TIME [epoch: 21.7 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10929973035356211		[learning rate: 0.0045709]
	Learning Rate: 0.00457088
	LOSS [training: 0.10929973035356211 | validation: 0.17523053457514684]
	TIME [epoch: 21.7 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11116360312933445		[learning rate: 0.0045507]
	Learning Rate: 0.00455069
	LOSS [training: 0.11116360312933445 | validation: 0.18883753062303438]
	TIME [epoch: 21.7 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09775168005902413		[learning rate: 0.0045306]
	Learning Rate: 0.00453058
	LOSS [training: 0.09775168005902413 | validation: 0.17465440964732243]
	TIME [epoch: 21.7 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09487732651439022		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 0.09487732651439022 | validation: 0.15995129982605952]
	TIME [epoch: 21.7 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0973996225487665		[learning rate: 0.0044906]
	Learning Rate: 0.00449063
	LOSS [training: 0.0973996225487665 | validation: 0.1676439436453686]
	TIME [epoch: 21.7 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1037146325992134		[learning rate: 0.0044708]
	Learning Rate: 0.00447079
	LOSS [training: 0.1037146325992134 | validation: 0.15101546596828758]
	TIME [epoch: 21.7 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10335234128296604		[learning rate: 0.004451]
	Learning Rate: 0.00445104
	LOSS [training: 0.10335234128296604 | validation: 0.16582957898601786]
	TIME [epoch: 21.7 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11648283753834746		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 0.11648283753834746 | validation: 0.17532512296754874]
	TIME [epoch: 21.7 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10235605024140541		[learning rate: 0.0044118]
	Learning Rate: 0.0044118
	LOSS [training: 0.10235605024140541 | validation: 0.15748655736911463]
	TIME [epoch: 21.7 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09143067414138382		[learning rate: 0.0043923]
	Learning Rate: 0.0043923
	LOSS [training: 0.09143067414138382 | validation: 0.1891409026536514]
	TIME [epoch: 21.7 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11386968170297904		[learning rate: 0.0043729]
	Learning Rate: 0.0043729
	LOSS [training: 0.11386968170297904 | validation: 0.16637736724734284]
	TIME [epoch: 21.7 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11183695106559947		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 0.11183695106559947 | validation: 0.19153085032635092]
	TIME [epoch: 21.7 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09577966228932903		[learning rate: 0.0043343]
	Learning Rate: 0.00433434
	LOSS [training: 0.09577966228932903 | validation: 0.15542029021471337]
	TIME [epoch: 21.7 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08977564917967953		[learning rate: 0.0043152]
	Learning Rate: 0.00431519
	LOSS [training: 0.08977564917967953 | validation: 0.16110172101416417]
	TIME [epoch: 21.7 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1176813802872038		[learning rate: 0.0042961]
	Learning Rate: 0.00429612
	LOSS [training: 0.1176813802872038 | validation: 0.19030099237979203]
	TIME [epoch: 21.7 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10876021371703781		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 0.10876021371703781 | validation: 0.15414764967661349]
	TIME [epoch: 21.7 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1049692759196067		[learning rate: 0.0042582]
	Learning Rate: 0.00425825
	LOSS [training: 0.1049692759196067 | validation: 0.1596889742718144]
	TIME [epoch: 21.7 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10332969514701573		[learning rate: 0.0042394]
	Learning Rate: 0.00423943
	LOSS [training: 0.10332969514701573 | validation: 0.14738232588777]
	TIME [epoch: 21.7 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v1_20240624_133245/states/model_facs_dec2b_2dpca_v1_234.pth
	Model improved!!!
EPOCH 235/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08239714748244013		[learning rate: 0.0042207]
	Learning Rate: 0.0042207
	LOSS [training: 0.08239714748244013 | validation: 0.16673131907202637]
	TIME [epoch: 21.7 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09808290096672893		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 0.09808290096672893 | validation: 0.1774634836565282]
	TIME [epoch: 21.7 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09711236716907161		[learning rate: 0.0041835]
	Learning Rate: 0.00418349
	LOSS [training: 0.09711236716907161 | validation: 0.1580472734226843]
	TIME [epoch: 21.7 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09292752368692384		[learning rate: 0.004165]
	Learning Rate: 0.004165
	LOSS [training: 0.09292752368692384 | validation: 0.17396692730089736]
	TIME [epoch: 21.7 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09638075917432512		[learning rate: 0.0041466]
	Learning Rate: 0.0041466
	LOSS [training: 0.09638075917432512 | validation: 0.17461372862300545]
	TIME [epoch: 21.7 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09825204850512895		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 0.09825204850512895 | validation: 0.14997757807018733]
	TIME [epoch: 21.7 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10008708680064256		[learning rate: 0.00411]
	Learning Rate: 0.00411004
	LOSS [training: 0.10008708680064256 | validation: 0.1602296245481147]
	TIME [epoch: 21.6 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09591614098352849		[learning rate: 0.0040919]
	Learning Rate: 0.00409188
	LOSS [training: 0.09591614098352849 | validation: 0.1459444018854345]
	TIME [epoch: 21.7 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v1_20240624_133245/states/model_facs_dec2b_2dpca_v1_242.pth
	Model improved!!!
EPOCH 243/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11241018264647192		[learning rate: 0.0040738]
	Learning Rate: 0.0040738
	LOSS [training: 0.11241018264647192 | validation: 0.17635368591907208]
	TIME [epoch: 21.7 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09309894604082297		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.09309894604082297 | validation: 0.1523227992866525]
	TIME [epoch: 21.7 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1073005280209947		[learning rate: 0.0040379]
	Learning Rate: 0.00403788
	LOSS [training: 0.1073005280209947 | validation: 0.1720820226932705]
	TIME [epoch: 21.7 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11100653173405797		[learning rate: 0.00402]
	Learning Rate: 0.00402004
	LOSS [training: 0.11100653173405797 | validation: 0.15227498010617901]
	TIME [epoch: 21.7 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11316004967435359		[learning rate: 0.0040023]
	Learning Rate: 0.00400228
	LOSS [training: 0.11316004967435359 | validation: 0.1955185460471598]
	TIME [epoch: 21.7 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11238665019252278		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 0.11238665019252278 | validation: 0.15491826502973985]
	TIME [epoch: 21.6 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1168339145341053		[learning rate: 0.003967]
	Learning Rate: 0.00396699
	LOSS [training: 0.1168339145341053 | validation: 0.183488958821022]
	TIME [epoch: 21.7 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10413627657614741		[learning rate: 0.0039495]
	Learning Rate: 0.00394947
	LOSS [training: 0.10413627657614741 | validation: 0.1783833686714042]
	TIME [epoch: 21.7 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09728338705947426		[learning rate: 0.003932]
	Learning Rate: 0.00393202
	LOSS [training: 0.09728338705947426 | validation: 0.15592476532799524]
	TIME [epoch: 21.7 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10282108316461998		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 0.10282108316461998 | validation: 0.1703859550721372]
	TIME [epoch: 21.7 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1034487094441133		[learning rate: 0.0038973]
	Learning Rate: 0.00389735
	LOSS [training: 0.1034487094441133 | validation: 0.14896166107935058]
	TIME [epoch: 21.7 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09238431760623197		[learning rate: 0.0038801]
	Learning Rate: 0.00388013
	LOSS [training: 0.09238431760623197 | validation: 0.16733260470325592]
	TIME [epoch: 21.7 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10265068552661505		[learning rate: 0.003863]
	Learning Rate: 0.00386299
	LOSS [training: 0.10265068552661505 | validation: 0.167860798311187]
	TIME [epoch: 21.7 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10395477148079997		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 0.10395477148079997 | validation: 0.14468777005568134]
	TIME [epoch: 21.7 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v1_20240624_133245/states/model_facs_dec2b_2dpca_v1_256.pth
	Model improved!!!
EPOCH 257/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09807186027880804		[learning rate: 0.0038289]
	Learning Rate: 0.00382893
	LOSS [training: 0.09807186027880804 | validation: 0.16120229248599469]
	TIME [epoch: 21.6 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09447865270768256		[learning rate: 0.003812]
	Learning Rate: 0.00381201
	LOSS [training: 0.09447865270768256 | validation: 0.14478998234335805]
	TIME [epoch: 21.7 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09557004534754272		[learning rate: 0.0037952]
	Learning Rate: 0.00379517
	LOSS [training: 0.09557004534754272 | validation: 0.16872946402375325]
	TIME [epoch: 21.7 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10762550391726149		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 0.10762550391726149 | validation: 0.16775294110491448]
	TIME [epoch: 21.7 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09392789645997764		[learning rate: 0.0037617]
	Learning Rate: 0.0037617
	LOSS [training: 0.09392789645997764 | validation: 0.17168415502311524]
	TIME [epoch: 21.7 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09398363884553322		[learning rate: 0.0037451]
	Learning Rate: 0.00374508
	LOSS [training: 0.09398363884553322 | validation: 0.19415429997464717]
	TIME [epoch: 21.7 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10160282925632569		[learning rate: 0.0037285]
	Learning Rate: 0.00372854
	LOSS [training: 0.10160282925632569 | validation: 0.15523996152879982]
	TIME [epoch: 21.7 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08519603550927621		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 0.08519603550927621 | validation: 0.16772833224559938]
	TIME [epoch: 21.7 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10001379347282971		[learning rate: 0.0036957]
	Learning Rate: 0.00369566
	LOSS [training: 0.10001379347282971 | validation: 0.15926585834009363]
	TIME [epoch: 21.7 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09615040639328314		[learning rate: 0.0036793]
	Learning Rate: 0.00367933
	LOSS [training: 0.09615040639328314 | validation: 0.15550843651389085]
	TIME [epoch: 21.7 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09611411230513443		[learning rate: 0.0036631]
	Learning Rate: 0.00366308
	LOSS [training: 0.09611411230513443 | validation: 0.21866032644256764]
	TIME [epoch: 21.7 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11460841193365487		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 0.11460841193365487 | validation: 0.16301335643036097]
	TIME [epoch: 21.7 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09538127261410927		[learning rate: 0.0036308]
	Learning Rate: 0.00363078
	LOSS [training: 0.09538127261410927 | validation: 0.17645966655129422]
	TIME [epoch: 21.6 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10421524004636842		[learning rate: 0.0036147]
	Learning Rate: 0.00361474
	LOSS [training: 0.10421524004636842 | validation: 0.1439258253319372]
	TIME [epoch: 21.7 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v1_20240624_133245/states/model_facs_dec2b_2dpca_v1_270.pth
	Model improved!!!
EPOCH 271/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1067858578615134		[learning rate: 0.0035988]
	Learning Rate: 0.00359877
	LOSS [training: 0.1067858578615134 | validation: 0.15329310497416412]
	TIME [epoch: 21.7 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08308940630734316		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 0.08308940630734316 | validation: 0.1683818307873892]
	TIME [epoch: 21.7 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11109588447509192		[learning rate: 0.003567]
	Learning Rate: 0.00356704
	LOSS [training: 0.11109588447509192 | validation: 0.15146485084508415]
	TIME [epoch: 21.7 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10657240380369766		[learning rate: 0.0035513]
	Learning Rate: 0.00355128
	LOSS [training: 0.10657240380369766 | validation: 0.1476215982904871]
	TIME [epoch: 21.7 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10608660564962191		[learning rate: 0.0035356]
	Learning Rate: 0.00353559
	LOSS [training: 0.10608660564962191 | validation: 0.22977646469493418]
	TIME [epoch: 21.7 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10703059666047803		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 0.10703059666047803 | validation: 0.14511174538110144]
	TIME [epoch: 21.6 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09919961067760137		[learning rate: 0.0035044]
	Learning Rate: 0.00350441
	LOSS [training: 0.09919961067760137 | validation: 0.186668461047555]
	TIME [epoch: 21.7 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09668794493794067		[learning rate: 0.0034889]
	Learning Rate: 0.00348893
	LOSS [training: 0.09668794493794067 | validation: 0.1427422626574548]
	TIME [epoch: 21.7 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v1_20240624_133245/states/model_facs_dec2b_2dpca_v1_278.pth
	Model improved!!!
EPOCH 279/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09401730468139426		[learning rate: 0.0034735]
	Learning Rate: 0.00347352
	LOSS [training: 0.09401730468139426 | validation: 0.17543226641612264]
	TIME [epoch: 21.6 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09154147074084633		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.09154147074084633 | validation: 0.1577509243852686]
	TIME [epoch: 21.7 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09703835780628298		[learning rate: 0.0034429]
	Learning Rate: 0.00344289
	LOSS [training: 0.09703835780628298 | validation: 0.1920036603024062]
	TIME [epoch: 21.7 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10376810824308505		[learning rate: 0.0034277]
	Learning Rate: 0.00342768
	LOSS [training: 0.10376810824308505 | validation: 0.16003656816683545]
	TIME [epoch: 21.7 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09344256914822417		[learning rate: 0.0034125]
	Learning Rate: 0.00341253
	LOSS [training: 0.09344256914822417 | validation: 0.14918042924142394]
	TIME [epoch: 21.7 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1020826459733147		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 0.1020826459733147 | validation: 0.15410626258616575]
	TIME [epoch: 21.7 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10029835568536638		[learning rate: 0.0033824]
	Learning Rate: 0.00338245
	LOSS [training: 0.10029835568536638 | validation: 0.14530792305939583]
	TIME [epoch: 21.6 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09768485466683893		[learning rate: 0.0033675]
	Learning Rate: 0.0033675
	LOSS [training: 0.09768485466683893 | validation: 0.16064942084345285]
	TIME [epoch: 21.7 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09905119416252042		[learning rate: 0.0033526]
	Learning Rate: 0.00335262
	LOSS [training: 0.09905119416252042 | validation: 0.15109258216782934]
	TIME [epoch: 21.7 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09962619506548427		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 0.09962619506548427 | validation: 0.16509562821559476]
	TIME [epoch: 21.7 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08900161002867765		[learning rate: 0.0033231]
	Learning Rate: 0.00332306
	LOSS [training: 0.08900161002867765 | validation: 0.1476039903019627]
	TIME [epoch: 21.6 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0934758330503845		[learning rate: 0.0033084]
	Learning Rate: 0.00330838
	LOSS [training: 0.0934758330503845 | validation: 0.15251408498486482]
	TIME [epoch: 21.7 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13013120446790807		[learning rate: 0.0032938]
	Learning Rate: 0.00329376
	LOSS [training: 0.13013120446790807 | validation: 0.1854195720415912]
	TIME [epoch: 21.6 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12606545633843566		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 0.12606545633843566 | validation: 0.16934429156306646]
	TIME [epoch: 21.6 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10395166127963824		[learning rate: 0.0032647]
	Learning Rate: 0.00326472
	LOSS [training: 0.10395166127963824 | validation: 0.17904129530719812]
	TIME [epoch: 21.7 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09501618674723843		[learning rate: 0.0032503]
	Learning Rate: 0.0032503
	LOSS [training: 0.09501618674723843 | validation: 0.15241551546465212]
	TIME [epoch: 21.7 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10046083622385948		[learning rate: 0.0032359]
	Learning Rate: 0.00323594
	LOSS [training: 0.10046083622385948 | validation: 0.163914119292015]
	TIME [epoch: 21.6 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09291303371175344		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 0.09291303371175344 | validation: 0.14469969210878394]
	TIME [epoch: 21.7 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09812806815016242		[learning rate: 0.0032074]
	Learning Rate: 0.00320741
	LOSS [training: 0.09812806815016242 | validation: 0.15819754772140884]
	TIME [epoch: 21.7 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09532360697716893		[learning rate: 0.0031932]
	Learning Rate: 0.00319323
	LOSS [training: 0.09532360697716893 | validation: 0.17385978085332277]
	TIME [epoch: 21.6 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10495098393855842		[learning rate: 0.0031791]
	Learning Rate: 0.00317913
	LOSS [training: 0.10495098393855842 | validation: 0.19349399163484343]
	TIME [epoch: 21.6 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10180456653334594		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 0.10180456653334594 | validation: 0.1492801602220699]
	TIME [epoch: 21.7 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09755992872858806		[learning rate: 0.0031511]
	Learning Rate: 0.0031511
	LOSS [training: 0.09755992872858806 | validation: 0.1625621694569258]
	TIME [epoch: 21.6 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09257903689667461		[learning rate: 0.0031372]
	Learning Rate: 0.00313717
	LOSS [training: 0.09257903689667461 | validation: 0.1412746365346789]
	TIME [epoch: 21.6 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v1_20240624_133245/states/model_facs_dec2b_2dpca_v1_302.pth
	Model improved!!!
EPOCH 303/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10606968288040544		[learning rate: 0.0031233]
	Learning Rate: 0.00312331
	LOSS [training: 0.10606968288040544 | validation: 0.16410960186713572]
	TIME [epoch: 21.7 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08884154016319776		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 0.08884154016319776 | validation: 0.1574653334210085]
	TIME [epoch: 21.6 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09132137658058578		[learning rate: 0.0030958]
	Learning Rate: 0.00309577
	LOSS [training: 0.09132137658058578 | validation: 0.1541247486484582]
	TIME [epoch: 21.6 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09705564824186667		[learning rate: 0.0030821]
	Learning Rate: 0.0030821
	LOSS [training: 0.09705564824186667 | validation: 0.17571002104982628]
	TIME [epoch: 21.7 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10585732479505776		[learning rate: 0.0030685]
	Learning Rate: 0.00306848
	LOSS [training: 0.10585732479505776 | validation: 0.1573933613036942]
	TIME [epoch: 21.6 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09271336099726275		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 0.09271336099726275 | validation: 0.16445386474340845]
	TIME [epoch: 21.6 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10175533855619867		[learning rate: 0.0030414]
	Learning Rate: 0.00304142
	LOSS [training: 0.10175533855619867 | validation: 0.16679266005055443]
	TIME [epoch: 21.6 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10395317071968571		[learning rate: 0.003028]
	Learning Rate: 0.00302799
	LOSS [training: 0.10395317071968571 | validation: 0.15854511829147253]
	TIME [epoch: 21.6 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09427995769883503		[learning rate: 0.0030146]
	Learning Rate: 0.00301461
	LOSS [training: 0.09427995769883503 | validation: 0.20214629796650055]
	TIME [epoch: 21.6 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10309309223175786		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 0.10309309223175786 | validation: 0.17000293798609173]
	TIME [epoch: 21.7 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10726035781354448		[learning rate: 0.002988]
	Learning Rate: 0.00298803
	LOSS [training: 0.10726035781354448 | validation: 0.15464540691933334]
	TIME [epoch: 21.7 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09425763846004723		[learning rate: 0.0029748]
	Learning Rate: 0.00297483
	LOSS [training: 0.09425763846004723 | validation: 0.16567423300089457]
	TIME [epoch: 21.6 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09745229622203115		[learning rate: 0.0029617]
	Learning Rate: 0.00296168
	LOSS [training: 0.09745229622203115 | validation: 0.1528104153810273]
	TIME [epoch: 21.6 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09125788703612361		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.09125788703612361 | validation: 0.16503711656007197]
	TIME [epoch: 21.7 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0929862042264335		[learning rate: 0.0029356]
	Learning Rate: 0.00293557
	LOSS [training: 0.0929862042264335 | validation: 0.14599076802256294]
	TIME [epoch: 21.7 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10438582874836026		[learning rate: 0.0029226]
	Learning Rate: 0.0029226
	LOSS [training: 0.10438582874836026 | validation: 0.15893375542591356]
	TIME [epoch: 21.7 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09444280250675832		[learning rate: 0.0029097]
	Learning Rate: 0.00290969
	LOSS [training: 0.09444280250675832 | validation: 0.146545107608795]
	TIME [epoch: 21.7 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09905612361614974		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 0.09905612361614974 | validation: 0.15878713414506862]
	TIME [epoch: 21.7 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09007048396326824		[learning rate: 0.002884]
	Learning Rate: 0.00288403
	LOSS [training: 0.09007048396326824 | validation: 0.17077198229305804]
	TIME [epoch: 21.7 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10263670052334428		[learning rate: 0.0028713]
	Learning Rate: 0.00287129
	LOSS [training: 0.10263670052334428 | validation: 0.15011419627499503]
	TIME [epoch: 21.7 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09686481609592867		[learning rate: 0.0028586]
	Learning Rate: 0.0028586
	LOSS [training: 0.09686481609592867 | validation: 0.15950376762156088]
	TIME [epoch: 21.7 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09740837818228958		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 0.09740837818228958 | validation: 0.1703549652793783]
	TIME [epoch: 21.6 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10439565343422967		[learning rate: 0.0028334]
	Learning Rate: 0.0028334
	LOSS [training: 0.10439565343422967 | validation: 0.1458771391122314]
	TIME [epoch: 21.6 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09825493860493979		[learning rate: 0.0028209]
	Learning Rate: 0.00282088
	LOSS [training: 0.09825493860493979 | validation: 0.16031617390663916]
	TIME [epoch: 21.6 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1023559654494934		[learning rate: 0.0028084]
	Learning Rate: 0.00280842
	LOSS [training: 0.1023559654494934 | validation: 0.15129383780461012]
	TIME [epoch: 21.7 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09539143534510298		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 0.09539143534510298 | validation: 0.16799086876247363]
	TIME [epoch: 21.7 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10198587907741694		[learning rate: 0.0027837]
	Learning Rate: 0.00278366
	LOSS [training: 0.10198587907741694 | validation: 0.14602252264517812]
	TIME [epoch: 21.7 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10013936507824046		[learning rate: 0.0027714]
	Learning Rate: 0.00277136
	LOSS [training: 0.10013936507824046 | validation: 0.15416434470983614]
	TIME [epoch: 21.7 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09008725670435598		[learning rate: 0.0027591]
	Learning Rate: 0.00275911
	LOSS [training: 0.09008725670435598 | validation: 0.1491420316306629]
	TIME [epoch: 21.7 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09171838297465755		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 0.09171838297465755 | validation: 0.15478998738501937]
	TIME [epoch: 21.7 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0929514418176853		[learning rate: 0.0027348]
	Learning Rate: 0.00273478
	LOSS [training: 0.0929514418176853 | validation: 0.16456201974698614]
	TIME [epoch: 21.6 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09935614423032627		[learning rate: 0.0027227]
	Learning Rate: 0.0027227
	LOSS [training: 0.09935614423032627 | validation: 0.17976567303032578]
	TIME [epoch: 21.7 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10027350131159736		[learning rate: 0.0027107]
	Learning Rate: 0.00271067
	LOSS [training: 0.10027350131159736 | validation: 0.14071840776382455]
	TIME [epoch: 21.7 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v1_20240624_133245/states/model_facs_dec2b_2dpca_v1_335.pth
	Model improved!!!
EPOCH 336/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09894637667124909		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 0.09894637667124909 | validation: 0.1503910423483577]
	TIME [epoch: 21.7 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07934537898433795		[learning rate: 0.0026868]
	Learning Rate: 0.00268677
	LOSS [training: 0.07934537898433795 | validation: 0.15894539583652795]
	TIME [epoch: 21.7 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09490436389618677		[learning rate: 0.0026749]
	Learning Rate: 0.0026749
	LOSS [training: 0.09490436389618677 | validation: 0.1792071587576139]
	TIME [epoch: 21.7 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10037069104374177		[learning rate: 0.0026631]
	Learning Rate: 0.00266308
	LOSS [training: 0.10037069104374177 | validation: 0.1596004332619709]
	TIME [epoch: 21.7 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1074821059286946		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 0.1074821059286946 | validation: 0.17348642983178203]
	TIME [epoch: 21.6 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11719866106225545		[learning rate: 0.0026396]
	Learning Rate: 0.0026396
	LOSS [training: 0.11719866106225545 | validation: 0.16941798185963114]
	TIME [epoch: 21.7 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10103156128830496		[learning rate: 0.0026279]
	Learning Rate: 0.00262794
	LOSS [training: 0.10103156128830496 | validation: 0.15318350015742435]
	TIME [epoch: 21.7 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09649046631500527		[learning rate: 0.0026163]
	Learning Rate: 0.00261633
	LOSS [training: 0.09649046631500527 | validation: 0.16335780828095348]
	TIME [epoch: 21.7 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09876138161903047		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 0.09876138161903047 | validation: 0.15237798054624255]
	TIME [epoch: 21.7 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08823828438610956		[learning rate: 0.0025933]
	Learning Rate: 0.00259326
	LOSS [training: 0.08823828438610956 | validation: 0.15709240761909796]
	TIME [epoch: 21.7 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09590015560222484		[learning rate: 0.0025818]
	Learning Rate: 0.0025818
	LOSS [training: 0.09590015560222484 | validation: 0.15488027183513228]
	TIME [epoch: 21.7 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11799514258997386		[learning rate: 0.0025704]
	Learning Rate: 0.0025704
	LOSS [training: 0.11799514258997386 | validation: 0.17625148003330277]
	TIME [epoch: 21.7 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10495517558648142		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.10495517558648142 | validation: 0.14177234161072605]
	TIME [epoch: 21.6 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09631938146514285		[learning rate: 0.0025477]
	Learning Rate: 0.00254773
	LOSS [training: 0.09631938146514285 | validation: 0.15762294480956873]
	TIME [epoch: 21.6 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0963117599289742		[learning rate: 0.0025365]
	Learning Rate: 0.00253648
	LOSS [training: 0.0963117599289742 | validation: 0.16858984291505077]
	TIME [epoch: 21.7 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0911933458070976		[learning rate: 0.0025253]
	Learning Rate: 0.00252527
	LOSS [training: 0.0911933458070976 | validation: 0.13915167826015287]
	TIME [epoch: 21.7 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v1_20240624_133245/states/model_facs_dec2b_2dpca_v1_351.pth
	Model improved!!!
EPOCH 352/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0885720839335496		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.0885720839335496 | validation: 0.15147314184327512]
	TIME [epoch: 21.7 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09232244817905366		[learning rate: 0.002503]
	Learning Rate: 0.002503
	LOSS [training: 0.09232244817905366 | validation: 0.16686800075396763]
	TIME [epoch: 21.7 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08715749592896953		[learning rate: 0.0024919]
	Learning Rate: 0.00249194
	LOSS [training: 0.08715749592896953 | validation: 0.14670756220891978]
	TIME [epoch: 21.6 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09758715631038113		[learning rate: 0.0024809]
	Learning Rate: 0.00248093
	LOSS [training: 0.09758715631038113 | validation: 0.15650451353974904]
	TIME [epoch: 21.7 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09617954612143353		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 0.09617954612143353 | validation: 0.15127846803343067]
	TIME [epoch: 21.7 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0887263438498163		[learning rate: 0.0024591]
	Learning Rate: 0.00245906
	LOSS [training: 0.0887263438498163 | validation: 0.16278527475187016]
	TIME [epoch: 21.7 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08940178879931956		[learning rate: 0.0024482]
	Learning Rate: 0.0024482
	LOSS [training: 0.08940178879931956 | validation: 0.15923242776237534]
	TIME [epoch: 21.6 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09573498169295391		[learning rate: 0.0024374]
	Learning Rate: 0.00243738
	LOSS [training: 0.09573498169295391 | validation: 0.15840138623156078]
	TIME [epoch: 21.7 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09135443193152297		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.09135443193152297 | validation: 0.17351141333581244]
	TIME [epoch: 21.7 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10804656402082091		[learning rate: 0.0024159]
	Learning Rate: 0.00241589
	LOSS [training: 0.10804656402082091 | validation: 0.145158669431066]
	TIME [epoch: 21.7 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09909861451088138		[learning rate: 0.0024052]
	Learning Rate: 0.00240521
	LOSS [training: 0.09909861451088138 | validation: 0.17369293936653352]
	TIME [epoch: 21.7 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09270084618771815		[learning rate: 0.0023946]
	Learning Rate: 0.00239459
	LOSS [training: 0.09270084618771815 | validation: 0.15446003862116262]
	TIME [epoch: 21.7 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1008717243884496		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 0.1008717243884496 | validation: 0.141460676143114]
	TIME [epoch: 21.7 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09740526485985801		[learning rate: 0.0023735]
	Learning Rate: 0.00237347
	LOSS [training: 0.09740526485985801 | validation: 0.16620139406121373]
	TIME [epoch: 21.6 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09300059618113843		[learning rate: 0.002363]
	Learning Rate: 0.00236299
	LOSS [training: 0.09300059618113843 | validation: 0.1531749200366238]
	TIME [epoch: 21.7 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0938443247144127		[learning rate: 0.0023525]
	Learning Rate: 0.00235255
	LOSS [training: 0.0938443247144127 | validation: 0.1521319660182885]
	TIME [epoch: 21.7 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09139124264310114		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.09139124264310114 | validation: 0.14971775822328143]
	TIME [epoch: 21.6 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09487965059735128		[learning rate: 0.0023318]
	Learning Rate: 0.00233181
	LOSS [training: 0.09487965059735128 | validation: 0.18770895087743666]
	TIME [epoch: 21.7 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11008021841109294		[learning rate: 0.0023215]
	Learning Rate: 0.0023215
	LOSS [training: 0.11008021841109294 | validation: 0.15000883480470173]
	TIME [epoch: 21.6 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08990133722184078		[learning rate: 0.0023112]
	Learning Rate: 0.00231125
	LOSS [training: 0.08990133722184078 | validation: 0.1532188225398616]
	TIME [epoch: 21.6 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08811294559619284		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.08811294559619284 | validation: 0.14829119476026884]
	TIME [epoch: 21.6 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09160775892668567		[learning rate: 0.0022909]
	Learning Rate: 0.00229087
	LOSS [training: 0.09160775892668567 | validation: 0.15514491056177368]
	TIME [epoch: 21.7 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10099243939384994		[learning rate: 0.0022807]
	Learning Rate: 0.00228075
	LOSS [training: 0.10099243939384994 | validation: 0.18581874256533726]
	TIME [epoch: 21.6 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09033773955483963		[learning rate: 0.0022707]
	Learning Rate: 0.00227067
	LOSS [training: 0.09033773955483963 | validation: 0.1900335404410238]
	TIME [epoch: 21.7 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09278936917616562		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.09278936917616562 | validation: 0.15628255874929914]
	TIME [epoch: 21.6 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08233103657088948		[learning rate: 0.0022506]
	Learning Rate: 0.00225065
	LOSS [training: 0.08233103657088948 | validation: 0.16497502371899883]
	TIME [epoch: 21.6 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09367835756057888		[learning rate: 0.0022407]
	Learning Rate: 0.0022407
	LOSS [training: 0.09367835756057888 | validation: 0.1428955256533527]
	TIME [epoch: 21.6 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09539759638295708		[learning rate: 0.0022308]
	Learning Rate: 0.0022308
	LOSS [training: 0.09539759638295708 | validation: 0.15095194968591238]
	TIME [epoch: 21.7 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08898912012867122		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.08898912012867122 | validation: 0.14503661793316577]
	TIME [epoch: 21.6 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10400421793129092		[learning rate: 0.0022111]
	Learning Rate: 0.00221114
	LOSS [training: 0.10400421793129092 | validation: 0.16611017339507506]
	TIME [epoch: 21.6 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09010922605542765		[learning rate: 0.0022014]
	Learning Rate: 0.00220137
	LOSS [training: 0.09010922605542765 | validation: 0.16210185494119225]
	TIME [epoch: 21.6 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08565606905388586		[learning rate: 0.0021916]
	Learning Rate: 0.00219164
	LOSS [training: 0.08565606905388586 | validation: 0.1655145369777125]
	TIME [epoch: 21.6 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0988878343348715		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.0988878343348715 | validation: 0.14837501945568654]
	TIME [epoch: 21.6 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09693553782400495		[learning rate: 0.0021723]
	Learning Rate: 0.00217232
	LOSS [training: 0.09693553782400495 | validation: 0.15127265666736672]
	TIME [epoch: 21.6 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09345744133583904		[learning rate: 0.0021627]
	Learning Rate: 0.00216272
	LOSS [training: 0.09345744133583904 | validation: 0.14735875410782198]
	TIME [epoch: 21.7 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0987140710581359		[learning rate: 0.0021532]
	Learning Rate: 0.00215316
	LOSS [training: 0.0987140710581359 | validation: 0.16587628943607544]
	TIME [epoch: 21.6 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08895195861900901		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.08895195861900901 | validation: 0.15489399853737618]
	TIME [epoch: 21.6 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09473206865039262		[learning rate: 0.0021342]
	Learning Rate: 0.00213418
	LOSS [training: 0.09473206865039262 | validation: 0.1598467351580799]
	TIME [epoch: 21.7 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09020710660483763		[learning rate: 0.0021247]
	Learning Rate: 0.00212475
	LOSS [training: 0.09020710660483763 | validation: 0.15982716621499754]
	TIME [epoch: 21.6 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0926899999527286		[learning rate: 0.0021154]
	Learning Rate: 0.00211536
	LOSS [training: 0.0926899999527286 | validation: 0.1391759369343319]
	TIME [epoch: 21.6 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09150792605222971		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.09150792605222971 | validation: 0.16094306670356115]
	TIME [epoch: 21.7 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09521385018502622		[learning rate: 0.0020967]
	Learning Rate: 0.00209671
	LOSS [training: 0.09521385018502622 | validation: 0.15257879517289302]
	TIME [epoch: 21.7 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09464940251411098		[learning rate: 0.0020874]
	Learning Rate: 0.00208745
	LOSS [training: 0.09464940251411098 | validation: 0.14756251784670352]
	TIME [epoch: 21.6 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08716830093852053		[learning rate: 0.0020782]
	Learning Rate: 0.00207822
	LOSS [training: 0.08716830093852053 | validation: 0.16773238347816996]
	TIME [epoch: 21.6 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09628381982215498		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.09628381982215498 | validation: 0.1538223334763588]
	TIME [epoch: 21.6 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09560170557141652		[learning rate: 0.0020599]
	Learning Rate: 0.0020599
	LOSS [training: 0.09560170557141652 | validation: 0.1708346719620261]
	TIME [epoch: 21.7 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0901454828292945		[learning rate: 0.0020508]
	Learning Rate: 0.0020508
	LOSS [training: 0.0901454828292945 | validation: 0.1407906219573335]
	TIME [epoch: 21.7 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10363698976332669		[learning rate: 0.0020417]
	Learning Rate: 0.00204174
	LOSS [training: 0.10363698976332669 | validation: 0.17089355960245492]
	TIME [epoch: 21.6 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08514360132591463		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.08514360132591463 | validation: 0.15299822524575027]
	TIME [epoch: 21.6 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0983175950301964		[learning rate: 0.0020237]
	Learning Rate: 0.00202374
	LOSS [training: 0.0983175950301964 | validation: 0.1656387981350696]
	TIME [epoch: 21.7 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0853800500360704		[learning rate: 0.0020148]
	Learning Rate: 0.00201479
	LOSS [training: 0.0853800500360704 | validation: 0.14486385770734433]
	TIME [epoch: 21.6 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08791934893538392		[learning rate: 0.0020059]
	Learning Rate: 0.00200589
	LOSS [training: 0.08791934893538392 | validation: 0.15927309357397026]
	TIME [epoch: 21.7 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08946046002141414		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.08946046002141414 | validation: 0.15200980214149917]
	TIME [epoch: 21.7 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08485301085126953		[learning rate: 0.0019882]
	Learning Rate: 0.00198821
	LOSS [training: 0.08485301085126953 | validation: 0.14519404660695345]
	TIME [epoch: 21.7 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08335581349221965		[learning rate: 0.0019794]
	Learning Rate: 0.00197942
	LOSS [training: 0.08335581349221965 | validation: 0.15383953444163959]
	TIME [epoch: 21.7 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08565297323751672		[learning rate: 0.0019707]
	Learning Rate: 0.00197068
	LOSS [training: 0.08565297323751672 | validation: 0.14935199339635155]
	TIME [epoch: 21.7 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09005960358981008		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.09005960358981008 | validation: 0.153034714405476]
	TIME [epoch: 21.7 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0832208610678227		[learning rate: 0.0019533]
	Learning Rate: 0.0019533
	LOSS [training: 0.0832208610678227 | validation: 0.15396394794174306]
	TIME [epoch: 21.7 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09135589791796468		[learning rate: 0.0019447]
	Learning Rate: 0.00194467
	LOSS [training: 0.09135589791796468 | validation: 0.15782740571432716]
	TIME [epoch: 21.7 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09232893273900589		[learning rate: 0.0019361]
	Learning Rate: 0.00193608
	LOSS [training: 0.09232893273900589 | validation: 0.15499024111203377]
	TIME [epoch: 21.7 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09173292839071279		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.09173292839071279 | validation: 0.13785111483686027]
	TIME [epoch: 21.6 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v1_20240624_133245/states/model_facs_dec2b_2dpca_v1_412.pth
	Model improved!!!
EPOCH 413/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09195249771245204		[learning rate: 0.001919]
	Learning Rate: 0.00191901
	LOSS [training: 0.09195249771245204 | validation: 0.15359426231694953]
	TIME [epoch: 21.6 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08932437132201809		[learning rate: 0.0019105]
	Learning Rate: 0.00191053
	LOSS [training: 0.08932437132201809 | validation: 0.13949338060704497]
	TIME [epoch: 21.6 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09048895687246833		[learning rate: 0.0019021]
	Learning Rate: 0.00190209
	LOSS [training: 0.09048895687246833 | validation: 0.14729313156666415]
	TIME [epoch: 21.6 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08377643032229555		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.08377643032229555 | validation: 0.14239608984687827]
	TIME [epoch: 21.6 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08438954711470593		[learning rate: 0.0018853]
	Learning Rate: 0.00188532
	LOSS [training: 0.08438954711470593 | validation: 0.15409329930151774]
	TIME [epoch: 21.6 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09835831650009594		[learning rate: 0.001877]
	Learning Rate: 0.00187699
	LOSS [training: 0.09835831650009594 | validation: 0.15528612342400414]
	TIME [epoch: 21.6 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08507447943661897		[learning rate: 0.0018687]
	Learning Rate: 0.0018687
	LOSS [training: 0.08507447943661897 | validation: 0.151488394625018]
	TIME [epoch: 21.6 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09902210798247868		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.09902210798247868 | validation: 0.14645560865733584]
	TIME [epoch: 21.6 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08841674459401347		[learning rate: 0.0018522]
	Learning Rate: 0.00185222
	LOSS [training: 0.08841674459401347 | validation: 0.15865144125102548]
	TIME [epoch: 21.6 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08745813635298563		[learning rate: 0.001844]
	Learning Rate: 0.00184404
	LOSS [training: 0.08745813635298563 | validation: 0.1482774941767181]
	TIME [epoch: 21.6 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09335243563257076		[learning rate: 0.0018359]
	Learning Rate: 0.00183589
	LOSS [training: 0.09335243563257076 | validation: 0.17499320582730282]
	TIME [epoch: 21.6 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08805415187984189		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.08805415187984189 | validation: 0.1343590557807662]
	TIME [epoch: 21.6 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v1_20240624_133245/states/model_facs_dec2b_2dpca_v1_424.pth
	Model improved!!!
EPOCH 425/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10154388327832867		[learning rate: 0.0018197]
	Learning Rate: 0.0018197
	LOSS [training: 0.10154388327832867 | validation: 0.15495952728734882]
	TIME [epoch: 21.7 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09107855959078726		[learning rate: 0.0018117]
	Learning Rate: 0.00181166
	LOSS [training: 0.09107855959078726 | validation: 0.14527944051051792]
	TIME [epoch: 21.7 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09870533475357404		[learning rate: 0.0018037]
	Learning Rate: 0.00180366
	LOSS [training: 0.09870533475357404 | validation: 0.1603169758142271]
	TIME [epoch: 21.7 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08574158375428582		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.08574158375428582 | validation: 0.1608636276007135]
	TIME [epoch: 21.7 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09062546581620554		[learning rate: 0.0017878]
	Learning Rate: 0.00178775
	LOSS [training: 0.09062546581620554 | validation: 0.15629838743104665]
	TIME [epoch: 21.7 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08617879178305164		[learning rate: 0.0017799]
	Learning Rate: 0.00177985
	LOSS [training: 0.08617879178305164 | validation: 0.15378605358113004]
	TIME [epoch: 21.7 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09128725746701286		[learning rate: 0.001772]
	Learning Rate: 0.00177199
	LOSS [training: 0.09128725746701286 | validation: 0.15149504841638584]
	TIME [epoch: 21.7 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08587783195415485		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.08587783195415485 | validation: 0.15352216966150808]
	TIME [epoch: 21.7 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09125786968013924		[learning rate: 0.0017564]
	Learning Rate: 0.00175637
	LOSS [training: 0.09125786968013924 | validation: 0.15156064585450246]
	TIME [epoch: 21.7 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09502672604718923		[learning rate: 0.0017486]
	Learning Rate: 0.00174861
	LOSS [training: 0.09502672604718923 | validation: 0.15542512552605592]
	TIME [epoch: 21.7 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09456826609398222		[learning rate: 0.0017409]
	Learning Rate: 0.00174088
	LOSS [training: 0.09456826609398222 | validation: 0.15177298237413545]
	TIME [epoch: 21.7 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0937212519455997		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.0937212519455997 | validation: 0.14493217573234687]
	TIME [epoch: 21.7 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09714429121766154		[learning rate: 0.0017255]
	Learning Rate: 0.00172553
	LOSS [training: 0.09714429121766154 | validation: 0.15806866882074713]
	TIME [epoch: 21.7 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09436407758730173		[learning rate: 0.0017179]
	Learning Rate: 0.00171791
	LOSS [training: 0.09436407758730173 | validation: 0.15524565159233022]
	TIME [epoch: 21.7 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09682781078137333		[learning rate: 0.0017103]
	Learning Rate: 0.00171032
	LOSS [training: 0.09682781078137333 | validation: 0.1727029685607533]
	TIME [epoch: 21.7 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09294631382609365		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.09294631382609365 | validation: 0.14990902728464411]
	TIME [epoch: 21.6 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08118672506166194		[learning rate: 0.0016952]
	Learning Rate: 0.00169524
	LOSS [training: 0.08118672506166194 | validation: 0.16313168835193453]
	TIME [epoch: 21.7 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09536855139676724		[learning rate: 0.0016877]
	Learning Rate: 0.00168775
	LOSS [training: 0.09536855139676724 | validation: 0.13984461723928068]
	TIME [epoch: 21.6 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09956445010458063		[learning rate: 0.0016803]
	Learning Rate: 0.00168029
	LOSS [training: 0.09956445010458063 | validation: 0.157949092797378]
	TIME [epoch: 21.6 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0934627104417036		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.0934627104417036 | validation: 0.14052219203746813]
	TIME [epoch: 21.6 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10125707340322583		[learning rate: 0.0016655]
	Learning Rate: 0.00166548
	LOSS [training: 0.10125707340322583 | validation: 0.1477876680538125]
	TIME [epoch: 21.7 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08389423247019381		[learning rate: 0.0016581]
	Learning Rate: 0.00165812
	LOSS [training: 0.08389423247019381 | validation: 0.1662295606595845]
	TIME [epoch: 21.7 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09189970525804908		[learning rate: 0.0016508]
	Learning Rate: 0.00165079
	LOSS [training: 0.09189970525804908 | validation: 0.136287098565058]
	TIME [epoch: 21.7 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08730996159128994		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.08730996159128994 | validation: 0.1574397109997444]
	TIME [epoch: 21.7 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08904802651086967		[learning rate: 0.0016362]
	Learning Rate: 0.00163624
	LOSS [training: 0.08904802651086967 | validation: 0.15040352232130247]
	TIME [epoch: 21.6 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08534200644367818		[learning rate: 0.001629]
	Learning Rate: 0.00162901
	LOSS [training: 0.08534200644367818 | validation: 0.17095270789694478]
	TIME [epoch: 21.7 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08048897523913538		[learning rate: 0.0016218]
	Learning Rate: 0.00162181
	LOSS [training: 0.08048897523913538 | validation: 0.15032372789309595]
	TIME [epoch: 21.7 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09003606437415908		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.09003606437415908 | validation: 0.1608964927874371]
	TIME [epoch: 21.7 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08415145864549958		[learning rate: 0.0016075]
	Learning Rate: 0.00160751
	LOSS [training: 0.08415145864549958 | validation: 0.17804830682325537]
	TIME [epoch: 21.6 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09641421198508185		[learning rate: 0.0016004]
	Learning Rate: 0.00160041
	LOSS [training: 0.09641421198508185 | validation: 0.1646186567895043]
	TIME [epoch: 21.7 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08623003249849662		[learning rate: 0.0015933]
	Learning Rate: 0.00159334
	LOSS [training: 0.08623003249849662 | validation: 0.1693526655743974]
	TIME [epoch: 21.7 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0873475379535478		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.0873475379535478 | validation: 0.15107692333860162]
	TIME [epoch: 21.7 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07575688448025357		[learning rate: 0.0015793]
	Learning Rate: 0.00157929
	LOSS [training: 0.07575688448025357 | validation: 0.14958816024259047]
	TIME [epoch: 21.7 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0878501118361885		[learning rate: 0.0015723]
	Learning Rate: 0.00157231
	LOSS [training: 0.0878501118361885 | validation: 0.1637338381182321]
	TIME [epoch: 21.7 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08340875965664316		[learning rate: 0.0015654]
	Learning Rate: 0.00156536
	LOSS [training: 0.08340875965664316 | validation: 0.14513167287070305]
	TIME [epoch: 21.7 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08918154439009698		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.08918154439009698 | validation: 0.1556286159736575]
	TIME [epoch: 21.6 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09332950503209325		[learning rate: 0.0015516]
	Learning Rate: 0.00155156
	LOSS [training: 0.09332950503209325 | validation: 0.16018384295133925]
	TIME [epoch: 21.7 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0924825506355161		[learning rate: 0.0015447]
	Learning Rate: 0.00154471
	LOSS [training: 0.0924825506355161 | validation: 0.1436919568156522]
	TIME [epoch: 21.6 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0870942118266251		[learning rate: 0.0015379]
	Learning Rate: 0.00153788
	LOSS [training: 0.0870942118266251 | validation: 0.1656992948173417]
	TIME [epoch: 21.7 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09093823331356665		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.09093823331356665 | validation: 0.1600302214365953]
	TIME [epoch: 21.7 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09208940915825475		[learning rate: 0.0015243]
	Learning Rate: 0.00152432
	LOSS [training: 0.09208940915825475 | validation: 0.14790714703709323]
	TIME [epoch: 21.7 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0973291312983851		[learning rate: 0.0015176]
	Learning Rate: 0.00151759
	LOSS [training: 0.0973291312983851 | validation: 0.14250513547915827]
	TIME [epoch: 21.7 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0938623848903807		[learning rate: 0.0015109]
	Learning Rate: 0.00151088
	LOSS [training: 0.0938623848903807 | validation: 0.14990229461672921]
	TIME [epoch: 21.7 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08861479980612286		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.08861479980612286 | validation: 0.14365907978212689]
	TIME [epoch: 21.7 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09140223800743415		[learning rate: 0.0014976]
	Learning Rate: 0.00149756
	LOSS [training: 0.09140223800743415 | validation: 0.15874133139519278]
	TIME [epoch: 21.7 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08902815042538423		[learning rate: 0.0014909]
	Learning Rate: 0.00149094
	LOSS [training: 0.08902815042538423 | validation: 0.15113026639230545]
	TIME [epoch: 21.7 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08359806718109943		[learning rate: 0.0014844]
	Learning Rate: 0.00148436
	LOSS [training: 0.08359806718109943 | validation: 0.14802108267292904]
	TIME [epoch: 21.7 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0856197935573684		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.0856197935573684 | validation: 0.1652491376792466]
	TIME [epoch: 21.7 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09404496521857111		[learning rate: 0.0014713]
	Learning Rate: 0.00147127
	LOSS [training: 0.09404496521857111 | validation: 0.1561552050937737]
	TIME [epoch: 21.7 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09037801436271513		[learning rate: 0.0014648]
	Learning Rate: 0.00146477
	LOSS [training: 0.09037801436271513 | validation: 0.13847874758286882]
	TIME [epoch: 21.7 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09820770243667576		[learning rate: 0.0014583]
	Learning Rate: 0.0014583
	LOSS [training: 0.09820770243667576 | validation: 0.14754663609045052]
	TIME [epoch: 21.7 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08898485180736015		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.08898485180736015 | validation: 0.15813342309091732]
	TIME [epoch: 21.7 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0909402366024505		[learning rate: 0.0014454]
	Learning Rate: 0.00144544
	LOSS [training: 0.0909402366024505 | validation: 0.14546192201663954]
	TIME [epoch: 21.7 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09402097896939354		[learning rate: 0.0014391]
	Learning Rate: 0.00143905
	LOSS [training: 0.09402097896939354 | validation: 0.17294938702077342]
	TIME [epoch: 21.7 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0913890929213884		[learning rate: 0.0014327]
	Learning Rate: 0.0014327
	LOSS [training: 0.0913890929213884 | validation: 0.13921501733669064]
	TIME [epoch: 21.7 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09509202438872458		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.09509202438872458 | validation: 0.15174464185387102]
	TIME [epoch: 21.7 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08207848395761225		[learning rate: 0.0014201]
	Learning Rate: 0.00142006
	LOSS [training: 0.08207848395761225 | validation: 0.1550612767954182]
	TIME [epoch: 21.7 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08453656231687164		[learning rate: 0.0014138]
	Learning Rate: 0.00141379
	LOSS [training: 0.08453656231687164 | validation: 0.14656608687161238]
	TIME [epoch: 21.7 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08737912737156299		[learning rate: 0.0014075]
	Learning Rate: 0.00140754
	LOSS [training: 0.08737912737156299 | validation: 0.15852746265461057]
	TIME [epoch: 21.7 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08813797448622776		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.08813797448622776 | validation: 0.15568421582382153]
	TIME [epoch: 21.7 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08662450416247314		[learning rate: 0.0013951]
	Learning Rate: 0.00139513
	LOSS [training: 0.08662450416247314 | validation: 0.14620607425466672]
	TIME [epoch: 21.7 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08898977595312535		[learning rate: 0.001389]
	Learning Rate: 0.00138897
	LOSS [training: 0.08898977595312535 | validation: 0.1664536186866759]
	TIME [epoch: 21.7 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08829908421518148		[learning rate: 0.0013828]
	Learning Rate: 0.00138283
	LOSS [training: 0.08829908421518148 | validation: 0.1428252607496999]
	TIME [epoch: 21.7 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09135870938397275		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.09135870938397275 | validation: 0.14914939172154432]
	TIME [epoch: 21.7 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08900119236228758		[learning rate: 0.0013706]
	Learning Rate: 0.00137064
	LOSS [training: 0.08900119236228758 | validation: 0.1627930945599366]
	TIME [epoch: 21.7 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.080025877727437		[learning rate: 0.0013646]
	Learning Rate: 0.00136458
	LOSS [training: 0.080025877727437 | validation: 0.14837976061395142]
	TIME [epoch: 21.7 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08900508458420689		[learning rate: 0.0013586]
	Learning Rate: 0.00135855
	LOSS [training: 0.08900508458420689 | validation: 0.1496299572170496]
	TIME [epoch: 21.7 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08634838503504502		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.08634838503504502 | validation: 0.1517084602851214]
	TIME [epoch: 21.7 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08568473235054543		[learning rate: 0.0013466]
	Learning Rate: 0.00134658
	LOSS [training: 0.08568473235054543 | validation: 0.16573178932947472]
	TIME [epoch: 21.7 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0823584964659278		[learning rate: 0.0013406]
	Learning Rate: 0.00134063
	LOSS [training: 0.0823584964659278 | validation: 0.16214892696217498]
	TIME [epoch: 21.7 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09156011793633598		[learning rate: 0.0013347]
	Learning Rate: 0.0013347
	LOSS [training: 0.09156011793633598 | validation: 0.15871594064738664]
	TIME [epoch: 21.7 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09927519017717049		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.09927519017717049 | validation: 0.1491135776607285]
	TIME [epoch: 21.7 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09454787361320358		[learning rate: 0.0013229]
	Learning Rate: 0.00132293
	LOSS [training: 0.09454787361320358 | validation: 0.15703690466526085]
	TIME [epoch: 21.9 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0901113844904122		[learning rate: 0.0013171]
	Learning Rate: 0.00131709
	LOSS [training: 0.0901113844904122 | validation: 0.15345815846162464]
	TIME [epoch: 21.8 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09056070746066482		[learning rate: 0.0013113]
	Learning Rate: 0.00131127
	LOSS [training: 0.09056070746066482 | validation: 0.14551864803702677]
	TIME [epoch: 21.7 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08350075905729008		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.08350075905729008 | validation: 0.15010560368299214]
	TIME [epoch: 21.8 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08097508279610274		[learning rate: 0.0012997]
	Learning Rate: 0.00129971
	LOSS [training: 0.08097508279610274 | validation: 0.16978657610339454]
	TIME [epoch: 21.8 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09264878439523043		[learning rate: 0.001294]
	Learning Rate: 0.00129397
	LOSS [training: 0.09264878439523043 | validation: 0.146944103051518]
	TIME [epoch: 21.7 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08635242660973372		[learning rate: 0.0012882]
	Learning Rate: 0.00128825
	LOSS [training: 0.08635242660973372 | validation: 0.13370580244143954]
	TIME [epoch: 21.7 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v1_20240624_133245/states/model_facs_dec2b_2dpca_v1_503.pth
	Model improved!!!
EPOCH 504/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08852337543690186		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.08852337543690186 | validation: 0.16429610218297006]
	TIME [epoch: 21.6 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08734333041063982		[learning rate: 0.0012769]
	Learning Rate: 0.00127689
	LOSS [training: 0.08734333041063982 | validation: 0.15823971049644497]
	TIME [epoch: 21.8 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09523927055787942		[learning rate: 0.0012712]
	Learning Rate: 0.00127125
	LOSS [training: 0.09523927055787942 | validation: 0.15834642953462247]
	TIME [epoch: 21.7 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08503464663696829		[learning rate: 0.0012656]
	Learning Rate: 0.00126563
	LOSS [training: 0.08503464663696829 | validation: 0.1566468325605851]
	TIME [epoch: 21.7 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09735370983010075		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.09735370983010075 | validation: 0.15332471217188026]
	TIME [epoch: 21.7 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09815245828710259		[learning rate: 0.0012545]
	Learning Rate: 0.00125447
	LOSS [training: 0.09815245828710259 | validation: 0.15080094355171583]
	TIME [epoch: 21.5 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08375476385827667		[learning rate: 0.0012489]
	Learning Rate: 0.00124893
	LOSS [training: 0.08375476385827667 | validation: 0.14560345899436936]
	TIME [epoch: 21.6 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09050240861440709		[learning rate: 0.0012434]
	Learning Rate: 0.00124341
	LOSS [training: 0.09050240861440709 | validation: 0.14783204102753983]
	TIME [epoch: 21.7 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09297316750225473		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.09297316750225473 | validation: 0.1488187285412247]
	TIME [epoch: 21.7 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08728313353269004		[learning rate: 0.0012324]
	Learning Rate: 0.00123245
	LOSS [training: 0.08728313353269004 | validation: 0.15902362523302271]
	TIME [epoch: 21.6 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0876100753811726		[learning rate: 0.001227]
	Learning Rate: 0.001227
	LOSS [training: 0.0876100753811726 | validation: 0.15379871045006746]
	TIME [epoch: 21.7 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08918734923156743		[learning rate: 0.0012216]
	Learning Rate: 0.00122158
	LOSS [training: 0.08918734923156743 | validation: 0.14903588373317228]
	TIME [epoch: 21.7 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08739669622941529		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.08739669622941529 | validation: 0.15796878795445207]
	TIME [epoch: 21.6 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0895873858515937		[learning rate: 0.0012108]
	Learning Rate: 0.00121081
	LOSS [training: 0.0895873858515937 | validation: 0.16188505800578973]
	TIME [epoch: 21.7 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08906894953120532		[learning rate: 0.0012055]
	Learning Rate: 0.00120546
	LOSS [training: 0.08906894953120532 | validation: 0.1523495980161857]
	TIME [epoch: 21.7 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08488012238334416		[learning rate: 0.0012001]
	Learning Rate: 0.00120014
	LOSS [training: 0.08488012238334416 | validation: 0.1485622280399452]
	TIME [epoch: 21.7 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08867005923249648		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.08867005923249648 | validation: 0.16007689606097822]
	TIME [epoch: 21.7 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08747141195235583		[learning rate: 0.0011896]
	Learning Rate: 0.00118956
	LOSS [training: 0.08747141195235583 | validation: 0.15871624418435357]
	TIME [epoch: 21.7 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08824472268346732		[learning rate: 0.0011843]
	Learning Rate: 0.0011843
	LOSS [training: 0.08824472268346732 | validation: 0.14758088266157163]
	TIME [epoch: 21.7 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08913406518072724		[learning rate: 0.0011791]
	Learning Rate: 0.00117907
	LOSS [training: 0.08913406518072724 | validation: 0.13792305964242868]
	TIME [epoch: 21.7 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08865148090340116		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.08865148090340116 | validation: 0.14882282584112622]
	TIME [epoch: 21.7 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09794860910469566		[learning rate: 0.0011687]
	Learning Rate: 0.00116867
	LOSS [training: 0.09794860910469566 | validation: 0.1595024414640685]
	TIME [epoch: 21.7 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09713856134637222		[learning rate: 0.0011635]
	Learning Rate: 0.00116351
	LOSS [training: 0.09713856134637222 | validation: 0.14028186736723694]
	TIME [epoch: 21.7 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09414905305418605		[learning rate: 0.0011584]
	Learning Rate: 0.00115837
	LOSS [training: 0.09414905305418605 | validation: 0.1522111250393206]
	TIME [epoch: 21.8 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08689750639171798		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.08689750639171798 | validation: 0.1454104852491253]
	TIME [epoch: 21.8 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08954620958902974		[learning rate: 0.0011482]
	Learning Rate: 0.00114815
	LOSS [training: 0.08954620958902974 | validation: 0.15873543908168997]
	TIME [epoch: 21.7 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08668572586793061		[learning rate: 0.0011431]
	Learning Rate: 0.00114308
	LOSS [training: 0.08668572586793061 | validation: 0.15124398686006524]
	TIME [epoch: 21.7 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08579967859886849		[learning rate: 0.001138]
	Learning Rate: 0.00113803
	LOSS [training: 0.08579967859886849 | validation: 0.14009020811709175]
	TIME [epoch: 21.6 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09322425132376447		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.09322425132376447 | validation: 0.14417334243154997]
	TIME [epoch: 21.6 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0867832683846784		[learning rate: 0.001128]
	Learning Rate: 0.001128
	LOSS [training: 0.0867832683846784 | validation: 0.15220043088557025]
	TIME [epoch: 21.6 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08771363925925875		[learning rate: 0.001123]
	Learning Rate: 0.00112301
	LOSS [training: 0.08771363925925875 | validation: 0.1595501155675957]
	TIME [epoch: 21.7 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08418652196247807		[learning rate: 0.0011181]
	Learning Rate: 0.00111805
	LOSS [training: 0.08418652196247807 | validation: 0.15011481063792204]
	TIME [epoch: 21.8 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08733708177185456		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.08733708177185456 | validation: 0.14946916143269925]
	TIME [epoch: 21.7 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08925802907217872		[learning rate: 0.0011082]
	Learning Rate: 0.00110819
	LOSS [training: 0.08925802907217872 | validation: 0.14480177777020983]
	TIME [epoch: 21.7 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09053975281641866		[learning rate: 0.0011033]
	Learning Rate: 0.0011033
	LOSS [training: 0.09053975281641866 | validation: 0.15353920794655912]
	TIME [epoch: 21.7 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09366229099105657		[learning rate: 0.0010984]
	Learning Rate: 0.00109842
	LOSS [training: 0.09366229099105657 | validation: 0.15882370568505044]
	TIME [epoch: 21.5 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08779823760414332		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.08779823760414332 | validation: 0.152194642996371]
	TIME [epoch: 21.6 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08661683883008313		[learning rate: 0.0010887]
	Learning Rate: 0.00108874
	LOSS [training: 0.08661683883008313 | validation: 0.14963627500378465]
	TIME [epoch: 21.7 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08535502033316877		[learning rate: 0.0010839]
	Learning Rate: 0.00108393
	LOSS [training: 0.08535502033316877 | validation: 0.14615626282369376]
	TIME [epoch: 21.7 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08458974415563672		[learning rate: 0.0010791]
	Learning Rate: 0.00107914
	LOSS [training: 0.08458974415563672 | validation: 0.1393299461646786]
	TIME [epoch: 21.7 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08849347623538531		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.08849347623538531 | validation: 0.15408953208128057]
	TIME [epoch: 21.7 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09326670662033068		[learning rate: 0.0010696]
	Learning Rate: 0.00106962
	LOSS [training: 0.09326670662033068 | validation: 0.15011402294117068]
	TIME [epoch: 21.7 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08676576256936588		[learning rate: 0.0010649]
	Learning Rate: 0.0010649
	LOSS [training: 0.08676576256936588 | validation: 0.151638920751473]
	TIME [epoch: 21.7 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0919025049067165		[learning rate: 0.0010602]
	Learning Rate: 0.00106019
	LOSS [training: 0.0919025049067165 | validation: 0.14735027761750596]
	TIME [epoch: 21.7 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08786040085523274		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.08786040085523274 | validation: 0.15346976813590138]
	TIME [epoch: 21.6 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08638159175175786		[learning rate: 0.0010508]
	Learning Rate: 0.00105084
	LOSS [training: 0.08638159175175786 | validation: 0.1465645386652827]
	TIME [epoch: 21.7 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08839669083804988		[learning rate: 0.0010462]
	Learning Rate: 0.0010462
	LOSS [training: 0.08839669083804988 | validation: 0.1521190378285016]
	TIME [epoch: 21.7 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08508772200441732		[learning rate: 0.0010416]
	Learning Rate: 0.00104158
	LOSS [training: 0.08508772200441732 | validation: 0.1533049458051251]
	TIME [epoch: 21.6 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08573324321877783		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.08573324321877783 | validation: 0.16656365094090947]
	TIME [epoch: 21.7 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08832989313412157		[learning rate: 0.0010324]
	Learning Rate: 0.0010324
	LOSS [training: 0.08832989313412157 | validation: 0.1571772150009136]
	TIME [epoch: 21.7 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0891466621641024		[learning rate: 0.0010278]
	Learning Rate: 0.00102783
	LOSS [training: 0.0891466621641024 | validation: 0.1544766051082726]
	TIME [epoch: 21.7 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08662921238118695		[learning rate: 0.0010233]
	Learning Rate: 0.00102329
	LOSS [training: 0.08662921238118695 | validation: 0.14993978681203285]
	TIME [epoch: 21.7 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0962545982964343		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.0962545982964343 | validation: 0.15899967821450878]
	TIME [epoch: 21.7 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08822547008648854		[learning rate: 0.0010143]
	Learning Rate: 0.00101427
	LOSS [training: 0.08822547008648854 | validation: 0.14661610539988304]
	TIME [epoch: 21.7 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09444736757966206		[learning rate: 0.0010098]
	Learning Rate: 0.00100979
	LOSS [training: 0.09444736757966206 | validation: 0.1486106228196142]
	TIME [epoch: 21.7 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09379262612051806		[learning rate: 0.0010053]
	Learning Rate: 0.00100533
	LOSS [training: 0.09379262612051806 | validation: 0.15758961587567746]
	TIME [epoch: 21.8 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08680489859737658		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.08680489859737658 | validation: 0.152990039627336]
	TIME [epoch: 21.8 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0885266750518802		[learning rate: 0.00099646]
	Learning Rate: 0.000996464
	LOSS [training: 0.0885266750518802 | validation: 0.1406090513278275]
	TIME [epoch: 21.7 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0838837605828693		[learning rate: 0.00099206]
	Learning Rate: 0.000992061
	LOSS [training: 0.0838837605828693 | validation: 0.14689594875709183]
	TIME [epoch: 21.8 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09093380531868364		[learning rate: 0.00098768]
	Learning Rate: 0.000987678
	LOSS [training: 0.09093380531868364 | validation: 0.14592735290801517]
	TIME [epoch: 21.7 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08694918646031516		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.08694918646031516 | validation: 0.155552240190877]
	TIME [epoch: 21.6 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.092012217606655		[learning rate: 0.00097897]
	Learning Rate: 0.00097897
	LOSS [training: 0.092012217606655 | validation: 0.151175384841618]
	TIME [epoch: 21.6 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.089228413284396		[learning rate: 0.00097464]
	Learning Rate: 0.000974644
	LOSS [training: 0.089228413284396 | validation: 0.15891061517074426]
	TIME [epoch: 21.8 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08720437414307902		[learning rate: 0.00097034]
	Learning Rate: 0.000970338
	LOSS [training: 0.08720437414307902 | validation: 0.14229877464244614]
	TIME [epoch: 21.7 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08049951804561006		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.08049951804561006 | validation: 0.14953643701332867]
	TIME [epoch: 21.7 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07824804773586017		[learning rate: 0.00096178]
	Learning Rate: 0.000961783
	LOSS [training: 0.07824804773586017 | validation: 0.14905932131795183]
	TIME [epoch: 21.7 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08969944284382518		[learning rate: 0.00095753]
	Learning Rate: 0.000957533
	LOSS [training: 0.08969944284382518 | validation: 0.1469181285159318]
	TIME [epoch: 21.6 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09269456193914612		[learning rate: 0.0009533]
	Learning Rate: 0.000953303
	LOSS [training: 0.09269456193914612 | validation: 0.16600102935726796]
	TIME [epoch: 21.4 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08973190136077158		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.08973190136077158 | validation: 0.14734832015067498]
	TIME [epoch: 21.7 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08628996744930119		[learning rate: 0.0009449]
	Learning Rate: 0.000944897
	LOSS [training: 0.08628996744930119 | validation: 0.15003125569221729]
	TIME [epoch: 21.6 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09268846104770784		[learning rate: 0.00094072]
	Learning Rate: 0.000940723
	LOSS [training: 0.09268846104770784 | validation: 0.15680569485378149]
	TIME [epoch: 21.7 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08260755127134664		[learning rate: 0.00093657]
	Learning Rate: 0.000936566
	LOSS [training: 0.08260755127134664 | validation: 0.15174632443157726]
	TIME [epoch: 21.7 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09386279366345193		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.09386279366345193 | validation: 0.15139393014361133]
	TIME [epoch: 21.7 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07994081169496417		[learning rate: 0.00092831]
	Learning Rate: 0.000928309
	LOSS [training: 0.07994081169496417 | validation: 0.1460765383096156]
	TIME [epoch: 21.6 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08990425365995758		[learning rate: 0.00092421]
	Learning Rate: 0.000924207
	LOSS [training: 0.08990425365995758 | validation: 0.15571845790812952]
	TIME [epoch: 21.7 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09249150136209112		[learning rate: 0.00092012]
	Learning Rate: 0.000920124
	LOSS [training: 0.09249150136209112 | validation: 0.15934563163646767]
	TIME [epoch: 21.7 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07937072845575566		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.07937072845575566 | validation: 0.13896454275973613]
	TIME [epoch: 21.7 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08776273234665578		[learning rate: 0.00091201]
	Learning Rate: 0.000912011
	LOSS [training: 0.08776273234665578 | validation: 0.1550699250285441]
	TIME [epoch: 21.7 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07857319852746245		[learning rate: 0.00090798]
	Learning Rate: 0.000907981
	LOSS [training: 0.07857319852746245 | validation: 0.1450365083792491]
	TIME [epoch: 21.7 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08737949993646599		[learning rate: 0.00090397]
	Learning Rate: 0.00090397
	LOSS [training: 0.08737949993646599 | validation: 0.15159962101204205]
	TIME [epoch: 21.7 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09294200422176868		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.09294200422176868 | validation: 0.16167005831964396]
	TIME [epoch: 21.7 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08723419349119016		[learning rate: 0.000896]
	Learning Rate: 0.000895999
	LOSS [training: 0.08723419349119016 | validation: 0.15037665629128724]
	TIME [epoch: 21.7 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08793900995971174		[learning rate: 0.00089204]
	Learning Rate: 0.000892041
	LOSS [training: 0.08793900995971174 | validation: 0.16279392976484758]
	TIME [epoch: 21.7 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08733614984363776		[learning rate: 0.0008881]
	Learning Rate: 0.000888099
	LOSS [training: 0.08733614984363776 | validation: 0.15081583882560834]
	TIME [epoch: 21.7 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08590142685461456		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.08590142685461456 | validation: 0.15148606798485797]
	TIME [epoch: 21.7 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0912023367796757		[learning rate: 0.00088027]
	Learning Rate: 0.000880269
	LOSS [training: 0.0912023367796757 | validation: 0.15822496522777915]
	TIME [epoch: 21.8 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08441780117265997		[learning rate: 0.00087638]
	Learning Rate: 0.00087638
	LOSS [training: 0.08441780117265997 | validation: 0.15677912381273212]
	TIME [epoch: 21.9 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08972397257113685		[learning rate: 0.00087251]
	Learning Rate: 0.000872508
	LOSS [training: 0.08972397257113685 | validation: 0.13579624942820845]
	TIME [epoch: 21.8 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08805782806003255		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.08805782806003255 | validation: 0.1352245263298203]
	TIME [epoch: 21.7 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09181542378687166		[learning rate: 0.00086481]
	Learning Rate: 0.000864815
	LOSS [training: 0.09181542378687166 | validation: 0.14626274609701]
	TIME [epoch: 21.7 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08201647159275123		[learning rate: 0.00086099]
	Learning Rate: 0.000860994
	LOSS [training: 0.08201647159275123 | validation: 0.14839802013341113]
	TIME [epoch: 21.7 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08418046682563193		[learning rate: 0.00085719]
	Learning Rate: 0.00085719
	LOSS [training: 0.08418046682563193 | validation: 0.16447097011341757]
	TIME [epoch: 21.5 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09384057306317353		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.09384057306317353 | validation: 0.14693105178023078]
	TIME [epoch: 21.6 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08363675811145319		[learning rate: 0.00084963]
	Learning Rate: 0.000849632
	LOSS [training: 0.08363675811145319 | validation: 0.15047706217951962]
	TIME [epoch: 21.7 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08436157749722406		[learning rate: 0.00084588]
	Learning Rate: 0.000845878
	LOSS [training: 0.08436157749722406 | validation: 0.15385402237266452]
	TIME [epoch: 21.7 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07885773587172698		[learning rate: 0.00084214]
	Learning Rate: 0.000842141
	LOSS [training: 0.07885773587172698 | validation: 0.1494532230081317]
	TIME [epoch: 21.8 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08889915392351144		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.08889915392351144 | validation: 0.16606729157221187]
	TIME [epoch: 21.8 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08230202890047585		[learning rate: 0.00083472]
	Learning Rate: 0.000834715
	LOSS [training: 0.08230202890047585 | validation: 0.15797901347202822]
	TIME [epoch: 21.6 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08313206338756172		[learning rate: 0.00083103]
	Learning Rate: 0.000831028
	LOSS [training: 0.08313206338756172 | validation: 0.1547807364475743]
	TIME [epoch: 21.6 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09001029098288538		[learning rate: 0.00082736]
	Learning Rate: 0.000827356
	LOSS [training: 0.09001029098288538 | validation: 0.15886712385381166]
	TIME [epoch: 21.7 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0885031304657945		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.0885031304657945 | validation: 0.1512140030620797]
	TIME [epoch: 21.6 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08143667337263112		[learning rate: 0.00082006]
	Learning Rate: 0.000820061
	LOSS [training: 0.08143667337263112 | validation: 0.15465485386605596]
	TIME [epoch: 21.6 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09622601240903557		[learning rate: 0.00081644]
	Learning Rate: 0.000816438
	LOSS [training: 0.09622601240903557 | validation: 0.14606430463470882]
	TIME [epoch: 21.7 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08989952172076027		[learning rate: 0.00081283]
	Learning Rate: 0.000812831
	LOSS [training: 0.08989952172076027 | validation: 0.14319397647689838]
	TIME [epoch: 21.6 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08479673457348655		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.08479673457348655 | validation: 0.1409633590129686]
	TIME [epoch: 21.7 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07944296635963127		[learning rate: 0.00080566]
	Learning Rate: 0.000805664
	LOSS [training: 0.07944296635963127 | validation: 0.14355943458898995]
	TIME [epoch: 21.7 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09390253023075483		[learning rate: 0.0008021]
	Learning Rate: 0.000802104
	LOSS [training: 0.09390253023075483 | validation: 0.14376857705772517]
	TIME [epoch: 21.7 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08214428628397133		[learning rate: 0.00079856]
	Learning Rate: 0.00079856
	LOSS [training: 0.08214428628397133 | validation: 0.14721006252021762]
	TIME [epoch: 21.7 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09108353213038194		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.09108353213038194 | validation: 0.1561501534454914]
	TIME [epoch: 21.7 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08991012186840977		[learning rate: 0.00079152]
	Learning Rate: 0.000791519
	LOSS [training: 0.08991012186840977 | validation: 0.14332795824565642]
	TIME [epoch: 21.7 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08154991144419346		[learning rate: 0.00078802]
	Learning Rate: 0.000788022
	LOSS [training: 0.08154991144419346 | validation: 0.14354579936991557]
	TIME [epoch: 21.7 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08725224787979319		[learning rate: 0.00078454]
	Learning Rate: 0.000784541
	LOSS [training: 0.08725224787979319 | validation: 0.1556271035054245]
	TIME [epoch: 21.7 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08491291890776305		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.08491291890776305 | validation: 0.15510898101190876]
	TIME [epoch: 21.7 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08931097854992637		[learning rate: 0.00077762]
	Learning Rate: 0.000777623
	LOSS [training: 0.08931097854992637 | validation: 0.15057839250641436]
	TIME [epoch: 21.7 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09629038654713284		[learning rate: 0.00077419]
	Learning Rate: 0.000774188
	LOSS [training: 0.09629038654713284 | validation: 0.1498124948118486]
	TIME [epoch: 21.7 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09001722810970661		[learning rate: 0.00077077]
	Learning Rate: 0.000770767
	LOSS [training: 0.09001722810970661 | validation: 0.1520286213764064]
	TIME [epoch: 21.7 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09181701863313327		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.09181701863313327 | validation: 0.1510704052517974]
	TIME [epoch: 21.8 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08608118476481888		[learning rate: 0.00076397]
	Learning Rate: 0.000763971
	LOSS [training: 0.08608118476481888 | validation: 0.14633257990055829]
	TIME [epoch: 21.7 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08901248408175677		[learning rate: 0.0007606]
	Learning Rate: 0.000760596
	LOSS [training: 0.08901248408175677 | validation: 0.15246275875071483]
	TIME [epoch: 21.8 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09368347704024033		[learning rate: 0.00075724]
	Learning Rate: 0.000757235
	LOSS [training: 0.09368347704024033 | validation: 0.1546700439729028]
	TIME [epoch: 21.8 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08124784907389798		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.08124784907389798 | validation: 0.1584805450182978]
	TIME [epoch: 21.6 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.092291036810264		[learning rate: 0.00075056]
	Learning Rate: 0.000750559
	LOSS [training: 0.092291036810264 | validation: 0.15075399805881493]
	TIME [epoch: 21.7 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08640829227847753		[learning rate: 0.00074724]
	Learning Rate: 0.000747242
	LOSS [training: 0.08640829227847753 | validation: 0.16195025176467762]
	TIME [epoch: 21.6 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08577478554182867		[learning rate: 0.00074394]
	Learning Rate: 0.000743941
	LOSS [training: 0.08577478554182867 | validation: 0.1455932807349457]
	TIME [epoch: 21.7 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09114829578938523		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.09114829578938523 | validation: 0.15751835306867937]
	TIME [epoch: 21.7 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09398745930476164		[learning rate: 0.00073738]
	Learning Rate: 0.000737382
	LOSS [training: 0.09398745930476164 | validation: 0.1498627465027025]
	TIME [epoch: 21.7 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08080026480417066		[learning rate: 0.00073412]
	Learning Rate: 0.000734124
	LOSS [training: 0.08080026480417066 | validation: 0.14479586643261305]
	TIME [epoch: 21.7 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0893255995859489		[learning rate: 0.00073088]
	Learning Rate: 0.00073088
	LOSS [training: 0.0893255995859489 | validation: 0.14844685692535453]
	TIME [epoch: 21.7 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09483349846431052		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 0.09483349846431052 | validation: 0.14166526086705655]
	TIME [epoch: 21.8 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0892145005029889		[learning rate: 0.00072444]
	Learning Rate: 0.000724436
	LOSS [training: 0.0892145005029889 | validation: 0.15842919093363403]
	TIME [epoch: 21.6 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08779312051232718		[learning rate: 0.00072124]
	Learning Rate: 0.000721235
	LOSS [training: 0.08779312051232718 | validation: 0.1449423815212266]
	TIME [epoch: 21.6 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08894544489030565		[learning rate: 0.00071805]
	Learning Rate: 0.000718049
	LOSS [training: 0.08894544489030565 | validation: 0.1440596177001576]
	TIME [epoch: 21.7 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08380023820749541		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.08380023820749541 | validation: 0.14009540044847912]
	TIME [epoch: 21.6 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08399029846389602		[learning rate: 0.00071172]
	Learning Rate: 0.000711718
	LOSS [training: 0.08399029846389602 | validation: 0.14366929934966105]
	TIME [epoch: 21.6 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08999800847142049		[learning rate: 0.00070857]
	Learning Rate: 0.000708573
	LOSS [training: 0.08999800847142049 | validation: 0.1401538597706081]
	TIME [epoch: 21.6 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09171154213088159		[learning rate: 0.00070544]
	Learning Rate: 0.000705442
	LOSS [training: 0.09171154213088159 | validation: 0.15813097840007814]
	TIME [epoch: 21.6 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0860048875836418		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.0860048875836418 | validation: 0.15121395490099238]
	TIME [epoch: 21.6 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09064022670160846		[learning rate: 0.00069922]
	Learning Rate: 0.000699222
	LOSS [training: 0.09064022670160846 | validation: 0.14666683260891605]
	TIME [epoch: 21.7 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07310885673394893		[learning rate: 0.00069613]
	Learning Rate: 0.000696133
	LOSS [training: 0.07310885673394893 | validation: 0.14848403993916573]
	TIME [epoch: 21.6 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08514898340989707		[learning rate: 0.00069306]
	Learning Rate: 0.000693058
	LOSS [training: 0.08514898340989707 | validation: 0.1454786863142558]
	TIME [epoch: 21.6 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08738280152247926		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 0.08738280152247926 | validation: 0.14333810182760243]
	TIME [epoch: 21.6 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08681132404678905		[learning rate: 0.00068695]
	Learning Rate: 0.000686947
	LOSS [training: 0.08681132404678905 | validation: 0.14465790007773752]
	TIME [epoch: 21.6 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08569468515535386		[learning rate: 0.00068391]
	Learning Rate: 0.000683912
	LOSS [training: 0.08569468515535386 | validation: 0.1460882385263665]
	TIME [epoch: 21.7 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08294083290404422		[learning rate: 0.00068089]
	Learning Rate: 0.00068089
	LOSS [training: 0.08294083290404422 | validation: 0.14321259160264363]
	TIME [epoch: 21.7 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08258937522932		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 0.08258937522932 | validation: 0.14295980004548234]
	TIME [epoch: 21.7 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08501413235097162		[learning rate: 0.00067489]
	Learning Rate: 0.000674887
	LOSS [training: 0.08501413235097162 | validation: 0.1518495471014251]
	TIME [epoch: 21.7 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08418900771169846		[learning rate: 0.0006719]
	Learning Rate: 0.000671905
	LOSS [training: 0.08418900771169846 | validation: 0.15092451166425058]
	TIME [epoch: 21.7 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08915600449677644		[learning rate: 0.00066894]
	Learning Rate: 0.000668936
	LOSS [training: 0.08915600449677644 | validation: 0.1455383446682694]
	TIME [epoch: 21.7 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07978882214080782		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 0.07978882214080782 | validation: 0.14777991823437622]
	TIME [epoch: 21.8 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09313834818376461		[learning rate: 0.00066304]
	Learning Rate: 0.000663038
	LOSS [training: 0.09313834818376461 | validation: 0.14951834942442999]
	TIME [epoch: 21.7 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09153517253332025		[learning rate: 0.00066011]
	Learning Rate: 0.000660109
	LOSS [training: 0.09153517253332025 | validation: 0.1534550637210113]
	TIME [epoch: 21.7 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08320427502822723		[learning rate: 0.00065719]
	Learning Rate: 0.000657192
	LOSS [training: 0.08320427502822723 | validation: 0.15825365682385462]
	TIME [epoch: 21.7 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09009613644081091		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 0.09009613644081091 | validation: 0.15496572377093581]
	TIME [epoch: 21.7 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08271872815165601		[learning rate: 0.0006514]
	Learning Rate: 0.000651398
	LOSS [training: 0.08271872815165601 | validation: 0.1501085556933744]
	TIME [epoch: 21.6 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08622062147012062		[learning rate: 0.00064852]
	Learning Rate: 0.00064852
	LOSS [training: 0.08622062147012062 | validation: 0.14168383270553905]
	TIME [epoch: 21.6 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08455071850542277		[learning rate: 0.00064565]
	Learning Rate: 0.000645654
	LOSS [training: 0.08455071850542277 | validation: 0.1448422019969192]
	TIME [epoch: 21.7 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08529652300801041		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 0.08529652300801041 | validation: 0.14165672679596758]
	TIME [epoch: 21.7 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08753712995494714		[learning rate: 0.00063996]
	Learning Rate: 0.000639962
	LOSS [training: 0.08753712995494714 | validation: 0.1508871479160982]
	TIME [epoch: 21.8 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07647928967128045		[learning rate: 0.00063713]
	Learning Rate: 0.000637134
	LOSS [training: 0.07647928967128045 | validation: 0.14689835903728918]
	TIME [epoch: 21.7 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09018380899538442		[learning rate: 0.00063432]
	Learning Rate: 0.000634319
	LOSS [training: 0.09018380899538442 | validation: 0.15400450203847182]
	TIME [epoch: 21.7 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08292117582662978		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 0.08292117582662978 | validation: 0.15385541796580948]
	TIME [epoch: 21.6 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08939832669259964		[learning rate: 0.00062873]
	Learning Rate: 0.000628726
	LOSS [training: 0.08939832669259964 | validation: 0.15773108481067116]
	TIME [epoch: 21.4 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0828671118501599		[learning rate: 0.00062595]
	Learning Rate: 0.000625948
	LOSS [training: 0.0828671118501599 | validation: 0.14739888170865673]
	TIME [epoch: 21.6 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08471756957149233		[learning rate: 0.00062318]
	Learning Rate: 0.000623183
	LOSS [training: 0.08471756957149233 | validation: 0.15492098298499865]
	TIME [epoch: 21.7 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08553108707799766		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 0.08553108707799766 | validation: 0.16394024992137374]
	TIME [epoch: 21.7 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07785686560275311		[learning rate: 0.00061769]
	Learning Rate: 0.000617688
	LOSS [training: 0.07785686560275311 | validation: 0.16017482554608373]
	TIME [epoch: 21.7 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09504173813062823		[learning rate: 0.00061496]
	Learning Rate: 0.000614959
	LOSS [training: 0.09504173813062823 | validation: 0.14545889603309772]
	TIME [epoch: 21.7 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.082142377718911		[learning rate: 0.00061224]
	Learning Rate: 0.000612242
	LOSS [training: 0.082142377718911 | validation: 0.15011088633079]
	TIME [epoch: 21.6 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08472833061520962		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 0.08472833061520962 | validation: 0.15835167932927652]
	TIME [epoch: 21.7 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08963962591438872		[learning rate: 0.00060684]
	Learning Rate: 0.000606844
	LOSS [training: 0.08963962591438872 | validation: 0.15103668227206674]
	TIME [epoch: 21.7 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10053047701513458		[learning rate: 0.00060416]
	Learning Rate: 0.000604163
	LOSS [training: 0.10053047701513458 | validation: 0.14816258333628798]
	TIME [epoch: 21.6 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08859222116745459		[learning rate: 0.00060149]
	Learning Rate: 0.000601493
	LOSS [training: 0.08859222116745459 | validation: 0.1555669043150564]
	TIME [epoch: 21.7 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08041102665639346		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.08041102665639346 | validation: 0.14027170477598666]
	TIME [epoch: 21.6 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0913687454551795		[learning rate: 0.00059619]
	Learning Rate: 0.00059619
	LOSS [training: 0.0913687454551795 | validation: 0.14604994114597178]
	TIME [epoch: 21.7 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08926491774196703		[learning rate: 0.00059356]
	Learning Rate: 0.000593556
	LOSS [training: 0.08926491774196703 | validation: 0.14356039843325005]
	TIME [epoch: 21.7 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08795476387506455		[learning rate: 0.00059093]
	Learning Rate: 0.000590933
	LOSS [training: 0.08795476387506455 | validation: 0.1544039234073226]
	TIME [epoch: 21.7 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08664618452995299		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 0.08664618452995299 | validation: 0.14614649311240677]
	TIME [epoch: 21.7 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08374989373443407		[learning rate: 0.00058572]
	Learning Rate: 0.000585723
	LOSS [training: 0.08374989373443407 | validation: 0.1516844285907087]
	TIME [epoch: 21.7 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08930897809086444		[learning rate: 0.00058314]
	Learning Rate: 0.000583135
	LOSS [training: 0.08930897809086444 | validation: 0.1434687509218893]
	TIME [epoch: 21.8 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08232971066405068		[learning rate: 0.00058056]
	Learning Rate: 0.000580559
	LOSS [training: 0.08232971066405068 | validation: 0.14287456652187347]
	TIME [epoch: 21.7 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0862507763437097		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 0.0862507763437097 | validation: 0.1406681802368823]
	TIME [epoch: 21.7 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08431476141198112		[learning rate: 0.00057544]
	Learning Rate: 0.00057544
	LOSS [training: 0.08431476141198112 | validation: 0.14335704005402133]
	TIME [epoch: 21.7 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0875882822873915		[learning rate: 0.0005729]
	Learning Rate: 0.000572898
	LOSS [training: 0.0875882822873915 | validation: 0.1632429464418641]
	TIME [epoch: 21.6 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0865455808280822		[learning rate: 0.00057037]
	Learning Rate: 0.000570366
	LOSS [training: 0.0865455808280822 | validation: 0.14374571575176515]
	TIME [epoch: 21.6 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08889473717967035		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 0.08889473717967035 | validation: 0.14177729732953492]
	TIME [epoch: 21.5 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07825019760259014		[learning rate: 0.00056534]
	Learning Rate: 0.000565337
	LOSS [training: 0.07825019760259014 | validation: 0.15132231086377554]
	TIME [epoch: 21.6 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08292585171856967		[learning rate: 0.00056284]
	Learning Rate: 0.00056284
	LOSS [training: 0.08292585171856967 | validation: 0.1439878710922328]
	TIME [epoch: 21.7 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08619159831854475		[learning rate: 0.00056035]
	Learning Rate: 0.000560353
	LOSS [training: 0.08619159831854475 | validation: 0.14099392863997418]
	TIME [epoch: 21.7 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0851158560808336		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 0.0851158560808336 | validation: 0.144445850124716]
	TIME [epoch: 21.6 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.088039987042126		[learning rate: 0.00055541]
	Learning Rate: 0.000555412
	LOSS [training: 0.088039987042126 | validation: 0.14693602644001028]
	TIME [epoch: 21.6 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08882206009804092		[learning rate: 0.00055296]
	Learning Rate: 0.000552958
	LOSS [training: 0.08882206009804092 | validation: 0.14913722746601651]
	TIME [epoch: 21.6 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08474936655324657		[learning rate: 0.00055052]
	Learning Rate: 0.000550515
	LOSS [training: 0.08474936655324657 | validation: 0.1563680738481476]
	TIME [epoch: 21.7 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08428493813242102		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 0.08428493813242102 | validation: 0.1503023951530564]
	TIME [epoch: 21.7 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09241244691930205		[learning rate: 0.00054566]
	Learning Rate: 0.000545661
	LOSS [training: 0.09241244691930205 | validation: 0.14623085372742325]
	TIME [epoch: 21.5 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08457117322612887		[learning rate: 0.00054325]
	Learning Rate: 0.00054325
	LOSS [training: 0.08457117322612887 | validation: 0.1559188920049528]
	TIME [epoch: 21.7 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0855373189032789		[learning rate: 0.00054085]
	Learning Rate: 0.00054085
	LOSS [training: 0.0855373189032789 | validation: 0.16551934006630029]
	TIME [epoch: 21.6 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08728362993426073		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 0.08728362993426073 | validation: 0.14756912255864696]
	TIME [epoch: 21.7 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09072264895989943		[learning rate: 0.00053608]
	Learning Rate: 0.000536081
	LOSS [training: 0.09072264895989943 | validation: 0.14576501668496333]
	TIME [epoch: 21.7 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08638604519464887		[learning rate: 0.00053371]
	Learning Rate: 0.000533713
	LOSS [training: 0.08638604519464887 | validation: 0.15431973489435652]
	TIME [epoch: 21.8 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08319972152577737		[learning rate: 0.00053135]
	Learning Rate: 0.000531355
	LOSS [training: 0.08319972152577737 | validation: 0.1491545209595603]
	TIME [epoch: 21.6 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09864797232506589		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 0.09864797232506589 | validation: 0.15192064092673685]
	TIME [epoch: 21.7 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v1_20240624_133245/states/model_facs_dec2b_2dpca_v1_704.pth
Halted early. No improvement in validation loss for 200 epochs.
Finished training in 15348.846 seconds.
