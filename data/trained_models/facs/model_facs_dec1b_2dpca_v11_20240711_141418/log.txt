Args:
Namespace(name='model_facs_dec1b_2dpca_v11', outdir='out/model_training/model_facs_dec1b_2dpca_v11', training_data='data/training_data/facs/pca/dec1_fitonsubset/transition1_subset_epi_tr_ce_an_pc12/training', validation_data='data/training_data/facs/pca/dec1_fitonsubset/transition1_subset_epi_tr_ce_an_pc12/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=10, batch_size=50, patience=200, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, quadratic_a=1.0, quadratic_b=1.0, ndims=2, nparams=2, nsigs=2, ncells=400, ncells_sample=400, model_do_sample=False, dt=0.005, dt_schedule='stepped', dt_schedule_bounds=[500, 1000, 1500], dt_schedule_scales=[0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=True, sigma=0.8, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', kernel='multiscale', bw_range=[0.2, 0.5, 0.9, 1.1, 1.3, 1.5, 2.0], optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 267768544

Training model...

Saving initial model state to: out/model_training/model_facs_dec1b_2dpca_v11_20240711_141418/states/model_facs_dec1b_2dpca_v11_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.9353840003834346		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9353840003834346 | validation: 0.7797272830823083]
	TIME [epoch: 44.6 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v11_20240711_141418/states/model_facs_dec1b_2dpca_v11_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.8527890523107245		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8527890523107245 | validation: 0.7395557057398764]
	TIME [epoch: 9.78 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v11_20240711_141418/states/model_facs_dec1b_2dpca_v11_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7964638522008232		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7964638522008232 | validation: 0.6906666752538784]
	TIME [epoch: 9.78 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v11_20240711_141418/states/model_facs_dec1b_2dpca_v11_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7764734112741543		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7764734112741543 | validation: 0.630295074233979]
	TIME [epoch: 9.76 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v11_20240711_141418/states/model_facs_dec1b_2dpca_v11_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7121976317024118		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7121976317024118 | validation: 0.5970671047776069]
	TIME [epoch: 9.76 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v11_20240711_141418/states/model_facs_dec1b_2dpca_v11_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6565055465999013		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6565055465999013 | validation: 0.6032122090330493]
	TIME [epoch: 9.78 sec]
EPOCH 7/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7406207925180477		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7406207925180477 | validation: 0.6333304610383144]
	TIME [epoch: 9.76 sec]
EPOCH 8/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7064925309095941		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7064925309095941 | validation: 0.6155423925812874]
	TIME [epoch: 9.76 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6375563283983685		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6375563283983685 | validation: 0.6278642286330918]
	TIME [epoch: 9.76 sec]
EPOCH 10/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5481171259164341		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5481171259164341 | validation: 0.6800381154633307]
	TIME [epoch: 9.78 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5462289625870838		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5462289625870838 | validation: 0.4853596587077421]
	TIME [epoch: 9.76 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v11_20240711_141418/states/model_facs_dec1b_2dpca_v11_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5363437723163139		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5363437723163139 | validation: 0.471768546835497]
	TIME [epoch: 9.76 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v11_20240711_141418/states/model_facs_dec1b_2dpca_v11_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4669129170801859		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4669129170801859 | validation: 0.46845511204929335]
	TIME [epoch: 9.75 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v11_20240711_141418/states/model_facs_dec1b_2dpca_v11_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.49092710767267		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.49092710767267 | validation: 0.4576818779985442]
	TIME [epoch: 9.77 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v11_20240711_141418/states/model_facs_dec1b_2dpca_v11_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4456456023364673		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4456456023364673 | validation: 0.42820083625912686]
	TIME [epoch: 9.75 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v11_20240711_141418/states/model_facs_dec1b_2dpca_v11_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5103113033105067		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5103113033105067 | validation: 0.4464238375505628]
	TIME [epoch: 9.75 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.47711685785464986		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.47711685785464986 | validation: 0.48282776515411696]
	TIME [epoch: 9.77 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.47987907035431276		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.47987907035431276 | validation: 0.4665029186429094]
	TIME [epoch: 9.74 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4378588174420842		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4378588174420842 | validation: 0.4328476783984586]
	TIME [epoch: 9.75 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4680935410927678		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4680935410927678 | validation: 0.5049519256113414]
	TIME [epoch: 9.75 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5220716890908363		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5220716890908363 | validation: 0.43592820289949835]
	TIME [epoch: 9.76 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.44438754795799346		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.44438754795799346 | validation: 0.421808928446456]
	TIME [epoch: 9.75 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v11_20240711_141418/states/model_facs_dec1b_2dpca_v11_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4582437812967545		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4582437812967545 | validation: 0.590711436160035]
	TIME [epoch: 9.76 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.44796011971214966		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.44796011971214966 | validation: 0.4319843922350427]
	TIME [epoch: 9.76 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.43697686436325445		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.43697686436325445 | validation: 0.4302700510033108]
	TIME [epoch: 9.75 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4028817807147818		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4028817807147818 | validation: 0.48714410973163175]
	TIME [epoch: 9.76 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.42226955295427704		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.42226955295427704 | validation: 0.4526753338870506]
	TIME [epoch: 9.75 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4088328133148765		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4088328133148765 | validation: 0.41038524602068377]
	TIME [epoch: 9.77 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v11_20240711_141418/states/model_facs_dec1b_2dpca_v11_28.pth
	Model improved!!!
EPOCH 29/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4150061318034446		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4150061318034446 | validation: 0.45486929453345726]
	TIME [epoch: 9.77 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.44149594041860346		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.44149594041860346 | validation: 0.3993060723381624]
	TIME [epoch: 9.76 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v11_20240711_141418/states/model_facs_dec1b_2dpca_v11_30.pth
	Model improved!!!
EPOCH 31/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.41982649723476784		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.41982649723476784 | validation: 0.377668435229889]
	TIME [epoch: 9.76 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v11_20240711_141418/states/model_facs_dec1b_2dpca_v11_31.pth
	Model improved!!!
EPOCH 32/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3823612988185435		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3823612988185435 | validation: 0.3554756388538376]
	TIME [epoch: 9.76 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v11_20240711_141418/states/model_facs_dec1b_2dpca_v11_32.pth
	Model improved!!!
EPOCH 33/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3837077807032535		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3837077807032535 | validation: 0.3552761618830684]
	TIME [epoch: 9.76 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v11_20240711_141418/states/model_facs_dec1b_2dpca_v11_33.pth
	Model improved!!!
EPOCH 34/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4000246509800033		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4000246509800033 | validation: 0.4349801341105417]
	TIME [epoch: 9.76 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.41045156370408875		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.41045156370408875 | validation: 0.4593075832912973]
	TIME [epoch: 9.78 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.42444953494873805		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.42444953494873805 | validation: 0.45752144443772036]
	TIME [epoch: 9.76 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.44244192253450354		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.44244192253450354 | validation: 0.40545420017440537]
	TIME [epoch: 9.76 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3932069088138572		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3932069088138572 | validation: 0.3803459322738267]
	TIME [epoch: 9.77 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.37628563181331887		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.37628563181331887 | validation: 0.3704105991945732]
	TIME [epoch: 9.77 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3988472627219457		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3988472627219457 | validation: 0.43595295218225266]
	TIME [epoch: 9.76 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4368350899629063		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4368350899629063 | validation: 0.3611747148018002]
	TIME [epoch: 9.76 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3855401531957892		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3855401531957892 | validation: 0.3829745453763114]
	TIME [epoch: 9.78 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4669431210071218		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4669431210071218 | validation: 0.40684613592491575]
	TIME [epoch: 9.76 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.46441065590735253		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.46441065590735253 | validation: 0.403480878267305]
	TIME [epoch: 9.76 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4023792784951498		[learning rate: 0.0099823]
	Learning Rate: 0.0099823
	LOSS [training: 0.4023792784951498 | validation: 0.41374672627336845]
	TIME [epoch: 9.75 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4035327302064015		[learning rate: 0.0099426]
	Learning Rate: 0.0099426
	LOSS [training: 0.4035327302064015 | validation: 0.3579183154497378]
	TIME [epoch: 9.77 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4278865935585179		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 0.4278865935585179 | validation: 0.3343319063201845]
	TIME [epoch: 9.75 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v11_20240711_141418/states/model_facs_dec1b_2dpca_v11_47.pth
	Model improved!!!
EPOCH 48/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.394280597300425		[learning rate: 0.0098637]
	Learning Rate: 0.00986367
	LOSS [training: 0.394280597300425 | validation: 0.37752722755125756]
	TIME [epoch: 9.76 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4043054713266914		[learning rate: 0.0098244]
	Learning Rate: 0.00982444
	LOSS [training: 0.4043054713266914 | validation: 0.34102453760281115]
	TIME [epoch: 9.77 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3936926997226111		[learning rate: 0.0097854]
	Learning Rate: 0.00978536
	LOSS [training: 0.3936926997226111 | validation: 0.5401064829328811]
	TIME [epoch: 9.76 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.43739276397173665		[learning rate: 0.0097464]
	Learning Rate: 0.00974644
	LOSS [training: 0.43739276397173665 | validation: 0.35901819772785415]
	TIME [epoch: 9.76 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3962358306899141		[learning rate: 0.0097077]
	Learning Rate: 0.00970768
	LOSS [training: 0.3962358306899141 | validation: 0.3641759042878713]
	TIME [epoch: 9.75 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.40402175994852874		[learning rate: 0.0096691]
	Learning Rate: 0.00966907
	LOSS [training: 0.40402175994852874 | validation: 0.38202557528894554]
	TIME [epoch: 9.77 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4082213907232302		[learning rate: 0.0096306]
	Learning Rate: 0.00963061
	LOSS [training: 0.4082213907232302 | validation: 0.41097406377219325]
	TIME [epoch: 9.75 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.38246865977883326		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 0.38246865977883326 | validation: 0.34234962863862084]
	TIME [epoch: 9.75 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4037504824824954		[learning rate: 0.0095542]
	Learning Rate: 0.00955415
	LOSS [training: 0.4037504824824954 | validation: 0.4695912326438518]
	TIME [epoch: 9.76 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4047811525802729		[learning rate: 0.0095162]
	Learning Rate: 0.00951616
	LOSS [training: 0.4047811525802729 | validation: 0.43922333311713346]
	TIME [epoch: 9.77 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3829557041872445		[learning rate: 0.0094783]
	Learning Rate: 0.00947831
	LOSS [training: 0.3829557041872445 | validation: 0.4248763799873815]
	TIME [epoch: 9.75 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4005317471068078		[learning rate: 0.0094406]
	Learning Rate: 0.00944061
	LOSS [training: 0.4005317471068078 | validation: 0.3519704600840107]
	TIME [epoch: 9.76 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.38297823361794125		[learning rate: 0.0094031]
	Learning Rate: 0.00940306
	LOSS [training: 0.38297823361794125 | validation: 0.3974628039027203]
	TIME [epoch: 9.78 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.39502819540350176		[learning rate: 0.0093657]
	Learning Rate: 0.00936566
	LOSS [training: 0.39502819540350176 | validation: 0.34899133830649093]
	TIME [epoch: 9.76 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.39143329405132565		[learning rate: 0.0093284]
	Learning Rate: 0.00932841
	LOSS [training: 0.39143329405132565 | validation: 0.39777853554925696]
	TIME [epoch: 9.75 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.39658694899629765		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 0.39658694899629765 | validation: 0.38190926932583497]
	TIME [epoch: 9.75 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3983775582181238		[learning rate: 0.0092544]
	Learning Rate: 0.00925435
	LOSS [training: 0.3983775582181238 | validation: 0.4073784999892839]
	TIME [epoch: 9.76 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3786988082929003		[learning rate: 0.0092175]
	Learning Rate: 0.00921755
	LOSS [training: 0.3786988082929003 | validation: 0.33064092352510593]
	TIME [epoch: 9.75 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v11_20240711_141418/states/model_facs_dec1b_2dpca_v11_65.pth
	Model improved!!!
EPOCH 66/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3828295319092138		[learning rate: 0.0091809]
	Learning Rate: 0.00918089
	LOSS [training: 0.3828295319092138 | validation: 0.38178539258323124]
	TIME [epoch: 9.76 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5281815719905123		[learning rate: 0.0091444]
	Learning Rate: 0.00914437
	LOSS [training: 0.5281815719905123 | validation: 0.46639396482426526]
	TIME [epoch: 9.77 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4512145980316892		[learning rate: 0.009108]
	Learning Rate: 0.009108
	LOSS [training: 0.4512145980316892 | validation: 0.3397324720674904]
	TIME [epoch: 9.77 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3688458764820926		[learning rate: 0.0090718]
	Learning Rate: 0.00907178
	LOSS [training: 0.3688458764820926 | validation: 0.34813517907642405]
	TIME [epoch: 9.76 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3792006613107595		[learning rate: 0.0090357]
	Learning Rate: 0.00903569
	LOSS [training: 0.3792006613107595 | validation: 0.38527271877383773]
	TIME [epoch: 9.76 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4563741086869262		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 0.4563741086869262 | validation: 0.4255609981081478]
	TIME [epoch: 9.77 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5298751525186687		[learning rate: 0.008964]
	Learning Rate: 0.00896396
	LOSS [training: 0.5298751525186687 | validation: 0.40139865786690965]
	TIME [epoch: 9.76 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.44487945537554474		[learning rate: 0.0089283]
	Learning Rate: 0.00892831
	LOSS [training: 0.44487945537554474 | validation: 0.3594684224526151]
	TIME [epoch: 9.75 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.39934441191086556		[learning rate: 0.0088928]
	Learning Rate: 0.0088928
	LOSS [training: 0.39934441191086556 | validation: 0.3805443169333441]
	TIME [epoch: 9.76 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.42236181167726716		[learning rate: 0.0088574]
	Learning Rate: 0.00885743
	LOSS [training: 0.42236181167726716 | validation: 0.3738764627494656]
	TIME [epoch: 9.78 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.37797190106160894		[learning rate: 0.0088222]
	Learning Rate: 0.0088222
	LOSS [training: 0.37797190106160894 | validation: 0.37227260536770784]
	TIME [epoch: 9.75 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.41187869640454067		[learning rate: 0.0087871]
	Learning Rate: 0.00878711
	LOSS [training: 0.41187869640454067 | validation: 0.36691327947549]
	TIME [epoch: 9.75 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.38521863486708335		[learning rate: 0.0087522]
	Learning Rate: 0.00875216
	LOSS [training: 0.38521863486708335 | validation: 0.3754013999837337]
	TIME [epoch: 9.77 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3750505346740569		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 0.3750505346740569 | validation: 0.43252762241621123]
	TIME [epoch: 9.76 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.37993265960359934		[learning rate: 0.0086827]
	Learning Rate: 0.00868268
	LOSS [training: 0.37993265960359934 | validation: 0.3332382201193433]
	TIME [epoch: 9.76 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3525099633416871		[learning rate: 0.0086481]
	Learning Rate: 0.00864815
	LOSS [training: 0.3525099633416871 | validation: 0.34258000223780866]
	TIME [epoch: 9.76 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3746536533736923		[learning rate: 0.0086138]
	Learning Rate: 0.00861375
	LOSS [training: 0.3746536533736923 | validation: 0.3851489040071482]
	TIME [epoch: 9.78 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3700622876981889		[learning rate: 0.0085795]
	Learning Rate: 0.00857949
	LOSS [training: 0.3700622876981889 | validation: 0.3651808199725779]
	TIME [epoch: 9.76 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.37758634385817036		[learning rate: 0.0085454]
	Learning Rate: 0.00854537
	LOSS [training: 0.37758634385817036 | validation: 0.42157594797731657]
	TIME [epoch: 9.75 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3856742714142037		[learning rate: 0.0085114]
	Learning Rate: 0.00851138
	LOSS [training: 0.3856742714142037 | validation: 0.38249457773833734]
	TIME [epoch: 9.75 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.38499835859528775		[learning rate: 0.0084775]
	Learning Rate: 0.00847753
	LOSS [training: 0.38499835859528775 | validation: 0.3909056297173109]
	TIME [epoch: 9.77 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3719688656127902		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 0.3719688656127902 | validation: 0.33396255486752013]
	TIME [epoch: 9.76 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.36109586984332126		[learning rate: 0.0084102]
	Learning Rate: 0.00841023
	LOSS [training: 0.36109586984332126 | validation: 0.3923774545419009]
	TIME [epoch: 9.76 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3906536772972056		[learning rate: 0.0083768]
	Learning Rate: 0.00837678
	LOSS [training: 0.3906536772972056 | validation: 0.34428234804010066]
	TIME [epoch: 9.77 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3670824824388677		[learning rate: 0.0083435]
	Learning Rate: 0.00834346
	LOSS [training: 0.3670824824388677 | validation: 0.4436539004835236]
	TIME [epoch: 9.77 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.36351093851928984		[learning rate: 0.0083103]
	Learning Rate: 0.00831027
	LOSS [training: 0.36351093851928984 | validation: 0.3302751415893457]
	TIME [epoch: 9.76 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v11_20240711_141418/states/model_facs_dec1b_2dpca_v11_91.pth
	Model improved!!!
EPOCH 92/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.35527915121321546		[learning rate: 0.0082772]
	Learning Rate: 0.00827722
	LOSS [training: 0.35527915121321546 | validation: 0.3705827107862684]
	TIME [epoch: 9.75 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3476536074516825		[learning rate: 0.0082443]
	Learning Rate: 0.0082443
	LOSS [training: 0.3476536074516825 | validation: 0.3453131646957296]
	TIME [epoch: 9.77 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3814709769102683		[learning rate: 0.0082115]
	Learning Rate: 0.00821151
	LOSS [training: 0.3814709769102683 | validation: 0.3328275480620603]
	TIME [epoch: 9.75 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3324662950253705		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 0.3324662950253705 | validation: 0.296655804094538]
	TIME [epoch: 9.74 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v11_20240711_141418/states/model_facs_dec1b_2dpca_v11_95.pth
	Model improved!!!
EPOCH 96/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.34521839512357544		[learning rate: 0.0081463]
	Learning Rate: 0.00814632
	LOSS [training: 0.34521839512357544 | validation: 0.3622514310498473]
	TIME [epoch: 9.74 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3543660766485157		[learning rate: 0.0081139]
	Learning Rate: 0.00811392
	LOSS [training: 0.3543660766485157 | validation: 0.3594975900995011]
	TIME [epoch: 9.75 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.35961966556725944		[learning rate: 0.0080816]
	Learning Rate: 0.00808165
	LOSS [training: 0.35961966556725944 | validation: 0.37761209504950666]
	TIME [epoch: 9.73 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.39236119280856246		[learning rate: 0.0080495]
	Learning Rate: 0.00804951
	LOSS [training: 0.39236119280856246 | validation: 0.35679324227551745]
	TIME [epoch: 9.73 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.38298886545844124		[learning rate: 0.0080175]
	Learning Rate: 0.00801749
	LOSS [training: 0.38298886545844124 | validation: 0.41187026235482865]
	TIME [epoch: 9.76 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.35983839748923385		[learning rate: 0.0079856]
	Learning Rate: 0.0079856
	LOSS [training: 0.35983839748923385 | validation: 0.4362725379363274]
	TIME [epoch: 9.74 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3420965513060017		[learning rate: 0.0079538]
	Learning Rate: 0.00795384
	LOSS [training: 0.3420965513060017 | validation: 0.32530865537536685]
	TIME [epoch: 9.75 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.35722494568011326		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 0.35722494568011326 | validation: 0.3691043284063352]
	TIME [epoch: 9.74 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3333875534401666		[learning rate: 0.0078907]
	Learning Rate: 0.0078907
	LOSS [training: 0.3333875534401666 | validation: 0.3497415702292686]
	TIME [epoch: 9.76 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3244587935925061		[learning rate: 0.0078593]
	Learning Rate: 0.00785931
	LOSS [training: 0.3244587935925061 | validation: 0.32905584828182666]
	TIME [epoch: 9.75 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3234942324703082		[learning rate: 0.0078281]
	Learning Rate: 0.00782805
	LOSS [training: 0.3234942324703082 | validation: 0.3137953878917708]
	TIME [epoch: 9.74 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3416611589774565		[learning rate: 0.0077969]
	Learning Rate: 0.00779692
	LOSS [training: 0.3416611589774565 | validation: 0.34641433145111117]
	TIME [epoch: 9.75 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3533740783968041		[learning rate: 0.0077659]
	Learning Rate: 0.00776591
	LOSS [training: 0.3533740783968041 | validation: 0.2923458770719046]
	TIME [epoch: 9.75 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v11_20240711_141418/states/model_facs_dec1b_2dpca_v11_108.pth
	Model improved!!!
EPOCH 109/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.33875404734790326		[learning rate: 0.007735]
	Learning Rate: 0.00773502
	LOSS [training: 0.33875404734790326 | validation: 0.34988131070856887]
	TIME [epoch: 9.76 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3406101632449812		[learning rate: 0.0077043]
	Learning Rate: 0.00770426
	LOSS [training: 0.3406101632449812 | validation: 0.34688156281939253]
	TIME [epoch: 9.75 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3311888333998777		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 0.3311888333998777 | validation: 0.37424944646102176]
	TIME [epoch: 9.75 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.34502568965069313		[learning rate: 0.0076431]
	Learning Rate: 0.00764309
	LOSS [training: 0.34502568965069313 | validation: 0.3123358871877053]
	TIME [epoch: 9.74 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.986067614768787		[learning rate: 0.0076127]
	Learning Rate: 0.00761269
	LOSS [training: 0.986067614768787 | validation: 0.6345232329187656]
	TIME [epoch: 9.75 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5603292536883887		[learning rate: 0.0075824]
	Learning Rate: 0.00758242
	LOSS [training: 0.5603292536883887 | validation: 0.3839546276211552]
	TIME [epoch: 9.74 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4051073048885341		[learning rate: 0.0075523]
	Learning Rate: 0.00755226
	LOSS [training: 0.4051073048885341 | validation: 0.34652861040163085]
	TIME [epoch: 9.75 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3556885477862359		[learning rate: 0.0075222]
	Learning Rate: 0.00752222
	LOSS [training: 0.3556885477862359 | validation: 0.35544716579749946]
	TIME [epoch: 9.74 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.34977279312484405		[learning rate: 0.0074923]
	Learning Rate: 0.0074923
	LOSS [training: 0.34977279312484405 | validation: 0.3400615204388851]
	TIME [epoch: 9.74 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.33214641090641617		[learning rate: 0.0074625]
	Learning Rate: 0.0074625
	LOSS [training: 0.33214641090641617 | validation: 0.33984250120230863]
	TIME [epoch: 9.76 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.33663928885573047		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 0.33663928885573047 | validation: 0.34586226158068895]
	TIME [epoch: 9.76 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.33851291765203534		[learning rate: 0.0074033]
	Learning Rate: 0.00740326
	LOSS [training: 0.33851291765203534 | validation: 0.3676935845971562]
	TIME [epoch: 9.75 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32750217126817543		[learning rate: 0.0073738]
	Learning Rate: 0.00737382
	LOSS [training: 0.32750217126817543 | validation: 0.3078666175439039]
	TIME [epoch: 9.75 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3350259539426174		[learning rate: 0.0073445]
	Learning Rate: 0.00734449
	LOSS [training: 0.3350259539426174 | validation: 0.3275451749157153]
	TIME [epoch: 9.77 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.33504237709876145		[learning rate: 0.0073153]
	Learning Rate: 0.00731528
	LOSS [training: 0.33504237709876145 | validation: 0.3074882845175735]
	TIME [epoch: 9.75 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3458520280538322		[learning rate: 0.0072862]
	Learning Rate: 0.00728618
	LOSS [training: 0.3458520280538322 | validation: 0.3844216135255074]
	TIME [epoch: 9.75 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.35559132567111046		[learning rate: 0.0072572]
	Learning Rate: 0.0072572
	LOSS [training: 0.35559132567111046 | validation: 0.3179857098776696]
	TIME [epoch: 9.75 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3414221941641183		[learning rate: 0.0072283]
	Learning Rate: 0.00722834
	LOSS [training: 0.3414221941641183 | validation: 0.37534119837254676]
	TIME [epoch: 9.77 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3338266527715863		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 0.3338266527715863 | validation: 0.30662472542271874]
	TIME [epoch: 9.75 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.40337865894902647		[learning rate: 0.007171]
	Learning Rate: 0.00717095
	LOSS [training: 0.40337865894902647 | validation: 0.3239284201498937]
	TIME [epoch: 9.74 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32890877537048063		[learning rate: 0.0071424]
	Learning Rate: 0.00714243
	LOSS [training: 0.32890877537048063 | validation: 0.33218674115618085]
	TIME [epoch: 9.76 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3373038597237547		[learning rate: 0.007114]
	Learning Rate: 0.00711403
	LOSS [training: 0.3373038597237547 | validation: 0.3611637105556678]
	TIME [epoch: 9.76 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.36837488970250426		[learning rate: 0.0070857]
	Learning Rate: 0.00708573
	LOSS [training: 0.36837488970250426 | validation: 0.32254096645812824]
	TIME [epoch: 9.75 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.33750153768196145		[learning rate: 0.0070575]
	Learning Rate: 0.00705755
	LOSS [training: 0.33750153768196145 | validation: 0.3388455534748235]
	TIME [epoch: 9.75 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3263187240000581		[learning rate: 0.0070295]
	Learning Rate: 0.00702948
	LOSS [training: 0.3263187240000581 | validation: 0.3115796278492132]
	TIME [epoch: 9.76 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3327613779662321		[learning rate: 0.0070015]
	Learning Rate: 0.00700152
	LOSS [training: 0.3327613779662321 | validation: 0.4053915390283656]
	TIME [epoch: 9.74 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3700638391910265		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 0.3700638391910265 | validation: 0.3200775336121858]
	TIME [epoch: 9.75 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.35823740560088524		[learning rate: 0.0069459]
	Learning Rate: 0.00694594
	LOSS [training: 0.35823740560088524 | validation: 0.3634561293704711]
	TIME [epoch: 9.75 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3298746124746683		[learning rate: 0.0069183]
	Learning Rate: 0.00691831
	LOSS [training: 0.3298746124746683 | validation: 0.33039881092003115]
	TIME [epoch: 9.77 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3127894896452695		[learning rate: 0.0068908]
	Learning Rate: 0.00689079
	LOSS [training: 0.3127894896452695 | validation: 0.4066686292889775]
	TIME [epoch: 9.76 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.36807345974602323		[learning rate: 0.0068634]
	Learning Rate: 0.00686339
	LOSS [training: 0.36807345974602323 | validation: 0.33782750506552117]
	TIME [epoch: 9.75 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.340772150080818		[learning rate: 0.0068361]
	Learning Rate: 0.00683609
	LOSS [training: 0.340772150080818 | validation: 0.30999938505497376]
	TIME [epoch: 9.76 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3155533135418444		[learning rate: 0.0068089]
	Learning Rate: 0.0068089
	LOSS [training: 0.3155533135418444 | validation: 0.33833481220686]
	TIME [epoch: 9.76 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3333196268108848		[learning rate: 0.0067818]
	Learning Rate: 0.00678182
	LOSS [training: 0.3333196268108848 | validation: 0.3078547011438776]
	TIME [epoch: 9.75 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3594625676253815		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 0.3594625676253815 | validation: 0.3245366923403663]
	TIME [epoch: 9.75 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3111027269790801		[learning rate: 0.006728]
	Learning Rate: 0.00672798
	LOSS [training: 0.3111027269790801 | validation: 0.3125362061412497]
	TIME [epoch: 9.77 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3165985072788935		[learning rate: 0.0067012]
	Learning Rate: 0.00670122
	LOSS [training: 0.3165985072788935 | validation: 0.36932659879363045]
	TIME [epoch: 9.76 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3489220642485915		[learning rate: 0.0066746]
	Learning Rate: 0.00667457
	LOSS [training: 0.3489220642485915 | validation: 0.30517092789473044]
	TIME [epoch: 9.75 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.30269368039725614		[learning rate: 0.006648]
	Learning Rate: 0.00664802
	LOSS [training: 0.30269368039725614 | validation: 0.30554898161861577]
	TIME [epoch: 9.74 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3105848393055547		[learning rate: 0.0066216]
	Learning Rate: 0.00662158
	LOSS [training: 0.3105848393055547 | validation: 0.33608954432144295]
	TIME [epoch: 9.76 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3470704893133833		[learning rate: 0.0065952]
	Learning Rate: 0.00659524
	LOSS [training: 0.3470704893133833 | validation: 0.32311463705751436]
	TIME [epoch: 9.74 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.30765565386892824		[learning rate: 0.006569]
	Learning Rate: 0.00656901
	LOSS [training: 0.30765565386892824 | validation: 0.29966972917604684]
	TIME [epoch: 9.75 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.30320462418505034		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 0.30320462418505034 | validation: 0.3279641456284943]
	TIME [epoch: 9.76 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32338626199452336		[learning rate: 0.0065169]
	Learning Rate: 0.00651686
	LOSS [training: 0.32338626199452336 | validation: 0.32282601448736564]
	TIME [epoch: 9.75 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.30415310665690976		[learning rate: 0.0064909]
	Learning Rate: 0.00649094
	LOSS [training: 0.30415310665690976 | validation: 0.29663137922793925]
	TIME [epoch: 9.75 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3208074637852472		[learning rate: 0.0064651]
	Learning Rate: 0.00646512
	LOSS [training: 0.3208074637852472 | validation: 0.32533518761050984]
	TIME [epoch: 9.75 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.324556731071589		[learning rate: 0.0064394]
	Learning Rate: 0.00643941
	LOSS [training: 0.324556731071589 | validation: 0.30185078779352104]
	TIME [epoch: 9.77 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3006473676442906		[learning rate: 0.0064138]
	Learning Rate: 0.0064138
	LOSS [training: 0.3006473676442906 | validation: 0.39265928163583136]
	TIME [epoch: 9.75 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32181205743696917		[learning rate: 0.0063883]
	Learning Rate: 0.00638829
	LOSS [training: 0.32181205743696917 | validation: 0.3164301176119629]
	TIME [epoch: 9.74 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.30958737669254904		[learning rate: 0.0063629]
	Learning Rate: 0.00636288
	LOSS [training: 0.30958737669254904 | validation: 0.33384468263359907]
	TIME [epoch: 9.75 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3115771934389391		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 0.3115771934389391 | validation: 0.2962536868143572]
	TIME [epoch: 9.76 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.29078485658138714		[learning rate: 0.0063124]
	Learning Rate: 0.00631237
	LOSS [training: 0.29078485658138714 | validation: 0.321719942101051]
	TIME [epoch: 9.74 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4734001025681618		[learning rate: 0.0062873]
	Learning Rate: 0.00628726
	LOSS [training: 0.4734001025681618 | validation: 0.47114570815185886]
	TIME [epoch: 9.74 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6165104104388457		[learning rate: 0.0062623]
	Learning Rate: 0.00626226
	LOSS [training: 0.6165104104388457 | validation: 0.4255622000317375]
	TIME [epoch: 9.78 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5283216788389872		[learning rate: 0.0062373]
	Learning Rate: 0.00623735
	LOSS [training: 0.5283216788389872 | validation: 0.38042771000325315]
	TIME [epoch: 9.75 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.46340853713761554		[learning rate: 0.0062125]
	Learning Rate: 0.00621254
	LOSS [training: 0.46340853713761554 | validation: 0.35930597700266925]
	TIME [epoch: 9.75 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.42328549925033365		[learning rate: 0.0061878]
	Learning Rate: 0.00618783
	LOSS [training: 0.42328549925033365 | validation: 0.33541662474919953]
	TIME [epoch: 9.74 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4158317649134091		[learning rate: 0.0061632]
	Learning Rate: 0.00616322
	LOSS [training: 0.4158317649134091 | validation: 0.38390080388062486]
	TIME [epoch: 9.77 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4060818072342624		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 0.4060818072342624 | validation: 0.3198060518888049]
	TIME [epoch: 9.74 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.36743758694938844		[learning rate: 0.0061143]
	Learning Rate: 0.00611429
	LOSS [training: 0.36743758694938844 | validation: 0.3131908524127125]
	TIME [epoch: 9.74 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3571985159797375		[learning rate: 0.00609]
	Learning Rate: 0.00608997
	LOSS [training: 0.3571985159797375 | validation: 0.31535843676353126]
	TIME [epoch: 9.74 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3445809407682203		[learning rate: 0.0060658]
	Learning Rate: 0.00606575
	LOSS [training: 0.3445809407682203 | validation: 0.3403989470790446]
	TIME [epoch: 9.76 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3307688523064925		[learning rate: 0.0060416]
	Learning Rate: 0.00604163
	LOSS [training: 0.3307688523064925 | validation: 0.2984547444115123]
	TIME [epoch: 9.74 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.31966850084289555		[learning rate: 0.0060176]
	Learning Rate: 0.0060176
	LOSS [training: 0.31966850084289555 | validation: 0.3760361643853848]
	TIME [epoch: 9.74 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3342210329444543		[learning rate: 0.0059937]
	Learning Rate: 0.00599366
	LOSS [training: 0.3342210329444543 | validation: 0.31076452193053006]
	TIME [epoch: 9.76 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3268260103139953		[learning rate: 0.0059698]
	Learning Rate: 0.00596982
	LOSS [training: 0.3268260103139953 | validation: 0.30546294322358414]
	TIME [epoch: 9.74 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3342589321842314		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 0.3342589321842314 | validation: 0.3104684245416024]
	TIME [epoch: 9.74 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3100184832312195		[learning rate: 0.0059224]
	Learning Rate: 0.00592243
	LOSS [training: 0.3100184832312195 | validation: 0.3547911145927386]
	TIME [epoch: 9.73 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4559147506236465		[learning rate: 0.0058989]
	Learning Rate: 0.00589888
	LOSS [training: 0.4559147506236465 | validation: 0.41089394022919556]
	TIME [epoch: 9.76 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4487924282753759		[learning rate: 0.0058754]
	Learning Rate: 0.00587541
	LOSS [training: 0.4487924282753759 | validation: 0.3909767274662421]
	TIME [epoch: 9.74 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.42226604730515604		[learning rate: 0.005852]
	Learning Rate: 0.00585205
	LOSS [training: 0.42226604730515604 | validation: 0.34412443242614715]
	TIME [epoch: 9.75 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.40112820468780314		[learning rate: 0.0058288]
	Learning Rate: 0.00582877
	LOSS [training: 0.40112820468780314 | validation: 0.348679654031563]
	TIME [epoch: 9.74 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3636202126794126		[learning rate: 0.0058056]
	Learning Rate: 0.00580559
	LOSS [training: 0.3636202126794126 | validation: 0.33155383861666493]
	TIME [epoch: 9.76 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3986318352166918		[learning rate: 0.0057825]
	Learning Rate: 0.0057825
	LOSS [training: 0.3986318352166918 | validation: 0.3242669610201728]
	TIME [epoch: 9.74 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.36833692387427514		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 0.36833692387427514 | validation: 0.2923168169155308]
	TIME [epoch: 9.74 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v11_20240711_141418/states/model_facs_dec1b_2dpca_v11_183.pth
	Model improved!!!
EPOCH 184/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.33692992167641683		[learning rate: 0.0057366]
	Learning Rate: 0.00573659
	LOSS [training: 0.33692992167641683 | validation: 0.3179116714393876]
	TIME [epoch: 10 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3269374662011013		[learning rate: 0.0057138]
	Learning Rate: 0.00571377
	LOSS [training: 0.3269374662011013 | validation: 0.32416225363883566]
	TIME [epoch: 9.76 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3120576702955247		[learning rate: 0.005691]
	Learning Rate: 0.00569105
	LOSS [training: 0.3120576702955247 | validation: 0.279206524403117]
	TIME [epoch: 9.75 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v11_20240711_141418/states/model_facs_dec1b_2dpca_v11_186.pth
	Model improved!!!
EPOCH 187/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3117745221012622		[learning rate: 0.0056684]
	Learning Rate: 0.00566841
	LOSS [training: 0.3117745221012622 | validation: 0.27478145168767404]
	TIME [epoch: 9.76 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v11_20240711_141418/states/model_facs_dec1b_2dpca_v11_187.pth
	Model improved!!!
EPOCH 188/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32861294249622514		[learning rate: 0.0056459]
	Learning Rate: 0.00564587
	LOSS [training: 0.32861294249622514 | validation: 0.2901106849457095]
	TIME [epoch: 9.78 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32638029193873336		[learning rate: 0.0056234]
	Learning Rate: 0.00562341
	LOSS [training: 0.32638029193873336 | validation: 0.2873282563608966]
	TIME [epoch: 9.75 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32775376801559003		[learning rate: 0.005601]
	Learning Rate: 0.00560105
	LOSS [training: 0.32775376801559003 | validation: 0.2809899527474383]
	TIME [epoch: 9.75 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.33039949371300925		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 0.33039949371300925 | validation: 0.29428902610367386]
	TIME [epoch: 9.76 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.34083652087999217		[learning rate: 0.0055566]
	Learning Rate: 0.00555658
	LOSS [training: 0.34083652087999217 | validation: 0.3347021885506489]
	TIME [epoch: 9.76 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3226824687011448		[learning rate: 0.0055345]
	Learning Rate: 0.00553448
	LOSS [training: 0.3226824687011448 | validation: 0.27098318228905954]
	TIME [epoch: 9.74 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v11_20240711_141418/states/model_facs_dec1b_2dpca_v11_193.pth
	Model improved!!!
EPOCH 194/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2892087750501257		[learning rate: 0.0055125]
	Learning Rate: 0.00551247
	LOSS [training: 0.2892087750501257 | validation: 0.2712354781028371]
	TIME [epoch: 9.76 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.30513534987982344		[learning rate: 0.0054905]
	Learning Rate: 0.00549054
	LOSS [training: 0.30513534987982344 | validation: 0.28888176938594434]
	TIME [epoch: 9.77 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.31308299384860266		[learning rate: 0.0054687]
	Learning Rate: 0.00546871
	LOSS [training: 0.31308299384860266 | validation: 0.47186701271463766]
	TIME [epoch: 9.75 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.31654839724217565		[learning rate: 0.005447]
	Learning Rate: 0.00544696
	LOSS [training: 0.31654839724217565 | validation: 0.3243634398009772]
	TIME [epoch: 9.75 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3268390735750973		[learning rate: 0.0054253]
	Learning Rate: 0.00542529
	LOSS [training: 0.3268390735750973 | validation: 0.3154861102017573]
	TIME [epoch: 9.76 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32235795537306156		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 0.32235795537306156 | validation: 0.27957440991247157]
	TIME [epoch: 9.76 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.30841098850211685		[learning rate: 0.0053822]
	Learning Rate: 0.00538222
	LOSS [training: 0.30841098850211685 | validation: 0.27943795053391357]
	TIME [epoch: 9.75 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.30905486144695665		[learning rate: 0.0053608]
	Learning Rate: 0.00536081
	LOSS [training: 0.30905486144695665 | validation: 0.27102900017381215]
	TIME [epoch: 9.76 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.30529261669120683		[learning rate: 0.0053395]
	Learning Rate: 0.00533949
	LOSS [training: 0.30529261669120683 | validation: 0.3200718862126388]
	TIME [epoch: 9.76 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4141670112837615		[learning rate: 0.0053183]
	Learning Rate: 0.00531826
	LOSS [training: 0.4141670112837615 | validation: 0.3211140816680959]
	TIME [epoch: 9.76 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.31468084957819403		[learning rate: 0.0052971]
	Learning Rate: 0.0052971
	LOSS [training: 0.31468084957819403 | validation: 0.28939267932047485]
	TIME [epoch: 9.74 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2988138525682824		[learning rate: 0.005276]
	Learning Rate: 0.00527604
	LOSS [training: 0.2988138525682824 | validation: 0.2680549881708319]
	TIME [epoch: 9.75 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v11_20240711_141418/states/model_facs_dec1b_2dpca_v11_205.pth
	Model improved!!!
EPOCH 206/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.31190618216323		[learning rate: 0.0052551]
	Learning Rate: 0.00525505
	LOSS [training: 0.31190618216323 | validation: 0.28467858955343395]
	TIME [epoch: 9.77 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.320375949752724		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 0.320375949752724 | validation: 0.27658629949162894]
	TIME [epoch: 9.74 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3052655965604979		[learning rate: 0.0052133]
	Learning Rate: 0.00521333
	LOSS [training: 0.3052655965604979 | validation: 0.2650827523516964]
	TIME [epoch: 9.74 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v11_20240711_141418/states/model_facs_dec1b_2dpca_v11_208.pth
	Model improved!!!
EPOCH 209/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2879396125448326		[learning rate: 0.0051926]
	Learning Rate: 0.0051926
	LOSS [training: 0.2879396125448326 | validation: 0.3150086132885003]
	TIME [epoch: 9.75 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3403069551306844		[learning rate: 0.0051719]
	Learning Rate: 0.00517194
	LOSS [training: 0.3403069551306844 | validation: 0.33441252077735883]
	TIME [epoch: 9.76 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3117273378307288		[learning rate: 0.0051514]
	Learning Rate: 0.00515137
	LOSS [training: 0.3117273378307288 | validation: 0.2695661571702529]
	TIME [epoch: 9.74 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.28611892598974314		[learning rate: 0.0051309]
	Learning Rate: 0.00513089
	LOSS [training: 0.28611892598974314 | validation: 0.3534063087247844]
	TIME [epoch: 9.75 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2883590001616341		[learning rate: 0.0051105]
	Learning Rate: 0.00511048
	LOSS [training: 0.2883590001616341 | validation: 0.26936239444105325]
	TIME [epoch: 9.76 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.29176085225111126		[learning rate: 0.0050902]
	Learning Rate: 0.00509015
	LOSS [training: 0.29176085225111126 | validation: 0.2830609495122012]
	TIME [epoch: 9.74 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3182928626276665		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 0.3182928626276665 | validation: 0.2621610701730863]
	TIME [epoch: 9.75 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v11_20240711_141418/states/model_facs_dec1b_2dpca_v11_215.pth
	Model improved!!!
EPOCH 216/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2872810209868911		[learning rate: 0.0050497]
	Learning Rate: 0.00504974
	LOSS [training: 0.2872810209868911 | validation: 0.2788045371199689]
	TIME [epoch: 9.75 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.29352055461539023		[learning rate: 0.0050297]
	Learning Rate: 0.00502966
	LOSS [training: 0.29352055461539023 | validation: 0.2701597514992378]
	TIME [epoch: 9.76 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32002761496213744		[learning rate: 0.0050097]
	Learning Rate: 0.00500965
	LOSS [training: 0.32002761496213744 | validation: 0.3327679991529628]
	TIME [epoch: 9.74 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3095339790125861		[learning rate: 0.0049897]
	Learning Rate: 0.00498973
	LOSS [training: 0.3095339790125861 | validation: 0.3261893622760627]
	TIME [epoch: 9.74 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2979509960632417		[learning rate: 0.0049699]
	Learning Rate: 0.00496988
	LOSS [training: 0.2979509960632417 | validation: 0.26186762681598214]
	TIME [epoch: 9.75 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v11_20240711_141418/states/model_facs_dec1b_2dpca_v11_220.pth
	Model improved!!!
EPOCH 221/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.30187727841265954		[learning rate: 0.0049501]
	Learning Rate: 0.00495012
	LOSS [training: 0.30187727841265954 | validation: 0.3021110060617563]
	TIME [epoch: 9.76 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3001126265430181		[learning rate: 0.0049304]
	Learning Rate: 0.00493043
	LOSS [training: 0.3001126265430181 | validation: 0.3761047806265986]
	TIME [epoch: 9.75 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3428897132636937		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 0.3428897132636937 | validation: 0.29743325525389863]
	TIME [epoch: 9.75 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.31832707677844213		[learning rate: 0.0048913]
	Learning Rate: 0.00489129
	LOSS [training: 0.31832707677844213 | validation: 0.2764747827070117]
	TIME [epoch: 9.76 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.28533287760541126		[learning rate: 0.0048718]
	Learning Rate: 0.00487183
	LOSS [training: 0.28533287760541126 | validation: 0.29545311106881733]
	TIME [epoch: 9.74 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2855790983624095		[learning rate: 0.0048525]
	Learning Rate: 0.00485245
	LOSS [training: 0.2855790983624095 | validation: 0.296653063227447]
	TIME [epoch: 9.74 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.29159388819015136		[learning rate: 0.0048332]
	Learning Rate: 0.00483316
	LOSS [training: 0.29159388819015136 | validation: 0.2681805033824153]
	TIME [epoch: 9.74 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2820271460895245		[learning rate: 0.0048139]
	Learning Rate: 0.00481393
	LOSS [training: 0.2820271460895245 | validation: 0.2758433586638473]
	TIME [epoch: 9.76 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2816433683322324		[learning rate: 0.0047948]
	Learning Rate: 0.00479479
	LOSS [training: 0.2816433683322324 | validation: 0.26356628110720653]
	TIME [epoch: 9.74 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2787010130369672		[learning rate: 0.0047757]
	Learning Rate: 0.00477572
	LOSS [training: 0.2787010130369672 | validation: 0.25962105292747395]
	TIME [epoch: 9.74 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v11_20240711_141418/states/model_facs_dec1b_2dpca_v11_230.pth
	Model improved!!!
EPOCH 231/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2891922732085065		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.2891922732085065 | validation: 0.29086513335922654]
	TIME [epoch: 9.76 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4027384276053374		[learning rate: 0.0047378]
	Learning Rate: 0.0047378
	LOSS [training: 0.4027384276053374 | validation: 0.30519795062729316]
	TIME [epoch: 9.74 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.30241925181213014		[learning rate: 0.004719]
	Learning Rate: 0.00471896
	LOSS [training: 0.30241925181213014 | validation: 0.29768269361536126]
	TIME [epoch: 9.74 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2967236995187651		[learning rate: 0.0047002]
	Learning Rate: 0.00470019
	LOSS [training: 0.2967236995187651 | validation: 0.2845888856657798]
	TIME [epoch: 9.74 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3157294264129493		[learning rate: 0.0046815]
	Learning Rate: 0.0046815
	LOSS [training: 0.3157294264129493 | validation: 0.2879021182176721]
	TIME [epoch: 9.75 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.28740091953558405		[learning rate: 0.0046629]
	Learning Rate: 0.00466288
	LOSS [training: 0.28740091953558405 | validation: 0.2662271808766029]
	TIME [epoch: 9.73 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.27408244438603185		[learning rate: 0.0046443]
	Learning Rate: 0.00464433
	LOSS [training: 0.27408244438603185 | validation: 0.2573779113795543]
	TIME [epoch: 9.74 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v11_20240711_141418/states/model_facs_dec1b_2dpca_v11_237.pth
	Model improved!!!
EPOCH 238/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2810613604087193		[learning rate: 0.0046259]
	Learning Rate: 0.00462586
	LOSS [training: 0.2810613604087193 | validation: 0.2686434082407401]
	TIME [epoch: 9.75 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.27468849815401497		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 0.27468849815401497 | validation: 0.27592812018949725]
	TIME [epoch: 9.75 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2896935635836904		[learning rate: 0.0045891]
	Learning Rate: 0.00458913
	LOSS [training: 0.2896935635836904 | validation: 0.27185588465772187]
	TIME [epoch: 9.74 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2793825671121576		[learning rate: 0.0045709]
	Learning Rate: 0.00457088
	LOSS [training: 0.2793825671121576 | validation: 0.27816774826194124]
	TIME [epoch: 9.73 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.277359466643622		[learning rate: 0.0045527]
	Learning Rate: 0.0045527
	LOSS [training: 0.277359466643622 | validation: 0.2600669487018711]
	TIME [epoch: 9.75 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3095544007297032		[learning rate: 0.0045346]
	Learning Rate: 0.00453459
	LOSS [training: 0.3095544007297032 | validation: 0.2831224980582979]
	TIME [epoch: 9.74 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.31454246794377533		[learning rate: 0.0045166]
	Learning Rate: 0.00451656
	LOSS [training: 0.31454246794377533 | validation: 0.2908384514617498]
	TIME [epoch: 9.73 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32870651579943844		[learning rate: 0.0044986]
	Learning Rate: 0.0044986
	LOSS [training: 0.32870651579943844 | validation: 0.27988843716998135]
	TIME [epoch: 9.74 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3377436712272097		[learning rate: 0.0044807]
	Learning Rate: 0.0044807
	LOSS [training: 0.3377436712272097 | validation: 0.27634877271707914]
	TIME [epoch: 9.76 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.29596220485288793		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 0.29596220485288793 | validation: 0.30651210821007363]
	TIME [epoch: 9.74 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.28270143949809523		[learning rate: 0.0044451]
	Learning Rate: 0.00444513
	LOSS [training: 0.28270143949809523 | validation: 0.2901281746524359]
	TIME [epoch: 9.74 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2944115961307551		[learning rate: 0.0044275]
	Learning Rate: 0.00442745
	LOSS [training: 0.2944115961307551 | validation: 0.28221366031198847]
	TIME [epoch: 9.75 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3353722586190244		[learning rate: 0.0044098]
	Learning Rate: 0.00440984
	LOSS [training: 0.3353722586190244 | validation: 0.3022570459817822]
	TIME [epoch: 9.75 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.44544161976572916		[learning rate: 0.0043923]
	Learning Rate: 0.0043923
	LOSS [training: 0.44544161976572916 | validation: 0.29798383786269456]
	TIME [epoch: 9.74 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3466216522459148		[learning rate: 0.0043748]
	Learning Rate: 0.00437483
	LOSS [training: 0.3466216522459148 | validation: 0.31079258758484946]
	TIME [epoch: 9.74 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.31894758427053166		[learning rate: 0.0043574]
	Learning Rate: 0.00435743
	LOSS [training: 0.31894758427053166 | validation: 0.2855973137835531]
	TIME [epoch: 9.76 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.28474173772303174		[learning rate: 0.0043401]
	Learning Rate: 0.0043401
	LOSS [training: 0.28474173772303174 | validation: 0.2705270841551882]
	TIME [epoch: 9.74 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2774596128509639		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 0.2774596128509639 | validation: 0.2700619271962063]
	TIME [epoch: 9.74 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.27809680714912216		[learning rate: 0.0043056]
	Learning Rate: 0.00430565
	LOSS [training: 0.27809680714912216 | validation: 0.27956859386804184]
	TIME [epoch: 9.73 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.28491964440515294		[learning rate: 0.0042885]
	Learning Rate: 0.00428852
	LOSS [training: 0.28491964440515294 | validation: 0.32822738055463746]
	TIME [epoch: 9.75 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2760528721063866		[learning rate: 0.0042715]
	Learning Rate: 0.00427147
	LOSS [training: 0.2760528721063866 | validation: 0.2993499182493113]
	TIME [epoch: 9.74 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.29855756206887346		[learning rate: 0.0042545]
	Learning Rate: 0.00425448
	LOSS [training: 0.29855756206887346 | validation: 0.2870992679141494]
	TIME [epoch: 9.73 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.31293379815420636		[learning rate: 0.0042376]
	Learning Rate: 0.00423756
	LOSS [training: 0.31293379815420636 | validation: 0.3146560594272909]
	TIME [epoch: 9.74 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2958182200513092		[learning rate: 0.0042207]
	Learning Rate: 0.0042207
	LOSS [training: 0.2958182200513092 | validation: 0.297792715058584]
	TIME [epoch: 9.74 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.28928405331199686		[learning rate: 0.0042039]
	Learning Rate: 0.00420391
	LOSS [training: 0.28928405331199686 | validation: 0.28377483436203493]
	TIME [epoch: 9.74 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2827107536541171		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 0.2827107536541171 | validation: 0.2594550733566541]
	TIME [epoch: 9.73 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.27703016998700486		[learning rate: 0.0041705]
	Learning Rate: 0.00417054
	LOSS [training: 0.27703016998700486 | validation: 0.2801840164688202]
	TIME [epoch: 9.75 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2857607269852629		[learning rate: 0.004154]
	Learning Rate: 0.00415395
	LOSS [training: 0.2857607269852629 | validation: 0.31177992077990513]
	TIME [epoch: 9.74 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2905854154185963		[learning rate: 0.0041374]
	Learning Rate: 0.00413743
	LOSS [training: 0.2905854154185963 | validation: 0.2861158260170376]
	TIME [epoch: 9.73 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2838830126658819		[learning rate: 0.004121]
	Learning Rate: 0.00412098
	LOSS [training: 0.2838830126658819 | validation: 0.27313582100891415]
	TIME [epoch: 9.73 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2808607119262541		[learning rate: 0.0041046]
	Learning Rate: 0.00410458
	LOSS [training: 0.2808607119262541 | validation: 0.2821348172924739]
	TIME [epoch: 9.75 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2785133985241		[learning rate: 0.0040883]
	Learning Rate: 0.00408826
	LOSS [training: 0.2785133985241 | validation: 0.26624382515873457]
	TIME [epoch: 9.73 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.29528598049710597		[learning rate: 0.004072]
	Learning Rate: 0.004072
	LOSS [training: 0.29528598049710597 | validation: 0.26433302754214644]
	TIME [epoch: 9.74 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2911348600883773		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.2911348600883773 | validation: 0.2731183275415526]
	TIME [epoch: 9.74 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2960247337003856		[learning rate: 0.0040397]
	Learning Rate: 0.00403967
	LOSS [training: 0.2960247337003856 | validation: 0.27604167204911495]
	TIME [epoch: 9.74 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.28023248756644953		[learning rate: 0.0040236]
	Learning Rate: 0.00402361
	LOSS [training: 0.28023248756644953 | validation: 0.31959677303344425]
	TIME [epoch: 9.73 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.281187779870784		[learning rate: 0.0040076]
	Learning Rate: 0.0040076
	LOSS [training: 0.281187779870784 | validation: 0.26074975179648935]
	TIME [epoch: 9.73 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2885728010872664		[learning rate: 0.0039917]
	Learning Rate: 0.00399166
	LOSS [training: 0.2885728010872664 | validation: 0.2974902822230353]
	TIME [epoch: 9.75 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2950652950742037		[learning rate: 0.0039758]
	Learning Rate: 0.00397579
	LOSS [training: 0.2950652950742037 | validation: 0.2768301780552861]
	TIME [epoch: 9.73 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3069026392008861		[learning rate: 0.00396]
	Learning Rate: 0.00395997
	LOSS [training: 0.3069026392008861 | validation: 0.2907737266230521]
	TIME [epoch: 9.74 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.28743116430625404		[learning rate: 0.0039442]
	Learning Rate: 0.00394422
	LOSS [training: 0.28743116430625404 | validation: 0.281625651916681]
	TIME [epoch: 9.74 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2711792938520559		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 0.2711792938520559 | validation: 0.2665985589190155]
	TIME [epoch: 9.75 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.27514953213376814		[learning rate: 0.0039129]
	Learning Rate: 0.00391291
	LOSS [training: 0.27514953213376814 | validation: 0.2834056418220454]
	TIME [epoch: 9.74 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.27082338481446216		[learning rate: 0.0038973]
	Learning Rate: 0.00389735
	LOSS [training: 0.27082338481446216 | validation: 0.27400519011386254]
	TIME [epoch: 9.74 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2817080918514857		[learning rate: 0.0038818]
	Learning Rate: 0.00388185
	LOSS [training: 0.2817080918514857 | validation: 0.27630115814780026]
	TIME [epoch: 9.74 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2665791263202093		[learning rate: 0.0038664]
	Learning Rate: 0.00386641
	LOSS [training: 0.2665791263202093 | validation: 0.274771133148202]
	TIME [epoch: 9.74 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.27031984782684115		[learning rate: 0.003851]
	Learning Rate: 0.00385103
	LOSS [training: 0.27031984782684115 | validation: 0.2777491700296102]
	TIME [epoch: 9.73 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.30822119269510495		[learning rate: 0.0038357]
	Learning Rate: 0.00383571
	LOSS [training: 0.30822119269510495 | validation: 0.29607787799678625]
	TIME [epoch: 9.74 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26657426279724644		[learning rate: 0.0038205]
	Learning Rate: 0.00382046
	LOSS [training: 0.26657426279724644 | validation: 0.26049409511220284]
	TIME [epoch: 9.75 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2675305031194873		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 0.2675305031194873 | validation: 0.26367044561621206]
	TIME [epoch: 9.74 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.29305057452313066		[learning rate: 0.0037901]
	Learning Rate: 0.00379013
	LOSS [training: 0.29305057452313066 | validation: 0.302555666824224]
	TIME [epoch: 9.73 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2926014813054209		[learning rate: 0.0037751]
	Learning Rate: 0.00377505
	LOSS [training: 0.2926014813054209 | validation: 0.2865824590326213]
	TIME [epoch: 9.74 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2815247072114653		[learning rate: 0.00376]
	Learning Rate: 0.00376004
	LOSS [training: 0.2815247072114653 | validation: 0.28483897628513655]
	TIME [epoch: 9.76 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2687733991089337		[learning rate: 0.0037451]
	Learning Rate: 0.00374508
	LOSS [training: 0.2687733991089337 | validation: 0.2828113379705765]
	TIME [epoch: 9.74 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.266592823619569		[learning rate: 0.0037302]
	Learning Rate: 0.00373019
	LOSS [training: 0.266592823619569 | validation: 0.2810580113307935]
	TIME [epoch: 9.74 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.28063652968410735		[learning rate: 0.0037154]
	Learning Rate: 0.00371535
	LOSS [training: 0.28063652968410735 | validation: 0.2792413478373025]
	TIME [epoch: 9.75 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.27012207281413		[learning rate: 0.0037006]
	Learning Rate: 0.00370058
	LOSS [training: 0.27012207281413 | validation: 0.29158616433673923]
	TIME [epoch: 9.74 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2870467738944284		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 0.2870467738944284 | validation: 0.2785941731265046]
	TIME [epoch: 9.74 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2782485245889773		[learning rate: 0.0036712]
	Learning Rate: 0.0036712
	LOSS [training: 0.2782485245889773 | validation: 0.30698422899214045]
	TIME [epoch: 9.73 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2758158553560841		[learning rate: 0.0036566]
	Learning Rate: 0.0036566
	LOSS [training: 0.2758158553560841 | validation: 0.27598788385761097]
	TIME [epoch: 9.75 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2667191834873932		[learning rate: 0.0036421]
	Learning Rate: 0.00364205
	LOSS [training: 0.2667191834873932 | validation: 0.2675591955463967]
	TIME [epoch: 9.73 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2590579386216592		[learning rate: 0.0036276]
	Learning Rate: 0.00362757
	LOSS [training: 0.2590579386216592 | validation: 0.26262381472559554]
	TIME [epoch: 9.73 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.29735995568533863		[learning rate: 0.0036131]
	Learning Rate: 0.00361314
	LOSS [training: 0.29735995568533863 | validation: 0.28020307873426314]
	TIME [epoch: 9.73 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2721019014914052		[learning rate: 0.0035988]
	Learning Rate: 0.00359877
	LOSS [training: 0.2721019014914052 | validation: 0.27657432060222714]
	TIME [epoch: 9.76 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2668912270138891		[learning rate: 0.0035845]
	Learning Rate: 0.00358445
	LOSS [training: 0.2668912270138891 | validation: 0.2784469978267604]
	TIME [epoch: 9.74 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26759937441194187		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 0.26759937441194187 | validation: 0.3360658916883999]
	TIME [epoch: 9.73 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.29049136784872825		[learning rate: 0.003556]
	Learning Rate: 0.003556
	LOSS [training: 0.29049136784872825 | validation: 0.2503229698850581]
	TIME [epoch: 9.75 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v11_20240711_141418/states/model_facs_dec1b_2dpca_v11_304.pth
	Model improved!!!
EPOCH 305/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25399325830785247		[learning rate: 0.0035419]
	Learning Rate: 0.00354185
	LOSS [training: 0.25399325830785247 | validation: 0.26817808643946495]
	TIME [epoch: 9.75 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2856562054691295		[learning rate: 0.0035278]
	Learning Rate: 0.00352777
	LOSS [training: 0.2856562054691295 | validation: 0.26628540762726527]
	TIME [epoch: 9.74 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25849335921639477		[learning rate: 0.0035137]
	Learning Rate: 0.00351374
	LOSS [training: 0.25849335921639477 | validation: 0.25981903495369485]
	TIME [epoch: 9.74 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2534233571008957		[learning rate: 0.0034998]
	Learning Rate: 0.00349976
	LOSS [training: 0.2534233571008957 | validation: 0.2804180045678308]
	TIME [epoch: 9.76 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25724372863959916		[learning rate: 0.0034858]
	Learning Rate: 0.00348584
	LOSS [training: 0.25724372863959916 | validation: 0.26363543027040726]
	TIME [epoch: 9.74 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25881115604715155		[learning rate: 0.003472]
	Learning Rate: 0.00347198
	LOSS [training: 0.25881115604715155 | validation: 0.27275070496907555]
	TIME [epoch: 9.74 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2724926057400362		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.2724926057400362 | validation: 0.2868370419070795]
	TIME [epoch: 9.74 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.29429149477832406		[learning rate: 0.0034444]
	Learning Rate: 0.00344441
	LOSS [training: 0.29429149477832406 | validation: 0.2554060182104518]
	TIME [epoch: 9.76 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2548281813605976		[learning rate: 0.0034307]
	Learning Rate: 0.00343071
	LOSS [training: 0.2548281813605976 | validation: 0.24174650812476486]
	TIME [epoch: 9.74 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v11_20240711_141418/states/model_facs_dec1b_2dpca_v11_313.pth
	Model improved!!!
EPOCH 314/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2577913277158724		[learning rate: 0.0034171]
	Learning Rate: 0.00341707
	LOSS [training: 0.2577913277158724 | validation: 0.26536203041027606]
	TIME [epoch: 9.76 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.27050259666931314		[learning rate: 0.0034035]
	Learning Rate: 0.00340348
	LOSS [training: 0.27050259666931314 | validation: 0.2527721488411146]
	TIME [epoch: 9.77 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2610636581737535		[learning rate: 0.0033899]
	Learning Rate: 0.00338994
	LOSS [training: 0.2610636581737535 | validation: 0.26361233660163996]
	TIME [epoch: 9.75 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.27609231975997983		[learning rate: 0.0033765]
	Learning Rate: 0.00337646
	LOSS [training: 0.27609231975997983 | validation: 0.25983407988274504]
	TIME [epoch: 9.75 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.27030905835847235		[learning rate: 0.003363]
	Learning Rate: 0.00336303
	LOSS [training: 0.27030905835847235 | validation: 0.24660970227994533]
	TIME [epoch: 9.76 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2599972119208139		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 0.2599972119208139 | validation: 0.2523510514702506]
	TIME [epoch: 9.77 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25038417129490276		[learning rate: 0.0033363]
	Learning Rate: 0.00333633
	LOSS [training: 0.25038417129490276 | validation: 0.2620379990759446]
	TIME [epoch: 9.75 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2761162390698153		[learning rate: 0.0033231]
	Learning Rate: 0.00332306
	LOSS [training: 0.2761162390698153 | validation: 0.2561179646277793]
	TIME [epoch: 9.75 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2509606167934409		[learning rate: 0.0033098]
	Learning Rate: 0.00330985
	LOSS [training: 0.2509606167934409 | validation: 0.3152410985419579]
	TIME [epoch: 9.76 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.263147535083182		[learning rate: 0.0032967]
	Learning Rate: 0.00329668
	LOSS [training: 0.263147535083182 | validation: 0.2702060357357955]
	TIME [epoch: 9.77 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.29418005624499244		[learning rate: 0.0032836]
	Learning Rate: 0.00328357
	LOSS [training: 0.29418005624499244 | validation: 0.3083420906921407]
	TIME [epoch: 9.75 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.27084318718269945		[learning rate: 0.0032705]
	Learning Rate: 0.00327051
	LOSS [training: 0.27084318718269945 | validation: 0.26365855551418976]
	TIME [epoch: 9.75 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25138151901350797		[learning rate: 0.0032575]
	Learning Rate: 0.0032575
	LOSS [training: 0.25138151901350797 | validation: 0.24343898963613247]
	TIME [epoch: 9.76 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26041350494772053		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 0.26041350494772053 | validation: 0.2691383128029713]
	TIME [epoch: 9.75 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26038935987216727		[learning rate: 0.0032316]
	Learning Rate: 0.00323164
	LOSS [training: 0.26038935987216727 | validation: 0.2546377965961283]
	TIME [epoch: 9.75 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26627591755887314		[learning rate: 0.0032188]
	Learning Rate: 0.00321879
	LOSS [training: 0.26627591755887314 | validation: 0.31621903647039257]
	TIME [epoch: 9.74 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3334604796920983		[learning rate: 0.003206]
	Learning Rate: 0.00320599
	LOSS [training: 0.3334604796920983 | validation: 0.28801977153125724]
	TIME [epoch: 9.77 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.27241910524489144		[learning rate: 0.0031932]
	Learning Rate: 0.00319323
	LOSS [training: 0.27241910524489144 | validation: 0.2676579903616868]
	TIME [epoch: 9.74 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2654340206713355		[learning rate: 0.0031805]
	Learning Rate: 0.00318053
	LOSS [training: 0.2654340206713355 | validation: 0.2651554535694456]
	TIME [epoch: 9.75 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.27551170395311114		[learning rate: 0.0031679]
	Learning Rate: 0.00316788
	LOSS [training: 0.27551170395311114 | validation: 0.2765061698208829]
	TIME [epoch: 9.75 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26048016605907853		[learning rate: 0.0031553]
	Learning Rate: 0.00315528
	LOSS [training: 0.26048016605907853 | validation: 0.2838195591901809]
	TIME [epoch: 9.76 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26066262102075094		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 0.26066262102075094 | validation: 0.26692006141916774]
	TIME [epoch: 9.75 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2602336013145059		[learning rate: 0.0031302]
	Learning Rate: 0.00313023
	LOSS [training: 0.2602336013145059 | validation: 0.2697047777791153]
	TIME [epoch: 9.74 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2506592035070274		[learning rate: 0.0031178]
	Learning Rate: 0.00311779
	LOSS [training: 0.2506592035070274 | validation: 0.27333658664663785]
	TIME [epoch: 9.76 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3247981243464564		[learning rate: 0.0031054]
	Learning Rate: 0.00310538
	LOSS [training: 0.3247981243464564 | validation: 0.2937618920567519]
	TIME [epoch: 9.75 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3280448375732154		[learning rate: 0.003093]
	Learning Rate: 0.00309303
	LOSS [training: 0.3280448375732154 | validation: 0.313281279159434]
	TIME [epoch: 9.75 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3028349724424173		[learning rate: 0.0030807]
	Learning Rate: 0.00308073
	LOSS [training: 0.3028349724424173 | validation: 0.26780483095005153]
	TIME [epoch: 9.75 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3015288474700427		[learning rate: 0.0030685]
	Learning Rate: 0.00306848
	LOSS [training: 0.3015288474700427 | validation: 0.3123669638948573]
	TIME [epoch: 9.77 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.29114386955102517		[learning rate: 0.0030563]
	Learning Rate: 0.00305627
	LOSS [training: 0.29114386955102517 | validation: 0.33576081064171953]
	TIME [epoch: 9.74 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2778061018474115		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 0.2778061018474115 | validation: 0.2567987890733966]
	TIME [epoch: 9.74 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2480105047913981		[learning rate: 0.003032]
	Learning Rate: 0.00303201
	LOSS [training: 0.2480105047913981 | validation: 0.2977526573749172]
	TIME [epoch: 9.75 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.31268702698833967		[learning rate: 0.00302]
	Learning Rate: 0.00301995
	LOSS [training: 0.31268702698833967 | validation: 0.2699879826714652]
	TIME [epoch: 9.76 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2539362234629647		[learning rate: 0.0030079]
	Learning Rate: 0.00300794
	LOSS [training: 0.2539362234629647 | validation: 0.25821513051819184]
	TIME [epoch: 9.74 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2659050211369225		[learning rate: 0.002996]
	Learning Rate: 0.00299598
	LOSS [training: 0.2659050211369225 | validation: 0.2776542144518235]
	TIME [epoch: 9.74 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3037310740630471		[learning rate: 0.0029841]
	Learning Rate: 0.00298406
	LOSS [training: 0.3037310740630471 | validation: 0.3372801467685035]
	TIME [epoch: 9.76 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2993259422480661		[learning rate: 0.0029722]
	Learning Rate: 0.00297219
	LOSS [training: 0.2993259422480661 | validation: 0.2962499770139614]
	TIME [epoch: 9.75 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2757150362679701		[learning rate: 0.0029604]
	Learning Rate: 0.00296037
	LOSS [training: 0.2757150362679701 | validation: 0.2694476666526169]
	TIME [epoch: 9.75 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26977192145848694		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.26977192145848694 | validation: 0.2730224844227365]
	TIME [epoch: 9.75 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2689539397521613		[learning rate: 0.0029369]
	Learning Rate: 0.00293687
	LOSS [training: 0.2689539397521613 | validation: 0.2575381874121837]
	TIME [epoch: 9.77 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.28277054110660155		[learning rate: 0.0029252]
	Learning Rate: 0.00292519
	LOSS [training: 0.28277054110660155 | validation: 0.27705694128393316]
	TIME [epoch: 9.75 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3033351808421509		[learning rate: 0.0029136]
	Learning Rate: 0.00291355
	LOSS [training: 0.3033351808421509 | validation: 0.3364633183306451]
	TIME [epoch: 9.75 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3028392400414619		[learning rate: 0.002902]
	Learning Rate: 0.00290197
	LOSS [training: 0.3028392400414619 | validation: 0.2678717857547771]
	TIME [epoch: 9.75 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2732805216648496		[learning rate: 0.0028904]
	Learning Rate: 0.00289042
	LOSS [training: 0.2732805216648496 | validation: 0.27167018554395983]
	TIME [epoch: 9.75 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2928020760334665		[learning rate: 0.0028789]
	Learning Rate: 0.00287893
	LOSS [training: 0.2928020760334665 | validation: 0.3795401806572198]
	TIME [epoch: 9.75 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.27841825369680456		[learning rate: 0.0028675]
	Learning Rate: 0.00286748
	LOSS [training: 0.27841825369680456 | validation: 0.2565411059170963]
	TIME [epoch: 9.74 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2796028754836849		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 0.2796028754836849 | validation: 0.27152430008974066]
	TIME [epoch: 9.76 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26494976967770884		[learning rate: 0.0028447]
	Learning Rate: 0.00284471
	LOSS [training: 0.26494976967770884 | validation: 0.26595287661400546]
	TIME [epoch: 9.75 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2996066974054934		[learning rate: 0.0028334]
	Learning Rate: 0.0028334
	LOSS [training: 0.2996066974054934 | validation: 0.26431560609423166]
	TIME [epoch: 9.75 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2636582151825465		[learning rate: 0.0028221]
	Learning Rate: 0.00282213
	LOSS [training: 0.2636582151825465 | validation: 0.2861981051903144]
	TIME [epoch: 9.75 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2785327775523978		[learning rate: 0.0028109]
	Learning Rate: 0.00281091
	LOSS [training: 0.2785327775523978 | validation: 0.26205715006349667]
	TIME [epoch: 9.77 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2569279013085851		[learning rate: 0.0027997]
	Learning Rate: 0.00279973
	LOSS [training: 0.2569279013085851 | validation: 0.26693565777580575]
	TIME [epoch: 9.74 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2728037401221889		[learning rate: 0.0027886]
	Learning Rate: 0.00278859
	LOSS [training: 0.2728037401221889 | validation: 0.25839105264386253]
	TIME [epoch: 9.75 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.28307292323488614		[learning rate: 0.0027775]
	Learning Rate: 0.0027775
	LOSS [training: 0.28307292323488614 | validation: 0.30410870041914595]
	TIME [epoch: 9.74 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.284845889297576		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 0.284845889297576 | validation: 0.2953500377264513]
	TIME [epoch: 9.76 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26244689355407624		[learning rate: 0.0027554]
	Learning Rate: 0.00275545
	LOSS [training: 0.26244689355407624 | validation: 0.2670719670887466]
	TIME [epoch: 9.75 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25850921739489013		[learning rate: 0.0027445]
	Learning Rate: 0.00274449
	LOSS [training: 0.25850921739489013 | validation: 0.283605626035102]
	TIME [epoch: 9.74 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3282648342111391		[learning rate: 0.0027336]
	Learning Rate: 0.00273357
	LOSS [training: 0.3282648342111391 | validation: 0.2936782836849699]
	TIME [epoch: 9.77 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.28062318679913595		[learning rate: 0.0027227]
	Learning Rate: 0.0027227
	LOSS [training: 0.28062318679913595 | validation: 0.27926408561411636]
	TIME [epoch: 9.76 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.27158493619580226		[learning rate: 0.0027119]
	Learning Rate: 0.00271187
	LOSS [training: 0.27158493619580226 | validation: 0.2789555537961412]
	TIME [epoch: 9.74 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.271483843607258		[learning rate: 0.0027011]
	Learning Rate: 0.00270109
	LOSS [training: 0.271483843607258 | validation: 0.2994952585159417]
	TIME [epoch: 9.75 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.29138505517521573		[learning rate: 0.0026903]
	Learning Rate: 0.00269034
	LOSS [training: 0.29138505517521573 | validation: 0.31028631406940016]
	TIME [epoch: 9.77 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.282507413598732		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 0.282507413598732 | validation: 0.2586842116794148]
	TIME [epoch: 9.76 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2664118953321616		[learning rate: 0.002669]
	Learning Rate: 0.00266899
	LOSS [training: 0.2664118953321616 | validation: 0.2685757771060997]
	TIME [epoch: 9.75 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.260644381544593		[learning rate: 0.0026584]
	Learning Rate: 0.00265837
	LOSS [training: 0.260644381544593 | validation: 0.27659487903095925]
	TIME [epoch: 9.76 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2753882432484506		[learning rate: 0.0026478]
	Learning Rate: 0.0026478
	LOSS [training: 0.2753882432484506 | validation: 0.28521585046644826]
	TIME [epoch: 9.76 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2886564133078052		[learning rate: 0.0026373]
	Learning Rate: 0.00263727
	LOSS [training: 0.2886564133078052 | validation: 0.2595031070764814]
	TIME [epoch: 9.75 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2657774349788409		[learning rate: 0.0026268]
	Learning Rate: 0.00262678
	LOSS [training: 0.2657774349788409 | validation: 0.2629763783276043]
	TIME [epoch: 9.75 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2773409581259185		[learning rate: 0.0026163]
	Learning Rate: 0.00261633
	LOSS [training: 0.2773409581259185 | validation: 0.2707287636749627]
	TIME [epoch: 9.77 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.29744116780093877		[learning rate: 0.0026059]
	Learning Rate: 0.00260592
	LOSS [training: 0.29744116780093877 | validation: 0.29264945096793155]
	TIME [epoch: 9.75 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3150515473942133		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 0.3150515473942133 | validation: 0.29606979093580754]
	TIME [epoch: 9.74 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3035906677361223		[learning rate: 0.0025852]
	Learning Rate: 0.00258523
	LOSS [training: 0.3035906677361223 | validation: 0.303206227313029]
	TIME [epoch: 9.75 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.30253292526058334		[learning rate: 0.002575]
	Learning Rate: 0.00257495
	LOSS [training: 0.30253292526058334 | validation: 0.2818449135175888]
	TIME [epoch: 9.77 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2694854396507568		[learning rate: 0.0025647]
	Learning Rate: 0.00256471
	LOSS [training: 0.2694854396507568 | validation: 0.2547688591749956]
	TIME [epoch: 9.74 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.28577894206766635		[learning rate: 0.0025545]
	Learning Rate: 0.00255451
	LOSS [training: 0.28577894206766635 | validation: 0.2722057034995253]
	TIME [epoch: 9.75 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2560924942322348		[learning rate: 0.0025444]
	Learning Rate: 0.00254435
	LOSS [training: 0.2560924942322348 | validation: 0.25887051526966043]
	TIME [epoch: 9.76 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26285423736513885		[learning rate: 0.0025342]
	Learning Rate: 0.00253423
	LOSS [training: 0.26285423736513885 | validation: 0.24409719010289282]
	TIME [epoch: 9.75 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2604277283382103		[learning rate: 0.0025242]
	Learning Rate: 0.00252415
	LOSS [training: 0.2604277283382103 | validation: 0.24971112440541637]
	TIME [epoch: 9.74 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26312275648037453		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.26312275648037453 | validation: 0.25893823864716814]
	TIME [epoch: 9.74 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25395031449141425		[learning rate: 0.0025041]
	Learning Rate: 0.00250411
	LOSS [training: 0.25395031449141425 | validation: 0.2572166884584004]
	TIME [epoch: 9.75 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25299760606659216		[learning rate: 0.0024942]
	Learning Rate: 0.00249415
	LOSS [training: 0.25299760606659216 | validation: 0.24800212313330317]
	TIME [epoch: 9.74 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2585993988413856		[learning rate: 0.0024842]
	Learning Rate: 0.00248423
	LOSS [training: 0.2585993988413856 | validation: 0.2534166468558469]
	TIME [epoch: 9.75 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24789309060281997		[learning rate: 0.0024744]
	Learning Rate: 0.00247435
	LOSS [training: 0.24789309060281997 | validation: 0.2586789531892492]
	TIME [epoch: 9.75 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25361274843586606		[learning rate: 0.0024645]
	Learning Rate: 0.00246451
	LOSS [training: 0.25361274843586606 | validation: 0.23985113850874992]
	TIME [epoch: 9.76 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v11_20240711_141418/states/model_facs_dec1b_2dpca_v11_396.pth
	Model improved!!!
EPOCH 397/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25552436490391434		[learning rate: 0.0024547]
	Learning Rate: 0.00245471
	LOSS [training: 0.25552436490391434 | validation: 0.25966948630876313]
	TIME [epoch: 9.76 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25570640762878666		[learning rate: 0.0024449]
	Learning Rate: 0.00244495
	LOSS [training: 0.25570640762878666 | validation: 0.26631671826160397]
	TIME [epoch: 9.74 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24880719830785195		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 0.24880719830785195 | validation: 0.2612051452358838]
	TIME [epoch: 9.76 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2826057134865474		[learning rate: 0.0024255]
	Learning Rate: 0.00242554
	LOSS [training: 0.2826057134865474 | validation: 0.25141027274757777]
	TIME [epoch: 9.75 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25202898433100285		[learning rate: 0.0024159]
	Learning Rate: 0.00241589
	LOSS [training: 0.25202898433100285 | validation: 0.25433546976592053]
	TIME [epoch: 9.76 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2769732056254772		[learning rate: 0.0024063]
	Learning Rate: 0.00240628
	LOSS [training: 0.2769732056254772 | validation: 0.24490102049846824]
	TIME [epoch: 9.75 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26534172053225985		[learning rate: 0.0023967]
	Learning Rate: 0.00239671
	LOSS [training: 0.26534172053225985 | validation: 0.26068857165572507]
	TIME [epoch: 9.77 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2593283633533109		[learning rate: 0.0023872]
	Learning Rate: 0.00238718
	LOSS [training: 0.2593283633533109 | validation: 0.2698645581820296]
	TIME [epoch: 9.75 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25747217005189715		[learning rate: 0.0023777]
	Learning Rate: 0.00237768
	LOSS [training: 0.25747217005189715 | validation: 0.2546577786882716]
	TIME [epoch: 9.75 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.246303861727727		[learning rate: 0.0023682]
	Learning Rate: 0.00236823
	LOSS [training: 0.246303861727727 | validation: 0.23635264735654715]
	TIME [epoch: 9.75 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v11_20240711_141418/states/model_facs_dec1b_2dpca_v11_406.pth
	Model improved!!!
EPOCH 407/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2463099856416618		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 0.2463099856416618 | validation: 0.27630570054586323]
	TIME [epoch: 9.77 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2632596154510764		[learning rate: 0.0023494]
	Learning Rate: 0.00234942
	LOSS [training: 0.2632596154510764 | validation: 0.24644172747291568]
	TIME [epoch: 9.75 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2670146754367929		[learning rate: 0.0023401]
	Learning Rate: 0.00234008
	LOSS [training: 0.2670146754367929 | validation: 0.29294931951195097]
	TIME [epoch: 9.74 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.31844897039236914		[learning rate: 0.0023308]
	Learning Rate: 0.00233077
	LOSS [training: 0.31844897039236914 | validation: 0.2729971632331389]
	TIME [epoch: 9.76 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2794754585407603		[learning rate: 0.0023215]
	Learning Rate: 0.0023215
	LOSS [training: 0.2794754585407603 | validation: 0.2515144519370859]
	TIME [epoch: 9.74 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2557020483737628		[learning rate: 0.0023123]
	Learning Rate: 0.00231227
	LOSS [training: 0.2557020483737628 | validation: 0.2817146128912652]
	TIME [epoch: 9.74 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2723093897619239		[learning rate: 0.0023031]
	Learning Rate: 0.00230307
	LOSS [training: 0.2723093897619239 | validation: 0.2753994560307926]
	TIME [epoch: 9.74 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2530685799471607		[learning rate: 0.0022939]
	Learning Rate: 0.00229391
	LOSS [training: 0.2530685799471607 | validation: 0.23776769594807812]
	TIME [epoch: 9.76 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2963411435101944		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 0.2963411435101944 | validation: 0.27523595160957515]
	TIME [epoch: 9.74 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.276157041687405		[learning rate: 0.0022757]
	Learning Rate: 0.0022757
	LOSS [training: 0.276157041687405 | validation: 0.2599010362811126]
	TIME [epoch: 9.75 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2688765203711022		[learning rate: 0.0022667]
	Learning Rate: 0.00226665
	LOSS [training: 0.2688765203711022 | validation: 0.2623871153000653]
	TIME [epoch: 9.75 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.29843099551574476		[learning rate: 0.0022576]
	Learning Rate: 0.00225764
	LOSS [training: 0.29843099551574476 | validation: 0.2773771324755502]
	TIME [epoch: 9.77 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.267542812110681		[learning rate: 0.0022487]
	Learning Rate: 0.00224866
	LOSS [training: 0.267542812110681 | validation: 0.273954044086272]
	TIME [epoch: 9.74 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.28205648126085825		[learning rate: 0.0022397]
	Learning Rate: 0.00223971
	LOSS [training: 0.28205648126085825 | validation: 0.26012129885900886]
	TIME [epoch: 9.75 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2647071485009198		[learning rate: 0.0022308]
	Learning Rate: 0.0022308
	LOSS [training: 0.2647071485009198 | validation: 0.2357174144292422]
	TIME [epoch: 9.76 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v11_20240711_141418/states/model_facs_dec1b_2dpca_v11_421.pth
	Model improved!!!
EPOCH 422/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24922806493645197		[learning rate: 0.0022219]
	Learning Rate: 0.00222193
	LOSS [training: 0.24922806493645197 | validation: 0.2483227755095891]
	TIME [epoch: 9.75 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2527091371123228		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.2527091371123228 | validation: 0.24725247483060406]
	TIME [epoch: 9.74 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2566940083864628		[learning rate: 0.0022043]
	Learning Rate: 0.00220429
	LOSS [training: 0.2566940083864628 | validation: 0.24452370114411984]
	TIME [epoch: 9.75 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24946888535787318		[learning rate: 0.0021955]
	Learning Rate: 0.00219553
	LOSS [training: 0.24946888535787318 | validation: 0.2519053956611227]
	TIME [epoch: 9.75 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26250384629380596		[learning rate: 0.0021868]
	Learning Rate: 0.00218679
	LOSS [training: 0.26250384629380596 | validation: 0.26901022927301244]
	TIME [epoch: 9.75 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2664386710460476		[learning rate: 0.0021781]
	Learning Rate: 0.0021781
	LOSS [training: 0.2664386710460476 | validation: 0.2616940017051281]
	TIME [epoch: 9.74 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24887287379333983		[learning rate: 0.0021694]
	Learning Rate: 0.00216943
	LOSS [training: 0.24887287379333983 | validation: 0.24423066312981434]
	TIME [epoch: 9.75 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26249086964117857		[learning rate: 0.0021608]
	Learning Rate: 0.0021608
	LOSS [training: 0.26249086964117857 | validation: 0.24306340185781453]
	TIME [epoch: 9.74 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2534183781485946		[learning rate: 0.0021522]
	Learning Rate: 0.00215221
	LOSS [training: 0.2534183781485946 | validation: 0.2406227847826005]
	TIME [epoch: 9.74 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2598294438478864		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.2598294438478864 | validation: 0.25690307088441583]
	TIME [epoch: 9.74 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26916958213134523		[learning rate: 0.0021351]
	Learning Rate: 0.00213512
	LOSS [training: 0.26916958213134523 | validation: 0.3157166808586832]
	TIME [epoch: 9.76 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.285566424978901		[learning rate: 0.0021266]
	Learning Rate: 0.00212663
	LOSS [training: 0.285566424978901 | validation: 0.2585464062755185]
	TIME [epoch: 9.74 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2541375706677487		[learning rate: 0.0021182]
	Learning Rate: 0.00211817
	LOSS [training: 0.2541375706677487 | validation: 0.24702605672502345]
	TIME [epoch: 9.74 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24751454009787585		[learning rate: 0.0021097]
	Learning Rate: 0.00210975
	LOSS [training: 0.24751454009787585 | validation: 0.2447971952628992]
	TIME [epoch: 9.73 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2705449511761333		[learning rate: 0.0021014]
	Learning Rate: 0.00210136
	LOSS [training: 0.2705449511761333 | validation: 0.27411184900337593]
	TIME [epoch: 9.76 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2715676783653076		[learning rate: 0.002093]
	Learning Rate: 0.002093
	LOSS [training: 0.2715676783653076 | validation: 0.28140339114177326]
	TIME [epoch: 9.74 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2724661655379583		[learning rate: 0.0020847]
	Learning Rate: 0.00208468
	LOSS [training: 0.2724661655379583 | validation: 0.35203533879725457]
	TIME [epoch: 9.74 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.27702411163680457		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.27702411163680457 | validation: 0.2522080561748457]
	TIME [epoch: 9.75 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2627996132292391		[learning rate: 0.0020681]
	Learning Rate: 0.00206813
	LOSS [training: 0.2627996132292391 | validation: 0.24730258790224618]
	TIME [epoch: 9.75 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2664097363140719		[learning rate: 0.0020599]
	Learning Rate: 0.0020599
	LOSS [training: 0.2664097363140719 | validation: 0.2567477486041751]
	TIME [epoch: 9.74 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2622702580723977		[learning rate: 0.0020517]
	Learning Rate: 0.00205171
	LOSS [training: 0.2622702580723977 | validation: 0.29502332748163507]
	TIME [epoch: 9.74 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.27609936522819833		[learning rate: 0.0020435]
	Learning Rate: 0.00204355
	LOSS [training: 0.27609936522819833 | validation: 0.25381987283379437]
	TIME [epoch: 9.75 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2593553707788042		[learning rate: 0.0020354]
	Learning Rate: 0.00203542
	LOSS [training: 0.2593553707788042 | validation: 0.2584905091113281]
	TIME [epoch: 9.74 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2772230411539572		[learning rate: 0.0020273]
	Learning Rate: 0.00202732
	LOSS [training: 0.2772230411539572 | validation: 0.30861769727932725]
	TIME [epoch: 9.73 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.28239341518395134		[learning rate: 0.0020193]
	Learning Rate: 0.00201926
	LOSS [training: 0.28239341518395134 | validation: 0.258372991135179]
	TIME [epoch: 9.74 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26082409158781317		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 0.26082409158781317 | validation: 0.2844012384686835]
	TIME [epoch: 9.75 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2648689299769885		[learning rate: 0.0020032]
	Learning Rate: 0.00200323
	LOSS [training: 0.2648689299769885 | validation: 0.2516871894678848]
	TIME [epoch: 9.75 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26425658943874986		[learning rate: 0.0019953]
	Learning Rate: 0.00199526
	LOSS [training: 0.26425658943874986 | validation: 0.2599793593053125]
	TIME [epoch: 9.74 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26713368679068267		[learning rate: 0.0019873]
	Learning Rate: 0.00198733
	LOSS [training: 0.26713368679068267 | validation: 0.2921958237300691]
	TIME [epoch: 9.76 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3111189631248319		[learning rate: 0.0019794]
	Learning Rate: 0.00197942
	LOSS [training: 0.3111189631248319 | validation: 0.32390221670160224]
	TIME [epoch: 9.75 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.28407629060157025		[learning rate: 0.0019715]
	Learning Rate: 0.00197155
	LOSS [training: 0.28407629060157025 | validation: 0.27132618596591973]
	TIME [epoch: 9.74 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2675324622542876		[learning rate: 0.0019637]
	Learning Rate: 0.00196371
	LOSS [training: 0.2675324622542876 | validation: 0.26189064233853826]
	TIME [epoch: 9.73 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2618305593117737		[learning rate: 0.0019559]
	Learning Rate: 0.0019559
	LOSS [training: 0.2618305593117737 | validation: 0.25838662682877744]
	TIME [epoch: 9.75 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2700654013904325		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 0.2700654013904325 | validation: 0.30502738856269296]
	TIME [epoch: 9.74 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.27610827916410796		[learning rate: 0.0019404]
	Learning Rate: 0.00194037
	LOSS [training: 0.27610827916410796 | validation: 0.25290298948700185]
	TIME [epoch: 9.74 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.264955372869963		[learning rate: 0.0019327]
	Learning Rate: 0.00193265
	LOSS [training: 0.264955372869963 | validation: 0.25634401411550356]
	TIME [epoch: 9.73 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25659308564350186		[learning rate: 0.001925]
	Learning Rate: 0.00192497
	LOSS [training: 0.25659308564350186 | validation: 0.2596579407526165]
	TIME [epoch: 9.75 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2753510285294568		[learning rate: 0.0019173]
	Learning Rate: 0.00191731
	LOSS [training: 0.2753510285294568 | validation: 0.2908814486457474]
	TIME [epoch: 9.74 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2732138962373462		[learning rate: 0.0019097]
	Learning Rate: 0.00190968
	LOSS [training: 0.2732138962373462 | validation: 0.2610077253718978]
	TIME [epoch: 9.74 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25676202713559193		[learning rate: 0.0019021]
	Learning Rate: 0.00190209
	LOSS [training: 0.25676202713559193 | validation: 0.25206145012873843]
	TIME [epoch: 9.75 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2825116696988477		[learning rate: 0.0018945]
	Learning Rate: 0.00189452
	LOSS [training: 0.2825116696988477 | validation: 0.2669552140164422]
	TIME [epoch: 9.75 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2676303694756956		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.2676303694756956 | validation: 0.27104714678066705]
	TIME [epoch: 9.74 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2826767140420993		[learning rate: 0.0018795]
	Learning Rate: 0.00187948
	LOSS [training: 0.2826767140420993 | validation: 0.34706535418408685]
	TIME [epoch: 9.74 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2965626038781324		[learning rate: 0.001872]
	Learning Rate: 0.00187201
	LOSS [training: 0.2965626038781324 | validation: 0.2673095469670711]
	TIME [epoch: 9.76 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2627261192314067		[learning rate: 0.0018646]
	Learning Rate: 0.00186456
	LOSS [training: 0.2627261192314067 | validation: 0.2622767510380192]
	TIME [epoch: 9.74 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26245037255348463		[learning rate: 0.0018571]
	Learning Rate: 0.00185715
	LOSS [training: 0.26245037255348463 | validation: 0.34178570336233943]
	TIME [epoch: 9.74 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.29949744433075454		[learning rate: 0.0018498]
	Learning Rate: 0.00184976
	LOSS [training: 0.29949744433075454 | validation: 0.2840388606209897]
	TIME [epoch: 9.74 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2706886795449722		[learning rate: 0.0018424]
	Learning Rate: 0.0018424
	LOSS [training: 0.2706886795449722 | validation: 0.2799667754790018]
	TIME [epoch: 9.75 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.27524363295981336		[learning rate: 0.0018351]
	Learning Rate: 0.00183508
	LOSS [training: 0.27524363295981336 | validation: 0.25655070871775687]
	TIME [epoch: 9.74 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.28032409480127995		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.28032409480127995 | validation: 0.28421221470462676]
	TIME [epoch: 9.74 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.28271874727596863		[learning rate: 0.0018205]
	Learning Rate: 0.00182051
	LOSS [training: 0.28271874727596863 | validation: 0.2733709640504725]
	TIME [epoch: 9.75 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2692774977208438		[learning rate: 0.0018133]
	Learning Rate: 0.00181327
	LOSS [training: 0.2692774977208438 | validation: 0.26484361182538113]
	TIME [epoch: 9.75 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26865793376610464		[learning rate: 0.0018061]
	Learning Rate: 0.00180605
	LOSS [training: 0.26865793376610464 | validation: 0.2686308801079593]
	TIME [epoch: 9.74 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.27672717879346165		[learning rate: 0.0017989]
	Learning Rate: 0.00179887
	LOSS [training: 0.27672717879346165 | validation: 0.27459608600229124]
	TIME [epoch: 9.74 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2690396621690066		[learning rate: 0.0017917]
	Learning Rate: 0.00179172
	LOSS [training: 0.2690396621690066 | validation: 0.2777575670951405]
	TIME [epoch: 9.76 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.27265492544453634		[learning rate: 0.0017846]
	Learning Rate: 0.00178459
	LOSS [training: 0.27265492544453634 | validation: 0.2962997375960532]
	TIME [epoch: 9.74 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.27475247905349415		[learning rate: 0.0017775]
	Learning Rate: 0.00177749
	LOSS [training: 0.27475247905349415 | validation: 0.26375051610512673]
	TIME [epoch: 9.74 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2662382560498925		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.2662382560498925 | validation: 0.28732886946358194]
	TIME [epoch: 9.74 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2666322886995154		[learning rate: 0.0017634]
	Learning Rate: 0.00176338
	LOSS [training: 0.2666322886995154 | validation: 0.25409117791872127]
	TIME [epoch: 9.76 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2665704369999792		[learning rate: 0.0017564]
	Learning Rate: 0.00175637
	LOSS [training: 0.2665704369999792 | validation: 0.26218169277989734]
	TIME [epoch: 9.74 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2674654522564313		[learning rate: 0.0017494]
	Learning Rate: 0.00174938
	LOSS [training: 0.2674654522564313 | validation: 0.2937133738264583]
	TIME [epoch: 9.75 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2742552498893994		[learning rate: 0.0017424]
	Learning Rate: 0.00174242
	LOSS [training: 0.2742552498893994 | validation: 0.25469588696649315]
	TIME [epoch: 9.75 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2642811593278958		[learning rate: 0.0017355]
	Learning Rate: 0.00173549
	LOSS [training: 0.2642811593278958 | validation: 0.2626610657016698]
	TIME [epoch: 9.75 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26053257722492895		[learning rate: 0.0017286]
	Learning Rate: 0.00172859
	LOSS [training: 0.26053257722492895 | validation: 0.27447619228892883]
	TIME [epoch: 9.74 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26108843438648777		[learning rate: 0.0017217]
	Learning Rate: 0.00172172
	LOSS [training: 0.26108843438648777 | validation: 0.27060350767154173]
	TIME [epoch: 9.74 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25837091866095885		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 0.25837091866095885 | validation: 0.26813762088600407]
	TIME [epoch: 9.76 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2602724238439691		[learning rate: 0.001708]
	Learning Rate: 0.00170805
	LOSS [training: 0.2602724238439691 | validation: 0.27447375413951436]
	TIME [epoch: 9.74 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2583713261510118		[learning rate: 0.0017013]
	Learning Rate: 0.00170125
	LOSS [training: 0.2583713261510118 | validation: 0.2572911620296484]
	TIME [epoch: 9.74 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.27317726946307747		[learning rate: 0.0016945]
	Learning Rate: 0.00169449
	LOSS [training: 0.27317726946307747 | validation: 0.24805604017889574]
	TIME [epoch: 9.74 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2613971287582906		[learning rate: 0.0016877]
	Learning Rate: 0.00168775
	LOSS [training: 0.2613971287582906 | validation: 0.2524378361807832]
	TIME [epoch: 9.75 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25381188380829006		[learning rate: 0.001681]
	Learning Rate: 0.00168104
	LOSS [training: 0.25381188380829006 | validation: 0.26816585248691455]
	TIME [epoch: 9.74 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26565132873479		[learning rate: 0.0016743]
	Learning Rate: 0.00167435
	LOSS [training: 0.26565132873479 | validation: 0.27670738474935686]
	TIME [epoch: 9.74 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2782017868769057		[learning rate: 0.0016677]
	Learning Rate: 0.00166769
	LOSS [training: 0.2782017868769057 | validation: 0.2566836076123691]
	TIME [epoch: 9.75 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26138066701747753		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.26138066701747753 | validation: 0.2651527157629868]
	TIME [epoch: 9.74 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.27263385991511085		[learning rate: 0.0016545]
	Learning Rate: 0.00165445
	LOSS [training: 0.27263385991511085 | validation: 0.27755679922339704]
	TIME [epoch: 9.74 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2748244713008302		[learning rate: 0.0016479]
	Learning Rate: 0.00164787
	LOSS [training: 0.2748244713008302 | validation: 0.25919186577313097]
	TIME [epoch: 9.73 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.27080549233712065		[learning rate: 0.0016413]
	Learning Rate: 0.00164132
	LOSS [training: 0.27080549233712065 | validation: 0.2670397849192896]
	TIME [epoch: 9.76 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2606812612792698		[learning rate: 0.0016348]
	Learning Rate: 0.00163479
	LOSS [training: 0.2606812612792698 | validation: 0.2634567501720698]
	TIME [epoch: 9.74 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2571873964816598		[learning rate: 0.0016283]
	Learning Rate: 0.00162829
	LOSS [training: 0.2571873964816598 | validation: 0.27465243323773886]
	TIME [epoch: 9.74 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2676614242582037		[learning rate: 0.0016218]
	Learning Rate: 0.00162181
	LOSS [training: 0.2676614242582037 | validation: 0.2552986771720722]
	TIME [epoch: 44.4 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25229330435243985		[learning rate: 0.0016154]
	Learning Rate: 0.00161536
	LOSS [training: 0.25229330435243985 | validation: 0.25313094311330764]
	TIME [epoch: 18.9 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2537283426208989		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 0.2537283426208989 | validation: 0.25095757425615495]
	TIME [epoch: 18.8 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25177877597419607		[learning rate: 0.0016025]
	Learning Rate: 0.00160254
	LOSS [training: 0.25177877597419607 | validation: 0.27405327307944016]
	TIME [epoch: 18.9 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2618096770054486		[learning rate: 0.0015962]
	Learning Rate: 0.00159616
	LOSS [training: 0.2618096770054486 | validation: 0.27284353030563313]
	TIME [epoch: 18.8 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2572790705331921		[learning rate: 0.0015898]
	Learning Rate: 0.00158981
	LOSS [training: 0.2572790705331921 | validation: 0.24683558379108872]
	TIME [epoch: 18.8 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.256319520571233		[learning rate: 0.0015835]
	Learning Rate: 0.00158349
	LOSS [training: 0.256319520571233 | validation: 0.25475509443334543]
	TIME [epoch: 18.8 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2539078241819721		[learning rate: 0.0015772]
	Learning Rate: 0.00157719
	LOSS [training: 0.2539078241819721 | validation: 0.24963869433174918]
	TIME [epoch: 18.9 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25956202744272727		[learning rate: 0.0015709]
	Learning Rate: 0.00157092
	LOSS [training: 0.25956202744272727 | validation: 0.2553280810717144]
	TIME [epoch: 18.8 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2658320990723632		[learning rate: 0.0015647]
	Learning Rate: 0.00156467
	LOSS [training: 0.2658320990723632 | validation: 0.2582600436674617]
	TIME [epoch: 18.9 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2545143781190965		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.2545143781190965 | validation: 0.25992918415971866]
	TIME [epoch: 18.8 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26231553988511425		[learning rate: 0.0015522]
	Learning Rate: 0.00155225
	LOSS [training: 0.26231553988511425 | validation: 0.2599332185911943]
	TIME [epoch: 18.8 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2706042255464473		[learning rate: 0.0015461]
	Learning Rate: 0.00154608
	LOSS [training: 0.2706042255464473 | validation: 0.2607040187981464]
	TIME [epoch: 18.8 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25434275716419125		[learning rate: 0.0015399]
	Learning Rate: 0.00153993
	LOSS [training: 0.25434275716419125 | validation: 0.253821765301478]
	TIME [epoch: 18.8 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26831714916932364		[learning rate: 0.0015338]
	Learning Rate: 0.0015338
	LOSS [training: 0.26831714916932364 | validation: 0.2712815040443653]
	TIME [epoch: 18.8 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25998914128757633		[learning rate: 0.0015277]
	Learning Rate: 0.0015277
	LOSS [training: 0.25998914128757633 | validation: 0.2589002477115729]
	TIME [epoch: 18.8 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.263778965957363		[learning rate: 0.0015216]
	Learning Rate: 0.00152163
	LOSS [training: 0.263778965957363 | validation: 0.2679413249102439]
	TIME [epoch: 18.8 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2625307308423808		[learning rate: 0.0015156]
	Learning Rate: 0.00151557
	LOSS [training: 0.2625307308423808 | validation: 0.2494243201594431]
	TIME [epoch: 18.8 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25363716140927545		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.25363716140927545 | validation: 0.24713528243731608]
	TIME [epoch: 18.8 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26592627178022954		[learning rate: 0.0015035]
	Learning Rate: 0.00150354
	LOSS [training: 0.26592627178022954 | validation: 0.2496022014222182]
	TIME [epoch: 18.8 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26006591852692706		[learning rate: 0.0014976]
	Learning Rate: 0.00149756
	LOSS [training: 0.26006591852692706 | validation: 0.26566515854197276]
	TIME [epoch: 18.8 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24881063401438233		[learning rate: 0.0014916]
	Learning Rate: 0.00149161
	LOSS [training: 0.24881063401438233 | validation: 0.25049536144584506]
	TIME [epoch: 18.8 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2614647687320031		[learning rate: 0.0014857]
	Learning Rate: 0.00148567
	LOSS [training: 0.2614647687320031 | validation: 0.26389967884630994]
	TIME [epoch: 18.8 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24980899707496126		[learning rate: 0.0014798]
	Learning Rate: 0.00147976
	LOSS [training: 0.24980899707496126 | validation: 0.25067963615658573]
	TIME [epoch: 18.8 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26560206268007636		[learning rate: 0.0014739]
	Learning Rate: 0.00147388
	LOSS [training: 0.26560206268007636 | validation: 0.2671862399598891]
	TIME [epoch: 18.8 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2546383385428392		[learning rate: 0.001468]
	Learning Rate: 0.00146802
	LOSS [training: 0.2546383385428392 | validation: 0.2637598338421402]
	TIME [epoch: 18.8 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.264010994295376		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.264010994295376 | validation: 0.2629085023626671]
	TIME [epoch: 18.8 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26043970781647463		[learning rate: 0.0014564]
	Learning Rate: 0.00145636
	LOSS [training: 0.26043970781647463 | validation: 0.25765537630081636]
	TIME [epoch: 18.8 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2532083001592865		[learning rate: 0.0014506]
	Learning Rate: 0.00145057
	LOSS [training: 0.2532083001592865 | validation: 0.2610516489832447]
	TIME [epoch: 18.8 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26421915726898926		[learning rate: 0.0014448]
	Learning Rate: 0.0014448
	LOSS [training: 0.26421915726898926 | validation: 0.24888837213943157]
	TIME [epoch: 18.8 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2613869242494608		[learning rate: 0.0014391]
	Learning Rate: 0.00143905
	LOSS [training: 0.2613869242494608 | validation: 0.26323179822906473]
	TIME [epoch: 18.8 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25749731377315055		[learning rate: 0.0014333]
	Learning Rate: 0.00143333
	LOSS [training: 0.25749731377315055 | validation: 0.254443825448166]
	TIME [epoch: 18.8 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2660730076260791		[learning rate: 0.0014276]
	Learning Rate: 0.00142763
	LOSS [training: 0.2660730076260791 | validation: 0.26023321091755874]
	TIME [epoch: 18.8 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26100207463498726		[learning rate: 0.001422]
	Learning Rate: 0.00142195
	LOSS [training: 0.26100207463498726 | validation: 0.2774014539176262]
	TIME [epoch: 18.8 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25697121636216097		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.25697121636216097 | validation: 0.2655005267955274]
	TIME [epoch: 18.8 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2592247875582961		[learning rate: 0.0014107]
	Learning Rate: 0.00141066
	LOSS [training: 0.2592247875582961 | validation: 0.26290869240211145]
	TIME [epoch: 18.8 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.27563597287951125		[learning rate: 0.0014051]
	Learning Rate: 0.00140505
	LOSS [training: 0.27563597287951125 | validation: 0.2714058640417806]
	TIME [epoch: 18.8 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3123399499599997		[learning rate: 0.0013995]
	Learning Rate: 0.00139946
	LOSS [training: 0.3123399499599997 | validation: 0.27589805473502294]
	TIME [epoch: 18.8 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2699502428675308		[learning rate: 0.0013939]
	Learning Rate: 0.0013939
	LOSS [training: 0.2699502428675308 | validation: 0.2509749936847625]
	TIME [epoch: 18.8 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25402732824309254		[learning rate: 0.0013884]
	Learning Rate: 0.00138835
	LOSS [training: 0.25402732824309254 | validation: 0.247606416240086]
	TIME [epoch: 18.8 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24549292666508166		[learning rate: 0.0013828]
	Learning Rate: 0.00138283
	LOSS [training: 0.24549292666508166 | validation: 0.2503566724262801]
	TIME [epoch: 18.8 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2377195014924666		[learning rate: 0.0013773]
	Learning Rate: 0.00137733
	LOSS [training: 0.2377195014924666 | validation: 0.2508904163239232]
	TIME [epoch: 18.8 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24968389757362303		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 0.24968389757362303 | validation: 0.2521888369681712]
	TIME [epoch: 18.8 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2629805658168378		[learning rate: 0.0013664]
	Learning Rate: 0.0013664
	LOSS [training: 0.2629805658168378 | validation: 0.2646795131356095]
	TIME [epoch: 18.8 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26834871930553433		[learning rate: 0.001361]
	Learning Rate: 0.00136096
	LOSS [training: 0.26834871930553433 | validation: 0.2393684201303119]
	TIME [epoch: 18.8 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2653961978508251		[learning rate: 0.0013555]
	Learning Rate: 0.00135555
	LOSS [training: 0.2653961978508251 | validation: 0.243805767937391]
	TIME [epoch: 18.8 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2486382955372849		[learning rate: 0.0013502]
	Learning Rate: 0.00135016
	LOSS [training: 0.2486382955372849 | validation: 0.25417665245066917]
	TIME [epoch: 18.8 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2508934747836413		[learning rate: 0.0013448]
	Learning Rate: 0.00134479
	LOSS [training: 0.2508934747836413 | validation: 0.25848273408680106]
	TIME [epoch: 18.8 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24627385931576906		[learning rate: 0.0013394]
	Learning Rate: 0.00133944
	LOSS [training: 0.24627385931576906 | validation: 0.24562090511874146]
	TIME [epoch: 18.8 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24876489618063818		[learning rate: 0.0013341]
	Learning Rate: 0.00133411
	LOSS [training: 0.24876489618063818 | validation: 0.252191909115987]
	TIME [epoch: 18.8 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2586569143613573		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.2586569143613573 | validation: 0.2500884303039934]
	TIME [epoch: 18.8 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2466553830255823		[learning rate: 0.0013235]
	Learning Rate: 0.00132352
	LOSS [training: 0.2466553830255823 | validation: 0.26602509255494955]
	TIME [epoch: 18.8 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2649913457962842		[learning rate: 0.0013183]
	Learning Rate: 0.00131826
	LOSS [training: 0.2649913457962842 | validation: 0.2651525161630114]
	TIME [epoch: 18.8 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2601972958085869		[learning rate: 0.001313]
	Learning Rate: 0.00131301
	LOSS [training: 0.2601972958085869 | validation: 0.2550742040463862]
	TIME [epoch: 18.8 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2506010781387717		[learning rate: 0.0013078]
	Learning Rate: 0.00130779
	LOSS [training: 0.2506010781387717 | validation: 0.26497656761434885]
	TIME [epoch: 18.8 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2541445274513762		[learning rate: 0.0013026]
	Learning Rate: 0.00130259
	LOSS [training: 0.2541445274513762 | validation: 0.25238979408896434]
	TIME [epoch: 18.8 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25165531200278773		[learning rate: 0.0012974]
	Learning Rate: 0.00129741
	LOSS [training: 0.25165531200278773 | validation: 0.25453156966765705]
	TIME [epoch: 18.8 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2524385139472779		[learning rate: 0.0012922]
	Learning Rate: 0.00129225
	LOSS [training: 0.2524385139472779 | validation: 0.251155306334789]
	TIME [epoch: 18.8 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24507792522770622		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 0.24507792522770622 | validation: 0.24764365292839674]
	TIME [epoch: 18.8 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2546392506985981		[learning rate: 0.001282]
	Learning Rate: 0.00128199
	LOSS [training: 0.2546392506985981 | validation: 0.2487060966741232]
	TIME [epoch: 18.8 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25290738297826265		[learning rate: 0.0012769]
	Learning Rate: 0.00127689
	LOSS [training: 0.25290738297826265 | validation: 0.26302779668690573]
	TIME [epoch: 18.8 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2557587674930696		[learning rate: 0.0012718]
	Learning Rate: 0.00127181
	LOSS [training: 0.2557587674930696 | validation: 0.24121006666011796]
	TIME [epoch: 18.8 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25454523762582215		[learning rate: 0.0012668]
	Learning Rate: 0.00126675
	LOSS [training: 0.25454523762582215 | validation: 0.24674509185357762]
	TIME [epoch: 18.8 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.273813187169736		[learning rate: 0.0012617]
	Learning Rate: 0.00126172
	LOSS [training: 0.273813187169736 | validation: 0.30025848932640864]
	TIME [epoch: 18.9 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.27225735336565654		[learning rate: 0.0012567]
	Learning Rate: 0.0012567
	LOSS [training: 0.27225735336565654 | validation: 0.2507324691878686]
	TIME [epoch: 18.8 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24250735293466935		[learning rate: 0.0012517]
	Learning Rate: 0.0012517
	LOSS [training: 0.24250735293466935 | validation: 0.23888384980387034]
	TIME [epoch: 18.8 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25381626532502577		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 0.25381626532502577 | validation: 0.24873592078676993]
	TIME [epoch: 18.8 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24777761592744524		[learning rate: 0.0012418]
	Learning Rate: 0.00124176
	LOSS [training: 0.24777761592744524 | validation: 0.26014508815112103]
	TIME [epoch: 18.8 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25959341638849764		[learning rate: 0.0012368]
	Learning Rate: 0.00123682
	LOSS [training: 0.25959341638849764 | validation: 0.27124593338523545]
	TIME [epoch: 18.8 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2724270134250133		[learning rate: 0.0012319]
	Learning Rate: 0.0012319
	LOSS [training: 0.2724270134250133 | validation: 0.2646665642050081]
	TIME [epoch: 18.8 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.259356341509266		[learning rate: 0.001227]
	Learning Rate: 0.001227
	LOSS [training: 0.259356341509266 | validation: 0.25255710774527695]
	TIME [epoch: 18.8 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24067003704412182		[learning rate: 0.0012221]
	Learning Rate: 0.00122212
	LOSS [training: 0.24067003704412182 | validation: 0.23703713294321851]
	TIME [epoch: 18.8 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24051574740053447		[learning rate: 0.0012173]
	Learning Rate: 0.00121726
	LOSS [training: 0.24051574740053447 | validation: 0.24054849807858228]
	TIME [epoch: 18.8 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24096902707007128		[learning rate: 0.0012124]
	Learning Rate: 0.00121242
	LOSS [training: 0.24096902707007128 | validation: 0.23857328172147332]
	TIME [epoch: 18.8 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24721404549745202		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 0.24721404549745202 | validation: 0.24521275934414125]
	TIME [epoch: 18.8 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2502466814094886		[learning rate: 0.0012028]
	Learning Rate: 0.0012028
	LOSS [training: 0.2502466814094886 | validation: 0.23831624261600562]
	TIME [epoch: 18.8 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2520476866358784		[learning rate: 0.001198]
	Learning Rate: 0.00119801
	LOSS [training: 0.2520476866358784 | validation: 0.23308573854268513]
	TIME [epoch: 18.8 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v11_20240711_141418/states/model_facs_dec1b_2dpca_v11_577.pth
	Model improved!!!
EPOCH 578/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25107302055423797		[learning rate: 0.0011932]
	Learning Rate: 0.00119325
	LOSS [training: 0.25107302055423797 | validation: 0.25707867678669194]
	TIME [epoch: 18.8 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25929954979592423		[learning rate: 0.0011885]
	Learning Rate: 0.0011885
	LOSS [training: 0.25929954979592423 | validation: 0.24834522520386138]
	TIME [epoch: 18.8 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25195042066603235		[learning rate: 0.0011838]
	Learning Rate: 0.00118378
	LOSS [training: 0.25195042066603235 | validation: 0.24537173028397402]
	TIME [epoch: 18.8 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24358217179240688		[learning rate: 0.0011791]
	Learning Rate: 0.00117907
	LOSS [training: 0.24358217179240688 | validation: 0.24812592452833693]
	TIME [epoch: 18.8 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2568601545154279		[learning rate: 0.0011744]
	Learning Rate: 0.00117438
	LOSS [training: 0.2568601545154279 | validation: 0.2738692132298365]
	TIME [epoch: 18.8 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25882602115490827		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 0.25882602115490827 | validation: 0.26398306352013223]
	TIME [epoch: 18.8 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2679770762489655		[learning rate: 0.0011651]
	Learning Rate: 0.00116505
	LOSS [training: 0.2679770762489655 | validation: 0.28081314828797205]
	TIME [epoch: 18.8 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26897315774507313		[learning rate: 0.0011604]
	Learning Rate: 0.00116042
	LOSS [training: 0.26897315774507313 | validation: 0.25867216628092443]
	TIME [epoch: 18.8 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26070499679708625		[learning rate: 0.0011558]
	Learning Rate: 0.00115581
	LOSS [training: 0.26070499679708625 | validation: 0.2529026034351484]
	TIME [epoch: 18.8 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24843946876427253		[learning rate: 0.0011512]
	Learning Rate: 0.00115121
	LOSS [training: 0.24843946876427253 | validation: 0.24576306345530236]
	TIME [epoch: 18.8 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2483978190565042		[learning rate: 0.0011466]
	Learning Rate: 0.00114663
	LOSS [training: 0.2483978190565042 | validation: 0.24928230787067412]
	TIME [epoch: 18.8 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2428109246959422		[learning rate: 0.0011421]
	Learning Rate: 0.00114207
	LOSS [training: 0.2428109246959422 | validation: 0.2437522128966024]
	TIME [epoch: 18.8 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2548918756252801		[learning rate: 0.0011375]
	Learning Rate: 0.00113753
	LOSS [training: 0.2548918756252801 | validation: 0.2511577308122135]
	TIME [epoch: 18.8 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25236977254172516		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.25236977254172516 | validation: 0.24268518058741143]
	TIME [epoch: 18.8 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24193400451566255		[learning rate: 0.0011285]
	Learning Rate: 0.0011285
	LOSS [training: 0.24193400451566255 | validation: 0.23716392748388632]
	TIME [epoch: 18.8 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24628670075707573		[learning rate: 0.001124]
	Learning Rate: 0.00112401
	LOSS [training: 0.24628670075707573 | validation: 0.23947985110928943]
	TIME [epoch: 18.8 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2468962919170966		[learning rate: 0.0011195]
	Learning Rate: 0.00111954
	LOSS [training: 0.2468962919170966 | validation: 0.2577470254346374]
	TIME [epoch: 18.8 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26582622371838394		[learning rate: 0.0011151]
	Learning Rate: 0.00111508
	LOSS [training: 0.26582622371838394 | validation: 0.27621422447448907]
	TIME [epoch: 18.8 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26199036422084354		[learning rate: 0.0011106]
	Learning Rate: 0.00111065
	LOSS [training: 0.26199036422084354 | validation: 0.2585435169581795]
	TIME [epoch: 18.8 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2444423950253537		[learning rate: 0.0011062]
	Learning Rate: 0.00110623
	LOSS [training: 0.2444423950253537 | validation: 0.2454732596051617]
	TIME [epoch: 18.8 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2501242939561063		[learning rate: 0.0011018]
	Learning Rate: 0.00110183
	LOSS [training: 0.2501242939561063 | validation: 0.25070375100888287]
	TIME [epoch: 18.8 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24896260927272257		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 0.24896260927272257 | validation: 0.2569576820212046]
	TIME [epoch: 18.8 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24537105215637434		[learning rate: 0.0010931]
	Learning Rate: 0.00109309
	LOSS [training: 0.24537105215637434 | validation: 0.25139146358571585]
	TIME [epoch: 18.8 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2457775820283662		[learning rate: 0.0010887]
	Learning Rate: 0.00108874
	LOSS [training: 0.2457775820283662 | validation: 0.25159280611779844]
	TIME [epoch: 18.8 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25771296967486057		[learning rate: 0.0010844]
	Learning Rate: 0.00108441
	LOSS [training: 0.25771296967486057 | validation: 0.2520528975153882]
	TIME [epoch: 18.8 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2512188031035957		[learning rate: 0.0010801]
	Learning Rate: 0.00108009
	LOSS [training: 0.2512188031035957 | validation: 0.2528447253387994]
	TIME [epoch: 18.8 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.260863145329376		[learning rate: 0.0010758]
	Learning Rate: 0.0010758
	LOSS [training: 0.260863145329376 | validation: 0.2688331636895788]
	TIME [epoch: 18.8 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2595412481067376		[learning rate: 0.0010715]
	Learning Rate: 0.00107152
	LOSS [training: 0.2595412481067376 | validation: 0.2567327379025428]
	TIME [epoch: 18.8 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24880383078585666		[learning rate: 0.0010673]
	Learning Rate: 0.00106726
	LOSS [training: 0.24880383078585666 | validation: 0.2393881217178248]
	TIME [epoch: 18.8 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25661473572535987		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 0.25661473572535987 | validation: 0.2453209646853567]
	TIME [epoch: 18.8 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24953814618130452		[learning rate: 0.0010588]
	Learning Rate: 0.00105878
	LOSS [training: 0.24953814618130452 | validation: 0.25840074985614986]
	TIME [epoch: 18.8 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2502168512746286		[learning rate: 0.0010546]
	Learning Rate: 0.00105457
	LOSS [training: 0.2502168512746286 | validation: 0.2489030735046774]
	TIME [epoch: 18.8 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24787836359061688		[learning rate: 0.0010504]
	Learning Rate: 0.00105038
	LOSS [training: 0.24787836359061688 | validation: 0.25521174492158705]
	TIME [epoch: 18.8 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24994295153040888		[learning rate: 0.0010462]
	Learning Rate: 0.0010462
	LOSS [training: 0.24994295153040888 | validation: 0.24980982789029973]
	TIME [epoch: 18.8 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2591813422081907		[learning rate: 0.001042]
	Learning Rate: 0.00104204
	LOSS [training: 0.2591813422081907 | validation: 0.25182592143349386]
	TIME [epoch: 18.8 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26507760522777374		[learning rate: 0.0010379]
	Learning Rate: 0.0010379
	LOSS [training: 0.26507760522777374 | validation: 0.25540389681266634]
	TIME [epoch: 18.8 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2497256010612361		[learning rate: 0.0010338]
	Learning Rate: 0.00103377
	LOSS [training: 0.2497256010612361 | validation: 0.24879880463732756]
	TIME [epoch: 18.8 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26647911312483497		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 0.26647911312483497 | validation: 0.2602670627766038]
	TIME [epoch: 18.8 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26965777711391153		[learning rate: 0.0010256]
	Learning Rate: 0.00102556
	LOSS [training: 0.26965777711391153 | validation: 0.25197873479955585]
	TIME [epoch: 18.8 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25868636544118956		[learning rate: 0.0010215]
	Learning Rate: 0.00102148
	LOSS [training: 0.25868636544118956 | validation: 0.2692026670815765]
	TIME [epoch: 18.8 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25707271842039614		[learning rate: 0.0010174]
	Learning Rate: 0.00101742
	LOSS [training: 0.25707271842039614 | validation: 0.2492197982695835]
	TIME [epoch: 18.8 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2571426749961583		[learning rate: 0.0010134]
	Learning Rate: 0.00101337
	LOSS [training: 0.2571426749961583 | validation: 0.2694655728484415]
	TIME [epoch: 18.8 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25456473983905153		[learning rate: 0.0010093]
	Learning Rate: 0.00100934
	LOSS [training: 0.25456473983905153 | validation: 0.25810960864911864]
	TIME [epoch: 18.8 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25483504648354954		[learning rate: 0.0010053]
	Learning Rate: 0.00100533
	LOSS [training: 0.25483504648354954 | validation: 0.250328003982979]
	TIME [epoch: 18.8 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2555293745816847		[learning rate: 0.0010013]
	Learning Rate: 0.00100133
	LOSS [training: 0.2555293745816847 | validation: 0.25154399443965153]
	TIME [epoch: 18.8 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2545040738476136		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 0.2545040738476136 | validation: 0.25546256416531593]
	TIME [epoch: 18.8 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24847886442792383		[learning rate: 0.00099338]
	Learning Rate: 0.00099338
	LOSS [training: 0.24847886442792383 | validation: 0.24736984985817542]
	TIME [epoch: 18.8 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24860039421225036		[learning rate: 0.00098943]
	Learning Rate: 0.000989429
	LOSS [training: 0.24860039421225036 | validation: 0.2513226893597176]
	TIME [epoch: 18.8 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.251158106986161		[learning rate: 0.00098549]
	Learning Rate: 0.000985494
	LOSS [training: 0.251158106986161 | validation: 0.24690577215970744]
	TIME [epoch: 18.8 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25347717824786414		[learning rate: 0.00098157]
	Learning Rate: 0.000981574
	LOSS [training: 0.25347717824786414 | validation: 0.2474155676174795]
	TIME [epoch: 18.8 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2591048400005909		[learning rate: 0.00097767]
	Learning Rate: 0.00097767
	LOSS [training: 0.2591048400005909 | validation: 0.2435134210970568]
	TIME [epoch: 18.8 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24603259240243133		[learning rate: 0.00097378]
	Learning Rate: 0.000973782
	LOSS [training: 0.24603259240243133 | validation: 0.23908673318828438]
	TIME [epoch: 18.8 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.240698737165136		[learning rate: 0.00096991]
	Learning Rate: 0.000969909
	LOSS [training: 0.240698737165136 | validation: 0.2439728891751991]
	TIME [epoch: 18.8 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24392292563809415		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.24392292563809415 | validation: 0.24989140683768718]
	TIME [epoch: 18.8 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24874541841880257		[learning rate: 0.00096221]
	Learning Rate: 0.000962209
	LOSS [training: 0.24874541841880257 | validation: 0.239396699426438]
	TIME [epoch: 18.8 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2444849099802304		[learning rate: 0.00095838]
	Learning Rate: 0.000958382
	LOSS [training: 0.2444849099802304 | validation: 0.2490837197994707]
	TIME [epoch: 18.8 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25468430935877895		[learning rate: 0.00095457]
	Learning Rate: 0.00095457
	LOSS [training: 0.25468430935877895 | validation: 0.2559612746487347]
	TIME [epoch: 18.8 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24118932539673027		[learning rate: 0.00095077]
	Learning Rate: 0.000950773
	LOSS [training: 0.24118932539673027 | validation: 0.24337217822024076]
	TIME [epoch: 18.8 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2502061183989089		[learning rate: 0.00094699]
	Learning Rate: 0.000946992
	LOSS [training: 0.2502061183989089 | validation: 0.24732530996862212]
	TIME [epoch: 18.8 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24609086386438442		[learning rate: 0.00094323]
	Learning Rate: 0.000943225
	LOSS [training: 0.24609086386438442 | validation: 0.24111313647360805]
	TIME [epoch: 18.8 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25893059770420895		[learning rate: 0.00093947]
	Learning Rate: 0.000939474
	LOSS [training: 0.25893059770420895 | validation: 0.24251774677380977]
	TIME [epoch: 18.8 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25544186911118744		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.25544186911118744 | validation: 0.23976912629962888]
	TIME [epoch: 18.8 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2532740586181583		[learning rate: 0.00093202]
	Learning Rate: 0.000932015
	LOSS [training: 0.2532740586181583 | validation: 0.24803446650714028]
	TIME [epoch: 18.8 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2460855047608835		[learning rate: 0.00092831]
	Learning Rate: 0.000928309
	LOSS [training: 0.2460855047608835 | validation: 0.24995000779529702]
	TIME [epoch: 18.8 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24297186095252915		[learning rate: 0.00092462]
	Learning Rate: 0.000924616
	LOSS [training: 0.24297186095252915 | validation: 0.2538193860351357]
	TIME [epoch: 18.8 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25990860420852546		[learning rate: 0.00092094]
	Learning Rate: 0.000920939
	LOSS [training: 0.25990860420852546 | validation: 0.25170832728378634]
	TIME [epoch: 18.8 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25307667999670413		[learning rate: 0.00091728]
	Learning Rate: 0.000917276
	LOSS [training: 0.25307667999670413 | validation: 0.24843114198102817]
	TIME [epoch: 18.8 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24436841568444434		[learning rate: 0.00091363]
	Learning Rate: 0.000913628
	LOSS [training: 0.24436841568444434 | validation: 0.2423973500833998]
	TIME [epoch: 18.8 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.253457676445256		[learning rate: 0.00090999]
	Learning Rate: 0.000909994
	LOSS [training: 0.253457676445256 | validation: 0.24626625417216813]
	TIME [epoch: 18.8 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26134976458112874		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.26134976458112874 | validation: 0.252686252538254]
	TIME [epoch: 18.8 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24221854637854012		[learning rate: 0.00090277]
	Learning Rate: 0.00090277
	LOSS [training: 0.24221854637854012 | validation: 0.23987002325236348]
	TIME [epoch: 18.8 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.250721732191035		[learning rate: 0.00089918]
	Learning Rate: 0.000899179
	LOSS [training: 0.250721732191035 | validation: 0.2558107103255118]
	TIME [epoch: 18.8 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2455309179693186		[learning rate: 0.0008956]
	Learning Rate: 0.000895603
	LOSS [training: 0.2455309179693186 | validation: 0.24367810829774023]
	TIME [epoch: 18.8 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2466062324650901		[learning rate: 0.00089204]
	Learning Rate: 0.000892041
	LOSS [training: 0.2466062324650901 | validation: 0.24901221707253746]
	TIME [epoch: 18.8 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25235361656148214		[learning rate: 0.00088849]
	Learning Rate: 0.000888493
	LOSS [training: 0.25235361656148214 | validation: 0.25354149921886937]
	TIME [epoch: 18.8 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2539950926770981		[learning rate: 0.00088496]
	Learning Rate: 0.000884959
	LOSS [training: 0.2539950926770981 | validation: 0.26744936091479515]
	TIME [epoch: 18.8 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.246232520324522		[learning rate: 0.00088144]
	Learning Rate: 0.000881439
	LOSS [training: 0.246232520324522 | validation: 0.25033041038410236]
	TIME [epoch: 18.8 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2590580224225148		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 0.2590580224225148 | validation: 0.25503176038199177]
	TIME [epoch: 18.8 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24743112342766466		[learning rate: 0.00087444]
	Learning Rate: 0.000874441
	LOSS [training: 0.24743112342766466 | validation: 0.2436406130354206]
	TIME [epoch: 18.8 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24883701268326844		[learning rate: 0.00087096]
	Learning Rate: 0.000870964
	LOSS [training: 0.24883701268326844 | validation: 0.24262995607666377]
	TIME [epoch: 18.8 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23950737188409216		[learning rate: 0.0008675]
	Learning Rate: 0.0008675
	LOSS [training: 0.23950737188409216 | validation: 0.23439662047551776]
	TIME [epoch: 18.8 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25021469213886083		[learning rate: 0.00086405]
	Learning Rate: 0.000864049
	LOSS [training: 0.25021469213886083 | validation: 0.24284262759556294]
	TIME [epoch: 18.8 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24675153161706215		[learning rate: 0.00086061]
	Learning Rate: 0.000860613
	LOSS [training: 0.24675153161706215 | validation: 0.25223441064084356]
	TIME [epoch: 18.8 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2453944675882138		[learning rate: 0.00085719]
	Learning Rate: 0.00085719
	LOSS [training: 0.2453944675882138 | validation: 0.24452663554723264]
	TIME [epoch: 18.8 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25003347356459266		[learning rate: 0.00085378]
	Learning Rate: 0.00085378
	LOSS [training: 0.25003347356459266 | validation: 0.24363557882798736]
	TIME [epoch: 18.8 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2526640786743555		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 0.2526640786743555 | validation: 0.24346381147378965]
	TIME [epoch: 18.8 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2452608929430585		[learning rate: 0.000847]
	Learning Rate: 0.000847002
	LOSS [training: 0.2452608929430585 | validation: 0.2451334679194439]
	TIME [epoch: 18.8 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2432157409401442		[learning rate: 0.00084363]
	Learning Rate: 0.000843634
	LOSS [training: 0.2432157409401442 | validation: 0.23982067648111247]
	TIME [epoch: 18.8 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24311293677108234		[learning rate: 0.00084028]
	Learning Rate: 0.000840278
	LOSS [training: 0.24311293677108234 | validation: 0.24791958416968912]
	TIME [epoch: 18.8 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2422707596147297		[learning rate: 0.00083694]
	Learning Rate: 0.000836936
	LOSS [training: 0.2422707596147297 | validation: 0.23686657447681075]
	TIME [epoch: 18.8 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2348665761619804		[learning rate: 0.00083361]
	Learning Rate: 0.000833608
	LOSS [training: 0.2348665761619804 | validation: 0.24324685734894488]
	TIME [epoch: 18.8 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24337077991057146		[learning rate: 0.00083029]
	Learning Rate: 0.000830292
	LOSS [training: 0.24337077991057146 | validation: 0.2468687835309281]
	TIME [epoch: 18.8 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24181375666425697		[learning rate: 0.00082699]
	Learning Rate: 0.00082699
	LOSS [training: 0.24181375666425697 | validation: 0.23696117579473622]
	TIME [epoch: 18.8 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23915619520379336		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.23915619520379336 | validation: 0.2378743005562672]
	TIME [epoch: 18.8 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24474790575195973		[learning rate: 0.00082042]
	Learning Rate: 0.000820424
	LOSS [training: 0.24474790575195973 | validation: 0.24057485397789596]
	TIME [epoch: 18.8 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24327464968316606		[learning rate: 0.00081716]
	Learning Rate: 0.000817161
	LOSS [training: 0.24327464968316606 | validation: 0.2413162827434435]
	TIME [epoch: 18.8 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24378916880546164		[learning rate: 0.00081391]
	Learning Rate: 0.000813911
	LOSS [training: 0.24378916880546164 | validation: 0.2405171393924194]
	TIME [epoch: 18.8 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24235092600240515		[learning rate: 0.00081067]
	Learning Rate: 0.000810674
	LOSS [training: 0.24235092600240515 | validation: 0.24229668002240698]
	TIME [epoch: 18.8 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2510643830170568		[learning rate: 0.00080745]
	Learning Rate: 0.00080745
	LOSS [training: 0.2510643830170568 | validation: 0.243360699886875]
	TIME [epoch: 18.8 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2475525305556539		[learning rate: 0.00080424]
	Learning Rate: 0.000804238
	LOSS [training: 0.2475525305556539 | validation: 0.239804890216126]
	TIME [epoch: 18.8 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24235220101336402		[learning rate: 0.00080104]
	Learning Rate: 0.000801039
	LOSS [training: 0.24235220101336402 | validation: 0.2550502214201197]
	TIME [epoch: 18.8 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.250833164860149		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 0.250833164860149 | validation: 0.23893532984147692]
	TIME [epoch: 18.8 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24274215231466995		[learning rate: 0.00079468]
	Learning Rate: 0.00079468
	LOSS [training: 0.24274215231466995 | validation: 0.23710688106469274]
	TIME [epoch: 18.8 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23800526123451446		[learning rate: 0.00079152]
	Learning Rate: 0.000791519
	LOSS [training: 0.23800526123451446 | validation: 0.24114892313538655]
	TIME [epoch: 18.9 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24665144538463746		[learning rate: 0.00078837]
	Learning Rate: 0.000788371
	LOSS [training: 0.24665144538463746 | validation: 0.2502605333313833]
	TIME [epoch: 18.8 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2410072034425586		[learning rate: 0.00078524]
	Learning Rate: 0.000785236
	LOSS [training: 0.2410072034425586 | validation: 0.24006690073443382]
	TIME [epoch: 18.8 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24662436580958205		[learning rate: 0.00078211]
	Learning Rate: 0.000782113
	LOSS [training: 0.24662436580958205 | validation: 0.24492290328864033]
	TIME [epoch: 18.8 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23475458468744984		[learning rate: 0.000779]
	Learning Rate: 0.000779002
	LOSS [training: 0.23475458468744984 | validation: 0.24225286537356064]
	TIME [epoch: 18.8 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25513800791324365		[learning rate: 0.0007759]
	Learning Rate: 0.000775904
	LOSS [training: 0.25513800791324365 | validation: 0.24373757129111234]
	TIME [epoch: 18.8 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2427969530440149		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 0.2427969530440149 | validation: 0.24079198887534892]
	TIME [epoch: 18.8 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2414352712826458		[learning rate: 0.00076974]
	Learning Rate: 0.000769744
	LOSS [training: 0.2414352712826458 | validation: 0.2423811056292852]
	TIME [epoch: 18.8 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24281479239287662		[learning rate: 0.00076668]
	Learning Rate: 0.000766682
	LOSS [training: 0.24281479239287662 | validation: 0.2421160987928846]
	TIME [epoch: 18.8 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24021927076141475		[learning rate: 0.00076363]
	Learning Rate: 0.000763633
	LOSS [training: 0.24021927076141475 | validation: 0.24291440155027838]
	TIME [epoch: 18.8 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24936140834889947		[learning rate: 0.0007606]
	Learning Rate: 0.000760596
	LOSS [training: 0.24936140834889947 | validation: 0.25212316410599045]
	TIME [epoch: 18.8 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2479368689635738		[learning rate: 0.00075757]
	Learning Rate: 0.000757571
	LOSS [training: 0.2479368689635738 | validation: 0.24486463004359252]
	TIME [epoch: 18.8 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.234545441416381		[learning rate: 0.00075456]
	Learning Rate: 0.000754557
	LOSS [training: 0.234545441416381 | validation: 0.24278331549205606]
	TIME [epoch: 18.8 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24729475874026535		[learning rate: 0.00075156]
	Learning Rate: 0.000751556
	LOSS [training: 0.24729475874026535 | validation: 0.24176118494586712]
	TIME [epoch: 18.8 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24136306952995573		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 0.24136306952995573 | validation: 0.24105279734819848]
	TIME [epoch: 18.8 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23604952332696533		[learning rate: 0.00074559]
	Learning Rate: 0.00074559
	LOSS [training: 0.23604952332696533 | validation: 0.23655147110323477]
	TIME [epoch: 18.8 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23835854130583023		[learning rate: 0.00074262]
	Learning Rate: 0.000742624
	LOSS [training: 0.23835854130583023 | validation: 0.23550003114297194]
	TIME [epoch: 18.8 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24647145466474502		[learning rate: 0.00073967]
	Learning Rate: 0.000739671
	LOSS [training: 0.24647145466474502 | validation: 0.2449964483391648]
	TIME [epoch: 18.8 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2436691935413594		[learning rate: 0.00073673]
	Learning Rate: 0.000736729
	LOSS [training: 0.2436691935413594 | validation: 0.24030065257783706]
	TIME [epoch: 18.9 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2375035007732549		[learning rate: 0.0007338]
	Learning Rate: 0.000733799
	LOSS [training: 0.2375035007732549 | validation: 0.2377974526216685]
	TIME [epoch: 18.8 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2500030035861748		[learning rate: 0.00073088]
	Learning Rate: 0.00073088
	LOSS [training: 0.2500030035861748 | validation: 0.2402205623780309]
	TIME [epoch: 18.8 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2398806331297605		[learning rate: 0.00072797]
	Learning Rate: 0.000727973
	LOSS [training: 0.2398806331297605 | validation: 0.24510518394247655]
	TIME [epoch: 18.8 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23789237846432387		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 0.23789237846432387 | validation: 0.2404215409074403]
	TIME [epoch: 18.8 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2370362278651158		[learning rate: 0.00072219]
	Learning Rate: 0.000722194
	LOSS [training: 0.2370362278651158 | validation: 0.2395096405223482]
	TIME [epoch: 18.8 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24269651369058087		[learning rate: 0.00071932]
	Learning Rate: 0.000719322
	LOSS [training: 0.24269651369058087 | validation: 0.24785193953994017]
	TIME [epoch: 18.9 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23829537895377642		[learning rate: 0.00071646]
	Learning Rate: 0.000716461
	LOSS [training: 0.23829537895377642 | validation: 0.24189952014353938]
	TIME [epoch: 18.8 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24311405774890849		[learning rate: 0.00071361]
	Learning Rate: 0.000713611
	LOSS [training: 0.24311405774890849 | validation: 0.23890763051479866]
	TIME [epoch: 18.8 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2451970551544814		[learning rate: 0.00071077]
	Learning Rate: 0.000710773
	LOSS [training: 0.2451970551544814 | validation: 0.24569028312864064]
	TIME [epoch: 18.8 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.253131440099151		[learning rate: 0.00070795]
	Learning Rate: 0.000707946
	LOSS [training: 0.253131440099151 | validation: 0.24849129774656173]
	TIME [epoch: 18.8 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24737002867123056		[learning rate: 0.00070513]
	Learning Rate: 0.00070513
	LOSS [training: 0.24737002867123056 | validation: 0.24882733363683524]
	TIME [epoch: 18.8 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24019548568522817		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.24019548568522817 | validation: 0.2385890128625693]
	TIME [epoch: 18.8 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24053547065829836		[learning rate: 0.00069953]
	Learning Rate: 0.000699532
	LOSS [training: 0.24053547065829836 | validation: 0.2440104358602715]
	TIME [epoch: 18.8 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23727521882352307		[learning rate: 0.00069675]
	Learning Rate: 0.00069675
	LOSS [training: 0.23727521882352307 | validation: 0.24969475257392876]
	TIME [epoch: 18.8 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23628687682992627		[learning rate: 0.00069398]
	Learning Rate: 0.000693979
	LOSS [training: 0.23628687682992627 | validation: 0.238615551037734]
	TIME [epoch: 18.8 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24286934559815831		[learning rate: 0.00069122]
	Learning Rate: 0.000691219
	LOSS [training: 0.24286934559815831 | validation: 0.2416186895066784]
	TIME [epoch: 18.8 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23768078060951423		[learning rate: 0.00068847]
	Learning Rate: 0.000688469
	LOSS [training: 0.23768078060951423 | validation: 0.24002351750398251]
	TIME [epoch: 18.8 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24081006553052176		[learning rate: 0.00068573]
	Learning Rate: 0.000685731
	LOSS [training: 0.24081006553052176 | validation: 0.23639914496851624]
	TIME [epoch: 18.8 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24091359352448607		[learning rate: 0.000683]
	Learning Rate: 0.000683004
	LOSS [training: 0.24091359352448607 | validation: 0.24727145199312134]
	TIME [epoch: 18.8 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23993088287522257		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 0.23993088287522257 | validation: 0.24690841190642066]
	TIME [epoch: 18.8 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2478376578462663		[learning rate: 0.00067758]
	Learning Rate: 0.000677582
	LOSS [training: 0.2478376578462663 | validation: 0.2544962715870256]
	TIME [epoch: 18.8 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2458063555924394		[learning rate: 0.00067489]
	Learning Rate: 0.000674887
	LOSS [training: 0.2458063555924394 | validation: 0.24518282179942089]
	TIME [epoch: 18.8 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24104465910797077		[learning rate: 0.0006722]
	Learning Rate: 0.000672202
	LOSS [training: 0.24104465910797077 | validation: 0.23891210032749172]
	TIME [epoch: 18.9 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24828705327551187		[learning rate: 0.00066953]
	Learning Rate: 0.000669529
	LOSS [training: 0.24828705327551187 | validation: 0.23793536087428432]
	TIME [epoch: 18.8 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2469063272018105		[learning rate: 0.00066687]
	Learning Rate: 0.000666866
	LOSS [training: 0.2469063272018105 | validation: 0.24012758625274094]
	TIME [epoch: 18.9 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24150757298776693		[learning rate: 0.00066421]
	Learning Rate: 0.000664213
	LOSS [training: 0.24150757298776693 | validation: 0.25472660033566846]
	TIME [epoch: 18.8 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2524671010900092		[learning rate: 0.00066157]
	Learning Rate: 0.000661572
	LOSS [training: 0.2524671010900092 | validation: 0.23809082140865828]
	TIME [epoch: 18.8 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24179756960372847		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 0.24179756960372847 | validation: 0.2415194764315869]
	TIME [epoch: 18.9 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2439175826022438		[learning rate: 0.00065632]
	Learning Rate: 0.00065632
	LOSS [training: 0.2439175826022438 | validation: 0.24553617532530994]
	TIME [epoch: 18.8 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24435576649509944		[learning rate: 0.00065371]
	Learning Rate: 0.000653709
	LOSS [training: 0.24435576649509944 | validation: 0.24223716473370288]
	TIME [epoch: 18.9 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24248066460826717		[learning rate: 0.00065111]
	Learning Rate: 0.000651109
	LOSS [training: 0.24248066460826717 | validation: 0.24827375500839927]
	TIME [epoch: 18.8 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24782763300539035		[learning rate: 0.00064852]
	Learning Rate: 0.00064852
	LOSS [training: 0.24782763300539035 | validation: 0.2511235543604781]
	TIME [epoch: 18.9 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2464192631789495		[learning rate: 0.00064594]
	Learning Rate: 0.00064594
	LOSS [training: 0.2464192631789495 | validation: 0.24886486929810783]
	TIME [epoch: 18.8 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24620678682247568		[learning rate: 0.00064337]
	Learning Rate: 0.000643371
	LOSS [training: 0.24620678682247568 | validation: 0.240018515885777]
	TIME [epoch: 18.9 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24319092924516644		[learning rate: 0.00064081]
	Learning Rate: 0.000640812
	LOSS [training: 0.24319092924516644 | validation: 0.2405961432119422]
	TIME [epoch: 18.8 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23835621365101345		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 0.23835621365101345 | validation: 0.24151665559341523]
	TIME [epoch: 18.8 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2440483275831542		[learning rate: 0.00063572]
	Learning Rate: 0.000635725
	LOSS [training: 0.2440483275831542 | validation: 0.24287294404870413]
	TIME [epoch: 18.8 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24611158171869846		[learning rate: 0.0006332]
	Learning Rate: 0.000633196
	LOSS [training: 0.24611158171869846 | validation: 0.2435160722741278]
	TIME [epoch: 18.8 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24516910505535883		[learning rate: 0.00063068]
	Learning Rate: 0.000630678
	LOSS [training: 0.24516910505535883 | validation: 0.24582439820532453]
	TIME [epoch: 18.9 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23861340878736315		[learning rate: 0.00062817]
	Learning Rate: 0.00062817
	LOSS [training: 0.23861340878736315 | validation: 0.239303356698548]
	TIME [epoch: 18.8 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23919282644725998		[learning rate: 0.00062567]
	Learning Rate: 0.000625671
	LOSS [training: 0.23919282644725998 | validation: 0.24159128325835497]
	TIME [epoch: 18.8 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2368314708830964		[learning rate: 0.00062318]
	Learning Rate: 0.000623183
	LOSS [training: 0.2368314708830964 | validation: 0.23985688265589653]
	TIME [epoch: 18.8 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24254032898197123		[learning rate: 0.0006207]
	Learning Rate: 0.000620704
	LOSS [training: 0.24254032898197123 | validation: 0.23411759618682088]
	TIME [epoch: 18.8 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24799478137179115		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 0.24799478137179115 | validation: 0.23864577346877067]
	TIME [epoch: 18.8 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23676655130026455		[learning rate: 0.00061578]
	Learning Rate: 0.000615777
	LOSS [training: 0.23676655130026455 | validation: 0.23391127343700072]
	TIME [epoch: 18.8 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23138477854661904		[learning rate: 0.00061333]
	Learning Rate: 0.000613327
	LOSS [training: 0.23138477854661904 | validation: 0.2379259096513978]
	TIME [epoch: 18.8 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23887930969661342		[learning rate: 0.00061089]
	Learning Rate: 0.000610888
	LOSS [training: 0.23887930969661342 | validation: 0.2383592718105509]
	TIME [epoch: 18.8 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24574160892917737		[learning rate: 0.00060846]
	Learning Rate: 0.000608458
	LOSS [training: 0.24574160892917737 | validation: 0.23877290044283278]
	TIME [epoch: 18.8 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24152875291261966		[learning rate: 0.00060604]
	Learning Rate: 0.000606038
	LOSS [training: 0.24152875291261966 | validation: 0.2407119968083617]
	TIME [epoch: 18.8 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24200187120611572		[learning rate: 0.00060363]
	Learning Rate: 0.000603628
	LOSS [training: 0.24200187120611572 | validation: 0.2474820151540976]
	TIME [epoch: 18.8 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2423251011414861		[learning rate: 0.00060123]
	Learning Rate: 0.000601227
	LOSS [training: 0.2423251011414861 | validation: 0.23980197730343492]
	TIME [epoch: 18.8 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2530888800201223		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.2530888800201223 | validation: 0.24253878155467926]
	TIME [epoch: 18.8 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24044216864749796		[learning rate: 0.00059645]
	Learning Rate: 0.000596454
	LOSS [training: 0.24044216864749796 | validation: 0.2356491890074744]
	TIME [epoch: 18.8 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2403510287324297		[learning rate: 0.00059408]
	Learning Rate: 0.000594082
	LOSS [training: 0.2403510287324297 | validation: 0.23580465960262204]
	TIME [epoch: 18.8 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2422128623659733		[learning rate: 0.00059172]
	Learning Rate: 0.000591719
	LOSS [training: 0.2422128623659733 | validation: 0.2407538851452043]
	TIME [epoch: 18.9 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2476836396928993		[learning rate: 0.00058937]
	Learning Rate: 0.000589365
	LOSS [training: 0.2476836396928993 | validation: 0.2604898143150144]
	TIME [epoch: 18.8 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25200203080440103		[learning rate: 0.00058702]
	Learning Rate: 0.000587021
	LOSS [training: 0.25200203080440103 | validation: 0.2446760101442825]
	TIME [epoch: 18.9 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2465312225559743		[learning rate: 0.00058469]
	Learning Rate: 0.000584687
	LOSS [training: 0.2465312225559743 | validation: 0.24105193722968882]
	TIME [epoch: 18.8 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24002681536654982		[learning rate: 0.00058236]
	Learning Rate: 0.000582361
	LOSS [training: 0.24002681536654982 | validation: 0.2330451912909351]
	TIME [epoch: 18.9 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v11_20240711_141418/states/model_facs_dec1b_2dpca_v11_758.pth
	Model improved!!!
EPOCH 759/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.248670192577352		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 0.248670192577352 | validation: 0.24233170315421565]
	TIME [epoch: 18.9 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24129044813169795		[learning rate: 0.00057774]
	Learning Rate: 0.000577738
	LOSS [training: 0.24129044813169795 | validation: 0.24198745720433004]
	TIME [epoch: 18.8 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24088042193279216		[learning rate: 0.00057544]
	Learning Rate: 0.00057544
	LOSS [training: 0.24088042193279216 | validation: 0.23635444793691668]
	TIME [epoch: 18.9 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24863226786908343		[learning rate: 0.00057315]
	Learning Rate: 0.000573151
	LOSS [training: 0.24863226786908343 | validation: 0.24015804191147735]
	TIME [epoch: 18.8 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23835674201972676		[learning rate: 0.00057087]
	Learning Rate: 0.000570872
	LOSS [training: 0.23835674201972676 | validation: 0.2411371454958716]
	TIME [epoch: 18.9 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24398710095137263		[learning rate: 0.0005686]
	Learning Rate: 0.000568601
	LOSS [training: 0.24398710095137263 | validation: 0.23862146730916875]
	TIME [epoch: 18.8 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24533673681510834		[learning rate: 0.00056634]
	Learning Rate: 0.00056634
	LOSS [training: 0.24533673681510834 | validation: 0.24262146234642387]
	TIME [epoch: 18.9 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24441115249498424		[learning rate: 0.00056409]
	Learning Rate: 0.000564087
	LOSS [training: 0.24441115249498424 | validation: 0.24512084779216217]
	TIME [epoch: 18.8 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24628703893085058		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 0.24628703893085058 | validation: 0.23659422935302152]
	TIME [epoch: 18.9 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2428941217411733		[learning rate: 0.00055961]
	Learning Rate: 0.000559609
	LOSS [training: 0.2428941217411733 | validation: 0.23572992735367704]
	TIME [epoch: 18.8 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23675677265908426		[learning rate: 0.00055738]
	Learning Rate: 0.000557383
	LOSS [training: 0.23675677265908426 | validation: 0.24101134282445077]
	TIME [epoch: 18.9 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23892636929735986		[learning rate: 0.00055517]
	Learning Rate: 0.000555166
	LOSS [training: 0.23892636929735986 | validation: 0.24528623771139685]
	TIME [epoch: 18.8 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2394079137988609		[learning rate: 0.00055296]
	Learning Rate: 0.000552958
	LOSS [training: 0.2394079137988609 | validation: 0.23328557322459492]
	TIME [epoch: 18.9 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23091085493616267		[learning rate: 0.00055076]
	Learning Rate: 0.000550759
	LOSS [training: 0.23091085493616267 | validation: 0.2339152951366831]
	TIME [epoch: 18.8 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23983350482507287		[learning rate: 0.00054857]
	Learning Rate: 0.000548568
	LOSS [training: 0.23983350482507287 | validation: 0.24100370802074442]
	TIME [epoch: 18.9 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2412138072890011		[learning rate: 0.00054639]
	Learning Rate: 0.000546387
	LOSS [training: 0.2412138072890011 | validation: 0.23524693285579276]
	TIME [epoch: 18.8 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2387207623527969		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 0.2387207623527969 | validation: 0.23550354900034204]
	TIME [epoch: 18.9 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2439224485664441		[learning rate: 0.00054205]
	Learning Rate: 0.000542049
	LOSS [training: 0.2439224485664441 | validation: 0.25003373803488765]
	TIME [epoch: 18.8 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24003506534048982		[learning rate: 0.00053989]
	Learning Rate: 0.000539893
	LOSS [training: 0.24003506534048982 | validation: 0.23956742017212487]
	TIME [epoch: 18.9 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23972507171460722		[learning rate: 0.00053775]
	Learning Rate: 0.000537746
	LOSS [training: 0.23972507171460722 | validation: 0.23710168133214493]
	TIME [epoch: 18.8 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24157033100323272		[learning rate: 0.00053561]
	Learning Rate: 0.000535607
	LOSS [training: 0.24157033100323272 | validation: 0.23080534145415638]
	TIME [epoch: 18.8 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v11_20240711_141418/states/model_facs_dec1b_2dpca_v11_779.pth
	Model improved!!!
EPOCH 780/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2323534935437076		[learning rate: 0.00053348]
	Learning Rate: 0.000533477
	LOSS [training: 0.2323534935437076 | validation: 0.23646471613010664]
	TIME [epoch: 18.9 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24119085530166176		[learning rate: 0.00053135]
	Learning Rate: 0.000531355
	LOSS [training: 0.24119085530166176 | validation: 0.2383362618869455]
	TIME [epoch: 18.9 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23729175031298574		[learning rate: 0.00052924]
	Learning Rate: 0.000529241
	LOSS [training: 0.23729175031298574 | validation: 0.23538923800560094]
	TIME [epoch: 18.8 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24292266535133017		[learning rate: 0.00052714]
	Learning Rate: 0.000527136
	LOSS [training: 0.24292266535133017 | validation: 0.2508753109750244]
	TIME [epoch: 18.9 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24467547989078942		[learning rate: 0.00052504]
	Learning Rate: 0.00052504
	LOSS [training: 0.24467547989078942 | validation: 0.23761594690916618]
	TIME [epoch: 18.9 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23966462848737008		[learning rate: 0.00052295]
	Learning Rate: 0.000522952
	LOSS [training: 0.23966462848737008 | validation: 0.23588975485521177]
	TIME [epoch: 18.8 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2421681903249105		[learning rate: 0.00052087]
	Learning Rate: 0.000520872
	LOSS [training: 0.2421681903249105 | validation: 0.2397385596959833]
	TIME [epoch: 18.9 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2343042259831599		[learning rate: 0.0005188]
	Learning Rate: 0.0005188
	LOSS [training: 0.2343042259831599 | validation: 0.2332826770336965]
	TIME [epoch: 18.9 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2459204613932311		[learning rate: 0.00051674]
	Learning Rate: 0.000516737
	LOSS [training: 0.2459204613932311 | validation: 0.23640563957201394]
	TIME [epoch: 18.9 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24124309130877114		[learning rate: 0.00051468]
	Learning Rate: 0.000514681
	LOSS [training: 0.24124309130877114 | validation: 0.2356513088190691]
	TIME [epoch: 18.9 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23787094771090425		[learning rate: 0.00051263]
	Learning Rate: 0.000512634
	LOSS [training: 0.23787094771090425 | validation: 0.22982208221899175]
	TIME [epoch: 18.9 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v11_20240711_141418/states/model_facs_dec1b_2dpca_v11_790.pth
	Model improved!!!
EPOCH 791/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24144191285520014		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 0.24144191285520014 | validation: 0.23985547352089456]
	TIME [epoch: 18.9 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2344645142463167		[learning rate: 0.00050856]
	Learning Rate: 0.000508565
	LOSS [training: 0.2344645142463167 | validation: 0.24931285650837687]
	TIME [epoch: 18.9 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23511175379301263		[learning rate: 0.00050654]
	Learning Rate: 0.000506542
	LOSS [training: 0.23511175379301263 | validation: 0.2425281450552405]
	TIME [epoch: 18.9 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23559771414466496		[learning rate: 0.00050453]
	Learning Rate: 0.000504527
	LOSS [training: 0.23559771414466496 | validation: 0.24080753729674792]
	TIME [epoch: 18.9 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23409188290759106		[learning rate: 0.00050252]
	Learning Rate: 0.000502521
	LOSS [training: 0.23409188290759106 | validation: 0.2440069882882785]
	TIME [epoch: 18.9 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2364226703141574		[learning rate: 0.00050052]
	Learning Rate: 0.000500522
	LOSS [training: 0.2364226703141574 | validation: 0.24019214044697526]
	TIME [epoch: 18.9 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2418851027977181		[learning rate: 0.00049853]
	Learning Rate: 0.000498531
	LOSS [training: 0.2418851027977181 | validation: 0.2316873261637169]
	TIME [epoch: 18.9 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23721204631724582		[learning rate: 0.00049655]
	Learning Rate: 0.000496548
	LOSS [training: 0.23721204631724582 | validation: 0.23511278746930753]
	TIME [epoch: 18.9 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24470103255171727		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 0.24470103255171727 | validation: 0.23947840575172483]
	TIME [epoch: 18.9 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2367681812566299		[learning rate: 0.00049261]
	Learning Rate: 0.000492606
	LOSS [training: 0.2367681812566299 | validation: 0.23513792545303502]
	TIME [epoch: 18.9 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2435495724891225		[learning rate: 0.00049065]
	Learning Rate: 0.000490647
	LOSS [training: 0.2435495724891225 | validation: 0.24811880436095896]
	TIME [epoch: 18.9 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23675323254877373		[learning rate: 0.0004887]
	Learning Rate: 0.000488696
	LOSS [training: 0.23675323254877373 | validation: 0.23633708301398756]
	TIME [epoch: 18.9 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23576367131009285		[learning rate: 0.00048675]
	Learning Rate: 0.000486752
	LOSS [training: 0.23576367131009285 | validation: 0.2432032558016765]
	TIME [epoch: 18.9 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2397227553114092		[learning rate: 0.00048482]
	Learning Rate: 0.000484816
	LOSS [training: 0.2397227553114092 | validation: 0.23332076768776022]
	TIME [epoch: 18.9 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2476242573597474		[learning rate: 0.00048289]
	Learning Rate: 0.000482888
	LOSS [training: 0.2476242573597474 | validation: 0.23437960556954854]
	TIME [epoch: 18.9 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23710619289582613		[learning rate: 0.00048097]
	Learning Rate: 0.000480967
	LOSS [training: 0.23710619289582613 | validation: 0.23767993675193272]
	TIME [epoch: 18.9 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2404524947188789		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 0.2404524947188789 | validation: 0.2381996965400805]
	TIME [epoch: 18.9 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23367130978703315		[learning rate: 0.00047715]
	Learning Rate: 0.000477149
	LOSS [training: 0.23367130978703315 | validation: 0.2366426166157111]
	TIME [epoch: 18.9 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2422248699979498		[learning rate: 0.00047525]
	Learning Rate: 0.000475251
	LOSS [training: 0.2422248699979498 | validation: 0.2345800244355935]
	TIME [epoch: 18.9 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2365650326125842		[learning rate: 0.00047336]
	Learning Rate: 0.000473361
	LOSS [training: 0.2365650326125842 | validation: 0.2350880726311262]
	TIME [epoch: 18.9 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2397296552370959		[learning rate: 0.00047148]
	Learning Rate: 0.000471478
	LOSS [training: 0.2397296552370959 | validation: 0.23749070323297533]
	TIME [epoch: 18.9 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23858723624259673		[learning rate: 0.0004696]
	Learning Rate: 0.000469603
	LOSS [training: 0.23858723624259673 | validation: 0.23470694744854267]
	TIME [epoch: 18.9 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2405539223056623		[learning rate: 0.00046774]
	Learning Rate: 0.000467735
	LOSS [training: 0.2405539223056623 | validation: 0.23328218705438783]
	TIME [epoch: 18.9 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23795907521812543		[learning rate: 0.00046587]
	Learning Rate: 0.000465875
	LOSS [training: 0.23795907521812543 | validation: 0.23075042078838998]
	TIME [epoch: 18.9 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23564606889670983		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 0.23564606889670983 | validation: 0.23993366989490364]
	TIME [epoch: 18.9 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24892348708813752		[learning rate: 0.00046218]
	Learning Rate: 0.000462176
	LOSS [training: 0.24892348708813752 | validation: 0.23951873834531154]
	TIME [epoch: 18.9 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24442520617359806		[learning rate: 0.00046034]
	Learning Rate: 0.000460338
	LOSS [training: 0.24442520617359806 | validation: 0.23285323196390434]
	TIME [epoch: 18.9 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23595557194327613		[learning rate: 0.00045851]
	Learning Rate: 0.000458507
	LOSS [training: 0.23595557194327613 | validation: 0.23472585062083073]
	TIME [epoch: 18.9 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23691992603858006		[learning rate: 0.00045668]
	Learning Rate: 0.000456684
	LOSS [training: 0.23691992603858006 | validation: 0.24266857116153245]
	TIME [epoch: 18.9 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24170268350983098		[learning rate: 0.00045487]
	Learning Rate: 0.000454867
	LOSS [training: 0.24170268350983098 | validation: 0.24690570625314961]
	TIME [epoch: 18.9 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24010798451368373		[learning rate: 0.00045306]
	Learning Rate: 0.000453058
	LOSS [training: 0.24010798451368373 | validation: 0.2436721535772887]
	TIME [epoch: 18.9 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24352054603967385		[learning rate: 0.00045126]
	Learning Rate: 0.000451256
	LOSS [training: 0.24352054603967385 | validation: 0.23708572157011062]
	TIME [epoch: 18.9 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24249045995009		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 0.24249045995009 | validation: 0.23962426144811116]
	TIME [epoch: 18.9 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23606929945779248		[learning rate: 0.00044767]
	Learning Rate: 0.000447674
	LOSS [training: 0.23606929945779248 | validation: 0.23616818073736265]
	TIME [epoch: 18.9 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24195440931317724		[learning rate: 0.00044589]
	Learning Rate: 0.000445893
	LOSS [training: 0.24195440931317724 | validation: 0.2283555681278419]
	TIME [epoch: 18.9 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v11_20240711_141418/states/model_facs_dec1b_2dpca_v11_825.pth
	Model improved!!!
EPOCH 826/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23649309552645667		[learning rate: 0.00044412]
	Learning Rate: 0.00044412
	LOSS [training: 0.23649309552645667 | validation: 0.23461291179458957]
	TIME [epoch: 18.9 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2400863965144048		[learning rate: 0.00044235]
	Learning Rate: 0.000442353
	LOSS [training: 0.2400863965144048 | validation: 0.2360066090213353]
	TIME [epoch: 18.9 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23897880526069817		[learning rate: 0.00044059]
	Learning Rate: 0.000440594
	LOSS [training: 0.23897880526069817 | validation: 0.2555631085187073]
	TIME [epoch: 18.8 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24397459234803362		[learning rate: 0.00043884]
	Learning Rate: 0.000438842
	LOSS [training: 0.24397459234803362 | validation: 0.2419995543912905]
	TIME [epoch: 18.9 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24326656160637702		[learning rate: 0.0004371]
	Learning Rate: 0.000437096
	LOSS [training: 0.24326656160637702 | validation: 0.2500349393104066]
	TIME [epoch: 18.9 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24946678154075752		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 0.24946678154075752 | validation: 0.24848110059495676]
	TIME [epoch: 18.9 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23598150509517365		[learning rate: 0.00043363]
	Learning Rate: 0.000433626
	LOSS [training: 0.23598150509517365 | validation: 0.24192954748754797]
	TIME [epoch: 18.9 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24137694510312613		[learning rate: 0.0004319]
	Learning Rate: 0.000431901
	LOSS [training: 0.24137694510312613 | validation: 0.24176271054224463]
	TIME [epoch: 18.9 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2425144814223448		[learning rate: 0.00043018]
	Learning Rate: 0.000430184
	LOSS [training: 0.2425144814223448 | validation: 0.23319463672459784]
	TIME [epoch: 18.9 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2407036042369374		[learning rate: 0.00042847]
	Learning Rate: 0.000428473
	LOSS [training: 0.2407036042369374 | validation: 0.23634214772994805]
	TIME [epoch: 18.9 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23392516646207806		[learning rate: 0.00042677]
	Learning Rate: 0.000426768
	LOSS [training: 0.23392516646207806 | validation: 0.23533369435040327]
	TIME [epoch: 18.9 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23628395950639847		[learning rate: 0.00042507]
	Learning Rate: 0.000425071
	LOSS [training: 0.23628395950639847 | validation: 0.23966307277537385]
	TIME [epoch: 18.9 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23620617533301816		[learning rate: 0.00042338]
	Learning Rate: 0.00042338
	LOSS [training: 0.23620617533301816 | validation: 0.23377858280426828]
	TIME [epoch: 18.9 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24350022522135767		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 0.24350022522135767 | validation: 0.24235263484032682]
	TIME [epoch: 18.9 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24465673866524654		[learning rate: 0.00042002]
	Learning Rate: 0.000420019
	LOSS [training: 0.24465673866524654 | validation: 0.23696609118017825]
	TIME [epoch: 18.9 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2360841336483658		[learning rate: 0.00041835]
	Learning Rate: 0.000418349
	LOSS [training: 0.2360841336483658 | validation: 0.23910720380782785]
	TIME [epoch: 18.9 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23411615081237633		[learning rate: 0.00041668]
	Learning Rate: 0.000416685
	LOSS [training: 0.23411615081237633 | validation: 0.23739384237214609]
	TIME [epoch: 18.9 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24043170713445183		[learning rate: 0.00041503]
	Learning Rate: 0.000415028
	LOSS [training: 0.24043170713445183 | validation: 0.24129839165341363]
	TIME [epoch: 18.9 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24619146056983757		[learning rate: 0.00041338]
	Learning Rate: 0.000413377
	LOSS [training: 0.24619146056983757 | validation: 0.2355775298379581]
	TIME [epoch: 18.9 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2357370112940288		[learning rate: 0.00041173]
	Learning Rate: 0.000411733
	LOSS [training: 0.2357370112940288 | validation: 0.2344735113168568]
	TIME [epoch: 18.9 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2378734858237805		[learning rate: 0.0004101]
	Learning Rate: 0.000410095
	LOSS [training: 0.2378734858237805 | validation: 0.23939956764376918]
	TIME [epoch: 18.9 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24173402970504862		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 0.24173402970504862 | validation: 0.2413783383291829]
	TIME [epoch: 18.9 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24234239481075606		[learning rate: 0.00040684]
	Learning Rate: 0.00040684
	LOSS [training: 0.24234239481075606 | validation: 0.244835754623539]
	TIME [epoch: 18.9 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23945145107220045		[learning rate: 0.00040522]
	Learning Rate: 0.000405221
	LOSS [training: 0.23945145107220045 | validation: 0.23690025501972461]
	TIME [epoch: 18.9 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.239196925563049		[learning rate: 0.00040361]
	Learning Rate: 0.00040361
	LOSS [training: 0.239196925563049 | validation: 0.2411045680173165]
	TIME [epoch: 18.9 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23952804765171176		[learning rate: 0.000402]
	Learning Rate: 0.000402004
	LOSS [training: 0.23952804765171176 | validation: 0.23956659717896978]
	TIME [epoch: 18.8 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2527178280070473		[learning rate: 0.00040041]
	Learning Rate: 0.000400406
	LOSS [training: 0.2527178280070473 | validation: 0.24791767680113433]
	TIME [epoch: 18.9 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25424219044763163		[learning rate: 0.00039881]
	Learning Rate: 0.000398813
	LOSS [training: 0.25424219044763163 | validation: 0.2482871969116521]
	TIME [epoch: 18.9 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2430747905080574		[learning rate: 0.00039723]
	Learning Rate: 0.000397227
	LOSS [training: 0.2430747905080574 | validation: 0.24230525375410705]
	TIME [epoch: 18.9 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24325540798006454		[learning rate: 0.00039565]
	Learning Rate: 0.000395647
	LOSS [training: 0.24325540798006454 | validation: 0.23907499183455672]
	TIME [epoch: 18.9 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2303092135281154		[learning rate: 0.00039407]
	Learning Rate: 0.000394073
	LOSS [training: 0.2303092135281154 | validation: 0.23380877398242217]
	TIME [epoch: 18.9 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23587121303999087		[learning rate: 0.00039251]
	Learning Rate: 0.000392506
	LOSS [training: 0.23587121303999087 | validation: 0.23953477594561998]
	TIME [epoch: 18.9 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23695435576034576		[learning rate: 0.00039094]
	Learning Rate: 0.000390945
	LOSS [training: 0.23695435576034576 | validation: 0.23269808283814805]
	TIME [epoch: 18.9 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23766166622601778		[learning rate: 0.00038939]
	Learning Rate: 0.00038939
	LOSS [training: 0.23766166622601778 | validation: 0.23788381512522427]
	TIME [epoch: 18.9 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2379390038116965		[learning rate: 0.00038784]
	Learning Rate: 0.000387841
	LOSS [training: 0.2379390038116965 | validation: 0.23110249232306662]
	TIME [epoch: 18.9 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23536972349225765		[learning rate: 0.0003863]
	Learning Rate: 0.000386299
	LOSS [training: 0.23536972349225765 | validation: 0.23356017075804977]
	TIME [epoch: 18.9 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23512122217556053		[learning rate: 0.00038476]
	Learning Rate: 0.000384762
	LOSS [training: 0.23512122217556053 | validation: 0.23732120896855138]
	TIME [epoch: 18.9 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2453815302651872		[learning rate: 0.00038323]
	Learning Rate: 0.000383232
	LOSS [training: 0.2453815302651872 | validation: 0.23900138791453918]
	TIME [epoch: 18.9 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2359346463067339		[learning rate: 0.00038171]
	Learning Rate: 0.000381708
	LOSS [training: 0.2359346463067339 | validation: 0.23144874773007995]
	TIME [epoch: 18.9 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24351150002414576		[learning rate: 0.00038019]
	Learning Rate: 0.000380189
	LOSS [training: 0.24351150002414576 | validation: 0.2310559309479711]
	TIME [epoch: 18.9 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23573942436415501		[learning rate: 0.00037868]
	Learning Rate: 0.000378677
	LOSS [training: 0.23573942436415501 | validation: 0.23881245487763691]
	TIME [epoch: 18.9 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24298784558783723		[learning rate: 0.00037717]
	Learning Rate: 0.000377171
	LOSS [training: 0.24298784558783723 | validation: 0.23152298378652486]
	TIME [epoch: 18.9 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23249950660045737		[learning rate: 0.00037567]
	Learning Rate: 0.000375671
	LOSS [training: 0.23249950660045737 | validation: 0.23439786411102098]
	TIME [epoch: 18.9 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24285204796940935		[learning rate: 0.00037418]
	Learning Rate: 0.000374177
	LOSS [training: 0.24285204796940935 | validation: 0.23943248965784664]
	TIME [epoch: 18.9 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24283158493396328		[learning rate: 0.00037269]
	Learning Rate: 0.000372689
	LOSS [training: 0.24283158493396328 | validation: 0.24175970939072164]
	TIME [epoch: 18.9 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23539504228486324		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 0.23539504228486324 | validation: 0.23808989782036943]
	TIME [epoch: 18.9 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23292908920997737		[learning rate: 0.00036973]
	Learning Rate: 0.00036973
	LOSS [training: 0.23292908920997737 | validation: 0.2342659070482013]
	TIME [epoch: 18.9 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2302909386530481		[learning rate: 0.00036826]
	Learning Rate: 0.000368259
	LOSS [training: 0.2302909386530481 | validation: 0.24114474225115537]
	TIME [epoch: 18.9 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23926194547266233		[learning rate: 0.00036679]
	Learning Rate: 0.000366795
	LOSS [training: 0.23926194547266233 | validation: 0.24600795994309316]
	TIME [epoch: 18.9 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24047924360085876		[learning rate: 0.00036534]
	Learning Rate: 0.000365336
	LOSS [training: 0.24047924360085876 | validation: 0.24418758595887463]
	TIME [epoch: 18.9 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2408893990711459		[learning rate: 0.00036388]
	Learning Rate: 0.000363883
	LOSS [training: 0.2408893990711459 | validation: 0.23764142661891544]
	TIME [epoch: 18.9 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2388949341582598		[learning rate: 0.00036244]
	Learning Rate: 0.000362436
	LOSS [training: 0.2388949341582598 | validation: 0.2358705470270978]
	TIME [epoch: 18.9 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23640577536476512		[learning rate: 0.00036099]
	Learning Rate: 0.000360994
	LOSS [training: 0.23640577536476512 | validation: 0.23822917866446486]
	TIME [epoch: 18.9 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2299939962779691		[learning rate: 0.00035956]
	Learning Rate: 0.000359558
	LOSS [training: 0.2299939962779691 | validation: 0.24150241420515872]
	TIME [epoch: 18.9 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2510205497778081		[learning rate: 0.00035813]
	Learning Rate: 0.000358128
	LOSS [training: 0.2510205497778081 | validation: 0.2370971708295694]
	TIME [epoch: 18.9 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23125057693989012		[learning rate: 0.0003567]
	Learning Rate: 0.000356704
	LOSS [training: 0.23125057693989012 | validation: 0.2334939383173371]
	TIME [epoch: 18.9 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2390309610362209		[learning rate: 0.00035529]
	Learning Rate: 0.000355285
	LOSS [training: 0.2390309610362209 | validation: 0.2370689868815128]
	TIME [epoch: 18.9 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23938594151683854		[learning rate: 0.00035387]
	Learning Rate: 0.000353872
	LOSS [training: 0.23938594151683854 | validation: 0.23721495266553258]
	TIME [epoch: 18.9 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2337581855844946		[learning rate: 0.00035246]
	Learning Rate: 0.000352465
	LOSS [training: 0.2337581855844946 | validation: 0.23708806377262323]
	TIME [epoch: 18.9 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23115158370704356		[learning rate: 0.00035106]
	Learning Rate: 0.000351063
	LOSS [training: 0.23115158370704356 | validation: 0.23517094082834317]
	TIME [epoch: 18.9 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23386700657295048		[learning rate: 0.00034967]
	Learning Rate: 0.000349666
	LOSS [training: 0.23386700657295048 | validation: 0.22629695082465764]
	TIME [epoch: 18.9 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v11_20240711_141418/states/model_facs_dec1b_2dpca_v11_886.pth
	Model improved!!!
EPOCH 887/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23371599830912826		[learning rate: 0.00034828]
	Learning Rate: 0.000348276
	LOSS [training: 0.23371599830912826 | validation: 0.2400352798726888]
	TIME [epoch: 18.9 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23634961008083805		[learning rate: 0.00034689]
	Learning Rate: 0.000346891
	LOSS [training: 0.23634961008083805 | validation: 0.23921978842112906]
	TIME [epoch: 18.9 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24382817695763606		[learning rate: 0.00034551]
	Learning Rate: 0.000345511
	LOSS [training: 0.24382817695763606 | validation: 0.23207701219109475]
	TIME [epoch: 18.9 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23713847484044015		[learning rate: 0.00034414]
	Learning Rate: 0.000344137
	LOSS [training: 0.23713847484044015 | validation: 0.23795963112922885]
	TIME [epoch: 18.9 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23548246074616083		[learning rate: 0.00034277]
	Learning Rate: 0.000342768
	LOSS [training: 0.23548246074616083 | validation: 0.23675428437092627]
	TIME [epoch: 18.9 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23420282117343694		[learning rate: 0.0003414]
	Learning Rate: 0.000341405
	LOSS [training: 0.23420282117343694 | validation: 0.2376793923419736]
	TIME [epoch: 18.9 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23648791287434084		[learning rate: 0.00034005]
	Learning Rate: 0.000340047
	LOSS [training: 0.23648791287434084 | validation: 0.23793765524059354]
	TIME [epoch: 18.9 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23750769069455022		[learning rate: 0.00033869]
	Learning Rate: 0.000338694
	LOSS [training: 0.23750769069455022 | validation: 0.23707070526831617]
	TIME [epoch: 18.9 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.233324561447364		[learning rate: 0.00033735]
	Learning Rate: 0.000337347
	LOSS [training: 0.233324561447364 | validation: 0.235012924002053]
	TIME [epoch: 18.9 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23342331209261077		[learning rate: 0.00033601]
	Learning Rate: 0.000336005
	LOSS [training: 0.23342331209261077 | validation: 0.2383760148345026]
	TIME [epoch: 18.9 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23781282401281734		[learning rate: 0.00033467]
	Learning Rate: 0.000334669
	LOSS [training: 0.23781282401281734 | validation: 0.2377076694933673]
	TIME [epoch: 18.9 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2374059541169467		[learning rate: 0.00033334]
	Learning Rate: 0.000333338
	LOSS [training: 0.2374059541169467 | validation: 0.2361037042306243]
	TIME [epoch: 18.9 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23429586907045102		[learning rate: 0.00033201]
	Learning Rate: 0.000332012
	LOSS [training: 0.23429586907045102 | validation: 0.2341185353541822]
	TIME [epoch: 18.9 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23226885383681248		[learning rate: 0.00033069]
	Learning Rate: 0.000330692
	LOSS [training: 0.23226885383681248 | validation: 0.23636483030703723]
	TIME [epoch: 18.9 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23329579003545614		[learning rate: 0.00032938]
	Learning Rate: 0.000329376
	LOSS [training: 0.23329579003545614 | validation: 0.23539507137092333]
	TIME [epoch: 18.9 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24092044139703994		[learning rate: 0.00032807]
	Learning Rate: 0.000328066
	LOSS [training: 0.24092044139703994 | validation: 0.23231979785046333]
	TIME [epoch: 18.9 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2323096515099521		[learning rate: 0.00032676]
	Learning Rate: 0.000326761
	LOSS [training: 0.2323096515099521 | validation: 0.23902987692731656]
	TIME [epoch: 18.9 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23666307393831484		[learning rate: 0.00032546]
	Learning Rate: 0.000325462
	LOSS [training: 0.23666307393831484 | validation: 0.23398700536986355]
	TIME [epoch: 18.9 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24045112465394705		[learning rate: 0.00032417]
	Learning Rate: 0.000324167
	LOSS [training: 0.24045112465394705 | validation: 0.2335676364661418]
	TIME [epoch: 18.9 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.234306365319156		[learning rate: 0.00032288]
	Learning Rate: 0.000322878
	LOSS [training: 0.234306365319156 | validation: 0.22989489259251944]
	TIME [epoch: 18.9 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23504941360924084		[learning rate: 0.00032159]
	Learning Rate: 0.000321594
	LOSS [training: 0.23504941360924084 | validation: 0.2302130728990214]
	TIME [epoch: 18.9 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23929772003939823		[learning rate: 0.00032031]
	Learning Rate: 0.000320315
	LOSS [training: 0.23929772003939823 | validation: 0.2288501891279849]
	TIME [epoch: 18.9 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2347480759825172		[learning rate: 0.00031904]
	Learning Rate: 0.000319041
	LOSS [training: 0.2347480759825172 | validation: 0.23298777136393506]
	TIME [epoch: 18.9 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2367702804172142		[learning rate: 0.00031777]
	Learning Rate: 0.000317772
	LOSS [training: 0.2367702804172142 | validation: 0.2347384841991349]
	TIME [epoch: 18.9 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24436456407355717		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 0.24436456407355717 | validation: 0.2327263527586579]
	TIME [epoch: 18.9 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23677781842870368		[learning rate: 0.00031525]
	Learning Rate: 0.000315249
	LOSS [training: 0.23677781842870368 | validation: 0.23539339228264305]
	TIME [epoch: 18.9 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23586791401938045		[learning rate: 0.000314]
	Learning Rate: 0.000313995
	LOSS [training: 0.23586791401938045 | validation: 0.23146877138048355]
	TIME [epoch: 18.9 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2370587330135259		[learning rate: 0.00031275]
	Learning Rate: 0.000312746
	LOSS [training: 0.2370587330135259 | validation: 0.22843010163727934]
	TIME [epoch: 18.9 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23195251520975596		[learning rate: 0.0003115]
	Learning Rate: 0.000311503
	LOSS [training: 0.23195251520975596 | validation: 0.23977237782950378]
	TIME [epoch: 18.9 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23280275549317178		[learning rate: 0.00031026]
	Learning Rate: 0.000310264
	LOSS [training: 0.23280275549317178 | validation: 0.22892623493218425]
	TIME [epoch: 18.9 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23075761854589316		[learning rate: 0.00030903]
	Learning Rate: 0.00030903
	LOSS [training: 0.23075761854589316 | validation: 0.23903265361796802]
	TIME [epoch: 18.9 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23638141557301484		[learning rate: 0.0003078]
	Learning Rate: 0.0003078
	LOSS [training: 0.23638141557301484 | validation: 0.23637413278452443]
	TIME [epoch: 18.9 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2338992331132882		[learning rate: 0.00030658]
	Learning Rate: 0.000306576
	LOSS [training: 0.2338992331132882 | validation: 0.23466277645461844]
	TIME [epoch: 18.9 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23491466057037527		[learning rate: 0.00030536]
	Learning Rate: 0.000305357
	LOSS [training: 0.23491466057037527 | validation: 0.24065594143086874]
	TIME [epoch: 18.9 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23317446675699868		[learning rate: 0.00030414]
	Learning Rate: 0.000304142
	LOSS [training: 0.23317446675699868 | validation: 0.2334484767865967]
	TIME [epoch: 18.9 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2353729205434597		[learning rate: 0.00030293]
	Learning Rate: 0.000302933
	LOSS [training: 0.2353729205434597 | validation: 0.2318546026884926]
	TIME [epoch: 18.9 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23245400637453587		[learning rate: 0.00030173]
	Learning Rate: 0.000301728
	LOSS [training: 0.23245400637453587 | validation: 0.23545696610614947]
	TIME [epoch: 18.9 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23120764853848919		[learning rate: 0.00030053]
	Learning Rate: 0.000300528
	LOSS [training: 0.23120764853848919 | validation: 0.2315543722105739]
	TIME [epoch: 18.9 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23947714125881253		[learning rate: 0.00029933]
	Learning Rate: 0.000299333
	LOSS [training: 0.23947714125881253 | validation: 0.23138877123359758]
	TIME [epoch: 18.9 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23661964660319393		[learning rate: 0.00029814]
	Learning Rate: 0.000298142
	LOSS [training: 0.23661964660319393 | validation: 0.23812853640309745]
	TIME [epoch: 18.9 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23973532961048694		[learning rate: 0.00029696]
	Learning Rate: 0.000296956
	LOSS [training: 0.23973532961048694 | validation: 0.2307859430531995]
	TIME [epoch: 18.9 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23739049578666854		[learning rate: 0.00029578]
	Learning Rate: 0.000295775
	LOSS [training: 0.23739049578666854 | validation: 0.23514351153841456]
	TIME [epoch: 18.9 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23665800666164025		[learning rate: 0.0002946]
	Learning Rate: 0.000294599
	LOSS [training: 0.23665800666164025 | validation: 0.23966759351341507]
	TIME [epoch: 18.9 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23665029862801212		[learning rate: 0.00029343]
	Learning Rate: 0.000293427
	LOSS [training: 0.23665029862801212 | validation: 0.23956980840134978]
	TIME [epoch: 18.9 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24253580779447223		[learning rate: 0.00029226]
	Learning Rate: 0.00029226
	LOSS [training: 0.24253580779447223 | validation: 0.2365062459365756]
	TIME [epoch: 18.9 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22985277410018623		[learning rate: 0.0002911]
	Learning Rate: 0.000291098
	LOSS [training: 0.22985277410018623 | validation: 0.23641939219617286]
	TIME [epoch: 18.9 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23208290304360502		[learning rate: 0.00028994]
	Learning Rate: 0.00028994
	LOSS [training: 0.23208290304360502 | validation: 0.23802120124579257]
	TIME [epoch: 18.9 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24489675939899452		[learning rate: 0.00028879]
	Learning Rate: 0.000288786
	LOSS [training: 0.24489675939899452 | validation: 0.23867916850913465]
	TIME [epoch: 18.9 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22922126486777117		[learning rate: 0.00028764]
	Learning Rate: 0.000287638
	LOSS [training: 0.22922126486777117 | validation: 0.24983071716578067]
	TIME [epoch: 18.9 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24548608103228878		[learning rate: 0.00028649]
	Learning Rate: 0.000286494
	LOSS [training: 0.24548608103228878 | validation: 0.2429712774405663]
	TIME [epoch: 18.9 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2368904950353533		[learning rate: 0.00028535]
	Learning Rate: 0.000285354
	LOSS [training: 0.2368904950353533 | validation: 0.23000457282968778]
	TIME [epoch: 18.9 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22988732703022105		[learning rate: 0.00028422]
	Learning Rate: 0.00028422
	LOSS [training: 0.22988732703022105 | validation: 0.2389714297710801]
	TIME [epoch: 18.9 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2348829288727693		[learning rate: 0.00028309]
	Learning Rate: 0.000283089
	LOSS [training: 0.2348829288727693 | validation: 0.24159743400587094]
	TIME [epoch: 18.9 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22998185250469605		[learning rate: 0.00028196]
	Learning Rate: 0.000281963
	LOSS [training: 0.22998185250469605 | validation: 0.22628884063496324]
	TIME [epoch: 18.9 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v11_20240711_141418/states/model_facs_dec1b_2dpca_v11_940.pth
	Model improved!!!
EPOCH 941/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23915698334064217		[learning rate: 0.00028084]
	Learning Rate: 0.000280842
	LOSS [training: 0.23915698334064217 | validation: 0.2403100093683138]
	TIME [epoch: 18.9 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2423459628781425		[learning rate: 0.00027972]
	Learning Rate: 0.000279725
	LOSS [training: 0.2423459628781425 | validation: 0.2338676926098302]
	TIME [epoch: 18.9 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22841879720522323		[learning rate: 0.00027861]
	Learning Rate: 0.000278612
	LOSS [training: 0.22841879720522323 | validation: 0.23304874825247582]
	TIME [epoch: 18.9 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23287387972699547		[learning rate: 0.0002775]
	Learning Rate: 0.000277504
	LOSS [training: 0.23287387972699547 | validation: 0.2335687204403174]
	TIME [epoch: 18.9 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23693743923169044		[learning rate: 0.0002764]
	Learning Rate: 0.0002764
	LOSS [training: 0.23693743923169044 | validation: 0.23474970841806558]
	TIME [epoch: 18.9 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25044764197148045		[learning rate: 0.0002753]
	Learning Rate: 0.000275301
	LOSS [training: 0.25044764197148045 | validation: 0.23357481796942808]
	TIME [epoch: 18.9 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2296941188016351		[learning rate: 0.00027421]
	Learning Rate: 0.000274206
	LOSS [training: 0.2296941188016351 | validation: 0.23428337146231923]
	TIME [epoch: 18.9 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2312994638671084		[learning rate: 0.00027312]
	Learning Rate: 0.000273115
	LOSS [training: 0.2312994638671084 | validation: 0.23271132388645524]
	TIME [epoch: 18.9 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23624011131210457		[learning rate: 0.00027203]
	Learning Rate: 0.000272029
	LOSS [training: 0.23624011131210457 | validation: 0.23080175551688478]
	TIME [epoch: 18.9 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22813461238383473		[learning rate: 0.00027095]
	Learning Rate: 0.000270947
	LOSS [training: 0.22813461238383473 | validation: 0.22878484875647703]
	TIME [epoch: 18.9 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23496734476856002		[learning rate: 0.00026987]
	Learning Rate: 0.00026987
	LOSS [training: 0.23496734476856002 | validation: 0.23761509859887137]
	TIME [epoch: 18.9 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23804137485683993		[learning rate: 0.0002688]
	Learning Rate: 0.000268796
	LOSS [training: 0.23804137485683993 | validation: 0.24156718506140312]
	TIME [epoch: 18.9 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23070814560132405		[learning rate: 0.00026773]
	Learning Rate: 0.000267727
	LOSS [training: 0.23070814560132405 | validation: 0.22936455398162775]
	TIME [epoch: 18.9 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2358242897393034		[learning rate: 0.00026666]
	Learning Rate: 0.000266662
	LOSS [training: 0.2358242897393034 | validation: 0.23787417019079227]
	TIME [epoch: 18.9 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23025372685562473		[learning rate: 0.0002656]
	Learning Rate: 0.000265602
	LOSS [training: 0.23025372685562473 | validation: 0.23136792199317607]
	TIME [epoch: 18.9 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22979185353285717		[learning rate: 0.00026455]
	Learning Rate: 0.000264545
	LOSS [training: 0.22979185353285717 | validation: 0.23197241012368147]
	TIME [epoch: 18.9 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23004036162667096		[learning rate: 0.00026349]
	Learning Rate: 0.000263493
	LOSS [training: 0.23004036162667096 | validation: 0.23860257823637934]
	TIME [epoch: 18.9 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22900473650854541		[learning rate: 0.00026245]
	Learning Rate: 0.000262445
	LOSS [training: 0.22900473650854541 | validation: 0.23415731238512225]
	TIME [epoch: 18.9 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23927800510731176		[learning rate: 0.0002614]
	Learning Rate: 0.000261401
	LOSS [training: 0.23927800510731176 | validation: 0.2371973089473704]
	TIME [epoch: 18.9 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24177025524197468		[learning rate: 0.00026036]
	Learning Rate: 0.000260362
	LOSS [training: 0.24177025524197468 | validation: 0.2418225132356147]
	TIME [epoch: 18.9 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22936305596616802		[learning rate: 0.00025933]
	Learning Rate: 0.000259326
	LOSS [training: 0.22936305596616802 | validation: 0.23837192634900956]
	TIME [epoch: 18.9 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23388169566535089		[learning rate: 0.00025829]
	Learning Rate: 0.000258295
	LOSS [training: 0.23388169566535089 | validation: 0.23399967043372444]
	TIME [epoch: 18.9 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23688427844310966		[learning rate: 0.00025727]
	Learning Rate: 0.000257267
	LOSS [training: 0.23688427844310966 | validation: 0.23369807889165486]
	TIME [epoch: 18.9 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2335696577462635		[learning rate: 0.00025624]
	Learning Rate: 0.000256244
	LOSS [training: 0.2335696577462635 | validation: 0.23103919138306045]
	TIME [epoch: 18.9 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23478751266923392		[learning rate: 0.00025522]
	Learning Rate: 0.000255225
	LOSS [training: 0.23478751266923392 | validation: 0.2333342433807974]
	TIME [epoch: 18.9 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23964449521359807		[learning rate: 0.00025421]
	Learning Rate: 0.00025421
	LOSS [training: 0.23964449521359807 | validation: 0.23928363186234466]
	TIME [epoch: 18.9 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2337795949715373		[learning rate: 0.0002532]
	Learning Rate: 0.000253199
	LOSS [training: 0.2337795949715373 | validation: 0.23867252957402302]
	TIME [epoch: 18.9 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23433972993019075		[learning rate: 0.00025219]
	Learning Rate: 0.000252192
	LOSS [training: 0.23433972993019075 | validation: 0.2281301673815122]
	TIME [epoch: 18.9 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23389509450130908		[learning rate: 0.00025119]
	Learning Rate: 0.000251189
	LOSS [training: 0.23389509450130908 | validation: 0.23333268540271684]
	TIME [epoch: 18.9 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2444634610429981		[learning rate: 0.00025019]
	Learning Rate: 0.00025019
	LOSS [training: 0.2444634610429981 | validation: 0.23805131635466395]
	TIME [epoch: 18.9 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2397129714674771		[learning rate: 0.00024919]
	Learning Rate: 0.000249195
	LOSS [training: 0.2397129714674771 | validation: 0.23019692489972635]
	TIME [epoch: 18.9 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23208704289150647		[learning rate: 0.0002482]
	Learning Rate: 0.000248203
	LOSS [training: 0.23208704289150647 | validation: 0.23550089956493606]
	TIME [epoch: 18.9 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23249233823995105		[learning rate: 0.00024722]
	Learning Rate: 0.000247216
	LOSS [training: 0.23249233823995105 | validation: 0.23405518468593484]
	TIME [epoch: 18.9 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23639275811621255		[learning rate: 0.00024623]
	Learning Rate: 0.000246233
	LOSS [training: 0.23639275811621255 | validation: 0.23198822776991274]
	TIME [epoch: 18.9 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23766133340034154		[learning rate: 0.00024525]
	Learning Rate: 0.000245254
	LOSS [training: 0.23766133340034154 | validation: 0.23647977301213258]
	TIME [epoch: 18.9 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2386829127838104		[learning rate: 0.00024428]
	Learning Rate: 0.000244278
	LOSS [training: 0.2386829127838104 | validation: 0.23097524898504385]
	TIME [epoch: 18.9 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2360501791663022		[learning rate: 0.00024331]
	Learning Rate: 0.000243307
	LOSS [training: 0.2360501791663022 | validation: 0.23915285470187345]
	TIME [epoch: 18.9 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23474123638163802		[learning rate: 0.00024234]
	Learning Rate: 0.000242339
	LOSS [training: 0.23474123638163802 | validation: 0.2341386347621846]
	TIME [epoch: 18.9 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2375126484976222		[learning rate: 0.00024138]
	Learning Rate: 0.000241375
	LOSS [training: 0.2375126484976222 | validation: 0.23155248394555233]
	TIME [epoch: 18.9 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23633977925277783		[learning rate: 0.00024042]
	Learning Rate: 0.000240415
	LOSS [training: 0.23633977925277783 | validation: 0.23331041263937155]
	TIME [epoch: 18.9 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23692727538686548		[learning rate: 0.00023946]
	Learning Rate: 0.000239459
	LOSS [training: 0.23692727538686548 | validation: 0.24182882397354427]
	TIME [epoch: 18.9 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23673178783911883		[learning rate: 0.00023851]
	Learning Rate: 0.000238506
	LOSS [training: 0.23673178783911883 | validation: 0.23147717058937495]
	TIME [epoch: 18.9 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23686270880707377		[learning rate: 0.00023756]
	Learning Rate: 0.000237558
	LOSS [training: 0.23686270880707377 | validation: 0.23246044612289757]
	TIME [epoch: 18.9 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23857778110559444		[learning rate: 0.00023661]
	Learning Rate: 0.000236613
	LOSS [training: 0.23857778110559444 | validation: 0.2364933869395199]
	TIME [epoch: 18.9 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23896486980059883		[learning rate: 0.00023567]
	Learning Rate: 0.000235672
	LOSS [training: 0.23896486980059883 | validation: 0.23487294309295584]
	TIME [epoch: 18.9 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24083767360127753		[learning rate: 0.00023473]
	Learning Rate: 0.000234735
	LOSS [training: 0.24083767360127753 | validation: 0.23162137904495178]
	TIME [epoch: 18.9 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2339002216407945		[learning rate: 0.0002338]
	Learning Rate: 0.000233801
	LOSS [training: 0.2339002216407945 | validation: 0.23304773921877292]
	TIME [epoch: 18.9 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.231662366098631		[learning rate: 0.00023287]
	Learning Rate: 0.000232871
	LOSS [training: 0.231662366098631 | validation: 0.23774706501447307]
	TIME [epoch: 18.9 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2342622532890145		[learning rate: 0.00023194]
	Learning Rate: 0.000231945
	LOSS [training: 0.2342622532890145 | validation: 0.22544907330614997]
	TIME [epoch: 18.9 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v11_20240711_141418/states/model_facs_dec1b_2dpca_v11_989.pth
	Model improved!!!
EPOCH 990/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23334365970507942		[learning rate: 0.00023102]
	Learning Rate: 0.000231022
	LOSS [training: 0.23334365970507942 | validation: 0.2311601666106259]
	TIME [epoch: 18.9 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23589109594276492		[learning rate: 0.0002301]
	Learning Rate: 0.000230103
	LOSS [training: 0.23589109594276492 | validation: 0.23366028065277744]
	TIME [epoch: 18.9 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23402043769112332		[learning rate: 0.00022919]
	Learning Rate: 0.000229188
	LOSS [training: 0.23402043769112332 | validation: 0.2451554387624645]
	TIME [epoch: 18.9 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24052863112225797		[learning rate: 0.00022828]
	Learning Rate: 0.000228277
	LOSS [training: 0.24052863112225797 | validation: 0.22835977159028623]
	TIME [epoch: 18.9 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23207939673627184		[learning rate: 0.00022737]
	Learning Rate: 0.000227369
	LOSS [training: 0.23207939673627184 | validation: 0.23405530045964942]
	TIME [epoch: 18.9 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23018834005662253		[learning rate: 0.00022646]
	Learning Rate: 0.000226464
	LOSS [training: 0.23018834005662253 | validation: 0.23525826609667955]
	TIME [epoch: 18.9 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2294488562027104		[learning rate: 0.00022556]
	Learning Rate: 0.000225564
	LOSS [training: 0.2294488562027104 | validation: 0.23489870919549194]
	TIME [epoch: 18.9 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23228009948989614		[learning rate: 0.00022467]
	Learning Rate: 0.000224667
	LOSS [training: 0.23228009948989614 | validation: 0.23700113035987225]
	TIME [epoch: 18.9 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24360706621554595		[learning rate: 0.00022377]
	Learning Rate: 0.000223773
	LOSS [training: 0.24360706621554595 | validation: 0.23625596322191003]
	TIME [epoch: 18.9 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23641898372268924		[learning rate: 0.00022288]
	Learning Rate: 0.000222883
	LOSS [training: 0.23641898372268924 | validation: 0.23558033525085936]
	TIME [epoch: 18.9 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23837476296330115		[learning rate: 0.000222]
	Learning Rate: 0.000221997
	LOSS [training: 0.23837476296330115 | validation: 0.23219373911150448]
	TIME [epoch: 18.9 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2378074517062577		[learning rate: 0.00022111]
	Learning Rate: 0.000221114
	LOSS [training: 0.2378074517062577 | validation: 0.2324480899219709]
	TIME [epoch: 66.5 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23133646580231634		[learning rate: 0.00022023]
	Learning Rate: 0.000220234
	LOSS [training: 0.23133646580231634 | validation: 0.23083195378808333]
	TIME [epoch: 41 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2332079006948032		[learning rate: 0.00021936]
	Learning Rate: 0.000219358
	LOSS [training: 0.2332079006948032 | validation: 0.24072654619754225]
	TIME [epoch: 41 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2340575815156724		[learning rate: 0.00021849]
	Learning Rate: 0.000218486
	LOSS [training: 0.2340575815156724 | validation: 0.2331117552222834]
	TIME [epoch: 41 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22982489595099853		[learning rate: 0.00021762]
	Learning Rate: 0.000217617
	LOSS [training: 0.22982489595099853 | validation: 0.23756908295189275]
	TIME [epoch: 41 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23211607747864096		[learning rate: 0.00021675]
	Learning Rate: 0.000216751
	LOSS [training: 0.23211607747864096 | validation: 0.23592905370531989]
	TIME [epoch: 41 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23861863004262387		[learning rate: 0.00021589]
	Learning Rate: 0.000215889
	LOSS [training: 0.23861863004262387 | validation: 0.24093277546978126]
	TIME [epoch: 41 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22949164970341496		[learning rate: 0.00021503]
	Learning Rate: 0.00021503
	LOSS [training: 0.22949164970341496 | validation: 0.23338949235492173]
	TIME [epoch: 41 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2314740606404947		[learning rate: 0.00021418]
	Learning Rate: 0.000214175
	LOSS [training: 0.2314740606404947 | validation: 0.24026639352492335]
	TIME [epoch: 41 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23614642649848486		[learning rate: 0.00021332]
	Learning Rate: 0.000213323
	LOSS [training: 0.23614642649848486 | validation: 0.23564519137664997]
	TIME [epoch: 41 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23494500233547877		[learning rate: 0.00021247]
	Learning Rate: 0.000212475
	LOSS [training: 0.23494500233547877 | validation: 0.2335700367410726]
	TIME [epoch: 41 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23500712080371158		[learning rate: 0.00021163]
	Learning Rate: 0.00021163
	LOSS [training: 0.23500712080371158 | validation: 0.23560946946035094]
	TIME [epoch: 41 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22909364610460894		[learning rate: 0.00021079]
	Learning Rate: 0.000210788
	LOSS [training: 0.22909364610460894 | validation: 0.2338217862972111]
	TIME [epoch: 41 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23441401129387465		[learning rate: 0.00020995]
	Learning Rate: 0.00020995
	LOSS [training: 0.23441401129387465 | validation: 0.23645232061856541]
	TIME [epoch: 41 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23864542270564001		[learning rate: 0.00020911]
	Learning Rate: 0.000209115
	LOSS [training: 0.23864542270564001 | validation: 0.2371154891567242]
	TIME [epoch: 41 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23502608502361802		[learning rate: 0.00020828]
	Learning Rate: 0.000208283
	LOSS [training: 0.23502608502361802 | validation: 0.22874861838825886]
	TIME [epoch: 41 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23648651700083345		[learning rate: 0.00020745]
	Learning Rate: 0.000207455
	LOSS [training: 0.23648651700083345 | validation: 0.23200649152769642]
	TIME [epoch: 41 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23047795527889883		[learning rate: 0.00020663]
	Learning Rate: 0.00020663
	LOSS [training: 0.23047795527889883 | validation: 0.22987012450202618]
	TIME [epoch: 41 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22888896784668777		[learning rate: 0.00020581]
	Learning Rate: 0.000205808
	LOSS [training: 0.22888896784668777 | validation: 0.23626185566730373]
	TIME [epoch: 41 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23058940678909046		[learning rate: 0.00020499]
	Learning Rate: 0.000204989
	LOSS [training: 0.23058940678909046 | validation: 0.2326562143273124]
	TIME [epoch: 41 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23330246296429497		[learning rate: 0.00020417]
	Learning Rate: 0.000204174
	LOSS [training: 0.23330246296429497 | validation: 0.23428423250872948]
	TIME [epoch: 41 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2364021541737086		[learning rate: 0.00020336]
	Learning Rate: 0.000203362
	LOSS [training: 0.2364021541737086 | validation: 0.23491101091425887]
	TIME [epoch: 41 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2305035072375166		[learning rate: 0.00020255]
	Learning Rate: 0.000202553
	LOSS [training: 0.2305035072375166 | validation: 0.2304781990372078]
	TIME [epoch: 41 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2425873323196846		[learning rate: 0.00020175]
	Learning Rate: 0.000201747
	LOSS [training: 0.2425873323196846 | validation: 0.23219484797989423]
	TIME [epoch: 41 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24149142354266828		[learning rate: 0.00020094]
	Learning Rate: 0.000200945
	LOSS [training: 0.24149142354266828 | validation: 0.2322949110330108]
	TIME [epoch: 41 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22839765330328238		[learning rate: 0.00020015]
	Learning Rate: 0.000200146
	LOSS [training: 0.22839765330328238 | validation: 0.23076913514249237]
	TIME [epoch: 41 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23758977007561194		[learning rate: 0.00019935]
	Learning Rate: 0.00019935
	LOSS [training: 0.23758977007561194 | validation: 0.22989388431404745]
	TIME [epoch: 41 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23434969313843773		[learning rate: 0.00019856]
	Learning Rate: 0.000198557
	LOSS [training: 0.23434969313843773 | validation: 0.22270909068926287]
	TIME [epoch: 41 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v11_20240711_141418/states/model_facs_dec1b_2dpca_v11_1028.pth
	Model improved!!!
EPOCH 1029/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23836350363225764		[learning rate: 0.00019777]
	Learning Rate: 0.000197767
	LOSS [training: 0.23836350363225764 | validation: 0.23053278345645292]
	TIME [epoch: 41 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23292790738037095		[learning rate: 0.00019698]
	Learning Rate: 0.00019698
	LOSS [training: 0.23292790738037095 | validation: 0.2350656366767577]
	TIME [epoch: 41 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23320965779896857		[learning rate: 0.0001962]
	Learning Rate: 0.000196197
	LOSS [training: 0.23320965779896857 | validation: 0.23139283604373911]
	TIME [epoch: 41 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23750520798488767		[learning rate: 0.00019542]
	Learning Rate: 0.000195417
	LOSS [training: 0.23750520798488767 | validation: 0.23097797410546778]
	TIME [epoch: 41 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23192992179402275		[learning rate: 0.00019464]
	Learning Rate: 0.000194639
	LOSS [training: 0.23192992179402275 | validation: 0.23174432347833168]
	TIME [epoch: 41 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23030551609015293		[learning rate: 0.00019387]
	Learning Rate: 0.000193865
	LOSS [training: 0.23030551609015293 | validation: 0.23231731380923346]
	TIME [epoch: 41 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23790990290279856		[learning rate: 0.00019309]
	Learning Rate: 0.000193094
	LOSS [training: 0.23790990290279856 | validation: 0.230224907220394]
	TIME [epoch: 41 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22486044849532524		[learning rate: 0.00019233]
	Learning Rate: 0.000192326
	LOSS [training: 0.22486044849532524 | validation: 0.23313845377216671]
	TIME [epoch: 41 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2410893175867832		[learning rate: 0.00019156]
	Learning Rate: 0.000191561
	LOSS [training: 0.2410893175867832 | validation: 0.24257510503103547]
	TIME [epoch: 40.9 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23434962610265375		[learning rate: 0.0001908]
	Learning Rate: 0.000190799
	LOSS [training: 0.23434962610265375 | validation: 0.23914485492988863]
	TIME [epoch: 41 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23570525601902906		[learning rate: 0.00019004]
	Learning Rate: 0.00019004
	LOSS [training: 0.23570525601902906 | validation: 0.23935428795049174]
	TIME [epoch: 40.9 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2390839317266529		[learning rate: 0.00018928]
	Learning Rate: 0.000189285
	LOSS [training: 0.2390839317266529 | validation: 0.23253610435050365]
	TIME [epoch: 41 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24562980120088707		[learning rate: 0.00018853]
	Learning Rate: 0.000188532
	LOSS [training: 0.24562980120088707 | validation: 0.2346620454983598]
	TIME [epoch: 41 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2394585633236305		[learning rate: 0.00018778]
	Learning Rate: 0.000187782
	LOSS [training: 0.2394585633236305 | validation: 0.2334196666828218]
	TIME [epoch: 41 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23067713933193604		[learning rate: 0.00018704]
	Learning Rate: 0.000187035
	LOSS [training: 0.23067713933193604 | validation: 0.232576997198851]
	TIME [epoch: 40.9 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23728553810051142		[learning rate: 0.00018629]
	Learning Rate: 0.000186291
	LOSS [training: 0.23728553810051142 | validation: 0.23581713125012177]
	TIME [epoch: 41 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23349332253697666		[learning rate: 0.00018555]
	Learning Rate: 0.00018555
	LOSS [training: 0.23349332253697666 | validation: 0.2337142919593072]
	TIME [epoch: 41 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23278783243467116		[learning rate: 0.00018481]
	Learning Rate: 0.000184812
	LOSS [training: 0.23278783243467116 | validation: 0.23450723925939818]
	TIME [epoch: 41 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23599970423086564		[learning rate: 0.00018408]
	Learning Rate: 0.000184077
	LOSS [training: 0.23599970423086564 | validation: 0.23415487754840908]
	TIME [epoch: 41 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23304704342317484		[learning rate: 0.00018335]
	Learning Rate: 0.000183345
	LOSS [training: 0.23304704342317484 | validation: 0.23112989700785708]
	TIME [epoch: 41 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23360954767738423		[learning rate: 0.00018262]
	Learning Rate: 0.000182616
	LOSS [training: 0.23360954767738423 | validation: 0.23318783699478335]
	TIME [epoch: 41 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22619982808864078		[learning rate: 0.00018189]
	Learning Rate: 0.00018189
	LOSS [training: 0.22619982808864078 | validation: 0.23384896308735126]
	TIME [epoch: 41 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23771071703875096		[learning rate: 0.00018117]
	Learning Rate: 0.000181166
	LOSS [training: 0.23771071703875096 | validation: 0.23182834175138015]
	TIME [epoch: 41 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23549664439517784		[learning rate: 0.00018045]
	Learning Rate: 0.000180446
	LOSS [training: 0.23549664439517784 | validation: 0.23227161144431027]
	TIME [epoch: 41 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2308129672271885		[learning rate: 0.00017973]
	Learning Rate: 0.000179728
	LOSS [training: 0.2308129672271885 | validation: 0.2317052142024648]
	TIME [epoch: 41 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22969274952463797		[learning rate: 0.00017901]
	Learning Rate: 0.000179013
	LOSS [training: 0.22969274952463797 | validation: 0.2332763793860108]
	TIME [epoch: 41 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2317002572879368		[learning rate: 0.0001783]
	Learning Rate: 0.000178301
	LOSS [training: 0.2317002572879368 | validation: 0.23535157356462327]
	TIME [epoch: 41 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23493351457219092		[learning rate: 0.00017759]
	Learning Rate: 0.000177592
	LOSS [training: 0.23493351457219092 | validation: 0.2278634984873329]
	TIME [epoch: 41 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23018586238398864		[learning rate: 0.00017689]
	Learning Rate: 0.000176886
	LOSS [training: 0.23018586238398864 | validation: 0.22688145919605668]
	TIME [epoch: 41 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2331307118707501		[learning rate: 0.00017618]
	Learning Rate: 0.000176182
	LOSS [training: 0.2331307118707501 | validation: 0.23780133898387062]
	TIME [epoch: 41 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24252005503399854		[learning rate: 0.00017548]
	Learning Rate: 0.000175481
	LOSS [training: 0.24252005503399854 | validation: 0.2310493695162438]
	TIME [epoch: 41 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23479811258666558		[learning rate: 0.00017478]
	Learning Rate: 0.000174783
	LOSS [training: 0.23479811258666558 | validation: 0.23305745211368373]
	TIME [epoch: 41 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.234325100599756		[learning rate: 0.00017409]
	Learning Rate: 0.000174088
	LOSS [training: 0.234325100599756 | validation: 0.24041895694510088]
	TIME [epoch: 41 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2383264484261887		[learning rate: 0.0001734]
	Learning Rate: 0.000173396
	LOSS [training: 0.2383264484261887 | validation: 0.2376149312908689]
	TIME [epoch: 41 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24123779803612505		[learning rate: 0.00017271]
	Learning Rate: 0.000172706
	LOSS [training: 0.24123779803612505 | validation: 0.23747930843564857]
	TIME [epoch: 41 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23585736213319297		[learning rate: 0.00017202]
	Learning Rate: 0.000172019
	LOSS [training: 0.23585736213319297 | validation: 0.23498753880229017]
	TIME [epoch: 41 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23549508278976194		[learning rate: 0.00017134]
	Learning Rate: 0.000171335
	LOSS [training: 0.23549508278976194 | validation: 0.2336744408452447]
	TIME [epoch: 41 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2328458311299894		[learning rate: 0.00017065]
	Learning Rate: 0.000170654
	LOSS [training: 0.2328458311299894 | validation: 0.2361617438379854]
	TIME [epoch: 41 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2314915372187003		[learning rate: 0.00016997]
	Learning Rate: 0.000169975
	LOSS [training: 0.2314915372187003 | validation: 0.22596412544669237]
	TIME [epoch: 41 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23156702041464014		[learning rate: 0.0001693]
	Learning Rate: 0.000169299
	LOSS [training: 0.23156702041464014 | validation: 0.2404800329518658]
	TIME [epoch: 41 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2375904870940018		[learning rate: 0.00016863]
	Learning Rate: 0.000168625
	LOSS [training: 0.2375904870940018 | validation: 0.23561590875004174]
	TIME [epoch: 41 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23290341604588255		[learning rate: 0.00016795]
	Learning Rate: 0.000167955
	LOSS [training: 0.23290341604588255 | validation: 0.2341252219849758]
	TIME [epoch: 41 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23675182445876064		[learning rate: 0.00016729]
	Learning Rate: 0.000167287
	LOSS [training: 0.23675182445876064 | validation: 0.22880151344198563]
	TIME [epoch: 41 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2294280894792543		[learning rate: 0.00016662]
	Learning Rate: 0.000166621
	LOSS [training: 0.2294280894792543 | validation: 0.22923633675248772]
	TIME [epoch: 41 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2421262913472317		[learning rate: 0.00016596]
	Learning Rate: 0.000165959
	LOSS [training: 0.2421262913472317 | validation: 0.23540239999677076]
	TIME [epoch: 41 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23671331611359436		[learning rate: 0.0001653]
	Learning Rate: 0.000165299
	LOSS [training: 0.23671331611359436 | validation: 0.23185771387296006]
	TIME [epoch: 41 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23254302086343476		[learning rate: 0.00016464]
	Learning Rate: 0.000164641
	LOSS [training: 0.23254302086343476 | validation: 0.2280347216232887]
	TIME [epoch: 40.9 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22928697403283918		[learning rate: 0.00016399]
	Learning Rate: 0.000163986
	LOSS [training: 0.22928697403283918 | validation: 0.23560758720405958]
	TIME [epoch: 41 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23725085345939348		[learning rate: 0.00016333]
	Learning Rate: 0.000163334
	LOSS [training: 0.23725085345939348 | validation: 0.2327697185972752]
	TIME [epoch: 40.9 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23303107806608392		[learning rate: 0.00016268]
	Learning Rate: 0.000162685
	LOSS [training: 0.23303107806608392 | validation: 0.23463048200692774]
	TIME [epoch: 41 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2298337418996686		[learning rate: 0.00016204]
	Learning Rate: 0.000162037
	LOSS [training: 0.2298337418996686 | validation: 0.2313216680131855]
	TIME [epoch: 41 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23211294517789036		[learning rate: 0.00016139]
	Learning Rate: 0.000161393
	LOSS [training: 0.23211294517789036 | validation: 0.2334467276513575]
	TIME [epoch: 41 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23156053737730276		[learning rate: 0.00016075]
	Learning Rate: 0.000160751
	LOSS [training: 0.23156053737730276 | validation: 0.23320135026713434]
	TIME [epoch: 41 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2318738967443855		[learning rate: 0.00016011]
	Learning Rate: 0.000160112
	LOSS [training: 0.2318738967443855 | validation: 0.23243543060643318]
	TIME [epoch: 41 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23194553112612562		[learning rate: 0.00015947]
	Learning Rate: 0.000159475
	LOSS [training: 0.23194553112612562 | validation: 0.2365375416828861]
	TIME [epoch: 41 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23466080052832533		[learning rate: 0.00015884]
	Learning Rate: 0.000158841
	LOSS [training: 0.23466080052832533 | validation: 0.22703611501028548]
	TIME [epoch: 41 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23514778612496215		[learning rate: 0.00015821]
	Learning Rate: 0.000158209
	LOSS [training: 0.23514778612496215 | validation: 0.24121358996510184]
	TIME [epoch: 40.9 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23615463390747818		[learning rate: 0.00015758]
	Learning Rate: 0.00015758
	LOSS [training: 0.23615463390747818 | validation: 0.2377892114791582]
	TIME [epoch: 41 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23356705920609716		[learning rate: 0.00015695]
	Learning Rate: 0.000156953
	LOSS [training: 0.23356705920609716 | validation: 0.22781762645482045]
	TIME [epoch: 41 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23493325216266778		[learning rate: 0.00015633]
	Learning Rate: 0.000156329
	LOSS [training: 0.23493325216266778 | validation: 0.2363626561403545]
	TIME [epoch: 41 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2397383586457987		[learning rate: 0.00015571]
	Learning Rate: 0.000155707
	LOSS [training: 0.2397383586457987 | validation: 0.22972973750576017]
	TIME [epoch: 41 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2323481928249024		[learning rate: 0.00015509]
	Learning Rate: 0.000155088
	LOSS [training: 0.2323481928249024 | validation: 0.22924749209074013]
	TIME [epoch: 41 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23216573558323578		[learning rate: 0.00015447]
	Learning Rate: 0.000154471
	LOSS [training: 0.23216573558323578 | validation: 0.23642927206191316]
	TIME [epoch: 40.9 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23535209970164706		[learning rate: 0.00015386]
	Learning Rate: 0.000153856
	LOSS [training: 0.23535209970164706 | validation: 0.23292599670203504]
	TIME [epoch: 41 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2358379588847211		[learning rate: 0.00015324]
	Learning Rate: 0.000153244
	LOSS [training: 0.2358379588847211 | validation: 0.23601723815884162]
	TIME [epoch: 41 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23641414342945546		[learning rate: 0.00015263]
	Learning Rate: 0.000152635
	LOSS [training: 0.23641414342945546 | validation: 0.23601750688902498]
	TIME [epoch: 41 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2332266281584265		[learning rate: 0.00015203]
	Learning Rate: 0.000152028
	LOSS [training: 0.2332266281584265 | validation: 0.235001545037631]
	TIME [epoch: 41 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23189767935181096		[learning rate: 0.00015142]
	Learning Rate: 0.000151423
	LOSS [training: 0.23189767935181096 | validation: 0.22940347528939342]
	TIME [epoch: 41 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2371415647623744		[learning rate: 0.00015082]
	Learning Rate: 0.000150821
	LOSS [training: 0.2371415647623744 | validation: 0.2333046688921403]
	TIME [epoch: 40.9 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24015152509695012		[learning rate: 0.00015022]
	Learning Rate: 0.000150221
	LOSS [training: 0.24015152509695012 | validation: 0.23338150917342956]
	TIME [epoch: 41 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23305385010132434		[learning rate: 0.00014962]
	Learning Rate: 0.000149624
	LOSS [training: 0.23305385010132434 | validation: 0.23023784712423154]
	TIME [epoch: 41 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23475723979517818		[learning rate: 0.00014903]
	Learning Rate: 0.000149028
	LOSS [training: 0.23475723979517818 | validation: 0.23220071274217716]
	TIME [epoch: 41 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23537768276354776		[learning rate: 0.00014844]
	Learning Rate: 0.000148436
	LOSS [training: 0.23537768276354776 | validation: 0.22882078461360367]
	TIME [epoch: 41 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24070538770537261		[learning rate: 0.00014785]
	Learning Rate: 0.000147845
	LOSS [training: 0.24070538770537261 | validation: 0.2315920051422272]
	TIME [epoch: 41 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2364482361704895		[learning rate: 0.00014726]
	Learning Rate: 0.000147257
	LOSS [training: 0.2364482361704895 | validation: 0.22842460565233896]
	TIME [epoch: 40.9 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23412444816319436		[learning rate: 0.00014667]
	Learning Rate: 0.000146672
	LOSS [training: 0.23412444816319436 | validation: 0.23096503168581495]
	TIME [epoch: 41 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23649520947278355		[learning rate: 0.00014609]
	Learning Rate: 0.000146088
	LOSS [training: 0.23649520947278355 | validation: 0.22981088424663598]
	TIME [epoch: 41 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22808616118176428		[learning rate: 0.00014551]
	Learning Rate: 0.000145507
	LOSS [training: 0.22808616118176428 | validation: 0.23167886311223312]
	TIME [epoch: 41 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2418796701581235		[learning rate: 0.00014493]
	Learning Rate: 0.000144929
	LOSS [training: 0.2418796701581235 | validation: 0.23738653207259225]
	TIME [epoch: 41 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23199889984747873		[learning rate: 0.00014435]
	Learning Rate: 0.000144352
	LOSS [training: 0.23199889984747873 | validation: 0.23670401404582084]
	TIME [epoch: 41 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2313647945231064		[learning rate: 0.00014378]
	Learning Rate: 0.000143778
	LOSS [training: 0.2313647945231064 | validation: 0.23556011509868843]
	TIME [epoch: 41 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22906375646906282		[learning rate: 0.00014321]
	Learning Rate: 0.000143206
	LOSS [training: 0.22906375646906282 | validation: 0.2289699687371894]
	TIME [epoch: 41 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2324896668379028		[learning rate: 0.00014264]
	Learning Rate: 0.000142637
	LOSS [training: 0.2324896668379028 | validation: 0.23702977060907154]
	TIME [epoch: 41 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23283783171602046		[learning rate: 0.00014207]
	Learning Rate: 0.000142069
	LOSS [training: 0.23283783171602046 | validation: 0.2338840252598756]
	TIME [epoch: 41 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23541230871273822		[learning rate: 0.0001415]
	Learning Rate: 0.000141504
	LOSS [training: 0.23541230871273822 | validation: 0.23023845325859765]
	TIME [epoch: 40.9 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23701447887257487		[learning rate: 0.00014094]
	Learning Rate: 0.000140941
	LOSS [training: 0.23701447887257487 | validation: 0.23206084915891126]
	TIME [epoch: 41 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23231161019177204		[learning rate: 0.00014038]
	Learning Rate: 0.000140381
	LOSS [training: 0.23231161019177204 | validation: 0.228143138586911]
	TIME [epoch: 40.9 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24065817471336504		[learning rate: 0.00013982]
	Learning Rate: 0.000139822
	LOSS [training: 0.24065817471336504 | validation: 0.23366022034812262]
	TIME [epoch: 41 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23700110064291657		[learning rate: 0.00013927]
	Learning Rate: 0.000139266
	LOSS [training: 0.23700110064291657 | validation: 0.23372214698350965]
	TIME [epoch: 40.9 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23330989889773443		[learning rate: 0.00013871]
	Learning Rate: 0.000138712
	LOSS [training: 0.23330989889773443 | validation: 0.2337577737850869]
	TIME [epoch: 41 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23436551668141645		[learning rate: 0.00013816]
	Learning Rate: 0.000138161
	LOSS [training: 0.23436551668141645 | validation: 0.2293163285419988]
	TIME [epoch: 40.9 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24281016431754335		[learning rate: 0.00013761]
	Learning Rate: 0.000137611
	LOSS [training: 0.24281016431754335 | validation: 0.23071280550505763]
	TIME [epoch: 41 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2292793243586481		[learning rate: 0.00013706]
	Learning Rate: 0.000137064
	LOSS [training: 0.2292793243586481 | validation: 0.2273505873748304]
	TIME [epoch: 40.9 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2350916415560891		[learning rate: 0.00013652]
	Learning Rate: 0.000136519
	LOSS [training: 0.2350916415560891 | validation: 0.2319723558953088]
	TIME [epoch: 41 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24244786286509168		[learning rate: 0.00013598]
	Learning Rate: 0.000135976
	LOSS [training: 0.24244786286509168 | validation: 0.23442040870668568]
	TIME [epoch: 41 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23220099999748417		[learning rate: 0.00013543]
	Learning Rate: 0.000135435
	LOSS [training: 0.23220099999748417 | validation: 0.23321511551381588]
	TIME [epoch: 41 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23795325704501696		[learning rate: 0.0001349]
	Learning Rate: 0.000134896
	LOSS [training: 0.23795325704501696 | validation: 0.23005265004137126]
	TIME [epoch: 41 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23540294575539988		[learning rate: 0.00013436]
	Learning Rate: 0.00013436
	LOSS [training: 0.23540294575539988 | validation: 0.23370534042590946]
	TIME [epoch: 41 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24323221875347464		[learning rate: 0.00013383]
	Learning Rate: 0.000133825
	LOSS [training: 0.24323221875347464 | validation: 0.2305899139417978]
	TIME [epoch: 40.9 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23250333645870017		[learning rate: 0.00013329]
	Learning Rate: 0.000133293
	LOSS [training: 0.23250333645870017 | validation: 0.23320723395968748]
	TIME [epoch: 41 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2274952275528962		[learning rate: 0.00013276]
	Learning Rate: 0.000132763
	LOSS [training: 0.2274952275528962 | validation: 0.23307703224756002]
	TIME [epoch: 41 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23691529499269992		[learning rate: 0.00013223]
	Learning Rate: 0.000132235
	LOSS [training: 0.23691529499269992 | validation: 0.2327693175285109]
	TIME [epoch: 41 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23120495999876114		[learning rate: 0.00013171]
	Learning Rate: 0.000131709
	LOSS [training: 0.23120495999876114 | validation: 0.2318019695945437]
	TIME [epoch: 40.9 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22675895997043533		[learning rate: 0.00013119]
	Learning Rate: 0.000131185
	LOSS [training: 0.22675895997043533 | validation: 0.23225428510717]
	TIME [epoch: 41 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22444476332986266		[learning rate: 0.00013066]
	Learning Rate: 0.000130663
	LOSS [training: 0.22444476332986266 | validation: 0.2323182371691849]
	TIME [epoch: 40.9 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2290273976350952		[learning rate: 0.00013014]
	Learning Rate: 0.000130144
	LOSS [training: 0.2290273976350952 | validation: 0.2316198981466148]
	TIME [epoch: 41 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23546277177865552		[learning rate: 0.00012963]
	Learning Rate: 0.000129626
	LOSS [training: 0.23546277177865552 | validation: 0.23379592213006434]
	TIME [epoch: 40.9 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2305300181256548		[learning rate: 0.00012911]
	Learning Rate: 0.000129111
	LOSS [training: 0.2305300181256548 | validation: 0.2290596312106173]
	TIME [epoch: 41 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24089425657229407		[learning rate: 0.0001286]
	Learning Rate: 0.000128597
	LOSS [training: 0.24089425657229407 | validation: 0.23011367677409983]
	TIME [epoch: 40.9 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22849679518310337		[learning rate: 0.00012809]
	Learning Rate: 0.000128086
	LOSS [training: 0.22849679518310337 | validation: 0.23489047075851466]
	TIME [epoch: 41 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2304289577669937		[learning rate: 0.00012758]
	Learning Rate: 0.000127576
	LOSS [training: 0.2304289577669937 | validation: 0.22814883384416337]
	TIME [epoch: 40.9 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2318873504031093		[learning rate: 0.00012707]
	Learning Rate: 0.000127069
	LOSS [training: 0.2318873504031093 | validation: 0.23406626806161274]
	TIME [epoch: 41 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2284830032967537		[learning rate: 0.00012656]
	Learning Rate: 0.000126563
	LOSS [training: 0.2284830032967537 | validation: 0.24099615303036934]
	TIME [epoch: 40.9 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23082501587887194		[learning rate: 0.00012606]
	Learning Rate: 0.00012606
	LOSS [training: 0.23082501587887194 | validation: 0.2351491045805311]
	TIME [epoch: 41 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24511684988589005		[learning rate: 0.00012556]
	Learning Rate: 0.000125559
	LOSS [training: 0.24511684988589005 | validation: 0.23261234983152151]
	TIME [epoch: 40.9 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23247605378160355		[learning rate: 0.00012506]
	Learning Rate: 0.000125059
	LOSS [training: 0.23247605378160355 | validation: 0.22885980971973083]
	TIME [epoch: 41 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24597879119675042		[learning rate: 0.00012456]
	Learning Rate: 0.000124562
	LOSS [training: 0.24597879119675042 | validation: 0.23949950458619435]
	TIME [epoch: 40.9 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2298313417862613		[learning rate: 0.00012407]
	Learning Rate: 0.000124066
	LOSS [training: 0.2298313417862613 | validation: 0.23433105320308717]
	TIME [epoch: 41 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23427200352525132		[learning rate: 0.00012357]
	Learning Rate: 0.000123573
	LOSS [training: 0.23427200352525132 | validation: 0.23520458527609728]
	TIME [epoch: 40.9 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23963557116070935		[learning rate: 0.00012308]
	Learning Rate: 0.000123081
	LOSS [training: 0.23963557116070935 | validation: 0.2325885365856383]
	TIME [epoch: 41 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23196089529621233		[learning rate: 0.00012259]
	Learning Rate: 0.000122592
	LOSS [training: 0.23196089529621233 | validation: 0.23112453502838118]
	TIME [epoch: 40.9 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23979572995780377		[learning rate: 0.0001221]
	Learning Rate: 0.000122104
	LOSS [training: 0.23979572995780377 | validation: 0.23005645666589833]
	TIME [epoch: 41 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23494707952031524		[learning rate: 0.00012162]
	Learning Rate: 0.000121619
	LOSS [training: 0.23494707952031524 | validation: 0.22889013897814453]
	TIME [epoch: 40.9 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23539654492565484		[learning rate: 0.00012113]
	Learning Rate: 0.000121135
	LOSS [training: 0.23539654492565484 | validation: 0.23432534711549025]
	TIME [epoch: 41 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23192368652457576		[learning rate: 0.00012065]
	Learning Rate: 0.000120653
	LOSS [training: 0.23192368652457576 | validation: 0.23434694921235794]
	TIME [epoch: 40.9 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24310656943919812		[learning rate: 0.00012017]
	Learning Rate: 0.000120173
	LOSS [training: 0.24310656943919812 | validation: 0.23593033334343155]
	TIME [epoch: 41 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23060998989618411		[learning rate: 0.0001197]
	Learning Rate: 0.000119695
	LOSS [training: 0.23060998989618411 | validation: 0.23088791400609873]
	TIME [epoch: 40.9 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23296432747993936		[learning rate: 0.00011922]
	Learning Rate: 0.000119219
	LOSS [training: 0.23296432747993936 | validation: 0.22747552141849542]
	TIME [epoch: 41 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22969459753533578		[learning rate: 0.00011875]
	Learning Rate: 0.000118745
	LOSS [training: 0.22969459753533578 | validation: 0.2325184254638001]
	TIME [epoch: 40.9 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2280957299297516		[learning rate: 0.00011827]
	Learning Rate: 0.000118273
	LOSS [training: 0.2280957299297516 | validation: 0.23362411983258827]
	TIME [epoch: 41 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23335007665681096		[learning rate: 0.0001178]
	Learning Rate: 0.000117802
	LOSS [training: 0.23335007665681096 | validation: 0.23316904183523643]
	TIME [epoch: 40.9 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23256134368900996		[learning rate: 0.00011733]
	Learning Rate: 0.000117334
	LOSS [training: 0.23256134368900996 | validation: 0.23151886320340362]
	TIME [epoch: 41 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.246228238883973		[learning rate: 0.00011687]
	Learning Rate: 0.000116867
	LOSS [training: 0.246228238883973 | validation: 0.2308079269224904]
	TIME [epoch: 40.9 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2321922345142488		[learning rate: 0.0001164]
	Learning Rate: 0.000116402
	LOSS [training: 0.2321922345142488 | validation: 0.23048848600270833]
	TIME [epoch: 41 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23477201149578786		[learning rate: 0.00011594]
	Learning Rate: 0.000115939
	LOSS [training: 0.23477201149578786 | validation: 0.2290416001098084]
	TIME [epoch: 40.9 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2329287462301501		[learning rate: 0.00011548]
	Learning Rate: 0.000115478
	LOSS [training: 0.2329287462301501 | validation: 0.2316624369770543]
	TIME [epoch: 41 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23758979030608307		[learning rate: 0.00011502]
	Learning Rate: 0.000115019
	LOSS [training: 0.23758979030608307 | validation: 0.2244837353352728]
	TIME [epoch: 40.9 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23431016867338167		[learning rate: 0.00011456]
	Learning Rate: 0.000114561
	LOSS [training: 0.23431016867338167 | validation: 0.2303499233691916]
	TIME [epoch: 41 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22811839860871327		[learning rate: 0.00011411]
	Learning Rate: 0.000114106
	LOSS [training: 0.22811839860871327 | validation: 0.2334637430525337]
	TIME [epoch: 40.9 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24230575460276116		[learning rate: 0.00011365]
	Learning Rate: 0.000113652
	LOSS [training: 0.24230575460276116 | validation: 0.23694165670951634]
	TIME [epoch: 41 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22730737835396284		[learning rate: 0.0001132]
	Learning Rate: 0.0001132
	LOSS [training: 0.22730737835396284 | validation: 0.22939046248253767]
	TIME [epoch: 40.9 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2408337015534484		[learning rate: 0.00011275]
	Learning Rate: 0.00011275
	LOSS [training: 0.2408337015534484 | validation: 0.23196955164421826]
	TIME [epoch: 41 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23405434578052725		[learning rate: 0.0001123]
	Learning Rate: 0.000112301
	LOSS [training: 0.23405434578052725 | validation: 0.23229131258373484]
	TIME [epoch: 40.9 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23206797357513148		[learning rate: 0.00011185]
	Learning Rate: 0.000111855
	LOSS [training: 0.23206797357513148 | validation: 0.2346306098526303]
	TIME [epoch: 41 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23357632710387902		[learning rate: 0.00011141]
	Learning Rate: 0.00011141
	LOSS [training: 0.23357632710387902 | validation: 0.23739142006009786]
	TIME [epoch: 40.9 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2390374602577309		[learning rate: 0.00011097]
	Learning Rate: 0.000110967
	LOSS [training: 0.2390374602577309 | validation: 0.23175466168449663]
	TIME [epoch: 40.9 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2316715166543767		[learning rate: 0.00011053]
	Learning Rate: 0.000110525
	LOSS [training: 0.2316715166543767 | validation: 0.23299097583924686]
	TIME [epoch: 40.9 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23238089298977677		[learning rate: 0.00011009]
	Learning Rate: 0.000110086
	LOSS [training: 0.23238089298977677 | validation: 0.236986416154556]
	TIME [epoch: 41 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2323143307217005		[learning rate: 0.00010965]
	Learning Rate: 0.000109648
	LOSS [training: 0.2323143307217005 | validation: 0.23523837644816617]
	TIME [epoch: 40.9 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2353716001672036		[learning rate: 0.00010921]
	Learning Rate: 0.000109212
	LOSS [training: 0.2353716001672036 | validation: 0.2337272361083984]
	TIME [epoch: 41 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22750555254992477		[learning rate: 0.00010878]
	Learning Rate: 0.000108777
	LOSS [training: 0.22750555254992477 | validation: 0.23001905230685954]
	TIME [epoch: 40.9 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23382818683630394		[learning rate: 0.00010834]
	Learning Rate: 0.000108345
	LOSS [training: 0.23382818683630394 | validation: 0.23195666852780605]
	TIME [epoch: 41 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2275202861395571		[learning rate: 0.00010791]
	Learning Rate: 0.000107914
	LOSS [training: 0.2275202861395571 | validation: 0.2359507174217867]
	TIME [epoch: 41 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22757457041836268		[learning rate: 0.00010748]
	Learning Rate: 0.000107485
	LOSS [training: 0.22757457041836268 | validation: 0.23552751560583637]
	TIME [epoch: 41 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2316528484424121		[learning rate: 0.00010706]
	Learning Rate: 0.000107057
	LOSS [training: 0.2316528484424121 | validation: 0.23326692072132688]
	TIME [epoch: 41 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23464360731420042		[learning rate: 0.00010663]
	Learning Rate: 0.000106631
	LOSS [training: 0.23464360731420042 | validation: 0.23201238136521085]
	TIME [epoch: 41 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23711131233541888		[learning rate: 0.00010621]
	Learning Rate: 0.000106207
	LOSS [training: 0.23711131233541888 | validation: 0.22814269407212634]
	TIME [epoch: 40.9 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23133779404417654		[learning rate: 0.00010578]
	Learning Rate: 0.000105785
	LOSS [training: 0.23133779404417654 | validation: 0.23157920346574787]
	TIME [epoch: 41 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23865869063726627		[learning rate: 0.00010536]
	Learning Rate: 0.000105364
	LOSS [training: 0.23865869063726627 | validation: 0.23242178445190617]
	TIME [epoch: 41 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22864850386511193		[learning rate: 0.00010494]
	Learning Rate: 0.000104945
	LOSS [training: 0.22864850386511193 | validation: 0.23463205488526384]
	TIME [epoch: 41 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2337541246411383		[learning rate: 0.00010453]
	Learning Rate: 0.000104528
	LOSS [training: 0.2337541246411383 | validation: 0.23274705014745128]
	TIME [epoch: 40.9 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2384120323398743		[learning rate: 0.00010411]
	Learning Rate: 0.000104112
	LOSS [training: 0.2384120323398743 | validation: 0.22940653546033088]
	TIME [epoch: 41 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23261056808965813		[learning rate: 0.0001037]
	Learning Rate: 0.000103698
	LOSS [training: 0.23261056808965813 | validation: 0.2288658267448914]
	TIME [epoch: 40.9 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22975096756180147		[learning rate: 0.00010329]
	Learning Rate: 0.000103285
	LOSS [training: 0.22975096756180147 | validation: 0.23374393034538182]
	TIME [epoch: 41 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23004082855872085		[learning rate: 0.00010287]
	Learning Rate: 0.000102874
	LOSS [training: 0.23004082855872085 | validation: 0.23256118043965626]
	TIME [epoch: 40.9 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23549974087131498		[learning rate: 0.00010247]
	Learning Rate: 0.000102465
	LOSS [training: 0.23549974087131498 | validation: 0.23390942591261918]
	TIME [epoch: 41 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23605002406157943		[learning rate: 0.00010206]
	Learning Rate: 0.000102058
	LOSS [training: 0.23605002406157943 | validation: 0.2309346165860024]
	TIME [epoch: 40.9 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2289268053464798		[learning rate: 0.00010165]
	Learning Rate: 0.000101652
	LOSS [training: 0.2289268053464798 | validation: 0.23311924477666218]
	TIME [epoch: 40.9 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23484748470003927		[learning rate: 0.00010125]
	Learning Rate: 0.000101248
	LOSS [training: 0.23484748470003927 | validation: 0.231221938112984]
	TIME [epoch: 41 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23464551742080403		[learning rate: 0.00010084]
	Learning Rate: 0.000100845
	LOSS [training: 0.23464551742080403 | validation: 0.22998656428101932]
	TIME [epoch: 41 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23027278281642152		[learning rate: 0.00010044]
	Learning Rate: 0.000100444
	LOSS [training: 0.23027278281642152 | validation: 0.233687013218159]
	TIME [epoch: 40.9 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23299010836951434		[learning rate: 0.00010004]
	Learning Rate: 0.000100044
	LOSS [training: 0.23299010836951434 | validation: 0.22997277586818013]
	TIME [epoch: 41 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23598232482529402		[learning rate: 9.9646e-05]
	Learning Rate: 9.96464e-05
	LOSS [training: 0.23598232482529402 | validation: 0.22869734809729358]
	TIME [epoch: 41 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23217008109315873		[learning rate: 9.925e-05]
	Learning Rate: 9.92501e-05
	LOSS [training: 0.23217008109315873 | validation: 0.23174179548499235]
	TIME [epoch: 41 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22468907491359344		[learning rate: 9.8855e-05]
	Learning Rate: 9.88553e-05
	LOSS [training: 0.22468907491359344 | validation: 0.22797824721139368]
	TIME [epoch: 41 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23519979410129985		[learning rate: 9.8462e-05]
	Learning Rate: 9.84622e-05
	LOSS [training: 0.23519979410129985 | validation: 0.22894016356884034]
	TIME [epoch: 41 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23326883159070025		[learning rate: 9.8071e-05]
	Learning Rate: 9.80705e-05
	LOSS [training: 0.23326883159070025 | validation: 0.23122154637276818]
	TIME [epoch: 41 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23703718495924248		[learning rate: 9.768e-05]
	Learning Rate: 9.76805e-05
	LOSS [training: 0.23703718495924248 | validation: 0.23435368569732568]
	TIME [epoch: 41 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22764532618085973		[learning rate: 9.7292e-05]
	Learning Rate: 9.7292e-05
	LOSS [training: 0.22764532618085973 | validation: 0.23070118510964774]
	TIME [epoch: 41 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2343614877843122		[learning rate: 9.6905e-05]
	Learning Rate: 9.6905e-05
	LOSS [training: 0.2343614877843122 | validation: 0.2364117951762014]
	TIME [epoch: 41 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2394700131665746		[learning rate: 9.652e-05]
	Learning Rate: 9.65196e-05
	LOSS [training: 0.2394700131665746 | validation: 0.23097398572504532]
	TIME [epoch: 41 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23625190146955832		[learning rate: 9.6136e-05]
	Learning Rate: 9.61357e-05
	LOSS [training: 0.23625190146955832 | validation: 0.23337699404915685]
	TIME [epoch: 41 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23348100480652104		[learning rate: 9.5753e-05]
	Learning Rate: 9.57533e-05
	LOSS [training: 0.23348100480652104 | validation: 0.23462239526970557]
	TIME [epoch: 41 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23543793406092078		[learning rate: 9.5372e-05]
	Learning Rate: 9.53725e-05
	LOSS [training: 0.23543793406092078 | validation: 0.23422403620704121]
	TIME [epoch: 41 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23248569835977795		[learning rate: 9.4993e-05]
	Learning Rate: 9.49932e-05
	LOSS [training: 0.23248569835977795 | validation: 0.2353337969866161]
	TIME [epoch: 41 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22753022340102216		[learning rate: 9.4615e-05]
	Learning Rate: 9.46154e-05
	LOSS [training: 0.22753022340102216 | validation: 0.2314159662873858]
	TIME [epoch: 41 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2344584252788254		[learning rate: 9.4239e-05]
	Learning Rate: 9.4239e-05
	LOSS [training: 0.2344584252788254 | validation: 0.23056177608544642]
	TIME [epoch: 41 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2373969527189384		[learning rate: 9.3864e-05]
	Learning Rate: 9.38642e-05
	LOSS [training: 0.2373969527189384 | validation: 0.2268617270003049]
	TIME [epoch: 41 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22710309311857335		[learning rate: 9.3491e-05]
	Learning Rate: 9.34909e-05
	LOSS [training: 0.22710309311857335 | validation: 0.23263420124420692]
	TIME [epoch: 41 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2316929236664136		[learning rate: 9.3119e-05]
	Learning Rate: 9.3119e-05
	LOSS [training: 0.2316929236664136 | validation: 0.2336457167057196]
	TIME [epoch: 41 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2324053922724057		[learning rate: 9.2749e-05]
	Learning Rate: 9.27487e-05
	LOSS [training: 0.2324053922724057 | validation: 0.23261962248020063]
	TIME [epoch: 41 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23547803625610333		[learning rate: 9.238e-05]
	Learning Rate: 9.23798e-05
	LOSS [training: 0.23547803625610333 | validation: 0.22963418765248494]
	TIME [epoch: 41 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23896552800474266		[learning rate: 9.2012e-05]
	Learning Rate: 9.20124e-05
	LOSS [training: 0.23896552800474266 | validation: 0.22841240451111294]
	TIME [epoch: 41 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23814259050587042		[learning rate: 9.1646e-05]
	Learning Rate: 9.16464e-05
	LOSS [training: 0.23814259050587042 | validation: 0.23429720235289442]
	TIME [epoch: 41 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22915207334689702		[learning rate: 9.1282e-05]
	Learning Rate: 9.12819e-05
	LOSS [training: 0.22915207334689702 | validation: 0.22343828573341296]
	TIME [epoch: 41 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23160935932025423		[learning rate: 9.0919e-05]
	Learning Rate: 9.09188e-05
	LOSS [training: 0.23160935932025423 | validation: 0.23130612363165826]
	TIME [epoch: 41 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2335420478951484		[learning rate: 9.0557e-05]
	Learning Rate: 9.05572e-05
	LOSS [training: 0.2335420478951484 | validation: 0.2306114330818727]
	TIME [epoch: 41 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22869158741182083		[learning rate: 9.0197e-05]
	Learning Rate: 9.01971e-05
	LOSS [training: 0.22869158741182083 | validation: 0.23180544718649534]
	TIME [epoch: 41 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23385916540018917		[learning rate: 8.9838e-05]
	Learning Rate: 8.98383e-05
	LOSS [training: 0.23385916540018917 | validation: 0.22787360128918302]
	TIME [epoch: 41 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22992249981489332		[learning rate: 8.9481e-05]
	Learning Rate: 8.9481e-05
	LOSS [training: 0.22992249981489332 | validation: 0.23354670466402686]
	TIME [epoch: 41 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2338676025164657		[learning rate: 8.9125e-05]
	Learning Rate: 8.91251e-05
	LOSS [training: 0.2338676025164657 | validation: 0.2324196414923791]
	TIME [epoch: 41 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v11_20240711_141418/states/model_facs_dec1b_2dpca_v11_1229.pth
Halted early. No improvement in validation loss for 200 epochs.
Finished training in 23846.798 seconds.
