Args:
Namespace(name='model_facs_v3_dec2b_2dpca_v14b', outdir='out/model_training/model_facs_v3_dec2b_2dpca_v14b', training_data='data/training_data/facs_v3/pca/dec2_fitonsubset/transition2_subset_ce_pn_m_pc12/training', validation_data='data/training_data/facs_v3/pca/dec2_fitonsubset/transition2_subset_ce_pn_m_pc12/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=10, batch_size=50, patience=200, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, quadratic_a=1.0, quadratic_b=1.0, ndims=2, nparams=2, nsigs=2, ncells=200, ncells_sample=200, model_do_sample=False, dt=0.005, dt_schedule='stepped', dt_schedule_bounds=[50, 100, 200, 300], dt_schedule_scales=[0.5, 0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', kernel='multiscale', bw_range=[0.2, 0.5, 0.9, 1.1, 1.3, 1.5, 2.0], optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 3856927622

Training model...

Saving initial model state to: out/model_training/model_facs_v3_dec2b_2dpca_v14b_20240716_170458/states/model_facs_v3_dec2b_2dpca_v14b_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7185050601598166		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7185050601598166 | validation: 2.006043658570964]
	TIME [epoch: 27.2 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v14b_20240716_170458/states/model_facs_v3_dec2b_2dpca_v14b_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0897290240151443		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0897290240151443 | validation: 0.9756734884475811]
	TIME [epoch: 3.9 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v14b_20240716_170458/states/model_facs_v3_dec2b_2dpca_v14b_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7079332031643817		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7079332031643817 | validation: 0.8597862950713013]
	TIME [epoch: 3.87 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v14b_20240716_170458/states/model_facs_v3_dec2b_2dpca_v14b_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6496620998865844		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6496620998865844 | validation: 0.8384108424055866]
	TIME [epoch: 3.86 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v14b_20240716_170458/states/model_facs_v3_dec2b_2dpca_v14b_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5575970167053406		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5575970167053406 | validation: 0.7865702137668338]
	TIME [epoch: 3.88 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v14b_20240716_170458/states/model_facs_v3_dec2b_2dpca_v14b_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5596702069229674		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5596702069229674 | validation: 0.7043430879147128]
	TIME [epoch: 3.88 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v14b_20240716_170458/states/model_facs_v3_dec2b_2dpca_v14b_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5145081317490606		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5145081317490606 | validation: 0.7385302368569925]
	TIME [epoch: 3.86 sec]
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46450520787879573		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.46450520787879573 | validation: 0.7071296216625618]
	TIME [epoch: 3.86 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4676946053271575		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4676946053271575 | validation: 0.5730683939909164]
	TIME [epoch: 3.86 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v14b_20240716_170458/states/model_facs_v3_dec2b_2dpca_v14b_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5136077172362707		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5136077172362707 | validation: 0.5688806740376553]
	TIME [epoch: 3.88 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v14b_20240716_170458/states/model_facs_v3_dec2b_2dpca_v14b_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4459327940045591		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4459327940045591 | validation: 0.5835899595147127]
	TIME [epoch: 3.87 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45785762236191296		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.45785762236191296 | validation: 0.5553349582309026]
	TIME [epoch: 3.87 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v14b_20240716_170458/states/model_facs_v3_dec2b_2dpca_v14b_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3576340938304653		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3576340938304653 | validation: 0.5129255728338791]
	TIME [epoch: 3.87 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v14b_20240716_170458/states/model_facs_v3_dec2b_2dpca_v14b_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43383832319729304		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.43383832319729304 | validation: 0.5603192511251627]
	TIME [epoch: 3.87 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3909629365603542		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3909629365603542 | validation: 0.5099693820263483]
	TIME [epoch: 3.87 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v14b_20240716_170458/states/model_facs_v3_dec2b_2dpca_v14b_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3487696123001107		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3487696123001107 | validation: 0.746590350174141]
	TIME [epoch: 3.87 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42663478615850203		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.42663478615850203 | validation: 0.4903601373801154]
	TIME [epoch: 3.86 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v14b_20240716_170458/states/model_facs_v3_dec2b_2dpca_v14b_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3069090490734139		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3069090490734139 | validation: 0.4665793944055184]
	TIME [epoch: 3.86 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v14b_20240716_170458/states/model_facs_v3_dec2b_2dpca_v14b_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3181922520157784		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3181922520157784 | validation: 0.48790754471876285]
	TIME [epoch: 3.86 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.381685702541756		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.381685702541756 | validation: 0.4473006938878056]
	TIME [epoch: 3.86 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v14b_20240716_170458/states/model_facs_v3_dec2b_2dpca_v14b_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31261797239171396		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.31261797239171396 | validation: 0.526587898597273]
	TIME [epoch: 3.87 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3474363365078351		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3474363365078351 | validation: 0.4544328218386164]
	TIME [epoch: 3.86 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38240654260525075		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.38240654260525075 | validation: 0.4998528623039199]
	TIME [epoch: 3.86 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31433307383574594		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.31433307383574594 | validation: 0.44823158508706235]
	TIME [epoch: 3.86 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28127758925083557		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.28127758925083557 | validation: 0.4432698941567587]
	TIME [epoch: 3.85 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v14b_20240716_170458/states/model_facs_v3_dec2b_2dpca_v14b_25.pth
	Model improved!!!
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2914215347796263		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2914215347796263 | validation: 0.44707600061525843]
	TIME [epoch: 3.85 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2700596370822611		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2700596370822611 | validation: 0.4559283077471659]
	TIME [epoch: 3.86 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33059176689517594		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.33059176689517594 | validation: 0.4318676988573186]
	TIME [epoch: 3.86 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v14b_20240716_170458/states/model_facs_v3_dec2b_2dpca_v14b_28.pth
	Model improved!!!
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2729000625558541		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2729000625558541 | validation: 0.4318075984519712]
	TIME [epoch: 3.87 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v14b_20240716_170458/states/model_facs_v3_dec2b_2dpca_v14b_29.pth
	Model improved!!!
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25178909720383563		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.25178909720383563 | validation: 0.430740102426678]
	TIME [epoch: 3.87 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v14b_20240716_170458/states/model_facs_v3_dec2b_2dpca_v14b_30.pth
	Model improved!!!
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2600517736071764		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2600517736071764 | validation: 0.5297165208697974]
	TIME [epoch: 3.87 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3351656259439635		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3351656259439635 | validation: 0.43983333748266706]
	TIME [epoch: 3.87 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2876163228686166		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2876163228686166 | validation: 0.4172034915217252]
	TIME [epoch: 3.86 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v14b_20240716_170458/states/model_facs_v3_dec2b_2dpca_v14b_33.pth
	Model improved!!!
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2499877618717116		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2499877618717116 | validation: 0.4414062953792567]
	TIME [epoch: 3.87 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2882641747256158		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2882641747256158 | validation: 0.39125109473213004]
	TIME [epoch: 3.86 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v14b_20240716_170458/states/model_facs_v3_dec2b_2dpca_v14b_35.pth
	Model improved!!!
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27001758803647663		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.27001758803647663 | validation: 0.4133280965488971]
	TIME [epoch: 3.87 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2572632032608281		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2572632032608281 | validation: 0.40528125249694946]
	TIME [epoch: 3.87 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28347646049552977		[learning rate: 0.0099882]
	Learning Rate: 0.0099882
	LOSS [training: 0.28347646049552977 | validation: 0.3891624931674914]
	TIME [epoch: 3.86 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v14b_20240716_170458/states/model_facs_v3_dec2b_2dpca_v14b_38.pth
	Model improved!!!
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2686543207741984		[learning rate: 0.0099411]
	Learning Rate: 0.00994113
	LOSS [training: 0.2686543207741984 | validation: 0.4876778153325276]
	TIME [epoch: 3.85 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2753917252635746		[learning rate: 0.0098943]
	Learning Rate: 0.00989429
	LOSS [training: 0.2753917252635746 | validation: 0.4804344705369894]
	TIME [epoch: 3.85 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2585685743877037		[learning rate: 0.0098477]
	Learning Rate: 0.00984767
	LOSS [training: 0.2585685743877037 | validation: 0.49305832489706924]
	TIME [epoch: 3.86 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.268115178713197		[learning rate: 0.0098013]
	Learning Rate: 0.00980126
	LOSS [training: 0.268115178713197 | validation: 0.40233676571100807]
	TIME [epoch: 3.86 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24300107925245246		[learning rate: 0.0097551]
	Learning Rate: 0.00975508
	LOSS [training: 0.24300107925245246 | validation: 0.4331812616997014]
	TIME [epoch: 3.87 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26765944605002734		[learning rate: 0.0097091]
	Learning Rate: 0.00970911
	LOSS [training: 0.26765944605002734 | validation: 0.5983933211035972]
	TIME [epoch: 3.86 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25907282994608216		[learning rate: 0.0096634]
	Learning Rate: 0.00966336
	LOSS [training: 0.25907282994608216 | validation: 0.4296438925760853]
	TIME [epoch: 3.87 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24294615392365304		[learning rate: 0.0096178]
	Learning Rate: 0.00961783
	LOSS [training: 0.24294615392365304 | validation: 0.39381971184610276]
	TIME [epoch: 3.86 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2720739975917514		[learning rate: 0.0095725]
	Learning Rate: 0.00957251
	LOSS [training: 0.2720739975917514 | validation: 0.40920066308643743]
	TIME [epoch: 3.86 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22996434082205705		[learning rate: 0.0095274]
	Learning Rate: 0.0095274
	LOSS [training: 0.22996434082205705 | validation: 0.3864177485181897]
	TIME [epoch: 3.87 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v14b_20240716_170458/states/model_facs_v3_dec2b_2dpca_v14b_48.pth
	Model improved!!!
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20215661445098393		[learning rate: 0.0094825]
	Learning Rate: 0.0094825
	LOSS [training: 0.20215661445098393 | validation: 0.36436671621253863]
	TIME [epoch: 3.88 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v14b_20240716_170458/states/model_facs_v3_dec2b_2dpca_v14b_49.pth
	Model improved!!!
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2464727914945182		[learning rate: 0.0094378]
	Learning Rate: 0.00943782
	LOSS [training: 0.2464727914945182 | validation: 0.4230997627200346]
	TIME [epoch: 3.87 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2351535230629046		[learning rate: 0.0093933]
	Learning Rate: 0.00939335
	LOSS [training: 0.2351535230629046 | validation: 0.4254242510481674]
	TIME [epoch: 28.6 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24807523720738225		[learning rate: 0.0093491]
	Learning Rate: 0.00934909
	LOSS [training: 0.24807523720738225 | validation: 0.4372639019233452]
	TIME [epoch: 7.42 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21766941495387626		[learning rate: 0.009305]
	Learning Rate: 0.00930503
	LOSS [training: 0.21766941495387626 | validation: 0.40310821940612374]
	TIME [epoch: 7.42 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23335069547646412		[learning rate: 0.0092612]
	Learning Rate: 0.00926119
	LOSS [training: 0.23335069547646412 | validation: 0.4142769375687528]
	TIME [epoch: 7.41 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23117462516826223		[learning rate: 0.0092175]
	Learning Rate: 0.00921755
	LOSS [training: 0.23117462516826223 | validation: 0.4120997320968321]
	TIME [epoch: 7.41 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23658040389264345		[learning rate: 0.0091741]
	Learning Rate: 0.00917411
	LOSS [training: 0.23658040389264345 | validation: 0.3920694455480717]
	TIME [epoch: 7.4 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26111875533543794		[learning rate: 0.0091309]
	Learning Rate: 0.00913088
	LOSS [training: 0.26111875533543794 | validation: 0.37746088336081973]
	TIME [epoch: 7.41 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23190550113074038		[learning rate: 0.0090879]
	Learning Rate: 0.00908786
	LOSS [training: 0.23190550113074038 | validation: 0.46498501531235553]
	TIME [epoch: 7.4 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2467988485931762		[learning rate: 0.009045]
	Learning Rate: 0.00904503
	LOSS [training: 0.2467988485931762 | validation: 0.4024374404233848]
	TIME [epoch: 7.39 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2569779904533333		[learning rate: 0.0090024]
	Learning Rate: 0.00900241
	LOSS [training: 0.2569779904533333 | validation: 0.3866745265539351]
	TIME [epoch: 7.41 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2298605114093143		[learning rate: 0.00896]
	Learning Rate: 0.00895999
	LOSS [training: 0.2298605114093143 | validation: 0.40313759862967885]
	TIME [epoch: 7.4 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.214441772555963		[learning rate: 0.0089178]
	Learning Rate: 0.00891777
	LOSS [training: 0.214441772555963 | validation: 0.39992235760972106]
	TIME [epoch: 7.41 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2343861468477393		[learning rate: 0.0088758]
	Learning Rate: 0.00887575
	LOSS [training: 0.2343861468477393 | validation: 0.390796498239958]
	TIME [epoch: 7.41 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19769033355059934		[learning rate: 0.0088339]
	Learning Rate: 0.00883393
	LOSS [training: 0.19769033355059934 | validation: 0.3448289269831408]
	TIME [epoch: 7.41 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v14b_20240716_170458/states/model_facs_v3_dec2b_2dpca_v14b_64.pth
	Model improved!!!
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21974433880500627		[learning rate: 0.0087923]
	Learning Rate: 0.0087923
	LOSS [training: 0.21974433880500627 | validation: 0.3863568198224328]
	TIME [epoch: 7.39 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2224026320037646		[learning rate: 0.0087509]
	Learning Rate: 0.00875087
	LOSS [training: 0.2224026320037646 | validation: 0.4478867214583187]
	TIME [epoch: 7.39 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21731313889700082		[learning rate: 0.0087096]
	Learning Rate: 0.00870964
	LOSS [training: 0.21731313889700082 | validation: 0.3940510971653912]
	TIME [epoch: 7.39 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23590517019493		[learning rate: 0.0086686]
	Learning Rate: 0.00866859
	LOSS [training: 0.23590517019493 | validation: 0.34664367815212643]
	TIME [epoch: 7.4 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20480682025937538		[learning rate: 0.0086277]
	Learning Rate: 0.00862775
	LOSS [training: 0.20480682025937538 | validation: 0.339136177321766]
	TIME [epoch: 7.41 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v14b_20240716_170458/states/model_facs_v3_dec2b_2dpca_v14b_69.pth
	Model improved!!!
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19066900861174874		[learning rate: 0.0085871]
	Learning Rate: 0.00858709
	LOSS [training: 0.19066900861174874 | validation: 0.40301023519552703]
	TIME [epoch: 7.41 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2108802434553429		[learning rate: 0.0085466]
	Learning Rate: 0.00854663
	LOSS [training: 0.2108802434553429 | validation: 0.36934701609128956]
	TIME [epoch: 7.4 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24514435689947334		[learning rate: 0.0085064]
	Learning Rate: 0.00850636
	LOSS [training: 0.24514435689947334 | validation: 0.36296274749738827]
	TIME [epoch: 7.41 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24880109836943637		[learning rate: 0.0084663]
	Learning Rate: 0.00846627
	LOSS [training: 0.24880109836943637 | validation: 0.41504321305155983]
	TIME [epoch: 7.4 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22816394268895795		[learning rate: 0.0084264]
	Learning Rate: 0.00842638
	LOSS [training: 0.22816394268895795 | validation: 0.3762558453123504]
	TIME [epoch: 7.4 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20810574274241067		[learning rate: 0.0083867]
	Learning Rate: 0.00838667
	LOSS [training: 0.20810574274241067 | validation: 0.5022597018457216]
	TIME [epoch: 7.4 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.358593037144582		[learning rate: 0.0083472]
	Learning Rate: 0.00834715
	LOSS [training: 0.358593037144582 | validation: 0.44903469997260553]
	TIME [epoch: 7.41 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2220697729440436		[learning rate: 0.0083078]
	Learning Rate: 0.00830782
	LOSS [training: 0.2220697729440436 | validation: 0.34410870421447604]
	TIME [epoch: 7.4 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19996307918682482		[learning rate: 0.0082687]
	Learning Rate: 0.00826867
	LOSS [training: 0.19996307918682482 | validation: 0.3269718661725889]
	TIME [epoch: 7.4 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v14b_20240716_170458/states/model_facs_v3_dec2b_2dpca_v14b_78.pth
	Model improved!!!
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23027646103268717		[learning rate: 0.0082297]
	Learning Rate: 0.00822971
	LOSS [training: 0.23027646103268717 | validation: 0.5161692451117539]
	TIME [epoch: 7.4 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22040095483887784		[learning rate: 0.0081909]
	Learning Rate: 0.00819093
	LOSS [training: 0.22040095483887784 | validation: 0.36979476752687757]
	TIME [epoch: 7.43 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2126313142887737		[learning rate: 0.0081523]
	Learning Rate: 0.00815233
	LOSS [training: 0.2126313142887737 | validation: 0.517804887917028]
	TIME [epoch: 7.41 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23091006496288902		[learning rate: 0.0081139]
	Learning Rate: 0.00811392
	LOSS [training: 0.23091006496288902 | validation: 0.37509251066723537]
	TIME [epoch: 7.43 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21522154312812108		[learning rate: 0.0080757]
	Learning Rate: 0.00807569
	LOSS [training: 0.21522154312812108 | validation: 0.4209916376740265]
	TIME [epoch: 7.41 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20091446685933734		[learning rate: 0.0080376]
	Learning Rate: 0.00803763
	LOSS [training: 0.20091446685933734 | validation: 0.3602241709643747]
	TIME [epoch: 7.42 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.200398489868955		[learning rate: 0.0079998]
	Learning Rate: 0.00799976
	LOSS [training: 0.200398489868955 | validation: 0.4062597089488858]
	TIME [epoch: 7.41 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.253853055248813		[learning rate: 0.0079621]
	Learning Rate: 0.00796206
	LOSS [training: 0.253853055248813 | validation: 0.31799189945632966]
	TIME [epoch: 7.42 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v14b_20240716_170458/states/model_facs_v3_dec2b_2dpca_v14b_86.pth
	Model improved!!!
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19484319734693908		[learning rate: 0.0079245]
	Learning Rate: 0.00792455
	LOSS [training: 0.19484319734693908 | validation: 0.34827422092542315]
	TIME [epoch: 7.42 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18439765562986452		[learning rate: 0.0078872]
	Learning Rate: 0.0078872
	LOSS [training: 0.18439765562986452 | validation: 0.4405406153122811]
	TIME [epoch: 7.42 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20417750241083948		[learning rate: 0.00785]
	Learning Rate: 0.00785004
	LOSS [training: 0.20417750241083948 | validation: 0.42553998865947734]
	TIME [epoch: 7.41 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22828021400840276		[learning rate: 0.007813]
	Learning Rate: 0.00781305
	LOSS [training: 0.22828021400840276 | validation: 0.3600918874524941]
	TIME [epoch: 7.4 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18321971607107493		[learning rate: 0.0077762]
	Learning Rate: 0.00777623
	LOSS [training: 0.18321971607107493 | validation: 0.34055037836582364]
	TIME [epoch: 7.4 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2060412503081377		[learning rate: 0.0077396]
	Learning Rate: 0.00773959
	LOSS [training: 0.2060412503081377 | validation: 0.30533310344970843]
	TIME [epoch: 7.4 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v14b_20240716_170458/states/model_facs_v3_dec2b_2dpca_v14b_92.pth
	Model improved!!!
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21571327062020762		[learning rate: 0.0077031]
	Learning Rate: 0.00770312
	LOSS [training: 0.21571327062020762 | validation: 0.3757061293451742]
	TIME [epoch: 7.42 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23120452565980487		[learning rate: 0.0076668]
	Learning Rate: 0.00766682
	LOSS [training: 0.23120452565980487 | validation: 0.4047245442092109]
	TIME [epoch: 7.41 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19140204040360762		[learning rate: 0.0076307]
	Learning Rate: 0.0076307
	LOSS [training: 0.19140204040360762 | validation: 0.32543495855944976]
	TIME [epoch: 7.41 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23075343405177978		[learning rate: 0.0075947]
	Learning Rate: 0.00759474
	LOSS [training: 0.23075343405177978 | validation: 0.3381273830124822]
	TIME [epoch: 7.43 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17586483639945807		[learning rate: 0.007559]
	Learning Rate: 0.00755895
	LOSS [training: 0.17586483639945807 | validation: 0.3264818168706958]
	TIME [epoch: 7.41 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17702942260138127		[learning rate: 0.0075233]
	Learning Rate: 0.00752333
	LOSS [training: 0.17702942260138127 | validation: 0.35203638675982335]
	TIME [epoch: 7.4 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2171532121091882		[learning rate: 0.0074879]
	Learning Rate: 0.00748788
	LOSS [training: 0.2171532121091882 | validation: 0.5353696852815796]
	TIME [epoch: 7.39 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21327567890858073		[learning rate: 0.0074526]
	Learning Rate: 0.0074526
	LOSS [training: 0.21327567890858073 | validation: 0.3619848000154947]
	TIME [epoch: 7.4 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15357802800178574		[learning rate: 0.0074175]
	Learning Rate: 0.00741748
	LOSS [training: 0.15357802800178574 | validation: 0.35066374759887137]
	TIME [epoch: 37.1 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22435500520343604		[learning rate: 0.0073825]
	Learning Rate: 0.00738253
	LOSS [training: 0.22435500520343604 | validation: 0.41310520119479716]
	TIME [epoch: 16 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.218825588735046		[learning rate: 0.0073477]
	Learning Rate: 0.00734774
	LOSS [training: 0.218825588735046 | validation: 0.3491420871959937]
	TIME [epoch: 16 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1755282863123454		[learning rate: 0.0073131]
	Learning Rate: 0.00731312
	LOSS [training: 0.1755282863123454 | validation: 0.3043418269857541]
	TIME [epoch: 16 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v14b_20240716_170458/states/model_facs_v3_dec2b_2dpca_v14b_104.pth
	Model improved!!!
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20150827379710487		[learning rate: 0.0072787]
	Learning Rate: 0.00727866
	LOSS [training: 0.20150827379710487 | validation: 0.3354653352049132]
	TIME [epoch: 16 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2064338056415194		[learning rate: 0.0072444]
	Learning Rate: 0.00724436
	LOSS [training: 0.2064338056415194 | validation: 0.32088789131606166]
	TIME [epoch: 16 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21453479539764675		[learning rate: 0.0072102]
	Learning Rate: 0.00721022
	LOSS [training: 0.21453479539764675 | validation: 0.3250048071421559]
	TIME [epoch: 15.9 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18908938429277442		[learning rate: 0.0071762]
	Learning Rate: 0.00717625
	LOSS [training: 0.18908938429277442 | validation: 0.35940606877348863]
	TIME [epoch: 16 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20759111274029152		[learning rate: 0.0071424]
	Learning Rate: 0.00714243
	LOSS [training: 0.20759111274029152 | validation: 0.34452189928017185]
	TIME [epoch: 16 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20500412401198964		[learning rate: 0.0071088]
	Learning Rate: 0.00710878
	LOSS [training: 0.20500412401198964 | validation: 0.368910498187414]
	TIME [epoch: 16 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22236908905557778		[learning rate: 0.0070753]
	Learning Rate: 0.00707528
	LOSS [training: 0.22236908905557778 | validation: 0.4224496377991645]
	TIME [epoch: 16 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2122895112070801		[learning rate: 0.0070419]
	Learning Rate: 0.00704194
	LOSS [training: 0.2122895112070801 | validation: 0.40319858019092847]
	TIME [epoch: 16 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23312312963877674		[learning rate: 0.0070088]
	Learning Rate: 0.00700876
	LOSS [training: 0.23312312963877674 | validation: 0.36108179272854934]
	TIME [epoch: 16 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1740833725880463		[learning rate: 0.0069757]
	Learning Rate: 0.00697573
	LOSS [training: 0.1740833725880463 | validation: 0.34749989631955686]
	TIME [epoch: 16 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18298977269910166		[learning rate: 0.0069429]
	Learning Rate: 0.00694286
	LOSS [training: 0.18298977269910166 | validation: 0.34200397372221286]
	TIME [epoch: 16 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19776327467951968		[learning rate: 0.0069101]
	Learning Rate: 0.00691014
	LOSS [training: 0.19776327467951968 | validation: 0.33655759632563814]
	TIME [epoch: 16 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21205643714833108		[learning rate: 0.0068776]
	Learning Rate: 0.00687758
	LOSS [training: 0.21205643714833108 | validation: 0.6609655643766641]
	TIME [epoch: 16 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29448205960559737		[learning rate: 0.0068452]
	Learning Rate: 0.00684518
	LOSS [training: 0.29448205960559737 | validation: 0.39457701454394734]
	TIME [epoch: 16 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22614430405694372		[learning rate: 0.0068129]
	Learning Rate: 0.00681292
	LOSS [training: 0.22614430405694372 | validation: 0.3427381136942453]
	TIME [epoch: 16 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1862806027630319		[learning rate: 0.0067808]
	Learning Rate: 0.00678082
	LOSS [training: 0.1862806027630319 | validation: 0.3120811009383245]
	TIME [epoch: 16 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.189372276888384		[learning rate: 0.0067489]
	Learning Rate: 0.00674887
	LOSS [training: 0.189372276888384 | validation: 0.32280456435528887]
	TIME [epoch: 16 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18202561099313785		[learning rate: 0.0067171]
	Learning Rate: 0.00671706
	LOSS [training: 0.18202561099313785 | validation: 0.3380831807558601]
	TIME [epoch: 16 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20686209357387034		[learning rate: 0.0066854]
	Learning Rate: 0.00668541
	LOSS [training: 0.20686209357387034 | validation: 0.3167369816563996]
	TIME [epoch: 16 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1830244121487122		[learning rate: 0.0066539]
	Learning Rate: 0.00665391
	LOSS [training: 0.1830244121487122 | validation: 0.3570931269143955]
	TIME [epoch: 16 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16916789912026514		[learning rate: 0.0066226]
	Learning Rate: 0.00662256
	LOSS [training: 0.16916789912026514 | validation: 0.3997107726824033]
	TIME [epoch: 16 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20971505960423084		[learning rate: 0.0065913]
	Learning Rate: 0.00659135
	LOSS [training: 0.20971505960423084 | validation: 0.3655992340157973]
	TIME [epoch: 16 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16288749276713327		[learning rate: 0.0065603]
	Learning Rate: 0.00656029
	LOSS [training: 0.16288749276713327 | validation: 0.350850067353772]
	TIME [epoch: 16 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19344266905345434		[learning rate: 0.0065294]
	Learning Rate: 0.00652938
	LOSS [training: 0.19344266905345434 | validation: 0.3073724754072581]
	TIME [epoch: 16 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19682537485847107		[learning rate: 0.0064986]
	Learning Rate: 0.00649861
	LOSS [training: 0.19682537485847107 | validation: 0.4409517281082277]
	TIME [epoch: 15.9 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19028811054274766		[learning rate: 0.006468]
	Learning Rate: 0.00646799
	LOSS [training: 0.19028811054274766 | validation: 0.3122560731801447]
	TIME [epoch: 15.9 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1645818839147856		[learning rate: 0.0064375]
	Learning Rate: 0.00643751
	LOSS [training: 0.1645818839147856 | validation: 0.3434691351775619]
	TIME [epoch: 16 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18446425763340435		[learning rate: 0.0064072]
	Learning Rate: 0.00640718
	LOSS [training: 0.18446425763340435 | validation: 0.32894537884738545]
	TIME [epoch: 16 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17560609319569406		[learning rate: 0.006377]
	Learning Rate: 0.00637698
	LOSS [training: 0.17560609319569406 | validation: 0.30491440127357394]
	TIME [epoch: 15.9 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19942749662114467		[learning rate: 0.0063469]
	Learning Rate: 0.00634694
	LOSS [training: 0.19942749662114467 | validation: 0.3356108560127557]
	TIME [epoch: 16 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21262604922620426		[learning rate: 0.006317]
	Learning Rate: 0.00631703
	LOSS [training: 0.21262604922620426 | validation: 0.5360973131000811]
	TIME [epoch: 16 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2828104021830331		[learning rate: 0.0062873]
	Learning Rate: 0.00628726
	LOSS [training: 0.2828104021830331 | validation: 0.3767910976401544]
	TIME [epoch: 16 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.180408866643061		[learning rate: 0.0062576]
	Learning Rate: 0.00625764
	LOSS [training: 0.180408866643061 | validation: 0.33980306892173007]
	TIME [epoch: 16 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17253734633411838		[learning rate: 0.0062281]
	Learning Rate: 0.00622815
	LOSS [training: 0.17253734633411838 | validation: 0.38338964278450216]
	TIME [epoch: 15.9 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1963257205954629		[learning rate: 0.0061988]
	Learning Rate: 0.0061988
	LOSS [training: 0.1963257205954629 | validation: 0.38112827606081445]
	TIME [epoch: 16 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1695252559091604		[learning rate: 0.0061696]
	Learning Rate: 0.00616959
	LOSS [training: 0.1695252559091604 | validation: 0.36616111028065346]
	TIME [epoch: 15.9 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1931652477137099		[learning rate: 0.0061405]
	Learning Rate: 0.00614052
	LOSS [training: 0.1931652477137099 | validation: 0.3406970071134199]
	TIME [epoch: 16 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17574637764303352		[learning rate: 0.0061116]
	Learning Rate: 0.00611158
	LOSS [training: 0.17574637764303352 | validation: 0.3975182771762268]
	TIME [epoch: 16 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2002379197030008		[learning rate: 0.0060828]
	Learning Rate: 0.00608279
	LOSS [training: 0.2002379197030008 | validation: 0.3200864011950466]
	TIME [epoch: 16 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17773294014993707		[learning rate: 0.0060541]
	Learning Rate: 0.00605412
	LOSS [training: 0.17773294014993707 | validation: 0.3890758758209814]
	TIME [epoch: 16 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17560583506340638		[learning rate: 0.0060256]
	Learning Rate: 0.0060256
	LOSS [training: 0.17560583506340638 | validation: 0.34805692854445897]
	TIME [epoch: 16 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1660817976272303		[learning rate: 0.0059972]
	Learning Rate: 0.0059972
	LOSS [training: 0.1660817976272303 | validation: 0.3010136882139791]
	TIME [epoch: 16 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v14b_20240716_170458/states/model_facs_v3_dec2b_2dpca_v14b_146.pth
	Model improved!!!
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16239086656497992		[learning rate: 0.0059689]
	Learning Rate: 0.00596894
	LOSS [training: 0.16239086656497992 | validation: 0.3501695186588534]
	TIME [epoch: 16 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18677217507843832		[learning rate: 0.0059408]
	Learning Rate: 0.00594082
	LOSS [training: 0.18677217507843832 | validation: 0.3250687368772585]
	TIME [epoch: 16 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16352284532539568		[learning rate: 0.0059128]
	Learning Rate: 0.00591282
	LOSS [training: 0.16352284532539568 | validation: 0.35217681603808104]
	TIME [epoch: 16 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16793127647786724		[learning rate: 0.005885]
	Learning Rate: 0.00588496
	LOSS [training: 0.16793127647786724 | validation: 0.3649206182958542]
	TIME [epoch: 16 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19060541107812773		[learning rate: 0.0058572]
	Learning Rate: 0.00585723
	LOSS [training: 0.19060541107812773 | validation: 0.3357961435018986]
	TIME [epoch: 16 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18756474141636345		[learning rate: 0.0058296]
	Learning Rate: 0.00582963
	LOSS [training: 0.18756474141636345 | validation: 0.331560941315789]
	TIME [epoch: 16 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19122283449062644		[learning rate: 0.0058022]
	Learning Rate: 0.00580216
	LOSS [training: 0.19122283449062644 | validation: 0.3406098205685161]
	TIME [epoch: 16 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18064820550758387		[learning rate: 0.0057748]
	Learning Rate: 0.00577482
	LOSS [training: 0.18064820550758387 | validation: 0.3264701119725183]
	TIME [epoch: 16 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17144627978613047		[learning rate: 0.0057476]
	Learning Rate: 0.00574761
	LOSS [training: 0.17144627978613047 | validation: 0.4100760993717462]
	TIME [epoch: 16 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22459251542757508		[learning rate: 0.0057205]
	Learning Rate: 0.00572052
	LOSS [training: 0.22459251542757508 | validation: 0.35538774461708655]
	TIME [epoch: 16 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18455953267089262		[learning rate: 0.0056936]
	Learning Rate: 0.00569357
	LOSS [training: 0.18455953267089262 | validation: 0.32463357114902747]
	TIME [epoch: 16 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18483497766077034		[learning rate: 0.0056667]
	Learning Rate: 0.00566674
	LOSS [training: 0.18483497766077034 | validation: 0.33989684385423935]
	TIME [epoch: 16 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1977716384731167		[learning rate: 0.00564]
	Learning Rate: 0.00564004
	LOSS [training: 0.1977716384731167 | validation: 0.4134053891441093]
	TIME [epoch: 16 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1808358742240156		[learning rate: 0.0056135]
	Learning Rate: 0.00561346
	LOSS [training: 0.1808358742240156 | validation: 0.3408023028100415]
	TIME [epoch: 16 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17149700831054393		[learning rate: 0.005587]
	Learning Rate: 0.00558701
	LOSS [training: 0.17149700831054393 | validation: 0.3133882318880704]
	TIME [epoch: 15.9 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18599563039400044		[learning rate: 0.0055607]
	Learning Rate: 0.00556068
	LOSS [training: 0.18599563039400044 | validation: 0.3866915020261728]
	TIME [epoch: 16 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21791401164872315		[learning rate: 0.0055345]
	Learning Rate: 0.00553448
	LOSS [training: 0.21791401164872315 | validation: 0.3478969383666503]
	TIME [epoch: 16 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15265842549587472		[learning rate: 0.0055084]
	Learning Rate: 0.0055084
	LOSS [training: 0.15265842549587472 | validation: 0.36801776277407583]
	TIME [epoch: 16 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20451025560837258		[learning rate: 0.0054824]
	Learning Rate: 0.00548245
	LOSS [training: 0.20451025560837258 | validation: 0.399218087549601]
	TIME [epoch: 16 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19130367599238296		[learning rate: 0.0054566]
	Learning Rate: 0.00545661
	LOSS [training: 0.19130367599238296 | validation: 0.3041603459936933]
	TIME [epoch: 15.9 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17746222498721542		[learning rate: 0.0054309]
	Learning Rate: 0.0054309
	LOSS [training: 0.17746222498721542 | validation: 0.32204728808711786]
	TIME [epoch: 16 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14648703346197955		[learning rate: 0.0054053]
	Learning Rate: 0.00540531
	LOSS [training: 0.14648703346197955 | validation: 0.3539707627035901]
	TIME [epoch: 16 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1475797711816813		[learning rate: 0.0053798]
	Learning Rate: 0.00537984
	LOSS [training: 0.1475797711816813 | validation: 0.3306848567872659]
	TIME [epoch: 16 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18629485185775135		[learning rate: 0.0053545]
	Learning Rate: 0.00535449
	LOSS [training: 0.18629485185775135 | validation: 0.33591504276250145]
	TIME [epoch: 15.9 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15832807826857698		[learning rate: 0.0053293]
	Learning Rate: 0.00532926
	LOSS [training: 0.15832807826857698 | validation: 0.31495109891420636]
	TIME [epoch: 16 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18370612574701406		[learning rate: 0.0053041]
	Learning Rate: 0.00530415
	LOSS [training: 0.18370612574701406 | validation: 0.5632426599896784]
	TIME [epoch: 16 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20403941803823542		[learning rate: 0.0052792]
	Learning Rate: 0.00527915
	LOSS [training: 0.20403941803823542 | validation: 0.3462839336831928]
	TIME [epoch: 16 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1742771607581844		[learning rate: 0.0052543]
	Learning Rate: 0.00525428
	LOSS [training: 0.1742771607581844 | validation: 0.31619578881895166]
	TIME [epoch: 16 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19796410442786602		[learning rate: 0.0052295]
	Learning Rate: 0.00522952
	LOSS [training: 0.19796410442786602 | validation: 0.3313797745232193]
	TIME [epoch: 16 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14892858973589482		[learning rate: 0.0052049]
	Learning Rate: 0.00520487
	LOSS [training: 0.14892858973589482 | validation: 0.37059423001443653]
	TIME [epoch: 16 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15604604873575112		[learning rate: 0.0051803]
	Learning Rate: 0.00518035
	LOSS [training: 0.15604604873575112 | validation: 0.31606841448602524]
	TIME [epoch: 16 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1670883084324303		[learning rate: 0.0051559]
	Learning Rate: 0.00515594
	LOSS [training: 0.1670883084324303 | validation: 0.34042966676186726]
	TIME [epoch: 16 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1740317535314505		[learning rate: 0.0051316]
	Learning Rate: 0.00513164
	LOSS [training: 0.1740317535314505 | validation: 0.31029887979133136]
	TIME [epoch: 16 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17459800935759562		[learning rate: 0.0051075]
	Learning Rate: 0.00510746
	LOSS [training: 0.17459800935759562 | validation: 0.35034663412258715]
	TIME [epoch: 16 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15482214960747243		[learning rate: 0.0050834]
	Learning Rate: 0.00508339
	LOSS [training: 0.15482214960747243 | validation: 0.3132549998313456]
	TIME [epoch: 16 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16258064081784104		[learning rate: 0.0050594]
	Learning Rate: 0.00505944
	LOSS [training: 0.16258064081784104 | validation: 0.38108931922442824]
	TIME [epoch: 16 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18063226049736714		[learning rate: 0.0050356]
	Learning Rate: 0.0050356
	LOSS [training: 0.18063226049736714 | validation: 0.3719216534446977]
	TIME [epoch: 16 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20382251564293655		[learning rate: 0.0050119]
	Learning Rate: 0.00501187
	LOSS [training: 0.20382251564293655 | validation: 0.3102844128485144]
	TIME [epoch: 15.9 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1760100100171857		[learning rate: 0.0049883]
	Learning Rate: 0.00498826
	LOSS [training: 0.1760100100171857 | validation: 0.3305525276938467]
	TIME [epoch: 16 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15243793730291477		[learning rate: 0.0049648]
	Learning Rate: 0.00496475
	LOSS [training: 0.15243793730291477 | validation: 0.33996325798236016]
	TIME [epoch: 15.9 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14906928323817165		[learning rate: 0.0049414]
	Learning Rate: 0.00494136
	LOSS [training: 0.14906928323817165 | validation: 0.36273925492310166]
	TIME [epoch: 16 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19332782049576921		[learning rate: 0.0049181]
	Learning Rate: 0.00491807
	LOSS [training: 0.19332782049576921 | validation: 0.3723300495511251]
	TIME [epoch: 16 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19904270721656642		[learning rate: 0.0048949]
	Learning Rate: 0.0048949
	LOSS [training: 0.19904270721656642 | validation: 0.3535504334442931]
	TIME [epoch: 15.9 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18611507993237897		[learning rate: 0.0048718]
	Learning Rate: 0.00487183
	LOSS [training: 0.18611507993237897 | validation: 0.34336640441128113]
	TIME [epoch: 16 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16649250185161157		[learning rate: 0.0048489]
	Learning Rate: 0.00484888
	LOSS [training: 0.16649250185161157 | validation: 0.315948796422596]
	TIME [epoch: 16 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16817263490312462		[learning rate: 0.004826]
	Learning Rate: 0.00482603
	LOSS [training: 0.16817263490312462 | validation: 0.32141051017825717]
	TIME [epoch: 15.9 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15069044144669405		[learning rate: 0.0048033]
	Learning Rate: 0.00480329
	LOSS [training: 0.15069044144669405 | validation: 0.3737013778831295]
	TIME [epoch: 16 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1755558442645207		[learning rate: 0.0047807]
	Learning Rate: 0.00478065
	LOSS [training: 0.1755558442645207 | validation: 0.3352906755977107]
	TIME [epoch: 16 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15341817137801583		[learning rate: 0.0047581]
	Learning Rate: 0.00475813
	LOSS [training: 0.15341817137801583 | validation: 0.36471154995266636]
	TIME [epoch: 16 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1492387651696646		[learning rate: 0.0047357]
	Learning Rate: 0.0047357
	LOSS [training: 0.1492387651696646 | validation: 0.31929367741433173]
	TIME [epoch: 16 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1602076207837232		[learning rate: 0.0047134]
	Learning Rate: 0.00471339
	LOSS [training: 0.1602076207837232 | validation: 0.32998472004205315]
	TIME [epoch: 16 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1638120012348448		[learning rate: 0.0046912]
	Learning Rate: 0.00469118
	LOSS [training: 0.1638120012348448 | validation: 0.33841521428428356]
	TIME [epoch: 16 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17289561972229772		[learning rate: 0.0046691]
	Learning Rate: 0.00466907
	LOSS [training: 0.17289561972229772 | validation: 0.3308446982887458]
	TIME [epoch: 16 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1652213115184686		[learning rate: 0.0046471]
	Learning Rate: 0.00464707
	LOSS [training: 0.1652213115184686 | validation: 0.35667612800126375]
	TIME [epoch: 15.9 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1557089911735059		[learning rate: 0.0046252]
	Learning Rate: 0.00462518
	LOSS [training: 0.1557089911735059 | validation: 0.33991151030358147]
	TIME [epoch: 55.1 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16912896630734464		[learning rate: 0.0046034]
	Learning Rate: 0.00460338
	LOSS [training: 0.16912896630734464 | validation: 0.31536618644342956]
	TIME [epoch: 34.2 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13771993721091777		[learning rate: 0.0045817]
	Learning Rate: 0.00458169
	LOSS [training: 0.13771993721091777 | validation: 0.3935452218846429]
	TIME [epoch: 34.3 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2083001312217866		[learning rate: 0.0045601]
	Learning Rate: 0.0045601
	LOSS [training: 0.2083001312217866 | validation: 0.42062355949477154]
	TIME [epoch: 34.3 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17352451361029667		[learning rate: 0.0045386]
	Learning Rate: 0.00453861
	LOSS [training: 0.17352451361029667 | validation: 0.35043415883575557]
	TIME [epoch: 34.3 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17820284950429682		[learning rate: 0.0045172]
	Learning Rate: 0.00451723
	LOSS [training: 0.17820284950429682 | validation: 0.3164895525006245]
	TIME [epoch: 34.2 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15929342244906017		[learning rate: 0.0044959]
	Learning Rate: 0.00449594
	LOSS [training: 0.15929342244906017 | validation: 0.31369446362034614]
	TIME [epoch: 34.3 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18332987950726296		[learning rate: 0.0044748]
	Learning Rate: 0.00447475
	LOSS [training: 0.18332987950726296 | validation: 0.2894072863358223]
	TIME [epoch: 34.2 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v14b_20240716_170458/states/model_facs_v3_dec2b_2dpca_v14b_208.pth
	Model improved!!!
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19026953733752563		[learning rate: 0.0044537]
	Learning Rate: 0.00445367
	LOSS [training: 0.19026953733752563 | validation: 0.403492874181049]
	TIME [epoch: 34.2 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1702286063797203		[learning rate: 0.0044327]
	Learning Rate: 0.00443268
	LOSS [training: 0.1702286063797203 | validation: 0.29976561297630533]
	TIME [epoch: 34.2 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1680490330510442		[learning rate: 0.0044118]
	Learning Rate: 0.0044118
	LOSS [training: 0.1680490330510442 | validation: 0.3220050335573963]
	TIME [epoch: 34.3 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16381248686893551		[learning rate: 0.004391]
	Learning Rate: 0.00439101
	LOSS [training: 0.16381248686893551 | validation: 0.3440543349798493]
	TIME [epoch: 34.3 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16348088772050157		[learning rate: 0.0043703]
	Learning Rate: 0.00437032
	LOSS [training: 0.16348088772050157 | validation: 0.3227642364326001]
	TIME [epoch: 34.3 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1657190351035108		[learning rate: 0.0043497]
	Learning Rate: 0.00434972
	LOSS [training: 0.1657190351035108 | validation: 0.40282894689444093]
	TIME [epoch: 34.3 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1708923545197592		[learning rate: 0.0043292]
	Learning Rate: 0.00432923
	LOSS [training: 0.1708923545197592 | validation: 0.3139388089815848]
	TIME [epoch: 34.3 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13914861820118593		[learning rate: 0.0043088]
	Learning Rate: 0.00430883
	LOSS [training: 0.13914861820118593 | validation: 0.3328041214270432]
	TIME [epoch: 34.2 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16748936497896416		[learning rate: 0.0042885]
	Learning Rate: 0.00428852
	LOSS [training: 0.16748936497896416 | validation: 0.3222220444415388]
	TIME [epoch: 34.3 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16823175593886835		[learning rate: 0.0042683]
	Learning Rate: 0.00426831
	LOSS [training: 0.16823175593886835 | validation: 0.3574760734722585]
	TIME [epoch: 34.3 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16588478932085624		[learning rate: 0.0042482]
	Learning Rate: 0.0042482
	LOSS [training: 0.16588478932085624 | validation: 0.33261825994326016]
	TIME [epoch: 34.1 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17598300443716075		[learning rate: 0.0042282]
	Learning Rate: 0.00422818
	LOSS [training: 0.17598300443716075 | validation: 0.2980706752063889]
	TIME [epoch: 34.2 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17919831076553		[learning rate: 0.0042083]
	Learning Rate: 0.00420826
	LOSS [training: 0.17919831076553 | validation: 0.3319225981121509]
	TIME [epoch: 34.3 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17044995893898976		[learning rate: 0.0041884]
	Learning Rate: 0.00418843
	LOSS [training: 0.17044995893898976 | validation: 0.3228269259297341]
	TIME [epoch: 34.2 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17361700767140278		[learning rate: 0.0041687]
	Learning Rate: 0.00416869
	LOSS [training: 0.17361700767140278 | validation: 0.300021861757461]
	TIME [epoch: 34.3 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14817561901534493		[learning rate: 0.0041491]
	Learning Rate: 0.00414905
	LOSS [training: 0.14817561901534493 | validation: 0.36993923770346804]
	TIME [epoch: 34.2 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16185730418930833		[learning rate: 0.0041295]
	Learning Rate: 0.0041295
	LOSS [training: 0.16185730418930833 | validation: 0.32660671662911017]
	TIME [epoch: 34.3 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1451247043757982		[learning rate: 0.00411]
	Learning Rate: 0.00411004
	LOSS [training: 0.1451247043757982 | validation: 0.2982054129813996]
	TIME [epoch: 34.2 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1641374433644805		[learning rate: 0.0040907]
	Learning Rate: 0.00409067
	LOSS [training: 0.1641374433644805 | validation: 0.30715686311348017]
	TIME [epoch: 34.2 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14148293647281587		[learning rate: 0.0040714]
	Learning Rate: 0.0040714
	LOSS [training: 0.14148293647281587 | validation: 0.3110815557703106]
	TIME [epoch: 34.2 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18593149031840764		[learning rate: 0.0040522]
	Learning Rate: 0.00405221
	LOSS [training: 0.18593149031840764 | validation: 0.3034582989690869]
	TIME [epoch: 34.3 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14490158905207726		[learning rate: 0.0040331]
	Learning Rate: 0.00403312
	LOSS [training: 0.14490158905207726 | validation: 0.3563883570016407]
	TIME [epoch: 34.2 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19467691200746673		[learning rate: 0.0040141]
	Learning Rate: 0.00401411
	LOSS [training: 0.19467691200746673 | validation: 0.32892274149512235]
	TIME [epoch: 34.2 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16565625958664096		[learning rate: 0.0039952]
	Learning Rate: 0.0039952
	LOSS [training: 0.16565625958664096 | validation: 0.39562755374871567]
	TIME [epoch: 34.2 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15633148099197672		[learning rate: 0.0039764]
	Learning Rate: 0.00397637
	LOSS [training: 0.15633148099197672 | validation: 0.3205993685997504]
	TIME [epoch: 34.3 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15746540011790944		[learning rate: 0.0039576]
	Learning Rate: 0.00395764
	LOSS [training: 0.15746540011790944 | validation: 0.2900966832317313]
	TIME [epoch: 34.2 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15530873017493182		[learning rate: 0.003939]
	Learning Rate: 0.00393899
	LOSS [training: 0.15530873017493182 | validation: 0.29870605779312975]
	TIME [epoch: 34.3 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.157621479501589		[learning rate: 0.0039204]
	Learning Rate: 0.00392043
	LOSS [training: 0.157621479501589 | validation: 0.3260773953015296]
	TIME [epoch: 34.3 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15920577318343881		[learning rate: 0.003902]
	Learning Rate: 0.00390195
	LOSS [training: 0.15920577318343881 | validation: 0.3246338936732229]
	TIME [epoch: 34.3 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16838967129562984		[learning rate: 0.0038836]
	Learning Rate: 0.00388357
	LOSS [training: 0.16838967129562984 | validation: 0.3398153632474324]
	TIME [epoch: 34.3 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17109702743053407		[learning rate: 0.0038653]
	Learning Rate: 0.00386527
	LOSS [training: 0.17109702743053407 | validation: 0.31543726455405235]
	TIME [epoch: 34.3 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1546680736612454		[learning rate: 0.0038471]
	Learning Rate: 0.00384705
	LOSS [training: 0.1546680736612454 | validation: 0.3197595101283966]
	TIME [epoch: 34.3 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15298217149852628		[learning rate: 0.0038289]
	Learning Rate: 0.00382893
	LOSS [training: 0.15298217149852628 | validation: 0.3162187548460521]
	TIME [epoch: 34.3 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16033028726034915		[learning rate: 0.0038109]
	Learning Rate: 0.00381088
	LOSS [training: 0.16033028726034915 | validation: 0.3334255842137082]
	TIME [epoch: 34.3 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1659770827540779		[learning rate: 0.0037929]
	Learning Rate: 0.00379293
	LOSS [training: 0.1659770827540779 | validation: 0.3118855204819317]
	TIME [epoch: 34.3 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15062044808577923		[learning rate: 0.0037751]
	Learning Rate: 0.00377505
	LOSS [training: 0.15062044808577923 | validation: 0.3237995739807285]
	TIME [epoch: 34.3 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16574904552723452		[learning rate: 0.0037573]
	Learning Rate: 0.00375726
	LOSS [training: 0.16574904552723452 | validation: 0.33379740752955495]
	TIME [epoch: 34.3 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2022421373167525		[learning rate: 0.0037396]
	Learning Rate: 0.00373956
	LOSS [training: 0.2022421373167525 | validation: 0.3025577142854783]
	TIME [epoch: 34.3 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1581100247125885		[learning rate: 0.0037219]
	Learning Rate: 0.00372194
	LOSS [training: 0.1581100247125885 | validation: 0.3655898071218747]
	TIME [epoch: 34.2 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14764666527853154		[learning rate: 0.0037044]
	Learning Rate: 0.0037044
	LOSS [training: 0.14764666527853154 | validation: 0.2973952252109301]
	TIME [epoch: 34.3 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13611066837055158		[learning rate: 0.0036869]
	Learning Rate: 0.00368695
	LOSS [training: 0.13611066837055158 | validation: 0.3254961244350907]
	TIME [epoch: 34.3 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15669726774651505		[learning rate: 0.0036696]
	Learning Rate: 0.00366957
	LOSS [training: 0.15669726774651505 | validation: 0.31566357619032737]
	TIME [epoch: 34.3 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14037325476449505		[learning rate: 0.0036523]
	Learning Rate: 0.00365228
	LOSS [training: 0.14037325476449505 | validation: 0.30072218956654956]
	TIME [epoch: 34.3 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16114689403972196		[learning rate: 0.0036351]
	Learning Rate: 0.00363507
	LOSS [training: 0.16114689403972196 | validation: 0.28954916517049795]
	TIME [epoch: 34.3 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1947057428862628		[learning rate: 0.0036179]
	Learning Rate: 0.00361794
	LOSS [training: 0.1947057428862628 | validation: 0.3354493191814948]
	TIME [epoch: 34.2 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17164545956474234		[learning rate: 0.0036009]
	Learning Rate: 0.00360089
	LOSS [training: 0.17164545956474234 | validation: 0.3040807932777553]
	TIME [epoch: 34.3 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15425317301007285		[learning rate: 0.0035839]
	Learning Rate: 0.00358393
	LOSS [training: 0.15425317301007285 | validation: 0.3495555744932019]
	TIME [epoch: 34.2 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.144015957343186		[learning rate: 0.003567]
	Learning Rate: 0.00356704
	LOSS [training: 0.144015957343186 | validation: 0.33494040840703987]
	TIME [epoch: 34.3 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15967611951039765		[learning rate: 0.0035502]
	Learning Rate: 0.00355023
	LOSS [training: 0.15967611951039765 | validation: 0.32315831241696863]
	TIME [epoch: 34.3 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1435562797950505		[learning rate: 0.0035335]
	Learning Rate: 0.0035335
	LOSS [training: 0.1435562797950505 | validation: 0.31562152135478794]
	TIME [epoch: 34.2 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1557003223557047		[learning rate: 0.0035168]
	Learning Rate: 0.00351685
	LOSS [training: 0.1557003223557047 | validation: 0.29042224855921844]
	TIME [epoch: 34.3 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16109153457339115		[learning rate: 0.0035003]
	Learning Rate: 0.00350028
	LOSS [training: 0.16109153457339115 | validation: 0.3301518650895775]
	TIME [epoch: 34.2 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16127022582553202		[learning rate: 0.0034838]
	Learning Rate: 0.00348378
	LOSS [training: 0.16127022582553202 | validation: 0.35963906833979553]
	TIME [epoch: 34.3 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16904596223242754		[learning rate: 0.0034674]
	Learning Rate: 0.00346737
	LOSS [training: 0.16904596223242754 | validation: 0.3637938984302222]
	TIME [epoch: 34.2 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13742324299708214		[learning rate: 0.003451]
	Learning Rate: 0.00345103
	LOSS [training: 0.13742324299708214 | validation: 0.30690515580558275]
	TIME [epoch: 34.3 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14848011878299638		[learning rate: 0.0034348]
	Learning Rate: 0.00343477
	LOSS [training: 0.14848011878299638 | validation: 0.2989882850263851]
	TIME [epoch: 34.3 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15034288534463505		[learning rate: 0.0034186]
	Learning Rate: 0.00341858
	LOSS [training: 0.15034288534463505 | validation: 0.41604950831371773]
	TIME [epoch: 34.3 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16053006516930798		[learning rate: 0.0034025]
	Learning Rate: 0.00340247
	LOSS [training: 0.16053006516930798 | validation: 0.32776217773638006]
	TIME [epoch: 34.2 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15224493952649643		[learning rate: 0.0033864]
	Learning Rate: 0.00338644
	LOSS [training: 0.15224493952649643 | validation: 0.3205009431988066]
	TIME [epoch: 34.3 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1405285701668132		[learning rate: 0.0033705]
	Learning Rate: 0.00337048
	LOSS [training: 0.1405285701668132 | validation: 0.3068208659262588]
	TIME [epoch: 34.2 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1597074737068277		[learning rate: 0.0033546]
	Learning Rate: 0.0033546
	LOSS [training: 0.1597074737068277 | validation: 0.34465675240322385]
	TIME [epoch: 34.3 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16387542362400853		[learning rate: 0.0033388]
	Learning Rate: 0.00333879
	LOSS [training: 0.16387542362400853 | validation: 0.3248769786501101]
	TIME [epoch: 34.3 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1493011837456641		[learning rate: 0.0033231]
	Learning Rate: 0.00332306
	LOSS [training: 0.1493011837456641 | validation: 0.37944634164638547]
	TIME [epoch: 34.3 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14377800086051323		[learning rate: 0.0033074]
	Learning Rate: 0.0033074
	LOSS [training: 0.14377800086051323 | validation: 0.2850940195628684]
	TIME [epoch: 34.3 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v14b_20240716_170458/states/model_facs_v3_dec2b_2dpca_v14b_272.pth
	Model improved!!!
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15004793153378315		[learning rate: 0.0032918]
	Learning Rate: 0.00329182
	LOSS [training: 0.15004793153378315 | validation: 0.3492210973851807]
	TIME [epoch: 34.3 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15069405071730194		[learning rate: 0.0032763]
	Learning Rate: 0.00327631
	LOSS [training: 0.15069405071730194 | validation: 0.32026675577124425]
	TIME [epoch: 34.3 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16711163954590225		[learning rate: 0.0032609]
	Learning Rate: 0.00326087
	LOSS [training: 0.16711163954590225 | validation: 0.3445451922091923]
	TIME [epoch: 34.3 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16248749519182715		[learning rate: 0.0032455]
	Learning Rate: 0.0032455
	LOSS [training: 0.16248749519182715 | validation: 0.3340407067267429]
	TIME [epoch: 34.3 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14104179881686174		[learning rate: 0.0032302]
	Learning Rate: 0.00323021
	LOSS [training: 0.14104179881686174 | validation: 0.33285265096357053]
	TIME [epoch: 34.2 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1482348207389581		[learning rate: 0.003215]
	Learning Rate: 0.00321499
	LOSS [training: 0.1482348207389581 | validation: 0.3270319495676762]
	TIME [epoch: 34.4 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15061924425507167		[learning rate: 0.0031998]
	Learning Rate: 0.00319984
	LOSS [training: 0.15061924425507167 | validation: 0.3589055555527094]
	TIME [epoch: 34.2 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16517558500566668		[learning rate: 0.0031848]
	Learning Rate: 0.00318476
	LOSS [training: 0.16517558500566668 | validation: 0.30752876523739625]
	TIME [epoch: 34.3 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14942443179500425		[learning rate: 0.0031698]
	Learning Rate: 0.00316975
	LOSS [training: 0.14942443179500425 | validation: 0.288196725965293]
	TIME [epoch: 34.3 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1476925125331738		[learning rate: 0.0031548]
	Learning Rate: 0.00315482
	LOSS [training: 0.1476925125331738 | validation: 0.303632125725001]
	TIME [epoch: 34.4 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16281480112920743		[learning rate: 0.00314]
	Learning Rate: 0.00313995
	LOSS [training: 0.16281480112920743 | validation: 0.3189920788746727]
	TIME [epoch: 34.3 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1527156960650444		[learning rate: 0.0031252]
	Learning Rate: 0.00312516
	LOSS [training: 0.1527156960650444 | validation: 0.30365354862128496]
	TIME [epoch: 34.4 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14941701876180827		[learning rate: 0.0031104]
	Learning Rate: 0.00311043
	LOSS [training: 0.14941701876180827 | validation: 0.3558542788640787]
	TIME [epoch: 34.4 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16130897131061223		[learning rate: 0.0030958]
	Learning Rate: 0.00309577
	LOSS [training: 0.16130897131061223 | validation: 0.35005334963208934]
	TIME [epoch: 34.3 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15844406106236997		[learning rate: 0.0030812]
	Learning Rate: 0.00308119
	LOSS [training: 0.15844406106236997 | validation: 0.3476763886420498]
	TIME [epoch: 34.4 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1398000432388906		[learning rate: 0.0030667]
	Learning Rate: 0.00306667
	LOSS [training: 0.1398000432388906 | validation: 0.29835196170126005]
	TIME [epoch: 34.4 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1398728534929149		[learning rate: 0.0030522]
	Learning Rate: 0.00305222
	LOSS [training: 0.1398728534929149 | validation: 0.3195390452002956]
	TIME [epoch: 34.3 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1575730961101605		[learning rate: 0.0030378]
	Learning Rate: 0.00303783
	LOSS [training: 0.1575730961101605 | validation: 0.3047274943158357]
	TIME [epoch: 34.4 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1520186260969521		[learning rate: 0.0030235]
	Learning Rate: 0.00302352
	LOSS [training: 0.1520186260969521 | validation: 0.3018651518834631]
	TIME [epoch: 34.3 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14341454669479778		[learning rate: 0.0030093]
	Learning Rate: 0.00300927
	LOSS [training: 0.14341454669479778 | validation: 0.32165832903825164]
	TIME [epoch: 34.4 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16184070447291948		[learning rate: 0.0029951]
	Learning Rate: 0.00299509
	LOSS [training: 0.16184070447291948 | validation: 0.3403497090603643]
	TIME [epoch: 34.3 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14095560818721842		[learning rate: 0.002981]
	Learning Rate: 0.00298098
	LOSS [training: 0.14095560818721842 | validation: 0.3081570946424169]
	TIME [epoch: 34.4 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13983789565308571		[learning rate: 0.0029669]
	Learning Rate: 0.00296693
	LOSS [training: 0.13983789565308571 | validation: 0.34683128552139647]
	TIME [epoch: 34.4 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15386268507423903		[learning rate: 0.002953]
	Learning Rate: 0.00295295
	LOSS [training: 0.15386268507423903 | validation: 0.3007963800355699]
	TIME [epoch: 34.4 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14555668057028842		[learning rate: 0.002939]
	Learning Rate: 0.00293904
	LOSS [training: 0.14555668057028842 | validation: 0.33077883715778883]
	TIME [epoch: 34.4 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13993146737654602		[learning rate: 0.0029252]
	Learning Rate: 0.00292519
	LOSS [training: 0.13993146737654602 | validation: 0.3328305081807909]
	TIME [epoch: 34.4 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1522279270523045		[learning rate: 0.0029114]
	Learning Rate: 0.0029114
	LOSS [training: 0.1522279270523045 | validation: 0.30544541277752457]
	TIME [epoch: 34.4 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15127991045309555		[learning rate: 0.0028977]
	Learning Rate: 0.00289769
	LOSS [training: 0.15127991045309555 | validation: 0.3536750378282192]
	TIME [epoch: 34.4 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16297932611711213		[learning rate: 0.002884]
	Learning Rate: 0.00288403
	LOSS [training: 0.16297932611711213 | validation: 0.3249782024319416]
	TIME [epoch: 92 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19425019248784078		[learning rate: 0.0028704]
	Learning Rate: 0.00287044
	LOSS [training: 0.19425019248784078 | validation: 0.33383606446042813]
	TIME [epoch: 70.9 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1598305187563519		[learning rate: 0.0028569]
	Learning Rate: 0.00285692
	LOSS [training: 0.1598305187563519 | validation: 0.3163414669376509]
	TIME [epoch: 70.9 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14688432292765474		[learning rate: 0.0028435]
	Learning Rate: 0.00284345
	LOSS [training: 0.14688432292765474 | validation: 0.28195285444410817]
	TIME [epoch: 71 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v14b_20240716_170458/states/model_facs_v3_dec2b_2dpca_v14b_304.pth
	Model improved!!!
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17335458098464335		[learning rate: 0.0028301]
	Learning Rate: 0.00283005
	LOSS [training: 0.17335458098464335 | validation: 0.3382763042966522]
	TIME [epoch: 71 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15731967933888025		[learning rate: 0.0028167]
	Learning Rate: 0.00281672
	LOSS [training: 0.15731967933888025 | validation: 0.3296406490227903]
	TIME [epoch: 71 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13350730550425507		[learning rate: 0.0028034]
	Learning Rate: 0.00280345
	LOSS [training: 0.13350730550425507 | validation: 0.3221814207127507]
	TIME [epoch: 70.9 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14881823756525678		[learning rate: 0.0027902]
	Learning Rate: 0.00279024
	LOSS [training: 0.14881823756525678 | validation: 0.32207712590075765]
	TIME [epoch: 70.9 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14490075875359248		[learning rate: 0.0027771]
	Learning Rate: 0.00277709
	LOSS [training: 0.14490075875359248 | validation: 0.30519159499492765]
	TIME [epoch: 70.9 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15343869857082965		[learning rate: 0.002764]
	Learning Rate: 0.002764
	LOSS [training: 0.15343869857082965 | validation: 0.30712397474184855]
	TIME [epoch: 70.9 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17215809334858784		[learning rate: 0.002751]
	Learning Rate: 0.00275098
	LOSS [training: 0.17215809334858784 | validation: 0.311470807300294]
	TIME [epoch: 70.9 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15232169870188164		[learning rate: 0.002738]
	Learning Rate: 0.00273802
	LOSS [training: 0.15232169870188164 | validation: 0.31823991562876697]
	TIME [epoch: 70.9 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18809718256296434		[learning rate: 0.0027251]
	Learning Rate: 0.00272511
	LOSS [training: 0.18809718256296434 | validation: 0.32345483853713364]
	TIME [epoch: 70.9 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14767963579679208		[learning rate: 0.0027123]
	Learning Rate: 0.00271227
	LOSS [training: 0.14767963579679208 | validation: 0.40317117345020936]
	TIME [epoch: 70.9 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14746546168469232		[learning rate: 0.0026995]
	Learning Rate: 0.00269949
	LOSS [training: 0.14746546168469232 | validation: 0.31662191425096553]
	TIME [epoch: 71 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1543619348612469		[learning rate: 0.0026868]
	Learning Rate: 0.00268677
	LOSS [training: 0.1543619348612469 | validation: 0.3286887472243239]
	TIME [epoch: 71 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15346919703280015		[learning rate: 0.0026741]
	Learning Rate: 0.00267411
	LOSS [training: 0.15346919703280015 | validation: 0.29195805466660546]
	TIME [epoch: 71.1 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14440097569512253		[learning rate: 0.0026615]
	Learning Rate: 0.00266151
	LOSS [training: 0.14440097569512253 | validation: 0.3407515000287696]
	TIME [epoch: 70.9 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13724940127224297		[learning rate: 0.002649]
	Learning Rate: 0.00264897
	LOSS [training: 0.13724940127224297 | validation: 0.3068288420917073]
	TIME [epoch: 71 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1348908637787261		[learning rate: 0.0026365]
	Learning Rate: 0.00263649
	LOSS [training: 0.1348908637787261 | validation: 0.32641630536612254]
	TIME [epoch: 71.1 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16575893723953516		[learning rate: 0.0026241]
	Learning Rate: 0.00262406
	LOSS [training: 0.16575893723953516 | validation: 0.29941159904860143]
	TIME [epoch: 71.1 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14404308690461043		[learning rate: 0.0026117]
	Learning Rate: 0.0026117
	LOSS [training: 0.14404308690461043 | validation: 0.31278088479513094]
	TIME [epoch: 71 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15507850352483027		[learning rate: 0.0025994]
	Learning Rate: 0.00259939
	LOSS [training: 0.15507850352483027 | validation: 0.2930167548305503]
	TIME [epoch: 71.1 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15961464727546243		[learning rate: 0.0025871]
	Learning Rate: 0.00258714
	LOSS [training: 0.15961464727546243 | validation: 0.3598810700764397]
	TIME [epoch: 71.1 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1644524786435698		[learning rate: 0.002575]
	Learning Rate: 0.00257495
	LOSS [training: 0.1644524786435698 | validation: 0.34569350965203993]
	TIME [epoch: 70.9 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18904389641863295		[learning rate: 0.0025628]
	Learning Rate: 0.00256282
	LOSS [training: 0.18904389641863295 | validation: 0.326475945817794]
	TIME [epoch: 71.1 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16185526312176982		[learning rate: 0.0025507]
	Learning Rate: 0.00255074
	LOSS [training: 0.16185526312176982 | validation: 0.3536199571063712]
	TIME [epoch: 71 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16313153227219224		[learning rate: 0.0025387]
	Learning Rate: 0.00253872
	LOSS [training: 0.16313153227219224 | validation: 0.3088433948767719]
	TIME [epoch: 71.1 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1419959976912426		[learning rate: 0.0025268]
	Learning Rate: 0.00252676
	LOSS [training: 0.1419959976912426 | validation: 0.3080058061190621]
	TIME [epoch: 71.1 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13979734356959178		[learning rate: 0.0025149]
	Learning Rate: 0.00251485
	LOSS [training: 0.13979734356959178 | validation: 0.3388375167045928]
	TIME [epoch: 71 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14735068052134562		[learning rate: 0.002503]
	Learning Rate: 0.002503
	LOSS [training: 0.14735068052134562 | validation: 0.31762415786982406]
	TIME [epoch: 71.1 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14332593565124857		[learning rate: 0.0024912]
	Learning Rate: 0.00249121
	LOSS [training: 0.14332593565124857 | validation: 0.29946592338405115]
	TIME [epoch: 71.1 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13310257393775637		[learning rate: 0.0024795]
	Learning Rate: 0.00247947
	LOSS [training: 0.13310257393775637 | validation: 0.2946247984797154]
	TIME [epoch: 71 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14080865433811124		[learning rate: 0.0024678]
	Learning Rate: 0.00246779
	LOSS [training: 0.14080865433811124 | validation: 0.2923692926731143]
	TIME [epoch: 70.9 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18634030095624413		[learning rate: 0.0024562]
	Learning Rate: 0.00245616
	LOSS [training: 0.18634030095624413 | validation: 0.42415626649325344]
	TIME [epoch: 70.9 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16493095069131594		[learning rate: 0.0024446]
	Learning Rate: 0.00244458
	LOSS [training: 0.16493095069131594 | validation: 0.2905850002566774]
	TIME [epoch: 70.8 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15973977437416836		[learning rate: 0.0024331]
	Learning Rate: 0.00243307
	LOSS [training: 0.15973977437416836 | validation: 0.3162722418118697]
	TIME [epoch: 71 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1942187848787595		[learning rate: 0.0024216]
	Learning Rate: 0.0024216
	LOSS [training: 0.1942187848787595 | validation: 0.36302235127476723]
	TIME [epoch: 71 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1593482391457805		[learning rate: 0.0024102]
	Learning Rate: 0.00241019
	LOSS [training: 0.1593482391457805 | validation: 0.31342094126335335]
	TIME [epoch: 70.9 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16388764742624543		[learning rate: 0.0023988]
	Learning Rate: 0.00239883
	LOSS [training: 0.16388764742624543 | validation: 0.32286365546633655]
	TIME [epoch: 70.9 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16536443360933714		[learning rate: 0.0023875]
	Learning Rate: 0.00238753
	LOSS [training: 0.16536443360933714 | validation: 0.34089323210028716]
	TIME [epoch: 70.9 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13515104643429782		[learning rate: 0.0023763]
	Learning Rate: 0.00237628
	LOSS [training: 0.13515104643429782 | validation: 0.3123493142051677]
	TIME [epoch: 71.1 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1613181804867305		[learning rate: 0.0023651]
	Learning Rate: 0.00236508
	LOSS [training: 0.1613181804867305 | validation: 0.3128234323127922]
	TIME [epoch: 71 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14219974017445478		[learning rate: 0.0023539]
	Learning Rate: 0.00235394
	LOSS [training: 0.14219974017445478 | validation: 0.32260024279766236]
	TIME [epoch: 71 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14794991407217506		[learning rate: 0.0023428]
	Learning Rate: 0.00234285
	LOSS [training: 0.14794991407217506 | validation: 0.3351526134255403]
	TIME [epoch: 71 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13317533277687066		[learning rate: 0.0023318]
	Learning Rate: 0.00233181
	LOSS [training: 0.13317533277687066 | validation: 0.3135234490670817]
	TIME [epoch: 70.9 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16230305688940613		[learning rate: 0.0023208]
	Learning Rate: 0.00232082
	LOSS [training: 0.16230305688940613 | validation: 0.3326661242809589]
	TIME [epoch: 71.1 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13235727078495624		[learning rate: 0.0023099]
	Learning Rate: 0.00230988
	LOSS [training: 0.13235727078495624 | validation: 0.3108279668455587]
	TIME [epoch: 70.9 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1481255416979618		[learning rate: 0.002299]
	Learning Rate: 0.002299
	LOSS [training: 0.1481255416979618 | validation: 0.3156382014838122]
	TIME [epoch: 71.1 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15659250218245263		[learning rate: 0.0022882]
	Learning Rate: 0.00228816
	LOSS [training: 0.15659250218245263 | validation: 0.31650826226322026]
	TIME [epoch: 70.9 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14303506825656348		[learning rate: 0.0022774]
	Learning Rate: 0.00227738
	LOSS [training: 0.14303506825656348 | validation: 0.3675695807314792]
	TIME [epoch: 71 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1526013500424659		[learning rate: 0.0022667]
	Learning Rate: 0.00226665
	LOSS [training: 0.1526013500424659 | validation: 0.2982064232556512]
	TIME [epoch: 71.1 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14903672580074978		[learning rate: 0.002256]
	Learning Rate: 0.00225597
	LOSS [training: 0.14903672580074978 | validation: 0.31558648700932224]
	TIME [epoch: 71.1 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14005555398886105		[learning rate: 0.0022453]
	Learning Rate: 0.00224534
	LOSS [training: 0.14005555398886105 | validation: 0.3046495548880044]
	TIME [epoch: 71.1 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13475702049776517		[learning rate: 0.0022348]
	Learning Rate: 0.00223476
	LOSS [training: 0.13475702049776517 | validation: 0.3105279726873582]
	TIME [epoch: 71.1 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18273726999349976		[learning rate: 0.0022242]
	Learning Rate: 0.00222423
	LOSS [training: 0.18273726999349976 | validation: 0.35647921729923704]
	TIME [epoch: 70.9 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1365188643300099		[learning rate: 0.0022137]
	Learning Rate: 0.00221375
	LOSS [training: 0.1365188643300099 | validation: 0.3047211952765709]
	TIME [epoch: 70.9 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14593079666624817		[learning rate: 0.0022033]
	Learning Rate: 0.00220332
	LOSS [training: 0.14593079666624817 | validation: 0.3091615476095661]
	TIME [epoch: 70.9 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15524038614177083		[learning rate: 0.0021929]
	Learning Rate: 0.00219293
	LOSS [training: 0.15524038614177083 | validation: 0.29267226051392164]
	TIME [epoch: 70.8 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1688063789981094		[learning rate: 0.0021826]
	Learning Rate: 0.0021826
	LOSS [training: 0.1688063789981094 | validation: 0.32743209031714715]
	TIME [epoch: 71.1 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13342165229475275		[learning rate: 0.0021723]
	Learning Rate: 0.00217232
	LOSS [training: 0.13342165229475275 | validation: 0.33927048798442816]
	TIME [epoch: 71 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1411367134172124		[learning rate: 0.0021621]
	Learning Rate: 0.00216208
	LOSS [training: 0.1411367134172124 | validation: 0.2990833570688662]
	TIME [epoch: 71 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14417014357456182		[learning rate: 0.0021519]
	Learning Rate: 0.00215189
	LOSS [training: 0.14417014357456182 | validation: 0.30959166698773904]
	TIME [epoch: 71 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16593933512388664		[learning rate: 0.0021418]
	Learning Rate: 0.00214175
	LOSS [training: 0.16593933512388664 | validation: 0.3057061382514352]
	TIME [epoch: 71.1 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1572998399253198		[learning rate: 0.0021317]
	Learning Rate: 0.00213166
	LOSS [training: 0.1572998399253198 | validation: 0.32325836139804454]
	TIME [epoch: 70.8 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15545519904515862		[learning rate: 0.0021216]
	Learning Rate: 0.00212162
	LOSS [training: 0.15545519904515862 | validation: 0.30591895774262434]
	TIME [epoch: 71 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15555501536352948		[learning rate: 0.0021116]
	Learning Rate: 0.00211162
	LOSS [training: 0.15555501536352948 | validation: 0.3251364269461062]
	TIME [epoch: 71 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16068107537749782		[learning rate: 0.0021017]
	Learning Rate: 0.00210167
	LOSS [training: 0.16068107537749782 | validation: 0.29177230397405174]
	TIME [epoch: 71 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14558200272092214		[learning rate: 0.0020918]
	Learning Rate: 0.00209176
	LOSS [training: 0.14558200272092214 | validation: 0.29327575615314844]
	TIME [epoch: 70.9 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13711294119117548		[learning rate: 0.0020819]
	Learning Rate: 0.00208191
	LOSS [training: 0.13711294119117548 | validation: 0.29509990862210167]
	TIME [epoch: 71 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1485198121362884		[learning rate: 0.0020721]
	Learning Rate: 0.0020721
	LOSS [training: 0.1485198121362884 | validation: 0.2929964353971047]
	TIME [epoch: 70.9 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17407114772027915		[learning rate: 0.0020623]
	Learning Rate: 0.00206233
	LOSS [training: 0.17407114772027915 | validation: 0.3303725394491696]
	TIME [epoch: 71.1 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15438052674425531		[learning rate: 0.0020526]
	Learning Rate: 0.00205262
	LOSS [training: 0.15438052674425531 | validation: 0.31676365494039976]
	TIME [epoch: 70.9 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1576074516730783		[learning rate: 0.0020429]
	Learning Rate: 0.00204294
	LOSS [training: 0.1576074516730783 | validation: 0.34215251237862415]
	TIME [epoch: 70.9 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13486453196609174		[learning rate: 0.0020333]
	Learning Rate: 0.00203332
	LOSS [training: 0.13486453196609174 | validation: 0.29600040578822767]
	TIME [epoch: 71.1 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14921925494688237		[learning rate: 0.0020237]
	Learning Rate: 0.00202374
	LOSS [training: 0.14921925494688237 | validation: 0.3173629555691065]
	TIME [epoch: 71 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14701406159842959		[learning rate: 0.0020142]
	Learning Rate: 0.0020142
	LOSS [training: 0.14701406159842959 | validation: 0.3158201092291326]
	TIME [epoch: 70.9 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1460980006566023		[learning rate: 0.0020047]
	Learning Rate: 0.00200471
	LOSS [training: 0.1460980006566023 | validation: 0.32080174381663884]
	TIME [epoch: 71.1 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17196034352440026		[learning rate: 0.0019953]
	Learning Rate: 0.00199526
	LOSS [training: 0.17196034352440026 | validation: 0.3442621589123206]
	TIME [epoch: 71 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15788951781084992		[learning rate: 0.0019859]
	Learning Rate: 0.00198586
	LOSS [training: 0.15788951781084992 | validation: 0.29830156913527833]
	TIME [epoch: 70.9 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14874197609307402		[learning rate: 0.0019765]
	Learning Rate: 0.0019765
	LOSS [training: 0.14874197609307402 | validation: 0.34208521047601226]
	TIME [epoch: 70.8 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14020239343396898		[learning rate: 0.0019672]
	Learning Rate: 0.00196719
	LOSS [training: 0.14020239343396898 | validation: 0.29176396940695803]
	TIME [epoch: 71 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13178907192804928		[learning rate: 0.0019579]
	Learning Rate: 0.00195792
	LOSS [training: 0.13178907192804928 | validation: 0.3031266038323626]
	TIME [epoch: 70.9 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13199870758913895		[learning rate: 0.0019487]
	Learning Rate: 0.00194869
	LOSS [training: 0.13199870758913895 | validation: 0.29722347939036364]
	TIME [epoch: 70.9 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14864584684747364		[learning rate: 0.0019395]
	Learning Rate: 0.00193951
	LOSS [training: 0.14864584684747364 | validation: 0.39523938757225263]
	TIME [epoch: 70.8 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14656813441532301		[learning rate: 0.0019304]
	Learning Rate: 0.00193037
	LOSS [training: 0.14656813441532301 | validation: 0.29098403994463556]
	TIME [epoch: 71.1 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1535233820914052		[learning rate: 0.0019213]
	Learning Rate: 0.00192128
	LOSS [training: 0.1535233820914052 | validation: 0.30927879218767473]
	TIME [epoch: 71 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13678552373307448		[learning rate: 0.0019122]
	Learning Rate: 0.00191222
	LOSS [training: 0.13678552373307448 | validation: 0.317218464174979]
	TIME [epoch: 71 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14519775751421624		[learning rate: 0.0019032]
	Learning Rate: 0.00190321
	LOSS [training: 0.14519775751421624 | validation: 0.3069586220450443]
	TIME [epoch: 71 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1556978935207043		[learning rate: 0.0018942]
	Learning Rate: 0.00189424
	LOSS [training: 0.1556978935207043 | validation: 0.287375087599231]
	TIME [epoch: 71.1 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1449449288886675		[learning rate: 0.0018853]
	Learning Rate: 0.00188532
	LOSS [training: 0.1449449288886675 | validation: 0.3430403879815993]
	TIME [epoch: 71 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1549505810869679		[learning rate: 0.0018764]
	Learning Rate: 0.00187643
	LOSS [training: 0.1549505810869679 | validation: 0.3129773901864601]
	TIME [epoch: 70.9 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14790117720873536		[learning rate: 0.0018676]
	Learning Rate: 0.00186759
	LOSS [training: 0.14790117720873536 | validation: 0.34125766134075985]
	TIME [epoch: 71 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15490492082028634		[learning rate: 0.0018588]
	Learning Rate: 0.00185879
	LOSS [training: 0.15490492082028634 | validation: 0.3106579915305784]
	TIME [epoch: 71 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15043925872481362		[learning rate: 0.00185]
	Learning Rate: 0.00185003
	LOSS [training: 0.15043925872481362 | validation: 0.31844845623459256]
	TIME [epoch: 71.1 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17051812104634917		[learning rate: 0.0018413]
	Learning Rate: 0.00184132
	LOSS [training: 0.17051812104634917 | validation: 0.3618271492956176]
	TIME [epoch: 70.7 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15022826068919284		[learning rate: 0.0018326]
	Learning Rate: 0.00183264
	LOSS [training: 0.15022826068919284 | validation: 0.31001713598792957]
	TIME [epoch: 71.1 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1522279860224559		[learning rate: 0.001824]
	Learning Rate: 0.001824
	LOSS [training: 0.1522279860224559 | validation: 0.3289884173939258]
	TIME [epoch: 71 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13959672914253482		[learning rate: 0.0018154]
	Learning Rate: 0.00181541
	LOSS [training: 0.13959672914253482 | validation: 0.3019711365266126]
	TIME [epoch: 71.1 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13551847730569969		[learning rate: 0.0018069]
	Learning Rate: 0.00180685
	LOSS [training: 0.13551847730569969 | validation: 0.29656282266457024]
	TIME [epoch: 71.1 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14839832204345058		[learning rate: 0.0017983]
	Learning Rate: 0.00179834
	LOSS [training: 0.14839832204345058 | validation: 0.2944298926480643]
	TIME [epoch: 71.1 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1333283175754706		[learning rate: 0.0017899]
	Learning Rate: 0.00178987
	LOSS [training: 0.1333283175754706 | validation: 0.32438871879271547]
	TIME [epoch: 71.1 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13076399661054833		[learning rate: 0.0017814]
	Learning Rate: 0.00178143
	LOSS [training: 0.13076399661054833 | validation: 0.3023031924961205]
	TIME [epoch: 70.9 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14897970349900105		[learning rate: 0.001773]
	Learning Rate: 0.00177304
	LOSS [training: 0.14897970349900105 | validation: 0.29180947218623066]
	TIME [epoch: 71.1 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1363262859377979		[learning rate: 0.0017647]
	Learning Rate: 0.00176468
	LOSS [training: 0.1363262859377979 | validation: 0.3165916393092913]
	TIME [epoch: 71.1 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16396013309390517		[learning rate: 0.0017564]
	Learning Rate: 0.00175637
	LOSS [training: 0.16396013309390517 | validation: 0.3295994863364661]
	TIME [epoch: 71.1 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12571946637071074		[learning rate: 0.0017481]
	Learning Rate: 0.00174809
	LOSS [training: 0.12571946637071074 | validation: 0.27951475418069205]
	TIME [epoch: 71.1 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v14b_20240716_170458/states/model_facs_v3_dec2b_2dpca_v14b_407.pth
	Model improved!!!
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1380324143012428		[learning rate: 0.0017399]
	Learning Rate: 0.00173985
	LOSS [training: 0.1380324143012428 | validation: 0.30540465045416887]
	TIME [epoch: 71 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1625566844563051		[learning rate: 0.0017317]
	Learning Rate: 0.00173166
	LOSS [training: 0.1625566844563051 | validation: 0.31591929549684994]
	TIME [epoch: 71 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15576687920104762		[learning rate: 0.0017235]
	Learning Rate: 0.0017235
	LOSS [training: 0.15576687920104762 | validation: 0.32797643646834057]
	TIME [epoch: 71 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1421603235898303		[learning rate: 0.0017154]
	Learning Rate: 0.00171537
	LOSS [training: 0.1421603235898303 | validation: 0.2986172417476672]
	TIME [epoch: 70.9 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14419582915496612		[learning rate: 0.0017073]
	Learning Rate: 0.00170729
	LOSS [training: 0.14419582915496612 | validation: 0.286217320821118]
	TIME [epoch: 70.9 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15562541281378714		[learning rate: 0.0016992]
	Learning Rate: 0.00169925
	LOSS [training: 0.15562541281378714 | validation: 0.34161489821962865]
	TIME [epoch: 71 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13242518679919407		[learning rate: 0.0016912]
	Learning Rate: 0.00169124
	LOSS [training: 0.13242518679919407 | validation: 0.28866229048192465]
	TIME [epoch: 71 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13806243443354718		[learning rate: 0.0016833]
	Learning Rate: 0.00168327
	LOSS [training: 0.13806243443354718 | validation: 0.305051687161211]
	TIME [epoch: 70.9 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1610667132458764		[learning rate: 0.0016753]
	Learning Rate: 0.00167534
	LOSS [training: 0.1610667132458764 | validation: 0.2925233546424659]
	TIME [epoch: 70.9 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13877204054784303		[learning rate: 0.0016674]
	Learning Rate: 0.00166744
	LOSS [training: 0.13877204054784303 | validation: 0.3262242794317427]
	TIME [epoch: 70.9 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.136945036608567		[learning rate: 0.0016596]
	Learning Rate: 0.00165959
	LOSS [training: 0.136945036608567 | validation: 0.32388999976274946]
	TIME [epoch: 70.9 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14443803448132853		[learning rate: 0.0016518]
	Learning Rate: 0.00165177
	LOSS [training: 0.14443803448132853 | validation: 0.3095916610602674]
	TIME [epoch: 70.9 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1445438491136813		[learning rate: 0.001644]
	Learning Rate: 0.00164398
	LOSS [training: 0.1445438491136813 | validation: 0.32032684877365175]
	TIME [epoch: 71 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12809751697445354		[learning rate: 0.0016362]
	Learning Rate: 0.00163624
	LOSS [training: 0.12809751697445354 | validation: 0.28780254804647015]
	TIME [epoch: 70.9 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1446321788203783		[learning rate: 0.0016285]
	Learning Rate: 0.00162853
	LOSS [training: 0.1446321788203783 | validation: 0.29944837802479257]
	TIME [epoch: 71 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12823549800002196		[learning rate: 0.0016209]
	Learning Rate: 0.00162085
	LOSS [training: 0.12823549800002196 | validation: 0.30131400559714283]
	TIME [epoch: 70.8 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14586576478657307		[learning rate: 0.0016132]
	Learning Rate: 0.00161322
	LOSS [training: 0.14586576478657307 | validation: 0.3097441383507186]
	TIME [epoch: 71 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12558916571775053		[learning rate: 0.0016056]
	Learning Rate: 0.00160561
	LOSS [training: 0.12558916571775053 | validation: 0.2877664692223562]
	TIME [epoch: 70.9 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14665417801649774		[learning rate: 0.001598]
	Learning Rate: 0.00159805
	LOSS [training: 0.14665417801649774 | validation: 0.31331325223114664]
	TIME [epoch: 70.9 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12541661219013464		[learning rate: 0.0015905]
	Learning Rate: 0.00159052
	LOSS [training: 0.12541661219013464 | validation: 0.2811629750935125]
	TIME [epoch: 70.9 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14909824702779528		[learning rate: 0.001583]
	Learning Rate: 0.00158302
	LOSS [training: 0.14909824702779528 | validation: 0.3866841091817091]
	TIME [epoch: 70.9 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1328136137212848		[learning rate: 0.0015756]
	Learning Rate: 0.00157556
	LOSS [training: 0.1328136137212848 | validation: 0.3157305773644902]
	TIME [epoch: 70.9 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14165076882008468		[learning rate: 0.0015681]
	Learning Rate: 0.00156814
	LOSS [training: 0.14165076882008468 | validation: 0.30625589215212123]
	TIME [epoch: 70.9 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1519883060193571		[learning rate: 0.0015607]
	Learning Rate: 0.00156075
	LOSS [training: 0.1519883060193571 | validation: 0.30100668686174253]
	TIME [epoch: 70.9 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13827295608942636		[learning rate: 0.0015534]
	Learning Rate: 0.0015534
	LOSS [training: 0.13827295608942636 | validation: 0.2992721820004865]
	TIME [epoch: 70.9 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14675979264747246		[learning rate: 0.0015461]
	Learning Rate: 0.00154608
	LOSS [training: 0.14675979264747246 | validation: 0.31840522108176234]
	TIME [epoch: 70.9 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14473340815781		[learning rate: 0.0015388]
	Learning Rate: 0.00153879
	LOSS [training: 0.14473340815781 | validation: 0.3047354573749071]
	TIME [epoch: 70.7 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13252754642105394		[learning rate: 0.0015315]
	Learning Rate: 0.00153154
	LOSS [training: 0.13252754642105394 | validation: 0.32091863212441507]
	TIME [epoch: 71 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1485542093766553		[learning rate: 0.0015243]
	Learning Rate: 0.00152432
	LOSS [training: 0.1485542093766553 | validation: 0.29525072578952655]
	TIME [epoch: 70.9 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14256637162642524		[learning rate: 0.0015171]
	Learning Rate: 0.00151714
	LOSS [training: 0.14256637162642524 | validation: 0.3144063906131166]
	TIME [epoch: 70.9 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12855830687083472		[learning rate: 0.00151]
	Learning Rate: 0.00150999
	LOSS [training: 0.12855830687083472 | validation: 0.30104363159169883]
	TIME [epoch: 70.9 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12897337180989163		[learning rate: 0.0015029]
	Learning Rate: 0.00150288
	LOSS [training: 0.12897337180989163 | validation: 0.31421804827830996]
	TIME [epoch: 70.9 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14489079999456259		[learning rate: 0.0014958]
	Learning Rate: 0.00149579
	LOSS [training: 0.14489079999456259 | validation: 0.33390908478234227]
	TIME [epoch: 71 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14233513233618783		[learning rate: 0.0014887]
	Learning Rate: 0.00148875
	LOSS [training: 0.14233513233618783 | validation: 0.2847792394729898]
	TIME [epoch: 70.9 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13638528584649676		[learning rate: 0.0014817]
	Learning Rate: 0.00148173
	LOSS [training: 0.13638528584649676 | validation: 0.3011755939061408]
	TIME [epoch: 70.9 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16053702377210857		[learning rate: 0.0014747]
	Learning Rate: 0.00147475
	LOSS [training: 0.16053702377210857 | validation: 0.31696558617837167]
	TIME [epoch: 71.1 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14871274270536455		[learning rate: 0.0014678]
	Learning Rate: 0.0014678
	LOSS [training: 0.14871274270536455 | validation: 0.3353962229025678]
	TIME [epoch: 70.8 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14924943361152554		[learning rate: 0.0014609]
	Learning Rate: 0.00146088
	LOSS [training: 0.14924943361152554 | validation: 0.2999145867076127]
	TIME [epoch: 71 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13718408825556144		[learning rate: 0.001454]
	Learning Rate: 0.001454
	LOSS [training: 0.13718408825556144 | validation: 0.30444030233980063]
	TIME [epoch: 71 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13093446985481402		[learning rate: 0.0014471]
	Learning Rate: 0.00144715
	LOSS [training: 0.13093446985481402 | validation: 0.3039488483704202]
	TIME [epoch: 70.9 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14719789093290847		[learning rate: 0.0014403]
	Learning Rate: 0.00144033
	LOSS [training: 0.14719789093290847 | validation: 0.3095958909789496]
	TIME [epoch: 70.7 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14401698888818093		[learning rate: 0.0014335]
	Learning Rate: 0.00143354
	LOSS [training: 0.14401698888818093 | validation: 0.3111551905778205]
	TIME [epoch: 71 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12411015352545296		[learning rate: 0.0014268]
	Learning Rate: 0.00142679
	LOSS [training: 0.12411015352545296 | validation: 0.3419319518924356]
	TIME [epoch: 71 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14866485976824398		[learning rate: 0.0014201]
	Learning Rate: 0.00142006
	LOSS [training: 0.14866485976824398 | validation: 0.31235399064916836]
	TIME [epoch: 70.9 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14844905803434805		[learning rate: 0.0014134]
	Learning Rate: 0.00141337
	LOSS [training: 0.14844905803434805 | validation: 0.3011390842029735]
	TIME [epoch: 70.9 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13209850246203667		[learning rate: 0.0014067]
	Learning Rate: 0.00140671
	LOSS [training: 0.13209850246203667 | validation: 0.3195321628829384]
	TIME [epoch: 71 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15315154472409895		[learning rate: 0.0014001]
	Learning Rate: 0.00140008
	LOSS [training: 0.15315154472409895 | validation: 0.2888958357773127]
	TIME [epoch: 70.9 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15285368787347875		[learning rate: 0.0013935]
	Learning Rate: 0.00139349
	LOSS [training: 0.15285368787347875 | validation: 0.29024285627530455]
	TIME [epoch: 70.8 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15254684553369802		[learning rate: 0.0013869]
	Learning Rate: 0.00138692
	LOSS [training: 0.15254684553369802 | validation: 0.3321656686341188]
	TIME [epoch: 70.9 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16286044761870216		[learning rate: 0.0013804]
	Learning Rate: 0.00138038
	LOSS [training: 0.16286044761870216 | validation: 0.3036681742935918]
	TIME [epoch: 70.9 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15234663543400512		[learning rate: 0.0013739]
	Learning Rate: 0.00137388
	LOSS [training: 0.15234663543400512 | validation: 0.32458293411177325]
	TIME [epoch: 71 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18857491574757979		[learning rate: 0.0013674]
	Learning Rate: 0.00136741
	LOSS [training: 0.18857491574757979 | validation: 0.34824388729985833]
	TIME [epoch: 70.8 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14243458988625501		[learning rate: 0.001361]
	Learning Rate: 0.00136096
	LOSS [training: 0.14243458988625501 | validation: 0.2947024753559987]
	TIME [epoch: 70.9 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14050401586514885		[learning rate: 0.0013545]
	Learning Rate: 0.00135455
	LOSS [training: 0.14050401586514885 | validation: 0.32684043678109637]
	TIME [epoch: 70.9 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13653938635356572		[learning rate: 0.0013482]
	Learning Rate: 0.00134817
	LOSS [training: 0.13653938635356572 | validation: 0.294663372287193]
	TIME [epoch: 71 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15049445879790294		[learning rate: 0.0013418]
	Learning Rate: 0.00134181
	LOSS [training: 0.15049445879790294 | validation: 0.31889446641200137]
	TIME [epoch: 70.9 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1416851092821012		[learning rate: 0.0013355]
	Learning Rate: 0.00133549
	LOSS [training: 0.1416851092821012 | validation: 0.32929894293399037]
	TIME [epoch: 70.8 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1295064525054983		[learning rate: 0.0013292]
	Learning Rate: 0.0013292
	LOSS [training: 0.1295064525054983 | validation: 0.3043899731944273]
	TIME [epoch: 70.9 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15167176025528456		[learning rate: 0.0013229]
	Learning Rate: 0.00132293
	LOSS [training: 0.15167176025528456 | validation: 0.3174032059673111]
	TIME [epoch: 70.9 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13539781048545538		[learning rate: 0.0013167]
	Learning Rate: 0.0013167
	LOSS [training: 0.13539781048545538 | validation: 0.30712617663810343]
	TIME [epoch: 70.9 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1485949365821569		[learning rate: 0.0013105]
	Learning Rate: 0.0013105
	LOSS [training: 0.1485949365821569 | validation: 0.3151707529308788]
	TIME [epoch: 71 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15879226495054163		[learning rate: 0.0013043]
	Learning Rate: 0.00130432
	LOSS [training: 0.15879226495054163 | validation: 0.3029150885682727]
	TIME [epoch: 70.9 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15473310780896568		[learning rate: 0.0012982]
	Learning Rate: 0.00129818
	LOSS [training: 0.15473310780896568 | validation: 0.33577247612255184]
	TIME [epoch: 71 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13363872064044935		[learning rate: 0.0012921]
	Learning Rate: 0.00129206
	LOSS [training: 0.13363872064044935 | validation: 0.3049766464644103]
	TIME [epoch: 70.9 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15835534119928402		[learning rate: 0.001286]
	Learning Rate: 0.00128597
	LOSS [training: 0.15835534119928402 | validation: 0.31513750135724083]
	TIME [epoch: 70.9 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14682103589460907		[learning rate: 0.0012799]
	Learning Rate: 0.00127991
	LOSS [training: 0.14682103589460907 | validation: 0.32263578946941623]
	TIME [epoch: 71 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15087307859441		[learning rate: 0.0012739]
	Learning Rate: 0.00127388
	LOSS [training: 0.15087307859441 | validation: 0.2966718576493649]
	TIME [epoch: 71 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14421638998784467		[learning rate: 0.0012679]
	Learning Rate: 0.00126788
	LOSS [training: 0.14421638998784467 | validation: 0.3113630738152464]
	TIME [epoch: 70.8 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1340336885551559		[learning rate: 0.0012619]
	Learning Rate: 0.0012619
	LOSS [training: 0.1340336885551559 | validation: 0.306348224660379]
	TIME [epoch: 71.1 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14675736670302758		[learning rate: 0.001256]
	Learning Rate: 0.00125596
	LOSS [training: 0.14675736670302758 | validation: 0.30977289277568737]
	TIME [epoch: 71 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15595702115540722		[learning rate: 0.00125]
	Learning Rate: 0.00125004
	LOSS [training: 0.15595702115540722 | validation: 0.3040215828158425]
	TIME [epoch: 71 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1307425973416645		[learning rate: 0.0012441]
	Learning Rate: 0.00124415
	LOSS [training: 0.1307425973416645 | validation: 0.3085832724912671]
	TIME [epoch: 71 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1536142089382993		[learning rate: 0.0012383]
	Learning Rate: 0.00123828
	LOSS [training: 0.1536142089382993 | validation: 0.3321060060103565]
	TIME [epoch: 70.9 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1441169667259965		[learning rate: 0.0012324]
	Learning Rate: 0.00123245
	LOSS [training: 0.1441169667259965 | validation: 0.31139267781366986]
	TIME [epoch: 71.1 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1336673324779218		[learning rate: 0.0012266]
	Learning Rate: 0.00122664
	LOSS [training: 0.1336673324779218 | validation: 0.29985555198198893]
	TIME [epoch: 71 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12700089489124264		[learning rate: 0.0012209]
	Learning Rate: 0.00122086
	LOSS [training: 0.12700089489124264 | validation: 0.34007386275539037]
	TIME [epoch: 71 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14983950643705296		[learning rate: 0.0012151]
	Learning Rate: 0.00121511
	LOSS [training: 0.14983950643705296 | validation: 0.3064672713061391]
	TIME [epoch: 71 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16378969669529514		[learning rate: 0.0012094]
	Learning Rate: 0.00120938
	LOSS [training: 0.16378969669529514 | validation: 0.34134179638051626]
	TIME [epoch: 71.1 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12933246319241182		[learning rate: 0.0012037]
	Learning Rate: 0.00120368
	LOSS [training: 0.12933246319241182 | validation: 0.28427578232055883]
	TIME [epoch: 71 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13847470299719966		[learning rate: 0.001198]
	Learning Rate: 0.00119801
	LOSS [training: 0.13847470299719966 | validation: 0.3121987185138818]
	TIME [epoch: 71.1 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1487421456246911		[learning rate: 0.0011924]
	Learning Rate: 0.00119237
	LOSS [training: 0.1487421456246911 | validation: 0.3071435622109985]
	TIME [epoch: 71 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14497411301878343		[learning rate: 0.0011867]
	Learning Rate: 0.00118675
	LOSS [training: 0.14497411301878343 | validation: 0.32256245388411087]
	TIME [epoch: 70.9 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1254781347157897		[learning rate: 0.0011812]
	Learning Rate: 0.00118116
	LOSS [training: 0.1254781347157897 | validation: 0.31040187998828717]
	TIME [epoch: 71 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1363950811626483		[learning rate: 0.0011756]
	Learning Rate: 0.00117559
	LOSS [training: 0.1363950811626483 | validation: 0.32000893109055845]
	TIME [epoch: 71 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15635626296239427		[learning rate: 0.0011701]
	Learning Rate: 0.00117005
	LOSS [training: 0.15635626296239427 | validation: 0.3122543726774012]
	TIME [epoch: 71.1 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1727761179677246		[learning rate: 0.0011645]
	Learning Rate: 0.00116454
	LOSS [training: 0.1727761179677246 | validation: 0.3079384538581769]
	TIME [epoch: 70.9 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13167399315112455		[learning rate: 0.0011591]
	Learning Rate: 0.00115905
	LOSS [training: 0.13167399315112455 | validation: 0.3090552653368038]
	TIME [epoch: 71.1 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14284275289095694		[learning rate: 0.0011536]
	Learning Rate: 0.00115359
	LOSS [training: 0.14284275289095694 | validation: 0.33527119884019585]
	TIME [epoch: 71 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13315684246915951		[learning rate: 0.0011482]
	Learning Rate: 0.00114815
	LOSS [training: 0.13315684246915951 | validation: 0.2940746619780612]
	TIME [epoch: 71 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13416117325916144		[learning rate: 0.0011427]
	Learning Rate: 0.00114274
	LOSS [training: 0.13416117325916144 | validation: 0.30196165894426574]
	TIME [epoch: 70.8 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14249313971897956		[learning rate: 0.0011374]
	Learning Rate: 0.00113736
	LOSS [training: 0.14249313971897956 | validation: 0.2945275494825335]
	TIME [epoch: 71.1 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13421876267976468		[learning rate: 0.001132]
	Learning Rate: 0.001132
	LOSS [training: 0.13421876267976468 | validation: 0.3119035392542442]
	TIME [epoch: 71 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1503116402155774		[learning rate: 0.0011267]
	Learning Rate: 0.00112667
	LOSS [training: 0.1503116402155774 | validation: 0.3004022223442875]
	TIME [epoch: 71 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13062199334914446		[learning rate: 0.0011214]
	Learning Rate: 0.00112136
	LOSS [training: 0.13062199334914446 | validation: 0.32368564198560956]
	TIME [epoch: 71 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13789802427883155		[learning rate: 0.0011161]
	Learning Rate: 0.00111607
	LOSS [training: 0.13789802427883155 | validation: 0.2807900908241416]
	TIME [epoch: 70.9 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13295463699369522		[learning rate: 0.0011108]
	Learning Rate: 0.00111081
	LOSS [training: 0.13295463699369522 | validation: 0.279859573688893]
	TIME [epoch: 71 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14203751433350553		[learning rate: 0.0011056]
	Learning Rate: 0.00110558
	LOSS [training: 0.14203751433350553 | validation: 0.3011905363803156]
	TIME [epoch: 70.9 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12612478944512442		[learning rate: 0.0011004]
	Learning Rate: 0.00110037
	LOSS [training: 0.12612478944512442 | validation: 0.2916366965611723]
	TIME [epoch: 71 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16098324421175395		[learning rate: 0.0010952]
	Learning Rate: 0.00109518
	LOSS [training: 0.16098324421175395 | validation: 0.30551211348200796]
	TIME [epoch: 70.9 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.147465386170215		[learning rate: 0.00109]
	Learning Rate: 0.00109002
	LOSS [training: 0.147465386170215 | validation: 0.3037649529141059]
	TIME [epoch: 71.1 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.130868350483829		[learning rate: 0.0010849]
	Learning Rate: 0.00108489
	LOSS [training: 0.130868350483829 | validation: 0.33106722666024424]
	TIME [epoch: 70.9 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1333662670957183		[learning rate: 0.0010798]
	Learning Rate: 0.00107978
	LOSS [training: 0.1333662670957183 | validation: 0.30833174605599345]
	TIME [epoch: 71 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13901127134396124		[learning rate: 0.0010747]
	Learning Rate: 0.00107469
	LOSS [training: 0.13901127134396124 | validation: 0.28947151133025545]
	TIME [epoch: 70.8 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16204039113487811		[learning rate: 0.0010696]
	Learning Rate: 0.00106962
	LOSS [training: 0.16204039113487811 | validation: 0.32362569877096997]
	TIME [epoch: 70.9 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1433025277899399		[learning rate: 0.0010646]
	Learning Rate: 0.00106458
	LOSS [training: 0.1433025277899399 | validation: 0.291248253925614]
	TIME [epoch: 71.1 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1487303468689854		[learning rate: 0.0010596]
	Learning Rate: 0.00105957
	LOSS [training: 0.1487303468689854 | validation: 0.2883724451729457]
	TIME [epoch: 71 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1375803188147133		[learning rate: 0.0010546]
	Learning Rate: 0.00105457
	LOSS [training: 0.1375803188147133 | validation: 0.3126628667091915]
	TIME [epoch: 71 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1282403500701912		[learning rate: 0.0010496]
	Learning Rate: 0.0010496
	LOSS [training: 0.1282403500701912 | validation: 0.2956905426266987]
	TIME [epoch: 71 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14743018372706498		[learning rate: 0.0010447]
	Learning Rate: 0.00104466
	LOSS [training: 0.14743018372706498 | validation: 0.3020420644109237]
	TIME [epoch: 71.1 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1411398590035914		[learning rate: 0.0010397]
	Learning Rate: 0.00103974
	LOSS [training: 0.1411398590035914 | validation: 0.28771221568531774]
	TIME [epoch: 71 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1514954036141202		[learning rate: 0.0010348]
	Learning Rate: 0.00103484
	LOSS [training: 0.1514954036141202 | validation: 0.306643361037686]
	TIME [epoch: 71.1 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15755150696785325		[learning rate: 0.00103]
	Learning Rate: 0.00102996
	LOSS [training: 0.15755150696785325 | validation: 0.29437792612434155]
	TIME [epoch: 71 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13454662555451213		[learning rate: 0.0010251]
	Learning Rate: 0.00102511
	LOSS [training: 0.13454662555451213 | validation: 0.3105018524994737]
	TIME [epoch: 71.1 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1417401946078361		[learning rate: 0.0010203]
	Learning Rate: 0.00102028
	LOSS [training: 0.1417401946078361 | validation: 0.29339353934907225]
	TIME [epoch: 71 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14639945994217035		[learning rate: 0.0010155]
	Learning Rate: 0.00101547
	LOSS [training: 0.14639945994217035 | validation: 0.3035348572865518]
	TIME [epoch: 71.1 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13209678813115447		[learning rate: 0.0010107]
	Learning Rate: 0.00101068
	LOSS [training: 0.13209678813115447 | validation: 0.2950295873985209]
	TIME [epoch: 71 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13721745084868694		[learning rate: 0.0010059]
	Learning Rate: 0.00100592
	LOSS [training: 0.13721745084868694 | validation: 0.30107061575004157]
	TIME [epoch: 71.1 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1441964552165373		[learning rate: 0.0010012]
	Learning Rate: 0.00100118
	LOSS [training: 0.1441964552165373 | validation: 0.2991928662797172]
	TIME [epoch: 71 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14259634259056472		[learning rate: 0.00099646]
	Learning Rate: 0.000996464
	LOSS [training: 0.14259634259056472 | validation: 0.30150796686027675]
	TIME [epoch: 71.1 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14537430977595683		[learning rate: 0.00099177]
	Learning Rate: 0.000991768
	LOSS [training: 0.14537430977595683 | validation: 0.28771387910619123]
	TIME [epoch: 71.1 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15056793541609942		[learning rate: 0.0009871]
	Learning Rate: 0.000987095
	LOSS [training: 0.15056793541609942 | validation: 0.30569042531665835]
	TIME [epoch: 71.1 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1675772096545073		[learning rate: 0.00098244]
	Learning Rate: 0.000982444
	LOSS [training: 0.1675772096545073 | validation: 0.2945299977027108]
	TIME [epoch: 70.8 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13115737066073346		[learning rate: 0.00097781]
	Learning Rate: 0.000977814
	LOSS [training: 0.13115737066073346 | validation: 0.31207576149121263]
	TIME [epoch: 71.1 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14839339744350438		[learning rate: 0.00097321]
	Learning Rate: 0.000973207
	LOSS [training: 0.14839339744350438 | validation: 0.313789148236264]
	TIME [epoch: 70.9 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14609818022121063		[learning rate: 0.00096862]
	Learning Rate: 0.000968621
	LOSS [training: 0.14609818022121063 | validation: 0.29950799280558027]
	TIME [epoch: 70.9 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13080677122723958		[learning rate: 0.00096406]
	Learning Rate: 0.000964057
	LOSS [training: 0.13080677122723958 | validation: 0.3150722451738668]
	TIME [epoch: 70.9 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1520667528630199		[learning rate: 0.00095951]
	Learning Rate: 0.000959514
	LOSS [training: 0.1520667528630199 | validation: 0.3120189068304057]
	TIME [epoch: 70.8 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12489875669286069		[learning rate: 0.00095499]
	Learning Rate: 0.000954993
	LOSS [training: 0.12489875669286069 | validation: 0.3013302242805425]
	TIME [epoch: 70.9 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12882031727354826		[learning rate: 0.00095049]
	Learning Rate: 0.000950493
	LOSS [training: 0.12882031727354826 | validation: 0.30281795283396207]
	TIME [epoch: 71 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13571995798576583		[learning rate: 0.00094601]
	Learning Rate: 0.000946014
	LOSS [training: 0.13571995798576583 | validation: 0.3151837170634565]
	TIME [epoch: 71.2 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13034688829216656		[learning rate: 0.00094156]
	Learning Rate: 0.000941556
	LOSS [training: 0.13034688829216656 | validation: 0.31876199707636665]
	TIME [epoch: 71.1 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13782912332275488		[learning rate: 0.00093712]
	Learning Rate: 0.000937119
	LOSS [training: 0.13782912332275488 | validation: 0.3028099572387169]
	TIME [epoch: 71 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13263207914158565		[learning rate: 0.0009327]
	Learning Rate: 0.000932703
	LOSS [training: 0.13263207914158565 | validation: 0.3113893613183601]
	TIME [epoch: 71.1 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13721545217252254		[learning rate: 0.00092831]
	Learning Rate: 0.000928309
	LOSS [training: 0.13721545217252254 | validation: 0.30410636874907915]
	TIME [epoch: 71 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12101272654056901		[learning rate: 0.00092393]
	Learning Rate: 0.000923934
	LOSS [training: 0.12101272654056901 | validation: 0.30598565794585847]
	TIME [epoch: 71.1 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13423015363879173		[learning rate: 0.00091958]
	Learning Rate: 0.000919581
	LOSS [training: 0.13423015363879173 | validation: 0.30768153081357824]
	TIME [epoch: 71.1 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13650375485250427		[learning rate: 0.00091525]
	Learning Rate: 0.000915247
	LOSS [training: 0.13650375485250427 | validation: 0.3015679503327114]
	TIME [epoch: 71.1 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1294452762217621		[learning rate: 0.00091093]
	Learning Rate: 0.000910934
	LOSS [training: 0.1294452762217621 | validation: 0.290685070922232]
	TIME [epoch: 70.8 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1238353048393836		[learning rate: 0.00090664]
	Learning Rate: 0.000906642
	LOSS [training: 0.1238353048393836 | validation: 0.31046174977324226]
	TIME [epoch: 71 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13500396794434105		[learning rate: 0.00090237]
	Learning Rate: 0.00090237
	LOSS [training: 0.13500396794434105 | validation: 0.28321244924653066]
	TIME [epoch: 71 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12343248937155482		[learning rate: 0.00089812]
	Learning Rate: 0.000898118
	LOSS [training: 0.12343248937155482 | validation: 0.30969712245018777]
	TIME [epoch: 70.8 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1298887028584816		[learning rate: 0.00089389]
	Learning Rate: 0.000893886
	LOSS [training: 0.1298887028584816 | validation: 0.29262482801037426]
	TIME [epoch: 71.1 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14402909063201424		[learning rate: 0.00088967]
	Learning Rate: 0.000889674
	LOSS [training: 0.14402909063201424 | validation: 0.28466882592382103]
	TIME [epoch: 70.8 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1423122565663644		[learning rate: 0.00088548]
	Learning Rate: 0.000885481
	LOSS [training: 0.1423122565663644 | validation: 0.2837860841035751]
	TIME [epoch: 71.1 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1475399152069672		[learning rate: 0.00088131]
	Learning Rate: 0.000881309
	LOSS [training: 0.1475399152069672 | validation: 0.31456016265708125]
	TIME [epoch: 70.9 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1460383422202944		[learning rate: 0.00087716]
	Learning Rate: 0.000877156
	LOSS [training: 0.1460383422202944 | validation: 0.3222808142244218]
	TIME [epoch: 70.9 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16917031341620126		[learning rate: 0.00087302]
	Learning Rate: 0.000873023
	LOSS [training: 0.16917031341620126 | validation: 0.3208728637975932]
	TIME [epoch: 71 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.152520623720941		[learning rate: 0.00086891]
	Learning Rate: 0.000868909
	LOSS [training: 0.152520623720941 | validation: 0.30091678148715995]
	TIME [epoch: 70.8 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12460481224105947		[learning rate: 0.00086481]
	Learning Rate: 0.000864815
	LOSS [training: 0.12460481224105947 | validation: 0.32403784404450675]
	TIME [epoch: 70.8 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17445633054133566		[learning rate: 0.00086074]
	Learning Rate: 0.00086074
	LOSS [training: 0.17445633054133566 | validation: 0.3120950504160737]
	TIME [epoch: 70.9 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12610792494153045		[learning rate: 0.00085668]
	Learning Rate: 0.000856684
	LOSS [training: 0.12610792494153045 | validation: 0.3156540178977225]
	TIME [epoch: 70.8 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1579600821948062		[learning rate: 0.00085265]
	Learning Rate: 0.000852647
	LOSS [training: 0.1579600821948062 | validation: 0.3320564176072557]
	TIME [epoch: 71.1 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1254402015676547		[learning rate: 0.00084863]
	Learning Rate: 0.000848629
	LOSS [training: 0.1254402015676547 | validation: 0.2949297828744148]
	TIME [epoch: 71.1 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15121172227240995		[learning rate: 0.00084463]
	Learning Rate: 0.00084463
	LOSS [training: 0.15121172227240995 | validation: 0.3065150076343413]
	TIME [epoch: 71 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12080289374875863		[learning rate: 0.00084065]
	Learning Rate: 0.00084065
	LOSS [training: 0.12080289374875863 | validation: 0.29363543122530494]
	TIME [epoch: 71 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15356776479041348		[learning rate: 0.00083669]
	Learning Rate: 0.000836689
	LOSS [training: 0.15356776479041348 | validation: 0.30284185863161256]
	TIME [epoch: 71 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1521731670234125		[learning rate: 0.00083275]
	Learning Rate: 0.000832746
	LOSS [training: 0.1521731670234125 | validation: 0.305907886685468]
	TIME [epoch: 70.9 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15131357655713604		[learning rate: 0.00082882]
	Learning Rate: 0.000828822
	LOSS [training: 0.15131357655713604 | validation: 0.3020696308988966]
	TIME [epoch: 71 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1223113153909537		[learning rate: 0.00082492]
	Learning Rate: 0.000824917
	LOSS [training: 0.1223113153909537 | validation: 0.3043030902820507]
	TIME [epoch: 71 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13510286608157196		[learning rate: 0.00082103]
	Learning Rate: 0.00082103
	LOSS [training: 0.13510286608157196 | validation: 0.2952953079113491]
	TIME [epoch: 71 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1389397243960256		[learning rate: 0.00081716]
	Learning Rate: 0.000817161
	LOSS [training: 0.1389397243960256 | validation: 0.30035344677670406]
	TIME [epoch: 71 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13102457362277625		[learning rate: 0.00081331]
	Learning Rate: 0.000813311
	LOSS [training: 0.13102457362277625 | validation: 0.2995667174959074]
	TIME [epoch: 70.9 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12731709963953078		[learning rate: 0.00080948]
	Learning Rate: 0.000809478
	LOSS [training: 0.12731709963953078 | validation: 0.30955439307080657]
	TIME [epoch: 71.1 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13495143228126188		[learning rate: 0.00080566]
	Learning Rate: 0.000805664
	LOSS [training: 0.13495143228126188 | validation: 0.31225400161264316]
	TIME [epoch: 70.9 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12569868539965076		[learning rate: 0.00080187]
	Learning Rate: 0.000801868
	LOSS [training: 0.12569868539965076 | validation: 0.28094521871304096]
	TIME [epoch: 70.9 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14326990810372853		[learning rate: 0.00079809]
	Learning Rate: 0.000798089
	LOSS [training: 0.14326990810372853 | validation: 0.2910893297180882]
	TIME [epoch: 70.9 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14186593847096102		[learning rate: 0.00079433]
	Learning Rate: 0.000794328
	LOSS [training: 0.14186593847096102 | validation: 0.3016316506133752]
	TIME [epoch: 71 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14121991053784144		[learning rate: 0.00079059]
	Learning Rate: 0.000790585
	LOSS [training: 0.14121991053784144 | validation: 0.3015237908043117]
	TIME [epoch: 71 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14582459189381347		[learning rate: 0.00078686]
	Learning Rate: 0.00078686
	LOSS [training: 0.14582459189381347 | validation: 0.31042349410314085]
	TIME [epoch: 71 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12879398177945797		[learning rate: 0.00078315]
	Learning Rate: 0.000783152
	LOSS [training: 0.12879398177945797 | validation: 0.3042872737326245]
	TIME [epoch: 71 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15589089725857572		[learning rate: 0.00077946]
	Learning Rate: 0.000779462
	LOSS [training: 0.15589089725857572 | validation: 0.30349412118116864]
	TIME [epoch: 71 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12995484840267682		[learning rate: 0.00077579]
	Learning Rate: 0.000775789
	LOSS [training: 0.12995484840267682 | validation: 0.30370981890684123]
	TIME [epoch: 70.9 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13422770412683727		[learning rate: 0.00077213]
	Learning Rate: 0.000772133
	LOSS [training: 0.13422770412683727 | validation: 0.313735539364836]
	TIME [epoch: 70.7 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.141069079515003		[learning rate: 0.00076849]
	Learning Rate: 0.000768495
	LOSS [training: 0.141069079515003 | validation: 0.2963265531585977]
	TIME [epoch: 71.1 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13620182915260365		[learning rate: 0.00076487]
	Learning Rate: 0.000764874
	LOSS [training: 0.13620182915260365 | validation: 0.28861272314059844]
	TIME [epoch: 71.1 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13601913539632093		[learning rate: 0.00076127]
	Learning Rate: 0.00076127
	LOSS [training: 0.13601913539632093 | validation: 0.30159053171914857]
	TIME [epoch: 71.1 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16322234466669985		[learning rate: 0.00075768]
	Learning Rate: 0.000757682
	LOSS [training: 0.16322234466669985 | validation: 0.2990595115149634]
	TIME [epoch: 71.1 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12630950265711227		[learning rate: 0.00075411]
	Learning Rate: 0.000754112
	LOSS [training: 0.12630950265711227 | validation: 0.2903364512018506]
	TIME [epoch: 71 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13185024385303917		[learning rate: 0.00075056]
	Learning Rate: 0.000750559
	LOSS [training: 0.13185024385303917 | validation: 0.29138628689293783]
	TIME [epoch: 71 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1368892309702278		[learning rate: 0.00074702]
	Learning Rate: 0.000747022
	LOSS [training: 0.1368892309702278 | validation: 0.29953704245077056]
	TIME [epoch: 71 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12949367554396674		[learning rate: 0.0007435]
	Learning Rate: 0.000743502
	LOSS [training: 0.12949367554396674 | validation: 0.3080687619018193]
	TIME [epoch: 70.9 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12207643074290447		[learning rate: 0.00074]
	Learning Rate: 0.000739998
	LOSS [training: 0.12207643074290447 | validation: 0.3362275153551958]
	TIME [epoch: 70.9 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14520484195247108		[learning rate: 0.00073651]
	Learning Rate: 0.000736511
	LOSS [training: 0.14520484195247108 | validation: 0.3114509317057284]
	TIME [epoch: 70.8 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12876705376508368		[learning rate: 0.00073304]
	Learning Rate: 0.000733041
	LOSS [training: 0.12876705376508368 | validation: 0.29761254180864893]
	TIME [epoch: 70.9 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1314213491587063		[learning rate: 0.00072959]
	Learning Rate: 0.000729587
	LOSS [training: 0.1314213491587063 | validation: 0.3079440430514806]
	TIME [epoch: 70.9 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13642042095491722		[learning rate: 0.00072615]
	Learning Rate: 0.000726149
	LOSS [training: 0.13642042095491722 | validation: 0.30586080436710444]
	TIME [epoch: 70.8 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12637885326437506		[learning rate: 0.00072273]
	Learning Rate: 0.000722727
	LOSS [training: 0.12637885326437506 | validation: 0.30981136667272546]
	TIME [epoch: 71 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12480395552777061		[learning rate: 0.00071932]
	Learning Rate: 0.000719321
	LOSS [training: 0.12480395552777061 | validation: 0.30032713819724655]
	TIME [epoch: 71 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12330136633226423		[learning rate: 0.00071593]
	Learning Rate: 0.000715932
	LOSS [training: 0.12330136633226423 | validation: 0.2976244525841551]
	TIME [epoch: 70.8 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14421153281504356		[learning rate: 0.00071256]
	Learning Rate: 0.000712558
	LOSS [training: 0.14421153281504356 | validation: 0.3123499060861905]
	TIME [epoch: 71.1 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12809725919084844		[learning rate: 0.0007092]
	Learning Rate: 0.000709201
	LOSS [training: 0.12809725919084844 | validation: 0.2818942165108414]
	TIME [epoch: 70.9 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1272927558218988		[learning rate: 0.00070586]
	Learning Rate: 0.000705859
	LOSS [training: 0.1272927558218988 | validation: 0.29776502059279314]
	TIME [epoch: 70.9 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13421848979439915		[learning rate: 0.00070253]
	Learning Rate: 0.000702533
	LOSS [training: 0.13421848979439915 | validation: 0.3121019278582616]
	TIME [epoch: 70.9 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12733017909222064		[learning rate: 0.00069922]
	Learning Rate: 0.000699222
	LOSS [training: 0.12733017909222064 | validation: 0.28005730919410116]
	TIME [epoch: 70.8 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14290989047636343		[learning rate: 0.00069593]
	Learning Rate: 0.000695928
	LOSS [training: 0.14290989047636343 | validation: 0.3012374533829288]
	TIME [epoch: 70.9 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14755586142513583		[learning rate: 0.00069265]
	Learning Rate: 0.000692648
	LOSS [training: 0.14755586142513583 | validation: 0.31034012000698746]
	TIME [epoch: 70.9 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14862252064141251		[learning rate: 0.00068938]
	Learning Rate: 0.000689385
	LOSS [training: 0.14862252064141251 | validation: 0.31339981522548693]
	TIME [epoch: 71 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11759334921477081		[learning rate: 0.00068614]
	Learning Rate: 0.000686136
	LOSS [training: 0.11759334921477081 | validation: 0.3022603561376113]
	TIME [epoch: 70.8 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13924569947656223		[learning rate: 0.0006829]
	Learning Rate: 0.000682903
	LOSS [training: 0.13924569947656223 | validation: 0.29897332786996134]
	TIME [epoch: 70.9 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12080230248688895		[learning rate: 0.00067969]
	Learning Rate: 0.000679685
	LOSS [training: 0.12080230248688895 | validation: 0.3034597701059456]
	TIME [epoch: 70.9 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13125315850501293		[learning rate: 0.00067648]
	Learning Rate: 0.000676482
	LOSS [training: 0.13125315850501293 | validation: 0.3081728114900338]
	TIME [epoch: 70.9 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v14b_20240716_170458/states/model_facs_v3_dec2b_2dpca_v14b_608.pth
Halted early. No improvement in validation loss for 200 epochs.
Finished training in 27621.921 seconds.
