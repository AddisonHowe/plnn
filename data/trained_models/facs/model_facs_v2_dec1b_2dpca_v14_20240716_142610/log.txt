Args:
Namespace(name='model_facs_v2_dec1b_2dpca_v14', outdir='out/model_training/model_facs_v2_dec1b_2dpca_v14', training_data='data/training_data/facs_v2/pca/dec1_fitonsubset/transition1_subset_epi_tr_ce_an_pc12/training', validation_data='data/training_data/facs_v2/pca/dec1_fitonsubset/transition1_subset_epi_tr_ce_an_pc12/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=10, batch_size=50, patience=200, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, quadratic_a=1.0, quadratic_b=1.0, ndims=2, nparams=2, nsigs=2, ncells=200, ncells_sample=200, model_do_sample=False, dt=0.005, dt_schedule='stepped', dt_schedule_bounds=[50, 500, 1000], dt_schedule_scales=[0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', kernel='multiscale', bw_range=[0.2, 0.5, 0.9, 1.1, 1.3, 1.5, 2.0], optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 1570866983

Training model...

Saving initial model state to: out/model_training/model_facs_v2_dec1b_2dpca_v14_20240716_142610/states/model_facs_v2_dec1b_2dpca_v14_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.1722297369486012		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1722297369486012 | validation: 0.9751165156465387]
	TIME [epoch: 31.2 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v14_20240716_142610/states/model_facs_v2_dec1b_2dpca_v14_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.023750418825651		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.023750418825651 | validation: 0.9309321247558241]
	TIME [epoch: 7.95 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v14_20240716_142610/states/model_facs_v2_dec1b_2dpca_v14_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.9891768445906978		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9891768445906978 | validation: 0.9118704340492355]
	TIME [epoch: 7.92 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v14_20240716_142610/states/model_facs_v2_dec1b_2dpca_v14_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.90662029099473		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.90662029099473 | validation: 0.8010776435045177]
	TIME [epoch: 7.96 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v14_20240716_142610/states/model_facs_v2_dec1b_2dpca_v14_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.911324955012431		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.911324955012431 | validation: 0.7520776975323568]
	TIME [epoch: 8.22 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v14_20240716_142610/states/model_facs_v2_dec1b_2dpca_v14_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.8859943690953522		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8859943690953522 | validation: 0.694587979647553]
	TIME [epoch: 7.92 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v14_20240716_142610/states/model_facs_v2_dec1b_2dpca_v14_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.8354543759329229		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8354543759329229 | validation: 0.6904243691360984]
	TIME [epoch: 7.95 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v14_20240716_142610/states/model_facs_v2_dec1b_2dpca_v14_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7847454214526941		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7847454214526941 | validation: 0.7718357668859512]
	TIME [epoch: 7.94 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7186176395101914		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7186176395101914 | validation: 0.610437822210916]
	TIME [epoch: 7.97 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v14_20240716_142610/states/model_facs_v2_dec1b_2dpca_v14_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6434603416774872		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6434603416774872 | validation: 0.5907677118614625]
	TIME [epoch: 7.92 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v14_20240716_142610/states/model_facs_v2_dec1b_2dpca_v14_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5540311018540639		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5540311018540639 | validation: 0.513449779873378]
	TIME [epoch: 7.93 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v14_20240716_142610/states/model_facs_v2_dec1b_2dpca_v14_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5163998696717854		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5163998696717854 | validation: 0.40474345083206603]
	TIME [epoch: 7.93 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v14_20240716_142610/states/model_facs_v2_dec1b_2dpca_v14_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.44256480663443276		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.44256480663443276 | validation: 0.48274360788662296]
	TIME [epoch: 7.92 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4178618064056688		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4178618064056688 | validation: 0.33942925607327884]
	TIME [epoch: 7.93 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v14_20240716_142610/states/model_facs_v2_dec1b_2dpca_v14_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4015382622016331		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4015382622016331 | validation: 0.3839951035460591]
	TIME [epoch: 7.92 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3800897813089146		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3800897813089146 | validation: 0.35346434117306785]
	TIME [epoch: 7.93 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3655256425524413		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3655256425524413 | validation: 0.31429962525971483]
	TIME [epoch: 7.92 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v14_20240716_142610/states/model_facs_v2_dec1b_2dpca_v14_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3698056415980673		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3698056415980673 | validation: 0.37825613626301163]
	TIME [epoch: 7.95 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3666446372651016		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3666446372651016 | validation: 0.2952448888256926]
	TIME [epoch: 7.93 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v14_20240716_142610/states/model_facs_v2_dec1b_2dpca_v14_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3480637334392523		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3480637334392523 | validation: 0.31651772462774447]
	TIME [epoch: 7.93 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3482147650982761		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3482147650982761 | validation: 0.29581497293263237]
	TIME [epoch: 7.92 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3361293690256728		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3361293690256728 | validation: 0.3018754998778822]
	TIME [epoch: 7.91 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32486270933913686		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.32486270933913686 | validation: 0.3555705044651112]
	TIME [epoch: 7.93 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.35502471412230696		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.35502471412230696 | validation: 0.3287770340336966]
	TIME [epoch: 7.94 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.33266734900600564		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.33266734900600564 | validation: 0.30900558955061286]
	TIME [epoch: 7.93 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3249450833889162		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3249450833889162 | validation: 0.3413055992832733]
	TIME [epoch: 7.93 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3173795715960228		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3173795715960228 | validation: 0.2737572096433622]
	TIME [epoch: 7.92 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v14_20240716_142610/states/model_facs_v2_dec1b_2dpca_v14_27.pth
	Model improved!!!
EPOCH 28/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3129554628693335		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3129554628693335 | validation: 0.25161334278328396]
	TIME [epoch: 7.95 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v14_20240716_142610/states/model_facs_v2_dec1b_2dpca_v14_28.pth
	Model improved!!!
EPOCH 29/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3238603179120825		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3238603179120825 | validation: 0.2560020827511887]
	TIME [epoch: 7.93 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3190989224214056		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3190989224214056 | validation: 0.2775126473100099]
	TIME [epoch: 7.96 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.31345973439426034		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.31345973439426034 | validation: 0.2681603153939422]
	TIME [epoch: 7.94 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3208795109605491		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3208795109605491 | validation: 0.26236073884796635]
	TIME [epoch: 7.92 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32625243716275704		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.32625243716275704 | validation: 0.25503207796320243]
	TIME [epoch: 7.93 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3017472904188161		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3017472904188161 | validation: 0.29923929990679776]
	TIME [epoch: 7.95 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3064495020788789		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3064495020788789 | validation: 0.25846095069464015]
	TIME [epoch: 7.93 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.29274302673070013		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.29274302673070013 | validation: 0.2775574428489386]
	TIME [epoch: 7.94 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3305351713305967		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3305351713305967 | validation: 0.27580256672472075]
	TIME [epoch: 7.93 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.28707689252896623		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.28707689252896623 | validation: 0.25517246461373094]
	TIME [epoch: 7.94 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2757245219097573		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2757245219097573 | validation: 0.25581834787075747]
	TIME [epoch: 7.94 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.27978915964768974		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.27978915964768974 | validation: 0.2682809690292359]
	TIME [epoch: 7.97 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2807925740603351		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2807925740603351 | validation: 0.2939663442304573]
	TIME [epoch: 7.94 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.29345215088302645		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.29345215088302645 | validation: 0.24201284477482415]
	TIME [epoch: 7.94 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v14_20240716_142610/states/model_facs_v2_dec1b_2dpca_v14_42.pth
	Model improved!!!
EPOCH 43/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.27955370044735156		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.27955370044735156 | validation: 0.24381893910112673]
	TIME [epoch: 7.93 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2655158924957419		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2655158924957419 | validation: 0.24576038799213912]
	TIME [epoch: 8.01 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2712467295076459		[learning rate: 0.0099823]
	Learning Rate: 0.0099823
	LOSS [training: 0.2712467295076459 | validation: 0.235770564783766]
	TIME [epoch: 7.93 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v14_20240716_142610/states/model_facs_v2_dec1b_2dpca_v14_45.pth
	Model improved!!!
EPOCH 46/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2714588032313646		[learning rate: 0.0099426]
	Learning Rate: 0.0099426
	LOSS [training: 0.2714588032313646 | validation: 0.23199159134602954]
	TIME [epoch: 7.92 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v14_20240716_142610/states/model_facs_v2_dec1b_2dpca_v14_46.pth
	Model improved!!!
EPOCH 47/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2670350669026786		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 0.2670350669026786 | validation: 0.24199734325498307]
	TIME [epoch: 7.93 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2727015941151153		[learning rate: 0.0098637]
	Learning Rate: 0.00986367
	LOSS [training: 0.2727015941151153 | validation: 0.2208993639314536]
	TIME [epoch: 7.94 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v14_20240716_142610/states/model_facs_v2_dec1b_2dpca_v14_48.pth
	Model improved!!!
EPOCH 49/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2682138064289021		[learning rate: 0.0098244]
	Learning Rate: 0.00982444
	LOSS [training: 0.2682138064289021 | validation: 0.23006107166112044]
	TIME [epoch: 7.92 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.27487847966924844		[learning rate: 0.0097854]
	Learning Rate: 0.00978536
	LOSS [training: 0.27487847966924844 | validation: 0.2166349260275804]
	TIME [epoch: 7.92 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v14_20240716_142610/states/model_facs_v2_dec1b_2dpca_v14_50.pth
	Model improved!!!
EPOCH 51/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25735396555600604		[learning rate: 0.0097464]
	Learning Rate: 0.00974644
	LOSS [training: 0.25735396555600604 | validation: 0.2192188536668874]
	TIME [epoch: 36.5 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2648459813084368		[learning rate: 0.0097077]
	Learning Rate: 0.00970768
	LOSS [training: 0.2648459813084368 | validation: 0.217180771029181]
	TIME [epoch: 15.3 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2734243141096034		[learning rate: 0.0096691]
	Learning Rate: 0.00966907
	LOSS [training: 0.2734243141096034 | validation: 0.22856349160082887]
	TIME [epoch: 15.3 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26513033561666677		[learning rate: 0.0096306]
	Learning Rate: 0.00963061
	LOSS [training: 0.26513033561666677 | validation: 0.21017164122181517]
	TIME [epoch: 15.3 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v14_20240716_142610/states/model_facs_v2_dec1b_2dpca_v14_54.pth
	Model improved!!!
EPOCH 55/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2694872819454061		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 0.2694872819454061 | validation: 0.22032403390847294]
	TIME [epoch: 15.3 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26575818401941775		[learning rate: 0.0095542]
	Learning Rate: 0.00955415
	LOSS [training: 0.26575818401941775 | validation: 0.21277277809961403]
	TIME [epoch: 15.3 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2629171225558562		[learning rate: 0.0095162]
	Learning Rate: 0.00951616
	LOSS [training: 0.2629171225558562 | validation: 0.21642120056481978]
	TIME [epoch: 15.4 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2587463623233924		[learning rate: 0.0094783]
	Learning Rate: 0.00947831
	LOSS [training: 0.2587463623233924 | validation: 0.20807509168250596]
	TIME [epoch: 15.3 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v14_20240716_142610/states/model_facs_v2_dec1b_2dpca_v14_58.pth
	Model improved!!!
EPOCH 59/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2670904060495797		[learning rate: 0.0094406]
	Learning Rate: 0.00944061
	LOSS [training: 0.2670904060495797 | validation: 0.24534241917089883]
	TIME [epoch: 15.3 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.265359721878726		[learning rate: 0.0094031]
	Learning Rate: 0.00940306
	LOSS [training: 0.265359721878726 | validation: 0.21362493984252637]
	TIME [epoch: 15.3 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2583101348011734		[learning rate: 0.0093657]
	Learning Rate: 0.00936566
	LOSS [training: 0.2583101348011734 | validation: 0.21256545843340188]
	TIME [epoch: 15.3 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2578503075234915		[learning rate: 0.0093284]
	Learning Rate: 0.00932841
	LOSS [training: 0.2578503075234915 | validation: 0.21532457840276922]
	TIME [epoch: 15.3 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2539942018012838		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 0.2539942018012838 | validation: 0.2200515609325897]
	TIME [epoch: 15.3 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2571163963704269		[learning rate: 0.0092544]
	Learning Rate: 0.00925435
	LOSS [training: 0.2571163963704269 | validation: 0.20213358255793534]
	TIME [epoch: 15.3 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v14_20240716_142610/states/model_facs_v2_dec1b_2dpca_v14_64.pth
	Model improved!!!
EPOCH 65/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24339641197783168		[learning rate: 0.0092175]
	Learning Rate: 0.00921755
	LOSS [training: 0.24339641197783168 | validation: 0.21205842458691077]
	TIME [epoch: 15.3 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2625490336404614		[learning rate: 0.0091809]
	Learning Rate: 0.00918089
	LOSS [training: 0.2625490336404614 | validation: 0.2009363458363817]
	TIME [epoch: 15.3 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v14_20240716_142610/states/model_facs_v2_dec1b_2dpca_v14_66.pth
	Model improved!!!
EPOCH 67/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.254833645420884		[learning rate: 0.0091444]
	Learning Rate: 0.00914437
	LOSS [training: 0.254833645420884 | validation: 0.20066675183741464]
	TIME [epoch: 15.3 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v14_20240716_142610/states/model_facs_v2_dec1b_2dpca_v14_67.pth
	Model improved!!!
EPOCH 68/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25558749084004817		[learning rate: 0.009108]
	Learning Rate: 0.009108
	LOSS [training: 0.25558749084004817 | validation: 0.23158096806408404]
	TIME [epoch: 15.3 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2653066501923798		[learning rate: 0.0090718]
	Learning Rate: 0.00907178
	LOSS [training: 0.2653066501923798 | validation: 0.20875636994253105]
	TIME [epoch: 15.3 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25549037591845175		[learning rate: 0.0090357]
	Learning Rate: 0.00903569
	LOSS [training: 0.25549037591845175 | validation: 0.20949850366102168]
	TIME [epoch: 15.3 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2554121782066943		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 0.2554121782066943 | validation: 0.21382582578756684]
	TIME [epoch: 15.3 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2594871410947504		[learning rate: 0.008964]
	Learning Rate: 0.00896396
	LOSS [training: 0.2594871410947504 | validation: 0.20537643250144466]
	TIME [epoch: 15.3 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25601300295739776		[learning rate: 0.0089283]
	Learning Rate: 0.00892831
	LOSS [training: 0.25601300295739776 | validation: 0.20691444139929116]
	TIME [epoch: 15.3 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25163243257770457		[learning rate: 0.0088928]
	Learning Rate: 0.0088928
	LOSS [training: 0.25163243257770457 | validation: 0.20852065210392498]
	TIME [epoch: 15.3 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2639620657639996		[learning rate: 0.0088574]
	Learning Rate: 0.00885743
	LOSS [training: 0.2639620657639996 | validation: 0.19688601560767136]
	TIME [epoch: 15.3 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v14_20240716_142610/states/model_facs_v2_dec1b_2dpca_v14_75.pth
	Model improved!!!
EPOCH 76/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25293205875215613		[learning rate: 0.0088222]
	Learning Rate: 0.0088222
	LOSS [training: 0.25293205875215613 | validation: 0.20754338330312788]
	TIME [epoch: 15.3 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25053533628756913		[learning rate: 0.0087871]
	Learning Rate: 0.00878711
	LOSS [training: 0.25053533628756913 | validation: 0.19944312533145853]
	TIME [epoch: 15.3 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26993548559953096		[learning rate: 0.0087522]
	Learning Rate: 0.00875216
	LOSS [training: 0.26993548559953096 | validation: 0.19968467079956134]
	TIME [epoch: 15.3 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24460958982757924		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 0.24460958982757924 | validation: 0.21322264174330324]
	TIME [epoch: 15.3 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25787084106970165		[learning rate: 0.0086827]
	Learning Rate: 0.00868268
	LOSS [training: 0.25787084106970165 | validation: 0.2090391978303622]
	TIME [epoch: 15.2 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2568987495676301		[learning rate: 0.0086481]
	Learning Rate: 0.00864815
	LOSS [training: 0.2568987495676301 | validation: 0.20206347718891365]
	TIME [epoch: 15.3 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24101614633949117		[learning rate: 0.0086138]
	Learning Rate: 0.00861375
	LOSS [training: 0.24101614633949117 | validation: 0.21182654742701396]
	TIME [epoch: 15.3 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26101333436475926		[learning rate: 0.0085795]
	Learning Rate: 0.00857949
	LOSS [training: 0.26101333436475926 | validation: 0.2274268280363799]
	TIME [epoch: 15.3 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24844976355816945		[learning rate: 0.0085454]
	Learning Rate: 0.00854537
	LOSS [training: 0.24844976355816945 | validation: 0.20175684281135]
	TIME [epoch: 15.3 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25722756361437704		[learning rate: 0.0085114]
	Learning Rate: 0.00851138
	LOSS [training: 0.25722756361437704 | validation: 0.21253866374251337]
	TIME [epoch: 15.3 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24819238953783673		[learning rate: 0.0084775]
	Learning Rate: 0.00847753
	LOSS [training: 0.24819238953783673 | validation: 0.2184728176693489]
	TIME [epoch: 15.2 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23844465975461293		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 0.23844465975461293 | validation: 0.2113270455659299]
	TIME [epoch: 15.3 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24601769041312516		[learning rate: 0.0084102]
	Learning Rate: 0.00841023
	LOSS [training: 0.24601769041312516 | validation: 0.20182657399523238]
	TIME [epoch: 15.2 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24332000781236512		[learning rate: 0.0083768]
	Learning Rate: 0.00837678
	LOSS [training: 0.24332000781236512 | validation: 0.19997047391379585]
	TIME [epoch: 15.3 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2606851596403959		[learning rate: 0.0083435]
	Learning Rate: 0.00834346
	LOSS [training: 0.2606851596403959 | validation: 0.20717916428220412]
	TIME [epoch: 15.3 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24193327496043043		[learning rate: 0.0083103]
	Learning Rate: 0.00831027
	LOSS [training: 0.24193327496043043 | validation: 0.18755430030546436]
	TIME [epoch: 15.3 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v14_20240716_142610/states/model_facs_v2_dec1b_2dpca_v14_91.pth
	Model improved!!!
EPOCH 92/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2507551576842605		[learning rate: 0.0082772]
	Learning Rate: 0.00827722
	LOSS [training: 0.2507551576842605 | validation: 0.21577459324040169]
	TIME [epoch: 15.3 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2505270513879836		[learning rate: 0.0082443]
	Learning Rate: 0.0082443
	LOSS [training: 0.2505270513879836 | validation: 0.20541308727041846]
	TIME [epoch: 15.3 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24974461901331135		[learning rate: 0.0082115]
	Learning Rate: 0.00821151
	LOSS [training: 0.24974461901331135 | validation: 0.24324050680957607]
	TIME [epoch: 15.3 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2538245257595642		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 0.2538245257595642 | validation: 0.2173433807391109]
	TIME [epoch: 15.3 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24881518617394832		[learning rate: 0.0081463]
	Learning Rate: 0.00814632
	LOSS [training: 0.24881518617394832 | validation: 0.2005793926812835]
	TIME [epoch: 15.3 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2433425546089416		[learning rate: 0.0081139]
	Learning Rate: 0.00811392
	LOSS [training: 0.2433425546089416 | validation: 0.20319959610999022]
	TIME [epoch: 15.3 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2410205434047224		[learning rate: 0.0080816]
	Learning Rate: 0.00808165
	LOSS [training: 0.2410205434047224 | validation: 0.19829078078176443]
	TIME [epoch: 15.3 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26113567394665593		[learning rate: 0.0080495]
	Learning Rate: 0.00804951
	LOSS [training: 0.26113567394665593 | validation: 0.21481409287929504]
	TIME [epoch: 15.3 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2554933376920476		[learning rate: 0.0080175]
	Learning Rate: 0.00801749
	LOSS [training: 0.2554933376920476 | validation: 0.20963293427890695]
	TIME [epoch: 15.3 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24661225340951917		[learning rate: 0.0079856]
	Learning Rate: 0.0079856
	LOSS [training: 0.24661225340951917 | validation: 0.21868859667015988]
	TIME [epoch: 15.3 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26535795661153583		[learning rate: 0.0079538]
	Learning Rate: 0.00795384
	LOSS [training: 0.26535795661153583 | validation: 0.19623340256546332]
	TIME [epoch: 15.3 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25267815373489255		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 0.25267815373489255 | validation: 0.19420611178656041]
	TIME [epoch: 15.2 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25483406342680426		[learning rate: 0.0078907]
	Learning Rate: 0.0078907
	LOSS [training: 0.25483406342680426 | validation: 0.20029477405810633]
	TIME [epoch: 15.2 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2493063901216352		[learning rate: 0.0078593]
	Learning Rate: 0.00785931
	LOSS [training: 0.2493063901216352 | validation: 0.19944124591668572]
	TIME [epoch: 15.2 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2438586959265323		[learning rate: 0.0078281]
	Learning Rate: 0.00782805
	LOSS [training: 0.2438586959265323 | validation: 0.1980646722275434]
	TIME [epoch: 15.3 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2452275267370897		[learning rate: 0.0077969]
	Learning Rate: 0.00779692
	LOSS [training: 0.2452275267370897 | validation: 0.201494730954965]
	TIME [epoch: 15.3 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24263809322682922		[learning rate: 0.0077659]
	Learning Rate: 0.00776591
	LOSS [training: 0.24263809322682922 | validation: 0.19734311436638602]
	TIME [epoch: 15.3 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2496693027266232		[learning rate: 0.007735]
	Learning Rate: 0.00773502
	LOSS [training: 0.2496693027266232 | validation: 0.19104796169875346]
	TIME [epoch: 15.3 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24055594349533693		[learning rate: 0.0077043]
	Learning Rate: 0.00770426
	LOSS [training: 0.24055594349533693 | validation: 0.19338478562709616]
	TIME [epoch: 15.3 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25902644238521555		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 0.25902644238521555 | validation: 0.20360801010528645]
	TIME [epoch: 15.3 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2513202241516556		[learning rate: 0.0076431]
	Learning Rate: 0.00764309
	LOSS [training: 0.2513202241516556 | validation: 0.18689011809267508]
	TIME [epoch: 15.3 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v14_20240716_142610/states/model_facs_v2_dec1b_2dpca_v14_112.pth
	Model improved!!!
EPOCH 113/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23850039808409987		[learning rate: 0.0076127]
	Learning Rate: 0.00761269
	LOSS [training: 0.23850039808409987 | validation: 0.19643413964493933]
	TIME [epoch: 15.3 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24840635671822112		[learning rate: 0.0075824]
	Learning Rate: 0.00758242
	LOSS [training: 0.24840635671822112 | validation: 0.20422754059513873]
	TIME [epoch: 15.3 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24147696708387845		[learning rate: 0.0075523]
	Learning Rate: 0.00755226
	LOSS [training: 0.24147696708387845 | validation: 0.20410425326113]
	TIME [epoch: 15.3 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2505547315345034		[learning rate: 0.0075222]
	Learning Rate: 0.00752222
	LOSS [training: 0.2505547315345034 | validation: 0.19495268135151222]
	TIME [epoch: 15.3 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25097661050690273		[learning rate: 0.0074923]
	Learning Rate: 0.0074923
	LOSS [training: 0.25097661050690273 | validation: 0.224533428505018]
	TIME [epoch: 15.3 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24244825651318264		[learning rate: 0.0074625]
	Learning Rate: 0.0074625
	LOSS [training: 0.24244825651318264 | validation: 0.22313162816816395]
	TIME [epoch: 15.3 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25142987231812813		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 0.25142987231812813 | validation: 0.2037368313411712]
	TIME [epoch: 15.3 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25008936169223683		[learning rate: 0.0074033]
	Learning Rate: 0.00740326
	LOSS [training: 0.25008936169223683 | validation: 0.19911794613615616]
	TIME [epoch: 15.3 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25137769219824846		[learning rate: 0.0073738]
	Learning Rate: 0.00737382
	LOSS [training: 0.25137769219824846 | validation: 0.20366030744284985]
	TIME [epoch: 15.2 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24309314163035278		[learning rate: 0.0073445]
	Learning Rate: 0.00734449
	LOSS [training: 0.24309314163035278 | validation: 0.2008548235435737]
	TIME [epoch: 15.3 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23909772840353558		[learning rate: 0.0073153]
	Learning Rate: 0.00731528
	LOSS [training: 0.23909772840353558 | validation: 0.19965061535595974]
	TIME [epoch: 15.3 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.249827160203553		[learning rate: 0.0072862]
	Learning Rate: 0.00728618
	LOSS [training: 0.249827160203553 | validation: 0.19888302216561604]
	TIME [epoch: 15.2 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24402492397266837		[learning rate: 0.0072572]
	Learning Rate: 0.0072572
	LOSS [training: 0.24402492397266837 | validation: 0.19593249874790725]
	TIME [epoch: 15.2 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24656412203848324		[learning rate: 0.0072283]
	Learning Rate: 0.00722834
	LOSS [training: 0.24656412203848324 | validation: 0.1964107167434971]
	TIME [epoch: 15.2 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23849972181688248		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 0.23849972181688248 | validation: 0.22543957922891272]
	TIME [epoch: 15.3 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2530756296817278		[learning rate: 0.007171]
	Learning Rate: 0.00717095
	LOSS [training: 0.2530756296817278 | validation: 0.20092427845870575]
	TIME [epoch: 15.2 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2381363067541538		[learning rate: 0.0071424]
	Learning Rate: 0.00714243
	LOSS [training: 0.2381363067541538 | validation: 0.2012750527045629]
	TIME [epoch: 15.2 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2463069041744888		[learning rate: 0.007114]
	Learning Rate: 0.00711403
	LOSS [training: 0.2463069041744888 | validation: 0.20406135275552878]
	TIME [epoch: 15.2 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2450047962850642		[learning rate: 0.0070857]
	Learning Rate: 0.00708573
	LOSS [training: 0.2450047962850642 | validation: 0.20537014731533199]
	TIME [epoch: 15.3 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24421931674281133		[learning rate: 0.0070575]
	Learning Rate: 0.00705755
	LOSS [training: 0.24421931674281133 | validation: 0.19289461618858644]
	TIME [epoch: 15.3 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24375784124708014		[learning rate: 0.0070295]
	Learning Rate: 0.00702948
	LOSS [training: 0.24375784124708014 | validation: 0.21774470197865559]
	TIME [epoch: 15.2 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24838099858618387		[learning rate: 0.0070015]
	Learning Rate: 0.00700152
	LOSS [training: 0.24838099858618387 | validation: 0.20199314820541395]
	TIME [epoch: 15.3 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24342347033097023		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 0.24342347033097023 | validation: 0.20844360561421454]
	TIME [epoch: 15.3 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23305862161263283		[learning rate: 0.0069459]
	Learning Rate: 0.00694594
	LOSS [training: 0.23305862161263283 | validation: 0.19691794462330015]
	TIME [epoch: 15.3 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24482450951758217		[learning rate: 0.0069183]
	Learning Rate: 0.00691831
	LOSS [training: 0.24482450951758217 | validation: 0.18339939837356645]
	TIME [epoch: 15.2 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v14_20240716_142610/states/model_facs_v2_dec1b_2dpca_v14_137.pth
	Model improved!!!
EPOCH 138/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23922495314164852		[learning rate: 0.0068908]
	Learning Rate: 0.00689079
	LOSS [training: 0.23922495314164852 | validation: 0.20030154188081487]
	TIME [epoch: 15.2 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2497479767174672		[learning rate: 0.0068634]
	Learning Rate: 0.00686339
	LOSS [training: 0.2497479767174672 | validation: 0.19993015943342302]
	TIME [epoch: 15.2 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24846854616704833		[learning rate: 0.0068361]
	Learning Rate: 0.00683609
	LOSS [training: 0.24846854616704833 | validation: 0.24118902314828256]
	TIME [epoch: 15.2 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25309901292220327		[learning rate: 0.0068089]
	Learning Rate: 0.0068089
	LOSS [training: 0.25309901292220327 | validation: 0.20938094115079764]
	TIME [epoch: 15.2 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2511835721392133		[learning rate: 0.0067818]
	Learning Rate: 0.00678182
	LOSS [training: 0.2511835721392133 | validation: 0.19560857978429896]
	TIME [epoch: 15.2 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2447785999153823		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 0.2447785999153823 | validation: 0.20114499788020415]
	TIME [epoch: 15.2 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23404905206403814		[learning rate: 0.006728]
	Learning Rate: 0.00672798
	LOSS [training: 0.23404905206403814 | validation: 0.19339280867001074]
	TIME [epoch: 15.2 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25735491935889787		[learning rate: 0.0067012]
	Learning Rate: 0.00670122
	LOSS [training: 0.25735491935889787 | validation: 0.19362589625326948]
	TIME [epoch: 15.3 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25478817560917955		[learning rate: 0.0066746]
	Learning Rate: 0.00667457
	LOSS [training: 0.25478817560917955 | validation: 0.2002999206825345]
	TIME [epoch: 15.2 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24912592796369756		[learning rate: 0.006648]
	Learning Rate: 0.00664802
	LOSS [training: 0.24912592796369756 | validation: 0.2050899620553129]
	TIME [epoch: 15.2 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23399920585116282		[learning rate: 0.0066216]
	Learning Rate: 0.00662158
	LOSS [training: 0.23399920585116282 | validation: 0.19286797532481229]
	TIME [epoch: 15.2 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2400185721762123		[learning rate: 0.0065952]
	Learning Rate: 0.00659524
	LOSS [training: 0.2400185721762123 | validation: 0.1933007041539893]
	TIME [epoch: 15.3 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24888825572016554		[learning rate: 0.006569]
	Learning Rate: 0.00656901
	LOSS [training: 0.24888825572016554 | validation: 0.2053674798033523]
	TIME [epoch: 15.2 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24363743824233486		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 0.24363743824233486 | validation: 0.18861672438602126]
	TIME [epoch: 15.2 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24419710838289374		[learning rate: 0.0065169]
	Learning Rate: 0.00651686
	LOSS [training: 0.24419710838289374 | validation: 0.2020015074918013]
	TIME [epoch: 15.2 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23630740758321048		[learning rate: 0.0064909]
	Learning Rate: 0.00649094
	LOSS [training: 0.23630740758321048 | validation: 0.19891144488910734]
	TIME [epoch: 15.3 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24385775799839438		[learning rate: 0.0064651]
	Learning Rate: 0.00646512
	LOSS [training: 0.24385775799839438 | validation: 0.20234992216539194]
	TIME [epoch: 15.2 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2503098506311456		[learning rate: 0.0064394]
	Learning Rate: 0.00643941
	LOSS [training: 0.2503098506311456 | validation: 0.1945002012368769]
	TIME [epoch: 15.3 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24043120753794522		[learning rate: 0.0064138]
	Learning Rate: 0.0064138
	LOSS [training: 0.24043120753794522 | validation: 0.19674244298796625]
	TIME [epoch: 15.2 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24181284273451242		[learning rate: 0.0063883]
	Learning Rate: 0.00638829
	LOSS [training: 0.24181284273451242 | validation: 0.19305702541249609]
	TIME [epoch: 15.2 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2381746829218932		[learning rate: 0.0063629]
	Learning Rate: 0.00636288
	LOSS [training: 0.2381746829218932 | validation: 0.19716652894366238]
	TIME [epoch: 15.2 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2416101021593938		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 0.2416101021593938 | validation: 0.20888458496366566]
	TIME [epoch: 15.2 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.25057955856528136		[learning rate: 0.0063124]
	Learning Rate: 0.00631237
	LOSS [training: 0.25057955856528136 | validation: 0.1927814664795809]
	TIME [epoch: 15.2 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23932036486605954		[learning rate: 0.0062873]
	Learning Rate: 0.00628726
	LOSS [training: 0.23932036486605954 | validation: 0.1878989126136301]
	TIME [epoch: 15.3 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2401910526636687		[learning rate: 0.0062623]
	Learning Rate: 0.00626226
	LOSS [training: 0.2401910526636687 | validation: 0.1909718897653277]
	TIME [epoch: 15.2 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23714448731869928		[learning rate: 0.0062373]
	Learning Rate: 0.00623735
	LOSS [training: 0.23714448731869928 | validation: 0.20031671502631943]
	TIME [epoch: 15.2 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23504411717141505		[learning rate: 0.0062125]
	Learning Rate: 0.00621254
	LOSS [training: 0.23504411717141505 | validation: 0.21147533418775274]
	TIME [epoch: 15.3 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23836454004520682		[learning rate: 0.0061878]
	Learning Rate: 0.00618783
	LOSS [training: 0.23836454004520682 | validation: 0.2022128256579026]
	TIME [epoch: 15.2 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24451885049188865		[learning rate: 0.0061632]
	Learning Rate: 0.00616322
	LOSS [training: 0.24451885049188865 | validation: 0.18473689470127203]
	TIME [epoch: 15.2 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24210235849800923		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 0.24210235849800923 | validation: 0.21046907358476688]
	TIME [epoch: 15.2 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.250574818964696		[learning rate: 0.0061143]
	Learning Rate: 0.00611429
	LOSS [training: 0.250574818964696 | validation: 0.20025024314347237]
	TIME [epoch: 15.2 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2531307473448766		[learning rate: 0.00609]
	Learning Rate: 0.00608997
	LOSS [training: 0.2531307473448766 | validation: 0.19766028661220503]
	TIME [epoch: 15.2 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2435790432670545		[learning rate: 0.0060658]
	Learning Rate: 0.00606575
	LOSS [training: 0.2435790432670545 | validation: 0.19294094275652518]
	TIME [epoch: 15.2 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23750672538483858		[learning rate: 0.0060416]
	Learning Rate: 0.00604163
	LOSS [training: 0.23750672538483858 | validation: 0.205792012954526]
	TIME [epoch: 15.2 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24918951677915643		[learning rate: 0.0060176]
	Learning Rate: 0.0060176
	LOSS [training: 0.24918951677915643 | validation: 0.19874928928900934]
	TIME [epoch: 15.3 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2401280366602492		[learning rate: 0.0059937]
	Learning Rate: 0.00599366
	LOSS [training: 0.2401280366602492 | validation: 0.20586023091192404]
	TIME [epoch: 15.3 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24424357086929613		[learning rate: 0.0059698]
	Learning Rate: 0.00596982
	LOSS [training: 0.24424357086929613 | validation: 0.19725934247357133]
	TIME [epoch: 15.2 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24650724229166704		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 0.24650724229166704 | validation: 0.19658500186106648]
	TIME [epoch: 15.3 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24218165141804063		[learning rate: 0.0059224]
	Learning Rate: 0.00592243
	LOSS [training: 0.24218165141804063 | validation: 0.18813818417602018]
	TIME [epoch: 15.2 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23618793745646854		[learning rate: 0.0058989]
	Learning Rate: 0.00589888
	LOSS [training: 0.23618793745646854 | validation: 0.20323398224531458]
	TIME [epoch: 15.2 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24408411610397687		[learning rate: 0.0058754]
	Learning Rate: 0.00587541
	LOSS [training: 0.24408411610397687 | validation: 0.20014541429225904]
	TIME [epoch: 15.3 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23360296876380193		[learning rate: 0.005852]
	Learning Rate: 0.00585205
	LOSS [training: 0.23360296876380193 | validation: 0.19823794043156448]
	TIME [epoch: 15.2 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24462260591745025		[learning rate: 0.0058288]
	Learning Rate: 0.00582877
	LOSS [training: 0.24462260591745025 | validation: 0.23126732243932935]
	TIME [epoch: 15.3 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24695910339826865		[learning rate: 0.0058056]
	Learning Rate: 0.00580559
	LOSS [training: 0.24695910339826865 | validation: 0.19744459355395794]
	TIME [epoch: 15.3 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2413680658048824		[learning rate: 0.0057825]
	Learning Rate: 0.0057825
	LOSS [training: 0.2413680658048824 | validation: 0.1997606737143494]
	TIME [epoch: 15.2 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2326509430555203		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 0.2326509430555203 | validation: 0.19243807398354745]
	TIME [epoch: 15.3 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23277601733846154		[learning rate: 0.0057366]
	Learning Rate: 0.00573659
	LOSS [training: 0.23277601733846154 | validation: 0.2134417258324152]
	TIME [epoch: 15.3 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2507600049455354		[learning rate: 0.0057138]
	Learning Rate: 0.00571377
	LOSS [training: 0.2507600049455354 | validation: 0.1854780557625953]
	TIME [epoch: 15.2 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23689180601859514		[learning rate: 0.005691]
	Learning Rate: 0.00569105
	LOSS [training: 0.23689180601859514 | validation: 0.18968741148919244]
	TIME [epoch: 15.2 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2432461200693303		[learning rate: 0.0056684]
	Learning Rate: 0.00566841
	LOSS [training: 0.2432461200693303 | validation: 0.19423977783039267]
	TIME [epoch: 15.2 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23184391848818636		[learning rate: 0.0056459]
	Learning Rate: 0.00564587
	LOSS [training: 0.23184391848818636 | validation: 0.20412191456860898]
	TIME [epoch: 15.3 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24170838573407993		[learning rate: 0.0056234]
	Learning Rate: 0.00562341
	LOSS [training: 0.24170838573407993 | validation: 0.23180624720052245]
	TIME [epoch: 15.3 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24612939099811731		[learning rate: 0.005601]
	Learning Rate: 0.00560105
	LOSS [training: 0.24612939099811731 | validation: 0.19480088135917564]
	TIME [epoch: 15.2 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23666897823316832		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 0.23666897823316832 | validation: 0.18986853286640729]
	TIME [epoch: 15.3 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2409504876848491		[learning rate: 0.0055566]
	Learning Rate: 0.00555658
	LOSS [training: 0.2409504876848491 | validation: 0.21417597327233437]
	TIME [epoch: 15.3 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2328268804377815		[learning rate: 0.0055345]
	Learning Rate: 0.00553448
	LOSS [training: 0.2328268804377815 | validation: 0.19685219905583493]
	TIME [epoch: 15.2 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24114190061324756		[learning rate: 0.0055125]
	Learning Rate: 0.00551247
	LOSS [training: 0.24114190061324756 | validation: 0.2244439492164728]
	TIME [epoch: 15.2 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.248556783122361		[learning rate: 0.0054905]
	Learning Rate: 0.00549054
	LOSS [training: 0.248556783122361 | validation: 0.20368564041025086]
	TIME [epoch: 15.3 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23701553591798438		[learning rate: 0.0054687]
	Learning Rate: 0.00546871
	LOSS [training: 0.23701553591798438 | validation: 0.20415892292445648]
	TIME [epoch: 15.2 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2480224153549854		[learning rate: 0.005447]
	Learning Rate: 0.00544696
	LOSS [training: 0.2480224153549854 | validation: 0.19246155165352802]
	TIME [epoch: 15.3 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2378769705360076		[learning rate: 0.0054253]
	Learning Rate: 0.00542529
	LOSS [training: 0.2378769705360076 | validation: 0.19287884261356877]
	TIME [epoch: 15.2 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24442108011105684		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 0.24442108011105684 | validation: 0.18785679327305832]
	TIME [epoch: 15.2 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2346011649708578		[learning rate: 0.0053822]
	Learning Rate: 0.00538222
	LOSS [training: 0.2346011649708578 | validation: 0.19777261733812412]
	TIME [epoch: 15.3 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2502255522765752		[learning rate: 0.0053608]
	Learning Rate: 0.00536081
	LOSS [training: 0.2502255522765752 | validation: 0.19649106376324457]
	TIME [epoch: 15.3 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23224059805839317		[learning rate: 0.0053395]
	Learning Rate: 0.00533949
	LOSS [training: 0.23224059805839317 | validation: 0.20042502680428873]
	TIME [epoch: 15.3 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23397020345353903		[learning rate: 0.0053183]
	Learning Rate: 0.00531826
	LOSS [training: 0.23397020345353903 | validation: 0.2055655219124876]
	TIME [epoch: 15.3 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2359199225116272		[learning rate: 0.0052971]
	Learning Rate: 0.0052971
	LOSS [training: 0.2359199225116272 | validation: 0.19319924343965447]
	TIME [epoch: 15.2 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2435520465196628		[learning rate: 0.005276]
	Learning Rate: 0.00527604
	LOSS [training: 0.2435520465196628 | validation: 0.19679255804247675]
	TIME [epoch: 15.3 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23669505315708117		[learning rate: 0.0052551]
	Learning Rate: 0.00525505
	LOSS [training: 0.23669505315708117 | validation: 0.2130229095434156]
	TIME [epoch: 15.2 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24030655109016597		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 0.24030655109016597 | validation: 0.20199703475387842]
	TIME [epoch: 15.3 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24157676774719677		[learning rate: 0.0052133]
	Learning Rate: 0.00521333
	LOSS [training: 0.24157676774719677 | validation: 0.19788528354321921]
	TIME [epoch: 15.3 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24218742643653993		[learning rate: 0.0051926]
	Learning Rate: 0.0051926
	LOSS [training: 0.24218742643653993 | validation: 0.1883707439979547]
	TIME [epoch: 15.2 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23287943529785185		[learning rate: 0.0051719]
	Learning Rate: 0.00517194
	LOSS [training: 0.23287943529785185 | validation: 0.1943811974500949]
	TIME [epoch: 15.2 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2499580647213134		[learning rate: 0.0051514]
	Learning Rate: 0.00515137
	LOSS [training: 0.2499580647213134 | validation: 0.19440365099400386]
	TIME [epoch: 15.2 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2308117413230843		[learning rate: 0.0051309]
	Learning Rate: 0.00513089
	LOSS [training: 0.2308117413230843 | validation: 0.19578634401389772]
	TIME [epoch: 15.2 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24636766907097962		[learning rate: 0.0051105]
	Learning Rate: 0.00511048
	LOSS [training: 0.24636766907097962 | validation: 0.18799030790111226]
	TIME [epoch: 15.2 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23947347025390028		[learning rate: 0.0050902]
	Learning Rate: 0.00509015
	LOSS [training: 0.23947347025390028 | validation: 0.19787231450772008]
	TIME [epoch: 15.3 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23444016121078037		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 0.23444016121078037 | validation: 0.19020020522511505]
	TIME [epoch: 15.3 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23932825166692392		[learning rate: 0.0050497]
	Learning Rate: 0.00504974
	LOSS [training: 0.23932825166692392 | validation: 0.19952243767268202]
	TIME [epoch: 15.3 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2441126355931162		[learning rate: 0.0050297]
	Learning Rate: 0.00502966
	LOSS [training: 0.2441126355931162 | validation: 0.19475271102327243]
	TIME [epoch: 15.3 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23655364108494295		[learning rate: 0.0050097]
	Learning Rate: 0.00500965
	LOSS [training: 0.23655364108494295 | validation: 0.19358155563028648]
	TIME [epoch: 15.3 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23512890384402446		[learning rate: 0.0049897]
	Learning Rate: 0.00498973
	LOSS [training: 0.23512890384402446 | validation: 0.19127075587550518]
	TIME [epoch: 15.3 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23857469439402423		[learning rate: 0.0049699]
	Learning Rate: 0.00496988
	LOSS [training: 0.23857469439402423 | validation: 0.19611431914808913]
	TIME [epoch: 15.2 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2382478620148902		[learning rate: 0.0049501]
	Learning Rate: 0.00495012
	LOSS [training: 0.2382478620148902 | validation: 0.18651942673678343]
	TIME [epoch: 15.2 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23150284658754927		[learning rate: 0.0049304]
	Learning Rate: 0.00493043
	LOSS [training: 0.23150284658754927 | validation: 0.18928830982505634]
	TIME [epoch: 15.3 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23715505692696784		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 0.23715505692696784 | validation: 0.19659835734624637]
	TIME [epoch: 15.2 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2339987054944218		[learning rate: 0.0048913]
	Learning Rate: 0.00489129
	LOSS [training: 0.2339987054944218 | validation: 0.19508719621429887]
	TIME [epoch: 15.2 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23782211639073247		[learning rate: 0.0048718]
	Learning Rate: 0.00487183
	LOSS [training: 0.23782211639073247 | validation: 0.20529176286734954]
	TIME [epoch: 15.3 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2488824526023514		[learning rate: 0.0048525]
	Learning Rate: 0.00485245
	LOSS [training: 0.2488824526023514 | validation: 0.1907450427505328]
	TIME [epoch: 15.2 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23224553312679794		[learning rate: 0.0048332]
	Learning Rate: 0.00483316
	LOSS [training: 0.23224553312679794 | validation: 0.1921698407592369]
	TIME [epoch: 15.2 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22710574583310322		[learning rate: 0.0048139]
	Learning Rate: 0.00481393
	LOSS [training: 0.22710574583310322 | validation: 0.1995634590002769]
	TIME [epoch: 15.2 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2385978826357285		[learning rate: 0.0047948]
	Learning Rate: 0.00479479
	LOSS [training: 0.2385978826357285 | validation: 0.1966717740642408]
	TIME [epoch: 15.2 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24095149534813654		[learning rate: 0.0047757]
	Learning Rate: 0.00477572
	LOSS [training: 0.24095149534813654 | validation: 0.19598185615472358]
	TIME [epoch: 15.3 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2333679228065107		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.2333679228065107 | validation: 0.18240323265441355]
	TIME [epoch: 15.2 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v14_20240716_142610/states/model_facs_v2_dec1b_2dpca_v14_231.pth
	Model improved!!!
EPOCH 232/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24230964529965585		[learning rate: 0.0047378]
	Learning Rate: 0.0047378
	LOSS [training: 0.24230964529965585 | validation: 0.201408766739298]
	TIME [epoch: 15.3 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23561789407265524		[learning rate: 0.004719]
	Learning Rate: 0.00471896
	LOSS [training: 0.23561789407265524 | validation: 0.21030267711540834]
	TIME [epoch: 15.2 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23186674280892414		[learning rate: 0.0047002]
	Learning Rate: 0.00470019
	LOSS [training: 0.23186674280892414 | validation: 0.19742652948762568]
	TIME [epoch: 15.2 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2386398267157333		[learning rate: 0.0046815]
	Learning Rate: 0.0046815
	LOSS [training: 0.2386398267157333 | validation: 0.20661955807339177]
	TIME [epoch: 15.2 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24082917004397908		[learning rate: 0.0046629]
	Learning Rate: 0.00466288
	LOSS [training: 0.24082917004397908 | validation: 0.19551960098690185]
	TIME [epoch: 15.2 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2289112581693781		[learning rate: 0.0046443]
	Learning Rate: 0.00464433
	LOSS [training: 0.2289112581693781 | validation: 0.18918847770736902]
	TIME [epoch: 15.2 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2456138132635997		[learning rate: 0.0046259]
	Learning Rate: 0.00462586
	LOSS [training: 0.2456138132635997 | validation: 0.19219159191391622]
	TIME [epoch: 15.2 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2434040000438841		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 0.2434040000438841 | validation: 0.19339104994679826]
	TIME [epoch: 15.3 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2430306835709125		[learning rate: 0.0045891]
	Learning Rate: 0.00458913
	LOSS [training: 0.2430306835709125 | validation: 0.20118908917810904]
	TIME [epoch: 15.2 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2392873033507684		[learning rate: 0.0045709]
	Learning Rate: 0.00457088
	LOSS [training: 0.2392873033507684 | validation: 0.1934614024181855]
	TIME [epoch: 15.2 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23746524062396002		[learning rate: 0.0045527]
	Learning Rate: 0.0045527
	LOSS [training: 0.23746524062396002 | validation: 0.19273157301060592]
	TIME [epoch: 15.2 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24123764275521264		[learning rate: 0.0045346]
	Learning Rate: 0.00453459
	LOSS [training: 0.24123764275521264 | validation: 0.19684472131460287]
	TIME [epoch: 15.3 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24371755753370813		[learning rate: 0.0045166]
	Learning Rate: 0.00451656
	LOSS [training: 0.24371755753370813 | validation: 0.19903759614156874]
	TIME [epoch: 15.3 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22938322875683767		[learning rate: 0.0044986]
	Learning Rate: 0.0044986
	LOSS [training: 0.22938322875683767 | validation: 0.18954987893434982]
	TIME [epoch: 15.2 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2358938905654717		[learning rate: 0.0044807]
	Learning Rate: 0.0044807
	LOSS [training: 0.2358938905654717 | validation: 0.1901060715068082]
	TIME [epoch: 15.2 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2378745643727528		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 0.2378745643727528 | validation: 0.19087627134391186]
	TIME [epoch: 15.3 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23458117141586354		[learning rate: 0.0044451]
	Learning Rate: 0.00444513
	LOSS [training: 0.23458117141586354 | validation: 0.18698103383649706]
	TIME [epoch: 15.3 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2401215636583219		[learning rate: 0.0044275]
	Learning Rate: 0.00442745
	LOSS [training: 0.2401215636583219 | validation: 0.2004946326716252]
	TIME [epoch: 15.2 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23940295174434242		[learning rate: 0.0044098]
	Learning Rate: 0.00440984
	LOSS [training: 0.23940295174434242 | validation: 0.18773937509377003]
	TIME [epoch: 15.3 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22609337675433455		[learning rate: 0.0043923]
	Learning Rate: 0.0043923
	LOSS [training: 0.22609337675433455 | validation: 0.22029453280069392]
	TIME [epoch: 15.2 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23370955533013277		[learning rate: 0.0043748]
	Learning Rate: 0.00437483
	LOSS [training: 0.23370955533013277 | validation: 0.18825418074519132]
	TIME [epoch: 15.3 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24127450310168447		[learning rate: 0.0043574]
	Learning Rate: 0.00435743
	LOSS [training: 0.24127450310168447 | validation: 0.18791172574430234]
	TIME [epoch: 15.2 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23212327524977872		[learning rate: 0.0043401]
	Learning Rate: 0.0043401
	LOSS [training: 0.23212327524977872 | validation: 0.1853060504662272]
	TIME [epoch: 15.2 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23276124327876044		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 0.23276124327876044 | validation: 0.19477544782921208]
	TIME [epoch: 15.2 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2355633020736662		[learning rate: 0.0043056]
	Learning Rate: 0.00430565
	LOSS [training: 0.2355633020736662 | validation: 0.19541410980030918]
	TIME [epoch: 15.3 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24173851576523683		[learning rate: 0.0042885]
	Learning Rate: 0.00428852
	LOSS [training: 0.24173851576523683 | validation: 0.19460632475770492]
	TIME [epoch: 15.2 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23334558418084494		[learning rate: 0.0042715]
	Learning Rate: 0.00427147
	LOSS [training: 0.23334558418084494 | validation: 0.1916874494566867]
	TIME [epoch: 15.3 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23482746449998723		[learning rate: 0.0042545]
	Learning Rate: 0.00425448
	LOSS [training: 0.23482746449998723 | validation: 0.19321010496792174]
	TIME [epoch: 15.3 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23421098800140142		[learning rate: 0.0042376]
	Learning Rate: 0.00423756
	LOSS [training: 0.23421098800140142 | validation: 0.20145223883035207]
	TIME [epoch: 15.3 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23692705795780755		[learning rate: 0.0042207]
	Learning Rate: 0.0042207
	LOSS [training: 0.23692705795780755 | validation: 0.2002066224343809]
	TIME [epoch: 15.3 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23334106212562566		[learning rate: 0.0042039]
	Learning Rate: 0.00420391
	LOSS [training: 0.23334106212562566 | validation: 0.19059897332898448]
	TIME [epoch: 15.3 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2369737971984237		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 0.2369737971984237 | validation: 0.18863927246808584]
	TIME [epoch: 15.2 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22829821762057081		[learning rate: 0.0041705]
	Learning Rate: 0.00417054
	LOSS [training: 0.22829821762057081 | validation: 0.19257526118772514]
	TIME [epoch: 15.2 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23072952440869088		[learning rate: 0.004154]
	Learning Rate: 0.00415395
	LOSS [training: 0.23072952440869088 | validation: 0.19706258353207473]
	TIME [epoch: 15.2 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2447244918209815		[learning rate: 0.0041374]
	Learning Rate: 0.00413743
	LOSS [training: 0.2447244918209815 | validation: 0.20747128279525034]
	TIME [epoch: 15.3 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23879995124356151		[learning rate: 0.004121]
	Learning Rate: 0.00412098
	LOSS [training: 0.23879995124356151 | validation: 0.19214162372911595]
	TIME [epoch: 15.2 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2381550534605138		[learning rate: 0.0041046]
	Learning Rate: 0.00410458
	LOSS [training: 0.2381550534605138 | validation: 0.18479903051377167]
	TIME [epoch: 15.2 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24002343526626202		[learning rate: 0.0040883]
	Learning Rate: 0.00408826
	LOSS [training: 0.24002343526626202 | validation: 0.18986772505457583]
	TIME [epoch: 15.2 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2297461230992855		[learning rate: 0.004072]
	Learning Rate: 0.004072
	LOSS [training: 0.2297461230992855 | validation: 0.20176811916539142]
	TIME [epoch: 15.3 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22726536107054157		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.22726536107054157 | validation: 0.18866914980709962]
	TIME [epoch: 15.2 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22757969244462414		[learning rate: 0.0040397]
	Learning Rate: 0.00403967
	LOSS [training: 0.22757969244462414 | validation: 0.20038900050840178]
	TIME [epoch: 15.2 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.237165746509185		[learning rate: 0.0040236]
	Learning Rate: 0.00402361
	LOSS [training: 0.237165746509185 | validation: 0.200770328397605]
	TIME [epoch: 15.2 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.237312400842186		[learning rate: 0.0040076]
	Learning Rate: 0.0040076
	LOSS [training: 0.237312400842186 | validation: 0.1908869371811214]
	TIME [epoch: 15.3 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23883390443261854		[learning rate: 0.0039917]
	Learning Rate: 0.00399166
	LOSS [training: 0.23883390443261854 | validation: 0.194752723894968]
	TIME [epoch: 15.2 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23038866960973645		[learning rate: 0.0039758]
	Learning Rate: 0.00397579
	LOSS [training: 0.23038866960973645 | validation: 0.19508378393757134]
	TIME [epoch: 15.2 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23136967311151008		[learning rate: 0.00396]
	Learning Rate: 0.00395997
	LOSS [training: 0.23136967311151008 | validation: 0.19690075148490724]
	TIME [epoch: 15.3 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22827919487788145		[learning rate: 0.0039442]
	Learning Rate: 0.00394422
	LOSS [training: 0.22827919487788145 | validation: 0.1915935360929584]
	TIME [epoch: 15.3 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24035200047766228		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 0.24035200047766228 | validation: 0.19165781382390693]
	TIME [epoch: 15.2 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23439474041314462		[learning rate: 0.0039129]
	Learning Rate: 0.00391291
	LOSS [training: 0.23439474041314462 | validation: 0.1967028815537593]
	TIME [epoch: 15.3 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23980921609844566		[learning rate: 0.0038973]
	Learning Rate: 0.00389735
	LOSS [training: 0.23980921609844566 | validation: 0.1979672943790461]
	TIME [epoch: 15.2 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22691294442161375		[learning rate: 0.0038818]
	Learning Rate: 0.00388185
	LOSS [training: 0.22691294442161375 | validation: 0.20068852986917726]
	TIME [epoch: 15.2 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23537322305134817		[learning rate: 0.0038664]
	Learning Rate: 0.00386641
	LOSS [training: 0.23537322305134817 | validation: 0.19737265183737135]
	TIME [epoch: 15.2 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23252416904612636		[learning rate: 0.003851]
	Learning Rate: 0.00385103
	LOSS [training: 0.23252416904612636 | validation: 0.19719428051028332]
	TIME [epoch: 15.2 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23368090786942253		[learning rate: 0.0038357]
	Learning Rate: 0.00383571
	LOSS [training: 0.23368090786942253 | validation: 0.1875469997723933]
	TIME [epoch: 15.2 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22993418858549328		[learning rate: 0.0038205]
	Learning Rate: 0.00382046
	LOSS [training: 0.22993418858549328 | validation: 0.19899333118811594]
	TIME [epoch: 15.2 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23509386634419224		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 0.23509386634419224 | validation: 0.19153674853756725]
	TIME [epoch: 15.3 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23868323722659643		[learning rate: 0.0037901]
	Learning Rate: 0.00379013
	LOSS [training: 0.23868323722659643 | validation: 0.19260074856936454]
	TIME [epoch: 15.2 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2315198450373049		[learning rate: 0.0037751]
	Learning Rate: 0.00377505
	LOSS [training: 0.2315198450373049 | validation: 0.1993301267566439]
	TIME [epoch: 15.2 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2365550542314177		[learning rate: 0.00376]
	Learning Rate: 0.00376004
	LOSS [training: 0.2365550542314177 | validation: 0.18517716610493096]
	TIME [epoch: 15.2 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22357143257570666		[learning rate: 0.0037451]
	Learning Rate: 0.00374508
	LOSS [training: 0.22357143257570666 | validation: 0.19377252783245016]
	TIME [epoch: 15.3 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2230495186162807		[learning rate: 0.0037302]
	Learning Rate: 0.00373019
	LOSS [training: 0.2230495186162807 | validation: 0.19010702962413556]
	TIME [epoch: 15.2 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23449318371774958		[learning rate: 0.0037154]
	Learning Rate: 0.00371535
	LOSS [training: 0.23449318371774958 | validation: 0.19101299987284795]
	TIME [epoch: 15.2 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2330473180159445		[learning rate: 0.0037006]
	Learning Rate: 0.00370058
	LOSS [training: 0.2330473180159445 | validation: 0.1949841857023531]
	TIME [epoch: 15.3 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23670877567095505		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 0.23670877567095505 | validation: 0.1891918915200177]
	TIME [epoch: 15.2 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23511493049398036		[learning rate: 0.0036712]
	Learning Rate: 0.0036712
	LOSS [training: 0.23511493049398036 | validation: 0.1906926241279649]
	TIME [epoch: 15.3 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23564911920199666		[learning rate: 0.0036566]
	Learning Rate: 0.0036566
	LOSS [training: 0.23564911920199666 | validation: 0.18902166820680338]
	TIME [epoch: 15.2 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22971275668271346		[learning rate: 0.0036421]
	Learning Rate: 0.00364205
	LOSS [training: 0.22971275668271346 | validation: 0.1919860410924669]
	TIME [epoch: 15.2 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23031288062670718		[learning rate: 0.0036276]
	Learning Rate: 0.00362757
	LOSS [training: 0.23031288062670718 | validation: 0.19670800310507783]
	TIME [epoch: 15.3 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24475788802398155		[learning rate: 0.0036131]
	Learning Rate: 0.00361314
	LOSS [training: 0.24475788802398155 | validation: 0.18710112979613808]
	TIME [epoch: 15.3 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2355218600239652		[learning rate: 0.0035988]
	Learning Rate: 0.00359877
	LOSS [training: 0.2355218600239652 | validation: 0.19637008480213483]
	TIME [epoch: 15.2 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2380257576164757		[learning rate: 0.0035845]
	Learning Rate: 0.00358445
	LOSS [training: 0.2380257576164757 | validation: 0.1918538141483627]
	TIME [epoch: 15.3 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23435349433175512		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 0.23435349433175512 | validation: 0.19323695426246512]
	TIME [epoch: 15.3 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2326909816009196		[learning rate: 0.003556]
	Learning Rate: 0.003556
	LOSS [training: 0.2326909816009196 | validation: 0.19351800896913196]
	TIME [epoch: 15.3 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23198249459498665		[learning rate: 0.0035419]
	Learning Rate: 0.00354185
	LOSS [training: 0.23198249459498665 | validation: 0.18344241509727355]
	TIME [epoch: 15.3 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23193065076600444		[learning rate: 0.0035278]
	Learning Rate: 0.00352777
	LOSS [training: 0.23193065076600444 | validation: 0.18903947679044797]
	TIME [epoch: 15.3 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23019491077445553		[learning rate: 0.0035137]
	Learning Rate: 0.00351374
	LOSS [training: 0.23019491077445553 | validation: 0.18985907350427073]
	TIME [epoch: 15.3 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22978693823239082		[learning rate: 0.0034998]
	Learning Rate: 0.00349976
	LOSS [training: 0.22978693823239082 | validation: 0.19576057717452094]
	TIME [epoch: 15.3 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23482827032573056		[learning rate: 0.0034858]
	Learning Rate: 0.00348584
	LOSS [training: 0.23482827032573056 | validation: 0.19497998134471142]
	TIME [epoch: 15.2 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2417352262754958		[learning rate: 0.003472]
	Learning Rate: 0.00347198
	LOSS [training: 0.2417352262754958 | validation: 0.1962035163504107]
	TIME [epoch: 15.3 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23816333257408515		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.23816333257408515 | validation: 0.19110692599256174]
	TIME [epoch: 15.2 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22844453218969762		[learning rate: 0.0034444]
	Learning Rate: 0.00344441
	LOSS [training: 0.22844453218969762 | validation: 0.19143530758761737]
	TIME [epoch: 15.2 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23475505159354298		[learning rate: 0.0034307]
	Learning Rate: 0.00343071
	LOSS [training: 0.23475505159354298 | validation: 0.19312248298153317]
	TIME [epoch: 15.3 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23212325855943833		[learning rate: 0.0034171]
	Learning Rate: 0.00341707
	LOSS [training: 0.23212325855943833 | validation: 0.19281294218430534]
	TIME [epoch: 15.3 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22940171368222254		[learning rate: 0.0034035]
	Learning Rate: 0.00340348
	LOSS [training: 0.22940171368222254 | validation: 0.1966424621901904]
	TIME [epoch: 15.3 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23052571962529667		[learning rate: 0.0033899]
	Learning Rate: 0.00338994
	LOSS [training: 0.23052571962529667 | validation: 0.19278387045492168]
	TIME [epoch: 15.3 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23237458291729704		[learning rate: 0.0033765]
	Learning Rate: 0.00337646
	LOSS [training: 0.23237458291729704 | validation: 0.19606169629622305]
	TIME [epoch: 15.3 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2306243436168533		[learning rate: 0.003363]
	Learning Rate: 0.00336303
	LOSS [training: 0.2306243436168533 | validation: 0.19103202536761055]
	TIME [epoch: 15.3 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23386083337454563		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 0.23386083337454563 | validation: 0.18431912132274852]
	TIME [epoch: 15.3 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23105758691444725		[learning rate: 0.0033363]
	Learning Rate: 0.00333633
	LOSS [training: 0.23105758691444725 | validation: 0.19904709281227972]
	TIME [epoch: 15.3 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22846421583023757		[learning rate: 0.0033231]
	Learning Rate: 0.00332306
	LOSS [training: 0.22846421583023757 | validation: 0.1904620392068766]
	TIME [epoch: 15.3 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.237881010963087		[learning rate: 0.0033098]
	Learning Rate: 0.00330985
	LOSS [training: 0.237881010963087 | validation: 0.20686004839032485]
	TIME [epoch: 15.2 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2337849866470827		[learning rate: 0.0032967]
	Learning Rate: 0.00329668
	LOSS [training: 0.2337849866470827 | validation: 0.18291247442050929]
	TIME [epoch: 15.2 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22676610848154866		[learning rate: 0.0032836]
	Learning Rate: 0.00328357
	LOSS [training: 0.22676610848154866 | validation: 0.1864774289032192]
	TIME [epoch: 15.3 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24069409611443987		[learning rate: 0.0032705]
	Learning Rate: 0.00327051
	LOSS [training: 0.24069409611443987 | validation: 0.1841853004650557]
	TIME [epoch: 15.3 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22550056965962315		[learning rate: 0.0032575]
	Learning Rate: 0.0032575
	LOSS [training: 0.22550056965962315 | validation: 0.18907330707836192]
	TIME [epoch: 15.2 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22923867722578184		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 0.22923867722578184 | validation: 0.19743439725693251]
	TIME [epoch: 15.3 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22671813218220743		[learning rate: 0.0032316]
	Learning Rate: 0.00323164
	LOSS [training: 0.22671813218220743 | validation: 0.19313846757463746]
	TIME [epoch: 15.2 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2400920688722611		[learning rate: 0.0032188]
	Learning Rate: 0.00321879
	LOSS [training: 0.2400920688722611 | validation: 0.18881886931363576]
	TIME [epoch: 15.3 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2266131358877499		[learning rate: 0.003206]
	Learning Rate: 0.00320599
	LOSS [training: 0.2266131358877499 | validation: 0.18908159969754365]
	TIME [epoch: 15.3 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23544658999521786		[learning rate: 0.0031932]
	Learning Rate: 0.00319323
	LOSS [training: 0.23544658999521786 | validation: 0.19275221071745147]
	TIME [epoch: 15.3 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2351281713042719		[learning rate: 0.0031805]
	Learning Rate: 0.00318053
	LOSS [training: 0.2351281713042719 | validation: 0.1983211735610529]
	TIME [epoch: 15.3 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2355391885942706		[learning rate: 0.0031679]
	Learning Rate: 0.00316788
	LOSS [training: 0.2355391885942706 | validation: 0.1906985538231888]
	TIME [epoch: 15.3 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24096096565227532		[learning rate: 0.0031553]
	Learning Rate: 0.00315528
	LOSS [training: 0.24096096565227532 | validation: 0.1904410102561736]
	TIME [epoch: 15.2 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2351345072596996		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 0.2351345072596996 | validation: 0.19768302775948293]
	TIME [epoch: 15.3 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2290072410989597		[learning rate: 0.0031302]
	Learning Rate: 0.00313023
	LOSS [training: 0.2290072410989597 | validation: 0.18595146935198226]
	TIME [epoch: 15.2 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23496689277026672		[learning rate: 0.0031178]
	Learning Rate: 0.00311779
	LOSS [training: 0.23496689277026672 | validation: 0.19297025357185105]
	TIME [epoch: 15.2 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22792621805156876		[learning rate: 0.0031054]
	Learning Rate: 0.00310538
	LOSS [training: 0.22792621805156876 | validation: 0.19137635374019651]
	TIME [epoch: 15.3 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23128851635001954		[learning rate: 0.003093]
	Learning Rate: 0.00309303
	LOSS [training: 0.23128851635001954 | validation: 0.18816904423948366]
	TIME [epoch: 15.2 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22630702099830793		[learning rate: 0.0030807]
	Learning Rate: 0.00308073
	LOSS [training: 0.22630702099830793 | validation: 0.19476224934277214]
	TIME [epoch: 15.2 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23514799342876913		[learning rate: 0.0030685]
	Learning Rate: 0.00306848
	LOSS [training: 0.23514799342876913 | validation: 0.2070290156671291]
	TIME [epoch: 15.3 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23514128822102817		[learning rate: 0.0030563]
	Learning Rate: 0.00305627
	LOSS [training: 0.23514128822102817 | validation: 0.18354480869252643]
	TIME [epoch: 15.2 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23021564732410965		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 0.23021564732410965 | validation: 0.19281931261942203]
	TIME [epoch: 15.3 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23495450929922168		[learning rate: 0.003032]
	Learning Rate: 0.00303201
	LOSS [training: 0.23495450929922168 | validation: 0.18958537399816427]
	TIME [epoch: 15.2 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22962983340631174		[learning rate: 0.00302]
	Learning Rate: 0.00301995
	LOSS [training: 0.22962983340631174 | validation: 0.19263924641740876]
	TIME [epoch: 15.2 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2423376682708222		[learning rate: 0.0030079]
	Learning Rate: 0.00300794
	LOSS [training: 0.2423376682708222 | validation: 0.18739322733453403]
	TIME [epoch: 15.3 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2349812878175583		[learning rate: 0.002996]
	Learning Rate: 0.00299598
	LOSS [training: 0.2349812878175583 | validation: 0.21032224653981055]
	TIME [epoch: 15.3 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2273181179685183		[learning rate: 0.0029841]
	Learning Rate: 0.00298406
	LOSS [training: 0.2273181179685183 | validation: 0.19555022133115352]
	TIME [epoch: 15.2 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23055629906453387		[learning rate: 0.0029722]
	Learning Rate: 0.00297219
	LOSS [training: 0.23055629906453387 | validation: 0.18990943684082207]
	TIME [epoch: 15.2 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23096530391731923		[learning rate: 0.0029604]
	Learning Rate: 0.00296037
	LOSS [training: 0.23096530391731923 | validation: 0.19418659157207968]
	TIME [epoch: 15.2 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.231783681038756		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.231783681038756 | validation: 0.19014028890497375]
	TIME [epoch: 15.2 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22428456207219558		[learning rate: 0.0029369]
	Learning Rate: 0.00293687
	LOSS [training: 0.22428456207219558 | validation: 0.1939974647887293]
	TIME [epoch: 15.2 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2326992843954587		[learning rate: 0.0029252]
	Learning Rate: 0.00292519
	LOSS [training: 0.2326992843954587 | validation: 0.18975553328717756]
	TIME [epoch: 15.2 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23434851689460348		[learning rate: 0.0029136]
	Learning Rate: 0.00291355
	LOSS [training: 0.23434851689460348 | validation: 0.19605186245286127]
	TIME [epoch: 15.3 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23204820200201162		[learning rate: 0.002902]
	Learning Rate: 0.00290197
	LOSS [training: 0.23204820200201162 | validation: 0.19152122050018378]
	TIME [epoch: 15.3 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2173341710822216		[learning rate: 0.0028904]
	Learning Rate: 0.00289042
	LOSS [training: 0.2173341710822216 | validation: 0.1878162350340366]
	TIME [epoch: 15.2 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22899250675310137		[learning rate: 0.0028789]
	Learning Rate: 0.00287893
	LOSS [training: 0.22899250675310137 | validation: 0.19016931089287398]
	TIME [epoch: 15.3 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23005231749508537		[learning rate: 0.0028675]
	Learning Rate: 0.00286748
	LOSS [training: 0.23005231749508537 | validation: 0.19106408785715262]
	TIME [epoch: 15.2 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2314676224132717		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 0.2314676224132717 | validation: 0.19240328335973556]
	TIME [epoch: 15.2 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22733623629761254		[learning rate: 0.0028447]
	Learning Rate: 0.00284471
	LOSS [training: 0.22733623629761254 | validation: 0.1918813543307801]
	TIME [epoch: 15.3 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2290643374692673		[learning rate: 0.0028334]
	Learning Rate: 0.0028334
	LOSS [training: 0.2290643374692673 | validation: 0.18906178567398696]
	TIME [epoch: 15.2 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22717495052703818		[learning rate: 0.0028221]
	Learning Rate: 0.00282213
	LOSS [training: 0.22717495052703818 | validation: 0.18359128752394713]
	TIME [epoch: 15.3 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2315306104555742		[learning rate: 0.0028109]
	Learning Rate: 0.00281091
	LOSS [training: 0.2315306104555742 | validation: 0.1895099411525613]
	TIME [epoch: 15.3 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23366445441788583		[learning rate: 0.0027997]
	Learning Rate: 0.00279973
	LOSS [training: 0.23366445441788583 | validation: 0.19313133575870103]
	TIME [epoch: 15.2 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22305931595307024		[learning rate: 0.0027886]
	Learning Rate: 0.00278859
	LOSS [training: 0.22305931595307024 | validation: 0.18825079374011383]
	TIME [epoch: 15.2 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23331850855646957		[learning rate: 0.0027775]
	Learning Rate: 0.0027775
	LOSS [training: 0.23331850855646957 | validation: 0.18869601276344833]
	TIME [epoch: 15.3 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23639311757024498		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 0.23639311757024498 | validation: 0.18225534104115848]
	TIME [epoch: 15.3 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v14_20240716_142610/states/model_facs_v2_dec1b_2dpca_v14_367.pth
	Model improved!!!
EPOCH 368/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22199372881075602		[learning rate: 0.0027554]
	Learning Rate: 0.00275545
	LOSS [training: 0.22199372881075602 | validation: 0.19011152358035793]
	TIME [epoch: 15.3 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23359320536862438		[learning rate: 0.0027445]
	Learning Rate: 0.00274449
	LOSS [training: 0.23359320536862438 | validation: 0.18645439277210568]
	TIME [epoch: 15.2 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23107836499353882		[learning rate: 0.0027336]
	Learning Rate: 0.00273357
	LOSS [training: 0.23107836499353882 | validation: 0.1856949857481272]
	TIME [epoch: 15.2 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2313522849372292		[learning rate: 0.0027227]
	Learning Rate: 0.0027227
	LOSS [training: 0.2313522849372292 | validation: 0.1886495863878662]
	TIME [epoch: 15.2 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2237569452400393		[learning rate: 0.0027119]
	Learning Rate: 0.00271187
	LOSS [training: 0.2237569452400393 | validation: 0.20198028631572645]
	TIME [epoch: 15.2 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23279181399953675		[learning rate: 0.0027011]
	Learning Rate: 0.00270109
	LOSS [training: 0.23279181399953675 | validation: 0.188854267072533]
	TIME [epoch: 15.2 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24051050713763208		[learning rate: 0.0026903]
	Learning Rate: 0.00269034
	LOSS [training: 0.24051050713763208 | validation: 0.20483119369568126]
	TIME [epoch: 15.3 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23482713919738268		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 0.23482713919738268 | validation: 0.19259959191013745]
	TIME [epoch: 15.3 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2300292595210714		[learning rate: 0.002669]
	Learning Rate: 0.00266899
	LOSS [training: 0.2300292595210714 | validation: 0.19431621754355644]
	TIME [epoch: 15.2 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2335093475330492		[learning rate: 0.0026584]
	Learning Rate: 0.00265837
	LOSS [training: 0.2335093475330492 | validation: 0.18359340001037938]
	TIME [epoch: 15.3 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23233847258968188		[learning rate: 0.0026478]
	Learning Rate: 0.0026478
	LOSS [training: 0.23233847258968188 | validation: 0.18517307435996988]
	TIME [epoch: 15.2 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2283557531594809		[learning rate: 0.0026373]
	Learning Rate: 0.00263727
	LOSS [training: 0.2283557531594809 | validation: 0.18910752176297527]
	TIME [epoch: 15.3 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2313544672985707		[learning rate: 0.0026268]
	Learning Rate: 0.00262678
	LOSS [training: 0.2313544672985707 | validation: 0.19789529685608717]
	TIME [epoch: 15.2 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23646461665093088		[learning rate: 0.0026163]
	Learning Rate: 0.00261633
	LOSS [training: 0.23646461665093088 | validation: 0.18193056264715587]
	TIME [epoch: 15.2 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v14_20240716_142610/states/model_facs_v2_dec1b_2dpca_v14_381.pth
	Model improved!!!
EPOCH 382/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2370745712406045		[learning rate: 0.0026059]
	Learning Rate: 0.00260592
	LOSS [training: 0.2370745712406045 | validation: 0.19413972243461633]
	TIME [epoch: 15.3 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23011758944495295		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 0.23011758944495295 | validation: 0.20432310149321187]
	TIME [epoch: 15.3 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23171547568855633		[learning rate: 0.0025852]
	Learning Rate: 0.00258523
	LOSS [training: 0.23171547568855633 | validation: 0.1937378530573901]
	TIME [epoch: 15.3 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22829518880642474		[learning rate: 0.002575]
	Learning Rate: 0.00257495
	LOSS [training: 0.22829518880642474 | validation: 0.1918154835502037]
	TIME [epoch: 15.3 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22874200827148183		[learning rate: 0.0025647]
	Learning Rate: 0.00256471
	LOSS [training: 0.22874200827148183 | validation: 0.19105940393894139]
	TIME [epoch: 15.3 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23420621163495983		[learning rate: 0.0025545]
	Learning Rate: 0.00255451
	LOSS [training: 0.23420621163495983 | validation: 0.18717303523107623]
	TIME [epoch: 15.3 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.227292853443031		[learning rate: 0.0025444]
	Learning Rate: 0.00254435
	LOSS [training: 0.227292853443031 | validation: 0.1948154799444178]
	TIME [epoch: 15.3 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2261979644661867		[learning rate: 0.0025342]
	Learning Rate: 0.00253423
	LOSS [training: 0.2261979644661867 | validation: 0.18900494761777714]
	TIME [epoch: 15.3 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23115622361249338		[learning rate: 0.0025242]
	Learning Rate: 0.00252415
	LOSS [training: 0.23115622361249338 | validation: 0.18823791928772282]
	TIME [epoch: 15.3 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23575642338814706		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.23575642338814706 | validation: 0.19207525775878692]
	TIME [epoch: 15.3 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23437911545603393		[learning rate: 0.0025041]
	Learning Rate: 0.00250411
	LOSS [training: 0.23437911545603393 | validation: 0.18560187464292469]
	TIME [epoch: 15.3 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23260904686513395		[learning rate: 0.0024942]
	Learning Rate: 0.00249415
	LOSS [training: 0.23260904686513395 | validation: 0.19391384268554837]
	TIME [epoch: 15.3 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2266223362507052		[learning rate: 0.0024842]
	Learning Rate: 0.00248423
	LOSS [training: 0.2266223362507052 | validation: 0.18650607211425901]
	TIME [epoch: 15.3 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22905723645559967		[learning rate: 0.0024744]
	Learning Rate: 0.00247435
	LOSS [training: 0.22905723645559967 | validation: 0.18998155630477814]
	TIME [epoch: 15.3 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2245577075990467		[learning rate: 0.0024645]
	Learning Rate: 0.00246451
	LOSS [training: 0.2245577075990467 | validation: 0.19283675177989307]
	TIME [epoch: 15.3 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22417748296294424		[learning rate: 0.0024547]
	Learning Rate: 0.00245471
	LOSS [training: 0.22417748296294424 | validation: 0.1971428189404681]
	TIME [epoch: 15.3 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23084596790852802		[learning rate: 0.0024449]
	Learning Rate: 0.00244495
	LOSS [training: 0.23084596790852802 | validation: 0.18213558269136357]
	TIME [epoch: 15.3 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23013844084914664		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 0.23013844084914664 | validation: 0.19225876683510876]
	TIME [epoch: 15.3 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22217236100306403		[learning rate: 0.0024255]
	Learning Rate: 0.00242554
	LOSS [training: 0.22217236100306403 | validation: 0.18817745621302215]
	TIME [epoch: 15.3 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2278951395492312		[learning rate: 0.0024159]
	Learning Rate: 0.00241589
	LOSS [training: 0.2278951395492312 | validation: 0.17950738646696968]
	TIME [epoch: 15.3 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v14_20240716_142610/states/model_facs_v2_dec1b_2dpca_v14_401.pth
	Model improved!!!
EPOCH 402/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23371433591723273		[learning rate: 0.0024063]
	Learning Rate: 0.00240628
	LOSS [training: 0.23371433591723273 | validation: 0.19117217960978916]
	TIME [epoch: 15.3 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2333760535108181		[learning rate: 0.0023967]
	Learning Rate: 0.00239671
	LOSS [training: 0.2333760535108181 | validation: 0.1878602345291113]
	TIME [epoch: 15.3 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2282219817066654		[learning rate: 0.0023872]
	Learning Rate: 0.00238718
	LOSS [training: 0.2282219817066654 | validation: 0.18946596693121573]
	TIME [epoch: 15.3 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23306884183521218		[learning rate: 0.0023777]
	Learning Rate: 0.00237768
	LOSS [training: 0.23306884183521218 | validation: 0.19789520576066894]
	TIME [epoch: 15.3 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2305269869279402		[learning rate: 0.0023682]
	Learning Rate: 0.00236823
	LOSS [training: 0.2305269869279402 | validation: 0.18214380120098675]
	TIME [epoch: 15.3 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2328639633819854		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 0.2328639633819854 | validation: 0.1902853329983219]
	TIME [epoch: 15.3 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22896777115556746		[learning rate: 0.0023494]
	Learning Rate: 0.00234942
	LOSS [training: 0.22896777115556746 | validation: 0.19429847142794626]
	TIME [epoch: 15.3 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22452561646429167		[learning rate: 0.0023401]
	Learning Rate: 0.00234008
	LOSS [training: 0.22452561646429167 | validation: 0.19253319846437494]
	TIME [epoch: 15.3 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22651290020629114		[learning rate: 0.0023308]
	Learning Rate: 0.00233077
	LOSS [training: 0.22651290020629114 | validation: 0.1904995965400707]
	TIME [epoch: 15.3 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23442648446059453		[learning rate: 0.0023215]
	Learning Rate: 0.0023215
	LOSS [training: 0.23442648446059453 | validation: 0.19243884377132]
	TIME [epoch: 15.3 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.221336951391965		[learning rate: 0.0023123]
	Learning Rate: 0.00231227
	LOSS [training: 0.221336951391965 | validation: 0.1893278136784698]
	TIME [epoch: 15.3 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2308545002901518		[learning rate: 0.0023031]
	Learning Rate: 0.00230307
	LOSS [training: 0.2308545002901518 | validation: 0.18452589077894638]
	TIME [epoch: 15.3 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22135353044291328		[learning rate: 0.0022939]
	Learning Rate: 0.00229391
	LOSS [training: 0.22135353044291328 | validation: 0.20084984788060645]
	TIME [epoch: 15.3 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23167777251326926		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 0.23167777251326926 | validation: 0.19234494257172624]
	TIME [epoch: 15.3 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22525139796897944		[learning rate: 0.0022757]
	Learning Rate: 0.0022757
	LOSS [training: 0.22525139796897944 | validation: 0.19297072566347562]
	TIME [epoch: 15.3 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2293379486035894		[learning rate: 0.0022667]
	Learning Rate: 0.00226665
	LOSS [training: 0.2293379486035894 | validation: 0.18457047239658309]
	TIME [epoch: 15.3 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23303453113784445		[learning rate: 0.0022576]
	Learning Rate: 0.00225764
	LOSS [training: 0.23303453113784445 | validation: 0.1934799477465777]
	TIME [epoch: 15.3 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2239914300079834		[learning rate: 0.0022487]
	Learning Rate: 0.00224866
	LOSS [training: 0.2239914300079834 | validation: 0.1953503475796824]
	TIME [epoch: 15.3 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23356411987271683		[learning rate: 0.0022397]
	Learning Rate: 0.00223971
	LOSS [training: 0.23356411987271683 | validation: 0.18349827654501322]
	TIME [epoch: 15.3 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22929597190359224		[learning rate: 0.0022308]
	Learning Rate: 0.0022308
	LOSS [training: 0.22929597190359224 | validation: 0.19057169614778896]
	TIME [epoch: 15.3 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22728163632484455		[learning rate: 0.0022219]
	Learning Rate: 0.00222193
	LOSS [training: 0.22728163632484455 | validation: 0.1896913330114526]
	TIME [epoch: 15.3 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2355217834070773		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.2355217834070773 | validation: 0.18861446879736365]
	TIME [epoch: 15.3 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22822297240478276		[learning rate: 0.0022043]
	Learning Rate: 0.00220429
	LOSS [training: 0.22822297240478276 | validation: 0.18641036415288115]
	TIME [epoch: 15.3 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23292042574957858		[learning rate: 0.0021955]
	Learning Rate: 0.00219553
	LOSS [training: 0.23292042574957858 | validation: 0.18831171601634855]
	TIME [epoch: 15.3 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2272189996620135		[learning rate: 0.0021868]
	Learning Rate: 0.00218679
	LOSS [training: 0.2272189996620135 | validation: 0.19502975269839537]
	TIME [epoch: 15.3 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22918863382058946		[learning rate: 0.0021781]
	Learning Rate: 0.0021781
	LOSS [training: 0.22918863382058946 | validation: 0.19192350337720165]
	TIME [epoch: 15.3 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2303497703780542		[learning rate: 0.0021694]
	Learning Rate: 0.00216943
	LOSS [training: 0.2303497703780542 | validation: 0.19001728890054298]
	TIME [epoch: 15.3 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22661853396800927		[learning rate: 0.0021608]
	Learning Rate: 0.0021608
	LOSS [training: 0.22661853396800927 | validation: 0.19647754952016855]
	TIME [epoch: 15.3 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23353393480601092		[learning rate: 0.0021522]
	Learning Rate: 0.00215221
	LOSS [training: 0.23353393480601092 | validation: 0.18581727243385376]
	TIME [epoch: 15.2 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23386366567414518		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.23386366567414518 | validation: 0.19250358421772565]
	TIME [epoch: 15.3 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23229674487440366		[learning rate: 0.0021351]
	Learning Rate: 0.00213512
	LOSS [training: 0.23229674487440366 | validation: 0.18347715040203283]
	TIME [epoch: 15.3 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22790765719146583		[learning rate: 0.0021266]
	Learning Rate: 0.00212663
	LOSS [training: 0.22790765719146583 | validation: 0.19562913410883292]
	TIME [epoch: 15.3 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22545987857162514		[learning rate: 0.0021182]
	Learning Rate: 0.00211817
	LOSS [training: 0.22545987857162514 | validation: 0.18375413709076643]
	TIME [epoch: 15.3 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22506055580059303		[learning rate: 0.0021097]
	Learning Rate: 0.00210975
	LOSS [training: 0.22506055580059303 | validation: 0.18412908837808264]
	TIME [epoch: 15.3 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2312882690383173		[learning rate: 0.0021014]
	Learning Rate: 0.00210136
	LOSS [training: 0.2312882690383173 | validation: 0.1870070523066951]
	TIME [epoch: 15.2 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22488114846111085		[learning rate: 0.002093]
	Learning Rate: 0.002093
	LOSS [training: 0.22488114846111085 | validation: 0.19051596091583217]
	TIME [epoch: 15.3 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.232197129260766		[learning rate: 0.0020847]
	Learning Rate: 0.00208468
	LOSS [training: 0.232197129260766 | validation: 0.18587187294689675]
	TIME [epoch: 15.3 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23008135172064584		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.23008135172064584 | validation: 0.193674065872124]
	TIME [epoch: 15.3 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22530231853864732		[learning rate: 0.0020681]
	Learning Rate: 0.00206813
	LOSS [training: 0.22530231853864732 | validation: 0.18706044037133587]
	TIME [epoch: 15.3 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22881958350930004		[learning rate: 0.0020599]
	Learning Rate: 0.0020599
	LOSS [training: 0.22881958350930004 | validation: 0.193784583354074]
	TIME [epoch: 15.3 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22535550389327755		[learning rate: 0.0020517]
	Learning Rate: 0.00205171
	LOSS [training: 0.22535550389327755 | validation: 0.19499407158206772]
	TIME [epoch: 15.2 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2301932865847857		[learning rate: 0.0020435]
	Learning Rate: 0.00204355
	LOSS [training: 0.2301932865847857 | validation: 0.1904768592752015]
	TIME [epoch: 15.3 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2358672606078724		[learning rate: 0.0020354]
	Learning Rate: 0.00203542
	LOSS [training: 0.2358672606078724 | validation: 0.1846518187382708]
	TIME [epoch: 15.3 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23245187454460814		[learning rate: 0.0020273]
	Learning Rate: 0.00202732
	LOSS [training: 0.23245187454460814 | validation: 0.18886137216480509]
	TIME [epoch: 15.4 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2337787404027728		[learning rate: 0.0020193]
	Learning Rate: 0.00201926
	LOSS [training: 0.2337787404027728 | validation: 0.19316840281238973]
	TIME [epoch: 15.3 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2250749423200131		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 0.2250749423200131 | validation: 0.18896153100342106]
	TIME [epoch: 15.3 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2377088539060145		[learning rate: 0.0020032]
	Learning Rate: 0.00200323
	LOSS [training: 0.2377088539060145 | validation: 0.19527783335597107]
	TIME [epoch: 15.3 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23745268277206863		[learning rate: 0.0019953]
	Learning Rate: 0.00199526
	LOSS [training: 0.23745268277206863 | validation: 0.19518344852379796]
	TIME [epoch: 15.3 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2254604363110991		[learning rate: 0.0019873]
	Learning Rate: 0.00198733
	LOSS [training: 0.2254604363110991 | validation: 0.18381944521071633]
	TIME [epoch: 15.3 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22762591870687895		[learning rate: 0.0019794]
	Learning Rate: 0.00197942
	LOSS [training: 0.22762591870687895 | validation: 0.18570149152442766]
	TIME [epoch: 15.3 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2335739982856794		[learning rate: 0.0019715]
	Learning Rate: 0.00197155
	LOSS [training: 0.2335739982856794 | validation: 0.18815173000887037]
	TIME [epoch: 15.3 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22880046994949435		[learning rate: 0.0019637]
	Learning Rate: 0.00196371
	LOSS [training: 0.22880046994949435 | validation: 0.1861309185628707]
	TIME [epoch: 15.3 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23370114793840566		[learning rate: 0.0019559]
	Learning Rate: 0.0019559
	LOSS [training: 0.23370114793840566 | validation: 0.18606856905810615]
	TIME [epoch: 15.3 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23167672505661516		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 0.23167672505661516 | validation: 0.18238777307279205]
	TIME [epoch: 15.3 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22540068834115048		[learning rate: 0.0019404]
	Learning Rate: 0.00194037
	LOSS [training: 0.22540068834115048 | validation: 0.18294041156319096]
	TIME [epoch: 15.3 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2291573123617002		[learning rate: 0.0019327]
	Learning Rate: 0.00193265
	LOSS [training: 0.2291573123617002 | validation: 0.19207425960541652]
	TIME [epoch: 15.2 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2292420789448316		[learning rate: 0.001925]
	Learning Rate: 0.00192497
	LOSS [training: 0.2292420789448316 | validation: 0.1828113538624497]
	TIME [epoch: 15.3 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22895978335899125		[learning rate: 0.0019173]
	Learning Rate: 0.00191731
	LOSS [training: 0.22895978335899125 | validation: 0.18296876989370364]
	TIME [epoch: 15.3 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23408937454824072		[learning rate: 0.0019097]
	Learning Rate: 0.00190968
	LOSS [training: 0.23408937454824072 | validation: 0.1903437373907571]
	TIME [epoch: 15.2 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23059289821108514		[learning rate: 0.0019021]
	Learning Rate: 0.00190209
	LOSS [training: 0.23059289821108514 | validation: 0.18572096017427506]
	TIME [epoch: 15.2 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22470137816302374		[learning rate: 0.0018945]
	Learning Rate: 0.00189452
	LOSS [training: 0.22470137816302374 | validation: 0.19281667224494947]
	TIME [epoch: 15.3 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2344320299596236		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.2344320299596236 | validation: 0.1864207619144611]
	TIME [epoch: 15.2 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2384158081151477		[learning rate: 0.0018795]
	Learning Rate: 0.00187948
	LOSS [training: 0.2384158081151477 | validation: 0.19451553888453932]
	TIME [epoch: 15.3 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2338202649799982		[learning rate: 0.001872]
	Learning Rate: 0.00187201
	LOSS [training: 0.2338202649799982 | validation: 0.19415556672156295]
	TIME [epoch: 15.3 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22449611997060137		[learning rate: 0.0018646]
	Learning Rate: 0.00186456
	LOSS [training: 0.22449611997060137 | validation: 0.18929420839469566]
	TIME [epoch: 15.4 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22894712714447354		[learning rate: 0.0018571]
	Learning Rate: 0.00185715
	LOSS [training: 0.22894712714447354 | validation: 0.19795745419506489]
	TIME [epoch: 15.3 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2355669074329965		[learning rate: 0.0018498]
	Learning Rate: 0.00184976
	LOSS [training: 0.2355669074329965 | validation: 0.19119478939540321]
	TIME [epoch: 15.3 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2252985555295911		[learning rate: 0.0018424]
	Learning Rate: 0.0018424
	LOSS [training: 0.2252985555295911 | validation: 0.18790258187793094]
	TIME [epoch: 15.3 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22251463098659466		[learning rate: 0.0018351]
	Learning Rate: 0.00183508
	LOSS [training: 0.22251463098659466 | validation: 0.1898676429426796]
	TIME [epoch: 15.3 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2246980612753868		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.2246980612753868 | validation: 0.1862096837807145]
	TIME [epoch: 15.3 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23332030992345779		[learning rate: 0.0018205]
	Learning Rate: 0.00182051
	LOSS [training: 0.23332030992345779 | validation: 0.18944528701863086]
	TIME [epoch: 15.3 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2343541725647487		[learning rate: 0.0018133]
	Learning Rate: 0.00181327
	LOSS [training: 0.2343541725647487 | validation: 0.19115619771485368]
	TIME [epoch: 15.3 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23028213825977023		[learning rate: 0.0018061]
	Learning Rate: 0.00180605
	LOSS [training: 0.23028213825977023 | validation: 0.19549458300146952]
	TIME [epoch: 15.3 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2364097100008794		[learning rate: 0.0017989]
	Learning Rate: 0.00179887
	LOSS [training: 0.2364097100008794 | validation: 0.18796388023630367]
	TIME [epoch: 15.3 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22783202505486055		[learning rate: 0.0017917]
	Learning Rate: 0.00179172
	LOSS [training: 0.22783202505486055 | validation: 0.18788214100699666]
	TIME [epoch: 15.3 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22892732779748576		[learning rate: 0.0017846]
	Learning Rate: 0.00178459
	LOSS [training: 0.22892732779748576 | validation: 0.18894646129848733]
	TIME [epoch: 15.2 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2319868376375424		[learning rate: 0.0017775]
	Learning Rate: 0.00177749
	LOSS [training: 0.2319868376375424 | validation: 0.18345495254145233]
	TIME [epoch: 15.3 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23467018325227482		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.23467018325227482 | validation: 0.19000574903835413]
	TIME [epoch: 15.3 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2276874012675384		[learning rate: 0.0017634]
	Learning Rate: 0.00176338
	LOSS [training: 0.2276874012675384 | validation: 0.18964311421733487]
	TIME [epoch: 15.3 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2310153862992506		[learning rate: 0.0017564]
	Learning Rate: 0.00175637
	LOSS [training: 0.2310153862992506 | validation: 0.18092082276344618]
	TIME [epoch: 15.3 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.21734621434883986		[learning rate: 0.0017494]
	Learning Rate: 0.00174938
	LOSS [training: 0.21734621434883986 | validation: 0.1843153541196144]
	TIME [epoch: 15.3 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2274061802015352		[learning rate: 0.0017424]
	Learning Rate: 0.00174242
	LOSS [training: 0.2274061802015352 | validation: 0.19675276209873335]
	TIME [epoch: 15.3 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23469822093890447		[learning rate: 0.0017355]
	Learning Rate: 0.00173549
	LOSS [training: 0.23469822093890447 | validation: 0.19070532266820645]
	TIME [epoch: 15.3 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22525786206081072		[learning rate: 0.0017286]
	Learning Rate: 0.00172859
	LOSS [training: 0.22525786206081072 | validation: 0.18576792889846028]
	TIME [epoch: 15.3 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22897711920303537		[learning rate: 0.0017217]
	Learning Rate: 0.00172172
	LOSS [training: 0.22897711920303537 | validation: 0.2027081962943679]
	TIME [epoch: 15.3 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22903269513694857		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 0.22903269513694857 | validation: 0.19033668670307508]
	TIME [epoch: 15.3 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2227420926126148		[learning rate: 0.001708]
	Learning Rate: 0.00170805
	LOSS [training: 0.2227420926126148 | validation: 0.18733465476358874]
	TIME [epoch: 15.3 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23076676137150928		[learning rate: 0.0017013]
	Learning Rate: 0.00170125
	LOSS [training: 0.23076676137150928 | validation: 0.185794297953394]
	TIME [epoch: 15.2 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2315025796628084		[learning rate: 0.0016945]
	Learning Rate: 0.00169449
	LOSS [training: 0.2315025796628084 | validation: 0.18163934607471555]
	TIME [epoch: 15.3 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2259368330856985		[learning rate: 0.0016877]
	Learning Rate: 0.00168775
	LOSS [training: 0.2259368330856985 | validation: 0.18844037634414385]
	TIME [epoch: 15.2 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22943783131519396		[learning rate: 0.001681]
	Learning Rate: 0.00168104
	LOSS [training: 0.22943783131519396 | validation: 0.19131250775269518]
	TIME [epoch: 15.3 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2289982853300471		[learning rate: 0.0016743]
	Learning Rate: 0.00167435
	LOSS [training: 0.2289982853300471 | validation: 0.180966189422811]
	TIME [epoch: 15.3 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23059476603662032		[learning rate: 0.0016677]
	Learning Rate: 0.00166769
	LOSS [training: 0.23059476603662032 | validation: 0.19081824739947828]
	TIME [epoch: 15.3 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22700310419657155		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.22700310419657155 | validation: 0.18910179365857843]
	TIME [epoch: 15.3 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2316730243239254		[learning rate: 0.0016545]
	Learning Rate: 0.00165445
	LOSS [training: 0.2316730243239254 | validation: 0.18780367778893492]
	TIME [epoch: 15.3 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2387704057911709		[learning rate: 0.0016479]
	Learning Rate: 0.00164787
	LOSS [training: 0.2387704057911709 | validation: 0.20010786198348446]
	TIME [epoch: 15.3 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2315200072434384		[learning rate: 0.0016413]
	Learning Rate: 0.00164132
	LOSS [training: 0.2315200072434384 | validation: 0.18670846048953807]
	TIME [epoch: 15.3 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22845449079186933		[learning rate: 0.0016348]
	Learning Rate: 0.00163479
	LOSS [training: 0.22845449079186933 | validation: 0.19514035510587663]
	TIME [epoch: 15.2 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2257779299483334		[learning rate: 0.0016283]
	Learning Rate: 0.00162829
	LOSS [training: 0.2257779299483334 | validation: 0.18794858406120302]
	TIME [epoch: 15.3 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23437408309487717		[learning rate: 0.0016218]
	Learning Rate: 0.00162181
	LOSS [training: 0.23437408309487717 | validation: 0.1825525481738824]
	TIME [epoch: 54.1 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23076844453684917		[learning rate: 0.0016154]
	Learning Rate: 0.00161536
	LOSS [training: 0.23076844453684917 | validation: 0.18800627360074912]
	TIME [epoch: 33.4 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2311541418557183		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 0.2311541418557183 | validation: 0.18831112622956647]
	TIME [epoch: 33.3 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23472267360874166		[learning rate: 0.0016025]
	Learning Rate: 0.00160254
	LOSS [training: 0.23472267360874166 | validation: 0.19290669502575514]
	TIME [epoch: 33.3 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23143947011160262		[learning rate: 0.0015962]
	Learning Rate: 0.00159616
	LOSS [training: 0.23143947011160262 | validation: 0.18578489015832786]
	TIME [epoch: 33.3 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22804025399701894		[learning rate: 0.0015898]
	Learning Rate: 0.00158981
	LOSS [training: 0.22804025399701894 | validation: 0.18577528209232944]
	TIME [epoch: 33.3 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2237185542010061		[learning rate: 0.0015835]
	Learning Rate: 0.00158349
	LOSS [training: 0.2237185542010061 | validation: 0.18879694678990086]
	TIME [epoch: 33.3 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2313632626068624		[learning rate: 0.0015772]
	Learning Rate: 0.00157719
	LOSS [training: 0.2313632626068624 | validation: 0.1844856731860272]
	TIME [epoch: 33.3 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22636213481970524		[learning rate: 0.0015709]
	Learning Rate: 0.00157092
	LOSS [training: 0.22636213481970524 | validation: 0.1871983268827806]
	TIME [epoch: 33.3 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22672588554068934		[learning rate: 0.0015647]
	Learning Rate: 0.00156467
	LOSS [training: 0.22672588554068934 | validation: 0.19176009912743203]
	TIME [epoch: 33.4 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2282317727916959		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.2282317727916959 | validation: 0.19063306672888694]
	TIME [epoch: 33.4 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23452548861882894		[learning rate: 0.0015522]
	Learning Rate: 0.00155225
	LOSS [training: 0.23452548861882894 | validation: 0.18959489816162486]
	TIME [epoch: 33.3 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23224651513326527		[learning rate: 0.0015461]
	Learning Rate: 0.00154608
	LOSS [training: 0.23224651513326527 | validation: 0.19395860174988178]
	TIME [epoch: 33.4 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2288703169244035		[learning rate: 0.0015399]
	Learning Rate: 0.00153993
	LOSS [training: 0.2288703169244035 | validation: 0.1956078303379823]
	TIME [epoch: 33.3 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23000724108346393		[learning rate: 0.0015338]
	Learning Rate: 0.0015338
	LOSS [training: 0.23000724108346393 | validation: 0.19742036151998413]
	TIME [epoch: 33.3 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22342734819952476		[learning rate: 0.0015277]
	Learning Rate: 0.0015277
	LOSS [training: 0.22342734819952476 | validation: 0.1795093551034279]
	TIME [epoch: 33.3 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24100347554154766		[learning rate: 0.0015216]
	Learning Rate: 0.00152163
	LOSS [training: 0.24100347554154766 | validation: 0.1945821169320982]
	TIME [epoch: 33.3 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23248013412372293		[learning rate: 0.0015156]
	Learning Rate: 0.00151557
	LOSS [training: 0.23248013412372293 | validation: 0.1841056805436723]
	TIME [epoch: 33.3 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22553039145790693		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.22553039145790693 | validation: 0.189676332598758]
	TIME [epoch: 33.3 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23844273782993486		[learning rate: 0.0015035]
	Learning Rate: 0.00150354
	LOSS [training: 0.23844273782993486 | validation: 0.18727213430451475]
	TIME [epoch: 33.3 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2303873724807606		[learning rate: 0.0014976]
	Learning Rate: 0.00149756
	LOSS [training: 0.2303873724807606 | validation: 0.18996051346736947]
	TIME [epoch: 33.3 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22875171777705733		[learning rate: 0.0014916]
	Learning Rate: 0.00149161
	LOSS [training: 0.22875171777705733 | validation: 0.18425794807632437]
	TIME [epoch: 33.3 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2305092438102232		[learning rate: 0.0014857]
	Learning Rate: 0.00148567
	LOSS [training: 0.2305092438102232 | validation: 0.1863013417987304]
	TIME [epoch: 33.3 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23133800826210493		[learning rate: 0.0014798]
	Learning Rate: 0.00147976
	LOSS [training: 0.23133800826210493 | validation: 0.19032689793228638]
	TIME [epoch: 33.3 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2263382688060672		[learning rate: 0.0014739]
	Learning Rate: 0.00147388
	LOSS [training: 0.2263382688060672 | validation: 0.19238679705650216]
	TIME [epoch: 33.4 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23007583481168567		[learning rate: 0.001468]
	Learning Rate: 0.00146802
	LOSS [training: 0.23007583481168567 | validation: 0.18397778785502855]
	TIME [epoch: 33.3 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23266308813884531		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.23266308813884531 | validation: 0.194160910651383]
	TIME [epoch: 33.3 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22671797599052937		[learning rate: 0.0014564]
	Learning Rate: 0.00145636
	LOSS [training: 0.22671797599052937 | validation: 0.18519084656704807]
	TIME [epoch: 33.4 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2342093393805801		[learning rate: 0.0014506]
	Learning Rate: 0.00145057
	LOSS [training: 0.2342093393805801 | validation: 0.18862092297625951]
	TIME [epoch: 33.3 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.21839985237818638		[learning rate: 0.0014448]
	Learning Rate: 0.0014448
	LOSS [training: 0.21839985237818638 | validation: 0.1895306382483999]
	TIME [epoch: 33.3 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2263038644106397		[learning rate: 0.0014391]
	Learning Rate: 0.00143905
	LOSS [training: 0.2263038644106397 | validation: 0.18805717538110375]
	TIME [epoch: 33.3 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2366967966308053		[learning rate: 0.0014333]
	Learning Rate: 0.00143333
	LOSS [training: 0.2366967966308053 | validation: 0.18817256015979777]
	TIME [epoch: 33.3 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22307966600538526		[learning rate: 0.0014276]
	Learning Rate: 0.00142763
	LOSS [training: 0.22307966600538526 | validation: 0.18738891001353775]
	TIME [epoch: 33.3 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23002668710180652		[learning rate: 0.001422]
	Learning Rate: 0.00142195
	LOSS [training: 0.23002668710180652 | validation: 0.19910052542799078]
	TIME [epoch: 33.3 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2321252633301062		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.2321252633301062 | validation: 0.18519513278754834]
	TIME [epoch: 33.3 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22853657752006948		[learning rate: 0.0014107]
	Learning Rate: 0.00141066
	LOSS [training: 0.22853657752006948 | validation: 0.18330381247092778]
	TIME [epoch: 33.3 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2219177209683497		[learning rate: 0.0014051]
	Learning Rate: 0.00140505
	LOSS [training: 0.2219177209683497 | validation: 0.18492162247506955]
	TIME [epoch: 33.3 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22727724110183523		[learning rate: 0.0013995]
	Learning Rate: 0.00139946
	LOSS [training: 0.22727724110183523 | validation: 0.18638879000522743]
	TIME [epoch: 33.4 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23367579686868123		[learning rate: 0.0013939]
	Learning Rate: 0.0013939
	LOSS [training: 0.23367579686868123 | validation: 0.19266399210161717]
	TIME [epoch: 33.3 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22559138423290678		[learning rate: 0.0013884]
	Learning Rate: 0.00138835
	LOSS [training: 0.22559138423290678 | validation: 0.19175831561202106]
	TIME [epoch: 33.3 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22795329217599486		[learning rate: 0.0013828]
	Learning Rate: 0.00138283
	LOSS [training: 0.22795329217599486 | validation: 0.18548716244085345]
	TIME [epoch: 33.3 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2367138128696955		[learning rate: 0.0013773]
	Learning Rate: 0.00137733
	LOSS [training: 0.2367138128696955 | validation: 0.1835624401448701]
	TIME [epoch: 33.3 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22488732431823577		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 0.22488732431823577 | validation: 0.19142580050206823]
	TIME [epoch: 33.3 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2243319524885391		[learning rate: 0.0013664]
	Learning Rate: 0.0013664
	LOSS [training: 0.2243319524885391 | validation: 0.18478080185345244]
	TIME [epoch: 33.3 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22216542166456488		[learning rate: 0.001361]
	Learning Rate: 0.00136096
	LOSS [training: 0.22216542166456488 | validation: 0.19153057681850952]
	TIME [epoch: 33.3 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23294763515538033		[learning rate: 0.0013555]
	Learning Rate: 0.00135555
	LOSS [training: 0.23294763515538033 | validation: 0.18555988230255038]
	TIME [epoch: 33.4 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2221596928796614		[learning rate: 0.0013502]
	Learning Rate: 0.00135016
	LOSS [training: 0.2221596928796614 | validation: 0.18748517680532556]
	TIME [epoch: 33.3 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2349935691880988		[learning rate: 0.0013448]
	Learning Rate: 0.00134479
	LOSS [training: 0.2349935691880988 | validation: 0.18152436939418096]
	TIME [epoch: 33.3 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22694626213637445		[learning rate: 0.0013394]
	Learning Rate: 0.00133944
	LOSS [training: 0.22694626213637445 | validation: 0.18521752173224418]
	TIME [epoch: 33.3 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22234749404740015		[learning rate: 0.0013341]
	Learning Rate: 0.00133411
	LOSS [training: 0.22234749404740015 | validation: 0.18586401703536048]
	TIME [epoch: 33.3 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2343637209995797		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.2343637209995797 | validation: 0.18353318341197591]
	TIME [epoch: 33.3 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22901061770535833		[learning rate: 0.0013235]
	Learning Rate: 0.00132352
	LOSS [training: 0.22901061770535833 | validation: 0.19225923133867487]
	TIME [epoch: 33.3 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2379731504095371		[learning rate: 0.0013183]
	Learning Rate: 0.00131826
	LOSS [training: 0.2379731504095371 | validation: 0.1885781156012884]
	TIME [epoch: 33.3 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23085315020754704		[learning rate: 0.001313]
	Learning Rate: 0.00131301
	LOSS [training: 0.23085315020754704 | validation: 0.18576629227412567]
	TIME [epoch: 33.3 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22748424435069184		[learning rate: 0.0013078]
	Learning Rate: 0.00130779
	LOSS [training: 0.22748424435069184 | validation: 0.1858004286640769]
	TIME [epoch: 33.3 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22178897941769976		[learning rate: 0.0013026]
	Learning Rate: 0.00130259
	LOSS [training: 0.22178897941769976 | validation: 0.19274187565094483]
	TIME [epoch: 33.3 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23033910088198825		[learning rate: 0.0012974]
	Learning Rate: 0.00129741
	LOSS [training: 0.23033910088198825 | validation: 0.18406247725702354]
	TIME [epoch: 33.3 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2305301027867033		[learning rate: 0.0012922]
	Learning Rate: 0.00129225
	LOSS [training: 0.2305301027867033 | validation: 0.195511359529775]
	TIME [epoch: 33.3 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2290445713499762		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 0.2290445713499762 | validation: 0.18553979984147043]
	TIME [epoch: 33.3 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23380931233656582		[learning rate: 0.001282]
	Learning Rate: 0.00128199
	LOSS [training: 0.23380931233656582 | validation: 0.19272100019902913]
	TIME [epoch: 33.3 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23339408014270868		[learning rate: 0.0012769]
	Learning Rate: 0.00127689
	LOSS [training: 0.23339408014270868 | validation: 0.19280019165695914]
	TIME [epoch: 33.3 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22744683323980144		[learning rate: 0.0012718]
	Learning Rate: 0.00127181
	LOSS [training: 0.22744683323980144 | validation: 0.18792914488876714]
	TIME [epoch: 33.3 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2346725386778898		[learning rate: 0.0012668]
	Learning Rate: 0.00126675
	LOSS [training: 0.2346725386778898 | validation: 0.19053652365059304]
	TIME [epoch: 33.3 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23546693605263375		[learning rate: 0.0012617]
	Learning Rate: 0.00126172
	LOSS [training: 0.23546693605263375 | validation: 0.1950043388482265]
	TIME [epoch: 33.3 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2224942079338417		[learning rate: 0.0012567]
	Learning Rate: 0.0012567
	LOSS [training: 0.2224942079338417 | validation: 0.18385306655297542]
	TIME [epoch: 33.3 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2252903364140772		[learning rate: 0.0012517]
	Learning Rate: 0.0012517
	LOSS [training: 0.2252903364140772 | validation: 0.1962633507146824]
	TIME [epoch: 33.3 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22385251783366433		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 0.22385251783366433 | validation: 0.18401037257484426]
	TIME [epoch: 33.3 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22834295735483717		[learning rate: 0.0012418]
	Learning Rate: 0.00124176
	LOSS [training: 0.22834295735483717 | validation: 0.1867935409464439]
	TIME [epoch: 33.3 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22272488006739596		[learning rate: 0.0012368]
	Learning Rate: 0.00123682
	LOSS [training: 0.22272488006739596 | validation: 0.1974928499760637]
	TIME [epoch: 33.3 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22668721105246498		[learning rate: 0.0012319]
	Learning Rate: 0.0012319
	LOSS [training: 0.22668721105246498 | validation: 0.1861723627147065]
	TIME [epoch: 33.3 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23249600739908016		[learning rate: 0.001227]
	Learning Rate: 0.001227
	LOSS [training: 0.23249600739908016 | validation: 0.1934042630812539]
	TIME [epoch: 33.3 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22779822883759224		[learning rate: 0.0012221]
	Learning Rate: 0.00122212
	LOSS [training: 0.22779822883759224 | validation: 0.1824627496771286]
	TIME [epoch: 33.3 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.226814889517409		[learning rate: 0.0012173]
	Learning Rate: 0.00121726
	LOSS [training: 0.226814889517409 | validation: 0.19240701942089317]
	TIME [epoch: 33.3 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22986758007194355		[learning rate: 0.0012124]
	Learning Rate: 0.00121242
	LOSS [training: 0.22986758007194355 | validation: 0.1882070603538769]
	TIME [epoch: 33.3 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2284711505726971		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 0.2284711505726971 | validation: 0.18657627517717107]
	TIME [epoch: 33.3 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.225691913251563		[learning rate: 0.0012028]
	Learning Rate: 0.0012028
	LOSS [training: 0.225691913251563 | validation: 0.18496039975383752]
	TIME [epoch: 33.3 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22986469066202148		[learning rate: 0.001198]
	Learning Rate: 0.00119801
	LOSS [training: 0.22986469066202148 | validation: 0.18902642752399962]
	TIME [epoch: 33.3 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22311317503847253		[learning rate: 0.0011932]
	Learning Rate: 0.00119325
	LOSS [training: 0.22311317503847253 | validation: 0.18598934441682163]
	TIME [epoch: 33.3 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22933124010748443		[learning rate: 0.0011885]
	Learning Rate: 0.0011885
	LOSS [training: 0.22933124010748443 | validation: 0.18714683620226663]
	TIME [epoch: 33.3 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22573385978971608		[learning rate: 0.0011838]
	Learning Rate: 0.00118378
	LOSS [training: 0.22573385978971608 | validation: 0.1901607246772333]
	TIME [epoch: 33.3 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22805167594678016		[learning rate: 0.0011791]
	Learning Rate: 0.00117907
	LOSS [training: 0.22805167594678016 | validation: 0.1945369332431965]
	TIME [epoch: 33.3 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23354301228381347		[learning rate: 0.0011744]
	Learning Rate: 0.00117438
	LOSS [training: 0.23354301228381347 | validation: 0.18898021014420097]
	TIME [epoch: 33.3 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2277998235894496		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 0.2277998235894496 | validation: 0.1925973142584604]
	TIME [epoch: 33.3 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22956844986950392		[learning rate: 0.0011651]
	Learning Rate: 0.00116505
	LOSS [training: 0.22956844986950392 | validation: 0.1857961707749848]
	TIME [epoch: 33.3 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23376463535612016		[learning rate: 0.0011604]
	Learning Rate: 0.00116042
	LOSS [training: 0.23376463535612016 | validation: 0.1884850584914759]
	TIME [epoch: 33.3 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2295264782888734		[learning rate: 0.0011558]
	Learning Rate: 0.00115581
	LOSS [training: 0.2295264782888734 | validation: 0.18063171643174475]
	TIME [epoch: 33.3 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22730963730633894		[learning rate: 0.0011512]
	Learning Rate: 0.00115121
	LOSS [training: 0.22730963730633894 | validation: 0.18137725919612008]
	TIME [epoch: 33.3 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22973128146131228		[learning rate: 0.0011466]
	Learning Rate: 0.00114663
	LOSS [training: 0.22973128146131228 | validation: 0.181164646292236]
	TIME [epoch: 33.3 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22964396890352334		[learning rate: 0.0011421]
	Learning Rate: 0.00114207
	LOSS [training: 0.22964396890352334 | validation: 0.18636211025960078]
	TIME [epoch: 33.3 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23764205500844218		[learning rate: 0.0011375]
	Learning Rate: 0.00113753
	LOSS [training: 0.23764205500844218 | validation: 0.1892805145883392]
	TIME [epoch: 33.3 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22886041661625192		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.22886041661625192 | validation: 0.19209237137683816]
	TIME [epoch: 33.3 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2349232319218354		[learning rate: 0.0011285]
	Learning Rate: 0.0011285
	LOSS [training: 0.2349232319218354 | validation: 0.18398461118659243]
	TIME [epoch: 33.3 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.221914494404393		[learning rate: 0.001124]
	Learning Rate: 0.00112401
	LOSS [training: 0.221914494404393 | validation: 0.19005655346955425]
	TIME [epoch: 33.3 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22388290401464028		[learning rate: 0.0011195]
	Learning Rate: 0.00111954
	LOSS [training: 0.22388290401464028 | validation: 0.19119238655060805]
	TIME [epoch: 33.3 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22796475501102315		[learning rate: 0.0011151]
	Learning Rate: 0.00111508
	LOSS [training: 0.22796475501102315 | validation: 0.1875786535211003]
	TIME [epoch: 33.3 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22800061475904287		[learning rate: 0.0011106]
	Learning Rate: 0.00111065
	LOSS [training: 0.22800061475904287 | validation: 0.18464318409098765]
	TIME [epoch: 33.3 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2282197118967666		[learning rate: 0.0011062]
	Learning Rate: 0.00110623
	LOSS [training: 0.2282197118967666 | validation: 0.18719304876972576]
	TIME [epoch: 33.3 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22137619212450718		[learning rate: 0.0011018]
	Learning Rate: 0.00110183
	LOSS [training: 0.22137619212450718 | validation: 0.17641916899706173]
	TIME [epoch: 33.3 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v14_20240716_142610/states/model_facs_v2_dec1b_2dpca_v14_598.pth
	Model improved!!!
EPOCH 599/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23197530820933704		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 0.23197530820933704 | validation: 0.1957054943498963]
	TIME [epoch: 33.3 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22466865205290876		[learning rate: 0.0010931]
	Learning Rate: 0.00109309
	LOSS [training: 0.22466865205290876 | validation: 0.18637963647220132]
	TIME [epoch: 33.3 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22388859022938734		[learning rate: 0.0010887]
	Learning Rate: 0.00108874
	LOSS [training: 0.22388859022938734 | validation: 0.1896225927351551]
	TIME [epoch: 33.3 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22734159158666462		[learning rate: 0.0010844]
	Learning Rate: 0.00108441
	LOSS [training: 0.22734159158666462 | validation: 0.18626951206076664]
	TIME [epoch: 33.4 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22078887029338523		[learning rate: 0.0010801]
	Learning Rate: 0.00108009
	LOSS [training: 0.22078887029338523 | validation: 0.18319999476811805]
	TIME [epoch: 33.3 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22742687191230923		[learning rate: 0.0010758]
	Learning Rate: 0.0010758
	LOSS [training: 0.22742687191230923 | validation: 0.18645884479485936]
	TIME [epoch: 33.3 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2353492933845225		[learning rate: 0.0010715]
	Learning Rate: 0.00107152
	LOSS [training: 0.2353492933845225 | validation: 0.18824106774010482]
	TIME [epoch: 33.3 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23333036753316616		[learning rate: 0.0010673]
	Learning Rate: 0.00106726
	LOSS [training: 0.23333036753316616 | validation: 0.18376063434909473]
	TIME [epoch: 33.3 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23210796257844363		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 0.23210796257844363 | validation: 0.18791724636302853]
	TIME [epoch: 33.3 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23120050159381897		[learning rate: 0.0010588]
	Learning Rate: 0.00105878
	LOSS [training: 0.23120050159381897 | validation: 0.1833390423331274]
	TIME [epoch: 33.4 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23307355615998887		[learning rate: 0.0010546]
	Learning Rate: 0.00105457
	LOSS [training: 0.23307355615998887 | validation: 0.18307047213809624]
	TIME [epoch: 33.3 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23136702526689248		[learning rate: 0.0010504]
	Learning Rate: 0.00105038
	LOSS [training: 0.23136702526689248 | validation: 0.18367562760488407]
	TIME [epoch: 33.3 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2268062322609625		[learning rate: 0.0010462]
	Learning Rate: 0.0010462
	LOSS [training: 0.2268062322609625 | validation: 0.1865580546525724]
	TIME [epoch: 33.3 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2165237980330136		[learning rate: 0.001042]
	Learning Rate: 0.00104204
	LOSS [training: 0.2165237980330136 | validation: 0.1871452226354034]
	TIME [epoch: 33.3 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22013137867413637		[learning rate: 0.0010379]
	Learning Rate: 0.0010379
	LOSS [training: 0.22013137867413637 | validation: 0.18961614252188813]
	TIME [epoch: 33.3 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22240599067972142		[learning rate: 0.0010338]
	Learning Rate: 0.00103377
	LOSS [training: 0.22240599067972142 | validation: 0.18849335116551677]
	TIME [epoch: 33.3 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22601038734549495		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 0.22601038734549495 | validation: 0.18580289406426154]
	TIME [epoch: 33.3 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22152394956853988		[learning rate: 0.0010256]
	Learning Rate: 0.00102556
	LOSS [training: 0.22152394956853988 | validation: 0.19256917857859307]
	TIME [epoch: 33.3 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2235737802085641		[learning rate: 0.0010215]
	Learning Rate: 0.00102148
	LOSS [training: 0.2235737802085641 | validation: 0.17904263151186867]
	TIME [epoch: 33.3 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23799781478860954		[learning rate: 0.0010174]
	Learning Rate: 0.00101742
	LOSS [training: 0.23799781478860954 | validation: 0.1814261845897882]
	TIME [epoch: 33.3 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22683464881052784		[learning rate: 0.0010134]
	Learning Rate: 0.00101337
	LOSS [training: 0.22683464881052784 | validation: 0.1872084292918039]
	TIME [epoch: 33.3 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22365069620194905		[learning rate: 0.0010093]
	Learning Rate: 0.00100934
	LOSS [training: 0.22365069620194905 | validation: 0.18293471529205166]
	TIME [epoch: 33.3 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23039664714731525		[learning rate: 0.0010053]
	Learning Rate: 0.00100533
	LOSS [training: 0.23039664714731525 | validation: 0.1882735285071247]
	TIME [epoch: 33.3 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23627856487302804		[learning rate: 0.0010013]
	Learning Rate: 0.00100133
	LOSS [training: 0.23627856487302804 | validation: 0.18697164485061984]
	TIME [epoch: 33.4 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2212549358775322		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 0.2212549358775322 | validation: 0.19411293160573773]
	TIME [epoch: 33.3 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.21775211508097997		[learning rate: 0.00099338]
	Learning Rate: 0.00099338
	LOSS [training: 0.21775211508097997 | validation: 0.1825250817039043]
	TIME [epoch: 33.3 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22392405208669958		[learning rate: 0.00098943]
	Learning Rate: 0.000989429
	LOSS [training: 0.22392405208669958 | validation: 0.19065045234676864]
	TIME [epoch: 33.3 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22661693566862942		[learning rate: 0.00098549]
	Learning Rate: 0.000985494
	LOSS [training: 0.22661693566862942 | validation: 0.18760533460849205]
	TIME [epoch: 33.3 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22804488911489795		[learning rate: 0.00098157]
	Learning Rate: 0.000981574
	LOSS [training: 0.22804488911489795 | validation: 0.185803980109873]
	TIME [epoch: 33.3 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22575256884726846		[learning rate: 0.00097767]
	Learning Rate: 0.00097767
	LOSS [training: 0.22575256884726846 | validation: 0.19282440413653565]
	TIME [epoch: 33.3 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22727284365229627		[learning rate: 0.00097378]
	Learning Rate: 0.000973782
	LOSS [training: 0.22727284365229627 | validation: 0.18729063354714623]
	TIME [epoch: 33.3 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2274982139813045		[learning rate: 0.00096991]
	Learning Rate: 0.000969909
	LOSS [training: 0.2274982139813045 | validation: 0.1899689789063535]
	TIME [epoch: 33.3 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23123136145967216		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.23123136145967216 | validation: 0.1851421743542268]
	TIME [epoch: 33.3 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22818446518583257		[learning rate: 0.00096221]
	Learning Rate: 0.000962209
	LOSS [training: 0.22818446518583257 | validation: 0.17511673474501502]
	TIME [epoch: 33.3 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v14_20240716_142610/states/model_facs_v2_dec1b_2dpca_v14_632.pth
	Model improved!!!
EPOCH 633/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2364204654135659		[learning rate: 0.00095838]
	Learning Rate: 0.000958382
	LOSS [training: 0.2364204654135659 | validation: 0.18560891410721786]
	TIME [epoch: 33.3 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2307184348456638		[learning rate: 0.00095457]
	Learning Rate: 0.00095457
	LOSS [training: 0.2307184348456638 | validation: 0.18829627384877945]
	TIME [epoch: 33.3 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23130229202822314		[learning rate: 0.00095077]
	Learning Rate: 0.000950773
	LOSS [training: 0.23130229202822314 | validation: 0.18996498599691586]
	TIME [epoch: 33.3 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22264222709836268		[learning rate: 0.00094699]
	Learning Rate: 0.000946992
	LOSS [training: 0.22264222709836268 | validation: 0.18815377015397022]
	TIME [epoch: 33.3 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22087650989690277		[learning rate: 0.00094323]
	Learning Rate: 0.000943225
	LOSS [training: 0.22087650989690277 | validation: 0.19118161500871264]
	TIME [epoch: 33.3 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22897340108829972		[learning rate: 0.00093947]
	Learning Rate: 0.000939474
	LOSS [training: 0.22897340108829972 | validation: 0.18762770462113645]
	TIME [epoch: 33.3 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22970175838304177		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.22970175838304177 | validation: 0.18129556566459434]
	TIME [epoch: 33.3 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22967500497949725		[learning rate: 0.00093202]
	Learning Rate: 0.000932015
	LOSS [training: 0.22967500497949725 | validation: 0.19049922995512245]
	TIME [epoch: 33.3 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22954595877536438		[learning rate: 0.00092831]
	Learning Rate: 0.000928309
	LOSS [training: 0.22954595877536438 | validation: 0.19085996482494322]
	TIME [epoch: 33.3 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2303040316325044		[learning rate: 0.00092462]
	Learning Rate: 0.000924616
	LOSS [training: 0.2303040316325044 | validation: 0.1978617081626115]
	TIME [epoch: 33.3 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22660055473082347		[learning rate: 0.00092094]
	Learning Rate: 0.000920939
	LOSS [training: 0.22660055473082347 | validation: 0.18670150441890554]
	TIME [epoch: 33.3 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22127284667959327		[learning rate: 0.00091728]
	Learning Rate: 0.000917276
	LOSS [training: 0.22127284667959327 | validation: 0.19891171696832108]
	TIME [epoch: 33.3 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2332319668605007		[learning rate: 0.00091363]
	Learning Rate: 0.000913628
	LOSS [training: 0.2332319668605007 | validation: 0.18779154048381128]
	TIME [epoch: 33.3 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22398066237441883		[learning rate: 0.00090999]
	Learning Rate: 0.000909994
	LOSS [training: 0.22398066237441883 | validation: 0.1833792844089433]
	TIME [epoch: 33.3 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22316197528536952		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.22316197528536952 | validation: 0.1889526737266603]
	TIME [epoch: 33.3 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2256814088340945		[learning rate: 0.00090277]
	Learning Rate: 0.00090277
	LOSS [training: 0.2256814088340945 | validation: 0.18843809226584035]
	TIME [epoch: 33.3 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23308505567421933		[learning rate: 0.00089918]
	Learning Rate: 0.000899179
	LOSS [training: 0.23308505567421933 | validation: 0.19210628832581128]
	TIME [epoch: 33.4 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22400674673178747		[learning rate: 0.0008956]
	Learning Rate: 0.000895603
	LOSS [training: 0.22400674673178747 | validation: 0.19083912985960483]
	TIME [epoch: 33.3 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23462586335180471		[learning rate: 0.00089204]
	Learning Rate: 0.000892041
	LOSS [training: 0.23462586335180471 | validation: 0.18881607929291114]
	TIME [epoch: 33.3 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23324581928132573		[learning rate: 0.00088849]
	Learning Rate: 0.000888493
	LOSS [training: 0.23324581928132573 | validation: 0.19094416180797216]
	TIME [epoch: 33.3 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22507178656618398		[learning rate: 0.00088496]
	Learning Rate: 0.000884959
	LOSS [training: 0.22507178656618398 | validation: 0.19092745987719228]
	TIME [epoch: 33.3 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22646176133601548		[learning rate: 0.00088144]
	Learning Rate: 0.000881439
	LOSS [training: 0.22646176133601548 | validation: 0.18689678013004707]
	TIME [epoch: 33.3 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22325911484207012		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 0.22325911484207012 | validation: 0.1839459775825172]
	TIME [epoch: 33.3 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22305815681668292		[learning rate: 0.00087444]
	Learning Rate: 0.000874441
	LOSS [training: 0.22305815681668292 | validation: 0.1839090270715493]
	TIME [epoch: 33.3 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22948891155692971		[learning rate: 0.00087096]
	Learning Rate: 0.000870964
	LOSS [training: 0.22948891155692971 | validation: 0.1884470327750333]
	TIME [epoch: 33.3 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22896728851880788		[learning rate: 0.0008675]
	Learning Rate: 0.0008675
	LOSS [training: 0.22896728851880788 | validation: 0.18797476972514143]
	TIME [epoch: 33.3 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22415589171381103		[learning rate: 0.00086405]
	Learning Rate: 0.000864049
	LOSS [training: 0.22415589171381103 | validation: 0.1891434001238465]
	TIME [epoch: 33.3 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23598387995629627		[learning rate: 0.00086061]
	Learning Rate: 0.000860613
	LOSS [training: 0.23598387995629627 | validation: 0.1850610548689968]
	TIME [epoch: 33.3 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23153533053767258		[learning rate: 0.00085719]
	Learning Rate: 0.00085719
	LOSS [training: 0.23153533053767258 | validation: 0.19023971327502048]
	TIME [epoch: 33.3 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22732959724748122		[learning rate: 0.00085378]
	Learning Rate: 0.00085378
	LOSS [training: 0.22732959724748122 | validation: 0.18532502280847124]
	TIME [epoch: 33.3 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23260416231692524		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 0.23260416231692524 | validation: 0.19028734281216578]
	TIME [epoch: 33.3 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22289692781408327		[learning rate: 0.000847]
	Learning Rate: 0.000847002
	LOSS [training: 0.22289692781408327 | validation: 0.18785967403879264]
	TIME [epoch: 33.3 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22481722961574746		[learning rate: 0.00084363]
	Learning Rate: 0.000843634
	LOSS [training: 0.22481722961574746 | validation: 0.1767129801704024]
	TIME [epoch: 33.3 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22525027877464676		[learning rate: 0.00084028]
	Learning Rate: 0.000840278
	LOSS [training: 0.22525027877464676 | validation: 0.18531807761409086]
	TIME [epoch: 33.3 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22543055119505753		[learning rate: 0.00083694]
	Learning Rate: 0.000836936
	LOSS [training: 0.22543055119505753 | validation: 0.1923676964652112]
	TIME [epoch: 33.3 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2320202122967827		[learning rate: 0.00083361]
	Learning Rate: 0.000833608
	LOSS [training: 0.2320202122967827 | validation: 0.18400369912869977]
	TIME [epoch: 33.3 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22210666020139264		[learning rate: 0.00083029]
	Learning Rate: 0.000830292
	LOSS [training: 0.22210666020139264 | validation: 0.18901635948213874]
	TIME [epoch: 33.3 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22526615124246085		[learning rate: 0.00082699]
	Learning Rate: 0.00082699
	LOSS [training: 0.22526615124246085 | validation: 0.18644547163022046]
	TIME [epoch: 33.3 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.236500915233329		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.236500915233329 | validation: 0.1918653932055537]
	TIME [epoch: 33.3 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22063658297248112		[learning rate: 0.00082042]
	Learning Rate: 0.000820424
	LOSS [training: 0.22063658297248112 | validation: 0.18943602329529802]
	TIME [epoch: 33.3 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22763219435138776		[learning rate: 0.00081716]
	Learning Rate: 0.000817161
	LOSS [training: 0.22763219435138776 | validation: 0.18483509137928467]
	TIME [epoch: 33.3 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22927988996864507		[learning rate: 0.00081391]
	Learning Rate: 0.000813911
	LOSS [training: 0.22927988996864507 | validation: 0.19226788241721138]
	TIME [epoch: 33.3 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22134361021350296		[learning rate: 0.00081067]
	Learning Rate: 0.000810674
	LOSS [training: 0.22134361021350296 | validation: 0.18321144323177688]
	TIME [epoch: 33.3 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22505212175265876		[learning rate: 0.00080745]
	Learning Rate: 0.00080745
	LOSS [training: 0.22505212175265876 | validation: 0.1836197461010905]
	TIME [epoch: 33.3 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22724481455006312		[learning rate: 0.00080424]
	Learning Rate: 0.000804238
	LOSS [training: 0.22724481455006312 | validation: 0.1899933798011543]
	TIME [epoch: 33.3 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22973108927931682		[learning rate: 0.00080104]
	Learning Rate: 0.000801039
	LOSS [training: 0.22973108927931682 | validation: 0.1935933395934409]
	TIME [epoch: 33.3 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22511853546903893		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 0.22511853546903893 | validation: 0.19410250060592352]
	TIME [epoch: 33.3 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2278370628736423		[learning rate: 0.00079468]
	Learning Rate: 0.00079468
	LOSS [training: 0.2278370628736423 | validation: 0.18417474890523244]
	TIME [epoch: 33.3 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23527526667928647		[learning rate: 0.00079152]
	Learning Rate: 0.000791519
	LOSS [training: 0.23527526667928647 | validation: 0.18133985242241543]
	TIME [epoch: 33.3 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22190786867119405		[learning rate: 0.00078837]
	Learning Rate: 0.000788371
	LOSS [training: 0.22190786867119405 | validation: 0.1909931182283174]
	TIME [epoch: 33.3 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2207799878935257		[learning rate: 0.00078524]
	Learning Rate: 0.000785236
	LOSS [training: 0.2207799878935257 | validation: 0.18439026256484825]
	TIME [epoch: 33.3 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23118826166088846		[learning rate: 0.00078211]
	Learning Rate: 0.000782113
	LOSS [training: 0.23118826166088846 | validation: 0.1847335689332507]
	TIME [epoch: 33.3 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2224483801569346		[learning rate: 0.000779]
	Learning Rate: 0.000779002
	LOSS [training: 0.2224483801569346 | validation: 0.18549098122069912]
	TIME [epoch: 33.3 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22901631889485607		[learning rate: 0.0007759]
	Learning Rate: 0.000775904
	LOSS [training: 0.22901631889485607 | validation: 0.19188802136035574]
	TIME [epoch: 33.3 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22745559097880896		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 0.22745559097880896 | validation: 0.190271997750361]
	TIME [epoch: 33.3 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2208315376830937		[learning rate: 0.00076974]
	Learning Rate: 0.000769744
	LOSS [training: 0.2208315376830937 | validation: 0.18652887514736738]
	TIME [epoch: 33.3 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2216107560215158		[learning rate: 0.00076668]
	Learning Rate: 0.000766682
	LOSS [training: 0.2216107560215158 | validation: 0.19454031973292382]
	TIME [epoch: 33.3 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22648549271796345		[learning rate: 0.00076363]
	Learning Rate: 0.000763633
	LOSS [training: 0.22648549271796345 | validation: 0.18669066233768805]
	TIME [epoch: 33.3 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22534624557689714		[learning rate: 0.0007606]
	Learning Rate: 0.000760596
	LOSS [training: 0.22534624557689714 | validation: 0.18805024741942883]
	TIME [epoch: 33.3 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22172796806131512		[learning rate: 0.00075757]
	Learning Rate: 0.000757571
	LOSS [training: 0.22172796806131512 | validation: 0.1814789379615736]
	TIME [epoch: 33.3 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2250344871030534		[learning rate: 0.00075456]
	Learning Rate: 0.000754557
	LOSS [training: 0.2250344871030534 | validation: 0.1842798789020792]
	TIME [epoch: 33.3 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22709913788737732		[learning rate: 0.00075156]
	Learning Rate: 0.000751556
	LOSS [training: 0.22709913788737732 | validation: 0.19314729389386087]
	TIME [epoch: 33.3 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22372185284994042		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 0.22372185284994042 | validation: 0.18557907777732727]
	TIME [epoch: 33.3 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22721405440210882		[learning rate: 0.00074559]
	Learning Rate: 0.00074559
	LOSS [training: 0.22721405440210882 | validation: 0.18319177508585355]
	TIME [epoch: 33.3 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2206956285359618		[learning rate: 0.00074262]
	Learning Rate: 0.000742624
	LOSS [training: 0.2206956285359618 | validation: 0.19246359237546867]
	TIME [epoch: 33.3 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22765691051542283		[learning rate: 0.00073967]
	Learning Rate: 0.000739671
	LOSS [training: 0.22765691051542283 | validation: 0.1877509341214733]
	TIME [epoch: 33.3 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22486212290398364		[learning rate: 0.00073673]
	Learning Rate: 0.000736729
	LOSS [training: 0.22486212290398364 | validation: 0.18127217769576845]
	TIME [epoch: 33.3 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23272792785195165		[learning rate: 0.0007338]
	Learning Rate: 0.000733799
	LOSS [training: 0.23272792785195165 | validation: 0.18576768411027403]
	TIME [epoch: 33.4 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2257346352170525		[learning rate: 0.00073088]
	Learning Rate: 0.00073088
	LOSS [training: 0.2257346352170525 | validation: 0.18699250512075277]
	TIME [epoch: 33.3 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22600604092204638		[learning rate: 0.00072797]
	Learning Rate: 0.000727973
	LOSS [training: 0.22600604092204638 | validation: 0.19597841106178776]
	TIME [epoch: 33.3 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22249453375939623		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 0.22249453375939623 | validation: 0.1849366767392366]
	TIME [epoch: 33.3 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23215667750340746		[learning rate: 0.00072219]
	Learning Rate: 0.000722194
	LOSS [training: 0.23215667750340746 | validation: 0.18456106967955124]
	TIME [epoch: 33.3 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22371490000871427		[learning rate: 0.00071932]
	Learning Rate: 0.000719322
	LOSS [training: 0.22371490000871427 | validation: 0.18525533325424237]
	TIME [epoch: 33.3 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23021424231923207		[learning rate: 0.00071646]
	Learning Rate: 0.000716461
	LOSS [training: 0.23021424231923207 | validation: 0.18627330975276396]
	TIME [epoch: 33.3 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2258893967222734		[learning rate: 0.00071361]
	Learning Rate: 0.000713611
	LOSS [training: 0.2258893967222734 | validation: 0.19202556423553893]
	TIME [epoch: 33.3 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23213586150938634		[learning rate: 0.00071077]
	Learning Rate: 0.000710773
	LOSS [training: 0.23213586150938634 | validation: 0.19050635576952119]
	TIME [epoch: 33.3 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2258159250603478		[learning rate: 0.00070795]
	Learning Rate: 0.000707946
	LOSS [training: 0.2258159250603478 | validation: 0.18055636144490836]
	TIME [epoch: 33.3 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22693846205094806		[learning rate: 0.00070513]
	Learning Rate: 0.00070513
	LOSS [training: 0.22693846205094806 | validation: 0.18394924721177555]
	TIME [epoch: 33.3 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22549586915738948		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.22549586915738948 | validation: 0.18126378056501638]
	TIME [epoch: 33.3 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22528589544633248		[learning rate: 0.00069953]
	Learning Rate: 0.000699532
	LOSS [training: 0.22528589544633248 | validation: 0.1830833849679431]
	TIME [epoch: 33.3 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22794684244113808		[learning rate: 0.00069675]
	Learning Rate: 0.00069675
	LOSS [training: 0.22794684244113808 | validation: 0.18847695226053368]
	TIME [epoch: 33.3 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2301171685629065		[learning rate: 0.00069398]
	Learning Rate: 0.000693979
	LOSS [training: 0.2301171685629065 | validation: 0.18766824787988404]
	TIME [epoch: 33.3 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.21952395898070465		[learning rate: 0.00069122]
	Learning Rate: 0.000691219
	LOSS [training: 0.21952395898070465 | validation: 0.18915043746116067]
	TIME [epoch: 33.3 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23091937673758883		[learning rate: 0.00068847]
	Learning Rate: 0.000688469
	LOSS [training: 0.23091937673758883 | validation: 0.19688394033169113]
	TIME [epoch: 33.3 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22783982872378322		[learning rate: 0.00068573]
	Learning Rate: 0.000685731
	LOSS [training: 0.22783982872378322 | validation: 0.19624105286098437]
	TIME [epoch: 33.3 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22422938979946594		[learning rate: 0.000683]
	Learning Rate: 0.000683004
	LOSS [training: 0.22422938979946594 | validation: 0.18984663366131965]
	TIME [epoch: 33.3 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2346480832551272		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 0.2346480832551272 | validation: 0.19140444174887442]
	TIME [epoch: 33.3 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23067503936948366		[learning rate: 0.00067758]
	Learning Rate: 0.000677582
	LOSS [training: 0.23067503936948366 | validation: 0.18743016434367987]
	TIME [epoch: 33.3 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23365373341805537		[learning rate: 0.00067489]
	Learning Rate: 0.000674887
	LOSS [training: 0.23365373341805537 | validation: 0.1893450311028178]
	TIME [epoch: 33.3 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23060668288269007		[learning rate: 0.0006722]
	Learning Rate: 0.000672202
	LOSS [training: 0.23060668288269007 | validation: 0.18589250574688737]
	TIME [epoch: 33.3 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22575036205638227		[learning rate: 0.00066953]
	Learning Rate: 0.000669529
	LOSS [training: 0.22575036205638227 | validation: 0.1865382380226066]
	TIME [epoch: 33.3 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22727191845940733		[learning rate: 0.00066687]
	Learning Rate: 0.000666866
	LOSS [training: 0.22727191845940733 | validation: 0.18983551566577123]
	TIME [epoch: 33.3 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2256922147044867		[learning rate: 0.00066421]
	Learning Rate: 0.000664213
	LOSS [training: 0.2256922147044867 | validation: 0.18724558953739753]
	TIME [epoch: 33.3 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22260354025678616		[learning rate: 0.00066157]
	Learning Rate: 0.000661572
	LOSS [training: 0.22260354025678616 | validation: 0.19477874572296947]
	TIME [epoch: 33.3 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22459157496827828		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 0.22459157496827828 | validation: 0.18722402236535773]
	TIME [epoch: 33.3 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22615342025015206		[learning rate: 0.00065632]
	Learning Rate: 0.00065632
	LOSS [training: 0.22615342025015206 | validation: 0.18409353944883694]
	TIME [epoch: 33.3 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2235354132884791		[learning rate: 0.00065371]
	Learning Rate: 0.000653709
	LOSS [training: 0.2235354132884791 | validation: 0.18323352528431974]
	TIME [epoch: 33.3 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23069575720634405		[learning rate: 0.00065111]
	Learning Rate: 0.000651109
	LOSS [training: 0.23069575720634405 | validation: 0.1885170932077294]
	TIME [epoch: 33.3 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22103870093340233		[learning rate: 0.00064852]
	Learning Rate: 0.00064852
	LOSS [training: 0.22103870093340233 | validation: 0.18959745416504487]
	TIME [epoch: 33.3 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2241241567471271		[learning rate: 0.00064594]
	Learning Rate: 0.00064594
	LOSS [training: 0.2241241567471271 | validation: 0.18139264912013214]
	TIME [epoch: 33.3 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22796043141006336		[learning rate: 0.00064337]
	Learning Rate: 0.000643371
	LOSS [training: 0.22796043141006336 | validation: 0.19061584164612286]
	TIME [epoch: 33.3 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23004326304961487		[learning rate: 0.00064081]
	Learning Rate: 0.000640812
	LOSS [training: 0.23004326304961487 | validation: 0.18446017554018754]
	TIME [epoch: 33.3 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23403285232765844		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 0.23403285232765844 | validation: 0.18504849312432742]
	TIME [epoch: 33.3 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23135716509640336		[learning rate: 0.00063572]
	Learning Rate: 0.000635725
	LOSS [training: 0.23135716509640336 | validation: 0.1906337973527263]
	TIME [epoch: 33.3 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23192817472677918		[learning rate: 0.0006332]
	Learning Rate: 0.000633196
	LOSS [training: 0.23192817472677918 | validation: 0.19254071625884875]
	TIME [epoch: 33.3 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2259382783829744		[learning rate: 0.00063068]
	Learning Rate: 0.000630678
	LOSS [training: 0.2259382783829744 | validation: 0.19221256763899258]
	TIME [epoch: 33.3 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22809987551214084		[learning rate: 0.00062817]
	Learning Rate: 0.00062817
	LOSS [training: 0.22809987551214084 | validation: 0.18806080684651616]
	TIME [epoch: 33.3 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2265451412522138		[learning rate: 0.00062567]
	Learning Rate: 0.000625671
	LOSS [training: 0.2265451412522138 | validation: 0.1879800307783859]
	TIME [epoch: 33.3 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22392644464684455		[learning rate: 0.00062318]
	Learning Rate: 0.000623183
	LOSS [training: 0.22392644464684455 | validation: 0.19086902029656233]
	TIME [epoch: 33.3 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22779454819050304		[learning rate: 0.0006207]
	Learning Rate: 0.000620704
	LOSS [training: 0.22779454819050304 | validation: 0.1848707988708054]
	TIME [epoch: 33.3 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2283474874648925		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 0.2283474874648925 | validation: 0.18998653457324166]
	TIME [epoch: 33.3 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22713186358099213		[learning rate: 0.00061578]
	Learning Rate: 0.000615777
	LOSS [training: 0.22713186358099213 | validation: 0.18489905188573014]
	TIME [epoch: 33.3 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.21902539248536984		[learning rate: 0.00061333]
	Learning Rate: 0.000613327
	LOSS [training: 0.21902539248536984 | validation: 0.19191738572434996]
	TIME [epoch: 33.3 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2236235777806669		[learning rate: 0.00061089]
	Learning Rate: 0.000610888
	LOSS [training: 0.2236235777806669 | validation: 0.1838101629448066]
	TIME [epoch: 33.3 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22317209630268753		[learning rate: 0.00060846]
	Learning Rate: 0.000608458
	LOSS [training: 0.22317209630268753 | validation: 0.18230177779254486]
	TIME [epoch: 33.3 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22703636009253245		[learning rate: 0.00060604]
	Learning Rate: 0.000606038
	LOSS [training: 0.22703636009253245 | validation: 0.17955333789565606]
	TIME [epoch: 33.2 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22018097634744918		[learning rate: 0.00060363]
	Learning Rate: 0.000603628
	LOSS [training: 0.22018097634744918 | validation: 0.19082341519851398]
	TIME [epoch: 33.3 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23284803051198327		[learning rate: 0.00060123]
	Learning Rate: 0.000601227
	LOSS [training: 0.23284803051198327 | validation: 0.1827373358223565]
	TIME [epoch: 33.3 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22818371290900646		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.22818371290900646 | validation: 0.18070684925353256]
	TIME [epoch: 33.3 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22936587216470017		[learning rate: 0.00059645]
	Learning Rate: 0.000596454
	LOSS [training: 0.22936587216470017 | validation: 0.1920882888984962]
	TIME [epoch: 33.3 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2261164960641893		[learning rate: 0.00059408]
	Learning Rate: 0.000594082
	LOSS [training: 0.2261164960641893 | validation: 0.1849500388972497]
	TIME [epoch: 33.3 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.224309352158984		[learning rate: 0.00059172]
	Learning Rate: 0.000591719
	LOSS [training: 0.224309352158984 | validation: 0.1900948958547603]
	TIME [epoch: 33.3 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2312462730032872		[learning rate: 0.00058937]
	Learning Rate: 0.000589365
	LOSS [training: 0.2312462730032872 | validation: 0.19022028961717372]
	TIME [epoch: 33.3 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22445933751557412		[learning rate: 0.00058702]
	Learning Rate: 0.000587021
	LOSS [training: 0.22445933751557412 | validation: 0.18754593465052102]
	TIME [epoch: 33.3 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22822354164135372		[learning rate: 0.00058469]
	Learning Rate: 0.000584687
	LOSS [training: 0.22822354164135372 | validation: 0.17717042141933678]
	TIME [epoch: 33.3 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.233763687346848		[learning rate: 0.00058236]
	Learning Rate: 0.000582361
	LOSS [training: 0.233763687346848 | validation: 0.1928305660036482]
	TIME [epoch: 33.3 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22650901939182544		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 0.22650901939182544 | validation: 0.18602381216338704]
	TIME [epoch: 33.3 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23516505162498122		[learning rate: 0.00057774]
	Learning Rate: 0.000577738
	LOSS [training: 0.23516505162498122 | validation: 0.18185157537331648]
	TIME [epoch: 33.3 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.230993603821697		[learning rate: 0.00057544]
	Learning Rate: 0.00057544
	LOSS [training: 0.230993603821697 | validation: 0.18437608117055887]
	TIME [epoch: 33.3 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22687827155618134		[learning rate: 0.00057315]
	Learning Rate: 0.000573151
	LOSS [training: 0.22687827155618134 | validation: 0.19174859321968313]
	TIME [epoch: 33.3 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2264657070702578		[learning rate: 0.00057087]
	Learning Rate: 0.000570872
	LOSS [training: 0.2264657070702578 | validation: 0.18808235938378054]
	TIME [epoch: 33.3 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23328902729227144		[learning rate: 0.0005686]
	Learning Rate: 0.000568601
	LOSS [training: 0.23328902729227144 | validation: 0.18706791385722807]
	TIME [epoch: 33.3 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22644490285780078		[learning rate: 0.00056634]
	Learning Rate: 0.00056634
	LOSS [training: 0.22644490285780078 | validation: 0.1866259462373659]
	TIME [epoch: 33.3 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22659512537721493		[learning rate: 0.00056409]
	Learning Rate: 0.000564087
	LOSS [training: 0.22659512537721493 | validation: 0.18050232918049794]
	TIME [epoch: 33.2 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22769235930451778		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 0.22769235930451778 | validation: 0.18963980659139965]
	TIME [epoch: 33.2 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23283007169176162		[learning rate: 0.00055961]
	Learning Rate: 0.000559609
	LOSS [training: 0.23283007169176162 | validation: 0.19274411929765362]
	TIME [epoch: 33.2 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22463997397758353		[learning rate: 0.00055738]
	Learning Rate: 0.000557383
	LOSS [training: 0.22463997397758353 | validation: 0.18604419514587775]
	TIME [epoch: 33.2 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22205606321923815		[learning rate: 0.00055517]
	Learning Rate: 0.000555166
	LOSS [training: 0.22205606321923815 | validation: 0.1850454069725152]
	TIME [epoch: 33.2 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22379152662925186		[learning rate: 0.00055296]
	Learning Rate: 0.000552958
	LOSS [training: 0.22379152662925186 | validation: 0.18763265672569004]
	TIME [epoch: 33.2 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22585899984229874		[learning rate: 0.00055076]
	Learning Rate: 0.000550759
	LOSS [training: 0.22585899984229874 | validation: 0.19911326891812126]
	TIME [epoch: 33.2 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22716284108911436		[learning rate: 0.00054857]
	Learning Rate: 0.000548568
	LOSS [training: 0.22716284108911436 | validation: 0.18718195202645233]
	TIME [epoch: 33.2 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2275688848555439		[learning rate: 0.00054639]
	Learning Rate: 0.000546387
	LOSS [training: 0.2275688848555439 | validation: 0.18633877610283145]
	TIME [epoch: 33.2 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22208345476168057		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 0.22208345476168057 | validation: 0.18854012810314696]
	TIME [epoch: 33.2 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22306693540962877		[learning rate: 0.00054205]
	Learning Rate: 0.000542049
	LOSS [training: 0.22306693540962877 | validation: 0.18384022010497375]
	TIME [epoch: 33.2 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22168069301458848		[learning rate: 0.00053989]
	Learning Rate: 0.000539893
	LOSS [training: 0.22168069301458848 | validation: 0.18159886090024036]
	TIME [epoch: 33.2 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23006511147329878		[learning rate: 0.00053775]
	Learning Rate: 0.000537746
	LOSS [training: 0.23006511147329878 | validation: 0.1832259646916544]
	TIME [epoch: 33.2 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22784962113142754		[learning rate: 0.00053561]
	Learning Rate: 0.000535607
	LOSS [training: 0.22784962113142754 | validation: 0.1872579950362387]
	TIME [epoch: 33.2 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22989591868239628		[learning rate: 0.00053348]
	Learning Rate: 0.000533477
	LOSS [training: 0.22989591868239628 | validation: 0.1846630053309736]
	TIME [epoch: 33.2 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2203139285809743		[learning rate: 0.00053135]
	Learning Rate: 0.000531355
	LOSS [training: 0.2203139285809743 | validation: 0.18720781477990434]
	TIME [epoch: 33.2 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2167652737808749		[learning rate: 0.00052924]
	Learning Rate: 0.000529241
	LOSS [training: 0.2167652737808749 | validation: 0.18253913223802934]
	TIME [epoch: 33.2 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22871224860044675		[learning rate: 0.00052714]
	Learning Rate: 0.000527136
	LOSS [training: 0.22871224860044675 | validation: 0.1844274696022304]
	TIME [epoch: 33.2 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2237702084249015		[learning rate: 0.00052504]
	Learning Rate: 0.00052504
	LOSS [training: 0.2237702084249015 | validation: 0.19116055822495354]
	TIME [epoch: 33.2 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23284506861890486		[learning rate: 0.00052295]
	Learning Rate: 0.000522952
	LOSS [training: 0.23284506861890486 | validation: 0.19129208867663397]
	TIME [epoch: 33.2 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2221381406439756		[learning rate: 0.00052087]
	Learning Rate: 0.000520872
	LOSS [training: 0.2221381406439756 | validation: 0.18106460991382528]
	TIME [epoch: 33.2 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23271480985349177		[learning rate: 0.0005188]
	Learning Rate: 0.0005188
	LOSS [training: 0.23271480985349177 | validation: 0.18066833223100573]
	TIME [epoch: 33.2 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2173414620161861		[learning rate: 0.00051674]
	Learning Rate: 0.000516737
	LOSS [training: 0.2173414620161861 | validation: 0.19094156259036668]
	TIME [epoch: 33.2 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2280662622346454		[learning rate: 0.00051468]
	Learning Rate: 0.000514681
	LOSS [training: 0.2280662622346454 | validation: 0.18382130219688722]
	TIME [epoch: 33.2 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.21936265475747607		[learning rate: 0.00051263]
	Learning Rate: 0.000512634
	LOSS [training: 0.21936265475747607 | validation: 0.18890089378195535]
	TIME [epoch: 33.2 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22759848832171622		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 0.22759848832171622 | validation: 0.1941728160223229]
	TIME [epoch: 33.2 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22903520452638		[learning rate: 0.00050856]
	Learning Rate: 0.000508565
	LOSS [training: 0.22903520452638 | validation: 0.18278729119072037]
	TIME [epoch: 33.2 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23720216836191493		[learning rate: 0.00050654]
	Learning Rate: 0.000506542
	LOSS [training: 0.23720216836191493 | validation: 0.18292467937086926]
	TIME [epoch: 33.2 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2322790661964954		[learning rate: 0.00050453]
	Learning Rate: 0.000504527
	LOSS [training: 0.2322790661964954 | validation: 0.18617748240070736]
	TIME [epoch: 33.2 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22886709686482393		[learning rate: 0.00050252]
	Learning Rate: 0.000502521
	LOSS [training: 0.22886709686482393 | validation: 0.1848550452983118]
	TIME [epoch: 33.2 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23430092881653744		[learning rate: 0.00050052]
	Learning Rate: 0.000500522
	LOSS [training: 0.23430092881653744 | validation: 0.1750261117434563]
	TIME [epoch: 33.2 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v14_20240716_142610/states/model_facs_v2_dec1b_2dpca_v14_796.pth
	Model improved!!!
EPOCH 797/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2259569811177589		[learning rate: 0.00049853]
	Learning Rate: 0.000498531
	LOSS [training: 0.2259569811177589 | validation: 0.19262903031709153]
	TIME [epoch: 33.3 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22458873447897953		[learning rate: 0.00049655]
	Learning Rate: 0.000496548
	LOSS [training: 0.22458873447897953 | validation: 0.18823750524202187]
	TIME [epoch: 33.2 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22356177523911017		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 0.22356177523911017 | validation: 0.19137807130890355]
	TIME [epoch: 33.2 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2282891792178374		[learning rate: 0.00049261]
	Learning Rate: 0.000492606
	LOSS [training: 0.2282891792178374 | validation: 0.1875880243911176]
	TIME [epoch: 33.2 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22820182973696646		[learning rate: 0.00049065]
	Learning Rate: 0.000490647
	LOSS [training: 0.22820182973696646 | validation: 0.18989761055856658]
	TIME [epoch: 33.3 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23126037259207155		[learning rate: 0.0004887]
	Learning Rate: 0.000488696
	LOSS [training: 0.23126037259207155 | validation: 0.18437293594180898]
	TIME [epoch: 33.3 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22938726899654574		[learning rate: 0.00048675]
	Learning Rate: 0.000486752
	LOSS [training: 0.22938726899654574 | validation: 0.18252555172513835]
	TIME [epoch: 33.3 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.225098803680558		[learning rate: 0.00048482]
	Learning Rate: 0.000484816
	LOSS [training: 0.225098803680558 | validation: 0.1894444757659196]
	TIME [epoch: 33.2 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22174636795483676		[learning rate: 0.00048289]
	Learning Rate: 0.000482888
	LOSS [training: 0.22174636795483676 | validation: 0.18397307895369486]
	TIME [epoch: 33.2 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23142223879651289		[learning rate: 0.00048097]
	Learning Rate: 0.000480967
	LOSS [training: 0.23142223879651289 | validation: 0.18241042255985113]
	TIME [epoch: 33.2 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22837554348752928		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 0.22837554348752928 | validation: 0.18025171951236368]
	TIME [epoch: 33.3 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2323325394173409		[learning rate: 0.00047715]
	Learning Rate: 0.000477149
	LOSS [training: 0.2323325394173409 | validation: 0.19010798682270408]
	TIME [epoch: 33.3 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2261242169217662		[learning rate: 0.00047525]
	Learning Rate: 0.000475251
	LOSS [training: 0.2261242169217662 | validation: 0.18255543243575223]
	TIME [epoch: 33.3 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2273761733942308		[learning rate: 0.00047336]
	Learning Rate: 0.000473361
	LOSS [training: 0.2273761733942308 | validation: 0.18694649811075328]
	TIME [epoch: 33.3 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22717423595198508		[learning rate: 0.00047148]
	Learning Rate: 0.000471478
	LOSS [training: 0.22717423595198508 | validation: 0.18167449618712253]
	TIME [epoch: 33.3 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22298879530470694		[learning rate: 0.0004696]
	Learning Rate: 0.000469603
	LOSS [training: 0.22298879530470694 | validation: 0.19411803519796528]
	TIME [epoch: 33.3 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.21895307474693193		[learning rate: 0.00046774]
	Learning Rate: 0.000467735
	LOSS [training: 0.21895307474693193 | validation: 0.1866135351322032]
	TIME [epoch: 33.2 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22742011781195565		[learning rate: 0.00046587]
	Learning Rate: 0.000465875
	LOSS [training: 0.22742011781195565 | validation: 0.1917127706903905]
	TIME [epoch: 33.3 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22906335176916176		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 0.22906335176916176 | validation: 0.18704593811160203]
	TIME [epoch: 33.3 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22638214183959665		[learning rate: 0.00046218]
	Learning Rate: 0.000462176
	LOSS [training: 0.22638214183959665 | validation: 0.18856224609452793]
	TIME [epoch: 33.2 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22707221261798402		[learning rate: 0.00046034]
	Learning Rate: 0.000460338
	LOSS [training: 0.22707221261798402 | validation: 0.19422632450496846]
	TIME [epoch: 33.2 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2308570775985229		[learning rate: 0.00045851]
	Learning Rate: 0.000458507
	LOSS [training: 0.2308570775985229 | validation: 0.18423308275882794]
	TIME [epoch: 33.3 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22669309944147786		[learning rate: 0.00045668]
	Learning Rate: 0.000456684
	LOSS [training: 0.22669309944147786 | validation: 0.1904200753563929]
	TIME [epoch: 33.2 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23093863651723812		[learning rate: 0.00045487]
	Learning Rate: 0.000454867
	LOSS [training: 0.23093863651723812 | validation: 0.19521977542614385]
	TIME [epoch: 33.3 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2298533185297007		[learning rate: 0.00045306]
	Learning Rate: 0.000453058
	LOSS [training: 0.2298533185297007 | validation: 0.1946322166885641]
	TIME [epoch: 33.2 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23271569823214003		[learning rate: 0.00045126]
	Learning Rate: 0.000451256
	LOSS [training: 0.23271569823214003 | validation: 0.1864565633612788]
	TIME [epoch: 33.2 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22658347722275726		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 0.22658347722275726 | validation: 0.1949705631617469]
	TIME [epoch: 33.2 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22943873508167772		[learning rate: 0.00044767]
	Learning Rate: 0.000447674
	LOSS [training: 0.22943873508167772 | validation: 0.18915085213051852]
	TIME [epoch: 33.3 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22865222463442944		[learning rate: 0.00044589]
	Learning Rate: 0.000445893
	LOSS [training: 0.22865222463442944 | validation: 0.180876560587347]
	TIME [epoch: 33.2 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22490240951201665		[learning rate: 0.00044412]
	Learning Rate: 0.00044412
	LOSS [training: 0.22490240951201665 | validation: 0.19097995128904435]
	TIME [epoch: 33.3 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.219315690298336		[learning rate: 0.00044235]
	Learning Rate: 0.000442353
	LOSS [training: 0.219315690298336 | validation: 0.18096576582462928]
	TIME [epoch: 33.3 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22199851847433982		[learning rate: 0.00044059]
	Learning Rate: 0.000440594
	LOSS [training: 0.22199851847433982 | validation: 0.18858667848345195]
	TIME [epoch: 33.2 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22719204307646962		[learning rate: 0.00043884]
	Learning Rate: 0.000438842
	LOSS [training: 0.22719204307646962 | validation: 0.18343372851042056]
	TIME [epoch: 33.2 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22283699431571968		[learning rate: 0.0004371]
	Learning Rate: 0.000437096
	LOSS [training: 0.22283699431571968 | validation: 0.18575868676603421]
	TIME [epoch: 33.3 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.228797408344285		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 0.228797408344285 | validation: 0.1837943859523062]
	TIME [epoch: 33.2 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22633283300705054		[learning rate: 0.00043363]
	Learning Rate: 0.000433626
	LOSS [training: 0.22633283300705054 | validation: 0.18588820181040294]
	TIME [epoch: 33.2 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2241166048434859		[learning rate: 0.0004319]
	Learning Rate: 0.000431901
	LOSS [training: 0.2241166048434859 | validation: 0.18391635726749217]
	TIME [epoch: 33.2 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22839137489197928		[learning rate: 0.00043018]
	Learning Rate: 0.000430184
	LOSS [training: 0.22839137489197928 | validation: 0.18962892430860126]
	TIME [epoch: 33.3 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22558784847912078		[learning rate: 0.00042847]
	Learning Rate: 0.000428473
	LOSS [training: 0.22558784847912078 | validation: 0.18572674016298513]
	TIME [epoch: 33.3 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23074555710272696		[learning rate: 0.00042677]
	Learning Rate: 0.000426768
	LOSS [training: 0.23074555710272696 | validation: 0.19132738759089019]
	TIME [epoch: 33.3 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2286992878814496		[learning rate: 0.00042507]
	Learning Rate: 0.000425071
	LOSS [training: 0.2286992878814496 | validation: 0.1911572405291331]
	TIME [epoch: 33.3 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23234315583819332		[learning rate: 0.00042338]
	Learning Rate: 0.00042338
	LOSS [training: 0.23234315583819332 | validation: 0.1935714583776777]
	TIME [epoch: 33.3 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.21869399569275103		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 0.21869399569275103 | validation: 0.18442529228822485]
	TIME [epoch: 33.2 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23141640654859075		[learning rate: 0.00042002]
	Learning Rate: 0.000420019
	LOSS [training: 0.23141640654859075 | validation: 0.19070896892095557]
	TIME [epoch: 33.3 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.21977080890538572		[learning rate: 0.00041835]
	Learning Rate: 0.000418349
	LOSS [training: 0.21977080890538572 | validation: 0.1854867853525707]
	TIME [epoch: 33.3 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22469372922721917		[learning rate: 0.00041668]
	Learning Rate: 0.000416685
	LOSS [training: 0.22469372922721917 | validation: 0.18702174574304778]
	TIME [epoch: 33.3 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22732406987273102		[learning rate: 0.00041503]
	Learning Rate: 0.000415028
	LOSS [training: 0.22732406987273102 | validation: 0.19211517877923204]
	TIME [epoch: 33.2 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2242165063730303		[learning rate: 0.00041338]
	Learning Rate: 0.000413377
	LOSS [training: 0.2242165063730303 | validation: 0.1846541804506498]
	TIME [epoch: 33.3 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2217644059555062		[learning rate: 0.00041173]
	Learning Rate: 0.000411733
	LOSS [training: 0.2217644059555062 | validation: 0.18851268099133517]
	TIME [epoch: 33.3 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2266729442100494		[learning rate: 0.0004101]
	Learning Rate: 0.000410095
	LOSS [training: 0.2266729442100494 | validation: 0.1893408959238568]
	TIME [epoch: 33.3 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22525557373075966		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 0.22525557373075966 | validation: 0.19517637147411043]
	TIME [epoch: 33.2 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22498488960029256		[learning rate: 0.00040684]
	Learning Rate: 0.00040684
	LOSS [training: 0.22498488960029256 | validation: 0.1870723069085555]
	TIME [epoch: 33.3 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2219788224443897		[learning rate: 0.00040522]
	Learning Rate: 0.000405221
	LOSS [training: 0.2219788224443897 | validation: 0.18771560296531903]
	TIME [epoch: 33.3 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2218705642597239		[learning rate: 0.00040361]
	Learning Rate: 0.00040361
	LOSS [training: 0.2218705642597239 | validation: 0.19026395162741086]
	TIME [epoch: 33.3 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2269916174424953		[learning rate: 0.000402]
	Learning Rate: 0.000402004
	LOSS [training: 0.2269916174424953 | validation: 0.19346323458938552]
	TIME [epoch: 33.3 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2270496607715789		[learning rate: 0.00040041]
	Learning Rate: 0.000400406
	LOSS [training: 0.2270496607715789 | validation: 0.1849799314350065]
	TIME [epoch: 33.3 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2250656011484194		[learning rate: 0.00039881]
	Learning Rate: 0.000398813
	LOSS [training: 0.2250656011484194 | validation: 0.18418225607345579]
	TIME [epoch: 33.3 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22152415754711033		[learning rate: 0.00039723]
	Learning Rate: 0.000397227
	LOSS [training: 0.22152415754711033 | validation: 0.19063651733569958]
	TIME [epoch: 33.2 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22872915072396324		[learning rate: 0.00039565]
	Learning Rate: 0.000395647
	LOSS [training: 0.22872915072396324 | validation: 0.1853509759938341]
	TIME [epoch: 33.3 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23139491460880032		[learning rate: 0.00039407]
	Learning Rate: 0.000394073
	LOSS [training: 0.23139491460880032 | validation: 0.1938847916905283]
	TIME [epoch: 33.3 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22452533825377088		[learning rate: 0.00039251]
	Learning Rate: 0.000392506
	LOSS [training: 0.22452533825377088 | validation: 0.18767880680569618]
	TIME [epoch: 33.3 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22889856582965334		[learning rate: 0.00039094]
	Learning Rate: 0.000390945
	LOSS [training: 0.22889856582965334 | validation: 0.18480203923682262]
	TIME [epoch: 33.3 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.21891834213004094		[learning rate: 0.00038939]
	Learning Rate: 0.00038939
	LOSS [training: 0.21891834213004094 | validation: 0.18441670690351952]
	TIME [epoch: 33.3 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2275320939874389		[learning rate: 0.00038784]
	Learning Rate: 0.000387841
	LOSS [training: 0.2275320939874389 | validation: 0.18430869210278084]
	TIME [epoch: 33.3 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2193716420022467		[learning rate: 0.0003863]
	Learning Rate: 0.000386299
	LOSS [training: 0.2193716420022467 | validation: 0.18434467219724476]
	TIME [epoch: 33.3 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22719520214703687		[learning rate: 0.00038476]
	Learning Rate: 0.000384762
	LOSS [training: 0.22719520214703687 | validation: 0.18011128202943158]
	TIME [epoch: 33.3 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22512618892282354		[learning rate: 0.00038323]
	Learning Rate: 0.000383232
	LOSS [training: 0.22512618892282354 | validation: 0.18813271997123385]
	TIME [epoch: 33.3 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22998645432978304		[learning rate: 0.00038171]
	Learning Rate: 0.000381708
	LOSS [training: 0.22998645432978304 | validation: 0.1823405729191229]
	TIME [epoch: 33.3 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22602334269100133		[learning rate: 0.00038019]
	Learning Rate: 0.000380189
	LOSS [training: 0.22602334269100133 | validation: 0.18985077695901015]
	TIME [epoch: 33.3 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2269056730495221		[learning rate: 0.00037868]
	Learning Rate: 0.000378677
	LOSS [training: 0.2269056730495221 | validation: 0.17875761126368853]
	TIME [epoch: 33.3 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2244558140341773		[learning rate: 0.00037717]
	Learning Rate: 0.000377171
	LOSS [training: 0.2244558140341773 | validation: 0.1882274977513973]
	TIME [epoch: 33.3 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23128253918411446		[learning rate: 0.00037567]
	Learning Rate: 0.000375671
	LOSS [training: 0.23128253918411446 | validation: 0.19068749664959736]
	TIME [epoch: 33.3 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23045144730197295		[learning rate: 0.00037418]
	Learning Rate: 0.000374177
	LOSS [training: 0.23045144730197295 | validation: 0.1831009285242418]
	TIME [epoch: 33.2 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22608863218901595		[learning rate: 0.00037269]
	Learning Rate: 0.000372689
	LOSS [training: 0.22608863218901595 | validation: 0.18699276597382147]
	TIME [epoch: 33.2 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23077554278064527		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 0.23077554278064527 | validation: 0.18395195861283214]
	TIME [epoch: 33.2 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22697412271756218		[learning rate: 0.00036973]
	Learning Rate: 0.00036973
	LOSS [training: 0.22697412271756218 | validation: 0.18928630095381282]
	TIME [epoch: 33.2 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22404817731376733		[learning rate: 0.00036826]
	Learning Rate: 0.000368259
	LOSS [training: 0.22404817731376733 | validation: 0.19028432402711498]
	TIME [epoch: 33.3 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22925085737132372		[learning rate: 0.00036679]
	Learning Rate: 0.000366795
	LOSS [training: 0.22925085737132372 | validation: 0.19480272316257136]
	TIME [epoch: 33.3 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22142025698363216		[learning rate: 0.00036534]
	Learning Rate: 0.000365336
	LOSS [training: 0.22142025698363216 | validation: 0.18859229037617808]
	TIME [epoch: 33.2 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22625655343997753		[learning rate: 0.00036388]
	Learning Rate: 0.000363883
	LOSS [training: 0.22625655343997753 | validation: 0.19188170775259875]
	TIME [epoch: 33.2 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22916529128972585		[learning rate: 0.00036244]
	Learning Rate: 0.000362436
	LOSS [training: 0.22916529128972585 | validation: 0.18244414025942174]
	TIME [epoch: 33.2 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22392344083951288		[learning rate: 0.00036099]
	Learning Rate: 0.000360994
	LOSS [training: 0.22392344083951288 | validation: 0.18845289955425798]
	TIME [epoch: 33.2 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22541152931640904		[learning rate: 0.00035956]
	Learning Rate: 0.000359558
	LOSS [training: 0.22541152931640904 | validation: 0.18445327865053907]
	TIME [epoch: 33.3 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22903265942327808		[learning rate: 0.00035813]
	Learning Rate: 0.000358128
	LOSS [training: 0.22903265942327808 | validation: 0.19004220499149996]
	TIME [epoch: 33.3 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22042859906407353		[learning rate: 0.0003567]
	Learning Rate: 0.000356704
	LOSS [training: 0.22042859906407353 | validation: 0.18607034188334587]
	TIME [epoch: 33.3 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22517914751815285		[learning rate: 0.00035529]
	Learning Rate: 0.000355285
	LOSS [training: 0.22517914751815285 | validation: 0.18122404056359978]
	TIME [epoch: 33.4 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22105470527236337		[learning rate: 0.00035387]
	Learning Rate: 0.000353872
	LOSS [training: 0.22105470527236337 | validation: 0.18257045362419116]
	TIME [epoch: 33.2 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23084935234190274		[learning rate: 0.00035246]
	Learning Rate: 0.000352465
	LOSS [training: 0.23084935234190274 | validation: 0.18333112033256266]
	TIME [epoch: 33.3 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23081567236212772		[learning rate: 0.00035106]
	Learning Rate: 0.000351063
	LOSS [training: 0.23081567236212772 | validation: 0.18373375206628062]
	TIME [epoch: 33.3 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22935219891844266		[learning rate: 0.00034967]
	Learning Rate: 0.000349666
	LOSS [training: 0.22935219891844266 | validation: 0.18802821297457145]
	TIME [epoch: 33.3 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.21671827173149294		[learning rate: 0.00034828]
	Learning Rate: 0.000348276
	LOSS [training: 0.21671827173149294 | validation: 0.1900657826863497]
	TIME [epoch: 33.2 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2223742578539246		[learning rate: 0.00034689]
	Learning Rate: 0.000346891
	LOSS [training: 0.2223742578539246 | validation: 0.18626108777528863]
	TIME [epoch: 33.3 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2239236195633699		[learning rate: 0.00034551]
	Learning Rate: 0.000345511
	LOSS [training: 0.2239236195633699 | validation: 0.19463854392827779]
	TIME [epoch: 33.3 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22643025506951597		[learning rate: 0.00034414]
	Learning Rate: 0.000344137
	LOSS [training: 0.22643025506951597 | validation: 0.18361748900896205]
	TIME [epoch: 33.3 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2220894364948953		[learning rate: 0.00034277]
	Learning Rate: 0.000342768
	LOSS [training: 0.2220894364948953 | validation: 0.18142473688844968]
	TIME [epoch: 33.3 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22655211570526523		[learning rate: 0.0003414]
	Learning Rate: 0.000341405
	LOSS [training: 0.22655211570526523 | validation: 0.19171411055650805]
	TIME [epoch: 33.2 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2308335543747179		[learning rate: 0.00034005]
	Learning Rate: 0.000340047
	LOSS [training: 0.2308335543747179 | validation: 0.1820038035355168]
	TIME [epoch: 33.2 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22865314045908308		[learning rate: 0.00033869]
	Learning Rate: 0.000338694
	LOSS [training: 0.22865314045908308 | validation: 0.1930523547734181]
	TIME [epoch: 33.3 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22446830819595742		[learning rate: 0.00033735]
	Learning Rate: 0.000337347
	LOSS [training: 0.22446830819595742 | validation: 0.1864199745588178]
	TIME [epoch: 33.2 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22205335666743448		[learning rate: 0.00033601]
	Learning Rate: 0.000336005
	LOSS [training: 0.22205335666743448 | validation: 0.18685330738091138]
	TIME [epoch: 33.2 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22513891883301834		[learning rate: 0.00033467]
	Learning Rate: 0.000334669
	LOSS [training: 0.22513891883301834 | validation: 0.1771947419792314]
	TIME [epoch: 33.3 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22737158421798906		[learning rate: 0.00033334]
	Learning Rate: 0.000333338
	LOSS [training: 0.22737158421798906 | validation: 0.1832145860646442]
	TIME [epoch: 33.2 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22494861203157837		[learning rate: 0.00033201]
	Learning Rate: 0.000332012
	LOSS [training: 0.22494861203157837 | validation: 0.1877275384049764]
	TIME [epoch: 33.3 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22481147181744177		[learning rate: 0.00033069]
	Learning Rate: 0.000330692
	LOSS [training: 0.22481147181744177 | validation: 0.19102784043493443]
	TIME [epoch: 33.2 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2267710522337902		[learning rate: 0.00032938]
	Learning Rate: 0.000329376
	LOSS [training: 0.2267710522337902 | validation: 0.18329936752378914]
	TIME [epoch: 33.3 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.21637025606929713		[learning rate: 0.00032807]
	Learning Rate: 0.000328066
	LOSS [training: 0.21637025606929713 | validation: 0.184026203136268]
	TIME [epoch: 33.3 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22152773996361583		[learning rate: 0.00032676]
	Learning Rate: 0.000326761
	LOSS [training: 0.22152773996361583 | validation: 0.18698789290852463]
	TIME [epoch: 33.2 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22769845865746202		[learning rate: 0.00032546]
	Learning Rate: 0.000325462
	LOSS [training: 0.22769845865746202 | validation: 0.188828385956556]
	TIME [epoch: 33.3 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.223609998846012		[learning rate: 0.00032417]
	Learning Rate: 0.000324167
	LOSS [training: 0.223609998846012 | validation: 0.1830688819707612]
	TIME [epoch: 33.3 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22422886685121776		[learning rate: 0.00032288]
	Learning Rate: 0.000322878
	LOSS [training: 0.22422886685121776 | validation: 0.18634693643775085]
	TIME [epoch: 33.3 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23429454193363622		[learning rate: 0.00032159]
	Learning Rate: 0.000321594
	LOSS [training: 0.23429454193363622 | validation: 0.1860022227006438]
	TIME [epoch: 33.3 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22288633595160226		[learning rate: 0.00032031]
	Learning Rate: 0.000320315
	LOSS [training: 0.22288633595160226 | validation: 0.1791213006699952]
	TIME [epoch: 33.3 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24334486079265372		[learning rate: 0.00031904]
	Learning Rate: 0.000319041
	LOSS [training: 0.24334486079265372 | validation: 0.18133518030100265]
	TIME [epoch: 33.3 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.21670709805806979		[learning rate: 0.00031777]
	Learning Rate: 0.000317772
	LOSS [training: 0.21670709805806979 | validation: 0.1882640761536574]
	TIME [epoch: 33.3 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.217678413259678		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 0.217678413259678 | validation: 0.1900159349280232]
	TIME [epoch: 33.3 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2287544980166907		[learning rate: 0.00031525]
	Learning Rate: 0.000315249
	LOSS [training: 0.2287544980166907 | validation: 0.18177462537421507]
	TIME [epoch: 33.3 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22946614236455012		[learning rate: 0.000314]
	Learning Rate: 0.000313995
	LOSS [training: 0.22946614236455012 | validation: 0.19228221918746488]
	TIME [epoch: 33.3 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2243444043035693		[learning rate: 0.00031275]
	Learning Rate: 0.000312746
	LOSS [training: 0.2243444043035693 | validation: 0.18898552342871563]
	TIME [epoch: 33.3 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22722717021952915		[learning rate: 0.0003115]
	Learning Rate: 0.000311503
	LOSS [training: 0.22722717021952915 | validation: 0.18095098338587967]
	TIME [epoch: 33.3 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22125336102513257		[learning rate: 0.00031026]
	Learning Rate: 0.000310264
	LOSS [training: 0.22125336102513257 | validation: 0.18585066122061822]
	TIME [epoch: 33.3 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.21922979385658026		[learning rate: 0.00030903]
	Learning Rate: 0.00030903
	LOSS [training: 0.21922979385658026 | validation: 0.18515947030749746]
	TIME [epoch: 33.3 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2289442135854249		[learning rate: 0.0003078]
	Learning Rate: 0.0003078
	LOSS [training: 0.2289442135854249 | validation: 0.18542353520813887]
	TIME [epoch: 33.3 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.21815174649775557		[learning rate: 0.00030658]
	Learning Rate: 0.000306576
	LOSS [training: 0.21815174649775557 | validation: 0.18644203037533025]
	TIME [epoch: 33.3 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22556723772146675		[learning rate: 0.00030536]
	Learning Rate: 0.000305357
	LOSS [training: 0.22556723772146675 | validation: 0.18314774763679192]
	TIME [epoch: 33.3 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22629975819213646		[learning rate: 0.00030414]
	Learning Rate: 0.000304142
	LOSS [training: 0.22629975819213646 | validation: 0.18661684270273265]
	TIME [epoch: 33.3 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2270167976238399		[learning rate: 0.00030293]
	Learning Rate: 0.000302933
	LOSS [training: 0.2270167976238399 | validation: 0.18891274108100448]
	TIME [epoch: 33.3 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2198778931887948		[learning rate: 0.00030173]
	Learning Rate: 0.000301728
	LOSS [training: 0.2198778931887948 | validation: 0.18339837075665244]
	TIME [epoch: 33.3 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2243430288475746		[learning rate: 0.00030053]
	Learning Rate: 0.000300528
	LOSS [training: 0.2243430288475746 | validation: 0.18624274941530203]
	TIME [epoch: 33.3 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2241042967196106		[learning rate: 0.00029933]
	Learning Rate: 0.000299333
	LOSS [training: 0.2241042967196106 | validation: 0.18867658186015815]
	TIME [epoch: 33.3 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22287856605034861		[learning rate: 0.00029814]
	Learning Rate: 0.000298142
	LOSS [training: 0.22287856605034861 | validation: 0.1828022165554813]
	TIME [epoch: 33.3 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2228171813654993		[learning rate: 0.00029696]
	Learning Rate: 0.000296956
	LOSS [training: 0.2228171813654993 | validation: 0.19246404373004483]
	TIME [epoch: 33.3 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22315779342107803		[learning rate: 0.00029578]
	Learning Rate: 0.000295775
	LOSS [training: 0.22315779342107803 | validation: 0.19004302878652776]
	TIME [epoch: 33.3 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23182413895483236		[learning rate: 0.0002946]
	Learning Rate: 0.000294599
	LOSS [training: 0.23182413895483236 | validation: 0.18077138915447125]
	TIME [epoch: 33.3 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23251200001180194		[learning rate: 0.00029343]
	Learning Rate: 0.000293427
	LOSS [training: 0.23251200001180194 | validation: 0.18493269666092804]
	TIME [epoch: 33.3 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22071207878613164		[learning rate: 0.00029226]
	Learning Rate: 0.00029226
	LOSS [training: 0.22071207878613164 | validation: 0.18188387849320722]
	TIME [epoch: 33.3 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2309436764186637		[learning rate: 0.0002911]
	Learning Rate: 0.000291098
	LOSS [training: 0.2309436764186637 | validation: 0.1897125354284833]
	TIME [epoch: 33.3 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2202298491033624		[learning rate: 0.00028994]
	Learning Rate: 0.00028994
	LOSS [training: 0.2202298491033624 | validation: 0.1872896770429131]
	TIME [epoch: 33.3 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22842578324905627		[learning rate: 0.00028879]
	Learning Rate: 0.000288786
	LOSS [training: 0.22842578324905627 | validation: 0.18416553857180024]
	TIME [epoch: 33.3 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22705749052219593		[learning rate: 0.00028764]
	Learning Rate: 0.000287638
	LOSS [training: 0.22705749052219593 | validation: 0.1827558288356756]
	TIME [epoch: 33.3 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22780627341981383		[learning rate: 0.00028649]
	Learning Rate: 0.000286494
	LOSS [training: 0.22780627341981383 | validation: 0.18759918461972366]
	TIME [epoch: 33.3 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23275553468748067		[learning rate: 0.00028535]
	Learning Rate: 0.000285354
	LOSS [training: 0.23275553468748067 | validation: 0.19222616317121968]
	TIME [epoch: 33.3 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22800864860893233		[learning rate: 0.00028422]
	Learning Rate: 0.00028422
	LOSS [training: 0.22800864860893233 | validation: 0.18207786138561496]
	TIME [epoch: 33.3 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2241854213722877		[learning rate: 0.00028309]
	Learning Rate: 0.000283089
	LOSS [training: 0.2241854213722877 | validation: 0.18167038447927783]
	TIME [epoch: 33.3 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22668164507165495		[learning rate: 0.00028196]
	Learning Rate: 0.000281963
	LOSS [training: 0.22668164507165495 | validation: 0.18425976665529997]
	TIME [epoch: 33.4 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24368508249184964		[learning rate: 0.00028084]
	Learning Rate: 0.000280842
	LOSS [training: 0.24368508249184964 | validation: 0.1906871353554313]
	TIME [epoch: 33.3 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22043817304519486		[learning rate: 0.00027972]
	Learning Rate: 0.000279725
	LOSS [training: 0.22043817304519486 | validation: 0.18865670164960366]
	TIME [epoch: 33.3 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22802754825561544		[learning rate: 0.00027861]
	Learning Rate: 0.000278612
	LOSS [training: 0.22802754825561544 | validation: 0.19007585564762952]
	TIME [epoch: 33.3 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.223517998125376		[learning rate: 0.0002775]
	Learning Rate: 0.000277504
	LOSS [training: 0.223517998125376 | validation: 0.17928392329577494]
	TIME [epoch: 33.3 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22132803414029623		[learning rate: 0.0002764]
	Learning Rate: 0.0002764
	LOSS [training: 0.22132803414029623 | validation: 0.19609248271942487]
	TIME [epoch: 33.3 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22604029403807424		[learning rate: 0.0002753]
	Learning Rate: 0.000275301
	LOSS [training: 0.22604029403807424 | validation: 0.18409131569723852]
	TIME [epoch: 33.3 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22665962014430427		[learning rate: 0.00027421]
	Learning Rate: 0.000274206
	LOSS [training: 0.22665962014430427 | validation: 0.18728241384950867]
	TIME [epoch: 33.3 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2301284523577072		[learning rate: 0.00027312]
	Learning Rate: 0.000273115
	LOSS [training: 0.2301284523577072 | validation: 0.19094737583888685]
	TIME [epoch: 33.3 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22856798123542157		[learning rate: 0.00027203]
	Learning Rate: 0.000272029
	LOSS [training: 0.22856798123542157 | validation: 0.1868662146445134]
	TIME [epoch: 33.3 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22799596408792372		[learning rate: 0.00027095]
	Learning Rate: 0.000270947
	LOSS [training: 0.22799596408792372 | validation: 0.18421373784457815]
	TIME [epoch: 33.3 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22023011531541148		[learning rate: 0.00026987]
	Learning Rate: 0.00026987
	LOSS [training: 0.22023011531541148 | validation: 0.17929737568799836]
	TIME [epoch: 33.3 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22661025558467784		[learning rate: 0.0002688]
	Learning Rate: 0.000268796
	LOSS [training: 0.22661025558467784 | validation: 0.18086336986969626]
	TIME [epoch: 33.3 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22999012009287803		[learning rate: 0.00026773]
	Learning Rate: 0.000267727
	LOSS [training: 0.22999012009287803 | validation: 0.18231348267093034]
	TIME [epoch: 33.3 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2222578201075243		[learning rate: 0.00026666]
	Learning Rate: 0.000266662
	LOSS [training: 0.2222578201075243 | validation: 0.18721516829144827]
	TIME [epoch: 33.3 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22839266642043882		[learning rate: 0.0002656]
	Learning Rate: 0.000265602
	LOSS [training: 0.22839266642043882 | validation: 0.19059023541991565]
	TIME [epoch: 33.3 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22739302634321643		[learning rate: 0.00026455]
	Learning Rate: 0.000264545
	LOSS [training: 0.22739302634321643 | validation: 0.18221934033939574]
	TIME [epoch: 33.3 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22417705683068856		[learning rate: 0.00026349]
	Learning Rate: 0.000263493
	LOSS [training: 0.22417705683068856 | validation: 0.1898867217919792]
	TIME [epoch: 33.3 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.21904067626859425		[learning rate: 0.00026245]
	Learning Rate: 0.000262445
	LOSS [training: 0.21904067626859425 | validation: 0.18378440819112496]
	TIME [epoch: 33.3 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2256525018418805		[learning rate: 0.0002614]
	Learning Rate: 0.000261401
	LOSS [training: 0.2256525018418805 | validation: 0.18707418360497946]
	TIME [epoch: 33.3 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2251220006335181		[learning rate: 0.00026036]
	Learning Rate: 0.000260362
	LOSS [training: 0.2251220006335181 | validation: 0.1807506208163397]
	TIME [epoch: 33.3 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22211366848283193		[learning rate: 0.00025933]
	Learning Rate: 0.000259326
	LOSS [training: 0.22211366848283193 | validation: 0.19091196004437008]
	TIME [epoch: 33.3 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2227687525248201		[learning rate: 0.00025829]
	Learning Rate: 0.000258295
	LOSS [training: 0.2227687525248201 | validation: 0.1849518540850513]
	TIME [epoch: 33.3 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2303699366729025		[learning rate: 0.00025727]
	Learning Rate: 0.000257267
	LOSS [training: 0.2303699366729025 | validation: 0.18879994949883946]
	TIME [epoch: 33.3 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22805684177261984		[learning rate: 0.00025624]
	Learning Rate: 0.000256244
	LOSS [training: 0.22805684177261984 | validation: 0.18577795696834015]
	TIME [epoch: 33.3 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2339629473222279		[learning rate: 0.00025522]
	Learning Rate: 0.000255225
	LOSS [training: 0.2339629473222279 | validation: 0.18840341998539742]
	TIME [epoch: 33.3 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2294842850209684		[learning rate: 0.00025421]
	Learning Rate: 0.00025421
	LOSS [training: 0.2294842850209684 | validation: 0.1809380463349907]
	TIME [epoch: 33.3 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22250198561009263		[learning rate: 0.0002532]
	Learning Rate: 0.000253199
	LOSS [training: 0.22250198561009263 | validation: 0.18170819259782803]
	TIME [epoch: 33.3 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23289551994825405		[learning rate: 0.00025219]
	Learning Rate: 0.000252192
	LOSS [training: 0.23289551994825405 | validation: 0.1871098686238427]
	TIME [epoch: 33.3 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22149415320876908		[learning rate: 0.00025119]
	Learning Rate: 0.000251189
	LOSS [training: 0.22149415320876908 | validation: 0.1865187345084493]
	TIME [epoch: 33.2 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22989297252220625		[learning rate: 0.00025019]
	Learning Rate: 0.00025019
	LOSS [training: 0.22989297252220625 | validation: 0.18970665916601306]
	TIME [epoch: 33.3 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2258618354386357		[learning rate: 0.00024919]
	Learning Rate: 0.000249195
	LOSS [training: 0.2258618354386357 | validation: 0.1804679070235266]
	TIME [epoch: 33.3 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2310487427650466		[learning rate: 0.0002482]
	Learning Rate: 0.000248203
	LOSS [training: 0.2310487427650466 | validation: 0.1915437141868564]
	TIME [epoch: 33.3 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22035796622425344		[learning rate: 0.00024722]
	Learning Rate: 0.000247216
	LOSS [training: 0.22035796622425344 | validation: 0.1903049933311489]
	TIME [epoch: 33.3 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2311828178168935		[learning rate: 0.00024623]
	Learning Rate: 0.000246233
	LOSS [training: 0.2311828178168935 | validation: 0.18265551097996022]
	TIME [epoch: 33.3 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2206954400192134		[learning rate: 0.00024525]
	Learning Rate: 0.000245254
	LOSS [training: 0.2206954400192134 | validation: 0.19136772461598106]
	TIME [epoch: 33.3 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.223981411059198		[learning rate: 0.00024428]
	Learning Rate: 0.000244278
	LOSS [training: 0.223981411059198 | validation: 0.19151379257874113]
	TIME [epoch: 33.3 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23281800257771146		[learning rate: 0.00024331]
	Learning Rate: 0.000243307
	LOSS [training: 0.23281800257771146 | validation: 0.18332845390475142]
	TIME [epoch: 33.3 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22746146166265058		[learning rate: 0.00024234]
	Learning Rate: 0.000242339
	LOSS [training: 0.22746146166265058 | validation: 0.19170151399689708]
	TIME [epoch: 33.3 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22505935263515164		[learning rate: 0.00024138]
	Learning Rate: 0.000241375
	LOSS [training: 0.22505935263515164 | validation: 0.1799628353310958]
	TIME [epoch: 33.2 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23460397445559578		[learning rate: 0.00024042]
	Learning Rate: 0.000240415
	LOSS [training: 0.23460397445559578 | validation: 0.18027620247144666]
	TIME [epoch: 33.3 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2282834868030026		[learning rate: 0.00023946]
	Learning Rate: 0.000239459
	LOSS [training: 0.2282834868030026 | validation: 0.18730466545915134]
	TIME [epoch: 33.2 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22447374202930515		[learning rate: 0.00023851]
	Learning Rate: 0.000238506
	LOSS [training: 0.22447374202930515 | validation: 0.19710482148215183]
	TIME [epoch: 33.3 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2300102908688872		[learning rate: 0.00023756]
	Learning Rate: 0.000237558
	LOSS [training: 0.2300102908688872 | validation: 0.18929527210563984]
	TIME [epoch: 33.2 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22430738737043368		[learning rate: 0.00023661]
	Learning Rate: 0.000236613
	LOSS [training: 0.22430738737043368 | validation: 0.19321579171343226]
	TIME [epoch: 33.3 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22144066192478873		[learning rate: 0.00023567]
	Learning Rate: 0.000235672
	LOSS [training: 0.22144066192478873 | validation: 0.18618260989369204]
	TIME [epoch: 33.3 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22098612835788828		[learning rate: 0.00023473]
	Learning Rate: 0.000234735
	LOSS [training: 0.22098612835788828 | validation: 0.1872272690144599]
	TIME [epoch: 33.3 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22517558036538438		[learning rate: 0.0002338]
	Learning Rate: 0.000233801
	LOSS [training: 0.22517558036538438 | validation: 0.18381549214548284]
	TIME [epoch: 33.3 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.21539359792504006		[learning rate: 0.00023287]
	Learning Rate: 0.000232871
	LOSS [training: 0.21539359792504006 | validation: 0.19331920197088692]
	TIME [epoch: 33.3 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.21933759817603354		[learning rate: 0.00023194]
	Learning Rate: 0.000231945
	LOSS [training: 0.21933759817603354 | validation: 0.1860192536017165]
	TIME [epoch: 33.2 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2307125240050668		[learning rate: 0.00023102]
	Learning Rate: 0.000231022
	LOSS [training: 0.2307125240050668 | validation: 0.19180869666217998]
	TIME [epoch: 33.2 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2302539989376419		[learning rate: 0.0002301]
	Learning Rate: 0.000230103
	LOSS [training: 0.2302539989376419 | validation: 0.18953250535301816]
	TIME [epoch: 33.3 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22855810043336916		[learning rate: 0.00022919]
	Learning Rate: 0.000229188
	LOSS [training: 0.22855810043336916 | validation: 0.1912224840841691]
	TIME [epoch: 33.3 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22271053309125685		[learning rate: 0.00022828]
	Learning Rate: 0.000228277
	LOSS [training: 0.22271053309125685 | validation: 0.19188767556187716]
	TIME [epoch: 33.3 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22449330883866608		[learning rate: 0.00022737]
	Learning Rate: 0.000227369
	LOSS [training: 0.22449330883866608 | validation: 0.18422155874175694]
	TIME [epoch: 33.3 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2249406040499392		[learning rate: 0.00022646]
	Learning Rate: 0.000226464
	LOSS [training: 0.2249406040499392 | validation: 0.18275546491675465]
	TIME [epoch: 33.2 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2274698919936247		[learning rate: 0.00022556]
	Learning Rate: 0.000225564
	LOSS [training: 0.2274698919936247 | validation: 0.1883728129061219]
	TIME [epoch: 33.3 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22751253426855206		[learning rate: 0.00022467]
	Learning Rate: 0.000224667
	LOSS [training: 0.22751253426855206 | validation: 0.18638127201660035]
	TIME [epoch: 33.3 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v14_20240716_142610/states/model_facs_v2_dec1b_2dpca_v14_997.pth
Halted early. No improvement in validation loss for 200 epochs.
Finished training in 23996.583 seconds.
