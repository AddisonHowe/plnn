Args:
Namespace(name='model_facs_v4_dec2b_2dpca_v14', outdir='out/model_training/model_facs_v4_dec2b_2dpca_v14', training_data='data/training_data/facs_v4/pca/dec2_fitonsubset/transition2_subset_ce_pn_m_pc12/training', validation_data='data/training_data/facs_v4/pca/dec2_fitonsubset/transition2_subset_ce_pn_m_pc12/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=10, batch_size=50, patience=200, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, quadratic_a=1.0, quadratic_b=1.0, ndims=2, nparams=2, nsigs=2, ncells=200, ncells_sample=200, model_do_sample=False, dt=0.005, dt_schedule='stepped', dt_schedule_bounds=[50, 500, 1000], dt_schedule_scales=[0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', kernel='multiscale', bw_range=[0.2, 0.5, 0.9, 1.1, 1.3, 1.5, 2.0], optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 2355489558

Training model...

Saving initial model state to: out/model_training/model_facs_v4_dec2b_2dpca_v14_20240719_004707/states/model_facs_v4_dec2b_2dpca_v14_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8944516443915705		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8944516443915705 | validation: 0.9944678159502279]
	TIME [epoch: 30.8 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v14_20240719_004707/states/model_facs_v4_dec2b_2dpca_v14_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7526328110838193		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7526328110838193 | validation: 0.9223291423665125]
	TIME [epoch: 3.98 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v14_20240719_004707/states/model_facs_v4_dec2b_2dpca_v14_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6385155560018838		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6385155560018838 | validation: 0.8117814625397699]
	TIME [epoch: 3.96 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v14_20240719_004707/states/model_facs_v4_dec2b_2dpca_v14_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5749360446795346		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5749360446795346 | validation: 0.8614302750599213]
	TIME [epoch: 3.96 sec]
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7036960177439843		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7036960177439843 | validation: 0.7145656567066714]
	TIME [epoch: 3.96 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v14_20240719_004707/states/model_facs_v4_dec2b_2dpca_v14_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5326026921950524		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5326026921950524 | validation: 0.7418300802879009]
	TIME [epoch: 3.96 sec]
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4839197215613261		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4839197215613261 | validation: 0.6405188219213419]
	TIME [epoch: 3.95 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v14_20240719_004707/states/model_facs_v4_dec2b_2dpca_v14_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43595800492279363		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.43595800492279363 | validation: 0.6826792947533137]
	TIME [epoch: 3.98 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44313877021926723		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.44313877021926723 | validation: 0.7049385134426951]
	TIME [epoch: 3.96 sec]
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4915543697029753		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4915543697029753 | validation: 0.5899238344721334]
	TIME [epoch: 3.97 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v14_20240719_004707/states/model_facs_v4_dec2b_2dpca_v14_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36042376977984036		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.36042376977984036 | validation: 0.5524158878799397]
	TIME [epoch: 3.96 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v14_20240719_004707/states/model_facs_v4_dec2b_2dpca_v14_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39149980179463006		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.39149980179463006 | validation: 0.8312921983916716]
	TIME [epoch: 3.96 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5641108633104397		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5641108633104397 | validation: 0.5485729073537444]
	TIME [epoch: 3.95 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v14_20240719_004707/states/model_facs_v4_dec2b_2dpca_v14_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3602698572386129		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3602698572386129 | validation: 0.5758121558331004]
	TIME [epoch: 3.95 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4189165669212841		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4189165669212841 | validation: 0.516466490521027]
	TIME [epoch: 3.96 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v14_20240719_004707/states/model_facs_v4_dec2b_2dpca_v14_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3090907690548207		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3090907690548207 | validation: 0.5307011121744103]
	TIME [epoch: 3.96 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3450040034444728		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3450040034444728 | validation: 0.5112366484045022]
	TIME [epoch: 3.95 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v14_20240719_004707/states/model_facs_v4_dec2b_2dpca_v14_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35090574676226416		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.35090574676226416 | validation: 0.42547035457981347]
	TIME [epoch: 3.96 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v14_20240719_004707/states/model_facs_v4_dec2b_2dpca_v14_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2975658129634536		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2975658129634536 | validation: 0.42395508155212097]
	TIME [epoch: 3.96 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v14_20240719_004707/states/model_facs_v4_dec2b_2dpca_v14_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31748525043109405		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.31748525043109405 | validation: 0.5121158291863082]
	TIME [epoch: 3.97 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3663037053804054		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3663037053804054 | validation: 0.4600025773451044]
	TIME [epoch: 3.96 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31278851285151305		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.31278851285151305 | validation: 0.44661163769650136]
	TIME [epoch: 3.98 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3391514278746474		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3391514278746474 | validation: 0.48172409777392655]
	TIME [epoch: 3.96 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33410491998151237		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.33410491998151237 | validation: 0.5175497903690609]
	TIME [epoch: 3.96 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3151359583809408		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3151359583809408 | validation: 0.43097179859522067]
	TIME [epoch: 3.97 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24502028181850602		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24502028181850602 | validation: 0.39717104031354467]
	TIME [epoch: 3.96 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v14_20240719_004707/states/model_facs_v4_dec2b_2dpca_v14_26.pth
	Model improved!!!
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23839679402797243		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23839679402797243 | validation: 0.48792080999903065]
	TIME [epoch: 3.95 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29713217185408336		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.29713217185408336 | validation: 0.5286487416582872]
	TIME [epoch: 3.95 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3207230440066809		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3207230440066809 | validation: 0.4923775743033498]
	TIME [epoch: 3.95 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3287023567032179		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3287023567032179 | validation: 0.4590230786621867]
	TIME [epoch: 3.95 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27915271034136196		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.27915271034136196 | validation: 0.3960529750737429]
	TIME [epoch: 3.95 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v14_20240719_004707/states/model_facs_v4_dec2b_2dpca_v14_31.pth
	Model improved!!!
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23848831620450628		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23848831620450628 | validation: 0.4045024760172568]
	TIME [epoch: 3.95 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2922006527870066		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2922006527870066 | validation: 0.4567755899397008]
	TIME [epoch: 3.96 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28357397807076357		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.28357397807076357 | validation: 0.4497995912017496]
	TIME [epoch: 3.97 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2890928536375252		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2890928536375252 | validation: 0.40445982590238616]
	TIME [epoch: 3.97 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2285966531893913		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2285966531893913 | validation: 0.363682992356534]
	TIME [epoch: 3.96 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v14_20240719_004707/states/model_facs_v4_dec2b_2dpca_v14_36.pth
	Model improved!!!
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23216271179293183		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23216271179293183 | validation: 0.40934147536284327]
	TIME [epoch: 3.98 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2359969096244109		[learning rate: 0.0099882]
	Learning Rate: 0.0099882
	LOSS [training: 0.2359969096244109 | validation: 0.37357177456667734]
	TIME [epoch: 3.95 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2146845776113212		[learning rate: 0.0099411]
	Learning Rate: 0.00994113
	LOSS [training: 0.2146845776113212 | validation: 0.43545725182292905]
	TIME [epoch: 3.95 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2647139834981774		[learning rate: 0.0098943]
	Learning Rate: 0.00989429
	LOSS [training: 0.2647139834981774 | validation: 0.43865880144319447]
	TIME [epoch: 3.94 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2640855788819149		[learning rate: 0.0098477]
	Learning Rate: 0.00984767
	LOSS [training: 0.2640855788819149 | validation: 0.3994626041354488]
	TIME [epoch: 3.95 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23233852364559088		[learning rate: 0.0098013]
	Learning Rate: 0.00980126
	LOSS [training: 0.23233852364559088 | validation: 0.5236531079834732]
	TIME [epoch: 3.95 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28541406787054413		[learning rate: 0.0097551]
	Learning Rate: 0.00975508
	LOSS [training: 0.28541406787054413 | validation: 0.3515873825919532]
	TIME [epoch: 3.95 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v14_20240719_004707/states/model_facs_v4_dec2b_2dpca_v14_43.pth
	Model improved!!!
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21188983999002536		[learning rate: 0.0097091]
	Learning Rate: 0.00970911
	LOSS [training: 0.21188983999002536 | validation: 0.4214306719905488]
	TIME [epoch: 3.95 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2659296265404111		[learning rate: 0.0096634]
	Learning Rate: 0.00966336
	LOSS [training: 0.2659296265404111 | validation: 0.5127158933894808]
	TIME [epoch: 3.95 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2781636233484031		[learning rate: 0.0096178]
	Learning Rate: 0.00961783
	LOSS [training: 0.2781636233484031 | validation: 0.397870686957465]
	TIME [epoch: 3.95 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.204970889178745		[learning rate: 0.0095725]
	Learning Rate: 0.00957251
	LOSS [training: 0.204970889178745 | validation: 0.40137589566782106]
	TIME [epoch: 3.95 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26919538773406576		[learning rate: 0.0095274]
	Learning Rate: 0.0095274
	LOSS [training: 0.26919538773406576 | validation: 0.3789496332620105]
	TIME [epoch: 3.97 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.224023017484709		[learning rate: 0.0094825]
	Learning Rate: 0.0094825
	LOSS [training: 0.224023017484709 | validation: 0.4237124186571891]
	TIME [epoch: 3.96 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2334510624658783		[learning rate: 0.0094378]
	Learning Rate: 0.00943782
	LOSS [training: 0.2334510624658783 | validation: 0.3628381894824043]
	TIME [epoch: 3.96 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2087561813078488		[learning rate: 0.0093933]
	Learning Rate: 0.00939335
	LOSS [training: 0.2087561813078488 | validation: 0.4421403341976493]
	TIME [epoch: 32.3 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.258859270168574		[learning rate: 0.0093491]
	Learning Rate: 0.00934909
	LOSS [training: 0.258859270168574 | validation: 0.36208406779990965]
	TIME [epoch: 7.61 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2210742520975689		[learning rate: 0.009305]
	Learning Rate: 0.00930503
	LOSS [training: 0.2210742520975689 | validation: 0.3770178909948646]
	TIME [epoch: 7.62 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24386687083182734		[learning rate: 0.0092612]
	Learning Rate: 0.00926119
	LOSS [training: 0.24386687083182734 | validation: 0.4230321463137963]
	TIME [epoch: 7.63 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21100844642983735		[learning rate: 0.0092175]
	Learning Rate: 0.00921755
	LOSS [training: 0.21100844642983735 | validation: 0.41360094810123604]
	TIME [epoch: 7.64 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1958101784931807		[learning rate: 0.0091741]
	Learning Rate: 0.00917411
	LOSS [training: 0.1958101784931807 | validation: 0.3459422388471622]
	TIME [epoch: 7.6 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v14_20240719_004707/states/model_facs_v4_dec2b_2dpca_v14_56.pth
	Model improved!!!
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23544589864731205		[learning rate: 0.0091309]
	Learning Rate: 0.00913088
	LOSS [training: 0.23544589864731205 | validation: 0.3962564202100766]
	TIME [epoch: 7.6 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23937242763225824		[learning rate: 0.0090879]
	Learning Rate: 0.00908786
	LOSS [training: 0.23937242763225824 | validation: 0.4111257628237325]
	TIME [epoch: 7.6 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20139706494510484		[learning rate: 0.009045]
	Learning Rate: 0.00904503
	LOSS [training: 0.20139706494510484 | validation: 0.3960997889961204]
	TIME [epoch: 7.6 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21584077249096129		[learning rate: 0.0090024]
	Learning Rate: 0.00900241
	LOSS [training: 0.21584077249096129 | validation: 0.35558530683760114]
	TIME [epoch: 7.59 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23393133563952834		[learning rate: 0.00896]
	Learning Rate: 0.00895999
	LOSS [training: 0.23393133563952834 | validation: 0.36566615256141216]
	TIME [epoch: 7.61 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23188390238625436		[learning rate: 0.0089178]
	Learning Rate: 0.00891777
	LOSS [training: 0.23188390238625436 | validation: 0.5240734632495884]
	TIME [epoch: 7.66 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2388026669485238		[learning rate: 0.0088758]
	Learning Rate: 0.00887575
	LOSS [training: 0.2388026669485238 | validation: 0.5276091406893865]
	TIME [epoch: 7.61 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2283777864211445		[learning rate: 0.0088339]
	Learning Rate: 0.00883393
	LOSS [training: 0.2283777864211445 | validation: 0.4383232573390438]
	TIME [epoch: 7.62 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2084575648814629		[learning rate: 0.0087923]
	Learning Rate: 0.0087923
	LOSS [training: 0.2084575648814629 | validation: 0.5010402583752415]
	TIME [epoch: 7.6 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2151262546065638		[learning rate: 0.0087509]
	Learning Rate: 0.00875087
	LOSS [training: 0.2151262546065638 | validation: 0.35638647955536773]
	TIME [epoch: 7.6 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21529442698046083		[learning rate: 0.0087096]
	Learning Rate: 0.00870964
	LOSS [training: 0.21529442698046083 | validation: 0.3955755070154554]
	TIME [epoch: 7.61 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.226463392504135		[learning rate: 0.0086686]
	Learning Rate: 0.00866859
	LOSS [training: 0.226463392504135 | validation: 0.34341824778366975]
	TIME [epoch: 7.61 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v14_20240719_004707/states/model_facs_v4_dec2b_2dpca_v14_68.pth
	Model improved!!!
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19191623932515872		[learning rate: 0.0086277]
	Learning Rate: 0.00862775
	LOSS [training: 0.19191623932515872 | validation: 0.42340971954453405]
	TIME [epoch: 7.62 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24417228249964015		[learning rate: 0.0085871]
	Learning Rate: 0.00858709
	LOSS [training: 0.24417228249964015 | validation: 0.39787760623573065]
	TIME [epoch: 7.61 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18916006499182242		[learning rate: 0.0085466]
	Learning Rate: 0.00854663
	LOSS [training: 0.18916006499182242 | validation: 0.4688551747595314]
	TIME [epoch: 7.61 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22023396249095684		[learning rate: 0.0085064]
	Learning Rate: 0.00850636
	LOSS [training: 0.22023396249095684 | validation: 0.4939833375597989]
	TIME [epoch: 7.61 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25534671972164463		[learning rate: 0.0084663]
	Learning Rate: 0.00846627
	LOSS [training: 0.25534671972164463 | validation: 0.405730253642412]
	TIME [epoch: 7.6 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2254139058649289		[learning rate: 0.0084264]
	Learning Rate: 0.00842638
	LOSS [training: 0.2254139058649289 | validation: 0.36297730949840107]
	TIME [epoch: 7.6 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21015922051985036		[learning rate: 0.0083867]
	Learning Rate: 0.00838667
	LOSS [training: 0.21015922051985036 | validation: 0.6520162196858423]
	TIME [epoch: 7.6 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25156147606735707		[learning rate: 0.0083472]
	Learning Rate: 0.00834715
	LOSS [training: 0.25156147606735707 | validation: 0.40426582630141417]
	TIME [epoch: 7.6 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18493026357815884		[learning rate: 0.0083078]
	Learning Rate: 0.00830782
	LOSS [training: 0.18493026357815884 | validation: 0.3520202778337086]
	TIME [epoch: 7.62 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16749628842382347		[learning rate: 0.0082687]
	Learning Rate: 0.00826867
	LOSS [training: 0.16749628842382347 | validation: 0.39444092376139184]
	TIME [epoch: 7.64 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19778879692904006		[learning rate: 0.0082297]
	Learning Rate: 0.00822971
	LOSS [training: 0.19778879692904006 | validation: 0.4256143617087181]
	TIME [epoch: 7.64 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2238491273158612		[learning rate: 0.0081909]
	Learning Rate: 0.00819093
	LOSS [training: 0.2238491273158612 | validation: 0.35880559698415815]
	TIME [epoch: 7.63 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22880151351957986		[learning rate: 0.0081523]
	Learning Rate: 0.00815233
	LOSS [training: 0.22880151351957986 | validation: 0.6285023050168621]
	TIME [epoch: 7.61 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27720527006773793		[learning rate: 0.0081139]
	Learning Rate: 0.00811392
	LOSS [training: 0.27720527006773793 | validation: 0.43998048755986846]
	TIME [epoch: 7.6 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18685376482929564		[learning rate: 0.0080757]
	Learning Rate: 0.00807569
	LOSS [training: 0.18685376482929564 | validation: 0.3709200279562702]
	TIME [epoch: 7.64 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19586022890038365		[learning rate: 0.0080376]
	Learning Rate: 0.00803763
	LOSS [training: 0.19586022890038365 | validation: 0.3400070434230063]
	TIME [epoch: 7.62 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v14_20240719_004707/states/model_facs_v4_dec2b_2dpca_v14_84.pth
	Model improved!!!
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19736900486339393		[learning rate: 0.0079998]
	Learning Rate: 0.00799976
	LOSS [training: 0.19736900486339393 | validation: 0.3326465175239723]
	TIME [epoch: 7.61 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v14_20240719_004707/states/model_facs_v4_dec2b_2dpca_v14_85.pth
	Model improved!!!
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19902933678747295		[learning rate: 0.0079621]
	Learning Rate: 0.00796206
	LOSS [training: 0.19902933678747295 | validation: 0.40949904564105116]
	TIME [epoch: 7.62 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2076561504428434		[learning rate: 0.0079245]
	Learning Rate: 0.00792455
	LOSS [training: 0.2076561504428434 | validation: 0.3548843814016776]
	TIME [epoch: 7.6 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19523091236501952		[learning rate: 0.0078872]
	Learning Rate: 0.0078872
	LOSS [training: 0.19523091236501952 | validation: 0.38979443764031313]
	TIME [epoch: 7.6 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17721787869225342		[learning rate: 0.00785]
	Learning Rate: 0.00785004
	LOSS [training: 0.17721787869225342 | validation: 0.38659474088973284]
	TIME [epoch: 7.6 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24939195539950512		[learning rate: 0.007813]
	Learning Rate: 0.00781305
	LOSS [training: 0.24939195539950512 | validation: 0.43825144240286407]
	TIME [epoch: 7.61 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20084888330102765		[learning rate: 0.0077762]
	Learning Rate: 0.00777623
	LOSS [training: 0.20084888330102765 | validation: 0.4357925089953515]
	TIME [epoch: 7.63 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21306900228411452		[learning rate: 0.0077396]
	Learning Rate: 0.00773959
	LOSS [training: 0.21306900228411452 | validation: 0.37370242319412555]
	TIME [epoch: 7.6 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17101750664675855		[learning rate: 0.0077031]
	Learning Rate: 0.00770312
	LOSS [training: 0.17101750664675855 | validation: 0.3693728214851675]
	TIME [epoch: 7.62 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18230261482908067		[learning rate: 0.0076668]
	Learning Rate: 0.00766682
	LOSS [training: 0.18230261482908067 | validation: 0.6076199592186264]
	TIME [epoch: 7.6 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21273080585757037		[learning rate: 0.0076307]
	Learning Rate: 0.0076307
	LOSS [training: 0.21273080585757037 | validation: 0.3922609607530858]
	TIME [epoch: 7.62 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1766208967712759		[learning rate: 0.0075947]
	Learning Rate: 0.00759474
	LOSS [training: 0.1766208967712759 | validation: 0.34205366372913565]
	TIME [epoch: 7.61 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16281271412960918		[learning rate: 0.007559]
	Learning Rate: 0.00755895
	LOSS [training: 0.16281271412960918 | validation: 0.4314144628298356]
	TIME [epoch: 7.61 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19604427339607475		[learning rate: 0.0075233]
	Learning Rate: 0.00752333
	LOSS [training: 0.19604427339607475 | validation: 0.39235478668745255]
	TIME [epoch: 7.61 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17868354469786926		[learning rate: 0.0074879]
	Learning Rate: 0.00748788
	LOSS [training: 0.17868354469786926 | validation: 0.32556874595949736]
	TIME [epoch: 7.6 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v14_20240719_004707/states/model_facs_v4_dec2b_2dpca_v14_99.pth
	Model improved!!!
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1746530163064115		[learning rate: 0.0074526]
	Learning Rate: 0.0074526
	LOSS [training: 0.1746530163064115 | validation: 0.3974984617195143]
	TIME [epoch: 7.63 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.206565284579262		[learning rate: 0.0074175]
	Learning Rate: 0.00741748
	LOSS [training: 0.206565284579262 | validation: 0.31827813148850004]
	TIME [epoch: 7.61 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v14_20240719_004707/states/model_facs_v4_dec2b_2dpca_v14_101.pth
	Model improved!!!
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20064577558815822		[learning rate: 0.0073825]
	Learning Rate: 0.00738253
	LOSS [training: 0.20064577558815822 | validation: 0.5228660832409583]
	TIME [epoch: 7.62 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24805793116203118		[learning rate: 0.0073477]
	Learning Rate: 0.00734774
	LOSS [training: 0.24805793116203118 | validation: 0.49127215408302916]
	TIME [epoch: 7.6 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18042210552866628		[learning rate: 0.0073131]
	Learning Rate: 0.00731312
	LOSS [training: 0.18042210552866628 | validation: 0.3862412840948547]
	TIME [epoch: 7.62 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1567870210067356		[learning rate: 0.0072787]
	Learning Rate: 0.00727866
	LOSS [training: 0.1567870210067356 | validation: 0.37628854415176116]
	TIME [epoch: 7.64 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16585043590042176		[learning rate: 0.0072444]
	Learning Rate: 0.00724436
	LOSS [training: 0.16585043590042176 | validation: 0.3511318073604555]
	TIME [epoch: 7.61 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14865287706466376		[learning rate: 0.0072102]
	Learning Rate: 0.00721022
	LOSS [training: 0.14865287706466376 | validation: 0.332422667891327]
	TIME [epoch: 7.6 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2089159943755885		[learning rate: 0.0071762]
	Learning Rate: 0.00717625
	LOSS [training: 0.2089159943755885 | validation: 0.484864172468429]
	TIME [epoch: 7.62 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18937565242485105		[learning rate: 0.0071424]
	Learning Rate: 0.00714243
	LOSS [training: 0.18937565242485105 | validation: 0.3581736236755041]
	TIME [epoch: 7.6 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1804676601451553		[learning rate: 0.0071088]
	Learning Rate: 0.00710878
	LOSS [training: 0.1804676601451553 | validation: 0.3312214525978607]
	TIME [epoch: 7.63 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20489964215823947		[learning rate: 0.0070753]
	Learning Rate: 0.00707528
	LOSS [training: 0.20489964215823947 | validation: 0.35114107189866367]
	TIME [epoch: 7.6 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15109555134684785		[learning rate: 0.0070419]
	Learning Rate: 0.00704194
	LOSS [training: 0.15109555134684785 | validation: 0.48052167099803045]
	TIME [epoch: 7.6 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1780292936250937		[learning rate: 0.0070088]
	Learning Rate: 0.00700876
	LOSS [training: 0.1780292936250937 | validation: 0.5571840898503867]
	TIME [epoch: 7.62 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19199712305817554		[learning rate: 0.0069757]
	Learning Rate: 0.00697573
	LOSS [training: 0.19199712305817554 | validation: 0.3439890699627686]
	TIME [epoch: 7.62 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15126103383438763		[learning rate: 0.0069429]
	Learning Rate: 0.00694286
	LOSS [training: 0.15126103383438763 | validation: 0.36558080667918724]
	TIME [epoch: 7.63 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14681866969660695		[learning rate: 0.0069101]
	Learning Rate: 0.00691014
	LOSS [training: 0.14681866969660695 | validation: 0.33604406934510994]
	TIME [epoch: 7.6 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18325085946549793		[learning rate: 0.0068776]
	Learning Rate: 0.00687758
	LOSS [training: 0.18325085946549793 | validation: 0.42945501664301466]
	TIME [epoch: 7.61 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21439309564063513		[learning rate: 0.0068452]
	Learning Rate: 0.00684518
	LOSS [training: 0.21439309564063513 | validation: 0.4618126969628348]
	TIME [epoch: 7.6 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20457707926596969		[learning rate: 0.0068129]
	Learning Rate: 0.00681292
	LOSS [training: 0.20457707926596969 | validation: 0.5668533502311708]
	TIME [epoch: 7.63 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2115405117851856		[learning rate: 0.0067808]
	Learning Rate: 0.00678082
	LOSS [training: 0.2115405117851856 | validation: 0.43273463362946907]
	TIME [epoch: 7.62 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19756489404879274		[learning rate: 0.0067489]
	Learning Rate: 0.00674887
	LOSS [training: 0.19756489404879274 | validation: 0.4137814048330979]
	TIME [epoch: 7.63 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1673913864192101		[learning rate: 0.0067171]
	Learning Rate: 0.00671706
	LOSS [training: 0.1673913864192101 | validation: 0.3442144461916124]
	TIME [epoch: 7.63 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1620057482234619		[learning rate: 0.0066854]
	Learning Rate: 0.00668541
	LOSS [training: 0.1620057482234619 | validation: 0.42211470790581934]
	TIME [epoch: 7.61 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18018954402862036		[learning rate: 0.0066539]
	Learning Rate: 0.00665391
	LOSS [training: 0.18018954402862036 | validation: 0.3374218055850552]
	TIME [epoch: 7.61 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1712153045297615		[learning rate: 0.0066226]
	Learning Rate: 0.00662256
	LOSS [training: 0.1712153045297615 | validation: 0.36858292354815836]
	TIME [epoch: 7.6 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17470995187332122		[learning rate: 0.0065913]
	Learning Rate: 0.00659135
	LOSS [training: 0.17470995187332122 | validation: 0.3659114843705833]
	TIME [epoch: 7.6 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16380877136388342		[learning rate: 0.0065603]
	Learning Rate: 0.00656029
	LOSS [training: 0.16380877136388342 | validation: 0.3351217129842158]
	TIME [epoch: 7.6 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1842028386599749		[learning rate: 0.0065294]
	Learning Rate: 0.00652938
	LOSS [training: 0.1842028386599749 | validation: 0.30725915110180946]
	TIME [epoch: 7.61 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v14_20240719_004707/states/model_facs_v4_dec2b_2dpca_v14_128.pth
	Model improved!!!
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15439782763298854		[learning rate: 0.0064986]
	Learning Rate: 0.00649861
	LOSS [training: 0.15439782763298854 | validation: 0.3213160963687101]
	TIME [epoch: 7.63 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17573528033149796		[learning rate: 0.006468]
	Learning Rate: 0.00646799
	LOSS [training: 0.17573528033149796 | validation: 0.3672082064650991]
	TIME [epoch: 7.63 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16487897575463342		[learning rate: 0.0064375]
	Learning Rate: 0.00643751
	LOSS [training: 0.16487897575463342 | validation: 0.45279720244860644]
	TIME [epoch: 7.6 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17021771012147202		[learning rate: 0.0064072]
	Learning Rate: 0.00640718
	LOSS [training: 0.17021771012147202 | validation: 0.47085630528399736]
	TIME [epoch: 7.61 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18005661548176083		[learning rate: 0.006377]
	Learning Rate: 0.00637698
	LOSS [training: 0.18005661548176083 | validation: 0.3727024893390939]
	TIME [epoch: 7.61 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16759658789803283		[learning rate: 0.0063469]
	Learning Rate: 0.00634694
	LOSS [training: 0.16759658789803283 | validation: 0.44645078618986406]
	TIME [epoch: 7.61 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17299410351096767		[learning rate: 0.006317]
	Learning Rate: 0.00631703
	LOSS [training: 0.17299410351096767 | validation: 0.4823587804770533]
	TIME [epoch: 7.6 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1616092414337241		[learning rate: 0.0062873]
	Learning Rate: 0.00628726
	LOSS [training: 0.1616092414337241 | validation: 0.44541077513226474]
	TIME [epoch: 7.64 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1544984634897835		[learning rate: 0.0062576]
	Learning Rate: 0.00625764
	LOSS [training: 0.1544984634897835 | validation: 0.33567671520832504]
	TIME [epoch: 7.61 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15826993031440617		[learning rate: 0.0062281]
	Learning Rate: 0.00622815
	LOSS [training: 0.15826993031440617 | validation: 0.3371672098347568]
	TIME [epoch: 7.62 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15927686511581435		[learning rate: 0.0061988]
	Learning Rate: 0.0061988
	LOSS [training: 0.15927686511581435 | validation: 0.43708917046093576]
	TIME [epoch: 7.6 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1976473218144283		[learning rate: 0.0061696]
	Learning Rate: 0.00616959
	LOSS [training: 0.1976473218144283 | validation: 0.5157309546381165]
	TIME [epoch: 7.6 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.162707043936603		[learning rate: 0.0061405]
	Learning Rate: 0.00614052
	LOSS [training: 0.162707043936603 | validation: 0.41378927925195436]
	TIME [epoch: 7.61 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15719845847813352		[learning rate: 0.0061116]
	Learning Rate: 0.00611158
	LOSS [training: 0.15719845847813352 | validation: 0.3316900857247539]
	TIME [epoch: 7.61 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1487506970048702		[learning rate: 0.0060828]
	Learning Rate: 0.00608279
	LOSS [training: 0.1487506970048702 | validation: 0.3772246813237501]
	TIME [epoch: 7.63 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17787880574715736		[learning rate: 0.0060541]
	Learning Rate: 0.00605412
	LOSS [training: 0.17787880574715736 | validation: 0.35410702262327204]
	TIME [epoch: 7.62 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1741125150859497		[learning rate: 0.0060256]
	Learning Rate: 0.0060256
	LOSS [training: 0.1741125150859497 | validation: 0.3081293919208749]
	TIME [epoch: 7.61 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14678833312732198		[learning rate: 0.0059972]
	Learning Rate: 0.0059972
	LOSS [training: 0.14678833312732198 | validation: 0.3678810460017909]
	TIME [epoch: 7.6 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16379239614614874		[learning rate: 0.0059689]
	Learning Rate: 0.00596894
	LOSS [training: 0.16379239614614874 | validation: 0.40465108177831777]
	TIME [epoch: 7.61 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21893041175897826		[learning rate: 0.0059408]
	Learning Rate: 0.00594082
	LOSS [training: 0.21893041175897826 | validation: 0.3007132104153825]
	TIME [epoch: 7.62 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v14_20240719_004707/states/model_facs_v4_dec2b_2dpca_v14_148.pth
	Model improved!!!
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1706190946008741		[learning rate: 0.0059128]
	Learning Rate: 0.00591282
	LOSS [training: 0.1706190946008741 | validation: 0.31131768444888164]
	TIME [epoch: 7.61 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18725624898753804		[learning rate: 0.005885]
	Learning Rate: 0.00588496
	LOSS [training: 0.18725624898753804 | validation: 0.3525404478531766]
	TIME [epoch: 7.61 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15846089054967982		[learning rate: 0.0058572]
	Learning Rate: 0.00585723
	LOSS [training: 0.15846089054967982 | validation: 0.4593927297221406]
	TIME [epoch: 7.62 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20637926544198476		[learning rate: 0.0058296]
	Learning Rate: 0.00582963
	LOSS [training: 0.20637926544198476 | validation: 0.3109450009070642]
	TIME [epoch: 7.64 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1487038435626028		[learning rate: 0.0058022]
	Learning Rate: 0.00580216
	LOSS [training: 0.1487038435626028 | validation: 0.39300057253082327]
	TIME [epoch: 7.61 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19575605541104837		[learning rate: 0.0057748]
	Learning Rate: 0.00577482
	LOSS [training: 0.19575605541104837 | validation: 0.2923446291792387]
	TIME [epoch: 7.61 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v14_20240719_004707/states/model_facs_v4_dec2b_2dpca_v14_154.pth
	Model improved!!!
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1523451406166441		[learning rate: 0.0057476]
	Learning Rate: 0.00574761
	LOSS [training: 0.1523451406166441 | validation: 0.30803119009472907]
	TIME [epoch: 7.6 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1714637880818846		[learning rate: 0.0057205]
	Learning Rate: 0.00572052
	LOSS [training: 0.1714637880818846 | validation: 0.3220812309422931]
	TIME [epoch: 7.61 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14236257974904304		[learning rate: 0.0056936]
	Learning Rate: 0.00569357
	LOSS [training: 0.14236257974904304 | validation: 0.348042337083634]
	TIME [epoch: 7.62 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15117795479931045		[learning rate: 0.0056667]
	Learning Rate: 0.00566674
	LOSS [training: 0.15117795479931045 | validation: 0.3240616460516036]
	TIME [epoch: 7.63 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15834441184118508		[learning rate: 0.00564]
	Learning Rate: 0.00564004
	LOSS [training: 0.15834441184118508 | validation: 0.35040385947469005]
	TIME [epoch: 7.64 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1712540174911313		[learning rate: 0.0056135]
	Learning Rate: 0.00561346
	LOSS [training: 0.1712540174911313 | validation: 0.46522944472467054]
	TIME [epoch: 7.63 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17871501656517563		[learning rate: 0.005587]
	Learning Rate: 0.00558701
	LOSS [training: 0.17871501656517563 | validation: 0.4521562683915932]
	TIME [epoch: 7.59 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17344181092172994		[learning rate: 0.0055607]
	Learning Rate: 0.00556068
	LOSS [training: 0.17344181092172994 | validation: 0.36421578751097494]
	TIME [epoch: 7.61 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13087043398110776		[learning rate: 0.0055345]
	Learning Rate: 0.00553448
	LOSS [training: 0.13087043398110776 | validation: 0.3386501447098154]
	TIME [epoch: 7.6 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17840007585550882		[learning rate: 0.0055084]
	Learning Rate: 0.0055084
	LOSS [training: 0.17840007585550882 | validation: 0.4057083106857871]
	TIME [epoch: 7.6 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16553388980576897		[learning rate: 0.0054824]
	Learning Rate: 0.00548245
	LOSS [training: 0.16553388980576897 | validation: 0.38826948373925335]
	TIME [epoch: 7.59 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14840427481902876		[learning rate: 0.0054566]
	Learning Rate: 0.00545661
	LOSS [training: 0.14840427481902876 | validation: 0.3160413014494555]
	TIME [epoch: 7.61 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15892986969556006		[learning rate: 0.0054309]
	Learning Rate: 0.0054309
	LOSS [training: 0.15892986969556006 | validation: 0.31114661768243695]
	TIME [epoch: 7.65 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13958063958695147		[learning rate: 0.0054053]
	Learning Rate: 0.00540531
	LOSS [training: 0.13958063958695147 | validation: 0.46092099796996944]
	TIME [epoch: 7.6 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1689654241608191		[learning rate: 0.0053798]
	Learning Rate: 0.00537984
	LOSS [training: 0.1689654241608191 | validation: 0.2908625537443133]
	TIME [epoch: 7.59 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v14_20240719_004707/states/model_facs_v4_dec2b_2dpca_v14_169.pth
	Model improved!!!
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1723497508725545		[learning rate: 0.0053545]
	Learning Rate: 0.00535449
	LOSS [training: 0.1723497508725545 | validation: 0.30222970308328045]
	TIME [epoch: 7.6 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16201205911167316		[learning rate: 0.0053293]
	Learning Rate: 0.00532926
	LOSS [training: 0.16201205911167316 | validation: 0.3790257057336527]
	TIME [epoch: 7.61 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16350159379492174		[learning rate: 0.0053041]
	Learning Rate: 0.00530415
	LOSS [training: 0.16350159379492174 | validation: 0.36878296902475927]
	TIME [epoch: 7.6 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1684169885308644		[learning rate: 0.0052792]
	Learning Rate: 0.00527915
	LOSS [training: 0.1684169885308644 | validation: 0.32680341866692597]
	TIME [epoch: 7.63 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1604572991697126		[learning rate: 0.0052543]
	Learning Rate: 0.00525428
	LOSS [training: 0.1604572991697126 | validation: 0.316865192910505]
	TIME [epoch: 7.63 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1504130976196863		[learning rate: 0.0052295]
	Learning Rate: 0.00522952
	LOSS [training: 0.1504130976196863 | validation: 0.3059078416756853]
	TIME [epoch: 7.62 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13726810877679382		[learning rate: 0.0052049]
	Learning Rate: 0.00520487
	LOSS [training: 0.13726810877679382 | validation: 0.32766753287790884]
	TIME [epoch: 7.6 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14963704001527278		[learning rate: 0.0051803]
	Learning Rate: 0.00518035
	LOSS [training: 0.14963704001527278 | validation: 0.4461016255890276]
	TIME [epoch: 7.6 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15044692314437622		[learning rate: 0.0051559]
	Learning Rate: 0.00515594
	LOSS [training: 0.15044692314437622 | validation: 0.46957971692273776]
	TIME [epoch: 7.59 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15506267189853473		[learning rate: 0.0051316]
	Learning Rate: 0.00513164
	LOSS [training: 0.15506267189853473 | validation: 0.4033008793762654]
	TIME [epoch: 7.59 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15420011574637263		[learning rate: 0.0051075]
	Learning Rate: 0.00510746
	LOSS [training: 0.15420011574637263 | validation: 0.3179733920908308]
	TIME [epoch: 7.6 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15398650891420304		[learning rate: 0.0050834]
	Learning Rate: 0.00508339
	LOSS [training: 0.15398650891420304 | validation: 0.2877703880568056]
	TIME [epoch: 7.63 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v14_20240719_004707/states/model_facs_v4_dec2b_2dpca_v14_181.pth
	Model improved!!!
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13862495454963786		[learning rate: 0.0050594]
	Learning Rate: 0.00505944
	LOSS [training: 0.13862495454963786 | validation: 0.4037358718250505]
	TIME [epoch: 7.63 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18089046059336822		[learning rate: 0.0050356]
	Learning Rate: 0.0050356
	LOSS [training: 0.18089046059336822 | validation: 0.32097910066757523]
	TIME [epoch: 7.6 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1424594426169542		[learning rate: 0.0050119]
	Learning Rate: 0.00501187
	LOSS [training: 0.1424594426169542 | validation: 0.4173019566531382]
	TIME [epoch: 7.6 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15118869464019527		[learning rate: 0.0049883]
	Learning Rate: 0.00498826
	LOSS [training: 0.15118869464019527 | validation: 0.4006814647274409]
	TIME [epoch: 7.61 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1597320467214191		[learning rate: 0.0049648]
	Learning Rate: 0.00496475
	LOSS [training: 0.1597320467214191 | validation: 0.40241327017401884]
	TIME [epoch: 7.62 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15138802008947577		[learning rate: 0.0049414]
	Learning Rate: 0.00494136
	LOSS [training: 0.15138802008947577 | validation: 0.35468881194988977]
	TIME [epoch: 7.63 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14748068500825698		[learning rate: 0.0049181]
	Learning Rate: 0.00491807
	LOSS [training: 0.14748068500825698 | validation: 0.3804317258865539]
	TIME [epoch: 7.62 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1377539258065406		[learning rate: 0.0048949]
	Learning Rate: 0.0048949
	LOSS [training: 0.1377539258065406 | validation: 0.30905168806535677]
	TIME [epoch: 7.61 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16641921125673462		[learning rate: 0.0048718]
	Learning Rate: 0.00487183
	LOSS [training: 0.16641921125673462 | validation: 0.34348761056897703]
	TIME [epoch: 7.6 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1531617274362093		[learning rate: 0.0048489]
	Learning Rate: 0.00484888
	LOSS [training: 0.1531617274362093 | validation: 0.2900365654355467]
	TIME [epoch: 7.62 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14003641842969866		[learning rate: 0.004826]
	Learning Rate: 0.00482603
	LOSS [training: 0.14003641842969866 | validation: 0.40048391731094685]
	TIME [epoch: 7.6 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16601692166386045		[learning rate: 0.0048033]
	Learning Rate: 0.00480329
	LOSS [training: 0.16601692166386045 | validation: 0.33184170775599287]
	TIME [epoch: 7.62 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16294278758824		[learning rate: 0.0047807]
	Learning Rate: 0.00478065
	LOSS [training: 0.16294278758824 | validation: 0.372435855236665]
	TIME [epoch: 7.61 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15003625707099622		[learning rate: 0.0047581]
	Learning Rate: 0.00475813
	LOSS [training: 0.15003625707099622 | validation: 0.3880619758260454]
	TIME [epoch: 7.63 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15972905032442528		[learning rate: 0.0047357]
	Learning Rate: 0.0047357
	LOSS [training: 0.15972905032442528 | validation: 0.3481982970681241]
	TIME [epoch: 7.63 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17177136719380218		[learning rate: 0.0047134]
	Learning Rate: 0.00471339
	LOSS [training: 0.17177136719380218 | validation: 0.30567519331904985]
	TIME [epoch: 7.64 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1522731604950764		[learning rate: 0.0046912]
	Learning Rate: 0.00469118
	LOSS [training: 0.1522731604950764 | validation: 0.30800408946087965]
	TIME [epoch: 7.63 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1360085144835873		[learning rate: 0.0046691]
	Learning Rate: 0.00466907
	LOSS [training: 0.1360085144835873 | validation: 0.30588261844429215]
	TIME [epoch: 7.63 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13903136341322214		[learning rate: 0.0046471]
	Learning Rate: 0.00464707
	LOSS [training: 0.13903136341322214 | validation: 0.30880034669621675]
	TIME [epoch: 7.6 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14072330814099968		[learning rate: 0.0046252]
	Learning Rate: 0.00462518
	LOSS [training: 0.14072330814099968 | validation: 0.3858856973203629]
	TIME [epoch: 7.62 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16074800457855312		[learning rate: 0.0046034]
	Learning Rate: 0.00460338
	LOSS [training: 0.16074800457855312 | validation: 0.3240232744180923]
	TIME [epoch: 7.6 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17783833219068962		[learning rate: 0.0045817]
	Learning Rate: 0.00458169
	LOSS [training: 0.17783833219068962 | validation: 0.30502302830794914]
	TIME [epoch: 7.6 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15982122819240757		[learning rate: 0.0045601]
	Learning Rate: 0.0045601
	LOSS [training: 0.15982122819240757 | validation: 0.4117470325434639]
	TIME [epoch: 7.62 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12409028884925129		[learning rate: 0.0045386]
	Learning Rate: 0.00453861
	LOSS [training: 0.12409028884925129 | validation: 0.31579126829939785]
	TIME [epoch: 7.6 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14696679542445734		[learning rate: 0.0045172]
	Learning Rate: 0.00451723
	LOSS [training: 0.14696679542445734 | validation: 0.3465438725194887]
	TIME [epoch: 7.61 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15706079518324084		[learning rate: 0.0044959]
	Learning Rate: 0.00449594
	LOSS [training: 0.15706079518324084 | validation: 0.3826108978196267]
	TIME [epoch: 7.6 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13378427408543592		[learning rate: 0.0044748]
	Learning Rate: 0.00447475
	LOSS [training: 0.13378427408543592 | validation: 0.3672677529410825]
	TIME [epoch: 7.6 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13284052438706415		[learning rate: 0.0044537]
	Learning Rate: 0.00445367
	LOSS [training: 0.13284052438706415 | validation: 0.37179295328265005]
	TIME [epoch: 7.62 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14286240915886939		[learning rate: 0.0044327]
	Learning Rate: 0.00443268
	LOSS [training: 0.14286240915886939 | validation: 0.3003372261334978]
	TIME [epoch: 7.6 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1346669227474917		[learning rate: 0.0044118]
	Learning Rate: 0.0044118
	LOSS [training: 0.1346669227474917 | validation: 0.34660299545102924]
	TIME [epoch: 7.6 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14502905517678186		[learning rate: 0.004391]
	Learning Rate: 0.00439101
	LOSS [training: 0.14502905517678186 | validation: 0.32602478397905915]
	TIME [epoch: 7.6 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14379735820819772		[learning rate: 0.0043703]
	Learning Rate: 0.00437032
	LOSS [training: 0.14379735820819772 | validation: 0.3163725706682187]
	TIME [epoch: 7.61 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.173348267762224		[learning rate: 0.0043497]
	Learning Rate: 0.00434972
	LOSS [training: 0.173348267762224 | validation: 0.32755483882076997]
	TIME [epoch: 7.6 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1321683255972167		[learning rate: 0.0043292]
	Learning Rate: 0.00432923
	LOSS [training: 0.1321683255972167 | validation: 0.344944120774436]
	TIME [epoch: 7.6 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14470818161106402		[learning rate: 0.0043088]
	Learning Rate: 0.00430883
	LOSS [training: 0.14470818161106402 | validation: 0.3232277324688575]
	TIME [epoch: 7.64 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16217687728576058		[learning rate: 0.0042885]
	Learning Rate: 0.00428852
	LOSS [training: 0.16217687728576058 | validation: 0.29538538560646316]
	TIME [epoch: 7.64 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12709938622888156		[learning rate: 0.0042683]
	Learning Rate: 0.00426831
	LOSS [training: 0.12709938622888156 | validation: 0.3017899391318526]
	TIME [epoch: 7.61 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1399463799369718		[learning rate: 0.0042482]
	Learning Rate: 0.0042482
	LOSS [training: 0.1399463799369718 | validation: 0.4064483901095569]
	TIME [epoch: 7.6 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14773573743157542		[learning rate: 0.0042282]
	Learning Rate: 0.00422818
	LOSS [training: 0.14773573743157542 | validation: 0.29647572793199306]
	TIME [epoch: 7.6 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12144271823980753		[learning rate: 0.0042083]
	Learning Rate: 0.00420826
	LOSS [training: 0.12144271823980753 | validation: 0.3311365266207163]
	TIME [epoch: 7.6 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14479747760300385		[learning rate: 0.0041884]
	Learning Rate: 0.00418843
	LOSS [training: 0.14479747760300385 | validation: 0.35441121289497707]
	TIME [epoch: 7.62 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1539880540179778		[learning rate: 0.0041687]
	Learning Rate: 0.00416869
	LOSS [training: 0.1539880540179778 | validation: 0.4131598646822259]
	TIME [epoch: 7.6 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1521269421297075		[learning rate: 0.0041491]
	Learning Rate: 0.00414905
	LOSS [training: 0.1521269421297075 | validation: 0.39478289398144195]
	TIME [epoch: 7.61 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13748530835307124		[learning rate: 0.0041295]
	Learning Rate: 0.0041295
	LOSS [training: 0.13748530835307124 | validation: 0.3166075373202339]
	TIME [epoch: 7.6 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1370931732409591		[learning rate: 0.00411]
	Learning Rate: 0.00411004
	LOSS [training: 0.1370931732409591 | validation: 0.3091996841431767]
	TIME [epoch: 7.62 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14439847175628662		[learning rate: 0.0040907]
	Learning Rate: 0.00409067
	LOSS [training: 0.14439847175628662 | validation: 0.3392853752106676]
	TIME [epoch: 7.64 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13194877635845306		[learning rate: 0.0040714]
	Learning Rate: 0.0040714
	LOSS [training: 0.13194877635845306 | validation: 0.3574739483293647]
	TIME [epoch: 7.62 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14395977823110254		[learning rate: 0.0040522]
	Learning Rate: 0.00405221
	LOSS [training: 0.14395977823110254 | validation: 0.3081402255795215]
	TIME [epoch: 7.6 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13768204720917182		[learning rate: 0.0040331]
	Learning Rate: 0.00403312
	LOSS [training: 0.13768204720917182 | validation: 0.31172494542437185]
	TIME [epoch: 7.61 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15108941940802353		[learning rate: 0.0040141]
	Learning Rate: 0.00401411
	LOSS [training: 0.15108941940802353 | validation: 0.40795811080531]
	TIME [epoch: 7.62 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1383279018745521		[learning rate: 0.0039952]
	Learning Rate: 0.0039952
	LOSS [training: 0.1383279018745521 | validation: 0.3092503472354969]
	TIME [epoch: 7.61 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14535344105536996		[learning rate: 0.0039764]
	Learning Rate: 0.00397637
	LOSS [training: 0.14535344105536996 | validation: 0.3638832708422361]
	TIME [epoch: 7.62 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14080379454377984		[learning rate: 0.0039576]
	Learning Rate: 0.00395764
	LOSS [training: 0.14080379454377984 | validation: 0.3152304654208375]
	TIME [epoch: 7.62 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13434503789712593		[learning rate: 0.003939]
	Learning Rate: 0.00393899
	LOSS [training: 0.13434503789712593 | validation: 0.31526644482941624]
	TIME [epoch: 7.63 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14156174302283658		[learning rate: 0.0039204]
	Learning Rate: 0.00392043
	LOSS [training: 0.14156174302283658 | validation: 0.3586972579553463]
	TIME [epoch: 7.61 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13417751162984318		[learning rate: 0.003902]
	Learning Rate: 0.00390195
	LOSS [training: 0.13417751162984318 | validation: 0.3853988866493988]
	TIME [epoch: 7.6 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1436263205533064		[learning rate: 0.0038836]
	Learning Rate: 0.00388357
	LOSS [training: 0.1436263205533064 | validation: 0.34222502998335846]
	TIME [epoch: 7.59 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13000629967506713		[learning rate: 0.0038653]
	Learning Rate: 0.00386527
	LOSS [training: 0.13000629967506713 | validation: 0.3625953897099301]
	TIME [epoch: 7.62 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15743531351719806		[learning rate: 0.0038471]
	Learning Rate: 0.00384705
	LOSS [training: 0.15743531351719806 | validation: 0.298019971794581]
	TIME [epoch: 7.63 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12323406631126778		[learning rate: 0.0038289]
	Learning Rate: 0.00382893
	LOSS [training: 0.12323406631126778 | validation: 0.31632960196985566]
	TIME [epoch: 7.59 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14219131886122968		[learning rate: 0.0038109]
	Learning Rate: 0.00381088
	LOSS [training: 0.14219131886122968 | validation: 0.36238908192961505]
	TIME [epoch: 7.61 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14983498668467946		[learning rate: 0.0037929]
	Learning Rate: 0.00379293
	LOSS [training: 0.14983498668467946 | validation: 0.32712097323108014]
	TIME [epoch: 7.61 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13989547924070148		[learning rate: 0.0037751]
	Learning Rate: 0.00377505
	LOSS [training: 0.13989547924070148 | validation: 0.3081179378594355]
	TIME [epoch: 7.62 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11674905560032768		[learning rate: 0.0037573]
	Learning Rate: 0.00375726
	LOSS [training: 0.11674905560032768 | validation: 0.34085160633404565]
	TIME [epoch: 7.61 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14759648372777354		[learning rate: 0.0037396]
	Learning Rate: 0.00373956
	LOSS [training: 0.14759648372777354 | validation: 0.2855973156426532]
	TIME [epoch: 7.61 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v14_20240719_004707/states/model_facs_v4_dec2b_2dpca_v14_246.pth
	Model improved!!!
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13559409071737627		[learning rate: 0.0037219]
	Learning Rate: 0.00372194
	LOSS [training: 0.13559409071737627 | validation: 0.29237453650225476]
	TIME [epoch: 7.61 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1369183587130764		[learning rate: 0.0037044]
	Learning Rate: 0.0037044
	LOSS [training: 0.1369183587130764 | validation: 0.3159425964211956]
	TIME [epoch: 7.61 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14650915981962545		[learning rate: 0.0036869]
	Learning Rate: 0.00368695
	LOSS [training: 0.14650915981962545 | validation: 0.38131046376325045]
	TIME [epoch: 7.6 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13373943414865563		[learning rate: 0.0036696]
	Learning Rate: 0.00366957
	LOSS [training: 0.13373943414865563 | validation: 0.31239396834003513]
	TIME [epoch: 7.63 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1385416845144663		[learning rate: 0.0036523]
	Learning Rate: 0.00365228
	LOSS [training: 0.1385416845144663 | validation: 0.32381450473897067]
	TIME [epoch: 7.63 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12904385519029657		[learning rate: 0.0036351]
	Learning Rate: 0.00363507
	LOSS [training: 0.12904385519029657 | validation: 0.33395791450824486]
	TIME [epoch: 7.64 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15216697768121412		[learning rate: 0.0036179]
	Learning Rate: 0.00361794
	LOSS [training: 0.15216697768121412 | validation: 0.3810312374417844]
	TIME [epoch: 7.61 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12976396318606975		[learning rate: 0.0036009]
	Learning Rate: 0.00360089
	LOSS [training: 0.12976396318606975 | validation: 0.31657792575444904]
	TIME [epoch: 7.61 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1478648399135568		[learning rate: 0.0035839]
	Learning Rate: 0.00358393
	LOSS [training: 0.1478648399135568 | validation: 0.34059381937455174]
	TIME [epoch: 7.6 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13379434333405482		[learning rate: 0.003567]
	Learning Rate: 0.00356704
	LOSS [training: 0.13379434333405482 | validation: 0.3694057342219594]
	TIME [epoch: 7.6 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13743601618988244		[learning rate: 0.0035502]
	Learning Rate: 0.00355023
	LOSS [training: 0.13743601618988244 | validation: 0.3450748876236269]
	TIME [epoch: 7.62 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14119705827323192		[learning rate: 0.0035335]
	Learning Rate: 0.0035335
	LOSS [training: 0.14119705827323192 | validation: 0.3055562948144602]
	TIME [epoch: 7.63 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1401192878132661		[learning rate: 0.0035168]
	Learning Rate: 0.00351685
	LOSS [training: 0.1401192878132661 | validation: 0.34096614702585026]
	TIME [epoch: 7.61 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12129805728174817		[learning rate: 0.0035003]
	Learning Rate: 0.00350028
	LOSS [training: 0.12129805728174817 | validation: 0.3150866370915966]
	TIME [epoch: 7.6 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14540056409761096		[learning rate: 0.0034838]
	Learning Rate: 0.00348378
	LOSS [training: 0.14540056409761096 | validation: 0.2988337615212734]
	TIME [epoch: 7.61 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1269090137527736		[learning rate: 0.0034674]
	Learning Rate: 0.00346737
	LOSS [training: 0.1269090137527736 | validation: 0.30048936836369083]
	TIME [epoch: 7.64 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1398475582651667		[learning rate: 0.003451]
	Learning Rate: 0.00345103
	LOSS [training: 0.1398475582651667 | validation: 0.27200076898056724]
	TIME [epoch: 7.62 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v14_20240719_004707/states/model_facs_v4_dec2b_2dpca_v14_263.pth
	Model improved!!!
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12176971090704529		[learning rate: 0.0034348]
	Learning Rate: 0.00343477
	LOSS [training: 0.12176971090704529 | validation: 0.3883294147387046]
	TIME [epoch: 7.63 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13862684872549255		[learning rate: 0.0034186]
	Learning Rate: 0.00341858
	LOSS [training: 0.13862684872549255 | validation: 0.34147856008901734]
	TIME [epoch: 7.61 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12859175941007384		[learning rate: 0.0034025]
	Learning Rate: 0.00340247
	LOSS [training: 0.12859175941007384 | validation: 0.3363236744322815]
	TIME [epoch: 7.62 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1254586574782315		[learning rate: 0.0033864]
	Learning Rate: 0.00338644
	LOSS [training: 0.1254586574782315 | validation: 0.31351779105179456]
	TIME [epoch: 7.59 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1406118187878941		[learning rate: 0.0033705]
	Learning Rate: 0.00337048
	LOSS [training: 0.1406118187878941 | validation: 0.2866785191537123]
	TIME [epoch: 7.59 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14049841058733695		[learning rate: 0.0033546]
	Learning Rate: 0.0033546
	LOSS [training: 0.14049841058733695 | validation: 0.3472690406466504]
	TIME [epoch: 7.61 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14407002917041925		[learning rate: 0.0033388]
	Learning Rate: 0.00333879
	LOSS [training: 0.14407002917041925 | validation: 0.28345425605296865]
	TIME [epoch: 7.6 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12053125002070875		[learning rate: 0.0033231]
	Learning Rate: 0.00332306
	LOSS [training: 0.12053125002070875 | validation: 0.35544950212779675]
	TIME [epoch: 7.63 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16562669851544096		[learning rate: 0.0033074]
	Learning Rate: 0.0033074
	LOSS [training: 0.16562669851544096 | validation: 0.2902940840887941]
	TIME [epoch: 7.63 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13779665759231965		[learning rate: 0.0032918]
	Learning Rate: 0.00329182
	LOSS [training: 0.13779665759231965 | validation: 0.34151795283271147]
	TIME [epoch: 7.6 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14309320639027448		[learning rate: 0.0032763]
	Learning Rate: 0.00327631
	LOSS [training: 0.14309320639027448 | validation: 0.36150988936048756]
	TIME [epoch: 7.64 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14948796001213385		[learning rate: 0.0032609]
	Learning Rate: 0.00326087
	LOSS [training: 0.14948796001213385 | validation: 0.304245083109055]
	TIME [epoch: 7.61 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11810441634203028		[learning rate: 0.0032455]
	Learning Rate: 0.0032455
	LOSS [training: 0.11810441634203028 | validation: 0.43468556354756394]
	TIME [epoch: 7.6 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15340117588575272		[learning rate: 0.0032302]
	Learning Rate: 0.00323021
	LOSS [training: 0.15340117588575272 | validation: 0.2997452774126735]
	TIME [epoch: 7.6 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11971536656795634		[learning rate: 0.003215]
	Learning Rate: 0.00321499
	LOSS [training: 0.11971536656795634 | validation: 0.3534059948891035]
	TIME [epoch: 7.65 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12659019276544647		[learning rate: 0.0031998]
	Learning Rate: 0.00319984
	LOSS [training: 0.12659019276544647 | validation: 0.2916407802840014]
	TIME [epoch: 7.63 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13632933351788473		[learning rate: 0.0031848]
	Learning Rate: 0.00318476
	LOSS [training: 0.13632933351788473 | validation: 0.29492408259928604]
	TIME [epoch: 7.62 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11842618904546193		[learning rate: 0.0031698]
	Learning Rate: 0.00316975
	LOSS [training: 0.11842618904546193 | validation: 0.3172444161679571]
	TIME [epoch: 7.6 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13996407567642266		[learning rate: 0.0031548]
	Learning Rate: 0.00315482
	LOSS [training: 0.13996407567642266 | validation: 0.342736723343944]
	TIME [epoch: 7.6 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15050477094629267		[learning rate: 0.00314]
	Learning Rate: 0.00313995
	LOSS [training: 0.15050477094629267 | validation: 0.28588058506836844]
	TIME [epoch: 7.6 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13775405321942386		[learning rate: 0.0031252]
	Learning Rate: 0.00312516
	LOSS [training: 0.13775405321942386 | validation: 0.3590330825389212]
	TIME [epoch: 7.62 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13503181001038775		[learning rate: 0.0031104]
	Learning Rate: 0.00311043
	LOSS [training: 0.13503181001038775 | validation: 0.36153026799235266]
	TIME [epoch: 7.61 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15573409609443606		[learning rate: 0.0030958]
	Learning Rate: 0.00309577
	LOSS [training: 0.15573409609443606 | validation: 0.3614770826810482]
	TIME [epoch: 7.6 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15090687137338313		[learning rate: 0.0030812]
	Learning Rate: 0.00308119
	LOSS [training: 0.15090687137338313 | validation: 0.36619319438469844]
	TIME [epoch: 7.61 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14312468020997132		[learning rate: 0.0030667]
	Learning Rate: 0.00306667
	LOSS [training: 0.14312468020997132 | validation: 0.2954150292769508]
	TIME [epoch: 7.62 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12092139258569468		[learning rate: 0.0030522]
	Learning Rate: 0.00305222
	LOSS [training: 0.12092139258569468 | validation: 0.32754267782581864]
	TIME [epoch: 7.64 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14703723762367782		[learning rate: 0.0030378]
	Learning Rate: 0.00303783
	LOSS [training: 0.14703723762367782 | validation: 0.32184020621920345]
	TIME [epoch: 7.6 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14473487747642072		[learning rate: 0.0030235]
	Learning Rate: 0.00302352
	LOSS [training: 0.14473487747642072 | validation: 0.3440229545722226]
	TIME [epoch: 7.6 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13002514506845464		[learning rate: 0.0030093]
	Learning Rate: 0.00300927
	LOSS [training: 0.13002514506845464 | validation: 0.3030029077136488]
	TIME [epoch: 7.61 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12946288471072545		[learning rate: 0.0029951]
	Learning Rate: 0.00299509
	LOSS [training: 0.12946288471072545 | validation: 0.2932767110647483]
	TIME [epoch: 7.61 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13375129623864843		[learning rate: 0.002981]
	Learning Rate: 0.00298098
	LOSS [training: 0.13375129623864843 | validation: 0.33402073814490735]
	TIME [epoch: 7.61 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12052344713500343		[learning rate: 0.0029669]
	Learning Rate: 0.00296693
	LOSS [training: 0.12052344713500343 | validation: 0.3166653103578383]
	TIME [epoch: 7.63 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14111095873957696		[learning rate: 0.002953]
	Learning Rate: 0.00295295
	LOSS [training: 0.14111095873957696 | validation: 0.3389362809291347]
	TIME [epoch: 7.63 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13343956756404618		[learning rate: 0.002939]
	Learning Rate: 0.00293904
	LOSS [training: 0.13343956756404618 | validation: 0.29186458644905056]
	TIME [epoch: 7.62 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1329682133448482		[learning rate: 0.0029252]
	Learning Rate: 0.00292519
	LOSS [training: 0.1329682133448482 | validation: 0.32506438651131686]
	TIME [epoch: 7.62 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1376906638393418		[learning rate: 0.0029114]
	Learning Rate: 0.0029114
	LOSS [training: 0.1376906638393418 | validation: 0.3169963818786018]
	TIME [epoch: 7.6 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1488899013974564		[learning rate: 0.0028977]
	Learning Rate: 0.00289769
	LOSS [training: 0.1488899013974564 | validation: 0.31564894731655396]
	TIME [epoch: 7.6 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1363464257288513		[learning rate: 0.002884]
	Learning Rate: 0.00288403
	LOSS [training: 0.1363464257288513 | validation: 0.3119592513314281]
	TIME [epoch: 7.6 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14467706476800882		[learning rate: 0.0028704]
	Learning Rate: 0.00287044
	LOSS [training: 0.14467706476800882 | validation: 0.41541411980932275]
	TIME [epoch: 7.62 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13734458759020035		[learning rate: 0.0028569]
	Learning Rate: 0.00285692
	LOSS [training: 0.13734458759020035 | validation: 0.3085869511141609]
	TIME [epoch: 7.63 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11678470313143137		[learning rate: 0.0028435]
	Learning Rate: 0.00284345
	LOSS [training: 0.11678470313143137 | validation: 0.3164178122210451]
	TIME [epoch: 7.59 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1471706304266904		[learning rate: 0.0028301]
	Learning Rate: 0.00283005
	LOSS [training: 0.1471706304266904 | validation: 0.35771317435082794]
	TIME [epoch: 7.62 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1395617514033645		[learning rate: 0.0028167]
	Learning Rate: 0.00281672
	LOSS [training: 0.1395617514033645 | validation: 0.3520667451537614]
	TIME [epoch: 7.61 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15386184221822555		[learning rate: 0.0028034]
	Learning Rate: 0.00280345
	LOSS [training: 0.15386184221822555 | validation: 0.3465150019617922]
	TIME [epoch: 7.62 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14908327450879968		[learning rate: 0.0027902]
	Learning Rate: 0.00279024
	LOSS [training: 0.14908327450879968 | validation: 0.33527054925451266]
	TIME [epoch: 7.61 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15015913515642504		[learning rate: 0.0027771]
	Learning Rate: 0.00277709
	LOSS [training: 0.15015913515642504 | validation: 0.33768581175289647]
	TIME [epoch: 7.63 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1509949242344673		[learning rate: 0.002764]
	Learning Rate: 0.002764
	LOSS [training: 0.1509949242344673 | validation: 0.29286891430030837]
	TIME [epoch: 7.62 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12087215128985511		[learning rate: 0.002751]
	Learning Rate: 0.00275098
	LOSS [training: 0.12087215128985511 | validation: 0.3151098271671109]
	TIME [epoch: 7.62 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10910301549223506		[learning rate: 0.002738]
	Learning Rate: 0.00273802
	LOSS [training: 0.10910301549223506 | validation: 0.31408455902584764]
	TIME [epoch: 7.6 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13374568453922786		[learning rate: 0.0027251]
	Learning Rate: 0.00272511
	LOSS [training: 0.13374568453922786 | validation: 0.3391318256196478]
	TIME [epoch: 7.6 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12091973481418807		[learning rate: 0.0027123]
	Learning Rate: 0.00271227
	LOSS [training: 0.12091973481418807 | validation: 0.30392260758498846]
	TIME [epoch: 7.6 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11887320873745441		[learning rate: 0.0026995]
	Learning Rate: 0.00269949
	LOSS [training: 0.11887320873745441 | validation: 0.29628344409934126]
	TIME [epoch: 7.62 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11237562408346752		[learning rate: 0.0026868]
	Learning Rate: 0.00268677
	LOSS [training: 0.11237562408346752 | validation: 0.3542015649416874]
	TIME [epoch: 7.62 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11228805671802602		[learning rate: 0.0026741]
	Learning Rate: 0.00267411
	LOSS [training: 0.11228805671802602 | validation: 0.31998255654598384]
	TIME [epoch: 7.63 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1381494990354531		[learning rate: 0.0026615]
	Learning Rate: 0.00266151
	LOSS [training: 0.1381494990354531 | validation: 0.3000049691600354]
	TIME [epoch: 7.65 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1178395460939909		[learning rate: 0.002649]
	Learning Rate: 0.00264897
	LOSS [training: 0.1178395460939909 | validation: 0.315923466150548]
	TIME [epoch: 7.62 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12456593354225275		[learning rate: 0.0026365]
	Learning Rate: 0.00263649
	LOSS [training: 0.12456593354225275 | validation: 0.3272418340683443]
	TIME [epoch: 7.61 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1341457385697401		[learning rate: 0.0026241]
	Learning Rate: 0.00262406
	LOSS [training: 0.1341457385697401 | validation: 0.38082367095197167]
	TIME [epoch: 7.6 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12935432259864138		[learning rate: 0.0026117]
	Learning Rate: 0.0026117
	LOSS [training: 0.12935432259864138 | validation: 0.3184793337654492]
	TIME [epoch: 7.59 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1449056029267885		[learning rate: 0.0025994]
	Learning Rate: 0.00259939
	LOSS [training: 0.1449056029267885 | validation: 0.3195972493794146]
	TIME [epoch: 7.6 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13206909867489136		[learning rate: 0.0025871]
	Learning Rate: 0.00258714
	LOSS [training: 0.13206909867489136 | validation: 0.2831385120571802]
	TIME [epoch: 7.65 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13238651947444013		[learning rate: 0.002575]
	Learning Rate: 0.00257495
	LOSS [training: 0.13238651947444013 | validation: 0.32260000797625943]
	TIME [epoch: 7.62 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13256157258223034		[learning rate: 0.0025628]
	Learning Rate: 0.00256282
	LOSS [training: 0.13256157258223034 | validation: 0.36666515355819684]
	TIME [epoch: 7.61 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12260232543874461		[learning rate: 0.0025507]
	Learning Rate: 0.00255074
	LOSS [training: 0.12260232543874461 | validation: 0.3063270389318499]
	TIME [epoch: 7.6 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1515008314356939		[learning rate: 0.0025387]
	Learning Rate: 0.00253872
	LOSS [training: 0.1515008314356939 | validation: 0.3734728552849056]
	TIME [epoch: 7.6 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.139320548863546		[learning rate: 0.0025268]
	Learning Rate: 0.00252676
	LOSS [training: 0.139320548863546 | validation: 0.31671954133268276]
	TIME [epoch: 7.6 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12407223818838582		[learning rate: 0.0025149]
	Learning Rate: 0.00251485
	LOSS [training: 0.12407223818838582 | validation: 0.31730224858389616]
	TIME [epoch: 7.6 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1372406312801971		[learning rate: 0.002503]
	Learning Rate: 0.002503
	LOSS [training: 0.1372406312801971 | validation: 0.32925000912685964]
	TIME [epoch: 7.61 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12047367004839114		[learning rate: 0.0024912]
	Learning Rate: 0.00249121
	LOSS [training: 0.12047367004839114 | validation: 0.3246291170364467]
	TIME [epoch: 7.62 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10674655263181018		[learning rate: 0.0024795]
	Learning Rate: 0.00247947
	LOSS [training: 0.10674655263181018 | validation: 0.29367060583195426]
	TIME [epoch: 7.62 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11932878642636086		[learning rate: 0.0024678]
	Learning Rate: 0.00246779
	LOSS [training: 0.11932878642636086 | validation: 0.3463881893027925]
	TIME [epoch: 7.6 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17544395573521443		[learning rate: 0.0024562]
	Learning Rate: 0.00245616
	LOSS [training: 0.17544395573521443 | validation: 0.29962818450913287]
	TIME [epoch: 7.6 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1437208996837265		[learning rate: 0.0024446]
	Learning Rate: 0.00244458
	LOSS [training: 0.1437208996837265 | validation: 0.2884543477297365]
	TIME [epoch: 7.59 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1231024338226868		[learning rate: 0.0024331]
	Learning Rate: 0.00243307
	LOSS [training: 0.1231024338226868 | validation: 0.311112966581774]
	TIME [epoch: 7.61 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14143174884917153		[learning rate: 0.0024216]
	Learning Rate: 0.0024216
	LOSS [training: 0.14143174884917153 | validation: 0.3052248130351985]
	TIME [epoch: 7.6 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12171123148400093		[learning rate: 0.0024102]
	Learning Rate: 0.00241019
	LOSS [training: 0.12171123148400093 | validation: 0.32951739272570674]
	TIME [epoch: 7.59 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12490346748635578		[learning rate: 0.0023988]
	Learning Rate: 0.00239883
	LOSS [training: 0.12490346748635578 | validation: 0.30359198632020934]
	TIME [epoch: 7.6 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14303619803406523		[learning rate: 0.0023875]
	Learning Rate: 0.00238753
	LOSS [training: 0.14303619803406523 | validation: 0.32305434661176163]
	TIME [epoch: 7.61 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14832018800248775		[learning rate: 0.0023763]
	Learning Rate: 0.00237628
	LOSS [training: 0.14832018800248775 | validation: 0.3505305784929413]
	TIME [epoch: 7.61 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13775085621455813		[learning rate: 0.0023651]
	Learning Rate: 0.00236508
	LOSS [training: 0.13775085621455813 | validation: 0.37309657682658987]
	TIME [epoch: 7.62 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12322320146883545		[learning rate: 0.0023539]
	Learning Rate: 0.00235394
	LOSS [training: 0.12322320146883545 | validation: 0.3109947560867611]
	TIME [epoch: 7.61 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11446716860416062		[learning rate: 0.0023428]
	Learning Rate: 0.00234285
	LOSS [training: 0.11446716860416062 | validation: 0.3061990011701292]
	TIME [epoch: 7.61 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1274578105678241		[learning rate: 0.0023318]
	Learning Rate: 0.00233181
	LOSS [training: 0.1274578105678241 | validation: 0.32350861241139606]
	TIME [epoch: 7.63 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13072132857882782		[learning rate: 0.0023208]
	Learning Rate: 0.00232082
	LOSS [training: 0.13072132857882782 | validation: 0.3138947061674741]
	TIME [epoch: 7.61 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.140638287779367		[learning rate: 0.0023099]
	Learning Rate: 0.00230988
	LOSS [training: 0.140638287779367 | validation: 0.3042093047110292]
	TIME [epoch: 7.6 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11431294207744154		[learning rate: 0.002299]
	Learning Rate: 0.002299
	LOSS [training: 0.11431294207744154 | validation: 0.2887624854011974]
	TIME [epoch: 7.59 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13421238093749965		[learning rate: 0.0022882]
	Learning Rate: 0.00228816
	LOSS [training: 0.13421238093749965 | validation: 0.3080666229998692]
	TIME [epoch: 7.6 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13316852056110517		[learning rate: 0.0022774]
	Learning Rate: 0.00227738
	LOSS [training: 0.13316852056110517 | validation: 0.28883520223863]
	TIME [epoch: 7.62 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11214887640258288		[learning rate: 0.0022667]
	Learning Rate: 0.00226665
	LOSS [training: 0.11214887640258288 | validation: 0.31605410902995723]
	TIME [epoch: 7.59 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14542442774058917		[learning rate: 0.002256]
	Learning Rate: 0.00225597
	LOSS [training: 0.14542442774058917 | validation: 0.3507736929245717]
	TIME [epoch: 7.62 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13011699274177058		[learning rate: 0.0022453]
	Learning Rate: 0.00224534
	LOSS [training: 0.13011699274177058 | validation: 0.29919542681200695]
	TIME [epoch: 7.62 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11166189884517663		[learning rate: 0.0022348]
	Learning Rate: 0.00223476
	LOSS [training: 0.11166189884517663 | validation: 0.3337480317489117]
	TIME [epoch: 7.64 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12739707660186084		[learning rate: 0.0022242]
	Learning Rate: 0.00222423
	LOSS [training: 0.12739707660186084 | validation: 0.32632930999175963]
	TIME [epoch: 7.6 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13450599041254235		[learning rate: 0.0022137]
	Learning Rate: 0.00221375
	LOSS [training: 0.13450599041254235 | validation: 0.28059875845542087]
	TIME [epoch: 7.6 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12454254507473592		[learning rate: 0.0022033]
	Learning Rate: 0.00220332
	LOSS [training: 0.12454254507473592 | validation: 0.35290024362657]
	TIME [epoch: 7.6 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1252613147680929		[learning rate: 0.0021929]
	Learning Rate: 0.00219293
	LOSS [training: 0.1252613147680929 | validation: 0.3355497406691609]
	TIME [epoch: 7.63 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11886831611697952		[learning rate: 0.0021826]
	Learning Rate: 0.0021826
	LOSS [training: 0.11886831611697952 | validation: 0.2962508817952642]
	TIME [epoch: 7.62 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1312558808302023		[learning rate: 0.0021723]
	Learning Rate: 0.00217232
	LOSS [training: 0.1312558808302023 | validation: 0.34991436091578565]
	TIME [epoch: 7.61 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12254792489159543		[learning rate: 0.0021621]
	Learning Rate: 0.00216208
	LOSS [training: 0.12254792489159543 | validation: 0.37943731381863005]
	TIME [epoch: 7.6 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14852755016157215		[learning rate: 0.0021519]
	Learning Rate: 0.00215189
	LOSS [training: 0.14852755016157215 | validation: 0.3276998653115021]
	TIME [epoch: 7.61 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11944902661497306		[learning rate: 0.0021418]
	Learning Rate: 0.00214175
	LOSS [training: 0.11944902661497306 | validation: 0.2879522213877662]
	TIME [epoch: 7.62 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11999575039751229		[learning rate: 0.0021317]
	Learning Rate: 0.00213166
	LOSS [training: 0.11999575039751229 | validation: 0.32980189978849905]
	TIME [epoch: 7.62 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11684348545480439		[learning rate: 0.0021216]
	Learning Rate: 0.00212162
	LOSS [training: 0.11684348545480439 | validation: 0.2960387847862858]
	TIME [epoch: 7.63 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11679706240876794		[learning rate: 0.0021116]
	Learning Rate: 0.00211162
	LOSS [training: 0.11679706240876794 | validation: 0.31481173512971433]
	TIME [epoch: 7.63 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11895717374935141		[learning rate: 0.0021017]
	Learning Rate: 0.00210167
	LOSS [training: 0.11895717374935141 | validation: 0.33284027467998967]
	TIME [epoch: 7.63 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14109795233016184		[learning rate: 0.0020918]
	Learning Rate: 0.00209176
	LOSS [training: 0.14109795233016184 | validation: 0.32314850783140653]
	TIME [epoch: 7.6 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11811329027162942		[learning rate: 0.0020819]
	Learning Rate: 0.00208191
	LOSS [training: 0.11811329027162942 | validation: 0.3305406823818876]
	TIME [epoch: 7.6 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12274166001487025		[learning rate: 0.0020721]
	Learning Rate: 0.0020721
	LOSS [training: 0.12274166001487025 | validation: 0.3154418171641055]
	TIME [epoch: 7.63 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11239034332859543		[learning rate: 0.0020623]
	Learning Rate: 0.00206233
	LOSS [training: 0.11239034332859543 | validation: 0.3242161899371427]
	TIME [epoch: 7.61 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1009545247898733		[learning rate: 0.0020526]
	Learning Rate: 0.00205262
	LOSS [training: 0.1009545247898733 | validation: 0.354482018179002]
	TIME [epoch: 7.61 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12509831161935392		[learning rate: 0.0020429]
	Learning Rate: 0.00204294
	LOSS [training: 0.12509831161935392 | validation: 0.3309592078973848]
	TIME [epoch: 7.6 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13089916088701536		[learning rate: 0.0020333]
	Learning Rate: 0.00203332
	LOSS [training: 0.13089916088701536 | validation: 0.30004360030336663]
	TIME [epoch: 7.61 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10966004741245636		[learning rate: 0.0020237]
	Learning Rate: 0.00202374
	LOSS [training: 0.10966004741245636 | validation: 0.302176040169547]
	TIME [epoch: 7.61 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11981142583779808		[learning rate: 0.0020142]
	Learning Rate: 0.0020142
	LOSS [training: 0.11981142583779808 | validation: 0.31968736517754087]
	TIME [epoch: 7.62 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1350071101267011		[learning rate: 0.0020047]
	Learning Rate: 0.00200471
	LOSS [training: 0.1350071101267011 | validation: 0.3164176391625777]
	TIME [epoch: 7.61 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12014594391720919		[learning rate: 0.0019953]
	Learning Rate: 0.00199526
	LOSS [training: 0.12014594391720919 | validation: 0.34601813813502935]
	TIME [epoch: 7.6 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12531071902806523		[learning rate: 0.0019859]
	Learning Rate: 0.00198586
	LOSS [training: 0.12531071902806523 | validation: 0.3119257226961656]
	TIME [epoch: 7.59 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1473486168535214		[learning rate: 0.0019765]
	Learning Rate: 0.0019765
	LOSS [training: 0.1473486168535214 | validation: 0.29916719427697563]
	TIME [epoch: 7.63 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11384775279212987		[learning rate: 0.0019672]
	Learning Rate: 0.00196719
	LOSS [training: 0.11384775279212987 | validation: 0.36433426606017105]
	TIME [epoch: 7.62 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11063015430480959		[learning rate: 0.0019579]
	Learning Rate: 0.00195792
	LOSS [training: 0.11063015430480959 | validation: 0.3067134514682137]
	TIME [epoch: 7.61 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1259423521730439		[learning rate: 0.0019487]
	Learning Rate: 0.00194869
	LOSS [training: 0.1259423521730439 | validation: 0.34606757441896346]
	TIME [epoch: 7.59 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13906566411784832		[learning rate: 0.0019395]
	Learning Rate: 0.00193951
	LOSS [training: 0.13906566411784832 | validation: 0.3539717840640678]
	TIME [epoch: 7.6 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13907919255669468		[learning rate: 0.0019304]
	Learning Rate: 0.00193037
	LOSS [training: 0.13907919255669468 | validation: 0.3337663155584208]
	TIME [epoch: 7.61 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12493551109469876		[learning rate: 0.0019213]
	Learning Rate: 0.00192128
	LOSS [training: 0.12493551109469876 | validation: 0.2833858359901223]
	TIME [epoch: 7.6 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13127450911739869		[learning rate: 0.0019122]
	Learning Rate: 0.00191222
	LOSS [training: 0.13127450911739869 | validation: 0.32867528337060065]
	TIME [epoch: 7.59 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12311019966797715		[learning rate: 0.0019032]
	Learning Rate: 0.00190321
	LOSS [training: 0.12311019966797715 | validation: 0.3154140557408773]
	TIME [epoch: 7.61 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.126649899543288		[learning rate: 0.0018942]
	Learning Rate: 0.00189424
	LOSS [training: 0.126649899543288 | validation: 0.3163414965794492]
	TIME [epoch: 7.62 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12630838046518128		[learning rate: 0.0018853]
	Learning Rate: 0.00188532
	LOSS [training: 0.12630838046518128 | validation: 0.2881492102982347]
	TIME [epoch: 7.63 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1125174687184343		[learning rate: 0.0018764]
	Learning Rate: 0.00187643
	LOSS [training: 0.1125174687184343 | validation: 0.3129321478391903]
	TIME [epoch: 7.6 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12165699051530993		[learning rate: 0.0018676]
	Learning Rate: 0.00186759
	LOSS [training: 0.12165699051530993 | validation: 0.3104412262580548]
	TIME [epoch: 7.6 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1354536955494035		[learning rate: 0.0018588]
	Learning Rate: 0.00185879
	LOSS [training: 0.1354536955494035 | validation: 0.32528196546673727]
	TIME [epoch: 7.61 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15295859690072156		[learning rate: 0.00185]
	Learning Rate: 0.00185003
	LOSS [training: 0.15295859690072156 | validation: 0.3313135203148876]
	TIME [epoch: 7.62 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12150291441585574		[learning rate: 0.0018413]
	Learning Rate: 0.00184132
	LOSS [training: 0.12150291441585574 | validation: 0.3054257312821186]
	TIME [epoch: 7.6 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12516427305045924		[learning rate: 0.0018326]
	Learning Rate: 0.00183264
	LOSS [training: 0.12516427305045924 | validation: 0.2815922663791883]
	TIME [epoch: 7.63 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11155758461032378		[learning rate: 0.001824]
	Learning Rate: 0.001824
	LOSS [training: 0.11155758461032378 | validation: 0.3452675476908833]
	TIME [epoch: 7.6 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1265448675304698		[learning rate: 0.0018154]
	Learning Rate: 0.00181541
	LOSS [training: 0.1265448675304698 | validation: 0.3061481748675273]
	TIME [epoch: 7.63 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12043238867883876		[learning rate: 0.0018069]
	Learning Rate: 0.00180685
	LOSS [training: 0.12043238867883876 | validation: 0.3065434237759173]
	TIME [epoch: 7.6 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11822058201523927		[learning rate: 0.0017983]
	Learning Rate: 0.00179834
	LOSS [training: 0.11822058201523927 | validation: 0.3484954699122461]
	TIME [epoch: 7.61 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13121993452528335		[learning rate: 0.0017899]
	Learning Rate: 0.00178987
	LOSS [training: 0.13121993452528335 | validation: 0.3145714655723594]
	TIME [epoch: 7.6 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13111491543964443		[learning rate: 0.0017814]
	Learning Rate: 0.00178143
	LOSS [training: 0.13111491543964443 | validation: 0.32942070922733724]
	TIME [epoch: 7.61 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14164169838036447		[learning rate: 0.001773]
	Learning Rate: 0.00177304
	LOSS [training: 0.14164169838036447 | validation: 0.3241643140648283]
	TIME [epoch: 7.61 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11684801657806038		[learning rate: 0.0017647]
	Learning Rate: 0.00176468
	LOSS [training: 0.11684801657806038 | validation: 0.34101667735025554]
	TIME [epoch: 7.6 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11719607285593794		[learning rate: 0.0017564]
	Learning Rate: 0.00175637
	LOSS [training: 0.11719607285593794 | validation: 0.30201564899883]
	TIME [epoch: 7.6 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10491636149199544		[learning rate: 0.0017481]
	Learning Rate: 0.00174809
	LOSS [training: 0.10491636149199544 | validation: 0.2973994389263771]
	TIME [epoch: 7.59 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13416481488534326		[learning rate: 0.0017399]
	Learning Rate: 0.00173985
	LOSS [training: 0.13416481488534326 | validation: 0.3251868710764474]
	TIME [epoch: 7.61 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10679210170455919		[learning rate: 0.0017317]
	Learning Rate: 0.00173166
	LOSS [training: 0.10679210170455919 | validation: 0.34290116269675935]
	TIME [epoch: 7.6 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12344509355651864		[learning rate: 0.0017235]
	Learning Rate: 0.0017235
	LOSS [training: 0.12344509355651864 | validation: 0.28507577181191684]
	TIME [epoch: 7.62 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1164730368284846		[learning rate: 0.0017154]
	Learning Rate: 0.00171537
	LOSS [training: 0.1164730368284846 | validation: 0.3266059495088201]
	TIME [epoch: 7.63 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11198878178420674		[learning rate: 0.0017073]
	Learning Rate: 0.00170729
	LOSS [training: 0.11198878178420674 | validation: 0.3014030405636693]
	TIME [epoch: 7.62 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11903547861154518		[learning rate: 0.0016992]
	Learning Rate: 0.00169925
	LOSS [training: 0.11903547861154518 | validation: 0.3337959934434786]
	TIME [epoch: 7.61 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1433071006959057		[learning rate: 0.0016912]
	Learning Rate: 0.00169124
	LOSS [training: 0.1433071006959057 | validation: 0.2992454414215555]
	TIME [epoch: 7.61 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12321740829812611		[learning rate: 0.0016833]
	Learning Rate: 0.00168327
	LOSS [training: 0.12321740829812611 | validation: 0.33926103568545996]
	TIME [epoch: 7.59 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.112172239835613		[learning rate: 0.0016753]
	Learning Rate: 0.00167534
	LOSS [training: 0.112172239835613 | validation: 0.2977111182212726]
	TIME [epoch: 7.6 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12148719127152097		[learning rate: 0.0016674]
	Learning Rate: 0.00166744
	LOSS [training: 0.12148719127152097 | validation: 0.314106971747964]
	TIME [epoch: 7.61 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12789845783860823		[learning rate: 0.0016596]
	Learning Rate: 0.00165959
	LOSS [training: 0.12789845783860823 | validation: 0.3155457025998774]
	TIME [epoch: 7.61 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10854482876636125		[learning rate: 0.0016518]
	Learning Rate: 0.00165177
	LOSS [training: 0.10854482876636125 | validation: 0.30284211573193404]
	TIME [epoch: 7.62 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1109027373913763		[learning rate: 0.001644]
	Learning Rate: 0.00164398
	LOSS [training: 0.1109027373913763 | validation: 0.3190676226810725]
	TIME [epoch: 7.62 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10982268738460609		[learning rate: 0.0016362]
	Learning Rate: 0.00163624
	LOSS [training: 0.10982268738460609 | validation: 0.30759839687475754]
	TIME [epoch: 7.62 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11312473598100131		[learning rate: 0.0016285]
	Learning Rate: 0.00162853
	LOSS [training: 0.11312473598100131 | validation: 0.3415809333713243]
	TIME [epoch: 7.6 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11259961749454539		[learning rate: 0.0016209]
	Learning Rate: 0.00162085
	LOSS [training: 0.11259961749454539 | validation: 0.2873611203354025]
	TIME [epoch: 7.59 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11522868782143751		[learning rate: 0.0016132]
	Learning Rate: 0.00161322
	LOSS [training: 0.11522868782143751 | validation: 0.3158699000759792]
	TIME [epoch: 7.59 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14403754881305086		[learning rate: 0.0016056]
	Learning Rate: 0.00160561
	LOSS [training: 0.14403754881305086 | validation: 0.34040878045512557]
	TIME [epoch: 7.6 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1293559099785184		[learning rate: 0.001598]
	Learning Rate: 0.00159805
	LOSS [training: 0.1293559099785184 | validation: 0.29350799687895224]
	TIME [epoch: 7.62 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1179218954110034		[learning rate: 0.0015905]
	Learning Rate: 0.00159052
	LOSS [training: 0.1179218954110034 | validation: 0.30192352215754886]
	TIME [epoch: 7.61 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12998844643849966		[learning rate: 0.001583]
	Learning Rate: 0.00158302
	LOSS [training: 0.12998844643849966 | validation: 0.3137878813066169]
	TIME [epoch: 7.6 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11863742519888784		[learning rate: 0.0015756]
	Learning Rate: 0.00157556
	LOSS [training: 0.11863742519888784 | validation: 0.303018747795998]
	TIME [epoch: 7.6 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11556567158734493		[learning rate: 0.0015681]
	Learning Rate: 0.00156814
	LOSS [training: 0.11556567158734493 | validation: 0.29443065282353387]
	TIME [epoch: 7.6 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12027222247068789		[learning rate: 0.0015607]
	Learning Rate: 0.00156075
	LOSS [training: 0.12027222247068789 | validation: 0.3136822653036085]
	TIME [epoch: 7.59 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1070448312101734		[learning rate: 0.0015534]
	Learning Rate: 0.0015534
	LOSS [training: 0.1070448312101734 | validation: 0.2837113260814206]
	TIME [epoch: 7.59 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12034495938104166		[learning rate: 0.0015461]
	Learning Rate: 0.00154608
	LOSS [training: 0.12034495938104166 | validation: 0.3364287679760907]
	TIME [epoch: 7.59 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1307043782317003		[learning rate: 0.0015388]
	Learning Rate: 0.00153879
	LOSS [training: 0.1307043782317003 | validation: 0.3189348711486754]
	TIME [epoch: 7.6 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12074870884546376		[learning rate: 0.0015315]
	Learning Rate: 0.00153154
	LOSS [training: 0.12074870884546376 | validation: 0.2860164641811328]
	TIME [epoch: 7.61 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11429929015592438		[learning rate: 0.0015243]
	Learning Rate: 0.00152432
	LOSS [training: 0.11429929015592438 | validation: 0.31482968602482364]
	TIME [epoch: 7.6 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13935222417881193		[learning rate: 0.0015171]
	Learning Rate: 0.00151714
	LOSS [training: 0.13935222417881193 | validation: 0.30896288734538946]
	TIME [epoch: 7.59 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11294464808400645		[learning rate: 0.00151]
	Learning Rate: 0.00150999
	LOSS [training: 0.11294464808400645 | validation: 0.313050981637883]
	TIME [epoch: 7.59 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11977913025180137		[learning rate: 0.0015029]
	Learning Rate: 0.00150288
	LOSS [training: 0.11977913025180137 | validation: 0.3202509352162457]
	TIME [epoch: 7.6 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13027264752801515		[learning rate: 0.0014958]
	Learning Rate: 0.00149579
	LOSS [training: 0.13027264752801515 | validation: 0.3717503048860419]
	TIME [epoch: 7.59 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12281236861927673		[learning rate: 0.0014887]
	Learning Rate: 0.00148875
	LOSS [training: 0.12281236861927673 | validation: 0.3020189882280769]
	TIME [epoch: 7.61 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11280997177857416		[learning rate: 0.0014817]
	Learning Rate: 0.00148173
	LOSS [training: 0.11280997177857416 | validation: 0.32343924204514496]
	TIME [epoch: 7.6 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11448546000142834		[learning rate: 0.0014747]
	Learning Rate: 0.00147475
	LOSS [training: 0.11448546000142834 | validation: 0.2941346595399451]
	TIME [epoch: 7.6 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11506151525769416		[learning rate: 0.0014678]
	Learning Rate: 0.0014678
	LOSS [training: 0.11506151525769416 | validation: 0.31025929659321094]
	TIME [epoch: 7.59 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1188482054857073		[learning rate: 0.0014609]
	Learning Rate: 0.00146088
	LOSS [training: 0.1188482054857073 | validation: 0.31839120279111965]
	TIME [epoch: 7.59 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12695938320495792		[learning rate: 0.001454]
	Learning Rate: 0.001454
	LOSS [training: 0.12695938320495792 | validation: 0.32757013333294993]
	TIME [epoch: 7.58 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1281109228001369		[learning rate: 0.0014471]
	Learning Rate: 0.00144715
	LOSS [training: 0.1281109228001369 | validation: 0.2833712278396591]
	TIME [epoch: 7.59 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11746832854771531		[learning rate: 0.0014403]
	Learning Rate: 0.00144033
	LOSS [training: 0.11746832854771531 | validation: 0.32905548328482864]
	TIME [epoch: 7.65 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10548892342383917		[learning rate: 0.0014335]
	Learning Rate: 0.00143354
	LOSS [training: 0.10548892342383917 | validation: 0.32717686899803755]
	TIME [epoch: 7.62 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10705292906404261		[learning rate: 0.0014268]
	Learning Rate: 0.00142679
	LOSS [training: 0.10705292906404261 | validation: 0.3147782456229859]
	TIME [epoch: 7.59 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12415075592395265		[learning rate: 0.0014201]
	Learning Rate: 0.00142006
	LOSS [training: 0.12415075592395265 | validation: 0.29730007220659593]
	TIME [epoch: 7.59 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11596153311956961		[learning rate: 0.0014134]
	Learning Rate: 0.00141337
	LOSS [training: 0.11596153311956961 | validation: 0.28465351176962567]
	TIME [epoch: 7.6 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12328953451408828		[learning rate: 0.0014067]
	Learning Rate: 0.00140671
	LOSS [training: 0.12328953451408828 | validation: 0.35106383484250164]
	TIME [epoch: 7.61 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12270464863177039		[learning rate: 0.0014001]
	Learning Rate: 0.00140008
	LOSS [training: 0.12270464863177039 | validation: 0.3007414130034204]
	TIME [epoch: 7.6 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13327329829812165		[learning rate: 0.0013935]
	Learning Rate: 0.00139349
	LOSS [training: 0.13327329829812165 | validation: 0.34797929327934285]
	TIME [epoch: 7.62 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12663485045789874		[learning rate: 0.0013869]
	Learning Rate: 0.00138692
	LOSS [training: 0.12663485045789874 | validation: 0.29663277255421794]
	TIME [epoch: 7.61 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11749955582392324		[learning rate: 0.0013804]
	Learning Rate: 0.00138038
	LOSS [training: 0.11749955582392324 | validation: 0.3159233658519744]
	TIME [epoch: 7.61 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10962737640386798		[learning rate: 0.0013739]
	Learning Rate: 0.00137388
	LOSS [training: 0.10962737640386798 | validation: 0.29161633028923467]
	TIME [epoch: 7.59 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14344494669947205		[learning rate: 0.0013674]
	Learning Rate: 0.00136741
	LOSS [training: 0.14344494669947205 | validation: 0.3470217109842674]
	TIME [epoch: 7.6 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13390993161151438		[learning rate: 0.001361]
	Learning Rate: 0.00136096
	LOSS [training: 0.13390993161151438 | validation: 0.3115375538554213]
	TIME [epoch: 7.6 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11756320298056755		[learning rate: 0.0013545]
	Learning Rate: 0.00135455
	LOSS [training: 0.11756320298056755 | validation: 0.30647879432223857]
	TIME [epoch: 7.61 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11547500622700749		[learning rate: 0.0013482]
	Learning Rate: 0.00134817
	LOSS [training: 0.11547500622700749 | validation: 0.3354370168875709]
	TIME [epoch: 7.6 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11952139736460961		[learning rate: 0.0013418]
	Learning Rate: 0.00134181
	LOSS [training: 0.11952139736460961 | validation: 0.2907554440092487]
	TIME [epoch: 7.61 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12988111102298636		[learning rate: 0.0013355]
	Learning Rate: 0.00133549
	LOSS [training: 0.12988111102298636 | validation: 0.3552098056126469]
	TIME [epoch: 7.63 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v14_20240719_004707/states/model_facs_v4_dec2b_2dpca_v14_464.pth
Halted early. No improvement in validation loss for 200 epochs.
Finished training in 3432.111 seconds.
