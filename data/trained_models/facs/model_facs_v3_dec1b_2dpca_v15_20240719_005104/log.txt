Args:
Namespace(name='model_facs_v3_dec1b_2dpca_v15', outdir='out/model_training/model_facs_v3_dec1b_2dpca_v15', training_data='data/training_data/facs_v3/pca/dec1_fitonsubset/transition1_subset_epi_tr_ce_an_pc12/training', validation_data='data/training_data/facs_v3/pca/dec1_fitonsubset/transition1_subset_epi_tr_ce_an_pc12/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=10, batch_size=50, patience=200, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, quadratic_a=1.0, quadratic_b=1.0, ndims=2, nparams=2, nsigs=2, ncells=100, ncells_sample=100, model_do_sample=False, dt=0.005, dt_schedule='stepped', dt_schedule_bounds=[50, 500, 1000], dt_schedule_scales=[0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', kernel='multiscale', bw_range=[0.2, 0.5, 0.9, 1.1, 1.3, 1.5, 2.0], optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 1417725271

Training model...

Saving initial model state to: out/model_training/model_facs_v3_dec1b_2dpca_v15_20240719_005104/states/model_facs_v3_dec1b_2dpca_v15_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 6/6] avg loss: 2.0006644140533707		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.0006644140533707 | validation: 1.4588812665741333]
	TIME [epoch: 22.3 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15_20240719_005104/states/model_facs_v3_dec1b_2dpca_v15_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.3928904524561236		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3928904524561236 | validation: 1.195460311998348]
	TIME [epoch: 5.24 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15_20240719_005104/states/model_facs_v3_dec1b_2dpca_v15_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.2967385358342536		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2967385358342536 | validation: 1.1642519187885996]
	TIME [epoch: 5.24 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15_20240719_005104/states/model_facs_v3_dec1b_2dpca_v15_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.2438109733783744		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2438109733783744 | validation: 1.082695959628647]
	TIME [epoch: 5.23 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15_20240719_005104/states/model_facs_v3_dec1b_2dpca_v15_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.227432095177446		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.227432095177446 | validation: 1.1080497984350959]
	TIME [epoch: 5.22 sec]
EPOCH 6/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.189602569299374		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.189602569299374 | validation: 1.039605962168317]
	TIME [epoch: 5.26 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15_20240719_005104/states/model_facs_v3_dec1b_2dpca_v15_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.1626305254393074		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1626305254393074 | validation: 0.9801231153964185]
	TIME [epoch: 5.26 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15_20240719_005104/states/model_facs_v3_dec1b_2dpca_v15_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.0967932970021768		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0967932970021768 | validation: 0.9146539451642001]
	TIME [epoch: 5.27 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15_20240719_005104/states/model_facs_v3_dec1b_2dpca_v15_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.0961461430996284		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0961461430996284 | validation: 0.9345772323679787]
	TIME [epoch: 5.23 sec]
EPOCH 10/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.0090589896239515		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0090589896239515 | validation: 0.8751793177480355]
	TIME [epoch: 5.22 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15_20240719_005104/states/model_facs_v3_dec1b_2dpca_v15_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.003845291219606		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.003845291219606 | validation: 0.8237824772742588]
	TIME [epoch: 5.22 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15_20240719_005104/states/model_facs_v3_dec1b_2dpca_v15_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.9741204152907567		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9741204152907567 | validation: 0.8437740612437834]
	TIME [epoch: 5.22 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.9013531263824129		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9013531263824129 | validation: 0.7760660814540199]
	TIME [epoch: 5.23 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15_20240719_005104/states/model_facs_v3_dec1b_2dpca_v15_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.9377927983872629		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9377927983872629 | validation: 0.7425895610277359]
	TIME [epoch: 5.21 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15_20240719_005104/states/model_facs_v3_dec1b_2dpca_v15_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.8406280717638275		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8406280717638275 | validation: 0.6832808543963804]
	TIME [epoch: 5.22 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15_20240719_005104/states/model_facs_v3_dec1b_2dpca_v15_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.7498469542866221		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7498469542866221 | validation: 0.6340187205921954]
	TIME [epoch: 5.24 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15_20240719_005104/states/model_facs_v3_dec1b_2dpca_v15_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.7299154251138237		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7299154251138237 | validation: 0.5750469885097607]
	TIME [epoch: 5.27 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15_20240719_005104/states/model_facs_v3_dec1b_2dpca_v15_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.6276337930377476		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6276337930377476 | validation: 0.5263691686594016]
	TIME [epoch: 5.26 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15_20240719_005104/states/model_facs_v3_dec1b_2dpca_v15_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.586085402294591		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.586085402294591 | validation: 0.5211463614738592]
	TIME [epoch: 5.23 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15_20240719_005104/states/model_facs_v3_dec1b_2dpca_v15_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5306050499405138		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5306050499405138 | validation: 0.5916394698316775]
	TIME [epoch: 5.26 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5283243452072208		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5283243452072208 | validation: 0.37793979429942703]
	TIME [epoch: 5.23 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15_20240719_005104/states/model_facs_v3_dec1b_2dpca_v15_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4551910275407829		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4551910275407829 | validation: 0.4067418426675011]
	TIME [epoch: 5.22 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.42181915115135715		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.42181915115135715 | validation: 0.35802494675605623]
	TIME [epoch: 5.23 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15_20240719_005104/states/model_facs_v3_dec1b_2dpca_v15_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4460677781807245		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4460677781807245 | validation: 0.41771884644416557]
	TIME [epoch: 5.23 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4215502990503341		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4215502990503341 | validation: 0.3366482438237547]
	TIME [epoch: 5.23 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15_20240719_005104/states/model_facs_v3_dec1b_2dpca_v15_25.pth
	Model improved!!!
EPOCH 26/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.40561224024219794		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.40561224024219794 | validation: 0.3377887435062044]
	TIME [epoch: 5.26 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3907778569123663		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3907778569123663 | validation: 0.37765581319237235]
	TIME [epoch: 5.24 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.40472875245645196		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.40472875245645196 | validation: 0.292652306057824]
	TIME [epoch: 5.24 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15_20240719_005104/states/model_facs_v3_dec1b_2dpca_v15_28.pth
	Model improved!!!
EPOCH 29/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.38379654366347077		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.38379654366347077 | validation: 0.32782645621479833]
	TIME [epoch: 5.25 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4039179115141572		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4039179115141572 | validation: 0.3808832691021946]
	TIME [epoch: 5.24 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.39720021200617167		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.39720021200617167 | validation: 0.30464659577793557]
	TIME [epoch: 5.23 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.36241542107988484		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.36241542107988484 | validation: 0.29602576805016123]
	TIME [epoch: 5.23 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.36709594141162655		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.36709594141162655 | validation: 0.29495288879844467]
	TIME [epoch: 5.22 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.38659643685016315		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.38659643685016315 | validation: 0.30497705516454976]
	TIME [epoch: 5.23 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3622926488660787		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3622926488660787 | validation: 0.2735056276634633]
	TIME [epoch: 5.24 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15_20240719_005104/states/model_facs_v3_dec1b_2dpca_v15_35.pth
	Model improved!!!
EPOCH 36/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.34542197337408936		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.34542197337408936 | validation: 0.2932724378293302]
	TIME [epoch: 5.23 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3464657683009429		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3464657683009429 | validation: 0.3009714131171982]
	TIME [epoch: 5.23 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.34518036078849407		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.34518036078849407 | validation: 0.285900642798142]
	TIME [epoch: 5.23 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3317135137195934		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3317135137195934 | validation: 0.26797003178402523]
	TIME [epoch: 5.26 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15_20240719_005104/states/model_facs_v3_dec1b_2dpca_v15_39.pth
	Model improved!!!
EPOCH 40/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.34768639893727		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.34768639893727 | validation: 0.27046235467849]
	TIME [epoch: 5.26 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3312101108392574		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3312101108392574 | validation: 0.2508661665494353]
	TIME [epoch: 5.26 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15_20240719_005104/states/model_facs_v3_dec1b_2dpca_v15_41.pth
	Model improved!!!
EPOCH 42/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3197801932939188		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3197801932939188 | validation: 0.27445719883762826]
	TIME [epoch: 5.27 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.33297224593018865		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.33297224593018865 | validation: 0.28392715897578713]
	TIME [epoch: 5.24 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.317519850737378		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.317519850737378 | validation: 0.2672036633563548]
	TIME [epoch: 5.22 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.35731742890786605		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.35731742890786605 | validation: 0.2489107950928]
	TIME [epoch: 5.22 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15_20240719_005104/states/model_facs_v3_dec1b_2dpca_v15_45.pth
	Model improved!!!
EPOCH 46/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3173649723316005		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3173649723316005 | validation: 0.2816486809784041]
	TIME [epoch: 5.25 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3116918830664525		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3116918830664525 | validation: 0.2562576049960584]
	TIME [epoch: 5.29 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3453412899276281		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3453412899276281 | validation: 0.2883682742774517]
	TIME [epoch: 5.25 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.31944548261549427		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.31944548261549427 | validation: 0.24251462520578276]
	TIME [epoch: 5.24 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15_20240719_005104/states/model_facs_v3_dec1b_2dpca_v15_49.pth
	Model improved!!!
EPOCH 50/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29883494731472443		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.29883494731472443 | validation: 0.25157134915079266]
	TIME [epoch: 5.23 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2966960345237018		[learning rate: 0.0099705]
	Learning Rate: 0.00997052
	LOSS [training: 0.2966960345237018 | validation: 0.2592600893499352]
	TIME [epoch: 24.8 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.31315515994393733		[learning rate: 0.0099353]
	Learning Rate: 0.00993527
	LOSS [training: 0.31315515994393733 | validation: 0.24192218295818183]
	TIME [epoch: 9.99 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15_20240719_005104/states/model_facs_v3_dec1b_2dpca_v15_52.pth
	Model improved!!!
EPOCH 53/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3315309930037884		[learning rate: 0.0099001]
	Learning Rate: 0.00990013
	LOSS [training: 0.3315309930037884 | validation: 0.2295298397943367]
	TIME [epoch: 9.98 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15_20240719_005104/states/model_facs_v3_dec1b_2dpca_v15_53.pth
	Model improved!!!
EPOCH 54/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29148336921746665		[learning rate: 0.0098651]
	Learning Rate: 0.00986512
	LOSS [training: 0.29148336921746665 | validation: 0.24987275802241501]
	TIME [epoch: 10 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28671844597623414		[learning rate: 0.0098302]
	Learning Rate: 0.00983024
	LOSS [training: 0.28671844597623414 | validation: 0.26520046269050485]
	TIME [epoch: 9.99 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2978489934207412		[learning rate: 0.0097955]
	Learning Rate: 0.00979548
	LOSS [training: 0.2978489934207412 | validation: 0.25714772115598017]
	TIME [epoch: 10 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.31313042184133616		[learning rate: 0.0097608]
	Learning Rate: 0.00976084
	LOSS [training: 0.31313042184133616 | validation: 0.25805881809749925]
	TIME [epoch: 10 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3002512788188794		[learning rate: 0.0097263]
	Learning Rate: 0.00972632
	LOSS [training: 0.3002512788188794 | validation: 0.23391537839394258]
	TIME [epoch: 9.99 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.298274248979267		[learning rate: 0.0096919]
	Learning Rate: 0.00969193
	LOSS [training: 0.298274248979267 | validation: 0.28024034768849665]
	TIME [epoch: 9.99 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.31686639435454333		[learning rate: 0.0096577]
	Learning Rate: 0.00965766
	LOSS [training: 0.31686639435454333 | validation: 0.24904441572487895]
	TIME [epoch: 9.98 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.30390186099750743		[learning rate: 0.0096235]
	Learning Rate: 0.00962351
	LOSS [training: 0.30390186099750743 | validation: 0.2597570859706241]
	TIME [epoch: 9.97 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2986900997861212		[learning rate: 0.0095895]
	Learning Rate: 0.00958948
	LOSS [training: 0.2986900997861212 | validation: 0.3008320248655133]
	TIME [epoch: 9.99 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3140602708017294		[learning rate: 0.0095556]
	Learning Rate: 0.00955557
	LOSS [training: 0.3140602708017294 | validation: 0.2588288788792118]
	TIME [epoch: 10 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29521307179560125		[learning rate: 0.0095218]
	Learning Rate: 0.00952177
	LOSS [training: 0.29521307179560125 | validation: 0.24509671351376056]
	TIME [epoch: 10 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2996119404961075		[learning rate: 0.0094881]
	Learning Rate: 0.0094881
	LOSS [training: 0.2996119404961075 | validation: 0.2596951851551817]
	TIME [epoch: 9.99 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3085096394244536		[learning rate: 0.0094546]
	Learning Rate: 0.00945455
	LOSS [training: 0.3085096394244536 | validation: 0.24435683570936093]
	TIME [epoch: 10 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27710806670644533		[learning rate: 0.0094211]
	Learning Rate: 0.00942112
	LOSS [training: 0.27710806670644533 | validation: 0.26918154047047427]
	TIME [epoch: 10 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.30780406363401347		[learning rate: 0.0093878]
	Learning Rate: 0.00938781
	LOSS [training: 0.30780406363401347 | validation: 0.22460427136523342]
	TIME [epoch: 9.97 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15_20240719_005104/states/model_facs_v3_dec1b_2dpca_v15_68.pth
	Model improved!!!
EPOCH 69/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2899150192785786		[learning rate: 0.0093546]
	Learning Rate: 0.00935461
	LOSS [training: 0.2899150192785786 | validation: 0.2234162151404054]
	TIME [epoch: 9.98 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15_20240719_005104/states/model_facs_v3_dec1b_2dpca_v15_69.pth
	Model improved!!!
EPOCH 70/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.30472451293171693		[learning rate: 0.0093215]
	Learning Rate: 0.00932153
	LOSS [training: 0.30472451293171693 | validation: 0.23079736864694178]
	TIME [epoch: 10 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2822728529478858		[learning rate: 0.0092886]
	Learning Rate: 0.00928857
	LOSS [training: 0.2822728529478858 | validation: 0.23386531239864797]
	TIME [epoch: 10 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29175544800656855		[learning rate: 0.0092557]
	Learning Rate: 0.00925572
	LOSS [training: 0.29175544800656855 | validation: 0.22613483086648306]
	TIME [epoch: 9.98 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2874766348056016		[learning rate: 0.009223]
	Learning Rate: 0.00922299
	LOSS [training: 0.2874766348056016 | validation: 0.23922787941662227]
	TIME [epoch: 9.97 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.31192717031781936		[learning rate: 0.0091904]
	Learning Rate: 0.00919038
	LOSS [training: 0.31192717031781936 | validation: 0.2546469743130616]
	TIME [epoch: 10 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.30700263933561356		[learning rate: 0.0091579]
	Learning Rate: 0.00915788
	LOSS [training: 0.30700263933561356 | validation: 0.23064791069501184]
	TIME [epoch: 10 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27386289930163793		[learning rate: 0.0091255]
	Learning Rate: 0.00912549
	LOSS [training: 0.27386289930163793 | validation: 0.22370787351802957]
	TIME [epoch: 10 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2646678977376437		[learning rate: 0.0090932]
	Learning Rate: 0.00909323
	LOSS [training: 0.2646678977376437 | validation: 0.22137637293331708]
	TIME [epoch: 10 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15_20240719_005104/states/model_facs_v3_dec1b_2dpca_v15_77.pth
	Model improved!!!
EPOCH 78/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.34097564073132663		[learning rate: 0.0090611]
	Learning Rate: 0.00906107
	LOSS [training: 0.34097564073132663 | validation: 0.2526541726090189]
	TIME [epoch: 9.97 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3379719782710273		[learning rate: 0.009029]
	Learning Rate: 0.00902903
	LOSS [training: 0.3379719782710273 | validation: 0.28275692884664727]
	TIME [epoch: 9.96 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.33224508302268535		[learning rate: 0.0089971]
	Learning Rate: 0.0089971
	LOSS [training: 0.33224508302268535 | validation: 0.22609782462930186]
	TIME [epoch: 9.97 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3092194243780983		[learning rate: 0.0089653]
	Learning Rate: 0.00896528
	LOSS [training: 0.3092194243780983 | validation: 0.2300937249317852]
	TIME [epoch: 9.97 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3231631140582288		[learning rate: 0.0089336]
	Learning Rate: 0.00893358
	LOSS [training: 0.3231631140582288 | validation: 0.26033250632914556]
	TIME [epoch: 10 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.30236021267343		[learning rate: 0.008902]
	Learning Rate: 0.00890199
	LOSS [training: 0.30236021267343 | validation: 0.22152930202902485]
	TIME [epoch: 10 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3032335403048889		[learning rate: 0.0088705]
	Learning Rate: 0.00887051
	LOSS [training: 0.3032335403048889 | validation: 0.23750388072873382]
	TIME [epoch: 9.99 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3033583674698618		[learning rate: 0.0088391]
	Learning Rate: 0.00883914
	LOSS [training: 0.3033583674698618 | validation: 0.21611551919695682]
	TIME [epoch: 9.99 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15_20240719_005104/states/model_facs_v3_dec1b_2dpca_v15_85.pth
	Model improved!!!
EPOCH 86/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.290252631844651		[learning rate: 0.0088079]
	Learning Rate: 0.00880789
	LOSS [training: 0.290252631844651 | validation: 0.24261534329024662]
	TIME [epoch: 9.99 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2959859033671323		[learning rate: 0.0087767]
	Learning Rate: 0.00877674
	LOSS [training: 0.2959859033671323 | validation: 0.24984645978311476]
	TIME [epoch: 10 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29038139837024135		[learning rate: 0.0087457]
	Learning Rate: 0.00874571
	LOSS [training: 0.29038139837024135 | validation: 0.21738181897165845]
	TIME [epoch: 9.98 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2725716239805709		[learning rate: 0.0087148]
	Learning Rate: 0.00871478
	LOSS [training: 0.2725716239805709 | validation: 0.24241909465571915]
	TIME [epoch: 9.97 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2822419381997487		[learning rate: 0.008684]
	Learning Rate: 0.00868396
	LOSS [training: 0.2822419381997487 | validation: 0.22514041951840474]
	TIME [epoch: 9.96 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.283744262126955		[learning rate: 0.0086533]
	Learning Rate: 0.00865326
	LOSS [training: 0.283744262126955 | validation: 0.21296779688747067]
	TIME [epoch: 9.97 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15_20240719_005104/states/model_facs_v3_dec1b_2dpca_v15_91.pth
	Model improved!!!
EPOCH 92/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2857362346547909		[learning rate: 0.0086227]
	Learning Rate: 0.00862265
	LOSS [training: 0.2857362346547909 | validation: 0.2623434099101146]
	TIME [epoch: 10 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2893057331181635		[learning rate: 0.0085922]
	Learning Rate: 0.00859216
	LOSS [training: 0.2893057331181635 | validation: 0.21746366153033575]
	TIME [epoch: 10 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29099240812399946		[learning rate: 0.0085618]
	Learning Rate: 0.00856178
	LOSS [training: 0.29099240812399946 | validation: 0.21877477712580373]
	TIME [epoch: 10 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2856370671289132		[learning rate: 0.0085315]
	Learning Rate: 0.0085315
	LOSS [training: 0.2856370671289132 | validation: 0.22650751130377506]
	TIME [epoch: 9.97 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2850119763817301		[learning rate: 0.0085013]
	Learning Rate: 0.00850134
	LOSS [training: 0.2850119763817301 | validation: 0.22612614327114935]
	TIME [epoch: 9.98 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2879581049474707		[learning rate: 0.0084713]
	Learning Rate: 0.00847127
	LOSS [training: 0.2879581049474707 | validation: 0.21841482922323632]
	TIME [epoch: 9.99 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3061236227421863		[learning rate: 0.0084413]
	Learning Rate: 0.00844132
	LOSS [training: 0.3061236227421863 | validation: 0.238283421474294]
	TIME [epoch: 9.99 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.289509787298792		[learning rate: 0.0084115]
	Learning Rate: 0.00841147
	LOSS [training: 0.289509787298792 | validation: 0.23073538576943262]
	TIME [epoch: 10 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2809344531672832		[learning rate: 0.0083817]
	Learning Rate: 0.00838172
	LOSS [training: 0.2809344531672832 | validation: 0.22169072067970658]
	TIME [epoch: 10 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.275079942348824		[learning rate: 0.0083521]
	Learning Rate: 0.00835208
	LOSS [training: 0.275079942348824 | validation: 0.2235029860744711]
	TIME [epoch: 9.98 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28454012016944435		[learning rate: 0.0083225]
	Learning Rate: 0.00832255
	LOSS [training: 0.28454012016944435 | validation: 0.21871222858842604]
	TIME [epoch: 9.97 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2905018317622201		[learning rate: 0.0082931]
	Learning Rate: 0.00829312
	LOSS [training: 0.2905018317622201 | validation: 0.21670765258614466]
	TIME [epoch: 9.98 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2713520797055076		[learning rate: 0.0082638]
	Learning Rate: 0.00826379
	LOSS [training: 0.2713520797055076 | validation: 0.23298824746377828]
	TIME [epoch: 10 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28709897265497614		[learning rate: 0.0082346]
	Learning Rate: 0.00823457
	LOSS [training: 0.28709897265497614 | validation: 0.232151326646378]
	TIME [epoch: 10 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28858964896870337		[learning rate: 0.0082055]
	Learning Rate: 0.00820545
	LOSS [training: 0.28858964896870337 | validation: 0.2117749129369829]
	TIME [epoch: 9.99 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15_20240719_005104/states/model_facs_v3_dec1b_2dpca_v15_106.pth
	Model improved!!!
EPOCH 107/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2854248748765123		[learning rate: 0.0081764]
	Learning Rate: 0.00817644
	LOSS [training: 0.2854248748765123 | validation: 0.22609063618203828]
	TIME [epoch: 9.96 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28042250655481155		[learning rate: 0.0081475]
	Learning Rate: 0.00814752
	LOSS [training: 0.28042250655481155 | validation: 0.215202339290501]
	TIME [epoch: 9.97 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2750362655210096		[learning rate: 0.0081187]
	Learning Rate: 0.00811871
	LOSS [training: 0.2750362655210096 | validation: 0.2380327018862874]
	TIME [epoch: 9.97 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2895439364400993		[learning rate: 0.00809]
	Learning Rate: 0.00809
	LOSS [training: 0.2895439364400993 | validation: 0.22492838601163098]
	TIME [epoch: 9.98 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2581329819820439		[learning rate: 0.0080614]
	Learning Rate: 0.0080614
	LOSS [training: 0.2581329819820439 | validation: 0.24756964243963325]
	TIME [epoch: 10 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29781868452192645		[learning rate: 0.0080329]
	Learning Rate: 0.00803289
	LOSS [training: 0.29781868452192645 | validation: 0.2446223879550522]
	TIME [epoch: 9.97 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26701098017436903		[learning rate: 0.0080045]
	Learning Rate: 0.00800448
	LOSS [training: 0.26701098017436903 | validation: 0.22545555523972866]
	TIME [epoch: 9.96 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26868452248243857		[learning rate: 0.0079762]
	Learning Rate: 0.00797618
	LOSS [training: 0.26868452248243857 | validation: 0.21880739699902346]
	TIME [epoch: 9.98 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2794012415741027		[learning rate: 0.007948]
	Learning Rate: 0.00794797
	LOSS [training: 0.2794012415741027 | validation: 0.21645264252596402]
	TIME [epoch: 10 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2736883035785887		[learning rate: 0.0079199]
	Learning Rate: 0.00791987
	LOSS [training: 0.2736883035785887 | validation: 0.21537074986902877]
	TIME [epoch: 10 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2797586984580512		[learning rate: 0.0078919]
	Learning Rate: 0.00789186
	LOSS [training: 0.2797586984580512 | validation: 0.21859619141695735]
	TIME [epoch: 10 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2737013237767097		[learning rate: 0.007864]
	Learning Rate: 0.00786395
	LOSS [training: 0.2737013237767097 | validation: 0.23344343701158793]
	TIME [epoch: 9.98 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28593487942671264		[learning rate: 0.0078361]
	Learning Rate: 0.00783615
	LOSS [training: 0.28593487942671264 | validation: 0.21685098182419224]
	TIME [epoch: 9.97 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2649206942021111		[learning rate: 0.0078084]
	Learning Rate: 0.00780844
	LOSS [training: 0.2649206942021111 | validation: 0.23205771413385912]
	TIME [epoch: 9.98 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26929423530701785		[learning rate: 0.0077808]
	Learning Rate: 0.00778083
	LOSS [training: 0.26929423530701785 | validation: 0.23487656430180878]
	TIME [epoch: 9.99 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2762933612571781		[learning rate: 0.0077533]
	Learning Rate: 0.00775331
	LOSS [training: 0.2762933612571781 | validation: 0.20972122643009916]
	TIME [epoch: 10 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15_20240719_005104/states/model_facs_v3_dec1b_2dpca_v15_122.pth
	Model improved!!!
EPOCH 123/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2806820411837141		[learning rate: 0.0077259]
	Learning Rate: 0.00772589
	LOSS [training: 0.2806820411837141 | validation: 0.20882847218566475]
	TIME [epoch: 10 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15_20240719_005104/states/model_facs_v3_dec1b_2dpca_v15_123.pth
	Model improved!!!
EPOCH 124/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2680227749464957		[learning rate: 0.0076986]
	Learning Rate: 0.00769857
	LOSS [training: 0.2680227749464957 | validation: 0.2214632109762075]
	TIME [epoch: 9.98 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2633426934492196		[learning rate: 0.0076714]
	Learning Rate: 0.00767135
	LOSS [training: 0.2633426934492196 | validation: 0.21420033549756204]
	TIME [epoch: 9.98 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29751377995709744		[learning rate: 0.0076442]
	Learning Rate: 0.00764422
	LOSS [training: 0.29751377995709744 | validation: 0.2273401457854248]
	TIME [epoch: 10 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2781596870279411		[learning rate: 0.0076172]
	Learning Rate: 0.00761719
	LOSS [training: 0.2781596870279411 | validation: 0.21981325846349525]
	TIME [epoch: 10 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26376750308477015		[learning rate: 0.0075903]
	Learning Rate: 0.00759025
	LOSS [training: 0.26376750308477015 | validation: 0.2171255239580902]
	TIME [epoch: 9.98 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2751821506388881		[learning rate: 0.0075634]
	Learning Rate: 0.00756341
	LOSS [training: 0.2751821506388881 | validation: 0.21875192456492973]
	TIME [epoch: 9.99 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2702183958112218		[learning rate: 0.0075367]
	Learning Rate: 0.00753667
	LOSS [training: 0.2702183958112218 | validation: 0.24021356152922163]
	TIME [epoch: 9.97 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27138506893112146		[learning rate: 0.00751]
	Learning Rate: 0.00751002
	LOSS [training: 0.27138506893112146 | validation: 0.2048618563551579]
	TIME [epoch: 10 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15_20240719_005104/states/model_facs_v3_dec1b_2dpca_v15_131.pth
	Model improved!!!
EPOCH 132/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26866288858918685		[learning rate: 0.0074835]
	Learning Rate: 0.00748346
	LOSS [training: 0.26866288858918685 | validation: 0.2306786150454636]
	TIME [epoch: 10 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2660121527533861		[learning rate: 0.007457]
	Learning Rate: 0.007457
	LOSS [training: 0.2660121527533861 | validation: 0.2262042917753043]
	TIME [epoch: 10 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27174318909104456		[learning rate: 0.0074306]
	Learning Rate: 0.00743063
	LOSS [training: 0.27174318909104456 | validation: 0.2105249054313672]
	TIME [epoch: 10 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27435033377930146		[learning rate: 0.0074044]
	Learning Rate: 0.00740435
	LOSS [training: 0.27435033377930146 | validation: 0.2267598764606577]
	TIME [epoch: 10 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28339062363348294		[learning rate: 0.0073782]
	Learning Rate: 0.00737817
	LOSS [training: 0.28339062363348294 | validation: 0.26445688429420716]
	TIME [epoch: 9.95 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3025432212524061		[learning rate: 0.0073521]
	Learning Rate: 0.00735208
	LOSS [training: 0.3025432212524061 | validation: 0.21277073645469038]
	TIME [epoch: 9.96 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27469546262675243		[learning rate: 0.0073261]
	Learning Rate: 0.00732608
	LOSS [training: 0.27469546262675243 | validation: 0.21271421398085807]
	TIME [epoch: 9.96 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.252753960126012		[learning rate: 0.0073002]
	Learning Rate: 0.00730018
	LOSS [training: 0.252753960126012 | validation: 0.23260812662801417]
	TIME [epoch: 9.96 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27305232567726123		[learning rate: 0.0072744]
	Learning Rate: 0.00727436
	LOSS [training: 0.27305232567726123 | validation: 0.21513232355218212]
	TIME [epoch: 9.97 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2816252369877172		[learning rate: 0.0072486]
	Learning Rate: 0.00724864
	LOSS [training: 0.2816252369877172 | validation: 0.2240879099321352]
	TIME [epoch: 9.97 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2668246753271505		[learning rate: 0.007223]
	Learning Rate: 0.007223
	LOSS [training: 0.2668246753271505 | validation: 0.2096951473004418]
	TIME [epoch: 9.96 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27328599237233236		[learning rate: 0.0071975]
	Learning Rate: 0.00719746
	LOSS [training: 0.27328599237233236 | validation: 0.2328728998029682]
	TIME [epoch: 9.97 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2721018733121557		[learning rate: 0.007172]
	Learning Rate: 0.00717201
	LOSS [training: 0.2721018733121557 | validation: 0.21238024634043767]
	TIME [epoch: 9.96 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2661474942774836		[learning rate: 0.0071467]
	Learning Rate: 0.00714665
	LOSS [training: 0.2661474942774836 | validation: 0.2259419452003379]
	TIME [epoch: 9.96 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2652407924712576		[learning rate: 0.0071214]
	Learning Rate: 0.00712138
	LOSS [training: 0.2652407924712576 | validation: 0.2247714978586474]
	TIME [epoch: 9.97 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27279859809421175		[learning rate: 0.0070962]
	Learning Rate: 0.0070962
	LOSS [training: 0.27279859809421175 | validation: 0.23066414551773415]
	TIME [epoch: 9.98 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25949137427791835		[learning rate: 0.0070711]
	Learning Rate: 0.0070711
	LOSS [training: 0.25949137427791835 | validation: 0.2138266079720581]
	TIME [epoch: 10 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2620588475099357		[learning rate: 0.0070461]
	Learning Rate: 0.0070461
	LOSS [training: 0.2620588475099357 | validation: 0.2301454414644426]
	TIME [epoch: 10.1 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25640517680335756		[learning rate: 0.0070212]
	Learning Rate: 0.00702118
	LOSS [training: 0.25640517680335756 | validation: 0.23498614740620738]
	TIME [epoch: 9.99 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2863137548025867		[learning rate: 0.0069964]
	Learning Rate: 0.00699635
	LOSS [training: 0.2863137548025867 | validation: 0.21264403294737094]
	TIME [epoch: 9.97 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2626198162522314		[learning rate: 0.0069716]
	Learning Rate: 0.00697161
	LOSS [training: 0.2626198162522314 | validation: 0.21752469259538043]
	TIME [epoch: 9.98 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27863303743199386		[learning rate: 0.006947]
	Learning Rate: 0.00694696
	LOSS [training: 0.27863303743199386 | validation: 0.22066572174537905]
	TIME [epoch: 9.97 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2710247700580925		[learning rate: 0.0069224]
	Learning Rate: 0.00692239
	LOSS [training: 0.2710247700580925 | validation: 0.22933405734290296]
	TIME [epoch: 9.98 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.266970403516548		[learning rate: 0.0068979]
	Learning Rate: 0.00689792
	LOSS [training: 0.266970403516548 | validation: 0.21032057961508688]
	TIME [epoch: 9.99 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27888616682580547		[learning rate: 0.0068735]
	Learning Rate: 0.00687352
	LOSS [training: 0.27888616682580547 | validation: 0.21531883883959635]
	TIME [epoch: 10 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26510347600556416		[learning rate: 0.0068492]
	Learning Rate: 0.00684922
	LOSS [training: 0.26510347600556416 | validation: 0.20733094607923103]
	TIME [epoch: 10 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25732816411520604		[learning rate: 0.006825]
	Learning Rate: 0.006825
	LOSS [training: 0.25732816411520604 | validation: 0.2139174419487498]
	TIME [epoch: 10 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2590560176035099		[learning rate: 0.0068009]
	Learning Rate: 0.00680086
	LOSS [training: 0.2590560176035099 | validation: 0.22256788437380054]
	TIME [epoch: 9.98 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2765208582610213		[learning rate: 0.0067768]
	Learning Rate: 0.00677681
	LOSS [training: 0.2765208582610213 | validation: 0.22048030184763587]
	TIME [epoch: 9.99 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2749358211712368		[learning rate: 0.0067529]
	Learning Rate: 0.00675285
	LOSS [training: 0.2749358211712368 | validation: 0.2155278333087808]
	TIME [epoch: 10 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.257809530703954		[learning rate: 0.006729]
	Learning Rate: 0.00672897
	LOSS [training: 0.257809530703954 | validation: 0.2191326918584895]
	TIME [epoch: 10 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2740310285020879		[learning rate: 0.0067052]
	Learning Rate: 0.00670518
	LOSS [training: 0.2740310285020879 | validation: 0.2338456775954026]
	TIME [epoch: 10 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26472441727936685		[learning rate: 0.0066815]
	Learning Rate: 0.00668147
	LOSS [training: 0.26472441727936685 | validation: 0.22476281230513914]
	TIME [epoch: 9.99 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25569070210394146		[learning rate: 0.0066578]
	Learning Rate: 0.00665784
	LOSS [training: 0.25569070210394146 | validation: 0.2289271550823046]
	TIME [epoch: 9.97 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2715149497278888		[learning rate: 0.0066343]
	Learning Rate: 0.0066343
	LOSS [training: 0.2715149497278888 | validation: 0.23035442118578803]
	TIME [epoch: 10 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2701889275074411		[learning rate: 0.0066108]
	Learning Rate: 0.00661084
	LOSS [training: 0.2701889275074411 | validation: 0.23577843114400357]
	TIME [epoch: 9.98 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25132085850217983		[learning rate: 0.0065875]
	Learning Rate: 0.00658746
	LOSS [training: 0.25132085850217983 | validation: 0.21570369404512593]
	TIME [epoch: 10 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28639297282408466		[learning rate: 0.0065642]
	Learning Rate: 0.00656416
	LOSS [training: 0.28639297282408466 | validation: 0.22248379949609598]
	TIME [epoch: 9.98 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27018779380658825		[learning rate: 0.006541]
	Learning Rate: 0.00654095
	LOSS [training: 0.27018779380658825 | validation: 0.22054636168542308]
	TIME [epoch: 9.98 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28048158703141696		[learning rate: 0.0065178]
	Learning Rate: 0.00651782
	LOSS [training: 0.28048158703141696 | validation: 0.22754877587286462]
	TIME [epoch: 9.98 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2827033244857475		[learning rate: 0.0064948]
	Learning Rate: 0.00649477
	LOSS [training: 0.2827033244857475 | validation: 0.20505425147252368]
	TIME [epoch: 10 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26074790809139825		[learning rate: 0.0064718]
	Learning Rate: 0.00647181
	LOSS [training: 0.26074790809139825 | validation: 0.2113889391991453]
	TIME [epoch: 9.98 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2637188294224831		[learning rate: 0.0064489]
	Learning Rate: 0.00644892
	LOSS [training: 0.2637188294224831 | validation: 0.21258466527714964]
	TIME [epoch: 10 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2593086910481362		[learning rate: 0.0064261]
	Learning Rate: 0.00642612
	LOSS [training: 0.2593086910481362 | validation: 0.22108803091173276]
	TIME [epoch: 10 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25431058724054506		[learning rate: 0.0064034]
	Learning Rate: 0.00640339
	LOSS [training: 0.25431058724054506 | validation: 0.2241247164761176]
	TIME [epoch: 10 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25288522324537266		[learning rate: 0.0063808]
	Learning Rate: 0.00638075
	LOSS [training: 0.25288522324537266 | validation: 0.22222739110373899]
	TIME [epoch: 9.99 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2787583991404941		[learning rate: 0.0063582]
	Learning Rate: 0.00635819
	LOSS [training: 0.2787583991404941 | validation: 0.22917615354881676]
	TIME [epoch: 10 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26020851722184185		[learning rate: 0.0063357]
	Learning Rate: 0.0063357
	LOSS [training: 0.26020851722184185 | validation: 0.2220486457771112]
	TIME [epoch: 9.98 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2714882873156665		[learning rate: 0.0063133]
	Learning Rate: 0.0063133
	LOSS [training: 0.2714882873156665 | validation: 0.2274442174843251]
	TIME [epoch: 10 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26684827965534713		[learning rate: 0.006291]
	Learning Rate: 0.00629097
	LOSS [training: 0.26684827965534713 | validation: 0.2109413404873331]
	TIME [epoch: 10 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2567662150755504		[learning rate: 0.0062687]
	Learning Rate: 0.00626873
	LOSS [training: 0.2567662150755504 | validation: 0.22060417256199435]
	TIME [epoch: 9.99 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26519412139429704		[learning rate: 0.0062466]
	Learning Rate: 0.00624656
	LOSS [training: 0.26519412139429704 | validation: 0.2189823716132783]
	TIME [epoch: 10 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2676556394466589		[learning rate: 0.0062245]
	Learning Rate: 0.00622447
	LOSS [training: 0.2676556394466589 | validation: 0.20967379109089573]
	TIME [epoch: 10 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26022782037675823		[learning rate: 0.0062025]
	Learning Rate: 0.00620246
	LOSS [training: 0.26022782037675823 | validation: 0.2140290078098611]
	TIME [epoch: 10 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2676827162548954		[learning rate: 0.0061805]
	Learning Rate: 0.00618053
	LOSS [training: 0.2676827162548954 | validation: 0.22695275218311095]
	TIME [epoch: 9.98 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25917300187427106		[learning rate: 0.0061587]
	Learning Rate: 0.00615867
	LOSS [training: 0.25917300187427106 | validation: 0.218924147240228]
	TIME [epoch: 9.98 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2523588969072724		[learning rate: 0.0061369]
	Learning Rate: 0.00613689
	LOSS [training: 0.2523588969072724 | validation: 0.21462432083100053]
	TIME [epoch: 9.97 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.258922683551491		[learning rate: 0.0061152]
	Learning Rate: 0.00611519
	LOSS [training: 0.258922683551491 | validation: 0.22058425746140112]
	TIME [epoch: 9.97 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2629616230114219		[learning rate: 0.0060936]
	Learning Rate: 0.00609357
	LOSS [training: 0.2629616230114219 | validation: 0.22405225674811707]
	TIME [epoch: 10 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24758596223577678		[learning rate: 0.006072]
	Learning Rate: 0.00607202
	LOSS [training: 0.24758596223577678 | validation: 0.21844733249258966]
	TIME [epoch: 10 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2762391197469102		[learning rate: 0.0060505]
	Learning Rate: 0.00605055
	LOSS [training: 0.2762391197469102 | validation: 0.2141852620864945]
	TIME [epoch: 10 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2650145450763714		[learning rate: 0.0060292]
	Learning Rate: 0.00602915
	LOSS [training: 0.2650145450763714 | validation: 0.21474822061173088]
	TIME [epoch: 10 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2681491032519096		[learning rate: 0.0060078]
	Learning Rate: 0.00600783
	LOSS [training: 0.2681491032519096 | validation: 0.21356041490531436]
	TIME [epoch: 9.97 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25313715389145475		[learning rate: 0.0059866]
	Learning Rate: 0.00598659
	LOSS [training: 0.25313715389145475 | validation: 0.20614014571979777]
	TIME [epoch: 10 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2698250224769167		[learning rate: 0.0059654]
	Learning Rate: 0.00596542
	LOSS [training: 0.2698250224769167 | validation: 0.21450912178975695]
	TIME [epoch: 10.1 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25897947400550514		[learning rate: 0.0059443]
	Learning Rate: 0.00594433
	LOSS [training: 0.25897947400550514 | validation: 0.21355973010043144]
	TIME [epoch: 9.99 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2501294122256305		[learning rate: 0.0059233]
	Learning Rate: 0.0059233
	LOSS [training: 0.2501294122256305 | validation: 0.22227444947473188]
	TIME [epoch: 9.97 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2614977433848621		[learning rate: 0.0059024]
	Learning Rate: 0.00590236
	LOSS [training: 0.2614977433848621 | validation: 0.2191068601120804]
	TIME [epoch: 9.98 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26964685399611515		[learning rate: 0.0058815]
	Learning Rate: 0.00588149
	LOSS [training: 0.26964685399611515 | validation: 0.21678955603707797]
	TIME [epoch: 9.98 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2590329198712414		[learning rate: 0.0058607]
	Learning Rate: 0.00586069
	LOSS [training: 0.2590329198712414 | validation: 0.2301522580120287]
	TIME [epoch: 9.98 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2589918972722047		[learning rate: 0.00584]
	Learning Rate: 0.00583996
	LOSS [training: 0.2589918972722047 | validation: 0.2084928448932045]
	TIME [epoch: 9.98 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25859748373709607		[learning rate: 0.0058193]
	Learning Rate: 0.00581931
	LOSS [training: 0.25859748373709607 | validation: 0.21917572363834523]
	TIME [epoch: 9.97 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27234295705523853		[learning rate: 0.0057987]
	Learning Rate: 0.00579874
	LOSS [training: 0.27234295705523853 | validation: 0.2100342854352159]
	TIME [epoch: 10 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26365523732856916		[learning rate: 0.0057782]
	Learning Rate: 0.00577823
	LOSS [training: 0.26365523732856916 | validation: 0.23743660598583424]
	TIME [epoch: 9.97 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27460447278763683		[learning rate: 0.0057578]
	Learning Rate: 0.0057578
	LOSS [training: 0.27460447278763683 | validation: 0.21845653088428135]
	TIME [epoch: 9.99 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2713948096146381		[learning rate: 0.0057374]
	Learning Rate: 0.00573744
	LOSS [training: 0.2713948096146381 | validation: 0.2105372422783541]
	TIME [epoch: 9.98 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2638284360470402		[learning rate: 0.0057171]
	Learning Rate: 0.00571715
	LOSS [training: 0.2638284360470402 | validation: 0.21723583560623866]
	TIME [epoch: 9.99 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25482517468999016		[learning rate: 0.0056969]
	Learning Rate: 0.00569693
	LOSS [training: 0.25482517468999016 | validation: 0.2117489407721939]
	TIME [epoch: 10 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26751953780292326		[learning rate: 0.0056768]
	Learning Rate: 0.00567679
	LOSS [training: 0.26751953780292326 | validation: 0.20424375929680588]
	TIME [epoch: 10.3 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15_20240719_005104/states/model_facs_v3_dec1b_2dpca_v15_210.pth
	Model improved!!!
EPOCH 211/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26038323279985		[learning rate: 0.0056567]
	Learning Rate: 0.00565671
	LOSS [training: 0.26038323279985 | validation: 0.21270244272333438]
	TIME [epoch: 9.98 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26288158973094383		[learning rate: 0.0056367]
	Learning Rate: 0.00563671
	LOSS [training: 0.26288158973094383 | validation: 0.21409853332753875]
	TIME [epoch: 9.96 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2561220599357066		[learning rate: 0.0056168]
	Learning Rate: 0.00561678
	LOSS [training: 0.2561220599357066 | validation: 0.22123715163824995]
	TIME [epoch: 9.98 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2590909458097614		[learning rate: 0.0055969]
	Learning Rate: 0.00559691
	LOSS [training: 0.2590909458097614 | validation: 0.22680404353207498]
	TIME [epoch: 9.99 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26916740864101146		[learning rate: 0.0055771]
	Learning Rate: 0.00557712
	LOSS [training: 0.26916740864101146 | validation: 0.21716927645381662]
	TIME [epoch: 9.98 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2593084399428374		[learning rate: 0.0055574]
	Learning Rate: 0.0055574
	LOSS [training: 0.2593084399428374 | validation: 0.21099242518515035]
	TIME [epoch: 10 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2568692905469528		[learning rate: 0.0055378]
	Learning Rate: 0.00553775
	LOSS [training: 0.2568692905469528 | validation: 0.22040214921745643]
	TIME [epoch: 9.97 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26308556503136593		[learning rate: 0.0055182]
	Learning Rate: 0.00551817
	LOSS [training: 0.26308556503136593 | validation: 0.21362945610523565]
	TIME [epoch: 9.99 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2501480115962656		[learning rate: 0.0054987]
	Learning Rate: 0.00549865
	LOSS [training: 0.2501480115962656 | validation: 0.22068257932474689]
	TIME [epoch: 10 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27027627179677666		[learning rate: 0.0054792]
	Learning Rate: 0.00547921
	LOSS [training: 0.27027627179677666 | validation: 0.22161313350143352]
	TIME [epoch: 9.98 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25615727149294726		[learning rate: 0.0054598]
	Learning Rate: 0.00545983
	LOSS [training: 0.25615727149294726 | validation: 0.21357220277339328]
	TIME [epoch: 9.98 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2614217297388203		[learning rate: 0.0054405]
	Learning Rate: 0.00544053
	LOSS [training: 0.2614217297388203 | validation: 0.21813214108590345]
	TIME [epoch: 9.97 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26326041560722474		[learning rate: 0.0054213]
	Learning Rate: 0.00542129
	LOSS [training: 0.26326041560722474 | validation: 0.21035896778990368]
	TIME [epoch: 9.97 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26061566865826175		[learning rate: 0.0054021]
	Learning Rate: 0.00540212
	LOSS [training: 0.26061566865826175 | validation: 0.21943951028876296]
	TIME [epoch: 9.97 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25591264217330123		[learning rate: 0.005383]
	Learning Rate: 0.00538302
	LOSS [training: 0.25591264217330123 | validation: 0.228903574506686]
	TIME [epoch: 10 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2639599557128285		[learning rate: 0.005364]
	Learning Rate: 0.00536398
	LOSS [training: 0.2639599557128285 | validation: 0.23139839930067332]
	TIME [epoch: 10 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26577960609946333		[learning rate: 0.005345]
	Learning Rate: 0.00534501
	LOSS [training: 0.26577960609946333 | validation: 0.21862250243412823]
	TIME [epoch: 9.97 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26033100668666526		[learning rate: 0.0053261]
	Learning Rate: 0.00532611
	LOSS [training: 0.26033100668666526 | validation: 0.2176049059067923]
	TIME [epoch: 9.95 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2533308694447218		[learning rate: 0.0053073]
	Learning Rate: 0.00530728
	LOSS [training: 0.2533308694447218 | validation: 0.22484849124529965]
	TIME [epoch: 9.95 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2655792764413392		[learning rate: 0.0052885]
	Learning Rate: 0.00528851
	LOSS [training: 0.2655792764413392 | validation: 0.2403553736052913]
	TIME [epoch: 9.98 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27405859297151314		[learning rate: 0.0052698]
	Learning Rate: 0.00526981
	LOSS [training: 0.27405859297151314 | validation: 0.21923964692732537]
	TIME [epoch: 10 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2497733261387063		[learning rate: 0.0052512]
	Learning Rate: 0.00525117
	LOSS [training: 0.2497733261387063 | validation: 0.21485455865398578]
	TIME [epoch: 9.97 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25556641468584446		[learning rate: 0.0052326]
	Learning Rate: 0.0052326
	LOSS [training: 0.25556641468584446 | validation: 0.21522711270911862]
	TIME [epoch: 9.98 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2515632346911671		[learning rate: 0.0052141]
	Learning Rate: 0.0052141
	LOSS [training: 0.2515632346911671 | validation: 0.22217171958179235]
	TIME [epoch: 9.96 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.266178155509862		[learning rate: 0.0051957]
	Learning Rate: 0.00519566
	LOSS [training: 0.266178155509862 | validation: 0.2110450526257805]
	TIME [epoch: 9.98 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25786163427615144		[learning rate: 0.0051773]
	Learning Rate: 0.00517729
	LOSS [training: 0.25786163427615144 | validation: 0.20801200330065397]
	TIME [epoch: 10 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2432816886456414		[learning rate: 0.005159]
	Learning Rate: 0.00515898
	LOSS [training: 0.2432816886456414 | validation: 0.23320330428048405]
	TIME [epoch: 10 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2580610147050903		[learning rate: 0.0051407]
	Learning Rate: 0.00514074
	LOSS [training: 0.2580610147050903 | validation: 0.2140354058487394]
	TIME [epoch: 9.99 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25808589979383895		[learning rate: 0.0051226]
	Learning Rate: 0.00512256
	LOSS [training: 0.25808589979383895 | validation: 0.20174126575596835]
	TIME [epoch: 9.99 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15_20240719_005104/states/model_facs_v3_dec1b_2dpca_v15_239.pth
	Model improved!!!
EPOCH 240/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2678003384483187		[learning rate: 0.0051044]
	Learning Rate: 0.00510445
	LOSS [training: 0.2678003384483187 | validation: 0.21333370982376137]
	TIME [epoch: 9.97 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2619187477219544		[learning rate: 0.0050864]
	Learning Rate: 0.0050864
	LOSS [training: 0.2619187477219544 | validation: 0.2015428674484399]
	TIME [epoch: 9.97 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15_20240719_005104/states/model_facs_v3_dec1b_2dpca_v15_241.pth
	Model improved!!!
EPOCH 242/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2650030675718804		[learning rate: 0.0050684]
	Learning Rate: 0.00506841
	LOSS [training: 0.2650030675718804 | validation: 0.21319140617412974]
	TIME [epoch: 9.98 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.256216264990558		[learning rate: 0.0050505]
	Learning Rate: 0.00505049
	LOSS [training: 0.256216264990558 | validation: 0.20731391262719337]
	TIME [epoch: 10 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2565473937864779		[learning rate: 0.0050326]
	Learning Rate: 0.00503263
	LOSS [training: 0.2565473937864779 | validation: 0.21427833276324323]
	TIME [epoch: 9.98 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25416828996870017		[learning rate: 0.0050148]
	Learning Rate: 0.00501483
	LOSS [training: 0.25416828996870017 | validation: 0.2054679910288928]
	TIME [epoch: 10 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25804454957026335		[learning rate: 0.0049971]
	Learning Rate: 0.0049971
	LOSS [training: 0.25804454957026335 | validation: 0.20647512447089417]
	TIME [epoch: 9.98 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2602540859859249		[learning rate: 0.0049794]
	Learning Rate: 0.00497943
	LOSS [training: 0.2602540859859249 | validation: 0.22869638230556788]
	TIME [epoch: 10 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24859810970589655		[learning rate: 0.0049618]
	Learning Rate: 0.00496182
	LOSS [training: 0.24859810970589655 | validation: 0.22432286079485494]
	TIME [epoch: 10 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2651154452285131		[learning rate: 0.0049443]
	Learning Rate: 0.00494427
	LOSS [training: 0.2651154452285131 | validation: 0.21492558764741437]
	TIME [epoch: 9.97 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26023410925798945		[learning rate: 0.0049268]
	Learning Rate: 0.00492679
	LOSS [training: 0.26023410925798945 | validation: 0.21308362106417764]
	TIME [epoch: 9.97 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25960790415223806		[learning rate: 0.0049094]
	Learning Rate: 0.00490937
	LOSS [training: 0.25960790415223806 | validation: 0.2133892332590619]
	TIME [epoch: 9.98 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24817820865752807		[learning rate: 0.004892]
	Learning Rate: 0.00489201
	LOSS [training: 0.24817820865752807 | validation: 0.2190123320407325]
	TIME [epoch: 9.98 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25256578125464363		[learning rate: 0.0048747]
	Learning Rate: 0.00487471
	LOSS [training: 0.25256578125464363 | validation: 0.21208671454525857]
	TIME [epoch: 10 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24770904649283465		[learning rate: 0.0048575]
	Learning Rate: 0.00485747
	LOSS [training: 0.24770904649283465 | validation: 0.21022522964271168]
	TIME [epoch: 10 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2570276928850777		[learning rate: 0.0048403]
	Learning Rate: 0.00484029
	LOSS [training: 0.2570276928850777 | validation: 0.22490961215320268]
	TIME [epoch: 9.98 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2551270959492677		[learning rate: 0.0048232]
	Learning Rate: 0.00482318
	LOSS [training: 0.2551270959492677 | validation: 0.21038069584423386]
	TIME [epoch: 9.99 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26509734225879966		[learning rate: 0.0048061]
	Learning Rate: 0.00480612
	LOSS [training: 0.26509734225879966 | validation: 0.20669727432743742]
	TIME [epoch: 10 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2538686231647302		[learning rate: 0.0047891]
	Learning Rate: 0.00478913
	LOSS [training: 0.2538686231647302 | validation: 0.21130558399821128]
	TIME [epoch: 10 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.257298259339614		[learning rate: 0.0047722]
	Learning Rate: 0.00477219
	LOSS [training: 0.257298259339614 | validation: 0.22567116746514082]
	TIME [epoch: 9.99 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27027933511980856		[learning rate: 0.0047553]
	Learning Rate: 0.00475532
	LOSS [training: 0.27027933511980856 | validation: 0.20229569404785316]
	TIME [epoch: 9.97 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2596837781726857		[learning rate: 0.0047385]
	Learning Rate: 0.0047385
	LOSS [training: 0.2596837781726857 | validation: 0.21477869324693266]
	TIME [epoch: 9.98 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25629557523214846		[learning rate: 0.0047217]
	Learning Rate: 0.00472175
	LOSS [training: 0.25629557523214846 | validation: 0.21758256150727454]
	TIME [epoch: 10 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26441064655078356		[learning rate: 0.004705]
	Learning Rate: 0.00470505
	LOSS [training: 0.26441064655078356 | validation: 0.21384413308994868]
	TIME [epoch: 10 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25087056290350845		[learning rate: 0.0046884]
	Learning Rate: 0.00468841
	LOSS [training: 0.25087056290350845 | validation: 0.20922972917388893]
	TIME [epoch: 9.99 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2517482156908059		[learning rate: 0.0046718]
	Learning Rate: 0.00467183
	LOSS [training: 0.2517482156908059 | validation: 0.19909892390326198]
	TIME [epoch: 9.98 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15_20240719_005104/states/model_facs_v3_dec1b_2dpca_v15_265.pth
	Model improved!!!
EPOCH 266/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26194015859128444		[learning rate: 0.0046553]
	Learning Rate: 0.00465531
	LOSS [training: 0.26194015859128444 | validation: 0.236379242771617]
	TIME [epoch: 10 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.270598659682246		[learning rate: 0.0046388]
	Learning Rate: 0.00463885
	LOSS [training: 0.270598659682246 | validation: 0.2009808095464846]
	TIME [epoch: 9.98 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24774349576586877		[learning rate: 0.0046224]
	Learning Rate: 0.00462245
	LOSS [training: 0.24774349576586877 | validation: 0.20532490691025082]
	TIME [epoch: 9.97 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24828417102606026		[learning rate: 0.0046061]
	Learning Rate: 0.0046061
	LOSS [training: 0.24828417102606026 | validation: 0.20956389070395964]
	TIME [epoch: 9.96 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2562430377485454		[learning rate: 0.0045898]
	Learning Rate: 0.00458981
	LOSS [training: 0.2562430377485454 | validation: 0.209479868498]
	TIME [epoch: 9.98 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26215665931613136		[learning rate: 0.0045736]
	Learning Rate: 0.00457358
	LOSS [training: 0.26215665931613136 | validation: 0.20631778458851713]
	TIME [epoch: 9.98 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2586018715386244		[learning rate: 0.0045574]
	Learning Rate: 0.00455741
	LOSS [training: 0.2586018715386244 | validation: 0.22028953549868144]
	TIME [epoch: 9.98 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2413114723824333		[learning rate: 0.0045413]
	Learning Rate: 0.00454129
	LOSS [training: 0.2413114723824333 | validation: 0.215204586426781]
	TIME [epoch: 9.97 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2617110231360957		[learning rate: 0.0045252]
	Learning Rate: 0.00452523
	LOSS [training: 0.2617110231360957 | validation: 0.20527065386632487]
	TIME [epoch: 10 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2698926472862397		[learning rate: 0.0045092]
	Learning Rate: 0.00450923
	LOSS [training: 0.2698926472862397 | validation: 0.22389831359286072]
	TIME [epoch: 9.98 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24181163287195048		[learning rate: 0.0044933]
	Learning Rate: 0.00449329
	LOSS [training: 0.24181163287195048 | validation: 0.2144129171046608]
	TIME [epoch: 9.97 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2668247607755936		[learning rate: 0.0044774]
	Learning Rate: 0.0044774
	LOSS [training: 0.2668247607755936 | validation: 0.21428420660245956]
	TIME [epoch: 9.98 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24361985189966526		[learning rate: 0.0044616]
	Learning Rate: 0.00446156
	LOSS [training: 0.24361985189966526 | validation: 0.206274041509944]
	TIME [epoch: 9.97 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24684173524601408		[learning rate: 0.0044458]
	Learning Rate: 0.00444579
	LOSS [training: 0.24684173524601408 | validation: 0.21922781111093603]
	TIME [epoch: 9.96 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24940325294308296		[learning rate: 0.0044301]
	Learning Rate: 0.00443007
	LOSS [training: 0.24940325294308296 | validation: 0.2226764946742228]
	TIME [epoch: 9.99 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2423126645971941		[learning rate: 0.0044144]
	Learning Rate: 0.0044144
	LOSS [training: 0.2423126645971941 | validation: 0.20699844525889505]
	TIME [epoch: 10 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25416293621195135		[learning rate: 0.0043988]
	Learning Rate: 0.00439879
	LOSS [training: 0.25416293621195135 | validation: 0.20728871203729668]
	TIME [epoch: 9.98 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2504625271703717		[learning rate: 0.0043832]
	Learning Rate: 0.00438324
	LOSS [training: 0.2504625271703717 | validation: 0.20757906796949163]
	TIME [epoch: 9.97 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24591854601722987		[learning rate: 0.0043677]
	Learning Rate: 0.00436774
	LOSS [training: 0.24591854601722987 | validation: 0.21799084566179783]
	TIME [epoch: 9.96 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28170652342494823		[learning rate: 0.0043523]
	Learning Rate: 0.00435229
	LOSS [training: 0.28170652342494823 | validation: 0.20925629047245914]
	TIME [epoch: 9.98 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24355150157454672		[learning rate: 0.0043369]
	Learning Rate: 0.0043369
	LOSS [training: 0.24355150157454672 | validation: 0.2238745081360968]
	TIME [epoch: 10 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2483582680246708		[learning rate: 0.0043216]
	Learning Rate: 0.00432156
	LOSS [training: 0.2483582680246708 | validation: 0.2200179690556508]
	TIME [epoch: 9.97 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2554663084027558		[learning rate: 0.0043063]
	Learning Rate: 0.00430628
	LOSS [training: 0.2554663084027558 | validation: 0.21391716040273928]
	TIME [epoch: 9.99 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24994595943122552		[learning rate: 0.0042911]
	Learning Rate: 0.00429106
	LOSS [training: 0.24994595943122552 | validation: 0.21124468973849436]
	TIME [epoch: 9.98 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24820611434461007		[learning rate: 0.0042759]
	Learning Rate: 0.00427588
	LOSS [training: 0.24820611434461007 | validation: 0.2249715591723045]
	TIME [epoch: 9.97 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2558319672142966		[learning rate: 0.0042608]
	Learning Rate: 0.00426076
	LOSS [training: 0.2558319672142966 | validation: 0.21514044539616028]
	TIME [epoch: 9.98 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26707590419078686		[learning rate: 0.0042457]
	Learning Rate: 0.00424569
	LOSS [training: 0.26707590419078686 | validation: 0.21856236091436462]
	TIME [epoch: 9.98 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.265221391112091		[learning rate: 0.0042307]
	Learning Rate: 0.00423068
	LOSS [training: 0.265221391112091 | validation: 0.2185581062140353]
	TIME [epoch: 9.98 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24463779217252726		[learning rate: 0.0042157]
	Learning Rate: 0.00421572
	LOSS [training: 0.24463779217252726 | validation: 0.2089686201259017]
	TIME [epoch: 9.98 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23319355982408316		[learning rate: 0.0042008]
	Learning Rate: 0.00420081
	LOSS [training: 0.23319355982408316 | validation: 0.2123960631411772]
	TIME [epoch: 9.98 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2575555857718408		[learning rate: 0.004186]
	Learning Rate: 0.00418596
	LOSS [training: 0.2575555857718408 | validation: 0.21465495280980407]
	TIME [epoch: 9.99 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.251186956082632		[learning rate: 0.0041712]
	Learning Rate: 0.00417116
	LOSS [training: 0.251186956082632 | validation: 0.2158078487867196]
	TIME [epoch: 10 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2534215315273301		[learning rate: 0.0041564]
	Learning Rate: 0.00415641
	LOSS [training: 0.2534215315273301 | validation: 0.20321369425933183]
	TIME [epoch: 9.98 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2598922090994552		[learning rate: 0.0041417]
	Learning Rate: 0.00414171
	LOSS [training: 0.2598922090994552 | validation: 0.20642117070911184]
	TIME [epoch: 9.97 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25742872425295443		[learning rate: 0.0041271]
	Learning Rate: 0.00412706
	LOSS [training: 0.25742872425295443 | validation: 0.21089339993467834]
	TIME [epoch: 9.97 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24737720721408563		[learning rate: 0.0041125]
	Learning Rate: 0.00411247
	LOSS [training: 0.24737720721408563 | validation: 0.21052416904343535]
	TIME [epoch: 9.96 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2613318245945902		[learning rate: 0.0040979]
	Learning Rate: 0.00409793
	LOSS [training: 0.2613318245945902 | validation: 0.21901047624122905]
	TIME [epoch: 9.97 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26456461658001595		[learning rate: 0.0040834]
	Learning Rate: 0.00408344
	LOSS [training: 0.26456461658001595 | validation: 0.2038852119702245]
	TIME [epoch: 10 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2562364889340684		[learning rate: 0.004069]
	Learning Rate: 0.004069
	LOSS [training: 0.2562364889340684 | validation: 0.21999525526519842]
	TIME [epoch: 9.97 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2511008168158844		[learning rate: 0.0040546]
	Learning Rate: 0.00405461
	LOSS [training: 0.2511008168158844 | validation: 0.22456981952997]
	TIME [epoch: 9.96 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.255228558174437		[learning rate: 0.0040403]
	Learning Rate: 0.00404027
	LOSS [training: 0.255228558174437 | validation: 0.21940816336057828]
	TIME [epoch: 9.97 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2456562069053471		[learning rate: 0.004026]
	Learning Rate: 0.00402598
	LOSS [training: 0.2456562069053471 | validation: 0.21699006840961976]
	TIME [epoch: 9.96 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25832943143549225		[learning rate: 0.0040117]
	Learning Rate: 0.00401175
	LOSS [training: 0.25832943143549225 | validation: 0.2176954416537087]
	TIME [epoch: 9.97 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24990877478883222		[learning rate: 0.0039976]
	Learning Rate: 0.00399756
	LOSS [training: 0.24990877478883222 | validation: 0.21238548959369496]
	TIME [epoch: 9.99 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24812831697102064		[learning rate: 0.0039834]
	Learning Rate: 0.00398342
	LOSS [training: 0.24812831697102064 | validation: 0.2070450059579203]
	TIME [epoch: 9.97 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24775001580783365		[learning rate: 0.0039693]
	Learning Rate: 0.00396934
	LOSS [training: 0.24775001580783365 | validation: 0.22721783924248284]
	TIME [epoch: 9.96 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2539790816440169		[learning rate: 0.0039553]
	Learning Rate: 0.0039553
	LOSS [training: 0.2539790816440169 | validation: 0.22351473011939796]
	TIME [epoch: 9.95 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2438306892530732		[learning rate: 0.0039413]
	Learning Rate: 0.00394131
	LOSS [training: 0.2438306892530732 | validation: 0.20485113491778445]
	TIME [epoch: 9.96 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24621527897122966		[learning rate: 0.0039274]
	Learning Rate: 0.00392738
	LOSS [training: 0.24621527897122966 | validation: 0.2135606465015103]
	TIME [epoch: 9.97 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2578700079767711		[learning rate: 0.0039135]
	Learning Rate: 0.00391349
	LOSS [training: 0.2578700079767711 | validation: 0.2075458739993213]
	TIME [epoch: 9.98 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24941766461925272		[learning rate: 0.0038997]
	Learning Rate: 0.00389965
	LOSS [training: 0.24941766461925272 | validation: 0.21464231446531454]
	TIME [epoch: 9.97 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25266159444550157		[learning rate: 0.0038859]
	Learning Rate: 0.00388586
	LOSS [training: 0.25266159444550157 | validation: 0.23289847139110118]
	TIME [epoch: 9.98 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2458871322126339		[learning rate: 0.0038721]
	Learning Rate: 0.00387212
	LOSS [training: 0.2458871322126339 | validation: 0.212782707166267]
	TIME [epoch: 9.97 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25859149333287446		[learning rate: 0.0038584]
	Learning Rate: 0.00385843
	LOSS [training: 0.25859149333287446 | validation: 0.21557828242704113]
	TIME [epoch: 9.98 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2511912359323561		[learning rate: 0.0038448]
	Learning Rate: 0.00384478
	LOSS [training: 0.2511912359323561 | validation: 0.21362144070761974]
	TIME [epoch: 10 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24806265569987648		[learning rate: 0.0038312]
	Learning Rate: 0.00383119
	LOSS [training: 0.24806265569987648 | validation: 0.21184067542254584]
	TIME [epoch: 9.97 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2525513268446032		[learning rate: 0.0038176]
	Learning Rate: 0.00381764
	LOSS [training: 0.2525513268446032 | validation: 0.20037995446163218]
	TIME [epoch: 9.96 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24252525677994		[learning rate: 0.0038041]
	Learning Rate: 0.00380414
	LOSS [training: 0.24252525677994 | validation: 0.21505039478082083]
	TIME [epoch: 9.98 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2505492319102047		[learning rate: 0.0037907]
	Learning Rate: 0.00379069
	LOSS [training: 0.2505492319102047 | validation: 0.2246847387860756]
	TIME [epoch: 9.96 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25891134296588886		[learning rate: 0.0037773]
	Learning Rate: 0.00377728
	LOSS [training: 0.25891134296588886 | validation: 0.20658160850868476]
	TIME [epoch: 10 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25697668707722526		[learning rate: 0.0037639]
	Learning Rate: 0.00376393
	LOSS [training: 0.25697668707722526 | validation: 0.20635316859174582]
	TIME [epoch: 9.99 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25587178607959943		[learning rate: 0.0037506]
	Learning Rate: 0.00375062
	LOSS [training: 0.25587178607959943 | validation: 0.2053078604113195]
	TIME [epoch: 9.97 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24341902429823928		[learning rate: 0.0037374]
	Learning Rate: 0.00373735
	LOSS [training: 0.24341902429823928 | validation: 0.21583810759998429]
	TIME [epoch: 9.95 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.255083049993633		[learning rate: 0.0037241]
	Learning Rate: 0.00372414
	LOSS [training: 0.255083049993633 | validation: 0.22613308148002317]
	TIME [epoch: 9.98 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24705808405122498		[learning rate: 0.003711]
	Learning Rate: 0.00371097
	LOSS [training: 0.24705808405122498 | validation: 0.2150384330516713]
	TIME [epoch: 10 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25207336587541307		[learning rate: 0.0036978]
	Learning Rate: 0.00369785
	LOSS [training: 0.25207336587541307 | validation: 0.22127058449750586]
	TIME [epoch: 9.99 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2480276899316319		[learning rate: 0.0036848]
	Learning Rate: 0.00368477
	LOSS [training: 0.2480276899316319 | validation: 0.21539747506417242]
	TIME [epoch: 9.98 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24475527414383513		[learning rate: 0.0036717]
	Learning Rate: 0.00367174
	LOSS [training: 0.24475527414383513 | validation: 0.2019765919393436]
	TIME [epoch: 9.97 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24871038531654918		[learning rate: 0.0036588]
	Learning Rate: 0.00365875
	LOSS [training: 0.24871038531654918 | validation: 0.20734301726261192]
	TIME [epoch: 9.97 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2452932733361076		[learning rate: 0.0036458]
	Learning Rate: 0.00364582
	LOSS [training: 0.2452932733361076 | validation: 0.22499888820488234]
	TIME [epoch: 9.97 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2529875951565596		[learning rate: 0.0036329]
	Learning Rate: 0.00363292
	LOSS [training: 0.2529875951565596 | validation: 0.21149496582112676]
	TIME [epoch: 9.97 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2522083756655231		[learning rate: 0.0036201]
	Learning Rate: 0.00362008
	LOSS [training: 0.2522083756655231 | validation: 0.21719253463405966]
	TIME [epoch: 10 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2579299636184223		[learning rate: 0.0036073]
	Learning Rate: 0.00360728
	LOSS [training: 0.2579299636184223 | validation: 0.2081416090335808]
	TIME [epoch: 9.97 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2469426879873685		[learning rate: 0.0035945]
	Learning Rate: 0.00359452
	LOSS [training: 0.2469426879873685 | validation: 0.19823147266984398]
	TIME [epoch: 9.96 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15_20240719_005104/states/model_facs_v3_dec1b_2dpca_v15_339.pth
	Model improved!!!
EPOCH 340/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26285229713702796		[learning rate: 0.0035818]
	Learning Rate: 0.00358181
	LOSS [training: 0.26285229713702796 | validation: 0.21056304143585186]
	TIME [epoch: 9.98 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25629223768486514		[learning rate: 0.0035691]
	Learning Rate: 0.00356914
	LOSS [training: 0.25629223768486514 | validation: 0.22197877379995373]
	TIME [epoch: 9.97 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24438459122352416		[learning rate: 0.0035565]
	Learning Rate: 0.00355652
	LOSS [training: 0.24438459122352416 | validation: 0.21072138748214558]
	TIME [epoch: 9.96 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2546010772747225		[learning rate: 0.0035439]
	Learning Rate: 0.00354395
	LOSS [training: 0.2546010772747225 | validation: 0.21453897968582605]
	TIME [epoch: 9.97 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.251589879466543		[learning rate: 0.0035314]
	Learning Rate: 0.00353141
	LOSS [training: 0.251589879466543 | validation: 0.20843470111452378]
	TIME [epoch: 9.97 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2456899903737141		[learning rate: 0.0035189]
	Learning Rate: 0.00351893
	LOSS [training: 0.2456899903737141 | validation: 0.22242601278482427]
	TIME [epoch: 9.96 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24953905530322665		[learning rate: 0.0035065]
	Learning Rate: 0.00350648
	LOSS [training: 0.24953905530322665 | validation: 0.2206467261709888]
	TIME [epoch: 9.98 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25988103874170615		[learning rate: 0.0034941]
	Learning Rate: 0.00349408
	LOSS [training: 0.25988103874170615 | validation: 0.21652473948862522]
	TIME [epoch: 9.96 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2575286720513313		[learning rate: 0.0034817]
	Learning Rate: 0.00348173
	LOSS [training: 0.2575286720513313 | validation: 0.21785939735607512]
	TIME [epoch: 9.97 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2561256895271755		[learning rate: 0.0034694]
	Learning Rate: 0.00346942
	LOSS [training: 0.2561256895271755 | validation: 0.21811505358676989]
	TIME [epoch: 9.98 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24010112167579825		[learning rate: 0.0034571]
	Learning Rate: 0.00345715
	LOSS [training: 0.24010112167579825 | validation: 0.22305829510847758]
	TIME [epoch: 9.96 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25939164378866114		[learning rate: 0.0034449]
	Learning Rate: 0.00344492
	LOSS [training: 0.25939164378866114 | validation: 0.22152869513292814]
	TIME [epoch: 9.96 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2509871181065632		[learning rate: 0.0034327]
	Learning Rate: 0.00343274
	LOSS [training: 0.2509871181065632 | validation: 0.20382269456627888]
	TIME [epoch: 9.97 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2502242456771096		[learning rate: 0.0034206]
	Learning Rate: 0.0034206
	LOSS [training: 0.2502242456771096 | validation: 0.21411461634365941]
	TIME [epoch: 9.96 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2470681008670582		[learning rate: 0.0034085]
	Learning Rate: 0.00340851
	LOSS [training: 0.2470681008670582 | validation: 0.21796202854930097]
	TIME [epoch: 9.96 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.248099628690022		[learning rate: 0.0033965]
	Learning Rate: 0.00339645
	LOSS [training: 0.248099628690022 | validation: 0.21089328117897957]
	TIME [epoch: 9.97 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25560751870588416		[learning rate: 0.0033844]
	Learning Rate: 0.00338444
	LOSS [training: 0.25560751870588416 | validation: 0.20100322112315]
	TIME [epoch: 9.97 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2546013244378989		[learning rate: 0.0033725]
	Learning Rate: 0.00337247
	LOSS [training: 0.2546013244378989 | validation: 0.2132220605371859]
	TIME [epoch: 9.96 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2510844451606635		[learning rate: 0.0033605]
	Learning Rate: 0.00336055
	LOSS [training: 0.2510844451606635 | validation: 0.22045168759010209]
	TIME [epoch: 9.97 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26204744431483956		[learning rate: 0.0033487]
	Learning Rate: 0.00334867
	LOSS [training: 0.26204744431483956 | validation: 0.20393421825292596]
	TIME [epoch: 9.95 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24024757789703602		[learning rate: 0.0033368]
	Learning Rate: 0.00333682
	LOSS [training: 0.24024757789703602 | validation: 0.22311546123559892]
	TIME [epoch: 9.96 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25644537798962214		[learning rate: 0.003325]
	Learning Rate: 0.00332502
	LOSS [training: 0.25644537798962214 | validation: 0.20581750906367652]
	TIME [epoch: 9.97 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.251414279888822		[learning rate: 0.0033133]
	Learning Rate: 0.00331327
	LOSS [training: 0.251414279888822 | validation: 0.2147241119346987]
	TIME [epoch: 9.96 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25157400950852016		[learning rate: 0.0033016]
	Learning Rate: 0.00330155
	LOSS [training: 0.25157400950852016 | validation: 0.20781571539759663]
	TIME [epoch: 9.97 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2550269092216069		[learning rate: 0.0032899]
	Learning Rate: 0.00328988
	LOSS [training: 0.2550269092216069 | validation: 0.20470821965849156]
	TIME [epoch: 9.97 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25673592506076814		[learning rate: 0.0032782]
	Learning Rate: 0.00327824
	LOSS [training: 0.25673592506076814 | validation: 0.2228266852138477]
	TIME [epoch: 9.95 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2582254354860823		[learning rate: 0.0032666]
	Learning Rate: 0.00326665
	LOSS [training: 0.2582254354860823 | validation: 0.20253984823800014]
	TIME [epoch: 9.96 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24585793069943643		[learning rate: 0.0032551]
	Learning Rate: 0.0032551
	LOSS [training: 0.24585793069943643 | validation: 0.2107228154420308]
	TIME [epoch: 9.97 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25027554193120377		[learning rate: 0.0032436]
	Learning Rate: 0.00324359
	LOSS [training: 0.25027554193120377 | validation: 0.20951773302888888]
	TIME [epoch: 9.96 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25866453762666336		[learning rate: 0.0032321]
	Learning Rate: 0.00323212
	LOSS [training: 0.25866453762666336 | validation: 0.21630486712300492]
	TIME [epoch: 9.97 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25102416235810426		[learning rate: 0.0032207]
	Learning Rate: 0.00322069
	LOSS [training: 0.25102416235810426 | validation: 0.22446696808788474]
	TIME [epoch: 9.97 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25145202624904545		[learning rate: 0.0032093]
	Learning Rate: 0.0032093
	LOSS [training: 0.25145202624904545 | validation: 0.21068220203995575]
	TIME [epoch: 9.95 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2502553549585947		[learning rate: 0.003198]
	Learning Rate: 0.00319795
	LOSS [training: 0.2502553549585947 | validation: 0.2218765623757854]
	TIME [epoch: 9.98 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24804885925570933		[learning rate: 0.0031866]
	Learning Rate: 0.00318664
	LOSS [training: 0.24804885925570933 | validation: 0.21058995300552782]
	TIME [epoch: 9.96 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2427391012715064		[learning rate: 0.0031754]
	Learning Rate: 0.00317537
	LOSS [training: 0.2427391012715064 | validation: 0.2201201062421378]
	TIME [epoch: 9.98 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24693983620687962		[learning rate: 0.0031641]
	Learning Rate: 0.00316415
	LOSS [training: 0.24693983620687962 | validation: 0.21107453444268565]
	TIME [epoch: 9.97 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.254608466880889		[learning rate: 0.003153]
	Learning Rate: 0.00315296
	LOSS [training: 0.254608466880889 | validation: 0.22145106246282237]
	TIME [epoch: 9.96 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.246314149699417		[learning rate: 0.0031418]
	Learning Rate: 0.00314181
	LOSS [training: 0.246314149699417 | validation: 0.2091660465170782]
	TIME [epoch: 9.96 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2516700761929027		[learning rate: 0.0031307]
	Learning Rate: 0.0031307
	LOSS [training: 0.2516700761929027 | validation: 0.19998636630986855]
	TIME [epoch: 9.98 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23637443385547674		[learning rate: 0.0031196]
	Learning Rate: 0.00311963
	LOSS [training: 0.23637443385547674 | validation: 0.2049169213018817]
	TIME [epoch: 9.96 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25118317696648823		[learning rate: 0.0031086]
	Learning Rate: 0.00310859
	LOSS [training: 0.25118317696648823 | validation: 0.20733056219890206]
	TIME [epoch: 9.96 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24908027351982776		[learning rate: 0.0030976]
	Learning Rate: 0.0030976
	LOSS [training: 0.24908027351982776 | validation: 0.2069070666011375]
	TIME [epoch: 9.96 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2553182991276091		[learning rate: 0.0030866]
	Learning Rate: 0.00308665
	LOSS [training: 0.2553182991276091 | validation: 0.212326342531265]
	TIME [epoch: 9.96 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2536009214446082		[learning rate: 0.0030757]
	Learning Rate: 0.00307573
	LOSS [training: 0.2536009214446082 | validation: 0.2152935238416768]
	TIME [epoch: 9.95 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24573352172103605		[learning rate: 0.0030649]
	Learning Rate: 0.00306486
	LOSS [training: 0.24573352172103605 | validation: 0.21022922643351505]
	TIME [epoch: 9.99 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24346396534305717		[learning rate: 0.003054]
	Learning Rate: 0.00305402
	LOSS [training: 0.24346396534305717 | validation: 0.20408708021069]
	TIME [epoch: 9.95 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.245784529381602		[learning rate: 0.0030432]
	Learning Rate: 0.00304322
	LOSS [training: 0.245784529381602 | validation: 0.21062393289440476]
	TIME [epoch: 9.96 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24757643483243388		[learning rate: 0.0030325]
	Learning Rate: 0.00303246
	LOSS [training: 0.24757643483243388 | validation: 0.21283630798998826]
	TIME [epoch: 9.99 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24425004335323253		[learning rate: 0.0030217]
	Learning Rate: 0.00302174
	LOSS [training: 0.24425004335323253 | validation: 0.2105804094840384]
	TIME [epoch: 9.96 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24325485002585276		[learning rate: 0.003011]
	Learning Rate: 0.00301105
	LOSS [training: 0.24325485002585276 | validation: 0.21616113589833885]
	TIME [epoch: 9.97 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2628783159969279		[learning rate: 0.0030004]
	Learning Rate: 0.0030004
	LOSS [training: 0.2628783159969279 | validation: 0.21340779479339855]
	TIME [epoch: 9.97 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2577376970663139		[learning rate: 0.0029898]
	Learning Rate: 0.00298979
	LOSS [training: 0.2577376970663139 | validation: 0.2139874658572185]
	TIME [epoch: 9.95 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25125760945846615		[learning rate: 0.0029792]
	Learning Rate: 0.00297922
	LOSS [training: 0.25125760945846615 | validation: 0.20810181387236523]
	TIME [epoch: 9.95 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2509884765515769		[learning rate: 0.0029687]
	Learning Rate: 0.00296869
	LOSS [training: 0.2509884765515769 | validation: 0.2151391392380387]
	TIME [epoch: 9.97 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2506322066187962		[learning rate: 0.0029582]
	Learning Rate: 0.00295819
	LOSS [training: 0.2506322066187962 | validation: 0.22975990449389383]
	TIME [epoch: 9.95 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2513922200517245		[learning rate: 0.0029477]
	Learning Rate: 0.00294773
	LOSS [training: 0.2513922200517245 | validation: 0.2183682701623451]
	TIME [epoch: 9.99 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24277988083573532		[learning rate: 0.0029373]
	Learning Rate: 0.0029373
	LOSS [training: 0.24277988083573532 | validation: 0.20836046678572817]
	TIME [epoch: 9.98 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2513620995521026		[learning rate: 0.0029269]
	Learning Rate: 0.00292692
	LOSS [training: 0.2513620995521026 | validation: 0.19956717833401552]
	TIME [epoch: 9.95 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2548796801980841		[learning rate: 0.0029166]
	Learning Rate: 0.00291657
	LOSS [training: 0.2548796801980841 | validation: 0.21979075355484143]
	TIME [epoch: 9.96 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24695309776872174		[learning rate: 0.0029063]
	Learning Rate: 0.00290625
	LOSS [training: 0.24695309776872174 | validation: 0.20667023155272846]
	TIME [epoch: 9.98 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2499253911323265		[learning rate: 0.002896]
	Learning Rate: 0.00289598
	LOSS [training: 0.2499253911323265 | validation: 0.21456851560748413]
	TIME [epoch: 9.96 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24906956476837785		[learning rate: 0.0028857]
	Learning Rate: 0.00288573
	LOSS [training: 0.24906956476837785 | validation: 0.20782060835019434]
	TIME [epoch: 9.97 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24623954317184604		[learning rate: 0.0028755]
	Learning Rate: 0.00287553
	LOSS [training: 0.24623954317184604 | validation: 0.20122835584001103]
	TIME [epoch: 9.97 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2502684014055097		[learning rate: 0.0028654]
	Learning Rate: 0.00286536
	LOSS [training: 0.2502684014055097 | validation: 0.22036932376311888]
	TIME [epoch: 9.96 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24577214871061295		[learning rate: 0.0028552]
	Learning Rate: 0.00285523
	LOSS [training: 0.24577214871061295 | validation: 0.20432386192153618]
	TIME [epoch: 9.98 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24731316649704796		[learning rate: 0.0028451]
	Learning Rate: 0.00284513
	LOSS [training: 0.24731316649704796 | validation: 0.2108150008669754]
	TIME [epoch: 9.97 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24317649160568403		[learning rate: 0.0028351]
	Learning Rate: 0.00283507
	LOSS [training: 0.24317649160568403 | validation: 0.21333196745793362]
	TIME [epoch: 9.97 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26066751508491254		[learning rate: 0.002825]
	Learning Rate: 0.00282505
	LOSS [training: 0.26066751508491254 | validation: 0.2061518357249636]
	TIME [epoch: 9.98 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25378227854479307		[learning rate: 0.0028151]
	Learning Rate: 0.00281506
	LOSS [training: 0.25378227854479307 | validation: 0.20682221907909035]
	TIME [epoch: 9.97 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2527817552289824		[learning rate: 0.0028051]
	Learning Rate: 0.0028051
	LOSS [training: 0.2527817552289824 | validation: 0.2191231684763948]
	TIME [epoch: 9.96 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2441471047843755		[learning rate: 0.0027952]
	Learning Rate: 0.00279518
	LOSS [training: 0.2441471047843755 | validation: 0.20513702048230198]
	TIME [epoch: 9.97 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24394137667747848		[learning rate: 0.0027853]
	Learning Rate: 0.0027853
	LOSS [training: 0.24394137667747848 | validation: 0.2136191362898951]
	TIME [epoch: 9.97 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24334814364106072		[learning rate: 0.0027754]
	Learning Rate: 0.00277545
	LOSS [training: 0.24334814364106072 | validation: 0.20757884924869935]
	TIME [epoch: 9.97 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24681325524597217		[learning rate: 0.0027656]
	Learning Rate: 0.00276564
	LOSS [training: 0.24681325524597217 | validation: 0.20482223837780858]
	TIME [epoch: 9.97 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24765377381847667		[learning rate: 0.0027559]
	Learning Rate: 0.00275586
	LOSS [training: 0.24765377381847667 | validation: 0.20576721494188616]
	TIME [epoch: 9.97 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2628107899251287		[learning rate: 0.0027461]
	Learning Rate: 0.00274611
	LOSS [training: 0.2628107899251287 | validation: 0.2194651028630768]
	TIME [epoch: 9.97 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2627935888300588		[learning rate: 0.0027364]
	Learning Rate: 0.0027364
	LOSS [training: 0.2627935888300588 | validation: 0.20381073764633068]
	TIME [epoch: 9.99 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.258508970782476		[learning rate: 0.0027267]
	Learning Rate: 0.00272672
	LOSS [training: 0.258508970782476 | validation: 0.1967850150225946]
	TIME [epoch: 9.96 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15_20240719_005104/states/model_facs_v3_dec1b_2dpca_v15_417.pth
	Model improved!!!
EPOCH 418/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2521359503737795		[learning rate: 0.0027171]
	Learning Rate: 0.00271708
	LOSS [training: 0.2521359503737795 | validation: 0.20984930860470447]
	TIME [epoch: 9.96 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2402836464288518		[learning rate: 0.0027075]
	Learning Rate: 0.00270747
	LOSS [training: 0.2402836464288518 | validation: 0.20993975226330389]
	TIME [epoch: 9.98 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24638164933635479		[learning rate: 0.0026979]
	Learning Rate: 0.0026979
	LOSS [training: 0.24638164933635479 | validation: 0.21619468917554535]
	TIME [epoch: 9.96 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24166378817670656		[learning rate: 0.0026884]
	Learning Rate: 0.00268836
	LOSS [training: 0.24166378817670656 | validation: 0.21193237101917045]
	TIME [epoch: 9.98 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2369887154571407		[learning rate: 0.0026789]
	Learning Rate: 0.00267885
	LOSS [training: 0.2369887154571407 | validation: 0.20464025906840547]
	TIME [epoch: 9.98 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25729603709864585		[learning rate: 0.0026694]
	Learning Rate: 0.00266938
	LOSS [training: 0.25729603709864585 | validation: 0.20879898578824657]
	TIME [epoch: 9.98 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24605116544709316		[learning rate: 0.0026599]
	Learning Rate: 0.00265994
	LOSS [training: 0.24605116544709316 | validation: 0.21755897845088273]
	TIME [epoch: 9.97 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2346962308193842		[learning rate: 0.0026505]
	Learning Rate: 0.00265053
	LOSS [training: 0.2346962308193842 | validation: 0.20032272889069228]
	TIME [epoch: 9.98 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2632373108281539		[learning rate: 0.0026412]
	Learning Rate: 0.00264116
	LOSS [training: 0.2632373108281539 | validation: 0.21186711809006606]
	TIME [epoch: 9.96 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24884718626878075		[learning rate: 0.0026318]
	Learning Rate: 0.00263182
	LOSS [training: 0.24884718626878075 | validation: 0.21442335313267505]
	TIME [epoch: 9.97 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24242057791294466		[learning rate: 0.0026225]
	Learning Rate: 0.00262251
	LOSS [training: 0.24242057791294466 | validation: 0.20740523716540685]
	TIME [epoch: 9.98 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24672826826420777		[learning rate: 0.0026132]
	Learning Rate: 0.00261324
	LOSS [training: 0.24672826826420777 | validation: 0.20476395314938559]
	TIME [epoch: 9.97 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25174787734358767		[learning rate: 0.002604]
	Learning Rate: 0.002604
	LOSS [training: 0.25174787734358767 | validation: 0.2101880836322998]
	TIME [epoch: 9.99 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24349940775495216		[learning rate: 0.0025948]
	Learning Rate: 0.00259479
	LOSS [training: 0.24349940775495216 | validation: 0.2053451994589767]
	TIME [epoch: 9.97 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2565833965221121		[learning rate: 0.0025856]
	Learning Rate: 0.00258562
	LOSS [training: 0.2565833965221121 | validation: 0.21721201829149747]
	TIME [epoch: 9.96 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24407562245398137		[learning rate: 0.0025765]
	Learning Rate: 0.00257647
	LOSS [training: 0.24407562245398137 | validation: 0.20136022728120434]
	TIME [epoch: 9.97 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25300160429519186		[learning rate: 0.0025674]
	Learning Rate: 0.00256736
	LOSS [training: 0.25300160429519186 | validation: 0.21383239159136164]
	TIME [epoch: 9.97 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25099010017345186		[learning rate: 0.0025583]
	Learning Rate: 0.00255828
	LOSS [training: 0.25099010017345186 | validation: 0.2015010920752184]
	TIME [epoch: 9.96 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2561252562957909		[learning rate: 0.0025492]
	Learning Rate: 0.00254924
	LOSS [training: 0.2561252562957909 | validation: 0.1989416170096411]
	TIME [epoch: 9.98 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23985210648348357		[learning rate: 0.0025402]
	Learning Rate: 0.00254022
	LOSS [training: 0.23985210648348357 | validation: 0.21323484509421994]
	TIME [epoch: 9.99 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2551618931777591		[learning rate: 0.0025312]
	Learning Rate: 0.00253124
	LOSS [training: 0.2551618931777591 | validation: 0.1986765679224905]
	TIME [epoch: 9.97 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24062706815001697		[learning rate: 0.0025223]
	Learning Rate: 0.00252229
	LOSS [training: 0.24062706815001697 | validation: 0.20952583615501555]
	TIME [epoch: 9.99 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24917834287100163		[learning rate: 0.0025134]
	Learning Rate: 0.00251337
	LOSS [training: 0.24917834287100163 | validation: 0.2149908317435431]
	TIME [epoch: 9.97 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24270471142868544		[learning rate: 0.0025045]
	Learning Rate: 0.00250448
	LOSS [training: 0.24270471142868544 | validation: 0.2134751525653089]
	TIME [epoch: 9.98 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24037801313197124		[learning rate: 0.0024956]
	Learning Rate: 0.00249563
	LOSS [training: 0.24037801313197124 | validation: 0.22440063695372875]
	TIME [epoch: 9.99 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.258693097260452		[learning rate: 0.0024868]
	Learning Rate: 0.0024868
	LOSS [training: 0.258693097260452 | validation: 0.21111546094057201]
	TIME [epoch: 9.96 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24883186814938038		[learning rate: 0.002478]
	Learning Rate: 0.00247801
	LOSS [training: 0.24883186814938038 | validation: 0.21580866033792953]
	TIME [epoch: 9.96 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24974517307593624		[learning rate: 0.0024692]
	Learning Rate: 0.00246924
	LOSS [training: 0.24974517307593624 | validation: 0.20215006905906438]
	TIME [epoch: 9.98 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25957319835975723		[learning rate: 0.0024605]
	Learning Rate: 0.00246051
	LOSS [training: 0.25957319835975723 | validation: 0.2178111602460831]
	TIME [epoch: 9.97 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24795518282866358		[learning rate: 0.0024518]
	Learning Rate: 0.00245181
	LOSS [training: 0.24795518282866358 | validation: 0.21215984655106115]
	TIME [epoch: 9.98 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26271934323537555		[learning rate: 0.0024431]
	Learning Rate: 0.00244314
	LOSS [training: 0.26271934323537555 | validation: 0.21752422117354753]
	TIME [epoch: 9.98 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24880819687970104		[learning rate: 0.0024345]
	Learning Rate: 0.0024345
	LOSS [training: 0.24880819687970104 | validation: 0.20572359311365856]
	TIME [epoch: 9.97 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2498250349610109		[learning rate: 0.0024259]
	Learning Rate: 0.00242589
	LOSS [training: 0.2498250349610109 | validation: 0.21226382841736027]
	TIME [epoch: 9.97 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2456956953750554		[learning rate: 0.0024173]
	Learning Rate: 0.00241732
	LOSS [training: 0.2456956953750554 | validation: 0.21129316176502538]
	TIME [epoch: 9.99 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24504881253676655		[learning rate: 0.0024088]
	Learning Rate: 0.00240877
	LOSS [training: 0.24504881253676655 | validation: 0.2154056849372874]
	TIME [epoch: 9.97 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2550487022583577		[learning rate: 0.0024002]
	Learning Rate: 0.00240025
	LOSS [training: 0.2550487022583577 | validation: 0.20757529004874176]
	TIME [epoch: 9.96 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26092817949596125		[learning rate: 0.0023918]
	Learning Rate: 0.00239176
	LOSS [training: 0.26092817949596125 | validation: 0.20411907228806445]
	TIME [epoch: 9.97 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24853353982001924		[learning rate: 0.0023833]
	Learning Rate: 0.0023833
	LOSS [training: 0.24853353982001924 | validation: 0.22384271083201973]
	TIME [epoch: 9.96 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24768666036028733		[learning rate: 0.0023749]
	Learning Rate: 0.00237488
	LOSS [training: 0.24768666036028733 | validation: 0.2155953041939486]
	TIME [epoch: 9.97 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24994582705832843		[learning rate: 0.0023665]
	Learning Rate: 0.00236648
	LOSS [training: 0.24994582705832843 | validation: 0.22026605147554582]
	TIME [epoch: 9.98 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23706298755241087		[learning rate: 0.0023581]
	Learning Rate: 0.00235811
	LOSS [training: 0.23706298755241087 | validation: 0.211176367927819]
	TIME [epoch: 9.96 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24374032727318684		[learning rate: 0.0023498]
	Learning Rate: 0.00234977
	LOSS [training: 0.24374032727318684 | validation: 0.20756601087319698]
	TIME [epoch: 9.98 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24566196679255237		[learning rate: 0.0023415]
	Learning Rate: 0.00234146
	LOSS [training: 0.24566196679255237 | validation: 0.20249420282949443]
	TIME [epoch: 9.97 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24240421548317828		[learning rate: 0.0023332]
	Learning Rate: 0.00233318
	LOSS [training: 0.24240421548317828 | validation: 0.21092732145597842]
	TIME [epoch: 9.97 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2512565761554479		[learning rate: 0.0023249]
	Learning Rate: 0.00232493
	LOSS [training: 0.2512565761554479 | validation: 0.2080844257583459]
	TIME [epoch: 9.98 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2503678939481678		[learning rate: 0.0023167]
	Learning Rate: 0.00231671
	LOSS [training: 0.2503678939481678 | validation: 0.2239214467903093]
	TIME [epoch: 9.96 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24862442658426		[learning rate: 0.0023085]
	Learning Rate: 0.00230852
	LOSS [training: 0.24862442658426 | validation: 0.21335306581698193]
	TIME [epoch: 9.96 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24735229682053794		[learning rate: 0.0023004]
	Learning Rate: 0.00230035
	LOSS [training: 0.24735229682053794 | validation: 0.22051849445067298]
	TIME [epoch: 9.97 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2428100115726974		[learning rate: 0.0022922]
	Learning Rate: 0.00229222
	LOSS [training: 0.2428100115726974 | validation: 0.2086524820850113]
	TIME [epoch: 9.96 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25282495302174357		[learning rate: 0.0022841]
	Learning Rate: 0.00228411
	LOSS [training: 0.25282495302174357 | validation: 0.2079527838757173]
	TIME [epoch: 9.98 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2479347460073292		[learning rate: 0.002276]
	Learning Rate: 0.00227604
	LOSS [training: 0.2479347460073292 | validation: 0.2193418904490252]
	TIME [epoch: 9.99 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24758231943584538		[learning rate: 0.002268]
	Learning Rate: 0.00226799
	LOSS [training: 0.24758231943584538 | validation: 0.20541915121833565]
	TIME [epoch: 9.95 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24536405357992055		[learning rate: 0.00226]
	Learning Rate: 0.00225997
	LOSS [training: 0.24536405357992055 | validation: 0.21706148689030264]
	TIME [epoch: 9.95 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2555400413041717		[learning rate: 0.002252]
	Learning Rate: 0.00225198
	LOSS [training: 0.2555400413041717 | validation: 0.21645786007870602]
	TIME [epoch: 9.99 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24942186704855449		[learning rate: 0.002244]
	Learning Rate: 0.00224401
	LOSS [training: 0.24942186704855449 | validation: 0.22071373552297496]
	TIME [epoch: 9.98 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2416952214799851		[learning rate: 0.0022361]
	Learning Rate: 0.00223608
	LOSS [training: 0.2416952214799851 | validation: 0.20559408094188902]
	TIME [epoch: 9.96 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24757859843277363		[learning rate: 0.0022282]
	Learning Rate: 0.00222817
	LOSS [training: 0.24757859843277363 | validation: 0.1990707262848078]
	TIME [epoch: 9.97 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25967042583791883		[learning rate: 0.0022203]
	Learning Rate: 0.00222029
	LOSS [training: 0.25967042583791883 | validation: 0.2084171106588518]
	TIME [epoch: 9.96 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23859045235878437		[learning rate: 0.0022124]
	Learning Rate: 0.00221244
	LOSS [training: 0.23859045235878437 | validation: 0.20887325033406628]
	TIME [epoch: 9.96 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24815958060631327		[learning rate: 0.0022046]
	Learning Rate: 0.00220462
	LOSS [training: 0.24815958060631327 | validation: 0.20720376801920376]
	TIME [epoch: 9.98 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24004126562362674		[learning rate: 0.0021968]
	Learning Rate: 0.00219682
	LOSS [training: 0.24004126562362674 | validation: 0.20340914120680015]
	TIME [epoch: 9.97 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24934733642211648		[learning rate: 0.0021891]
	Learning Rate: 0.00218905
	LOSS [training: 0.24934733642211648 | validation: 0.20060940817275238]
	TIME [epoch: 9.96 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26959643700254415		[learning rate: 0.0021813]
	Learning Rate: 0.00218131
	LOSS [training: 0.26959643700254415 | validation: 0.21479771683714183]
	TIME [epoch: 9.98 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25617705720768574		[learning rate: 0.0021736]
	Learning Rate: 0.0021736
	LOSS [training: 0.25617705720768574 | validation: 0.20628851505540324]
	TIME [epoch: 9.96 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2458520016401736		[learning rate: 0.0021659]
	Learning Rate: 0.00216591
	LOSS [training: 0.2458520016401736 | validation: 0.20787803832682172]
	TIME [epoch: 9.97 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24970430258234058		[learning rate: 0.0021583]
	Learning Rate: 0.00215825
	LOSS [training: 0.24970430258234058 | validation: 0.21118814843859024]
	TIME [epoch: 9.97 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23819184078940892		[learning rate: 0.0021506]
	Learning Rate: 0.00215062
	LOSS [training: 0.23819184078940892 | validation: 0.20736044789906766]
	TIME [epoch: 9.96 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2422528440314962		[learning rate: 0.002143]
	Learning Rate: 0.00214302
	LOSS [training: 0.2422528440314962 | validation: 0.20624569535194764]
	TIME [epoch: 9.98 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24899305764607726		[learning rate: 0.0021354]
	Learning Rate: 0.00213544
	LOSS [training: 0.24899305764607726 | validation: 0.2107779912798456]
	TIME [epoch: 9.97 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26480592534811265		[learning rate: 0.0021279]
	Learning Rate: 0.00212789
	LOSS [training: 0.26480592534811265 | validation: 0.21119153531637497]
	TIME [epoch: 9.96 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2575442201965825		[learning rate: 0.0021204]
	Learning Rate: 0.00212036
	LOSS [training: 0.2575442201965825 | validation: 0.20356005699714194]
	TIME [epoch: 9.98 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24535049622238947		[learning rate: 0.0021129]
	Learning Rate: 0.00211287
	LOSS [training: 0.24535049622238947 | validation: 0.21485389499396387]
	TIME [epoch: 9.97 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24610679339169625		[learning rate: 0.0021054]
	Learning Rate: 0.00210539
	LOSS [training: 0.24610679339169625 | validation: 0.21035858857212203]
	TIME [epoch: 9.97 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24797880141810383		[learning rate: 0.0020979]
	Learning Rate: 0.00209795
	LOSS [training: 0.24797880141810383 | validation: 0.20447826325528956]
	TIME [epoch: 9.97 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2493354861848126		[learning rate: 0.0020905]
	Learning Rate: 0.00209053
	LOSS [training: 0.2493354861848126 | validation: 0.20959134266475998]
	TIME [epoch: 9.96 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24899433985354788		[learning rate: 0.0020831]
	Learning Rate: 0.00208314
	LOSS [training: 0.24899433985354788 | validation: 0.21206013399146334]
	TIME [epoch: 9.95 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25093798260098926		[learning rate: 0.0020758]
	Learning Rate: 0.00207577
	LOSS [training: 0.25093798260098926 | validation: 0.21010667438908287]
	TIME [epoch: 9.98 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24425389989497845		[learning rate: 0.0020684]
	Learning Rate: 0.00206843
	LOSS [training: 0.24425389989497845 | validation: 0.20440765595827629]
	TIME [epoch: 9.95 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24785372859178748		[learning rate: 0.0020611]
	Learning Rate: 0.00206112
	LOSS [training: 0.24785372859178748 | validation: 0.2178060304305224]
	TIME [epoch: 9.98 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24528068980576986		[learning rate: 0.0020538]
	Learning Rate: 0.00205383
	LOSS [training: 0.24528068980576986 | validation: 0.20516893421190127]
	TIME [epoch: 9.99 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25233404282022637		[learning rate: 0.0020466]
	Learning Rate: 0.00204657
	LOSS [training: 0.25233404282022637 | validation: 0.21766752202402162]
	TIME [epoch: 9.97 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2483773833047899		[learning rate: 0.0020393]
	Learning Rate: 0.00203933
	LOSS [training: 0.2483773833047899 | validation: 0.20550858289411505]
	TIME [epoch: 9.97 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2583299234442124		[learning rate: 0.0020321]
	Learning Rate: 0.00203212
	LOSS [training: 0.2583299234442124 | validation: 0.20844564352817038]
	TIME [epoch: 9.98 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23916778750119314		[learning rate: 0.0020249]
	Learning Rate: 0.00202493
	LOSS [training: 0.23916778750119314 | validation: 0.20043611798335786]
	TIME [epoch: 36.4 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24233377213595797		[learning rate: 0.0020178]
	Learning Rate: 0.00201777
	LOSS [training: 0.24233377213595797 | validation: 0.21043628491521632]
	TIME [epoch: 21.7 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24100094510183068		[learning rate: 0.0020106]
	Learning Rate: 0.00201064
	LOSS [training: 0.24100094510183068 | validation: 0.19799429076948094]
	TIME [epoch: 21.6 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25175191651774226		[learning rate: 0.0020035]
	Learning Rate: 0.00200353
	LOSS [training: 0.25175191651774226 | validation: 0.21074079572523577]
	TIME [epoch: 21.6 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2516810609262808		[learning rate: 0.0019964]
	Learning Rate: 0.00199644
	LOSS [training: 0.2516810609262808 | validation: 0.21481365194227867]
	TIME [epoch: 21.7 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24475832917388543		[learning rate: 0.0019894]
	Learning Rate: 0.00198938
	LOSS [training: 0.24475832917388543 | validation: 0.2058992901590298]
	TIME [epoch: 21.7 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24327934447175104		[learning rate: 0.0019823]
	Learning Rate: 0.00198235
	LOSS [training: 0.24327934447175104 | validation: 0.20312306566870802]
	TIME [epoch: 21.7 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25148468574090377		[learning rate: 0.0019753]
	Learning Rate: 0.00197534
	LOSS [training: 0.25148468574090377 | validation: 0.21186952264079503]
	TIME [epoch: 21.7 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24012468961688352		[learning rate: 0.0019684]
	Learning Rate: 0.00196835
	LOSS [training: 0.24012468961688352 | validation: 0.20928388280392674]
	TIME [epoch: 21.6 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24424488877702963		[learning rate: 0.0019614]
	Learning Rate: 0.00196139
	LOSS [training: 0.24424488877702963 | validation: 0.20218042714999776]
	TIME [epoch: 21.7 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2483862728639998		[learning rate: 0.0019545]
	Learning Rate: 0.00195445
	LOSS [training: 0.2483862728639998 | validation: 0.20659060464007228]
	TIME [epoch: 21.6 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24665923417867763		[learning rate: 0.0019475]
	Learning Rate: 0.00194754
	LOSS [training: 0.24665923417867763 | validation: 0.21508260774376997]
	TIME [epoch: 21.7 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24557267770957966		[learning rate: 0.0019407]
	Learning Rate: 0.00194066
	LOSS [training: 0.24557267770957966 | validation: 0.21720352422809683]
	TIME [epoch: 21.6 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.250124578237252		[learning rate: 0.0019338]
	Learning Rate: 0.00193379
	LOSS [training: 0.250124578237252 | validation: 0.2001782814501915]
	TIME [epoch: 21.6 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24807687813136667		[learning rate: 0.001927]
	Learning Rate: 0.00192696
	LOSS [training: 0.24807687813136667 | validation: 0.20832534404873454]
	TIME [epoch: 21.7 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23909075275682887		[learning rate: 0.0019201]
	Learning Rate: 0.00192014
	LOSS [training: 0.23909075275682887 | validation: 0.21854204427186677]
	TIME [epoch: 21.7 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2494500797207084		[learning rate: 0.0019134]
	Learning Rate: 0.00191335
	LOSS [training: 0.2494500797207084 | validation: 0.20331563107879305]
	TIME [epoch: 21.6 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24749977069005344		[learning rate: 0.0019066]
	Learning Rate: 0.00190659
	LOSS [training: 0.24749977069005344 | validation: 0.2000677224281961]
	TIME [epoch: 21.7 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24516910876456488		[learning rate: 0.0018998]
	Learning Rate: 0.00189984
	LOSS [training: 0.24516910876456488 | validation: 0.2212058648756004]
	TIME [epoch: 21.7 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25881241461636656		[learning rate: 0.0018931]
	Learning Rate: 0.00189313
	LOSS [training: 0.25881241461636656 | validation: 0.2147035011783613]
	TIME [epoch: 21.7 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24227811871067642		[learning rate: 0.0018864]
	Learning Rate: 0.00188643
	LOSS [training: 0.24227811871067642 | validation: 0.21241669707556526]
	TIME [epoch: 21.7 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25299512779198186		[learning rate: 0.0018798]
	Learning Rate: 0.00187976
	LOSS [training: 0.25299512779198186 | validation: 0.2062039298449307]
	TIME [epoch: 21.6 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24448124079580444		[learning rate: 0.0018731]
	Learning Rate: 0.00187311
	LOSS [training: 0.24448124079580444 | validation: 0.20424054401799277]
	TIME [epoch: 21.6 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2364466633403274		[learning rate: 0.0018665]
	Learning Rate: 0.00186649
	LOSS [training: 0.2364466633403274 | validation: 0.20484869128258568]
	TIME [epoch: 21.7 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24254282301662808		[learning rate: 0.0018599]
	Learning Rate: 0.00185989
	LOSS [training: 0.24254282301662808 | validation: 0.19906409130239205]
	TIME [epoch: 21.6 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.260987000486133		[learning rate: 0.0018533]
	Learning Rate: 0.00185331
	LOSS [training: 0.260987000486133 | validation: 0.20381516667891453]
	TIME [epoch: 21.7 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2510445042379151		[learning rate: 0.0018468]
	Learning Rate: 0.00184676
	LOSS [training: 0.2510445042379151 | validation: 0.20874880195888382]
	TIME [epoch: 21.7 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24265327702151232		[learning rate: 0.0018402]
	Learning Rate: 0.00184023
	LOSS [training: 0.24265327702151232 | validation: 0.2048147930388266]
	TIME [epoch: 21.7 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23834920260985734		[learning rate: 0.0018337]
	Learning Rate: 0.00183372
	LOSS [training: 0.23834920260985734 | validation: 0.21515753964221979]
	TIME [epoch: 21.6 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24691729903186732		[learning rate: 0.0018272]
	Learning Rate: 0.00182724
	LOSS [training: 0.24691729903186732 | validation: 0.2041211810485465]
	TIME [epoch: 21.7 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25025863960359057		[learning rate: 0.0018208]
	Learning Rate: 0.00182078
	LOSS [training: 0.25025863960359057 | validation: 0.21532740746095874]
	TIME [epoch: 21.6 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2506539922212798		[learning rate: 0.0018143]
	Learning Rate: 0.00181434
	LOSS [training: 0.2506539922212798 | validation: 0.21214526957376162]
	TIME [epoch: 21.7 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24737199030310653		[learning rate: 0.0018079]
	Learning Rate: 0.00180792
	LOSS [training: 0.24737199030310653 | validation: 0.20378431122709723]
	TIME [epoch: 21.7 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24344325822339294		[learning rate: 0.0018015]
	Learning Rate: 0.00180153
	LOSS [training: 0.24344325822339294 | validation: 0.2141788722104067]
	TIME [epoch: 21.7 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24250898372666208		[learning rate: 0.0017952]
	Learning Rate: 0.00179516
	LOSS [training: 0.24250898372666208 | validation: 0.2161728486879894]
	TIME [epoch: 21.7 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24610992646653854		[learning rate: 0.0017888]
	Learning Rate: 0.00178881
	LOSS [training: 0.24610992646653854 | validation: 0.20148864657987203]
	TIME [epoch: 21.7 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24505474396484417		[learning rate: 0.0017825]
	Learning Rate: 0.00178248
	LOSS [training: 0.24505474396484417 | validation: 0.20357990777654114]
	TIME [epoch: 21.7 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2494613511938104		[learning rate: 0.0017762]
	Learning Rate: 0.00177618
	LOSS [training: 0.2494613511938104 | validation: 0.19949972476656502]
	TIME [epoch: 21.7 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23306975556579568		[learning rate: 0.0017699]
	Learning Rate: 0.0017699
	LOSS [training: 0.23306975556579568 | validation: 0.21629583601145158]
	TIME [epoch: 21.7 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24224517787031993		[learning rate: 0.0017636]
	Learning Rate: 0.00176364
	LOSS [training: 0.24224517787031993 | validation: 0.20074901309234808]
	TIME [epoch: 21.7 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24622289387229937		[learning rate: 0.0017574]
	Learning Rate: 0.0017574
	LOSS [training: 0.24622289387229937 | validation: 0.2031419360431445]
	TIME [epoch: 21.7 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2536139380027504		[learning rate: 0.0017512]
	Learning Rate: 0.00175119
	LOSS [training: 0.2536139380027504 | validation: 0.21692347831865116]
	TIME [epoch: 21.7 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2543535865346023		[learning rate: 0.001745]
	Learning Rate: 0.001745
	LOSS [training: 0.2543535865346023 | validation: 0.22665696654870127]
	TIME [epoch: 21.7 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24115316091255956		[learning rate: 0.0017388]
	Learning Rate: 0.00173883
	LOSS [training: 0.24115316091255956 | validation: 0.21080665807866933]
	TIME [epoch: 21.7 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.244130977453932		[learning rate: 0.0017327]
	Learning Rate: 0.00173268
	LOSS [training: 0.244130977453932 | validation: 0.20528499590684426]
	TIME [epoch: 21.7 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24966624529571801		[learning rate: 0.0017266]
	Learning Rate: 0.00172655
	LOSS [training: 0.24966624529571801 | validation: 0.20907986754241353]
	TIME [epoch: 21.7 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23696971528594854		[learning rate: 0.0017204]
	Learning Rate: 0.00172045
	LOSS [training: 0.23696971528594854 | validation: 0.207504952983019]
	TIME [epoch: 21.7 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2502918566777404		[learning rate: 0.0017144]
	Learning Rate: 0.00171436
	LOSS [training: 0.2502918566777404 | validation: 0.20944676796767295]
	TIME [epoch: 21.7 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25720732298434895		[learning rate: 0.0017083]
	Learning Rate: 0.0017083
	LOSS [training: 0.25720732298434895 | validation: 0.216437545479463]
	TIME [epoch: 21.6 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2480579570438505		[learning rate: 0.0017023]
	Learning Rate: 0.00170226
	LOSS [training: 0.2480579570438505 | validation: 0.21054688559299645]
	TIME [epoch: 21.7 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2568952298025396		[learning rate: 0.0016962]
	Learning Rate: 0.00169624
	LOSS [training: 0.2568952298025396 | validation: 0.22509965286740896]
	TIME [epoch: 21.7 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25412171484265217		[learning rate: 0.0016902]
	Learning Rate: 0.00169024
	LOSS [training: 0.25412171484265217 | validation: 0.2105929513568002]
	TIME [epoch: 21.7 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2455810310040193		[learning rate: 0.0016843]
	Learning Rate: 0.00168426
	LOSS [training: 0.2455810310040193 | validation: 0.21069248927908654]
	TIME [epoch: 21.7 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2552301733822641		[learning rate: 0.0016783]
	Learning Rate: 0.00167831
	LOSS [training: 0.2552301733822641 | validation: 0.2047436231869521]
	TIME [epoch: 21.6 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24325724892065134		[learning rate: 0.0016724]
	Learning Rate: 0.00167237
	LOSS [training: 0.24325724892065134 | validation: 0.2068000710498929]
	TIME [epoch: 21.7 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2424944695646111		[learning rate: 0.0016665]
	Learning Rate: 0.00166646
	LOSS [training: 0.2424944695646111 | validation: 0.20810383428647866]
	TIME [epoch: 21.7 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24769573661020286		[learning rate: 0.0016606]
	Learning Rate: 0.00166057
	LOSS [training: 0.24769573661020286 | validation: 0.20015802380824557]
	TIME [epoch: 21.7 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2536787823028599		[learning rate: 0.0016547]
	Learning Rate: 0.00165469
	LOSS [training: 0.2536787823028599 | validation: 0.19920956279457766]
	TIME [epoch: 21.7 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25376906322822496		[learning rate: 0.0016488]
	Learning Rate: 0.00164884
	LOSS [training: 0.25376906322822496 | validation: 0.21309912363113526]
	TIME [epoch: 21.7 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2461483818114607		[learning rate: 0.001643]
	Learning Rate: 0.00164301
	LOSS [training: 0.2461483818114607 | validation: 0.20541358448117278]
	TIME [epoch: 21.7 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2372153385690973		[learning rate: 0.0016372]
	Learning Rate: 0.0016372
	LOSS [training: 0.2372153385690973 | validation: 0.21213257718057746]
	TIME [epoch: 21.7 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24744108527074782		[learning rate: 0.0016314]
	Learning Rate: 0.00163141
	LOSS [training: 0.24744108527074782 | validation: 0.20221003778937968]
	TIME [epoch: 21.7 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25645346746048686		[learning rate: 0.0016256]
	Learning Rate: 0.00162564
	LOSS [training: 0.25645346746048686 | validation: 0.20680825459337876]
	TIME [epoch: 21.6 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24914905184182531		[learning rate: 0.0016199]
	Learning Rate: 0.0016199
	LOSS [training: 0.24914905184182531 | validation: 0.2165125595729287]
	TIME [epoch: 21.6 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24237373492025716		[learning rate: 0.0016142]
	Learning Rate: 0.00161417
	LOSS [training: 0.24237373492025716 | validation: 0.21173777423566026]
	TIME [epoch: 21.6 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2468703376636654		[learning rate: 0.0016085]
	Learning Rate: 0.00160846
	LOSS [training: 0.2468703376636654 | validation: 0.22300965041385207]
	TIME [epoch: 21.6 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.251565260615995		[learning rate: 0.0016028]
	Learning Rate: 0.00160277
	LOSS [training: 0.251565260615995 | validation: 0.2046736393385805]
	TIME [epoch: 21.6 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24980799166175938		[learning rate: 0.0015971]
	Learning Rate: 0.0015971
	LOSS [training: 0.24980799166175938 | validation: 0.21286544342063385]
	TIME [epoch: 21.6 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24741050627113717		[learning rate: 0.0015915]
	Learning Rate: 0.00159146
	LOSS [training: 0.24741050627113717 | validation: 0.2176628443449021]
	TIME [epoch: 21.6 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25321114077403056		[learning rate: 0.0015858]
	Learning Rate: 0.00158583
	LOSS [training: 0.25321114077403056 | validation: 0.21323893875633065]
	TIME [epoch: 21.6 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2470138097564921		[learning rate: 0.0015802]
	Learning Rate: 0.00158022
	LOSS [training: 0.2470138097564921 | validation: 0.21646307038381035]
	TIME [epoch: 21.7 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24280748602711547		[learning rate: 0.0015746]
	Learning Rate: 0.00157463
	LOSS [training: 0.24280748602711547 | validation: 0.2103531514539768]
	TIME [epoch: 21.7 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24582409720311993		[learning rate: 0.0015691]
	Learning Rate: 0.00156907
	LOSS [training: 0.24582409720311993 | validation: 0.21998442228934872]
	TIME [epoch: 21.7 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2484661054614513		[learning rate: 0.0015635]
	Learning Rate: 0.00156352
	LOSS [training: 0.2484661054614513 | validation: 0.21654521193424117]
	TIME [epoch: 21.7 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25321977920153854		[learning rate: 0.001558]
	Learning Rate: 0.00155799
	LOSS [training: 0.25321977920153854 | validation: 0.21830521276250286]
	TIME [epoch: 21.7 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2453419540008389		[learning rate: 0.0015525]
	Learning Rate: 0.00155248
	LOSS [training: 0.2453419540008389 | validation: 0.23628945918483296]
	TIME [epoch: 21.7 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2376325641487312		[learning rate: 0.001547]
	Learning Rate: 0.00154699
	LOSS [training: 0.2376325641487312 | validation: 0.2069687565235617]
	TIME [epoch: 21.7 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24253607047184722		[learning rate: 0.0015415]
	Learning Rate: 0.00154152
	LOSS [training: 0.24253607047184722 | validation: 0.20124034641501104]
	TIME [epoch: 21.7 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2436347097879108		[learning rate: 0.0015361]
	Learning Rate: 0.00153607
	LOSS [training: 0.2436347097879108 | validation: 0.21304492214373613]
	TIME [epoch: 21.7 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2448758788000062		[learning rate: 0.0015306]
	Learning Rate: 0.00153064
	LOSS [training: 0.2448758788000062 | validation: 0.20838637848670297]
	TIME [epoch: 21.7 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24252353728261425		[learning rate: 0.0015252]
	Learning Rate: 0.00152522
	LOSS [training: 0.24252353728261425 | validation: 0.2181601104663188]
	TIME [epoch: 21.7 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23795628164104396		[learning rate: 0.0015198]
	Learning Rate: 0.00151983
	LOSS [training: 0.23795628164104396 | validation: 0.20343705191668016]
	TIME [epoch: 21.7 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24230399144144746		[learning rate: 0.0015145]
	Learning Rate: 0.00151446
	LOSS [training: 0.24230399144144746 | validation: 0.20887685468205702]
	TIME [epoch: 21.7 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23421783610277444		[learning rate: 0.0015091]
	Learning Rate: 0.0015091
	LOSS [training: 0.23421783610277444 | validation: 0.20617171467258624]
	TIME [epoch: 21.7 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23898163780068735		[learning rate: 0.0015038]
	Learning Rate: 0.00150376
	LOSS [training: 0.23898163780068735 | validation: 0.21767436612006782]
	TIME [epoch: 21.7 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2473801235666159		[learning rate: 0.0014984]
	Learning Rate: 0.00149845
	LOSS [training: 0.2473801235666159 | validation: 0.2144371029703523]
	TIME [epoch: 21.7 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23911958907473915		[learning rate: 0.0014931]
	Learning Rate: 0.00149315
	LOSS [training: 0.23911958907473915 | validation: 0.20230066531062452]
	TIME [epoch: 21.7 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24576033122714203		[learning rate: 0.0014879]
	Learning Rate: 0.00148787
	LOSS [training: 0.24576033122714203 | validation: 0.20408341288984572]
	TIME [epoch: 21.7 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23403487519651245		[learning rate: 0.0014826]
	Learning Rate: 0.00148261
	LOSS [training: 0.23403487519651245 | validation: 0.2018359841497977]
	TIME [epoch: 21.7 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23798862729389628		[learning rate: 0.0014774]
	Learning Rate: 0.00147736
	LOSS [training: 0.23798862729389628 | validation: 0.22506162274235111]
	TIME [epoch: 21.7 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2386669695321093		[learning rate: 0.0014721]
	Learning Rate: 0.00147214
	LOSS [training: 0.2386669695321093 | validation: 0.2072316891395945]
	TIME [epoch: 21.7 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24075548199332572		[learning rate: 0.0014669]
	Learning Rate: 0.00146693
	LOSS [training: 0.24075548199332572 | validation: 0.20302689476543553]
	TIME [epoch: 21.6 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2288773102836342		[learning rate: 0.0014617]
	Learning Rate: 0.00146175
	LOSS [training: 0.2288773102836342 | validation: 0.20374468944076352]
	TIME [epoch: 21.7 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2375664563865182		[learning rate: 0.0014566]
	Learning Rate: 0.00145658
	LOSS [training: 0.2375664563865182 | validation: 0.21885173110061867]
	TIME [epoch: 21.7 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23755019091588916		[learning rate: 0.0014514]
	Learning Rate: 0.00145143
	LOSS [training: 0.23755019091588916 | validation: 0.22470708315851545]
	TIME [epoch: 21.7 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2530396200719734		[learning rate: 0.0014463]
	Learning Rate: 0.00144629
	LOSS [training: 0.2530396200719734 | validation: 0.21677639250907005]
	TIME [epoch: 21.7 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24488511290406292		[learning rate: 0.0014412]
	Learning Rate: 0.00144118
	LOSS [training: 0.24488511290406292 | validation: 0.20826327174310508]
	TIME [epoch: 21.7 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25045775091325856		[learning rate: 0.0014361]
	Learning Rate: 0.00143608
	LOSS [training: 0.25045775091325856 | validation: 0.20399711590488864]
	TIME [epoch: 21.7 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24019357183003678		[learning rate: 0.001431]
	Learning Rate: 0.001431
	LOSS [training: 0.24019357183003678 | validation: 0.21401396302085862]
	TIME [epoch: 21.7 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23591942383458475		[learning rate: 0.0014259]
	Learning Rate: 0.00142594
	LOSS [training: 0.23591942383458475 | validation: 0.21366557232203176]
	TIME [epoch: 21.7 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24559893284198278		[learning rate: 0.0014209]
	Learning Rate: 0.0014209
	LOSS [training: 0.24559893284198278 | validation: 0.2027419712196159]
	TIME [epoch: 21.7 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2403163133531143		[learning rate: 0.0014159]
	Learning Rate: 0.00141588
	LOSS [training: 0.2403163133531143 | validation: 0.2179485165631355]
	TIME [epoch: 21.7 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25365754387511114		[learning rate: 0.0014109]
	Learning Rate: 0.00141087
	LOSS [training: 0.25365754387511114 | validation: 0.2137254859043642]
	TIME [epoch: 21.7 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2513538790793904		[learning rate: 0.0014059]
	Learning Rate: 0.00140588
	LOSS [training: 0.2513538790793904 | validation: 0.2281443448965855]
	TIME [epoch: 21.7 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2516811374277904		[learning rate: 0.0014009]
	Learning Rate: 0.00140091
	LOSS [training: 0.2516811374277904 | validation: 0.21505767471332074]
	TIME [epoch: 21.7 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24057734327915034		[learning rate: 0.001396]
	Learning Rate: 0.00139596
	LOSS [training: 0.24057734327915034 | validation: 0.21014882886808794]
	TIME [epoch: 21.7 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24031449192279097		[learning rate: 0.001391]
	Learning Rate: 0.00139102
	LOSS [training: 0.24031449192279097 | validation: 0.2152038610827674]
	TIME [epoch: 21.7 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23643648677125514		[learning rate: 0.0013861]
	Learning Rate: 0.0013861
	LOSS [training: 0.23643648677125514 | validation: 0.22204154036486767]
	TIME [epoch: 21.7 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24857648469530932		[learning rate: 0.0013812]
	Learning Rate: 0.0013812
	LOSS [training: 0.24857648469530932 | validation: 0.22672942244403252]
	TIME [epoch: 21.7 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2486966664463842		[learning rate: 0.0013763]
	Learning Rate: 0.00137632
	LOSS [training: 0.2486966664463842 | validation: 0.22173380444953947]
	TIME [epoch: 21.7 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24079981874097525		[learning rate: 0.0013714]
	Learning Rate: 0.00137145
	LOSS [training: 0.24079981874097525 | validation: 0.21992246105716914]
	TIME [epoch: 21.7 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23844231990676576		[learning rate: 0.0013666]
	Learning Rate: 0.0013666
	LOSS [training: 0.23844231990676576 | validation: 0.2165828450106023]
	TIME [epoch: 21.7 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23514051587673693		[learning rate: 0.0013618]
	Learning Rate: 0.00136177
	LOSS [training: 0.23514051587673693 | validation: 0.22042079189057198]
	TIME [epoch: 21.7 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24463218672242548		[learning rate: 0.001357]
	Learning Rate: 0.00135695
	LOSS [training: 0.24463218672242548 | validation: 0.20840623366842817]
	TIME [epoch: 21.7 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2439886588985051		[learning rate: 0.0013522]
	Learning Rate: 0.00135215
	LOSS [training: 0.2439886588985051 | validation: 0.20675802850017905]
	TIME [epoch: 21.7 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2526608691725245		[learning rate: 0.0013474]
	Learning Rate: 0.00134737
	LOSS [training: 0.2526608691725245 | validation: 0.2218575044882757]
	TIME [epoch: 21.7 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24652288188209934		[learning rate: 0.0013426]
	Learning Rate: 0.00134261
	LOSS [training: 0.24652288188209934 | validation: 0.21387837889186345]
	TIME [epoch: 21.7 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2580907448815042		[learning rate: 0.0013379]
	Learning Rate: 0.00133786
	LOSS [training: 0.2580907448815042 | validation: 0.20779145743124858]
	TIME [epoch: 21.7 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15_20240719_005104/states/model_facs_v3_dec1b_2dpca_v15_618.pth
Halted early. No improvement in validation loss for 200 epochs.
Finished training in 7404.416 seconds.
