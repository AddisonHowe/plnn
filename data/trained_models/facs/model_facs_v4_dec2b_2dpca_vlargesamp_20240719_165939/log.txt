Args:
Namespace(name='model_facs_v4_dec2b_2dpca_vlargesamp', outdir='out/model_training/model_facs_v4_dec2b_2dpca_vlargesamp', training_data='data/training_data/facs_v4/pca/dec2_fitonsubset/transition2_subset_ce_pn_m_pc12/training', validation_data='data/training_data/facs_v4/pca/dec2_fitonsubset/transition2_subset_ce_pn_m_pc12/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=10, batch_size=50, patience=200, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, quadratic_a=1.0, quadratic_b=1.0, ndims=2, nparams=2, nsigs=2, ncells=2000, ncells_sample=2000, model_do_sample=False, dt=0.005, dt_schedule='stepped', dt_schedule_bounds=[150, 250, 350, 450], dt_schedule_scales=[0.8, 0.8, 0.8, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', kernel='multiscale', bw_range=[0.2, 0.5, 0.9, 1.1, 1.3, 1.5, 2.0], optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=0.0001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 3074054673

Training model...

Saving initial model state to: out/model_training/model_facs_v4_dec2b_2dpca_vlargesamp_20240719_165939/states/model_facs_v4_dec2b_2dpca_vlargesamp_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.61194391957756		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.61194391957756 | validation: 1.1157181343965188]
	TIME [epoch: 39.6 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_vlargesamp_20240719_165939/states/model_facs_v4_dec2b_2dpca_vlargesamp_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7926504164734725		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7926504164734725 | validation: 0.8610499861740631]
	TIME [epoch: 11 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_vlargesamp_20240719_165939/states/model_facs_v4_dec2b_2dpca_vlargesamp_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.704072022348756		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.704072022348756 | validation: 0.8164823727493973]
	TIME [epoch: 11 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_vlargesamp_20240719_165939/states/model_facs_v4_dec2b_2dpca_vlargesamp_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6117696754920362		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6117696754920362 | validation: 0.7348955634109722]
	TIME [epoch: 11 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_vlargesamp_20240719_165939/states/model_facs_v4_dec2b_2dpca_vlargesamp_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5908504526637195		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5908504526637195 | validation: 0.7442372791219236]
	TIME [epoch: 11 sec]
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.584091643681711		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.584091643681711 | validation: 0.9093195792635066]
	TIME [epoch: 11 sec]
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6235499447730081		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6235499447730081 | validation: 0.7180545402978274]
	TIME [epoch: 11 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_vlargesamp_20240719_165939/states/model_facs_v4_dec2b_2dpca_vlargesamp_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5022628992987179		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5022628992987179 | validation: 0.6448619743706988]
	TIME [epoch: 11 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_vlargesamp_20240719_165939/states/model_facs_v4_dec2b_2dpca_vlargesamp_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5455409261153281		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5455409261153281 | validation: 0.5689409330433608]
	TIME [epoch: 11 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_vlargesamp_20240719_165939/states/model_facs_v4_dec2b_2dpca_vlargesamp_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4955391346369209		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4955391346369209 | validation: 0.5476913314451518]
	TIME [epoch: 11 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_vlargesamp_20240719_165939/states/model_facs_v4_dec2b_2dpca_vlargesamp_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4358852745168916		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4358852745168916 | validation: 0.5412854479417757]
	TIME [epoch: 11 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_vlargesamp_20240719_165939/states/model_facs_v4_dec2b_2dpca_vlargesamp_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41380186418413434		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.41380186418413434 | validation: 0.546325908363487]
	TIME [epoch: 11 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45344116566577963		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.45344116566577963 | validation: 0.4910007615357395]
	TIME [epoch: 11 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_vlargesamp_20240719_165939/states/model_facs_v4_dec2b_2dpca_vlargesamp_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.410079486919439		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.410079486919439 | validation: 0.5537544893801831]
	TIME [epoch: 11 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3719845169098126		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3719845169098126 | validation: 0.568022769058495]
	TIME [epoch: 11 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40536627304640827		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.40536627304640827 | validation: 0.4648281055333694]
	TIME [epoch: 11 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_vlargesamp_20240719_165939/states/model_facs_v4_dec2b_2dpca_vlargesamp_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3615448117927964		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3615448117927964 | validation: 0.4988588926209244]
	TIME [epoch: 11 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.374317924137466		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.374317924137466 | validation: 0.5815097644684901]
	TIME [epoch: 11 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37422967734510426		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.37422967734510426 | validation: 0.42927636065550445]
	TIME [epoch: 11 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_vlargesamp_20240719_165939/states/model_facs_v4_dec2b_2dpca_vlargesamp_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32242167124469134		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.32242167124469134 | validation: 0.5152484834852937]
	TIME [epoch: 11 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37192232636475064		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.37192232636475064 | validation: 0.4763674775759693]
	TIME [epoch: 11 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3000604769651735		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3000604769651735 | validation: 0.4007343982500447]
	TIME [epoch: 11 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_vlargesamp_20240719_165939/states/model_facs_v4_dec2b_2dpca_vlargesamp_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3207088402727876		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3207088402727876 | validation: 0.38724825191363976]
	TIME [epoch: 11 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_vlargesamp_20240719_165939/states/model_facs_v4_dec2b_2dpca_vlargesamp_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.303690773144016		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.303690773144016 | validation: 0.4263577024512531]
	TIME [epoch: 11 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2878138547844322		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2878138547844322 | validation: 0.4305033630798104]
	TIME [epoch: 11 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25027726565109776		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.25027726565109776 | validation: 0.3528375903449612]
	TIME [epoch: 11 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_vlargesamp_20240719_165939/states/model_facs_v4_dec2b_2dpca_vlargesamp_26.pth
	Model improved!!!
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2214232324516942		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2214232324516942 | validation: 0.4438414798688989]
	TIME [epoch: 11 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2746526450696361		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2746526450696361 | validation: 0.3594916795932711]
	TIME [epoch: 11 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23919492551803107		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23919492551803107 | validation: 0.41694754533690376]
	TIME [epoch: 11 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26574538534726716		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.26574538534726716 | validation: 0.4293376242861936]
	TIME [epoch: 11 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24483917778760483		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24483917778760483 | validation: 0.36765647751563457]
	TIME [epoch: 11 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2517832201209086		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2517832201209086 | validation: 0.38456658318050235]
	TIME [epoch: 11 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2660915557790642		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2660915557790642 | validation: 0.4531955547147231]
	TIME [epoch: 11 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25566695103427506		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.25566695103427506 | validation: 0.4455234166491693]
	TIME [epoch: 11 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2601036951276702		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2601036951276702 | validation: 0.38802341113242234]
	TIME [epoch: 11 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24599046104531863		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24599046104531863 | validation: 0.3844276888978358]
	TIME [epoch: 11 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2053287679005543		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2053287679005543 | validation: 0.3813159043191701]
	TIME [epoch: 11 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2669540823889669		[learning rate: 0.0099921]
	Learning Rate: 0.00999213
	LOSS [training: 0.2669540823889669 | validation: 0.4032956531347531]
	TIME [epoch: 11 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25938284029474085		[learning rate: 0.0099607]
	Learning Rate: 0.00996072
	LOSS [training: 0.25938284029474085 | validation: 0.431226668838658]
	TIME [epoch: 11 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2515576493160353		[learning rate: 0.0099294]
	Learning Rate: 0.0099294
	LOSS [training: 0.2515576493160353 | validation: 0.46194315802946095]
	TIME [epoch: 11 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23605119043923023		[learning rate: 0.0098982]
	Learning Rate: 0.00989818
	LOSS [training: 0.23605119043923023 | validation: 0.41966504192839327]
	TIME [epoch: 11 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24465651802801716		[learning rate: 0.0098671]
	Learning Rate: 0.00986707
	LOSS [training: 0.24465651802801716 | validation: 0.38371076448245955]
	TIME [epoch: 11 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21671246537403416		[learning rate: 0.009836]
	Learning Rate: 0.00983604
	LOSS [training: 0.21671246537403416 | validation: 0.35799917000192566]
	TIME [epoch: 11 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2137984317245414		[learning rate: 0.0098051]
	Learning Rate: 0.00980512
	LOSS [training: 0.2137984317245414 | validation: 0.3641125309399027]
	TIME [epoch: 11 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24913870157647794		[learning rate: 0.0097743]
	Learning Rate: 0.0097743
	LOSS [training: 0.24913870157647794 | validation: 0.5553738252268152]
	TIME [epoch: 11 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2730535020471771		[learning rate: 0.0097436]
	Learning Rate: 0.00974357
	LOSS [training: 0.2730535020471771 | validation: 0.38602062465589254]
	TIME [epoch: 11 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21526293671809518		[learning rate: 0.0097129]
	Learning Rate: 0.00971293
	LOSS [training: 0.21526293671809518 | validation: 0.32844196831594213]
	TIME [epoch: 11 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_vlargesamp_20240719_165939/states/model_facs_v4_dec2b_2dpca_vlargesamp_47.pth
	Model improved!!!
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2094035488430756		[learning rate: 0.0096824]
	Learning Rate: 0.0096824
	LOSS [training: 0.2094035488430756 | validation: 0.5327837622526927]
	TIME [epoch: 11 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3395883043855712		[learning rate: 0.009652]
	Learning Rate: 0.00965196
	LOSS [training: 0.3395883043855712 | validation: 0.38013551265312917]
	TIME [epoch: 11 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21802415754926113		[learning rate: 0.0096216]
	Learning Rate: 0.00962161
	LOSS [training: 0.21802415754926113 | validation: 0.3616001887854643]
	TIME [epoch: 10.9 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23831616440853196		[learning rate: 0.0095914]
	Learning Rate: 0.00959136
	LOSS [training: 0.23831616440853196 | validation: 0.49547560749215547]
	TIME [epoch: 10.9 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1981332580267358		[learning rate: 0.0095612]
	Learning Rate: 0.00956121
	LOSS [training: 0.1981332580267358 | validation: 0.3816190877846829]
	TIME [epoch: 10.9 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22767396103582044		[learning rate: 0.0095311]
	Learning Rate: 0.00953115
	LOSS [training: 0.22767396103582044 | validation: 0.3551841957092249]
	TIME [epoch: 11 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2433512560522522		[learning rate: 0.0095012]
	Learning Rate: 0.00950118
	LOSS [training: 0.2433512560522522 | validation: 0.4469982985181391]
	TIME [epoch: 11 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25012582629498037		[learning rate: 0.0094713]
	Learning Rate: 0.00947131
	LOSS [training: 0.25012582629498037 | validation: 0.45752456351708415]
	TIME [epoch: 11 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28690831709572095		[learning rate: 0.0094415]
	Learning Rate: 0.00944154
	LOSS [training: 0.28690831709572095 | validation: 0.5109728498420598]
	TIME [epoch: 11 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22530712581834658		[learning rate: 0.0094119]
	Learning Rate: 0.00941185
	LOSS [training: 0.22530712581834658 | validation: 0.3528320824358952]
	TIME [epoch: 11 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17871365527783722		[learning rate: 0.0093823]
	Learning Rate: 0.00938226
	LOSS [training: 0.17871365527783722 | validation: 0.34818297417717436]
	TIME [epoch: 10.9 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2257030885897353		[learning rate: 0.0093528]
	Learning Rate: 0.00935277
	LOSS [training: 0.2257030885897353 | validation: 0.4269056532605937]
	TIME [epoch: 10.9 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23708554150756855		[learning rate: 0.0093234]
	Learning Rate: 0.00932336
	LOSS [training: 0.23708554150756855 | validation: 0.5590617812244608]
	TIME [epoch: 10.9 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22661887349828297		[learning rate: 0.0092941]
	Learning Rate: 0.00929405
	LOSS [training: 0.22661887349828297 | validation: 0.38913225967497944]
	TIME [epoch: 11 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.268585461572481		[learning rate: 0.0092648]
	Learning Rate: 0.00926483
	LOSS [training: 0.268585461572481 | validation: 0.42187136350238297]
	TIME [epoch: 10.9 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21130741512145146		[learning rate: 0.0092357]
	Learning Rate: 0.00923571
	LOSS [training: 0.21130741512145146 | validation: 0.3476344886348443]
	TIME [epoch: 11 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1706152190272282		[learning rate: 0.0092067]
	Learning Rate: 0.00920667
	LOSS [training: 0.1706152190272282 | validation: 0.4084553000345892]
	TIME [epoch: 10.9 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20149140165493754		[learning rate: 0.0091777]
	Learning Rate: 0.00917772
	LOSS [training: 0.20149140165493754 | validation: 0.3811570994177888]
	TIME [epoch: 11 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20441006182218496		[learning rate: 0.0091489]
	Learning Rate: 0.00914887
	LOSS [training: 0.20441006182218496 | validation: 0.4602989798525262]
	TIME [epoch: 10.9 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20456837273990686		[learning rate: 0.0091201]
	Learning Rate: 0.00912011
	LOSS [training: 0.20456837273990686 | validation: 0.3778035320279245]
	TIME [epoch: 10.9 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1850940750397443		[learning rate: 0.0090914]
	Learning Rate: 0.00909144
	LOSS [training: 0.1850940750397443 | validation: 0.35842648162274326]
	TIME [epoch: 11 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17864042041834868		[learning rate: 0.0090629]
	Learning Rate: 0.00906285
	LOSS [training: 0.17864042041834868 | validation: 0.33019124988898885]
	TIME [epoch: 11 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18313320265756378		[learning rate: 0.0090344]
	Learning Rate: 0.00903436
	LOSS [training: 0.18313320265756378 | validation: 0.42088367109408686]
	TIME [epoch: 10.9 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26949826154742734		[learning rate: 0.009006]
	Learning Rate: 0.00900596
	LOSS [training: 0.26949826154742734 | validation: 0.39518737165656803]
	TIME [epoch: 11 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2134661341842614		[learning rate: 0.0089776]
	Learning Rate: 0.00897764
	LOSS [training: 0.2134661341842614 | validation: 0.3579904334730535]
	TIME [epoch: 11 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19948776087707226		[learning rate: 0.0089494]
	Learning Rate: 0.00894942
	LOSS [training: 0.19948776087707226 | validation: 0.377383944773199]
	TIME [epoch: 11 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22290676440469537		[learning rate: 0.0089213]
	Learning Rate: 0.00892128
	LOSS [training: 0.22290676440469537 | validation: 0.45016730680271977]
	TIME [epoch: 11 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19119082105971327		[learning rate: 0.0088932]
	Learning Rate: 0.00889324
	LOSS [training: 0.19119082105971327 | validation: 0.31523366450643053]
	TIME [epoch: 11 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_vlargesamp_20240719_165939/states/model_facs_v4_dec2b_2dpca_vlargesamp_75.pth
	Model improved!!!
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18766143756552317		[learning rate: 0.0088653]
	Learning Rate: 0.00886528
	LOSS [training: 0.18766143756552317 | validation: 0.32639995942062183]
	TIME [epoch: 11 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20532396170097572		[learning rate: 0.0088374]
	Learning Rate: 0.00883741
	LOSS [training: 0.20532396170097572 | validation: 0.532095656438762]
	TIME [epoch: 10.9 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2343980422082309		[learning rate: 0.0088096]
	Learning Rate: 0.00880962
	LOSS [training: 0.2343980422082309 | validation: 0.4201658145532092]
	TIME [epoch: 10.9 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18521316127495022		[learning rate: 0.0087819]
	Learning Rate: 0.00878192
	LOSS [training: 0.18521316127495022 | validation: 0.33568637922415595]
	TIME [epoch: 11 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17115143208629122		[learning rate: 0.0087543]
	Learning Rate: 0.00875432
	LOSS [training: 0.17115143208629122 | validation: 0.3785860551476572]
	TIME [epoch: 11 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18289222673613453		[learning rate: 0.0087268]
	Learning Rate: 0.00872679
	LOSS [training: 0.18289222673613453 | validation: 0.5075149177036407]
	TIME [epoch: 10.9 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20053015254844597		[learning rate: 0.0086994]
	Learning Rate: 0.00869936
	LOSS [training: 0.20053015254844597 | validation: 0.4747502565378382]
	TIME [epoch: 10.9 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20870853412268747		[learning rate: 0.008672]
	Learning Rate: 0.00867201
	LOSS [training: 0.20870853412268747 | validation: 0.4364412841092769]
	TIME [epoch: 10.9 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19386790228447381		[learning rate: 0.0086447]
	Learning Rate: 0.00864474
	LOSS [training: 0.19386790228447381 | validation: 0.44877182697045126]
	TIME [epoch: 11 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21354020226317694		[learning rate: 0.0086176]
	Learning Rate: 0.00861757
	LOSS [training: 0.21354020226317694 | validation: 0.43512910461629173]
	TIME [epoch: 11 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1868080989102589		[learning rate: 0.0085905]
	Learning Rate: 0.00859047
	LOSS [training: 0.1868080989102589 | validation: 0.3588813166278471]
	TIME [epoch: 10.9 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19498009043993944		[learning rate: 0.0085635]
	Learning Rate: 0.00856347
	LOSS [training: 0.19498009043993944 | validation: 0.3959757896082903]
	TIME [epoch: 10.9 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19787297906537915		[learning rate: 0.0085365]
	Learning Rate: 0.00853654
	LOSS [training: 0.19787297906537915 | validation: 0.3591320088087558]
	TIME [epoch: 11 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2072729681103275		[learning rate: 0.0085097]
	Learning Rate: 0.0085097
	LOSS [training: 0.2072729681103275 | validation: 0.3708286471724377]
	TIME [epoch: 10.9 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20619630253640442		[learning rate: 0.008483]
	Learning Rate: 0.00848295
	LOSS [training: 0.20619630253640442 | validation: 0.3455333236799477]
	TIME [epoch: 10.9 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21165715807471566		[learning rate: 0.0084563]
	Learning Rate: 0.00845628
	LOSS [training: 0.21165715807471566 | validation: 0.4683323166803352]
	TIME [epoch: 10.9 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19032579294150728		[learning rate: 0.0084297]
	Learning Rate: 0.0084297
	LOSS [training: 0.19032579294150728 | validation: 0.3073899846838956]
	TIME [epoch: 11 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_vlargesamp_20240719_165939/states/model_facs_v4_dec2b_2dpca_vlargesamp_92.pth
	Model improved!!!
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1453411494580729		[learning rate: 0.0084032]
	Learning Rate: 0.0084032
	LOSS [training: 0.1453411494580729 | validation: 0.31289163067313913]
	TIME [epoch: 10.9 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1843015440555044		[learning rate: 0.0083768]
	Learning Rate: 0.00837678
	LOSS [training: 0.1843015440555044 | validation: 0.45272354366605366]
	TIME [epoch: 10.9 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18278964782240936		[learning rate: 0.0083504]
	Learning Rate: 0.00835044
	LOSS [training: 0.18278964782240936 | validation: 0.3463361218094633]
	TIME [epoch: 10.9 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1709064598833257		[learning rate: 0.0083242]
	Learning Rate: 0.00832419
	LOSS [training: 0.1709064598833257 | validation: 0.33227345291121557]
	TIME [epoch: 11 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18580464758235216		[learning rate: 0.008298]
	Learning Rate: 0.00829802
	LOSS [training: 0.18580464758235216 | validation: 0.34888511382022475]
	TIME [epoch: 10.9 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18143205916365274		[learning rate: 0.0082719]
	Learning Rate: 0.00827193
	LOSS [training: 0.18143205916365274 | validation: 0.3644914798744777]
	TIME [epoch: 10.9 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1925452725729		[learning rate: 0.0082459]
	Learning Rate: 0.00824592
	LOSS [training: 0.1925452725729 | validation: 0.3590687899430213]
	TIME [epoch: 10.9 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18107824625751015		[learning rate: 0.00822]
	Learning Rate: 0.00822
	LOSS [training: 0.18107824625751015 | validation: 0.4185198741783105]
	TIME [epoch: 11 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18207622936878262		[learning rate: 0.0081942]
	Learning Rate: 0.00819416
	LOSS [training: 0.18207622936878262 | validation: 0.32239114263394575]
	TIME [epoch: 10.9 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17081640127133718		[learning rate: 0.0081684]
	Learning Rate: 0.00816839
	LOSS [training: 0.17081640127133718 | validation: 0.42413483659264695]
	TIME [epoch: 10.9 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27260252378051564		[learning rate: 0.0081427]
	Learning Rate: 0.00814271
	LOSS [training: 0.27260252378051564 | validation: 0.3797698859066652]
	TIME [epoch: 10.9 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2493514894510687		[learning rate: 0.0081171]
	Learning Rate: 0.00811712
	LOSS [training: 0.2493514894510687 | validation: 0.38061952018278866]
	TIME [epoch: 11 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20266733692011576		[learning rate: 0.0080916]
	Learning Rate: 0.0080916
	LOSS [training: 0.20266733692011576 | validation: 0.4747163920835086]
	TIME [epoch: 10.9 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1939407844955538		[learning rate: 0.0080662]
	Learning Rate: 0.00806616
	LOSS [training: 0.1939407844955538 | validation: 0.3786935612826905]
	TIME [epoch: 10.9 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2089013310129776		[learning rate: 0.0080408]
	Learning Rate: 0.0080408
	LOSS [training: 0.2089013310129776 | validation: 0.3384601195590415]
	TIME [epoch: 10.9 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1851662097265059		[learning rate: 0.0080155]
	Learning Rate: 0.00801552
	LOSS [training: 0.1851662097265059 | validation: 0.35199031703913636]
	TIME [epoch: 10.9 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17346187724370382		[learning rate: 0.0079903]
	Learning Rate: 0.00799032
	LOSS [training: 0.17346187724370382 | validation: 0.3111811160477682]
	TIME [epoch: 10.9 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17341597813197523		[learning rate: 0.0079652]
	Learning Rate: 0.0079652
	LOSS [training: 0.17341597813197523 | validation: 0.35367286742158893]
	TIME [epoch: 10.9 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18483416355912913		[learning rate: 0.0079402]
	Learning Rate: 0.00794016
	LOSS [training: 0.18483416355912913 | validation: 0.41519945620712495]
	TIME [epoch: 10.9 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16477588097256202		[learning rate: 0.0079152]
	Learning Rate: 0.00791519
	LOSS [training: 0.16477588097256202 | validation: 0.32320662841236986]
	TIME [epoch: 10.9 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21378433031205646		[learning rate: 0.0078903]
	Learning Rate: 0.00789031
	LOSS [training: 0.21378433031205646 | validation: 0.3116118285448583]
	TIME [epoch: 10.9 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17487312370172797		[learning rate: 0.0078655]
	Learning Rate: 0.0078655
	LOSS [training: 0.17487312370172797 | validation: 0.34145565289539664]
	TIME [epoch: 10.9 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1802438805508314		[learning rate: 0.0078408]
	Learning Rate: 0.00784077
	LOSS [training: 0.1802438805508314 | validation: 0.33053114455221977]
	TIME [epoch: 11 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19198466059769664		[learning rate: 0.0078161]
	Learning Rate: 0.00781612
	LOSS [training: 0.19198466059769664 | validation: 0.5373921373547985]
	TIME [epoch: 10.9 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22249756697364073		[learning rate: 0.0077916]
	Learning Rate: 0.00779155
	LOSS [training: 0.22249756697364073 | validation: 0.389867469265064]
	TIME [epoch: 10.9 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19098053514931415		[learning rate: 0.0077671]
	Learning Rate: 0.00776706
	LOSS [training: 0.19098053514931415 | validation: 0.41995363083616494]
	TIME [epoch: 10.9 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18909086738461536		[learning rate: 0.0077426]
	Learning Rate: 0.00774264
	LOSS [training: 0.18909086738461536 | validation: 0.3515644445329448]
	TIME [epoch: 11 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19908223519155338		[learning rate: 0.0077183]
	Learning Rate: 0.00771829
	LOSS [training: 0.19908223519155338 | validation: 0.3918653841848838]
	TIME [epoch: 10.9 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18194206620797027		[learning rate: 0.007694]
	Learning Rate: 0.00769403
	LOSS [training: 0.18194206620797027 | validation: 0.3301580261976381]
	TIME [epoch: 10.9 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1904451479711637		[learning rate: 0.0076698]
	Learning Rate: 0.00766984
	LOSS [training: 0.1904451479711637 | validation: 0.3386875733878467]
	TIME [epoch: 10.9 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19913121021271749		[learning rate: 0.0076457]
	Learning Rate: 0.00764573
	LOSS [training: 0.19913121021271749 | validation: 0.3266309044349232]
	TIME [epoch: 11 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14574996278249436		[learning rate: 0.0076217]
	Learning Rate: 0.00762169
	LOSS [training: 0.14574996278249436 | validation: 0.4384725121594669]
	TIME [epoch: 10.9 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16886850285195096		[learning rate: 0.0075977]
	Learning Rate: 0.00759773
	LOSS [training: 0.16886850285195096 | validation: 0.38171926707304454]
	TIME [epoch: 10.9 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21275073115976703		[learning rate: 0.0075738]
	Learning Rate: 0.00757384
	LOSS [training: 0.21275073115976703 | validation: 0.3411886487758753]
	TIME [epoch: 10.9 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16992825105266257		[learning rate: 0.00755]
	Learning Rate: 0.00755003
	LOSS [training: 0.16992825105266257 | validation: 0.3198873620585162]
	TIME [epoch: 11 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15783222503038924		[learning rate: 0.0075263]
	Learning Rate: 0.00752629
	LOSS [training: 0.15783222503038924 | validation: 0.3217738591126251]
	TIME [epoch: 10.9 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16789619598515648		[learning rate: 0.0075026]
	Learning Rate: 0.00750263
	LOSS [training: 0.16789619598515648 | validation: 0.35329928336243754]
	TIME [epoch: 10.9 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1577271939978704		[learning rate: 0.007479]
	Learning Rate: 0.00747904
	LOSS [training: 0.1577271939978704 | validation: 0.37063047172090174]
	TIME [epoch: 10.9 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19441453905014866		[learning rate: 0.0074555]
	Learning Rate: 0.00745553
	LOSS [training: 0.19441453905014866 | validation: 0.3078844334810648]
	TIME [epoch: 11 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15861775245144705		[learning rate: 0.0074321]
	Learning Rate: 0.00743209
	LOSS [training: 0.15861775245144705 | validation: 0.35351701282264747]
	TIME [epoch: 10.9 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17852475861259473		[learning rate: 0.0074087]
	Learning Rate: 0.00740873
	LOSS [training: 0.17852475861259473 | validation: 0.4041248353361957]
	TIME [epoch: 10.9 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17290908811603406		[learning rate: 0.0073854]
	Learning Rate: 0.00738544
	LOSS [training: 0.17290908811603406 | validation: 0.42719952908190617]
	TIME [epoch: 10.9 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21308450704019838		[learning rate: 0.0073622]
	Learning Rate: 0.00736222
	LOSS [training: 0.21308450704019838 | validation: 0.3985266338828106]
	TIME [epoch: 11 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16434533454658773		[learning rate: 0.0073391]
	Learning Rate: 0.00733907
	LOSS [training: 0.16434533454658773 | validation: 0.3359365409746045]
	TIME [epoch: 10.9 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1739743728617769		[learning rate: 0.007316]
	Learning Rate: 0.007316
	LOSS [training: 0.1739743728617769 | validation: 0.3512337635035523]
	TIME [epoch: 10.9 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17222295513988187		[learning rate: 0.007293]
	Learning Rate: 0.007293
	LOSS [training: 0.17222295513988187 | validation: 0.33635078978364746]
	TIME [epoch: 10.9 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1614081537169056		[learning rate: 0.0072701]
	Learning Rate: 0.00727007
	LOSS [training: 0.1614081537169056 | validation: 0.38753187583965193]
	TIME [epoch: 11 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16998005874759872		[learning rate: 0.0072472]
	Learning Rate: 0.00724721
	LOSS [training: 0.16998005874759872 | validation: 0.6459258686041613]
	TIME [epoch: 10.9 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2014641932946499		[learning rate: 0.0072244]
	Learning Rate: 0.00722443
	LOSS [training: 0.2014641932946499 | validation: 0.3445883551987151]
	TIME [epoch: 10.9 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1884600804538339		[learning rate: 0.0072017]
	Learning Rate: 0.00720171
	LOSS [training: 0.1884600804538339 | validation: 0.3911400877795722]
	TIME [epoch: 10.9 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18771143614906532		[learning rate: 0.0071791]
	Learning Rate: 0.00717907
	LOSS [training: 0.18771143614906532 | validation: 0.29939556236435777]
	TIME [epoch: 11 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_vlargesamp_20240719_165939/states/model_facs_v4_dec2b_2dpca_vlargesamp_143.pth
	Model improved!!!
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19503795216305417		[learning rate: 0.0071565]
	Learning Rate: 0.0071565
	LOSS [training: 0.19503795216305417 | validation: 0.37634849295663647]
	TIME [epoch: 10.9 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17496729347118		[learning rate: 0.007134]
	Learning Rate: 0.007134
	LOSS [training: 0.17496729347118 | validation: 0.3857854292595932]
	TIME [epoch: 10.9 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17138504182983344		[learning rate: 0.0071116]
	Learning Rate: 0.00711157
	LOSS [training: 0.17138504182983344 | validation: 0.39927698875134704]
	TIME [epoch: 10.9 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14288919098857902		[learning rate: 0.0070892]
	Learning Rate: 0.00708922
	LOSS [training: 0.14288919098857902 | validation: 0.3593191442602884]
	TIME [epoch: 11 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14276008479424376		[learning rate: 0.0070669]
	Learning Rate: 0.00706693
	LOSS [training: 0.14276008479424376 | validation: 0.3831092089702857]
	TIME [epoch: 10.9 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14547294513536552		[learning rate: 0.0070447]
	Learning Rate: 0.00704471
	LOSS [training: 0.14547294513536552 | validation: 0.3441354159703239]
	TIME [epoch: 10.9 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1977786939355503		[learning rate: 0.0070226]
	Learning Rate: 0.00702256
	LOSS [training: 0.1977786939355503 | validation: 0.36839548828333035]
	TIME [epoch: 10.9 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20641191400542508		[learning rate: 0.0070005]
	Learning Rate: 0.00700049
	LOSS [training: 0.20641191400542508 | validation: 0.41325149464232547]
	TIME [epoch: 39 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17260348282514396		[learning rate: 0.0069785]
	Learning Rate: 0.00697848
	LOSS [training: 0.17260348282514396 | validation: 0.31697055746209896]
	TIME [epoch: 13.5 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1879417835705734		[learning rate: 0.0069565]
	Learning Rate: 0.00695654
	LOSS [training: 0.1879417835705734 | validation: 0.33283393424830937]
	TIME [epoch: 13.4 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2106022379709296		[learning rate: 0.0069347]
	Learning Rate: 0.00693467
	LOSS [training: 0.2106022379709296 | validation: 0.36081534628375556]
	TIME [epoch: 13.4 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16728842770044186		[learning rate: 0.0069129]
	Learning Rate: 0.00691287
	LOSS [training: 0.16728842770044186 | validation: 0.3637090209574262]
	TIME [epoch: 13.4 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14299835581865417		[learning rate: 0.0068911]
	Learning Rate: 0.00689113
	LOSS [training: 0.14299835581865417 | validation: 0.3916833196480591]
	TIME [epoch: 13.4 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16171041541407136		[learning rate: 0.0068695]
	Learning Rate: 0.00686947
	LOSS [training: 0.16171041541407136 | validation: 0.3255845661251583]
	TIME [epoch: 13.4 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1598512375300093		[learning rate: 0.0068479]
	Learning Rate: 0.00684787
	LOSS [training: 0.1598512375300093 | validation: 0.32579052711665585]
	TIME [epoch: 13.4 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16337299184171608		[learning rate: 0.0068263]
	Learning Rate: 0.00682634
	LOSS [training: 0.16337299184171608 | validation: 0.3158158237045404]
	TIME [epoch: 13.4 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1854544729232555		[learning rate: 0.0068049]
	Learning Rate: 0.00680488
	LOSS [training: 0.1854544729232555 | validation: 0.4210230242393854]
	TIME [epoch: 13.4 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2137470027802649		[learning rate: 0.0067835]
	Learning Rate: 0.00678349
	LOSS [training: 0.2137470027802649 | validation: 0.32263120687806124]
	TIME [epoch: 13.4 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16326320192237143		[learning rate: 0.0067622]
	Learning Rate: 0.00676216
	LOSS [training: 0.16326320192237143 | validation: 0.3788733760107024]
	TIME [epoch: 13.4 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18065650986760254		[learning rate: 0.0067409]
	Learning Rate: 0.0067409
	LOSS [training: 0.18065650986760254 | validation: 0.30690564878791743]
	TIME [epoch: 13.4 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16400463738243604		[learning rate: 0.0067197]
	Learning Rate: 0.00671971
	LOSS [training: 0.16400463738243604 | validation: 0.3556286535383718]
	TIME [epoch: 13.4 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15885999370772177		[learning rate: 0.0066986]
	Learning Rate: 0.00669858
	LOSS [training: 0.15885999370772177 | validation: 0.309917183866884]
	TIME [epoch: 13.4 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14962168261006775		[learning rate: 0.0066775]
	Learning Rate: 0.00667752
	LOSS [training: 0.14962168261006775 | validation: 0.3363333066792992]
	TIME [epoch: 13.4 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16150396291690552		[learning rate: 0.0066565]
	Learning Rate: 0.00665653
	LOSS [training: 0.16150396291690552 | validation: 0.43110843330409737]
	TIME [epoch: 13.4 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24424431294444776		[learning rate: 0.0066356]
	Learning Rate: 0.0066356
	LOSS [training: 0.24424431294444776 | validation: 0.30903489664701556]
	TIME [epoch: 13.4 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15425374163408834		[learning rate: 0.0066147]
	Learning Rate: 0.00661474
	LOSS [training: 0.15425374163408834 | validation: 0.34998811619438347]
	TIME [epoch: 13.4 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16149643006391373		[learning rate: 0.0065939]
	Learning Rate: 0.00659394
	LOSS [training: 0.16149643006391373 | validation: 0.38513038875254835]
	TIME [epoch: 13.4 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15410755285006125		[learning rate: 0.0065732]
	Learning Rate: 0.00657321
	LOSS [training: 0.15410755285006125 | validation: 0.44076204374100364]
	TIME [epoch: 13.4 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.156395958541732		[learning rate: 0.0065525]
	Learning Rate: 0.00655255
	LOSS [training: 0.156395958541732 | validation: 0.44254887129680676]
	TIME [epoch: 13.4 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19304906048524717		[learning rate: 0.0065319]
	Learning Rate: 0.00653195
	LOSS [training: 0.19304906048524717 | validation: 0.5200809278105551]
	TIME [epoch: 13.4 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20471590731163375		[learning rate: 0.0065114]
	Learning Rate: 0.00651141
	LOSS [training: 0.20471590731163375 | validation: 0.3790339101974747]
	TIME [epoch: 13.4 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16753734567514011		[learning rate: 0.0064909]
	Learning Rate: 0.00649094
	LOSS [training: 0.16753734567514011 | validation: 0.6099814354352632]
	TIME [epoch: 13.4 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19318788575987436		[learning rate: 0.0064705]
	Learning Rate: 0.00647053
	LOSS [training: 0.19318788575987436 | validation: 0.3581589906632088]
	TIME [epoch: 13.4 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16076774400717053		[learning rate: 0.0064502]
	Learning Rate: 0.00645019
	LOSS [training: 0.16076774400717053 | validation: 0.34815574037149943]
	TIME [epoch: 13.4 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1612872151601202		[learning rate: 0.0064299]
	Learning Rate: 0.00642991
	LOSS [training: 0.1612872151601202 | validation: 0.39566696007708435]
	TIME [epoch: 13.4 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1876441722559466		[learning rate: 0.0064097]
	Learning Rate: 0.0064097
	LOSS [training: 0.1876441722559466 | validation: 0.4034139144952561]
	TIME [epoch: 13.4 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1539363928940748		[learning rate: 0.0063895]
	Learning Rate: 0.00638955
	LOSS [training: 0.1539363928940748 | validation: 0.33244075323273325]
	TIME [epoch: 13.4 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1739057400892186		[learning rate: 0.0063695]
	Learning Rate: 0.00636946
	LOSS [training: 0.1739057400892186 | validation: 0.4725428253156053]
	TIME [epoch: 13.4 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17271726757867362		[learning rate: 0.0063494]
	Learning Rate: 0.00634943
	LOSS [training: 0.17271726757867362 | validation: 0.32891315832286844]
	TIME [epoch: 13.4 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1478168678547936		[learning rate: 0.0063295]
	Learning Rate: 0.00632947
	LOSS [training: 0.1478168678547936 | validation: 0.3425845512288922]
	TIME [epoch: 13.4 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14817238841665542		[learning rate: 0.0063096]
	Learning Rate: 0.00630957
	LOSS [training: 0.14817238841665542 | validation: 0.3820975020277252]
	TIME [epoch: 13.4 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18060136370046231		[learning rate: 0.0062897]
	Learning Rate: 0.00628974
	LOSS [training: 0.18060136370046231 | validation: 0.3674260047481216]
	TIME [epoch: 13.4 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19640926468417752		[learning rate: 0.00627]
	Learning Rate: 0.00626996
	LOSS [training: 0.19640926468417752 | validation: 0.3455568738289778]
	TIME [epoch: 13.4 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17151534929621753		[learning rate: 0.0062503]
	Learning Rate: 0.00625025
	LOSS [training: 0.17151534929621753 | validation: 0.33009360181857694]
	TIME [epoch: 13.4 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17724837113042585		[learning rate: 0.0062306]
	Learning Rate: 0.0062306
	LOSS [training: 0.17724837113042585 | validation: 0.296068175314667]
	TIME [epoch: 13.4 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_vlargesamp_20240719_165939/states/model_facs_v4_dec2b_2dpca_vlargesamp_188.pth
	Model improved!!!
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16601515519487317		[learning rate: 0.006211]
	Learning Rate: 0.00621101
	LOSS [training: 0.16601515519487317 | validation: 0.30612335440131133]
	TIME [epoch: 13.4 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19299967111596755		[learning rate: 0.0061915]
	Learning Rate: 0.00619149
	LOSS [training: 0.19299967111596755 | validation: 0.3644561427187304]
	TIME [epoch: 13.4 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15985399348931376		[learning rate: 0.006172]
	Learning Rate: 0.00617202
	LOSS [training: 0.15985399348931376 | validation: 0.3339462302476693]
	TIME [epoch: 13.4 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1468350372910835		[learning rate: 0.0061526]
	Learning Rate: 0.00615262
	LOSS [training: 0.1468350372910835 | validation: 0.3678799243085059]
	TIME [epoch: 13.4 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14396777482279263		[learning rate: 0.0061333]
	Learning Rate: 0.00613327
	LOSS [training: 0.14396777482279263 | validation: 0.3563350286447151]
	TIME [epoch: 13.4 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16565623204132524		[learning rate: 0.006114]
	Learning Rate: 0.00611399
	LOSS [training: 0.16565623204132524 | validation: 0.3264286409762485]
	TIME [epoch: 13.4 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1433699089078753		[learning rate: 0.0060948]
	Learning Rate: 0.00609477
	LOSS [training: 0.1433699089078753 | validation: 0.3490395857540975]
	TIME [epoch: 13.4 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15551968474285763		[learning rate: 0.0060756]
	Learning Rate: 0.00607561
	LOSS [training: 0.15551968474285763 | validation: 0.3776402432050873]
	TIME [epoch: 13.4 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16056326738171814		[learning rate: 0.0060565]
	Learning Rate: 0.00605651
	LOSS [training: 0.16056326738171814 | validation: 0.31698741856644147]
	TIME [epoch: 13.4 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1428404519845748		[learning rate: 0.0060375]
	Learning Rate: 0.00603747
	LOSS [training: 0.1428404519845748 | validation: 0.384841039562649]
	TIME [epoch: 13.4 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14975810288158664		[learning rate: 0.0060185]
	Learning Rate: 0.00601848
	LOSS [training: 0.14975810288158664 | validation: 0.364771555587757]
	TIME [epoch: 13.4 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14802592345402213		[learning rate: 0.0059996]
	Learning Rate: 0.00599956
	LOSS [training: 0.14802592345402213 | validation: 0.4029549955761579]
	TIME [epoch: 13.4 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17854367544774752		[learning rate: 0.0059807]
	Learning Rate: 0.0059807
	LOSS [training: 0.17854367544774752 | validation: 0.32462440648413615]
	TIME [epoch: 13.4 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1588339127350016		[learning rate: 0.0059619]
	Learning Rate: 0.0059619
	LOSS [training: 0.1588339127350016 | validation: 0.3581504036012263]
	TIME [epoch: 13.4 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16168348268947508		[learning rate: 0.0059432]
	Learning Rate: 0.00594316
	LOSS [training: 0.16168348268947508 | validation: 0.31822980218824015]
	TIME [epoch: 13.4 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15583765828774643		[learning rate: 0.0059245]
	Learning Rate: 0.00592447
	LOSS [training: 0.15583765828774643 | validation: 0.3900924588128152]
	TIME [epoch: 13.4 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15372748555162954		[learning rate: 0.0059058]
	Learning Rate: 0.00590584
	LOSS [training: 0.15372748555162954 | validation: 0.34136255695405204]
	TIME [epoch: 13.4 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12739540519462403		[learning rate: 0.0058873]
	Learning Rate: 0.00588728
	LOSS [training: 0.12739540519462403 | validation: 0.37187688014532644]
	TIME [epoch: 13.4 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14743414802348015		[learning rate: 0.0058688]
	Learning Rate: 0.00586877
	LOSS [training: 0.14743414802348015 | validation: 0.43115409875158095]
	TIME [epoch: 13.4 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15245059013835607		[learning rate: 0.0058503]
	Learning Rate: 0.00585032
	LOSS [training: 0.15245059013835607 | validation: 0.3171395786804255]
	TIME [epoch: 13.4 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16798825024294523		[learning rate: 0.0058319]
	Learning Rate: 0.00583193
	LOSS [training: 0.16798825024294523 | validation: 0.4748800403621578]
	TIME [epoch: 13.4 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18110191468173387		[learning rate: 0.0058136]
	Learning Rate: 0.00581359
	LOSS [training: 0.18110191468173387 | validation: 0.304760544015807]
	TIME [epoch: 13.4 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13702615508370644		[learning rate: 0.0057953]
	Learning Rate: 0.00579531
	LOSS [training: 0.13702615508370644 | validation: 0.3374153683065537]
	TIME [epoch: 13.4 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14623935230639554		[learning rate: 0.0057771]
	Learning Rate: 0.00577709
	LOSS [training: 0.14623935230639554 | validation: 0.34071943490470774]
	TIME [epoch: 13.4 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18458636898320124		[learning rate: 0.0057589]
	Learning Rate: 0.00575893
	LOSS [training: 0.18458636898320124 | validation: 0.3541022632185991]
	TIME [epoch: 13.4 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18552000110010364		[learning rate: 0.0057408]
	Learning Rate: 0.00574083
	LOSS [training: 0.18552000110010364 | validation: 0.32784293017638033]
	TIME [epoch: 13.4 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18465381673277786		[learning rate: 0.0057228]
	Learning Rate: 0.00572278
	LOSS [training: 0.18465381673277786 | validation: 0.3656996247187852]
	TIME [epoch: 13.4 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.152429447192021		[learning rate: 0.0057048]
	Learning Rate: 0.00570478
	LOSS [training: 0.152429447192021 | validation: 0.31869862366039203]
	TIME [epoch: 13.4 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1397713086313826		[learning rate: 0.0056868]
	Learning Rate: 0.00568685
	LOSS [training: 0.1397713086313826 | validation: 0.31752602064564645]
	TIME [epoch: 13.4 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13727272792458325		[learning rate: 0.005669]
	Learning Rate: 0.00566897
	LOSS [training: 0.13727272792458325 | validation: 0.3368575319748913]
	TIME [epoch: 13.4 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14539236070789244		[learning rate: 0.0056511]
	Learning Rate: 0.00565115
	LOSS [training: 0.14539236070789244 | validation: 0.30976259662646244]
	TIME [epoch: 13.4 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14370737370334252		[learning rate: 0.0056334]
	Learning Rate: 0.00563338
	LOSS [training: 0.14370737370334252 | validation: 0.31384149263324523]
	TIME [epoch: 13.4 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1486020091143068		[learning rate: 0.0056157]
	Learning Rate: 0.00561567
	LOSS [training: 0.1486020091143068 | validation: 0.3468117106093615]
	TIME [epoch: 13.4 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20093605309445808		[learning rate: 0.005598]
	Learning Rate: 0.00559802
	LOSS [training: 0.20093605309445808 | validation: 0.36724227375059915]
	TIME [epoch: 13.4 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1624119254799617		[learning rate: 0.0055804]
	Learning Rate: 0.00558042
	LOSS [training: 0.1624119254799617 | validation: 0.363738823106435]
	TIME [epoch: 13.4 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14787091766820204		[learning rate: 0.0055629]
	Learning Rate: 0.00556287
	LOSS [training: 0.14787091766820204 | validation: 0.38424119421593506]
	TIME [epoch: 13.4 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15200821281405275		[learning rate: 0.0055454]
	Learning Rate: 0.00554538
	LOSS [training: 0.15200821281405275 | validation: 0.307963888512509]
	TIME [epoch: 13.4 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14454793180434514		[learning rate: 0.0055279]
	Learning Rate: 0.00552795
	LOSS [training: 0.14454793180434514 | validation: 0.34719949676919726]
	TIME [epoch: 13.4 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13459841249403895		[learning rate: 0.0055106]
	Learning Rate: 0.00551057
	LOSS [training: 0.13459841249403895 | validation: 0.2889169287092613]
	TIME [epoch: 13.4 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_vlargesamp_20240719_165939/states/model_facs_v4_dec2b_2dpca_vlargesamp_227.pth
	Model improved!!!
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14752822041827648		[learning rate: 0.0054932]
	Learning Rate: 0.00549325
	LOSS [training: 0.14752822041827648 | validation: 0.37208641163944683]
	TIME [epoch: 13.4 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1644634433745633		[learning rate: 0.005476]
	Learning Rate: 0.00547598
	LOSS [training: 0.1644634433745633 | validation: 0.3637437497811322]
	TIME [epoch: 13.4 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15581394473690235		[learning rate: 0.0054588]
	Learning Rate: 0.00545876
	LOSS [training: 0.15581394473690235 | validation: 0.3769260144892421]
	TIME [epoch: 13.4 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14407499106012914		[learning rate: 0.0054416]
	Learning Rate: 0.0054416
	LOSS [training: 0.14407499106012914 | validation: 0.32226185695516946]
	TIME [epoch: 13.4 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1272636877538976		[learning rate: 0.0054245]
	Learning Rate: 0.00542449
	LOSS [training: 0.1272636877538976 | validation: 0.30395457756334654]
	TIME [epoch: 13.4 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1302332298383876		[learning rate: 0.0054074]
	Learning Rate: 0.00540744
	LOSS [training: 0.1302332298383876 | validation: 0.33792877200630134]
	TIME [epoch: 13.4 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13039151832209323		[learning rate: 0.0053904]
	Learning Rate: 0.00539044
	LOSS [training: 0.13039151832209323 | validation: 0.3621064952146825]
	TIME [epoch: 13.4 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.147778016349366		[learning rate: 0.0053735]
	Learning Rate: 0.00537349
	LOSS [training: 0.147778016349366 | validation: 0.3358231173424793]
	TIME [epoch: 13.4 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13190127070344881		[learning rate: 0.0053566]
	Learning Rate: 0.0053566
	LOSS [training: 0.13190127070344881 | validation: 0.32828775779892483]
	TIME [epoch: 13.4 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16694492524874757		[learning rate: 0.0053398]
	Learning Rate: 0.00533975
	LOSS [training: 0.16694492524874757 | validation: 0.3375797848827553]
	TIME [epoch: 13.4 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12882922897680807		[learning rate: 0.005323]
	Learning Rate: 0.00532297
	LOSS [training: 0.12882922897680807 | validation: 0.3615986799557826]
	TIME [epoch: 13.4 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14451687324576518		[learning rate: 0.0053062]
	Learning Rate: 0.00530623
	LOSS [training: 0.14451687324576518 | validation: 0.36159651784699975]
	TIME [epoch: 13.4 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14464185275395858		[learning rate: 0.0052896]
	Learning Rate: 0.00528955
	LOSS [training: 0.14464185275395858 | validation: 0.36135769936472517]
	TIME [epoch: 13.4 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14747159125855722		[learning rate: 0.0052729]
	Learning Rate: 0.00527292
	LOSS [training: 0.14747159125855722 | validation: 0.3144937865463832]
	TIME [epoch: 13.4 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11824706063738956		[learning rate: 0.0052563]
	Learning Rate: 0.00525634
	LOSS [training: 0.11824706063738956 | validation: 0.35278624519690555]
	TIME [epoch: 13.4 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15997007586865475		[learning rate: 0.0052398]
	Learning Rate: 0.00523982
	LOSS [training: 0.15997007586865475 | validation: 0.35296003751998206]
	TIME [epoch: 13.4 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13071936824287356		[learning rate: 0.0052233]
	Learning Rate: 0.00522335
	LOSS [training: 0.13071936824287356 | validation: 0.3247002528232592]
	TIME [epoch: 13.4 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14448239321291828		[learning rate: 0.0052069]
	Learning Rate: 0.00520692
	LOSS [training: 0.14448239321291828 | validation: 0.3049305210767129]
	TIME [epoch: 13.4 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14282479294369554		[learning rate: 0.0051906]
	Learning Rate: 0.00519055
	LOSS [training: 0.14282479294369554 | validation: 0.2875639222693724]
	TIME [epoch: 13.4 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_vlargesamp_20240719_165939/states/model_facs_v4_dec2b_2dpca_vlargesamp_246.pth
	Model improved!!!
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14775292215723998		[learning rate: 0.0051742]
	Learning Rate: 0.00517423
	LOSS [training: 0.14775292215723998 | validation: 0.3887828015600676]
	TIME [epoch: 13.4 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13762291621447897		[learning rate: 0.005158]
	Learning Rate: 0.00515797
	LOSS [training: 0.13762291621447897 | validation: 0.3237283155809214]
	TIME [epoch: 13.4 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15484887068710826		[learning rate: 0.0051418]
	Learning Rate: 0.00514175
	LOSS [training: 0.15484887068710826 | validation: 0.3743569369155336]
	TIME [epoch: 13.4 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14267054806759505		[learning rate: 0.0051256]
	Learning Rate: 0.00512559
	LOSS [training: 0.14267054806759505 | validation: 0.3127960023617425]
	TIME [epoch: 13.4 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13548128126100373		[learning rate: 0.0051095]
	Learning Rate: 0.00510947
	LOSS [training: 0.13548128126100373 | validation: 0.3640205420341527]
	TIME [epoch: 42.3 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13842120698532487		[learning rate: 0.0050934]
	Learning Rate: 0.00509341
	LOSS [training: 0.13842120698532487 | validation: 0.34656374199244916]
	TIME [epoch: 16.6 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13353394413371394		[learning rate: 0.0050774]
	Learning Rate: 0.0050774
	LOSS [training: 0.13353394413371394 | validation: 0.332649058879439]
	TIME [epoch: 16.6 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14830792589070635		[learning rate: 0.0050614]
	Learning Rate: 0.00506143
	LOSS [training: 0.14830792589070635 | validation: 0.3398641411669107]
	TIME [epoch: 16.6 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14227605243473018		[learning rate: 0.0050455]
	Learning Rate: 0.00504552
	LOSS [training: 0.14227605243473018 | validation: 0.32122030390818396]
	TIME [epoch: 16.6 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13010736170020093		[learning rate: 0.0050297]
	Learning Rate: 0.00502966
	LOSS [training: 0.13010736170020093 | validation: 0.3504775228947205]
	TIME [epoch: 16.6 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12696850303385		[learning rate: 0.0050138]
	Learning Rate: 0.00501385
	LOSS [training: 0.12696850303385 | validation: 0.3464898726669327]
	TIME [epoch: 16.6 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13170657762554194		[learning rate: 0.0049981]
	Learning Rate: 0.00499808
	LOSS [training: 0.13170657762554194 | validation: 0.4920988830611097]
	TIME [epoch: 16.6 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15572653709730283		[learning rate: 0.0049824]
	Learning Rate: 0.00498237
	LOSS [training: 0.15572653709730283 | validation: 0.3498484403591815]
	TIME [epoch: 16.6 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13191170571536473		[learning rate: 0.0049667]
	Learning Rate: 0.0049667
	LOSS [training: 0.13191170571536473 | validation: 0.3806793382917047]
	TIME [epoch: 16.6 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1316326424809878		[learning rate: 0.0049511]
	Learning Rate: 0.00495109
	LOSS [training: 0.1316326424809878 | validation: 0.31447508568980703]
	TIME [epoch: 16.6 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14328216081098222		[learning rate: 0.0049355]
	Learning Rate: 0.00493552
	LOSS [training: 0.14328216081098222 | validation: 0.37733651229333565]
	TIME [epoch: 16.6 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15125764004747574		[learning rate: 0.00492]
	Learning Rate: 0.00492001
	LOSS [training: 0.15125764004747574 | validation: 0.3086261613046662]
	TIME [epoch: 16.6 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1299297405181431		[learning rate: 0.0049045]
	Learning Rate: 0.00490454
	LOSS [training: 0.1299297405181431 | validation: 0.29721413925423534]
	TIME [epoch: 16.6 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12880536027362965		[learning rate: 0.0048891]
	Learning Rate: 0.00488912
	LOSS [training: 0.12880536027362965 | validation: 0.3286648237327]
	TIME [epoch: 16.6 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12704893213068336		[learning rate: 0.0048737]
	Learning Rate: 0.00487375
	LOSS [training: 0.12704893213068336 | validation: 0.3071830873096475]
	TIME [epoch: 16.6 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12882788898218922		[learning rate: 0.0048584]
	Learning Rate: 0.00485843
	LOSS [training: 0.12882788898218922 | validation: 0.31670846404681285]
	TIME [epoch: 16.6 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13045705261980786		[learning rate: 0.0048432]
	Learning Rate: 0.00484315
	LOSS [training: 0.13045705261980786 | validation: 0.31758832808476234]
	TIME [epoch: 16.6 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14344674740389207		[learning rate: 0.0048279]
	Learning Rate: 0.00482793
	LOSS [training: 0.14344674740389207 | validation: 0.3278428979214085]
	TIME [epoch: 16.6 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14013515945046817		[learning rate: 0.0048127]
	Learning Rate: 0.00481275
	LOSS [training: 0.14013515945046817 | validation: 0.3678747829868093]
	TIME [epoch: 16.6 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14653395632521118		[learning rate: 0.0047976]
	Learning Rate: 0.00479762
	LOSS [training: 0.14653395632521118 | validation: 0.32316538913849435]
	TIME [epoch: 16.6 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12919372709377616		[learning rate: 0.0047825]
	Learning Rate: 0.00478253
	LOSS [training: 0.12919372709377616 | validation: 0.2981245270962033]
	TIME [epoch: 16.6 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13575071994037574		[learning rate: 0.0047675]
	Learning Rate: 0.0047675
	LOSS [training: 0.13575071994037574 | validation: 0.3135953638071913]
	TIME [epoch: 16.6 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14171748259776015		[learning rate: 0.0047525]
	Learning Rate: 0.00475251
	LOSS [training: 0.14171748259776015 | validation: 0.3980403869509715]
	TIME [epoch: 16.6 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15575794767385112		[learning rate: 0.0047376]
	Learning Rate: 0.00473757
	LOSS [training: 0.15575794767385112 | validation: 0.32730930330705393]
	TIME [epoch: 16.6 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12939661447227707		[learning rate: 0.0047227]
	Learning Rate: 0.00472267
	LOSS [training: 0.12939661447227707 | validation: 0.33715062934507084]
	TIME [epoch: 16.6 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1295186260620993		[learning rate: 0.0047078]
	Learning Rate: 0.00470783
	LOSS [training: 0.1295186260620993 | validation: 0.33259609068493856]
	TIME [epoch: 16.6 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1394955774229913		[learning rate: 0.004693]
	Learning Rate: 0.00469303
	LOSS [training: 0.1394955774229913 | validation: 0.36896611590794326]
	TIME [epoch: 16.6 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1323482664309373		[learning rate: 0.0046783]
	Learning Rate: 0.00467827
	LOSS [training: 0.1323482664309373 | validation: 0.3666532606692386]
	TIME [epoch: 16.6 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11750440781814928		[learning rate: 0.0046636]
	Learning Rate: 0.00466356
	LOSS [training: 0.11750440781814928 | validation: 0.3146859234086783]
	TIME [epoch: 16.6 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14017639151585864		[learning rate: 0.0046489]
	Learning Rate: 0.0046489
	LOSS [training: 0.14017639151585864 | validation: 0.3073027672402877]
	TIME [epoch: 16.6 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13945630315316854		[learning rate: 0.0046343]
	Learning Rate: 0.00463429
	LOSS [training: 0.13945630315316854 | validation: 0.3497480383473127]
	TIME [epoch: 16.6 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13022253144213358		[learning rate: 0.0046197]
	Learning Rate: 0.00461972
	LOSS [training: 0.13022253144213358 | validation: 0.2994635219045734]
	TIME [epoch: 16.6 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13231979338599664		[learning rate: 0.0046052]
	Learning Rate: 0.00460519
	LOSS [training: 0.13231979338599664 | validation: 0.3166522423095304]
	TIME [epoch: 16.6 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12330477041710868		[learning rate: 0.0045907]
	Learning Rate: 0.00459072
	LOSS [training: 0.12330477041710868 | validation: 0.33340394955220787]
	TIME [epoch: 16.6 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14070068013059778		[learning rate: 0.0045763]
	Learning Rate: 0.00457628
	LOSS [training: 0.14070068013059778 | validation: 0.310555478410498]
	TIME [epoch: 16.6 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1320060699564817		[learning rate: 0.0045619]
	Learning Rate: 0.0045619
	LOSS [training: 0.1320060699564817 | validation: 0.2942075823880918]
	TIME [epoch: 16.6 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1320595217915798		[learning rate: 0.0045476]
	Learning Rate: 0.00454755
	LOSS [training: 0.1320595217915798 | validation: 0.381423039292431]
	TIME [epoch: 16.6 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1317201523544448		[learning rate: 0.0045333]
	Learning Rate: 0.00453326
	LOSS [training: 0.1317201523544448 | validation: 0.33061315432171096]
	TIME [epoch: 16.6 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13025772416772058		[learning rate: 0.004519]
	Learning Rate: 0.004519
	LOSS [training: 0.13025772416772058 | validation: 0.32403477236924294]
	TIME [epoch: 16.6 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1520994466227258		[learning rate: 0.0045048]
	Learning Rate: 0.0045048
	LOSS [training: 0.1520994466227258 | validation: 0.4540940069757458]
	TIME [epoch: 16.6 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14421224403472357		[learning rate: 0.0044906]
	Learning Rate: 0.00449063
	LOSS [training: 0.14421224403472357 | validation: 0.3523289411036652]
	TIME [epoch: 16.6 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.140165987263201		[learning rate: 0.0044765]
	Learning Rate: 0.00447652
	LOSS [training: 0.140165987263201 | validation: 0.31139038402668184]
	TIME [epoch: 16.6 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14032790990408195		[learning rate: 0.0044624]
	Learning Rate: 0.00446244
	LOSS [training: 0.14032790990408195 | validation: 0.31261301858535]
	TIME [epoch: 16.6 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12238917973653272		[learning rate: 0.0044484]
	Learning Rate: 0.00444841
	LOSS [training: 0.12238917973653272 | validation: 0.37883697345265854]
	TIME [epoch: 16.6 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14278651527372016		[learning rate: 0.0044344]
	Learning Rate: 0.00443443
	LOSS [training: 0.14278651527372016 | validation: 0.3172067377277611]
	TIME [epoch: 16.6 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12986671747745995		[learning rate: 0.0044205]
	Learning Rate: 0.00442049
	LOSS [training: 0.12986671747745995 | validation: 0.312401290602751]
	TIME [epoch: 16.6 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13796760311657008		[learning rate: 0.0044066]
	Learning Rate: 0.00440659
	LOSS [training: 0.13796760311657008 | validation: 0.3420014942636329]
	TIME [epoch: 16.6 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15198778462422458		[learning rate: 0.0043927]
	Learning Rate: 0.00439274
	LOSS [training: 0.15198778462422458 | validation: 0.2937755264416617]
	TIME [epoch: 16.6 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13375310666366685		[learning rate: 0.0043789]
	Learning Rate: 0.00437893
	LOSS [training: 0.13375310666366685 | validation: 0.3139089500143996]
	TIME [epoch: 16.6 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14880385650630665		[learning rate: 0.0043652]
	Learning Rate: 0.00436516
	LOSS [training: 0.14880385650630665 | validation: 0.4319217056122002]
	TIME [epoch: 16.5 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14099652854507508		[learning rate: 0.0043514]
	Learning Rate: 0.00435143
	LOSS [training: 0.14099652854507508 | validation: 0.33443246977813784]
	TIME [epoch: 16.6 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13147476478936454		[learning rate: 0.0043378]
	Learning Rate: 0.00433775
	LOSS [training: 0.13147476478936454 | validation: 0.2921199820405471]
	TIME [epoch: 16.5 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12431243400321768		[learning rate: 0.0043241]
	Learning Rate: 0.00432412
	LOSS [training: 0.12431243400321768 | validation: 0.2967760959259109]
	TIME [epoch: 16.6 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12490522577876326		[learning rate: 0.0043105]
	Learning Rate: 0.00431052
	LOSS [training: 0.12490522577876326 | validation: 0.36121635567543064]
	TIME [epoch: 16.5 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11850762679607965		[learning rate: 0.004297]
	Learning Rate: 0.00429697
	LOSS [training: 0.11850762679607965 | validation: 0.2862917957033115]
	TIME [epoch: 16.5 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_vlargesamp_20240719_165939/states/model_facs_v4_dec2b_2dpca_vlargesamp_306.pth
	Model improved!!!
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12206228888088089		[learning rate: 0.0042835]
	Learning Rate: 0.00428346
	LOSS [training: 0.12206228888088089 | validation: 0.29697799178390605]
	TIME [epoch: 16.6 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12620670299022574		[learning rate: 0.00427]
	Learning Rate: 0.00426999
	LOSS [training: 0.12620670299022574 | validation: 0.33050663505637323]
	TIME [epoch: 16.5 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1393470172515386		[learning rate: 0.0042566]
	Learning Rate: 0.00425657
	LOSS [training: 0.1393470172515386 | validation: 0.39401982089771703]
	TIME [epoch: 16.5 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.132716385831896		[learning rate: 0.0042432]
	Learning Rate: 0.00424319
	LOSS [training: 0.132716385831896 | validation: 0.3155407560511503]
	TIME [epoch: 16.6 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13595666945133172		[learning rate: 0.0042298]
	Learning Rate: 0.00422985
	LOSS [training: 0.13595666945133172 | validation: 0.32538535169014093]
	TIME [epoch: 16.5 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12484918454190577		[learning rate: 0.0042165]
	Learning Rate: 0.00421655
	LOSS [training: 0.12484918454190577 | validation: 0.3799949113859139]
	TIME [epoch: 16.6 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14324553350973934		[learning rate: 0.0042033]
	Learning Rate: 0.00420329
	LOSS [training: 0.14324553350973934 | validation: 0.38391678532930884]
	TIME [epoch: 16.6 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1357510516987468		[learning rate: 0.0041901]
	Learning Rate: 0.00419008
	LOSS [training: 0.1357510516987468 | validation: 0.3044145673933655]
	TIME [epoch: 16.5 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11788865184292557		[learning rate: 0.0041769]
	Learning Rate: 0.00417691
	LOSS [training: 0.11788865184292557 | validation: 0.3281053766516068]
	TIME [epoch: 16.6 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12568689718590123		[learning rate: 0.0041638]
	Learning Rate: 0.00416377
	LOSS [training: 0.12568689718590123 | validation: 0.34638399292776023]
	TIME [epoch: 16.5 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12399168553158457		[learning rate: 0.0041507]
	Learning Rate: 0.00415068
	LOSS [training: 0.12399168553158457 | validation: 0.34352610660384564]
	TIME [epoch: 16.6 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13058375899313535		[learning rate: 0.0041376]
	Learning Rate: 0.00413763
	LOSS [training: 0.13058375899313535 | validation: 0.3899275259631484]
	TIME [epoch: 16.6 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13492517155537137		[learning rate: 0.0041246]
	Learning Rate: 0.00412463
	LOSS [training: 0.13492517155537137 | validation: 0.3634135421770623]
	TIME [epoch: 16.5 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14698394613385102		[learning rate: 0.0041117]
	Learning Rate: 0.00411166
	LOSS [training: 0.14698394613385102 | validation: 0.33015073754118807]
	TIME [epoch: 16.6 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12086130217603713		[learning rate: 0.0040987]
	Learning Rate: 0.00409873
	LOSS [training: 0.12086130217603713 | validation: 0.3172675714903118]
	TIME [epoch: 16.5 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11883989508278311		[learning rate: 0.0040858]
	Learning Rate: 0.00408585
	LOSS [training: 0.11883989508278311 | validation: 0.39340769042595936]
	TIME [epoch: 16.5 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13289360965692426		[learning rate: 0.004073]
	Learning Rate: 0.004073
	LOSS [training: 0.13289360965692426 | validation: 0.3960608933272147]
	TIME [epoch: 16.6 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12692124315056202		[learning rate: 0.0040602]
	Learning Rate: 0.0040602
	LOSS [training: 0.12692124315056202 | validation: 0.3238675308199216]
	TIME [epoch: 16.5 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1279600118556554		[learning rate: 0.0040474]
	Learning Rate: 0.00404743
	LOSS [training: 0.1279600118556554 | validation: 0.32286168359949585]
	TIME [epoch: 16.6 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1335042370898628		[learning rate: 0.0040347]
	Learning Rate: 0.00403471
	LOSS [training: 0.1335042370898628 | validation: 0.367887517520767]
	TIME [epoch: 16.5 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12813380804050808		[learning rate: 0.004022]
	Learning Rate: 0.00402202
	LOSS [training: 0.12813380804050808 | validation: 0.37569716418301013]
	TIME [epoch: 16.5 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13766103112760517		[learning rate: 0.0040094]
	Learning Rate: 0.00400938
	LOSS [training: 0.13766103112760517 | validation: 0.3517690181915418]
	TIME [epoch: 16.6 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1265770283517967		[learning rate: 0.0039968]
	Learning Rate: 0.00399677
	LOSS [training: 0.1265770283517967 | validation: 0.34776535728122887]
	TIME [epoch: 16.5 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1183437802671062		[learning rate: 0.0039842]
	Learning Rate: 0.00398421
	LOSS [training: 0.1183437802671062 | validation: 0.3851143116533223]
	TIME [epoch: 16.5 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10901541156039993		[learning rate: 0.0039717]
	Learning Rate: 0.00397168
	LOSS [training: 0.10901541156039993 | validation: 0.3605995042700724]
	TIME [epoch: 16.6 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21470427337744802		[learning rate: 0.0039592]
	Learning Rate: 0.00395919
	LOSS [training: 0.21470427337744802 | validation: 0.3372832793649349]
	TIME [epoch: 16.5 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1463312954501003		[learning rate: 0.0039467]
	Learning Rate: 0.00394675
	LOSS [training: 0.1463312954501003 | validation: 0.36214174652437275]
	TIME [epoch: 16.6 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14867188414044355		[learning rate: 0.0039343]
	Learning Rate: 0.00393434
	LOSS [training: 0.14867188414044355 | validation: 0.3465952374586365]
	TIME [epoch: 16.5 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1338635778269054		[learning rate: 0.003922]
	Learning Rate: 0.00392197
	LOSS [training: 0.1338635778269054 | validation: 0.331779304775948]
	TIME [epoch: 16.5 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14856331073380497		[learning rate: 0.0039096]
	Learning Rate: 0.00390964
	LOSS [training: 0.14856331073380497 | validation: 0.4215278716982718]
	TIME [epoch: 16.6 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15863701835680183		[learning rate: 0.0038973]
	Learning Rate: 0.00389735
	LOSS [training: 0.15863701835680183 | validation: 0.3039070387069524]
	TIME [epoch: 16.6 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14340613665850266		[learning rate: 0.0038851]
	Learning Rate: 0.0038851
	LOSS [training: 0.14340613665850266 | validation: 0.3016568971696041]
	TIME [epoch: 16.6 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12880941736434187		[learning rate: 0.0038729]
	Learning Rate: 0.00387288
	LOSS [training: 0.12880941736434187 | validation: 0.30771037692616215]
	TIME [epoch: 16.5 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12063814246734647		[learning rate: 0.0038607]
	Learning Rate: 0.00386071
	LOSS [training: 0.12063814246734647 | validation: 0.3086346929904637]
	TIME [epoch: 16.5 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12404046727862199		[learning rate: 0.0038486]
	Learning Rate: 0.00384857
	LOSS [training: 0.12404046727862199 | validation: 0.30756855591183446]
	TIME [epoch: 16.6 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1299948593476975		[learning rate: 0.0038365]
	Learning Rate: 0.00383647
	LOSS [training: 0.1299948593476975 | validation: 0.3529922686654536]
	TIME [epoch: 16.5 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12013905029069509		[learning rate: 0.0038244]
	Learning Rate: 0.00382441
	LOSS [training: 0.12013905029069509 | validation: 0.30536870311099124]
	TIME [epoch: 16.6 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12681714835413394		[learning rate: 0.0038124]
	Learning Rate: 0.00381238
	LOSS [training: 0.12681714835413394 | validation: 0.3075569868518095]
	TIME [epoch: 16.6 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12261780891652997		[learning rate: 0.0038004]
	Learning Rate: 0.0038004
	LOSS [training: 0.12261780891652997 | validation: 0.29716514051247345]
	TIME [epoch: 16.5 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1268879911883534		[learning rate: 0.0037884]
	Learning Rate: 0.00378845
	LOSS [training: 0.1268879911883534 | validation: 0.3465583140755522]
	TIME [epoch: 16.6 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1305734438450341		[learning rate: 0.0037765]
	Learning Rate: 0.00377654
	LOSS [training: 0.1305734438450341 | validation: 0.31977726807822604]
	TIME [epoch: 16.5 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14500861351384176		[learning rate: 0.0037647]
	Learning Rate: 0.00376467
	LOSS [training: 0.14500861351384176 | validation: 0.36769677240493537]
	TIME [epoch: 16.5 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.157524232010057		[learning rate: 0.0037528]
	Learning Rate: 0.00375283
	LOSS [training: 0.157524232010057 | validation: 0.3020516100600696]
	TIME [epoch: 16.6 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1292061635239777		[learning rate: 0.003741]
	Learning Rate: 0.00374103
	LOSS [training: 0.1292061635239777 | validation: 0.28101124327380783]
	TIME [epoch: 16.6 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_vlargesamp_20240719_165939/states/model_facs_v4_dec2b_2dpca_vlargesamp_350.pth
	Model improved!!!
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1352360638143045		[learning rate: 0.0037293]
	Learning Rate: 0.00372927
	LOSS [training: 0.1352360638143045 | validation: 0.30137975755637986]
	TIME [epoch: 46.4 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11842148015938779		[learning rate: 0.0037175]
	Learning Rate: 0.00371755
	LOSS [training: 0.11842148015938779 | validation: 0.3292976086917288]
	TIME [epoch: 20.5 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12332404437197966		[learning rate: 0.0037059]
	Learning Rate: 0.00370586
	LOSS [training: 0.12332404437197966 | validation: 0.35027773676257845]
	TIME [epoch: 20.4 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1352942129997782		[learning rate: 0.0036942]
	Learning Rate: 0.00369421
	LOSS [training: 0.1352942129997782 | validation: 0.3001618704495843]
	TIME [epoch: 20.4 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1204877216530941		[learning rate: 0.0036826]
	Learning Rate: 0.00368259
	LOSS [training: 0.1204877216530941 | validation: 0.34094136900171823]
	TIME [epoch: 20.5 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1260895869866319		[learning rate: 0.003671]
	Learning Rate: 0.00367102
	LOSS [training: 0.1260895869866319 | validation: 0.31063271875371823]
	TIME [epoch: 20.4 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11379913563964035		[learning rate: 0.0036595]
	Learning Rate: 0.00365948
	LOSS [training: 0.11379913563964035 | validation: 0.33867534893733436]
	TIME [epoch: 20.5 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1283059162067924		[learning rate: 0.003648]
	Learning Rate: 0.00364797
	LOSS [training: 0.1283059162067924 | validation: 0.37382175520526084]
	TIME [epoch: 20.4 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11995644975710615		[learning rate: 0.0036365]
	Learning Rate: 0.0036365
	LOSS [training: 0.11995644975710615 | validation: 0.29887548698842337]
	TIME [epoch: 20.5 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12299695345989134		[learning rate: 0.0036251]
	Learning Rate: 0.00362507
	LOSS [training: 0.12299695345989134 | validation: 0.3375999189008005]
	TIME [epoch: 20.4 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12476880016910916		[learning rate: 0.0036137]
	Learning Rate: 0.00361367
	LOSS [training: 0.12476880016910916 | validation: 0.29019073114402616]
	TIME [epoch: 20.4 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12303000926707287		[learning rate: 0.0036023]
	Learning Rate: 0.00360231
	LOSS [training: 0.12303000926707287 | validation: 0.3153529708804098]
	TIME [epoch: 20.4 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11083253882581674		[learning rate: 0.003591]
	Learning Rate: 0.00359099
	LOSS [training: 0.11083253882581674 | validation: 0.3396151710344724]
	TIME [epoch: 20.4 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1249126062221453		[learning rate: 0.0035797]
	Learning Rate: 0.0035797
	LOSS [training: 0.1249126062221453 | validation: 0.3483806216276434]
	TIME [epoch: 20.5 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12323672911621653		[learning rate: 0.0035684]
	Learning Rate: 0.00356844
	LOSS [training: 0.12323672911621653 | validation: 0.38535340152487385]
	TIME [epoch: 20.4 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1266427299235544		[learning rate: 0.0035572]
	Learning Rate: 0.00355722
	LOSS [training: 0.1266427299235544 | validation: 0.3272386571729846]
	TIME [epoch: 20.5 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.129550411721182		[learning rate: 0.003546]
	Learning Rate: 0.00354604
	LOSS [training: 0.129550411721182 | validation: 0.30364407946679783]
	TIME [epoch: 20.4 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12290868326088186		[learning rate: 0.0035349]
	Learning Rate: 0.00353489
	LOSS [training: 0.12290868326088186 | validation: 0.32646877063539365]
	TIME [epoch: 20.4 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1322869707163585		[learning rate: 0.0035238]
	Learning Rate: 0.00352378
	LOSS [training: 0.1322869707163585 | validation: 0.31291324868598647]
	TIME [epoch: 20.4 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1235327459112758		[learning rate: 0.0035127]
	Learning Rate: 0.0035127
	LOSS [training: 0.1235327459112758 | validation: 0.31089941455476094]
	TIME [epoch: 20.4 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11775344302753557		[learning rate: 0.0035017]
	Learning Rate: 0.00350166
	LOSS [training: 0.11775344302753557 | validation: 0.32571365169500055]
	TIME [epoch: 20.4 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11410505792442446		[learning rate: 0.0034906]
	Learning Rate: 0.00349065
	LOSS [training: 0.11410505792442446 | validation: 0.37027036928260304]
	TIME [epoch: 20.4 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12995480178616145		[learning rate: 0.0034797]
	Learning Rate: 0.00347967
	LOSS [training: 0.12995480178616145 | validation: 0.3079706766708381]
	TIME [epoch: 20.5 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1376218037607594		[learning rate: 0.0034687]
	Learning Rate: 0.00346873
	LOSS [training: 0.1376218037607594 | validation: 0.30549209935893556]
	TIME [epoch: 20.4 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13261775314341978		[learning rate: 0.0034578]
	Learning Rate: 0.00345783
	LOSS [training: 0.13261775314341978 | validation: 0.31944586250932355]
	TIME [epoch: 20.5 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1455138118188499		[learning rate: 0.003447]
	Learning Rate: 0.00344696
	LOSS [training: 0.1455138118188499 | validation: 0.3442231890907383]
	TIME [epoch: 20.4 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13209769344679834		[learning rate: 0.0034361]
	Learning Rate: 0.00343612
	LOSS [training: 0.13209769344679834 | validation: 0.34666330640657317]
	TIME [epoch: 20.5 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11909747061121559		[learning rate: 0.0034253]
	Learning Rate: 0.00342532
	LOSS [training: 0.11909747061121559 | validation: 0.3054497764821944]
	TIME [epoch: 20.4 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12216058234324241		[learning rate: 0.0034145]
	Learning Rate: 0.00341455
	LOSS [training: 0.12216058234324241 | validation: 0.29170018063444253]
	TIME [epoch: 20.5 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1241224037666235		[learning rate: 0.0034038]
	Learning Rate: 0.00340381
	LOSS [training: 0.1241224037666235 | validation: 0.312419158980021]
	TIME [epoch: 20.4 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12736060235431845		[learning rate: 0.0033931]
	Learning Rate: 0.00339311
	LOSS [training: 0.12736060235431845 | validation: 0.30118137441160553]
	TIME [epoch: 20.5 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13849249696247654		[learning rate: 0.0033824]
	Learning Rate: 0.00338245
	LOSS [training: 0.13849249696247654 | validation: 0.3329605520910006]
	TIME [epoch: 20.5 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11270063775363925		[learning rate: 0.0033718]
	Learning Rate: 0.00337181
	LOSS [training: 0.11270063775363925 | validation: 0.29172092901829927]
	TIME [epoch: 20.4 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13584378705809222		[learning rate: 0.0033612]
	Learning Rate: 0.00336121
	LOSS [training: 0.13584378705809222 | validation: 0.36819597174732743]
	TIME [epoch: 20.5 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12641962308253957		[learning rate: 0.0033506]
	Learning Rate: 0.00335064
	LOSS [training: 0.12641962308253957 | validation: 0.35773136923203647]
	TIME [epoch: 20.4 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12600981771739908		[learning rate: 0.0033401]
	Learning Rate: 0.00334011
	LOSS [training: 0.12600981771739908 | validation: 0.30553437179049125]
	TIME [epoch: 20.5 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1316912470985311		[learning rate: 0.0033296]
	Learning Rate: 0.00332961
	LOSS [training: 0.1316912470985311 | validation: 0.32261918028108805]
	TIME [epoch: 20.4 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12966595507107073		[learning rate: 0.0033191]
	Learning Rate: 0.00331914
	LOSS [training: 0.12966595507107073 | validation: 0.32598022035065155]
	TIME [epoch: 20.5 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.127765840262556		[learning rate: 0.0033087]
	Learning Rate: 0.00330871
	LOSS [training: 0.127765840262556 | validation: 0.30671174917689975]
	TIME [epoch: 20.4 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12908681120462365		[learning rate: 0.0032983]
	Learning Rate: 0.0032983
	LOSS [training: 0.12908681120462365 | validation: 0.29001685625442675]
	TIME [epoch: 20.4 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11470779394594974		[learning rate: 0.0032879]
	Learning Rate: 0.00328793
	LOSS [training: 0.11470779394594974 | validation: 0.2970671741989208]
	TIME [epoch: 20.5 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12721670873499266		[learning rate: 0.0032776]
	Learning Rate: 0.0032776
	LOSS [training: 0.12721670873499266 | validation: 0.29424707213980494]
	TIME [epoch: 20.4 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13858893373091175		[learning rate: 0.0032673]
	Learning Rate: 0.00326729
	LOSS [training: 0.13858893373091175 | validation: 0.33398604281402844]
	TIME [epoch: 20.5 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13074711386887186		[learning rate: 0.003257]
	Learning Rate: 0.00325702
	LOSS [training: 0.13074711386887186 | validation: 0.29738256208200814]
	TIME [epoch: 20.4 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14365445453206355		[learning rate: 0.0032468]
	Learning Rate: 0.00324678
	LOSS [training: 0.14365445453206355 | validation: 0.32579141160389524]
	TIME [epoch: 20.5 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14656425754986868		[learning rate: 0.0032366]
	Learning Rate: 0.00323657
	LOSS [training: 0.14656425754986868 | validation: 0.2872360677808812]
	TIME [epoch: 20.4 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11252195302004755		[learning rate: 0.0032264]
	Learning Rate: 0.0032264
	LOSS [training: 0.11252195302004755 | validation: 0.33551690126232137]
	TIME [epoch: 20.5 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11610068421940864		[learning rate: 0.0032163]
	Learning Rate: 0.00321625
	LOSS [training: 0.11610068421940864 | validation: 0.28950385609421203]
	TIME [epoch: 20.5 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.124153663939286		[learning rate: 0.0032061]
	Learning Rate: 0.00320614
	LOSS [training: 0.124153663939286 | validation: 0.32623744807785565]
	TIME [epoch: 20.4 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12364907800398153		[learning rate: 0.0031961]
	Learning Rate: 0.00319606
	LOSS [training: 0.12364907800398153 | validation: 0.32384846844440573]
	TIME [epoch: 20.5 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12693335808918266		[learning rate: 0.003186]
	Learning Rate: 0.00318602
	LOSS [training: 0.12693335808918266 | validation: 0.2854063692829974]
	TIME [epoch: 20.4 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11014591002404114		[learning rate: 0.003176]
	Learning Rate: 0.003176
	LOSS [training: 0.11014591002404114 | validation: 0.29101145429866837]
	TIME [epoch: 20.4 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11361419978139968		[learning rate: 0.003166]
	Learning Rate: 0.00316601
	LOSS [training: 0.11361419978139968 | validation: 0.2978490963322725]
	TIME [epoch: 20.4 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13848911858767235		[learning rate: 0.0031561]
	Learning Rate: 0.00315606
	LOSS [training: 0.13848911858767235 | validation: 0.33645454029328103]
	TIME [epoch: 20.4 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13037905525277227		[learning rate: 0.0031461]
	Learning Rate: 0.00314614
	LOSS [training: 0.13037905525277227 | validation: 0.3108645762110785]
	TIME [epoch: 20.4 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11003088834554337		[learning rate: 0.0031362]
	Learning Rate: 0.00313625
	LOSS [training: 0.11003088834554337 | validation: 0.2826238515601319]
	TIME [epoch: 20.4 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13004435173217513		[learning rate: 0.0031264]
	Learning Rate: 0.00312639
	LOSS [training: 0.13004435173217513 | validation: 0.29688939713060847]
	TIME [epoch: 20.4 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12034528800450008		[learning rate: 0.0031166]
	Learning Rate: 0.00311656
	LOSS [training: 0.12034528800450008 | validation: 0.374937765522561]
	TIME [epoch: 20.4 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12303130320765288		[learning rate: 0.0031068]
	Learning Rate: 0.00310676
	LOSS [training: 0.12303130320765288 | validation: 0.30236059814114424]
	TIME [epoch: 20.5 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11105161226099405		[learning rate: 0.003097]
	Learning Rate: 0.00309699
	LOSS [training: 0.11105161226099405 | validation: 0.29160706208684467]
	TIME [epoch: 20.4 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12894195211863205		[learning rate: 0.0030873]
	Learning Rate: 0.00308726
	LOSS [training: 0.12894195211863205 | validation: 0.30803183817305807]
	TIME [epoch: 20.5 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12331042035931014		[learning rate: 0.0030775]
	Learning Rate: 0.00307755
	LOSS [training: 0.12331042035931014 | validation: 0.2919993984607612]
	TIME [epoch: 20.4 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11340169483370596		[learning rate: 0.0030679]
	Learning Rate: 0.00306787
	LOSS [training: 0.11340169483370596 | validation: 0.34378485546195764]
	TIME [epoch: 20.4 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1106400520047225		[learning rate: 0.0030582]
	Learning Rate: 0.00305823
	LOSS [training: 0.1106400520047225 | validation: 0.3418471470981751]
	TIME [epoch: 20.4 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1286203953060548		[learning rate: 0.0030486]
	Learning Rate: 0.00304861
	LOSS [training: 0.1286203953060548 | validation: 0.3036595593131873]
	TIME [epoch: 20.4 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12225276646056804		[learning rate: 0.003039]
	Learning Rate: 0.00303903
	LOSS [training: 0.12225276646056804 | validation: 0.32768078583200827]
	TIME [epoch: 20.4 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11109341494499267		[learning rate: 0.0030295]
	Learning Rate: 0.00302948
	LOSS [training: 0.11109341494499267 | validation: 0.28239645660704316]
	TIME [epoch: 20.4 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11226921511821192		[learning rate: 0.00302]
	Learning Rate: 0.00301995
	LOSS [training: 0.11226921511821192 | validation: 0.31488546536306483]
	TIME [epoch: 20.5 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12140498742690142		[learning rate: 0.0030105]
	Learning Rate: 0.00301046
	LOSS [training: 0.12140498742690142 | validation: 0.3062646133306497]
	TIME [epoch: 20.4 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12048892635162765		[learning rate: 0.003001]
	Learning Rate: 0.00300099
	LOSS [training: 0.12048892635162765 | validation: 0.30970197871595906]
	TIME [epoch: 20.4 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12520462667667936		[learning rate: 0.0029916]
	Learning Rate: 0.00299156
	LOSS [training: 0.12520462667667936 | validation: 0.2870613338384289]
	TIME [epoch: 20.4 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10835376060587397		[learning rate: 0.0029822]
	Learning Rate: 0.00298215
	LOSS [training: 0.10835376060587397 | validation: 0.29815079719690546]
	TIME [epoch: 20.4 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.108940337268661		[learning rate: 0.0029728]
	Learning Rate: 0.00297278
	LOSS [training: 0.108940337268661 | validation: 0.3180714946451047]
	TIME [epoch: 20.4 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12129854984788371		[learning rate: 0.0029634]
	Learning Rate: 0.00296343
	LOSS [training: 0.12129854984788371 | validation: 0.3048778272676547]
	TIME [epoch: 20.4 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10805617304139532		[learning rate: 0.0029541]
	Learning Rate: 0.00295411
	LOSS [training: 0.10805617304139532 | validation: 0.32507004914009124]
	TIME [epoch: 20.4 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11522844782105364		[learning rate: 0.0029448]
	Learning Rate: 0.00294483
	LOSS [training: 0.11522844782105364 | validation: 0.3137914791936652]
	TIME [epoch: 20.4 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1292060788414558		[learning rate: 0.0029356]
	Learning Rate: 0.00293557
	LOSS [training: 0.1292060788414558 | validation: 0.2931046236233759]
	TIME [epoch: 20.4 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11541014093573791		[learning rate: 0.0029263]
	Learning Rate: 0.00292634
	LOSS [training: 0.11541014093573791 | validation: 0.3053511446347619]
	TIME [epoch: 20.4 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1281368235152383		[learning rate: 0.0029171]
	Learning Rate: 0.00291714
	LOSS [training: 0.1281368235152383 | validation: 0.31340245511268605]
	TIME [epoch: 20.4 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12997019286388845		[learning rate: 0.002908]
	Learning Rate: 0.00290797
	LOSS [training: 0.12997019286388845 | validation: 0.29560395414663454]
	TIME [epoch: 20.4 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11756113669796611		[learning rate: 0.0028988]
	Learning Rate: 0.00289883
	LOSS [training: 0.11756113669796611 | validation: 0.3631695552577876]
	TIME [epoch: 20.4 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10992329213382947		[learning rate: 0.0028897]
	Learning Rate: 0.00288971
	LOSS [training: 0.10992329213382947 | validation: 0.29696635125466625]
	TIME [epoch: 20.4 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12210703632591262		[learning rate: 0.0028806]
	Learning Rate: 0.00288063
	LOSS [training: 0.12210703632591262 | validation: 0.2847748668916939]
	TIME [epoch: 20.4 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11788752364201271		[learning rate: 0.0028716]
	Learning Rate: 0.00287157
	LOSS [training: 0.11788752364201271 | validation: 0.27901646855699047]
	TIME [epoch: 20.4 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_vlargesamp_20240719_165939/states/model_facs_v4_dec2b_2dpca_vlargesamp_434.pth
	Model improved!!!
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10837356460052974		[learning rate: 0.0028625]
	Learning Rate: 0.00286254
	LOSS [training: 0.10837356460052974 | validation: 0.3245632784591913]
	TIME [epoch: 20.4 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12509924126786495		[learning rate: 0.0028535]
	Learning Rate: 0.00285354
	LOSS [training: 0.12509924126786495 | validation: 0.3655441338686721]
	TIME [epoch: 20.5 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13214487452193477		[learning rate: 0.0028446]
	Learning Rate: 0.00284457
	LOSS [training: 0.13214487452193477 | validation: 0.3257393757076837]
	TIME [epoch: 20.4 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1302808873208144		[learning rate: 0.0028356]
	Learning Rate: 0.00283563
	LOSS [training: 0.1302808873208144 | validation: 0.28413890302957867]
	TIME [epoch: 20.5 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10692487348028559		[learning rate: 0.0028267]
	Learning Rate: 0.00282672
	LOSS [training: 0.10692487348028559 | validation: 0.2892278598402611]
	TIME [epoch: 20.4 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12670080546828333		[learning rate: 0.0028178]
	Learning Rate: 0.00281783
	LOSS [training: 0.12670080546828333 | validation: 0.32300680505207746]
	TIME [epoch: 20.4 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1131811477287088		[learning rate: 0.002809]
	Learning Rate: 0.00280897
	LOSS [training: 0.1131811477287088 | validation: 0.3081239372873608]
	TIME [epoch: 20.4 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11637965855954924		[learning rate: 0.0028001]
	Learning Rate: 0.00280014
	LOSS [training: 0.11637965855954924 | validation: 0.28448218873550746]
	TIME [epoch: 20.4 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10595747380535941		[learning rate: 0.0027913]
	Learning Rate: 0.00279133
	LOSS [training: 0.10595747380535941 | validation: 0.3352428240835447]
	TIME [epoch: 20.4 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11213276761376596		[learning rate: 0.0027826]
	Learning Rate: 0.00278256
	LOSS [training: 0.11213276761376596 | validation: 0.3284739525936298]
	TIME [epoch: 20.4 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1196411519318391		[learning rate: 0.0027738]
	Learning Rate: 0.00277381
	LOSS [training: 0.1196411519318391 | validation: 0.31127363343247555]
	TIME [epoch: 20.4 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12560921795321964		[learning rate: 0.0027651]
	Learning Rate: 0.00276509
	LOSS [training: 0.12560921795321964 | validation: 0.2973509747123095]
	TIME [epoch: 20.4 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11463756430044308		[learning rate: 0.0027564]
	Learning Rate: 0.0027564
	LOSS [training: 0.11463756430044308 | validation: 0.31796862996939745]
	TIME [epoch: 20.4 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1230569084314386		[learning rate: 0.0027477]
	Learning Rate: 0.00274773
	LOSS [training: 0.1230569084314386 | validation: 0.2789911066483697]
	TIME [epoch: 20.4 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_vlargesamp_20240719_165939/states/model_facs_v4_dec2b_2dpca_vlargesamp_448.pth
	Model improved!!!
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10780457617361285		[learning rate: 0.0027391]
	Learning Rate: 0.00273909
	LOSS [training: 0.10780457617361285 | validation: 0.31341813232936144]
	TIME [epoch: 20.4 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11480941788345321		[learning rate: 0.0027305]
	Learning Rate: 0.00273048
	LOSS [training: 0.11480941788345321 | validation: 0.36680696192370543]
	TIME [epoch: 20.4 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13927422721093902		[learning rate: 0.0027219]
	Learning Rate: 0.0027219
	LOSS [training: 0.13927422721093902 | validation: 0.2849670514233631]
	TIME [epoch: 67.9 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12316309925920388		[learning rate: 0.0027133]
	Learning Rate: 0.00271334
	LOSS [training: 0.12316309925920388 | validation: 0.2813809584809032]
	TIME [epoch: 42.3 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11293613920563988		[learning rate: 0.0027048]
	Learning Rate: 0.00270481
	LOSS [training: 0.11293613920563988 | validation: 0.3036086356220237]
	TIME [epoch: 42.3 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11153189584801458		[learning rate: 0.0026963]
	Learning Rate: 0.00269631
	LOSS [training: 0.11153189584801458 | validation: 0.29763673692723347]
	TIME [epoch: 42.3 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12026821169946053		[learning rate: 0.0026878]
	Learning Rate: 0.00268783
	LOSS [training: 0.12026821169946053 | validation: 0.2971616659722536]
	TIME [epoch: 42.4 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13071782827000414		[learning rate: 0.0026794]
	Learning Rate: 0.00267938
	LOSS [training: 0.13071782827000414 | validation: 0.28456964966136095]
	TIME [epoch: 42.3 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12360644654169256		[learning rate: 0.002671]
	Learning Rate: 0.00267096
	LOSS [training: 0.12360644654169256 | validation: 0.3643900106251804]
	TIME [epoch: 42.3 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12543041876007		[learning rate: 0.0026626]
	Learning Rate: 0.00266256
	LOSS [training: 0.12543041876007 | validation: 0.31470266681547665]
	TIME [epoch: 42.4 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12270747437690153		[learning rate: 0.0026542]
	Learning Rate: 0.00265419
	LOSS [training: 0.12270747437690153 | validation: 0.3103439168495451]
	TIME [epoch: 42.3 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10413914053451073		[learning rate: 0.0026458]
	Learning Rate: 0.00264584
	LOSS [training: 0.10413914053451073 | validation: 0.30054181432577526]
	TIME [epoch: 42.3 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10977206923740014		[learning rate: 0.0026375]
	Learning Rate: 0.00263752
	LOSS [training: 0.10977206923740014 | validation: 0.3040880285163267]
	TIME [epoch: 42.3 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1193701322284475		[learning rate: 0.0026292]
	Learning Rate: 0.00262923
	LOSS [training: 0.1193701322284475 | validation: 0.3156504121925784]
	TIME [epoch: 42.3 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11645369110665661		[learning rate: 0.002621]
	Learning Rate: 0.00262097
	LOSS [training: 0.11645369110665661 | validation: 0.3293221445436667]
	TIME [epoch: 42.3 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11727596399312928		[learning rate: 0.0026127]
	Learning Rate: 0.00261273
	LOSS [training: 0.11727596399312928 | validation: 0.36779201009749235]
	TIME [epoch: 42.3 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12046912950798047		[learning rate: 0.0026045]
	Learning Rate: 0.00260451
	LOSS [training: 0.12046912950798047 | validation: 0.30482266515766787]
	TIME [epoch: 42.4 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12442982757068731		[learning rate: 0.0025963]
	Learning Rate: 0.00259632
	LOSS [training: 0.12442982757068731 | validation: 0.31176938830931233]
	TIME [epoch: 42.4 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11829685238047412		[learning rate: 0.0025882]
	Learning Rate: 0.00258816
	LOSS [training: 0.11829685238047412 | validation: 0.30728623079135803]
	TIME [epoch: 42.4 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10907056709614774		[learning rate: 0.00258]
	Learning Rate: 0.00258003
	LOSS [training: 0.10907056709614774 | validation: 0.2954478156212481]
	TIME [epoch: 42.3 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12229309424645213		[learning rate: 0.0025719]
	Learning Rate: 0.00257191
	LOSS [training: 0.12229309424645213 | validation: 0.27870535440771144]
	TIME [epoch: 42.4 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_vlargesamp_20240719_165939/states/model_facs_v4_dec2b_2dpca_vlargesamp_469.pth
	Model improved!!!
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12073779084822331		[learning rate: 0.0025638]
	Learning Rate: 0.00256383
	LOSS [training: 0.12073779084822331 | validation: 0.31008403847331445]
	TIME [epoch: 42.3 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12827552649122903		[learning rate: 0.0025558]
	Learning Rate: 0.00255577
	LOSS [training: 0.12827552649122903 | validation: 0.35800869193360013]
	TIME [epoch: 42.3 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12505064020701545		[learning rate: 0.0025477]
	Learning Rate: 0.00254773
	LOSS [training: 0.12505064020701545 | validation: 0.29197741299515045]
	TIME [epoch: 42.2 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10973007612826595		[learning rate: 0.0025397]
	Learning Rate: 0.00253972
	LOSS [training: 0.10973007612826595 | validation: 0.2834570499450554]
	TIME [epoch: 42.3 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12253798734566931		[learning rate: 0.0025317]
	Learning Rate: 0.00253174
	LOSS [training: 0.12253798734566931 | validation: 0.33010135261052287]
	TIME [epoch: 42.3 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11795959977573711		[learning rate: 0.0025238]
	Learning Rate: 0.00252378
	LOSS [training: 0.11795959977573711 | validation: 0.2784190028577754]
	TIME [epoch: 42.3 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_vlargesamp_20240719_165939/states/model_facs_v4_dec2b_2dpca_vlargesamp_475.pth
	Model improved!!!
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12173717636568226		[learning rate: 0.0025158]
	Learning Rate: 0.00251584
	LOSS [training: 0.12173717636568226 | validation: 0.3114983625654538]
	TIME [epoch: 42.4 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10793139301577788		[learning rate: 0.0025079]
	Learning Rate: 0.00250794
	LOSS [training: 0.10793139301577788 | validation: 0.2743517345366226]
	TIME [epoch: 42.4 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_vlargesamp_20240719_165939/states/model_facs_v4_dec2b_2dpca_vlargesamp_477.pth
	Model improved!!!
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11084760050694581		[learning rate: 0.0025001]
	Learning Rate: 0.00250005
	LOSS [training: 0.11084760050694581 | validation: 0.267489433602653]
	TIME [epoch: 42.3 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_vlargesamp_20240719_165939/states/model_facs_v4_dec2b_2dpca_vlargesamp_478.pth
	Model improved!!!
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11196471141316047		[learning rate: 0.0024922]
	Learning Rate: 0.00249219
	LOSS [training: 0.11196471141316047 | validation: 0.32388055172429575]
	TIME [epoch: 42.3 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11433180639486612		[learning rate: 0.0024844]
	Learning Rate: 0.00248436
	LOSS [training: 0.11433180639486612 | validation: 0.2711137906143509]
	TIME [epoch: 42.3 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1109960256355306		[learning rate: 0.0024765]
	Learning Rate: 0.00247654
	LOSS [training: 0.1109960256355306 | validation: 0.3155559106744394]
	TIME [epoch: 42.3 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1265587446199862		[learning rate: 0.0024688]
	Learning Rate: 0.00246876
	LOSS [training: 0.1265587446199862 | validation: 0.2951363875062766]
	TIME [epoch: 42.3 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12649166105651363		[learning rate: 0.002461]
	Learning Rate: 0.002461
	LOSS [training: 0.12649166105651363 | validation: 0.3146112035297516]
	TIME [epoch: 42.3 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1036964012185493		[learning rate: 0.0024533]
	Learning Rate: 0.00245326
	LOSS [training: 0.1036964012185493 | validation: 0.30437602012022996]
	TIME [epoch: 42.3 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1075306967957672		[learning rate: 0.0024455]
	Learning Rate: 0.00244555
	LOSS [training: 0.1075306967957672 | validation: 0.3041936739040437]
	TIME [epoch: 42.3 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10865577625747402		[learning rate: 0.0024379]
	Learning Rate: 0.00243786
	LOSS [training: 0.10865577625747402 | validation: 0.3223983479287705]
	TIME [epoch: 42.4 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10435428790074557		[learning rate: 0.0024302]
	Learning Rate: 0.00243019
	LOSS [training: 0.10435428790074557 | validation: 0.3041311414818392]
	TIME [epoch: 42.3 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1083809990875843		[learning rate: 0.0024226]
	Learning Rate: 0.00242255
	LOSS [training: 0.1083809990875843 | validation: 0.2954218810161634]
	TIME [epoch: 42.4 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12283791535973229		[learning rate: 0.0024149]
	Learning Rate: 0.00241494
	LOSS [training: 0.12283791535973229 | validation: 0.29882638107293713]
	TIME [epoch: 42.3 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11345247620542426		[learning rate: 0.0024073]
	Learning Rate: 0.00240735
	LOSS [training: 0.11345247620542426 | validation: 0.2895526268754552]
	TIME [epoch: 42.3 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12263034152341346		[learning rate: 0.0023998]
	Learning Rate: 0.00239978
	LOSS [training: 0.12263034152341346 | validation: 0.31139926977802684]
	TIME [epoch: 42.4 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11401885855008856		[learning rate: 0.0023922]
	Learning Rate: 0.00239223
	LOSS [training: 0.11401885855008856 | validation: 0.32466628014453336]
	TIME [epoch: 42.4 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1159368298893077		[learning rate: 0.0023847]
	Learning Rate: 0.00238471
	LOSS [training: 0.1159368298893077 | validation: 0.2990707918872984]
	TIME [epoch: 42.3 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12376037457532385		[learning rate: 0.0023772]
	Learning Rate: 0.00237721
	LOSS [training: 0.12376037457532385 | validation: 0.273865595543277]
	TIME [epoch: 42.3 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11337833424528485		[learning rate: 0.0023697]
	Learning Rate: 0.00236974
	LOSS [training: 0.11337833424528485 | validation: 0.2836023791717231]
	TIME [epoch: 42.4 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10563622776318138		[learning rate: 0.0023623]
	Learning Rate: 0.00236229
	LOSS [training: 0.10563622776318138 | validation: 0.3164039101717313]
	TIME [epoch: 42.4 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12103775793361556		[learning rate: 0.0023549]
	Learning Rate: 0.00235486
	LOSS [training: 0.12103775793361556 | validation: 0.30992691567271496]
	TIME [epoch: 42.4 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12231280381822614		[learning rate: 0.0023475]
	Learning Rate: 0.00234746
	LOSS [training: 0.12231280381822614 | validation: 0.2673284773160957]
	TIME [epoch: 42.3 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_vlargesamp_20240719_165939/states/model_facs_v4_dec2b_2dpca_vlargesamp_498.pth
	Model improved!!!
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12286824321803294		[learning rate: 0.0023401]
	Learning Rate: 0.00234008
	LOSS [training: 0.12286824321803294 | validation: 0.2879492532091018]
	TIME [epoch: 42.4 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1325471263119886		[learning rate: 0.0023327]
	Learning Rate: 0.00233272
	LOSS [training: 0.1325471263119886 | validation: 0.3362956975268686]
	TIME [epoch: 42.3 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13095815580435008		[learning rate: 0.0023254]
	Learning Rate: 0.00232539
	LOSS [training: 0.13095815580435008 | validation: 0.3159452545868364]
	TIME [epoch: 42.4 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1110324173037111		[learning rate: 0.0023181]
	Learning Rate: 0.00231808
	LOSS [training: 0.1110324173037111 | validation: 0.2767579509758324]
	TIME [epoch: 42.4 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10759561815641236		[learning rate: 0.0023108]
	Learning Rate: 0.00231079
	LOSS [training: 0.10759561815641236 | validation: 0.31244292715893063]
	TIME [epoch: 42.4 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11439522417001655		[learning rate: 0.0023035]
	Learning Rate: 0.00230353
	LOSS [training: 0.11439522417001655 | validation: 0.2921470024483241]
	TIME [epoch: 42.4 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11590549302226011		[learning rate: 0.0022963]
	Learning Rate: 0.00229628
	LOSS [training: 0.11590549302226011 | validation: 0.27134988711896757]
	TIME [epoch: 42.4 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10715424761275806		[learning rate: 0.0022891]
	Learning Rate: 0.00228906
	LOSS [training: 0.10715424761275806 | validation: 0.2751951692362826]
	TIME [epoch: 42.4 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10299398898433938		[learning rate: 0.0022819]
	Learning Rate: 0.00228187
	LOSS [training: 0.10299398898433938 | validation: 0.3382870856339296]
	TIME [epoch: 42.4 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1116475174792155		[learning rate: 0.0022747]
	Learning Rate: 0.00227469
	LOSS [training: 0.1116475174792155 | validation: 0.2787770224340881]
	TIME [epoch: 42.4 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11441053443708986		[learning rate: 0.0022675]
	Learning Rate: 0.00226754
	LOSS [training: 0.11441053443708986 | validation: 0.28387550190625044]
	TIME [epoch: 42.4 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11156088052930926		[learning rate: 0.0022604]
	Learning Rate: 0.00226041
	LOSS [training: 0.11156088052930926 | validation: 0.31566174557885956]
	TIME [epoch: 42.4 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11611205501145276		[learning rate: 0.0022533]
	Learning Rate: 0.00225331
	LOSS [training: 0.11611205501145276 | validation: 0.29277823022509275]
	TIME [epoch: 42.4 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10740344648752427		[learning rate: 0.0022462]
	Learning Rate: 0.00224622
	LOSS [training: 0.10740344648752427 | validation: 0.30717955301648875]
	TIME [epoch: 42.4 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11047515122024944		[learning rate: 0.0022392]
	Learning Rate: 0.00223916
	LOSS [training: 0.11047515122024944 | validation: 0.2731426526916391]
	TIME [epoch: 42.4 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12003105230810995		[learning rate: 0.0022321]
	Learning Rate: 0.00223212
	LOSS [training: 0.12003105230810995 | validation: 0.29381902040456415]
	TIME [epoch: 42.4 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10676448530002378		[learning rate: 0.0022251]
	Learning Rate: 0.0022251
	LOSS [training: 0.10676448530002378 | validation: 0.3071553374036073]
	TIME [epoch: 42.4 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11076966800518763		[learning rate: 0.0022181]
	Learning Rate: 0.00221811
	LOSS [training: 0.11076966800518763 | validation: 0.3024460621901747]
	TIME [epoch: 42.4 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1182189942515387		[learning rate: 0.0022111]
	Learning Rate: 0.00221114
	LOSS [training: 0.1182189942515387 | validation: 0.30438225147485815]
	TIME [epoch: 42.4 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12091007698185031		[learning rate: 0.0022042]
	Learning Rate: 0.00220418
	LOSS [training: 0.12091007698185031 | validation: 0.31804348328419935]
	TIME [epoch: 42.4 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1047676582656918		[learning rate: 0.0021973]
	Learning Rate: 0.00219725
	LOSS [training: 0.1047676582656918 | validation: 0.26232662787140915]
	TIME [epoch: 42.4 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_vlargesamp_20240719_165939/states/model_facs_v4_dec2b_2dpca_vlargesamp_519.pth
	Model improved!!!
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1135842455855126		[learning rate: 0.0021903]
	Learning Rate: 0.00219035
	LOSS [training: 0.1135842455855126 | validation: 0.3151191965514994]
	TIME [epoch: 42.4 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11436828793940726		[learning rate: 0.0021835]
	Learning Rate: 0.00218346
	LOSS [training: 0.11436828793940726 | validation: 0.27953185010847204]
	TIME [epoch: 42.4 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10625659118658336		[learning rate: 0.0021766]
	Learning Rate: 0.0021766
	LOSS [training: 0.10625659118658336 | validation: 0.286693046184779]
	TIME [epoch: 42.4 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11430964716145289		[learning rate: 0.0021698]
	Learning Rate: 0.00216975
	LOSS [training: 0.11430964716145289 | validation: 0.3378912653680897]
	TIME [epoch: 42.4 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11258637081466868		[learning rate: 0.0021629]
	Learning Rate: 0.00216293
	LOSS [training: 0.11258637081466868 | validation: 0.2997832815457643]
	TIME [epoch: 42.4 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10808646036005315		[learning rate: 0.0021561]
	Learning Rate: 0.00215613
	LOSS [training: 0.10808646036005315 | validation: 0.29109025709845726]
	TIME [epoch: 42.4 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1159335406483354		[learning rate: 0.0021494]
	Learning Rate: 0.00214935
	LOSS [training: 0.1159335406483354 | validation: 0.29363263250881866]
	TIME [epoch: 42.4 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1246178383965959		[learning rate: 0.0021426]
	Learning Rate: 0.0021426
	LOSS [training: 0.1246178383965959 | validation: 0.2986746074759081]
	TIME [epoch: 42.4 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10715513973024487		[learning rate: 0.0021359]
	Learning Rate: 0.00213586
	LOSS [training: 0.10715513973024487 | validation: 0.3449758124517479]
	TIME [epoch: 42.4 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11423710137133897		[learning rate: 0.0021291]
	Learning Rate: 0.00212914
	LOSS [training: 0.11423710137133897 | validation: 0.29541089483651073]
	TIME [epoch: 42.4 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10681990344134998		[learning rate: 0.0021225]
	Learning Rate: 0.00212245
	LOSS [training: 0.10681990344134998 | validation: 0.2854965611972405]
	TIME [epoch: 42.4 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12126469746248505		[learning rate: 0.0021158]
	Learning Rate: 0.00211578
	LOSS [training: 0.12126469746248505 | validation: 0.2725536375708942]
	TIME [epoch: 42.4 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12109526076882964		[learning rate: 0.0021091]
	Learning Rate: 0.00210913
	LOSS [training: 0.12109526076882964 | validation: 0.26957545794756055]
	TIME [epoch: 42.4 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11111651864044665		[learning rate: 0.0021025]
	Learning Rate: 0.0021025
	LOSS [training: 0.11111651864044665 | validation: 0.2813790717236962]
	TIME [epoch: 42.4 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10808084196333627		[learning rate: 0.0020959]
	Learning Rate: 0.00209589
	LOSS [training: 0.10808084196333627 | validation: 0.3001067946907111]
	TIME [epoch: 42.4 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1044914567573607		[learning rate: 0.0020893]
	Learning Rate: 0.0020893
	LOSS [training: 0.1044914567573607 | validation: 0.2676326654858074]
	TIME [epoch: 42.4 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10393609787303708		[learning rate: 0.0020827]
	Learning Rate: 0.00208273
	LOSS [training: 0.10393609787303708 | validation: 0.29448310286801604]
	TIME [epoch: 42.4 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12592353351677793		[learning rate: 0.0020762]
	Learning Rate: 0.00207618
	LOSS [training: 0.12592353351677793 | validation: 0.2637771372066158]
	TIME [epoch: 42.4 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.108048728867736		[learning rate: 0.0020697]
	Learning Rate: 0.00206965
	LOSS [training: 0.108048728867736 | validation: 0.3242899623961058]
	TIME [epoch: 42.4 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1255591545935026		[learning rate: 0.0020631]
	Learning Rate: 0.00206315
	LOSS [training: 0.1255591545935026 | validation: 0.3029905743778849]
	TIME [epoch: 42.4 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12252614257048827		[learning rate: 0.0020567]
	Learning Rate: 0.00205666
	LOSS [training: 0.12252614257048827 | validation: 0.28720472627057053]
	TIME [epoch: 42.4 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10741702600626098		[learning rate: 0.0020502]
	Learning Rate: 0.00205019
	LOSS [training: 0.10741702600626098 | validation: 0.3466894744766197]
	TIME [epoch: 42.4 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11347079222119283		[learning rate: 0.0020437]
	Learning Rate: 0.00204375
	LOSS [training: 0.11347079222119283 | validation: 0.29198928475427616]
	TIME [epoch: 42.4 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10429007228372303		[learning rate: 0.0020373]
	Learning Rate: 0.00203732
	LOSS [training: 0.10429007228372303 | validation: 0.2974621851087701]
	TIME [epoch: 42.4 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10979692483377558		[learning rate: 0.0020309]
	Learning Rate: 0.00203092
	LOSS [training: 0.10979692483377558 | validation: 0.27533098228970804]
	TIME [epoch: 42.4 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11276917685345755		[learning rate: 0.0020245]
	Learning Rate: 0.00202453
	LOSS [training: 0.11276917685345755 | validation: 0.27634432723429275]
	TIME [epoch: 42.4 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10405918614571374		[learning rate: 0.0020182]
	Learning Rate: 0.00201817
	LOSS [training: 0.10405918614571374 | validation: 0.26434535041984036]
	TIME [epoch: 42.4 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.115102043689337		[learning rate: 0.0020118]
	Learning Rate: 0.00201182
	LOSS [training: 0.115102043689337 | validation: 0.3114395271504642]
	TIME [epoch: 42.4 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10687577586164473		[learning rate: 0.0020055]
	Learning Rate: 0.0020055
	LOSS [training: 0.10687577586164473 | validation: 0.2848724629422515]
	TIME [epoch: 42.4 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10731938245459557		[learning rate: 0.0019992]
	Learning Rate: 0.00199919
	LOSS [training: 0.10731938245459557 | validation: 0.3116602895294139]
	TIME [epoch: 42.4 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10870106924400454		[learning rate: 0.0019929]
	Learning Rate: 0.00199291
	LOSS [training: 0.10870106924400454 | validation: 0.2712293733797062]
	TIME [epoch: 42.4 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.112255554084506		[learning rate: 0.0019866]
	Learning Rate: 0.00198664
	LOSS [training: 0.112255554084506 | validation: 0.2700203556535333]
	TIME [epoch: 42.4 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11161236328926687		[learning rate: 0.0019804]
	Learning Rate: 0.0019804
	LOSS [training: 0.11161236328926687 | validation: 0.3045870217730624]
	TIME [epoch: 42.4 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12113099183974871		[learning rate: 0.0019742]
	Learning Rate: 0.00197417
	LOSS [training: 0.12113099183974871 | validation: 0.27464931794201086]
	TIME [epoch: 42.4 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11039529016854728		[learning rate: 0.001968]
	Learning Rate: 0.00196796
	LOSS [training: 0.11039529016854728 | validation: 0.3102660411201676]
	TIME [epoch: 42.4 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11232331716945408		[learning rate: 0.0019618]
	Learning Rate: 0.00196178
	LOSS [training: 0.11232331716945408 | validation: 0.28129482732246547]
	TIME [epoch: 42.4 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10920724510811644		[learning rate: 0.0019556]
	Learning Rate: 0.00195561
	LOSS [training: 0.10920724510811644 | validation: 0.29419218623209487]
	TIME [epoch: 42.4 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10756970777985166		[learning rate: 0.0019495]
	Learning Rate: 0.00194946
	LOSS [training: 0.10756970777985166 | validation: 0.2997982883185148]
	TIME [epoch: 42.4 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10560817299022926		[learning rate: 0.0019433]
	Learning Rate: 0.00194333
	LOSS [training: 0.10560817299022926 | validation: 0.31193040225527124]
	TIME [epoch: 42.4 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10413556609762298		[learning rate: 0.0019372]
	Learning Rate: 0.00193722
	LOSS [training: 0.10413556609762298 | validation: 0.27816422276274133]
	TIME [epoch: 42.4 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10915771122861112		[learning rate: 0.0019311]
	Learning Rate: 0.00193113
	LOSS [training: 0.10915771122861112 | validation: 0.308982869985242]
	TIME [epoch: 42.4 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11390633604477929		[learning rate: 0.0019251]
	Learning Rate: 0.00192506
	LOSS [training: 0.11390633604477929 | validation: 0.30391660970558915]
	TIME [epoch: 42.4 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1106690618163467		[learning rate: 0.001919]
	Learning Rate: 0.00191901
	LOSS [training: 0.1106690618163467 | validation: 0.2905564379984507]
	TIME [epoch: 42.4 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13407078810383372		[learning rate: 0.001913]
	Learning Rate: 0.00191298
	LOSS [training: 0.13407078810383372 | validation: 0.2769969332206373]
	TIME [epoch: 42.4 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.125042623852779		[learning rate: 0.001907]
	Learning Rate: 0.00190696
	LOSS [training: 0.125042623852779 | validation: 0.27301316408225224]
	TIME [epoch: 42.4 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11384363459207629		[learning rate: 0.001901]
	Learning Rate: 0.00190097
	LOSS [training: 0.11384363459207629 | validation: 0.28106125820485495]
	TIME [epoch: 42.4 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11521735113075943		[learning rate: 0.001895]
	Learning Rate: 0.00189499
	LOSS [training: 0.11521735113075943 | validation: 0.30650070934012646]
	TIME [epoch: 42.4 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11183496874427629		[learning rate: 0.001889]
	Learning Rate: 0.00188903
	LOSS [training: 0.11183496874427629 | validation: 0.2800580891025105]
	TIME [epoch: 42.4 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09888309689657006		[learning rate: 0.0018831]
	Learning Rate: 0.00188309
	LOSS [training: 0.09888309689657006 | validation: 0.32375345877436046]
	TIME [epoch: 42.4 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12334502868856995		[learning rate: 0.0018772]
	Learning Rate: 0.00187717
	LOSS [training: 0.12334502868856995 | validation: 0.2772788848579777]
	TIME [epoch: 42.4 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11650508718563765		[learning rate: 0.0018713]
	Learning Rate: 0.00187127
	LOSS [training: 0.11650508718563765 | validation: 0.27802993572398954]
	TIME [epoch: 42.4 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11712953345994545		[learning rate: 0.0018654]
	Learning Rate: 0.00186539
	LOSS [training: 0.11712953345994545 | validation: 0.2921651963073516]
	TIME [epoch: 42.4 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12659302323767446		[learning rate: 0.0018595]
	Learning Rate: 0.00185952
	LOSS [training: 0.12659302323767446 | validation: 0.3356384256671962]
	TIME [epoch: 42.4 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12423725755427492		[learning rate: 0.0018537]
	Learning Rate: 0.00185368
	LOSS [training: 0.12423725755427492 | validation: 0.300958564946034]
	TIME [epoch: 42.4 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11374077810448885		[learning rate: 0.0018478]
	Learning Rate: 0.00184785
	LOSS [training: 0.11374077810448885 | validation: 0.2870487608808186]
	TIME [epoch: 42.4 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10516500400131855		[learning rate: 0.001842]
	Learning Rate: 0.00184204
	LOSS [training: 0.10516500400131855 | validation: 0.3119535740739673]
	TIME [epoch: 42.4 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11120119436868797		[learning rate: 0.0018362]
	Learning Rate: 0.00183625
	LOSS [training: 0.11120119436868797 | validation: 0.2909292557662518]
	TIME [epoch: 42.4 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10625202330996701		[learning rate: 0.0018305]
	Learning Rate: 0.00183048
	LOSS [training: 0.10625202330996701 | validation: 0.27566904230027495]
	TIME [epoch: 42.4 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11042080054576967		[learning rate: 0.0018247]
	Learning Rate: 0.00182472
	LOSS [training: 0.11042080054576967 | validation: 0.3002023462920505]
	TIME [epoch: 42.4 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1034804306041091		[learning rate: 0.001819]
	Learning Rate: 0.00181898
	LOSS [training: 0.1034804306041091 | validation: 0.288647022772129]
	TIME [epoch: 42.4 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1118291267255149		[learning rate: 0.0018133]
	Learning Rate: 0.00181327
	LOSS [training: 0.1118291267255149 | validation: 0.28967290381104016]
	TIME [epoch: 42.4 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11591751670535905		[learning rate: 0.0018076]
	Learning Rate: 0.00180757
	LOSS [training: 0.11591751670535905 | validation: 0.2904809508486234]
	TIME [epoch: 42.4 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10412820598655473		[learning rate: 0.0018019]
	Learning Rate: 0.00180188
	LOSS [training: 0.10412820598655473 | validation: 0.2788963161430481]
	TIME [epoch: 42.4 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11594726928811579		[learning rate: 0.0017962]
	Learning Rate: 0.00179622
	LOSS [training: 0.11594726928811579 | validation: 0.26465460892411735]
	TIME [epoch: 42.4 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11212139292602596		[learning rate: 0.0017906]
	Learning Rate: 0.00179057
	LOSS [training: 0.11212139292602596 | validation: 0.30818525349814585]
	TIME [epoch: 42.4 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1099935415216693		[learning rate: 0.0017849]
	Learning Rate: 0.00178494
	LOSS [training: 0.1099935415216693 | validation: 0.27609432555488667]
	TIME [epoch: 42.4 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1188347219958567		[learning rate: 0.0017793]
	Learning Rate: 0.00177933
	LOSS [training: 0.1188347219958567 | validation: 0.27558849464615154]
	TIME [epoch: 42.4 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11384240210586347		[learning rate: 0.0017737]
	Learning Rate: 0.00177374
	LOSS [training: 0.11384240210586347 | validation: 0.2988741089261022]
	TIME [epoch: 42.4 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10097435380831388		[learning rate: 0.0017682]
	Learning Rate: 0.00176816
	LOSS [training: 0.10097435380831388 | validation: 0.31484138967015907]
	TIME [epoch: 42.4 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10396297287514264		[learning rate: 0.0017626]
	Learning Rate: 0.0017626
	LOSS [training: 0.10396297287514264 | validation: 0.3415901294171464]
	TIME [epoch: 42.4 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11161752416598557		[learning rate: 0.0017571]
	Learning Rate: 0.00175706
	LOSS [training: 0.11161752416598557 | validation: 0.2793548101887509]
	TIME [epoch: 42.4 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11585835519240051		[learning rate: 0.0017515]
	Learning Rate: 0.00175153
	LOSS [training: 0.11585835519240051 | validation: 0.271835431934025]
	TIME [epoch: 42.4 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11497121402751831		[learning rate: 0.001746]
	Learning Rate: 0.00174603
	LOSS [training: 0.11497121402751831 | validation: 0.2724631409873735]
	TIME [epoch: 42.4 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10586787378737363		[learning rate: 0.0017405]
	Learning Rate: 0.00174054
	LOSS [training: 0.10586787378737363 | validation: 0.27993572455348975]
	TIME [epoch: 42.4 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12048586098019182		[learning rate: 0.0017351]
	Learning Rate: 0.00173507
	LOSS [training: 0.12048586098019182 | validation: 0.2656702404256728]
	TIME [epoch: 42.4 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10080675180474025		[learning rate: 0.0017296]
	Learning Rate: 0.00172961
	LOSS [training: 0.10080675180474025 | validation: 0.291655817931041]
	TIME [epoch: 42.4 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10617662016873723		[learning rate: 0.0017242]
	Learning Rate: 0.00172417
	LOSS [training: 0.10617662016873723 | validation: 0.3152988997735291]
	TIME [epoch: 42.4 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1101398781205877		[learning rate: 0.0017188]
	Learning Rate: 0.00171875
	LOSS [training: 0.1101398781205877 | validation: 0.28490681508873156]
	TIME [epoch: 42.4 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11174362248587852		[learning rate: 0.0017134]
	Learning Rate: 0.00171335
	LOSS [training: 0.11174362248587852 | validation: 0.26028951213568885]
	TIME [epoch: 42.4 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_vlargesamp_20240719_165939/states/model_facs_v4_dec2b_2dpca_vlargesamp_598.pth
	Model improved!!!
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11303212997900323		[learning rate: 0.001708]
	Learning Rate: 0.00170796
	LOSS [training: 0.11303212997900323 | validation: 0.27720184892424204]
	TIME [epoch: 42.3 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11149402618934871		[learning rate: 0.0017026]
	Learning Rate: 0.00170259
	LOSS [training: 0.11149402618934871 | validation: 0.3165119759398105]
	TIME [epoch: 42.3 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10714113467279665		[learning rate: 0.0016972]
	Learning Rate: 0.00169724
	LOSS [training: 0.10714113467279665 | validation: 0.26723918763444143]
	TIME [epoch: 42.3 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1073951549243033		[learning rate: 0.0016919]
	Learning Rate: 0.00169191
	LOSS [training: 0.1073951549243033 | validation: 0.2687309713171274]
	TIME [epoch: 42.3 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10100524657299789		[learning rate: 0.0016866]
	Learning Rate: 0.00168659
	LOSS [training: 0.10100524657299789 | validation: 0.31535898821466524]
	TIME [epoch: 42.3 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10400883606432018		[learning rate: 0.0016813]
	Learning Rate: 0.00168128
	LOSS [training: 0.10400883606432018 | validation: 0.26577555436575934]
	TIME [epoch: 42.4 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1254603135992584		[learning rate: 0.001676]
	Learning Rate: 0.001676
	LOSS [training: 0.1254603135992584 | validation: 0.2968713773455912]
	TIME [epoch: 42.3 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10000677205934451		[learning rate: 0.0016707]
	Learning Rate: 0.00167073
	LOSS [training: 0.10000677205934451 | validation: 0.2962731273857581]
	TIME [epoch: 42.4 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09992194864627454		[learning rate: 0.0016655]
	Learning Rate: 0.00166548
	LOSS [training: 0.09992194864627454 | validation: 0.27597145827277525]
	TIME [epoch: 42.3 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10465237982581785		[learning rate: 0.0016602]
	Learning Rate: 0.00166024
	LOSS [training: 0.10465237982581785 | validation: 0.29547116817706776]
	TIME [epoch: 42.4 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11008479547441755		[learning rate: 0.001655]
	Learning Rate: 0.00165502
	LOSS [training: 0.11008479547441755 | validation: 0.2957255862639966]
	TIME [epoch: 42.4 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1179974578888281		[learning rate: 0.0016498]
	Learning Rate: 0.00164982
	LOSS [training: 0.1179974578888281 | validation: 0.29654682233714746]
	TIME [epoch: 42.3 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12206184727422817		[learning rate: 0.0016446]
	Learning Rate: 0.00164463
	LOSS [training: 0.12206184727422817 | validation: 0.29282936144789795]
	TIME [epoch: 42.4 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11360260036660487		[learning rate: 0.0016395]
	Learning Rate: 0.00163946
	LOSS [training: 0.11360260036660487 | validation: 0.2841559296940645]
	TIME [epoch: 42.4 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10445563353429885		[learning rate: 0.0016343]
	Learning Rate: 0.00163431
	LOSS [training: 0.10445563353429885 | validation: 0.3122804681434986]
	TIME [epoch: 42.4 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12242822913612872		[learning rate: 0.0016292]
	Learning Rate: 0.00162917
	LOSS [training: 0.12242822913612872 | validation: 0.26180026906951376]
	TIME [epoch: 42.4 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11447637893555176		[learning rate: 0.001624]
	Learning Rate: 0.00162405
	LOSS [training: 0.11447637893555176 | validation: 0.26973492124093296]
	TIME [epoch: 42.4 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11452368677131311		[learning rate: 0.0016189]
	Learning Rate: 0.00161894
	LOSS [training: 0.11452368677131311 | validation: 0.26028708395446953]
	TIME [epoch: 42.4 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_vlargesamp_20240719_165939/states/model_facs_v4_dec2b_2dpca_vlargesamp_616.pth
	Model improved!!!
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11133838823118886		[learning rate: 0.0016139]
	Learning Rate: 0.00161385
	LOSS [training: 0.11133838823118886 | validation: 0.2838169712684583]
	TIME [epoch: 42.3 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10162547965993375		[learning rate: 0.0016088]
	Learning Rate: 0.00160878
	LOSS [training: 0.10162547965993375 | validation: 0.2567887675793448]
	TIME [epoch: 42.3 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_vlargesamp_20240719_165939/states/model_facs_v4_dec2b_2dpca_vlargesamp_618.pth
	Model improved!!!
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12118862667842051		[learning rate: 0.0016037]
	Learning Rate: 0.00160372
	LOSS [training: 0.12118862667842051 | validation: 0.28831505715687233]
	TIME [epoch: 42.3 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11519064420373734		[learning rate: 0.0015987]
	Learning Rate: 0.00159868
	LOSS [training: 0.11519064420373734 | validation: 0.2655277335815174]
	TIME [epoch: 42.3 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10252407813158651		[learning rate: 0.0015937]
	Learning Rate: 0.00159365
	LOSS [training: 0.10252407813158651 | validation: 0.28918821354810387]
	TIME [epoch: 42.4 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10122812899926394		[learning rate: 0.0015886]
	Learning Rate: 0.00158864
	LOSS [training: 0.10122812899926394 | validation: 0.27843774659837595]
	TIME [epoch: 42.3 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1134025157520224		[learning rate: 0.0015836]
	Learning Rate: 0.00158365
	LOSS [training: 0.1134025157520224 | validation: 0.25496291566961]
	TIME [epoch: 42.3 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_vlargesamp_20240719_165939/states/model_facs_v4_dec2b_2dpca_vlargesamp_623.pth
	Model improved!!!
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11107854325659282		[learning rate: 0.0015787]
	Learning Rate: 0.00157867
	LOSS [training: 0.11107854325659282 | validation: 0.287736816274187]
	TIME [epoch: 42.3 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11084796385266821		[learning rate: 0.0015737]
	Learning Rate: 0.0015737
	LOSS [training: 0.11084796385266821 | validation: 0.27145997099804325]
	TIME [epoch: 42.3 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10490913652562914		[learning rate: 0.0015688]
	Learning Rate: 0.00156876
	LOSS [training: 0.10490913652562914 | validation: 0.27383111458872006]
	TIME [epoch: 42.2 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10788622815117507		[learning rate: 0.0015638]
	Learning Rate: 0.00156382
	LOSS [training: 0.10788622815117507 | validation: 0.26107737439205014]
	TIME [epoch: 42.3 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10038158385241157		[learning rate: 0.0015589]
	Learning Rate: 0.00155891
	LOSS [training: 0.10038158385241157 | validation: 0.26324878926928214]
	TIME [epoch: 42.2 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1049820293677704		[learning rate: 0.001554]
	Learning Rate: 0.00155401
	LOSS [training: 0.1049820293677704 | validation: 0.3028289943207942]
	TIME [epoch: 42.3 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10779283478291442		[learning rate: 0.0015491]
	Learning Rate: 0.00154912
	LOSS [training: 0.10779283478291442 | validation: 0.2870931420513563]
	TIME [epoch: 42.2 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10780544298315867		[learning rate: 0.0015443]
	Learning Rate: 0.00154425
	LOSS [training: 0.10780544298315867 | validation: 0.2784616301037005]
	TIME [epoch: 42.2 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11365188035170573		[learning rate: 0.0015394]
	Learning Rate: 0.0015394
	LOSS [training: 0.11365188035170573 | validation: 0.2910352900245975]
	TIME [epoch: 42.2 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12215117434084348		[learning rate: 0.0015346]
	Learning Rate: 0.00153456
	LOSS [training: 0.12215117434084348 | validation: 0.27114763544286097]
	TIME [epoch: 42.3 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11466829023673847		[learning rate: 0.0015297]
	Learning Rate: 0.00152973
	LOSS [training: 0.11466829023673847 | validation: 0.24721095316427696]
	TIME [epoch: 42.3 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_vlargesamp_20240719_165939/states/model_facs_v4_dec2b_2dpca_vlargesamp_634.pth
	Model improved!!!
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10489343114436707		[learning rate: 0.0015249]
	Learning Rate: 0.00152492
	LOSS [training: 0.10489343114436707 | validation: 0.3195325761815918]
	TIME [epoch: 42.4 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.107288279342644		[learning rate: 0.0015201]
	Learning Rate: 0.00152013
	LOSS [training: 0.107288279342644 | validation: 0.2662321143109922]
	TIME [epoch: 42.4 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10207213026570698		[learning rate: 0.0015153]
	Learning Rate: 0.00151535
	LOSS [training: 0.10207213026570698 | validation: 0.2804636840696482]
	TIME [epoch: 42.4 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10351195961093348		[learning rate: 0.0015106]
	Learning Rate: 0.00151059
	LOSS [training: 0.10351195961093348 | validation: 0.26200915392504354]
	TIME [epoch: 42.4 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11712442433138484		[learning rate: 0.0015058]
	Learning Rate: 0.00150584
	LOSS [training: 0.11712442433138484 | validation: 0.28208563713609414]
	TIME [epoch: 42.4 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11523787686775247		[learning rate: 0.0015011]
	Learning Rate: 0.0015011
	LOSS [training: 0.11523787686775247 | validation: 0.27913770745634275]
	TIME [epoch: 42.4 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10178575835938553		[learning rate: 0.0014964]
	Learning Rate: 0.00149638
	LOSS [training: 0.10178575835938553 | validation: 0.3156337828352108]
	TIME [epoch: 42.4 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1086120467600715		[learning rate: 0.0014917]
	Learning Rate: 0.00149168
	LOSS [training: 0.1086120467600715 | validation: 0.2850818211017256]
	TIME [epoch: 42.4 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0970874751392899		[learning rate: 0.001487]
	Learning Rate: 0.00148699
	LOSS [training: 0.0970874751392899 | validation: 0.2620735586841438]
	TIME [epoch: 42.4 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10160324821002505		[learning rate: 0.0014823]
	Learning Rate: 0.00148231
	LOSS [training: 0.10160324821002505 | validation: 0.29437538004150543]
	TIME [epoch: 42.4 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10307761791045357		[learning rate: 0.0014777]
	Learning Rate: 0.00147765
	LOSS [training: 0.10307761791045357 | validation: 0.2734640428492356]
	TIME [epoch: 42.4 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11018307273060392		[learning rate: 0.001473]
	Learning Rate: 0.00147301
	LOSS [training: 0.11018307273060392 | validation: 0.27591114797279787]
	TIME [epoch: 42.4 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0986276174030303		[learning rate: 0.0014684]
	Learning Rate: 0.00146838
	LOSS [training: 0.0986276174030303 | validation: 0.261356986011691]
	TIME [epoch: 42.4 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12475223329839993		[learning rate: 0.0014638]
	Learning Rate: 0.00146376
	LOSS [training: 0.12475223329839993 | validation: 0.2708059027936974]
	TIME [epoch: 42.4 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.108166544494831		[learning rate: 0.0014592]
	Learning Rate: 0.00145916
	LOSS [training: 0.108166544494831 | validation: 0.2769708382866704]
	TIME [epoch: 42.4 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09837746996757431		[learning rate: 0.0014546]
	Learning Rate: 0.00145457
	LOSS [training: 0.09837746996757431 | validation: 0.28635846218391875]
	TIME [epoch: 42.4 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10865519887506771		[learning rate: 0.00145]
	Learning Rate: 0.00145
	LOSS [training: 0.10865519887506771 | validation: 0.27514595718201557]
	TIME [epoch: 42.4 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09862271317884029		[learning rate: 0.0014454]
	Learning Rate: 0.00144544
	LOSS [training: 0.09862271317884029 | validation: 0.27987984544348266]
	TIME [epoch: 42.4 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10858436406776568		[learning rate: 0.0014409]
	Learning Rate: 0.0014409
	LOSS [training: 0.10858436406776568 | validation: 0.272503612346181]
	TIME [epoch: 42.4 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10744178876458557		[learning rate: 0.0014364]
	Learning Rate: 0.00143637
	LOSS [training: 0.10744178876458557 | validation: 0.2656447817255291]
	TIME [epoch: 42.4 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11717666283903341		[learning rate: 0.0014318]
	Learning Rate: 0.00143185
	LOSS [training: 0.11717666283903341 | validation: 0.2633623584110653]
	TIME [epoch: 42.4 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11398364028206268		[learning rate: 0.0014273]
	Learning Rate: 0.00142735
	LOSS [training: 0.11398364028206268 | validation: 0.2788508211639958]
	TIME [epoch: 42.4 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09889787032710107		[learning rate: 0.0014229]
	Learning Rate: 0.00142286
	LOSS [training: 0.09889787032710107 | validation: 0.2855285364121805]
	TIME [epoch: 42.4 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12612436522019352		[learning rate: 0.0014184]
	Learning Rate: 0.00141839
	LOSS [training: 0.12612436522019352 | validation: 0.26361094205482666]
	TIME [epoch: 42.4 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10145564631444084		[learning rate: 0.0014139]
	Learning Rate: 0.00141393
	LOSS [training: 0.10145564631444084 | validation: 0.28210191506214943]
	TIME [epoch: 42.4 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09602290106649188		[learning rate: 0.0014095]
	Learning Rate: 0.00140948
	LOSS [training: 0.09602290106649188 | validation: 0.2982068061356832]
	TIME [epoch: 42.4 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10027142408350309		[learning rate: 0.0014051]
	Learning Rate: 0.00140505
	LOSS [training: 0.10027142408350309 | validation: 0.266216420552085]
	TIME [epoch: 42.4 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09714780817164842		[learning rate: 0.0014006]
	Learning Rate: 0.00140063
	LOSS [training: 0.09714780817164842 | validation: 0.263945684434123]
	TIME [epoch: 42.4 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11468774674551355		[learning rate: 0.0013962]
	Learning Rate: 0.00139623
	LOSS [training: 0.11468774674551355 | validation: 0.2927941427083862]
	TIME [epoch: 42.4 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10665081248010497		[learning rate: 0.0013918]
	Learning Rate: 0.00139184
	LOSS [training: 0.10665081248010497 | validation: 0.2926585784984097]
	TIME [epoch: 42.4 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10354454795436316		[learning rate: 0.0013875]
	Learning Rate: 0.00138747
	LOSS [training: 0.10354454795436316 | validation: 0.2694136955755532]
	TIME [epoch: 42.4 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10625712959783902		[learning rate: 0.0013831]
	Learning Rate: 0.0013831
	LOSS [training: 0.10625712959783902 | validation: 0.27631225142481297]
	TIME [epoch: 42.4 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10369347039454307		[learning rate: 0.0013788]
	Learning Rate: 0.00137876
	LOSS [training: 0.10369347039454307 | validation: 0.29275410438457455]
	TIME [epoch: 42.4 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11867776907173852		[learning rate: 0.0013744]
	Learning Rate: 0.00137442
	LOSS [training: 0.11867776907173852 | validation: 0.27213087519673074]
	TIME [epoch: 42.4 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10690538034585946		[learning rate: 0.0013701]
	Learning Rate: 0.0013701
	LOSS [training: 0.10690538034585946 | validation: 0.28158527456946425]
	TIME [epoch: 42.4 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09652021721949301		[learning rate: 0.0013658]
	Learning Rate: 0.00136579
	LOSS [training: 0.09652021721949301 | validation: 0.26434639383288144]
	TIME [epoch: 42.4 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10070777743542031		[learning rate: 0.0013615]
	Learning Rate: 0.0013615
	LOSS [training: 0.10070777743542031 | validation: 0.30910221263946464]
	TIME [epoch: 42.4 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10925968097148933		[learning rate: 0.0013572]
	Learning Rate: 0.00135722
	LOSS [training: 0.10925968097148933 | validation: 0.30074455139318956]
	TIME [epoch: 42.4 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12016627580832695		[learning rate: 0.001353]
	Learning Rate: 0.00135295
	LOSS [training: 0.12016627580832695 | validation: 0.29754639966014357]
	TIME [epoch: 42.4 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11477131122518011		[learning rate: 0.0013487]
	Learning Rate: 0.0013487
	LOSS [training: 0.11477131122518011 | validation: 0.28220367210538166]
	TIME [epoch: 42.3 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09924958433838435		[learning rate: 0.0013445]
	Learning Rate: 0.00134446
	LOSS [training: 0.09924958433838435 | validation: 0.2599866410339123]
	TIME [epoch: 42.4 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1093431649250025		[learning rate: 0.0013402]
	Learning Rate: 0.00134023
	LOSS [training: 0.1093431649250025 | validation: 0.2734655718207807]
	TIME [epoch: 42.4 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10943964224525257		[learning rate: 0.001336]
	Learning Rate: 0.00133602
	LOSS [training: 0.10943964224525257 | validation: 0.28544836503318954]
	TIME [epoch: 42.4 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10884859968959756		[learning rate: 0.0013318]
	Learning Rate: 0.00133182
	LOSS [training: 0.10884859968959756 | validation: 0.26621721819294997]
	TIME [epoch: 42.4 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10251551834747863		[learning rate: 0.0013276]
	Learning Rate: 0.00132763
	LOSS [training: 0.10251551834747863 | validation: 0.28866119198762474]
	TIME [epoch: 42.3 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09906193984428868		[learning rate: 0.0013235]
	Learning Rate: 0.00132346
	LOSS [training: 0.09906193984428868 | validation: 0.2546572714645607]
	TIME [epoch: 42.3 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10291794241520114		[learning rate: 0.0013193]
	Learning Rate: 0.00131929
	LOSS [training: 0.10291794241520114 | validation: 0.25635738658061197]
	TIME [epoch: 42.3 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11073159245317872		[learning rate: 0.0013151]
	Learning Rate: 0.00131515
	LOSS [training: 0.11073159245317872 | validation: 0.2747581124258297]
	TIME [epoch: 42.4 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11716617541299465		[learning rate: 0.001311]
	Learning Rate: 0.00131101
	LOSS [training: 0.11716617541299465 | validation: 0.2687753241506182]
	TIME [epoch: 42.3 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11201218874254944		[learning rate: 0.0013069]
	Learning Rate: 0.00130689
	LOSS [training: 0.11201218874254944 | validation: 0.25833826214792077]
	TIME [epoch: 42.3 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11735235716332712		[learning rate: 0.0013028]
	Learning Rate: 0.00130278
	LOSS [training: 0.11735235716332712 | validation: 0.29501579649857607]
	TIME [epoch: 42.3 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11466434577664722		[learning rate: 0.0012987]
	Learning Rate: 0.00129869
	LOSS [training: 0.11466434577664722 | validation: 0.27842225509626334]
	TIME [epoch: 42.4 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09903627437151413		[learning rate: 0.0012946]
	Learning Rate: 0.0012946
	LOSS [training: 0.09903627437151413 | validation: 0.28404520128788047]
	TIME [epoch: 42.3 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09484872310316853		[learning rate: 0.0012905]
	Learning Rate: 0.00129053
	LOSS [training: 0.09484872310316853 | validation: 0.2921723520876828]
	TIME [epoch: 42.3 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10128140846749625		[learning rate: 0.0012865]
	Learning Rate: 0.00128648
	LOSS [training: 0.10128140846749625 | validation: 0.34405854516111056]
	TIME [epoch: 42.3 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11440261846198531		[learning rate: 0.0012824]
	Learning Rate: 0.00128243
	LOSS [training: 0.11440261846198531 | validation: 0.2528508472579813]
	TIME [epoch: 42.3 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11312147088219743		[learning rate: 0.0012784]
	Learning Rate: 0.0012784
	LOSS [training: 0.11312147088219743 | validation: 0.2718744788448715]
	TIME [epoch: 42.4 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11743837024263457		[learning rate: 0.0012744]
	Learning Rate: 0.00127438
	LOSS [training: 0.11743837024263457 | validation: 0.2977903386610971]
	TIME [epoch: 42.4 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10433173807270069		[learning rate: 0.0012704]
	Learning Rate: 0.00127037
	LOSS [training: 0.10433173807270069 | validation: 0.2964186585413047]
	TIME [epoch: 42.3 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10111830993400345		[learning rate: 0.0012664]
	Learning Rate: 0.00126638
	LOSS [training: 0.10111830993400345 | validation: 0.25838842812839435]
	TIME [epoch: 42.3 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1010906643509063		[learning rate: 0.0012624]
	Learning Rate: 0.0012624
	LOSS [training: 0.1010906643509063 | validation: 0.2710566441028844]
	TIME [epoch: 42.3 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09764219214775094		[learning rate: 0.0012584]
	Learning Rate: 0.00125843
	LOSS [training: 0.09764219214775094 | validation: 0.30136232630168674]
	TIME [epoch: 42.3 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10838883056555065		[learning rate: 0.0012545]
	Learning Rate: 0.00125447
	LOSS [training: 0.10838883056555065 | validation: 0.2745326865448482]
	TIME [epoch: 42.3 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09948840336658865		[learning rate: 0.0012505]
	Learning Rate: 0.00125053
	LOSS [training: 0.09948840336658865 | validation: 0.2627288881765173]
	TIME [epoch: 42.3 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11575938799789603		[learning rate: 0.0012466]
	Learning Rate: 0.0012466
	LOSS [training: 0.11575938799789603 | validation: 0.27443023579511694]
	TIME [epoch: 42.3 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10629931509668428		[learning rate: 0.0012427]
	Learning Rate: 0.00124268
	LOSS [training: 0.10629931509668428 | validation: 0.31910025722147506]
	TIME [epoch: 42.4 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09916614828135632		[learning rate: 0.0012388]
	Learning Rate: 0.00123877
	LOSS [training: 0.09916614828135632 | validation: 0.2602255134074671]
	TIME [epoch: 42.3 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10671156428559027		[learning rate: 0.0012349]
	Learning Rate: 0.00123488
	LOSS [training: 0.10671156428559027 | validation: 0.26941848866095097]
	TIME [epoch: 42.3 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10923601487629514		[learning rate: 0.001231]
	Learning Rate: 0.001231
	LOSS [training: 0.10923601487629514 | validation: 0.2683568042780432]
	TIME [epoch: 42.3 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10851085918850058		[learning rate: 0.0012271]
	Learning Rate: 0.00122713
	LOSS [training: 0.10851085918850058 | validation: 0.2580741445906946]
	TIME [epoch: 42.3 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11006481943507017		[learning rate: 0.0012233]
	Learning Rate: 0.00122327
	LOSS [training: 0.11006481943507017 | validation: 0.3056228566179124]
	TIME [epoch: 42.3 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1099242149900356		[learning rate: 0.0012194]
	Learning Rate: 0.00121942
	LOSS [training: 0.1099242149900356 | validation: 0.2599548970426727]
	TIME [epoch: 42.3 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09846581981431113		[learning rate: 0.0012156]
	Learning Rate: 0.00121559
	LOSS [training: 0.09846581981431113 | validation: 0.2866189384068928]
	TIME [epoch: 42.3 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10916734738418007		[learning rate: 0.0012118]
	Learning Rate: 0.00121177
	LOSS [training: 0.10916734738418007 | validation: 0.2765294088892351]
	TIME [epoch: 42.3 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10822014740727864		[learning rate: 0.001208]
	Learning Rate: 0.00120796
	LOSS [training: 0.10822014740727864 | validation: 0.258495648625056]
	TIME [epoch: 42.3 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10221745684749883		[learning rate: 0.0012042]
	Learning Rate: 0.00120416
	LOSS [training: 0.10221745684749883 | validation: 0.3045148366088457]
	TIME [epoch: 42.3 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10791221128034334		[learning rate: 0.0012004]
	Learning Rate: 0.00120037
	LOSS [training: 0.10791221128034334 | validation: 0.2623065031887356]
	TIME [epoch: 42.3 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10630838469213406		[learning rate: 0.0011966]
	Learning Rate: 0.0011966
	LOSS [training: 0.10630838469213406 | validation: 0.2784087441987366]
	TIME [epoch: 42.3 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.096182828133701		[learning rate: 0.0011928]
	Learning Rate: 0.00119284
	LOSS [training: 0.096182828133701 | validation: 0.26783055576163683]
	TIME [epoch: 42.3 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09872139987521353		[learning rate: 0.0011891]
	Learning Rate: 0.00118909
	LOSS [training: 0.09872139987521353 | validation: 0.31103475609672737]
	TIME [epoch: 42.3 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11017539445925215		[learning rate: 0.0011853]
	Learning Rate: 0.00118535
	LOSS [training: 0.11017539445925215 | validation: 0.2946834036709923]
	TIME [epoch: 42.3 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10925909309060229		[learning rate: 0.0011816]
	Learning Rate: 0.00118162
	LOSS [training: 0.10925909309060229 | validation: 0.28836439077997444]
	TIME [epoch: 42.3 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10966115040772079		[learning rate: 0.0011779]
	Learning Rate: 0.00117791
	LOSS [training: 0.10966115040772079 | validation: 0.28309174922995395]
	TIME [epoch: 42.3 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10546662362168342		[learning rate: 0.0011742]
	Learning Rate: 0.0011742
	LOSS [training: 0.10546662362168342 | validation: 0.2731455275301612]
	TIME [epoch: 42.3 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10838332859555791		[learning rate: 0.0011705]
	Learning Rate: 0.00117051
	LOSS [training: 0.10838332859555791 | validation: 0.2624423117794306]
	TIME [epoch: 42.3 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09678411944942157		[learning rate: 0.0011668]
	Learning Rate: 0.00116683
	LOSS [training: 0.09678411944942157 | validation: 0.28199509352501395]
	TIME [epoch: 42.3 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09839124144367808		[learning rate: 0.0011632]
	Learning Rate: 0.00116316
	LOSS [training: 0.09839124144367808 | validation: 0.26057968582757307]
	TIME [epoch: 42.3 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10477481104215271		[learning rate: 0.0011595]
	Learning Rate: 0.00115951
	LOSS [training: 0.10477481104215271 | validation: 0.28470205412978977]
	TIME [epoch: 42.3 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09690557654616354		[learning rate: 0.0011559]
	Learning Rate: 0.00115586
	LOSS [training: 0.09690557654616354 | validation: 0.2675591156541115]
	TIME [epoch: 42.3 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10493185427694597		[learning rate: 0.0011522]
	Learning Rate: 0.00115223
	LOSS [training: 0.10493185427694597 | validation: 0.3259470669955286]
	TIME [epoch: 42.3 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10881293880708576		[learning rate: 0.0011486]
	Learning Rate: 0.00114861
	LOSS [training: 0.10881293880708576 | validation: 0.25524056990917304]
	TIME [epoch: 42.3 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1074217108810198		[learning rate: 0.001145]
	Learning Rate: 0.00114499
	LOSS [training: 0.1074217108810198 | validation: 0.2855346178953411]
	TIME [epoch: 42.3 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10360468870510504		[learning rate: 0.0011414]
	Learning Rate: 0.00114139
	LOSS [training: 0.10360468870510504 | validation: 0.2669443449442968]
	TIME [epoch: 42.3 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10773827046752119		[learning rate: 0.0011378]
	Learning Rate: 0.00113781
	LOSS [training: 0.10773827046752119 | validation: 0.269697156768912]
	TIME [epoch: 42.3 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09966625498055827		[learning rate: 0.0011342]
	Learning Rate: 0.00113423
	LOSS [training: 0.09966625498055827 | validation: 0.26308718497064165]
	TIME [epoch: 42.4 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10559192089994965		[learning rate: 0.0011307]
	Learning Rate: 0.00113066
	LOSS [training: 0.10559192089994965 | validation: 0.264873362068077]
	TIME [epoch: 42.4 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09478380131301317		[learning rate: 0.0011271]
	Learning Rate: 0.00112711
	LOSS [training: 0.09478380131301317 | validation: 0.2952201035376676]
	TIME [epoch: 42.4 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11041868950393278		[learning rate: 0.0011236]
	Learning Rate: 0.00112357
	LOSS [training: 0.11041868950393278 | validation: 0.28251763652053075]
	TIME [epoch: 42.4 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11318713635409808		[learning rate: 0.00112]
	Learning Rate: 0.00112003
	LOSS [training: 0.11318713635409808 | validation: 0.2915516997135674]
	TIME [epoch: 42.3 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11669057976984261		[learning rate: 0.0011165]
	Learning Rate: 0.00111651
	LOSS [training: 0.11669057976984261 | validation: 0.2906080009377205]
	TIME [epoch: 42.3 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10008269524210892		[learning rate: 0.001113]
	Learning Rate: 0.001113
	LOSS [training: 0.10008269524210892 | validation: 0.2807733442900778]
	TIME [epoch: 42.4 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10080491805971731		[learning rate: 0.0011095]
	Learning Rate: 0.0011095
	LOSS [training: 0.10080491805971731 | validation: 0.29129894446224924]
	TIME [epoch: 42.4 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10698018807420195		[learning rate: 0.001106]
	Learning Rate: 0.00110601
	LOSS [training: 0.10698018807420195 | validation: 0.25424176521194397]
	TIME [epoch: 42.4 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10722214112921472		[learning rate: 0.0011025]
	Learning Rate: 0.00110254
	LOSS [training: 0.10722214112921472 | validation: 0.2612963711303558]
	TIME [epoch: 42.4 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10035884841358458		[learning rate: 0.0010991]
	Learning Rate: 0.00109907
	LOSS [training: 0.10035884841358458 | validation: 0.27362820275365185]
	TIME [epoch: 42.3 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10053177262954253		[learning rate: 0.0010956]
	Learning Rate: 0.00109562
	LOSS [training: 0.10053177262954253 | validation: 0.27599042634120974]
	TIME [epoch: 42.3 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10019696621525798		[learning rate: 0.0010922]
	Learning Rate: 0.00109217
	LOSS [training: 0.10019696621525798 | validation: 0.26711106689396646]
	TIME [epoch: 42.2 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09666955379640307		[learning rate: 0.0010887]
	Learning Rate: 0.00108874
	LOSS [training: 0.09666955379640307 | validation: 0.26181481828487374]
	TIME [epoch: 42.3 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09542847903845098		[learning rate: 0.0010853]
	Learning Rate: 0.00108531
	LOSS [training: 0.09542847903845098 | validation: 0.26115283079630813]
	TIME [epoch: 42.4 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09784354153042737		[learning rate: 0.0010819]
	Learning Rate: 0.0010819
	LOSS [training: 0.09784354153042737 | validation: 0.27353324238503596]
	TIME [epoch: 42.4 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11666163111256815		[learning rate: 0.0010785]
	Learning Rate: 0.0010785
	LOSS [training: 0.11666163111256815 | validation: 0.26904952137536847]
	TIME [epoch: 42.3 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09874424025311272		[learning rate: 0.0010751]
	Learning Rate: 0.00107511
	LOSS [training: 0.09874424025311272 | validation: 0.26010167383615557]
	TIME [epoch: 42.3 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09708858750978733		[learning rate: 0.0010717]
	Learning Rate: 0.00107173
	LOSS [training: 0.09708858750978733 | validation: 0.2805293824025765]
	TIME [epoch: 42.4 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09900749999764083		[learning rate: 0.0010684]
	Learning Rate: 0.00106836
	LOSS [training: 0.09900749999764083 | validation: 0.27036829747337443]
	TIME [epoch: 42.4 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10011990517435693		[learning rate: 0.001065]
	Learning Rate: 0.001065
	LOSS [training: 0.10011990517435693 | validation: 0.25120754622858055]
	TIME [epoch: 42.3 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1154414222033761		[learning rate: 0.0010617]
	Learning Rate: 0.00106165
	LOSS [training: 0.1154414222033761 | validation: 0.2895276812200776]
	TIME [epoch: 42.3 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09794861222081526		[learning rate: 0.0010583]
	Learning Rate: 0.00105832
	LOSS [training: 0.09794861222081526 | validation: 0.2729228803485454]
	TIME [epoch: 42.4 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0929662518574419		[learning rate: 0.001055]
	Learning Rate: 0.00105499
	LOSS [training: 0.0929662518574419 | validation: 0.2668317788882463]
	TIME [epoch: 42.3 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09764844450785494		[learning rate: 0.0010517]
	Learning Rate: 0.00105167
	LOSS [training: 0.09764844450785494 | validation: 0.30667759627669716]
	TIME [epoch: 42.4 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10083617076346937		[learning rate: 0.0010484]
	Learning Rate: 0.00104837
	LOSS [training: 0.10083617076346937 | validation: 0.26863225700348076]
	TIME [epoch: 42.4 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09811864842026949		[learning rate: 0.0010451]
	Learning Rate: 0.00104507
	LOSS [training: 0.09811864842026949 | validation: 0.2786240476665162]
	TIME [epoch: 42.3 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10548147421988936		[learning rate: 0.0010418]
	Learning Rate: 0.00104178
	LOSS [training: 0.10548147421988936 | validation: 0.27815921788832204]
	TIME [epoch: 42.3 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0968972269344987		[learning rate: 0.0010385]
	Learning Rate: 0.00103851
	LOSS [training: 0.0968972269344987 | validation: 0.2759949580282507]
	TIME [epoch: 42.4 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09617194377837276		[learning rate: 0.0010352]
	Learning Rate: 0.00103524
	LOSS [training: 0.09617194377837276 | validation: 0.25645191854983385]
	TIME [epoch: 42.4 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10370779878146781		[learning rate: 0.001032]
	Learning Rate: 0.00103199
	LOSS [training: 0.10370779878146781 | validation: 0.26862866020698367]
	TIME [epoch: 42.3 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09400023376764131		[learning rate: 0.0010287]
	Learning Rate: 0.00102874
	LOSS [training: 0.09400023376764131 | validation: 0.26702083476352717]
	TIME [epoch: 42.3 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12139453698864813		[learning rate: 0.0010255]
	Learning Rate: 0.00102551
	LOSS [training: 0.12139453698864813 | validation: 0.28154398064404396]
	TIME [epoch: 42.4 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09935053656169714		[learning rate: 0.0010223]
	Learning Rate: 0.00102229
	LOSS [training: 0.09935053656169714 | validation: 0.25224670323218706]
	TIME [epoch: 42.4 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11377026300370696		[learning rate: 0.0010191]
	Learning Rate: 0.00101907
	LOSS [training: 0.11377026300370696 | validation: 0.2664453502545745]
	TIME [epoch: 42.3 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10918821375348382		[learning rate: 0.0010159]
	Learning Rate: 0.00101587
	LOSS [training: 0.10918821375348382 | validation: 0.25728260178576856]
	TIME [epoch: 42.3 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1070242348406478		[learning rate: 0.0010127]
	Learning Rate: 0.00101268
	LOSS [training: 0.1070242348406478 | validation: 0.27875542990472285]
	TIME [epoch: 42.4 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10773378319743768		[learning rate: 0.0010095]
	Learning Rate: 0.00100949
	LOSS [training: 0.10773378319743768 | validation: 0.24899647079275292]
	TIME [epoch: 42.3 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0936725736442986		[learning rate: 0.0010063]
	Learning Rate: 0.00100632
	LOSS [training: 0.0936725736442986 | validation: 0.2900453572580644]
	TIME [epoch: 42.3 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10735105403006305		[learning rate: 0.0010032]
	Learning Rate: 0.00100315
	LOSS [training: 0.10735105403006305 | validation: 0.2538713174786909]
	TIME [epoch: 42.3 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09561620054580092		[learning rate: 0.001]
	Learning Rate: 0.001
	LOSS [training: 0.09561620054580092 | validation: 0.2645104063782113]
	TIME [epoch: 42.4 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0986221550127967		[learning rate: 0.00099686]
	Learning Rate: 0.000996856
	LOSS [training: 0.0986221550127967 | validation: 0.25740265437473847]
	TIME [epoch: 42.4 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10600134585517126		[learning rate: 0.00099372]
	Learning Rate: 0.000993722
	LOSS [training: 0.10600134585517126 | validation: 0.2628984034557399]
	TIME [epoch: 42.3 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09581710977900015		[learning rate: 0.0009906]
	Learning Rate: 0.000990598
	LOSS [training: 0.09581710977900015 | validation: 0.28807496618674827]
	TIME [epoch: 42.3 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09365333274754983		[learning rate: 0.00098748]
	Learning Rate: 0.000987484
	LOSS [training: 0.09365333274754983 | validation: 0.2945979220496433]
	TIME [epoch: 42.3 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11652149991247164		[learning rate: 0.00098438]
	Learning Rate: 0.000984379
	LOSS [training: 0.11652149991247164 | validation: 0.2579081743933488]
	TIME [epoch: 42.3 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09385905723994009		[learning rate: 0.00098128]
	Learning Rate: 0.000981284
	LOSS [training: 0.09385905723994009 | validation: 0.25155795527439045]
	TIME [epoch: 42.3 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1040519514880586		[learning rate: 0.0009782]
	Learning Rate: 0.000978199
	LOSS [training: 0.1040519514880586 | validation: 0.2655023339323047]
	TIME [epoch: 42.4 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09555246901239348		[learning rate: 0.00097512]
	Learning Rate: 0.000975124
	LOSS [training: 0.09555246901239348 | validation: 0.2638516077609633]
	TIME [epoch: 42.4 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10529534542328145		[learning rate: 0.00097206]
	Learning Rate: 0.000972058
	LOSS [training: 0.10529534542328145 | validation: 0.3086087407006748]
	TIME [epoch: 42.4 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10408668942319986		[learning rate: 0.000969]
	Learning Rate: 0.000969002
	LOSS [training: 0.10408668942319986 | validation: 0.2729619540622639]
	TIME [epoch: 42.3 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10534843785034174		[learning rate: 0.00096596]
	Learning Rate: 0.000965956
	LOSS [training: 0.10534843785034174 | validation: 0.26245354999046916]
	TIME [epoch: 42.3 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10576255826059777		[learning rate: 0.00096292]
	Learning Rate: 0.000962919
	LOSS [training: 0.10576255826059777 | validation: 0.2987243972300083]
	TIME [epoch: 42.3 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0943182736908537		[learning rate: 0.00095989]
	Learning Rate: 0.000959892
	LOSS [training: 0.0943182736908537 | validation: 0.2738507157628288]
	TIME [epoch: 42.4 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09678707718234611		[learning rate: 0.00095687]
	Learning Rate: 0.000956874
	LOSS [training: 0.09678707718234611 | validation: 0.29917478066583525]
	TIME [epoch: 42.3 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09610123995744782		[learning rate: 0.00095387]
	Learning Rate: 0.000953866
	LOSS [training: 0.09610123995744782 | validation: 0.2669499158302647]
	TIME [epoch: 42.3 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10332999418222068		[learning rate: 0.00095087]
	Learning Rate: 0.000950867
	LOSS [training: 0.10332999418222068 | validation: 0.2685662064221113]
	TIME [epoch: 42.3 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10246281374055391		[learning rate: 0.00094788]
	Learning Rate: 0.000947877
	LOSS [training: 0.10246281374055391 | validation: 0.25775487714625095]
	TIME [epoch: 42.4 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1000387362135537		[learning rate: 0.0009449]
	Learning Rate: 0.000944897
	LOSS [training: 0.1000387362135537 | validation: 0.26564366220248103]
	TIME [epoch: 42.3 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09447841117575125		[learning rate: 0.00094193]
	Learning Rate: 0.000941927
	LOSS [training: 0.09447841117575125 | validation: 0.2841041786142124]
	TIME [epoch: 42.3 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11046391980632572		[learning rate: 0.00093897]
	Learning Rate: 0.000938965
	LOSS [training: 0.11046391980632572 | validation: 0.2570722626361521]
	TIME [epoch: 42.3 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09427130763283527		[learning rate: 0.00093601]
	Learning Rate: 0.000936013
	LOSS [training: 0.09427130763283527 | validation: 0.27358719632789386]
	TIME [epoch: 42.4 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1011558294267209		[learning rate: 0.00093307]
	Learning Rate: 0.000933071
	LOSS [training: 0.1011558294267209 | validation: 0.26520987024006903]
	TIME [epoch: 42.3 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11119939268156279		[learning rate: 0.00093014]
	Learning Rate: 0.000930137
	LOSS [training: 0.11119939268156279 | validation: 0.2807010720214877]
	TIME [epoch: 42.3 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09479628222729151		[learning rate: 0.00092721]
	Learning Rate: 0.000927213
	LOSS [training: 0.09479628222729151 | validation: 0.2661667701698]
	TIME [epoch: 42.3 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11192173114063726		[learning rate: 0.0009243]
	Learning Rate: 0.000924298
	LOSS [training: 0.11192173114063726 | validation: 0.28462765518800165]
	TIME [epoch: 42.4 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11021227769862005		[learning rate: 0.00092139]
	Learning Rate: 0.000921392
	LOSS [training: 0.11021227769862005 | validation: 0.2923928980674808]
	TIME [epoch: 42.4 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10068393619970269		[learning rate: 0.0009185]
	Learning Rate: 0.000918495
	LOSS [training: 0.10068393619970269 | validation: 0.26647179281923977]
	TIME [epoch: 42.4 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09679582782162277		[learning rate: 0.00091561]
	Learning Rate: 0.000915607
	LOSS [training: 0.09679582782162277 | validation: 0.25563263802390007]
	TIME [epoch: 42.3 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10222847870768258		[learning rate: 0.00091273]
	Learning Rate: 0.000912729
	LOSS [training: 0.10222847870768258 | validation: 0.2918290745952583]
	TIME [epoch: 42.3 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09833904199750029		[learning rate: 0.00090986]
	Learning Rate: 0.000909859
	LOSS [training: 0.09833904199750029 | validation: 0.2802663675019266]
	TIME [epoch: 42.3 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10097524636047162		[learning rate: 0.000907]
	Learning Rate: 0.000906999
	LOSS [training: 0.10097524636047162 | validation: 0.2945906646227089]
	TIME [epoch: 42.4 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09583066014158174		[learning rate: 0.00090415]
	Learning Rate: 0.000904148
	LOSS [training: 0.09583066014158174 | validation: 0.25456714692321036]
	TIME [epoch: 42.3 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09474058475371347		[learning rate: 0.00090131]
	Learning Rate: 0.000901305
	LOSS [training: 0.09474058475371347 | validation: 0.26421902640627026]
	TIME [epoch: 42.3 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10397946499328867		[learning rate: 0.00089847]
	Learning Rate: 0.000898472
	LOSS [training: 0.10397946499328867 | validation: 0.26874752025660875]
	TIME [epoch: 42.3 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0992576241162142		[learning rate: 0.00089565]
	Learning Rate: 0.000895647
	LOSS [training: 0.0992576241162142 | validation: 0.270427094047093]
	TIME [epoch: 42.3 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10314933663138334		[learning rate: 0.00089283]
	Learning Rate: 0.000892831
	LOSS [training: 0.10314933663138334 | validation: 0.2776256246685963]
	TIME [epoch: 42.3 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11475991351321857		[learning rate: 0.00089002]
	Learning Rate: 0.000890024
	LOSS [training: 0.11475991351321857 | validation: 0.27359716555109065]
	TIME [epoch: 42.3 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09685105939659913		[learning rate: 0.00088723]
	Learning Rate: 0.000887226
	LOSS [training: 0.09685105939659913 | validation: 0.2708549975185816]
	TIME [epoch: 42.2 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12311668874223147		[learning rate: 0.00088444]
	Learning Rate: 0.000884437
	LOSS [training: 0.12311668874223147 | validation: 0.2682306217673212]
	TIME [epoch: 42.2 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09947158430317624		[learning rate: 0.00088166]
	Learning Rate: 0.000881656
	LOSS [training: 0.09947158430317624 | validation: 0.33477422228280795]
	TIME [epoch: 42.3 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10604558036774098		[learning rate: 0.00087888]
	Learning Rate: 0.000878884
	LOSS [training: 0.10604558036774098 | validation: 0.2545387252950731]
	TIME [epoch: 42.2 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09745986108389981		[learning rate: 0.00087612]
	Learning Rate: 0.000876121
	LOSS [training: 0.09745986108389981 | validation: 0.26047069415386803]
	TIME [epoch: 42.2 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09825324216322885		[learning rate: 0.00087337]
	Learning Rate: 0.000873366
	LOSS [training: 0.09825324216322885 | validation: 0.27613262811738515]
	TIME [epoch: 42.3 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09521698458497178		[learning rate: 0.00087062]
	Learning Rate: 0.000870621
	LOSS [training: 0.09521698458497178 | validation: 0.2585471327094769]
	TIME [epoch: 42.3 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11485497789944965		[learning rate: 0.00086788]
	Learning Rate: 0.000867884
	LOSS [training: 0.11485497789944965 | validation: 0.2750597062011863]
	TIME [epoch: 42.3 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09803765140177545		[learning rate: 0.00086516]
	Learning Rate: 0.000865155
	LOSS [training: 0.09803765140177545 | validation: 0.2593146787603864]
	TIME [epoch: 42.3 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11849366557463409		[learning rate: 0.00086244]
	Learning Rate: 0.000862435
	LOSS [training: 0.11849366557463409 | validation: 0.27381335346700336]
	TIME [epoch: 42.3 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10441073439553644		[learning rate: 0.00085972]
	Learning Rate: 0.000859724
	LOSS [training: 0.10441073439553644 | validation: 0.25715935044386706]
	TIME [epoch: 42.2 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09751349849436038		[learning rate: 0.00085702]
	Learning Rate: 0.000857021
	LOSS [training: 0.09751349849436038 | validation: 0.26623678469430767]
	TIME [epoch: 42.2 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09878854638769696		[learning rate: 0.00085433]
	Learning Rate: 0.000854327
	LOSS [training: 0.09878854638769696 | validation: 0.2620333897286196]
	TIME [epoch: 42.2 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09599319942878871		[learning rate: 0.00085164]
	Learning Rate: 0.000851641
	LOSS [training: 0.09599319942878871 | validation: 0.28483279279621676]
	TIME [epoch: 42.2 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09506649000395212		[learning rate: 0.00084896]
	Learning Rate: 0.000848963
	LOSS [training: 0.09506649000395212 | validation: 0.3073144430454019]
	TIME [epoch: 42.2 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10902850054239328		[learning rate: 0.00084629]
	Learning Rate: 0.000846294
	LOSS [training: 0.10902850054239328 | validation: 0.25699847433499584]
	TIME [epoch: 42.2 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09544994562476805		[learning rate: 0.00084363]
	Learning Rate: 0.000843634
	LOSS [training: 0.09544994562476805 | validation: 0.2737687789762991]
	TIME [epoch: 42.3 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09986493943346683		[learning rate: 0.00084098]
	Learning Rate: 0.000840981
	LOSS [training: 0.09986493943346683 | validation: 0.26465208390403266]
	TIME [epoch: 42.3 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0956903194017279		[learning rate: 0.00083834]
	Learning Rate: 0.000838337
	LOSS [training: 0.0956903194017279 | validation: 0.2655114915700693]
	TIME [epoch: 42.3 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09479454369893733		[learning rate: 0.0008357]
	Learning Rate: 0.000835702
	LOSS [training: 0.09479454369893733 | validation: 0.26488494806209856]
	TIME [epoch: 42.3 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09743321101141725		[learning rate: 0.00083307]
	Learning Rate: 0.000833074
	LOSS [training: 0.09743321101141725 | validation: 0.26694249747981036]
	TIME [epoch: 42.3 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09959192048259749		[learning rate: 0.00083046]
	Learning Rate: 0.000830455
	LOSS [training: 0.09959192048259749 | validation: 0.2982806835115204]
	TIME [epoch: 42.3 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0970201236021474		[learning rate: 0.00082784]
	Learning Rate: 0.000827844
	LOSS [training: 0.0970201236021474 | validation: 0.2719228045065185]
	TIME [epoch: 42.3 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11807840063287078		[learning rate: 0.00082524]
	Learning Rate: 0.000825242
	LOSS [training: 0.11807840063287078 | validation: 0.249194199596379]
	TIME [epoch: 42.3 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09579283438440758		[learning rate: 0.00082265]
	Learning Rate: 0.000822647
	LOSS [training: 0.09579283438440758 | validation: 0.27916173771503633]
	TIME [epoch: 42.3 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09620036181416632		[learning rate: 0.00082006]
	Learning Rate: 0.000820061
	LOSS [training: 0.09620036181416632 | validation: 0.2786225411291962]
	TIME [epoch: 42.3 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10235068400725074		[learning rate: 0.00081748]
	Learning Rate: 0.000817483
	LOSS [training: 0.10235068400725074 | validation: 0.2648178761896317]
	TIME [epoch: 42.3 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09652818605166105		[learning rate: 0.00081491]
	Learning Rate: 0.000814913
	LOSS [training: 0.09652818605166105 | validation: 0.2572722660677578]
	TIME [epoch: 42.3 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10973170461177023		[learning rate: 0.00081235]
	Learning Rate: 0.000812351
	LOSS [training: 0.10973170461177023 | validation: 0.2854035297571931]
	TIME [epoch: 42.3 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_vlargesamp_20240719_165939/states/model_facs_v4_dec2b_2dpca_vlargesamp_835.pth
Halted early. No improvement in validation loss for 200 epochs.
Finished training in 23186.092 seconds.
