Args:
Namespace(name='model_facs_v3_dec2b_2dpca_v12', outdir='out/model_training/model_facs_v3_dec2b_2dpca_v12', training_data='data/training_data/facs_v3/pca/dec2_fitonsubset/transition2_subset_ce_pn_m_pc12/training', validation_data='data/training_data/facs_v3/pca/dec2_fitonsubset/transition2_subset_ce_pn_m_pc12/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=10, batch_size=50, patience=200, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, quadratic_a=1.0, quadratic_b=1.0, ndims=2, nparams=2, nsigs=2, ncells=800, ncells_sample=800, model_do_sample=False, dt=0.005, dt_schedule='stepped', dt_schedule_bounds=[50, 500, 1000], dt_schedule_scales=[0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', kernel='multiscale', bw_range=[0.2, 0.5, 0.9, 1.1, 1.3, 1.5, 2.0], optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 4274620194

Training model...

Saving initial model state to: out/model_training/model_facs_v3_dec2b_2dpca_v12_20240716_190535/states/model_facs_v3_dec2b_2dpca_v12_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0666300013648773		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0666300013648773 | validation: 0.952198854575831]
	TIME [epoch: 33.5 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v12_20240716_190535/states/model_facs_v3_dec2b_2dpca_v12_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7338813645745428		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7338813645745428 | validation: 0.814801165584005]
	TIME [epoch: 6.11 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v12_20240716_190535/states/model_facs_v3_dec2b_2dpca_v12_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5908336074961594		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5908336074961594 | validation: 0.7932795049334664]
	TIME [epoch: 6.11 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v12_20240716_190535/states/model_facs_v3_dec2b_2dpca_v12_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5272539131264401		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5272539131264401 | validation: 0.7559220438982301]
	TIME [epoch: 6.09 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v12_20240716_190535/states/model_facs_v3_dec2b_2dpca_v12_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5236599171911311		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5236599171911311 | validation: 0.741704044564626]
	TIME [epoch: 6.1 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v12_20240716_190535/states/model_facs_v3_dec2b_2dpca_v12_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5120913460720223		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5120913460720223 | validation: 0.7057834269430863]
	TIME [epoch: 6.04 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v12_20240716_190535/states/model_facs_v3_dec2b_2dpca_v12_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48116151221239994		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.48116151221239994 | validation: 0.6793884197361253]
	TIME [epoch: 6.07 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v12_20240716_190535/states/model_facs_v3_dec2b_2dpca_v12_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45808382284125876		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.45808382284125876 | validation: 0.7172458162518851]
	TIME [epoch: 6.07 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.489049247124262		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.489049247124262 | validation: 0.784850992828371]
	TIME [epoch: 6.12 sec]
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4199004404144152		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4199004404144152 | validation: 0.7324184221623296]
	TIME [epoch: 6.09 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4916789531547991		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4916789531547991 | validation: 0.610218837391774]
	TIME [epoch: 6.07 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v12_20240716_190535/states/model_facs_v3_dec2b_2dpca_v12_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.457877496212592		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.457877496212592 | validation: 0.5866535106850069]
	TIME [epoch: 6.07 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v12_20240716_190535/states/model_facs_v3_dec2b_2dpca_v12_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36094850638497966		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.36094850638497966 | validation: 0.5609686674673855]
	TIME [epoch: 6.06 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v12_20240716_190535/states/model_facs_v3_dec2b_2dpca_v12_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34427749381136696		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.34427749381136696 | validation: 0.5612930264894529]
	TIME [epoch: 6.05 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44073538033240456		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.44073538033240456 | validation: 0.5663309905378474]
	TIME [epoch: 6.06 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3341145042365796		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3341145042365796 | validation: 0.573288019317771]
	TIME [epoch: 6.08 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.344818999711114		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.344818999711114 | validation: 0.5466438565645579]
	TIME [epoch: 6.07 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v12_20240716_190535/states/model_facs_v3_dec2b_2dpca_v12_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31836366464042964		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.31836366464042964 | validation: 0.5092270364550064]
	TIME [epoch: 6.06 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v12_20240716_190535/states/model_facs_v3_dec2b_2dpca_v12_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32238764260799874		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.32238764260799874 | validation: 0.5247572874814951]
	TIME [epoch: 6.05 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3289698644327471		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3289698644327471 | validation: 0.5053829416164435]
	TIME [epoch: 6.05 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v12_20240716_190535/states/model_facs_v3_dec2b_2dpca_v12_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30062638201599945		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.30062638201599945 | validation: 0.5370596238166656]
	TIME [epoch: 6.08 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3334957798931155		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3334957798931155 | validation: 0.5513829506053917]
	TIME [epoch: 6.08 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3583498463478948		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3583498463478948 | validation: 0.48464530329542527]
	TIME [epoch: 6.08 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v12_20240716_190535/states/model_facs_v3_dec2b_2dpca_v12_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2837334893684785		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2837334893684785 | validation: 0.5325506169225824]
	TIME [epoch: 6.07 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3187255953354359		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3187255953354359 | validation: 0.503372331022393]
	TIME [epoch: 6.08 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3079687297510285		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3079687297510285 | validation: 0.5664952060704387]
	TIME [epoch: 6.08 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28813275923357007		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.28813275923357007 | validation: 0.6218429677273458]
	TIME [epoch: 6.09 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33264380080184885		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.33264380080184885 | validation: 0.4686389787717502]
	TIME [epoch: 6.08 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v12_20240716_190535/states/model_facs_v3_dec2b_2dpca_v12_28.pth
	Model improved!!!
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3060940074376942		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3060940074376942 | validation: 0.46598594559098966]
	TIME [epoch: 6.08 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v12_20240716_190535/states/model_facs_v3_dec2b_2dpca_v12_29.pth
	Model improved!!!
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28431645907688907		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.28431645907688907 | validation: 0.5162727618423097]
	TIME [epoch: 6.1 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2877060913939986		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2877060913939986 | validation: 0.46321525120985063]
	TIME [epoch: 6.1 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v12_20240716_190535/states/model_facs_v3_dec2b_2dpca_v12_31.pth
	Model improved!!!
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31951432501419424		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.31951432501419424 | validation: 0.512818731102668]
	TIME [epoch: 6.11 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2962430310229935		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2962430310229935 | validation: 0.4996363922869057]
	TIME [epoch: 6.12 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3030169515561234		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3030169515561234 | validation: 0.46195624819284364]
	TIME [epoch: 6.1 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v12_20240716_190535/states/model_facs_v3_dec2b_2dpca_v12_34.pth
	Model improved!!!
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2867468169106237		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2867468169106237 | validation: 0.5820261753503211]
	TIME [epoch: 6.09 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32970468072101794		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.32970468072101794 | validation: 0.46388117230542875]
	TIME [epoch: 6.11 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23920864012521628		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23920864012521628 | validation: 0.5049886068450704]
	TIME [epoch: 6.1 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2877815545857323		[learning rate: 0.0099882]
	Learning Rate: 0.0099882
	LOSS [training: 0.2877815545857323 | validation: 0.541162529936994]
	TIME [epoch: 6.12 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3110458875634962		[learning rate: 0.0099411]
	Learning Rate: 0.00994113
	LOSS [training: 0.3110458875634962 | validation: 0.4782524026609752]
	TIME [epoch: 6.11 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25244770504941166		[learning rate: 0.0098943]
	Learning Rate: 0.00989429
	LOSS [training: 0.25244770504941166 | validation: 0.48041182185922116]
	TIME [epoch: 6.11 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.252758798463585		[learning rate: 0.0098477]
	Learning Rate: 0.00984767
	LOSS [training: 0.252758798463585 | validation: 0.4862173498930775]
	TIME [epoch: 6.1 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2674876035234418		[learning rate: 0.0098013]
	Learning Rate: 0.00980126
	LOSS [training: 0.2674876035234418 | validation: 0.4636638683650387]
	TIME [epoch: 6.1 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30810978288239943		[learning rate: 0.0097551]
	Learning Rate: 0.00975508
	LOSS [training: 0.30810978288239943 | validation: 0.467360620404264]
	TIME [epoch: 6.1 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26751556988074904		[learning rate: 0.0097091]
	Learning Rate: 0.00970911
	LOSS [training: 0.26751556988074904 | validation: 0.466300301230024]
	TIME [epoch: 6.11 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2587237980206733		[learning rate: 0.0096634]
	Learning Rate: 0.00966336
	LOSS [training: 0.2587237980206733 | validation: 0.43414554692879853]
	TIME [epoch: 6.11 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v12_20240716_190535/states/model_facs_v3_dec2b_2dpca_v12_45.pth
	Model improved!!!
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2463716855000282		[learning rate: 0.0096178]
	Learning Rate: 0.00961783
	LOSS [training: 0.2463716855000282 | validation: 0.423854222250998]
	TIME [epoch: 6.1 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v12_20240716_190535/states/model_facs_v3_dec2b_2dpca_v12_46.pth
	Model improved!!!
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2422982397751524		[learning rate: 0.0095725]
	Learning Rate: 0.00957251
	LOSS [training: 0.2422982397751524 | validation: 0.4797965028745421]
	TIME [epoch: 6.1 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.300021234596782		[learning rate: 0.0095274]
	Learning Rate: 0.0095274
	LOSS [training: 0.300021234596782 | validation: 0.4568462492467478]
	TIME [epoch: 6.09 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22096617629474877		[learning rate: 0.0094825]
	Learning Rate: 0.0094825
	LOSS [training: 0.22096617629474877 | validation: 0.4771509008700131]
	TIME [epoch: 6.09 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2532340746322736		[learning rate: 0.0094378]
	Learning Rate: 0.00943782
	LOSS [training: 0.2532340746322736 | validation: 0.41610054567871463]
	TIME [epoch: 6.16 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v12_20240716_190535/states/model_facs_v3_dec2b_2dpca_v12_50.pth
	Model improved!!!
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2319785473007432		[learning rate: 0.0093933]
	Learning Rate: 0.00939335
	LOSS [training: 0.2319785473007432 | validation: 0.4047363296078302]
	TIME [epoch: 37.3 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v12_20240716_190535/states/model_facs_v3_dec2b_2dpca_v12_51.pth
	Model improved!!!
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23895962638559365		[learning rate: 0.0093491]
	Learning Rate: 0.00934909
	LOSS [training: 0.23895962638559365 | validation: 0.4322515267476659]
	TIME [epoch: 11.7 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2876478511261864		[learning rate: 0.009305]
	Learning Rate: 0.00930503
	LOSS [training: 0.2876478511261864 | validation: 0.473660658906581]
	TIME [epoch: 11.7 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25511740978057634		[learning rate: 0.0092612]
	Learning Rate: 0.00926119
	LOSS [training: 0.25511740978057634 | validation: 0.39403567347425994]
	TIME [epoch: 11.7 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v12_20240716_190535/states/model_facs_v3_dec2b_2dpca_v12_54.pth
	Model improved!!!
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25626408411323043		[learning rate: 0.0092175]
	Learning Rate: 0.00921755
	LOSS [training: 0.25626408411323043 | validation: 0.4331711914361464]
	TIME [epoch: 11.6 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24216627932233334		[learning rate: 0.0091741]
	Learning Rate: 0.00917411
	LOSS [training: 0.24216627932233334 | validation: 0.38922869155332324]
	TIME [epoch: 11.6 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v12_20240716_190535/states/model_facs_v3_dec2b_2dpca_v12_56.pth
	Model improved!!!
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2687665421422775		[learning rate: 0.0091309]
	Learning Rate: 0.00913088
	LOSS [training: 0.2687665421422775 | validation: 0.46335889641404626]
	TIME [epoch: 11.6 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22015698390594612		[learning rate: 0.0090879]
	Learning Rate: 0.00908786
	LOSS [training: 0.22015698390594612 | validation: 0.49624954875319205]
	TIME [epoch: 11.7 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30997728273452574		[learning rate: 0.009045]
	Learning Rate: 0.00904503
	LOSS [training: 0.30997728273452574 | validation: 0.4477190114528477]
	TIME [epoch: 11.7 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23811752915699907		[learning rate: 0.0090024]
	Learning Rate: 0.00900241
	LOSS [training: 0.23811752915699907 | validation: 0.39025227618440006]
	TIME [epoch: 11.7 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22212030947113956		[learning rate: 0.00896]
	Learning Rate: 0.00895999
	LOSS [training: 0.22212030947113956 | validation: 0.4290980926492382]
	TIME [epoch: 11.7 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22737989202867043		[learning rate: 0.0089178]
	Learning Rate: 0.00891777
	LOSS [training: 0.22737989202867043 | validation: 0.42581880449975107]
	TIME [epoch: 11.7 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2327829070360784		[learning rate: 0.0088758]
	Learning Rate: 0.00887575
	LOSS [training: 0.2327829070360784 | validation: 0.42180796453046787]
	TIME [epoch: 11.7 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2279010274971533		[learning rate: 0.0088339]
	Learning Rate: 0.00883393
	LOSS [training: 0.2279010274971533 | validation: 0.3720870943422797]
	TIME [epoch: 11.7 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v12_20240716_190535/states/model_facs_v3_dec2b_2dpca_v12_64.pth
	Model improved!!!
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22678421587291303		[learning rate: 0.0087923]
	Learning Rate: 0.0087923
	LOSS [training: 0.22678421587291303 | validation: 0.6252026770011948]
	TIME [epoch: 11.7 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2755021536541522		[learning rate: 0.0087509]
	Learning Rate: 0.00875087
	LOSS [training: 0.2755021536541522 | validation: 0.39894212162681103]
	TIME [epoch: 11.7 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2713585107012309		[learning rate: 0.0087096]
	Learning Rate: 0.00870964
	LOSS [training: 0.2713585107012309 | validation: 0.42478099076694675]
	TIME [epoch: 11.7 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.221205009382238		[learning rate: 0.0086686]
	Learning Rate: 0.00866859
	LOSS [training: 0.221205009382238 | validation: 0.40898862698500593]
	TIME [epoch: 11.7 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23317535693326125		[learning rate: 0.0086277]
	Learning Rate: 0.00862775
	LOSS [training: 0.23317535693326125 | validation: 0.35529378789394317]
	TIME [epoch: 11.7 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v12_20240716_190535/states/model_facs_v3_dec2b_2dpca_v12_69.pth
	Model improved!!!
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2412544438793015		[learning rate: 0.0085871]
	Learning Rate: 0.00858709
	LOSS [training: 0.2412544438793015 | validation: 0.49901624151668006]
	TIME [epoch: 11.7 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24149337248786476		[learning rate: 0.0085466]
	Learning Rate: 0.00854663
	LOSS [training: 0.24149337248786476 | validation: 0.4526557928596327]
	TIME [epoch: 11.7 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27700875118177076		[learning rate: 0.0085064]
	Learning Rate: 0.00850636
	LOSS [training: 0.27700875118177076 | validation: 0.543117289953884]
	TIME [epoch: 11.7 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26659736008198837		[learning rate: 0.0084663]
	Learning Rate: 0.00846627
	LOSS [training: 0.26659736008198837 | validation: 0.35873506824364754]
	TIME [epoch: 11.7 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20885210341264748		[learning rate: 0.0084264]
	Learning Rate: 0.00842638
	LOSS [training: 0.20885210341264748 | validation: 0.46143629962353444]
	TIME [epoch: 11.7 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21866494808830783		[learning rate: 0.0083867]
	Learning Rate: 0.00838667
	LOSS [training: 0.21866494808830783 | validation: 0.3839407670871329]
	TIME [epoch: 11.7 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18778680732465705		[learning rate: 0.0083472]
	Learning Rate: 0.00834715
	LOSS [training: 0.18778680732465705 | validation: 0.5050588068264937]
	TIME [epoch: 11.7 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24637262918234668		[learning rate: 0.0083078]
	Learning Rate: 0.00830782
	LOSS [training: 0.24637262918234668 | validation: 0.3619717045220561]
	TIME [epoch: 11.7 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21175881935942792		[learning rate: 0.0082687]
	Learning Rate: 0.00826867
	LOSS [training: 0.21175881935942792 | validation: 0.46267187338055593]
	TIME [epoch: 11.7 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23913186968828193		[learning rate: 0.0082297]
	Learning Rate: 0.00822971
	LOSS [training: 0.23913186968828193 | validation: 0.4113751205967493]
	TIME [epoch: 11.6 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24849826521800114		[learning rate: 0.0081909]
	Learning Rate: 0.00819093
	LOSS [training: 0.24849826521800114 | validation: 0.39185245800380664]
	TIME [epoch: 11.7 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20509418815406408		[learning rate: 0.0081523]
	Learning Rate: 0.00815233
	LOSS [training: 0.20509418815406408 | validation: 0.3728959028155949]
	TIME [epoch: 11.7 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1961307073802236		[learning rate: 0.0081139]
	Learning Rate: 0.00811392
	LOSS [training: 0.1961307073802236 | validation: 0.45950437111137465]
	TIME [epoch: 11.7 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24746696304465396		[learning rate: 0.0080757]
	Learning Rate: 0.00807569
	LOSS [training: 0.24746696304465396 | validation: 0.4396913637616001]
	TIME [epoch: 11.7 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26294303519324547		[learning rate: 0.0080376]
	Learning Rate: 0.00803763
	LOSS [training: 0.26294303519324547 | validation: 0.47786078610969307]
	TIME [epoch: 11.7 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24448791316238144		[learning rate: 0.0079998]
	Learning Rate: 0.00799976
	LOSS [training: 0.24448791316238144 | validation: 0.38458963555234493]
	TIME [epoch: 11.6 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21269974706181247		[learning rate: 0.0079621]
	Learning Rate: 0.00796206
	LOSS [training: 0.21269974706181247 | validation: 0.386978412776521]
	TIME [epoch: 11.7 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1830010061754783		[learning rate: 0.0079245]
	Learning Rate: 0.00792455
	LOSS [training: 0.1830010061754783 | validation: 0.3653616838431256]
	TIME [epoch: 11.7 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20369942613054276		[learning rate: 0.0078872]
	Learning Rate: 0.0078872
	LOSS [training: 0.20369942613054276 | validation: 0.34852825308335805]
	TIME [epoch: 11.7 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v12_20240716_190535/states/model_facs_v3_dec2b_2dpca_v12_88.pth
	Model improved!!!
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20855802175696758		[learning rate: 0.00785]
	Learning Rate: 0.00785004
	LOSS [training: 0.20855802175696758 | validation: 0.43481033707657146]
	TIME [epoch: 11.7 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20739237501679578		[learning rate: 0.007813]
	Learning Rate: 0.00781305
	LOSS [training: 0.20739237501679578 | validation: 0.3629423944928537]
	TIME [epoch: 11.7 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16982729351714768		[learning rate: 0.0077762]
	Learning Rate: 0.00777623
	LOSS [training: 0.16982729351714768 | validation: 0.36961171384088204]
	TIME [epoch: 11.7 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22681752350969928		[learning rate: 0.0077396]
	Learning Rate: 0.00773959
	LOSS [training: 0.22681752350969928 | validation: 0.543513345140836]
	TIME [epoch: 11.7 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27592080118828644		[learning rate: 0.0077031]
	Learning Rate: 0.00770312
	LOSS [training: 0.27592080118828644 | validation: 0.381581064688319]
	TIME [epoch: 11.7 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2175826412508467		[learning rate: 0.0076668]
	Learning Rate: 0.00766682
	LOSS [training: 0.2175826412508467 | validation: 0.3488815565023009]
	TIME [epoch: 11.7 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15625488051678396		[learning rate: 0.0076307]
	Learning Rate: 0.0076307
	LOSS [training: 0.15625488051678396 | validation: 0.4230146115069715]
	TIME [epoch: 11.7 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22825058324130235		[learning rate: 0.0075947]
	Learning Rate: 0.00759474
	LOSS [training: 0.22825058324130235 | validation: 0.3720175765819399]
	TIME [epoch: 11.7 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21194436752963453		[learning rate: 0.007559]
	Learning Rate: 0.00755895
	LOSS [training: 0.21194436752963453 | validation: 0.4178215104748944]
	TIME [epoch: 11.7 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19581922996632262		[learning rate: 0.0075233]
	Learning Rate: 0.00752333
	LOSS [training: 0.19581922996632262 | validation: 0.3904847124237736]
	TIME [epoch: 11.7 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.245039033382008		[learning rate: 0.0074879]
	Learning Rate: 0.00748788
	LOSS [training: 0.245039033382008 | validation: 0.39729892959486324]
	TIME [epoch: 11.7 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19600035345511346		[learning rate: 0.0074526]
	Learning Rate: 0.0074526
	LOSS [training: 0.19600035345511346 | validation: 0.3351915017910445]
	TIME [epoch: 11.7 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v12_20240716_190535/states/model_facs_v3_dec2b_2dpca_v12_100.pth
	Model improved!!!
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.186436323961492		[learning rate: 0.0074175]
	Learning Rate: 0.00741748
	LOSS [training: 0.186436323961492 | validation: 0.3681772319868185]
	TIME [epoch: 11.7 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19244091602258762		[learning rate: 0.0073825]
	Learning Rate: 0.00738253
	LOSS [training: 0.19244091602258762 | validation: 0.42177827194811246]
	TIME [epoch: 11.7 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2294041722513088		[learning rate: 0.0073477]
	Learning Rate: 0.00734774
	LOSS [training: 0.2294041722513088 | validation: 0.48408955850637064]
	TIME [epoch: 11.7 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23340390909688127		[learning rate: 0.0073131]
	Learning Rate: 0.00731312
	LOSS [training: 0.23340390909688127 | validation: 0.3328530919282753]
	TIME [epoch: 11.7 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v12_20240716_190535/states/model_facs_v3_dec2b_2dpca_v12_104.pth
	Model improved!!!
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19250265204572478		[learning rate: 0.0072787]
	Learning Rate: 0.00727866
	LOSS [training: 0.19250265204572478 | validation: 0.45615439277495734]
	TIME [epoch: 11.7 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2155010234647539		[learning rate: 0.0072444]
	Learning Rate: 0.00724436
	LOSS [training: 0.2155010234647539 | validation: 0.7004716830869828]
	TIME [epoch: 11.7 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24738066345026832		[learning rate: 0.0072102]
	Learning Rate: 0.00721022
	LOSS [training: 0.24738066345026832 | validation: 0.35256774961599735]
	TIME [epoch: 11.7 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18573859054221778		[learning rate: 0.0071762]
	Learning Rate: 0.00717625
	LOSS [training: 0.18573859054221778 | validation: 0.39503048654661305]
	TIME [epoch: 11.7 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20190809012228		[learning rate: 0.0071424]
	Learning Rate: 0.00714243
	LOSS [training: 0.20190809012228 | validation: 0.3414993035355591]
	TIME [epoch: 11.7 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18171283993591456		[learning rate: 0.0071088]
	Learning Rate: 0.00710878
	LOSS [training: 0.18171283993591456 | validation: 0.40034808706862635]
	TIME [epoch: 11.7 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1988945207094105		[learning rate: 0.0070753]
	Learning Rate: 0.00707528
	LOSS [training: 0.1988945207094105 | validation: 0.3394618097209078]
	TIME [epoch: 11.7 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19689152957859357		[learning rate: 0.0070419]
	Learning Rate: 0.00704194
	LOSS [training: 0.19689152957859357 | validation: 0.4071959237532366]
	TIME [epoch: 11.7 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21666503840340617		[learning rate: 0.0070088]
	Learning Rate: 0.00700876
	LOSS [training: 0.21666503840340617 | validation: 0.40328626588020494]
	TIME [epoch: 11.7 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23454420455287514		[learning rate: 0.0069757]
	Learning Rate: 0.00697573
	LOSS [training: 0.23454420455287514 | validation: 0.400893247524975]
	TIME [epoch: 11.7 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21293992819589502		[learning rate: 0.0069429]
	Learning Rate: 0.00694286
	LOSS [training: 0.21293992819589502 | validation: 0.4319890814958235]
	TIME [epoch: 11.7 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23648787719476433		[learning rate: 0.0069101]
	Learning Rate: 0.00691014
	LOSS [training: 0.23648787719476433 | validation: 0.35176753918755066]
	TIME [epoch: 11.7 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2147898154352037		[learning rate: 0.0068776]
	Learning Rate: 0.00687758
	LOSS [training: 0.2147898154352037 | validation: 0.3372940100512162]
	TIME [epoch: 11.7 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19361542656664446		[learning rate: 0.0068452]
	Learning Rate: 0.00684518
	LOSS [training: 0.19361542656664446 | validation: 0.3746441729759804]
	TIME [epoch: 11.7 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20583683843646738		[learning rate: 0.0068129]
	Learning Rate: 0.00681292
	LOSS [training: 0.20583683843646738 | validation: 0.36095819581880356]
	TIME [epoch: 11.7 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1780807878619421		[learning rate: 0.0067808]
	Learning Rate: 0.00678082
	LOSS [training: 0.1780807878619421 | validation: 0.393383614383911]
	TIME [epoch: 11.7 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1936397488083426		[learning rate: 0.0067489]
	Learning Rate: 0.00674887
	LOSS [training: 0.1936397488083426 | validation: 0.3606578739621723]
	TIME [epoch: 11.7 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21468164692371527		[learning rate: 0.0067171]
	Learning Rate: 0.00671706
	LOSS [training: 0.21468164692371527 | validation: 0.505387995310479]
	TIME [epoch: 11.7 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20114174955413605		[learning rate: 0.0066854]
	Learning Rate: 0.00668541
	LOSS [training: 0.20114174955413605 | validation: 0.3413901700087852]
	TIME [epoch: 11.7 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.180229969576286		[learning rate: 0.0066539]
	Learning Rate: 0.00665391
	LOSS [training: 0.180229969576286 | validation: 0.39244605229926577]
	TIME [epoch: 11.7 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20409970065141977		[learning rate: 0.0066226]
	Learning Rate: 0.00662256
	LOSS [training: 0.20409970065141977 | validation: 0.33195269542494404]
	TIME [epoch: 11.7 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v12_20240716_190535/states/model_facs_v3_dec2b_2dpca_v12_125.pth
	Model improved!!!
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19509938474055802		[learning rate: 0.0065913]
	Learning Rate: 0.00659135
	LOSS [training: 0.19509938474055802 | validation: 0.4731782030539589]
	TIME [epoch: 11.7 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19615928076121672		[learning rate: 0.0065603]
	Learning Rate: 0.00656029
	LOSS [training: 0.19615928076121672 | validation: 0.3299362958497758]
	TIME [epoch: 11.7 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v12_20240716_190535/states/model_facs_v3_dec2b_2dpca_v12_127.pth
	Model improved!!!
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17558425360803293		[learning rate: 0.0065294]
	Learning Rate: 0.00652938
	LOSS [training: 0.17558425360803293 | validation: 0.31484884734269625]
	TIME [epoch: 11.7 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v12_20240716_190535/states/model_facs_v3_dec2b_2dpca_v12_128.pth
	Model improved!!!
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18182875156834624		[learning rate: 0.0064986]
	Learning Rate: 0.00649861
	LOSS [training: 0.18182875156834624 | validation: 0.41677651491135714]
	TIME [epoch: 11.7 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21390445582911263		[learning rate: 0.006468]
	Learning Rate: 0.00646799
	LOSS [training: 0.21390445582911263 | validation: 0.3740568901501262]
	TIME [epoch: 11.7 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1694233379723205		[learning rate: 0.0064375]
	Learning Rate: 0.00643751
	LOSS [training: 0.1694233379723205 | validation: 0.3660808635914379]
	TIME [epoch: 11.7 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20324808138144007		[learning rate: 0.0064072]
	Learning Rate: 0.00640718
	LOSS [training: 0.20324808138144007 | validation: 0.4930476981996132]
	TIME [epoch: 11.7 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2328059093178614		[learning rate: 0.006377]
	Learning Rate: 0.00637698
	LOSS [training: 0.2328059093178614 | validation: 0.33109793833666795]
	TIME [epoch: 11.7 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17696608931952562		[learning rate: 0.0063469]
	Learning Rate: 0.00634694
	LOSS [training: 0.17696608931952562 | validation: 0.3823933378425047]
	TIME [epoch: 11.7 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17119657155837356		[learning rate: 0.006317]
	Learning Rate: 0.00631703
	LOSS [training: 0.17119657155837356 | validation: 0.36145905044989235]
	TIME [epoch: 11.7 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18857561398918654		[learning rate: 0.0062873]
	Learning Rate: 0.00628726
	LOSS [training: 0.18857561398918654 | validation: 0.36603132015287265]
	TIME [epoch: 11.7 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1944242035215451		[learning rate: 0.0062576]
	Learning Rate: 0.00625764
	LOSS [training: 0.1944242035215451 | validation: 0.3081801278562603]
	TIME [epoch: 11.7 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v12_20240716_190535/states/model_facs_v3_dec2b_2dpca_v12_137.pth
	Model improved!!!
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16350789785713185		[learning rate: 0.0062281]
	Learning Rate: 0.00622815
	LOSS [training: 0.16350789785713185 | validation: 0.36695599708415]
	TIME [epoch: 11.7 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18770899229519356		[learning rate: 0.0061988]
	Learning Rate: 0.0061988
	LOSS [training: 0.18770899229519356 | validation: 0.31591498906865756]
	TIME [epoch: 11.7 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16896898514832887		[learning rate: 0.0061696]
	Learning Rate: 0.00616959
	LOSS [training: 0.16896898514832887 | validation: 0.35940834646151726]
	TIME [epoch: 11.7 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18056285030992825		[learning rate: 0.0061405]
	Learning Rate: 0.00614052
	LOSS [training: 0.18056285030992825 | validation: 0.34346850518668337]
	TIME [epoch: 11.7 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19095697348974583		[learning rate: 0.0061116]
	Learning Rate: 0.00611158
	LOSS [training: 0.19095697348974583 | validation: 0.3993958581043242]
	TIME [epoch: 11.7 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20718603122376497		[learning rate: 0.0060828]
	Learning Rate: 0.00608279
	LOSS [training: 0.20718603122376497 | validation: 0.3957209837128405]
	TIME [epoch: 11.7 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19354895369042932		[learning rate: 0.0060541]
	Learning Rate: 0.00605412
	LOSS [training: 0.19354895369042932 | validation: 0.3473932925560648]
	TIME [epoch: 11.7 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17592606005589895		[learning rate: 0.0060256]
	Learning Rate: 0.0060256
	LOSS [training: 0.17592606005589895 | validation: 0.31832412073341154]
	TIME [epoch: 11.7 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1741406171719169		[learning rate: 0.0059972]
	Learning Rate: 0.0059972
	LOSS [training: 0.1741406171719169 | validation: 0.3237170824779551]
	TIME [epoch: 11.7 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21929873344145978		[learning rate: 0.0059689]
	Learning Rate: 0.00596894
	LOSS [training: 0.21929873344145978 | validation: 0.40455425893715313]
	TIME [epoch: 11.7 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1930751249857544		[learning rate: 0.0059408]
	Learning Rate: 0.00594082
	LOSS [training: 0.1930751249857544 | validation: 0.3941929260913007]
	TIME [epoch: 11.7 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21867773219837372		[learning rate: 0.0059128]
	Learning Rate: 0.00591282
	LOSS [training: 0.21867773219837372 | validation: 0.3432354364227255]
	TIME [epoch: 11.7 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1683259817323463		[learning rate: 0.005885]
	Learning Rate: 0.00588496
	LOSS [training: 0.1683259817323463 | validation: 0.34013598146788676]
	TIME [epoch: 11.7 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18174359192617565		[learning rate: 0.0058572]
	Learning Rate: 0.00585723
	LOSS [training: 0.18174359192617565 | validation: 0.3246405572187853]
	TIME [epoch: 11.7 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1690003618067048		[learning rate: 0.0058296]
	Learning Rate: 0.00582963
	LOSS [training: 0.1690003618067048 | validation: 0.40176332675880627]
	TIME [epoch: 11.7 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18116347707166175		[learning rate: 0.0058022]
	Learning Rate: 0.00580216
	LOSS [training: 0.18116347707166175 | validation: 0.3377086337788223]
	TIME [epoch: 11.7 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20685042023632397		[learning rate: 0.0057748]
	Learning Rate: 0.00577482
	LOSS [training: 0.20685042023632397 | validation: 0.37442294991762626]
	TIME [epoch: 11.7 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19991493230729965		[learning rate: 0.0057476]
	Learning Rate: 0.00574761
	LOSS [training: 0.19991493230729965 | validation: 0.3151689274929939]
	TIME [epoch: 11.7 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1653171571255672		[learning rate: 0.0057205]
	Learning Rate: 0.00572052
	LOSS [training: 0.1653171571255672 | validation: 0.33152367426516205]
	TIME [epoch: 11.7 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1694627739949851		[learning rate: 0.0056936]
	Learning Rate: 0.00569357
	LOSS [training: 0.1694627739949851 | validation: 0.3256856280400908]
	TIME [epoch: 11.7 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20506447345768597		[learning rate: 0.0056667]
	Learning Rate: 0.00566674
	LOSS [training: 0.20506447345768597 | validation: 0.3624688378428012]
	TIME [epoch: 11.7 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1721802233277343		[learning rate: 0.00564]
	Learning Rate: 0.00564004
	LOSS [training: 0.1721802233277343 | validation: 0.40866564620652296]
	TIME [epoch: 11.7 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16409209623127702		[learning rate: 0.0056135]
	Learning Rate: 0.00561346
	LOSS [training: 0.16409209623127702 | validation: 0.3179395452625482]
	TIME [epoch: 11.7 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16524939010803055		[learning rate: 0.005587]
	Learning Rate: 0.00558701
	LOSS [training: 0.16524939010803055 | validation: 0.3414829213067528]
	TIME [epoch: 11.7 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17232386662928317		[learning rate: 0.0055607]
	Learning Rate: 0.00556068
	LOSS [training: 0.17232386662928317 | validation: 0.3394832424318314]
	TIME [epoch: 11.7 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15939993323234078		[learning rate: 0.0055345]
	Learning Rate: 0.00553448
	LOSS [training: 0.15939993323234078 | validation: 0.37634557317315637]
	TIME [epoch: 11.7 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20217377937571912		[learning rate: 0.0055084]
	Learning Rate: 0.0055084
	LOSS [training: 0.20217377937571912 | validation: 0.310488037973986]
	TIME [epoch: 11.7 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17708494897109292		[learning rate: 0.0054824]
	Learning Rate: 0.00548245
	LOSS [training: 0.17708494897109292 | validation: 0.35400885222711553]
	TIME [epoch: 11.7 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1938710708585471		[learning rate: 0.0054566]
	Learning Rate: 0.00545661
	LOSS [training: 0.1938710708585471 | validation: 0.38589501951036115]
	TIME [epoch: 11.7 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19674539733709318		[learning rate: 0.0054309]
	Learning Rate: 0.0054309
	LOSS [training: 0.19674539733709318 | validation: 0.4093845963184213]
	TIME [epoch: 11.7 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2056212890818726		[learning rate: 0.0054053]
	Learning Rate: 0.00540531
	LOSS [training: 0.2056212890818726 | validation: 0.408035343533051]
	TIME [epoch: 11.7 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18242765469363553		[learning rate: 0.0053798]
	Learning Rate: 0.00537984
	LOSS [training: 0.18242765469363553 | validation: 0.322493698728959]
	TIME [epoch: 11.7 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18617720574896893		[learning rate: 0.0053545]
	Learning Rate: 0.00535449
	LOSS [training: 0.18617720574896893 | validation: 0.3665345058905236]
	TIME [epoch: 11.7 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2074516690320531		[learning rate: 0.0053293]
	Learning Rate: 0.00532926
	LOSS [training: 0.2074516690320531 | validation: 0.307066092354918]
	TIME [epoch: 11.7 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v12_20240716_190535/states/model_facs_v3_dec2b_2dpca_v12_171.pth
	Model improved!!!
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15059697734912425		[learning rate: 0.0053041]
	Learning Rate: 0.00530415
	LOSS [training: 0.15059697734912425 | validation: 0.32333398630692983]
	TIME [epoch: 11.7 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15540593412389775		[learning rate: 0.0052792]
	Learning Rate: 0.00527915
	LOSS [training: 0.15540593412389775 | validation: 0.4035702709993496]
	TIME [epoch: 11.7 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17881421191208058		[learning rate: 0.0052543]
	Learning Rate: 0.00525428
	LOSS [training: 0.17881421191208058 | validation: 0.3231028821832046]
	TIME [epoch: 11.7 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17731817223264146		[learning rate: 0.0052295]
	Learning Rate: 0.00522952
	LOSS [training: 0.17731817223264146 | validation: 0.3666324917122954]
	TIME [epoch: 11.7 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19363485802101207		[learning rate: 0.0052049]
	Learning Rate: 0.00520487
	LOSS [training: 0.19363485802101207 | validation: 0.4229057030254192]
	TIME [epoch: 11.7 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17690087378793906		[learning rate: 0.0051803]
	Learning Rate: 0.00518035
	LOSS [training: 0.17690087378793906 | validation: 0.33295072573585877]
	TIME [epoch: 11.7 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17872845945354782		[learning rate: 0.0051559]
	Learning Rate: 0.00515594
	LOSS [training: 0.17872845945354782 | validation: 0.31778095928729955]
	TIME [epoch: 11.7 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2025619308730859		[learning rate: 0.0051316]
	Learning Rate: 0.00513164
	LOSS [training: 0.2025619308730859 | validation: 0.3150778434503277]
	TIME [epoch: 11.7 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18451219599900723		[learning rate: 0.0051075]
	Learning Rate: 0.00510746
	LOSS [training: 0.18451219599900723 | validation: 0.37914627153809216]
	TIME [epoch: 11.7 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17544967365910166		[learning rate: 0.0050834]
	Learning Rate: 0.00508339
	LOSS [training: 0.17544967365910166 | validation: 0.33951290758891856]
	TIME [epoch: 11.7 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1594439566574927		[learning rate: 0.0050594]
	Learning Rate: 0.00505944
	LOSS [training: 0.1594439566574927 | validation: 0.36599031689793554]
	TIME [epoch: 11.7 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16383920830882767		[learning rate: 0.0050356]
	Learning Rate: 0.0050356
	LOSS [training: 0.16383920830882767 | validation: 0.3380983359625021]
	TIME [epoch: 11.7 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1529473658167897		[learning rate: 0.0050119]
	Learning Rate: 0.00501187
	LOSS [training: 0.1529473658167897 | validation: 0.356895511997692]
	TIME [epoch: 11.7 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.188499632646445		[learning rate: 0.0049883]
	Learning Rate: 0.00498826
	LOSS [training: 0.188499632646445 | validation: 0.33041717969135836]
	TIME [epoch: 11.7 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1538609554422801		[learning rate: 0.0049648]
	Learning Rate: 0.00496475
	LOSS [training: 0.1538609554422801 | validation: 0.33595580866017083]
	TIME [epoch: 11.7 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1718704739072378		[learning rate: 0.0049414]
	Learning Rate: 0.00494136
	LOSS [training: 0.1718704739072378 | validation: 0.43732775176944794]
	TIME [epoch: 11.7 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18458187476886306		[learning rate: 0.0049181]
	Learning Rate: 0.00491807
	LOSS [training: 0.18458187476886306 | validation: 0.38785143894843505]
	TIME [epoch: 11.7 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17695430530155307		[learning rate: 0.0048949]
	Learning Rate: 0.0048949
	LOSS [training: 0.17695430530155307 | validation: 0.37699321457362045]
	TIME [epoch: 11.7 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19563482182025746		[learning rate: 0.0048718]
	Learning Rate: 0.00487183
	LOSS [training: 0.19563482182025746 | validation: 0.30802507964590903]
	TIME [epoch: 11.7 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16666738199632156		[learning rate: 0.0048489]
	Learning Rate: 0.00484888
	LOSS [training: 0.16666738199632156 | validation: 0.33431618473931585]
	TIME [epoch: 11.7 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16922204717044137		[learning rate: 0.004826]
	Learning Rate: 0.00482603
	LOSS [training: 0.16922204717044137 | validation: 0.3085261017051471]
	TIME [epoch: 11.7 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16865433804930585		[learning rate: 0.0048033]
	Learning Rate: 0.00480329
	LOSS [training: 0.16865433804930585 | validation: 0.35376146720975843]
	TIME [epoch: 11.7 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.182229464750163		[learning rate: 0.0047807]
	Learning Rate: 0.00478065
	LOSS [training: 0.182229464750163 | validation: 0.392972448714847]
	TIME [epoch: 11.7 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1866225766440961		[learning rate: 0.0047581]
	Learning Rate: 0.00475813
	LOSS [training: 0.1866225766440961 | validation: 0.4367896793069153]
	TIME [epoch: 11.7 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18100704220987918		[learning rate: 0.0047357]
	Learning Rate: 0.0047357
	LOSS [training: 0.18100704220987918 | validation: 0.3782506663681544]
	TIME [epoch: 11.7 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17587718951224152		[learning rate: 0.0047134]
	Learning Rate: 0.00471339
	LOSS [training: 0.17587718951224152 | validation: 0.37150805045161245]
	TIME [epoch: 11.7 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15014506528341282		[learning rate: 0.0046912]
	Learning Rate: 0.00469118
	LOSS [training: 0.15014506528341282 | validation: 0.33912322853128957]
	TIME [epoch: 11.7 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18306841270988938		[learning rate: 0.0046691]
	Learning Rate: 0.00466907
	LOSS [training: 0.18306841270988938 | validation: 0.35948158692114035]
	TIME [epoch: 11.7 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.170323710652291		[learning rate: 0.0046471]
	Learning Rate: 0.00464707
	LOSS [training: 0.170323710652291 | validation: 0.34129041179527675]
	TIME [epoch: 11.7 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17603814141818902		[learning rate: 0.0046252]
	Learning Rate: 0.00462518
	LOSS [training: 0.17603814141818902 | validation: 0.42287852531153425]
	TIME [epoch: 11.7 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1801167244538563		[learning rate: 0.0046034]
	Learning Rate: 0.00460338
	LOSS [training: 0.1801167244538563 | validation: 0.3259427838722286]
	TIME [epoch: 11.7 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16362199721697385		[learning rate: 0.0045817]
	Learning Rate: 0.00458169
	LOSS [training: 0.16362199721697385 | validation: 0.3582113268214085]
	TIME [epoch: 11.7 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14386924467590909		[learning rate: 0.0045601]
	Learning Rate: 0.0045601
	LOSS [training: 0.14386924467590909 | validation: 0.36243012145990827]
	TIME [epoch: 11.7 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18579348240322435		[learning rate: 0.0045386]
	Learning Rate: 0.00453861
	LOSS [training: 0.18579348240322435 | validation: 0.32874412953183235]
	TIME [epoch: 11.7 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15916993716665734		[learning rate: 0.0045172]
	Learning Rate: 0.00451723
	LOSS [training: 0.15916993716665734 | validation: 0.3780230867338371]
	TIME [epoch: 11.7 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15605448031218966		[learning rate: 0.0044959]
	Learning Rate: 0.00449594
	LOSS [training: 0.15605448031218966 | validation: 0.3434978888793666]
	TIME [epoch: 11.7 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17156901585437012		[learning rate: 0.0044748]
	Learning Rate: 0.00447475
	LOSS [training: 0.17156901585437012 | validation: 0.3544436123472502]
	TIME [epoch: 11.7 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17348276649554348		[learning rate: 0.0044537]
	Learning Rate: 0.00445367
	LOSS [training: 0.17348276649554348 | validation: 0.3167647438513022]
	TIME [epoch: 11.7 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17060380282947782		[learning rate: 0.0044327]
	Learning Rate: 0.00443268
	LOSS [training: 0.17060380282947782 | validation: 0.32464921713700695]
	TIME [epoch: 11.7 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1665333989554925		[learning rate: 0.0044118]
	Learning Rate: 0.0044118
	LOSS [training: 0.1665333989554925 | validation: 0.34482260860695685]
	TIME [epoch: 11.7 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15778758308021595		[learning rate: 0.004391]
	Learning Rate: 0.00439101
	LOSS [training: 0.15778758308021595 | validation: 0.3735257964111705]
	TIME [epoch: 11.7 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16951964227125244		[learning rate: 0.0043703]
	Learning Rate: 0.00437032
	LOSS [training: 0.16951964227125244 | validation: 0.36402315976306]
	TIME [epoch: 11.7 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1939733325247887		[learning rate: 0.0043497]
	Learning Rate: 0.00434972
	LOSS [training: 0.1939733325247887 | validation: 0.3396206187980654]
	TIME [epoch: 11.7 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16653182395475857		[learning rate: 0.0043292]
	Learning Rate: 0.00432923
	LOSS [training: 0.16653182395475857 | validation: 0.3259894240222691]
	TIME [epoch: 11.7 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1412251247578606		[learning rate: 0.0043088]
	Learning Rate: 0.00430883
	LOSS [training: 0.1412251247578606 | validation: 0.3383887350785637]
	TIME [epoch: 11.7 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16249022594095347		[learning rate: 0.0042885]
	Learning Rate: 0.00428852
	LOSS [training: 0.16249022594095347 | validation: 0.40078683577972446]
	TIME [epoch: 11.7 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15949218318324318		[learning rate: 0.0042683]
	Learning Rate: 0.00426831
	LOSS [training: 0.15949218318324318 | validation: 0.3205794464431677]
	TIME [epoch: 11.7 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15767810925704534		[learning rate: 0.0042482]
	Learning Rate: 0.0042482
	LOSS [training: 0.15767810925704534 | validation: 0.3586251435276043]
	TIME [epoch: 11.7 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1746946729248345		[learning rate: 0.0042282]
	Learning Rate: 0.00422818
	LOSS [training: 0.1746946729248345 | validation: 0.326670272758243]
	TIME [epoch: 11.7 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1614173082743222		[learning rate: 0.0042083]
	Learning Rate: 0.00420826
	LOSS [training: 0.1614173082743222 | validation: 0.35762530467252307]
	TIME [epoch: 11.7 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18174541654171855		[learning rate: 0.0041884]
	Learning Rate: 0.00418843
	LOSS [training: 0.18174541654171855 | validation: 0.3424035892884617]
	TIME [epoch: 11.7 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1680244833554857		[learning rate: 0.0041687]
	Learning Rate: 0.00416869
	LOSS [training: 0.1680244833554857 | validation: 0.516639740527333]
	TIME [epoch: 11.7 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18988884776034454		[learning rate: 0.0041491]
	Learning Rate: 0.00414905
	LOSS [training: 0.18988884776034454 | validation: 0.3281794637986271]
	TIME [epoch: 11.7 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1718228832855236		[learning rate: 0.0041295]
	Learning Rate: 0.0041295
	LOSS [training: 0.1718228832855236 | validation: 0.3606830300367543]
	TIME [epoch: 11.7 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1694155161635933		[learning rate: 0.00411]
	Learning Rate: 0.00411004
	LOSS [training: 0.1694155161635933 | validation: 0.33283666276455987]
	TIME [epoch: 11.7 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15370866954302304		[learning rate: 0.0040907]
	Learning Rate: 0.00409067
	LOSS [training: 0.15370866954302304 | validation: 0.3836432266775418]
	TIME [epoch: 11.7 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1577378860660255		[learning rate: 0.0040714]
	Learning Rate: 0.0040714
	LOSS [training: 0.1577378860660255 | validation: 0.3276273921356097]
	TIME [epoch: 11.7 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16110685653645035		[learning rate: 0.0040522]
	Learning Rate: 0.00405221
	LOSS [training: 0.16110685653645035 | validation: 0.34217936070584276]
	TIME [epoch: 11.7 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14417590552297901		[learning rate: 0.0040331]
	Learning Rate: 0.00403312
	LOSS [training: 0.14417590552297901 | validation: 0.3609143647062508]
	TIME [epoch: 11.7 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1711634817445165		[learning rate: 0.0040141]
	Learning Rate: 0.00401411
	LOSS [training: 0.1711634817445165 | validation: 0.3281155184861764]
	TIME [epoch: 11.7 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1615500801114382		[learning rate: 0.0039952]
	Learning Rate: 0.0039952
	LOSS [training: 0.1615500801114382 | validation: 0.33156179814192466]
	TIME [epoch: 11.7 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17113973263615795		[learning rate: 0.0039764]
	Learning Rate: 0.00397637
	LOSS [training: 0.17113973263615795 | validation: 0.3197810248300381]
	TIME [epoch: 11.7 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15163470277279142		[learning rate: 0.0039576]
	Learning Rate: 0.00395764
	LOSS [training: 0.15163470277279142 | validation: 0.31702075773564453]
	TIME [epoch: 11.7 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1580870093443869		[learning rate: 0.003939]
	Learning Rate: 0.00393899
	LOSS [training: 0.1580870093443869 | validation: 0.2995075043028576]
	TIME [epoch: 11.7 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v12_20240716_190535/states/model_facs_v3_dec2b_2dpca_v12_235.pth
	Model improved!!!
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1589206075767311		[learning rate: 0.0039204]
	Learning Rate: 0.00392043
	LOSS [training: 0.1589206075767311 | validation: 0.3855023814347533]
	TIME [epoch: 11.7 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18038732281286168		[learning rate: 0.003902]
	Learning Rate: 0.00390195
	LOSS [training: 0.18038732281286168 | validation: 0.3328090663398048]
	TIME [epoch: 11.7 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1690517719961729		[learning rate: 0.0038836]
	Learning Rate: 0.00388357
	LOSS [training: 0.1690517719961729 | validation: 0.35704560430357246]
	TIME [epoch: 11.7 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1577782679129569		[learning rate: 0.0038653]
	Learning Rate: 0.00386527
	LOSS [training: 0.1577782679129569 | validation: 0.34683453525478]
	TIME [epoch: 11.7 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1557059250189571		[learning rate: 0.0038471]
	Learning Rate: 0.00384705
	LOSS [training: 0.1557059250189571 | validation: 0.30254412372194767]
	TIME [epoch: 11.7 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1403014351855193		[learning rate: 0.0038289]
	Learning Rate: 0.00382893
	LOSS [training: 0.1403014351855193 | validation: 0.32689685413193165]
	TIME [epoch: 11.7 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15113653623909865		[learning rate: 0.0038109]
	Learning Rate: 0.00381088
	LOSS [training: 0.15113653623909865 | validation: 0.37144411591408105]
	TIME [epoch: 11.7 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14624871091688862		[learning rate: 0.0037929]
	Learning Rate: 0.00379293
	LOSS [training: 0.14624871091688862 | validation: 0.43175552929864314]
	TIME [epoch: 11.7 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1687576344433479		[learning rate: 0.0037751]
	Learning Rate: 0.00377505
	LOSS [training: 0.1687576344433479 | validation: 0.31758401228193156]
	TIME [epoch: 11.7 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16178605559995898		[learning rate: 0.0037573]
	Learning Rate: 0.00375726
	LOSS [training: 0.16178605559995898 | validation: 0.3497136472465725]
	TIME [epoch: 11.7 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17908281984869376		[learning rate: 0.0037396]
	Learning Rate: 0.00373956
	LOSS [training: 0.17908281984869376 | validation: 0.4377757812297298]
	TIME [epoch: 11.7 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16802858643367957		[learning rate: 0.0037219]
	Learning Rate: 0.00372194
	LOSS [training: 0.16802858643367957 | validation: 0.3068641751548861]
	TIME [epoch: 11.7 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1611766608651914		[learning rate: 0.0037044]
	Learning Rate: 0.0037044
	LOSS [training: 0.1611766608651914 | validation: 0.35151954909855326]
	TIME [epoch: 11.7 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16737191974267546		[learning rate: 0.0036869]
	Learning Rate: 0.00368695
	LOSS [training: 0.16737191974267546 | validation: 0.29485053275406176]
	TIME [epoch: 11.6 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v12_20240716_190535/states/model_facs_v3_dec2b_2dpca_v12_249.pth
	Model improved!!!
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15245951380105527		[learning rate: 0.0036696]
	Learning Rate: 0.00366957
	LOSS [training: 0.15245951380105527 | validation: 0.3350767255878042]
	TIME [epoch: 11.7 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15679891894564554		[learning rate: 0.0036523]
	Learning Rate: 0.00365228
	LOSS [training: 0.15679891894564554 | validation: 0.3230854104536584]
	TIME [epoch: 11.7 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15084482203208105		[learning rate: 0.0036351]
	Learning Rate: 0.00363507
	LOSS [training: 0.15084482203208105 | validation: 0.3219316537267453]
	TIME [epoch: 11.7 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17338877023517174		[learning rate: 0.0036179]
	Learning Rate: 0.00361794
	LOSS [training: 0.17338877023517174 | validation: 0.3250245935791441]
	TIME [epoch: 11.7 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1620226626569324		[learning rate: 0.0036009]
	Learning Rate: 0.00360089
	LOSS [training: 0.1620226626569324 | validation: 0.3331514843454837]
	TIME [epoch: 11.7 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14942848729085095		[learning rate: 0.0035839]
	Learning Rate: 0.00358393
	LOSS [training: 0.14942848729085095 | validation: 0.3177178662373097]
	TIME [epoch: 11.7 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14095267991927285		[learning rate: 0.003567]
	Learning Rate: 0.00356704
	LOSS [training: 0.14095267991927285 | validation: 0.3297656001049871]
	TIME [epoch: 11.7 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14736721213550374		[learning rate: 0.0035502]
	Learning Rate: 0.00355023
	LOSS [training: 0.14736721213550374 | validation: 0.306978369464573]
	TIME [epoch: 11.7 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.136108800029151		[learning rate: 0.0035335]
	Learning Rate: 0.0035335
	LOSS [training: 0.136108800029151 | validation: 0.2998324141802518]
	TIME [epoch: 11.7 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16798526423157503		[learning rate: 0.0035168]
	Learning Rate: 0.00351685
	LOSS [training: 0.16798526423157503 | validation: 0.3569794112399919]
	TIME [epoch: 11.7 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18518332034908666		[learning rate: 0.0035003]
	Learning Rate: 0.00350028
	LOSS [training: 0.18518332034908666 | validation: 0.3643012900278276]
	TIME [epoch: 11.7 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15685337997764942		[learning rate: 0.0034838]
	Learning Rate: 0.00348378
	LOSS [training: 0.15685337997764942 | validation: 0.3325016009276779]
	TIME [epoch: 11.7 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18056514857099032		[learning rate: 0.0034674]
	Learning Rate: 0.00346737
	LOSS [training: 0.18056514857099032 | validation: 0.3342253044233466]
	TIME [epoch: 11.7 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15734745678590853		[learning rate: 0.003451]
	Learning Rate: 0.00345103
	LOSS [training: 0.15734745678590853 | validation: 0.3416057482288523]
	TIME [epoch: 11.7 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14024226184622957		[learning rate: 0.0034348]
	Learning Rate: 0.00343477
	LOSS [training: 0.14024226184622957 | validation: 0.29652663264097706]
	TIME [epoch: 11.7 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14218052630655392		[learning rate: 0.0034186]
	Learning Rate: 0.00341858
	LOSS [training: 0.14218052630655392 | validation: 0.2998984690579812]
	TIME [epoch: 11.7 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1423384992372177		[learning rate: 0.0034025]
	Learning Rate: 0.00340247
	LOSS [training: 0.1423384992372177 | validation: 0.3302855912023182]
	TIME [epoch: 11.7 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16217084732030498		[learning rate: 0.0033864]
	Learning Rate: 0.00338644
	LOSS [training: 0.16217084732030498 | validation: 0.30823637405233933]
	TIME [epoch: 11.7 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16802259293848826		[learning rate: 0.0033705]
	Learning Rate: 0.00337048
	LOSS [training: 0.16802259293848826 | validation: 0.36800507892078105]
	TIME [epoch: 11.7 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16784170297345585		[learning rate: 0.0033546]
	Learning Rate: 0.0033546
	LOSS [training: 0.16784170297345585 | validation: 0.40354745823400723]
	TIME [epoch: 11.6 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17743939569293088		[learning rate: 0.0033388]
	Learning Rate: 0.00333879
	LOSS [training: 0.17743939569293088 | validation: 0.33915827184372527]
	TIME [epoch: 11.7 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15566070058265566		[learning rate: 0.0033231]
	Learning Rate: 0.00332306
	LOSS [training: 0.15566070058265566 | validation: 0.3452466218120428]
	TIME [epoch: 11.7 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1499020890977133		[learning rate: 0.0033074]
	Learning Rate: 0.0033074
	LOSS [training: 0.1499020890977133 | validation: 0.32388035522192266]
	TIME [epoch: 11.7 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16659849443800676		[learning rate: 0.0032918]
	Learning Rate: 0.00329182
	LOSS [training: 0.16659849443800676 | validation: 0.30082105194513525]
	TIME [epoch: 11.7 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1538780441850262		[learning rate: 0.0032763]
	Learning Rate: 0.00327631
	LOSS [training: 0.1538780441850262 | validation: 0.3183340435444491]
	TIME [epoch: 11.7 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14992819596193943		[learning rate: 0.0032609]
	Learning Rate: 0.00326087
	LOSS [training: 0.14992819596193943 | validation: 0.3829987340302789]
	TIME [epoch: 11.7 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15490420445823067		[learning rate: 0.0032455]
	Learning Rate: 0.0032455
	LOSS [training: 0.15490420445823067 | validation: 0.34570046733358994]
	TIME [epoch: 11.7 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1626491332850541		[learning rate: 0.0032302]
	Learning Rate: 0.00323021
	LOSS [training: 0.1626491332850541 | validation: 0.2914943897784612]
	TIME [epoch: 11.7 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v12_20240716_190535/states/model_facs_v3_dec2b_2dpca_v12_277.pth
	Model improved!!!
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1643561671090456		[learning rate: 0.003215]
	Learning Rate: 0.00321499
	LOSS [training: 0.1643561671090456 | validation: 0.3041079569698265]
	TIME [epoch: 11.7 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1418782123582083		[learning rate: 0.0031998]
	Learning Rate: 0.00319984
	LOSS [training: 0.1418782123582083 | validation: 0.31627733413409403]
	TIME [epoch: 11.7 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14442952284121033		[learning rate: 0.0031848]
	Learning Rate: 0.00318476
	LOSS [training: 0.14442952284121033 | validation: 0.31831787701894537]
	TIME [epoch: 11.7 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15359712641501283		[learning rate: 0.0031698]
	Learning Rate: 0.00316975
	LOSS [training: 0.15359712641501283 | validation: 0.31540399544969683]
	TIME [epoch: 11.7 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16324988869481244		[learning rate: 0.0031548]
	Learning Rate: 0.00315482
	LOSS [training: 0.16324988869481244 | validation: 0.3360951254658942]
	TIME [epoch: 11.7 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16707097828808146		[learning rate: 0.00314]
	Learning Rate: 0.00313995
	LOSS [training: 0.16707097828808146 | validation: 0.3088911031799121]
	TIME [epoch: 11.7 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14833903217000616		[learning rate: 0.0031252]
	Learning Rate: 0.00312516
	LOSS [training: 0.14833903217000616 | validation: 0.34878298095293414]
	TIME [epoch: 11.7 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1782326481059028		[learning rate: 0.0031104]
	Learning Rate: 0.00311043
	LOSS [training: 0.1782326481059028 | validation: 0.37216649422872916]
	TIME [epoch: 11.7 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16793019848886415		[learning rate: 0.0030958]
	Learning Rate: 0.00309577
	LOSS [training: 0.16793019848886415 | validation: 0.30795808878250985]
	TIME [epoch: 11.7 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1689747939957777		[learning rate: 0.0030812]
	Learning Rate: 0.00308119
	LOSS [training: 0.1689747939957777 | validation: 0.35616701783579874]
	TIME [epoch: 11.7 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1585769833554299		[learning rate: 0.0030667]
	Learning Rate: 0.00306667
	LOSS [training: 0.1585769833554299 | validation: 0.3259966932255725]
	TIME [epoch: 11.7 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1556153027611643		[learning rate: 0.0030522]
	Learning Rate: 0.00305222
	LOSS [training: 0.1556153027611643 | validation: 0.30537830188468007]
	TIME [epoch: 11.7 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15418925156344537		[learning rate: 0.0030378]
	Learning Rate: 0.00303783
	LOSS [training: 0.15418925156344537 | validation: 0.31469049759178613]
	TIME [epoch: 11.7 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14062767346927		[learning rate: 0.0030235]
	Learning Rate: 0.00302352
	LOSS [training: 0.14062767346927 | validation: 0.29531387740234877]
	TIME [epoch: 11.7 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15367822589890154		[learning rate: 0.0030093]
	Learning Rate: 0.00300927
	LOSS [training: 0.15367822589890154 | validation: 0.3269749614324241]
	TIME [epoch: 11.7 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1586163830079173		[learning rate: 0.0029951]
	Learning Rate: 0.00299509
	LOSS [training: 0.1586163830079173 | validation: 0.38128255943346295]
	TIME [epoch: 11.7 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16938826501909676		[learning rate: 0.002981]
	Learning Rate: 0.00298098
	LOSS [training: 0.16938826501909676 | validation: 0.378826718083648]
	TIME [epoch: 11.7 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14622224862022626		[learning rate: 0.0029669]
	Learning Rate: 0.00296693
	LOSS [training: 0.14622224862022626 | validation: 0.3450421587148458]
	TIME [epoch: 11.7 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.144832405163015		[learning rate: 0.002953]
	Learning Rate: 0.00295295
	LOSS [training: 0.144832405163015 | validation: 0.31896429036817314]
	TIME [epoch: 11.7 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15551021466611828		[learning rate: 0.002939]
	Learning Rate: 0.00293904
	LOSS [training: 0.15551021466611828 | validation: 0.3140335674655967]
	TIME [epoch: 11.7 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14801028436720962		[learning rate: 0.0029252]
	Learning Rate: 0.00292519
	LOSS [training: 0.14801028436720962 | validation: 0.29544058213522445]
	TIME [epoch: 11.7 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14296617544068035		[learning rate: 0.0029114]
	Learning Rate: 0.0029114
	LOSS [training: 0.14296617544068035 | validation: 0.3181903315043548]
	TIME [epoch: 11.7 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.150114811217498		[learning rate: 0.0028977]
	Learning Rate: 0.00289769
	LOSS [training: 0.150114811217498 | validation: 0.31265179485920097]
	TIME [epoch: 11.7 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1554481159103207		[learning rate: 0.002884]
	Learning Rate: 0.00288403
	LOSS [training: 0.1554481159103207 | validation: 0.3234824566229722]
	TIME [epoch: 11.7 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16585422209814735		[learning rate: 0.0028704]
	Learning Rate: 0.00287044
	LOSS [training: 0.16585422209814735 | validation: 0.34944229586948683]
	TIME [epoch: 11.7 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1454119954935815		[learning rate: 0.0028569]
	Learning Rate: 0.00285692
	LOSS [training: 0.1454119954935815 | validation: 0.3425462617985174]
	TIME [epoch: 11.7 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14510719834733635		[learning rate: 0.0028435]
	Learning Rate: 0.00284345
	LOSS [training: 0.14510719834733635 | validation: 0.3642354671570034]
	TIME [epoch: 11.7 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14990689808009652		[learning rate: 0.0028301]
	Learning Rate: 0.00283005
	LOSS [training: 0.14990689808009652 | validation: 0.3453500411134491]
	TIME [epoch: 11.7 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1556781253626084		[learning rate: 0.0028167]
	Learning Rate: 0.00281672
	LOSS [training: 0.1556781253626084 | validation: 0.33695051774226487]
	TIME [epoch: 11.7 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13677450312074957		[learning rate: 0.0028034]
	Learning Rate: 0.00280345
	LOSS [training: 0.13677450312074957 | validation: 0.3033375292850292]
	TIME [epoch: 11.7 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1413010655003151		[learning rate: 0.0027902]
	Learning Rate: 0.00279024
	LOSS [training: 0.1413010655003151 | validation: 0.32674194984139676]
	TIME [epoch: 11.7 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14845580796465713		[learning rate: 0.0027771]
	Learning Rate: 0.00277709
	LOSS [training: 0.14845580796465713 | validation: 0.3123623399998435]
	TIME [epoch: 11.7 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14463536024033327		[learning rate: 0.002764]
	Learning Rate: 0.002764
	LOSS [training: 0.14463536024033327 | validation: 0.3540829530387125]
	TIME [epoch: 11.7 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1496163225016348		[learning rate: 0.002751]
	Learning Rate: 0.00275098
	LOSS [training: 0.1496163225016348 | validation: 0.32138700524780156]
	TIME [epoch: 11.7 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1577284775103775		[learning rate: 0.002738]
	Learning Rate: 0.00273802
	LOSS [training: 0.1577284775103775 | validation: 0.3303707668990335]
	TIME [epoch: 11.7 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1542908944278763		[learning rate: 0.0027251]
	Learning Rate: 0.00272511
	LOSS [training: 0.1542908944278763 | validation: 0.2983582787135776]
	TIME [epoch: 11.7 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16418797499084514		[learning rate: 0.0027123]
	Learning Rate: 0.00271227
	LOSS [training: 0.16418797499084514 | validation: 0.3171281800766725]
	TIME [epoch: 11.7 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14652891250744615		[learning rate: 0.0026995]
	Learning Rate: 0.00269949
	LOSS [training: 0.14652891250744615 | validation: 0.3782532223372788]
	TIME [epoch: 11.7 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13138822378309975		[learning rate: 0.0026868]
	Learning Rate: 0.00268677
	LOSS [training: 0.13138822378309975 | validation: 0.3140438432055811]
	TIME [epoch: 11.7 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13768026191333693		[learning rate: 0.0026741]
	Learning Rate: 0.00267411
	LOSS [training: 0.13768026191333693 | validation: 0.32996123188428617]
	TIME [epoch: 11.7 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15720476206532777		[learning rate: 0.0026615]
	Learning Rate: 0.00266151
	LOSS [training: 0.15720476206532777 | validation: 0.3432713961238312]
	TIME [epoch: 11.7 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15718372107638146		[learning rate: 0.002649]
	Learning Rate: 0.00264897
	LOSS [training: 0.15718372107638146 | validation: 0.3462504679321824]
	TIME [epoch: 11.7 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18088130601357422		[learning rate: 0.0026365]
	Learning Rate: 0.00263649
	LOSS [training: 0.18088130601357422 | validation: 0.32935276725791574]
	TIME [epoch: 11.7 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1540207553561025		[learning rate: 0.0026241]
	Learning Rate: 0.00262406
	LOSS [training: 0.1540207553561025 | validation: 0.30627863847107994]
	TIME [epoch: 11.7 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15521312230491227		[learning rate: 0.0026117]
	Learning Rate: 0.0026117
	LOSS [training: 0.15521312230491227 | validation: 0.3174747017192034]
	TIME [epoch: 11.7 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16546766059859325		[learning rate: 0.0025994]
	Learning Rate: 0.00259939
	LOSS [training: 0.16546766059859325 | validation: 0.3522031603683391]
	TIME [epoch: 11.7 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14219659575041846		[learning rate: 0.0025871]
	Learning Rate: 0.00258714
	LOSS [training: 0.14219659575041846 | validation: 0.318143901311261]
	TIME [epoch: 11.7 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13155127984594045		[learning rate: 0.002575]
	Learning Rate: 0.00257495
	LOSS [training: 0.13155127984594045 | validation: 0.3564583769491681]
	TIME [epoch: 11.7 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1631748560238297		[learning rate: 0.0025628]
	Learning Rate: 0.00256282
	LOSS [training: 0.1631748560238297 | validation: 0.31178167251891115]
	TIME [epoch: 11.7 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17913479332524126		[learning rate: 0.0025507]
	Learning Rate: 0.00255074
	LOSS [training: 0.17913479332524126 | validation: 0.30400416963015064]
	TIME [epoch: 11.7 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13440726039807505		[learning rate: 0.0025387]
	Learning Rate: 0.00253872
	LOSS [training: 0.13440726039807505 | validation: 0.3299284362773538]
	TIME [epoch: 11.7 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1471690455286205		[learning rate: 0.0025268]
	Learning Rate: 0.00252676
	LOSS [training: 0.1471690455286205 | validation: 0.30196645006075973]
	TIME [epoch: 11.7 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14786290166993032		[learning rate: 0.0025149]
	Learning Rate: 0.00251485
	LOSS [training: 0.14786290166993032 | validation: 0.31426838218826375]
	TIME [epoch: 11.7 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14590663641602522		[learning rate: 0.002503]
	Learning Rate: 0.002503
	LOSS [training: 0.14590663641602522 | validation: 0.3001682209051209]
	TIME [epoch: 11.7 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14863848919023284		[learning rate: 0.0024912]
	Learning Rate: 0.00249121
	LOSS [training: 0.14863848919023284 | validation: 0.29318008878578944]
	TIME [epoch: 11.7 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16345431180801265		[learning rate: 0.0024795]
	Learning Rate: 0.00247947
	LOSS [training: 0.16345431180801265 | validation: 0.3423073847610343]
	TIME [epoch: 11.7 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1635732870316845		[learning rate: 0.0024678]
	Learning Rate: 0.00246779
	LOSS [training: 0.1635732870316845 | validation: 0.4068204553680974]
	TIME [epoch: 11.7 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15197016549995462		[learning rate: 0.0024562]
	Learning Rate: 0.00245616
	LOSS [training: 0.15197016549995462 | validation: 0.32802487439606054]
	TIME [epoch: 11.7 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14875227698683063		[learning rate: 0.0024446]
	Learning Rate: 0.00244458
	LOSS [training: 0.14875227698683063 | validation: 0.31238911367933303]
	TIME [epoch: 11.7 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14312609299106205		[learning rate: 0.0024331]
	Learning Rate: 0.00243307
	LOSS [training: 0.14312609299106205 | validation: 0.3273375374147094]
	TIME [epoch: 11.7 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13130594789669472		[learning rate: 0.0024216]
	Learning Rate: 0.0024216
	LOSS [training: 0.13130594789669472 | validation: 0.3240234060630952]
	TIME [epoch: 11.7 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16044397007874028		[learning rate: 0.0024102]
	Learning Rate: 0.00241019
	LOSS [training: 0.16044397007874028 | validation: 0.325929052060901]
	TIME [epoch: 11.7 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15828009335271656		[learning rate: 0.0023988]
	Learning Rate: 0.00239883
	LOSS [training: 0.15828009335271656 | validation: 0.31681608149127666]
	TIME [epoch: 11.7 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14707924976001646		[learning rate: 0.0023875]
	Learning Rate: 0.00238753
	LOSS [training: 0.14707924976001646 | validation: 0.3100955909626691]
	TIME [epoch: 11.7 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15127716812281378		[learning rate: 0.0023763]
	Learning Rate: 0.00237628
	LOSS [training: 0.15127716812281378 | validation: 0.3184674392203273]
	TIME [epoch: 11.7 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.168717875314991		[learning rate: 0.0023651]
	Learning Rate: 0.00236508
	LOSS [training: 0.168717875314991 | validation: 0.3170411591569469]
	TIME [epoch: 11.7 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1561069482776754		[learning rate: 0.0023539]
	Learning Rate: 0.00235394
	LOSS [training: 0.1561069482776754 | validation: 0.3018212449700338]
	TIME [epoch: 11.7 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1380011706168665		[learning rate: 0.0023428]
	Learning Rate: 0.00234285
	LOSS [training: 0.1380011706168665 | validation: 0.34732347904144756]
	TIME [epoch: 11.7 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15860820289427055		[learning rate: 0.0023318]
	Learning Rate: 0.00233181
	LOSS [training: 0.15860820289427055 | validation: 0.30634909038836655]
	TIME [epoch: 11.7 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.130966455730492		[learning rate: 0.0023208]
	Learning Rate: 0.00232082
	LOSS [training: 0.130966455730492 | validation: 0.30467717189752075]
	TIME [epoch: 11.7 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13326405093441507		[learning rate: 0.0023099]
	Learning Rate: 0.00230988
	LOSS [training: 0.13326405093441507 | validation: 0.3033979469515737]
	TIME [epoch: 11.6 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13785039630389148		[learning rate: 0.002299]
	Learning Rate: 0.002299
	LOSS [training: 0.13785039630389148 | validation: 0.3116568528643437]
	TIME [epoch: 11.7 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.140743788105628		[learning rate: 0.0022882]
	Learning Rate: 0.00228816
	LOSS [training: 0.140743788105628 | validation: 0.3168592517456475]
	TIME [epoch: 11.7 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12839473832184115		[learning rate: 0.0022774]
	Learning Rate: 0.00227738
	LOSS [training: 0.12839473832184115 | validation: 0.31737311836249615]
	TIME [epoch: 11.6 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1381431966192235		[learning rate: 0.0022667]
	Learning Rate: 0.00226665
	LOSS [training: 0.1381431966192235 | validation: 0.29283975003664553]
	TIME [epoch: 11.6 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1660709277053073		[learning rate: 0.002256]
	Learning Rate: 0.00225597
	LOSS [training: 0.1660709277053073 | validation: 0.3118367712605651]
	TIME [epoch: 11.7 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14677648069214172		[learning rate: 0.0022453]
	Learning Rate: 0.00224534
	LOSS [training: 0.14677648069214172 | validation: 0.33633310498580465]
	TIME [epoch: 11.6 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1611043549610549		[learning rate: 0.0022348]
	Learning Rate: 0.00223476
	LOSS [training: 0.1611043549610549 | validation: 0.2999165592356802]
	TIME [epoch: 11.7 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1612248183665575		[learning rate: 0.0022242]
	Learning Rate: 0.00222423
	LOSS [training: 0.1612248183665575 | validation: 0.34632574787519343]
	TIME [epoch: 11.7 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1690833778811287		[learning rate: 0.0022137]
	Learning Rate: 0.00221375
	LOSS [training: 0.1690833778811287 | validation: 0.30193268291204467]
	TIME [epoch: 11.7 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1498303062244319		[learning rate: 0.0022033]
	Learning Rate: 0.00220332
	LOSS [training: 0.1498303062244319 | validation: 0.36923298294303913]
	TIME [epoch: 11.7 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14605797206434792		[learning rate: 0.0021929]
	Learning Rate: 0.00219293
	LOSS [training: 0.14605797206434792 | validation: 0.325726856810308]
	TIME [epoch: 11.7 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15031791483335444		[learning rate: 0.0021826]
	Learning Rate: 0.0021826
	LOSS [training: 0.15031791483335444 | validation: 0.30204008950978845]
	TIME [epoch: 11.7 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13297669121684916		[learning rate: 0.0021723]
	Learning Rate: 0.00217232
	LOSS [training: 0.13297669121684916 | validation: 0.29225979520510675]
	TIME [epoch: 11.6 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13994276090179766		[learning rate: 0.0021621]
	Learning Rate: 0.00216208
	LOSS [training: 0.13994276090179766 | validation: 0.3165901386986708]
	TIME [epoch: 11.7 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13660203668663584		[learning rate: 0.0021519]
	Learning Rate: 0.00215189
	LOSS [training: 0.13660203668663584 | validation: 0.3336769643183411]
	TIME [epoch: 11.7 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14141236709754829		[learning rate: 0.0021418]
	Learning Rate: 0.00214175
	LOSS [training: 0.14141236709754829 | validation: 0.314969066177965]
	TIME [epoch: 11.6 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17655715328509053		[learning rate: 0.0021317]
	Learning Rate: 0.00213166
	LOSS [training: 0.17655715328509053 | validation: 0.3561148202754879]
	TIME [epoch: 11.7 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15863390698465568		[learning rate: 0.0021216]
	Learning Rate: 0.00212162
	LOSS [training: 0.15863390698465568 | validation: 0.29829872115082934]
	TIME [epoch: 11.7 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14853299915620544		[learning rate: 0.0021116]
	Learning Rate: 0.00211162
	LOSS [training: 0.14853299915620544 | validation: 0.3020320397036866]
	TIME [epoch: 11.7 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13987552220835922		[learning rate: 0.0021017]
	Learning Rate: 0.00210167
	LOSS [training: 0.13987552220835922 | validation: 0.33465081566725535]
	TIME [epoch: 11.7 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14156162657705318		[learning rate: 0.0020918]
	Learning Rate: 0.00209176
	LOSS [training: 0.14156162657705318 | validation: 0.2913728340677151]
	TIME [epoch: 11.7 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v12_20240716_190535/states/model_facs_v3_dec2b_2dpca_v12_369.pth
	Model improved!!!
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13563938407271192		[learning rate: 0.0020819]
	Learning Rate: 0.00208191
	LOSS [training: 0.13563938407271192 | validation: 0.31414215452927474]
	TIME [epoch: 11.6 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14199710511439637		[learning rate: 0.0020721]
	Learning Rate: 0.0020721
	LOSS [training: 0.14199710511439637 | validation: 0.29934107883843925]
	TIME [epoch: 11.6 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1353936493094542		[learning rate: 0.0020623]
	Learning Rate: 0.00206233
	LOSS [training: 0.1353936493094542 | validation: 0.3112877172226809]
	TIME [epoch: 11.7 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15078983039380792		[learning rate: 0.0020526]
	Learning Rate: 0.00205262
	LOSS [training: 0.15078983039380792 | validation: 0.31649976698784826]
	TIME [epoch: 11.7 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14996002753773824		[learning rate: 0.0020429]
	Learning Rate: 0.00204294
	LOSS [training: 0.14996002753773824 | validation: 0.3128420762119398]
	TIME [epoch: 11.7 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13586279851032823		[learning rate: 0.0020333]
	Learning Rate: 0.00203332
	LOSS [training: 0.13586279851032823 | validation: 0.3191911785057657]
	TIME [epoch: 11.7 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14832616358821815		[learning rate: 0.0020237]
	Learning Rate: 0.00202374
	LOSS [training: 0.14832616358821815 | validation: 0.30030721507749897]
	TIME [epoch: 11.7 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1370941362146288		[learning rate: 0.0020142]
	Learning Rate: 0.0020142
	LOSS [training: 0.1370941362146288 | validation: 0.302255958521269]
	TIME [epoch: 11.6 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1513963752775847		[learning rate: 0.0020047]
	Learning Rate: 0.00200471
	LOSS [training: 0.1513963752775847 | validation: 0.32554881813662007]
	TIME [epoch: 11.7 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14713892939474404		[learning rate: 0.0019953]
	Learning Rate: 0.00199526
	LOSS [training: 0.14713892939474404 | validation: 0.32848865566515256]
	TIME [epoch: 11.7 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1516062578972747		[learning rate: 0.0019859]
	Learning Rate: 0.00198586
	LOSS [training: 0.1516062578972747 | validation: 0.3424189017307817]
	TIME [epoch: 11.7 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13806379706694746		[learning rate: 0.0019765]
	Learning Rate: 0.0019765
	LOSS [training: 0.13806379706694746 | validation: 0.305355725761012]
	TIME [epoch: 11.7 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14948598668479773		[learning rate: 0.0019672]
	Learning Rate: 0.00196719
	LOSS [training: 0.14948598668479773 | validation: 0.34168529475905157]
	TIME [epoch: 11.7 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14949886648857805		[learning rate: 0.0019579]
	Learning Rate: 0.00195792
	LOSS [training: 0.14949886648857805 | validation: 0.3353498853781859]
	TIME [epoch: 11.7 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1474469825519784		[learning rate: 0.0019487]
	Learning Rate: 0.00194869
	LOSS [training: 0.1474469825519784 | validation: 0.3290158481102146]
	TIME [epoch: 11.7 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15203572832580034		[learning rate: 0.0019395]
	Learning Rate: 0.00193951
	LOSS [training: 0.15203572832580034 | validation: 0.3018727114632705]
	TIME [epoch: 11.7 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14122089617754038		[learning rate: 0.0019304]
	Learning Rate: 0.00193037
	LOSS [training: 0.14122089617754038 | validation: 0.2835078222107144]
	TIME [epoch: 11.7 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v12_20240716_190535/states/model_facs_v3_dec2b_2dpca_v12_386.pth
	Model improved!!!
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14701911212756755		[learning rate: 0.0019213]
	Learning Rate: 0.00192128
	LOSS [training: 0.14701911212756755 | validation: 0.33577728027138437]
	TIME [epoch: 11.7 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13365417241652103		[learning rate: 0.0019122]
	Learning Rate: 0.00191222
	LOSS [training: 0.13365417241652103 | validation: 0.3265055441509598]
	TIME [epoch: 11.7 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1425990264828708		[learning rate: 0.0019032]
	Learning Rate: 0.00190321
	LOSS [training: 0.1425990264828708 | validation: 0.30459905843879415]
	TIME [epoch: 11.7 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1335214578404171		[learning rate: 0.0018942]
	Learning Rate: 0.00189424
	LOSS [training: 0.1335214578404171 | validation: 0.31300957911248267]
	TIME [epoch: 11.7 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14839948908854675		[learning rate: 0.0018853]
	Learning Rate: 0.00188532
	LOSS [training: 0.14839948908854675 | validation: 0.32779544534327104]
	TIME [epoch: 11.7 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1428328317425998		[learning rate: 0.0018764]
	Learning Rate: 0.00187643
	LOSS [training: 0.1428328317425998 | validation: 0.29827430368198166]
	TIME [epoch: 11.7 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13931645042802884		[learning rate: 0.0018676]
	Learning Rate: 0.00186759
	LOSS [training: 0.13931645042802884 | validation: 0.3410614925778472]
	TIME [epoch: 11.7 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13674659484790108		[learning rate: 0.0018588]
	Learning Rate: 0.00185879
	LOSS [training: 0.13674659484790108 | validation: 0.32923501296298413]
	TIME [epoch: 11.7 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1453670301119215		[learning rate: 0.00185]
	Learning Rate: 0.00185003
	LOSS [training: 0.1453670301119215 | validation: 0.3335598225876199]
	TIME [epoch: 11.7 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15223268111325974		[learning rate: 0.0018413]
	Learning Rate: 0.00184132
	LOSS [training: 0.15223268111325974 | validation: 0.3053639254441419]
	TIME [epoch: 11.7 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15135006468940654		[learning rate: 0.0018326]
	Learning Rate: 0.00183264
	LOSS [training: 0.15135006468940654 | validation: 0.30283873604583994]
	TIME [epoch: 11.7 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13867141991909365		[learning rate: 0.001824]
	Learning Rate: 0.001824
	LOSS [training: 0.13867141991909365 | validation: 0.31707104362565175]
	TIME [epoch: 11.7 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14474504656731405		[learning rate: 0.0018154]
	Learning Rate: 0.00181541
	LOSS [training: 0.14474504656731405 | validation: 0.29727456957893883]
	TIME [epoch: 11.7 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1276496401636391		[learning rate: 0.0018069]
	Learning Rate: 0.00180685
	LOSS [training: 0.1276496401636391 | validation: 0.3068455464727697]
	TIME [epoch: 11.7 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15139472955750566		[learning rate: 0.0017983]
	Learning Rate: 0.00179834
	LOSS [training: 0.15139472955750566 | validation: 0.3211356802399821]
	TIME [epoch: 11.7 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16423044278397717		[learning rate: 0.0017899]
	Learning Rate: 0.00178987
	LOSS [training: 0.16423044278397717 | validation: 0.3277177144437002]
	TIME [epoch: 11.7 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1313876929571098		[learning rate: 0.0017814]
	Learning Rate: 0.00178143
	LOSS [training: 0.1313876929571098 | validation: 0.3077711458395457]
	TIME [epoch: 11.7 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15491712767614463		[learning rate: 0.001773]
	Learning Rate: 0.00177304
	LOSS [training: 0.15491712767614463 | validation: 0.31370607116422417]
	TIME [epoch: 11.7 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13454151260700795		[learning rate: 0.0017647]
	Learning Rate: 0.00176468
	LOSS [training: 0.13454151260700795 | validation: 0.29659952124954686]
	TIME [epoch: 11.7 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14764661118482228		[learning rate: 0.0017564]
	Learning Rate: 0.00175637
	LOSS [training: 0.14764661118482228 | validation: 0.3304676180380783]
	TIME [epoch: 11.7 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13706884448131398		[learning rate: 0.0017481]
	Learning Rate: 0.00174809
	LOSS [training: 0.13706884448131398 | validation: 0.3022512525791947]
	TIME [epoch: 11.7 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14113375740672698		[learning rate: 0.0017399]
	Learning Rate: 0.00173985
	LOSS [training: 0.14113375740672698 | validation: 0.30911348255249566]
	TIME [epoch: 11.7 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12836192802443336		[learning rate: 0.0017317]
	Learning Rate: 0.00173166
	LOSS [training: 0.12836192802443336 | validation: 0.31216229036022286]
	TIME [epoch: 11.7 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1440952247000582		[learning rate: 0.0017235]
	Learning Rate: 0.0017235
	LOSS [training: 0.1440952247000582 | validation: 0.30349261633581825]
	TIME [epoch: 11.7 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13388539445141323		[learning rate: 0.0017154]
	Learning Rate: 0.00171537
	LOSS [training: 0.13388539445141323 | validation: 0.31925308111951706]
	TIME [epoch: 11.7 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13591499797867673		[learning rate: 0.0017073]
	Learning Rate: 0.00170729
	LOSS [training: 0.13591499797867673 | validation: 0.3105287877960257]
	TIME [epoch: 11.7 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13951206860461973		[learning rate: 0.0016992]
	Learning Rate: 0.00169925
	LOSS [training: 0.13951206860461973 | validation: 0.3073008343796416]
	TIME [epoch: 11.7 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1608257056891969		[learning rate: 0.0016912]
	Learning Rate: 0.00169124
	LOSS [training: 0.1608257056891969 | validation: 0.3136661192297725]
	TIME [epoch: 11.7 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.146031177569823		[learning rate: 0.0016833]
	Learning Rate: 0.00168327
	LOSS [training: 0.146031177569823 | validation: 0.3020788535017444]
	TIME [epoch: 11.7 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15225990545335208		[learning rate: 0.0016753]
	Learning Rate: 0.00167534
	LOSS [training: 0.15225990545335208 | validation: 0.3618784998908434]
	TIME [epoch: 11.7 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1619668812250364		[learning rate: 0.0016674]
	Learning Rate: 0.00166744
	LOSS [training: 0.1619668812250364 | validation: 0.3234457426225488]
	TIME [epoch: 11.7 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15698265489980912		[learning rate: 0.0016596]
	Learning Rate: 0.00165959
	LOSS [training: 0.15698265489980912 | validation: 0.3165885034612831]
	TIME [epoch: 11.7 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.168125769586812		[learning rate: 0.0016518]
	Learning Rate: 0.00165177
	LOSS [training: 0.168125769586812 | validation: 0.3274515710031803]
	TIME [epoch: 11.7 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14762701603621348		[learning rate: 0.001644]
	Learning Rate: 0.00164398
	LOSS [training: 0.14762701603621348 | validation: 0.332791707991218]
	TIME [epoch: 11.7 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14923665127627062		[learning rate: 0.0016362]
	Learning Rate: 0.00163624
	LOSS [training: 0.14923665127627062 | validation: 0.30832004128554386]
	TIME [epoch: 11.7 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16364349482695179		[learning rate: 0.0016285]
	Learning Rate: 0.00162853
	LOSS [training: 0.16364349482695179 | validation: 0.3097341350450632]
	TIME [epoch: 11.7 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13392728930466818		[learning rate: 0.0016209]
	Learning Rate: 0.00162085
	LOSS [training: 0.13392728930466818 | validation: 0.311854936158891]
	TIME [epoch: 11.7 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1496986658337373		[learning rate: 0.0016132]
	Learning Rate: 0.00161322
	LOSS [training: 0.1496986658337373 | validation: 0.31028994329689374]
	TIME [epoch: 11.7 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14018288063631248		[learning rate: 0.0016056]
	Learning Rate: 0.00160561
	LOSS [training: 0.14018288063631248 | validation: 0.30588522020352704]
	TIME [epoch: 11.7 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1321342692760433		[learning rate: 0.001598]
	Learning Rate: 0.00159805
	LOSS [training: 0.1321342692760433 | validation: 0.2937483139329876]
	TIME [epoch: 11.7 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1422044982952677		[learning rate: 0.0015905]
	Learning Rate: 0.00159052
	LOSS [training: 0.1422044982952677 | validation: 0.2909046405271667]
	TIME [epoch: 11.7 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13156497300425013		[learning rate: 0.001583]
	Learning Rate: 0.00158302
	LOSS [training: 0.13156497300425013 | validation: 0.3231149945297851]
	TIME [epoch: 11.7 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1577908271033168		[learning rate: 0.0015756]
	Learning Rate: 0.00157556
	LOSS [training: 0.1577908271033168 | validation: 0.33100636171010944]
	TIME [epoch: 11.7 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15516619714282653		[learning rate: 0.0015681]
	Learning Rate: 0.00156814
	LOSS [training: 0.15516619714282653 | validation: 0.2924164621819489]
	TIME [epoch: 11.7 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15238574573474165		[learning rate: 0.0015607]
	Learning Rate: 0.00156075
	LOSS [training: 0.15238574573474165 | validation: 0.3137693361751825]
	TIME [epoch: 11.7 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14620202176477154		[learning rate: 0.0015534]
	Learning Rate: 0.0015534
	LOSS [training: 0.14620202176477154 | validation: 0.3151301475903237]
	TIME [epoch: 11.7 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15474951128495104		[learning rate: 0.0015461]
	Learning Rate: 0.00154608
	LOSS [training: 0.15474951128495104 | validation: 0.3273697777679453]
	TIME [epoch: 11.7 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1503611277703778		[learning rate: 0.0015388]
	Learning Rate: 0.00153879
	LOSS [training: 0.1503611277703778 | validation: 0.31344906782143983]
	TIME [epoch: 11.7 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.126985652391423		[learning rate: 0.0015315]
	Learning Rate: 0.00153154
	LOSS [training: 0.126985652391423 | validation: 0.30163693429884947]
	TIME [epoch: 11.7 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14412383838981957		[learning rate: 0.0015243]
	Learning Rate: 0.00152432
	LOSS [training: 0.14412383838981957 | validation: 0.31710781627297085]
	TIME [epoch: 11.7 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14561692669187806		[learning rate: 0.0015171]
	Learning Rate: 0.00151714
	LOSS [training: 0.14561692669187806 | validation: 0.33981403225162987]
	TIME [epoch: 11.7 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1505311061642859		[learning rate: 0.00151]
	Learning Rate: 0.00150999
	LOSS [training: 0.1505311061642859 | validation: 0.3289884210655394]
	TIME [epoch: 11.7 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15900915363150842		[learning rate: 0.0015029]
	Learning Rate: 0.00150288
	LOSS [training: 0.15900915363150842 | validation: 0.31524516994790197]
	TIME [epoch: 11.7 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13856514778493412		[learning rate: 0.0014958]
	Learning Rate: 0.00149579
	LOSS [training: 0.13856514778493412 | validation: 0.31567712548723703]
	TIME [epoch: 11.7 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14581758504891257		[learning rate: 0.0014887]
	Learning Rate: 0.00148875
	LOSS [training: 0.14581758504891257 | validation: 0.30375870962210705]
	TIME [epoch: 11.7 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1668422635623094		[learning rate: 0.0014817]
	Learning Rate: 0.00148173
	LOSS [training: 0.1668422635623094 | validation: 0.3293893476330019]
	TIME [epoch: 11.7 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1357905760643232		[learning rate: 0.0014747]
	Learning Rate: 0.00147475
	LOSS [training: 0.1357905760643232 | validation: 0.3297992550125253]
	TIME [epoch: 11.7 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13950702891462485		[learning rate: 0.0014678]
	Learning Rate: 0.0014678
	LOSS [training: 0.13950702891462485 | validation: 0.30173452821411717]
	TIME [epoch: 11.7 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13375009530312154		[learning rate: 0.0014609]
	Learning Rate: 0.00146088
	LOSS [training: 0.13375009530312154 | validation: 0.2901694142694609]
	TIME [epoch: 11.7 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1373003090485977		[learning rate: 0.001454]
	Learning Rate: 0.001454
	LOSS [training: 0.1373003090485977 | validation: 0.308851470080575]
	TIME [epoch: 11.7 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14965789640141586		[learning rate: 0.0014471]
	Learning Rate: 0.00144715
	LOSS [training: 0.14965789640141586 | validation: 0.30316329890117466]
	TIME [epoch: 11.7 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1362078196515238		[learning rate: 0.0014403]
	Learning Rate: 0.00144033
	LOSS [training: 0.1362078196515238 | validation: 0.30479954397554915]
	TIME [epoch: 11.7 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1377430259131624		[learning rate: 0.0014335]
	Learning Rate: 0.00143354
	LOSS [training: 0.1377430259131624 | validation: 0.30124588525655943]
	TIME [epoch: 11.7 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14383166750462767		[learning rate: 0.0014268]
	Learning Rate: 0.00142679
	LOSS [training: 0.14383166750462767 | validation: 0.30111179414387446]
	TIME [epoch: 11.7 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.159479060403781		[learning rate: 0.0014201]
	Learning Rate: 0.00142006
	LOSS [training: 0.159479060403781 | validation: 0.3046935845546028]
	TIME [epoch: 11.7 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1406150279590078		[learning rate: 0.0014134]
	Learning Rate: 0.00141337
	LOSS [training: 0.1406150279590078 | validation: 0.3209077552173269]
	TIME [epoch: 11.7 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14116303446398631		[learning rate: 0.0014067]
	Learning Rate: 0.00140671
	LOSS [training: 0.14116303446398631 | validation: 0.308365294851627]
	TIME [epoch: 11.7 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14701695819949664		[learning rate: 0.0014001]
	Learning Rate: 0.00140008
	LOSS [training: 0.14701695819949664 | validation: 0.3017751038463876]
	TIME [epoch: 11.7 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13350249292305089		[learning rate: 0.0013935]
	Learning Rate: 0.00139349
	LOSS [training: 0.13350249292305089 | validation: 0.30413617562326145]
	TIME [epoch: 11.7 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1412258016105094		[learning rate: 0.0013869]
	Learning Rate: 0.00138692
	LOSS [training: 0.1412258016105094 | validation: 0.30687129455356277]
	TIME [epoch: 11.7 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14385969440055524		[learning rate: 0.0013804]
	Learning Rate: 0.00138038
	LOSS [training: 0.14385969440055524 | validation: 0.29970373045492577]
	TIME [epoch: 11.7 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14268395296532593		[learning rate: 0.0013739]
	Learning Rate: 0.00137388
	LOSS [training: 0.14268395296532593 | validation: 0.3156807101693522]
	TIME [epoch: 11.7 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1271665163608618		[learning rate: 0.0013674]
	Learning Rate: 0.00136741
	LOSS [training: 0.1271665163608618 | validation: 0.2998464685413383]
	TIME [epoch: 11.7 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13405690470307544		[learning rate: 0.001361]
	Learning Rate: 0.00136096
	LOSS [training: 0.13405690470307544 | validation: 0.3170294695657516]
	TIME [epoch: 11.7 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1363970557751098		[learning rate: 0.0013545]
	Learning Rate: 0.00135455
	LOSS [training: 0.1363970557751098 | validation: 0.30894788723667943]
	TIME [epoch: 11.7 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14183035900213076		[learning rate: 0.0013482]
	Learning Rate: 0.00134817
	LOSS [training: 0.14183035900213076 | validation: 0.29903727779025935]
	TIME [epoch: 11.7 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12684201989836838		[learning rate: 0.0013418]
	Learning Rate: 0.00134181
	LOSS [training: 0.12684201989836838 | validation: 0.3027639775425575]
	TIME [epoch: 11.7 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13354869357197147		[learning rate: 0.0013355]
	Learning Rate: 0.00133549
	LOSS [training: 0.13354869357197147 | validation: 0.2938075728578966]
	TIME [epoch: 11.7 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15621508509489831		[learning rate: 0.0013292]
	Learning Rate: 0.0013292
	LOSS [training: 0.15621508509489831 | validation: 0.30768431766396814]
	TIME [epoch: 11.7 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13686047672223162		[learning rate: 0.0013229]
	Learning Rate: 0.00132293
	LOSS [training: 0.13686047672223162 | validation: 0.3050692706907871]
	TIME [epoch: 11.7 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1555021242393641		[learning rate: 0.0013167]
	Learning Rate: 0.0013167
	LOSS [training: 0.1555021242393641 | validation: 0.3129802987656242]
	TIME [epoch: 11.7 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1414080466253592		[learning rate: 0.0013105]
	Learning Rate: 0.0013105
	LOSS [training: 0.1414080466253592 | validation: 0.2927754616293548]
	TIME [epoch: 11.7 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13748746727795896		[learning rate: 0.0013043]
	Learning Rate: 0.00130432
	LOSS [training: 0.13748746727795896 | validation: 0.34053644353249024]
	TIME [epoch: 11.7 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12737329150710444		[learning rate: 0.0012982]
	Learning Rate: 0.00129818
	LOSS [training: 0.12737329150710444 | validation: 0.3057688413718222]
	TIME [epoch: 11.7 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14062225595144068		[learning rate: 0.0012921]
	Learning Rate: 0.00129206
	LOSS [training: 0.14062225595144068 | validation: 0.29980149908857096]
	TIME [epoch: 11.7 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14153391201661603		[learning rate: 0.001286]
	Learning Rate: 0.00128597
	LOSS [training: 0.14153391201661603 | validation: 0.30720203248395156]
	TIME [epoch: 11.7 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1532671782282446		[learning rate: 0.0012799]
	Learning Rate: 0.00127991
	LOSS [training: 0.1532671782282446 | validation: 0.3201648805183835]
	TIME [epoch: 11.7 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1766222365158428		[learning rate: 0.0012739]
	Learning Rate: 0.00127388
	LOSS [training: 0.1766222365158428 | validation: 0.31373370640633436]
	TIME [epoch: 11.7 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1426687832175289		[learning rate: 0.0012679]
	Learning Rate: 0.00126788
	LOSS [training: 0.1426687832175289 | validation: 0.3110706743578428]
	TIME [epoch: 11.7 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13254878425367211		[learning rate: 0.0012619]
	Learning Rate: 0.0012619
	LOSS [training: 0.13254878425367211 | validation: 0.311412249343139]
	TIME [epoch: 11.7 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14951737044458285		[learning rate: 0.001256]
	Learning Rate: 0.00125596
	LOSS [training: 0.14951737044458285 | validation: 0.29575173746419625]
	TIME [epoch: 11.7 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13883414625929566		[learning rate: 0.00125]
	Learning Rate: 0.00125004
	LOSS [training: 0.13883414625929566 | validation: 0.3105466161666019]
	TIME [epoch: 11.7 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14096444922077878		[learning rate: 0.0012441]
	Learning Rate: 0.00124415
	LOSS [training: 0.14096444922077878 | validation: 0.29751070055518825]
	TIME [epoch: 11.7 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14911421255874194		[learning rate: 0.0012383]
	Learning Rate: 0.00123828
	LOSS [training: 0.14911421255874194 | validation: 0.2902230078137237]
	TIME [epoch: 11.7 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16199333301069563		[learning rate: 0.0012324]
	Learning Rate: 0.00123245
	LOSS [training: 0.16199333301069563 | validation: 0.3041958408861488]
	TIME [epoch: 11.7 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13934532566473937		[learning rate: 0.0012266]
	Learning Rate: 0.00122664
	LOSS [training: 0.13934532566473937 | validation: 0.3165143803511967]
	TIME [epoch: 11.7 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1556529231907911		[learning rate: 0.0012209]
	Learning Rate: 0.00122086
	LOSS [training: 0.1556529231907911 | validation: 0.3347907250136152]
	TIME [epoch: 11.7 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14940398336255445		[learning rate: 0.0012151]
	Learning Rate: 0.00121511
	LOSS [training: 0.14940398336255445 | validation: 0.3169893510046125]
	TIME [epoch: 11.7 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1313949059219215		[learning rate: 0.0012094]
	Learning Rate: 0.00120938
	LOSS [training: 0.1313949059219215 | validation: 0.2974733620271908]
	TIME [epoch: 11.7 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12942932301027027		[learning rate: 0.0012037]
	Learning Rate: 0.00120368
	LOSS [training: 0.12942932301027027 | validation: 0.30759034122249324]
	TIME [epoch: 11.7 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14100935374680054		[learning rate: 0.001198]
	Learning Rate: 0.00119801
	LOSS [training: 0.14100935374680054 | validation: 0.3029957243242414]
	TIME [epoch: 11.7 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13104462983665396		[learning rate: 0.0011924]
	Learning Rate: 0.00119237
	LOSS [training: 0.13104462983665396 | validation: 0.31011283989850846]
	TIME [epoch: 11.7 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14127482661985236		[learning rate: 0.0011867]
	Learning Rate: 0.00118675
	LOSS [training: 0.14127482661985236 | validation: 0.2961623702454223]
	TIME [epoch: 11.7 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13694539062296687		[learning rate: 0.0011812]
	Learning Rate: 0.00118116
	LOSS [training: 0.13694539062296687 | validation: 0.3052123646440534]
	TIME [epoch: 11.7 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13581690266568736		[learning rate: 0.0011756]
	Learning Rate: 0.00117559
	LOSS [training: 0.13581690266568736 | validation: 0.30079346426842507]
	TIME [epoch: 11.7 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13879053760785087		[learning rate: 0.0011701]
	Learning Rate: 0.00117005
	LOSS [training: 0.13879053760785087 | validation: 0.3172269839994997]
	TIME [epoch: 11.7 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15241227360912607		[learning rate: 0.0011645]
	Learning Rate: 0.00116454
	LOSS [training: 0.15241227360912607 | validation: 0.3169691757973073]
	TIME [epoch: 11.7 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13765830493240244		[learning rate: 0.0011591]
	Learning Rate: 0.00115905
	LOSS [training: 0.13765830493240244 | validation: 0.3028548870685231]
	TIME [epoch: 11.7 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14238646826241855		[learning rate: 0.0011536]
	Learning Rate: 0.00115359
	LOSS [training: 0.14238646826241855 | validation: 0.3120427149757778]
	TIME [epoch: 11.7 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15282381540994117		[learning rate: 0.0011482]
	Learning Rate: 0.00114815
	LOSS [training: 0.15282381540994117 | validation: 0.3087318678009793]
	TIME [epoch: 11.7 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13923785531228872		[learning rate: 0.0011427]
	Learning Rate: 0.00114274
	LOSS [training: 0.13923785531228872 | validation: 0.29802242557049624]
	TIME [epoch: 11.7 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14312689154164804		[learning rate: 0.0011374]
	Learning Rate: 0.00113736
	LOSS [training: 0.14312689154164804 | validation: 0.30649613586089025]
	TIME [epoch: 11.7 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14545539950361996		[learning rate: 0.001132]
	Learning Rate: 0.001132
	LOSS [training: 0.14545539950361996 | validation: 0.30615280482158347]
	TIME [epoch: 11.7 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13962599434736606		[learning rate: 0.0011267]
	Learning Rate: 0.00112667
	LOSS [training: 0.13962599434736606 | validation: 0.3276391576149035]
	TIME [epoch: 11.7 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1329961065317562		[learning rate: 0.0011214]
	Learning Rate: 0.00112136
	LOSS [training: 0.1329961065317562 | validation: 0.30475467646405974]
	TIME [epoch: 50.5 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1468978884205479		[learning rate: 0.0011161]
	Learning Rate: 0.00111607
	LOSS [training: 0.1468978884205479 | validation: 0.28501991664054294]
	TIME [epoch: 25 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13858611640227264		[learning rate: 0.0011108]
	Learning Rate: 0.00111081
	LOSS [training: 0.13858611640227264 | validation: 0.31624739933645174]
	TIME [epoch: 24.9 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16030746072537425		[learning rate: 0.0011056]
	Learning Rate: 0.00110558
	LOSS [training: 0.16030746072537425 | validation: 0.3047585426347276]
	TIME [epoch: 24.9 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1353493134477862		[learning rate: 0.0011004]
	Learning Rate: 0.00110037
	LOSS [training: 0.1353493134477862 | validation: 0.31684519714241616]
	TIME [epoch: 24.9 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16391312841793526		[learning rate: 0.0010952]
	Learning Rate: 0.00109518
	LOSS [training: 0.16391312841793526 | validation: 0.30024301548803245]
	TIME [epoch: 25 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13318465921051514		[learning rate: 0.00109]
	Learning Rate: 0.00109002
	LOSS [training: 0.13318465921051514 | validation: 0.2893573107414055]
	TIME [epoch: 24.9 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1532676078410773		[learning rate: 0.0010849]
	Learning Rate: 0.00108489
	LOSS [training: 0.1532676078410773 | validation: 0.3168302858080569]
	TIME [epoch: 24.9 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16290954583449682		[learning rate: 0.0010798]
	Learning Rate: 0.00107978
	LOSS [training: 0.16290954583449682 | validation: 0.3063862238040035]
	TIME [epoch: 24.9 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1384359256988843		[learning rate: 0.0010747]
	Learning Rate: 0.00107469
	LOSS [training: 0.1384359256988843 | validation: 0.3005924916367838]
	TIME [epoch: 24.9 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13242710560912782		[learning rate: 0.0010696]
	Learning Rate: 0.00106962
	LOSS [training: 0.13242710560912782 | validation: 0.29625104855961876]
	TIME [epoch: 24.9 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1318955425805679		[learning rate: 0.0010646]
	Learning Rate: 0.00106458
	LOSS [training: 0.1318955425805679 | validation: 0.31422963773370766]
	TIME [epoch: 25 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14582430869162585		[learning rate: 0.0010596]
	Learning Rate: 0.00105957
	LOSS [training: 0.14582430869162585 | validation: 0.29590350937897364]
	TIME [epoch: 24.9 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13381582831514116		[learning rate: 0.0010546]
	Learning Rate: 0.00105457
	LOSS [training: 0.13381582831514116 | validation: 0.2944998135125957]
	TIME [epoch: 25 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.162096360710909		[learning rate: 0.0010496]
	Learning Rate: 0.0010496
	LOSS [training: 0.162096360710909 | validation: 0.32158040107386077]
	TIME [epoch: 25 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13931048818021297		[learning rate: 0.0010447]
	Learning Rate: 0.00104466
	LOSS [training: 0.13931048818021297 | validation: 0.30624988192153735]
	TIME [epoch: 24.9 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13617153269477197		[learning rate: 0.0010397]
	Learning Rate: 0.00103974
	LOSS [training: 0.13617153269477197 | validation: 0.30239009300122854]
	TIME [epoch: 24.9 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13582353813351333		[learning rate: 0.0010348]
	Learning Rate: 0.00103484
	LOSS [training: 0.13582353813351333 | validation: 0.2997477980468798]
	TIME [epoch: 25 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14775288067941048		[learning rate: 0.00103]
	Learning Rate: 0.00102996
	LOSS [training: 0.14775288067941048 | validation: 0.3212198434032104]
	TIME [epoch: 24.9 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1587204050825655		[learning rate: 0.0010251]
	Learning Rate: 0.00102511
	LOSS [training: 0.1587204050825655 | validation: 0.303838481007369]
	TIME [epoch: 24.9 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14725192339469778		[learning rate: 0.0010203]
	Learning Rate: 0.00102028
	LOSS [training: 0.14725192339469778 | validation: 0.3142002922241181]
	TIME [epoch: 24.9 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12411319578122339		[learning rate: 0.0010155]
	Learning Rate: 0.00101547
	LOSS [training: 0.12411319578122339 | validation: 0.30629857479328326]
	TIME [epoch: 24.9 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1442300976085395		[learning rate: 0.0010107]
	Learning Rate: 0.00101068
	LOSS [training: 0.1442300976085395 | validation: 0.31123421659636535]
	TIME [epoch: 24.9 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1348158740153237		[learning rate: 0.0010059]
	Learning Rate: 0.00100592
	LOSS [training: 0.1348158740153237 | validation: 0.3216153669808548]
	TIME [epoch: 24.9 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14146311768608802		[learning rate: 0.0010012]
	Learning Rate: 0.00100118
	LOSS [training: 0.14146311768608802 | validation: 0.293721765188176]
	TIME [epoch: 24.9 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13901239916731067		[learning rate: 0.00099646]
	Learning Rate: 0.000996464
	LOSS [training: 0.13901239916731067 | validation: 0.3147293224343609]
	TIME [epoch: 24.9 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14147355832363745		[learning rate: 0.00099177]
	Learning Rate: 0.000991768
	LOSS [training: 0.14147355832363745 | validation: 0.31524494575581957]
	TIME [epoch: 24.9 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1655003217569282		[learning rate: 0.0009871]
	Learning Rate: 0.000987095
	LOSS [training: 0.1655003217569282 | validation: 0.29951217074385933]
	TIME [epoch: 24.9 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1372816654613701		[learning rate: 0.00098244]
	Learning Rate: 0.000982444
	LOSS [training: 0.1372816654613701 | validation: 0.3106648647728088]
	TIME [epoch: 24.9 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14411549433198848		[learning rate: 0.00097781]
	Learning Rate: 0.000977814
	LOSS [training: 0.14411549433198848 | validation: 0.316540063898546]
	TIME [epoch: 24.9 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13543611656858093		[learning rate: 0.00097321]
	Learning Rate: 0.000973207
	LOSS [training: 0.13543611656858093 | validation: 0.3078588603603924]
	TIME [epoch: 24.9 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.138708710469272		[learning rate: 0.00096862]
	Learning Rate: 0.000968621
	LOSS [training: 0.138708710469272 | validation: 0.3121347340270517]
	TIME [epoch: 24.9 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14044587586768872		[learning rate: 0.00096406]
	Learning Rate: 0.000964057
	LOSS [training: 0.14044587586768872 | validation: 0.30353282984675334]
	TIME [epoch: 24.9 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13748101348878755		[learning rate: 0.00095951]
	Learning Rate: 0.000959514
	LOSS [training: 0.13748101348878755 | validation: 0.2917847260305521]
	TIME [epoch: 25 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14128073554791903		[learning rate: 0.00095499]
	Learning Rate: 0.000954993
	LOSS [training: 0.14128073554791903 | validation: 0.31132021855932607]
	TIME [epoch: 24.9 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15053334790711367		[learning rate: 0.00095049]
	Learning Rate: 0.000950493
	LOSS [training: 0.15053334790711367 | validation: 0.296306862337552]
	TIME [epoch: 25 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13656402000527545		[learning rate: 0.00094601]
	Learning Rate: 0.000946014
	LOSS [training: 0.13656402000527545 | validation: 0.32230432626751526]
	TIME [epoch: 24.9 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14068159872852315		[learning rate: 0.00094156]
	Learning Rate: 0.000941556
	LOSS [training: 0.14068159872852315 | validation: 0.29936019168325434]
	TIME [epoch: 24.9 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14337348295722002		[learning rate: 0.00093712]
	Learning Rate: 0.000937119
	LOSS [training: 0.14337348295722002 | validation: 0.31801189216924564]
	TIME [epoch: 24.9 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1375054304365461		[learning rate: 0.0009327]
	Learning Rate: 0.000932703
	LOSS [training: 0.1375054304365461 | validation: 0.30329062348245395]
	TIME [epoch: 25 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15379328087873606		[learning rate: 0.00092831]
	Learning Rate: 0.000928309
	LOSS [training: 0.15379328087873606 | validation: 0.3052044939430361]
	TIME [epoch: 24.9 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14865292360888507		[learning rate: 0.00092393]
	Learning Rate: 0.000923934
	LOSS [training: 0.14865292360888507 | validation: 0.30485277246208603]
	TIME [epoch: 24.9 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12220065554996258		[learning rate: 0.00091958]
	Learning Rate: 0.000919581
	LOSS [training: 0.12220065554996258 | validation: 0.2995164720039464]
	TIME [epoch: 24.9 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14207333705167724		[learning rate: 0.00091525]
	Learning Rate: 0.000915247
	LOSS [training: 0.14207333705167724 | validation: 0.30047857436430553]
	TIME [epoch: 24.9 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15334564686736946		[learning rate: 0.00091093]
	Learning Rate: 0.000910934
	LOSS [training: 0.15334564686736946 | validation: 0.30304736023206763]
	TIME [epoch: 24.9 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13513220294951356		[learning rate: 0.00090664]
	Learning Rate: 0.000906642
	LOSS [training: 0.13513220294951356 | validation: 0.3146485311951179]
	TIME [epoch: 25 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14280688174182396		[learning rate: 0.00090237]
	Learning Rate: 0.00090237
	LOSS [training: 0.14280688174182396 | validation: 0.31456406895694744]
	TIME [epoch: 24.9 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14398877570197588		[learning rate: 0.00089812]
	Learning Rate: 0.000898118
	LOSS [training: 0.14398877570197588 | validation: 0.316632629824088]
	TIME [epoch: 24.9 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14654597027822353		[learning rate: 0.00089389]
	Learning Rate: 0.000893886
	LOSS [training: 0.14654597027822353 | validation: 0.2988475319649622]
	TIME [epoch: 24.9 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1203916605260595		[learning rate: 0.00088967]
	Learning Rate: 0.000889674
	LOSS [training: 0.1203916605260595 | validation: 0.3206187128018686]
	TIME [epoch: 24.9 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13299950986521653		[learning rate: 0.00088548]
	Learning Rate: 0.000885481
	LOSS [training: 0.13299950986521653 | validation: 0.303560638688067]
	TIME [epoch: 24.9 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14695299726147149		[learning rate: 0.00088131]
	Learning Rate: 0.000881309
	LOSS [training: 0.14695299726147149 | validation: 0.30544086985329066]
	TIME [epoch: 24.9 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13728765521297637		[learning rate: 0.00087716]
	Learning Rate: 0.000877156
	LOSS [training: 0.13728765521297637 | validation: 0.30789075096884383]
	TIME [epoch: 24.9 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12801736292342455		[learning rate: 0.00087302]
	Learning Rate: 0.000873023
	LOSS [training: 0.12801736292342455 | validation: 0.3001753644613285]
	TIME [epoch: 25 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14181979573145315		[learning rate: 0.00086891]
	Learning Rate: 0.000868909
	LOSS [training: 0.14181979573145315 | validation: 0.3174326616812129]
	TIME [epoch: 24.9 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12920410525855705		[learning rate: 0.00086481]
	Learning Rate: 0.000864815
	LOSS [training: 0.12920410525855705 | validation: 0.30783580802601124]
	TIME [epoch: 24.9 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12543668510823727		[learning rate: 0.00086074]
	Learning Rate: 0.00086074
	LOSS [training: 0.12543668510823727 | validation: 0.3009703664868947]
	TIME [epoch: 24.9 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14780760921418976		[learning rate: 0.00085668]
	Learning Rate: 0.000856684
	LOSS [training: 0.14780760921418976 | validation: 0.29448155126569436]
	TIME [epoch: 24.9 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13848834103415464		[learning rate: 0.00085265]
	Learning Rate: 0.000852647
	LOSS [training: 0.13848834103415464 | validation: 0.30436261148239774]
	TIME [epoch: 25 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13703109939374844		[learning rate: 0.00084863]
	Learning Rate: 0.000848629
	LOSS [training: 0.13703109939374844 | validation: 0.30446617947938204]
	TIME [epoch: 24.9 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14309856675888416		[learning rate: 0.00084463]
	Learning Rate: 0.00084463
	LOSS [training: 0.14309856675888416 | validation: 0.3043977943565167]
	TIME [epoch: 24.9 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13582216490653837		[learning rate: 0.00084065]
	Learning Rate: 0.00084065
	LOSS [training: 0.13582216490653837 | validation: 0.30416136180747383]
	TIME [epoch: 24.9 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12704107836351558		[learning rate: 0.00083669]
	Learning Rate: 0.000836689
	LOSS [training: 0.12704107836351558 | validation: 0.3010693484865587]
	TIME [epoch: 24.9 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12524373721457252		[learning rate: 0.00083275]
	Learning Rate: 0.000832746
	LOSS [training: 0.12524373721457252 | validation: 0.31662984277534056]
	TIME [epoch: 24.9 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12556741812628766		[learning rate: 0.00082882]
	Learning Rate: 0.000828822
	LOSS [training: 0.12556741812628766 | validation: 0.3090236127181741]
	TIME [epoch: 24.9 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14619246064601915		[learning rate: 0.00082492]
	Learning Rate: 0.000824917
	LOSS [training: 0.14619246064601915 | validation: 0.3056543313203578]
	TIME [epoch: 24.9 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14594676564866452		[learning rate: 0.00082103]
	Learning Rate: 0.00082103
	LOSS [training: 0.14594676564866452 | validation: 0.3135696749387158]
	TIME [epoch: 24.9 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12482249257241257		[learning rate: 0.00081716]
	Learning Rate: 0.000817161
	LOSS [training: 0.12482249257241257 | validation: 0.29743715920334884]
	TIME [epoch: 24.9 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15368321315370648		[learning rate: 0.00081331]
	Learning Rate: 0.000813311
	LOSS [training: 0.15368321315370648 | validation: 0.3085116670543784]
	TIME [epoch: 24.9 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15148686388355942		[learning rate: 0.00080948]
	Learning Rate: 0.000809478
	LOSS [training: 0.15148686388355942 | validation: 0.3128328969864111]
	TIME [epoch: 24.9 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13565787626983355		[learning rate: 0.00080566]
	Learning Rate: 0.000805664
	LOSS [training: 0.13565787626983355 | validation: 0.30105364354685415]
	TIME [epoch: 24.9 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13978274894768775		[learning rate: 0.00080187]
	Learning Rate: 0.000801868
	LOSS [training: 0.13978274894768775 | validation: 0.2915174152862701]
	TIME [epoch: 24.9 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15105620776645065		[learning rate: 0.00079809]
	Learning Rate: 0.000798089
	LOSS [training: 0.15105620776645065 | validation: 0.3134719155299243]
	TIME [epoch: 24.9 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14400844749789657		[learning rate: 0.00079433]
	Learning Rate: 0.000794328
	LOSS [training: 0.14400844749789657 | validation: 0.30600012565092943]
	TIME [epoch: 24.9 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12573516820824598		[learning rate: 0.00079059]
	Learning Rate: 0.000790585
	LOSS [training: 0.12573516820824598 | validation: 0.3105432466999351]
	TIME [epoch: 24.9 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.135860783681242		[learning rate: 0.00078686]
	Learning Rate: 0.00078686
	LOSS [training: 0.135860783681242 | validation: 0.3100531354673613]
	TIME [epoch: 24.9 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1322197243938025		[learning rate: 0.00078315]
	Learning Rate: 0.000783152
	LOSS [training: 0.1322197243938025 | validation: 0.2989975295637703]
	TIME [epoch: 24.9 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13449066428352488		[learning rate: 0.00077946]
	Learning Rate: 0.000779462
	LOSS [training: 0.13449066428352488 | validation: 0.29329684764807135]
	TIME [epoch: 24.9 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14149342850061622		[learning rate: 0.00077579]
	Learning Rate: 0.000775789
	LOSS [training: 0.14149342850061622 | validation: 0.29952432592470013]
	TIME [epoch: 24.9 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1350195141357196		[learning rate: 0.00077213]
	Learning Rate: 0.000772133
	LOSS [training: 0.1350195141357196 | validation: 0.30339033072168986]
	TIME [epoch: 24.9 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13421216650038129		[learning rate: 0.00076849]
	Learning Rate: 0.000768495
	LOSS [training: 0.13421216650038129 | validation: 0.3012660915268815]
	TIME [epoch: 24.9 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14828071684334113		[learning rate: 0.00076487]
	Learning Rate: 0.000764874
	LOSS [training: 0.14828071684334113 | validation: 0.30421241008304317]
	TIME [epoch: 24.9 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1383546049237477		[learning rate: 0.00076127]
	Learning Rate: 0.00076127
	LOSS [training: 0.1383546049237477 | validation: 0.3038426791564678]
	TIME [epoch: 24.9 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12724928141282504		[learning rate: 0.00075768]
	Learning Rate: 0.000757682
	LOSS [training: 0.12724928141282504 | validation: 0.29690323209103475]
	TIME [epoch: 24.9 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13781906210921957		[learning rate: 0.00075411]
	Learning Rate: 0.000754112
	LOSS [training: 0.13781906210921957 | validation: 0.31014460425063867]
	TIME [epoch: 24.9 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13626256169679252		[learning rate: 0.00075056]
	Learning Rate: 0.000750559
	LOSS [training: 0.13626256169679252 | validation: 0.303792222735854]
	TIME [epoch: 24.9 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12990845325354566		[learning rate: 0.00074702]
	Learning Rate: 0.000747022
	LOSS [training: 0.12990845325354566 | validation: 0.30531959458044716]
	TIME [epoch: 24.9 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v12_20240716_190535/states/model_facs_v3_dec2b_2dpca_v12_587.pth
Halted early. No improvement in validation loss for 200 epochs.
Finished training in 7866.116 seconds.
