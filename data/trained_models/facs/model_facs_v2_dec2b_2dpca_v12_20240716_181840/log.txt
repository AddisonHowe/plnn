Args:
Namespace(name='model_facs_v2_dec2b_2dpca_v12', outdir='out/model_training/model_facs_v2_dec2b_2dpca_v12', training_data='data/training_data/facs_v2/pca/dec2_fitonsubset/transition2_subset_ce_pn_m_pc12/training', validation_data='data/training_data/facs_v2/pca/dec2_fitonsubset/transition2_subset_ce_pn_m_pc12/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=10, batch_size=50, patience=200, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, quadratic_a=1.0, quadratic_b=1.0, ndims=2, nparams=2, nsigs=2, ncells=800, ncells_sample=800, model_do_sample=False, dt=0.005, dt_schedule='stepped', dt_schedule_bounds=[50, 500, 1000], dt_schedule_scales=[0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', kernel='multiscale', bw_range=[0.2, 0.5, 0.9, 1.1, 1.3, 1.5, 2.0], optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 942221923

Training model...

Saving initial model state to: out/model_training/model_facs_v2_dec2b_2dpca_v12_20240716_181840/states/model_facs_v2_dec2b_2dpca_v12_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.063031165480409		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.063031165480409 | validation: 0.9126585508307872]
	TIME [epoch: 36.1 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v12_20240716_181840/states/model_facs_v2_dec2b_2dpca_v12_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.722995035039238		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.722995035039238 | validation: 0.80311113015231]
	TIME [epoch: 7.92 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v12_20240716_181840/states/model_facs_v2_dec2b_2dpca_v12_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6556175986783652		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6556175986783652 | validation: 0.7808467639747234]
	TIME [epoch: 7.91 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v12_20240716_181840/states/model_facs_v2_dec2b_2dpca_v12_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6831691544385068		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6831691544385068 | validation: 0.7725327126380069]
	TIME [epoch: 7.92 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v12_20240716_181840/states/model_facs_v2_dec2b_2dpca_v12_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6109133057628398		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6109133057628398 | validation: 0.71539877137054]
	TIME [epoch: 7.92 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v12_20240716_181840/states/model_facs_v2_dec2b_2dpca_v12_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6373778325111908		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6373778325111908 | validation: 0.6942428889559973]
	TIME [epoch: 7.93 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v12_20240716_181840/states/model_facs_v2_dec2b_2dpca_v12_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5544347716574596		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5544347716574596 | validation: 0.6508351270481298]
	TIME [epoch: 7.89 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v12_20240716_181840/states/model_facs_v2_dec2b_2dpca_v12_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5890039688245348		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5890039688245348 | validation: 0.6004460688298776]
	TIME [epoch: 7.91 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v12_20240716_181840/states/model_facs_v2_dec2b_2dpca_v12_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4740111714483263		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4740111714483263 | validation: 0.6219619436464128]
	TIME [epoch: 7.9 sec]
EPOCH 10/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41223841223231117		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.41223841223231117 | validation: 0.4882643500582541]
	TIME [epoch: 7.9 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v12_20240716_181840/states/model_facs_v2_dec2b_2dpca_v12_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46888313514281404		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.46888313514281404 | validation: 0.4511819614947295]
	TIME [epoch: 7.89 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v12_20240716_181840/states/model_facs_v2_dec2b_2dpca_v12_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34450197188720827		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.34450197188720827 | validation: 0.4250912578969542]
	TIME [epoch: 7.9 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v12_20240716_181840/states/model_facs_v2_dec2b_2dpca_v12_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.327830604194149		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.327830604194149 | validation: 0.5119735884891428]
	TIME [epoch: 7.9 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32013545116485526		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.32013545116485526 | validation: 0.4962051124549436]
	TIME [epoch: 7.89 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3783910768731084		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3783910768731084 | validation: 0.4283604317292694]
	TIME [epoch: 7.89 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3168317214251347		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3168317214251347 | validation: 0.45213461861408494]
	TIME [epoch: 7.89 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3136171483964572		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3136171483964572 | validation: 0.40859263866177364]
	TIME [epoch: 7.9 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v12_20240716_181840/states/model_facs_v2_dec2b_2dpca_v12_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31211650794407675		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.31211650794407675 | validation: 0.4474708648077405]
	TIME [epoch: 7.89 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3209964175017014		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3209964175017014 | validation: 0.4424243487053988]
	TIME [epoch: 7.88 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2893846914634851		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2893846914634851 | validation: 0.37870112893254637]
	TIME [epoch: 7.89 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v12_20240716_181840/states/model_facs_v2_dec2b_2dpca_v12_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25596622157790333		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.25596622157790333 | validation: 0.4294533006246769]
	TIME [epoch: 7.9 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29546538082445994		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.29546538082445994 | validation: 0.43285675043014127]
	TIME [epoch: 7.9 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2798132242968866		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2798132242968866 | validation: 0.4017698176340379]
	TIME [epoch: 7.89 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25755280672275827		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.25755280672275827 | validation: 0.4121123824389929]
	TIME [epoch: 7.89 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2517394411927885		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2517394411927885 | validation: 0.3989007557221503]
	TIME [epoch: 7.89 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31207579866408935		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.31207579866408935 | validation: 0.3720778169018275]
	TIME [epoch: 7.91 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v12_20240716_181840/states/model_facs_v2_dec2b_2dpca_v12_26.pth
	Model improved!!!
EPOCH 27/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24038251723531662		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24038251723531662 | validation: 0.37484950217565033]
	TIME [epoch: 7.91 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2898231030995306		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2898231030995306 | validation: 0.40283493059321]
	TIME [epoch: 7.91 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2571889808925275		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2571889808925275 | validation: 0.381215790044444]
	TIME [epoch: 7.91 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2350445094684881		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2350445094684881 | validation: 0.4198596875715789]
	TIME [epoch: 7.93 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29843505163672035		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.29843505163672035 | validation: 0.3821427083291632]
	TIME [epoch: 7.88 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23723389207840073		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23723389207840073 | validation: 0.3574104608194652]
	TIME [epoch: 7.89 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v12_20240716_181840/states/model_facs_v2_dec2b_2dpca_v12_32.pth
	Model improved!!!
EPOCH 33/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26457943807989154		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.26457943807989154 | validation: 0.40936721101200474]
	TIME [epoch: 7.89 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28237927068855245		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.28237927068855245 | validation: 0.3657012078472371]
	TIME [epoch: 7.9 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25530989421472605		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.25530989421472605 | validation: 0.39432476397571564]
	TIME [epoch: 7.9 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2562741526411474		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2562741526411474 | validation: 0.38320440982640863]
	TIME [epoch: 7.89 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23372965586644395		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23372965586644395 | validation: 0.37004321887659686]
	TIME [epoch: 7.89 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2763851560253719		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2763851560253719 | validation: 0.3919068288201834]
	TIME [epoch: 7.89 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23984678044402283		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23984678044402283 | validation: 0.3385862893550699]
	TIME [epoch: 7.9 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v12_20240716_181840/states/model_facs_v2_dec2b_2dpca_v12_39.pth
	Model improved!!!
EPOCH 40/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2403869816227128		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2403869816227128 | validation: 0.37235660387197034]
	TIME [epoch: 7.9 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.225941616785229		[learning rate: 0.0099646]
	Learning Rate: 0.00996464
	LOSS [training: 0.225941616785229 | validation: 0.3867269554781993]
	TIME [epoch: 7.89 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2350633078093336		[learning rate: 0.0099206]
	Learning Rate: 0.00992061
	LOSS [training: 0.2350633078093336 | validation: 0.3746752803674615]
	TIME [epoch: 7.89 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27201039775075386		[learning rate: 0.0098768]
	Learning Rate: 0.00987678
	LOSS [training: 0.27201039775075386 | validation: 0.3539731223831616]
	TIME [epoch: 7.9 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21272689751100718		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 0.21272689751100718 | validation: 0.4116691354536765]
	TIME [epoch: 7.9 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2576967613831941		[learning rate: 0.0097897]
	Learning Rate: 0.0097897
	LOSS [training: 0.2576967613831941 | validation: 0.36878366652284267]
	TIME [epoch: 7.89 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21842554318682034		[learning rate: 0.0097464]
	Learning Rate: 0.00974644
	LOSS [training: 0.21842554318682034 | validation: 0.42442276933865547]
	TIME [epoch: 7.89 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2384029381097942		[learning rate: 0.0097034]
	Learning Rate: 0.00970338
	LOSS [training: 0.2384029381097942 | validation: 0.38509884391061544]
	TIME [epoch: 7.89 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24452737461187984		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 0.24452737461187984 | validation: 0.3664542881893759]
	TIME [epoch: 7.91 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25941387611863387		[learning rate: 0.0096178]
	Learning Rate: 0.00961783
	LOSS [training: 0.25941387611863387 | validation: 0.37445014948403127]
	TIME [epoch: 7.89 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25216210537518247		[learning rate: 0.0095753]
	Learning Rate: 0.00957533
	LOSS [training: 0.25216210537518247 | validation: 0.3784823618719455]
	TIME [epoch: 7.89 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25005943129349484		[learning rate: 0.009533]
	Learning Rate: 0.00953303
	LOSS [training: 0.25005943129349484 | validation: 0.398157881916815]
	TIME [epoch: 40.8 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24690375600556785		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 0.24690375600556785 | validation: 0.36127044680456516]
	TIME [epoch: 15.3 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23429688370888585		[learning rate: 0.009449]
	Learning Rate: 0.00944897
	LOSS [training: 0.23429688370888585 | validation: 0.34503561924771053]
	TIME [epoch: 15.3 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21962120034251714		[learning rate: 0.0094072]
	Learning Rate: 0.00940722
	LOSS [training: 0.21962120034251714 | validation: 0.345964879501991]
	TIME [epoch: 15.2 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2298496575489341		[learning rate: 0.0093657]
	Learning Rate: 0.00936566
	LOSS [training: 0.2298496575489341 | validation: 0.4583870020991143]
	TIME [epoch: 15.3 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24640568714224206		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 0.24640568714224206 | validation: 0.3432679460377881]
	TIME [epoch: 15.3 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24746947183132723		[learning rate: 0.0092831]
	Learning Rate: 0.00928308
	LOSS [training: 0.24746947183132723 | validation: 0.38753630771076997]
	TIME [epoch: 15.3 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20637018547009026		[learning rate: 0.0092421]
	Learning Rate: 0.00924207
	LOSS [training: 0.20637018547009026 | validation: 0.3292320389289577]
	TIME [epoch: 15.2 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v12_20240716_181840/states/model_facs_v2_dec2b_2dpca_v12_58.pth
	Model improved!!!
EPOCH 59/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20579744255763127		[learning rate: 0.0092012]
	Learning Rate: 0.00920124
	LOSS [training: 0.20579744255763127 | validation: 0.3526659620844178]
	TIME [epoch: 15.3 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22924372341772292		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 0.22924372341772292 | validation: 0.3423537737905503]
	TIME [epoch: 15.3 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22868670801474428		[learning rate: 0.0091201]
	Learning Rate: 0.00912011
	LOSS [training: 0.22868670801474428 | validation: 0.4195027034950546]
	TIME [epoch: 15.2 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2233443614042115		[learning rate: 0.0090798]
	Learning Rate: 0.00907981
	LOSS [training: 0.2233443614042115 | validation: 0.5069757747819843]
	TIME [epoch: 15.3 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22995366980833526		[learning rate: 0.0090397]
	Learning Rate: 0.0090397
	LOSS [training: 0.22995366980833526 | validation: 0.35602234886209116]
	TIME [epoch: 15.2 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2116208174856579		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 0.2116208174856579 | validation: 0.34113131553013976]
	TIME [epoch: 15.3 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22640942546311163		[learning rate: 0.00896]
	Learning Rate: 0.00895999
	LOSS [training: 0.22640942546311163 | validation: 0.35893084772539846]
	TIME [epoch: 15.3 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21722045633710135		[learning rate: 0.0089204]
	Learning Rate: 0.00892041
	LOSS [training: 0.21722045633710135 | validation: 0.35219510189178077]
	TIME [epoch: 15.3 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21218364424136435		[learning rate: 0.008881]
	Learning Rate: 0.00888099
	LOSS [training: 0.21218364424136435 | validation: 0.3156598703614104]
	TIME [epoch: 15.3 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v12_20240716_181840/states/model_facs_v2_dec2b_2dpca_v12_67.pth
	Model improved!!!
EPOCH 68/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20122127706058546		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 0.20122127706058546 | validation: 0.3446255980468939]
	TIME [epoch: 15.3 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21123626154980624		[learning rate: 0.0088027]
	Learning Rate: 0.00880269
	LOSS [training: 0.21123626154980624 | validation: 0.4031313409047544]
	TIME [epoch: 15.3 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23305462985408631		[learning rate: 0.0087638]
	Learning Rate: 0.0087638
	LOSS [training: 0.23305462985408631 | validation: 0.36497562691844826]
	TIME [epoch: 15.3 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23196326218139585		[learning rate: 0.0087251]
	Learning Rate: 0.00872508
	LOSS [training: 0.23196326218139585 | validation: 0.36080719460048083]
	TIME [epoch: 15.3 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20672666535235132		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 0.20672666535235132 | validation: 0.39237733107885286]
	TIME [epoch: 15.3 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20271101097334038		[learning rate: 0.0086481]
	Learning Rate: 0.00864815
	LOSS [training: 0.20271101097334038 | validation: 0.4274797722881295]
	TIME [epoch: 15.3 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20123592255192407		[learning rate: 0.0086099]
	Learning Rate: 0.00860994
	LOSS [training: 0.20123592255192407 | validation: 0.3521638788185034]
	TIME [epoch: 15.3 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2037371730403831		[learning rate: 0.0085719]
	Learning Rate: 0.0085719
	LOSS [training: 0.2037371730403831 | validation: 0.3513955317417057]
	TIME [epoch: 15.3 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22131474836338497		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 0.22131474836338497 | validation: 0.30879367790214074]
	TIME [epoch: 15.3 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v12_20240716_181840/states/model_facs_v2_dec2b_2dpca_v12_76.pth
	Model improved!!!
EPOCH 77/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2398194582182526		[learning rate: 0.0084963]
	Learning Rate: 0.00849632
	LOSS [training: 0.2398194582182526 | validation: 0.3411641792604442]
	TIME [epoch: 15.3 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19055844964786936		[learning rate: 0.0084588]
	Learning Rate: 0.00845878
	LOSS [training: 0.19055844964786936 | validation: 0.3468105049325212]
	TIME [epoch: 15.3 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19024148391133686		[learning rate: 0.0084214]
	Learning Rate: 0.00842141
	LOSS [training: 0.19024148391133686 | validation: 0.35120343755403827]
	TIME [epoch: 15.2 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21968331812156489		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 0.21968331812156489 | validation: 0.3257778946066823]
	TIME [epoch: 15.3 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20360748691971584		[learning rate: 0.0083472]
	Learning Rate: 0.00834715
	LOSS [training: 0.20360748691971584 | validation: 0.31502015492294666]
	TIME [epoch: 15.3 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2073022830139335		[learning rate: 0.0083103]
	Learning Rate: 0.00831027
	LOSS [training: 0.2073022830139335 | validation: 0.3688734035303258]
	TIME [epoch: 15.3 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2016748435387708		[learning rate: 0.0082736]
	Learning Rate: 0.00827356
	LOSS [training: 0.2016748435387708 | validation: 0.4046532350220541]
	TIME [epoch: 15.3 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20372279316562505		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 0.20372279316562505 | validation: 0.3273777623228287]
	TIME [epoch: 15.2 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2002562257001718		[learning rate: 0.0082006]
	Learning Rate: 0.00820061
	LOSS [training: 0.2002562257001718 | validation: 0.3549776303020458]
	TIME [epoch: 15.3 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22731969550431158		[learning rate: 0.0081644]
	Learning Rate: 0.00816438
	LOSS [training: 0.22731969550431158 | validation: 0.3682675455738157]
	TIME [epoch: 15.3 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.206755877959508		[learning rate: 0.0081283]
	Learning Rate: 0.0081283
	LOSS [training: 0.206755877959508 | validation: 0.30389049330771767]
	TIME [epoch: 15.3 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v12_20240716_181840/states/model_facs_v2_dec2b_2dpca_v12_87.pth
	Model improved!!!
EPOCH 88/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2131410523081117		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 0.2131410523081117 | validation: 0.3111987658880744]
	TIME [epoch: 15.3 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18257537896118706		[learning rate: 0.0080566]
	Learning Rate: 0.00805664
	LOSS [training: 0.18257537896118706 | validation: 0.3484427080944097]
	TIME [epoch: 15.3 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21231992490205673		[learning rate: 0.008021]
	Learning Rate: 0.00802104
	LOSS [training: 0.21231992490205673 | validation: 0.33293849670722275]
	TIME [epoch: 15.3 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2177343328845962		[learning rate: 0.0079856]
	Learning Rate: 0.0079856
	LOSS [training: 0.2177343328845962 | validation: 0.42465339557752446]
	TIME [epoch: 15.3 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1992425308114251		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 0.1992425308114251 | validation: 0.29687025677991336]
	TIME [epoch: 15.3 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v12_20240716_181840/states/model_facs_v2_dec2b_2dpca_v12_92.pth
	Model improved!!!
EPOCH 93/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18209933027131892		[learning rate: 0.0079152]
	Learning Rate: 0.00791519
	LOSS [training: 0.18209933027131892 | validation: 0.3822797473994931]
	TIME [epoch: 15.3 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2080125369314874		[learning rate: 0.0078802]
	Learning Rate: 0.00788022
	LOSS [training: 0.2080125369314874 | validation: 0.3250646833451163]
	TIME [epoch: 15.3 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1819830684085076		[learning rate: 0.0078454]
	Learning Rate: 0.00784541
	LOSS [training: 0.1819830684085076 | validation: 0.3626864429864586]
	TIME [epoch: 15.3 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2027815138913483		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 0.2027815138913483 | validation: 0.33650875148573633]
	TIME [epoch: 15.3 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20705217578148422		[learning rate: 0.0077762]
	Learning Rate: 0.00777623
	LOSS [training: 0.20705217578148422 | validation: 0.3150618426514105]
	TIME [epoch: 15.3 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21004555229490665		[learning rate: 0.0077419]
	Learning Rate: 0.00774188
	LOSS [training: 0.21004555229490665 | validation: 0.35262298860545377]
	TIME [epoch: 15.3 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18823388795089893		[learning rate: 0.0077077]
	Learning Rate: 0.00770767
	LOSS [training: 0.18823388795089893 | validation: 0.40773673143147576]
	TIME [epoch: 15.3 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2232622360149752		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 0.2232622360149752 | validation: 0.34116092549803734]
	TIME [epoch: 15.3 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19651494735308753		[learning rate: 0.0076397]
	Learning Rate: 0.00763971
	LOSS [training: 0.19651494735308753 | validation: 0.3728310354707511]
	TIME [epoch: 15.3 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19668743737584599		[learning rate: 0.007606]
	Learning Rate: 0.00760596
	LOSS [training: 0.19668743737584599 | validation: 0.4032391232884437]
	TIME [epoch: 15.3 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19335067070354722		[learning rate: 0.0075724]
	Learning Rate: 0.00757235
	LOSS [training: 0.19335067070354722 | validation: 0.4062081574361067]
	TIME [epoch: 15.3 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21725567231891363		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 0.21725567231891363 | validation: 0.29593405887209306]
	TIME [epoch: 15.3 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v12_20240716_181840/states/model_facs_v2_dec2b_2dpca_v12_104.pth
	Model improved!!!
EPOCH 105/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20817543653255752		[learning rate: 0.0075056]
	Learning Rate: 0.00750559
	LOSS [training: 0.20817543653255752 | validation: 0.3238594464596714]
	TIME [epoch: 15.3 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1995727463257952		[learning rate: 0.0074724]
	Learning Rate: 0.00747242
	LOSS [training: 0.1995727463257952 | validation: 0.347172992729176]
	TIME [epoch: 15.3 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1974952250416133		[learning rate: 0.0074394]
	Learning Rate: 0.00743941
	LOSS [training: 0.1974952250416133 | validation: 0.3207616234913794]
	TIME [epoch: 15.3 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1837329605602978		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 0.1837329605602978 | validation: 0.3358971619250547]
	TIME [epoch: 15.3 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18585095257035678		[learning rate: 0.0073738]
	Learning Rate: 0.00737382
	LOSS [training: 0.18585095257035678 | validation: 0.3177401229429991]
	TIME [epoch: 15.3 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20428673834887437		[learning rate: 0.0073412]
	Learning Rate: 0.00734124
	LOSS [training: 0.20428673834887437 | validation: 0.3103228292151633]
	TIME [epoch: 15.3 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19357151856365493		[learning rate: 0.0073088]
	Learning Rate: 0.0073088
	LOSS [training: 0.19357151856365493 | validation: 0.30911757076621194]
	TIME [epoch: 15.3 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20395086166215443		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 0.20395086166215443 | validation: 0.38244994979049174]
	TIME [epoch: 15.3 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2135880343623419		[learning rate: 0.0072444]
	Learning Rate: 0.00724436
	LOSS [training: 0.2135880343623419 | validation: 0.3120495204222459]
	TIME [epoch: 15.3 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18473748326025824		[learning rate: 0.0072124]
	Learning Rate: 0.00721235
	LOSS [training: 0.18473748326025824 | validation: 0.3267107348809882]
	TIME [epoch: 15.3 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1830746072594739		[learning rate: 0.0071805]
	Learning Rate: 0.00718049
	LOSS [training: 0.1830746072594739 | validation: 0.351926372019983]
	TIME [epoch: 15.3 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2040372043939939		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 0.2040372043939939 | validation: 0.3475150929703254]
	TIME [epoch: 15.3 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20722182844428225		[learning rate: 0.0071172]
	Learning Rate: 0.00711718
	LOSS [training: 0.20722182844428225 | validation: 0.31829996870278604]
	TIME [epoch: 15.3 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18477283235369088		[learning rate: 0.0070857]
	Learning Rate: 0.00708573
	LOSS [training: 0.18477283235369088 | validation: 0.31727237169851874]
	TIME [epoch: 15.3 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20408900526196766		[learning rate: 0.0070544]
	Learning Rate: 0.00705442
	LOSS [training: 0.20408900526196766 | validation: 0.3987518185437265]
	TIME [epoch: 15.3 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19203851942434638		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 0.19203851942434638 | validation: 0.3319363392745778]
	TIME [epoch: 15.3 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1837236832338846		[learning rate: 0.0069922]
	Learning Rate: 0.00699222
	LOSS [training: 0.1837236832338846 | validation: 0.31333034071495386]
	TIME [epoch: 15.3 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19264669546696933		[learning rate: 0.0069613]
	Learning Rate: 0.00696133
	LOSS [training: 0.19264669546696933 | validation: 0.31213600000780656]
	TIME [epoch: 15.3 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18296112493158154		[learning rate: 0.0069306]
	Learning Rate: 0.00693057
	LOSS [training: 0.18296112493158154 | validation: 0.3086275528703976]
	TIME [epoch: 15.3 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1905846833272522		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 0.1905846833272522 | validation: 0.41095662483417683]
	TIME [epoch: 15.3 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19283119456295555		[learning rate: 0.0068695]
	Learning Rate: 0.00686947
	LOSS [training: 0.19283119456295555 | validation: 0.3606226686261747]
	TIME [epoch: 15.3 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17825125991110408		[learning rate: 0.0068391]
	Learning Rate: 0.00683912
	LOSS [training: 0.17825125991110408 | validation: 0.4023884660474248]
	TIME [epoch: 15.3 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21302998961571445		[learning rate: 0.0068089]
	Learning Rate: 0.0068089
	LOSS [training: 0.21302998961571445 | validation: 0.3538015093093004]
	TIME [epoch: 15.3 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2005674804108441		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 0.2005674804108441 | validation: 0.3255043914656766]
	TIME [epoch: 15.3 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19603883094811397		[learning rate: 0.0067489]
	Learning Rate: 0.00674887
	LOSS [training: 0.19603883094811397 | validation: 0.3124453718229409]
	TIME [epoch: 15.3 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17762975971447664		[learning rate: 0.006719]
	Learning Rate: 0.00671905
	LOSS [training: 0.17762975971447664 | validation: 0.3176661003861853]
	TIME [epoch: 15.3 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1939686735143192		[learning rate: 0.0066894]
	Learning Rate: 0.00668936
	LOSS [training: 0.1939686735143192 | validation: 0.3253107799646182]
	TIME [epoch: 15.3 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17611865756544307		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 0.17611865756544307 | validation: 0.3102496910043815]
	TIME [epoch: 15.3 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19593387415942448		[learning rate: 0.0066304]
	Learning Rate: 0.00663038
	LOSS [training: 0.19593387415942448 | validation: 0.2996195340156421]
	TIME [epoch: 15.3 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18475425825036218		[learning rate: 0.0066011]
	Learning Rate: 0.00660109
	LOSS [training: 0.18475425825036218 | validation: 0.32807279325166167]
	TIME [epoch: 15.3 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17916194971662394		[learning rate: 0.0065719]
	Learning Rate: 0.00657192
	LOSS [training: 0.17916194971662394 | validation: 0.3357463681641995]
	TIME [epoch: 15.3 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19349532589680035		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 0.19349532589680035 | validation: 0.33327825258563387]
	TIME [epoch: 15.2 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1922817226757489		[learning rate: 0.006514]
	Learning Rate: 0.00651398
	LOSS [training: 0.1922817226757489 | validation: 0.31329939196364237]
	TIME [epoch: 15.3 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17533824178039742		[learning rate: 0.0064852]
	Learning Rate: 0.00648519
	LOSS [training: 0.17533824178039742 | validation: 0.35007494610479256]
	TIME [epoch: 15.3 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18273442084435362		[learning rate: 0.0064565]
	Learning Rate: 0.00645654
	LOSS [training: 0.18273442084435362 | validation: 0.41321437563521335]
	TIME [epoch: 15.3 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1835654659128636		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 0.1835654659128636 | validation: 0.32242710751381076]
	TIME [epoch: 15.3 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18621400496009324		[learning rate: 0.0063996]
	Learning Rate: 0.00639961
	LOSS [training: 0.18621400496009324 | validation: 0.2915942941880037]
	TIME [epoch: 15.3 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v12_20240716_181840/states/model_facs_v2_dec2b_2dpca_v12_141.pth
	Model improved!!!
EPOCH 142/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1898178837213958		[learning rate: 0.0063713]
	Learning Rate: 0.00637134
	LOSS [training: 0.1898178837213958 | validation: 0.3061321952802182]
	TIME [epoch: 15.3 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17776425657596598		[learning rate: 0.0063432]
	Learning Rate: 0.00634319
	LOSS [training: 0.17776425657596598 | validation: 0.33063030617644906]
	TIME [epoch: 15.4 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1854940797285254		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 0.1854940797285254 | validation: 0.31151322626229144]
	TIME [epoch: 15.3 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19216215867574313		[learning rate: 0.0062873]
	Learning Rate: 0.00628726
	LOSS [training: 0.19216215867574313 | validation: 0.3796350918610291]
	TIME [epoch: 15.3 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2037739886234486		[learning rate: 0.0062595]
	Learning Rate: 0.00625948
	LOSS [training: 0.2037739886234486 | validation: 0.3340389241394635]
	TIME [epoch: 15.3 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1833111750117928		[learning rate: 0.0062318]
	Learning Rate: 0.00623183
	LOSS [training: 0.1833111750117928 | validation: 0.34649865840065]
	TIME [epoch: 15.3 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17915231031845416		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 0.17915231031845416 | validation: 0.32639691198307313]
	TIME [epoch: 15.3 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18293970050119027		[learning rate: 0.0061769]
	Learning Rate: 0.00617688
	LOSS [training: 0.18293970050119027 | validation: 0.4060839293952074]
	TIME [epoch: 15.3 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20552410997304746		[learning rate: 0.0061496]
	Learning Rate: 0.00614959
	LOSS [training: 0.20552410997304746 | validation: 0.42745432429921115]
	TIME [epoch: 15.3 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21452113970896355		[learning rate: 0.0061224]
	Learning Rate: 0.00612242
	LOSS [training: 0.21452113970896355 | validation: 0.35014190641386994]
	TIME [epoch: 15.3 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18447353998674976		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 0.18447353998674976 | validation: 0.3519080887638514]
	TIME [epoch: 15.3 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17433467982386727		[learning rate: 0.0060684]
	Learning Rate: 0.00606844
	LOSS [training: 0.17433467982386727 | validation: 0.2949054806066025]
	TIME [epoch: 15.3 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1862436027664011		[learning rate: 0.0060416]
	Learning Rate: 0.00604163
	LOSS [training: 0.1862436027664011 | validation: 0.3097109605822405]
	TIME [epoch: 15.3 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18288772607572482		[learning rate: 0.0060149]
	Learning Rate: 0.00601493
	LOSS [training: 0.18288772607572482 | validation: 0.3433230148077728]
	TIME [epoch: 15.3 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17224575072065143		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 0.17224575072065143 | validation: 0.31939736304298544]
	TIME [epoch: 15.3 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1903104371815554		[learning rate: 0.0059619]
	Learning Rate: 0.0059619
	LOSS [training: 0.1903104371815554 | validation: 0.3068392352736169]
	TIME [epoch: 15.3 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18098707282118473		[learning rate: 0.0059356]
	Learning Rate: 0.00593556
	LOSS [training: 0.18098707282118473 | validation: 0.3627938429827252]
	TIME [epoch: 15.3 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18043560805858413		[learning rate: 0.0059093]
	Learning Rate: 0.00590933
	LOSS [training: 0.18043560805858413 | validation: 0.3316699150680548]
	TIME [epoch: 15.3 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.200561431901084		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 0.200561431901084 | validation: 0.30641114972654476]
	TIME [epoch: 15.3 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17907888281056544		[learning rate: 0.0058572]
	Learning Rate: 0.00585723
	LOSS [training: 0.17907888281056544 | validation: 0.33100630870092135]
	TIME [epoch: 15.3 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16908683823801166		[learning rate: 0.0058314]
	Learning Rate: 0.00583135
	LOSS [training: 0.16908683823801166 | validation: 0.3106804720476007]
	TIME [epoch: 15.3 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1730794372758342		[learning rate: 0.0058056]
	Learning Rate: 0.00580559
	LOSS [training: 0.1730794372758342 | validation: 0.31032367955466394]
	TIME [epoch: 15.3 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17304897098300626		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 0.17304897098300626 | validation: 0.34401598367881325]
	TIME [epoch: 15.3 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17470892995546689		[learning rate: 0.0057544]
	Learning Rate: 0.0057544
	LOSS [training: 0.17470892995546689 | validation: 0.30612817303031353]
	TIME [epoch: 15.3 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18210330708249994		[learning rate: 0.005729]
	Learning Rate: 0.00572897
	LOSS [training: 0.18210330708249994 | validation: 0.30857156970175376]
	TIME [epoch: 15.3 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17551401062843033		[learning rate: 0.0057037]
	Learning Rate: 0.00570366
	LOSS [training: 0.17551401062843033 | validation: 0.32916287285071966]
	TIME [epoch: 15.3 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18042138599648577		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 0.18042138599648577 | validation: 0.3462936686414155]
	TIME [epoch: 15.3 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18218953452361153		[learning rate: 0.0056534]
	Learning Rate: 0.00565337
	LOSS [training: 0.18218953452361153 | validation: 0.336462224646646]
	TIME [epoch: 15.3 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1803092525737778		[learning rate: 0.0056284]
	Learning Rate: 0.0056284
	LOSS [training: 0.1803092525737778 | validation: 0.3058944752535847]
	TIME [epoch: 15.3 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17783630926641567		[learning rate: 0.0056035]
	Learning Rate: 0.00560353
	LOSS [training: 0.17783630926641567 | validation: 0.3129206566351242]
	TIME [epoch: 15.3 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17565472279593902		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 0.17565472279593902 | validation: 0.3125204678520258]
	TIME [epoch: 15.3 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1811723723635097		[learning rate: 0.0055541]
	Learning Rate: 0.00555412
	LOSS [training: 0.1811723723635097 | validation: 0.3600107847779912]
	TIME [epoch: 15.3 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17492979978631307		[learning rate: 0.0055296]
	Learning Rate: 0.00552958
	LOSS [training: 0.17492979978631307 | validation: 0.2984073973890902]
	TIME [epoch: 15.4 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17559271914013713		[learning rate: 0.0055052]
	Learning Rate: 0.00550515
	LOSS [training: 0.17559271914013713 | validation: 0.30505378252370335]
	TIME [epoch: 15.3 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18352934143289357		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 0.18352934143289357 | validation: 0.31262158670641754]
	TIME [epoch: 15.3 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16245849035643317		[learning rate: 0.0054566]
	Learning Rate: 0.00545661
	LOSS [training: 0.16245849035643317 | validation: 0.3088046470426169]
	TIME [epoch: 15.2 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1771471794499618		[learning rate: 0.0054325]
	Learning Rate: 0.0054325
	LOSS [training: 0.1771471794499618 | validation: 0.33005382231953156]
	TIME [epoch: 15.3 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18660994386683122		[learning rate: 0.0054085]
	Learning Rate: 0.0054085
	LOSS [training: 0.18660994386683122 | validation: 0.3277948396690745]
	TIME [epoch: 15.3 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17403444404743224		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 0.17403444404743224 | validation: 0.30393228814298473]
	TIME [epoch: 15.3 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17710324339216105		[learning rate: 0.0053608]
	Learning Rate: 0.00536081
	LOSS [training: 0.17710324339216105 | validation: 0.32711826130576716]
	TIME [epoch: 15.3 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18163880674028868		[learning rate: 0.0053371]
	Learning Rate: 0.00533713
	LOSS [training: 0.18163880674028868 | validation: 0.32075407283116797]
	TIME [epoch: 15.3 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18738708127240322		[learning rate: 0.0053135]
	Learning Rate: 0.00531355
	LOSS [training: 0.18738708127240322 | validation: 0.3535022626647354]
	TIME [epoch: 15.3 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1740027423012816		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 0.1740027423012816 | validation: 0.32333943392545655]
	TIME [epoch: 15.3 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1789551605205814		[learning rate: 0.0052667]
	Learning Rate: 0.0052667
	LOSS [training: 0.1789551605205814 | validation: 0.3078045515183628]
	TIME [epoch: 15.2 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17072367473565392		[learning rate: 0.0052434]
	Learning Rate: 0.00524343
	LOSS [training: 0.17072367473565392 | validation: 0.3211760987936766]
	TIME [epoch: 15.3 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16963397878482578		[learning rate: 0.0052203]
	Learning Rate: 0.00522026
	LOSS [training: 0.16963397878482578 | validation: 0.28951049065711376]
	TIME [epoch: 15.2 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v12_20240716_181840/states/model_facs_v2_dec2b_2dpca_v12_187.pth
	Model improved!!!
EPOCH 188/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16768399857959937		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 0.16768399857959937 | validation: 0.29909221846206097]
	TIME [epoch: 15.4 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17955761451262992		[learning rate: 0.0051742]
	Learning Rate: 0.00517423
	LOSS [training: 0.17955761451262992 | validation: 0.33825465737483806]
	TIME [epoch: 15.3 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16710307081701634		[learning rate: 0.0051514]
	Learning Rate: 0.00515137
	LOSS [training: 0.16710307081701634 | validation: 0.37007439882876164]
	TIME [epoch: 15.4 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1762927124707652		[learning rate: 0.0051286]
	Learning Rate: 0.00512861
	LOSS [training: 0.1762927124707652 | validation: 0.3000285069153682]
	TIME [epoch: 15.4 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17027688718256906		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 0.17027688718256906 | validation: 0.2929754903599513]
	TIME [epoch: 15.4 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1810107080881199		[learning rate: 0.0050834]
	Learning Rate: 0.00508339
	LOSS [training: 0.1810107080881199 | validation: 0.31486327080982734]
	TIME [epoch: 15.4 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17211285164698356		[learning rate: 0.0050609]
	Learning Rate: 0.00506093
	LOSS [training: 0.17211285164698356 | validation: 0.30582054566147004]
	TIME [epoch: 15.3 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1678414921051065		[learning rate: 0.0050386]
	Learning Rate: 0.00503857
	LOSS [training: 0.1678414921051065 | validation: 0.2994998317961216]
	TIME [epoch: 15.4 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16479142417564263		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 0.16479142417564263 | validation: 0.30354655229274036]
	TIME [epoch: 15.4 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17486332939058125		[learning rate: 0.0049941]
	Learning Rate: 0.00499415
	LOSS [training: 0.17486332939058125 | validation: 0.31347996859947713]
	TIME [epoch: 15.4 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17251250434257875		[learning rate: 0.0049721]
	Learning Rate: 0.00497208
	LOSS [training: 0.17251250434257875 | validation: 0.31264429442965913]
	TIME [epoch: 15.4 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18075206101055277		[learning rate: 0.0049501]
	Learning Rate: 0.00495012
	LOSS [training: 0.18075206101055277 | validation: 0.3248057148554205]
	TIME [epoch: 15.3 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16432409976308968		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 0.16432409976308968 | validation: 0.32182561773482377]
	TIME [epoch: 15.4 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17040313168317994		[learning rate: 0.0049065]
	Learning Rate: 0.00490647
	LOSS [training: 0.17040313168317994 | validation: 0.29534963206412573]
	TIME [epoch: 15.3 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18468633542569562		[learning rate: 0.0048848]
	Learning Rate: 0.00488479
	LOSS [training: 0.18468633542569562 | validation: 0.30778775299558414]
	TIME [epoch: 15.3 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1728307038006169		[learning rate: 0.0048632]
	Learning Rate: 0.00486321
	LOSS [training: 0.1728307038006169 | validation: 0.30785111904762114]
	TIME [epoch: 15.3 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18915348818569805		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 0.18915348818569805 | validation: 0.33198677848522296]
	TIME [epoch: 15.3 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1719742061375725		[learning rate: 0.0048203]
	Learning Rate: 0.00482033
	LOSS [training: 0.1719742061375725 | validation: 0.3064858916485279]
	TIME [epoch: 15.4 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17038937199567497		[learning rate: 0.004799]
	Learning Rate: 0.00479903
	LOSS [training: 0.17038937199567497 | validation: 0.28213581385221886]
	TIME [epoch: 15.3 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v12_20240716_181840/states/model_facs_v2_dec2b_2dpca_v12_206.pth
	Model improved!!!
EPOCH 207/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17058550460795516		[learning rate: 0.0047778]
	Learning Rate: 0.00477783
	LOSS [training: 0.17058550460795516 | validation: 0.28856726477506806]
	TIME [epoch: 15.3 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16375978176863185		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.16375978176863185 | validation: 0.3386421326340728]
	TIME [epoch: 15.3 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.181151121375532		[learning rate: 0.0047357]
	Learning Rate: 0.0047357
	LOSS [training: 0.181151121375532 | validation: 0.30775312115837056]
	TIME [epoch: 15.3 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16425887403968464		[learning rate: 0.0047148]
	Learning Rate: 0.00471478
	LOSS [training: 0.16425887403968464 | validation: 0.32969808925418886]
	TIME [epoch: 15.3 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17568383940504634		[learning rate: 0.0046939]
	Learning Rate: 0.00469395
	LOSS [training: 0.17568383940504634 | validation: 0.33334799449563]
	TIME [epoch: 15.3 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.168476175418751		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 0.168476175418751 | validation: 0.31271705195551325]
	TIME [epoch: 15.3 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18696147381464168		[learning rate: 0.0046526]
	Learning Rate: 0.00465256
	LOSS [training: 0.18696147381464168 | validation: 0.285759393304388]
	TIME [epoch: 15.3 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15962521521627218		[learning rate: 0.004632]
	Learning Rate: 0.00463201
	LOSS [training: 0.15962521521627218 | validation: 0.30311551515935853]
	TIME [epoch: 15.3 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17384084874240818		[learning rate: 0.0046115]
	Learning Rate: 0.00461154
	LOSS [training: 0.17384084874240818 | validation: 0.2899123148979995]
	TIME [epoch: 15.3 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15738032451502487		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 0.15738032451502487 | validation: 0.32148966167177717]
	TIME [epoch: 15.3 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16601121263942703		[learning rate: 0.0045709]
	Learning Rate: 0.00457088
	LOSS [training: 0.16601121263942703 | validation: 0.33342057304923517]
	TIME [epoch: 15.3 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1716603211947167		[learning rate: 0.0045507]
	Learning Rate: 0.00455069
	LOSS [training: 0.1716603211947167 | validation: 0.29544718228062355]
	TIME [epoch: 15.3 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16361597426761204		[learning rate: 0.0045306]
	Learning Rate: 0.00453058
	LOSS [training: 0.16361597426761204 | validation: 0.3107301248858121]
	TIME [epoch: 15.3 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17545832646444617		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 0.17545832646444617 | validation: 0.3248101086739764]
	TIME [epoch: 15.3 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17652352471065327		[learning rate: 0.0044906]
	Learning Rate: 0.00449063
	LOSS [training: 0.17652352471065327 | validation: 0.2972285407773242]
	TIME [epoch: 15.3 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17255184839072438		[learning rate: 0.0044708]
	Learning Rate: 0.00447079
	LOSS [training: 0.17255184839072438 | validation: 0.2996905479478767]
	TIME [epoch: 15.3 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17029625102223128		[learning rate: 0.004451]
	Learning Rate: 0.00445104
	LOSS [training: 0.17029625102223128 | validation: 0.2845108224467709]
	TIME [epoch: 15.3 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16482739114200115		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 0.16482739114200115 | validation: 0.35732181005260893]
	TIME [epoch: 15.3 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17191770494192093		[learning rate: 0.0044118]
	Learning Rate: 0.0044118
	LOSS [training: 0.17191770494192093 | validation: 0.2913544641728573]
	TIME [epoch: 15.3 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1605483920111326		[learning rate: 0.0043923]
	Learning Rate: 0.0043923
	LOSS [training: 0.1605483920111326 | validation: 0.30176795058505196]
	TIME [epoch: 15.3 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1724031027838431		[learning rate: 0.0043729]
	Learning Rate: 0.0043729
	LOSS [training: 0.1724031027838431 | validation: 0.28825834303090225]
	TIME [epoch: 15.2 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1672033388547748		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 0.1672033388547748 | validation: 0.30793876603412995]
	TIME [epoch: 15.3 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17087458391831406		[learning rate: 0.0043343]
	Learning Rate: 0.00433434
	LOSS [training: 0.17087458391831406 | validation: 0.3230532612057711]
	TIME [epoch: 15.3 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16809025652831153		[learning rate: 0.0043152]
	Learning Rate: 0.00431519
	LOSS [training: 0.16809025652831153 | validation: 0.3249303810703266]
	TIME [epoch: 15.3 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16656543374157226		[learning rate: 0.0042961]
	Learning Rate: 0.00429612
	LOSS [training: 0.16656543374157226 | validation: 0.29784349649987474]
	TIME [epoch: 15.3 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16603640688449714		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 0.16603640688449714 | validation: 0.30098358744029013]
	TIME [epoch: 15.3 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16226167177869005		[learning rate: 0.0042582]
	Learning Rate: 0.00425825
	LOSS [training: 0.16226167177869005 | validation: 0.3145848455498917]
	TIME [epoch: 15.3 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17139205539088714		[learning rate: 0.0042394]
	Learning Rate: 0.00423943
	LOSS [training: 0.17139205539088714 | validation: 0.3174247255196305]
	TIME [epoch: 15.3 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17031065777281493		[learning rate: 0.0042207]
	Learning Rate: 0.0042207
	LOSS [training: 0.17031065777281493 | validation: 0.3144369179562452]
	TIME [epoch: 15.3 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16125460731763272		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 0.16125460731763272 | validation: 0.2913889488555655]
	TIME [epoch: 15.3 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1632763250851541		[learning rate: 0.0041835]
	Learning Rate: 0.00418349
	LOSS [training: 0.1632763250851541 | validation: 0.3057746459985366]
	TIME [epoch: 15.3 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1678467026104135		[learning rate: 0.004165]
	Learning Rate: 0.004165
	LOSS [training: 0.1678467026104135 | validation: 0.2833806940645995]
	TIME [epoch: 15.3 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.161697431076434		[learning rate: 0.0041466]
	Learning Rate: 0.0041466
	LOSS [training: 0.161697431076434 | validation: 0.32585062694014777]
	TIME [epoch: 15.3 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16677282925133746		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 0.16677282925133746 | validation: 0.33821059889632343]
	TIME [epoch: 15.3 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16965484600860398		[learning rate: 0.00411]
	Learning Rate: 0.00411004
	LOSS [training: 0.16965484600860398 | validation: 0.3052650290574203]
	TIME [epoch: 15.2 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16075181294138446		[learning rate: 0.0040919]
	Learning Rate: 0.00409188
	LOSS [training: 0.16075181294138446 | validation: 0.287191838459611]
	TIME [epoch: 15.2 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16589891560273748		[learning rate: 0.0040738]
	Learning Rate: 0.0040738
	LOSS [training: 0.16589891560273748 | validation: 0.29163031309457865]
	TIME [epoch: 15.3 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17342876830094062		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.17342876830094062 | validation: 0.3088024150461465]
	TIME [epoch: 15.2 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16174232061578278		[learning rate: 0.0040379]
	Learning Rate: 0.00403788
	LOSS [training: 0.16174232061578278 | validation: 0.3070148450104982]
	TIME [epoch: 15.3 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16286788523937906		[learning rate: 0.00402]
	Learning Rate: 0.00402004
	LOSS [training: 0.16286788523937906 | validation: 0.3219633490129512]
	TIME [epoch: 15.2 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16826169137376493		[learning rate: 0.0040023]
	Learning Rate: 0.00400228
	LOSS [training: 0.16826169137376493 | validation: 0.2980396023689541]
	TIME [epoch: 15.2 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16113349105759833		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 0.16113349105759833 | validation: 0.32138556133335294]
	TIME [epoch: 15.3 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16876675331071844		[learning rate: 0.003967]
	Learning Rate: 0.00396699
	LOSS [training: 0.16876675331071844 | validation: 0.32400901948913396]
	TIME [epoch: 15.2 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16416053495216487		[learning rate: 0.0039495]
	Learning Rate: 0.00394947
	LOSS [training: 0.16416053495216487 | validation: 0.3121465645333948]
	TIME [epoch: 15.3 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15593548615718936		[learning rate: 0.003932]
	Learning Rate: 0.00393202
	LOSS [training: 0.15593548615718936 | validation: 0.28694776236722747]
	TIME [epoch: 15.2 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1674533115335725		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 0.1674533115335725 | validation: 0.31866403838779295]
	TIME [epoch: 15.3 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1620742262718554		[learning rate: 0.0038973]
	Learning Rate: 0.00389735
	LOSS [training: 0.1620742262718554 | validation: 0.32022584949494937]
	TIME [epoch: 15.2 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1649057684929957		[learning rate: 0.0038801]
	Learning Rate: 0.00388013
	LOSS [training: 0.1649057684929957 | validation: 0.28746820908311876]
	TIME [epoch: 15.2 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16984008114106225		[learning rate: 0.003863]
	Learning Rate: 0.00386299
	LOSS [training: 0.16984008114106225 | validation: 0.2788380317480904]
	TIME [epoch: 15.3 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v12_20240716_181840/states/model_facs_v2_dec2b_2dpca_v12_255.pth
	Model improved!!!
EPOCH 256/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15648079913075388		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 0.15648079913075388 | validation: 0.3051374153050292]
	TIME [epoch: 15.3 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16397754382291616		[learning rate: 0.0038289]
	Learning Rate: 0.00382893
	LOSS [training: 0.16397754382291616 | validation: 0.2781763196952962]
	TIME [epoch: 15.3 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v12_20240716_181840/states/model_facs_v2_dec2b_2dpca_v12_257.pth
	Model improved!!!
EPOCH 258/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1624615031234049		[learning rate: 0.003812]
	Learning Rate: 0.00381201
	LOSS [training: 0.1624615031234049 | validation: 0.32135514566104306]
	TIME [epoch: 15.3 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17899645761854605		[learning rate: 0.0037952]
	Learning Rate: 0.00379517
	LOSS [training: 0.17899645761854605 | validation: 0.3115773618288374]
	TIME [epoch: 15.3 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16296649769880847		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 0.16296649769880847 | validation: 0.29318714906569976]
	TIME [epoch: 15.3 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1679433248025472		[learning rate: 0.0037617]
	Learning Rate: 0.0037617
	LOSS [training: 0.1679433248025472 | validation: 0.3542755401558294]
	TIME [epoch: 15.3 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16332570726589982		[learning rate: 0.0037451]
	Learning Rate: 0.00374508
	LOSS [training: 0.16332570726589982 | validation: 0.3304387603472942]
	TIME [epoch: 15.3 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16637639514767905		[learning rate: 0.0037285]
	Learning Rate: 0.00372854
	LOSS [training: 0.16637639514767905 | validation: 0.29161030961287077]
	TIME [epoch: 15.2 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16342005517533448		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 0.16342005517533448 | validation: 0.30657222441639914]
	TIME [epoch: 15.3 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16238675699247385		[learning rate: 0.0036957]
	Learning Rate: 0.00369566
	LOSS [training: 0.16238675699247385 | validation: 0.30107647550564104]
	TIME [epoch: 15.3 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16714025890944262		[learning rate: 0.0036793]
	Learning Rate: 0.00367933
	LOSS [training: 0.16714025890944262 | validation: 0.31325800663487985]
	TIME [epoch: 15.3 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15949919146909247		[learning rate: 0.0036631]
	Learning Rate: 0.00366308
	LOSS [training: 0.15949919146909247 | validation: 0.2850167544825269]
	TIME [epoch: 15.3 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1693446310604457		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 0.1693446310604457 | validation: 0.2790930617879153]
	TIME [epoch: 15.3 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.161587897073691		[learning rate: 0.0036308]
	Learning Rate: 0.00363078
	LOSS [training: 0.161587897073691 | validation: 0.319958095574862]
	TIME [epoch: 15.3 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15781874094714538		[learning rate: 0.0036147]
	Learning Rate: 0.00361474
	LOSS [training: 0.15781874094714538 | validation: 0.3084641942571085]
	TIME [epoch: 15.3 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15981626788739048		[learning rate: 0.0035988]
	Learning Rate: 0.00359877
	LOSS [training: 0.15981626788739048 | validation: 0.297727873664393]
	TIME [epoch: 15.3 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16640996476695027		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 0.16640996476695027 | validation: 0.30332454379256374]
	TIME [epoch: 15.3 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16380592039635608		[learning rate: 0.003567]
	Learning Rate: 0.00356704
	LOSS [training: 0.16380592039635608 | validation: 0.2993952753554919]
	TIME [epoch: 15.3 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15888387092026868		[learning rate: 0.0035513]
	Learning Rate: 0.00355128
	LOSS [training: 0.15888387092026868 | validation: 0.30587213423326076]
	TIME [epoch: 15.3 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16551380471973715		[learning rate: 0.0035356]
	Learning Rate: 0.00353559
	LOSS [training: 0.16551380471973715 | validation: 0.287628325272908]
	TIME [epoch: 15.3 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15784432936656415		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 0.15784432936656415 | validation: 0.31557006276751826]
	TIME [epoch: 15.3 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15983828901389768		[learning rate: 0.0035044]
	Learning Rate: 0.00350441
	LOSS [training: 0.15983828901389768 | validation: 0.32220996989955625]
	TIME [epoch: 15.3 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16525296597309794		[learning rate: 0.0034889]
	Learning Rate: 0.00348893
	LOSS [training: 0.16525296597309794 | validation: 0.3079285424951454]
	TIME [epoch: 15.3 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1604934572307155		[learning rate: 0.0034735]
	Learning Rate: 0.00347352
	LOSS [training: 0.1604934572307155 | validation: 0.2839345153834678]
	TIME [epoch: 15.3 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16697501240641094		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.16697501240641094 | validation: 0.38451849047270537]
	TIME [epoch: 15.3 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17132712169395475		[learning rate: 0.0034429]
	Learning Rate: 0.00344289
	LOSS [training: 0.17132712169395475 | validation: 0.31622534257838886]
	TIME [epoch: 15.3 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1637679328802141		[learning rate: 0.0034277]
	Learning Rate: 0.00342768
	LOSS [training: 0.1637679328802141 | validation: 0.30193725010050004]
	TIME [epoch: 15.2 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16091682265293833		[learning rate: 0.0034125]
	Learning Rate: 0.00341253
	LOSS [training: 0.16091682265293833 | validation: 0.3052545160249589]
	TIME [epoch: 15.3 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15987425987733733		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 0.15987425987733733 | validation: 0.297845255543534]
	TIME [epoch: 15.3 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16375491662154984		[learning rate: 0.0033824]
	Learning Rate: 0.00338245
	LOSS [training: 0.16375491662154984 | validation: 0.32658275557737404]
	TIME [epoch: 15.3 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16398394555021195		[learning rate: 0.0033675]
	Learning Rate: 0.0033675
	LOSS [training: 0.16398394555021195 | validation: 0.29057456908986995]
	TIME [epoch: 15.3 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16440898781685132		[learning rate: 0.0033526]
	Learning Rate: 0.00335262
	LOSS [training: 0.16440898781685132 | validation: 0.2920254292046333]
	TIME [epoch: 15.2 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1593297903560957		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 0.1593297903560957 | validation: 0.29152156366313126]
	TIME [epoch: 15.3 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15824073905369224		[learning rate: 0.0033231]
	Learning Rate: 0.00332306
	LOSS [training: 0.15824073905369224 | validation: 0.2802891821009929]
	TIME [epoch: 15.3 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1609020029834065		[learning rate: 0.0033084]
	Learning Rate: 0.00330838
	LOSS [training: 0.1609020029834065 | validation: 0.2998808998110983]
	TIME [epoch: 15.3 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1593520421936941		[learning rate: 0.0032938]
	Learning Rate: 0.00329376
	LOSS [training: 0.1593520421936941 | validation: 0.29101966881164343]
	TIME [epoch: 15.3 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16630745431161675		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 0.16630745431161675 | validation: 0.3065629236137527]
	TIME [epoch: 15.3 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15683492650005587		[learning rate: 0.0032647]
	Learning Rate: 0.00326472
	LOSS [training: 0.15683492650005587 | validation: 0.2887757547716866]
	TIME [epoch: 15.3 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15532764839525356		[learning rate: 0.0032503]
	Learning Rate: 0.0032503
	LOSS [training: 0.15532764839525356 | validation: 0.2825166229468811]
	TIME [epoch: 15.3 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17050684495089796		[learning rate: 0.0032359]
	Learning Rate: 0.00323594
	LOSS [training: 0.17050684495089796 | validation: 0.29770788092461836]
	TIME [epoch: 15.3 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15667867209014846		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 0.15667867209014846 | validation: 0.30363635042928955]
	TIME [epoch: 15.3 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16021778666592562		[learning rate: 0.0032074]
	Learning Rate: 0.00320741
	LOSS [training: 0.16021778666592562 | validation: 0.2998813201061334]
	TIME [epoch: 15.3 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1622514056465923		[learning rate: 0.0031932]
	Learning Rate: 0.00319323
	LOSS [training: 0.1622514056465923 | validation: 0.28850058292675457]
	TIME [epoch: 15.3 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16243211003789249		[learning rate: 0.0031791]
	Learning Rate: 0.00317913
	LOSS [training: 0.16243211003789249 | validation: 0.27529494981827346]
	TIME [epoch: 15.2 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v12_20240716_181840/states/model_facs_v2_dec2b_2dpca_v12_299.pth
	Model improved!!!
EPOCH 300/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16018377328671743		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 0.16018377328671743 | validation: 0.29519217415360294]
	TIME [epoch: 15.3 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1645078936630585		[learning rate: 0.0031511]
	Learning Rate: 0.0031511
	LOSS [training: 0.1645078936630585 | validation: 0.31135703921422353]
	TIME [epoch: 15.3 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16248738503281915		[learning rate: 0.0031372]
	Learning Rate: 0.00313717
	LOSS [training: 0.16248738503281915 | validation: 0.29298839688480327]
	TIME [epoch: 15.3 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15643985880940825		[learning rate: 0.0031233]
	Learning Rate: 0.00312331
	LOSS [training: 0.15643985880940825 | validation: 0.3204546994091428]
	TIME [epoch: 15.3 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1630515844018868		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 0.1630515844018868 | validation: 0.32007060684437183]
	TIME [epoch: 15.3 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16076087235136388		[learning rate: 0.0030958]
	Learning Rate: 0.00309577
	LOSS [training: 0.16076087235136388 | validation: 0.28408119879586735]
	TIME [epoch: 15.3 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16565637678970369		[learning rate: 0.0030821]
	Learning Rate: 0.0030821
	LOSS [training: 0.16565637678970369 | validation: 0.2992654691633711]
	TIME [epoch: 15.3 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16361049788018053		[learning rate: 0.0030685]
	Learning Rate: 0.00306848
	LOSS [training: 0.16361049788018053 | validation: 0.30479913017689864]
	TIME [epoch: 15.3 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16487208438604387		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 0.16487208438604387 | validation: 0.2867582516914671]
	TIME [epoch: 15.3 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17074648006103063		[learning rate: 0.0030414]
	Learning Rate: 0.00304142
	LOSS [training: 0.17074648006103063 | validation: 0.2848716053979122]
	TIME [epoch: 15.3 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15784606654327835		[learning rate: 0.003028]
	Learning Rate: 0.00302799
	LOSS [training: 0.15784606654327835 | validation: 0.29484565659939715]
	TIME [epoch: 15.3 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16025223166432687		[learning rate: 0.0030146]
	Learning Rate: 0.00301461
	LOSS [training: 0.16025223166432687 | validation: 0.33869531250996043]
	TIME [epoch: 15.3 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1605006844878133		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 0.1605006844878133 | validation: 0.2984305267490173]
	TIME [epoch: 15.3 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15928845719280502		[learning rate: 0.002988]
	Learning Rate: 0.00298803
	LOSS [training: 0.15928845719280502 | validation: 0.2912553373388087]
	TIME [epoch: 15.3 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16237507204511326		[learning rate: 0.0029748]
	Learning Rate: 0.00297483
	LOSS [training: 0.16237507204511326 | validation: 0.29156926018947876]
	TIME [epoch: 15.3 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15300794086526368		[learning rate: 0.0029617]
	Learning Rate: 0.00296168
	LOSS [training: 0.15300794086526368 | validation: 0.2914255525711714]
	TIME [epoch: 15.3 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1644115886678534		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.1644115886678534 | validation: 0.33324084730948017]
	TIME [epoch: 15.3 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16417180322571379		[learning rate: 0.0029356]
	Learning Rate: 0.00293557
	LOSS [training: 0.16417180322571379 | validation: 0.29273051601115563]
	TIME [epoch: 15.3 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16132834546920755		[learning rate: 0.0029226]
	Learning Rate: 0.0029226
	LOSS [training: 0.16132834546920755 | validation: 0.2882630966401775]
	TIME [epoch: 15.3 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1595523024217082		[learning rate: 0.0029097]
	Learning Rate: 0.00290969
	LOSS [training: 0.1595523024217082 | validation: 0.28034497369211026]
	TIME [epoch: 15.3 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16068627998750687		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 0.16068627998750687 | validation: 0.3023240841237255]
	TIME [epoch: 15.3 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1630569172846597		[learning rate: 0.002884]
	Learning Rate: 0.00288403
	LOSS [training: 0.1630569172846597 | validation: 0.29833385349934216]
	TIME [epoch: 15.3 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16011903359703714		[learning rate: 0.0028713]
	Learning Rate: 0.00287129
	LOSS [training: 0.16011903359703714 | validation: 0.2942087217556459]
	TIME [epoch: 15.3 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15460854808978486		[learning rate: 0.0028586]
	Learning Rate: 0.0028586
	LOSS [training: 0.15460854808978486 | validation: 0.28896880913471396]
	TIME [epoch: 15.2 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16905910833063842		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 0.16905910833063842 | validation: 0.2952243765139421]
	TIME [epoch: 15.3 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15985243811144323		[learning rate: 0.0028334]
	Learning Rate: 0.0028334
	LOSS [training: 0.15985243811144323 | validation: 0.28510130493320407]
	TIME [epoch: 15.3 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15782474586351938		[learning rate: 0.0028209]
	Learning Rate: 0.00282088
	LOSS [training: 0.15782474586351938 | validation: 0.29528377028208713]
	TIME [epoch: 15.3 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1583387355339302		[learning rate: 0.0028084]
	Learning Rate: 0.00280842
	LOSS [training: 0.1583387355339302 | validation: 0.30199714635011765]
	TIME [epoch: 15.3 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1629281956404045		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 0.1629281956404045 | validation: 0.2971306925490074]
	TIME [epoch: 15.3 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15543079631059972		[learning rate: 0.0027837]
	Learning Rate: 0.00278366
	LOSS [training: 0.15543079631059972 | validation: 0.29908310410072]
	TIME [epoch: 15.3 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16352711271890347		[learning rate: 0.0027714]
	Learning Rate: 0.00277136
	LOSS [training: 0.16352711271890347 | validation: 0.28564434853259546]
	TIME [epoch: 15.3 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1573669195194039		[learning rate: 0.0027591]
	Learning Rate: 0.00275911
	LOSS [training: 0.1573669195194039 | validation: 0.2933109247370582]
	TIME [epoch: 15.3 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1577644531856664		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 0.1577644531856664 | validation: 0.29518705837204096]
	TIME [epoch: 15.3 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15868195569632476		[learning rate: 0.0027348]
	Learning Rate: 0.00273478
	LOSS [training: 0.15868195569632476 | validation: 0.2994602720944229]
	TIME [epoch: 15.3 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15683303992614073		[learning rate: 0.0027227]
	Learning Rate: 0.0027227
	LOSS [training: 0.15683303992614073 | validation: 0.3117237613578599]
	TIME [epoch: 15.3 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1615606292957517		[learning rate: 0.0027107]
	Learning Rate: 0.00271067
	LOSS [training: 0.1615606292957517 | validation: 0.30941189591807366]
	TIME [epoch: 15.3 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15768358941816413		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 0.15768358941816413 | validation: 0.29348788372439827]
	TIME [epoch: 15.3 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15598132711123391		[learning rate: 0.0026868]
	Learning Rate: 0.00268677
	LOSS [training: 0.15598132711123391 | validation: 0.2918580064573608]
	TIME [epoch: 15.3 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15680708782880406		[learning rate: 0.0026749]
	Learning Rate: 0.0026749
	LOSS [training: 0.15680708782880406 | validation: 0.29831905873328135]
	TIME [epoch: 15.3 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16117019856723397		[learning rate: 0.0026631]
	Learning Rate: 0.00266308
	LOSS [training: 0.16117019856723397 | validation: 0.3013428757762274]
	TIME [epoch: 15.3 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15759658793467832		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 0.15759658793467832 | validation: 0.3060196483607065]
	TIME [epoch: 15.3 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15013542143123926		[learning rate: 0.0026396]
	Learning Rate: 0.0026396
	LOSS [training: 0.15013542143123926 | validation: 0.2880937323606966]
	TIME [epoch: 15.3 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1615700111833187		[learning rate: 0.0026279]
	Learning Rate: 0.00262794
	LOSS [training: 0.1615700111833187 | validation: 0.28661952616448305]
	TIME [epoch: 15.3 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16208379813124668		[learning rate: 0.0026163]
	Learning Rate: 0.00261633
	LOSS [training: 0.16208379813124668 | validation: 0.29207259352512954]
	TIME [epoch: 15.3 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15739825920026881		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 0.15739825920026881 | validation: 0.29131349866570805]
	TIME [epoch: 15.3 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1532340718872633		[learning rate: 0.0025933]
	Learning Rate: 0.00259326
	LOSS [training: 0.1532340718872633 | validation: 0.3345386127973954]
	TIME [epoch: 15.3 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15448167425842693		[learning rate: 0.0025818]
	Learning Rate: 0.0025818
	LOSS [training: 0.15448167425842693 | validation: 0.32534782367111337]
	TIME [epoch: 15.3 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15837340205082584		[learning rate: 0.0025704]
	Learning Rate: 0.0025704
	LOSS [training: 0.15837340205082584 | validation: 0.2897422299080384]
	TIME [epoch: 15.3 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1570061034362729		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.1570061034362729 | validation: 0.28639228228986613]
	TIME [epoch: 15.3 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15884585191029998		[learning rate: 0.0025477]
	Learning Rate: 0.00254773
	LOSS [training: 0.15884585191029998 | validation: 0.292391709937803]
	TIME [epoch: 15.3 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15739025257639988		[learning rate: 0.0025365]
	Learning Rate: 0.00253648
	LOSS [training: 0.15739025257639988 | validation: 0.29282979011152366]
	TIME [epoch: 15.3 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16053408035810926		[learning rate: 0.0025253]
	Learning Rate: 0.00252527
	LOSS [training: 0.16053408035810926 | validation: 0.29159270323841574]
	TIME [epoch: 15.3 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1602746817426084		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.1602746817426084 | validation: 0.2947824013469914]
	TIME [epoch: 15.3 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1602826604286373		[learning rate: 0.002503]
	Learning Rate: 0.002503
	LOSS [training: 0.1602826604286373 | validation: 0.2920920136234013]
	TIME [epoch: 15.3 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15998371189222288		[learning rate: 0.0024919]
	Learning Rate: 0.00249194
	LOSS [training: 0.15998371189222288 | validation: 0.29667745268945866]
	TIME [epoch: 15.3 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.159087668882345		[learning rate: 0.0024809]
	Learning Rate: 0.00248093
	LOSS [training: 0.159087668882345 | validation: 0.31680741729057516]
	TIME [epoch: 15.3 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15931717585105293		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 0.15931717585105293 | validation: 0.2969124106402358]
	TIME [epoch: 15.3 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1546512172267191		[learning rate: 0.0024591]
	Learning Rate: 0.00245906
	LOSS [training: 0.1546512172267191 | validation: 0.3303405769553466]
	TIME [epoch: 15.3 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16273195791196962		[learning rate: 0.0024482]
	Learning Rate: 0.0024482
	LOSS [training: 0.16273195791196962 | validation: 0.30972963566304945]
	TIME [epoch: 15.3 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15954996890340123		[learning rate: 0.0024374]
	Learning Rate: 0.00243738
	LOSS [training: 0.15954996890340123 | validation: 0.3024757479456941]
	TIME [epoch: 15.3 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15279222037766332		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.15279222037766332 | validation: 0.29636565244811003]
	TIME [epoch: 15.3 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1555840614061226		[learning rate: 0.0024159]
	Learning Rate: 0.00241589
	LOSS [training: 0.1555840614061226 | validation: 0.30442803238595323]
	TIME [epoch: 15.3 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1532249065359928		[learning rate: 0.0024052]
	Learning Rate: 0.00240521
	LOSS [training: 0.1532249065359928 | validation: 0.3134529199425021]
	TIME [epoch: 15.3 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15907809914222254		[learning rate: 0.0023946]
	Learning Rate: 0.00239459
	LOSS [training: 0.15907809914222254 | validation: 0.3000959117542483]
	TIME [epoch: 15.3 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15804506717872147		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 0.15804506717872147 | validation: 0.2883653293274747]
	TIME [epoch: 15.3 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15928088857474415		[learning rate: 0.0023735]
	Learning Rate: 0.00237347
	LOSS [training: 0.15928088857474415 | validation: 0.3155702442848517]
	TIME [epoch: 15.3 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15860652841741782		[learning rate: 0.002363]
	Learning Rate: 0.00236299
	LOSS [training: 0.15860652841741782 | validation: 0.3162077407802291]
	TIME [epoch: 15.3 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1606169197398259		[learning rate: 0.0023525]
	Learning Rate: 0.00235255
	LOSS [training: 0.1606169197398259 | validation: 0.32740836322493405]
	TIME [epoch: 15.3 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15853799436156837		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.15853799436156837 | validation: 0.30849520896030713]
	TIME [epoch: 15.3 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16069615129739007		[learning rate: 0.0023318]
	Learning Rate: 0.00233181
	LOSS [training: 0.16069615129739007 | validation: 0.3082543944023109]
	TIME [epoch: 15.3 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1589169409182212		[learning rate: 0.0023215]
	Learning Rate: 0.0023215
	LOSS [training: 0.1589169409182212 | validation: 0.29466047353374647]
	TIME [epoch: 15.3 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15961810278511945		[learning rate: 0.0023112]
	Learning Rate: 0.00231125
	LOSS [training: 0.15961810278511945 | validation: 0.32160540014387573]
	TIME [epoch: 15.3 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1581053359751606		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.1581053359751606 | validation: 0.3155340059597736]
	TIME [epoch: 15.3 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15473801277266036		[learning rate: 0.0022909]
	Learning Rate: 0.00229087
	LOSS [training: 0.15473801277266036 | validation: 0.3081565882967979]
	TIME [epoch: 15.3 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1555463468018234		[learning rate: 0.0022807]
	Learning Rate: 0.00228075
	LOSS [training: 0.1555463468018234 | validation: 0.3086527885164116]
	TIME [epoch: 15.3 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16102438823940218		[learning rate: 0.0022707]
	Learning Rate: 0.00227067
	LOSS [training: 0.16102438823940218 | validation: 0.29532230941503373]
	TIME [epoch: 15.3 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15503854758935956		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.15503854758935956 | validation: 0.2985730530531774]
	TIME [epoch: 15.3 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1577164796623007		[learning rate: 0.0022506]
	Learning Rate: 0.00225065
	LOSS [training: 0.1577164796623007 | validation: 0.30314710780884835]
	TIME [epoch: 15.3 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16026242024367793		[learning rate: 0.0022407]
	Learning Rate: 0.0022407
	LOSS [training: 0.16026242024367793 | validation: 0.30690495225773945]
	TIME [epoch: 15.3 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.157916035273277		[learning rate: 0.0022308]
	Learning Rate: 0.0022308
	LOSS [training: 0.157916035273277 | validation: 0.28665496885879577]
	TIME [epoch: 15.3 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15825806007935223		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.15825806007935223 | validation: 0.3026808541532376]
	TIME [epoch: 15.3 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.154868528170815		[learning rate: 0.0022111]
	Learning Rate: 0.00221114
	LOSS [training: 0.154868528170815 | validation: 0.2912038098167538]
	TIME [epoch: 15.3 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15601884605393973		[learning rate: 0.0022014]
	Learning Rate: 0.00220137
	LOSS [training: 0.15601884605393973 | validation: 0.3158657100289319]
	TIME [epoch: 15.3 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15938099622809945		[learning rate: 0.0021916]
	Learning Rate: 0.00219164
	LOSS [training: 0.15938099622809945 | validation: 0.28549827575194764]
	TIME [epoch: 15.3 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15714414809191513		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.15714414809191513 | validation: 0.3152327745075621]
	TIME [epoch: 15.3 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15507642818934966		[learning rate: 0.0021723]
	Learning Rate: 0.00217232
	LOSS [training: 0.15507642818934966 | validation: 0.3027354849096947]
	TIME [epoch: 15.3 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15577648528693905		[learning rate: 0.0021627]
	Learning Rate: 0.00216272
	LOSS [training: 0.15577648528693905 | validation: 0.2997497588862717]
	TIME [epoch: 15.3 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15382674338525812		[learning rate: 0.0021532]
	Learning Rate: 0.00215316
	LOSS [training: 0.15382674338525812 | validation: 0.30528301957785864]
	TIME [epoch: 15.3 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1551994330298558		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.1551994330298558 | validation: 0.281596182587565]
	TIME [epoch: 15.3 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15415678288939771		[learning rate: 0.0021342]
	Learning Rate: 0.00213418
	LOSS [training: 0.15415678288939771 | validation: 0.3240337634676333]
	TIME [epoch: 15.3 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15871126555162826		[learning rate: 0.0021247]
	Learning Rate: 0.00212475
	LOSS [training: 0.15871126555162826 | validation: 0.29539972312188856]
	TIME [epoch: 15.3 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1522408998508556		[learning rate: 0.0021154]
	Learning Rate: 0.00211536
	LOSS [training: 0.1522408998508556 | validation: 0.29630416514441194]
	TIME [epoch: 15.3 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1566369604195306		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.1566369604195306 | validation: 0.2888002909468164]
	TIME [epoch: 15.3 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16029819736309067		[learning rate: 0.0020967]
	Learning Rate: 0.00209671
	LOSS [training: 0.16029819736309067 | validation: 0.30139660734980717]
	TIME [epoch: 15.3 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15698231028727408		[learning rate: 0.0020874]
	Learning Rate: 0.00208745
	LOSS [training: 0.15698231028727408 | validation: 0.2963642606908742]
	TIME [epoch: 15.3 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15581075629887242		[learning rate: 0.0020782]
	Learning Rate: 0.00207822
	LOSS [training: 0.15581075629887242 | validation: 0.30401531443776264]
	TIME [epoch: 15.3 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15515248416019603		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.15515248416019603 | validation: 0.294301868434882]
	TIME [epoch: 15.3 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15823592724074373		[learning rate: 0.0020599]
	Learning Rate: 0.0020599
	LOSS [training: 0.15823592724074373 | validation: 0.28727662775452967]
	TIME [epoch: 15.3 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15388023329360495		[learning rate: 0.0020508]
	Learning Rate: 0.0020508
	LOSS [training: 0.15388023329360495 | validation: 0.3071804895864271]
	TIME [epoch: 15.3 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15963003118629376		[learning rate: 0.0020417]
	Learning Rate: 0.00204174
	LOSS [training: 0.15963003118629376 | validation: 0.2927060530301374]
	TIME [epoch: 15.3 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15636032585489046		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.15636032585489046 | validation: 0.2948839334445904]
	TIME [epoch: 15.3 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15191563967358496		[learning rate: 0.0020237]
	Learning Rate: 0.00202374
	LOSS [training: 0.15191563967358496 | validation: 0.29460269600292643]
	TIME [epoch: 15.3 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1563536032264226		[learning rate: 0.0020148]
	Learning Rate: 0.00201479
	LOSS [training: 0.1563536032264226 | validation: 0.30078751987667873]
	TIME [epoch: 15.3 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15437130173990748		[learning rate: 0.0020059]
	Learning Rate: 0.00200589
	LOSS [training: 0.15437130173990748 | validation: 0.2948533800943016]
	TIME [epoch: 15.3 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15425219698207904		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.15425219698207904 | validation: 0.29966300051180367]
	TIME [epoch: 15.3 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15270524793103749		[learning rate: 0.0019882]
	Learning Rate: 0.00198821
	LOSS [training: 0.15270524793103749 | validation: 0.2847248877222188]
	TIME [epoch: 15.3 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16223544203469226		[learning rate: 0.0019794]
	Learning Rate: 0.00197942
	LOSS [training: 0.16223544203469226 | validation: 0.28796151415907484]
	TIME [epoch: 15.3 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15467646948642727		[learning rate: 0.0019707]
	Learning Rate: 0.00197068
	LOSS [training: 0.15467646948642727 | validation: 0.2991865022646762]
	TIME [epoch: 15.3 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15078345679165767		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.15078345679165767 | validation: 0.31580259841520947]
	TIME [epoch: 15.3 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15730117540197644		[learning rate: 0.0019533]
	Learning Rate: 0.0019533
	LOSS [training: 0.15730117540197644 | validation: 0.3012875398538412]
	TIME [epoch: 15.3 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15434369973065334		[learning rate: 0.0019447]
	Learning Rate: 0.00194467
	LOSS [training: 0.15434369973065334 | validation: 0.28169591281823203]
	TIME [epoch: 15.3 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15238954672324806		[learning rate: 0.0019361]
	Learning Rate: 0.00193608
	LOSS [training: 0.15238954672324806 | validation: 0.296135844533499]
	TIME [epoch: 15.3 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1588201754456576		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.1588201754456576 | validation: 0.30165307223239207]
	TIME [epoch: 15.3 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16229235801023073		[learning rate: 0.001919]
	Learning Rate: 0.00191901
	LOSS [training: 0.16229235801023073 | validation: 0.2926112378050429]
	TIME [epoch: 15.3 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15161384157749616		[learning rate: 0.0019105]
	Learning Rate: 0.00191053
	LOSS [training: 0.15161384157749616 | validation: 0.30549229649429327]
	TIME [epoch: 15.3 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15676775222505118		[learning rate: 0.0019021]
	Learning Rate: 0.00190209
	LOSS [training: 0.15676775222505118 | validation: 0.2907161840593921]
	TIME [epoch: 15.3 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15276697249261167		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.15276697249261167 | validation: 0.28200840583049036]
	TIME [epoch: 15.3 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1529775318795441		[learning rate: 0.0018853]
	Learning Rate: 0.00188532
	LOSS [training: 0.1529775318795441 | validation: 0.2961219681776403]
	TIME [epoch: 15.3 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1576135237782313		[learning rate: 0.001877]
	Learning Rate: 0.00187699
	LOSS [training: 0.1576135237782313 | validation: 0.2789379487228965]
	TIME [epoch: 15.3 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15733744292820115		[learning rate: 0.0018687]
	Learning Rate: 0.0018687
	LOSS [training: 0.15733744292820115 | validation: 0.3008143147232063]
	TIME [epoch: 15.3 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1551846940556944		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.1551846940556944 | validation: 0.28347206058662566]
	TIME [epoch: 15.3 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15453891088410296		[learning rate: 0.0018522]
	Learning Rate: 0.00185222
	LOSS [training: 0.15453891088410296 | validation: 0.2906217810221422]
	TIME [epoch: 15.3 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15677672619661243		[learning rate: 0.001844]
	Learning Rate: 0.00184404
	LOSS [training: 0.15677672619661243 | validation: 0.3062233670658836]
	TIME [epoch: 15.3 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16091260835273566		[learning rate: 0.0018359]
	Learning Rate: 0.00183589
	LOSS [training: 0.16091260835273566 | validation: 0.2851080023330631]
	TIME [epoch: 15.3 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.152819204083827		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.152819204083827 | validation: 0.2804703898862684]
	TIME [epoch: 15.3 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1536682913349134		[learning rate: 0.0018197]
	Learning Rate: 0.0018197
	LOSS [training: 0.1536682913349134 | validation: 0.2941658402003281]
	TIME [epoch: 15.3 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15108388893800032		[learning rate: 0.0018117]
	Learning Rate: 0.00181166
	LOSS [training: 0.15108388893800032 | validation: 0.285042366385017]
	TIME [epoch: 15.3 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15272011575639619		[learning rate: 0.0018037]
	Learning Rate: 0.00180366
	LOSS [training: 0.15272011575639619 | validation: 0.29609301798518695]
	TIME [epoch: 15.3 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15157332614076308		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.15157332614076308 | validation: 0.30247772903098735]
	TIME [epoch: 15.3 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1570452187556063		[learning rate: 0.0017878]
	Learning Rate: 0.00178775
	LOSS [training: 0.1570452187556063 | validation: 0.2896031858761605]
	TIME [epoch: 15.3 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15738657081343638		[learning rate: 0.0017799]
	Learning Rate: 0.00177985
	LOSS [training: 0.15738657081343638 | validation: 0.29640580128818544]
	TIME [epoch: 15.3 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1495551461564177		[learning rate: 0.001772]
	Learning Rate: 0.00177199
	LOSS [training: 0.1495551461564177 | validation: 0.2792466999818739]
	TIME [epoch: 15.3 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15599847986869592		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.15599847986869592 | validation: 0.27574625005237674]
	TIME [epoch: 15.3 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15510897985471853		[learning rate: 0.0017564]
	Learning Rate: 0.00175637
	LOSS [training: 0.15510897985471853 | validation: 0.29139002791141116]
	TIME [epoch: 15.3 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15474281478515228		[learning rate: 0.0017486]
	Learning Rate: 0.00174861
	LOSS [training: 0.15474281478515228 | validation: 0.289046675578871]
	TIME [epoch: 15.3 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15154177929733753		[learning rate: 0.0017409]
	Learning Rate: 0.00174088
	LOSS [training: 0.15154177929733753 | validation: 0.3102879517691212]
	TIME [epoch: 15.3 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1532851779176372		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.1532851779176372 | validation: 0.282942713086547]
	TIME [epoch: 15.3 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15327215888475748		[learning rate: 0.0017255]
	Learning Rate: 0.00172553
	LOSS [training: 0.15327215888475748 | validation: 0.29613886008441465]
	TIME [epoch: 15.3 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1564135775462646		[learning rate: 0.0017179]
	Learning Rate: 0.00171791
	LOSS [training: 0.1564135775462646 | validation: 0.2862272053833171]
	TIME [epoch: 15.3 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15985329335778864		[learning rate: 0.0017103]
	Learning Rate: 0.00171032
	LOSS [training: 0.15985329335778864 | validation: 0.3065650445033761]
	TIME [epoch: 15.3 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15190005366361603		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.15190005366361603 | validation: 0.302351851833679]
	TIME [epoch: 15.3 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1576107346750803		[learning rate: 0.0016952]
	Learning Rate: 0.00169524
	LOSS [training: 0.1576107346750803 | validation: 0.28864922613543265]
	TIME [epoch: 15.3 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15463845665510828		[learning rate: 0.0016877]
	Learning Rate: 0.00168775
	LOSS [training: 0.15463845665510828 | validation: 0.30886208597059844]
	TIME [epoch: 15.3 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15403899822575168		[learning rate: 0.0016803]
	Learning Rate: 0.00168029
	LOSS [training: 0.15403899822575168 | validation: 0.2925233096742289]
	TIME [epoch: 15.3 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15382764990470654		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.15382764990470654 | validation: 0.2870664997207182]
	TIME [epoch: 15.3 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1560169318353519		[learning rate: 0.0016655]
	Learning Rate: 0.00166548
	LOSS [training: 0.1560169318353519 | validation: 0.2940472578929286]
	TIME [epoch: 15.3 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1568484944691642		[learning rate: 0.0016581]
	Learning Rate: 0.00165812
	LOSS [training: 0.1568484944691642 | validation: 0.2959278751109094]
	TIME [epoch: 15.3 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14913592589227592		[learning rate: 0.0016508]
	Learning Rate: 0.00165079
	LOSS [training: 0.14913592589227592 | validation: 0.3085019461213157]
	TIME [epoch: 15.3 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15819023533056256		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.15819023533056256 | validation: 0.3009212402459985]
	TIME [epoch: 15.3 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15443215022800855		[learning rate: 0.0016362]
	Learning Rate: 0.00163624
	LOSS [training: 0.15443215022800855 | validation: 0.2788509823551045]
	TIME [epoch: 15.3 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15213466694529795		[learning rate: 0.001629]
	Learning Rate: 0.00162901
	LOSS [training: 0.15213466694529795 | validation: 0.29775301109519503]
	TIME [epoch: 15.3 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1506664980597507		[learning rate: 0.0016218]
	Learning Rate: 0.00162181
	LOSS [training: 0.1506664980597507 | validation: 0.29785838583322277]
	TIME [epoch: 15.2 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15239587464757912		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.15239587464757912 | validation: 0.3014963031290945]
	TIME [epoch: 15.3 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15209341735566856		[learning rate: 0.0016075]
	Learning Rate: 0.00160751
	LOSS [training: 0.15209341735566856 | validation: 0.3032891055613063]
	TIME [epoch: 15.3 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15454497183853327		[learning rate: 0.0016004]
	Learning Rate: 0.00160041
	LOSS [training: 0.15454497183853327 | validation: 0.29153913112857976]
	TIME [epoch: 15.3 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1550312717430603		[learning rate: 0.0015933]
	Learning Rate: 0.00159334
	LOSS [training: 0.1550312717430603 | validation: 0.2902267455463398]
	TIME [epoch: 15.3 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15328197268918703		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.15328197268918703 | validation: 0.3088950305426435]
	TIME [epoch: 15.3 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15106204758657182		[learning rate: 0.0015793]
	Learning Rate: 0.00157929
	LOSS [training: 0.15106204758657182 | validation: 0.28876388550102455]
	TIME [epoch: 15.3 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15335688405998443		[learning rate: 0.0015723]
	Learning Rate: 0.00157231
	LOSS [training: 0.15335688405998443 | validation: 0.29691220562905585]
	TIME [epoch: 15.3 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15522230387695682		[learning rate: 0.0015654]
	Learning Rate: 0.00156536
	LOSS [training: 0.15522230387695682 | validation: 0.2924636168776441]
	TIME [epoch: 15.3 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15415456112463444		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.15415456112463444 | validation: 0.2948953559561093]
	TIME [epoch: 15.3 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15394482805878598		[learning rate: 0.0015516]
	Learning Rate: 0.00155156
	LOSS [training: 0.15394482805878598 | validation: 0.288316804480818]
	TIME [epoch: 15.3 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15473363421195838		[learning rate: 0.0015447]
	Learning Rate: 0.00154471
	LOSS [training: 0.15473363421195838 | validation: 0.2968355620548395]
	TIME [epoch: 15.3 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15221389195811644		[learning rate: 0.0015379]
	Learning Rate: 0.00153788
	LOSS [training: 0.15221389195811644 | validation: 0.28538558748220355]
	TIME [epoch: 15.3 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15338933778097544		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.15338933778097544 | validation: 0.2961023405746054]
	TIME [epoch: 15.3 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1528203728993108		[learning rate: 0.0015243]
	Learning Rate: 0.00152432
	LOSS [training: 0.1528203728993108 | validation: 0.28634536946041295]
	TIME [epoch: 15.3 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15413267434429828		[learning rate: 0.0015176]
	Learning Rate: 0.00151759
	LOSS [training: 0.15413267434429828 | validation: 0.2886520023740331]
	TIME [epoch: 15.2 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15347637158005745		[learning rate: 0.0015109]
	Learning Rate: 0.00151088
	LOSS [training: 0.15347637158005745 | validation: 0.2977555135160233]
	TIME [epoch: 15.3 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1497928219368412		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.1497928219368412 | validation: 0.2822941136596259]
	TIME [epoch: 15.3 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1541062314350721		[learning rate: 0.0014976]
	Learning Rate: 0.00149756
	LOSS [training: 0.1541062314350721 | validation: 0.29795416668520086]
	TIME [epoch: 15.3 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15537411484640734		[learning rate: 0.0014909]
	Learning Rate: 0.00149094
	LOSS [training: 0.15537411484640734 | validation: 0.2928154162509985]
	TIME [epoch: 15.3 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1514907403933224		[learning rate: 0.0014844]
	Learning Rate: 0.00148436
	LOSS [training: 0.1514907403933224 | validation: 0.29382989107319296]
	TIME [epoch: 15.3 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15225765668416166		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.15225765668416166 | validation: 0.28417151184451195]
	TIME [epoch: 15.3 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15263294042536052		[learning rate: 0.0014713]
	Learning Rate: 0.00147127
	LOSS [training: 0.15263294042536052 | validation: 0.2879110723033054]
	TIME [epoch: 15.3 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1503925386604325		[learning rate: 0.0014648]
	Learning Rate: 0.00146477
	LOSS [training: 0.1503925386604325 | validation: 0.30353733880294]
	TIME [epoch: 15.3 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15217705789675318		[learning rate: 0.0014583]
	Learning Rate: 0.0014583
	LOSS [training: 0.15217705789675318 | validation: 0.29879812870451766]
	TIME [epoch: 15.3 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15233080390339077		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.15233080390339077 | validation: 0.30326393807905994]
	TIME [epoch: 15.2 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1528766948570442		[learning rate: 0.0014454]
	Learning Rate: 0.00144544
	LOSS [training: 0.1528766948570442 | validation: 0.30003468262350724]
	TIME [epoch: 15.3 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15578897322826574		[learning rate: 0.0014391]
	Learning Rate: 0.00143905
	LOSS [training: 0.15578897322826574 | validation: 0.2811869480194047]
	TIME [epoch: 15.2 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15311226746749473		[learning rate: 0.0014327]
	Learning Rate: 0.0014327
	LOSS [training: 0.15311226746749473 | validation: 0.2937001665581766]
	TIME [epoch: 15.3 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15122127074476835		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.15122127074476835 | validation: 0.2745848468700903]
	TIME [epoch: 15.3 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v12_20240716_181840/states/model_facs_v2_dec2b_2dpca_v12_480.pth
	Model improved!!!
EPOCH 481/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14957112828499325		[learning rate: 0.0014201]
	Learning Rate: 0.00142006
	LOSS [training: 0.14957112828499325 | validation: 0.29286045112271936]
	TIME [epoch: 15.3 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.153042352635706		[learning rate: 0.0014138]
	Learning Rate: 0.00141379
	LOSS [training: 0.153042352635706 | validation: 0.3049416754814292]
	TIME [epoch: 15.3 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15023684537562332		[learning rate: 0.0014075]
	Learning Rate: 0.00140754
	LOSS [training: 0.15023684537562332 | validation: 0.2827428325561735]
	TIME [epoch: 15.3 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15564641430323503		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.15564641430323503 | validation: 0.3125231600433051]
	TIME [epoch: 15.3 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15745259535018485		[learning rate: 0.0013951]
	Learning Rate: 0.00139513
	LOSS [training: 0.15745259535018485 | validation: 0.2877062414604794]
	TIME [epoch: 15.3 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15286142494796245		[learning rate: 0.001389]
	Learning Rate: 0.00138897
	LOSS [training: 0.15286142494796245 | validation: 0.28255784278863644]
	TIME [epoch: 15.3 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15288478882365522		[learning rate: 0.0013828]
	Learning Rate: 0.00138283
	LOSS [training: 0.15288478882365522 | validation: 0.2986930280228416]
	TIME [epoch: 15.3 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.150445888560806		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.150445888560806 | validation: 0.3004423117795069]
	TIME [epoch: 15.3 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15273023824234683		[learning rate: 0.0013706]
	Learning Rate: 0.00137064
	LOSS [training: 0.15273023824234683 | validation: 0.2881101547775644]
	TIME [epoch: 15.3 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15480388129687023		[learning rate: 0.0013646]
	Learning Rate: 0.00136458
	LOSS [training: 0.15480388129687023 | validation: 0.28176759740436325]
	TIME [epoch: 15.3 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1532993378546215		[learning rate: 0.0013586]
	Learning Rate: 0.00135855
	LOSS [training: 0.1532993378546215 | validation: 0.2860255677380657]
	TIME [epoch: 15.3 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15387583546360373		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.15387583546360373 | validation: 0.28131257579795876]
	TIME [epoch: 15.3 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1521070071632183		[learning rate: 0.0013466]
	Learning Rate: 0.00134658
	LOSS [training: 0.1521070071632183 | validation: 0.2855152606879569]
	TIME [epoch: 15.3 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15578003236472868		[learning rate: 0.0013406]
	Learning Rate: 0.00134063
	LOSS [training: 0.15578003236472868 | validation: 0.299924783951642]
	TIME [epoch: 15.3 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15189140728719783		[learning rate: 0.0013347]
	Learning Rate: 0.0013347
	LOSS [training: 0.15189140728719783 | validation: 0.30164376938688403]
	TIME [epoch: 15.3 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15220799985493985		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.15220799985493985 | validation: 0.3025642039766027]
	TIME [epoch: 15.3 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15263308655953964		[learning rate: 0.0013229]
	Learning Rate: 0.00132293
	LOSS [training: 0.15263308655953964 | validation: 0.2894124405990915]
	TIME [epoch: 15.3 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14913406728787504		[learning rate: 0.0013171]
	Learning Rate: 0.00131709
	LOSS [training: 0.14913406728787504 | validation: 0.3271834959212861]
	TIME [epoch: 15.3 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15597940914374997		[learning rate: 0.0013113]
	Learning Rate: 0.00131127
	LOSS [training: 0.15597940914374997 | validation: 0.2937836590335024]
	TIME [epoch: 15.3 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15454378916061356		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.15454378916061356 | validation: 0.28896130753692406]
	TIME [epoch: 15.3 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1470420368364294		[learning rate: 0.0012997]
	Learning Rate: 0.00129971
	LOSS [training: 0.1470420368364294 | validation: 0.28955903245066006]
	TIME [epoch: 58.5 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15285888821793686		[learning rate: 0.001294]
	Learning Rate: 0.00129397
	LOSS [training: 0.15285888821793686 | validation: 0.282819302251767]
	TIME [epoch: 32.7 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15061768892687372		[learning rate: 0.0012882]
	Learning Rate: 0.00128825
	LOSS [training: 0.15061768892687372 | validation: 0.2994828267479594]
	TIME [epoch: 32.7 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1508636011896042		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.1508636011896042 | validation: 0.28506054134273534]
	TIME [epoch: 32.7 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1518895884383294		[learning rate: 0.0012769]
	Learning Rate: 0.00127689
	LOSS [training: 0.1518895884383294 | validation: 0.2875723048523675]
	TIME [epoch: 32.7 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14970148302871236		[learning rate: 0.0012712]
	Learning Rate: 0.00127125
	LOSS [training: 0.14970148302871236 | validation: 0.2909679583115815]
	TIME [epoch: 32.7 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15275607381796083		[learning rate: 0.0012656]
	Learning Rate: 0.00126563
	LOSS [training: 0.15275607381796083 | validation: 0.2814740489214843]
	TIME [epoch: 32.7 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1536770293659703		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.1536770293659703 | validation: 0.29092740773309544]
	TIME [epoch: 32.7 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15167887615773598		[learning rate: 0.0012545]
	Learning Rate: 0.00125447
	LOSS [training: 0.15167887615773598 | validation: 0.28295543168729276]
	TIME [epoch: 32.7 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15152348911171312		[learning rate: 0.0012489]
	Learning Rate: 0.00124893
	LOSS [training: 0.15152348911171312 | validation: 0.295007778183545]
	TIME [epoch: 32.7 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14907729264832986		[learning rate: 0.0012434]
	Learning Rate: 0.00124341
	LOSS [training: 0.14907729264832986 | validation: 0.29463424642237634]
	TIME [epoch: 32.7 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15502485224854856		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.15502485224854856 | validation: 0.28221782010705215]
	TIME [epoch: 32.7 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15017360543987263		[learning rate: 0.0012324]
	Learning Rate: 0.00123245
	LOSS [training: 0.15017360543987263 | validation: 0.29352947486385145]
	TIME [epoch: 32.7 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15168894493773066		[learning rate: 0.001227]
	Learning Rate: 0.001227
	LOSS [training: 0.15168894493773066 | validation: 0.2963889528404902]
	TIME [epoch: 32.7 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1547728666967158		[learning rate: 0.0012216]
	Learning Rate: 0.00122158
	LOSS [training: 0.1547728666967158 | validation: 0.2987630244065631]
	TIME [epoch: 32.7 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14970877248967088		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.14970877248967088 | validation: 0.2794392272218406]
	TIME [epoch: 32.7 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14883842523330104		[learning rate: 0.0012108]
	Learning Rate: 0.00121081
	LOSS [training: 0.14883842523330104 | validation: 0.29418958696976377]
	TIME [epoch: 32.7 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15131756254735323		[learning rate: 0.0012055]
	Learning Rate: 0.00120546
	LOSS [training: 0.15131756254735323 | validation: 0.29945978941239254]
	TIME [epoch: 32.7 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15197558411089887		[learning rate: 0.0012001]
	Learning Rate: 0.00120014
	LOSS [training: 0.15197558411089887 | validation: 0.2907274363441752]
	TIME [epoch: 32.7 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15346026901161422		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.15346026901161422 | validation: 0.2898279021266985]
	TIME [epoch: 32.7 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1531562164507163		[learning rate: 0.0011896]
	Learning Rate: 0.00118956
	LOSS [training: 0.1531562164507163 | validation: 0.28505505232212436]
	TIME [epoch: 32.7 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1530421260327431		[learning rate: 0.0011843]
	Learning Rate: 0.0011843
	LOSS [training: 0.1530421260327431 | validation: 0.2946892210619536]
	TIME [epoch: 32.7 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15315970986312016		[learning rate: 0.0011791]
	Learning Rate: 0.00117907
	LOSS [training: 0.15315970986312016 | validation: 0.2869095406450309]
	TIME [epoch: 32.7 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.150599614015388		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.150599614015388 | validation: 0.29536938544941693]
	TIME [epoch: 32.7 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1561711141585969		[learning rate: 0.0011687]
	Learning Rate: 0.00116867
	LOSS [training: 0.1561711141585969 | validation: 0.2956617039867938]
	TIME [epoch: 32.7 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1526800753200217		[learning rate: 0.0011635]
	Learning Rate: 0.00116351
	LOSS [training: 0.1526800753200217 | validation: 0.3019499794264303]
	TIME [epoch: 32.7 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1504970614153184		[learning rate: 0.0011584]
	Learning Rate: 0.00115837
	LOSS [training: 0.1504970614153184 | validation: 0.3118556819365207]
	TIME [epoch: 32.7 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1519864224277529		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.1519864224277529 | validation: 0.28264083393507977]
	TIME [epoch: 32.7 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1513147498251171		[learning rate: 0.0011482]
	Learning Rate: 0.00114815
	LOSS [training: 0.1513147498251171 | validation: 0.2894256734236684]
	TIME [epoch: 32.7 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15228382571566218		[learning rate: 0.0011431]
	Learning Rate: 0.00114308
	LOSS [training: 0.15228382571566218 | validation: 0.2760192386244479]
	TIME [epoch: 32.7 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15378829606981345		[learning rate: 0.001138]
	Learning Rate: 0.00113803
	LOSS [training: 0.15378829606981345 | validation: 0.29364071817466725]
	TIME [epoch: 32.7 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14705372424640584		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.14705372424640584 | validation: 0.2815017995736349]
	TIME [epoch: 32.7 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15641181470741333		[learning rate: 0.001128]
	Learning Rate: 0.001128
	LOSS [training: 0.15641181470741333 | validation: 0.2948360661044531]
	TIME [epoch: 32.7 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15567455208951492		[learning rate: 0.001123]
	Learning Rate: 0.00112301
	LOSS [training: 0.15567455208951492 | validation: 0.2867902382144065]
	TIME [epoch: 32.7 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14572094522409323		[learning rate: 0.0011181]
	Learning Rate: 0.00111805
	LOSS [training: 0.14572094522409323 | validation: 0.2985978997152303]
	TIME [epoch: 32.7 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15205516695797633		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.15205516695797633 | validation: 0.2911565686828337]
	TIME [epoch: 32.7 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15283572739448192		[learning rate: 0.0011082]
	Learning Rate: 0.00110819
	LOSS [training: 0.15283572739448192 | validation: 0.30345756785061717]
	TIME [epoch: 32.7 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14861902693661153		[learning rate: 0.0011033]
	Learning Rate: 0.0011033
	LOSS [training: 0.14861902693661153 | validation: 0.29635514719800127]
	TIME [epoch: 32.7 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1503815255087963		[learning rate: 0.0010984]
	Learning Rate: 0.00109842
	LOSS [training: 0.1503815255087963 | validation: 0.2812518674979737]
	TIME [epoch: 32.7 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15396705302438987		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.15396705302438987 | validation: 0.2861801253610575]
	TIME [epoch: 32.7 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15261802458211646		[learning rate: 0.0010887]
	Learning Rate: 0.00108874
	LOSS [training: 0.15261802458211646 | validation: 0.28860948725606694]
	TIME [epoch: 32.7 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14661575446884004		[learning rate: 0.0010839]
	Learning Rate: 0.00108393
	LOSS [training: 0.14661575446884004 | validation: 0.29264153592791414]
	TIME [epoch: 32.7 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14664932947788117		[learning rate: 0.0010791]
	Learning Rate: 0.00107914
	LOSS [training: 0.14664932947788117 | validation: 0.28874220363275793]
	TIME [epoch: 32.7 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1533463375730461		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.1533463375730461 | validation: 0.28783086523418433]
	TIME [epoch: 32.7 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14981199203744053		[learning rate: 0.0010696]
	Learning Rate: 0.00106962
	LOSS [training: 0.14981199203744053 | validation: 0.2755194554894547]
	TIME [epoch: 32.7 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14927601393704912		[learning rate: 0.0010649]
	Learning Rate: 0.0010649
	LOSS [training: 0.14927601393704912 | validation: 0.282879404653681]
	TIME [epoch: 32.7 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14980685610880054		[learning rate: 0.0010602]
	Learning Rate: 0.00106019
	LOSS [training: 0.14980685610880054 | validation: 0.28693516178490375]
	TIME [epoch: 32.7 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1517403543137815		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.1517403543137815 | validation: 0.2945763720318788]
	TIME [epoch: 32.7 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15040280290166444		[learning rate: 0.0010508]
	Learning Rate: 0.00105084
	LOSS [training: 0.15040280290166444 | validation: 0.2845636585529329]
	TIME [epoch: 32.7 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14967162004256968		[learning rate: 0.0010462]
	Learning Rate: 0.0010462
	LOSS [training: 0.14967162004256968 | validation: 0.28985295847017084]
	TIME [epoch: 32.7 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15030369900392782		[learning rate: 0.0010416]
	Learning Rate: 0.00104158
	LOSS [training: 0.15030369900392782 | validation: 0.29457048202473823]
	TIME [epoch: 32.7 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1511766731740956		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.1511766731740956 | validation: 0.29316245629697923]
	TIME [epoch: 32.7 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1515432808471349		[learning rate: 0.0010324]
	Learning Rate: 0.0010324
	LOSS [training: 0.1515432808471349 | validation: 0.2868454625363021]
	TIME [epoch: 32.8 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1503191997589673		[learning rate: 0.0010278]
	Learning Rate: 0.00102783
	LOSS [training: 0.1503191997589673 | validation: 0.2870495630670125]
	TIME [epoch: 32.7 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15538056385408		[learning rate: 0.0010233]
	Learning Rate: 0.00102329
	LOSS [training: 0.15538056385408 | validation: 0.29098122329740767]
	TIME [epoch: 32.7 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14965420228661497		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.14965420228661497 | validation: 0.286666714445988]
	TIME [epoch: 32.7 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14856041879240145		[learning rate: 0.0010143]
	Learning Rate: 0.00101427
	LOSS [training: 0.14856041879240145 | validation: 0.28391516908375597]
	TIME [epoch: 32.7 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15008670201042854		[learning rate: 0.0010098]
	Learning Rate: 0.00100979
	LOSS [training: 0.15008670201042854 | validation: 0.2786860835047242]
	TIME [epoch: 32.7 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1517827052823205		[learning rate: 0.0010053]
	Learning Rate: 0.00100533
	LOSS [training: 0.1517827052823205 | validation: 0.3063472907338169]
	TIME [epoch: 32.7 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15122494331986364		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.15122494331986364 | validation: 0.2823654736407057]
	TIME [epoch: 32.7 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1490303442161148		[learning rate: 0.00099646]
	Learning Rate: 0.000996464
	LOSS [training: 0.1490303442161148 | validation: 0.29111968037597513]
	TIME [epoch: 32.7 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15238147443915512		[learning rate: 0.00099206]
	Learning Rate: 0.000992061
	LOSS [training: 0.15238147443915512 | validation: 0.28748862120672375]
	TIME [epoch: 32.7 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15157774136803018		[learning rate: 0.00098768]
	Learning Rate: 0.000987678
	LOSS [training: 0.15157774136803018 | validation: 0.2870913609534181]
	TIME [epoch: 32.7 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1475514671341877		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.1475514671341877 | validation: 0.28929476445364155]
	TIME [epoch: 32.7 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15533220214066418		[learning rate: 0.00097897]
	Learning Rate: 0.00097897
	LOSS [training: 0.15533220214066418 | validation: 0.296986940607333]
	TIME [epoch: 32.7 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14993385634763967		[learning rate: 0.00097464]
	Learning Rate: 0.000974644
	LOSS [training: 0.14993385634763967 | validation: 0.2797074865697639]
	TIME [epoch: 32.7 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15190652399376156		[learning rate: 0.00097034]
	Learning Rate: 0.000970338
	LOSS [training: 0.15190652399376156 | validation: 0.28415803559355535]
	TIME [epoch: 32.7 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15258304953341628		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.15258304953341628 | validation: 0.2951135096459301]
	TIME [epoch: 32.7 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15112201892090985		[learning rate: 0.00096178]
	Learning Rate: 0.000961783
	LOSS [training: 0.15112201892090985 | validation: 0.2972847960638647]
	TIME [epoch: 32.7 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15295878363095938		[learning rate: 0.00095753]
	Learning Rate: 0.000957533
	LOSS [training: 0.15295878363095938 | validation: 0.2855606422876712]
	TIME [epoch: 32.7 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15114889795021008		[learning rate: 0.0009533]
	Learning Rate: 0.000953303
	LOSS [training: 0.15114889795021008 | validation: 0.29055534256913956]
	TIME [epoch: 32.7 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15049127127117454		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.15049127127117454 | validation: 0.295632951111801]
	TIME [epoch: 32.7 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15187730073795871		[learning rate: 0.0009449]
	Learning Rate: 0.000944897
	LOSS [training: 0.15187730073795871 | validation: 0.2866510291402123]
	TIME [epoch: 32.7 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15073742592622213		[learning rate: 0.00094072]
	Learning Rate: 0.000940723
	LOSS [training: 0.15073742592622213 | validation: 0.3033535113394515]
	TIME [epoch: 32.7 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1524021129541281		[learning rate: 0.00093657]
	Learning Rate: 0.000936566
	LOSS [training: 0.1524021129541281 | validation: 0.28789434080863696]
	TIME [epoch: 32.7 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1492185978613239		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.1492185978613239 | validation: 0.28433473626886174]
	TIME [epoch: 32.7 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15323868146043398		[learning rate: 0.00092831]
	Learning Rate: 0.000928309
	LOSS [training: 0.15323868146043398 | validation: 0.28656718923839636]
	TIME [epoch: 32.7 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15193445026878655		[learning rate: 0.00092421]
	Learning Rate: 0.000924207
	LOSS [training: 0.15193445026878655 | validation: 0.28744453075866794]
	TIME [epoch: 32.7 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14727530745469042		[learning rate: 0.00092012]
	Learning Rate: 0.000920124
	LOSS [training: 0.14727530745469042 | validation: 0.29171846828760756]
	TIME [epoch: 32.7 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14871314196592472		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.14871314196592472 | validation: 0.30121331629221365]
	TIME [epoch: 32.7 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1546120534540751		[learning rate: 0.00091201]
	Learning Rate: 0.000912011
	LOSS [training: 0.1546120534540751 | validation: 0.2849732151345843]
	TIME [epoch: 32.7 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14696410903139895		[learning rate: 0.00090798]
	Learning Rate: 0.000907981
	LOSS [training: 0.14696410903139895 | validation: 0.30573431739113255]
	TIME [epoch: 32.7 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15457771132338405		[learning rate: 0.00090397]
	Learning Rate: 0.00090397
	LOSS [training: 0.15457771132338405 | validation: 0.28523811898891016]
	TIME [epoch: 32.7 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14941483114793763		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.14941483114793763 | validation: 0.2841133945194478]
	TIME [epoch: 32.7 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14567583736493347		[learning rate: 0.000896]
	Learning Rate: 0.000895999
	LOSS [training: 0.14567583736493347 | validation: 0.2910550008631893]
	TIME [epoch: 32.7 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1524668682610109		[learning rate: 0.00089204]
	Learning Rate: 0.000892041
	LOSS [training: 0.1524668682610109 | validation: 0.28439220799192727]
	TIME [epoch: 32.7 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1500045914583676		[learning rate: 0.0008881]
	Learning Rate: 0.000888099
	LOSS [training: 0.1500045914583676 | validation: 0.3051254798396015]
	TIME [epoch: 32.7 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14566889744446476		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.14566889744446476 | validation: 0.28513326683095114]
	TIME [epoch: 32.7 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.148971742696881		[learning rate: 0.00088027]
	Learning Rate: 0.000880269
	LOSS [training: 0.148971742696881 | validation: 0.28128094460496833]
	TIME [epoch: 32.7 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15037069387915905		[learning rate: 0.00087638]
	Learning Rate: 0.00087638
	LOSS [training: 0.15037069387915905 | validation: 0.2859198521540859]
	TIME [epoch: 32.7 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14762325776020516		[learning rate: 0.00087251]
	Learning Rate: 0.000872508
	LOSS [training: 0.14762325776020516 | validation: 0.292508254638584]
	TIME [epoch: 32.7 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15108736778312476		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.15108736778312476 | validation: 0.28475928071344875]
	TIME [epoch: 32.7 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15035579002286453		[learning rate: 0.00086481]
	Learning Rate: 0.000864815
	LOSS [training: 0.15035579002286453 | validation: 0.3065392937149608]
	TIME [epoch: 32.7 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14717665828916165		[learning rate: 0.00086099]
	Learning Rate: 0.000860994
	LOSS [training: 0.14717665828916165 | validation: 0.28529503661927397]
	TIME [epoch: 32.7 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15440353101242074		[learning rate: 0.00085719]
	Learning Rate: 0.00085719
	LOSS [training: 0.15440353101242074 | validation: 0.284639983539973]
	TIME [epoch: 32.7 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.151031271838615		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.151031271838615 | validation: 0.2802543655252333]
	TIME [epoch: 32.7 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15136004131222597		[learning rate: 0.00084963]
	Learning Rate: 0.000849632
	LOSS [training: 0.15136004131222597 | validation: 0.292827610195914]
	TIME [epoch: 32.7 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15344826393520852		[learning rate: 0.00084588]
	Learning Rate: 0.000845878
	LOSS [training: 0.15344826393520852 | validation: 0.3018484605572191]
	TIME [epoch: 32.7 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1498590813538721		[learning rate: 0.00084214]
	Learning Rate: 0.000842141
	LOSS [training: 0.1498590813538721 | validation: 0.2837401594486455]
	TIME [epoch: 32.7 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14878826094879655		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.14878826094879655 | validation: 0.2850013718016199]
	TIME [epoch: 32.7 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1475437798118596		[learning rate: 0.00083472]
	Learning Rate: 0.000834715
	LOSS [training: 0.1475437798118596 | validation: 0.30115022831809996]
	TIME [epoch: 32.7 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1489591787230474		[learning rate: 0.00083103]
	Learning Rate: 0.000831028
	LOSS [training: 0.1489591787230474 | validation: 0.2993742488535853]
	TIME [epoch: 32.7 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1497309838427597		[learning rate: 0.00082736]
	Learning Rate: 0.000827356
	LOSS [training: 0.1497309838427597 | validation: 0.28506705350721656]
	TIME [epoch: 32.7 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14754685870268794		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.14754685870268794 | validation: 0.2868666448948054]
	TIME [epoch: 32.7 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1518709205790521		[learning rate: 0.00082006]
	Learning Rate: 0.000820061
	LOSS [training: 0.1518709205790521 | validation: 0.29506671203580404]
	TIME [epoch: 32.7 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1472811304863386		[learning rate: 0.00081644]
	Learning Rate: 0.000816438
	LOSS [training: 0.1472811304863386 | validation: 0.2820987871985675]
	TIME [epoch: 32.7 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14921956389938323		[learning rate: 0.00081283]
	Learning Rate: 0.000812831
	LOSS [training: 0.14921956389938323 | validation: 0.28566007552325734]
	TIME [epoch: 32.7 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1505112948283603		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.1505112948283603 | validation: 0.28836029966606697]
	TIME [epoch: 32.7 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1512558009448734		[learning rate: 0.00080566]
	Learning Rate: 0.000805664
	LOSS [training: 0.1512558009448734 | validation: 0.28322951257864254]
	TIME [epoch: 32.7 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15164167095448539		[learning rate: 0.0008021]
	Learning Rate: 0.000802104
	LOSS [training: 0.15164167095448539 | validation: 0.2901040641398771]
	TIME [epoch: 32.7 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1500981534152181		[learning rate: 0.00079856]
	Learning Rate: 0.00079856
	LOSS [training: 0.1500981534152181 | validation: 0.294589026171472]
	TIME [epoch: 32.7 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14799903445257748		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.14799903445257748 | validation: 0.28344196812958505]
	TIME [epoch: 32.8 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15003109025729175		[learning rate: 0.00079152]
	Learning Rate: 0.000791519
	LOSS [training: 0.15003109025729175 | validation: 0.2869944730921209]
	TIME [epoch: 32.7 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14935565896171538		[learning rate: 0.00078802]
	Learning Rate: 0.000788022
	LOSS [training: 0.14935565896171538 | validation: 0.2776681527887882]
	TIME [epoch: 32.7 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15335735156956526		[learning rate: 0.00078454]
	Learning Rate: 0.000784541
	LOSS [training: 0.15335735156956526 | validation: 0.2983489021940683]
	TIME [epoch: 32.7 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1514796315468147		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.1514796315468147 | validation: 0.2947471286761646]
	TIME [epoch: 32.8 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15146811515341024		[learning rate: 0.00077762]
	Learning Rate: 0.000777623
	LOSS [training: 0.15146811515341024 | validation: 0.29508640758643545]
	TIME [epoch: 32.7 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15110112035924445		[learning rate: 0.00077419]
	Learning Rate: 0.000774188
	LOSS [training: 0.15110112035924445 | validation: 0.2819785126224886]
	TIME [epoch: 32.7 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1519035483886489		[learning rate: 0.00077077]
	Learning Rate: 0.000770767
	LOSS [training: 0.1519035483886489 | validation: 0.28651219977950393]
	TIME [epoch: 32.7 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14781490349669005		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.14781490349669005 | validation: 0.2900152505532019]
	TIME [epoch: 32.7 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1521109348992933		[learning rate: 0.00076397]
	Learning Rate: 0.000763971
	LOSS [training: 0.1521109348992933 | validation: 0.284775108209987]
	TIME [epoch: 32.7 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14872437455220147		[learning rate: 0.0007606]
	Learning Rate: 0.000760596
	LOSS [training: 0.14872437455220147 | validation: 0.28949578688757077]
	TIME [epoch: 32.7 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1495483861352783		[learning rate: 0.00075724]
	Learning Rate: 0.000757235
	LOSS [training: 0.1495483861352783 | validation: 0.2876010719611552]
	TIME [epoch: 32.7 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14778245303221377		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.14778245303221377 | validation: 0.28530683709714233]
	TIME [epoch: 32.7 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14774127916873953		[learning rate: 0.00075056]
	Learning Rate: 0.000750559
	LOSS [training: 0.14774127916873953 | validation: 0.28920388328918134]
	TIME [epoch: 32.7 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14964423525105236		[learning rate: 0.00074724]
	Learning Rate: 0.000747242
	LOSS [training: 0.14964423525105236 | validation: 0.2830161802105806]
	TIME [epoch: 32.8 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14817781910916422		[learning rate: 0.00074394]
	Learning Rate: 0.000743941
	LOSS [training: 0.14817781910916422 | validation: 0.2872086768045748]
	TIME [epoch: 32.7 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15157317633609382		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.15157317633609382 | validation: 0.28533396649524345]
	TIME [epoch: 32.7 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14976127871117825		[learning rate: 0.00073738]
	Learning Rate: 0.000737382
	LOSS [training: 0.14976127871117825 | validation: 0.28259560860169336]
	TIME [epoch: 32.7 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1512123838050993		[learning rate: 0.00073412]
	Learning Rate: 0.000734124
	LOSS [training: 0.1512123838050993 | validation: 0.28218138698261896]
	TIME [epoch: 32.7 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1489045027650627		[learning rate: 0.00073088]
	Learning Rate: 0.00073088
	LOSS [training: 0.1489045027650627 | validation: 0.28959338864654255]
	TIME [epoch: 32.8 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15129029902243385		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 0.15129029902243385 | validation: 0.2949618042685238]
	TIME [epoch: 32.7 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14899410180242875		[learning rate: 0.00072444]
	Learning Rate: 0.000724436
	LOSS [training: 0.14899410180242875 | validation: 0.2830507876894947]
	TIME [epoch: 32.8 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1488456365129372		[learning rate: 0.00072124]
	Learning Rate: 0.000721235
	LOSS [training: 0.1488456365129372 | validation: 0.2848275542993041]
	TIME [epoch: 32.6 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14797595981987183		[learning rate: 0.00071805]
	Learning Rate: 0.000718049
	LOSS [training: 0.14797595981987183 | validation: 0.28729325350828655]
	TIME [epoch: 32.8 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15083052532487945		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.15083052532487945 | validation: 0.2868055457578456]
	TIME [epoch: 32.7 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14908748642591868		[learning rate: 0.00071172]
	Learning Rate: 0.000711718
	LOSS [training: 0.14908748642591868 | validation: 0.2883321698798559]
	TIME [epoch: 32.8 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1504725422317846		[learning rate: 0.00070857]
	Learning Rate: 0.000708573
	LOSS [training: 0.1504725422317846 | validation: 0.29435951677185496]
	TIME [epoch: 32.6 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14910594449052234		[learning rate: 0.00070544]
	Learning Rate: 0.000705442
	LOSS [training: 0.14910594449052234 | validation: 0.29906359824868384]
	TIME [epoch: 32.8 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1475453053981119		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.1475453053981119 | validation: 0.2811117268923042]
	TIME [epoch: 32.7 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14938228857225072		[learning rate: 0.00069922]
	Learning Rate: 0.000699222
	LOSS [training: 0.14938228857225072 | validation: 0.27894965634846414]
	TIME [epoch: 32.6 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15043013748711193		[learning rate: 0.00069613]
	Learning Rate: 0.000696133
	LOSS [training: 0.15043013748711193 | validation: 0.28921242293339294]
	TIME [epoch: 32.8 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14886107997724765		[learning rate: 0.00069306]
	Learning Rate: 0.000693058
	LOSS [training: 0.14886107997724765 | validation: 0.2918798908046646]
	TIME [epoch: 32.7 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15289831487888345		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 0.15289831487888345 | validation: 0.2837985944472419]
	TIME [epoch: 32.8 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1505663247371222		[learning rate: 0.00068695]
	Learning Rate: 0.000686947
	LOSS [training: 0.1505663247371222 | validation: 0.28438141317213017]
	TIME [epoch: 32.7 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14793856599789532		[learning rate: 0.00068391]
	Learning Rate: 0.000683912
	LOSS [training: 0.14793856599789532 | validation: 0.28779814155665445]
	TIME [epoch: 32.8 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14770201542812197		[learning rate: 0.00068089]
	Learning Rate: 0.00068089
	LOSS [training: 0.14770201542812197 | validation: 0.2898915003244267]
	TIME [epoch: 32.7 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14699327237347923		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 0.14699327237347923 | validation: 0.2887665451763345]
	TIME [epoch: 32.7 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14968032252475966		[learning rate: 0.00067489]
	Learning Rate: 0.000674887
	LOSS [training: 0.14968032252475966 | validation: 0.2860337978222836]
	TIME [epoch: 32.7 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1457754947602154		[learning rate: 0.0006719]
	Learning Rate: 0.000671905
	LOSS [training: 0.1457754947602154 | validation: 0.2840081245299156]
	TIME [epoch: 32.8 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15073298327175413		[learning rate: 0.00066894]
	Learning Rate: 0.000668936
	LOSS [training: 0.15073298327175413 | validation: 0.2925319325173839]
	TIME [epoch: 32.7 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15073807126977862		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 0.15073807126977862 | validation: 0.28356243717206]
	TIME [epoch: 32.8 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15069617788727857		[learning rate: 0.00066304]
	Learning Rate: 0.000663038
	LOSS [training: 0.15069617788727857 | validation: 0.28276727848897826]
	TIME [epoch: 32.8 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14700664659433083		[learning rate: 0.00066011]
	Learning Rate: 0.000660109
	LOSS [training: 0.14700664659433083 | validation: 0.2896915421431676]
	TIME [epoch: 32.7 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1503755304319402		[learning rate: 0.00065719]
	Learning Rate: 0.000657192
	LOSS [training: 0.1503755304319402 | validation: 0.2797634778588996]
	TIME [epoch: 32.7 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15102993837405815		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 0.15102993837405815 | validation: 0.28919215337648746]
	TIME [epoch: 32.7 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1522722933193013		[learning rate: 0.0006514]
	Learning Rate: 0.000651398
	LOSS [training: 0.1522722933193013 | validation: 0.27734285482431487]
	TIME [epoch: 32.7 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14734254239404748		[learning rate: 0.00064852]
	Learning Rate: 0.00064852
	LOSS [training: 0.14734254239404748 | validation: 0.28376359915854377]
	TIME [epoch: 32.6 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14926002329526214		[learning rate: 0.00064565]
	Learning Rate: 0.000645654
	LOSS [training: 0.14926002329526214 | validation: 0.2796473108825024]
	TIME [epoch: 32.8 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14657283826776507		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 0.14657283826776507 | validation: 0.29295148758521183]
	TIME [epoch: 32.7 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14980808397293102		[learning rate: 0.00063996]
	Learning Rate: 0.000639962
	LOSS [training: 0.14980808397293102 | validation: 0.29260964307882364]
	TIME [epoch: 32.7 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1526934102178929		[learning rate: 0.00063713]
	Learning Rate: 0.000637134
	LOSS [training: 0.1526934102178929 | validation: 0.2946005292415887]
	TIME [epoch: 32.7 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14735870090137942		[learning rate: 0.00063432]
	Learning Rate: 0.000634319
	LOSS [training: 0.14735870090137942 | validation: 0.2920476987508176]
	TIME [epoch: 32.8 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15094252218147983		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 0.15094252218147983 | validation: 0.28539367812332705]
	TIME [epoch: 32.7 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14891983645660262		[learning rate: 0.00062873]
	Learning Rate: 0.000628726
	LOSS [training: 0.14891983645660262 | validation: 0.2866782893970342]
	TIME [epoch: 32.7 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14907495857340075		[learning rate: 0.00062595]
	Learning Rate: 0.000625948
	LOSS [training: 0.14907495857340075 | validation: 0.2963072666197371]
	TIME [epoch: 32.7 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14886005678938577		[learning rate: 0.00062318]
	Learning Rate: 0.000623183
	LOSS [training: 0.14886005678938577 | validation: 0.29423266331036696]
	TIME [epoch: 32.7 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14998516841205728		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 0.14998516841205728 | validation: 0.28103847457431347]
	TIME [epoch: 32.8 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14863655333921766		[learning rate: 0.00061769]
	Learning Rate: 0.000617688
	LOSS [training: 0.14863655333921766 | validation: 0.283294572144459]
	TIME [epoch: 32.7 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1501684443380351		[learning rate: 0.00061496]
	Learning Rate: 0.000614959
	LOSS [training: 0.1501684443380351 | validation: 0.29001140100866846]
	TIME [epoch: 32.7 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14744851877011234		[learning rate: 0.00061224]
	Learning Rate: 0.000612242
	LOSS [training: 0.14744851877011234 | validation: 0.28137740228963565]
	TIME [epoch: 32.7 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14941723268940252		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 0.14941723268940252 | validation: 0.2948277502993862]
	TIME [epoch: 32.7 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14563457297988108		[learning rate: 0.00060684]
	Learning Rate: 0.000606844
	LOSS [training: 0.14563457297988108 | validation: 0.2950384729248669]
	TIME [epoch: 32.7 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1485919468849733		[learning rate: 0.00060416]
	Learning Rate: 0.000604163
	LOSS [training: 0.1485919468849733 | validation: 0.280023977823029]
	TIME [epoch: 32.8 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15045494426443537		[learning rate: 0.00060149]
	Learning Rate: 0.000601493
	LOSS [training: 0.15045494426443537 | validation: 0.2829163954873739]
	TIME [epoch: 32.7 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1481949775678221		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.1481949775678221 | validation: 0.2892025034738447]
	TIME [epoch: 32.8 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14977277176933962		[learning rate: 0.00059619]
	Learning Rate: 0.00059619
	LOSS [training: 0.14977277176933962 | validation: 0.29327509993446566]
	TIME [epoch: 32.7 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14920870997184307		[learning rate: 0.00059356]
	Learning Rate: 0.000593556
	LOSS [training: 0.14920870997184307 | validation: 0.2880524960910884]
	TIME [epoch: 32.7 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14579905218313938		[learning rate: 0.00059093]
	Learning Rate: 0.000590933
	LOSS [training: 0.14579905218313938 | validation: 0.28450038249157744]
	TIME [epoch: 32.7 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1512775101808532		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 0.1512775101808532 | validation: 0.2855111209183375]
	TIME [epoch: 32.7 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14774559335936324		[learning rate: 0.00058572]
	Learning Rate: 0.000585723
	LOSS [training: 0.14774559335936324 | validation: 0.287688662788428]
	TIME [epoch: 32.7 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v12_20240716_181840/states/model_facs_v2_dec2b_2dpca_v12_681.pth
Halted early. No improvement in validation loss for 200 epochs.
Finished training in 13338.792 seconds.
