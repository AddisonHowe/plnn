Args:
Namespace(name='model_facs_v3_dec1b_2dpca_v14b', outdir='out/model_training/model_facs_v3_dec1b_2dpca_v14b', training_data='data/training_data/facs_v3/pca/dec1_fitonsubset/transition1_subset_epi_tr_ce_an_pc12/training', validation_data='data/training_data/facs_v3/pca/dec1_fitonsubset/transition1_subset_epi_tr_ce_an_pc12/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=10, batch_size=50, patience=200, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, quadratic_a=1.0, quadratic_b=1.0, ndims=2, nparams=2, nsigs=2, ncells=200, ncells_sample=200, model_do_sample=False, dt=0.005, dt_schedule='stepped', dt_schedule_bounds=[50, 100, 200, 300], dt_schedule_scales=[0.5, 0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', kernel='multiscale', bw_range=[0.2, 0.5, 0.9, 1.1, 1.3, 1.5, 2.0], optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 1824559475

Training model...

Saving initial model state to: out/model_training/model_facs_v3_dec1b_2dpca_v14b_20240716_161522/states/model_facs_v3_dec1b_2dpca_v14b_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.4037867116066638		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4037867116066638 | validation: 1.2351639335320617]
	TIME [epoch: 24.1 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14b_20240716_161522/states/model_facs_v3_dec1b_2dpca_v14b_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.284125207881495		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.284125207881495 | validation: 1.1571277884113327]
	TIME [epoch: 5.93 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14b_20240716_161522/states/model_facs_v3_dec1b_2dpca_v14b_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.2337299636097903		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2337299636097903 | validation: 1.1079010730078735]
	TIME [epoch: 5.9 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14b_20240716_161522/states/model_facs_v3_dec1b_2dpca_v14b_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.159443310204974		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.159443310204974 | validation: 1.046347498244344]
	TIME [epoch: 5.92 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14b_20240716_161522/states/model_facs_v3_dec1b_2dpca_v14b_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.1116202021437873		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1116202021437873 | validation: 0.9717420854939117]
	TIME [epoch: 5.97 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14b_20240716_161522/states/model_facs_v3_dec1b_2dpca_v14b_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.0342441464788443		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0342441464788443 | validation: 0.9135196835641086]
	TIME [epoch: 5.92 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14b_20240716_161522/states/model_facs_v3_dec1b_2dpca_v14b_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.9810963200048901		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9810963200048901 | validation: 0.9155311529627752]
	TIME [epoch: 5.93 sec]
EPOCH 8/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.9543859667270448		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9543859667270448 | validation: 0.8285459729002718]
	TIME [epoch: 5.93 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14b_20240716_161522/states/model_facs_v3_dec1b_2dpca_v14b_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.8379187447418177		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8379187447418177 | validation: 0.7869854986318746]
	TIME [epoch: 5.91 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14b_20240716_161522/states/model_facs_v3_dec1b_2dpca_v14b_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.8241411846653842		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8241411846653842 | validation: 0.6984095144390196]
	TIME [epoch: 5.91 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14b_20240716_161522/states/model_facs_v3_dec1b_2dpca_v14b_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.7924574379913771		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7924574379913771 | validation: 0.8417498798238657]
	TIME [epoch: 5.93 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.7113399000168338		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7113399000168338 | validation: 0.6575165775029289]
	TIME [epoch: 5.93 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14b_20240716_161522/states/model_facs_v3_dec1b_2dpca_v14b_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.7503226485743343		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7503226485743343 | validation: 0.6622653365991438]
	TIME [epoch: 5.92 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.6412148046218612		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6412148046218612 | validation: 0.5556782454493401]
	TIME [epoch: 5.92 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14b_20240716_161522/states/model_facs_v3_dec1b_2dpca_v14b_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5551357824545557		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5551357824545557 | validation: 0.5305380597770726]
	TIME [epoch: 5.93 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14b_20240716_161522/states/model_facs_v3_dec1b_2dpca_v14b_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5912979304162999		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5912979304162999 | validation: 0.6268685086032952]
	TIME [epoch: 5.92 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5716362583173215		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5716362583173215 | validation: 0.486596054243872]
	TIME [epoch: 5.92 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14b_20240716_161522/states/model_facs_v3_dec1b_2dpca_v14b_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.49863872469611087		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.49863872469611087 | validation: 0.4749867490252654]
	TIME [epoch: 5.92 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14b_20240716_161522/states/model_facs_v3_dec1b_2dpca_v14b_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5707196952798407		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5707196952798407 | validation: 0.45483089741907257]
	TIME [epoch: 5.92 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14b_20240716_161522/states/model_facs_v3_dec1b_2dpca_v14b_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.46967872311066633		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.46967872311066633 | validation: 0.4415331833782446]
	TIME [epoch: 5.92 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14b_20240716_161522/states/model_facs_v3_dec1b_2dpca_v14b_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.45319008390486154		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.45319008390486154 | validation: 0.41964803854592736]
	TIME [epoch: 5.92 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14b_20240716_161522/states/model_facs_v3_dec1b_2dpca_v14b_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.46175522764709		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.46175522764709 | validation: 0.39808497865788023]
	TIME [epoch: 5.92 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14b_20240716_161522/states/model_facs_v3_dec1b_2dpca_v14b_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.43580033814021296		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.43580033814021296 | validation: 0.4120010649524429]
	TIME [epoch: 5.93 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4841920678678417		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4841920678678417 | validation: 0.4202128055668579]
	TIME [epoch: 5.91 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.423645587634406		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.423645587634406 | validation: 0.39993497707834236]
	TIME [epoch: 5.91 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4084118896033772		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4084118896033772 | validation: 0.38952631579183994]
	TIME [epoch: 5.91 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14b_20240716_161522/states/model_facs_v3_dec1b_2dpca_v14b_26.pth
	Model improved!!!
EPOCH 27/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3849720851050981		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3849720851050981 | validation: 0.3733563992448121]
	TIME [epoch: 5.94 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14b_20240716_161522/states/model_facs_v3_dec1b_2dpca_v14b_27.pth
	Model improved!!!
EPOCH 28/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.428791381285686		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.428791381285686 | validation: 0.38742770857719716]
	TIME [epoch: 5.91 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.46256192055813905		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.46256192055813905 | validation: 0.39147344569624304]
	TIME [epoch: 5.9 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.42269068633996665		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.42269068633996665 | validation: 0.3503714685694907]
	TIME [epoch: 5.9 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14b_20240716_161522/states/model_facs_v3_dec1b_2dpca_v14b_30.pth
	Model improved!!!
EPOCH 31/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3968163283615785		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3968163283615785 | validation: 0.3569645320220566]
	TIME [epoch: 5.93 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4094253668860082		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4094253668860082 | validation: 0.3605591521700385]
	TIME [epoch: 5.93 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4062420462923171		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4062420462923171 | validation: 0.3526068341990508]
	TIME [epoch: 5.94 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4031180188014716		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4031180188014716 | validation: 0.35722530147683146]
	TIME [epoch: 5.93 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4294765764308845		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4294765764308845 | validation: 0.39273369400543373]
	TIME [epoch: 5.9 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4048795421576017		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4048795421576017 | validation: 0.3516265692528467]
	TIME [epoch: 5.91 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4048532477499065		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4048532477499065 | validation: 0.3456461904329468]
	TIME [epoch: 5.91 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14b_20240716_161522/states/model_facs_v3_dec1b_2dpca_v14b_37.pth
	Model improved!!!
EPOCH 38/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.40079063907643997		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.40079063907643997 | validation: 0.3343727381835942]
	TIME [epoch: 5.92 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14b_20240716_161522/states/model_facs_v3_dec1b_2dpca_v14b_38.pth
	Model improved!!!
EPOCH 39/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3953997327093663		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3953997327093663 | validation: 0.33547252020989055]
	TIME [epoch: 5.94 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3654341791380009		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3654341791380009 | validation: 0.3116222502141798]
	TIME [epoch: 7.24 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14b_20240716_161522/states/model_facs_v3_dec1b_2dpca_v14b_40.pth
	Model improved!!!
EPOCH 41/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3443867545070962		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3443867545070962 | validation: 0.29420774647388925]
	TIME [epoch: 5.92 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14b_20240716_161522/states/model_facs_v3_dec1b_2dpca_v14b_41.pth
	Model improved!!!
EPOCH 42/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3495636346999884		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3495636346999884 | validation: 0.3420051349826786]
	TIME [epoch: 5.94 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3570009404423387		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3570009404423387 | validation: 0.3170061451597543]
	TIME [epoch: 5.94 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.36395087644975893		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.36395087644975893 | validation: 0.2874518610810593]
	TIME [epoch: 5.93 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14b_20240716_161522/states/model_facs_v3_dec1b_2dpca_v14b_44.pth
	Model improved!!!
EPOCH 45/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.33071085164790376		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.33071085164790376 | validation: 0.277238125055593]
	TIME [epoch: 5.92 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14b_20240716_161522/states/model_facs_v3_dec1b_2dpca_v14b_45.pth
	Model improved!!!
EPOCH 46/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.337096957297428		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.337096957297428 | validation: 0.2842183376792953]
	TIME [epoch: 5.92 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.33299270420346366		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.33299270420346366 | validation: 0.26508037039172033]
	TIME [epoch: 5.92 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14b_20240716_161522/states/model_facs_v3_dec1b_2dpca_v14b_47.pth
	Model improved!!!
EPOCH 48/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.33208123373830384		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.33208123373830384 | validation: 0.2892499090583163]
	TIME [epoch: 5.93 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3206438428071838		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3206438428071838 | validation: 0.2793267421348523]
	TIME [epoch: 5.92 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3130783114672921		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3130783114672921 | validation: 0.2653339762969432]
	TIME [epoch: 5.92 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.33397068639952		[learning rate: 0.0099705]
	Learning Rate: 0.00997052
	LOSS [training: 0.33397068639952 | validation: 0.2801943573171404]
	TIME [epoch: 27.1 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.33598397470441405		[learning rate: 0.0099353]
	Learning Rate: 0.00993527
	LOSS [training: 0.33598397470441405 | validation: 0.25760746568010745]
	TIME [epoch: 11.4 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14b_20240716_161522/states/model_facs_v3_dec1b_2dpca_v14b_52.pth
	Model improved!!!
EPOCH 53/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3149459347381653		[learning rate: 0.0099001]
	Learning Rate: 0.00990013
	LOSS [training: 0.3149459347381653 | validation: 0.2461433472062248]
	TIME [epoch: 11.4 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14b_20240716_161522/states/model_facs_v3_dec1b_2dpca_v14b_53.pth
	Model improved!!!
EPOCH 54/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.31773188144036485		[learning rate: 0.0098651]
	Learning Rate: 0.00986512
	LOSS [training: 0.31773188144036485 | validation: 0.2635505178816063]
	TIME [epoch: 11.4 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.33918202725355556		[learning rate: 0.0098302]
	Learning Rate: 0.00983024
	LOSS [training: 0.33918202725355556 | validation: 0.26831327614192374]
	TIME [epoch: 11.4 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2943218240555065		[learning rate: 0.0097955]
	Learning Rate: 0.00979548
	LOSS [training: 0.2943218240555065 | validation: 0.2552950969432305]
	TIME [epoch: 11.4 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.31038443732124105		[learning rate: 0.0097608]
	Learning Rate: 0.00976084
	LOSS [training: 0.31038443732124105 | validation: 0.2595328203308029]
	TIME [epoch: 11.4 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3159450423114507		[learning rate: 0.0097263]
	Learning Rate: 0.00972632
	LOSS [training: 0.3159450423114507 | validation: 0.29529316082797585]
	TIME [epoch: 11.4 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3344399938886328		[learning rate: 0.0096919]
	Learning Rate: 0.00969193
	LOSS [training: 0.3344399938886328 | validation: 0.26272213621939916]
	TIME [epoch: 11.4 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.306770107315599		[learning rate: 0.0096577]
	Learning Rate: 0.00965766
	LOSS [training: 0.306770107315599 | validation: 0.2677908707790856]
	TIME [epoch: 11.4 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.30308832234881666		[learning rate: 0.0096235]
	Learning Rate: 0.00962351
	LOSS [training: 0.30308832234881666 | validation: 0.28107511256610784]
	TIME [epoch: 11.4 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3230255805944932		[learning rate: 0.0095895]
	Learning Rate: 0.00958948
	LOSS [training: 0.3230255805944932 | validation: 0.25503829546247975]
	TIME [epoch: 11.4 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.31212038044611407		[learning rate: 0.0095556]
	Learning Rate: 0.00955557
	LOSS [training: 0.31212038044611407 | validation: 0.25048416878300117]
	TIME [epoch: 11.4 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29932285033437706		[learning rate: 0.0095218]
	Learning Rate: 0.00952177
	LOSS [training: 0.29932285033437706 | validation: 0.25209013445097106]
	TIME [epoch: 11.4 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3034373079247202		[learning rate: 0.0094881]
	Learning Rate: 0.0094881
	LOSS [training: 0.3034373079247202 | validation: 0.24960191508742574]
	TIME [epoch: 11.4 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2944797638365305		[learning rate: 0.0094546]
	Learning Rate: 0.00945455
	LOSS [training: 0.2944797638365305 | validation: 0.2490494694104674]
	TIME [epoch: 11.4 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2979545269521109		[learning rate: 0.0094211]
	Learning Rate: 0.00942112
	LOSS [training: 0.2979545269521109 | validation: 0.24511679615207088]
	TIME [epoch: 11.4 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14b_20240716_161522/states/model_facs_v3_dec1b_2dpca_v14b_67.pth
	Model improved!!!
EPOCH 68/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.30720882532788846		[learning rate: 0.0093878]
	Learning Rate: 0.00938781
	LOSS [training: 0.30720882532788846 | validation: 0.2568167548876528]
	TIME [epoch: 11.4 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.30476147110694063		[learning rate: 0.0093546]
	Learning Rate: 0.00935461
	LOSS [training: 0.30476147110694063 | validation: 0.24424753878910063]
	TIME [epoch: 11.4 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14b_20240716_161522/states/model_facs_v3_dec1b_2dpca_v14b_69.pth
	Model improved!!!
EPOCH 70/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3010602393270744		[learning rate: 0.0093215]
	Learning Rate: 0.00932153
	LOSS [training: 0.3010602393270744 | validation: 0.23721042704849843]
	TIME [epoch: 11.4 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14b_20240716_161522/states/model_facs_v3_dec1b_2dpca_v14b_70.pth
	Model improved!!!
EPOCH 71/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3185497383184634		[learning rate: 0.0092886]
	Learning Rate: 0.00928857
	LOSS [training: 0.3185497383184634 | validation: 0.23518610330944228]
	TIME [epoch: 11.4 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14b_20240716_161522/states/model_facs_v3_dec1b_2dpca_v14b_71.pth
	Model improved!!!
EPOCH 72/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29351146217647356		[learning rate: 0.0092557]
	Learning Rate: 0.00925572
	LOSS [training: 0.29351146217647356 | validation: 0.24025863820426382]
	TIME [epoch: 11.3 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2845691703302134		[learning rate: 0.009223]
	Learning Rate: 0.00922299
	LOSS [training: 0.2845691703302134 | validation: 0.23303085198415854]
	TIME [epoch: 11.3 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14b_20240716_161522/states/model_facs_v3_dec1b_2dpca_v14b_73.pth
	Model improved!!!
EPOCH 74/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29954174731278504		[learning rate: 0.0091904]
	Learning Rate: 0.00919038
	LOSS [training: 0.29954174731278504 | validation: 0.26724388460086973]
	TIME [epoch: 11.3 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27946788707315773		[learning rate: 0.0091579]
	Learning Rate: 0.00915788
	LOSS [training: 0.27946788707315773 | validation: 0.23986620985065973]
	TIME [epoch: 11.3 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.307939233804665		[learning rate: 0.0091255]
	Learning Rate: 0.00912549
	LOSS [training: 0.307939233804665 | validation: 0.24626616752867844]
	TIME [epoch: 11.3 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2951396379370498		[learning rate: 0.0090932]
	Learning Rate: 0.00909323
	LOSS [training: 0.2951396379370498 | validation: 0.23276592771683252]
	TIME [epoch: 11.3 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14b_20240716_161522/states/model_facs_v3_dec1b_2dpca_v14b_77.pth
	Model improved!!!
EPOCH 78/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28867031757877404		[learning rate: 0.0090611]
	Learning Rate: 0.00906107
	LOSS [training: 0.28867031757877404 | validation: 0.252795059021271]
	TIME [epoch: 11.4 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27890267224661874		[learning rate: 0.009029]
	Learning Rate: 0.00902903
	LOSS [training: 0.27890267224661874 | validation: 0.24338335482535606]
	TIME [epoch: 11.4 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2901749770570973		[learning rate: 0.0089971]
	Learning Rate: 0.0089971
	LOSS [training: 0.2901749770570973 | validation: 0.23851260824151965]
	TIME [epoch: 11.4 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3150638670083704		[learning rate: 0.0089653]
	Learning Rate: 0.00896528
	LOSS [training: 0.3150638670083704 | validation: 0.2487588630231139]
	TIME [epoch: 11.4 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29379442950823736		[learning rate: 0.0089336]
	Learning Rate: 0.00893358
	LOSS [training: 0.29379442950823736 | validation: 0.22888397453569068]
	TIME [epoch: 11.4 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14b_20240716_161522/states/model_facs_v3_dec1b_2dpca_v14b_82.pth
	Model improved!!!
EPOCH 83/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27955253870207236		[learning rate: 0.008902]
	Learning Rate: 0.00890199
	LOSS [training: 0.27955253870207236 | validation: 0.23205233053952448]
	TIME [epoch: 11.4 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28099356248080837		[learning rate: 0.0088705]
	Learning Rate: 0.00887051
	LOSS [training: 0.28099356248080837 | validation: 0.24112385280710608]
	TIME [epoch: 11.4 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3076123377085801		[learning rate: 0.0088391]
	Learning Rate: 0.00883914
	LOSS [training: 0.3076123377085801 | validation: 0.24102518886125343]
	TIME [epoch: 11.4 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28136339200039895		[learning rate: 0.0088079]
	Learning Rate: 0.00880789
	LOSS [training: 0.28136339200039895 | validation: 0.2552709189892253]
	TIME [epoch: 11.4 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3060168486650838		[learning rate: 0.0087767]
	Learning Rate: 0.00877674
	LOSS [training: 0.3060168486650838 | validation: 0.24382055690659085]
	TIME [epoch: 11.4 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2895877739290325		[learning rate: 0.0087457]
	Learning Rate: 0.00874571
	LOSS [training: 0.2895877739290325 | validation: 0.2617450363097481]
	TIME [epoch: 11.4 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28217189150511596		[learning rate: 0.0087148]
	Learning Rate: 0.00871478
	LOSS [training: 0.28217189150511596 | validation: 0.2332883311814013]
	TIME [epoch: 11.4 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28393047075629496		[learning rate: 0.008684]
	Learning Rate: 0.00868396
	LOSS [training: 0.28393047075629496 | validation: 0.23394697875238002]
	TIME [epoch: 11.4 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3013733271505426		[learning rate: 0.0086533]
	Learning Rate: 0.00865326
	LOSS [training: 0.3013733271505426 | validation: 0.2660045852803289]
	TIME [epoch: 11.4 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2816717348146656		[learning rate: 0.0086227]
	Learning Rate: 0.00862265
	LOSS [training: 0.2816717348146656 | validation: 0.23520392528409717]
	TIME [epoch: 11.4 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29405309895520476		[learning rate: 0.0085922]
	Learning Rate: 0.00859216
	LOSS [training: 0.29405309895520476 | validation: 0.25280787352154943]
	TIME [epoch: 11.4 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2842196858021728		[learning rate: 0.0085618]
	Learning Rate: 0.00856178
	LOSS [training: 0.2842196858021728 | validation: 0.22908437895237094]
	TIME [epoch: 11.4 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27966537015203047		[learning rate: 0.0085315]
	Learning Rate: 0.0085315
	LOSS [training: 0.27966537015203047 | validation: 0.2365269270678647]
	TIME [epoch: 11.4 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3053421921359985		[learning rate: 0.0085013]
	Learning Rate: 0.00850134
	LOSS [training: 0.3053421921359985 | validation: 0.22687405150858025]
	TIME [epoch: 11.4 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14b_20240716_161522/states/model_facs_v3_dec1b_2dpca_v14b_96.pth
	Model improved!!!
EPOCH 97/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28444046546488333		[learning rate: 0.0084713]
	Learning Rate: 0.00847127
	LOSS [training: 0.28444046546488333 | validation: 0.2436475822703926]
	TIME [epoch: 11.4 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28984674884838885		[learning rate: 0.0084413]
	Learning Rate: 0.00844132
	LOSS [training: 0.28984674884838885 | validation: 0.22599580606693767]
	TIME [epoch: 11.4 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14b_20240716_161522/states/model_facs_v3_dec1b_2dpca_v14b_98.pth
	Model improved!!!
EPOCH 99/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2789710082678572		[learning rate: 0.0084115]
	Learning Rate: 0.00841147
	LOSS [training: 0.2789710082678572 | validation: 0.24428823548303608]
	TIME [epoch: 11.4 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28836663886376646		[learning rate: 0.0083817]
	Learning Rate: 0.00838172
	LOSS [training: 0.28836663886376646 | validation: 0.23848900108366305]
	TIME [epoch: 11.4 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27449936489119897		[learning rate: 0.0083521]
	Learning Rate: 0.00835208
	LOSS [training: 0.27449936489119897 | validation: 0.2376599193369333]
	TIME [epoch: 40.2 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2848340152115598		[learning rate: 0.0083225]
	Learning Rate: 0.00832255
	LOSS [training: 0.2848340152115598 | validation: 0.27431549700313]
	TIME [epoch: 24.6 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.32416889036795926		[learning rate: 0.0082931]
	Learning Rate: 0.00829312
	LOSS [training: 0.32416889036795926 | validation: 0.25066728116559245]
	TIME [epoch: 24.6 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2776945405786608		[learning rate: 0.0082638]
	Learning Rate: 0.00826379
	LOSS [training: 0.2776945405786608 | validation: 0.2428335907071857]
	TIME [epoch: 24.6 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28483539652234685		[learning rate: 0.0082346]
	Learning Rate: 0.00823457
	LOSS [training: 0.28483539652234685 | validation: 0.22968013773777832]
	TIME [epoch: 24.6 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27815510312556263		[learning rate: 0.0082055]
	Learning Rate: 0.00820545
	LOSS [training: 0.27815510312556263 | validation: 0.2313204072950738]
	TIME [epoch: 24.6 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2764325338683347		[learning rate: 0.0081764]
	Learning Rate: 0.00817644
	LOSS [training: 0.2764325338683347 | validation: 0.23534721283542942]
	TIME [epoch: 24.6 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2754132143921268		[learning rate: 0.0081475]
	Learning Rate: 0.00814752
	LOSS [training: 0.2754132143921268 | validation: 0.21550116966454635]
	TIME [epoch: 24.6 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14b_20240716_161522/states/model_facs_v3_dec1b_2dpca_v14b_108.pth
	Model improved!!!
EPOCH 109/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27528953267694484		[learning rate: 0.0081187]
	Learning Rate: 0.00811871
	LOSS [training: 0.27528953267694484 | validation: 0.22727341719353347]
	TIME [epoch: 24.6 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2815057986724692		[learning rate: 0.00809]
	Learning Rate: 0.00809
	LOSS [training: 0.2815057986724692 | validation: 0.21903578250265401]
	TIME [epoch: 24.6 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2709240194224441		[learning rate: 0.0080614]
	Learning Rate: 0.0080614
	LOSS [training: 0.2709240194224441 | validation: 0.22422667420052617]
	TIME [epoch: 24.6 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2814718844159038		[learning rate: 0.0080329]
	Learning Rate: 0.00803289
	LOSS [training: 0.2814718844159038 | validation: 0.23121816891114907]
	TIME [epoch: 24.6 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27058151877786935		[learning rate: 0.0080045]
	Learning Rate: 0.00800448
	LOSS [training: 0.27058151877786935 | validation: 0.21953371220282064]
	TIME [epoch: 24.6 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29549009093607964		[learning rate: 0.0079762]
	Learning Rate: 0.00797618
	LOSS [training: 0.29549009093607964 | validation: 0.2251632033480031]
	TIME [epoch: 24.6 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2728074950123573		[learning rate: 0.007948]
	Learning Rate: 0.00794797
	LOSS [training: 0.2728074950123573 | validation: 0.21658334089927017]
	TIME [epoch: 24.6 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2689297763186302		[learning rate: 0.0079199]
	Learning Rate: 0.00791987
	LOSS [training: 0.2689297763186302 | validation: 0.23611464862464251]
	TIME [epoch: 24.6 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2843928805788989		[learning rate: 0.0078919]
	Learning Rate: 0.00789186
	LOSS [training: 0.2843928805788989 | validation: 0.23095315133574723]
	TIME [epoch: 24.6 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2896930863398557		[learning rate: 0.007864]
	Learning Rate: 0.00786395
	LOSS [training: 0.2896930863398557 | validation: 0.21681374749346521]
	TIME [epoch: 24.6 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27156538738426667		[learning rate: 0.0078361]
	Learning Rate: 0.00783615
	LOSS [training: 0.27156538738426667 | validation: 0.235133797008184]
	TIME [epoch: 24.6 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27879347368375423		[learning rate: 0.0078084]
	Learning Rate: 0.00780844
	LOSS [training: 0.27879347368375423 | validation: 0.22140898108534568]
	TIME [epoch: 24.6 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27221713499204		[learning rate: 0.0077808]
	Learning Rate: 0.00778083
	LOSS [training: 0.27221713499204 | validation: 0.22330597750921116]
	TIME [epoch: 24.6 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2573492590320159		[learning rate: 0.0077533]
	Learning Rate: 0.00775331
	LOSS [training: 0.2573492590320159 | validation: 0.23870864016050647]
	TIME [epoch: 24.6 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2922800103634017		[learning rate: 0.0077259]
	Learning Rate: 0.00772589
	LOSS [training: 0.2922800103634017 | validation: 0.2211912662635256]
	TIME [epoch: 24.6 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2889301867104814		[learning rate: 0.0076986]
	Learning Rate: 0.00769857
	LOSS [training: 0.2889301867104814 | validation: 0.23969637091116708]
	TIME [epoch: 24.6 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2943882814064625		[learning rate: 0.0076714]
	Learning Rate: 0.00767135
	LOSS [training: 0.2943882814064625 | validation: 0.22247804380285063]
	TIME [epoch: 24.6 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29550204798678875		[learning rate: 0.0076442]
	Learning Rate: 0.00764422
	LOSS [training: 0.29550204798678875 | validation: 0.22258705498408848]
	TIME [epoch: 24.6 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25929517710249145		[learning rate: 0.0076172]
	Learning Rate: 0.00761719
	LOSS [training: 0.25929517710249145 | validation: 0.21834298179101036]
	TIME [epoch: 24.7 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27662022636448225		[learning rate: 0.0075903]
	Learning Rate: 0.00759025
	LOSS [training: 0.27662022636448225 | validation: 0.2305557813320382]
	TIME [epoch: 24.6 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2698011284550112		[learning rate: 0.0075634]
	Learning Rate: 0.00756341
	LOSS [training: 0.2698011284550112 | validation: 0.2301989053237122]
	TIME [epoch: 24.6 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28095989114892866		[learning rate: 0.0075367]
	Learning Rate: 0.00753667
	LOSS [training: 0.28095989114892866 | validation: 0.2407056525198486]
	TIME [epoch: 24.6 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2917260642146974		[learning rate: 0.00751]
	Learning Rate: 0.00751002
	LOSS [training: 0.2917260642146974 | validation: 0.23236065850950674]
	TIME [epoch: 24.6 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2635313670954022		[learning rate: 0.0074835]
	Learning Rate: 0.00748346
	LOSS [training: 0.2635313670954022 | validation: 0.2562803916478228]
	TIME [epoch: 24.6 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27269138998781606		[learning rate: 0.007457]
	Learning Rate: 0.007457
	LOSS [training: 0.27269138998781606 | validation: 0.23055003877183394]
	TIME [epoch: 24.6 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26875490186706447		[learning rate: 0.0074306]
	Learning Rate: 0.00743063
	LOSS [training: 0.26875490186706447 | validation: 0.21912114442300404]
	TIME [epoch: 24.6 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2616572313094126		[learning rate: 0.0074044]
	Learning Rate: 0.00740435
	LOSS [training: 0.2616572313094126 | validation: 0.2299744121213923]
	TIME [epoch: 24.6 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2714073223691206		[learning rate: 0.0073782]
	Learning Rate: 0.00737817
	LOSS [training: 0.2714073223691206 | validation: 0.27790243255854763]
	TIME [epoch: 24.6 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2779598041216726		[learning rate: 0.0073521]
	Learning Rate: 0.00735208
	LOSS [training: 0.2779598041216726 | validation: 0.21754535838300804]
	TIME [epoch: 24.6 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2805594253746556		[learning rate: 0.0073261]
	Learning Rate: 0.00732608
	LOSS [training: 0.2805594253746556 | validation: 0.23418327190099678]
	TIME [epoch: 24.6 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2741288896846027		[learning rate: 0.0073002]
	Learning Rate: 0.00730018
	LOSS [training: 0.2741288896846027 | validation: 0.22917489869678037]
	TIME [epoch: 24.6 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2778711253749575		[learning rate: 0.0072744]
	Learning Rate: 0.00727436
	LOSS [training: 0.2778711253749575 | validation: 0.23685770139967732]
	TIME [epoch: 24.6 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.277283163113274		[learning rate: 0.0072486]
	Learning Rate: 0.00724864
	LOSS [training: 0.277283163113274 | validation: 0.22824258999326216]
	TIME [epoch: 24.6 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2744015593196615		[learning rate: 0.007223]
	Learning Rate: 0.007223
	LOSS [training: 0.2744015593196615 | validation: 0.22416508024037865]
	TIME [epoch: 24.6 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2696144735729539		[learning rate: 0.0071975]
	Learning Rate: 0.00719746
	LOSS [training: 0.2696144735729539 | validation: 0.2367992191381242]
	TIME [epoch: 24.6 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2691814299795778		[learning rate: 0.007172]
	Learning Rate: 0.00717201
	LOSS [training: 0.2691814299795778 | validation: 0.22012275393876157]
	TIME [epoch: 24.6 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2747721669305936		[learning rate: 0.0071467]
	Learning Rate: 0.00714665
	LOSS [training: 0.2747721669305936 | validation: 0.22406509898707264]
	TIME [epoch: 24.6 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2587904278379554		[learning rate: 0.0071214]
	Learning Rate: 0.00712138
	LOSS [training: 0.2587904278379554 | validation: 0.24216530224147195]
	TIME [epoch: 24.6 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28949250223559614		[learning rate: 0.0070962]
	Learning Rate: 0.0070962
	LOSS [training: 0.28949250223559614 | validation: 0.210762359312228]
	TIME [epoch: 24.6 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14b_20240716_161522/states/model_facs_v3_dec1b_2dpca_v14b_147.pth
	Model improved!!!
EPOCH 148/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2694271605376727		[learning rate: 0.0070711]
	Learning Rate: 0.0070711
	LOSS [training: 0.2694271605376727 | validation: 0.2226017265817612]
	TIME [epoch: 24.6 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25679153437108637		[learning rate: 0.0070461]
	Learning Rate: 0.0070461
	LOSS [training: 0.25679153437108637 | validation: 0.21588929005804114]
	TIME [epoch: 24.6 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2648322936468048		[learning rate: 0.0070212]
	Learning Rate: 0.00702118
	LOSS [training: 0.2648322936468048 | validation: 0.22784662427001315]
	TIME [epoch: 24.6 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28610793221908487		[learning rate: 0.0069964]
	Learning Rate: 0.00699635
	LOSS [training: 0.28610793221908487 | validation: 0.22927891698860364]
	TIME [epoch: 24.6 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28100433786932116		[learning rate: 0.0069716]
	Learning Rate: 0.00697161
	LOSS [training: 0.28100433786932116 | validation: 0.2247812834060444]
	TIME [epoch: 24.6 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.263664293008676		[learning rate: 0.006947]
	Learning Rate: 0.00694696
	LOSS [training: 0.263664293008676 | validation: 0.22099862812839705]
	TIME [epoch: 24.6 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26304349764022655		[learning rate: 0.0069224]
	Learning Rate: 0.00692239
	LOSS [training: 0.26304349764022655 | validation: 0.23956008484792415]
	TIME [epoch: 24.6 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27062414820563396		[learning rate: 0.0068979]
	Learning Rate: 0.00689792
	LOSS [training: 0.27062414820563396 | validation: 0.223969099802712]
	TIME [epoch: 24.6 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2662587930220501		[learning rate: 0.0068735]
	Learning Rate: 0.00687352
	LOSS [training: 0.2662587930220501 | validation: 0.21288285348352765]
	TIME [epoch: 24.6 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2593870111454191		[learning rate: 0.0068492]
	Learning Rate: 0.00684922
	LOSS [training: 0.2593870111454191 | validation: 0.22763774883308946]
	TIME [epoch: 24.6 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27997274633087404		[learning rate: 0.006825]
	Learning Rate: 0.006825
	LOSS [training: 0.27997274633087404 | validation: 0.22031048193229594]
	TIME [epoch: 24.6 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26843280639818917		[learning rate: 0.0068009]
	Learning Rate: 0.00680086
	LOSS [training: 0.26843280639818917 | validation: 0.22375195795190272]
	TIME [epoch: 24.6 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25824280670234406		[learning rate: 0.0067768]
	Learning Rate: 0.00677681
	LOSS [training: 0.25824280670234406 | validation: 0.22052826104160142]
	TIME [epoch: 24.6 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2683685470659177		[learning rate: 0.0067529]
	Learning Rate: 0.00675285
	LOSS [training: 0.2683685470659177 | validation: 0.22799479944091802]
	TIME [epoch: 24.6 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2721371350288719		[learning rate: 0.006729]
	Learning Rate: 0.00672897
	LOSS [training: 0.2721371350288719 | validation: 0.22684174002983865]
	TIME [epoch: 24.6 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26295882989488434		[learning rate: 0.0067052]
	Learning Rate: 0.00670518
	LOSS [training: 0.26295882989488434 | validation: 0.21715885869424753]
	TIME [epoch: 24.6 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2691021194366137		[learning rate: 0.0066815]
	Learning Rate: 0.00668147
	LOSS [training: 0.2691021194366137 | validation: 0.21694597849285208]
	TIME [epoch: 24.6 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26566105630486936		[learning rate: 0.0066578]
	Learning Rate: 0.00665784
	LOSS [training: 0.26566105630486936 | validation: 0.22135275155631548]
	TIME [epoch: 24.6 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2660070420262252		[learning rate: 0.0066343]
	Learning Rate: 0.0066343
	LOSS [training: 0.2660070420262252 | validation: 0.2098740282839553]
	TIME [epoch: 24.6 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14b_20240716_161522/states/model_facs_v3_dec1b_2dpca_v14b_166.pth
	Model improved!!!
EPOCH 167/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26070423425869466		[learning rate: 0.0066108]
	Learning Rate: 0.00661084
	LOSS [training: 0.26070423425869466 | validation: 0.20917021375297354]
	TIME [epoch: 24.6 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14b_20240716_161522/states/model_facs_v3_dec1b_2dpca_v14b_167.pth
	Model improved!!!
EPOCH 168/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2546597615606397		[learning rate: 0.0065875]
	Learning Rate: 0.00658746
	LOSS [training: 0.2546597615606397 | validation: 0.22024667772078388]
	TIME [epoch: 24.6 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27038682538550246		[learning rate: 0.0065642]
	Learning Rate: 0.00656416
	LOSS [training: 0.27038682538550246 | validation: 0.21868228603367657]
	TIME [epoch: 24.6 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27771815107053804		[learning rate: 0.006541]
	Learning Rate: 0.00654095
	LOSS [training: 0.27771815107053804 | validation: 0.2075057052171312]
	TIME [epoch: 24.6 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14b_20240716_161522/states/model_facs_v3_dec1b_2dpca_v14b_170.pth
	Model improved!!!
EPOCH 171/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25557912351612544		[learning rate: 0.0065178]
	Learning Rate: 0.00651782
	LOSS [training: 0.25557912351612544 | validation: 0.21316819370311454]
	TIME [epoch: 24.5 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2667162233251137		[learning rate: 0.0064948]
	Learning Rate: 0.00649477
	LOSS [training: 0.2667162233251137 | validation: 0.2135049114312479]
	TIME [epoch: 24.6 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26687718757049966		[learning rate: 0.0064718]
	Learning Rate: 0.00647181
	LOSS [training: 0.26687718757049966 | validation: 0.22997653421169106]
	TIME [epoch: 24.5 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2698347510541634		[learning rate: 0.0064489]
	Learning Rate: 0.00644892
	LOSS [training: 0.2698347510541634 | validation: 0.2067917009133219]
	TIME [epoch: 24.5 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14b_20240716_161522/states/model_facs_v3_dec1b_2dpca_v14b_174.pth
	Model improved!!!
EPOCH 175/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.262855845300275		[learning rate: 0.0064261]
	Learning Rate: 0.00642612
	LOSS [training: 0.262855845300275 | validation: 0.21750458031025738]
	TIME [epoch: 24.5 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2607388478324571		[learning rate: 0.0064034]
	Learning Rate: 0.00640339
	LOSS [training: 0.2607388478324571 | validation: 0.2277674776511005]
	TIME [epoch: 24.6 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2738359218461782		[learning rate: 0.0063808]
	Learning Rate: 0.00638075
	LOSS [training: 0.2738359218461782 | validation: 0.21337580538079667]
	TIME [epoch: 24.5 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2556945895915956		[learning rate: 0.0063582]
	Learning Rate: 0.00635819
	LOSS [training: 0.2556945895915956 | validation: 0.2267388324992988]
	TIME [epoch: 24.6 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2652000970296906		[learning rate: 0.0063357]
	Learning Rate: 0.0063357
	LOSS [training: 0.2652000970296906 | validation: 0.22432127015105036]
	TIME [epoch: 24.5 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2629796542615367		[learning rate: 0.0063133]
	Learning Rate: 0.0063133
	LOSS [training: 0.2629796542615367 | validation: 0.21147153679469563]
	TIME [epoch: 24.5 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2697417088450958		[learning rate: 0.006291]
	Learning Rate: 0.00629097
	LOSS [training: 0.2697417088450958 | validation: 0.2238400538230821]
	TIME [epoch: 24.6 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26815694350457236		[learning rate: 0.0062687]
	Learning Rate: 0.00626873
	LOSS [training: 0.26815694350457236 | validation: 0.22535680598588118]
	TIME [epoch: 24.6 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26681219674915996		[learning rate: 0.0062466]
	Learning Rate: 0.00624656
	LOSS [training: 0.26681219674915996 | validation: 0.21877234213390157]
	TIME [epoch: 24.5 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25817289592730314		[learning rate: 0.0062245]
	Learning Rate: 0.00622447
	LOSS [training: 0.25817289592730314 | validation: 0.22463543057660756]
	TIME [epoch: 24.6 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2795518800504552		[learning rate: 0.0062025]
	Learning Rate: 0.00620246
	LOSS [training: 0.2795518800504552 | validation: 0.2114454345874872]
	TIME [epoch: 24.6 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26434874256440105		[learning rate: 0.0061805]
	Learning Rate: 0.00618053
	LOSS [training: 0.26434874256440105 | validation: 0.2259214108287766]
	TIME [epoch: 24.6 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2624505887767596		[learning rate: 0.0061587]
	Learning Rate: 0.00615867
	LOSS [training: 0.2624505887767596 | validation: 0.21902228902736365]
	TIME [epoch: 24.5 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25746031970798805		[learning rate: 0.0061369]
	Learning Rate: 0.00613689
	LOSS [training: 0.25746031970798805 | validation: 0.2202142766552368]
	TIME [epoch: 24.5 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26657494319008124		[learning rate: 0.0061152]
	Learning Rate: 0.00611519
	LOSS [training: 0.26657494319008124 | validation: 0.21823546254069393]
	TIME [epoch: 24.6 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2593558286707301		[learning rate: 0.0060936]
	Learning Rate: 0.00609357
	LOSS [training: 0.2593558286707301 | validation: 0.22942065211712775]
	TIME [epoch: 24.6 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25824496508672323		[learning rate: 0.006072]
	Learning Rate: 0.00607202
	LOSS [training: 0.25824496508672323 | validation: 0.22303485293843345]
	TIME [epoch: 24.6 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27206333531839494		[learning rate: 0.0060505]
	Learning Rate: 0.00605055
	LOSS [training: 0.27206333531839494 | validation: 0.21219754652911335]
	TIME [epoch: 24.6 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2597575323032927		[learning rate: 0.0060292]
	Learning Rate: 0.00602915
	LOSS [training: 0.2597575323032927 | validation: 0.22122476268520738]
	TIME [epoch: 24.6 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2609636143584067		[learning rate: 0.0060078]
	Learning Rate: 0.00600783
	LOSS [training: 0.2609636143584067 | validation: 0.21734930934140842]
	TIME [epoch: 24.6 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2508997098962935		[learning rate: 0.0059866]
	Learning Rate: 0.00598659
	LOSS [training: 0.2508997098962935 | validation: 0.21060854259883563]
	TIME [epoch: 24.6 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25479295746839115		[learning rate: 0.0059654]
	Learning Rate: 0.00596542
	LOSS [training: 0.25479295746839115 | validation: 0.2121025107218434]
	TIME [epoch: 24.6 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2562886941951035		[learning rate: 0.0059443]
	Learning Rate: 0.00594433
	LOSS [training: 0.2562886941951035 | validation: 0.2265059792914824]
	TIME [epoch: 24.6 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2820765680744732		[learning rate: 0.0059233]
	Learning Rate: 0.0059233
	LOSS [training: 0.2820765680744732 | validation: 0.21766746397622203]
	TIME [epoch: 24.6 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2515781700537532		[learning rate: 0.0059024]
	Learning Rate: 0.00590236
	LOSS [training: 0.2515781700537532 | validation: 0.2164837414304984]
	TIME [epoch: 24.6 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2709921945755016		[learning rate: 0.0058815]
	Learning Rate: 0.00588149
	LOSS [training: 0.2709921945755016 | validation: 0.21125293738380413]
	TIME [epoch: 24.6 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25718888317712657		[learning rate: 0.0058607]
	Learning Rate: 0.00586069
	LOSS [training: 0.25718888317712657 | validation: 0.2173085390150554]
	TIME [epoch: 68.5 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26761871621940525		[learning rate: 0.00584]
	Learning Rate: 0.00583996
	LOSS [training: 0.26761871621940525 | validation: 0.22746591098512683]
	TIME [epoch: 52.9 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.257527540632764		[learning rate: 0.0058193]
	Learning Rate: 0.00581931
	LOSS [training: 0.257527540632764 | validation: 0.2156706879947215]
	TIME [epoch: 52.9 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2682392707235606		[learning rate: 0.0057987]
	Learning Rate: 0.00579874
	LOSS [training: 0.2682392707235606 | validation: 0.20976447325336073]
	TIME [epoch: 52.9 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2502850474770307		[learning rate: 0.0057782]
	Learning Rate: 0.00577823
	LOSS [training: 0.2502850474770307 | validation: 0.2436200244163472]
	TIME [epoch: 52.9 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27465883076378356		[learning rate: 0.0057578]
	Learning Rate: 0.0057578
	LOSS [training: 0.27465883076378356 | validation: 0.23139460818241292]
	TIME [epoch: 52.9 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25590300573986124		[learning rate: 0.0057374]
	Learning Rate: 0.00573744
	LOSS [training: 0.25590300573986124 | validation: 0.21511660971735883]
	TIME [epoch: 52.9 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2568358930223952		[learning rate: 0.0057171]
	Learning Rate: 0.00571715
	LOSS [training: 0.2568358930223952 | validation: 0.22670856650936874]
	TIME [epoch: 52.9 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2647503505586478		[learning rate: 0.0056969]
	Learning Rate: 0.00569693
	LOSS [training: 0.2647503505586478 | validation: 0.22057346455369328]
	TIME [epoch: 52.9 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2606502005632205		[learning rate: 0.0056768]
	Learning Rate: 0.00567679
	LOSS [training: 0.2606502005632205 | validation: 0.21318086463443153]
	TIME [epoch: 52.9 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2573584664699039		[learning rate: 0.0056567]
	Learning Rate: 0.00565671
	LOSS [training: 0.2573584664699039 | validation: 0.210366973616488]
	TIME [epoch: 52.9 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2631067165269781		[learning rate: 0.0056367]
	Learning Rate: 0.00563671
	LOSS [training: 0.2631067165269781 | validation: 0.21688874059408708]
	TIME [epoch: 52.9 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25206275692080954		[learning rate: 0.0056168]
	Learning Rate: 0.00561678
	LOSS [training: 0.25206275692080954 | validation: 0.21832816500199423]
	TIME [epoch: 52.9 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2590332843579874		[learning rate: 0.0055969]
	Learning Rate: 0.00559691
	LOSS [training: 0.2590332843579874 | validation: 0.212219711808238]
	TIME [epoch: 52.9 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27110616405752697		[learning rate: 0.0055771]
	Learning Rate: 0.00557712
	LOSS [training: 0.27110616405752697 | validation: 0.2361927153507483]
	TIME [epoch: 52.9 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2595685566459826		[learning rate: 0.0055574]
	Learning Rate: 0.0055574
	LOSS [training: 0.2595685566459826 | validation: 0.21035857330647603]
	TIME [epoch: 52.9 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25558633744435616		[learning rate: 0.0055378]
	Learning Rate: 0.00553775
	LOSS [training: 0.25558633744435616 | validation: 0.21224860419207206]
	TIME [epoch: 52.9 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25346003052642735		[learning rate: 0.0055182]
	Learning Rate: 0.00551817
	LOSS [training: 0.25346003052642735 | validation: 0.2207080868555676]
	TIME [epoch: 52.9 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26097352583302563		[learning rate: 0.0054987]
	Learning Rate: 0.00549865
	LOSS [training: 0.26097352583302563 | validation: 0.23039690465606774]
	TIME [epoch: 52.9 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.250528138690489		[learning rate: 0.0054792]
	Learning Rate: 0.00547921
	LOSS [training: 0.250528138690489 | validation: 0.20755926527807875]
	TIME [epoch: 52.9 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27637649872775844		[learning rate: 0.0054598]
	Learning Rate: 0.00545983
	LOSS [training: 0.27637649872775844 | validation: 0.22151015997002435]
	TIME [epoch: 52.9 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2586482293088754		[learning rate: 0.0054405]
	Learning Rate: 0.00544053
	LOSS [training: 0.2586482293088754 | validation: 0.21699219990091176]
	TIME [epoch: 52.9 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2607648323769574		[learning rate: 0.0054213]
	Learning Rate: 0.00542129
	LOSS [training: 0.2607648323769574 | validation: 0.2145636422782788]
	TIME [epoch: 52.9 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26144986101602874		[learning rate: 0.0054021]
	Learning Rate: 0.00540212
	LOSS [training: 0.26144986101602874 | validation: 0.21819255283553743]
	TIME [epoch: 52.9 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2616816083778602		[learning rate: 0.005383]
	Learning Rate: 0.00538302
	LOSS [training: 0.2616816083778602 | validation: 0.22291593204017976]
	TIME [epoch: 52.9 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2544910128289531		[learning rate: 0.005364]
	Learning Rate: 0.00536398
	LOSS [training: 0.2544910128289531 | validation: 0.21402589578256856]
	TIME [epoch: 52.9 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.265724822187173		[learning rate: 0.005345]
	Learning Rate: 0.00534501
	LOSS [training: 0.265724822187173 | validation: 0.21642151680437297]
	TIME [epoch: 52.9 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25888313448151784		[learning rate: 0.0053261]
	Learning Rate: 0.00532611
	LOSS [training: 0.25888313448151784 | validation: 0.2229313946200162]
	TIME [epoch: 52.9 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2590389050839791		[learning rate: 0.0053073]
	Learning Rate: 0.00530728
	LOSS [training: 0.2590389050839791 | validation: 0.21507802120162317]
	TIME [epoch: 52.8 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2485818930450757		[learning rate: 0.0052885]
	Learning Rate: 0.00528851
	LOSS [training: 0.2485818930450757 | validation: 0.22531285042791965]
	TIME [epoch: 52.9 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2623546979660914		[learning rate: 0.0052698]
	Learning Rate: 0.00526981
	LOSS [training: 0.2623546979660914 | validation: 0.21745482989126388]
	TIME [epoch: 52.9 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2582436807215478		[learning rate: 0.0052512]
	Learning Rate: 0.00525117
	LOSS [training: 0.2582436807215478 | validation: 0.22591715486000283]
	TIME [epoch: 52.9 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25568497696692494		[learning rate: 0.0052326]
	Learning Rate: 0.0052326
	LOSS [training: 0.25568497696692494 | validation: 0.22573030744749997]
	TIME [epoch: 52.8 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25504766484555763		[learning rate: 0.0052141]
	Learning Rate: 0.0052141
	LOSS [training: 0.25504766484555763 | validation: 0.21198708561160878]
	TIME [epoch: 52.8 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25731120005192387		[learning rate: 0.0051957]
	Learning Rate: 0.00519566
	LOSS [training: 0.25731120005192387 | validation: 0.21202725018243712]
	TIME [epoch: 52.9 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.252118768487835		[learning rate: 0.0051773]
	Learning Rate: 0.00517729
	LOSS [training: 0.252118768487835 | validation: 0.21106893634086302]
	TIME [epoch: 52.8 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2651129520452506		[learning rate: 0.005159]
	Learning Rate: 0.00515898
	LOSS [training: 0.2651129520452506 | validation: 0.22042948551711197]
	TIME [epoch: 52.8 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2559866433386359		[learning rate: 0.0051407]
	Learning Rate: 0.00514074
	LOSS [training: 0.2559866433386359 | validation: 0.20215691154287577]
	TIME [epoch: 52.9 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14b_20240716_161522/states/model_facs_v3_dec1b_2dpca_v14b_238.pth
	Model improved!!!
EPOCH 239/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25172159649273834		[learning rate: 0.0051226]
	Learning Rate: 0.00512256
	LOSS [training: 0.25172159649273834 | validation: 0.21879035232153718]
	TIME [epoch: 52.8 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.270887679923759		[learning rate: 0.0051044]
	Learning Rate: 0.00510445
	LOSS [training: 0.270887679923759 | validation: 0.22691555480739653]
	TIME [epoch: 52.8 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25856043208001095		[learning rate: 0.0050864]
	Learning Rate: 0.0050864
	LOSS [training: 0.25856043208001095 | validation: 0.21792773230590973]
	TIME [epoch: 52.8 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2580389515254235		[learning rate: 0.0050684]
	Learning Rate: 0.00506841
	LOSS [training: 0.2580389515254235 | validation: 0.21523191739750094]
	TIME [epoch: 52.8 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24745922095760484		[learning rate: 0.0050505]
	Learning Rate: 0.00505049
	LOSS [training: 0.24745922095760484 | validation: 0.21000292587520838]
	TIME [epoch: 52.8 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24925063802643252		[learning rate: 0.0050326]
	Learning Rate: 0.00503263
	LOSS [training: 0.24925063802643252 | validation: 0.21902125703413805]
	TIME [epoch: 52.8 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2475200345973969		[learning rate: 0.0050148]
	Learning Rate: 0.00501483
	LOSS [training: 0.2475200345973969 | validation: 0.20898674862449443]
	TIME [epoch: 52.9 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2581747781679931		[learning rate: 0.0049971]
	Learning Rate: 0.0049971
	LOSS [training: 0.2581747781679931 | validation: 0.22727888511627742]
	TIME [epoch: 52.8 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2625268750036625		[learning rate: 0.0049794]
	Learning Rate: 0.00497943
	LOSS [training: 0.2625268750036625 | validation: 0.20666975105895732]
	TIME [epoch: 52.8 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2510642908372664		[learning rate: 0.0049618]
	Learning Rate: 0.00496182
	LOSS [training: 0.2510642908372664 | validation: 0.21274880830724255]
	TIME [epoch: 52.8 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26339879221056794		[learning rate: 0.0049443]
	Learning Rate: 0.00494427
	LOSS [training: 0.26339879221056794 | validation: 0.21333041415257042]
	TIME [epoch: 52.8 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26329720535777784		[learning rate: 0.0049268]
	Learning Rate: 0.00492679
	LOSS [training: 0.26329720535777784 | validation: 0.20938268178462055]
	TIME [epoch: 52.8 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24682227140507895		[learning rate: 0.0049094]
	Learning Rate: 0.00490937
	LOSS [training: 0.24682227140507895 | validation: 0.21161801719199175]
	TIME [epoch: 52.8 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24947322837311423		[learning rate: 0.004892]
	Learning Rate: 0.00489201
	LOSS [training: 0.24947322837311423 | validation: 0.21515283607671484]
	TIME [epoch: 52.9 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2515263347516568		[learning rate: 0.0048747]
	Learning Rate: 0.00487471
	LOSS [training: 0.2515263347516568 | validation: 0.21793320424475335]
	TIME [epoch: 52.8 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2503801584418352		[learning rate: 0.0048575]
	Learning Rate: 0.00485747
	LOSS [training: 0.2503801584418352 | validation: 0.21129819021903554]
	TIME [epoch: 52.8 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25753018081115014		[learning rate: 0.0048403]
	Learning Rate: 0.00484029
	LOSS [training: 0.25753018081115014 | validation: 0.215563690617341]
	TIME [epoch: 52.8 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2512876557370351		[learning rate: 0.0048232]
	Learning Rate: 0.00482318
	LOSS [training: 0.2512876557370351 | validation: 0.20518945384531]
	TIME [epoch: 52.8 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24485846641245643		[learning rate: 0.0048061]
	Learning Rate: 0.00480612
	LOSS [training: 0.24485846641245643 | validation: 0.2059135422743658]
	TIME [epoch: 52.8 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25051219471483716		[learning rate: 0.0047891]
	Learning Rate: 0.00478913
	LOSS [training: 0.25051219471483716 | validation: 0.2045318088015941]
	TIME [epoch: 52.8 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24841316837685745		[learning rate: 0.0047722]
	Learning Rate: 0.00477219
	LOSS [training: 0.24841316837685745 | validation: 0.21828014152373904]
	TIME [epoch: 52.8 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2626269383864426		[learning rate: 0.0047553]
	Learning Rate: 0.00475532
	LOSS [training: 0.2626269383864426 | validation: 0.21669508996944536]
	TIME [epoch: 52.8 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2609990145387639		[learning rate: 0.0047385]
	Learning Rate: 0.0047385
	LOSS [training: 0.2609990145387639 | validation: 0.21442642400665074]
	TIME [epoch: 52.8 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24751101924362748		[learning rate: 0.0047217]
	Learning Rate: 0.00472175
	LOSS [training: 0.24751101924362748 | validation: 0.21549733190515527]
	TIME [epoch: 52.8 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25897867343567815		[learning rate: 0.004705]
	Learning Rate: 0.00470505
	LOSS [training: 0.25897867343567815 | validation: 0.2166242320835028]
	TIME [epoch: 52.8 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24952189006423664		[learning rate: 0.0046884]
	Learning Rate: 0.00468841
	LOSS [training: 0.24952189006423664 | validation: 0.2025758160877027]
	TIME [epoch: 52.8 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2522446122779473		[learning rate: 0.0046718]
	Learning Rate: 0.00467183
	LOSS [training: 0.2522446122779473 | validation: 0.2127236103922443]
	TIME [epoch: 52.8 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25779563567738234		[learning rate: 0.0046553]
	Learning Rate: 0.00465531
	LOSS [training: 0.25779563567738234 | validation: 0.22605401405540237]
	TIME [epoch: 52.8 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2626363641964123		[learning rate: 0.0046388]
	Learning Rate: 0.00463885
	LOSS [training: 0.2626363641964123 | validation: 0.21759646869284524]
	TIME [epoch: 52.8 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25177613074996724		[learning rate: 0.0046224]
	Learning Rate: 0.00462245
	LOSS [training: 0.25177613074996724 | validation: 0.21808501719396886]
	TIME [epoch: 52.8 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.280408038617964		[learning rate: 0.0046061]
	Learning Rate: 0.0046061
	LOSS [training: 0.280408038617964 | validation: 0.21075455989182781]
	TIME [epoch: 52.8 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2647810340848506		[learning rate: 0.0045898]
	Learning Rate: 0.00458981
	LOSS [training: 0.2647810340848506 | validation: 0.20654271406378663]
	TIME [epoch: 52.8 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25018137277326913		[learning rate: 0.0045736]
	Learning Rate: 0.00457358
	LOSS [training: 0.25018137277326913 | validation: 0.21534598385272616]
	TIME [epoch: 52.8 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2564886261018164		[learning rate: 0.0045574]
	Learning Rate: 0.00455741
	LOSS [training: 0.2564886261018164 | validation: 0.2237214702128591]
	TIME [epoch: 52.8 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25277752656832114		[learning rate: 0.0045413]
	Learning Rate: 0.00454129
	LOSS [training: 0.25277752656832114 | validation: 0.21417039539924282]
	TIME [epoch: 52.8 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2565438138321494		[learning rate: 0.0045252]
	Learning Rate: 0.00452523
	LOSS [training: 0.2565438138321494 | validation: 0.20911598983155985]
	TIME [epoch: 52.8 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24958987606902835		[learning rate: 0.0045092]
	Learning Rate: 0.00450923
	LOSS [training: 0.24958987606902835 | validation: 0.21031367949835786]
	TIME [epoch: 52.8 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25983569865083017		[learning rate: 0.0044933]
	Learning Rate: 0.00449329
	LOSS [training: 0.25983569865083017 | validation: 0.2176596711138882]
	TIME [epoch: 52.8 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2613326139199506		[learning rate: 0.0044774]
	Learning Rate: 0.0044774
	LOSS [training: 0.2613326139199506 | validation: 0.2106961833135868]
	TIME [epoch: 52.8 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.257453787393433		[learning rate: 0.0044616]
	Learning Rate: 0.00446156
	LOSS [training: 0.257453787393433 | validation: 0.21536844517953888]
	TIME [epoch: 52.8 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25708341334124357		[learning rate: 0.0044458]
	Learning Rate: 0.00444579
	LOSS [training: 0.25708341334124357 | validation: 0.22380707709211708]
	TIME [epoch: 52.8 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2557248503454124		[learning rate: 0.0044301]
	Learning Rate: 0.00443007
	LOSS [training: 0.2557248503454124 | validation: 0.22283279218174493]
	TIME [epoch: 52.9 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2621126361367361		[learning rate: 0.0044144]
	Learning Rate: 0.0044144
	LOSS [training: 0.2621126361367361 | validation: 0.21675498346850858]
	TIME [epoch: 52.8 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2532897924658259		[learning rate: 0.0043988]
	Learning Rate: 0.00439879
	LOSS [training: 0.2532897924658259 | validation: 0.20200389839464106]
	TIME [epoch: 52.8 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14b_20240716_161522/states/model_facs_v3_dec1b_2dpca_v14b_282.pth
	Model improved!!!
EPOCH 283/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2555998662248052		[learning rate: 0.0043832]
	Learning Rate: 0.00438324
	LOSS [training: 0.2555998662248052 | validation: 0.2171357679577469]
	TIME [epoch: 52.8 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25224221113008194		[learning rate: 0.0043677]
	Learning Rate: 0.00436774
	LOSS [training: 0.25224221113008194 | validation: 0.21198556211755362]
	TIME [epoch: 52.8 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2583806389386645		[learning rate: 0.0043523]
	Learning Rate: 0.00435229
	LOSS [training: 0.2583806389386645 | validation: 0.21631352592904846]
	TIME [epoch: 52.9 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2527820103571119		[learning rate: 0.0043369]
	Learning Rate: 0.0043369
	LOSS [training: 0.2527820103571119 | validation: 0.21317466808493304]
	TIME [epoch: 52.9 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2585868787042767		[learning rate: 0.0043216]
	Learning Rate: 0.00432156
	LOSS [training: 0.2585868787042767 | validation: 0.2165765960427853]
	TIME [epoch: 52.8 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2504052929455505		[learning rate: 0.0043063]
	Learning Rate: 0.00430628
	LOSS [training: 0.2504052929455505 | validation: 0.22679127887663428]
	TIME [epoch: 52.9 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25589254451196747		[learning rate: 0.0042911]
	Learning Rate: 0.00429106
	LOSS [training: 0.25589254451196747 | validation: 0.22024364802603086]
	TIME [epoch: 52.8 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25557117545153524		[learning rate: 0.0042759]
	Learning Rate: 0.00427588
	LOSS [training: 0.25557117545153524 | validation: 0.21991292628897074]
	TIME [epoch: 52.8 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2538491547411158		[learning rate: 0.0042608]
	Learning Rate: 0.00426076
	LOSS [training: 0.2538491547411158 | validation: 0.22253338612606535]
	TIME [epoch: 52.8 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25258794969270126		[learning rate: 0.0042457]
	Learning Rate: 0.00424569
	LOSS [training: 0.25258794969270126 | validation: 0.2216069449316261]
	TIME [epoch: 52.8 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26312758726625246		[learning rate: 0.0042307]
	Learning Rate: 0.00423068
	LOSS [training: 0.26312758726625246 | validation: 0.21567600829379713]
	TIME [epoch: 52.8 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25158232556794047		[learning rate: 0.0042157]
	Learning Rate: 0.00421572
	LOSS [training: 0.25158232556794047 | validation: 0.21899829507871282]
	TIME [epoch: 52.8 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2510758227374665		[learning rate: 0.0042008]
	Learning Rate: 0.00420081
	LOSS [training: 0.2510758227374665 | validation: 0.22551596795227136]
	TIME [epoch: 52.8 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24222291498946014		[learning rate: 0.004186]
	Learning Rate: 0.00418596
	LOSS [training: 0.24222291498946014 | validation: 0.22660785664391928]
	TIME [epoch: 52.8 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25505175340373004		[learning rate: 0.0041712]
	Learning Rate: 0.00417116
	LOSS [training: 0.25505175340373004 | validation: 0.2155328158852448]
	TIME [epoch: 52.8 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24503058295062252		[learning rate: 0.0041564]
	Learning Rate: 0.00415641
	LOSS [training: 0.24503058295062252 | validation: 0.21724914025843772]
	TIME [epoch: 52.8 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2681489244953022		[learning rate: 0.0041417]
	Learning Rate: 0.00414171
	LOSS [training: 0.2681489244953022 | validation: 0.23276563199923855]
	TIME [epoch: 52.8 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26378583943142736		[learning rate: 0.0041271]
	Learning Rate: 0.00412706
	LOSS [training: 0.26378583943142736 | validation: 0.216794803925987]
	TIME [epoch: 52.8 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2523949058323331		[learning rate: 0.0041125]
	Learning Rate: 0.00411247
	LOSS [training: 0.2523949058323331 | validation: 0.2118125405969547]
	TIME [epoch: 125 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25578503438443084		[learning rate: 0.0040979]
	Learning Rate: 0.00409793
	LOSS [training: 0.25578503438443084 | validation: 0.21191337093515905]
	TIME [epoch: 109 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2582810765943256		[learning rate: 0.0040834]
	Learning Rate: 0.00408344
	LOSS [training: 0.2582810765943256 | validation: 0.2107952412895334]
	TIME [epoch: 109 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25147245005166813		[learning rate: 0.004069]
	Learning Rate: 0.004069
	LOSS [training: 0.25147245005166813 | validation: 0.22423253668659043]
	TIME [epoch: 110 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26036509988071194		[learning rate: 0.0040546]
	Learning Rate: 0.00405461
	LOSS [training: 0.26036509988071194 | validation: 0.21550225077866064]
	TIME [epoch: 110 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25773638987822856		[learning rate: 0.0040403]
	Learning Rate: 0.00404027
	LOSS [training: 0.25773638987822856 | validation: 0.2049882734485499]
	TIME [epoch: 110 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24349801736666313		[learning rate: 0.004026]
	Learning Rate: 0.00402598
	LOSS [training: 0.24349801736666313 | validation: 0.2144535120782421]
	TIME [epoch: 109 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24970970180262134		[learning rate: 0.0040117]
	Learning Rate: 0.00401175
	LOSS [training: 0.24970970180262134 | validation: 0.21602603332542994]
	TIME [epoch: 109 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2518067536977236		[learning rate: 0.0039976]
	Learning Rate: 0.00399756
	LOSS [training: 0.2518067536977236 | validation: 0.22259406760093298]
	TIME [epoch: 110 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2611080424175316		[learning rate: 0.0039834]
	Learning Rate: 0.00398342
	LOSS [training: 0.2611080424175316 | validation: 0.21537747323684409]
	TIME [epoch: 109 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24524998996459504		[learning rate: 0.0039693]
	Learning Rate: 0.00396934
	LOSS [training: 0.24524998996459504 | validation: 0.22543467498177794]
	TIME [epoch: 110 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2527982380271763		[learning rate: 0.0039553]
	Learning Rate: 0.0039553
	LOSS [training: 0.2527982380271763 | validation: 0.21863125747221357]
	TIME [epoch: 110 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25096788798930264		[learning rate: 0.0039413]
	Learning Rate: 0.00394131
	LOSS [training: 0.25096788798930264 | validation: 0.21395896137105525]
	TIME [epoch: 109 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2529087209697834		[learning rate: 0.0039274]
	Learning Rate: 0.00392738
	LOSS [training: 0.2529087209697834 | validation: 0.20897366445703716]
	TIME [epoch: 109 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2528864076402519		[learning rate: 0.0039135]
	Learning Rate: 0.00391349
	LOSS [training: 0.2528864076402519 | validation: 0.22019851583894842]
	TIME [epoch: 109 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24749667311535703		[learning rate: 0.0038997]
	Learning Rate: 0.00389965
	LOSS [training: 0.24749667311535703 | validation: 0.22062918583891666]
	TIME [epoch: 109 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24846458651551404		[learning rate: 0.0038859]
	Learning Rate: 0.00388586
	LOSS [training: 0.24846458651551404 | validation: 0.21241533217926922]
	TIME [epoch: 109 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24892890560322087		[learning rate: 0.0038721]
	Learning Rate: 0.00387212
	LOSS [training: 0.24892890560322087 | validation: 0.21013053513019214]
	TIME [epoch: 109 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26109242253038506		[learning rate: 0.0038584]
	Learning Rate: 0.00385843
	LOSS [training: 0.26109242253038506 | validation: 0.21833441364435685]
	TIME [epoch: 109 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26516449548058324		[learning rate: 0.0038448]
	Learning Rate: 0.00384478
	LOSS [training: 0.26516449548058324 | validation: 0.2141763019622604]
	TIME [epoch: 110 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24576271968717514		[learning rate: 0.0038312]
	Learning Rate: 0.00383119
	LOSS [training: 0.24576271968717514 | validation: 0.2189996136396024]
	TIME [epoch: 109 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25579007083986754		[learning rate: 0.0038176]
	Learning Rate: 0.00381764
	LOSS [training: 0.25579007083986754 | validation: 0.21036944987680367]
	TIME [epoch: 109 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2541163659061667		[learning rate: 0.0038041]
	Learning Rate: 0.00380414
	LOSS [training: 0.2541163659061667 | validation: 0.21511716815105383]
	TIME [epoch: 109 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2588525774959772		[learning rate: 0.0037907]
	Learning Rate: 0.00379069
	LOSS [training: 0.2588525774959772 | validation: 0.21373052648676788]
	TIME [epoch: 109 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25740293588361046		[learning rate: 0.0037773]
	Learning Rate: 0.00377728
	LOSS [training: 0.25740293588361046 | validation: 0.22224124987986632]
	TIME [epoch: 109 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2511110110612474		[learning rate: 0.0037639]
	Learning Rate: 0.00376393
	LOSS [training: 0.2511110110612474 | validation: 0.2099104701689581]
	TIME [epoch: 109 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2648771937473244		[learning rate: 0.0037506]
	Learning Rate: 0.00375062
	LOSS [training: 0.2648771937473244 | validation: 0.21581719065615204]
	TIME [epoch: 109 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2651458345029809		[learning rate: 0.0037374]
	Learning Rate: 0.00373735
	LOSS [training: 0.2651458345029809 | validation: 0.21232027741200404]
	TIME [epoch: 109 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.251213249557861		[learning rate: 0.0037241]
	Learning Rate: 0.00372414
	LOSS [training: 0.251213249557861 | validation: 0.20540924864598414]
	TIME [epoch: 109 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24770583084595368		[learning rate: 0.003711]
	Learning Rate: 0.00371097
	LOSS [training: 0.24770583084595368 | validation: 0.2061466904200253]
	TIME [epoch: 109 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25079474418277		[learning rate: 0.0036978]
	Learning Rate: 0.00369785
	LOSS [training: 0.25079474418277 | validation: 0.21945469512780108]
	TIME [epoch: 109 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24204435683205017		[learning rate: 0.0036848]
	Learning Rate: 0.00368477
	LOSS [training: 0.24204435683205017 | validation: 0.20911578029272193]
	TIME [epoch: 109 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2517467699974198		[learning rate: 0.0036717]
	Learning Rate: 0.00367174
	LOSS [training: 0.2517467699974198 | validation: 0.21175553378631448]
	TIME [epoch: 109 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25739278887453687		[learning rate: 0.0036588]
	Learning Rate: 0.00365875
	LOSS [training: 0.25739278887453687 | validation: 0.2173659770225453]
	TIME [epoch: 109 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26156953010187195		[learning rate: 0.0036458]
	Learning Rate: 0.00364582
	LOSS [training: 0.26156953010187195 | validation: 0.2041901839985541]
	TIME [epoch: 109 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24738645678506646		[learning rate: 0.0036329]
	Learning Rate: 0.00363292
	LOSS [training: 0.24738645678506646 | validation: 0.2085469417609327]
	TIME [epoch: 109 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25933833410904733		[learning rate: 0.0036201]
	Learning Rate: 0.00362008
	LOSS [training: 0.25933833410904733 | validation: 0.2134492476734232]
	TIME [epoch: 109 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25312064548460933		[learning rate: 0.0036073]
	Learning Rate: 0.00360728
	LOSS [training: 0.25312064548460933 | validation: 0.2077762416808684]
	TIME [epoch: 109 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25512220753466097		[learning rate: 0.0035945]
	Learning Rate: 0.00359452
	LOSS [training: 0.25512220753466097 | validation: 0.21257227807257642]
	TIME [epoch: 109 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25224107605618457		[learning rate: 0.0035818]
	Learning Rate: 0.00358181
	LOSS [training: 0.25224107605618457 | validation: 0.21877206740044114]
	TIME [epoch: 109 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24849730246627486		[learning rate: 0.0035691]
	Learning Rate: 0.00356914
	LOSS [training: 0.24849730246627486 | validation: 0.2150386689685905]
	TIME [epoch: 109 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25566007701272014		[learning rate: 0.0035565]
	Learning Rate: 0.00355652
	LOSS [training: 0.25566007701272014 | validation: 0.2096654840810359]
	TIME [epoch: 109 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2498217027213777		[learning rate: 0.0035439]
	Learning Rate: 0.00354395
	LOSS [training: 0.2498217027213777 | validation: 0.2114279631512042]
	TIME [epoch: 109 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24893076823366997		[learning rate: 0.0035314]
	Learning Rate: 0.00353141
	LOSS [training: 0.24893076823366997 | validation: 0.2222902494926716]
	TIME [epoch: 109 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.253140484162036		[learning rate: 0.0035189]
	Learning Rate: 0.00351893
	LOSS [training: 0.253140484162036 | validation: 0.21585730922480958]
	TIME [epoch: 109 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24761430789231423		[learning rate: 0.0035065]
	Learning Rate: 0.00350648
	LOSS [training: 0.24761430789231423 | validation: 0.2063691745454667]
	TIME [epoch: 110 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24876200428754572		[learning rate: 0.0034941]
	Learning Rate: 0.00349408
	LOSS [training: 0.24876200428754572 | validation: 0.2057043603013306]
	TIME [epoch: 110 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24846667857303942		[learning rate: 0.0034817]
	Learning Rate: 0.00348173
	LOSS [training: 0.24846667857303942 | validation: 0.20740142862615785]
	TIME [epoch: 110 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25008442963505945		[learning rate: 0.0034694]
	Learning Rate: 0.00346942
	LOSS [training: 0.25008442963505945 | validation: 0.2142836008396168]
	TIME [epoch: 109 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2443415273544569		[learning rate: 0.0034571]
	Learning Rate: 0.00345715
	LOSS [training: 0.2443415273544569 | validation: 0.21340250787801068]
	TIME [epoch: 109 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24506341791938457		[learning rate: 0.0034449]
	Learning Rate: 0.00344492
	LOSS [training: 0.24506341791938457 | validation: 0.2068356893473376]
	TIME [epoch: 109 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25162826561106216		[learning rate: 0.0034327]
	Learning Rate: 0.00343274
	LOSS [training: 0.25162826561106216 | validation: 0.21569593946797508]
	TIME [epoch: 109 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25018135047666984		[learning rate: 0.0034206]
	Learning Rate: 0.0034206
	LOSS [training: 0.25018135047666984 | validation: 0.2219992241788426]
	TIME [epoch: 109 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2446859435060584		[learning rate: 0.0034085]
	Learning Rate: 0.00340851
	LOSS [training: 0.2446859435060584 | validation: 0.21625790604907333]
	TIME [epoch: 110 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2612395837597569		[learning rate: 0.0033965]
	Learning Rate: 0.00339645
	LOSS [training: 0.2612395837597569 | validation: 0.24051953715364638]
	TIME [epoch: 109 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25056827450979896		[learning rate: 0.0033844]
	Learning Rate: 0.00338444
	LOSS [training: 0.25056827450979896 | validation: 0.21780001946144756]
	TIME [epoch: 110 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25361806888740407		[learning rate: 0.0033725]
	Learning Rate: 0.00337247
	LOSS [training: 0.25361806888740407 | validation: 0.2127715233705699]
	TIME [epoch: 110 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2509382645223701		[learning rate: 0.0033605]
	Learning Rate: 0.00336055
	LOSS [training: 0.2509382645223701 | validation: 0.2119642102093806]
	TIME [epoch: 109 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24342889622550193		[learning rate: 0.0033487]
	Learning Rate: 0.00334867
	LOSS [training: 0.24342889622550193 | validation: 0.21589867308959546]
	TIME [epoch: 109 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24668696947061028		[learning rate: 0.0033368]
	Learning Rate: 0.00333682
	LOSS [training: 0.24668696947061028 | validation: 0.2069634264688446]
	TIME [epoch: 109 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24900974702172132		[learning rate: 0.003325]
	Learning Rate: 0.00332502
	LOSS [training: 0.24900974702172132 | validation: 0.21302537323573678]
	TIME [epoch: 109 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24693398487314688		[learning rate: 0.0033133]
	Learning Rate: 0.00331327
	LOSS [training: 0.24693398487314688 | validation: 0.2253261298700615]
	TIME [epoch: 109 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25734667762391433		[learning rate: 0.0033016]
	Learning Rate: 0.00330155
	LOSS [training: 0.25734667762391433 | validation: 0.2523124234841865]
	TIME [epoch: 109 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2794849575383311		[learning rate: 0.0032899]
	Learning Rate: 0.00328988
	LOSS [training: 0.2794849575383311 | validation: 0.2189377675476479]
	TIME [epoch: 109 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2468194189170694		[learning rate: 0.0032782]
	Learning Rate: 0.00327824
	LOSS [training: 0.2468194189170694 | validation: 0.22242992384588023]
	TIME [epoch: 109 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2446057807535292		[learning rate: 0.0032666]
	Learning Rate: 0.00326665
	LOSS [training: 0.2446057807535292 | validation: 0.2090304660619849]
	TIME [epoch: 109 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24345836839622717		[learning rate: 0.0032551]
	Learning Rate: 0.0032551
	LOSS [training: 0.24345836839622717 | validation: 0.2146584511036726]
	TIME [epoch: 110 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24643166729971167		[learning rate: 0.0032436]
	Learning Rate: 0.00324359
	LOSS [training: 0.24643166729971167 | validation: 0.1974450624859443]
	TIME [epoch: 110 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14b_20240716_161522/states/model_facs_v3_dec1b_2dpca_v14b_368.pth
	Model improved!!!
EPOCH 369/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2462299721552638		[learning rate: 0.0032321]
	Learning Rate: 0.00323212
	LOSS [training: 0.2462299721552638 | validation: 0.20832378070092608]
	TIME [epoch: 109 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25053712866731065		[learning rate: 0.0032207]
	Learning Rate: 0.00322069
	LOSS [training: 0.25053712866731065 | validation: 0.2143608040715717]
	TIME [epoch: 110 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2594177315017802		[learning rate: 0.0032093]
	Learning Rate: 0.0032093
	LOSS [training: 0.2594177315017802 | validation: 0.21191569702814253]
	TIME [epoch: 109 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2574618228539655		[learning rate: 0.003198]
	Learning Rate: 0.00319795
	LOSS [training: 0.2574618228539655 | validation: 0.21864441002487434]
	TIME [epoch: 110 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24894968408750692		[learning rate: 0.0031866]
	Learning Rate: 0.00318664
	LOSS [training: 0.24894968408750692 | validation: 0.21175351784520008]
	TIME [epoch: 110 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24278409482014887		[learning rate: 0.0031754]
	Learning Rate: 0.00317537
	LOSS [training: 0.24278409482014887 | validation: 0.21222238173203087]
	TIME [epoch: 110 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2543264607262203		[learning rate: 0.0031641]
	Learning Rate: 0.00316415
	LOSS [training: 0.2543264607262203 | validation: 0.20817923459549076]
	TIME [epoch: 110 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2507253486676387		[learning rate: 0.003153]
	Learning Rate: 0.00315296
	LOSS [training: 0.2507253486676387 | validation: 0.21017722927242363]
	TIME [epoch: 110 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24943457520350057		[learning rate: 0.0031418]
	Learning Rate: 0.00314181
	LOSS [training: 0.24943457520350057 | validation: 0.21546274119170689]
	TIME [epoch: 110 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2495262130640642		[learning rate: 0.0031307]
	Learning Rate: 0.0031307
	LOSS [training: 0.2495262130640642 | validation: 0.20121840733080898]
	TIME [epoch: 109 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24920549912394183		[learning rate: 0.0031196]
	Learning Rate: 0.00311963
	LOSS [training: 0.24920549912394183 | validation: 0.20809572350540426]
	TIME [epoch: 110 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25369380770554706		[learning rate: 0.0031086]
	Learning Rate: 0.00310859
	LOSS [training: 0.25369380770554706 | validation: 0.21274489936305377]
	TIME [epoch: 110 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2534504986750718		[learning rate: 0.0030976]
	Learning Rate: 0.0030976
	LOSS [training: 0.2534504986750718 | validation: 0.217664861562635]
	TIME [epoch: 110 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25268369341905766		[learning rate: 0.0030866]
	Learning Rate: 0.00308665
	LOSS [training: 0.25268369341905766 | validation: 0.21461157238779544]
	TIME [epoch: 109 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25839547771837856		[learning rate: 0.0030757]
	Learning Rate: 0.00307573
	LOSS [training: 0.25839547771837856 | validation: 0.2132568356632539]
	TIME [epoch: 110 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2601011148350724		[learning rate: 0.0030649]
	Learning Rate: 0.00306486
	LOSS [training: 0.2601011148350724 | validation: 0.2174649286889913]
	TIME [epoch: 110 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.256872177707605		[learning rate: 0.003054]
	Learning Rate: 0.00305402
	LOSS [training: 0.256872177707605 | validation: 0.21123571166591323]
	TIME [epoch: 109 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24221431832657228		[learning rate: 0.0030432]
	Learning Rate: 0.00304322
	LOSS [training: 0.24221431832657228 | validation: 0.21234390571859704]
	TIME [epoch: 110 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25084481245562756		[learning rate: 0.0030325]
	Learning Rate: 0.00303246
	LOSS [training: 0.25084481245562756 | validation: 0.2069603832895325]
	TIME [epoch: 110 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24472779448267393		[learning rate: 0.0030217]
	Learning Rate: 0.00302174
	LOSS [training: 0.24472779448267393 | validation: 0.21850007568430976]
	TIME [epoch: 110 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24888112178567992		[learning rate: 0.003011]
	Learning Rate: 0.00301105
	LOSS [training: 0.24888112178567992 | validation: 0.2159670047662039]
	TIME [epoch: 109 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2514264307090717		[learning rate: 0.0030004]
	Learning Rate: 0.0030004
	LOSS [training: 0.2514264307090717 | validation: 0.21940100218560804]
	TIME [epoch: 110 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24138063491797726		[learning rate: 0.0029898]
	Learning Rate: 0.00298979
	LOSS [training: 0.24138063491797726 | validation: 0.21502409274342046]
	TIME [epoch: 110 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2536537276880914		[learning rate: 0.0029792]
	Learning Rate: 0.00297922
	LOSS [training: 0.2536537276880914 | validation: 0.21203331929658836]
	TIME [epoch: 110 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.248945668008831		[learning rate: 0.0029687]
	Learning Rate: 0.00296869
	LOSS [training: 0.248945668008831 | validation: 0.20179265509898406]
	TIME [epoch: 109 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24385712905309218		[learning rate: 0.0029582]
	Learning Rate: 0.00295819
	LOSS [training: 0.24385712905309218 | validation: 0.21455651980183746]
	TIME [epoch: 109 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24295264173955308		[learning rate: 0.0029477]
	Learning Rate: 0.00294773
	LOSS [training: 0.24295264173955308 | validation: 0.21054077421521353]
	TIME [epoch: 110 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24258062650859955		[learning rate: 0.0029373]
	Learning Rate: 0.0029373
	LOSS [training: 0.24258062650859955 | validation: 0.2106276551203004]
	TIME [epoch: 110 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2596829406143677		[learning rate: 0.0029269]
	Learning Rate: 0.00292692
	LOSS [training: 0.2596829406143677 | validation: 0.20807965708806417]
	TIME [epoch: 109 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24955270624663106		[learning rate: 0.0029166]
	Learning Rate: 0.00291657
	LOSS [training: 0.24955270624663106 | validation: 0.2121126766222002]
	TIME [epoch: 109 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2558616049096229		[learning rate: 0.0029063]
	Learning Rate: 0.00290625
	LOSS [training: 0.2558616049096229 | validation: 0.21595649435454586]
	TIME [epoch: 109 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25490342082776896		[learning rate: 0.002896]
	Learning Rate: 0.00289598
	LOSS [training: 0.25490342082776896 | validation: 0.20881047861351018]
	TIME [epoch: 110 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24999360664320303		[learning rate: 0.0028857]
	Learning Rate: 0.00288573
	LOSS [training: 0.24999360664320303 | validation: 0.21179758668056964]
	TIME [epoch: 109 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24227103313869938		[learning rate: 0.0028755]
	Learning Rate: 0.00287553
	LOSS [training: 0.24227103313869938 | validation: 0.20336412420245864]
	TIME [epoch: 109 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24977597652519634		[learning rate: 0.0028654]
	Learning Rate: 0.00286536
	LOSS [training: 0.24977597652519634 | validation: 0.2108454032373194]
	TIME [epoch: 109 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24959243911876836		[learning rate: 0.0028552]
	Learning Rate: 0.00285523
	LOSS [training: 0.24959243911876836 | validation: 0.20890839430162744]
	TIME [epoch: 109 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24488823049140665		[learning rate: 0.0028451]
	Learning Rate: 0.00284513
	LOSS [training: 0.24488823049140665 | validation: 0.2081047984575913]
	TIME [epoch: 109 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2519282783670948		[learning rate: 0.0028351]
	Learning Rate: 0.00283507
	LOSS [training: 0.2519282783670948 | validation: 0.22184131735090498]
	TIME [epoch: 109 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24681638670495262		[learning rate: 0.002825]
	Learning Rate: 0.00282505
	LOSS [training: 0.24681638670495262 | validation: 0.2044811392374452]
	TIME [epoch: 109 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23966855304556453		[learning rate: 0.0028151]
	Learning Rate: 0.00281506
	LOSS [training: 0.23966855304556453 | validation: 0.20358845497065192]
	TIME [epoch: 109 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2534943190538737		[learning rate: 0.0028051]
	Learning Rate: 0.0028051
	LOSS [training: 0.2534943190538737 | validation: 0.21902998580195057]
	TIME [epoch: 109 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25376308218989047		[learning rate: 0.0027952]
	Learning Rate: 0.00279518
	LOSS [training: 0.25376308218989047 | validation: 0.210194291593516]
	TIME [epoch: 109 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24575295489503743		[learning rate: 0.0027853]
	Learning Rate: 0.0027853
	LOSS [training: 0.24575295489503743 | validation: 0.21208787505260113]
	TIME [epoch: 109 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2511764216153402		[learning rate: 0.0027754]
	Learning Rate: 0.00277545
	LOSS [training: 0.2511764216153402 | validation: 0.2174750396154567]
	TIME [epoch: 109 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25458688111577094		[learning rate: 0.0027656]
	Learning Rate: 0.00276564
	LOSS [training: 0.25458688111577094 | validation: 0.213140025788474]
	TIME [epoch: 109 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2539952405141391		[learning rate: 0.0027559]
	Learning Rate: 0.00275586
	LOSS [training: 0.2539952405141391 | validation: 0.21418289577766894]
	TIME [epoch: 109 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23676250266602208		[learning rate: 0.0027461]
	Learning Rate: 0.00274611
	LOSS [training: 0.23676250266602208 | validation: 0.2119297564250001]
	TIME [epoch: 109 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24968964922555323		[learning rate: 0.0027364]
	Learning Rate: 0.0027364
	LOSS [training: 0.24968964922555323 | validation: 0.2213568722717926]
	TIME [epoch: 109 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2491570409857116		[learning rate: 0.0027267]
	Learning Rate: 0.00272672
	LOSS [training: 0.2491570409857116 | validation: 0.21021983910895936]
	TIME [epoch: 109 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2424375182778272		[learning rate: 0.0027171]
	Learning Rate: 0.00271708
	LOSS [training: 0.2424375182778272 | validation: 0.2196591672886191]
	TIME [epoch: 109 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24802489680892692		[learning rate: 0.0027075]
	Learning Rate: 0.00270747
	LOSS [training: 0.24802489680892692 | validation: 0.21339634491179765]
	TIME [epoch: 109 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2487588821787915		[learning rate: 0.0026979]
	Learning Rate: 0.0026979
	LOSS [training: 0.2487588821787915 | validation: 0.209235743601183]
	TIME [epoch: 110 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24270379591239344		[learning rate: 0.0026884]
	Learning Rate: 0.00268836
	LOSS [training: 0.24270379591239344 | validation: 0.2077552203500824]
	TIME [epoch: 110 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25025168093088657		[learning rate: 0.0026789]
	Learning Rate: 0.00267885
	LOSS [training: 0.25025168093088657 | validation: 0.21078859865695487]
	TIME [epoch: 110 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24559329942701802		[learning rate: 0.0026694]
	Learning Rate: 0.00266938
	LOSS [training: 0.24559329942701802 | validation: 0.20156483614869547]
	TIME [epoch: 110 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24552714362289263		[learning rate: 0.0026599]
	Learning Rate: 0.00265994
	LOSS [training: 0.24552714362289263 | validation: 0.217915450269331]
	TIME [epoch: 110 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25690530092337294		[learning rate: 0.0026505]
	Learning Rate: 0.00265053
	LOSS [training: 0.25690530092337294 | validation: 0.22223206535073076]
	TIME [epoch: 110 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2539159936073734		[learning rate: 0.0026412]
	Learning Rate: 0.00264116
	LOSS [training: 0.2539159936073734 | validation: 0.20770616150262686]
	TIME [epoch: 110 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2444453110353901		[learning rate: 0.0026318]
	Learning Rate: 0.00263182
	LOSS [training: 0.2444453110353901 | validation: 0.2211214614531846]
	TIME [epoch: 110 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2526643741707963		[learning rate: 0.0026225]
	Learning Rate: 0.00262251
	LOSS [training: 0.2526643741707963 | validation: 0.22167763023041812]
	TIME [epoch: 110 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24683435478499904		[learning rate: 0.0026132]
	Learning Rate: 0.00261324
	LOSS [training: 0.24683435478499904 | validation: 0.21270216324761457]
	TIME [epoch: 110 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24653431586850263		[learning rate: 0.002604]
	Learning Rate: 0.002604
	LOSS [training: 0.24653431586850263 | validation: 0.20476060500492324]
	TIME [epoch: 110 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24844227036661404		[learning rate: 0.0025948]
	Learning Rate: 0.00259479
	LOSS [training: 0.24844227036661404 | validation: 0.20429736103123997]
	TIME [epoch: 110 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25489641929667245		[learning rate: 0.0025856]
	Learning Rate: 0.00258562
	LOSS [training: 0.25489641929667245 | validation: 0.2144890407081078]
	TIME [epoch: 109 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.251073560976801		[learning rate: 0.0025765]
	Learning Rate: 0.00257647
	LOSS [training: 0.251073560976801 | validation: 0.20514800295958432]
	TIME [epoch: 109 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2474952898332037		[learning rate: 0.0025674]
	Learning Rate: 0.00256736
	LOSS [training: 0.2474952898332037 | validation: 0.2106552255166943]
	TIME [epoch: 110 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2487246010370757		[learning rate: 0.0025583]
	Learning Rate: 0.00255828
	LOSS [training: 0.2487246010370757 | validation: 0.2109992064193335]
	TIME [epoch: 110 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2510024604951565		[learning rate: 0.0025492]
	Learning Rate: 0.00254924
	LOSS [training: 0.2510024604951565 | validation: 0.21297244580196906]
	TIME [epoch: 110 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24029495084025343		[learning rate: 0.0025402]
	Learning Rate: 0.00254022
	LOSS [training: 0.24029495084025343 | validation: 0.21502879041647235]
	TIME [epoch: 109 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2520679598094615		[learning rate: 0.0025312]
	Learning Rate: 0.00253124
	LOSS [training: 0.2520679598094615 | validation: 0.20664537844950664]
	TIME [epoch: 109 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2442208380516623		[learning rate: 0.0025223]
	Learning Rate: 0.00252229
	LOSS [training: 0.2442208380516623 | validation: 0.21404493836996458]
	TIME [epoch: 109 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24899972963885322		[learning rate: 0.0025134]
	Learning Rate: 0.00251337
	LOSS [training: 0.24899972963885322 | validation: 0.21493300614521962]
	TIME [epoch: 109 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2536803006306689		[learning rate: 0.0025045]
	Learning Rate: 0.00250448
	LOSS [training: 0.2536803006306689 | validation: 0.21655678706707873]
	TIME [epoch: 109 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26012595213136597		[learning rate: 0.0024956]
	Learning Rate: 0.00249563
	LOSS [training: 0.26012595213136597 | validation: 0.21498031496761358]
	TIME [epoch: 109 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24614824276345262		[learning rate: 0.0024868]
	Learning Rate: 0.0024868
	LOSS [training: 0.24614824276345262 | validation: 0.20688615161622814]
	TIME [epoch: 109 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24272098794240957		[learning rate: 0.002478]
	Learning Rate: 0.00247801
	LOSS [training: 0.24272098794240957 | validation: 0.2085109689939811]
	TIME [epoch: 109 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24125315895091468		[learning rate: 0.0024692]
	Learning Rate: 0.00246924
	LOSS [training: 0.24125315895091468 | validation: 0.214646540883896]
	TIME [epoch: 109 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24459908435782748		[learning rate: 0.0024605]
	Learning Rate: 0.00246051
	LOSS [training: 0.24459908435782748 | validation: 0.21233054680275293]
	TIME [epoch: 110 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2539067334920176		[learning rate: 0.0024518]
	Learning Rate: 0.00245181
	LOSS [training: 0.2539067334920176 | validation: 0.2147455671433735]
	TIME [epoch: 109 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24815160854171944		[learning rate: 0.0024431]
	Learning Rate: 0.00244314
	LOSS [training: 0.24815160854171944 | validation: 0.21392804991763895]
	TIME [epoch: 109 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2551260826833958		[learning rate: 0.0024345]
	Learning Rate: 0.0024345
	LOSS [training: 0.2551260826833958 | validation: 0.21283705341775513]
	TIME [epoch: 109 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2470990952096593		[learning rate: 0.0024259]
	Learning Rate: 0.00242589
	LOSS [training: 0.2470990952096593 | validation: 0.2117061225985442]
	TIME [epoch: 109 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.247782882759904		[learning rate: 0.0024173]
	Learning Rate: 0.00241732
	LOSS [training: 0.247782882759904 | validation: 0.21387469355227884]
	TIME [epoch: 109 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2494929718543731		[learning rate: 0.0024088]
	Learning Rate: 0.00240877
	LOSS [training: 0.2494929718543731 | validation: 0.22395963320752643]
	TIME [epoch: 110 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.252352623662581		[learning rate: 0.0024002]
	Learning Rate: 0.00240025
	LOSS [training: 0.252352623662581 | validation: 0.21875808937283897]
	TIME [epoch: 109 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24444971183959283		[learning rate: 0.0023918]
	Learning Rate: 0.00239176
	LOSS [training: 0.24444971183959283 | validation: 0.21575470752459677]
	TIME [epoch: 110 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24024649085261365		[learning rate: 0.0023833]
	Learning Rate: 0.0023833
	LOSS [training: 0.24024649085261365 | validation: 0.20815189964004896]
	TIME [epoch: 109 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2485116270856591		[learning rate: 0.0023749]
	Learning Rate: 0.00237488
	LOSS [training: 0.2485116270856591 | validation: 0.2081966241519666]
	TIME [epoch: 109 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24605149237936183		[learning rate: 0.0023665]
	Learning Rate: 0.00236648
	LOSS [training: 0.24605149237936183 | validation: 0.2097196649419454]
	TIME [epoch: 109 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2455545079806247		[learning rate: 0.0023581]
	Learning Rate: 0.00235811
	LOSS [training: 0.2455545079806247 | validation: 0.20946781081556765]
	TIME [epoch: 109 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24545068633203504		[learning rate: 0.0023498]
	Learning Rate: 0.00234977
	LOSS [training: 0.24545068633203504 | validation: 0.21409127372512765]
	TIME [epoch: 109 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24979713151101035		[learning rate: 0.0023415]
	Learning Rate: 0.00234146
	LOSS [training: 0.24979713151101035 | validation: 0.21167527048714888]
	TIME [epoch: 109 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25018643930214896		[learning rate: 0.0023332]
	Learning Rate: 0.00233318
	LOSS [training: 0.25018643930214896 | validation: 0.2108831009874721]
	TIME [epoch: 109 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2555696094973039		[learning rate: 0.0023249]
	Learning Rate: 0.00232493
	LOSS [training: 0.2555696094973039 | validation: 0.20959704272598847]
	TIME [epoch: 109 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2526698626286023		[learning rate: 0.0023167]
	Learning Rate: 0.00231671
	LOSS [training: 0.2526698626286023 | validation: 0.21492587999950669]
	TIME [epoch: 109 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2461785502691408		[learning rate: 0.0023085]
	Learning Rate: 0.00230852
	LOSS [training: 0.2461785502691408 | validation: 0.20638095490976535]
	TIME [epoch: 109 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24993305718790312		[learning rate: 0.0023004]
	Learning Rate: 0.00230035
	LOSS [training: 0.24993305718790312 | validation: 0.20140104112288001]
	TIME [epoch: 109 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24290945252049034		[learning rate: 0.0022922]
	Learning Rate: 0.00229222
	LOSS [training: 0.24290945252049034 | validation: 0.20045474007099306]
	TIME [epoch: 110 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24501363242574656		[learning rate: 0.0022841]
	Learning Rate: 0.00228411
	LOSS [training: 0.24501363242574656 | validation: 0.2060513916028885]
	TIME [epoch: 109 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23691741719645723		[learning rate: 0.002276]
	Learning Rate: 0.00227604
	LOSS [training: 0.23691741719645723 | validation: 0.2079293758496942]
	TIME [epoch: 110 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25023051755204506		[learning rate: 0.002268]
	Learning Rate: 0.00226799
	LOSS [training: 0.25023051755204506 | validation: 0.21279630838312363]
	TIME [epoch: 109 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24798890511788185		[learning rate: 0.00226]
	Learning Rate: 0.00225997
	LOSS [training: 0.24798890511788185 | validation: 0.2069935591459851]
	TIME [epoch: 109 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24743196802720557		[learning rate: 0.002252]
	Learning Rate: 0.00225198
	LOSS [training: 0.24743196802720557 | validation: 0.21441298111105062]
	TIME [epoch: 109 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24422009824554272		[learning rate: 0.002244]
	Learning Rate: 0.00224401
	LOSS [training: 0.24422009824554272 | validation: 0.20744959664958182]
	TIME [epoch: 109 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24684524791483967		[learning rate: 0.0022361]
	Learning Rate: 0.00223608
	LOSS [training: 0.24684524791483967 | validation: 0.21263051270954608]
	TIME [epoch: 109 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2583935380568932		[learning rate: 0.0022282]
	Learning Rate: 0.00222817
	LOSS [training: 0.2583935380568932 | validation: 0.2024072882252655]
	TIME [epoch: 109 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2528995998248395		[learning rate: 0.0022203]
	Learning Rate: 0.00222029
	LOSS [training: 0.2528995998248395 | validation: 0.21028783783420657]
	TIME [epoch: 109 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2433471562683309		[learning rate: 0.0022124]
	Learning Rate: 0.00221244
	LOSS [training: 0.2433471562683309 | validation: 0.2087051190130536]
	TIME [epoch: 109 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24332369217932978		[learning rate: 0.0022046]
	Learning Rate: 0.00220462
	LOSS [training: 0.24332369217932978 | validation: 0.2048954039965773]
	TIME [epoch: 109 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23943650974926026		[learning rate: 0.0021968]
	Learning Rate: 0.00219682
	LOSS [training: 0.23943650974926026 | validation: 0.2102902327586694]
	TIME [epoch: 109 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2474868619914403		[learning rate: 0.0021891]
	Learning Rate: 0.00218905
	LOSS [training: 0.2474868619914403 | validation: 0.20460768175959018]
	TIME [epoch: 109 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25026589383216663		[learning rate: 0.0021813]
	Learning Rate: 0.00218131
	LOSS [training: 0.25026589383216663 | validation: 0.20837315584115657]
	TIME [epoch: 109 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24092273871780912		[learning rate: 0.0021736]
	Learning Rate: 0.0021736
	LOSS [training: 0.24092273871780912 | validation: 0.21298642511777732]
	TIME [epoch: 110 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24306387355130568		[learning rate: 0.0021659]
	Learning Rate: 0.00216591
	LOSS [training: 0.24306387355130568 | validation: 0.20899188243908032]
	TIME [epoch: 109 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24481717326234645		[learning rate: 0.0021583]
	Learning Rate: 0.00215825
	LOSS [training: 0.24481717326234645 | validation: 0.20859773442398333]
	TIME [epoch: 109 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2454818201693846		[learning rate: 0.0021506]
	Learning Rate: 0.00215062
	LOSS [training: 0.2454818201693846 | validation: 0.203240299410229]
	TIME [epoch: 109 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24508146024443536		[learning rate: 0.002143]
	Learning Rate: 0.00214302
	LOSS [training: 0.24508146024443536 | validation: 0.21506178607319462]
	TIME [epoch: 109 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24724033104783263		[learning rate: 0.0021354]
	Learning Rate: 0.00213544
	LOSS [training: 0.24724033104783263 | validation: 0.20629549997785962]
	TIME [epoch: 109 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23577730805011168		[learning rate: 0.0021279]
	Learning Rate: 0.00212789
	LOSS [training: 0.23577730805011168 | validation: 0.21276952859253234]
	TIME [epoch: 110 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2415259033956507		[learning rate: 0.0021204]
	Learning Rate: 0.00212036
	LOSS [training: 0.2415259033956507 | validation: 0.21051088603671136]
	TIME [epoch: 109 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24596989750035889		[learning rate: 0.0021129]
	Learning Rate: 0.00211287
	LOSS [training: 0.24596989750035889 | validation: 0.20783650335284704]
	TIME [epoch: 109 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2494663860721846		[learning rate: 0.0021054]
	Learning Rate: 0.00210539
	LOSS [training: 0.2494663860721846 | validation: 0.19833746972143357]
	TIME [epoch: 109 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.243457282537092		[learning rate: 0.0020979]
	Learning Rate: 0.00209795
	LOSS [training: 0.243457282537092 | validation: 0.2016474224390556]
	TIME [epoch: 109 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24357798073138978		[learning rate: 0.0020905]
	Learning Rate: 0.00209053
	LOSS [training: 0.24357798073138978 | validation: 0.19830581064350644]
	TIME [epoch: 109 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24433878402354267		[learning rate: 0.0020831]
	Learning Rate: 0.00208314
	LOSS [training: 0.24433878402354267 | validation: 0.20896132804459538]
	TIME [epoch: 109 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26598003999587577		[learning rate: 0.0020758]
	Learning Rate: 0.00207577
	LOSS [training: 0.26598003999587577 | validation: 0.20597121418443934]
	TIME [epoch: 109 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2454486772167137		[learning rate: 0.0020684]
	Learning Rate: 0.00206843
	LOSS [training: 0.2454486772167137 | validation: 0.2124390556401142]
	TIME [epoch: 109 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2401222571029793		[learning rate: 0.0020611]
	Learning Rate: 0.00206112
	LOSS [training: 0.2401222571029793 | validation: 0.20462535583594832]
	TIME [epoch: 109 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24480591100923807		[learning rate: 0.0020538]
	Learning Rate: 0.00205383
	LOSS [training: 0.24480591100923807 | validation: 0.20623697278991443]
	TIME [epoch: 109 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24485760358030992		[learning rate: 0.0020466]
	Learning Rate: 0.00204657
	LOSS [training: 0.24485760358030992 | validation: 0.20124955275437006]
	TIME [epoch: 109 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23555848967850934		[learning rate: 0.0020393]
	Learning Rate: 0.00203933
	LOSS [training: 0.23555848967850934 | validation: 0.2053026172304111]
	TIME [epoch: 109 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24885951927537353		[learning rate: 0.0020321]
	Learning Rate: 0.00203212
	LOSS [training: 0.24885951927537353 | validation: 0.2116466617872204]
	TIME [epoch: 109 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2514733022284104		[learning rate: 0.0020249]
	Learning Rate: 0.00202493
	LOSS [training: 0.2514733022284104 | validation: 0.21088399808108824]
	TIME [epoch: 109 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24893995768164554		[learning rate: 0.0020178]
	Learning Rate: 0.00201777
	LOSS [training: 0.24893995768164554 | validation: 0.20903852261097136]
	TIME [epoch: 109 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24798123976686412		[learning rate: 0.0020106]
	Learning Rate: 0.00201064
	LOSS [training: 0.24798123976686412 | validation: 0.2092491317344924]
	TIME [epoch: 109 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24440565568582917		[learning rate: 0.0020035]
	Learning Rate: 0.00200353
	LOSS [training: 0.24440565568582917 | validation: 0.20896979390900255]
	TIME [epoch: 109 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2455342465689716		[learning rate: 0.0019964]
	Learning Rate: 0.00199644
	LOSS [training: 0.2455342465689716 | validation: 0.20837787008149986]
	TIME [epoch: 109 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2445589673462897		[learning rate: 0.0019894]
	Learning Rate: 0.00198938
	LOSS [training: 0.2445589673462897 | validation: 0.20912409391239944]
	TIME [epoch: 109 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24746425211536896		[learning rate: 0.0019823]
	Learning Rate: 0.00198235
	LOSS [training: 0.24746425211536896 | validation: 0.20797090944425842]
	TIME [epoch: 109 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2465977510094245		[learning rate: 0.0019753]
	Learning Rate: 0.00197534
	LOSS [training: 0.2465977510094245 | validation: 0.20412426086426977]
	TIME [epoch: 109 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2521302104707916		[learning rate: 0.0019684]
	Learning Rate: 0.00196835
	LOSS [training: 0.2521302104707916 | validation: 0.21374806385367787]
	TIME [epoch: 109 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24661872405397048		[learning rate: 0.0019614]
	Learning Rate: 0.00196139
	LOSS [training: 0.24661872405397048 | validation: 0.2119240687884012]
	TIME [epoch: 109 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2543992618600383		[learning rate: 0.0019545]
	Learning Rate: 0.00195445
	LOSS [training: 0.2543992618600383 | validation: 0.21361077175818594]
	TIME [epoch: 109 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2508496841891353		[learning rate: 0.0019475]
	Learning Rate: 0.00194754
	LOSS [training: 0.2508496841891353 | validation: 0.21265358481665916]
	TIME [epoch: 109 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2441835206642724		[learning rate: 0.0019407]
	Learning Rate: 0.00194066
	LOSS [training: 0.2441835206642724 | validation: 0.20649925671733863]
	TIME [epoch: 109 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25216602759461737		[learning rate: 0.0019338]
	Learning Rate: 0.00193379
	LOSS [training: 0.25216602759461737 | validation: 0.2040513641617018]
	TIME [epoch: 109 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2439832814480932		[learning rate: 0.001927]
	Learning Rate: 0.00192696
	LOSS [training: 0.2439832814480932 | validation: 0.21415868207432717]
	TIME [epoch: 109 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2506784205081443		[learning rate: 0.0019201]
	Learning Rate: 0.00192014
	LOSS [training: 0.2506784205081443 | validation: 0.21382841677752137]
	TIME [epoch: 109 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24587933887521818		[learning rate: 0.0019134]
	Learning Rate: 0.00191335
	LOSS [training: 0.24587933887521818 | validation: 0.20354915784747002]
	TIME [epoch: 109 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24032884852183223		[learning rate: 0.0019066]
	Learning Rate: 0.00190659
	LOSS [training: 0.24032884852183223 | validation: 0.21205025820936324]
	TIME [epoch: 109 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24368513483539436		[learning rate: 0.0018998]
	Learning Rate: 0.00189984
	LOSS [training: 0.24368513483539436 | validation: 0.20200076786112664]
	TIME [epoch: 109 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24592841647105235		[learning rate: 0.0018931]
	Learning Rate: 0.00189313
	LOSS [training: 0.24592841647105235 | validation: 0.21174162099868238]
	TIME [epoch: 109 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24807625533771663		[learning rate: 0.0018864]
	Learning Rate: 0.00188643
	LOSS [training: 0.24807625533771663 | validation: 0.2209181947654816]
	TIME [epoch: 109 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25059076347126324		[learning rate: 0.0018798]
	Learning Rate: 0.00187976
	LOSS [training: 0.25059076347126324 | validation: 0.20742540649739008]
	TIME [epoch: 109 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24260547498299845		[learning rate: 0.0018731]
	Learning Rate: 0.00187311
	LOSS [training: 0.24260547498299845 | validation: 0.2141870035701528]
	TIME [epoch: 109 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24458567153789432		[learning rate: 0.0018665]
	Learning Rate: 0.00186649
	LOSS [training: 0.24458567153789432 | validation: 0.20792243878243086]
	TIME [epoch: 109 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24790391022769578		[learning rate: 0.0018599]
	Learning Rate: 0.00185989
	LOSS [training: 0.24790391022769578 | validation: 0.20869644810357108]
	TIME [epoch: 109 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2372340668944483		[learning rate: 0.0018533]
	Learning Rate: 0.00185331
	LOSS [training: 0.2372340668944483 | validation: 0.2098933983471487]
	TIME [epoch: 109 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24574896187219517		[learning rate: 0.0018468]
	Learning Rate: 0.00184676
	LOSS [training: 0.24574896187219517 | validation: 0.21414630084177055]
	TIME [epoch: 109 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24645357420695757		[learning rate: 0.0018402]
	Learning Rate: 0.00184023
	LOSS [training: 0.24645357420695757 | validation: 0.2029801911016001]
	TIME [epoch: 109 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24612978446606837		[learning rate: 0.0018337]
	Learning Rate: 0.00183372
	LOSS [training: 0.24612978446606837 | validation: 0.2158240883941696]
	TIME [epoch: 109 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24908954139009667		[learning rate: 0.0018272]
	Learning Rate: 0.00182724
	LOSS [training: 0.24908954139009667 | validation: 0.21033344596226433]
	TIME [epoch: 109 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23883854032624421		[learning rate: 0.0018208]
	Learning Rate: 0.00182078
	LOSS [training: 0.23883854032624421 | validation: 0.20253841783166648]
	TIME [epoch: 110 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24821762025578153		[learning rate: 0.0018143]
	Learning Rate: 0.00181434
	LOSS [training: 0.24821762025578153 | validation: 0.21521996731976825]
	TIME [epoch: 109 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24368679257410478		[learning rate: 0.0018079]
	Learning Rate: 0.00180792
	LOSS [training: 0.24368679257410478 | validation: 0.20700691633945306]
	TIME [epoch: 109 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24294006402980875		[learning rate: 0.0018015]
	Learning Rate: 0.00180153
	LOSS [training: 0.24294006402980875 | validation: 0.2117246310245978]
	TIME [epoch: 109 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25040929440226595		[learning rate: 0.0017952]
	Learning Rate: 0.00179516
	LOSS [training: 0.25040929440226595 | validation: 0.21646599849794831]
	TIME [epoch: 109 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24886307477039363		[learning rate: 0.0017888]
	Learning Rate: 0.00178881
	LOSS [training: 0.24886307477039363 | validation: 0.20593506510563672]
	TIME [epoch: 109 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24947175755795348		[learning rate: 0.0017825]
	Learning Rate: 0.00178248
	LOSS [training: 0.24947175755795348 | validation: 0.21247431169996092]
	TIME [epoch: 109 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24330815123373176		[learning rate: 0.0017762]
	Learning Rate: 0.00177618
	LOSS [training: 0.24330815123373176 | validation: 0.1982270315516117]
	TIME [epoch: 109 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23757897659246377		[learning rate: 0.0017699]
	Learning Rate: 0.0017699
	LOSS [training: 0.23757897659246377 | validation: 0.20814216237939825]
	TIME [epoch: 109 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.251041353390865		[learning rate: 0.0017636]
	Learning Rate: 0.00176364
	LOSS [training: 0.251041353390865 | validation: 0.21307147544007415]
	TIME [epoch: 109 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23742775402498761		[learning rate: 0.0017574]
	Learning Rate: 0.0017574
	LOSS [training: 0.23742775402498761 | validation: 0.20632914157867527]
	TIME [epoch: 109 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24534705309236818		[learning rate: 0.0017512]
	Learning Rate: 0.00175119
	LOSS [training: 0.24534705309236818 | validation: 0.2089155312873941]
	TIME [epoch: 109 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24688994855448199		[learning rate: 0.001745]
	Learning Rate: 0.001745
	LOSS [training: 0.24688994855448199 | validation: 0.21774662498603994]
	TIME [epoch: 109 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2484634670741929		[learning rate: 0.0017388]
	Learning Rate: 0.00173883
	LOSS [training: 0.2484634670741929 | validation: 0.2083176247486908]
	TIME [epoch: 109 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24180559450603023		[learning rate: 0.0017327]
	Learning Rate: 0.00173268
	LOSS [training: 0.24180559450603023 | validation: 0.21035597108874135]
	TIME [epoch: 109 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2363183766469014		[learning rate: 0.0017266]
	Learning Rate: 0.00172655
	LOSS [training: 0.2363183766469014 | validation: 0.22351496572054735]
	TIME [epoch: 109 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24567610758447442		[learning rate: 0.0017204]
	Learning Rate: 0.00172045
	LOSS [training: 0.24567610758447442 | validation: 0.21873984105859967]
	TIME [epoch: 109 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24451358339330845		[learning rate: 0.0017144]
	Learning Rate: 0.00171436
	LOSS [training: 0.24451358339330845 | validation: 0.2202457619258321]
	TIME [epoch: 109 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24380750130284226		[learning rate: 0.0017083]
	Learning Rate: 0.0017083
	LOSS [training: 0.24380750130284226 | validation: 0.21009374228239816]
	TIME [epoch: 109 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2437734375125421		[learning rate: 0.0017023]
	Learning Rate: 0.00170226
	LOSS [training: 0.2437734375125421 | validation: 0.20962039854598177]
	TIME [epoch: 109 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2425335661171731		[learning rate: 0.0016962]
	Learning Rate: 0.00169624
	LOSS [training: 0.2425335661171731 | validation: 0.21152783172824136]
	TIME [epoch: 109 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2516997313837471		[learning rate: 0.0016902]
	Learning Rate: 0.00169024
	LOSS [training: 0.2516997313837471 | validation: 0.21103208600957787]
	TIME [epoch: 109 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24111696498220428		[learning rate: 0.0016843]
	Learning Rate: 0.00168426
	LOSS [training: 0.24111696498220428 | validation: 0.2107855624109926]
	TIME [epoch: 109 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2453428368217722		[learning rate: 0.0016783]
	Learning Rate: 0.00167831
	LOSS [training: 0.2453428368217722 | validation: 0.21092399786386098]
	TIME [epoch: 109 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24482237937137097		[learning rate: 0.0016724]
	Learning Rate: 0.00167237
	LOSS [training: 0.24482237937137097 | validation: 0.21108423250085143]
	TIME [epoch: 109 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24186253168382307		[learning rate: 0.0016665]
	Learning Rate: 0.00166646
	LOSS [training: 0.24186253168382307 | validation: 0.2076182220202729]
	TIME [epoch: 109 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.243654279635808		[learning rate: 0.0016606]
	Learning Rate: 0.00166057
	LOSS [training: 0.243654279635808 | validation: 0.2072639119755538]
	TIME [epoch: 109 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2477673397239313		[learning rate: 0.0016547]
	Learning Rate: 0.00165469
	LOSS [training: 0.2477673397239313 | validation: 0.20049035843210522]
	TIME [epoch: 109 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2520901899952179		[learning rate: 0.0016488]
	Learning Rate: 0.00164884
	LOSS [training: 0.2520901899952179 | validation: 0.21255370692960746]
	TIME [epoch: 109 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24753823179888299		[learning rate: 0.001643]
	Learning Rate: 0.00164301
	LOSS [training: 0.24753823179888299 | validation: 0.2068210024224864]
	TIME [epoch: 109 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24756413790447276		[learning rate: 0.0016372]
	Learning Rate: 0.0016372
	LOSS [training: 0.24756413790447276 | validation: 0.20050501348935584]
	TIME [epoch: 109 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24194476869707385		[learning rate: 0.0016314]
	Learning Rate: 0.00163141
	LOSS [training: 0.24194476869707385 | validation: 0.21528651675541646]
	TIME [epoch: 109 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2506150441531557		[learning rate: 0.0016256]
	Learning Rate: 0.00162564
	LOSS [training: 0.2506150441531557 | validation: 0.2099795233397009]
	TIME [epoch: 109 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24364231683870485		[learning rate: 0.0016199]
	Learning Rate: 0.0016199
	LOSS [training: 0.24364231683870485 | validation: 0.2030094215456324]
	TIME [epoch: 109 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2466695712113477		[learning rate: 0.0016142]
	Learning Rate: 0.00161417
	LOSS [training: 0.2466695712113477 | validation: 0.20728133339764732]
	TIME [epoch: 109 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25161047871978276		[learning rate: 0.0016085]
	Learning Rate: 0.00160846
	LOSS [training: 0.25161047871978276 | validation: 0.21164987545178832]
	TIME [epoch: 109 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2490582861374846		[learning rate: 0.0016028]
	Learning Rate: 0.00160277
	LOSS [training: 0.2490582861374846 | validation: 0.20882786101425568]
	TIME [epoch: 109 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24360793065099373		[learning rate: 0.0015971]
	Learning Rate: 0.0015971
	LOSS [training: 0.24360793065099373 | validation: 0.21375231226748617]
	TIME [epoch: 109 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24469603901159953		[learning rate: 0.0015915]
	Learning Rate: 0.00159146
	LOSS [training: 0.24469603901159953 | validation: 0.21424950811253335]
	TIME [epoch: 109 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14b_20240716_161522/states/model_facs_v3_dec1b_2dpca_v14b_569.pth
Halted early. No improvement in validation loss for 200 epochs.
Finished training in 38191.237 seconds.
