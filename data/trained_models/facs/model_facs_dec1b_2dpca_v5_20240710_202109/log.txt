Args:
Namespace(name='model_facs_dec1b_2dpca_v5', outdir='out/model_training/model_facs_dec1b_2dpca_v5', training_data='data/training_data/facs/pca/dec1_fitonsubset/transition1_subset_epi_tr_ce_an_pc12/training', validation_data='data/training_data/facs/pca/dec1_fitonsubset/transition1_subset_epi_tr_ce_an_pc12/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=10, batch_size=50, patience=200, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=50, ncells_sample=50, model_do_sample=False, dt=0.005, dt_schedule='stepped', dt_schedule_bounds=[500, 1000, 1500], dt_schedule_scales=[0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=True, sigma=0.02, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', kernel='multiscale', bw_range=[0.2, 0.5, 0.9, 1.1, 1.3, 1.5, 2.0], optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 4189801175

Training model...

Saving initial model state to: out/model_training/model_facs_dec1b_2dpca_v5_20240710_202109/states/model_facs_dec1b_2dpca_v5_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.378773507150521		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.378773507150521 | validation: 1.1022528492385786]
	TIME [epoch: 35.9 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v5_20240710_202109/states/model_facs_dec1b_2dpca_v5_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.1796512210553205		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1796512210553205 | validation: 1.0341256156924268]
	TIME [epoch: 6.54 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v5_20240710_202109/states/model_facs_dec1b_2dpca_v5_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.081198265095769		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.081198265095769 | validation: 0.9878555312230912]
	TIME [epoch: 6.51 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v5_20240710_202109/states/model_facs_dec1b_2dpca_v5_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.0440398055556641		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0440398055556641 | validation: 1.0992604412106777]
	TIME [epoch: 6.51 sec]
EPOCH 5/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.0954786505903082		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0954786505903082 | validation: 0.8715047548090638]
	TIME [epoch: 6.51 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v5_20240710_202109/states/model_facs_dec1b_2dpca_v5_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.016264679911707		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.016264679911707 | validation: 0.8473572714407217]
	TIME [epoch: 6.52 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v5_20240710_202109/states/model_facs_dec1b_2dpca_v5_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.0241881625647717		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0241881625647717 | validation: 0.8563141552317161]
	TIME [epoch: 6.53 sec]
EPOCH 8/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.9131758872543703		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9131758872543703 | validation: 0.7639351992547401]
	TIME [epoch: 6.51 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v5_20240710_202109/states/model_facs_dec1b_2dpca_v5_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.8939632155810892		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8939632155810892 | validation: 0.922631397364524]
	TIME [epoch: 6.53 sec]
EPOCH 10/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.9001085656971662		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9001085656971662 | validation: 0.7059468649049035]
	TIME [epoch: 6.52 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v5_20240710_202109/states/model_facs_dec1b_2dpca_v5_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.8384939846822017		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8384939846822017 | validation: 0.7313932388312772]
	TIME [epoch: 6.51 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.835608133343616		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.835608133343616 | validation: 0.6890082820182611]
	TIME [epoch: 6.52 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v5_20240710_202109/states/model_facs_dec1b_2dpca_v5_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.8401457254469132		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8401457254469132 | validation: 0.5992149184753026]
	TIME [epoch: 6.6 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v5_20240710_202109/states/model_facs_dec1b_2dpca_v5_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.8288842198133531		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8288842198133531 | validation: 0.6324918520933559]
	TIME [epoch: 6.52 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.8371000960479044		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8371000960479044 | validation: 0.6887198177338693]
	TIME [epoch: 6.52 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7776618495436334		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7776618495436334 | validation: 0.7596212742143637]
	TIME [epoch: 6.51 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7188883596253183		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7188883596253183 | validation: 0.6258282602866349]
	TIME [epoch: 6.51 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.731871630203364		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.731871630203364 | validation: 0.6809511977966848]
	TIME [epoch: 6.5 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7185027076627848		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7185027076627848 | validation: 0.6780196673650791]
	TIME [epoch: 6.52 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7382608693498982		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7382608693498982 | validation: 0.6960011027814836]
	TIME [epoch: 6.52 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6459906168508972		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6459906168508972 | validation: 0.5705820044799976]
	TIME [epoch: 6.51 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v5_20240710_202109/states/model_facs_dec1b_2dpca_v5_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5710608462741642		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5710608462741642 | validation: 0.8988033443858778]
	TIME [epoch: 6.51 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6721604017792919		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6721604017792919 | validation: 0.5804131576573981]
	TIME [epoch: 6.51 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5253023646218206		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5253023646218206 | validation: 0.5040664096029348]
	TIME [epoch: 6.51 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v5_20240710_202109/states/model_facs_dec1b_2dpca_v5_24.pth
	Model improved!!!
EPOCH 25/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5874685117810334		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5874685117810334 | validation: 0.5872990342810287]
	TIME [epoch: 6.52 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5648776246978005		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5648776246978005 | validation: 0.566975413176794]
	TIME [epoch: 6.52 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5178920263638009		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5178920263638009 | validation: 0.5317153418848882]
	TIME [epoch: 6.5 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6013471257805184		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6013471257805184 | validation: 0.4737234589972548]
	TIME [epoch: 6.5 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v5_20240710_202109/states/model_facs_dec1b_2dpca_v5_28.pth
	Model improved!!!
EPOCH 29/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5639294893718667		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5639294893718667 | validation: 0.5654266168607194]
	TIME [epoch: 6.51 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.524626048202864		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.524626048202864 | validation: 0.563450965750876]
	TIME [epoch: 6.51 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5675583945849507		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5675583945849507 | validation: 0.5349084356763892]
	TIME [epoch: 6.5 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.517014143260465		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.517014143260465 | validation: 0.6186026495761807]
	TIME [epoch: 6.52 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5517348859736835		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5517348859736835 | validation: 0.7164030707990672]
	TIME [epoch: 6.51 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6436426751297935		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6436426751297935 | validation: 0.6992978635343242]
	TIME [epoch: 6.51 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5136740956272462		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5136740956272462 | validation: 0.5576932722823638]
	TIME [epoch: 6.51 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5023116436235254		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5023116436235254 | validation: 0.6180386136232463]
	TIME [epoch: 6.5 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5773454918109362		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5773454918109362 | validation: 0.5342069424818239]
	TIME [epoch: 6.5 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5489458639831173		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5489458639831173 | validation: 0.5763221286617861]
	TIME [epoch: 6.52 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5362053294449008		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5362053294449008 | validation: 0.4590879853389482]
	TIME [epoch: 6.52 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v5_20240710_202109/states/model_facs_dec1b_2dpca_v5_39.pth
	Model improved!!!
EPOCH 40/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.44697882563175956		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.44697882563175956 | validation: 0.5495311172165362]
	TIME [epoch: 6.51 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5924509081027297		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5924509081027297 | validation: 0.4651475737266315]
	TIME [epoch: 6.51 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.44040011040009946		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.44040011040009946 | validation: 0.516585300445017]
	TIME [epoch: 6.5 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.47072395066849804		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.47072395066849804 | validation: 0.4571429276536921]
	TIME [epoch: 6.51 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v5_20240710_202109/states/model_facs_dec1b_2dpca_v5_43.pth
	Model improved!!!
EPOCH 44/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4762586000805652		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4762586000805652 | validation: 0.4402769671918218]
	TIME [epoch: 6.51 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v5_20240710_202109/states/model_facs_dec1b_2dpca_v5_44.pth
	Model improved!!!
EPOCH 45/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5965336464328854		[learning rate: 0.0099823]
	Learning Rate: 0.0099823
	LOSS [training: 0.5965336464328854 | validation: 0.5409256495119339]
	TIME [epoch: 6.53 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5084617845050367		[learning rate: 0.0099426]
	Learning Rate: 0.0099426
	LOSS [training: 0.5084617845050367 | validation: 0.4309399818785223]
	TIME [epoch: 6.52 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v5_20240710_202109/states/model_facs_dec1b_2dpca_v5_46.pth
	Model improved!!!
EPOCH 47/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.47741005803784403		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 0.47741005803784403 | validation: 0.4536351900273911]
	TIME [epoch: 6.52 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.43274331633474294		[learning rate: 0.0098637]
	Learning Rate: 0.00986367
	LOSS [training: 0.43274331633474294 | validation: 0.475280582346984]
	TIME [epoch: 6.51 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.45775408171786036		[learning rate: 0.0098244]
	Learning Rate: 0.00982444
	LOSS [training: 0.45775408171786036 | validation: 0.523708279208253]
	TIME [epoch: 6.52 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5497090062283411		[learning rate: 0.0097854]
	Learning Rate: 0.00978536
	LOSS [training: 0.5497090062283411 | validation: 0.5137677733683788]
	TIME [epoch: 6.52 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.45191334863134475		[learning rate: 0.0097464]
	Learning Rate: 0.00974644
	LOSS [training: 0.45191334863134475 | validation: 0.4291469639913104]
	TIME [epoch: 6.52 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v5_20240710_202109/states/model_facs_dec1b_2dpca_v5_51.pth
	Model improved!!!
EPOCH 52/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.45836777077030966		[learning rate: 0.0097077]
	Learning Rate: 0.00970768
	LOSS [training: 0.45836777077030966 | validation: 0.5068958707572666]
	TIME [epoch: 6.52 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4823540571398681		[learning rate: 0.0096691]
	Learning Rate: 0.00966907
	LOSS [training: 0.4823540571398681 | validation: 0.48934926242174487]
	TIME [epoch: 6.51 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4372742856644709		[learning rate: 0.0096306]
	Learning Rate: 0.00963061
	LOSS [training: 0.4372742856644709 | validation: 0.5250317449916468]
	TIME [epoch: 6.51 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5089982300075448		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 0.5089982300075448 | validation: 0.5200546116446663]
	TIME [epoch: 6.5 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4353359035943949		[learning rate: 0.0095542]
	Learning Rate: 0.00955415
	LOSS [training: 0.4353359035943949 | validation: 0.5099466022096271]
	TIME [epoch: 6.51 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4430115955416842		[learning rate: 0.0095162]
	Learning Rate: 0.00951616
	LOSS [training: 0.4430115955416842 | validation: 0.4506190759847075]
	TIME [epoch: 6.52 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.46737510171283475		[learning rate: 0.0094783]
	Learning Rate: 0.00947831
	LOSS [training: 0.46737510171283475 | validation: 0.44952369549367743]
	TIME [epoch: 6.51 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.40143899140207895		[learning rate: 0.0094406]
	Learning Rate: 0.00944061
	LOSS [training: 0.40143899140207895 | validation: 0.4295160336398906]
	TIME [epoch: 6.5 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.45594261979710626		[learning rate: 0.0094031]
	Learning Rate: 0.00940306
	LOSS [training: 0.45594261979710626 | validation: 0.44531991057208964]
	TIME [epoch: 6.5 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.49458119321469773		[learning rate: 0.0093657]
	Learning Rate: 0.00936566
	LOSS [training: 0.49458119321469773 | validation: 0.5336059080104741]
	TIME [epoch: 6.51 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5177433875072311		[learning rate: 0.0093284]
	Learning Rate: 0.00932841
	LOSS [training: 0.5177433875072311 | validation: 0.42234212864958354]
	TIME [epoch: 6.5 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v5_20240710_202109/states/model_facs_dec1b_2dpca_v5_62.pth
	Model improved!!!
EPOCH 63/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5193229275767623		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 0.5193229275767623 | validation: 0.5493839646206016]
	TIME [epoch: 6.52 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5065176409271732		[learning rate: 0.0092544]
	Learning Rate: 0.00925435
	LOSS [training: 0.5065176409271732 | validation: 0.5876631788605249]
	TIME [epoch: 6.51 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4900372097975558		[learning rate: 0.0092175]
	Learning Rate: 0.00921755
	LOSS [training: 0.4900372097975558 | validation: 0.4156859170990339]
	TIME [epoch: 6.5 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v5_20240710_202109/states/model_facs_dec1b_2dpca_v5_65.pth
	Model improved!!!
EPOCH 66/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4177943044790934		[learning rate: 0.0091809]
	Learning Rate: 0.00918089
	LOSS [training: 0.4177943044790934 | validation: 0.6245328868814336]
	TIME [epoch: 6.51 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.597383608787686		[learning rate: 0.0091444]
	Learning Rate: 0.00914437
	LOSS [training: 0.597383608787686 | validation: 0.5165625917832355]
	TIME [epoch: 6.5 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.47525643128207906		[learning rate: 0.009108]
	Learning Rate: 0.009108
	LOSS [training: 0.47525643128207906 | validation: 0.4110994478546351]
	TIME [epoch: 6.51 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v5_20240710_202109/states/model_facs_dec1b_2dpca_v5_68.pth
	Model improved!!!
EPOCH 69/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4740084024768183		[learning rate: 0.0090718]
	Learning Rate: 0.00907178
	LOSS [training: 0.4740084024768183 | validation: 0.5192643096367189]
	TIME [epoch: 6.52 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.445230157796914		[learning rate: 0.0090357]
	Learning Rate: 0.00903569
	LOSS [training: 0.445230157796914 | validation: 0.42607332350304594]
	TIME [epoch: 6.51 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4149946558655191		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 0.4149946558655191 | validation: 0.44778473662340545]
	TIME [epoch: 6.51 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.41369444924641124		[learning rate: 0.008964]
	Learning Rate: 0.00896396
	LOSS [training: 0.41369444924641124 | validation: 0.4145989620665634]
	TIME [epoch: 6.5 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5354711877245673		[learning rate: 0.0089283]
	Learning Rate: 0.00892831
	LOSS [training: 0.5354711877245673 | validation: 0.4468111720342427]
	TIME [epoch: 6.5 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5218778221855165		[learning rate: 0.0088928]
	Learning Rate: 0.0088928
	LOSS [training: 0.5218778221855165 | validation: 0.4440882986671852]
	TIME [epoch: 6.5 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.47365934299802454		[learning rate: 0.0088574]
	Learning Rate: 0.00885743
	LOSS [training: 0.47365934299802454 | validation: 0.40480549615996536]
	TIME [epoch: 6.51 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v5_20240710_202109/states/model_facs_dec1b_2dpca_v5_75.pth
	Model improved!!!
EPOCH 76/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3994759692406741		[learning rate: 0.0088222]
	Learning Rate: 0.0088222
	LOSS [training: 0.3994759692406741 | validation: 0.45526223290422807]
	TIME [epoch: 6.52 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4401336313201306		[learning rate: 0.0087871]
	Learning Rate: 0.00878711
	LOSS [training: 0.4401336313201306 | validation: 0.37825010587354624]
	TIME [epoch: 6.5 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v5_20240710_202109/states/model_facs_dec1b_2dpca_v5_77.pth
	Model improved!!!
EPOCH 78/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4744696861260358		[learning rate: 0.0087522]
	Learning Rate: 0.00875216
	LOSS [training: 0.4744696861260358 | validation: 0.5320625970038922]
	TIME [epoch: 6.51 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.40761182183674183		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 0.40761182183674183 | validation: 0.442735736678995]
	TIME [epoch: 6.51 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4691172449713721		[learning rate: 0.0086827]
	Learning Rate: 0.00868268
	LOSS [training: 0.4691172449713721 | validation: 0.40831464556822333]
	TIME [epoch: 6.51 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.39115679861755986		[learning rate: 0.0086481]
	Learning Rate: 0.00864815
	LOSS [training: 0.39115679861755986 | validation: 0.3765582200431873]
	TIME [epoch: 6.5 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v5_20240710_202109/states/model_facs_dec1b_2dpca_v5_81.pth
	Model improved!!!
EPOCH 82/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.41457386998671036		[learning rate: 0.0086138]
	Learning Rate: 0.00861375
	LOSS [training: 0.41457386998671036 | validation: 0.46269690484575293]
	TIME [epoch: 6.53 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4259955385558739		[learning rate: 0.0085795]
	Learning Rate: 0.00857949
	LOSS [training: 0.4259955385558739 | validation: 0.5034566247686291]
	TIME [epoch: 6.51 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.42027668719705524		[learning rate: 0.0085454]
	Learning Rate: 0.00854537
	LOSS [training: 0.42027668719705524 | validation: 0.42418023962610835]
	TIME [epoch: 6.51 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4237299629475602		[learning rate: 0.0085114]
	Learning Rate: 0.00851138
	LOSS [training: 0.4237299629475602 | validation: 0.42291126600925316]
	TIME [epoch: 6.51 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.40415648373149077		[learning rate: 0.0084775]
	Learning Rate: 0.00847753
	LOSS [training: 0.40415648373149077 | validation: 0.38037353759859294]
	TIME [epoch: 6.51 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3884115817598029		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 0.3884115817598029 | validation: 0.4792152264056188]
	TIME [epoch: 6.51 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4262122705352338		[learning rate: 0.0084102]
	Learning Rate: 0.00841023
	LOSS [training: 0.4262122705352338 | validation: 0.40343746104703593]
	TIME [epoch: 6.51 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3947915697613712		[learning rate: 0.0083768]
	Learning Rate: 0.00837678
	LOSS [training: 0.3947915697613712 | validation: 0.4096260086644693]
	TIME [epoch: 6.52 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3782978067919367		[learning rate: 0.0083435]
	Learning Rate: 0.00834346
	LOSS [training: 0.3782978067919367 | validation: 0.41438282407231614]
	TIME [epoch: 6.51 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4142525218821749		[learning rate: 0.0083103]
	Learning Rate: 0.00831027
	LOSS [training: 0.4142525218821749 | validation: 0.3973285445600661]
	TIME [epoch: 6.51 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.425936769216166		[learning rate: 0.0082772]
	Learning Rate: 0.00827722
	LOSS [training: 0.425936769216166 | validation: 0.5224122660343846]
	TIME [epoch: 6.5 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5083696277838974		[learning rate: 0.0082443]
	Learning Rate: 0.0082443
	LOSS [training: 0.5083696277838974 | validation: 0.39896772496153976]
	TIME [epoch: 6.51 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4861997224383096		[learning rate: 0.0082115]
	Learning Rate: 0.00821151
	LOSS [training: 0.4861997224383096 | validation: 0.393480540758954]
	TIME [epoch: 6.51 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.37731480390243866		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 0.37731480390243866 | validation: 0.40356871828467256]
	TIME [epoch: 6.52 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3846201042719224		[learning rate: 0.0081463]
	Learning Rate: 0.00814632
	LOSS [training: 0.3846201042719224 | validation: 0.3762417073313985]
	TIME [epoch: 6.53 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v5_20240710_202109/states/model_facs_dec1b_2dpca_v5_96.pth
	Model improved!!!
EPOCH 97/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3847771841448114		[learning rate: 0.0081139]
	Learning Rate: 0.00811392
	LOSS [training: 0.3847771841448114 | validation: 0.40297744581760203]
	TIME [epoch: 6.58 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3719457683740026		[learning rate: 0.0080816]
	Learning Rate: 0.00808165
	LOSS [training: 0.3719457683740026 | validation: 0.45748706921329063]
	TIME [epoch: 6.58 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.35843077219019687		[learning rate: 0.0080495]
	Learning Rate: 0.00804951
	LOSS [training: 0.35843077219019687 | validation: 0.370753108199502]
	TIME [epoch: 6.58 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v5_20240710_202109/states/model_facs_dec1b_2dpca_v5_99.pth
	Model improved!!!
EPOCH 100/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.39992316334014627		[learning rate: 0.0080175]
	Learning Rate: 0.00801749
	LOSS [training: 0.39992316334014627 | validation: 0.4504232679965986]
	TIME [epoch: 6.57 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3554463628561062		[learning rate: 0.0079856]
	Learning Rate: 0.0079856
	LOSS [training: 0.3554463628561062 | validation: 0.3737414911843163]
	TIME [epoch: 6.59 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.38654976754295156		[learning rate: 0.0079538]
	Learning Rate: 0.00795384
	LOSS [training: 0.38654976754295156 | validation: 0.38891291099847064]
	TIME [epoch: 6.51 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.36940180785858234		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 0.36940180785858234 | validation: 0.37161998601923435]
	TIME [epoch: 6.52 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.35729912027581		[learning rate: 0.0078907]
	Learning Rate: 0.0078907
	LOSS [training: 0.35729912027581 | validation: 0.39694217443208846]
	TIME [epoch: 6.66 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.42199689993233935		[learning rate: 0.0078593]
	Learning Rate: 0.00785931
	LOSS [training: 0.42199689993233935 | validation: 0.37764823601280534]
	TIME [epoch: 6.59 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3698613559900198		[learning rate: 0.0078281]
	Learning Rate: 0.00782805
	LOSS [training: 0.3698613559900198 | validation: 0.37148498014590314]
	TIME [epoch: 6.61 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3814998573430797		[learning rate: 0.0077969]
	Learning Rate: 0.00779692
	LOSS [training: 0.3814998573430797 | validation: 0.3776797643048614]
	TIME [epoch: 6.61 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.38143589146164913		[learning rate: 0.0077659]
	Learning Rate: 0.00776591
	LOSS [training: 0.38143589146164913 | validation: 0.37781037838381776]
	TIME [epoch: 6.6 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.37125583453346805		[learning rate: 0.007735]
	Learning Rate: 0.00773502
	LOSS [training: 0.37125583453346805 | validation: 0.337853006091663]
	TIME [epoch: 6.52 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v5_20240710_202109/states/model_facs_dec1b_2dpca_v5_109.pth
	Model improved!!!
EPOCH 110/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3554631958503966		[learning rate: 0.0077043]
	Learning Rate: 0.00770426
	LOSS [training: 0.3554631958503966 | validation: 0.37828755543324066]
	TIME [epoch: 6.52 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.35650459917661254		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 0.35650459917661254 | validation: 0.3209462725051647]
	TIME [epoch: 6.52 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v5_20240710_202109/states/model_facs_dec1b_2dpca_v5_111.pth
	Model improved!!!
EPOCH 112/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.49733550593498993		[learning rate: 0.0076431]
	Learning Rate: 0.00764309
	LOSS [training: 0.49733550593498993 | validation: 0.45679452246198127]
	TIME [epoch: 6.51 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.48228379922431547		[learning rate: 0.0076127]
	Learning Rate: 0.00761269
	LOSS [training: 0.48228379922431547 | validation: 0.420279737763107]
	TIME [epoch: 6.51 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.37012895933832113		[learning rate: 0.0075824]
	Learning Rate: 0.00758242
	LOSS [training: 0.37012895933832113 | validation: 0.3589468262211695]
	TIME [epoch: 6.52 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3693018351781843		[learning rate: 0.0075523]
	Learning Rate: 0.00755226
	LOSS [training: 0.3693018351781843 | validation: 0.3956317369765401]
	TIME [epoch: 6.51 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3321330138613357		[learning rate: 0.0075222]
	Learning Rate: 0.00752222
	LOSS [training: 0.3321330138613357 | validation: 0.36261248815226854]
	TIME [epoch: 6.51 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.34611311626871566		[learning rate: 0.0074923]
	Learning Rate: 0.0074923
	LOSS [training: 0.34611311626871566 | validation: 0.44623904279294535]
	TIME [epoch: 6.52 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3626761855294287		[learning rate: 0.0074625]
	Learning Rate: 0.0074625
	LOSS [training: 0.3626761855294287 | validation: 0.3961307811194539]
	TIME [epoch: 6.51 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3470010555361062		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 0.3470010555361062 | validation: 0.3449340603028668]
	TIME [epoch: 6.51 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3675171149741276		[learning rate: 0.0074033]
	Learning Rate: 0.00740326
	LOSS [training: 0.3675171149741276 | validation: 0.37294470655222794]
	TIME [epoch: 6.5 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.35644961381772144		[learning rate: 0.0073738]
	Learning Rate: 0.00737382
	LOSS [training: 0.35644961381772144 | validation: 0.4071129781437902]
	TIME [epoch: 6.52 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.35744108532776697		[learning rate: 0.0073445]
	Learning Rate: 0.00734449
	LOSS [training: 0.35744108532776697 | validation: 0.4007620602010623]
	TIME [epoch: 6.5 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3344893569385372		[learning rate: 0.0073153]
	Learning Rate: 0.00731528
	LOSS [training: 0.3344893569385372 | validation: 0.3599528168861303]
	TIME [epoch: 6.51 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.38767048171330487		[learning rate: 0.0072862]
	Learning Rate: 0.00728618
	LOSS [training: 0.38767048171330487 | validation: 0.41792862022087673]
	TIME [epoch: 6.51 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3581518401709707		[learning rate: 0.0072572]
	Learning Rate: 0.0072572
	LOSS [training: 0.3581518401709707 | validation: 0.3457931547027197]
	TIME [epoch: 6.51 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.33981772360071816		[learning rate: 0.0072283]
	Learning Rate: 0.00722834
	LOSS [training: 0.33981772360071816 | validation: 0.3772801793683286]
	TIME [epoch: 6.5 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.35187959808143376		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 0.35187959808143376 | validation: 0.35254955095054175]
	TIME [epoch: 6.51 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3539717446219188		[learning rate: 0.007171]
	Learning Rate: 0.00717095
	LOSS [training: 0.3539717446219188 | validation: 0.3351846387036483]
	TIME [epoch: 6.51 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.34328128100033034		[learning rate: 0.0071424]
	Learning Rate: 0.00714243
	LOSS [training: 0.34328128100033034 | validation: 0.41051360659106156]
	TIME [epoch: 6.5 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.36809224326297196		[learning rate: 0.007114]
	Learning Rate: 0.00711403
	LOSS [training: 0.36809224326297196 | validation: 0.3586819032976001]
	TIME [epoch: 6.51 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.36033973674098696		[learning rate: 0.0070857]
	Learning Rate: 0.00708573
	LOSS [training: 0.36033973674098696 | validation: 0.36127162162903914]
	TIME [epoch: 6.5 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.35440784791336116		[learning rate: 0.0070575]
	Learning Rate: 0.00705755
	LOSS [training: 0.35440784791336116 | validation: 0.35532635740200036]
	TIME [epoch: 6.5 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3335080063214009		[learning rate: 0.0070295]
	Learning Rate: 0.00702948
	LOSS [training: 0.3335080063214009 | validation: 0.36487685775971374]
	TIME [epoch: 6.51 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3449990972140591		[learning rate: 0.0070015]
	Learning Rate: 0.00700152
	LOSS [training: 0.3449990972140591 | validation: 0.38243659439866756]
	TIME [epoch: 6.52 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.33664231179019516		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 0.33664231179019516 | validation: 0.36598621500771733]
	TIME [epoch: 6.51 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.35322813684135634		[learning rate: 0.0069459]
	Learning Rate: 0.00694594
	LOSS [training: 0.35322813684135634 | validation: 0.4276777858845679]
	TIME [epoch: 6.5 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4842276645700493		[learning rate: 0.0069183]
	Learning Rate: 0.00691831
	LOSS [training: 0.4842276645700493 | validation: 0.4302014775195124]
	TIME [epoch: 6.5 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.49374895602543745		[learning rate: 0.0068908]
	Learning Rate: 0.00689079
	LOSS [training: 0.49374895602543745 | validation: 0.39169273886629363]
	TIME [epoch: 6.51 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.44215308020677857		[learning rate: 0.0068634]
	Learning Rate: 0.00686339
	LOSS [training: 0.44215308020677857 | validation: 0.3705048001433441]
	TIME [epoch: 6.51 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4450586784026258		[learning rate: 0.0068361]
	Learning Rate: 0.00683609
	LOSS [training: 0.4450586784026258 | validation: 0.37183292334097495]
	TIME [epoch: 6.52 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.43442778936423054		[learning rate: 0.0068089]
	Learning Rate: 0.0068089
	LOSS [training: 0.43442778936423054 | validation: 0.4334250370776641]
	TIME [epoch: 6.51 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.40203272365700937		[learning rate: 0.0067818]
	Learning Rate: 0.00678182
	LOSS [training: 0.40203272365700937 | validation: 0.3419136750940786]
	TIME [epoch: 6.5 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3825456419082346		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 0.3825456419082346 | validation: 0.378674133762526]
	TIME [epoch: 6.51 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.35922687670719716		[learning rate: 0.006728]
	Learning Rate: 0.00672798
	LOSS [training: 0.35922687670719716 | validation: 0.37215719354676546]
	TIME [epoch: 6.5 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.35233341377427757		[learning rate: 0.0067012]
	Learning Rate: 0.00670122
	LOSS [training: 0.35233341377427757 | validation: 0.34216110000485167]
	TIME [epoch: 6.5 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.375917396769206		[learning rate: 0.0066746]
	Learning Rate: 0.00667457
	LOSS [training: 0.375917396769206 | validation: 0.3463266602278564]
	TIME [epoch: 6.52 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3511262936044525		[learning rate: 0.006648]
	Learning Rate: 0.00664802
	LOSS [training: 0.3511262936044525 | validation: 0.33371147797719763]
	TIME [epoch: 6.51 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3416935767744417		[learning rate: 0.0066216]
	Learning Rate: 0.00662158
	LOSS [training: 0.3416935767744417 | validation: 0.3350889394686928]
	TIME [epoch: 6.51 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.38148216178037647		[learning rate: 0.0065952]
	Learning Rate: 0.00659524
	LOSS [training: 0.38148216178037647 | validation: 0.40256589649924396]
	TIME [epoch: 6.51 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.370684466950163		[learning rate: 0.006569]
	Learning Rate: 0.00656901
	LOSS [training: 0.370684466950163 | validation: 0.3118886564372857]
	TIME [epoch: 6.5 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v5_20240710_202109/states/model_facs_dec1b_2dpca_v5_150.pth
	Model improved!!!
EPOCH 151/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3322602988727485		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 0.3322602988727485 | validation: 0.34460910030943764]
	TIME [epoch: 6.51 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3481889379486352		[learning rate: 0.0065169]
	Learning Rate: 0.00651686
	LOSS [training: 0.3481889379486352 | validation: 0.3298366559375567]
	TIME [epoch: 6.51 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3287038616252247		[learning rate: 0.0064909]
	Learning Rate: 0.00649094
	LOSS [training: 0.3287038616252247 | validation: 0.38356916600416724]
	TIME [epoch: 6.53 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.36313261711914546		[learning rate: 0.0064651]
	Learning Rate: 0.00646512
	LOSS [training: 0.36313261711914546 | validation: 0.41439390097429385]
	TIME [epoch: 6.51 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3316615445177135		[learning rate: 0.0064394]
	Learning Rate: 0.00643941
	LOSS [training: 0.3316615445177135 | validation: 0.3385664043653892]
	TIME [epoch: 6.51 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.36760860712332794		[learning rate: 0.0064138]
	Learning Rate: 0.0064138
	LOSS [training: 0.36760860712332794 | validation: 0.3194461517160397]
	TIME [epoch: 6.51 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32299152218100047		[learning rate: 0.0063883]
	Learning Rate: 0.00638829
	LOSS [training: 0.32299152218100047 | validation: 0.3457932424897462]
	TIME [epoch: 6.51 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.36484784195971126		[learning rate: 0.0063629]
	Learning Rate: 0.00636288
	LOSS [training: 0.36484784195971126 | validation: 0.33531580772848674]
	TIME [epoch: 6.5 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3322866428782615		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 0.3322866428782615 | validation: 0.36932428645424886]
	TIME [epoch: 6.51 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.331581954300197		[learning rate: 0.0063124]
	Learning Rate: 0.00631237
	LOSS [training: 0.331581954300197 | validation: 0.3144600485222705]
	TIME [epoch: 6.52 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3570069943816093		[learning rate: 0.0062873]
	Learning Rate: 0.00628726
	LOSS [training: 0.3570069943816093 | validation: 0.44243579554052526]
	TIME [epoch: 6.51 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.35305739425083604		[learning rate: 0.0062623]
	Learning Rate: 0.00626226
	LOSS [training: 0.35305739425083604 | validation: 0.3572774458081812]
	TIME [epoch: 6.5 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.35099408419937494		[learning rate: 0.0062373]
	Learning Rate: 0.00623735
	LOSS [training: 0.35099408419937494 | validation: 0.32599080909171557]
	TIME [epoch: 6.5 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32686099138715335		[learning rate: 0.0062125]
	Learning Rate: 0.00621254
	LOSS [training: 0.32686099138715335 | validation: 0.3601888155849199]
	TIME [epoch: 6.5 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3514216283492528		[learning rate: 0.0061878]
	Learning Rate: 0.00618783
	LOSS [training: 0.3514216283492528 | validation: 0.39758856571342155]
	TIME [epoch: 6.51 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3900570310613649		[learning rate: 0.0061632]
	Learning Rate: 0.00616322
	LOSS [training: 0.3900570310613649 | validation: 0.3541190137521847]
	TIME [epoch: 6.52 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3449253470775966		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 0.3449253470775966 | validation: 0.3205445486191518]
	TIME [epoch: 6.51 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3200338385843794		[learning rate: 0.0061143]
	Learning Rate: 0.00611429
	LOSS [training: 0.3200338385843794 | validation: 0.3189134502061699]
	TIME [epoch: 6.51 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4149259040551486		[learning rate: 0.00609]
	Learning Rate: 0.00608997
	LOSS [training: 0.4149259040551486 | validation: 0.3536513638931894]
	TIME [epoch: 6.51 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3235375267101394		[learning rate: 0.0060658]
	Learning Rate: 0.00606575
	LOSS [training: 0.3235375267101394 | validation: 0.4022104544921682]
	TIME [epoch: 6.5 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32175088881539265		[learning rate: 0.0060416]
	Learning Rate: 0.00604163
	LOSS [training: 0.32175088881539265 | validation: 0.3080213593696734]
	TIME [epoch: 6.51 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v5_20240710_202109/states/model_facs_dec1b_2dpca_v5_171.pth
	Model improved!!!
EPOCH 172/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3154875291620616		[learning rate: 0.0060176]
	Learning Rate: 0.0060176
	LOSS [training: 0.3154875291620616 | validation: 0.34201748282863165]
	TIME [epoch: 6.53 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.31413435928081507		[learning rate: 0.0059937]
	Learning Rate: 0.00599366
	LOSS [training: 0.31413435928081507 | validation: 0.386194102720851]
	TIME [epoch: 6.52 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.31831636505253835		[learning rate: 0.0059698]
	Learning Rate: 0.00596982
	LOSS [training: 0.31831636505253835 | validation: 0.33401201592925]
	TIME [epoch: 6.51 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.30340498299984875		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 0.30340498299984875 | validation: 0.334732801607618]
	TIME [epoch: 6.52 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.34381563889853084		[learning rate: 0.0059224]
	Learning Rate: 0.00592243
	LOSS [training: 0.34381563889853084 | validation: 0.29608956852162843]
	TIME [epoch: 6.52 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v5_20240710_202109/states/model_facs_dec1b_2dpca_v5_176.pth
	Model improved!!!
EPOCH 177/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3176944240942745		[learning rate: 0.0058989]
	Learning Rate: 0.00589888
	LOSS [training: 0.3176944240942745 | validation: 0.3425990738608269]
	TIME [epoch: 6.51 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32367510433078484		[learning rate: 0.0058754]
	Learning Rate: 0.00587541
	LOSS [training: 0.32367510433078484 | validation: 0.32641028160556296]
	TIME [epoch: 6.51 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3666874933539556		[learning rate: 0.005852]
	Learning Rate: 0.00585205
	LOSS [training: 0.3666874933539556 | validation: 0.33168426137138923]
	TIME [epoch: 6.52 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3190412262931633		[learning rate: 0.0058288]
	Learning Rate: 0.00582877
	LOSS [training: 0.3190412262931633 | validation: 0.3146503528874397]
	TIME [epoch: 6.51 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3276022688274606		[learning rate: 0.0058056]
	Learning Rate: 0.00580559
	LOSS [training: 0.3276022688274606 | validation: 0.3649527410875408]
	TIME [epoch: 6.51 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.30636493060052666		[learning rate: 0.0057825]
	Learning Rate: 0.0057825
	LOSS [training: 0.30636493060052666 | validation: 0.3189767924519685]
	TIME [epoch: 6.52 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3282050296157721		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 0.3282050296157721 | validation: 0.36158168951080716]
	TIME [epoch: 6.51 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3198059758920595		[learning rate: 0.0057366]
	Learning Rate: 0.00573659
	LOSS [training: 0.3198059758920595 | validation: 0.40462823412831933]
	TIME [epoch: 6.51 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3986913805436187		[learning rate: 0.0057138]
	Learning Rate: 0.00571377
	LOSS [training: 0.3986913805436187 | validation: 0.49436052035576983]
	TIME [epoch: 6.52 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.35235655986104597		[learning rate: 0.005691]
	Learning Rate: 0.00569105
	LOSS [training: 0.35235655986104597 | validation: 0.33334955064396127]
	TIME [epoch: 6.53 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.36959000230552297		[learning rate: 0.0056684]
	Learning Rate: 0.00566841
	LOSS [training: 0.36959000230552297 | validation: 0.33074397639960373]
	TIME [epoch: 6.52 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32042614834467353		[learning rate: 0.0056459]
	Learning Rate: 0.00564587
	LOSS [training: 0.32042614834467353 | validation: 0.3111257294708354]
	TIME [epoch: 6.51 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3146037515442671		[learning rate: 0.0056234]
	Learning Rate: 0.00562341
	LOSS [training: 0.3146037515442671 | validation: 0.3130651916448048]
	TIME [epoch: 6.51 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.31564750825833543		[learning rate: 0.005601]
	Learning Rate: 0.00560105
	LOSS [training: 0.31564750825833543 | validation: 0.3192503353399087]
	TIME [epoch: 6.51 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3109216420149274		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 0.3109216420149274 | validation: 0.32188724339278646]
	TIME [epoch: 6.51 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.41144183739526813		[learning rate: 0.0055566]
	Learning Rate: 0.00555658
	LOSS [training: 0.41144183739526813 | validation: 0.37867083870838225]
	TIME [epoch: 6.52 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.33779724232559555		[learning rate: 0.0055345]
	Learning Rate: 0.00553448
	LOSS [training: 0.33779724232559555 | validation: 0.35723144062556206]
	TIME [epoch: 6.52 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3328148353701267		[learning rate: 0.0055125]
	Learning Rate: 0.00551247
	LOSS [training: 0.3328148353701267 | validation: 0.3184378801562603]
	TIME [epoch: 6.51 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32443476199418564		[learning rate: 0.0054905]
	Learning Rate: 0.00549054
	LOSS [training: 0.32443476199418564 | validation: 0.37115502005345025]
	TIME [epoch: 6.51 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3167107585119892		[learning rate: 0.0054687]
	Learning Rate: 0.00546871
	LOSS [training: 0.3167107585119892 | validation: 0.32573967997999187]
	TIME [epoch: 6.51 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3334715848842317		[learning rate: 0.005447]
	Learning Rate: 0.00544696
	LOSS [training: 0.3334715848842317 | validation: 0.3349182187570176]
	TIME [epoch: 6.51 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3076100293849224		[learning rate: 0.0054253]
	Learning Rate: 0.00542529
	LOSS [training: 0.3076100293849224 | validation: 0.40566163828461993]
	TIME [epoch: 6.51 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 9/9] avg loss: 2.4962509620350075		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 2.4962509620350075 | validation: 2.8261451208576966]
	TIME [epoch: 6.52 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.4112823938807315		[learning rate: 0.0053822]
	Learning Rate: 0.00538222
	LOSS [training: 1.4112823938807315 | validation: 0.4906185523947352]
	TIME [epoch: 6.51 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5686630176946067		[learning rate: 0.0053608]
	Learning Rate: 0.00536081
	LOSS [training: 0.5686630176946067 | validation: 0.42849177040175135]
	TIME [epoch: 6.51 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.48539117406299087		[learning rate: 0.0053395]
	Learning Rate: 0.00533949
	LOSS [training: 0.48539117406299087 | validation: 0.3841172555624924]
	TIME [epoch: 6.51 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.36666666525595754		[learning rate: 0.0053183]
	Learning Rate: 0.00531826
	LOSS [training: 0.36666666525595754 | validation: 0.3732648040082455]
	TIME [epoch: 6.51 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3343083813947955		[learning rate: 0.0052971]
	Learning Rate: 0.0052971
	LOSS [training: 0.3343083813947955 | validation: 0.35076149421145164]
	TIME [epoch: 6.5 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.33088915837288707		[learning rate: 0.005276]
	Learning Rate: 0.00527604
	LOSS [training: 0.33088915837288707 | validation: 0.39347920772545464]
	TIME [epoch: 6.52 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32646262116789304		[learning rate: 0.0052551]
	Learning Rate: 0.00525505
	LOSS [training: 0.32646262116789304 | validation: 0.34701902711425997]
	TIME [epoch: 6.51 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.30704278042276767		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 0.30704278042276767 | validation: 0.3313254741646458]
	TIME [epoch: 6.51 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3075598645323024		[learning rate: 0.0052133]
	Learning Rate: 0.00521333
	LOSS [training: 0.3075598645323024 | validation: 0.32003209752462625]
	TIME [epoch: 6.51 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3368759276541375		[learning rate: 0.0051926]
	Learning Rate: 0.0051926
	LOSS [training: 0.3368759276541375 | validation: 0.3331129107078306]
	TIME [epoch: 6.51 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.29597950328894135		[learning rate: 0.0051719]
	Learning Rate: 0.00517194
	LOSS [training: 0.29597950328894135 | validation: 0.3539567471205783]
	TIME [epoch: 6.51 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32466824190389587		[learning rate: 0.0051514]
	Learning Rate: 0.00515137
	LOSS [training: 0.32466824190389587 | validation: 0.3708561319388662]
	TIME [epoch: 6.51 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3033673236835814		[learning rate: 0.0051309]
	Learning Rate: 0.00513089
	LOSS [training: 0.3033673236835814 | validation: 0.3319589786590903]
	TIME [epoch: 6.52 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.397573607195425		[learning rate: 0.0051105]
	Learning Rate: 0.00511048
	LOSS [training: 1.397573607195425 | validation: 3.0248990353437106]
	TIME [epoch: 6.51 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.9529685035837612		[learning rate: 0.0050902]
	Learning Rate: 0.00509015
	LOSS [training: 1.9529685035837612 | validation: 2.6997482560230153]
	TIME [epoch: 6.51 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 9/9] avg loss: 3.089210138207281		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 3.089210138207281 | validation: 2.0044839842557445]
	TIME [epoch: 6.5 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 9/9] avg loss: 2.102292587385935		[learning rate: 0.0050497]
	Learning Rate: 0.00504974
	LOSS [training: 2.102292587385935 | validation: 1.1592783304978407]
	TIME [epoch: 6.51 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.8428423393731329		[learning rate: 0.0050297]
	Learning Rate: 0.00502966
	LOSS [training: 0.8428423393731329 | validation: 0.5856945673286195]
	TIME [epoch: 6.51 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5070856806162545		[learning rate: 0.0050097]
	Learning Rate: 0.00500965
	LOSS [training: 0.5070856806162545 | validation: 0.4605098606837374]
	TIME [epoch: 6.51 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5680775253633498		[learning rate: 0.0049897]
	Learning Rate: 0.00498973
	LOSS [training: 0.5680775253633498 | validation: 0.4969062672278916]
	TIME [epoch: 6.52 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3762391998128894		[learning rate: 0.0049699]
	Learning Rate: 0.00496988
	LOSS [training: 0.3762391998128894 | validation: 0.34287969908879734]
	TIME [epoch: 6.52 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32441870620873153		[learning rate: 0.0049501]
	Learning Rate: 0.00495012
	LOSS [training: 0.32441870620873153 | validation: 0.3309804712424412]
	TIME [epoch: 6.5 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.31188938998812576		[learning rate: 0.0049304]
	Learning Rate: 0.00493043
	LOSS [training: 0.31188938998812576 | validation: 0.3136602117124289]
	TIME [epoch: 6.51 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.28945672323676036		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 0.28945672323676036 | validation: 0.3123176450564135]
	TIME [epoch: 6.51 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3096319997372742		[learning rate: 0.0048913]
	Learning Rate: 0.00489129
	LOSS [training: 0.3096319997372742 | validation: 0.3132111182172678]
	TIME [epoch: 6.52 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.30033354713356036		[learning rate: 0.0048718]
	Learning Rate: 0.00487183
	LOSS [training: 0.30033354713356036 | validation: 0.30034953437177514]
	TIME [epoch: 6.52 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.30495405608541987		[learning rate: 0.0048525]
	Learning Rate: 0.00485245
	LOSS [training: 0.30495405608541987 | validation: 0.3176326902075868]
	TIME [epoch: 6.51 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.36963125855081086		[learning rate: 0.0048332]
	Learning Rate: 0.00483316
	LOSS [training: 0.36963125855081086 | validation: 0.38904127764672464]
	TIME [epoch: 6.51 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3465774819244016		[learning rate: 0.0048139]
	Learning Rate: 0.00481393
	LOSS [training: 0.3465774819244016 | validation: 0.32812085724834705]
	TIME [epoch: 6.51 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3164701190793876		[learning rate: 0.0047948]
	Learning Rate: 0.00479479
	LOSS [training: 0.3164701190793876 | validation: 0.2939356677152199]
	TIME [epoch: 6.51 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v5_20240710_202109/states/model_facs_dec1b_2dpca_v5_229.pth
	Model improved!!!
EPOCH 230/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.31731797844840515		[learning rate: 0.0047757]
	Learning Rate: 0.00477572
	LOSS [training: 0.31731797844840515 | validation: 0.3325554452303409]
	TIME [epoch: 6.51 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.332154171801369		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.332154171801369 | validation: 0.3610299153652564]
	TIME [epoch: 6.53 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3263038180326052		[learning rate: 0.0047378]
	Learning Rate: 0.0047378
	LOSS [training: 0.3263038180326052 | validation: 0.29447763933121185]
	TIME [epoch: 6.5 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.31518628163383416		[learning rate: 0.004719]
	Learning Rate: 0.00471896
	LOSS [training: 0.31518628163383416 | validation: 0.30507641942023495]
	TIME [epoch: 6.51 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3040416142241271		[learning rate: 0.0047002]
	Learning Rate: 0.00470019
	LOSS [training: 0.3040416142241271 | validation: 0.319607087256474]
	TIME [epoch: 6.51 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32731772146882276		[learning rate: 0.0046815]
	Learning Rate: 0.0046815
	LOSS [training: 0.32731772146882276 | validation: 0.30559914963930446]
	TIME [epoch: 6.51 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.31563813942726743		[learning rate: 0.0046629]
	Learning Rate: 0.00466288
	LOSS [training: 0.31563813942726743 | validation: 0.30910873304379244]
	TIME [epoch: 6.5 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32420039909678144		[learning rate: 0.0046443]
	Learning Rate: 0.00464433
	LOSS [training: 0.32420039909678144 | validation: 0.3179387142905034]
	TIME [epoch: 6.51 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.30916405537542896		[learning rate: 0.0046259]
	Learning Rate: 0.00462586
	LOSS [training: 0.30916405537542896 | validation: 0.3036451766350071]
	TIME [epoch: 6.52 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3250420715371149		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 0.3250420715371149 | validation: 0.3124816338361122]
	TIME [epoch: 6.52 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.30487182271450197		[learning rate: 0.0045891]
	Learning Rate: 0.00458913
	LOSS [training: 0.30487182271450197 | validation: 0.36319134209830295]
	TIME [epoch: 6.5 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.31008835540976365		[learning rate: 0.0045709]
	Learning Rate: 0.00457088
	LOSS [training: 0.31008835540976365 | validation: 0.30433781955600364]
	TIME [epoch: 6.51 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.31294937076018087		[learning rate: 0.0045527]
	Learning Rate: 0.0045527
	LOSS [training: 0.31294937076018087 | validation: 0.3027249739204104]
	TIME [epoch: 6.5 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3060126168304239		[learning rate: 0.0045346]
	Learning Rate: 0.00453459
	LOSS [training: 0.3060126168304239 | validation: 0.29226922222007606]
	TIME [epoch: 6.51 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v5_20240710_202109/states/model_facs_dec1b_2dpca_v5_243.pth
	Model improved!!!
EPOCH 244/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2803235530527548		[learning rate: 0.0045166]
	Learning Rate: 0.00451656
	LOSS [training: 0.2803235530527548 | validation: 0.300111667389675]
	TIME [epoch: 6.52 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3173242249108317		[learning rate: 0.0044986]
	Learning Rate: 0.0044986
	LOSS [training: 0.3173242249108317 | validation: 0.27144129584227256]
	TIME [epoch: 6.51 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v5_20240710_202109/states/model_facs_dec1b_2dpca_v5_245.pth
	Model improved!!!
EPOCH 246/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.30685976343982196		[learning rate: 0.0044807]
	Learning Rate: 0.0044807
	LOSS [training: 0.30685976343982196 | validation: 0.3044737580414579]
	TIME [epoch: 6.51 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3086876981127511		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 0.3086876981127511 | validation: 0.3346270121695083]
	TIME [epoch: 6.51 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3197082698242853		[learning rate: 0.0044451]
	Learning Rate: 0.00444513
	LOSS [training: 0.3197082698242853 | validation: 0.3180858608128295]
	TIME [epoch: 6.51 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.29748616890963403		[learning rate: 0.0044275]
	Learning Rate: 0.00442745
	LOSS [training: 0.29748616890963403 | validation: 0.3201574563475952]
	TIME [epoch: 6.51 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3175684621872374		[learning rate: 0.0044098]
	Learning Rate: 0.00440984
	LOSS [training: 0.3175684621872374 | validation: 0.3440743083527912]
	TIME [epoch: 6.5 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.29979104750337005		[learning rate: 0.0043923]
	Learning Rate: 0.0043923
	LOSS [training: 0.29979104750337005 | validation: 0.2741897250859149]
	TIME [epoch: 6.52 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2960120836586804		[learning rate: 0.0043748]
	Learning Rate: 0.00437483
	LOSS [training: 0.2960120836586804 | validation: 0.3265185082746427]
	TIME [epoch: 6.52 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.29700504521749527		[learning rate: 0.0043574]
	Learning Rate: 0.00435743
	LOSS [training: 0.29700504521749527 | validation: 0.30180247827754425]
	TIME [epoch: 6.51 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.29432765309842895		[learning rate: 0.0043401]
	Learning Rate: 0.0043401
	LOSS [training: 0.29432765309842895 | validation: 0.3060239780945805]
	TIME [epoch: 6.51 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3053807609604148		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 0.3053807609604148 | validation: 0.30726422385042856]
	TIME [epoch: 6.51 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2833313759467593		[learning rate: 0.0043056]
	Learning Rate: 0.00430565
	LOSS [training: 0.2833313759467593 | validation: 0.3825912508657949]
	TIME [epoch: 6.51 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3150297137537306		[learning rate: 0.0042885]
	Learning Rate: 0.00428852
	LOSS [training: 0.3150297137537306 | validation: 0.3626482032882796]
	TIME [epoch: 6.51 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2896738856440421		[learning rate: 0.0042715]
	Learning Rate: 0.00427147
	LOSS [training: 0.2896738856440421 | validation: 0.31553510987190636]
	TIME [epoch: 6.52 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2908587256292155		[learning rate: 0.0042545]
	Learning Rate: 0.00425448
	LOSS [training: 0.2908587256292155 | validation: 0.32421220802390976]
	TIME [epoch: 6.51 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32492267380028644		[learning rate: 0.0042376]
	Learning Rate: 0.00423756
	LOSS [training: 0.32492267380028644 | validation: 0.35000553326488587]
	TIME [epoch: 6.52 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3088826255585437		[learning rate: 0.0042207]
	Learning Rate: 0.0042207
	LOSS [training: 0.3088826255585437 | validation: 0.3276187434906001]
	TIME [epoch: 6.51 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2895285592278065		[learning rate: 0.0042039]
	Learning Rate: 0.00420391
	LOSS [training: 0.2895285592278065 | validation: 0.29601747150452856]
	TIME [epoch: 6.51 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.27034167949016047		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 0.27034167949016047 | validation: 0.325004117641266]
	TIME [epoch: 6.5 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.29562301848717903		[learning rate: 0.0041705]
	Learning Rate: 0.00417054
	LOSS [training: 0.29562301848717903 | validation: 0.30932849937358353]
	TIME [epoch: 6.52 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.29531877264764145		[learning rate: 0.004154]
	Learning Rate: 0.00415395
	LOSS [training: 0.29531877264764145 | validation: 0.3124803484775393]
	TIME [epoch: 6.51 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.30446592082632457		[learning rate: 0.0041374]
	Learning Rate: 0.00413743
	LOSS [training: 0.30446592082632457 | validation: 0.3217741462670173]
	TIME [epoch: 6.51 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2904324629927292		[learning rate: 0.004121]
	Learning Rate: 0.00412098
	LOSS [training: 0.2904324629927292 | validation: 0.3031922065706477]
	TIME [epoch: 6.52 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4187517235619879		[learning rate: 0.0041046]
	Learning Rate: 0.00410458
	LOSS [training: 0.4187517235619879 | validation: 1.4658761582568047]
	TIME [epoch: 6.51 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.6887647813749356		[learning rate: 0.0040883]
	Learning Rate: 0.00408826
	LOSS [training: 1.6887647813749356 | validation: 1.7059638620556945]
	TIME [epoch: 6.51 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.1812924200239734		[learning rate: 0.004072]
	Learning Rate: 0.004072
	LOSS [training: 1.1812924200239734 | validation: 0.8750350057151101]
	TIME [epoch: 6.51 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.8230768734643162		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.8230768734643162 | validation: 0.5173180892111434]
	TIME [epoch: 6.52 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.44983672801658897		[learning rate: 0.0040397]
	Learning Rate: 0.00403967
	LOSS [training: 0.44983672801658897 | validation: 0.3538774524832962]
	TIME [epoch: 6.51 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.33607268335692225		[learning rate: 0.0040236]
	Learning Rate: 0.00402361
	LOSS [training: 0.33607268335692225 | validation: 0.29057852752822433]
	TIME [epoch: 6.5 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.29185269471592185		[learning rate: 0.0040076]
	Learning Rate: 0.0040076
	LOSS [training: 0.29185269471592185 | validation: 0.28967418811439577]
	TIME [epoch: 6.5 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.30992574710233456		[learning rate: 0.0039917]
	Learning Rate: 0.00399166
	LOSS [training: 0.30992574710233456 | validation: 0.2993544462527599]
	TIME [epoch: 6.51 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2854568194213831		[learning rate: 0.0039758]
	Learning Rate: 0.00397579
	LOSS [training: 0.2854568194213831 | validation: 0.33426949715052956]
	TIME [epoch: 6.5 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3137698432568625		[learning rate: 0.00396]
	Learning Rate: 0.00395997
	LOSS [training: 0.3137698432568625 | validation: 0.3096966718079017]
	TIME [epoch: 6.52 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2977330051276159		[learning rate: 0.0039442]
	Learning Rate: 0.00394422
	LOSS [training: 0.2977330051276159 | validation: 0.2964252179295152]
	TIME [epoch: 6.51 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2896445049857738		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 0.2896445049857738 | validation: 0.3020446290953346]
	TIME [epoch: 6.51 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2800927697195579		[learning rate: 0.0039129]
	Learning Rate: 0.00391291
	LOSS [training: 0.2800927697195579 | validation: 0.3458533008678086]
	TIME [epoch: 6.51 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2892837025456976		[learning rate: 0.0038973]
	Learning Rate: 0.00389735
	LOSS [training: 0.2892837025456976 | validation: 0.3656564574815747]
	TIME [epoch: 6.5 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3016555920358084		[learning rate: 0.0038818]
	Learning Rate: 0.00388185
	LOSS [training: 0.3016555920358084 | validation: 0.34011514062523424]
	TIME [epoch: 6.51 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2939422332192836		[learning rate: 0.0038664]
	Learning Rate: 0.00386641
	LOSS [training: 0.2939422332192836 | validation: 0.3144940926660521]
	TIME [epoch: 6.52 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.28824264661988		[learning rate: 0.003851]
	Learning Rate: 0.00385103
	LOSS [training: 0.28824264661988 | validation: 0.3156797876771158]
	TIME [epoch: 6.51 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2914649186200742		[learning rate: 0.0038357]
	Learning Rate: 0.00383571
	LOSS [training: 0.2914649186200742 | validation: 0.30878764777759005]
	TIME [epoch: 6.5 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.283989313378158		[learning rate: 0.0038205]
	Learning Rate: 0.00382046
	LOSS [training: 0.283989313378158 | validation: 0.3036290115962213]
	TIME [epoch: 6.51 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3711180150895751		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 0.3711180150895751 | validation: 0.40343924173646173]
	TIME [epoch: 6.51 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.34398447930042064		[learning rate: 0.0037901]
	Learning Rate: 0.00379013
	LOSS [training: 0.34398447930042064 | validation: 0.3548074958419081]
	TIME [epoch: 6.51 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.43235346336327835		[learning rate: 0.0037751]
	Learning Rate: 0.00377505
	LOSS [training: 0.43235346336327835 | validation: 0.3264493442512447]
	TIME [epoch: 6.5 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.31993701065048086		[learning rate: 0.00376]
	Learning Rate: 0.00376004
	LOSS [training: 0.31993701065048086 | validation: 0.3071117520487604]
	TIME [epoch: 6.52 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3039842183034456		[learning rate: 0.0037451]
	Learning Rate: 0.00374508
	LOSS [training: 0.3039842183034456 | validation: 0.336311512884544]
	TIME [epoch: 6.51 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3234481536398604		[learning rate: 0.0037302]
	Learning Rate: 0.00373019
	LOSS [training: 0.3234481536398604 | validation: 0.3506542709516771]
	TIME [epoch: 6.5 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3067721136607855		[learning rate: 0.0037154]
	Learning Rate: 0.00371535
	LOSS [training: 0.3067721136607855 | validation: 0.33920273280866936]
	TIME [epoch: 6.5 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.29436560142455837		[learning rate: 0.0037006]
	Learning Rate: 0.00370058
	LOSS [training: 0.29436560142455837 | validation: 0.29684136068245515]
	TIME [epoch: 6.5 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2868243935666558		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 0.2868243935666558 | validation: 0.30571411870070003]
	TIME [epoch: 6.51 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2861968597682915		[learning rate: 0.0036712]
	Learning Rate: 0.0036712
	LOSS [training: 0.2861968597682915 | validation: 0.29526548234527306]
	TIME [epoch: 6.52 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2837249949439636		[learning rate: 0.0036566]
	Learning Rate: 0.0036566
	LOSS [training: 0.2837249949439636 | validation: 0.3248316954585486]
	TIME [epoch: 6.51 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.27980052679466616		[learning rate: 0.0036421]
	Learning Rate: 0.00364205
	LOSS [training: 0.27980052679466616 | validation: 0.3277112932819642]
	TIME [epoch: 6.51 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.27445887091698773		[learning rate: 0.0036276]
	Learning Rate: 0.00362757
	LOSS [training: 0.27445887091698773 | validation: 0.32976570125953797]
	TIME [epoch: 6.51 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.530427553971519		[learning rate: 0.0036131]
	Learning Rate: 0.00361314
	LOSS [training: 0.530427553971519 | validation: 2.9708804109110036]
	TIME [epoch: 6.5 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 9/9] avg loss: 3.277912986928973		[learning rate: 0.0035988]
	Learning Rate: 0.00359877
	LOSS [training: 3.277912986928973 | validation: 3.913563409471023]
	TIME [epoch: 6.5 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 9/9] avg loss: 3.2320939172309764		[learning rate: 0.0035845]
	Learning Rate: 0.00358445
	LOSS [training: 3.2320939172309764 | validation: 1.724232746001137]
	TIME [epoch: 6.51 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.3324899617930501		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 1.3324899617930501 | validation: 1.250762523278019]
	TIME [epoch: 6.51 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.0527290517153327		[learning rate: 0.003556]
	Learning Rate: 0.003556
	LOSS [training: 1.0527290517153327 | validation: 1.4313049066054195]
	TIME [epoch: 6.51 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.5132080095195142		[learning rate: 0.0035419]
	Learning Rate: 0.00354185
	LOSS [training: 1.5132080095195142 | validation: 0.8963991210967379]
	TIME [epoch: 6.53 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.9346038195581676		[learning rate: 0.0035278]
	Learning Rate: 0.00352777
	LOSS [training: 0.9346038195581676 | validation: 0.8985265349541252]
	TIME [epoch: 6.52 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.027145822048923		[learning rate: 0.0035137]
	Learning Rate: 0.00351374
	LOSS [training: 1.027145822048923 | validation: 0.8486105907732032]
	TIME [epoch: 6.51 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6964997238556068		[learning rate: 0.0034998]
	Learning Rate: 0.00349976
	LOSS [training: 0.6964997238556068 | validation: 0.6138968696435996]
	TIME [epoch: 6.5 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5453718606162812		[learning rate: 0.0034858]
	Learning Rate: 0.00348584
	LOSS [training: 0.5453718606162812 | validation: 0.5027821136196586]
	TIME [epoch: 6.51 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6609223332140002		[learning rate: 0.003472]
	Learning Rate: 0.00347198
	LOSS [training: 0.6609223332140002 | validation: 1.9651959392025233]
	TIME [epoch: 6.51 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.995725932701645		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 1.995725932701645 | validation: 3.154073218633946]
	TIME [epoch: 6.5 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 9/9] avg loss: 2.987564966775766		[learning rate: 0.0034444]
	Learning Rate: 0.00344441
	LOSS [training: 2.987564966775766 | validation: 3.2018574767082866]
	TIME [epoch: 6.51 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 9/9] avg loss: 2.5752274601515857		[learning rate: 0.0034307]
	Learning Rate: 0.00343071
	LOSS [training: 2.5752274601515857 | validation: 1.7456981674605203]
	TIME [epoch: 6.51 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.281830477157699		[learning rate: 0.0034171]
	Learning Rate: 0.00341707
	LOSS [training: 1.281830477157699 | validation: 0.5050710507211458]
	TIME [epoch: 6.51 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.47388565359602886		[learning rate: 0.0034035]
	Learning Rate: 0.00340348
	LOSS [training: 0.47388565359602886 | validation: 0.4383160629982523]
	TIME [epoch: 6.5 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5559978508298135		[learning rate: 0.0033899]
	Learning Rate: 0.00338994
	LOSS [training: 0.5559978508298135 | validation: 0.9721617835914319]
	TIME [epoch: 6.52 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.910994910361167		[learning rate: 0.0033765]
	Learning Rate: 0.00337646
	LOSS [training: 0.910994910361167 | validation: 1.2488629811703547]
	TIME [epoch: 6.51 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7748725248172662		[learning rate: 0.003363]
	Learning Rate: 0.00336303
	LOSS [training: 0.7748725248172662 | validation: 0.5670223853960189]
	TIME [epoch: 6.51 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4998363416246725		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 0.4998363416246725 | validation: 0.4733010696912395]
	TIME [epoch: 6.51 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.47475014787368863		[learning rate: 0.0033363]
	Learning Rate: 0.00333633
	LOSS [training: 0.47475014787368863 | validation: 0.4148425290461354]
	TIME [epoch: 6.5 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4713282688930809		[learning rate: 0.0033231]
	Learning Rate: 0.00332306
	LOSS [training: 0.4713282688930809 | validation: 0.45994458718053866]
	TIME [epoch: 6.5 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3976985745404544		[learning rate: 0.0033098]
	Learning Rate: 0.00330985
	LOSS [training: 0.3976985745404544 | validation: 0.3929428954920807]
	TIME [epoch: 6.53 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4429886305476873		[learning rate: 0.0032967]
	Learning Rate: 0.00329668
	LOSS [training: 0.4429886305476873 | validation: 0.4792574488644067]
	TIME [epoch: 6.52 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3862159914912898		[learning rate: 0.0032836]
	Learning Rate: 0.00328357
	LOSS [training: 0.3862159914912898 | validation: 0.42459743253138854]
	TIME [epoch: 6.49 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.37600348200848577		[learning rate: 0.0032705]
	Learning Rate: 0.00327051
	LOSS [training: 0.37600348200848577 | validation: 0.38604534844803073]
	TIME [epoch: 6.5 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.35734273698911684		[learning rate: 0.0032575]
	Learning Rate: 0.0032575
	LOSS [training: 0.35734273698911684 | validation: 0.3852494176531236]
	TIME [epoch: 6.51 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.36177650019525714		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 0.36177650019525714 | validation: 0.37888566752222796]
	TIME [epoch: 6.5 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32878006134318327		[learning rate: 0.0032316]
	Learning Rate: 0.00323164
	LOSS [training: 0.32878006134318327 | validation: 0.415083524612234]
	TIME [epoch: 6.53 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.398442887804315		[learning rate: 0.0032188]
	Learning Rate: 0.00321879
	LOSS [training: 0.398442887804315 | validation: 0.37910601440598674]
	TIME [epoch: 6.53 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3484749547664044		[learning rate: 0.003206]
	Learning Rate: 0.00320599
	LOSS [training: 0.3484749547664044 | validation: 0.36133104125907406]
	TIME [epoch: 6.58 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.35126199081541526		[learning rate: 0.0031932]
	Learning Rate: 0.00319323
	LOSS [training: 0.35126199081541526 | validation: 0.3453989687362721]
	TIME [epoch: 6.58 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.33008372553232895		[learning rate: 0.0031805]
	Learning Rate: 0.00318053
	LOSS [training: 0.33008372553232895 | validation: 0.3554357639449989]
	TIME [epoch: 6.55 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3280329272327375		[learning rate: 0.0031679]
	Learning Rate: 0.00316788
	LOSS [training: 0.3280329272327375 | validation: 0.3354624295187761]
	TIME [epoch: 6.54 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3258208025681014		[learning rate: 0.0031553]
	Learning Rate: 0.00315528
	LOSS [training: 0.3258208025681014 | validation: 0.4022659370553832]
	TIME [epoch: 6.54 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3311308004929252		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 0.3311308004929252 | validation: 0.3462507163348135]
	TIME [epoch: 6.56 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6053778247048988		[learning rate: 0.0031302]
	Learning Rate: 0.00313023
	LOSS [training: 0.6053778247048988 | validation: 2.1949208855792284]
	TIME [epoch: 6.57 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.3494798872290985		[learning rate: 0.0031178]
	Learning Rate: 0.00311779
	LOSS [training: 1.3494798872290985 | validation: 0.48006516287471585]
	TIME [epoch: 6.55 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.39207330379848526		[learning rate: 0.0031054]
	Learning Rate: 0.00310538
	LOSS [training: 0.39207330379848526 | validation: 0.36960718952924093]
	TIME [epoch: 6.56 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3630782169002934		[learning rate: 0.003093]
	Learning Rate: 0.00309303
	LOSS [training: 0.3630782169002934 | validation: 0.3688760247693867]
	TIME [epoch: 6.55 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4902039421853826		[learning rate: 0.0030807]
	Learning Rate: 0.00308073
	LOSS [training: 0.4902039421853826 | validation: 0.4635739009381507]
	TIME [epoch: 6.53 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.45600971873752916		[learning rate: 0.0030685]
	Learning Rate: 0.00306848
	LOSS [training: 0.45600971873752916 | validation: 0.44401957820186055]
	TIME [epoch: 6.53 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.41037242381903094		[learning rate: 0.0030563]
	Learning Rate: 0.00305627
	LOSS [training: 0.41037242381903094 | validation: 0.44834949748696235]
	TIME [epoch: 6.52 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3712366364777336		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 0.3712366364777336 | validation: 0.33792117351592155]
	TIME [epoch: 6.51 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3256961683798424		[learning rate: 0.003032]
	Learning Rate: 0.00303201
	LOSS [training: 0.3256961683798424 | validation: 0.3330806065572795]
	TIME [epoch: 6.52 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.31315214955825205		[learning rate: 0.00302]
	Learning Rate: 0.00301995
	LOSS [training: 0.31315214955825205 | validation: 0.3639365663816999]
	TIME [epoch: 6.52 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.31301116586279404		[learning rate: 0.0030079]
	Learning Rate: 0.00300794
	LOSS [training: 0.31301116586279404 | validation: 0.33780049799221346]
	TIME [epoch: 6.51 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4752872747534585		[learning rate: 0.002996]
	Learning Rate: 0.00299598
	LOSS [training: 0.4752872747534585 | validation: 2.6605159202365507]
	TIME [epoch: 6.51 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 9/9] avg loss: 2.6200308925670304		[learning rate: 0.0029841]
	Learning Rate: 0.00298406
	LOSS [training: 2.6200308925670304 | validation: 1.0698404126633558]
	TIME [epoch: 6.52 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5183358530940464		[learning rate: 0.0029722]
	Learning Rate: 0.00297219
	LOSS [training: 0.5183358530940464 | validation: 0.4281630398739318]
	TIME [epoch: 6.53 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4122711932696961		[learning rate: 0.0029604]
	Learning Rate: 0.00296037
	LOSS [training: 0.4122711932696961 | validation: 0.3288443219584317]
	TIME [epoch: 6.54 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.354583659087864		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.354583659087864 | validation: 0.37117714710098093]
	TIME [epoch: 6.52 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.39520234973607543		[learning rate: 0.0029369]
	Learning Rate: 0.00293687
	LOSS [training: 0.39520234973607543 | validation: 0.37412013568579405]
	TIME [epoch: 6.51 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3620729648989016		[learning rate: 0.0029252]
	Learning Rate: 0.00292519
	LOSS [training: 0.3620729648989016 | validation: 0.3525821073106345]
	TIME [epoch: 6.51 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.320900354673084		[learning rate: 0.0029136]
	Learning Rate: 0.00291355
	LOSS [training: 0.320900354673084 | validation: 0.313445151296359]
	TIME [epoch: 6.52 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3706019068732218		[learning rate: 0.002902]
	Learning Rate: 0.00290197
	LOSS [training: 0.3706019068732218 | validation: 0.40329109625580173]
	TIME [epoch: 6.52 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3520599371565971		[learning rate: 0.0028904]
	Learning Rate: 0.00289042
	LOSS [training: 0.3520599371565971 | validation: 0.3734284242896407]
	TIME [epoch: 6.51 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3383168192912319		[learning rate: 0.0028789]
	Learning Rate: 0.00287893
	LOSS [training: 0.3383168192912319 | validation: 0.40261824112632477]
	TIME [epoch: 6.51 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3266071321843391		[learning rate: 0.0028675]
	Learning Rate: 0.00286748
	LOSS [training: 0.3266071321843391 | validation: 0.3311050231315404]
	TIME [epoch: 6.51 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.33524790001887017		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 0.33524790001887017 | validation: 0.31260682606932694]
	TIME [epoch: 6.5 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.30523140976550367		[learning rate: 0.0028447]
	Learning Rate: 0.00284471
	LOSS [training: 0.30523140976550367 | validation: 0.3247152413229042]
	TIME [epoch: 6.54 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3935650595062399		[learning rate: 0.0028334]
	Learning Rate: 0.0028334
	LOSS [training: 0.3935650595062399 | validation: 0.5413302435531643]
	TIME [epoch: 6.51 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.468116812981387		[learning rate: 0.0028221]
	Learning Rate: 0.00282213
	LOSS [training: 0.468116812981387 | validation: 0.42380260005461456]
	TIME [epoch: 6.5 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3659229674740207		[learning rate: 0.0028109]
	Learning Rate: 0.00281091
	LOSS [training: 0.3659229674740207 | validation: 0.35675950416023594]
	TIME [epoch: 6.51 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3291585913762691		[learning rate: 0.0027997]
	Learning Rate: 0.00279973
	LOSS [training: 0.3291585913762691 | validation: 0.3472493381889311]
	TIME [epoch: 6.51 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.35475627861604764		[learning rate: 0.0027886]
	Learning Rate: 0.00278859
	LOSS [training: 0.35475627861604764 | validation: 0.6141683461218796]
	TIME [epoch: 6.5 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5685721142639183		[learning rate: 0.0027775]
	Learning Rate: 0.0027775
	LOSS [training: 0.5685721142639183 | validation: 0.9722796199982444]
	TIME [epoch: 6.51 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7774756135236758		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 0.7774756135236758 | validation: 1.1166608059816518]
	TIME [epoch: 6.53 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7328037458185005		[learning rate: 0.0027554]
	Learning Rate: 0.00275545
	LOSS [training: 0.7328037458185005 | validation: 0.6550116529968548]
	TIME [epoch: 6.51 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.49101247880758486		[learning rate: 0.0027445]
	Learning Rate: 0.00274449
	LOSS [training: 0.49101247880758486 | validation: 0.40455439081510514]
	TIME [epoch: 6.53 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3727015385428267		[learning rate: 0.0027336]
	Learning Rate: 0.00273357
	LOSS [training: 0.3727015385428267 | validation: 0.3648637632971021]
	TIME [epoch: 6.51 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.34604599192159147		[learning rate: 0.0027227]
	Learning Rate: 0.0027227
	LOSS [training: 0.34604599192159147 | validation: 0.35940643797633853]
	TIME [epoch: 6.51 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32865041080110513		[learning rate: 0.0027119]
	Learning Rate: 0.00271187
	LOSS [training: 0.32865041080110513 | validation: 0.335732107673009]
	TIME [epoch: 6.51 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3075657468202915		[learning rate: 0.0027011]
	Learning Rate: 0.00270109
	LOSS [training: 0.3075657468202915 | validation: 0.3360064232357693]
	TIME [epoch: 6.52 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3204005474459916		[learning rate: 0.0026903]
	Learning Rate: 0.00269034
	LOSS [training: 0.3204005474459916 | validation: 0.35648823120496614]
	TIME [epoch: 6.52 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3440946012154751		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 0.3440946012154751 | validation: 0.3295589090857013]
	TIME [epoch: 6.52 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3117720929955844		[learning rate: 0.002669]
	Learning Rate: 0.00266899
	LOSS [training: 0.3117720929955844 | validation: 0.34754558239206673]
	TIME [epoch: 6.51 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.31921380581867953		[learning rate: 0.0026584]
	Learning Rate: 0.00265837
	LOSS [training: 0.31921380581867953 | validation: 0.33116906938276636]
	TIME [epoch: 6.51 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.29927357932959914		[learning rate: 0.0026478]
	Learning Rate: 0.0026478
	LOSS [training: 0.29927357932959914 | validation: 0.3230414847080759]
	TIME [epoch: 6.51 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.31787890102805655		[learning rate: 0.0026373]
	Learning Rate: 0.00263727
	LOSS [training: 0.31787890102805655 | validation: 0.6348465295886873]
	TIME [epoch: 6.52 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.8278455479496236		[learning rate: 0.0026268]
	Learning Rate: 0.00262678
	LOSS [training: 0.8278455479496236 | validation: 0.6149341546856903]
	TIME [epoch: 6.52 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5220292146487914		[learning rate: 0.0026163]
	Learning Rate: 0.00261633
	LOSS [training: 0.5220292146487914 | validation: 0.3853990380336511]
	TIME [epoch: 6.5 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3567821671770514		[learning rate: 0.0026059]
	Learning Rate: 0.00260592
	LOSS [training: 0.3567821671770514 | validation: 0.34228278010240254]
	TIME [epoch: 6.51 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.34438077245393295		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 0.34438077245393295 | validation: 0.3896269631814913]
	TIME [epoch: 6.51 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3948365466501673		[learning rate: 0.0025852]
	Learning Rate: 0.00258523
	LOSS [training: 0.3948365466501673 | validation: 0.371586492427615]
	TIME [epoch: 6.51 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3395213522378332		[learning rate: 0.002575]
	Learning Rate: 0.00257495
	LOSS [training: 0.3395213522378332 | validation: 0.35473617899091514]
	TIME [epoch: 6.51 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.35225495842327986		[learning rate: 0.0025647]
	Learning Rate: 0.00256471
	LOSS [training: 0.35225495842327986 | validation: 0.35601718382386655]
	TIME [epoch: 6.53 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32626293110801446		[learning rate: 0.0025545]
	Learning Rate: 0.00255451
	LOSS [training: 0.32626293110801446 | validation: 0.3519304798621057]
	TIME [epoch: 6.51 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3131269815488258		[learning rate: 0.0025444]
	Learning Rate: 0.00254435
	LOSS [training: 0.3131269815488258 | validation: 0.30565864536188975]
	TIME [epoch: 6.51 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.31966351434889906		[learning rate: 0.0025342]
	Learning Rate: 0.00253423
	LOSS [training: 0.31966351434889906 | validation: 0.30885755190059855]
	TIME [epoch: 6.51 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4348363106753004		[learning rate: 0.0025242]
	Learning Rate: 0.00252415
	LOSS [training: 0.4348363106753004 | validation: 0.6738321698032012]
	TIME [epoch: 6.5 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.484352434015109		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 1.484352434015109 | validation: 2.070674299831597]
	TIME [epoch: 6.51 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.8291787535823236		[learning rate: 0.0025041]
	Learning Rate: 0.00250411
	LOSS [training: 1.8291787535823236 | validation: 1.7620930198208236]
	TIME [epoch: 6.64 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.6698586244264684		[learning rate: 0.0024942]
	Learning Rate: 0.00249415
	LOSS [training: 1.6698586244264684 | validation: 1.737723745142419]
	TIME [epoch: 6.51 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.519917262758392		[learning rate: 0.0024842]
	Learning Rate: 0.00248423
	LOSS [training: 1.519917262758392 | validation: 2.1462941332125105]
	TIME [epoch: 6.51 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 9/9] avg loss: 2.314790399406001		[learning rate: 0.0024744]
	Learning Rate: 0.00247435
	LOSS [training: 2.314790399406001 | validation: 2.1980254456933648]
	TIME [epoch: 6.51 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.4116548062252632		[learning rate: 0.0024645]
	Learning Rate: 0.00246451
	LOSS [training: 1.4116548062252632 | validation: 1.2732489301192929]
	TIME [epoch: 6.5 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.9636891813376918		[learning rate: 0.0024547]
	Learning Rate: 0.00245471
	LOSS [training: 0.9636891813376918 | validation: 1.3145991621490443]
	TIME [epoch: 6.51 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.414110234234275		[learning rate: 0.0024449]
	Learning Rate: 0.00244495
	LOSS [training: 1.414110234234275 | validation: 1.1608424093480771]
	TIME [epoch: 6.51 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7432729317034706		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 0.7432729317034706 | validation: 0.5964337978422183]
	TIME [epoch: 6.52 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4754437611058501		[learning rate: 0.0024255]
	Learning Rate: 0.00242554
	LOSS [training: 0.4754437611058501 | validation: 0.4232481426314797]
	TIME [epoch: 6.51 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3755217985745303		[learning rate: 0.0024159]
	Learning Rate: 0.00241589
	LOSS [training: 0.3755217985745303 | validation: 0.3714683075723897]
	TIME [epoch: 6.55 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.366789628589678		[learning rate: 0.0024063]
	Learning Rate: 0.00240628
	LOSS [training: 0.366789628589678 | validation: 0.35677459736349454]
	TIME [epoch: 6.62 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3190083601727781		[learning rate: 0.0023967]
	Learning Rate: 0.00239671
	LOSS [training: 0.3190083601727781 | validation: 0.34074792056522696]
	TIME [epoch: 6.61 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.31482127512055746		[learning rate: 0.0023872]
	Learning Rate: 0.00238718
	LOSS [training: 0.31482127512055746 | validation: 0.3342868724072206]
	TIME [epoch: 6.58 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.312704883068157		[learning rate: 0.0023777]
	Learning Rate: 0.00237768
	LOSS [training: 0.312704883068157 | validation: 0.33632069728526676]
	TIME [epoch: 6.57 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.30349712711876076		[learning rate: 0.0023682]
	Learning Rate: 0.00236823
	LOSS [training: 0.30349712711876076 | validation: 0.3123017117491238]
	TIME [epoch: 6.58 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3266897971820845		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 0.3266897971820845 | validation: 0.33566089807154886]
	TIME [epoch: 6.58 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5081034382303838		[learning rate: 0.0023494]
	Learning Rate: 0.00234942
	LOSS [training: 0.5081034382303838 | validation: 0.30992360154216947]
	TIME [epoch: 6.57 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.353020202179216		[learning rate: 0.0023401]
	Learning Rate: 0.00234008
	LOSS [training: 0.353020202179216 | validation: 0.3377989313558084]
	TIME [epoch: 6.58 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.34273572304874933		[learning rate: 0.0023308]
	Learning Rate: 0.00233077
	LOSS [training: 0.34273572304874933 | validation: 0.37997369531442926]
	TIME [epoch: 6.58 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3483305856467348		[learning rate: 0.0023215]
	Learning Rate: 0.0023215
	LOSS [training: 0.3483305856467348 | validation: 0.34301344616042384]
	TIME [epoch: 6.58 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3315680740360081		[learning rate: 0.0023123]
	Learning Rate: 0.00231227
	LOSS [training: 0.3315680740360081 | validation: 0.3117596616062541]
	TIME [epoch: 6.6 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3007119486933712		[learning rate: 0.0023031]
	Learning Rate: 0.00230307
	LOSS [training: 0.3007119486933712 | validation: 0.30885082286822196]
	TIME [epoch: 6.57 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2995951117872197		[learning rate: 0.0022939]
	Learning Rate: 0.00229391
	LOSS [training: 0.2995951117872197 | validation: 0.30482721699935744]
	TIME [epoch: 6.61 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3165237789378759		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 0.3165237789378759 | validation: 0.3645704022877275]
	TIME [epoch: 6.6 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3143159147019116		[learning rate: 0.0022757]
	Learning Rate: 0.0022757
	LOSS [training: 0.3143159147019116 | validation: 0.3065781319556748]
	TIME [epoch: 6.62 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.28608188061569273		[learning rate: 0.0022667]
	Learning Rate: 0.00226665
	LOSS [training: 0.28608188061569273 | validation: 0.30176683536163534]
	TIME [epoch: 6.62 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.29050146297342255		[learning rate: 0.0022576]
	Learning Rate: 0.00225764
	LOSS [training: 0.29050146297342255 | validation: 0.3245078153189049]
	TIME [epoch: 6.61 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.36270327165538846		[learning rate: 0.0022487]
	Learning Rate: 0.00224866
	LOSS [training: 0.36270327165538846 | validation: 0.41285191444058567]
	TIME [epoch: 6.53 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.41295057916844724		[learning rate: 0.0022397]
	Learning Rate: 0.00223971
	LOSS [training: 0.41295057916844724 | validation: 0.5063953050637744]
	TIME [epoch: 6.6 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.43143650478978507		[learning rate: 0.0022308]
	Learning Rate: 0.0022308
	LOSS [training: 0.43143650478978507 | validation: 0.40413907967538154]
	TIME [epoch: 6.61 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3642074895621739		[learning rate: 0.0022219]
	Learning Rate: 0.00222193
	LOSS [training: 0.3642074895621739 | validation: 0.3222029998437165]
	TIME [epoch: 6.62 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.34977426945826234		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.34977426945826234 | validation: 0.5101042624037081]
	TIME [epoch: 6.64 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.416596609906905		[learning rate: 0.0022043]
	Learning Rate: 0.00220429
	LOSS [training: 0.416596609906905 | validation: 0.3770398599017552]
	TIME [epoch: 6.7 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3558478509357942		[learning rate: 0.0021955]
	Learning Rate: 0.00219553
	LOSS [training: 0.3558478509357942 | validation: 0.3512823510306212]
	TIME [epoch: 6.64 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.35498473185592966		[learning rate: 0.0021868]
	Learning Rate: 0.00218679
	LOSS [training: 0.35498473185592966 | validation: 0.3417466108426432]
	TIME [epoch: 6.65 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.31425653947833765		[learning rate: 0.0021781]
	Learning Rate: 0.0021781
	LOSS [training: 0.31425653947833765 | validation: 0.3169880404012638]
	TIME [epoch: 6.66 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.29567623779633095		[learning rate: 0.0021694]
	Learning Rate: 0.00216943
	LOSS [training: 0.29567623779633095 | validation: 0.32575995812034286]
	TIME [epoch: 6.61 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3054472663696453		[learning rate: 0.0021608]
	Learning Rate: 0.0021608
	LOSS [training: 0.3054472663696453 | validation: 0.30598054429126353]
	TIME [epoch: 6.59 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3177787211493013		[learning rate: 0.0021522]
	Learning Rate: 0.00215221
	LOSS [training: 0.3177787211493013 | validation: 0.31033253198212657]
	TIME [epoch: 6.56 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.29172333549933566		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.29172333549933566 | validation: 0.31077536319344995]
	TIME [epoch: 6.57 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.29676211482238		[learning rate: 0.0021351]
	Learning Rate: 0.00213512
	LOSS [training: 0.29676211482238 | validation: 0.3523592103287676]
	TIME [epoch: 6.52 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3056802902504362		[learning rate: 0.0021266]
	Learning Rate: 0.00212663
	LOSS [training: 0.3056802902504362 | validation: 0.35553826660221144]
	TIME [epoch: 6.51 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2835388300320182		[learning rate: 0.0021182]
	Learning Rate: 0.00211817
	LOSS [training: 0.2835388300320182 | validation: 0.35251645123502706]
	TIME [epoch: 6.53 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.35495780209931316		[learning rate: 0.0021097]
	Learning Rate: 0.00210975
	LOSS [training: 0.35495780209931316 | validation: 0.3710778057166531]
	TIME [epoch: 6.51 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.39947414731235703		[learning rate: 0.0021014]
	Learning Rate: 0.00210136
	LOSS [training: 0.39947414731235703 | validation: 0.3358787036806032]
	TIME [epoch: 6.53 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3101938791398626		[learning rate: 0.002093]
	Learning Rate: 0.002093
	LOSS [training: 0.3101938791398626 | validation: 0.34976329883357626]
	TIME [epoch: 6.54 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.31963828829542884		[learning rate: 0.0020847]
	Learning Rate: 0.00208468
	LOSS [training: 0.31963828829542884 | validation: 0.3421959318330029]
	TIME [epoch: 6.52 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.28459654980728427		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.28459654980728427 | validation: 0.31970202586879554]
	TIME [epoch: 6.52 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.29974913414414656		[learning rate: 0.0020681]
	Learning Rate: 0.00206813
	LOSS [training: 0.29974913414414656 | validation: 0.31886055590508894]
	TIME [epoch: 6.52 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3113887284955869		[learning rate: 0.0020599]
	Learning Rate: 0.0020599
	LOSS [training: 0.3113887284955869 | validation: 0.3189890460388872]
	TIME [epoch: 6.51 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2933605293297983		[learning rate: 0.0020517]
	Learning Rate: 0.00205171
	LOSS [training: 0.2933605293297983 | validation: 0.32454787255308426]
	TIME [epoch: 6.53 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.29635588232765503		[learning rate: 0.0020435]
	Learning Rate: 0.00204355
	LOSS [training: 0.29635588232765503 | validation: 0.3113610369142946]
	TIME [epoch: 6.52 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3871853864054022		[learning rate: 0.0020354]
	Learning Rate: 0.00203542
	LOSS [training: 0.3871853864054022 | validation: 0.8872438078423643]
	TIME [epoch: 6.52 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.0251147439044972		[learning rate: 0.0020273]
	Learning Rate: 0.00202732
	LOSS [training: 1.0251147439044972 | validation: 1.4527802959477514]
	TIME [epoch: 6.52 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.383064351427633		[learning rate: 0.0020193]
	Learning Rate: 0.00201926
	LOSS [training: 1.383064351427633 | validation: 2.0937138072619907]
	TIME [epoch: 6.52 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v5_20240710_202109/states/model_facs_dec1b_2dpca_v5_446.pth
Halted early. No improvement in validation loss for 200 epochs.
Finished training in 2989.390 seconds.
