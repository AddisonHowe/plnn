Args:
Namespace(name='model_facs_v2_dec2b_2dpca_v4', outdir='out/model_training/model_facs_v2_dec2b_2dpca_v4', training_data='data/training_data/facs_v2/pca/dec2_fitonsubset/transition2_subset_ce_pn_m_pc12/training', validation_data='data/training_data/facs_v2/pca/dec2_fitonsubset/transition2_subset_ce_pn_m_pc12/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=10, batch_size=50, patience=200, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, quadratic_a=1.0, quadratic_b=1.0, ndims=2, nparams=2, nsigs=2, ncells=1000, ncells_sample=1000, model_do_sample=False, dt=0.001, dt_schedule='stepped', dt_schedule_bounds=[200, 500, 1000], dt_schedule_scales=[0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=True, sigma=0.1, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', kernel='multiscale', bw_range=[0.2, 0.5, 0.9, 1.1, 1.3, 1.5, 2.0], optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 2449271950

Training model...

Saving initial model state to: out/model_training/model_facs_v2_dec2b_2dpca_v4_20240712_121719/states/model_facs_v2_dec2b_2dpca_v4_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1013888005717358		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1013888005717358 | validation: 0.7990968295956484]
	TIME [epoch: 93.3 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v4_20240712_121719/states/model_facs_v2_dec2b_2dpca_v4_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6198930847805799		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6198930847805799 | validation: 0.7124219088067774]
	TIME [epoch: 57.4 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v4_20240712_121719/states/model_facs_v2_dec2b_2dpca_v4_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.606417149323676		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.606417149323676 | validation: 0.6997852759948515]
	TIME [epoch: 57.3 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v4_20240712_121719/states/model_facs_v2_dec2b_2dpca_v4_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5255349047069313		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5255349047069313 | validation: 0.6848467949048395]
	TIME [epoch: 57.4 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v4_20240712_121719/states/model_facs_v2_dec2b_2dpca_v4_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5673358029802887		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5673358029802887 | validation: 0.6972830479134472]
	TIME [epoch: 57.4 sec]
EPOCH 6/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5395454054679402		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5395454054679402 | validation: 0.6407825710184647]
	TIME [epoch: 57.4 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v4_20240712_121719/states/model_facs_v2_dec2b_2dpca_v4_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5274515114404831		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5274515114404831 | validation: 0.6518215442643439]
	TIME [epoch: 57.4 sec]
EPOCH 8/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5096013256224187		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5096013256224187 | validation: 0.7194717109113349]
	TIME [epoch: 57.3 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5161388688454986		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5161388688454986 | validation: 0.6357262417910098]
	TIME [epoch: 57.3 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v4_20240712_121719/states/model_facs_v2_dec2b_2dpca_v4_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.535358776574314		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.535358776574314 | validation: 0.6333584735876304]
	TIME [epoch: 57.3 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v4_20240712_121719/states/model_facs_v2_dec2b_2dpca_v4_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5056610531077294		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5056610531077294 | validation: 0.6090075049717323]
	TIME [epoch: 57.3 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v4_20240712_121719/states/model_facs_v2_dec2b_2dpca_v4_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5031878328825471		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5031878328825471 | validation: 0.6338813946026419]
	TIME [epoch: 57.4 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5015110230137851		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5015110230137851 | validation: 0.6156121732458097]
	TIME [epoch: 57.4 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4804825652713031		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4804825652713031 | validation: 0.5770719783082269]
	TIME [epoch: 57.4 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v4_20240712_121719/states/model_facs_v2_dec2b_2dpca_v4_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.459570779130941		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.459570779130941 | validation: 0.7152937846514946]
	TIME [epoch: 57.4 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4690938955063739		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4690938955063739 | validation: 0.5870985021706349]
	TIME [epoch: 57.3 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4177341107415275		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4177341107415275 | validation: 0.822168050929396]
	TIME [epoch: 57.3 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44901426231829883		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.44901426231829883 | validation: 0.47845929335520976]
	TIME [epoch: 57.3 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v4_20240712_121719/states/model_facs_v2_dec2b_2dpca_v4_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36584563847352813		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.36584563847352813 | validation: 0.5948490685419102]
	TIME [epoch: 57.3 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40445084585439517		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.40445084585439517 | validation: 0.466016151628486]
	TIME [epoch: 57.3 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v4_20240712_121719/states/model_facs_v2_dec2b_2dpca_v4_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3140847187432193		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3140847187432193 | validation: 0.5451611075728685]
	TIME [epoch: 57.4 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4226778356503734		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4226778356503734 | validation: 0.4641369659242558]
	TIME [epoch: 57.4 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v4_20240712_121719/states/model_facs_v2_dec2b_2dpca_v4_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3135723966450317		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3135723966450317 | validation: 0.5036146858799269]
	TIME [epoch: 57.4 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3570537917035236		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3570537917035236 | validation: 0.4343482815202412]
	TIME [epoch: 57.3 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v4_20240712_121719/states/model_facs_v2_dec2b_2dpca_v4_24.pth
	Model improved!!!
EPOCH 25/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28687660375393564		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.28687660375393564 | validation: 0.4402872660228597]
	TIME [epoch: 57.4 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3795943276408579		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3795943276408579 | validation: 0.4317078089362537]
	TIME [epoch: 57.3 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v4_20240712_121719/states/model_facs_v2_dec2b_2dpca_v4_26.pth
	Model improved!!!
EPOCH 27/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2809425765789269		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2809425765789269 | validation: 0.44317973707851926]
	TIME [epoch: 57.3 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35137647062935135		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.35137647062935135 | validation: 0.4591485055753005]
	TIME [epoch: 57.3 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3363648640741487		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3363648640741487 | validation: 0.4293558895648685]
	TIME [epoch: 57.3 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v4_20240712_121719/states/model_facs_v2_dec2b_2dpca_v4_29.pth
	Model improved!!!
EPOCH 30/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2629923671308915		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2629923671308915 | validation: 0.4390302419980979]
	TIME [epoch: 57.3 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3526392031545165		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3526392031545165 | validation: 0.5125343769925631]
	TIME [epoch: 57.3 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27788487383746624		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.27788487383746624 | validation: 0.48241522131401854]
	TIME [epoch: 57.3 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31100691537696834		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.31100691537696834 | validation: 0.4271173239793902]
	TIME [epoch: 57.3 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v4_20240712_121719/states/model_facs_v2_dec2b_2dpca_v4_33.pth
	Model improved!!!
EPOCH 34/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26963785423277675		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.26963785423277675 | validation: 0.4214026380944441]
	TIME [epoch: 57.3 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v4_20240712_121719/states/model_facs_v2_dec2b_2dpca_v4_34.pth
	Model improved!!!
EPOCH 35/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2957860345742034		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2957860345742034 | validation: 0.42121558310469315]
	TIME [epoch: 57.3 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v4_20240712_121719/states/model_facs_v2_dec2b_2dpca_v4_35.pth
	Model improved!!!
EPOCH 36/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2745756868201504		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2745756868201504 | validation: 0.38091477749880165]
	TIME [epoch: 57.3 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v4_20240712_121719/states/model_facs_v2_dec2b_2dpca_v4_36.pth
	Model improved!!!
EPOCH 37/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27004511505814		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.27004511505814 | validation: 0.44859777937699463]
	TIME [epoch: 57.3 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30768907904778253		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.30768907904778253 | validation: 0.5145382310423182]
	TIME [epoch: 57.4 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3111397588870758		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3111397588870758 | validation: 0.3982126607329486]
	TIME [epoch: 57.4 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3047302528604035		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3047302528604035 | validation: 0.4567972450205291]
	TIME [epoch: 57.4 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29320333911031016		[learning rate: 0.0099646]
	Learning Rate: 0.00996464
	LOSS [training: 0.29320333911031016 | validation: 0.510252272672452]
	TIME [epoch: 57.4 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25951413512402816		[learning rate: 0.0099206]
	Learning Rate: 0.00992061
	LOSS [training: 0.25951413512402816 | validation: 0.46565978648046613]
	TIME [epoch: 57.3 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2525352465063906		[learning rate: 0.0098768]
	Learning Rate: 0.00987678
	LOSS [training: 0.2525352465063906 | validation: 0.37686446161486553]
	TIME [epoch: 57.3 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v4_20240712_121719/states/model_facs_v2_dec2b_2dpca_v4_43.pth
	Model improved!!!
EPOCH 44/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28809441670132857		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 0.28809441670132857 | validation: 0.4478508799616489]
	TIME [epoch: 57.3 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2720928497779108		[learning rate: 0.0097897]
	Learning Rate: 0.0097897
	LOSS [training: 0.2720928497779108 | validation: 0.41104709441077997]
	TIME [epoch: 57.3 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2607479336559794		[learning rate: 0.0097464]
	Learning Rate: 0.00974644
	LOSS [training: 0.2607479336559794 | validation: 0.4034222497801564]
	TIME [epoch: 57.3 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2655065441125596		[learning rate: 0.0097034]
	Learning Rate: 0.00970338
	LOSS [training: 0.2655065441125596 | validation: 0.39519366145149126]
	TIME [epoch: 57.3 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2653740139565171		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 0.2653740139565171 | validation: 0.35453964457494686]
	TIME [epoch: 57.3 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v4_20240712_121719/states/model_facs_v2_dec2b_2dpca_v4_48.pth
	Model improved!!!
EPOCH 49/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2593112079818197		[learning rate: 0.0096178]
	Learning Rate: 0.00961783
	LOSS [training: 0.2593112079818197 | validation: 0.37457394298523206]
	TIME [epoch: 57.4 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.253391096786836		[learning rate: 0.0095753]
	Learning Rate: 0.00957533
	LOSS [training: 0.253391096786836 | validation: 0.4593559677830419]
	TIME [epoch: 57.3 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29112122905339766		[learning rate: 0.009533]
	Learning Rate: 0.00953303
	LOSS [training: 0.29112122905339766 | validation: 0.43340302568557076]
	TIME [epoch: 57.3 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26569020090205836		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 0.26569020090205836 | validation: 0.44230745600277754]
	TIME [epoch: 57.6 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27818456451103		[learning rate: 0.009449]
	Learning Rate: 0.00944897
	LOSS [training: 0.27818456451103 | validation: 0.39223131594348704]
	TIME [epoch: 57.4 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2202175605876986		[learning rate: 0.0094072]
	Learning Rate: 0.00940722
	LOSS [training: 0.2202175605876986 | validation: 0.4493221835693185]
	TIME [epoch: 57.4 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2705700805468307		[learning rate: 0.0093657]
	Learning Rate: 0.00936566
	LOSS [training: 0.2705700805468307 | validation: 0.3892341649038191]
	TIME [epoch: 57.4 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24635534281199636		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 0.24635534281199636 | validation: 0.44765444553480005]
	TIME [epoch: 57.4 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2828867217735348		[learning rate: 0.0092831]
	Learning Rate: 0.00928308
	LOSS [training: 0.2828867217735348 | validation: 0.42080762339504707]
	TIME [epoch: 57.4 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23134888078358307		[learning rate: 0.0092421]
	Learning Rate: 0.00924207
	LOSS [training: 0.23134888078358307 | validation: 0.47766133195013644]
	TIME [epoch: 57.4 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24534915947613278		[learning rate: 0.0092012]
	Learning Rate: 0.00920124
	LOSS [training: 0.24534915947613278 | validation: 0.38886576422090596]
	TIME [epoch: 57.4 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23961395680397035		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 0.23961395680397035 | validation: 0.4155908367279688]
	TIME [epoch: 57.4 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25374674897417665		[learning rate: 0.0091201]
	Learning Rate: 0.00912011
	LOSS [training: 0.25374674897417665 | validation: 0.458395478263416]
	TIME [epoch: 57.3 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27306816752623553		[learning rate: 0.0090798]
	Learning Rate: 0.00907981
	LOSS [training: 0.27306816752623553 | validation: 0.5132617383799729]
	TIME [epoch: 57.4 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.271295228724932		[learning rate: 0.0090397]
	Learning Rate: 0.0090397
	LOSS [training: 0.271295228724932 | validation: 0.4572089662370806]
	TIME [epoch: 57.4 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2326982017544572		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 0.2326982017544572 | validation: 0.41852535430247384]
	TIME [epoch: 57.4 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24420544059239263		[learning rate: 0.00896]
	Learning Rate: 0.00895999
	LOSS [training: 0.24420544059239263 | validation: 0.47251404188520846]
	TIME [epoch: 57.4 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2525851064773056		[learning rate: 0.0089204]
	Learning Rate: 0.00892041
	LOSS [training: 0.2525851064773056 | validation: 0.39785165546948176]
	TIME [epoch: 57.4 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2654188008278695		[learning rate: 0.008881]
	Learning Rate: 0.00888099
	LOSS [training: 0.2654188008278695 | validation: 0.49185334750430926]
	TIME [epoch: 57.4 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25107643075260444		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 0.25107643075260444 | validation: 0.5350510370407183]
	TIME [epoch: 57.4 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22408197353902856		[learning rate: 0.0088027]
	Learning Rate: 0.00880269
	LOSS [training: 0.22408197353902856 | validation: 0.46537283903973875]
	TIME [epoch: 57.4 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2407489155540948		[learning rate: 0.0087638]
	Learning Rate: 0.0087638
	LOSS [training: 0.2407489155540948 | validation: 0.5312381713698662]
	TIME [epoch: 57.4 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.253722280816609		[learning rate: 0.0087251]
	Learning Rate: 0.00872508
	LOSS [training: 0.253722280816609 | validation: 0.37760156377090365]
	TIME [epoch: 57.4 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23280335830697826		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 0.23280335830697826 | validation: 0.3607885153722589]
	TIME [epoch: 57.4 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19708655658914936		[learning rate: 0.0086481]
	Learning Rate: 0.00864815
	LOSS [training: 0.19708655658914936 | validation: 0.3464190747624486]
	TIME [epoch: 57.4 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v4_20240712_121719/states/model_facs_v2_dec2b_2dpca_v4_73.pth
	Model improved!!!
EPOCH 74/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2312972053171228		[learning rate: 0.0086099]
	Learning Rate: 0.00860994
	LOSS [training: 0.2312972053171228 | validation: 0.3972930673802566]
	TIME [epoch: 57.4 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23666947817890627		[learning rate: 0.0085719]
	Learning Rate: 0.0085719
	LOSS [training: 0.23666947817890627 | validation: 0.4133899606831822]
	TIME [epoch: 57.4 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2872519067128039		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 0.2872519067128039 | validation: 0.3537267130600675]
	TIME [epoch: 57.4 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21165386810771308		[learning rate: 0.0084963]
	Learning Rate: 0.00849632
	LOSS [training: 0.21165386810771308 | validation: 0.3694072660646765]
	TIME [epoch: 57.5 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22062010264838522		[learning rate: 0.0084588]
	Learning Rate: 0.00845878
	LOSS [training: 0.22062010264838522 | validation: 0.3754518708957315]
	TIME [epoch: 57.4 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2278977522978563		[learning rate: 0.0084214]
	Learning Rate: 0.00842141
	LOSS [training: 0.2278977522978563 | validation: 0.4542745158785031]
	TIME [epoch: 57.4 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24584043881663192		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 0.24584043881663192 | validation: 0.3632257023743753]
	TIME [epoch: 57.4 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.214011252612664		[learning rate: 0.0083472]
	Learning Rate: 0.00834715
	LOSS [training: 0.214011252612664 | validation: 0.3208436390439129]
	TIME [epoch: 57.4 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v4_20240712_121719/states/model_facs_v2_dec2b_2dpca_v4_81.pth
	Model improved!!!
EPOCH 82/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2170708833111697		[learning rate: 0.0083103]
	Learning Rate: 0.00831027
	LOSS [training: 0.2170708833111697 | validation: 0.38161257290617084]
	TIME [epoch: 57.4 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2489624685717097		[learning rate: 0.0082736]
	Learning Rate: 0.00827356
	LOSS [training: 0.2489624685717097 | validation: 0.34402802466322646]
	TIME [epoch: 57.4 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22434510309072025		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 0.22434510309072025 | validation: 0.32945007765471607]
	TIME [epoch: 57.4 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2320420910894007		[learning rate: 0.0082006]
	Learning Rate: 0.00820061
	LOSS [training: 0.2320420910894007 | validation: 0.3858798216085741]
	TIME [epoch: 57.4 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21521370808203252		[learning rate: 0.0081644]
	Learning Rate: 0.00816438
	LOSS [training: 0.21521370808203252 | validation: 0.36058620767855837]
	TIME [epoch: 57.3 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23457011363523597		[learning rate: 0.0081283]
	Learning Rate: 0.0081283
	LOSS [training: 0.23457011363523597 | validation: 0.3520002484079678]
	TIME [epoch: 57.4 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20862477644316205		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 0.20862477644316205 | validation: 0.3743055996728517]
	TIME [epoch: 57.3 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.219696720570579		[learning rate: 0.0080566]
	Learning Rate: 0.00805664
	LOSS [training: 0.219696720570579 | validation: 0.3726722456631775]
	TIME [epoch: 57.4 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2349098854919193		[learning rate: 0.008021]
	Learning Rate: 0.00802104
	LOSS [training: 0.2349098854919193 | validation: 0.3493680485516879]
	TIME [epoch: 57.3 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19530912774646186		[learning rate: 0.0079856]
	Learning Rate: 0.0079856
	LOSS [training: 0.19530912774646186 | validation: 0.337102502784229]
	TIME [epoch: 57.3 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20819214027335092		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 0.20819214027335092 | validation: 0.4708521764490065]
	TIME [epoch: 57.3 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23196318440852895		[learning rate: 0.0079152]
	Learning Rate: 0.00791519
	LOSS [training: 0.23196318440852895 | validation: 0.3228361224659629]
	TIME [epoch: 57.4 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2339004691972942		[learning rate: 0.0078802]
	Learning Rate: 0.00788022
	LOSS [training: 0.2339004691972942 | validation: 0.3294412241988916]
	TIME [epoch: 57.3 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20175116641641916		[learning rate: 0.0078454]
	Learning Rate: 0.00784541
	LOSS [training: 0.20175116641641916 | validation: 0.4510678191631062]
	TIME [epoch: 57.3 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20693201187072857		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 0.20693201187072857 | validation: 0.3612603240233638]
	TIME [epoch: 57.3 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21009764072920145		[learning rate: 0.0077762]
	Learning Rate: 0.00777623
	LOSS [training: 0.21009764072920145 | validation: 0.4193292277953497]
	TIME [epoch: 57.3 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1969901749668864		[learning rate: 0.0077419]
	Learning Rate: 0.00774188
	LOSS [training: 0.1969901749668864 | validation: 0.34640917103348495]
	TIME [epoch: 57.3 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2191628704332378		[learning rate: 0.0077077]
	Learning Rate: 0.00770767
	LOSS [training: 0.2191628704332378 | validation: 0.3143225934488439]
	TIME [epoch: 57.3 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v4_20240712_121719/states/model_facs_v2_dec2b_2dpca_v4_99.pth
	Model improved!!!
EPOCH 100/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20685789921900585		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 0.20685789921900585 | validation: 0.3691576201431136]
	TIME [epoch: 57.4 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21657469395742773		[learning rate: 0.0076397]
	Learning Rate: 0.00763971
	LOSS [training: 0.21657469395742773 | validation: 0.3720651656378815]
	TIME [epoch: 57.4 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22562286826539818		[learning rate: 0.007606]
	Learning Rate: 0.00760596
	LOSS [training: 0.22562286826539818 | validation: 0.3254363077632654]
	TIME [epoch: 57.3 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2015331789217203		[learning rate: 0.0075724]
	Learning Rate: 0.00757235
	LOSS [training: 0.2015331789217203 | validation: 0.37905283456061556]
	TIME [epoch: 57.4 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2183021689939202		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 0.2183021689939202 | validation: 0.37831345813583334]
	TIME [epoch: 57.3 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21837627272001736		[learning rate: 0.0075056]
	Learning Rate: 0.00750559
	LOSS [training: 0.21837627272001736 | validation: 0.374195688784372]
	TIME [epoch: 57.4 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2029701804870677		[learning rate: 0.0074724]
	Learning Rate: 0.00747242
	LOSS [training: 0.2029701804870677 | validation: 0.34563236704230443]
	TIME [epoch: 57.3 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20785760410070314		[learning rate: 0.0074394]
	Learning Rate: 0.00743941
	LOSS [training: 0.20785760410070314 | validation: 0.3659345541838155]
	TIME [epoch: 57.4 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2056834381952107		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 0.2056834381952107 | validation: 0.4749327861703869]
	TIME [epoch: 57.4 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23085801491251065		[learning rate: 0.0073738]
	Learning Rate: 0.00737382
	LOSS [training: 0.23085801491251065 | validation: 0.3458329583135751]
	TIME [epoch: 57.4 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18754646232180724		[learning rate: 0.0073412]
	Learning Rate: 0.00734124
	LOSS [training: 0.18754646232180724 | validation: 0.3872081272717529]
	TIME [epoch: 57.3 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19540180075318203		[learning rate: 0.0073088]
	Learning Rate: 0.0073088
	LOSS [training: 0.19540180075318203 | validation: 0.3941199983713539]
	TIME [epoch: 57.4 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2307216522482459		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 0.2307216522482459 | validation: 0.328415619113026]
	TIME [epoch: 57.4 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1843651965037938		[learning rate: 0.0072444]
	Learning Rate: 0.00724436
	LOSS [training: 0.1843651965037938 | validation: 0.3830250371722023]
	TIME [epoch: 57.4 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2171543245638204		[learning rate: 0.0072124]
	Learning Rate: 0.00721235
	LOSS [training: 0.2171543245638204 | validation: 0.4368947122927555]
	TIME [epoch: 57.4 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23547088636583746		[learning rate: 0.0071805]
	Learning Rate: 0.00718049
	LOSS [training: 0.23547088636583746 | validation: 0.3759909292353432]
	TIME [epoch: 57.4 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18529193090297538		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 0.18529193090297538 | validation: 0.3693111259480611]
	TIME [epoch: 57.4 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2001421412437657		[learning rate: 0.0071172]
	Learning Rate: 0.00711718
	LOSS [training: 0.2001421412437657 | validation: 0.4105672708524648]
	TIME [epoch: 57.4 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.186090095480004		[learning rate: 0.0070857]
	Learning Rate: 0.00708573
	LOSS [training: 0.186090095480004 | validation: 0.3280447976112536]
	TIME [epoch: 57.4 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18939546760181208		[learning rate: 0.0070544]
	Learning Rate: 0.00705442
	LOSS [training: 0.18939546760181208 | validation: 0.32333577838741906]
	TIME [epoch: 57.4 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2009963517559532		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 0.2009963517559532 | validation: 0.3842976986628044]
	TIME [epoch: 57.3 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20151235567431583		[learning rate: 0.0069922]
	Learning Rate: 0.00699222
	LOSS [training: 0.20151235567431583 | validation: 0.32111435700705304]
	TIME [epoch: 57.4 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2100052889939556		[learning rate: 0.0069613]
	Learning Rate: 0.00696133
	LOSS [training: 0.2100052889939556 | validation: 0.45358536154830986]
	TIME [epoch: 57.3 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2092931816986189		[learning rate: 0.0069306]
	Learning Rate: 0.00693057
	LOSS [training: 0.2092931816986189 | validation: 0.3596376692118376]
	TIME [epoch: 57.4 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1780952191176494		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 0.1780952191176494 | validation: 0.31683451754734515]
	TIME [epoch: 57.4 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20909701408538311		[learning rate: 0.0068695]
	Learning Rate: 0.00686947
	LOSS [training: 0.20909701408538311 | validation: 0.39657374422653235]
	TIME [epoch: 57.4 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21843408165422312		[learning rate: 0.0068391]
	Learning Rate: 0.00683912
	LOSS [training: 0.21843408165422312 | validation: 0.30727214534996056]
	TIME [epoch: 57.4 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v4_20240712_121719/states/model_facs_v2_dec2b_2dpca_v4_126.pth
	Model improved!!!
EPOCH 127/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18583395393586616		[learning rate: 0.0068089]
	Learning Rate: 0.0068089
	LOSS [training: 0.18583395393586616 | validation: 0.3444844258638814]
	TIME [epoch: 57.3 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18931738789139935		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 0.18931738789139935 | validation: 0.3267473490157395]
	TIME [epoch: 57.3 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18337191417851542		[learning rate: 0.0067489]
	Learning Rate: 0.00674887
	LOSS [training: 0.18337191417851542 | validation: 0.43948413501540445]
	TIME [epoch: 57.4 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.227422313963273		[learning rate: 0.006719]
	Learning Rate: 0.00671905
	LOSS [training: 0.227422313963273 | validation: 0.3216468135699909]
	TIME [epoch: 57.3 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1848736488439334		[learning rate: 0.0066894]
	Learning Rate: 0.00668936
	LOSS [training: 0.1848736488439334 | validation: 0.4131895634904569]
	TIME [epoch: 57.3 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1934567275085494		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 0.1934567275085494 | validation: 0.39675485037344654]
	TIME [epoch: 57.3 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19048981123466432		[learning rate: 0.0066304]
	Learning Rate: 0.00663038
	LOSS [training: 0.19048981123466432 | validation: 0.3014086063671562]
	TIME [epoch: 57.3 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v4_20240712_121719/states/model_facs_v2_dec2b_2dpca_v4_133.pth
	Model improved!!!
EPOCH 134/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1839829666755107		[learning rate: 0.0066011]
	Learning Rate: 0.00660109
	LOSS [training: 0.1839829666755107 | validation: 0.31765664851685943]
	TIME [epoch: 57.3 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20122543281663569		[learning rate: 0.0065719]
	Learning Rate: 0.00657192
	LOSS [training: 0.20122543281663569 | validation: 0.3381713106530633]
	TIME [epoch: 57.3 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21345379655009644		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 0.21345379655009644 | validation: 0.3445062180671422]
	TIME [epoch: 57.3 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19350004154923248		[learning rate: 0.006514]
	Learning Rate: 0.00651398
	LOSS [training: 0.19350004154923248 | validation: 0.4352802381356065]
	TIME [epoch: 57.4 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19912233644558291		[learning rate: 0.0064852]
	Learning Rate: 0.00648519
	LOSS [training: 0.19912233644558291 | validation: 0.3500252611135408]
	TIME [epoch: 57.3 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18192698356694867		[learning rate: 0.0064565]
	Learning Rate: 0.00645654
	LOSS [training: 0.18192698356694867 | validation: 0.3866392865750597]
	TIME [epoch: 57.3 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1937884513281348		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 0.1937884513281348 | validation: 0.32274195455122984]
	TIME [epoch: 57.3 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1879365767474234		[learning rate: 0.0063996]
	Learning Rate: 0.00639961
	LOSS [training: 0.1879365767474234 | validation: 0.3936108954495635]
	TIME [epoch: 57.3 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1935292321129922		[learning rate: 0.0063713]
	Learning Rate: 0.00637134
	LOSS [training: 0.1935292321129922 | validation: 0.3121997565178188]
	TIME [epoch: 57.2 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18540565398438041		[learning rate: 0.0063432]
	Learning Rate: 0.00634319
	LOSS [training: 0.18540565398438041 | validation: 0.3630555967347456]
	TIME [epoch: 57.3 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18021482257797028		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 0.18021482257797028 | validation: 0.33180295510746066]
	TIME [epoch: 57.3 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20561560083380997		[learning rate: 0.0062873]
	Learning Rate: 0.00628726
	LOSS [training: 0.20561560083380997 | validation: 0.30403581206312985]
	TIME [epoch: 57.3 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19135949257644258		[learning rate: 0.0062595]
	Learning Rate: 0.00625948
	LOSS [training: 0.19135949257644258 | validation: 0.4238291965696169]
	TIME [epoch: 57.3 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19204778664973818		[learning rate: 0.0062318]
	Learning Rate: 0.00623183
	LOSS [training: 0.19204778664973818 | validation: 0.37670868878521935]
	TIME [epoch: 57.3 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18437315311907435		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 0.18437315311907435 | validation: 0.3518548455495816]
	TIME [epoch: 57.3 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18886132847539766		[learning rate: 0.0061769]
	Learning Rate: 0.00617688
	LOSS [training: 0.18886132847539766 | validation: 0.35214385386918867]
	TIME [epoch: 57.3 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18076401262680558		[learning rate: 0.0061496]
	Learning Rate: 0.00614959
	LOSS [training: 0.18076401262680558 | validation: 0.3184801277359639]
	TIME [epoch: 57.2 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18729168989966033		[learning rate: 0.0061224]
	Learning Rate: 0.00612242
	LOSS [training: 0.18729168989966033 | validation: 0.34069421397682004]
	TIME [epoch: 57.3 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19596503781802813		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 0.19596503781802813 | validation: 0.4191522291825448]
	TIME [epoch: 57.3 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18599106898253576		[learning rate: 0.0060684]
	Learning Rate: 0.00606844
	LOSS [training: 0.18599106898253576 | validation: 0.33914769058190103]
	TIME [epoch: 57.3 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1744590685077291		[learning rate: 0.0060416]
	Learning Rate: 0.00604163
	LOSS [training: 0.1744590685077291 | validation: 0.3109489233454316]
	TIME [epoch: 57.3 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19013704384630992		[learning rate: 0.0060149]
	Learning Rate: 0.00601493
	LOSS [training: 0.19013704384630992 | validation: 0.3511704860725662]
	TIME [epoch: 57.3 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20599641872851962		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 0.20599641872851962 | validation: 0.33191635149754845]
	TIME [epoch: 57.3 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20504429917074862		[learning rate: 0.0059619]
	Learning Rate: 0.0059619
	LOSS [training: 0.20504429917074862 | validation: 0.3142004417246348]
	TIME [epoch: 57.3 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1773540206541528		[learning rate: 0.0059356]
	Learning Rate: 0.00593556
	LOSS [training: 0.1773540206541528 | validation: 0.38948801517262355]
	TIME [epoch: 57.3 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18442026293292063		[learning rate: 0.0059093]
	Learning Rate: 0.00590933
	LOSS [training: 0.18442026293292063 | validation: 0.30007795973158924]
	TIME [epoch: 57.3 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v4_20240712_121719/states/model_facs_v2_dec2b_2dpca_v4_159.pth
	Model improved!!!
EPOCH 160/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1813117291981673		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 0.1813117291981673 | validation: 0.33427604660288085]
	TIME [epoch: 57.4 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1834775273318627		[learning rate: 0.0058572]
	Learning Rate: 0.00585723
	LOSS [training: 0.1834775273318627 | validation: 0.35110330504295706]
	TIME [epoch: 57.4 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18139538427007493		[learning rate: 0.0058314]
	Learning Rate: 0.00583135
	LOSS [training: 0.18139538427007493 | validation: 0.32447125332881943]
	TIME [epoch: 57.4 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17550951038156898		[learning rate: 0.0058056]
	Learning Rate: 0.00580559
	LOSS [training: 0.17550951038156898 | validation: 0.3025837649924819]
	TIME [epoch: 57.4 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20025382081785797		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 0.20025382081785797 | validation: 0.34788504744192844]
	TIME [epoch: 57.6 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.184848731310701		[learning rate: 0.0057544]
	Learning Rate: 0.0057544
	LOSS [training: 0.184848731310701 | validation: 0.37524258345262773]
	TIME [epoch: 57.3 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1914463109304209		[learning rate: 0.005729]
	Learning Rate: 0.00572897
	LOSS [training: 0.1914463109304209 | validation: 0.3803376311062091]
	TIME [epoch: 57.3 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1840750433316253		[learning rate: 0.0057037]
	Learning Rate: 0.00570366
	LOSS [training: 0.1840750433316253 | validation: 0.33522955263859666]
	TIME [epoch: 57.3 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19319412081847628		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 0.19319412081847628 | validation: 0.3320664489219818]
	TIME [epoch: 57.3 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17451401832740351		[learning rate: 0.0056534]
	Learning Rate: 0.00565337
	LOSS [training: 0.17451401832740351 | validation: 0.31730182171217497]
	TIME [epoch: 57.3 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18694204857766383		[learning rate: 0.0056284]
	Learning Rate: 0.0056284
	LOSS [training: 0.18694204857766383 | validation: 0.4256457089563255]
	TIME [epoch: 57.3 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18532550217094895		[learning rate: 0.0056035]
	Learning Rate: 0.00560353
	LOSS [training: 0.18532550217094895 | validation: 0.3331435665513812]
	TIME [epoch: 57.3 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19756950370414322		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 0.19756950370414322 | validation: 0.31075015092220915]
	TIME [epoch: 57.3 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18076723613679163		[learning rate: 0.0055541]
	Learning Rate: 0.00555412
	LOSS [training: 0.18076723613679163 | validation: 0.3305304563851698]
	TIME [epoch: 57.3 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17837417325171837		[learning rate: 0.0055296]
	Learning Rate: 0.00552958
	LOSS [training: 0.17837417325171837 | validation: 0.30564057689072877]
	TIME [epoch: 57.3 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1784787676017851		[learning rate: 0.0055052]
	Learning Rate: 0.00550515
	LOSS [training: 0.1784787676017851 | validation: 0.32816179246409766]
	TIME [epoch: 57.3 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.196126836781839		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 0.196126836781839 | validation: 0.32964235491069965]
	TIME [epoch: 57.4 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17575741977431575		[learning rate: 0.0054566]
	Learning Rate: 0.00545661
	LOSS [training: 0.17575741977431575 | validation: 0.3533649684864663]
	TIME [epoch: 57.4 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18401736525704487		[learning rate: 0.0054325]
	Learning Rate: 0.0054325
	LOSS [training: 0.18401736525704487 | validation: 0.3765221190450871]
	TIME [epoch: 57.4 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19008287429859028		[learning rate: 0.0054085]
	Learning Rate: 0.0054085
	LOSS [training: 0.19008287429859028 | validation: 0.30812465558237906]
	TIME [epoch: 57.4 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19015421875853697		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 0.19015421875853697 | validation: 0.32127700291495903]
	TIME [epoch: 57.4 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1856654275662144		[learning rate: 0.0053608]
	Learning Rate: 0.00536081
	LOSS [training: 0.1856654275662144 | validation: 0.29709689178111653]
	TIME [epoch: 57.4 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v4_20240712_121719/states/model_facs_v2_dec2b_2dpca_v4_181.pth
	Model improved!!!
EPOCH 182/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19080556522473885		[learning rate: 0.0053371]
	Learning Rate: 0.00533713
	LOSS [training: 0.19080556522473885 | validation: 0.32014519059505464]
	TIME [epoch: 57.4 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1745427313647565		[learning rate: 0.0053135]
	Learning Rate: 0.00531355
	LOSS [training: 0.1745427313647565 | validation: 0.34859625077590084]
	TIME [epoch: 57.3 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17577809349819262		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 0.17577809349819262 | validation: 0.3412791263334852]
	TIME [epoch: 57.4 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18648914885964274		[learning rate: 0.0052667]
	Learning Rate: 0.0052667
	LOSS [training: 0.18648914885964274 | validation: 0.35188572909513305]
	TIME [epoch: 57.4 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17876390105531464		[learning rate: 0.0052434]
	Learning Rate: 0.00524343
	LOSS [training: 0.17876390105531464 | validation: 0.33348319040143476]
	TIME [epoch: 57.4 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19316873883403082		[learning rate: 0.0052203]
	Learning Rate: 0.00522026
	LOSS [training: 0.19316873883403082 | validation: 0.30414980596857283]
	TIME [epoch: 57.4 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17847362328563537		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 0.17847362328563537 | validation: 0.30026059926587345]
	TIME [epoch: 57.4 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1703447395356838		[learning rate: 0.0051742]
	Learning Rate: 0.00517423
	LOSS [training: 0.1703447395356838 | validation: 0.3538977179976206]
	TIME [epoch: 57.4 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19750618810647433		[learning rate: 0.0051514]
	Learning Rate: 0.00515137
	LOSS [training: 0.19750618810647433 | validation: 0.3113967277575706]
	TIME [epoch: 57.4 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17275749314529165		[learning rate: 0.0051286]
	Learning Rate: 0.00512861
	LOSS [training: 0.17275749314529165 | validation: 0.30774349604222107]
	TIME [epoch: 57.3 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17584163143667753		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 0.17584163143667753 | validation: 0.33669051501536124]
	TIME [epoch: 57.3 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1816756038994877		[learning rate: 0.0050834]
	Learning Rate: 0.00508339
	LOSS [training: 0.1816756038994877 | validation: 0.34538524595839787]
	TIME [epoch: 57.3 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17109519762297817		[learning rate: 0.0050609]
	Learning Rate: 0.00506093
	LOSS [training: 0.17109519762297817 | validation: 0.32356131618901174]
	TIME [epoch: 57.4 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17649375099668635		[learning rate: 0.0050386]
	Learning Rate: 0.00503857
	LOSS [training: 0.17649375099668635 | validation: 0.32430662366969343]
	TIME [epoch: 57.4 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17399456927418916		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 0.17399456927418916 | validation: 0.3427189832276093]
	TIME [epoch: 57.4 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17893375149272936		[learning rate: 0.0049941]
	Learning Rate: 0.00499415
	LOSS [training: 0.17893375149272936 | validation: 0.33580958185113297]
	TIME [epoch: 57.4 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17432884318883468		[learning rate: 0.0049721]
	Learning Rate: 0.00497208
	LOSS [training: 0.17432884318883468 | validation: 0.34587440129757613]
	TIME [epoch: 57.3 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19058480140100467		[learning rate: 0.0049501]
	Learning Rate: 0.00495012
	LOSS [training: 0.19058480140100467 | validation: 0.30585230476937614]
	TIME [epoch: 57.3 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17354192710843583		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 0.17354192710843583 | validation: 0.356442979042411]
	TIME [epoch: 57.3 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17743232365129988		[learning rate: 0.0049065]
	Learning Rate: 0.00490647
	LOSS [training: 0.17743232365129988 | validation: 0.2941336415649828]
	TIME [epoch: 146 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v4_20240712_121719/states/model_facs_v2_dec2b_2dpca_v4_201.pth
	Model improved!!!
EPOCH 202/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1737691682718597		[learning rate: 0.0048848]
	Learning Rate: 0.00488479
	LOSS [training: 0.1737691682718597 | validation: 0.2966295209215167]
	TIME [epoch: 119 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17251541126766284		[learning rate: 0.0048632]
	Learning Rate: 0.00486321
	LOSS [training: 0.17251541126766284 | validation: 0.30609803091946575]
	TIME [epoch: 119 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18047981338010405		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 0.18047981338010405 | validation: 0.35936988503329625]
	TIME [epoch: 119 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18033611592702722		[learning rate: 0.0048203]
	Learning Rate: 0.00482033
	LOSS [training: 0.18033611592702722 | validation: 0.34319760026065554]
	TIME [epoch: 119 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17917027342455988		[learning rate: 0.004799]
	Learning Rate: 0.00479903
	LOSS [training: 0.17917027342455988 | validation: 0.3532741023126868]
	TIME [epoch: 119 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1761929394717328		[learning rate: 0.0047778]
	Learning Rate: 0.00477783
	LOSS [training: 0.1761929394717328 | validation: 0.29565581502007554]
	TIME [epoch: 119 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1707077658537207		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.1707077658537207 | validation: 0.3953524684782973]
	TIME [epoch: 119 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18432602797179382		[learning rate: 0.0047357]
	Learning Rate: 0.0047357
	LOSS [training: 0.18432602797179382 | validation: 0.30714610715582213]
	TIME [epoch: 119 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17072476805402811		[learning rate: 0.0047148]
	Learning Rate: 0.00471478
	LOSS [training: 0.17072476805402811 | validation: 0.3187258271381362]
	TIME [epoch: 119 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17147437896840198		[learning rate: 0.0046939]
	Learning Rate: 0.00469395
	LOSS [training: 0.17147437896840198 | validation: 0.3211443912645706]
	TIME [epoch: 119 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.172405778844145		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 0.172405778844145 | validation: 0.3606225291348847]
	TIME [epoch: 119 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17310764545458018		[learning rate: 0.0046526]
	Learning Rate: 0.00465256
	LOSS [training: 0.17310764545458018 | validation: 0.3204534594937789]
	TIME [epoch: 119 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18254868190959778		[learning rate: 0.004632]
	Learning Rate: 0.00463201
	LOSS [training: 0.18254868190959778 | validation: 0.4201805973878224]
	TIME [epoch: 119 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17162240445839871		[learning rate: 0.0046115]
	Learning Rate: 0.00461154
	LOSS [training: 0.17162240445839871 | validation: 0.32131991472009036]
	TIME [epoch: 119 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17044754167363424		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 0.17044754167363424 | validation: 0.3477877050109825]
	TIME [epoch: 119 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16602707812587736		[learning rate: 0.0045709]
	Learning Rate: 0.00457088
	LOSS [training: 0.16602707812587736 | validation: 0.31482366573314624]
	TIME [epoch: 119 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17901414290249484		[learning rate: 0.0045507]
	Learning Rate: 0.00455069
	LOSS [training: 0.17901414290249484 | validation: 0.3252145332217743]
	TIME [epoch: 119 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17374581091479868		[learning rate: 0.0045306]
	Learning Rate: 0.00453058
	LOSS [training: 0.17374581091479868 | validation: 0.3295140558152936]
	TIME [epoch: 119 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16996874937112466		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 0.16996874937112466 | validation: 0.30744883531590506]
	TIME [epoch: 119 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16942668171749978		[learning rate: 0.0044906]
	Learning Rate: 0.00449063
	LOSS [training: 0.16942668171749978 | validation: 0.331028068881522]
	TIME [epoch: 119 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1697701510884705		[learning rate: 0.0044708]
	Learning Rate: 0.00447079
	LOSS [training: 0.1697701510884705 | validation: 0.31037423297044214]
	TIME [epoch: 119 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17527175625636393		[learning rate: 0.004451]
	Learning Rate: 0.00445104
	LOSS [training: 0.17527175625636393 | validation: 0.33722331513732656]
	TIME [epoch: 119 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17103284691286585		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 0.17103284691286585 | validation: 0.31183304771231124]
	TIME [epoch: 119 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17288147591621383		[learning rate: 0.0044118]
	Learning Rate: 0.0044118
	LOSS [training: 0.17288147591621383 | validation: 0.34159062018456393]
	TIME [epoch: 119 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17454045447982322		[learning rate: 0.0043923]
	Learning Rate: 0.0043923
	LOSS [training: 0.17454045447982322 | validation: 0.31283377961385345]
	TIME [epoch: 119 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1771938774814708		[learning rate: 0.0043729]
	Learning Rate: 0.0043729
	LOSS [training: 0.1771938774814708 | validation: 0.3125432377485814]
	TIME [epoch: 119 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17421463630293066		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 0.17421463630293066 | validation: 0.3043547695327633]
	TIME [epoch: 119 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1742755678184087		[learning rate: 0.0043343]
	Learning Rate: 0.00433434
	LOSS [training: 0.1742755678184087 | validation: 0.2923507470651994]
	TIME [epoch: 119 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v4_20240712_121719/states/model_facs_v2_dec2b_2dpca_v4_229.pth
	Model improved!!!
EPOCH 230/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17104798552887998		[learning rate: 0.0043152]
	Learning Rate: 0.00431519
	LOSS [training: 0.17104798552887998 | validation: 0.2986707766938451]
	TIME [epoch: 119 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1797753258030142		[learning rate: 0.0042961]
	Learning Rate: 0.00429612
	LOSS [training: 0.1797753258030142 | validation: 0.321543965602159]
	TIME [epoch: 119 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17438252883674032		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 0.17438252883674032 | validation: 0.30145024139447646]
	TIME [epoch: 119 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17175180114070224		[learning rate: 0.0042582]
	Learning Rate: 0.00425825
	LOSS [training: 0.17175180114070224 | validation: 0.3522006706056943]
	TIME [epoch: 119 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18335272208346642		[learning rate: 0.0042394]
	Learning Rate: 0.00423943
	LOSS [training: 0.18335272208346642 | validation: 0.32914618511077565]
	TIME [epoch: 119 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17166476270737357		[learning rate: 0.0042207]
	Learning Rate: 0.0042207
	LOSS [training: 0.17166476270737357 | validation: 0.30155115626354234]
	TIME [epoch: 119 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16974972461943724		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 0.16974972461943724 | validation: 0.30392393290031705]
	TIME [epoch: 119 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1668745517289056		[learning rate: 0.0041835]
	Learning Rate: 0.00418349
	LOSS [training: 0.1668745517289056 | validation: 0.31470568489297795]
	TIME [epoch: 119 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17326314375673474		[learning rate: 0.004165]
	Learning Rate: 0.004165
	LOSS [training: 0.17326314375673474 | validation: 0.3519830549598348]
	TIME [epoch: 119 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17252019974033816		[learning rate: 0.0041466]
	Learning Rate: 0.0041466
	LOSS [training: 0.17252019974033816 | validation: 0.31351066590119836]
	TIME [epoch: 119 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16498303129217814		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 0.16498303129217814 | validation: 0.3331230051532304]
	TIME [epoch: 119 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16250339036739297		[learning rate: 0.00411]
	Learning Rate: 0.00411004
	LOSS [training: 0.16250339036739297 | validation: 0.3542378347393213]
	TIME [epoch: 119 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18196891310150481		[learning rate: 0.0040919]
	Learning Rate: 0.00409188
	LOSS [training: 0.18196891310150481 | validation: 0.3114176521454741]
	TIME [epoch: 119 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18366346595288127		[learning rate: 0.0040738]
	Learning Rate: 0.0040738
	LOSS [training: 0.18366346595288127 | validation: 0.33454144370080197]
	TIME [epoch: 119 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16852569559567998		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.16852569559567998 | validation: 0.283041952260593]
	TIME [epoch: 119 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v4_20240712_121719/states/model_facs_v2_dec2b_2dpca_v4_244.pth
	Model improved!!!
EPOCH 245/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16811873155035234		[learning rate: 0.0040379]
	Learning Rate: 0.00403788
	LOSS [training: 0.16811873155035234 | validation: 0.29269386929768254]
	TIME [epoch: 120 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16437521595346063		[learning rate: 0.00402]
	Learning Rate: 0.00402004
	LOSS [training: 0.16437521595346063 | validation: 0.32992887749913574]
	TIME [epoch: 120 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.169580772237461		[learning rate: 0.0040023]
	Learning Rate: 0.00400228
	LOSS [training: 0.169580772237461 | validation: 0.3022503101007099]
	TIME [epoch: 120 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16932518943035335		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 0.16932518943035335 | validation: 0.31466465607818106]
	TIME [epoch: 120 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16345962097449301		[learning rate: 0.003967]
	Learning Rate: 0.00396699
	LOSS [training: 0.16345962097449301 | validation: 0.29519435326670534]
	TIME [epoch: 120 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16121251134100037		[learning rate: 0.0039495]
	Learning Rate: 0.00394947
	LOSS [training: 0.16121251134100037 | validation: 0.30586375853240694]
	TIME [epoch: 120 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1717986003232511		[learning rate: 0.003932]
	Learning Rate: 0.00393202
	LOSS [training: 0.1717986003232511 | validation: 0.2994268207887078]
	TIME [epoch: 120 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16388416899697497		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 0.16388416899697497 | validation: 0.3212534169595596]
	TIME [epoch: 119 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18148719128617152		[learning rate: 0.0038973]
	Learning Rate: 0.00389735
	LOSS [training: 0.18148719128617152 | validation: 0.2990518402308175]
	TIME [epoch: 120 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17856254814418518		[learning rate: 0.0038801]
	Learning Rate: 0.00388013
	LOSS [training: 0.17856254814418518 | validation: 0.30015028091466717]
	TIME [epoch: 119 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17704178406586701		[learning rate: 0.003863]
	Learning Rate: 0.00386299
	LOSS [training: 0.17704178406586701 | validation: 0.3152657827556179]
	TIME [epoch: 120 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.167776245112396		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 0.167776245112396 | validation: 0.3063765494465153]
	TIME [epoch: 120 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1599634864455768		[learning rate: 0.0038289]
	Learning Rate: 0.00382893
	LOSS [training: 0.1599634864455768 | validation: 0.3239622071795405]
	TIME [epoch: 120 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17267018119332594		[learning rate: 0.003812]
	Learning Rate: 0.00381201
	LOSS [training: 0.17267018119332594 | validation: 0.3131464571108341]
	TIME [epoch: 119 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16030535538286367		[learning rate: 0.0037952]
	Learning Rate: 0.00379517
	LOSS [training: 0.16030535538286367 | validation: 0.3324927095008099]
	TIME [epoch: 120 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16321333947081665		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 0.16321333947081665 | validation: 0.34030705948660783]
	TIME [epoch: 120 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16578376600738678		[learning rate: 0.0037617]
	Learning Rate: 0.0037617
	LOSS [training: 0.16578376600738678 | validation: 0.29743695370809]
	TIME [epoch: 120 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16950846351953291		[learning rate: 0.0037451]
	Learning Rate: 0.00374508
	LOSS [training: 0.16950846351953291 | validation: 0.2989714307218782]
	TIME [epoch: 119 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16516927406120865		[learning rate: 0.0037285]
	Learning Rate: 0.00372854
	LOSS [training: 0.16516927406120865 | validation: 0.3168404470870231]
	TIME [epoch: 120 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16877398079384062		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 0.16877398079384062 | validation: 0.31014678624236436]
	TIME [epoch: 119 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1632757462816929		[learning rate: 0.0036957]
	Learning Rate: 0.00369566
	LOSS [training: 0.1632757462816929 | validation: 0.3068972876550486]
	TIME [epoch: 120 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17820507703680333		[learning rate: 0.0036793]
	Learning Rate: 0.00367933
	LOSS [training: 0.17820507703680333 | validation: 0.31296177330388925]
	TIME [epoch: 119 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16316293997475056		[learning rate: 0.0036631]
	Learning Rate: 0.00366308
	LOSS [training: 0.16316293997475056 | validation: 0.3415473308652469]
	TIME [epoch: 119 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15885120873460223		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 0.15885120873460223 | validation: 0.31991504357326334]
	TIME [epoch: 119 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1652101880749694		[learning rate: 0.0036308]
	Learning Rate: 0.00363078
	LOSS [training: 0.1652101880749694 | validation: 0.3659027257210462]
	TIME [epoch: 119 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1754347414049275		[learning rate: 0.0036147]
	Learning Rate: 0.00361474
	LOSS [training: 0.1754347414049275 | validation: 0.3364719294874999]
	TIME [epoch: 120 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17171569652507893		[learning rate: 0.0035988]
	Learning Rate: 0.00359877
	LOSS [training: 0.17171569652507893 | validation: 0.3013342732930466]
	TIME [epoch: 120 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16650389230424825		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 0.16650389230424825 | validation: 0.3252986611401211]
	TIME [epoch: 120 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16737846581112623		[learning rate: 0.003567]
	Learning Rate: 0.00356704
	LOSS [training: 0.16737846581112623 | validation: 0.3036108144451268]
	TIME [epoch: 120 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1673520071642754		[learning rate: 0.0035513]
	Learning Rate: 0.00355128
	LOSS [training: 0.1673520071642754 | validation: 0.30298459093202984]
	TIME [epoch: 120 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16371356412830668		[learning rate: 0.0035356]
	Learning Rate: 0.00353559
	LOSS [training: 0.16371356412830668 | validation: 0.29597826713361786]
	TIME [epoch: 120 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1557935260032574		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 0.1557935260032574 | validation: 0.29660863203834337]
	TIME [epoch: 119 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16734404031842506		[learning rate: 0.0035044]
	Learning Rate: 0.00350441
	LOSS [training: 0.16734404031842506 | validation: 0.29895110592509405]
	TIME [epoch: 120 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16015246322471058		[learning rate: 0.0034889]
	Learning Rate: 0.00348893
	LOSS [training: 0.16015246322471058 | validation: 0.2979007467571589]
	TIME [epoch: 120 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1750459151838156		[learning rate: 0.0034735]
	Learning Rate: 0.00347352
	LOSS [training: 0.1750459151838156 | validation: 0.30649692061884976]
	TIME [epoch: 120 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16851219268068368		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.16851219268068368 | validation: 0.2984211757857934]
	TIME [epoch: 119 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17445569544020728		[learning rate: 0.0034429]
	Learning Rate: 0.00344289
	LOSS [training: 0.17445569544020728 | validation: 0.2995674663412652]
	TIME [epoch: 120 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16188907346447706		[learning rate: 0.0034277]
	Learning Rate: 0.00342768
	LOSS [training: 0.16188907346447706 | validation: 0.34414136119174693]
	TIME [epoch: 119 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1719359510791963		[learning rate: 0.0034125]
	Learning Rate: 0.00341253
	LOSS [training: 0.1719359510791963 | validation: 0.30687159955091303]
	TIME [epoch: 120 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17469277605103498		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 0.17469277605103498 | validation: 0.29183367497402335]
	TIME [epoch: 119 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1615373960021144		[learning rate: 0.0033824]
	Learning Rate: 0.00338245
	LOSS [training: 0.1615373960021144 | validation: 0.3080606773152366]
	TIME [epoch: 120 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16567619282598153		[learning rate: 0.0033675]
	Learning Rate: 0.0033675
	LOSS [training: 0.16567619282598153 | validation: 0.31190299466229887]
	TIME [epoch: 119 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16049309535037182		[learning rate: 0.0033526]
	Learning Rate: 0.00335262
	LOSS [training: 0.16049309535037182 | validation: 0.3219830492580012]
	TIME [epoch: 120 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1607860418110784		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 0.1607860418110784 | validation: 0.33272091997091097]
	TIME [epoch: 119 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16497537997911016		[learning rate: 0.0033231]
	Learning Rate: 0.00332306
	LOSS [training: 0.16497537997911016 | validation: 0.3446583547562708]
	TIME [epoch: 120 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1669466598125398		[learning rate: 0.0033084]
	Learning Rate: 0.00330838
	LOSS [training: 0.1669466598125398 | validation: 0.30068901582282476]
	TIME [epoch: 119 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15908132907112776		[learning rate: 0.0032938]
	Learning Rate: 0.00329376
	LOSS [training: 0.15908132907112776 | validation: 0.28209207586713586]
	TIME [epoch: 120 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v4_20240712_121719/states/model_facs_v2_dec2b_2dpca_v4_291.pth
	Model improved!!!
EPOCH 292/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16834758524595408		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 0.16834758524595408 | validation: 0.30976574539676455]
	TIME [epoch: 120 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16678000023691902		[learning rate: 0.0032647]
	Learning Rate: 0.00326472
	LOSS [training: 0.16678000023691902 | validation: 0.28911204080548786]
	TIME [epoch: 120 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16910506988576096		[learning rate: 0.0032503]
	Learning Rate: 0.0032503
	LOSS [training: 0.16910506988576096 | validation: 0.30417188286232616]
	TIME [epoch: 120 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1628240395861754		[learning rate: 0.0032359]
	Learning Rate: 0.00323594
	LOSS [training: 0.1628240395861754 | validation: 0.30200724628218145]
	TIME [epoch: 120 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16273349897370898		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 0.16273349897370898 | validation: 0.32042421660147963]
	TIME [epoch: 120 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16140840656877678		[learning rate: 0.0032074]
	Learning Rate: 0.00320741
	LOSS [training: 0.16140840656877678 | validation: 0.2987765647138693]
	TIME [epoch: 120 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16481166608565984		[learning rate: 0.0031932]
	Learning Rate: 0.00319323
	LOSS [training: 0.16481166608565984 | validation: 0.295935540875441]
	TIME [epoch: 120 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16114954091443115		[learning rate: 0.0031791]
	Learning Rate: 0.00317913
	LOSS [training: 0.16114954091443115 | validation: 0.29890750781987213]
	TIME [epoch: 120 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1659917203082833		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 0.1659917203082833 | validation: 0.3360696998055127]
	TIME [epoch: 120 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16477466907873242		[learning rate: 0.0031511]
	Learning Rate: 0.0031511
	LOSS [training: 0.16477466907873242 | validation: 0.30542994752560837]
	TIME [epoch: 120 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15965963195471478		[learning rate: 0.0031372]
	Learning Rate: 0.00313717
	LOSS [training: 0.15965963195471478 | validation: 0.3108163348477843]
	TIME [epoch: 120 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1606338814564528		[learning rate: 0.0031233]
	Learning Rate: 0.00312331
	LOSS [training: 0.1606338814564528 | validation: 0.2997179524024148]
	TIME [epoch: 120 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17408791268861834		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 0.17408791268861834 | validation: 0.2994674521712534]
	TIME [epoch: 120 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16229924660948364		[learning rate: 0.0030958]
	Learning Rate: 0.00309577
	LOSS [training: 0.16229924660948364 | validation: 0.3232307669458924]
	TIME [epoch: 120 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16534546105115905		[learning rate: 0.0030821]
	Learning Rate: 0.0030821
	LOSS [training: 0.16534546105115905 | validation: 0.3172662221945744]
	TIME [epoch: 120 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16962524969825715		[learning rate: 0.0030685]
	Learning Rate: 0.00306848
	LOSS [training: 0.16962524969825715 | validation: 0.2901373173290632]
	TIME [epoch: 120 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15736023936476215		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 0.15736023936476215 | validation: 0.32144200022612757]
	TIME [epoch: 120 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1644726020474811		[learning rate: 0.0030414]
	Learning Rate: 0.00304142
	LOSS [training: 0.1644726020474811 | validation: 0.29112582043921903]
	TIME [epoch: 120 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16233613478039893		[learning rate: 0.003028]
	Learning Rate: 0.00302799
	LOSS [training: 0.16233613478039893 | validation: 0.3113357293736265]
	TIME [epoch: 120 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16392226151462744		[learning rate: 0.0030146]
	Learning Rate: 0.00301461
	LOSS [training: 0.16392226151462744 | validation: 0.31822972122917936]
	TIME [epoch: 120 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1623843698615613		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 0.1623843698615613 | validation: 0.2981329925863712]
	TIME [epoch: 120 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1595272507424571		[learning rate: 0.002988]
	Learning Rate: 0.00298803
	LOSS [training: 0.1595272507424571 | validation: 0.30921612642921753]
	TIME [epoch: 120 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1657658055330334		[learning rate: 0.0029748]
	Learning Rate: 0.00297483
	LOSS [training: 0.1657658055330334 | validation: 0.3760546468254407]
	TIME [epoch: 120 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17141899619853523		[learning rate: 0.0029617]
	Learning Rate: 0.00296168
	LOSS [training: 0.17141899619853523 | validation: 0.29917119301858547]
	TIME [epoch: 120 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1638407961238319		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.1638407961238319 | validation: 0.3167548122097411]
	TIME [epoch: 120 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16261975906516893		[learning rate: 0.0029356]
	Learning Rate: 0.00293557
	LOSS [training: 0.16261975906516893 | validation: 0.3295845647970935]
	TIME [epoch: 120 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16465097001569365		[learning rate: 0.0029226]
	Learning Rate: 0.0029226
	LOSS [training: 0.16465097001569365 | validation: 0.3292410304456885]
	TIME [epoch: 120 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15991937014562219		[learning rate: 0.0029097]
	Learning Rate: 0.00290969
	LOSS [training: 0.15991937014562219 | validation: 0.30584198607761476]
	TIME [epoch: 120 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16134762960187005		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 0.16134762960187005 | validation: 0.29704778667713033]
	TIME [epoch: 120 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16048792222550162		[learning rate: 0.002884]
	Learning Rate: 0.00288403
	LOSS [training: 0.16048792222550162 | validation: 0.3109660561429612]
	TIME [epoch: 120 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16662971611797134		[learning rate: 0.0028713]
	Learning Rate: 0.00287129
	LOSS [training: 0.16662971611797134 | validation: 0.2829430132594055]
	TIME [epoch: 120 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16098073046264566		[learning rate: 0.0028586]
	Learning Rate: 0.0028586
	LOSS [training: 0.16098073046264566 | validation: 0.2937281377610405]
	TIME [epoch: 120 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16148357531603996		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 0.16148357531603996 | validation: 0.2890851071080058]
	TIME [epoch: 120 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16036551778981498		[learning rate: 0.0028334]
	Learning Rate: 0.0028334
	LOSS [training: 0.16036551778981498 | validation: 0.33084973864641937]
	TIME [epoch: 119 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.159570545705304		[learning rate: 0.0028209]
	Learning Rate: 0.00282088
	LOSS [training: 0.159570545705304 | validation: 0.30796979097321636]
	TIME [epoch: 120 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16218682837109097		[learning rate: 0.0028084]
	Learning Rate: 0.00280842
	LOSS [training: 0.16218682837109097 | validation: 0.29445434096227313]
	TIME [epoch: 120 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1615150908361219		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 0.1615150908361219 | validation: 0.30870879846661586]
	TIME [epoch: 120 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17023164487457776		[learning rate: 0.0027837]
	Learning Rate: 0.00278366
	LOSS [training: 0.17023164487457776 | validation: 0.3115926852818795]
	TIME [epoch: 120 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15646060422691327		[learning rate: 0.0027714]
	Learning Rate: 0.00277136
	LOSS [training: 0.15646060422691327 | validation: 0.31279699531621274]
	TIME [epoch: 120 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16038165822879		[learning rate: 0.0027591]
	Learning Rate: 0.00275911
	LOSS [training: 0.16038165822879 | validation: 0.3046265910914048]
	TIME [epoch: 120 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16203948926321432		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 0.16203948926321432 | validation: 0.3037475049153534]
	TIME [epoch: 120 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16443719738499024		[learning rate: 0.0027348]
	Learning Rate: 0.00273478
	LOSS [training: 0.16443719738499024 | validation: 0.3200609861682221]
	TIME [epoch: 120 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16704296414539244		[learning rate: 0.0027227]
	Learning Rate: 0.0027227
	LOSS [training: 0.16704296414539244 | validation: 0.2927797463676227]
	TIME [epoch: 120 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15635242941006222		[learning rate: 0.0027107]
	Learning Rate: 0.00271067
	LOSS [training: 0.15635242941006222 | validation: 0.2920486364829777]
	TIME [epoch: 120 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1575350948328005		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 0.1575350948328005 | validation: 0.30700786301649446]
	TIME [epoch: 120 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16860845626834473		[learning rate: 0.0026868]
	Learning Rate: 0.00268677
	LOSS [training: 0.16860845626834473 | validation: 0.31593687524782194]
	TIME [epoch: 120 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1569494859517474		[learning rate: 0.0026749]
	Learning Rate: 0.0026749
	LOSS [training: 0.1569494859517474 | validation: 0.2957811425233403]
	TIME [epoch: 120 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16036103607125515		[learning rate: 0.0026631]
	Learning Rate: 0.00266308
	LOSS [training: 0.16036103607125515 | validation: 0.3032465436233522]
	TIME [epoch: 120 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.159516950439138		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 0.159516950439138 | validation: 0.3030570033297431]
	TIME [epoch: 120 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15922555620860473		[learning rate: 0.0026396]
	Learning Rate: 0.0026396
	LOSS [training: 0.15922555620860473 | validation: 0.2921584359787312]
	TIME [epoch: 120 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16384861383176835		[learning rate: 0.0026279]
	Learning Rate: 0.00262794
	LOSS [training: 0.16384861383176835 | validation: 0.30958812950547737]
	TIME [epoch: 119 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16057627205646324		[learning rate: 0.0026163]
	Learning Rate: 0.00261633
	LOSS [training: 0.16057627205646324 | validation: 0.30556211506527925]
	TIME [epoch: 119 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1624860690016491		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 0.1624860690016491 | validation: 0.3127071738044708]
	TIME [epoch: 119 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15708411041574402		[learning rate: 0.0025933]
	Learning Rate: 0.00259326
	LOSS [training: 0.15708411041574402 | validation: 0.30550674881693624]
	TIME [epoch: 119 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16275982090474286		[learning rate: 0.0025818]
	Learning Rate: 0.0025818
	LOSS [training: 0.16275982090474286 | validation: 0.2910055719814577]
	TIME [epoch: 119 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1550308658082534		[learning rate: 0.0025704]
	Learning Rate: 0.0025704
	LOSS [training: 0.1550308658082534 | validation: 0.298140232710342]
	TIME [epoch: 119 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1632157698456398		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.1632157698456398 | validation: 0.2937201701535313]
	TIME [epoch: 120 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1615472224938736		[learning rate: 0.0025477]
	Learning Rate: 0.00254773
	LOSS [training: 0.1615472224938736 | validation: 0.3027332808564798]
	TIME [epoch: 119 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16379409468175915		[learning rate: 0.0025365]
	Learning Rate: 0.00253648
	LOSS [training: 0.16379409468175915 | validation: 0.3023371301455946]
	TIME [epoch: 120 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16872490379935876		[learning rate: 0.0025253]
	Learning Rate: 0.00252527
	LOSS [training: 0.16872490379935876 | validation: 0.2825677457012466]
	TIME [epoch: 119 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15667648277734114		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.15667648277734114 | validation: 0.2916630201791621]
	TIME [epoch: 119 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1563036261658846		[learning rate: 0.002503]
	Learning Rate: 0.002503
	LOSS [training: 0.1563036261658846 | validation: 0.29557931089695233]
	TIME [epoch: 119 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15973417014809316		[learning rate: 0.0024919]
	Learning Rate: 0.00249194
	LOSS [training: 0.15973417014809316 | validation: 0.2959498914870112]
	TIME [epoch: 119 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15794384205167977		[learning rate: 0.0024809]
	Learning Rate: 0.00248093
	LOSS [training: 0.15794384205167977 | validation: 0.28627582072056634]
	TIME [epoch: 120 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15801074845633128		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 0.15801074845633128 | validation: 0.28709568260589546]
	TIME [epoch: 120 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15525974486289912		[learning rate: 0.0024591]
	Learning Rate: 0.00245906
	LOSS [training: 0.15525974486289912 | validation: 0.2945064315468057]
	TIME [epoch: 120 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15711172008608204		[learning rate: 0.0024482]
	Learning Rate: 0.0024482
	LOSS [training: 0.15711172008608204 | validation: 0.2961750401088185]
	TIME [epoch: 120 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16748264323122977		[learning rate: 0.0024374]
	Learning Rate: 0.00243738
	LOSS [training: 0.16748264323122977 | validation: 0.2896960859224361]
	TIME [epoch: 120 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1570957467521916		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.1570957467521916 | validation: 0.3179163184375937]
	TIME [epoch: 120 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16012683207614725		[learning rate: 0.0024159]
	Learning Rate: 0.00241589
	LOSS [training: 0.16012683207614725 | validation: 0.2836166547203733]
	TIME [epoch: 120 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15820437699482662		[learning rate: 0.0024052]
	Learning Rate: 0.00240521
	LOSS [training: 0.15820437699482662 | validation: 0.31002381778310184]
	TIME [epoch: 119 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16044140031354512		[learning rate: 0.0023946]
	Learning Rate: 0.00239459
	LOSS [training: 0.16044140031354512 | validation: 0.3010953708243288]
	TIME [epoch: 120 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1586017320932628		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 0.1586017320932628 | validation: 0.308163042887756]
	TIME [epoch: 120 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16108049764004517		[learning rate: 0.0023735]
	Learning Rate: 0.00237347
	LOSS [training: 0.16108049764004517 | validation: 0.3091837300232578]
	TIME [epoch: 120 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16082514156260502		[learning rate: 0.002363]
	Learning Rate: 0.00236299
	LOSS [training: 0.16082514156260502 | validation: 0.2856129743913763]
	TIME [epoch: 120 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1598046878925051		[learning rate: 0.0023525]
	Learning Rate: 0.00235255
	LOSS [training: 0.1598046878925051 | validation: 0.2973461299373492]
	TIME [epoch: 120 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1594937148570023		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.1594937148570023 | validation: 0.30855560671724075]
	TIME [epoch: 120 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15883734930864668		[learning rate: 0.0023318]
	Learning Rate: 0.00233181
	LOSS [training: 0.15883734930864668 | validation: 0.31382037550134456]
	TIME [epoch: 120 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1592055759212995		[learning rate: 0.0023215]
	Learning Rate: 0.0023215
	LOSS [training: 0.1592055759212995 | validation: 0.29838532228679815]
	TIME [epoch: 120 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15703723786349152		[learning rate: 0.0023112]
	Learning Rate: 0.00231125
	LOSS [training: 0.15703723786349152 | validation: 0.2912781009085837]
	TIME [epoch: 120 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15616702059884982		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.15616702059884982 | validation: 0.3138982762076285]
	TIME [epoch: 120 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15924316473197836		[learning rate: 0.0022909]
	Learning Rate: 0.00229087
	LOSS [training: 0.15924316473197836 | validation: 0.29702256425294904]
	TIME [epoch: 120 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1566648155969206		[learning rate: 0.0022807]
	Learning Rate: 0.00228075
	LOSS [training: 0.1566648155969206 | validation: 0.30614350068565327]
	TIME [epoch: 120 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15857520181990242		[learning rate: 0.0022707]
	Learning Rate: 0.00227067
	LOSS [training: 0.15857520181990242 | validation: 0.2962451435857178]
	TIME [epoch: 120 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15234895076378685		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.15234895076378685 | validation: 0.3253637050511688]
	TIME [epoch: 120 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1509099592791701		[learning rate: 0.0022506]
	Learning Rate: 0.00225065
	LOSS [training: 0.1509099592791701 | validation: 0.321137398750371]
	TIME [epoch: 120 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16953147766617335		[learning rate: 0.0022407]
	Learning Rate: 0.0022407
	LOSS [training: 0.16953147766617335 | validation: 0.32369792049186125]
	TIME [epoch: 120 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.159811371972636		[learning rate: 0.0022308]
	Learning Rate: 0.0022308
	LOSS [training: 0.159811371972636 | validation: 0.3159611958527694]
	TIME [epoch: 120 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1577454329117506		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.1577454329117506 | validation: 0.3043024011832658]
	TIME [epoch: 120 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1604494781705126		[learning rate: 0.0022111]
	Learning Rate: 0.00221114
	LOSS [training: 0.1604494781705126 | validation: 0.30211066584605767]
	TIME [epoch: 120 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15662886733317463		[learning rate: 0.0022014]
	Learning Rate: 0.00220137
	LOSS [training: 0.15662886733317463 | validation: 0.2901662651387716]
	TIME [epoch: 120 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15649879838202427		[learning rate: 0.0021916]
	Learning Rate: 0.00219164
	LOSS [training: 0.15649879838202427 | validation: 0.2848101395670185]
	TIME [epoch: 120 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1591731548471353		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.1591731548471353 | validation: 0.30869894977216655]
	TIME [epoch: 120 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15364930036103647		[learning rate: 0.0021723]
	Learning Rate: 0.00217232
	LOSS [training: 0.15364930036103647 | validation: 0.3066860343358316]
	TIME [epoch: 119 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16250646868695884		[learning rate: 0.0021627]
	Learning Rate: 0.00216272
	LOSS [training: 0.16250646868695884 | validation: 0.3025135599890373]
	TIME [epoch: 120 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15622841317054498		[learning rate: 0.0021532]
	Learning Rate: 0.00215316
	LOSS [training: 0.15622841317054498 | validation: 0.28606838113286803]
	TIME [epoch: 119 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15508506770323166		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.15508506770323166 | validation: 0.3027258475598865]
	TIME [epoch: 120 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1546044549828425		[learning rate: 0.0021342]
	Learning Rate: 0.00213418
	LOSS [training: 0.1546044549828425 | validation: 0.31511585009073045]
	TIME [epoch: 120 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1596803362349128		[learning rate: 0.0021247]
	Learning Rate: 0.00212475
	LOSS [training: 0.1596803362349128 | validation: 0.3106300172567109]
	TIME [epoch: 119 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15617697898439273		[learning rate: 0.0021154]
	Learning Rate: 0.00211536
	LOSS [training: 0.15617697898439273 | validation: 0.3070384485598778]
	TIME [epoch: 119 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15838697533479323		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.15838697533479323 | validation: 0.3068341220100464]
	TIME [epoch: 120 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15741536325498012		[learning rate: 0.0020967]
	Learning Rate: 0.00209671
	LOSS [training: 0.15741536325498012 | validation: 0.28719143642755507]
	TIME [epoch: 120 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15764379581606439		[learning rate: 0.0020874]
	Learning Rate: 0.00208745
	LOSS [training: 0.15764379581606439 | validation: 0.29659261958953115]
	TIME [epoch: 120 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15669136521762198		[learning rate: 0.0020782]
	Learning Rate: 0.00207822
	LOSS [training: 0.15669136521762198 | validation: 0.3027825160704242]
	TIME [epoch: 120 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15918170949248786		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.15918170949248786 | validation: 0.29021332838646685]
	TIME [epoch: 119 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15848750466964825		[learning rate: 0.0020599]
	Learning Rate: 0.0020599
	LOSS [training: 0.15848750466964825 | validation: 0.2913795997834086]
	TIME [epoch: 119 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1616716384149277		[learning rate: 0.0020508]
	Learning Rate: 0.0020508
	LOSS [training: 0.1616716384149277 | validation: 0.2917824535341843]
	TIME [epoch: 119 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1523951230237138		[learning rate: 0.0020417]
	Learning Rate: 0.00204174
	LOSS [training: 0.1523951230237138 | validation: 0.302135743451733]
	TIME [epoch: 119 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15589082430460005		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.15589082430460005 | validation: 0.30507470047467555]
	TIME [epoch: 119 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1582367535571061		[learning rate: 0.0020237]
	Learning Rate: 0.00202374
	LOSS [training: 0.1582367535571061 | validation: 0.3188365694406786]
	TIME [epoch: 120 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15538871235587512		[learning rate: 0.0020148]
	Learning Rate: 0.00201479
	LOSS [training: 0.15538871235587512 | validation: 0.31588183932034597]
	TIME [epoch: 120 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1630190909222635		[learning rate: 0.0020059]
	Learning Rate: 0.00200589
	LOSS [training: 0.1630190909222635 | validation: 0.31746836240563375]
	TIME [epoch: 119 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15695904250616952		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.15695904250616952 | validation: 0.295615308238887]
	TIME [epoch: 120 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15799941253986155		[learning rate: 0.0019882]
	Learning Rate: 0.00198821
	LOSS [training: 0.15799941253986155 | validation: 0.29608938514305977]
	TIME [epoch: 119 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1517701200453992		[learning rate: 0.0019794]
	Learning Rate: 0.00197942
	LOSS [training: 0.1517701200453992 | validation: 0.3115441623060595]
	TIME [epoch: 120 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15305970363379118		[learning rate: 0.0019707]
	Learning Rate: 0.00197068
	LOSS [training: 0.15305970363379118 | validation: 0.2904937542503202]
	TIME [epoch: 120 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15410226840057778		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.15410226840057778 | validation: 0.2981953536098014]
	TIME [epoch: 120 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16158814662363685		[learning rate: 0.0019533]
	Learning Rate: 0.0019533
	LOSS [training: 0.16158814662363685 | validation: 0.32014744720135857]
	TIME [epoch: 119 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1582945618097748		[learning rate: 0.0019447]
	Learning Rate: 0.00194467
	LOSS [training: 0.1582945618097748 | validation: 0.29016216064935674]
	TIME [epoch: 119 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15633179200675676		[learning rate: 0.0019361]
	Learning Rate: 0.00193608
	LOSS [training: 0.15633179200675676 | validation: 0.3021943867118965]
	TIME [epoch: 120 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15521608981060564		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.15521608981060564 | validation: 0.29243608344443833]
	TIME [epoch: 120 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15585357836295222		[learning rate: 0.001919]
	Learning Rate: 0.00191901
	LOSS [training: 0.15585357836295222 | validation: 0.2927173977901783]
	TIME [epoch: 120 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15518376986067586		[learning rate: 0.0019105]
	Learning Rate: 0.00191053
	LOSS [training: 0.15518376986067586 | validation: 0.29425417573836987]
	TIME [epoch: 120 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15355019505912837		[learning rate: 0.0019021]
	Learning Rate: 0.00190209
	LOSS [training: 0.15355019505912837 | validation: 0.29946635470337735]
	TIME [epoch: 120 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15770441930993115		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.15770441930993115 | validation: 0.3009089546222072]
	TIME [epoch: 119 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1555783245899989		[learning rate: 0.0018853]
	Learning Rate: 0.00188532
	LOSS [training: 0.1555783245899989 | validation: 0.2932243499837665]
	TIME [epoch: 119 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15109152285732114		[learning rate: 0.001877]
	Learning Rate: 0.00187699
	LOSS [training: 0.15109152285732114 | validation: 0.29306083262828503]
	TIME [epoch: 120 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15719300185029103		[learning rate: 0.0018687]
	Learning Rate: 0.0018687
	LOSS [training: 0.15719300185029103 | validation: 0.28476029416484505]
	TIME [epoch: 120 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15724311462123125		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.15724311462123125 | validation: 0.2997348234947319]
	TIME [epoch: 119 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1515230470398632		[learning rate: 0.0018522]
	Learning Rate: 0.00185222
	LOSS [training: 0.1515230470398632 | validation: 0.2868499466737103]
	TIME [epoch: 119 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15667463256265285		[learning rate: 0.001844]
	Learning Rate: 0.00184404
	LOSS [training: 0.15667463256265285 | validation: 0.28822013324391765]
	TIME [epoch: 119 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15510498819378107		[learning rate: 0.0018359]
	Learning Rate: 0.00183589
	LOSS [training: 0.15510498819378107 | validation: 0.29771432862750086]
	TIME [epoch: 119 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15644295741783998		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.15644295741783998 | validation: 0.285560342720094]
	TIME [epoch: 120 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15254796344570262		[learning rate: 0.0018197]
	Learning Rate: 0.0018197
	LOSS [training: 0.15254796344570262 | validation: 0.3059854494531955]
	TIME [epoch: 119 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15719452356644958		[learning rate: 0.0018117]
	Learning Rate: 0.00181166
	LOSS [training: 0.15719452356644958 | validation: 0.3014283146212269]
	TIME [epoch: 119 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15844790580492527		[learning rate: 0.0018037]
	Learning Rate: 0.00180366
	LOSS [training: 0.15844790580492527 | validation: 0.299060410169333]
	TIME [epoch: 119 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1581580994086771		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.1581580994086771 | validation: 0.30324975989769243]
	TIME [epoch: 119 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15455184286627016		[learning rate: 0.0017878]
	Learning Rate: 0.00178775
	LOSS [training: 0.15455184286627016 | validation: 0.2980135109761911]
	TIME [epoch: 119 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1575343183428098		[learning rate: 0.0017799]
	Learning Rate: 0.00177985
	LOSS [training: 0.1575343183428098 | validation: 0.2986811108710461]
	TIME [epoch: 119 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15275290401873193		[learning rate: 0.001772]
	Learning Rate: 0.00177199
	LOSS [training: 0.15275290401873193 | validation: 0.2970264275740166]
	TIME [epoch: 119 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16145425828894888		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.16145425828894888 | validation: 0.30321832843370267]
	TIME [epoch: 120 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15786601822682478		[learning rate: 0.0017564]
	Learning Rate: 0.00175637
	LOSS [training: 0.15786601822682478 | validation: 0.3328605699326175]
	TIME [epoch: 119 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16038518987998632		[learning rate: 0.0017486]
	Learning Rate: 0.00174861
	LOSS [training: 0.16038518987998632 | validation: 0.30151195939826725]
	TIME [epoch: 119 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15299593421620244		[learning rate: 0.0017409]
	Learning Rate: 0.00174088
	LOSS [training: 0.15299593421620244 | validation: 0.2875779939006359]
	TIME [epoch: 120 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15495085781386767		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.15495085781386767 | validation: 0.3192005683121769]
	TIME [epoch: 120 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15443626252892254		[learning rate: 0.0017255]
	Learning Rate: 0.00172553
	LOSS [training: 0.15443626252892254 | validation: 0.2910253466473384]
	TIME [epoch: 120 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15413607693063036		[learning rate: 0.0017179]
	Learning Rate: 0.00171791
	LOSS [training: 0.15413607693063036 | validation: 0.29278779580442343]
	TIME [epoch: 119 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15587922174466956		[learning rate: 0.0017103]
	Learning Rate: 0.00171032
	LOSS [training: 0.15587922174466956 | validation: 0.3141076284338225]
	TIME [epoch: 119 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15425907404105516		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.15425907404105516 | validation: 0.29849399645240676]
	TIME [epoch: 119 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15365410235022714		[learning rate: 0.0016952]
	Learning Rate: 0.00169524
	LOSS [training: 0.15365410235022714 | validation: 0.312079158759773]
	TIME [epoch: 119 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1560735500059967		[learning rate: 0.0016877]
	Learning Rate: 0.00168775
	LOSS [training: 0.1560735500059967 | validation: 0.3235740038149723]
	TIME [epoch: 120 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15118397171030218		[learning rate: 0.0016803]
	Learning Rate: 0.00168029
	LOSS [training: 0.15118397171030218 | validation: 0.30213016763703654]
	TIME [epoch: 120 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15126842407554966		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.15126842407554966 | validation: 0.32676679711493956]
	TIME [epoch: 120 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15334501782438184		[learning rate: 0.0016655]
	Learning Rate: 0.00166548
	LOSS [training: 0.15334501782438184 | validation: 0.3155950788331361]
	TIME [epoch: 120 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15419249430186763		[learning rate: 0.0016581]
	Learning Rate: 0.00165812
	LOSS [training: 0.15419249430186763 | validation: 0.31350805922224967]
	TIME [epoch: 120 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1547696178951848		[learning rate: 0.0016508]
	Learning Rate: 0.00165079
	LOSS [training: 0.1547696178951848 | validation: 0.2943613276713224]
	TIME [epoch: 119 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15820923714357985		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.15820923714357985 | validation: 0.2954986988409918]
	TIME [epoch: 120 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15272893755290187		[learning rate: 0.0016362]
	Learning Rate: 0.00163624
	LOSS [training: 0.15272893755290187 | validation: 0.3011485783849915]
	TIME [epoch: 119 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15168339820365073		[learning rate: 0.001629]
	Learning Rate: 0.00162901
	LOSS [training: 0.15168339820365073 | validation: 0.2871681864436312]
	TIME [epoch: 119 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15260947132021552		[learning rate: 0.0016218]
	Learning Rate: 0.00162181
	LOSS [training: 0.15260947132021552 | validation: 0.3004109095879873]
	TIME [epoch: 120 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.155251481782568		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.155251481782568 | validation: 0.30426834957620835]
	TIME [epoch: 120 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15131846454121495		[learning rate: 0.0016075]
	Learning Rate: 0.00160751
	LOSS [training: 0.15131846454121495 | validation: 0.30724572844520676]
	TIME [epoch: 120 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15042820494037487		[learning rate: 0.0016004]
	Learning Rate: 0.00160041
	LOSS [training: 0.15042820494037487 | validation: 0.30723573327832226]
	TIME [epoch: 120 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15854680292917692		[learning rate: 0.0015933]
	Learning Rate: 0.00159334
	LOSS [training: 0.15854680292917692 | validation: 0.28502462463120604]
	TIME [epoch: 120 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15400642208400406		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.15400642208400406 | validation: 0.3026490959224298]
	TIME [epoch: 120 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15302508676783608		[learning rate: 0.0015793]
	Learning Rate: 0.00157929
	LOSS [training: 0.15302508676783608 | validation: 0.2932536284610498]
	TIME [epoch: 120 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15682727512389993		[learning rate: 0.0015723]
	Learning Rate: 0.00157231
	LOSS [training: 0.15682727512389993 | validation: 0.29182040516765284]
	TIME [epoch: 120 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15571685018984296		[learning rate: 0.0015654]
	Learning Rate: 0.00156536
	LOSS [training: 0.15571685018984296 | validation: 0.28437637332048377]
	TIME [epoch: 120 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15079566558776622		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.15079566558776622 | validation: 0.30130451959679505]
	TIME [epoch: 120 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15361965907165423		[learning rate: 0.0015516]
	Learning Rate: 0.00155156
	LOSS [training: 0.15361965907165423 | validation: 0.2928278862195628]
	TIME [epoch: 119 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1520193920639662		[learning rate: 0.0015447]
	Learning Rate: 0.00154471
	LOSS [training: 0.1520193920639662 | validation: 0.29265766442452457]
	TIME [epoch: 119 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15512217033009829		[learning rate: 0.0015379]
	Learning Rate: 0.00153788
	LOSS [training: 0.15512217033009829 | validation: 0.2880079692460703]
	TIME [epoch: 119 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15529331945666178		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.15529331945666178 | validation: 0.28739745799516925]
	TIME [epoch: 120 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15007338611307947		[learning rate: 0.0015243]
	Learning Rate: 0.00152432
	LOSS [training: 0.15007338611307947 | validation: 0.2829198866184858]
	TIME [epoch: 120 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15606500807010157		[learning rate: 0.0015176]
	Learning Rate: 0.00151759
	LOSS [training: 0.15606500807010157 | validation: 0.29331899029315917]
	TIME [epoch: 119 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15252115680406902		[learning rate: 0.0015109]
	Learning Rate: 0.00151088
	LOSS [training: 0.15252115680406902 | validation: 0.30123817618510007]
	TIME [epoch: 120 sec]
EPOCH 468/2000:
	Training over batches...
