Args:
Namespace(name='model_facs_dec2b_2d_v1', outdir='out/model_training/model_facs_dec2b_2d_v1', training_data='data/training_data/facs/dec2_fitonsubset/transition2_subset_ce_pn_m_pc12/training', validation_data='data/training_data/facs/dec2_fitonsubset/transition2_subset_ce_pn_m_pc12/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=5, patience=200, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, dt=0.001, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 2190910329

Training model...

Saving initial model state to: out/model_training/model_facs_dec2b_2d_v1_20240622_102153/states/model_facs_dec2b_2d_v1_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6265004205137937		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6265004205137937 | validation: 0.5750626847653719]
	TIME [epoch: 45.6 sec]
	Saving model to: out/model_training/model_facs_dec2b_2d_v1_20240622_102153/states/model_facs_dec2b_2d_v1_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45444985788425496		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.45444985788425496 | validation: 0.4851999644314865]
	TIME [epoch: 21 sec]
	Saving model to: out/model_training/model_facs_dec2b_2d_v1_20240622_102153/states/model_facs_dec2b_2d_v1_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44644391798849803		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.44644391798849803 | validation: 0.5229757438335612]
	TIME [epoch: 20.9 sec]
EPOCH 4/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42497546877038295		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.42497546877038295 | validation: 0.45785445437815253]
	TIME [epoch: 21 sec]
	Saving model to: out/model_training/model_facs_dec2b_2d_v1_20240622_102153/states/model_facs_dec2b_2d_v1_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35819083742118885		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.35819083742118885 | validation: 0.39669278486284176]
	TIME [epoch: 21 sec]
	Saving model to: out/model_training/model_facs_dec2b_2d_v1_20240622_102153/states/model_facs_dec2b_2d_v1_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3755676086950402		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3755676086950402 | validation: 0.3836396363846577]
	TIME [epoch: 21 sec]
	Saving model to: out/model_training/model_facs_dec2b_2d_v1_20240622_102153/states/model_facs_dec2b_2d_v1_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3415984726580962		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3415984726580962 | validation: 0.36923750195717514]
	TIME [epoch: 20.9 sec]
	Saving model to: out/model_training/model_facs_dec2b_2d_v1_20240622_102153/states/model_facs_dec2b_2d_v1_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3326121114064679		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3326121114064679 | validation: 0.39034868647002874]
	TIME [epoch: 20.9 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31224342457104093		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.31224342457104093 | validation: 0.3794732465563911]
	TIME [epoch: 21 sec]
EPOCH 10/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2944317994730484		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2944317994730484 | validation: 0.401919473726576]
	TIME [epoch: 21.1 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2706869423327542		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2706869423327542 | validation: 0.3748452850694403]
	TIME [epoch: 21.1 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27200305554410953		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.27200305554410953 | validation: 0.31095983502051255]
	TIME [epoch: 21 sec]
	Saving model to: out/model_training/model_facs_dec2b_2d_v1_20240622_102153/states/model_facs_dec2b_2d_v1_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27647158291777885		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.27647158291777885 | validation: 0.3085927413303966]
	TIME [epoch: 21 sec]
	Saving model to: out/model_training/model_facs_dec2b_2d_v1_20240622_102153/states/model_facs_dec2b_2d_v1_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2767322879979438		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2767322879979438 | validation: 0.29419895439600346]
	TIME [epoch: 21.1 sec]
	Saving model to: out/model_training/model_facs_dec2b_2d_v1_20240622_102153/states/model_facs_dec2b_2d_v1_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.240794345514234		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.240794345514234 | validation: 0.32078583408741485]
	TIME [epoch: 21 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2515161491215197		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2515161491215197 | validation: 0.34492635038058433]
	TIME [epoch: 21 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22337130358643825		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22337130358643825 | validation: 0.3355770865380971]
	TIME [epoch: 21 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2230169383007352		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2230169383007352 | validation: 0.2737753213355485]
	TIME [epoch: 21 sec]
	Saving model to: out/model_training/model_facs_dec2b_2d_v1_20240622_102153/states/model_facs_dec2b_2d_v1_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22024887551671296		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22024887551671296 | validation: 0.25520683715071324]
	TIME [epoch: 21 sec]
	Saving model to: out/model_training/model_facs_dec2b_2d_v1_20240622_102153/states/model_facs_dec2b_2d_v1_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22267553287613068		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22267553287613068 | validation: 0.3077976700640054]
	TIME [epoch: 21 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1957255855062673		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1957255855062673 | validation: 0.2558291880381952]
	TIME [epoch: 21.1 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18868855556971184		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18868855556971184 | validation: 0.2293550970041356]
	TIME [epoch: 21 sec]
	Saving model to: out/model_training/model_facs_dec2b_2d_v1_20240622_102153/states/model_facs_dec2b_2d_v1_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20076477066261256		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20076477066261256 | validation: 0.29532178918066315]
	TIME [epoch: 21 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19960213662939102		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.19960213662939102 | validation: 0.22030136013862464]
	TIME [epoch: 20.9 sec]
	Saving model to: out/model_training/model_facs_dec2b_2d_v1_20240622_102153/states/model_facs_dec2b_2d_v1_24.pth
	Model improved!!!
EPOCH 25/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1575226552629808		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1575226552629808 | validation: 0.23438776992797244]
	TIME [epoch: 21.1 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17046936107966407		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17046936107966407 | validation: 0.24442135989345193]
	TIME [epoch: 20.9 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16513157056146335		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16513157056146335 | validation: 0.2007228875041453]
	TIME [epoch: 20.8 sec]
	Saving model to: out/model_training/model_facs_dec2b_2d_v1_20240622_102153/states/model_facs_dec2b_2d_v1_27.pth
	Model improved!!!
EPOCH 28/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17591437050055014		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17591437050055014 | validation: 0.21801951442624895]
	TIME [epoch: 20.8 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15663168405063033		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15663168405063033 | validation: 0.24494970661237034]
	TIME [epoch: 20.8 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18799299775169098		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18799299775169098 | validation: 0.22749183107767412]
	TIME [epoch: 20.8 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15997372855019315		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15997372855019315 | validation: 0.20270144936085593]
	TIME [epoch: 20.8 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.176151384064343		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.176151384064343 | validation: 0.2566165889528004]
	TIME [epoch: 21 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1851589055144268		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1851589055144268 | validation: 0.22058720566147527]
	TIME [epoch: 21 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17927659770329626		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17927659770329626 | validation: 0.20598496179635]
	TIME [epoch: 21.1 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16983949212091726		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16983949212091726 | validation: 0.21656672875624544]
	TIME [epoch: 21 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16779834154279846		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16779834154279846 | validation: 0.22256596674446866]
	TIME [epoch: 21 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17349897773946027		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17349897773946027 | validation: 0.26265117145026473]
	TIME [epoch: 21 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19067997883348672		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.19067997883348672 | validation: 0.20853438419649056]
	TIME [epoch: 21 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14306859326754567		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14306859326754567 | validation: 0.1933377174854508]
	TIME [epoch: 21 sec]
	Saving model to: out/model_training/model_facs_dec2b_2d_v1_20240622_102153/states/model_facs_dec2b_2d_v1_39.pth
	Model improved!!!
EPOCH 40/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16008636543651814		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16008636543651814 | validation: 0.2552754696377312]
	TIME [epoch: 21 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17649569018190578		[learning rate: 0.0099646]
	Learning Rate: 0.00996464
	LOSS [training: 0.17649569018190578 | validation: 0.20629436851535876]
	TIME [epoch: 21.1 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14502083521196169		[learning rate: 0.0099206]
	Learning Rate: 0.00992061
	LOSS [training: 0.14502083521196169 | validation: 0.2076187500956307]
	TIME [epoch: 21 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18515858491002563		[learning rate: 0.0098768]
	Learning Rate: 0.00987678
	LOSS [training: 0.18515858491002563 | validation: 0.24356313649875755]
	TIME [epoch: 21 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18853419053882137		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 0.18853419053882137 | validation: 0.23116380827853866]
	TIME [epoch: 21 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1537149681918756		[learning rate: 0.0097897]
	Learning Rate: 0.0097897
	LOSS [training: 0.1537149681918756 | validation: 0.20853900851892931]
	TIME [epoch: 21.1 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15342813200580435		[learning rate: 0.0097464]
	Learning Rate: 0.00974644
	LOSS [training: 0.15342813200580435 | validation: 0.2124933963557358]
	TIME [epoch: 21 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15250355374465963		[learning rate: 0.0097034]
	Learning Rate: 0.00970338
	LOSS [training: 0.15250355374465963 | validation: 0.18629312509821933]
	TIME [epoch: 21 sec]
	Saving model to: out/model_training/model_facs_dec2b_2d_v1_20240622_102153/states/model_facs_dec2b_2d_v1_47.pth
	Model improved!!!
EPOCH 48/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15594346099250322		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 0.15594346099250322 | validation: 0.20913325694572202]
	TIME [epoch: 21 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14407587458978918		[learning rate: 0.0096178]
	Learning Rate: 0.00961783
	LOSS [training: 0.14407587458978918 | validation: 0.25713669942254935]
	TIME [epoch: 21 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16848568465832217		[learning rate: 0.0095753]
	Learning Rate: 0.00957533
	LOSS [training: 0.16848568465832217 | validation: 0.23422192282378435]
	TIME [epoch: 21 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17267288143019352		[learning rate: 0.009533]
	Learning Rate: 0.00953303
	LOSS [training: 0.17267288143019352 | validation: 0.2066342987422128]
	TIME [epoch: 20.8 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14315698180237008		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 0.14315698180237008 | validation: 0.20432142157598124]
	TIME [epoch: 20.8 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13164863083214867		[learning rate: 0.009449]
	Learning Rate: 0.00944897
	LOSS [training: 0.13164863083214867 | validation: 0.22174743267701807]
	TIME [epoch: 20.8 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15816946527682746		[learning rate: 0.0094072]
	Learning Rate: 0.00940722
	LOSS [training: 0.15816946527682746 | validation: 0.22927439826275178]
	TIME [epoch: 20.8 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16984515923257523		[learning rate: 0.0093657]
	Learning Rate: 0.00936566
	LOSS [training: 0.16984515923257523 | validation: 0.22335824075210772]
	TIME [epoch: 20.8 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14635994626951734		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 0.14635994626951734 | validation: 0.2939989306837708]
	TIME [epoch: 20.9 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19585962706986543		[learning rate: 0.0092831]
	Learning Rate: 0.00928308
	LOSS [training: 0.19585962706986543 | validation: 0.20435072340385405]
	TIME [epoch: 21 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1561252759076974		[learning rate: 0.0092421]
	Learning Rate: 0.00924207
	LOSS [training: 0.1561252759076974 | validation: 0.20782935840578526]
	TIME [epoch: 21.1 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15701291357546862		[learning rate: 0.0092012]
	Learning Rate: 0.00920124
	LOSS [training: 0.15701291357546862 | validation: 0.1903534892538898]
	TIME [epoch: 21 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14390208311980332		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 0.14390208311980332 | validation: 0.18360575562313763]
	TIME [epoch: 21 sec]
	Saving model to: out/model_training/model_facs_dec2b_2d_v1_20240622_102153/states/model_facs_dec2b_2d_v1_60.pth
	Model improved!!!
EPOCH 61/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11594032653824593		[learning rate: 0.0091201]
	Learning Rate: 0.00912011
	LOSS [training: 0.11594032653824593 | validation: 0.22959340132815395]
	TIME [epoch: 21.1 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17486697053088912		[learning rate: 0.0090798]
	Learning Rate: 0.00907981
	LOSS [training: 0.17486697053088912 | validation: 0.2094325397177978]
	TIME [epoch: 21 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1342735013495155		[learning rate: 0.0090397]
	Learning Rate: 0.0090397
	LOSS [training: 0.1342735013495155 | validation: 0.19500510426547762]
	TIME [epoch: 21 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15806852513566821		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 0.15806852513566821 | validation: 0.2061126976669949]
	TIME [epoch: 20.9 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17197446722769555		[learning rate: 0.00896]
	Learning Rate: 0.00895999
	LOSS [training: 0.17197446722769555 | validation: 0.19984027605403748]
	TIME [epoch: 21 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12296020177366784		[learning rate: 0.0089204]
	Learning Rate: 0.00892041
	LOSS [training: 0.12296020177366784 | validation: 0.23419720822115148]
	TIME [epoch: 21 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1775146636631589		[learning rate: 0.008881]
	Learning Rate: 0.00888099
	LOSS [training: 0.1775146636631589 | validation: 0.20110479812938303]
	TIME [epoch: 21 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14472319543638973		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 0.14472319543638973 | validation: 0.18509047814102467]
	TIME [epoch: 21.1 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12464501306216928		[learning rate: 0.0088027]
	Learning Rate: 0.00880269
	LOSS [training: 0.12464501306216928 | validation: 0.19033776632347857]
	TIME [epoch: 21 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14743268009602023		[learning rate: 0.0087638]
	Learning Rate: 0.0087638
	LOSS [training: 0.14743268009602023 | validation: 0.19769463525961722]
	TIME [epoch: 21 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1528676822187358		[learning rate: 0.0087251]
	Learning Rate: 0.00872508
	LOSS [training: 0.1528676822187358 | validation: 0.17918596078938018]
	TIME [epoch: 21 sec]
	Saving model to: out/model_training/model_facs_dec2b_2d_v1_20240622_102153/states/model_facs_dec2b_2d_v1_71.pth
	Model improved!!!
EPOCH 72/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12933221887355958		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 0.12933221887355958 | validation: 0.1827762776627663]
	TIME [epoch: 21 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12207122882912358		[learning rate: 0.0086481]
	Learning Rate: 0.00864815
	LOSS [training: 0.12207122882912358 | validation: 0.2013649856192044]
	TIME [epoch: 21 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15849535784914665		[learning rate: 0.0086099]
	Learning Rate: 0.00860994
	LOSS [training: 0.15849535784914665 | validation: 0.20516547486937223]
	TIME [epoch: 21 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16179347170005984		[learning rate: 0.0085719]
	Learning Rate: 0.0085719
	LOSS [training: 0.16179347170005984 | validation: 0.18770586221940447]
	TIME [epoch: 21 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1230043599655346		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 0.1230043599655346 | validation: 0.19837323935573273]
	TIME [epoch: 20.9 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16826449278217376		[learning rate: 0.0084963]
	Learning Rate: 0.00849632
	LOSS [training: 0.16826449278217376 | validation: 0.20328046500556873]
	TIME [epoch: 21 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15423293074648736		[learning rate: 0.0084588]
	Learning Rate: 0.00845878
	LOSS [training: 0.15423293074648736 | validation: 0.19594172630159934]
	TIME [epoch: 21 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12493550757125886		[learning rate: 0.0084214]
	Learning Rate: 0.00842141
	LOSS [training: 0.12493550757125886 | validation: 0.16529753967196387]
	TIME [epoch: 21 sec]
	Saving model to: out/model_training/model_facs_dec2b_2d_v1_20240622_102153/states/model_facs_dec2b_2d_v1_79.pth
	Model improved!!!
EPOCH 80/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15636973863063858		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 0.15636973863063858 | validation: 0.18974773909793208]
	TIME [epoch: 21 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1366470995468369		[learning rate: 0.0083472]
	Learning Rate: 0.00834715
	LOSS [training: 0.1366470995468369 | validation: 0.18857737056235085]
	TIME [epoch: 21 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12836600690753622		[learning rate: 0.0083103]
	Learning Rate: 0.00831027
	LOSS [training: 0.12836600690753622 | validation: 0.23945283053416327]
	TIME [epoch: 21 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13640500665060135		[learning rate: 0.0082736]
	Learning Rate: 0.00827356
	LOSS [training: 0.13640500665060135 | validation: 0.1897213032353685]
	TIME [epoch: 21 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12290862636133879		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 0.12290862636133879 | validation: 0.19523983358062924]
	TIME [epoch: 21 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15213819059549163		[learning rate: 0.0082006]
	Learning Rate: 0.00820061
	LOSS [training: 0.15213819059549163 | validation: 0.18381829919939097]
	TIME [epoch: 21 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13538055626678416		[learning rate: 0.0081644]
	Learning Rate: 0.00816438
	LOSS [training: 0.13538055626678416 | validation: 0.186269254728558]
	TIME [epoch: 21 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1345639014804076		[learning rate: 0.0081283]
	Learning Rate: 0.0081283
	LOSS [training: 0.1345639014804076 | validation: 0.20075486008552318]
	TIME [epoch: 21 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14122371125845606		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 0.14122371125845606 | validation: 0.1710803809554301]
	TIME [epoch: 21 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13906667535947442		[learning rate: 0.0080566]
	Learning Rate: 0.00805664
	LOSS [training: 0.13906667535947442 | validation: 0.1937645118980042]
	TIME [epoch: 21 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13584252497578272		[learning rate: 0.008021]
	Learning Rate: 0.00802104
	LOSS [training: 0.13584252497578272 | validation: 0.1904897855421406]
	TIME [epoch: 20.9 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13752415589945338		[learning rate: 0.0079856]
	Learning Rate: 0.0079856
	LOSS [training: 0.13752415589945338 | validation: 0.18128979096445463]
	TIME [epoch: 21 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12153747027806142		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 0.12153747027806142 | validation: 0.17652013742367714]
	TIME [epoch: 21 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13624082695861733		[learning rate: 0.0079152]
	Learning Rate: 0.00791519
	LOSS [training: 0.13624082695861733 | validation: 0.17805482472069536]
	TIME [epoch: 21 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11581598365572607		[learning rate: 0.0078802]
	Learning Rate: 0.00788022
	LOSS [training: 0.11581598365572607 | validation: 0.2061106833917525]
	TIME [epoch: 21 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15957218276829954		[learning rate: 0.0078454]
	Learning Rate: 0.00784541
	LOSS [training: 0.15957218276829954 | validation: 0.18498452386914005]
	TIME [epoch: 21 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13465054421282194		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 0.13465054421282194 | validation: 0.17828259871222238]
	TIME [epoch: 21 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13056396936881612		[learning rate: 0.0077762]
	Learning Rate: 0.00777623
	LOSS [training: 0.13056396936881612 | validation: 0.18260366553020632]
	TIME [epoch: 21 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13474437892886884		[learning rate: 0.0077419]
	Learning Rate: 0.00774188
	LOSS [training: 0.13474437892886884 | validation: 0.17492061205235687]
	TIME [epoch: 21 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12739154801413086		[learning rate: 0.0077077]
	Learning Rate: 0.00770767
	LOSS [training: 0.12739154801413086 | validation: 0.1802441230226129]
	TIME [epoch: 21 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12326754705826506		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 0.12326754705826506 | validation: 0.17935594825174883]
	TIME [epoch: 21 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13131115690395986		[learning rate: 0.0076397]
	Learning Rate: 0.00763971
	LOSS [training: 0.13131115690395986 | validation: 0.20285138382779466]
	TIME [epoch: 21 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12567337640569293		[learning rate: 0.007606]
	Learning Rate: 0.00760596
	LOSS [training: 0.12567337640569293 | validation: 0.1990261445996091]
	TIME [epoch: 21 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13872158907754228		[learning rate: 0.0075724]
	Learning Rate: 0.00757235
	LOSS [training: 0.13872158907754228 | validation: 0.17826001898037358]
	TIME [epoch: 20.9 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11240121556397256		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 0.11240121556397256 | validation: 0.20781041010744503]
	TIME [epoch: 20.9 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12535054970780637		[learning rate: 0.0075056]
	Learning Rate: 0.00750559
	LOSS [training: 0.12535054970780637 | validation: 0.15783149638751678]
	TIME [epoch: 21 sec]
	Saving model to: out/model_training/model_facs_dec2b_2d_v1_20240622_102153/states/model_facs_dec2b_2d_v1_105.pth
	Model improved!!!
EPOCH 106/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11787972148190717		[learning rate: 0.0074724]
	Learning Rate: 0.00747242
	LOSS [training: 0.11787972148190717 | validation: 0.212142077064266]
	TIME [epoch: 20.9 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16059743194094392		[learning rate: 0.0074394]
	Learning Rate: 0.00743941
	LOSS [training: 0.16059743194094392 | validation: 0.20229114399170306]
	TIME [epoch: 21 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12751295983586602		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 0.12751295983586602 | validation: 0.16848347621560786]
	TIME [epoch: 21.1 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1094927663261787		[learning rate: 0.0073738]
	Learning Rate: 0.00737382
	LOSS [training: 0.1094927663261787 | validation: 0.19828208928017804]
	TIME [epoch: 20.9 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12319368914879818		[learning rate: 0.0073412]
	Learning Rate: 0.00734124
	LOSS [training: 0.12319368914879818 | validation: 0.20639960266237842]
	TIME [epoch: 20.8 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13982098792072742		[learning rate: 0.0073088]
	Learning Rate: 0.0073088
	LOSS [training: 0.13982098792072742 | validation: 0.17178623687105188]
	TIME [epoch: 20.8 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12878905323263753		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 0.12878905323263753 | validation: 0.18517417577636508]
	TIME [epoch: 20.8 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1375428781698135		[learning rate: 0.0072444]
	Learning Rate: 0.00724436
	LOSS [training: 0.1375428781698135 | validation: 0.1697949921192527]
	TIME [epoch: 20.8 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12789859389192507		[learning rate: 0.0072124]
	Learning Rate: 0.00721235
	LOSS [training: 0.12789859389192507 | validation: 0.22453391931756]
	TIME [epoch: 20.8 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16305963401355772		[learning rate: 0.0071805]
	Learning Rate: 0.00718049
	LOSS [training: 0.16305963401355772 | validation: 0.2530057301144073]
	TIME [epoch: 20.8 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12881864298142548		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 0.12881864298142548 | validation: 0.17303028142628213]
	TIME [epoch: 20.8 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13297661914353257		[learning rate: 0.0071172]
	Learning Rate: 0.00711718
	LOSS [training: 0.13297661914353257 | validation: 0.18736494856026162]
	TIME [epoch: 20.8 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13170525122876317		[learning rate: 0.0070857]
	Learning Rate: 0.00708573
	LOSS [training: 0.13170525122876317 | validation: 0.18509467139539418]
	TIME [epoch: 21 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13169084409776896		[learning rate: 0.0070544]
	Learning Rate: 0.00705442
	LOSS [training: 0.13169084409776896 | validation: 0.19460563977044146]
	TIME [epoch: 20.9 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14798305440392526		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 0.14798305440392526 | validation: 0.17567162311654075]
	TIME [epoch: 21 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12704504981852288		[learning rate: 0.0069922]
	Learning Rate: 0.00699222
	LOSS [training: 0.12704504981852288 | validation: 0.16827725707368102]
	TIME [epoch: 21 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11695195599229795		[learning rate: 0.0069613]
	Learning Rate: 0.00696133
	LOSS [training: 0.11695195599229795 | validation: 0.1783448193741452]
	TIME [epoch: 21 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11778805111125448		[learning rate: 0.0069306]
	Learning Rate: 0.00693057
	LOSS [training: 0.11778805111125448 | validation: 0.2480807230884224]
	TIME [epoch: 21 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13092295904814602		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 0.13092295904814602 | validation: 0.15555889404222042]
	TIME [epoch: 21 sec]
	Saving model to: out/model_training/model_facs_dec2b_2d_v1_20240622_102153/states/model_facs_dec2b_2d_v1_124.pth
	Model improved!!!
EPOCH 125/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11200717036196835		[learning rate: 0.0068695]
	Learning Rate: 0.00686947
	LOSS [training: 0.11200717036196835 | validation: 0.14893666021093727]
	TIME [epoch: 21 sec]
	Saving model to: out/model_training/model_facs_dec2b_2d_v1_20240622_102153/states/model_facs_dec2b_2d_v1_125.pth
	Model improved!!!
EPOCH 126/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12599293193603123		[learning rate: 0.0068391]
	Learning Rate: 0.00683912
	LOSS [training: 0.12599293193603123 | validation: 0.17829946708164873]
	TIME [epoch: 21 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1208122333030687		[learning rate: 0.0068089]
	Learning Rate: 0.0068089
	LOSS [training: 0.1208122333030687 | validation: 0.17650973932824673]
	TIME [epoch: 21 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1230662780976097		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 0.1230662780976097 | validation: 0.19552003387065212]
	TIME [epoch: 21.1 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12443023742453971		[learning rate: 0.0067489]
	Learning Rate: 0.00674887
	LOSS [training: 0.12443023742453971 | validation: 0.17484696028734642]
	TIME [epoch: 21 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14205732883075356		[learning rate: 0.006719]
	Learning Rate: 0.00671905
	LOSS [training: 0.14205732883075356 | validation: 0.19185922077881162]
	TIME [epoch: 21 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13068100223997467		[learning rate: 0.0066894]
	Learning Rate: 0.00668936
	LOSS [training: 0.13068100223997467 | validation: 0.19921276974232632]
	TIME [epoch: 21 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1245191296240415		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 0.1245191296240415 | validation: 0.1616120063205656]
	TIME [epoch: 21 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11258036262821643		[learning rate: 0.0066304]
	Learning Rate: 0.00663038
	LOSS [training: 0.11258036262821643 | validation: 0.1740211125711173]
	TIME [epoch: 21 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11928734709401827		[learning rate: 0.0066011]
	Learning Rate: 0.00660109
	LOSS [training: 0.11928734709401827 | validation: 0.151168484936979]
	TIME [epoch: 21 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1144763767225648		[learning rate: 0.0065719]
	Learning Rate: 0.00657192
	LOSS [training: 0.1144763767225648 | validation: 0.16871996992890817]
	TIME [epoch: 21.1 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11676234244216828		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 0.11676234244216828 | validation: 0.16585977006130836]
	TIME [epoch: 20.9 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.120881723537232		[learning rate: 0.006514]
	Learning Rate: 0.00651398
	LOSS [training: 0.120881723537232 | validation: 0.20318470985232598]
	TIME [epoch: 21 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13170776488949854		[learning rate: 0.0064852]
	Learning Rate: 0.00648519
	LOSS [training: 0.13170776488949854 | validation: 0.17787380456886137]
	TIME [epoch: 21.1 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11060240171339168		[learning rate: 0.0064565]
	Learning Rate: 0.00645654
	LOSS [training: 0.11060240171339168 | validation: 0.16535474965324692]
	TIME [epoch: 21 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1194799300316803		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 0.1194799300316803 | validation: 0.1790786028283012]
	TIME [epoch: 21 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11758645180616896		[learning rate: 0.0063996]
	Learning Rate: 0.00639961
	LOSS [training: 0.11758645180616896 | validation: 0.14964987058002835]
	TIME [epoch: 21 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12246584092828275		[learning rate: 0.0063713]
	Learning Rate: 0.00637134
	LOSS [training: 0.12246584092828275 | validation: 0.17019244630128152]
	TIME [epoch: 21 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11139646603667974		[learning rate: 0.0063432]
	Learning Rate: 0.00634319
	LOSS [training: 0.11139646603667974 | validation: 0.15359705749223654]
	TIME [epoch: 21 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11430860108250007		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 0.11430860108250007 | validation: 0.21607833481345737]
	TIME [epoch: 21 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11236174519232622		[learning rate: 0.0062873]
	Learning Rate: 0.00628726
	LOSS [training: 0.11236174519232622 | validation: 0.16867754654036024]
	TIME [epoch: 21.1 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14136284574817481		[learning rate: 0.0062595]
	Learning Rate: 0.00625948
	LOSS [training: 0.14136284574817481 | validation: 0.18158618418793881]
	TIME [epoch: 21 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1189972073584783		[learning rate: 0.0062318]
	Learning Rate: 0.00623183
	LOSS [training: 0.1189972073584783 | validation: 0.17011938515896552]
	TIME [epoch: 20.9 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11427731325419974		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 0.11427731325419974 | validation: 0.15608979404976908]
	TIME [epoch: 21.1 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10998096957037089		[learning rate: 0.0061769]
	Learning Rate: 0.00617688
	LOSS [training: 0.10998096957037089 | validation: 0.1717184465606702]
	TIME [epoch: 20.9 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1181846228796835		[learning rate: 0.0061496]
	Learning Rate: 0.00614959
	LOSS [training: 0.1181846228796835 | validation: 0.18566425968666161]
	TIME [epoch: 21 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12402787886150753		[learning rate: 0.0061224]
	Learning Rate: 0.00612242
	LOSS [training: 0.12402787886150753 | validation: 0.1769473702394871]
	TIME [epoch: 21 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12381890275901108		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 0.12381890275901108 | validation: 0.1470073983300455]
	TIME [epoch: 21 sec]
	Saving model to: out/model_training/model_facs_dec2b_2d_v1_20240622_102153/states/model_facs_dec2b_2d_v1_152.pth
	Model improved!!!
EPOCH 153/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11961751679382684		[learning rate: 0.0060684]
	Learning Rate: 0.00606844
	LOSS [training: 0.11961751679382684 | validation: 0.17763513058112185]
	TIME [epoch: 21 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14327617080373817		[learning rate: 0.0060416]
	Learning Rate: 0.00604163
	LOSS [training: 0.14327617080373817 | validation: 0.18152476684263105]
	TIME [epoch: 20.9 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12283357110717055		[learning rate: 0.0060149]
	Learning Rate: 0.00601493
	LOSS [training: 0.12283357110717055 | validation: 0.22552782600459043]
	TIME [epoch: 21 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11153856880140486		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 0.11153856880140486 | validation: 0.17115322932446195]
	TIME [epoch: 20.9 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12151616472992004		[learning rate: 0.0059619]
	Learning Rate: 0.0059619
	LOSS [training: 0.12151616472992004 | validation: 0.16579094787289128]
	TIME [epoch: 20.9 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11144926874985213		[learning rate: 0.0059356]
	Learning Rate: 0.00593556
	LOSS [training: 0.11144926874985213 | validation: 0.21863035202194375]
	TIME [epoch: 21 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16452228049157983		[learning rate: 0.0059093]
	Learning Rate: 0.00590933
	LOSS [training: 0.16452228049157983 | validation: 0.18385436567154717]
	TIME [epoch: 20.9 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13991341023214324		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 0.13991341023214324 | validation: 0.16268367617462037]
	TIME [epoch: 20.9 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12937125147649892		[learning rate: 0.0058572]
	Learning Rate: 0.00585723
	LOSS [training: 0.12937125147649892 | validation: 0.1952001592756697]
	TIME [epoch: 20.9 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12513476564381376		[learning rate: 0.0058314]
	Learning Rate: 0.00583135
	LOSS [training: 0.12513476564381376 | validation: 0.18145693853353734]
	TIME [epoch: 21 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12258569408377315		[learning rate: 0.0058056]
	Learning Rate: 0.00580559
	LOSS [training: 0.12258569408377315 | validation: 0.15338277695581817]
	TIME [epoch: 20.9 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11704744625343957		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 0.11704744625343957 | validation: 0.14763162583105732]
	TIME [epoch: 20.9 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11650874793519131		[learning rate: 0.0057544]
	Learning Rate: 0.0057544
	LOSS [training: 0.11650874793519131 | validation: 0.15884644732842274]
	TIME [epoch: 21 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09905996745062791		[learning rate: 0.005729]
	Learning Rate: 0.00572897
	LOSS [training: 0.09905996745062791 | validation: 0.17695330723937872]
	TIME [epoch: 20.9 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14223285903706356		[learning rate: 0.0057037]
	Learning Rate: 0.00570366
	LOSS [training: 0.14223285903706356 | validation: 0.16145742225141588]
	TIME [epoch: 20.9 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1195730742545219		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 0.1195730742545219 | validation: 0.16366417772980035]
	TIME [epoch: 21 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12696682499748127		[learning rate: 0.0056534]
	Learning Rate: 0.00565337
	LOSS [training: 0.12696682499748127 | validation: 0.16085035171158713]
	TIME [epoch: 20.9 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10289883645025359		[learning rate: 0.0056284]
	Learning Rate: 0.0056284
	LOSS [training: 0.10289883645025359 | validation: 0.18276918660810865]
	TIME [epoch: 21 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11151447252336644		[learning rate: 0.0056035]
	Learning Rate: 0.00560353
	LOSS [training: 0.11151447252336644 | validation: 0.16843918151730494]
	TIME [epoch: 21 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11421197820499729		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 0.11421197820499729 | validation: 0.17011932552495795]
	TIME [epoch: 20.9 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1156175088168437		[learning rate: 0.0055541]
	Learning Rate: 0.00555412
	LOSS [training: 0.1156175088168437 | validation: 0.15457269562833462]
	TIME [epoch: 20.9 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10988477103938019		[learning rate: 0.0055296]
	Learning Rate: 0.00552958
	LOSS [training: 0.10988477103938019 | validation: 0.1542311710682007]
	TIME [epoch: 20.9 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11287290834459848		[learning rate: 0.0055052]
	Learning Rate: 0.00550515
	LOSS [training: 0.11287290834459848 | validation: 0.15020063361083985]
	TIME [epoch: 20.9 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11283918875020542		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 0.11283918875020542 | validation: 0.1544814562433667]
	TIME [epoch: 20.9 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11423713534460869		[learning rate: 0.0054566]
	Learning Rate: 0.00545661
	LOSS [training: 0.11423713534460869 | validation: 0.21353137614184858]
	TIME [epoch: 20.9 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12285091728534799		[learning rate: 0.0054325]
	Learning Rate: 0.0054325
	LOSS [training: 0.12285091728534799 | validation: 0.14720990142817172]
	TIME [epoch: 21 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10917567771659609		[learning rate: 0.0054085]
	Learning Rate: 0.0054085
	LOSS [training: 0.10917567771659609 | validation: 0.15199408828850722]
	TIME [epoch: 20.9 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10799822559761588		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 0.10799822559761588 | validation: 0.17413132239109888]
	TIME [epoch: 20.9 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09911234205970275		[learning rate: 0.0053608]
	Learning Rate: 0.00536081
	LOSS [training: 0.09911234205970275 | validation: 0.1494228606872632]
	TIME [epoch: 21 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10804131195978672		[learning rate: 0.0053371]
	Learning Rate: 0.00533713
	LOSS [training: 0.10804131195978672 | validation: 0.16035830550614866]
	TIME [epoch: 20.9 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1130523237758416		[learning rate: 0.0053135]
	Learning Rate: 0.00531355
	LOSS [training: 0.1130523237758416 | validation: 0.15312156195562604]
	TIME [epoch: 20.9 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13227826565776624		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 0.13227826565776624 | validation: 0.152678224338839]
	TIME [epoch: 20.9 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11844384510668941		[learning rate: 0.0052667]
	Learning Rate: 0.0052667
	LOSS [training: 0.11844384510668941 | validation: 0.17586398228195313]
	TIME [epoch: 21 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11532051593932491		[learning rate: 0.0052434]
	Learning Rate: 0.00524343
	LOSS [training: 0.11532051593932491 | validation: 0.1505956952775222]
	TIME [epoch: 20.9 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0952862019531912		[learning rate: 0.0052203]
	Learning Rate: 0.00522026
	LOSS [training: 0.0952862019531912 | validation: 0.172685714354518]
	TIME [epoch: 20.9 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1150224120915215		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 0.1150224120915215 | validation: 0.1583727043044823]
	TIME [epoch: 21 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12734913167696996		[learning rate: 0.0051742]
	Learning Rate: 0.00517423
	LOSS [training: 0.12734913167696996 | validation: 0.14985226116624148]
	TIME [epoch: 20.9 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10696114705054294		[learning rate: 0.0051514]
	Learning Rate: 0.00515137
	LOSS [training: 0.10696114705054294 | validation: 0.18771918836989043]
	TIME [epoch: 20.9 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11850354595843593		[learning rate: 0.0051286]
	Learning Rate: 0.00512861
	LOSS [training: 0.11850354595843593 | validation: 0.16367140258529572]
	TIME [epoch: 21 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13761208058312271		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 0.13761208058312271 | validation: 0.17277964625238754]
	TIME [epoch: 20.9 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12680438003672728		[learning rate: 0.0050834]
	Learning Rate: 0.00508339
	LOSS [training: 0.12680438003672728 | validation: 0.14539186863634748]
	TIME [epoch: 20.9 sec]
	Saving model to: out/model_training/model_facs_dec2b_2d_v1_20240622_102153/states/model_facs_dec2b_2d_v1_193.pth
	Model improved!!!
EPOCH 194/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11475135020773035		[learning rate: 0.0050609]
	Learning Rate: 0.00506093
	LOSS [training: 0.11475135020773035 | validation: 0.17169930632749125]
	TIME [epoch: 20.9 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1077501277361014		[learning rate: 0.0050386]
	Learning Rate: 0.00503857
	LOSS [training: 0.1077501277361014 | validation: 0.14470749355842305]
	TIME [epoch: 21 sec]
	Saving model to: out/model_training/model_facs_dec2b_2d_v1_20240622_102153/states/model_facs_dec2b_2d_v1_195.pth
	Model improved!!!
EPOCH 196/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09731971882178297		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 0.09731971882178297 | validation: 0.15830542487203134]
	TIME [epoch: 20.9 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10482834771039143		[learning rate: 0.0049941]
	Learning Rate: 0.00499415
	LOSS [training: 0.10482834771039143 | validation: 0.15866698860038964]
	TIME [epoch: 20.9 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11963698070136852		[learning rate: 0.0049721]
	Learning Rate: 0.00497208
	LOSS [training: 0.11963698070136852 | validation: 0.1699748076240278]
	TIME [epoch: 21 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10838387088833716		[learning rate: 0.0049501]
	Learning Rate: 0.00495012
	LOSS [training: 0.10838387088833716 | validation: 0.15828984070895782]
	TIME [epoch: 20.9 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11453839003457669		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 0.11453839003457669 | validation: 0.14881975364271932]
	TIME [epoch: 20.9 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09724575217899892		[learning rate: 0.0049065]
	Learning Rate: 0.00490647
	LOSS [training: 0.09724575217899892 | validation: 0.15702605523092775]
	TIME [epoch: 21 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11361268730730507		[learning rate: 0.0048848]
	Learning Rate: 0.00488479
	LOSS [training: 0.11361268730730507 | validation: 0.19862603327622097]
	TIME [epoch: 20.9 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11181297572191713		[learning rate: 0.0048632]
	Learning Rate: 0.00486321
	LOSS [training: 0.11181297572191713 | validation: 0.14354980262410727]
	TIME [epoch: 20.9 sec]
	Saving model to: out/model_training/model_facs_dec2b_2d_v1_20240622_102153/states/model_facs_dec2b_2d_v1_203.pth
	Model improved!!!
EPOCH 204/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11452648504857352		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 0.11452648504857352 | validation: 0.16834427765191703]
	TIME [epoch: 21 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10461202336026987		[learning rate: 0.0048203]
	Learning Rate: 0.00482033
	LOSS [training: 0.10461202336026987 | validation: 0.15970625856488196]
	TIME [epoch: 21 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.112079630674189		[learning rate: 0.004799]
	Learning Rate: 0.00479903
	LOSS [training: 0.112079630674189 | validation: 0.14362393558469821]
	TIME [epoch: 20.9 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10661002515670473		[learning rate: 0.0047778]
	Learning Rate: 0.00477783
	LOSS [training: 0.10661002515670473 | validation: 0.18664473539230386]
	TIME [epoch: 21 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1117566886752693		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.1117566886752693 | validation: 0.14875037082943185]
	TIME [epoch: 20.9 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10424122318479911		[learning rate: 0.0047357]
	Learning Rate: 0.0047357
	LOSS [training: 0.10424122318479911 | validation: 0.1631567967268409]
	TIME [epoch: 20.8 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10874965045230205		[learning rate: 0.0047148]
	Learning Rate: 0.00471478
	LOSS [training: 0.10874965045230205 | validation: 0.14833907086967518]
	TIME [epoch: 20.9 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09455684927674154		[learning rate: 0.0046939]
	Learning Rate: 0.00469395
	LOSS [training: 0.09455684927674154 | validation: 0.15981953615693303]
	TIME [epoch: 20.8 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10056986117485307		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 0.10056986117485307 | validation: 0.15583767493433504]
	TIME [epoch: 20.8 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10139387769649914		[learning rate: 0.0046526]
	Learning Rate: 0.00465256
	LOSS [training: 0.10139387769649914 | validation: 0.20083879430391738]
	TIME [epoch: 20.9 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13992293646355844		[learning rate: 0.004632]
	Learning Rate: 0.00463201
	LOSS [training: 0.13992293646355844 | validation: 0.1573073661007864]
	TIME [epoch: 20.8 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11254959701078074		[learning rate: 0.0046115]
	Learning Rate: 0.00461154
	LOSS [training: 0.11254959701078074 | validation: 0.15508474033146527]
	TIME [epoch: 20.8 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10452331044645233		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 0.10452331044645233 | validation: 0.13457775201571417]
	TIME [epoch: 20.9 sec]
	Saving model to: out/model_training/model_facs_dec2b_2d_v1_20240622_102153/states/model_facs_dec2b_2d_v1_216.pth
	Model improved!!!
EPOCH 217/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09364823648660682		[learning rate: 0.0045709]
	Learning Rate: 0.00457088
	LOSS [training: 0.09364823648660682 | validation: 0.16615104856446]
	TIME [epoch: 20.8 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11289273850618975		[learning rate: 0.0045507]
	Learning Rate: 0.00455069
	LOSS [training: 0.11289273850618975 | validation: 0.14982255945145923]
	TIME [epoch: 20.8 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10407166016810512		[learning rate: 0.0045306]
	Learning Rate: 0.00453058
	LOSS [training: 0.10407166016810512 | validation: 0.14772756502218878]
	TIME [epoch: 20.9 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09470838824095643		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 0.09470838824095643 | validation: 0.16056322137788565]
	TIME [epoch: 20.8 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11018426179105476		[learning rate: 0.0044906]
	Learning Rate: 0.00449063
	LOSS [training: 0.11018426179105476 | validation: 0.14431188300833617]
	TIME [epoch: 20.8 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11948771883978666		[learning rate: 0.0044708]
	Learning Rate: 0.00447079
	LOSS [training: 0.11948771883978666 | validation: 0.14902210664428747]
	TIME [epoch: 20.8 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10120647142431324		[learning rate: 0.004451]
	Learning Rate: 0.00445104
	LOSS [training: 0.10120647142431324 | validation: 0.14017161669843964]
	TIME [epoch: 20.9 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10685887516927842		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 0.10685887516927842 | validation: 0.16118654746277497]
	TIME [epoch: 20.8 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12470587378799085		[learning rate: 0.0044118]
	Learning Rate: 0.0044118
	LOSS [training: 0.12470587378799085 | validation: 0.1914288443807684]
	TIME [epoch: 20.9 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11328085823286108		[learning rate: 0.0043923]
	Learning Rate: 0.0043923
	LOSS [training: 0.11328085823286108 | validation: 0.16064971978878545]
	TIME [epoch: 21 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09904179403607041		[learning rate: 0.0043729]
	Learning Rate: 0.0043729
	LOSS [training: 0.09904179403607041 | validation: 0.17897887834380888]
	TIME [epoch: 20.9 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11269579513716718		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 0.11269579513716718 | validation: 0.15109800377815424]
	TIME [epoch: 20.9 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09984914586270623		[learning rate: 0.0043343]
	Learning Rate: 0.00433434
	LOSS [training: 0.09984914586270623 | validation: 0.18291790050208895]
	TIME [epoch: 21 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10307634506556322		[learning rate: 0.0043152]
	Learning Rate: 0.00431519
	LOSS [training: 0.10307634506556322 | validation: 0.15208441593487226]
	TIME [epoch: 20.9 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12709743837201048		[learning rate: 0.0042961]
	Learning Rate: 0.00429612
	LOSS [training: 0.12709743837201048 | validation: 0.19245354213594865]
	TIME [epoch: 20.9 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10872321630675327		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 0.10872321630675327 | validation: 0.1458943810545408]
	TIME [epoch: 21 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10605167032723961		[learning rate: 0.0042582]
	Learning Rate: 0.00425825
	LOSS [training: 0.10605167032723961 | validation: 0.14165426474885642]
	TIME [epoch: 21 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09763257553870303		[learning rate: 0.0042394]
	Learning Rate: 0.00423943
	LOSS [training: 0.09763257553870303 | validation: 0.16816789344382246]
	TIME [epoch: 20.9 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10504719533955709		[learning rate: 0.0042207]
	Learning Rate: 0.0042207
	LOSS [training: 0.10504719533955709 | validation: 0.14589089567486913]
	TIME [epoch: 20.9 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09355268828787251		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 0.09355268828787251 | validation: 0.16703469412725241]
	TIME [epoch: 21 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1054259964818659		[learning rate: 0.0041835]
	Learning Rate: 0.00418349
	LOSS [training: 0.1054259964818659 | validation: 0.15028877774620858]
	TIME [epoch: 20.9 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10817500119772423		[learning rate: 0.004165]
	Learning Rate: 0.004165
	LOSS [training: 0.10817500119772423 | validation: 0.14011174159839007]
	TIME [epoch: 20.9 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10190096033023743		[learning rate: 0.0041466]
	Learning Rate: 0.0041466
	LOSS [training: 0.10190096033023743 | validation: 0.16025970779331225]
	TIME [epoch: 21 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10722572210759776		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 0.10722572210759776 | validation: 0.1482341522511233]
	TIME [epoch: 20.9 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09504484133089951		[learning rate: 0.00411]
	Learning Rate: 0.00411004
	LOSS [training: 0.09504484133089951 | validation: 0.14704282576062744]
	TIME [epoch: 20.8 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10626268677805209		[learning rate: 0.0040919]
	Learning Rate: 0.00409188
	LOSS [training: 0.10626268677805209 | validation: 0.17112079798352914]
	TIME [epoch: 21 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10586487691166797		[learning rate: 0.0040738]
	Learning Rate: 0.0040738
	LOSS [training: 0.10586487691166797 | validation: 0.1433936533039294]
	TIME [epoch: 20.9 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10039891045782837		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.10039891045782837 | validation: 0.1529975686156047]
	TIME [epoch: 20.9 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10103505829241306		[learning rate: 0.0040379]
	Learning Rate: 0.00403788
	LOSS [training: 0.10103505829241306 | validation: 0.13901302394375786]
	TIME [epoch: 20.9 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08384040056376471		[learning rate: 0.00402]
	Learning Rate: 0.00402004
	LOSS [training: 0.08384040056376471 | validation: 0.1575982150635975]
	TIME [epoch: 21 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10291985787734359		[learning rate: 0.0040023]
	Learning Rate: 0.00400228
	LOSS [training: 0.10291985787734359 | validation: 0.15842384428999293]
	TIME [epoch: 20.9 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09350063443531342		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 0.09350063443531342 | validation: 0.14954498454578938]
	TIME [epoch: 20.9 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10501979491651273		[learning rate: 0.003967]
	Learning Rate: 0.00396699
	LOSS [training: 0.10501979491651273 | validation: 0.1814406729458311]
	TIME [epoch: 21 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09479486927026161		[learning rate: 0.0039495]
	Learning Rate: 0.00394947
	LOSS [training: 0.09479486927026161 | validation: 0.1432144077914498]
	TIME [epoch: 20.9 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09259638651513627		[learning rate: 0.003932]
	Learning Rate: 0.00393202
	LOSS [training: 0.09259638651513627 | validation: 0.17452002811624337]
	TIME [epoch: 20.9 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10145434318042117		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 0.10145434318042117 | validation: 0.13730781803518205]
	TIME [epoch: 21 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10516089268916051		[learning rate: 0.0038973]
	Learning Rate: 0.00389735
	LOSS [training: 0.10516089268916051 | validation: 0.1788209813827119]
	TIME [epoch: 20.9 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11084201943818794		[learning rate: 0.0038801]
	Learning Rate: 0.00388013
	LOSS [training: 0.11084201943818794 | validation: 0.1357142906403609]
	TIME [epoch: 20.9 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09537319214373459		[learning rate: 0.003863]
	Learning Rate: 0.00386299
	LOSS [training: 0.09537319214373459 | validation: 0.16847623613532417]
	TIME [epoch: 20.9 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1029390278028109		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 0.1029390278028109 | validation: 0.14550994505579568]
	TIME [epoch: 21 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10348440061277756		[learning rate: 0.0038289]
	Learning Rate: 0.00382893
	LOSS [training: 0.10348440061277756 | validation: 0.15532745598458067]
	TIME [epoch: 20.9 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10205446484660152		[learning rate: 0.003812]
	Learning Rate: 0.00381201
	LOSS [training: 0.10205446484660152 | validation: 0.14863437006453178]
	TIME [epoch: 20.9 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09511985615685215		[learning rate: 0.0037952]
	Learning Rate: 0.00379517
	LOSS [training: 0.09511985615685215 | validation: 0.14769815396784786]
	TIME [epoch: 21 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10132826013073207		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 0.10132826013073207 | validation: 0.16445120065618066]
	TIME [epoch: 20.9 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09917130720492899		[learning rate: 0.0037617]
	Learning Rate: 0.0037617
	LOSS [training: 0.09917130720492899 | validation: 0.14458022830822212]
	TIME [epoch: 20.8 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10755791370783312		[learning rate: 0.0037451]
	Learning Rate: 0.00374508
	LOSS [training: 0.10755791370783312 | validation: 0.17577064736115167]
	TIME [epoch: 21 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11087465067152444		[learning rate: 0.0037285]
	Learning Rate: 0.00372854
	LOSS [training: 0.11087465067152444 | validation: 0.17594011066317328]
	TIME [epoch: 20.9 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10915703105655195		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 0.10915703105655195 | validation: 0.16681107860626448]
	TIME [epoch: 20.8 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10033480744447232		[learning rate: 0.0036957]
	Learning Rate: 0.00369566
	LOSS [training: 0.10033480744447232 | validation: 0.13991728754892518]
	TIME [epoch: 21 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09599702562468311		[learning rate: 0.0036793]
	Learning Rate: 0.00367933
	LOSS [training: 0.09599702562468311 | validation: 0.14627658198272964]
	TIME [epoch: 21 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10824425541269855		[learning rate: 0.0036631]
	Learning Rate: 0.00366308
	LOSS [training: 0.10824425541269855 | validation: 0.1561987211502018]
	TIME [epoch: 20.8 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09297368642520272		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 0.09297368642520272 | validation: 0.1445117697138833]
	TIME [epoch: 20.9 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10061468035039418		[learning rate: 0.0036308]
	Learning Rate: 0.00363078
	LOSS [training: 0.10061468035039418 | validation: 0.15230589815325662]
	TIME [epoch: 21 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09542915131249723		[learning rate: 0.0036147]
	Learning Rate: 0.00361474
	LOSS [training: 0.09542915131249723 | validation: 0.16955831957454146]
	TIME [epoch: 20.9 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09708563981483236		[learning rate: 0.0035988]
	Learning Rate: 0.00359877
	LOSS [training: 0.09708563981483236 | validation: 0.14621255922563736]
	TIME [epoch: 20.9 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09475135798357698		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 0.09475135798357698 | validation: 0.1424320928262505]
	TIME [epoch: 20.9 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1000116669042272		[learning rate: 0.003567]
	Learning Rate: 0.00356704
	LOSS [training: 0.1000116669042272 | validation: 0.16577892865507785]
	TIME [epoch: 20.9 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09641504582802538		[learning rate: 0.0035513]
	Learning Rate: 0.00355128
	LOSS [training: 0.09641504582802538 | validation: 0.14395980388281]
	TIME [epoch: 20.8 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0991586737464344		[learning rate: 0.0035356]
	Learning Rate: 0.00353559
	LOSS [training: 0.0991586737464344 | validation: 0.19627568768391443]
	TIME [epoch: 21 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1065751715959919		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 0.1065751715959919 | validation: 0.15314929700088198]
	TIME [epoch: 20.9 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10768366389468705		[learning rate: 0.0035044]
	Learning Rate: 0.00350441
	LOSS [training: 0.10768366389468705 | validation: 0.17822956419950614]
	TIME [epoch: 20.9 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09404588855032302		[learning rate: 0.0034889]
	Learning Rate: 0.00348893
	LOSS [training: 0.09404588855032302 | validation: 0.14051839781433095]
	TIME [epoch: 20.9 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09258701250921028		[learning rate: 0.0034735]
	Learning Rate: 0.00347352
	LOSS [training: 0.09258701250921028 | validation: 0.14482264106520154]
	TIME [epoch: 21 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09861203036268204		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.09861203036268204 | validation: 0.16470134341738293]
	TIME [epoch: 20.9 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12158956778158439		[learning rate: 0.0034429]
	Learning Rate: 0.00344289
	LOSS [training: 0.12158956778158439 | validation: 0.1354193455364443]
	TIME [epoch: 20.8 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09815807783550215		[learning rate: 0.0034277]
	Learning Rate: 0.00342768
	LOSS [training: 0.09815807783550215 | validation: 0.1396805638406154]
	TIME [epoch: 21 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09651055898813676		[learning rate: 0.0034125]
	Learning Rate: 0.00341253
	LOSS [training: 0.09651055898813676 | validation: 0.14220236903724895]
	TIME [epoch: 20.9 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09175365834198175		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 0.09175365834198175 | validation: 0.15282572090743388]
	TIME [epoch: 20.9 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09851065154016932		[learning rate: 0.0033824]
	Learning Rate: 0.00338245
	LOSS [training: 0.09851065154016932 | validation: 0.14336457775481284]
	TIME [epoch: 21 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09497184042292725		[learning rate: 0.0033675]
	Learning Rate: 0.0033675
	LOSS [training: 0.09497184042292725 | validation: 0.1444167450792172]
	TIME [epoch: 20.9 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09678727840685197		[learning rate: 0.0033526]
	Learning Rate: 0.00335262
	LOSS [training: 0.09678727840685197 | validation: 0.15368345467456762]
	TIME [epoch: 20.9 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10454573626495711		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 0.10454573626495711 | validation: 0.14124496894459382]
	TIME [epoch: 20.9 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09056431815097692		[learning rate: 0.0033231]
	Learning Rate: 0.00332306
	LOSS [training: 0.09056431815097692 | validation: 0.17395155503966955]
	TIME [epoch: 21 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11143936251364125		[learning rate: 0.0033084]
	Learning Rate: 0.00330838
	LOSS [training: 0.11143936251364125 | validation: 0.13839902768724746]
	TIME [epoch: 20.9 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.100711318475275		[learning rate: 0.0032938]
	Learning Rate: 0.00329376
	LOSS [training: 0.100711318475275 | validation: 0.16580536191728382]
	TIME [epoch: 20.9 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11070110360812246		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 0.11070110360812246 | validation: 0.1603737869947126]
	TIME [epoch: 20.9 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09952613769454349		[learning rate: 0.0032647]
	Learning Rate: 0.00326472
	LOSS [training: 0.09952613769454349 | validation: 0.17592207750696523]
	TIME [epoch: 20.9 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10114787985364855		[learning rate: 0.0032503]
	Learning Rate: 0.0032503
	LOSS [training: 0.10114787985364855 | validation: 0.1445986727538761]
	TIME [epoch: 20.8 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09498883657467032		[learning rate: 0.0032359]
	Learning Rate: 0.00323594
	LOSS [training: 0.09498883657467032 | validation: 0.14601733388525942]
	TIME [epoch: 20.9 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10112460388405656		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 0.10112460388405656 | validation: 0.1573667023546604]
	TIME [epoch: 21 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0952863602800446		[learning rate: 0.0032074]
	Learning Rate: 0.00320741
	LOSS [training: 0.0952863602800446 | validation: 0.14917892368426153]
	TIME [epoch: 20.9 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10035846840234704		[learning rate: 0.0031932]
	Learning Rate: 0.00319323
	LOSS [training: 0.10035846840234704 | validation: 0.1786372740751077]
	TIME [epoch: 21 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09524586232139345		[learning rate: 0.0031791]
	Learning Rate: 0.00317913
	LOSS [training: 0.09524586232139345 | validation: 0.14127894848431669]
	TIME [epoch: 21 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08961313235515667		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 0.08961313235515667 | validation: 0.14518564148048219]
	TIME [epoch: 20.9 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0962233126049656		[learning rate: 0.0031511]
	Learning Rate: 0.0031511
	LOSS [training: 0.0962233126049656 | validation: 0.16236866588309873]
	TIME [epoch: 20.9 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0949350277684762		[learning rate: 0.0031372]
	Learning Rate: 0.00313717
	LOSS [training: 0.0949350277684762 | validation: 0.14970283518340124]
	TIME [epoch: 21 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09274507675559548		[learning rate: 0.0031233]
	Learning Rate: 0.00312331
	LOSS [training: 0.09274507675559548 | validation: 0.18915882480579105]
	TIME [epoch: 21 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10241832525022407		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 0.10241832525022407 | validation: 0.1383975572115226]
	TIME [epoch: 20.9 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10480336232548122		[learning rate: 0.0030958]
	Learning Rate: 0.00309577
	LOSS [training: 0.10480336232548122 | validation: 0.1538442324618546]
	TIME [epoch: 21 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09026763611939206		[learning rate: 0.0030821]
	Learning Rate: 0.0030821
	LOSS [training: 0.09026763611939206 | validation: 0.14943064237912695]
	TIME [epoch: 20.8 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0944759726117323		[learning rate: 0.0030685]
	Learning Rate: 0.00306848
	LOSS [training: 0.0944759726117323 | validation: 0.160468637080111]
	TIME [epoch: 20.8 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0936169703506322		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 0.0936169703506322 | validation: 0.1292301235671598]
	TIME [epoch: 20.8 sec]
	Saving model to: out/model_training/model_facs_dec2b_2d_v1_20240622_102153/states/model_facs_dec2b_2d_v1_308.pth
	Model improved!!!
EPOCH 309/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09374036077964484		[learning rate: 0.0030414]
	Learning Rate: 0.00304142
	LOSS [training: 0.09374036077964484 | validation: 0.1540130815005064]
	TIME [epoch: 20.8 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09851543820007888		[learning rate: 0.003028]
	Learning Rate: 0.00302799
	LOSS [training: 0.09851543820007888 | validation: 0.137425327255096]
	TIME [epoch: 20.8 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.097606395749824		[learning rate: 0.0030146]
	Learning Rate: 0.00301461
	LOSS [training: 0.097606395749824 | validation: 0.1558699769088838]
	TIME [epoch: 20.8 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09473751161293997		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 0.09473751161293997 | validation: 0.14219673242578484]
	TIME [epoch: 20.8 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10209915682174661		[learning rate: 0.002988]
	Learning Rate: 0.00298803
	LOSS [training: 0.10209915682174661 | validation: 0.19744717219189822]
	TIME [epoch: 20.9 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0943917794135061		[learning rate: 0.0029748]
	Learning Rate: 0.00297483
	LOSS [training: 0.0943917794135061 | validation: 0.14751780857125332]
	TIME [epoch: 20.9 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09637350310231049		[learning rate: 0.0029617]
	Learning Rate: 0.00296168
	LOSS [training: 0.09637350310231049 | validation: 0.15672807000263964]
	TIME [epoch: 20.9 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09778743720625618		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.09778743720625618 | validation: 0.1496115618385819]
	TIME [epoch: 20.9 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10063669425656671		[learning rate: 0.0029356]
	Learning Rate: 0.00293557
	LOSS [training: 0.10063669425656671 | validation: 0.1686302356912973]
	TIME [epoch: 20.9 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09456790642187873		[learning rate: 0.0029226]
	Learning Rate: 0.0029226
	LOSS [training: 0.09456790642187873 | validation: 0.13218312638700286]
	TIME [epoch: 21 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08852234861674671		[learning rate: 0.0029097]
	Learning Rate: 0.00290969
	LOSS [training: 0.08852234861674671 | validation: 0.16014802553665347]
	TIME [epoch: 21 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09550923068940338		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 0.09550923068940338 | validation: 0.1391016253725274]
	TIME [epoch: 20.9 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09822586561056292		[learning rate: 0.002884]
	Learning Rate: 0.00288403
	LOSS [training: 0.09822586561056292 | validation: 0.14568468834225623]
	TIME [epoch: 21 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09701839847480005		[learning rate: 0.0028713]
	Learning Rate: 0.00287129
	LOSS [training: 0.09701839847480005 | validation: 0.14386598405832027]
	TIME [epoch: 21 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09533456044100545		[learning rate: 0.0028586]
	Learning Rate: 0.0028586
	LOSS [training: 0.09533456044100545 | validation: 0.12969466539320762]
	TIME [epoch: 20.9 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08509294935747269		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 0.08509294935747269 | validation: 0.18157722774599933]
	TIME [epoch: 20.9 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08162990059751307		[learning rate: 0.0028334]
	Learning Rate: 0.0028334
	LOSS [training: 0.08162990059751307 | validation: 0.12899049617271469]
	TIME [epoch: 21 sec]
	Saving model to: out/model_training/model_facs_dec2b_2d_v1_20240622_102153/states/model_facs_dec2b_2d_v1_325.pth
	Model improved!!!
EPOCH 326/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10318391477871072		[learning rate: 0.0028209]
	Learning Rate: 0.00282088
	LOSS [training: 0.10318391477871072 | validation: 0.17304684248257676]
	TIME [epoch: 21 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09151197280127077		[learning rate: 0.0028084]
	Learning Rate: 0.00280842
	LOSS [training: 0.09151197280127077 | validation: 0.13450862671609298]
	TIME [epoch: 20.9 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09264545984483127		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 0.09264545984483127 | validation: 0.16382425954666008]
	TIME [epoch: 21 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09749947180270983		[learning rate: 0.0027837]
	Learning Rate: 0.00278366
	LOSS [training: 0.09749947180270983 | validation: 0.13048746020075633]
	TIME [epoch: 20.9 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0998159457837259		[learning rate: 0.0027714]
	Learning Rate: 0.00277136
	LOSS [training: 0.0998159457837259 | validation: 0.16969208743989378]
	TIME [epoch: 20.9 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08428528954127548		[learning rate: 0.0027591]
	Learning Rate: 0.00275911
	LOSS [training: 0.08428528954127548 | validation: 0.15813309405126771]
	TIME [epoch: 20.9 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09106450213480462		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 0.09106450213480462 | validation: 0.16644273988475136]
	TIME [epoch: 21 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09858421535450992		[learning rate: 0.0027348]
	Learning Rate: 0.00273478
	LOSS [training: 0.09858421535450992 | validation: 0.14505615457325888]
	TIME [epoch: 20.9 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08600046442175178		[learning rate: 0.0027227]
	Learning Rate: 0.0027227
	LOSS [training: 0.08600046442175178 | validation: 0.15739056444718152]
	TIME [epoch: 20.9 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09688183354081308		[learning rate: 0.0027107]
	Learning Rate: 0.00271067
	LOSS [training: 0.09688183354081308 | validation: 0.1457888818536002]
	TIME [epoch: 21 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08998496744630294		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 0.08998496744630294 | validation: 0.14027732903098455]
	TIME [epoch: 20.9 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10285489903163655		[learning rate: 0.0026868]
	Learning Rate: 0.00268677
	LOSS [training: 0.10285489903163655 | validation: 0.1445780642333212]
	TIME [epoch: 20.9 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09485559419847076		[learning rate: 0.0026749]
	Learning Rate: 0.0026749
	LOSS [training: 0.09485559419847076 | validation: 0.12654894905813624]
	TIME [epoch: 21 sec]
	Saving model to: out/model_training/model_facs_dec2b_2d_v1_20240622_102153/states/model_facs_dec2b_2d_v1_338.pth
	Model improved!!!
EPOCH 339/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0937493756442547		[learning rate: 0.0026631]
	Learning Rate: 0.00266308
	LOSS [training: 0.0937493756442547 | validation: 0.15299634022633252]
	TIME [epoch: 21 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09353475927392327		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 0.09353475927392327 | validation: 0.1355808151292952]
	TIME [epoch: 20.8 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10205278090160197		[learning rate: 0.0026396]
	Learning Rate: 0.0026396
	LOSS [training: 0.10205278090160197 | validation: 0.16256157885988598]
	TIME [epoch: 20.9 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0902525137187838		[learning rate: 0.0026279]
	Learning Rate: 0.00262794
	LOSS [training: 0.0902525137187838 | validation: 0.12765694649927484]
	TIME [epoch: 21 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0868350493277872		[learning rate: 0.0026163]
	Learning Rate: 0.00261633
	LOSS [training: 0.0868350493277872 | validation: 0.15520705115524921]
	TIME [epoch: 20.9 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09079541813425326		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 0.09079541813425326 | validation: 0.14225434435375564]
	TIME [epoch: 20.9 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0911712605605411		[learning rate: 0.0025933]
	Learning Rate: 0.00259326
	LOSS [training: 0.0911712605605411 | validation: 0.15457467877910863]
	TIME [epoch: 20.9 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10047909151720666		[learning rate: 0.0025818]
	Learning Rate: 0.0025818
	LOSS [training: 0.10047909151720666 | validation: 0.13965060900538445]
	TIME [epoch: 20.9 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09243000903836082		[learning rate: 0.0025704]
	Learning Rate: 0.0025704
	LOSS [training: 0.09243000903836082 | validation: 0.13826878477413004]
	TIME [epoch: 20.9 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08863172175844328		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.08863172175844328 | validation: 0.13178563680320143]
	TIME [epoch: 20.9 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09028484951978562		[learning rate: 0.0025477]
	Learning Rate: 0.00254773
	LOSS [training: 0.09028484951978562 | validation: 0.1399765460295078]
	TIME [epoch: 20.9 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0935480636175787		[learning rate: 0.0025365]
	Learning Rate: 0.00253648
	LOSS [training: 0.0935480636175787 | validation: 0.13768157345608867]
	TIME [epoch: 20.8 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08392561245806576		[learning rate: 0.0025253]
	Learning Rate: 0.00252527
	LOSS [training: 0.08392561245806576 | validation: 0.15470732875832022]
	TIME [epoch: 20.9 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09745197018670407		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.09745197018670407 | validation: 0.14581867078146568]
	TIME [epoch: 20.9 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08578845788420353		[learning rate: 0.002503]
	Learning Rate: 0.002503
	LOSS [training: 0.08578845788420353 | validation: 0.1400487812632808]
	TIME [epoch: 20.9 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10001445610928586		[learning rate: 0.0024919]
	Learning Rate: 0.00249194
	LOSS [training: 0.10001445610928586 | validation: 0.13468543100685626]
	TIME [epoch: 20.9 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0903671639272498		[learning rate: 0.0024809]
	Learning Rate: 0.00248093
	LOSS [training: 0.0903671639272498 | validation: 0.16036627756891447]
	TIME [epoch: 21 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0912780733612692		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 0.0912780733612692 | validation: 0.12844616631425682]
	TIME [epoch: 20.9 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08899120425845375		[learning rate: 0.0024591]
	Learning Rate: 0.00245906
	LOSS [training: 0.08899120425845375 | validation: 0.14518374271047768]
	TIME [epoch: 20.8 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09227019331074895		[learning rate: 0.0024482]
	Learning Rate: 0.0024482
	LOSS [training: 0.09227019331074895 | validation: 0.13666148353975785]
	TIME [epoch: 21 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09389374666635975		[learning rate: 0.0024374]
	Learning Rate: 0.00243738
	LOSS [training: 0.09389374666635975 | validation: 0.1332799283675572]
	TIME [epoch: 20.9 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09029626743941922		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.09029626743941922 | validation: 0.13502933319636148]
	TIME [epoch: 20.9 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0899836531228859		[learning rate: 0.0024159]
	Learning Rate: 0.00241589
	LOSS [training: 0.0899836531228859 | validation: 0.14096882812070333]
	TIME [epoch: 20.9 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0955880648830221		[learning rate: 0.0024052]
	Learning Rate: 0.00240521
	LOSS [training: 0.0955880648830221 | validation: 0.12530238178105352]
	TIME [epoch: 20.9 sec]
	Saving model to: out/model_training/model_facs_dec2b_2d_v1_20240622_102153/states/model_facs_dec2b_2d_v1_362.pth
	Model improved!!!
EPOCH 363/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08395401084330142		[learning rate: 0.0023946]
	Learning Rate: 0.00239459
	LOSS [training: 0.08395401084330142 | validation: 0.14112085222618276]
	TIME [epoch: 20.9 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09675906464911392		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 0.09675906464911392 | validation: 0.1348797329464123]
	TIME [epoch: 20.9 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0923394019916743		[learning rate: 0.0023735]
	Learning Rate: 0.00237347
	LOSS [training: 0.0923394019916743 | validation: 0.1365060365105253]
	TIME [epoch: 20.9 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09365673643588762		[learning rate: 0.002363]
	Learning Rate: 0.00236299
	LOSS [training: 0.09365673643588762 | validation: 0.13666544032948408]
	TIME [epoch: 20.9 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09070917262814142		[learning rate: 0.0023525]
	Learning Rate: 0.00235255
	LOSS [training: 0.09070917262814142 | validation: 0.14197450928955938]
	TIME [epoch: 20.9 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08496600476120605		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.08496600476120605 | validation: 0.15037804874928534]
	TIME [epoch: 21 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09476067773201702		[learning rate: 0.0023318]
	Learning Rate: 0.00233181
	LOSS [training: 0.09476067773201702 | validation: 0.12958144627041635]
	TIME [epoch: 21 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08515821471293912		[learning rate: 0.0023215]
	Learning Rate: 0.0023215
	LOSS [training: 0.08515821471293912 | validation: 0.13816463064072312]
	TIME [epoch: 20.8 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09391554295964581		[learning rate: 0.0023112]
	Learning Rate: 0.00231125
	LOSS [training: 0.09391554295964581 | validation: 0.13983221498652948]
	TIME [epoch: 20.9 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08780812399090557		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.08780812399090557 | validation: 0.13418522641976258]
	TIME [epoch: 20.8 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08935182602631113		[learning rate: 0.0022909]
	Learning Rate: 0.00229087
	LOSS [training: 0.08935182602631113 | validation: 0.15308356077153826]
	TIME [epoch: 20.8 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10052033199884829		[learning rate: 0.0022807]
	Learning Rate: 0.00228075
	LOSS [training: 0.10052033199884829 | validation: 0.12564854484002685]
	TIME [epoch: 20.8 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08795477011661298		[learning rate: 0.0022707]
	Learning Rate: 0.00227067
	LOSS [training: 0.08795477011661298 | validation: 0.13976384841314046]
	TIME [epoch: 20.9 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08965624707513772		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.08965624707513772 | validation: 0.15035945528728603]
	TIME [epoch: 20.9 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09962404364539915		[learning rate: 0.0022506]
	Learning Rate: 0.00225065
	LOSS [training: 0.09962404364539915 | validation: 0.14862757266905308]
	TIME [epoch: 20.9 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09441068996754168		[learning rate: 0.0022407]
	Learning Rate: 0.0022407
	LOSS [training: 0.09441068996754168 | validation: 0.13255425028339315]
	TIME [epoch: 20.9 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08962375988054157		[learning rate: 0.0022308]
	Learning Rate: 0.0022308
	LOSS [training: 0.08962375988054157 | validation: 0.14440550379558884]
	TIME [epoch: 20.9 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09050166569037453		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.09050166569037453 | validation: 0.13816571297091002]
	TIME [epoch: 20.9 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09834165308642674		[learning rate: 0.0022111]
	Learning Rate: 0.00221114
	LOSS [training: 0.09834165308642674 | validation: 0.15085948310974223]
	TIME [epoch: 20.9 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09621435435416364		[learning rate: 0.0022014]
	Learning Rate: 0.00220137
	LOSS [training: 0.09621435435416364 | validation: 0.14575805128828317]
	TIME [epoch: 20.9 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09731981974960702		[learning rate: 0.0021916]
	Learning Rate: 0.00219164
	LOSS [training: 0.09731981974960702 | validation: 0.12882927120526222]
	TIME [epoch: 20.9 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07722512234490393		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.07722512234490393 | validation: 0.14070220076401713]
	TIME [epoch: 21 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0896503448625634		[learning rate: 0.0021723]
	Learning Rate: 0.00217232
	LOSS [training: 0.0896503448625634 | validation: 0.1454731187914839]
	TIME [epoch: 21 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09745711609065974		[learning rate: 0.0021627]
	Learning Rate: 0.00216272
	LOSS [training: 0.09745711609065974 | validation: 0.14427751355797658]
	TIME [epoch: 20.9 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08936462594869363		[learning rate: 0.0021532]
	Learning Rate: 0.00215316
	LOSS [training: 0.08936462594869363 | validation: 0.15262383825317852]
	TIME [epoch: 20.9 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08756806717325794		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.08756806717325794 | validation: 0.1352602886632101]
	TIME [epoch: 21 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09161677021919712		[learning rate: 0.0021342]
	Learning Rate: 0.00213418
	LOSS [training: 0.09161677021919712 | validation: 0.14987896201758158]
	TIME [epoch: 20.9 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0837186304148109		[learning rate: 0.0021247]
	Learning Rate: 0.00212475
	LOSS [training: 0.0837186304148109 | validation: 0.16847651212011783]
	TIME [epoch: 20.9 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08888410148050253		[learning rate: 0.0021154]
	Learning Rate: 0.00211536
	LOSS [training: 0.08888410148050253 | validation: 0.14374691708826023]
	TIME [epoch: 20.9 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10193445550034745		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.10193445550034745 | validation: 0.14236201582263588]
	TIME [epoch: 21 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09116877299852659		[learning rate: 0.0020967]
	Learning Rate: 0.00209671
	LOSS [training: 0.09116877299852659 | validation: 0.14449825597617053]
	TIME [epoch: 20.8 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08467213526152781		[learning rate: 0.0020874]
	Learning Rate: 0.00208745
	LOSS [training: 0.08467213526152781 | validation: 0.13620368252789244]
	TIME [epoch: 20.9 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08926091504370118		[learning rate: 0.0020782]
	Learning Rate: 0.00207822
	LOSS [training: 0.08926091504370118 | validation: 0.14154007922079112]
	TIME [epoch: 20.9 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08556624364207432		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.08556624364207432 | validation: 0.13458155323803414]
	TIME [epoch: 20.9 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0856684724375325		[learning rate: 0.0020599]
	Learning Rate: 0.0020599
	LOSS [training: 0.0856684724375325 | validation: 0.1310411211912993]
	TIME [epoch: 20.9 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08471319278511306		[learning rate: 0.0020508]
	Learning Rate: 0.0020508
	LOSS [training: 0.08471319278511306 | validation: 0.13780114220906312]
	TIME [epoch: 20.9 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08419550252351882		[learning rate: 0.0020417]
	Learning Rate: 0.00204174
	LOSS [training: 0.08419550252351882 | validation: 0.16435523637645183]
	TIME [epoch: 20.9 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09038691765249543		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.09038691765249543 | validation: 0.145668108804838]
	TIME [epoch: 20.8 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09051020736988702		[learning rate: 0.0020237]
	Learning Rate: 0.00202374
	LOSS [training: 0.09051020736988702 | validation: 0.1485091044600396]
	TIME [epoch: 21 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0841482826342532		[learning rate: 0.0020148]
	Learning Rate: 0.00201479
	LOSS [training: 0.0841482826342532 | validation: 0.1522865772103753]
	TIME [epoch: 20.9 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10001054498940218		[learning rate: 0.0020059]
	Learning Rate: 0.00200589
	LOSS [training: 0.10001054498940218 | validation: 0.14980738243774433]
	TIME [epoch: 20.8 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09077382857039198		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.09077382857039198 | validation: 0.14777332144321562]
	TIME [epoch: 20.9 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09595458783008588		[learning rate: 0.0019882]
	Learning Rate: 0.00198821
	LOSS [training: 0.09595458783008588 | validation: 0.19230966525955442]
	TIME [epoch: 20.9 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10333053273742039		[learning rate: 0.0019794]
	Learning Rate: 0.00197942
	LOSS [training: 0.10333053273742039 | validation: 0.13652710843115223]
	TIME [epoch: 20.9 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08429587989754922		[learning rate: 0.0019707]
	Learning Rate: 0.00197068
	LOSS [training: 0.08429587989754922 | validation: 0.14644022250232788]
	TIME [epoch: 20.9 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09038476458217075		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.09038476458217075 | validation: 0.13582591811789355]
	TIME [epoch: 20.9 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08781069254128238		[learning rate: 0.0019533]
	Learning Rate: 0.0019533
	LOSS [training: 0.08781069254128238 | validation: 0.15748817192019812]
	TIME [epoch: 20.9 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08961908102875793		[learning rate: 0.0019447]
	Learning Rate: 0.00194467
	LOSS [training: 0.08961908102875793 | validation: 0.1375950213048947]
	TIME [epoch: 20.9 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08781812203891802		[learning rate: 0.0019361]
	Learning Rate: 0.00193608
	LOSS [training: 0.08781812203891802 | validation: 0.13261333078896792]
	TIME [epoch: 20.9 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08442650422572022		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.08442650422572022 | validation: 0.1610346394910612]
	TIME [epoch: 20.9 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08165534873668343		[learning rate: 0.001919]
	Learning Rate: 0.00191901
	LOSS [training: 0.08165534873668343 | validation: 0.1367299686413389]
	TIME [epoch: 20.8 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08632427464331882		[learning rate: 0.0019105]
	Learning Rate: 0.00191053
	LOSS [training: 0.08632427464331882 | validation: 0.15412978581728004]
	TIME [epoch: 20.9 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08169509752909952		[learning rate: 0.0019021]
	Learning Rate: 0.00190209
	LOSS [training: 0.08169509752909952 | validation: 0.12909114029214985]
	TIME [epoch: 20.8 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09048363063840101		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.09048363063840101 | validation: 0.1375293537188861]
	TIME [epoch: 20.8 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08729235228433177		[learning rate: 0.0018853]
	Learning Rate: 0.00188532
	LOSS [training: 0.08729235228433177 | validation: 0.16804094449023146]
	TIME [epoch: 20.8 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08385807881086424		[learning rate: 0.001877]
	Learning Rate: 0.00187699
	LOSS [training: 0.08385807881086424 | validation: 0.13289105762273945]
	TIME [epoch: 20.8 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0885822892391018		[learning rate: 0.0018687]
	Learning Rate: 0.0018687
	LOSS [training: 0.0885822892391018 | validation: 0.13867553380597725]
	TIME [epoch: 20.8 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08743303978066433		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.08743303978066433 | validation: 0.1261510258347078]
	TIME [epoch: 20.8 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07554747118754843		[learning rate: 0.0018522]
	Learning Rate: 0.00185222
	LOSS [training: 0.07554747118754843 | validation: 0.1384499114508271]
	TIME [epoch: 20.8 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09298700523087433		[learning rate: 0.001844]
	Learning Rate: 0.00184404
	LOSS [training: 0.09298700523087433 | validation: 0.15339389709998652]
	TIME [epoch: 20.8 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09232159154444537		[learning rate: 0.0018359]
	Learning Rate: 0.00183589
	LOSS [training: 0.09232159154444537 | validation: 0.12969416672160572]
	TIME [epoch: 20.8 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09741621966085151		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.09741621966085151 | validation: 0.1448110923109546]
	TIME [epoch: 20.9 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09034518728854526		[learning rate: 0.0018197]
	Learning Rate: 0.0018197
	LOSS [training: 0.09034518728854526 | validation: 0.1698663439560657]
	TIME [epoch: 20.9 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08516828287765249		[learning rate: 0.0018117]
	Learning Rate: 0.00181166
	LOSS [training: 0.08516828287765249 | validation: 0.14040252173652418]
	TIME [epoch: 20.8 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09043239025281544		[learning rate: 0.0018037]
	Learning Rate: 0.00180366
	LOSS [training: 0.09043239025281544 | validation: 0.16255348815981835]
	TIME [epoch: 20.9 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09772740953685816		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.09772740953685816 | validation: 0.12942727629493703]
	TIME [epoch: 20.9 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08062101006545777		[learning rate: 0.0017878]
	Learning Rate: 0.00178775
	LOSS [training: 0.08062101006545777 | validation: 0.14561042284580666]
	TIME [epoch: 20.9 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08822259497795967		[learning rate: 0.0017799]
	Learning Rate: 0.00177985
	LOSS [training: 0.08822259497795967 | validation: 0.13579255695664683]
	TIME [epoch: 20.8 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08643783988942888		[learning rate: 0.001772]
	Learning Rate: 0.00177199
	LOSS [training: 0.08643783988942888 | validation: 0.15047495351202025]
	TIME [epoch: 20.9 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08411995113306711		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.08411995113306711 | validation: 0.13509046793114754]
	TIME [epoch: 20.9 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08941964784476254		[learning rate: 0.0017564]
	Learning Rate: 0.00175637
	LOSS [training: 0.08941964784476254 | validation: 0.13482803460248954]
	TIME [epoch: 20.8 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08671271043471648		[learning rate: 0.0017486]
	Learning Rate: 0.00174861
	LOSS [training: 0.08671271043471648 | validation: 0.13112698625767283]
	TIME [epoch: 20.9 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09912203217912703		[learning rate: 0.0017409]
	Learning Rate: 0.00174088
	LOSS [training: 0.09912203217912703 | validation: 0.1637568935181307]
	TIME [epoch: 20.9 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09138240612307744		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.09138240612307744 | validation: 0.12373187312193303]
	TIME [epoch: 20.9 sec]
	Saving model to: out/model_training/model_facs_dec2b_2d_v1_20240622_102153/states/model_facs_dec2b_2d_v1_436.pth
	Model improved!!!
EPOCH 437/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0931230893376311		[learning rate: 0.0017255]
	Learning Rate: 0.00172553
	LOSS [training: 0.0931230893376311 | validation: 0.1621402516242462]
	TIME [epoch: 20.9 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09284429468133945		[learning rate: 0.0017179]
	Learning Rate: 0.00171791
	LOSS [training: 0.09284429468133945 | validation: 0.1331164862664825]
	TIME [epoch: 20.9 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0867834691421541		[learning rate: 0.0017103]
	Learning Rate: 0.00171032
	LOSS [training: 0.0867834691421541 | validation: 0.1451180127797752]
	TIME [epoch: 20.8 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08900638317032654		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.08900638317032654 | validation: 0.13260950469273297]
	TIME [epoch: 20.8 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08985536636729959		[learning rate: 0.0016952]
	Learning Rate: 0.00169524
	LOSS [training: 0.08985536636729959 | validation: 0.14915761745580597]
	TIME [epoch: 20.9 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09048899460463389		[learning rate: 0.0016877]
	Learning Rate: 0.00168775
	LOSS [training: 0.09048899460463389 | validation: 0.1279711781380497]
	TIME [epoch: 20.9 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08905371477798858		[learning rate: 0.0016803]
	Learning Rate: 0.00168029
	LOSS [training: 0.08905371477798858 | validation: 0.14919541907754208]
	TIME [epoch: 20.8 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08967934508841778		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.08967934508841778 | validation: 0.12870814878621928]
	TIME [epoch: 20.9 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08873478598180509		[learning rate: 0.0016655]
	Learning Rate: 0.00166548
	LOSS [training: 0.08873478598180509 | validation: 0.171757935677064]
	TIME [epoch: 20.9 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08170767931863201		[learning rate: 0.0016581]
	Learning Rate: 0.00165812
	LOSS [training: 0.08170767931863201 | validation: 0.13337067887453857]
	TIME [epoch: 20.8 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0841605305870994		[learning rate: 0.0016508]
	Learning Rate: 0.00165079
	LOSS [training: 0.0841605305870994 | validation: 0.14626670642864037]
	TIME [epoch: 20.9 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0910812994387716		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.0910812994387716 | validation: 0.12851937258172927]
	TIME [epoch: 20.9 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07438702325779431		[learning rate: 0.0016362]
	Learning Rate: 0.00163624
	LOSS [training: 0.07438702325779431 | validation: 0.1451919504198588]
	TIME [epoch: 20.8 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0886769002793499		[learning rate: 0.001629]
	Learning Rate: 0.00162901
	LOSS [training: 0.0886769002793499 | validation: 0.13918737365331657]
	TIME [epoch: 20.9 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08294721135283378		[learning rate: 0.0016218]
	Learning Rate: 0.00162181
	LOSS [training: 0.08294721135283378 | validation: 0.14057410987379274]
	TIME [epoch: 20.9 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09329495382783358		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.09329495382783358 | validation: 0.14787314639479018]
	TIME [epoch: 20.9 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07966158861684186		[learning rate: 0.0016075]
	Learning Rate: 0.00160751
	LOSS [training: 0.07966158861684186 | validation: 0.13516675499621025]
	TIME [epoch: 20.8 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08334499670245253		[learning rate: 0.0016004]
	Learning Rate: 0.00160041
	LOSS [training: 0.08334499670245253 | validation: 0.13794088404267682]
	TIME [epoch: 20.8 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08261441558755966		[learning rate: 0.0015933]
	Learning Rate: 0.00159334
	LOSS [training: 0.08261441558755966 | validation: 0.14009543083549675]
	TIME [epoch: 20.9 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09262791603662388		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.09262791603662388 | validation: 0.1391925815312505]
	TIME [epoch: 20.8 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0792032907684379		[learning rate: 0.0015793]
	Learning Rate: 0.00157929
	LOSS [training: 0.0792032907684379 | validation: 0.14252501627843553]
	TIME [epoch: 20.9 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10113133405061321		[learning rate: 0.0015723]
	Learning Rate: 0.00157231
	LOSS [training: 0.10113133405061321 | validation: 0.134214524360448]
	TIME [epoch: 20.9 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08584824639198765		[learning rate: 0.0015654]
	Learning Rate: 0.00156536
	LOSS [training: 0.08584824639198765 | validation: 0.14316797754410385]
	TIME [epoch: 20.8 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09423657789953188		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.09423657789953188 | validation: 0.13788793931121157]
	TIME [epoch: 20.8 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0811090914312792		[learning rate: 0.0015516]
	Learning Rate: 0.00155156
	LOSS [training: 0.0811090914312792 | validation: 0.13200424621241735]
	TIME [epoch: 20.9 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08985824589215015		[learning rate: 0.0015447]
	Learning Rate: 0.00154471
	LOSS [training: 0.08985824589215015 | validation: 0.15466593519903477]
	TIME [epoch: 20.8 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08845327273273476		[learning rate: 0.0015379]
	Learning Rate: 0.00153788
	LOSS [training: 0.08845327273273476 | validation: 0.13995681381505728]
	TIME [epoch: 20.9 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09034971488255472		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.09034971488255472 | validation: 0.15912146367817853]
	TIME [epoch: 20.9 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08838251547827176		[learning rate: 0.0015243]
	Learning Rate: 0.00152432
	LOSS [training: 0.08838251547827176 | validation: 0.1339623102816197]
	TIME [epoch: 20.9 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08692643739792633		[learning rate: 0.0015176]
	Learning Rate: 0.00151759
	LOSS [training: 0.08692643739792633 | validation: 0.1386391360839435]
	TIME [epoch: 20.8 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08459211351349741		[learning rate: 0.0015109]
	Learning Rate: 0.00151088
	LOSS [training: 0.08459211351349741 | validation: 0.14475921151164103]
	TIME [epoch: 20.9 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08890756977026798		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.08890756977026798 | validation: 0.14021424639943247]
	TIME [epoch: 20.9 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09009171390327467		[learning rate: 0.0014976]
	Learning Rate: 0.00149756
	LOSS [training: 0.09009171390327467 | validation: 0.14308547398018082]
	TIME [epoch: 20.9 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08770776856655822		[learning rate: 0.0014909]
	Learning Rate: 0.00149094
	LOSS [training: 0.08770776856655822 | validation: 0.141747039371029]
	TIME [epoch: 20.9 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08109772933373843		[learning rate: 0.0014844]
	Learning Rate: 0.00148436
	LOSS [training: 0.08109772933373843 | validation: 0.13721396725107468]
	TIME [epoch: 20.9 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08633166746212409		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.08633166746212409 | validation: 0.1406361766578033]
	TIME [epoch: 20.8 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09145968578746812		[learning rate: 0.0014713]
	Learning Rate: 0.00147127
	LOSS [training: 0.09145968578746812 | validation: 0.1381962455916072]
	TIME [epoch: 20.9 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0871521783731789		[learning rate: 0.0014648]
	Learning Rate: 0.00146477
	LOSS [training: 0.0871521783731789 | validation: 0.1275558545938405]
	TIME [epoch: 20.9 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08636205000336054		[learning rate: 0.0014583]
	Learning Rate: 0.0014583
	LOSS [training: 0.08636205000336054 | validation: 0.1350448003016843]
	TIME [epoch: 20.9 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0853135286771513		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.0853135286771513 | validation: 0.13866000124768874]
	TIME [epoch: 20.8 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07840114391129785		[learning rate: 0.0014454]
	Learning Rate: 0.00144544
	LOSS [training: 0.07840114391129785 | validation: 0.15164913640968752]
	TIME [epoch: 20.9 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08273714119097661		[learning rate: 0.0014391]
	Learning Rate: 0.00143905
	LOSS [training: 0.08273714119097661 | validation: 0.13894477051317006]
	TIME [epoch: 20.9 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08123889705735336		[learning rate: 0.0014327]
	Learning Rate: 0.0014327
	LOSS [training: 0.08123889705735336 | validation: 0.15716488593310424]
	TIME [epoch: 20.8 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08700499351931948		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.08700499351931948 | validation: 0.1273789132505349]
	TIME [epoch: 20.9 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09254078383460905		[learning rate: 0.0014201]
	Learning Rate: 0.00142006
	LOSS [training: 0.09254078383460905 | validation: 0.13598777469095757]
	TIME [epoch: 20.9 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08413091847581812		[learning rate: 0.0014138]
	Learning Rate: 0.00141379
	LOSS [training: 0.08413091847581812 | validation: 0.14045983734292278]
	TIME [epoch: 20.9 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08874307879628678		[learning rate: 0.0014075]
	Learning Rate: 0.00140754
	LOSS [training: 0.08874307879628678 | validation: 0.1370898781734358]
	TIME [epoch: 20.9 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0815692148817613		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.0815692148817613 | validation: 0.1406551227211744]
	TIME [epoch: 20.9 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08702281563108258		[learning rate: 0.0013951]
	Learning Rate: 0.00139513
	LOSS [training: 0.08702281563108258 | validation: 0.14120980667022434]
	TIME [epoch: 20.9 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08695037713361128		[learning rate: 0.001389]
	Learning Rate: 0.00138897
	LOSS [training: 0.08695037713361128 | validation: 0.13299493501753934]
	TIME [epoch: 20.9 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09374488665982206		[learning rate: 0.0013828]
	Learning Rate: 0.00138283
	LOSS [training: 0.09374488665982206 | validation: 0.14895513050651363]
	TIME [epoch: 20.9 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08266796519740194		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.08266796519740194 | validation: 0.12638161366919293]
	TIME [epoch: 20.9 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08390576575760005		[learning rate: 0.0013706]
	Learning Rate: 0.00137064
	LOSS [training: 0.08390576575760005 | validation: 0.1453243871171305]
	TIME [epoch: 20.9 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08165077283392332		[learning rate: 0.0013646]
	Learning Rate: 0.00136458
	LOSS [training: 0.08165077283392332 | validation: 0.14400428030838341]
	TIME [epoch: 20.9 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09094334044370772		[learning rate: 0.0013586]
	Learning Rate: 0.00135855
	LOSS [training: 0.09094334044370772 | validation: 0.15256036216862523]
	TIME [epoch: 20.9 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08630018618865144		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.08630018618865144 | validation: 0.13992043312868946]
	TIME [epoch: 20.9 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09278063389684413		[learning rate: 0.0013466]
	Learning Rate: 0.00134658
	LOSS [training: 0.09278063389684413 | validation: 0.1409789128907281]
	TIME [epoch: 20.9 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08925828591161053		[learning rate: 0.0013406]
	Learning Rate: 0.00134063
	LOSS [training: 0.08925828591161053 | validation: 0.13937352202928627]
	TIME [epoch: 20.9 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09017802158639224		[learning rate: 0.0013347]
	Learning Rate: 0.0013347
	LOSS [training: 0.09017802158639224 | validation: 0.13539486372347692]
	TIME [epoch: 20.9 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07414208297541384		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.07414208297541384 | validation: 0.1185988753014656]
	TIME [epoch: 20.9 sec]
	Saving model to: out/model_training/model_facs_dec2b_2d_v1_20240622_102153/states/model_facs_dec2b_2d_v1_496.pth
	Model improved!!!
EPOCH 497/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08612624772544944		[learning rate: 0.0013229]
	Learning Rate: 0.00132293
	LOSS [training: 0.08612624772544944 | validation: 0.14584912701674407]
	TIME [epoch: 20.9 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.080389507825214		[learning rate: 0.0013171]
	Learning Rate: 0.00131709
	LOSS [training: 0.080389507825214 | validation: 0.1451337021727085]
	TIME [epoch: 20.9 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08754931134205342		[learning rate: 0.0013113]
	Learning Rate: 0.00131127
	LOSS [training: 0.08754931134205342 | validation: 0.13247728589844587]
	TIME [epoch: 20.9 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0859757197783857		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.0859757197783857 | validation: 0.1534584696687388]
	TIME [epoch: 20.9 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0884098227694054		[learning rate: 0.0012997]
	Learning Rate: 0.00129971
	LOSS [training: 0.0884098227694054 | validation: 0.13720348624825657]
	TIME [epoch: 20.9 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09050900888600238		[learning rate: 0.001294]
	Learning Rate: 0.00129397
	LOSS [training: 0.09050900888600238 | validation: 0.12994897993831556]
	TIME [epoch: 20.9 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09180079025738458		[learning rate: 0.0012882]
	Learning Rate: 0.00128825
	LOSS [training: 0.09180079025738458 | validation: 0.12707924596011666]
	TIME [epoch: 21 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08746696395379847		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.08746696395379847 | validation: 0.12739565919600943]
	TIME [epoch: 20.9 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08560617818625862		[learning rate: 0.0012769]
	Learning Rate: 0.00127689
	LOSS [training: 0.08560617818625862 | validation: 0.14124226805838808]
	TIME [epoch: 20.9 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09011220150588246		[learning rate: 0.0012712]
	Learning Rate: 0.00127125
	LOSS [training: 0.09011220150588246 | validation: 0.14077330917759348]
	TIME [epoch: 21 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09014114898438744		[learning rate: 0.0012656]
	Learning Rate: 0.00126563
	LOSS [training: 0.09014114898438744 | validation: 0.13982377468415078]
	TIME [epoch: 20.9 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08926370300103785		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.08926370300103785 | validation: 0.1457949860061296]
	TIME [epoch: 20.9 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08239198330116071		[learning rate: 0.0012545]
	Learning Rate: 0.00125447
	LOSS [training: 0.08239198330116071 | validation: 0.13918042717658932]
	TIME [epoch: 20.9 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08204400282031002		[learning rate: 0.0012489]
	Learning Rate: 0.00124893
	LOSS [training: 0.08204400282031002 | validation: 0.1563075657419912]
	TIME [epoch: 21 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08543767593047687		[learning rate: 0.0012434]
	Learning Rate: 0.00124341
	LOSS [training: 0.08543767593047687 | validation: 0.15027322250683467]
	TIME [epoch: 20.9 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08794141377104525		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.08794141377104525 | validation: 0.1494584061487097]
	TIME [epoch: 21 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09267860616808055		[learning rate: 0.0012324]
	Learning Rate: 0.00123245
	LOSS [training: 0.09267860616808055 | validation: 0.13942213904732376]
	TIME [epoch: 21 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08609436694427461		[learning rate: 0.001227]
	Learning Rate: 0.001227
	LOSS [training: 0.08609436694427461 | validation: 0.16651653385067214]
	TIME [epoch: 21 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09402201616111092		[learning rate: 0.0012216]
	Learning Rate: 0.00122158
	LOSS [training: 0.09402201616111092 | validation: 0.13461365037129625]
	TIME [epoch: 21 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08886972373353681		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.08886972373353681 | validation: 0.1446658658757014]
	TIME [epoch: 21 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08401144979520322		[learning rate: 0.0012108]
	Learning Rate: 0.00121081
	LOSS [training: 0.08401144979520322 | validation: 0.1385595403080324]
	TIME [epoch: 21 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0853975615136149		[learning rate: 0.0012055]
	Learning Rate: 0.00120546
	LOSS [training: 0.0853975615136149 | validation: 0.14696215788193992]
	TIME [epoch: 21 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08839306869931668		[learning rate: 0.0012001]
	Learning Rate: 0.00120014
	LOSS [training: 0.08839306869931668 | validation: 0.12781175733799505]
	TIME [epoch: 21 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0824422293713983		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.0824422293713983 | validation: 0.15637647742584707]
	TIME [epoch: 21 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08640195489939002		[learning rate: 0.0011896]
	Learning Rate: 0.00118956
	LOSS [training: 0.08640195489939002 | validation: 0.14314619426613073]
	TIME [epoch: 21 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0943523656055669		[learning rate: 0.0011843]
	Learning Rate: 0.0011843
	LOSS [training: 0.0943523656055669 | validation: 0.13652115904940068]
	TIME [epoch: 21 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.088879174528682		[learning rate: 0.0011791]
	Learning Rate: 0.00117907
	LOSS [training: 0.088879174528682 | validation: 0.1501783470947297]
	TIME [epoch: 21 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08741353702135964		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.08741353702135964 | validation: 0.13836030025085772]
	TIME [epoch: 21 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08111919316950393		[learning rate: 0.0011687]
	Learning Rate: 0.00116867
	LOSS [training: 0.08111919316950393 | validation: 0.1517669674851555]
	TIME [epoch: 21 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08509156113342922		[learning rate: 0.0011635]
	Learning Rate: 0.00116351
	LOSS [training: 0.08509156113342922 | validation: 0.1363068187666388]
	TIME [epoch: 21 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09756625567086101		[learning rate: 0.0011584]
	Learning Rate: 0.00115837
	LOSS [training: 0.09756625567086101 | validation: 0.12695156559261467]
	TIME [epoch: 21 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08967140110499164		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.08967140110499164 | validation: 0.15384660669124955]
	TIME [epoch: 21 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08549161281429632		[learning rate: 0.0011482]
	Learning Rate: 0.00114815
	LOSS [training: 0.08549161281429632 | validation: 0.1338719938048829]
	TIME [epoch: 21.1 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08424072781120488		[learning rate: 0.0011431]
	Learning Rate: 0.00114308
	LOSS [training: 0.08424072781120488 | validation: 0.1463729751285067]
	TIME [epoch: 21 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0810418721668984		[learning rate: 0.001138]
	Learning Rate: 0.00113803
	LOSS [training: 0.0810418721668984 | validation: 0.13228369120224562]
	TIME [epoch: 21 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07706944072097147		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.07706944072097147 | validation: 0.14200682497761935]
	TIME [epoch: 21 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0787523313688224		[learning rate: 0.001128]
	Learning Rate: 0.001128
	LOSS [training: 0.0787523313688224 | validation: 0.13970900955745044]
	TIME [epoch: 21.1 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08784650229867434		[learning rate: 0.001123]
	Learning Rate: 0.00112301
	LOSS [training: 0.08784650229867434 | validation: 0.1289243080712585]
	TIME [epoch: 21 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08533484362725818		[learning rate: 0.0011181]
	Learning Rate: 0.00111805
	LOSS [training: 0.08533484362725818 | validation: 0.1465740062950064]
	TIME [epoch: 21 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07670974562977302		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.07670974562977302 | validation: 0.13815818634635807]
	TIME [epoch: 21.1 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09105555408795776		[learning rate: 0.0011082]
	Learning Rate: 0.00110819
	LOSS [training: 0.09105555408795776 | validation: 0.13988185136795167]
	TIME [epoch: 21 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09062583148717226		[learning rate: 0.0011033]
	Learning Rate: 0.0011033
	LOSS [training: 0.09062583148717226 | validation: 0.14004268972619485]
	TIME [epoch: 21 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08546264525052182		[learning rate: 0.0010984]
	Learning Rate: 0.00109842
	LOSS [training: 0.08546264525052182 | validation: 0.14082547164804224]
	TIME [epoch: 21 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08733905187003684		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.08733905187003684 | validation: 0.12639104931041867]
	TIME [epoch: 21 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09032446966957686		[learning rate: 0.0010887]
	Learning Rate: 0.00108874
	LOSS [training: 0.09032446966957686 | validation: 0.14355133944029952]
	TIME [epoch: 21 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0828961159980769		[learning rate: 0.0010839]
	Learning Rate: 0.00108393
	LOSS [training: 0.0828961159980769 | validation: 0.12646599435184294]
	TIME [epoch: 21 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08845673470737377		[learning rate: 0.0010791]
	Learning Rate: 0.00107914
	LOSS [training: 0.08845673470737377 | validation: 0.13051171689407656]
	TIME [epoch: 21.1 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08785874614531611		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.08785874614531611 | validation: 0.13476792831418136]
	TIME [epoch: 21 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08951127857365827		[learning rate: 0.0010696]
	Learning Rate: 0.00106962
	LOSS [training: 0.08951127857365827 | validation: 0.13765495092468777]
	TIME [epoch: 21 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09345612120167357		[learning rate: 0.0010649]
	Learning Rate: 0.0010649
	LOSS [training: 0.09345612120167357 | validation: 0.14511701803249893]
	TIME [epoch: 21.1 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08206503494930223		[learning rate: 0.0010602]
	Learning Rate: 0.00106019
	LOSS [training: 0.08206503494930223 | validation: 0.14280390329691425]
	TIME [epoch: 21 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07923287830061533		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.07923287830061533 | validation: 0.14264368161471802]
	TIME [epoch: 21 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08286715374502202		[learning rate: 0.0010508]
	Learning Rate: 0.00105084
	LOSS [training: 0.08286715374502202 | validation: 0.14356207423510167]
	TIME [epoch: 21.1 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0847494712472751		[learning rate: 0.0010462]
	Learning Rate: 0.0010462
	LOSS [training: 0.0847494712472751 | validation: 0.14953058409680703]
	TIME [epoch: 21 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08578125924421934		[learning rate: 0.0010416]
	Learning Rate: 0.00104158
	LOSS [training: 0.08578125924421934 | validation: 0.14017427454382728]
	TIME [epoch: 21 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08783633656022424		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.08783633656022424 | validation: 0.13740418517896621]
	TIME [epoch: 21 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08251194032971951		[learning rate: 0.0010324]
	Learning Rate: 0.0010324
	LOSS [training: 0.08251194032971951 | validation: 0.1465786441595919]
	TIME [epoch: 21.1 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08592213189688225		[learning rate: 0.0010278]
	Learning Rate: 0.00102783
	LOSS [training: 0.08592213189688225 | validation: 0.1409052383033717]
	TIME [epoch: 21 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0842616353522014		[learning rate: 0.0010233]
	Learning Rate: 0.00102329
	LOSS [training: 0.0842616353522014 | validation: 0.13363145038106908]
	TIME [epoch: 21 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08217429867659891		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.08217429867659891 | validation: 0.1479911673122869]
	TIME [epoch: 21.1 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08947436145925114		[learning rate: 0.0010143]
	Learning Rate: 0.00101427
	LOSS [training: 0.08947436145925114 | validation: 0.14225083168438526]
	TIME [epoch: 21 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08726359199455344		[learning rate: 0.0010098]
	Learning Rate: 0.00100979
	LOSS [training: 0.08726359199455344 | validation: 0.13038334680477942]
	TIME [epoch: 21 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07928953070135805		[learning rate: 0.0010053]
	Learning Rate: 0.00100533
	LOSS [training: 0.07928953070135805 | validation: 0.14423031641883988]
	TIME [epoch: 21 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09072957764863668		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.09072957764863668 | validation: 0.1274066445031377]
	TIME [epoch: 21 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08518840989830703		[learning rate: 0.00099646]
	Learning Rate: 0.000996464
	LOSS [training: 0.08518840989830703 | validation: 0.13545703951651625]
	TIME [epoch: 21 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08777571669555864		[learning rate: 0.00099206]
	Learning Rate: 0.000992061
	LOSS [training: 0.08777571669555864 | validation: 0.13605437241117882]
	TIME [epoch: 21 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08318063515437957		[learning rate: 0.00098768]
	Learning Rate: 0.000987678
	LOSS [training: 0.08318063515437957 | validation: 0.14891495816423053]
	TIME [epoch: 21.1 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07424485637928194		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.07424485637928194 | validation: 0.12927886003421435]
	TIME [epoch: 21 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08198884729735603		[learning rate: 0.00097897]
	Learning Rate: 0.00097897
	LOSS [training: 0.08198884729735603 | validation: 0.1333037957328593]
	TIME [epoch: 21 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09797746816060579		[learning rate: 0.00097464]
	Learning Rate: 0.000974644
	LOSS [training: 0.09797746816060579 | validation: 0.12775022436559932]
	TIME [epoch: 21.1 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08250415862185188		[learning rate: 0.00097034]
	Learning Rate: 0.000970338
	LOSS [training: 0.08250415862185188 | validation: 0.16148131041057662]
	TIME [epoch: 21 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08499798318085525		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.08499798318085525 | validation: 0.14143292308547917]
	TIME [epoch: 21 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08445091492558976		[learning rate: 0.00096178]
	Learning Rate: 0.000961783
	LOSS [training: 0.08445091492558976 | validation: 0.13513512176716025]
	TIME [epoch: 21.1 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08489410295412123		[learning rate: 0.00095753]
	Learning Rate: 0.000957533
	LOSS [training: 0.08489410295412123 | validation: 0.14615176672163877]
	TIME [epoch: 21 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0854369785037239		[learning rate: 0.0009533]
	Learning Rate: 0.000953303
	LOSS [training: 0.0854369785037239 | validation: 0.14372901901929158]
	TIME [epoch: 21 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0785565448143434		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.0785565448143434 | validation: 0.14648334304894872]
	TIME [epoch: 21 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08630697543312604		[learning rate: 0.0009449]
	Learning Rate: 0.000944897
	LOSS [training: 0.08630697543312604 | validation: 0.13649544017291512]
	TIME [epoch: 21.1 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08534230522737454		[learning rate: 0.00094072]
	Learning Rate: 0.000940723
	LOSS [training: 0.08534230522737454 | validation: 0.14007981430953]
	TIME [epoch: 21 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08391396617990174		[learning rate: 0.00093657]
	Learning Rate: 0.000936566
	LOSS [training: 0.08391396617990174 | validation: 0.1491410468891848]
	TIME [epoch: 21 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08696194324906208		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.08696194324906208 | validation: 0.13613992514448195]
	TIME [epoch: 21.1 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07444623401503289		[learning rate: 0.00092831]
	Learning Rate: 0.000928309
	LOSS [training: 0.07444623401503289 | validation: 0.127903931114712]
	TIME [epoch: 20.8 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07990757627373599		[learning rate: 0.00092421]
	Learning Rate: 0.000924207
	LOSS [training: 0.07990757627373599 | validation: 0.13850463437742888]
	TIME [epoch: 20.8 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0897600301576545		[learning rate: 0.00092012]
	Learning Rate: 0.000920124
	LOSS [training: 0.0897600301576545 | validation: 0.1382942007270744]
	TIME [epoch: 20.8 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08138738574695101		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.08138738574695101 | validation: 0.14511825247595303]
	TIME [epoch: 21 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07952459587629018		[learning rate: 0.00091201]
	Learning Rate: 0.000912011
	LOSS [training: 0.07952459587629018 | validation: 0.15295234265025565]
	TIME [epoch: 21 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0800420513641685		[learning rate: 0.00090798]
	Learning Rate: 0.000907981
	LOSS [training: 0.0800420513641685 | validation: 0.13269813694278543]
	TIME [epoch: 20.9 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07776525601576001		[learning rate: 0.00090397]
	Learning Rate: 0.00090397
	LOSS [training: 0.07776525601576001 | validation: 0.17011107213479565]
	TIME [epoch: 21.1 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08487023722501538		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.08487023722501538 | validation: 0.1382705105572735]
	TIME [epoch: 21 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08195018996339312		[learning rate: 0.000896]
	Learning Rate: 0.000895999
	LOSS [training: 0.08195018996339312 | validation: 0.1369606830497256]
	TIME [epoch: 21 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08681688708375031		[learning rate: 0.00089204]
	Learning Rate: 0.000892041
	LOSS [training: 0.08681688708375031 | validation: 0.13148404709353984]
	TIME [epoch: 21.1 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07942065206641372		[learning rate: 0.0008881]
	Learning Rate: 0.000888099
	LOSS [training: 0.07942065206641372 | validation: 0.14824132092960066]
	TIME [epoch: 21 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08349600423446682		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.08349600423446682 | validation: 0.13612373453998425]
	TIME [epoch: 21 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07831591253153947		[learning rate: 0.00088027]
	Learning Rate: 0.000880269
	LOSS [training: 0.07831591253153947 | validation: 0.13751096974935997]
	TIME [epoch: 21 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07642275738942556		[learning rate: 0.00087638]
	Learning Rate: 0.00087638
	LOSS [training: 0.07642275738942556 | validation: 0.12701517511482502]
	TIME [epoch: 21 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08208725910072712		[learning rate: 0.00087251]
	Learning Rate: 0.000872508
	LOSS [training: 0.08208725910072712 | validation: 0.1438395477672155]
	TIME [epoch: 21 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08112689033181991		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.08112689033181991 | validation: 0.13611655344686882]
	TIME [epoch: 21 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07728320614124082		[learning rate: 0.00086481]
	Learning Rate: 0.000864815
	LOSS [training: 0.07728320614124082 | validation: 0.13419818371824419]
	TIME [epoch: 21 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08125206192854717		[learning rate: 0.00086099]
	Learning Rate: 0.000860994
	LOSS [training: 0.08125206192854717 | validation: 0.1556577622199696]
	TIME [epoch: 21 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07884429286722053		[learning rate: 0.00085719]
	Learning Rate: 0.00085719
	LOSS [training: 0.07884429286722053 | validation: 0.14797064907314134]
	TIME [epoch: 21 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08032264173855491		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.08032264173855491 | validation: 0.14106109858298688]
	TIME [epoch: 21 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07838303221680808		[learning rate: 0.00084963]
	Learning Rate: 0.000849632
	LOSS [training: 0.07838303221680808 | validation: 0.13446157175513984]
	TIME [epoch: 21 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08124388084855491		[learning rate: 0.00084588]
	Learning Rate: 0.000845878
	LOSS [training: 0.08124388084855491 | validation: 0.13921827706186515]
	TIME [epoch: 21 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08222465949668015		[learning rate: 0.00084214]
	Learning Rate: 0.000842141
	LOSS [training: 0.08222465949668015 | validation: 0.1358025033645286]
	TIME [epoch: 21 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0786562172728835		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.0786562172728835 | validation: 0.13753815520085982]
	TIME [epoch: 21 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.083661234427215		[learning rate: 0.00083472]
	Learning Rate: 0.000834715
	LOSS [training: 0.083661234427215 | validation: 0.13590669666946814]
	TIME [epoch: 21 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0857218951739049		[learning rate: 0.00083103]
	Learning Rate: 0.000831028
	LOSS [training: 0.0857218951739049 | validation: 0.12611159288566834]
	TIME [epoch: 20.9 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08318701539192344		[learning rate: 0.00082736]
	Learning Rate: 0.000827356
	LOSS [training: 0.08318701539192344 | validation: 0.13905596941621498]
	TIME [epoch: 21 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08546564429640971		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.08546564429640971 | validation: 0.13367822158877637]
	TIME [epoch: 21 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08517965237814194		[learning rate: 0.00082006]
	Learning Rate: 0.000820061
	LOSS [training: 0.08517965237814194 | validation: 0.13852696382323415]
	TIME [epoch: 20.9 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07661213175472062		[learning rate: 0.00081644]
	Learning Rate: 0.000816438
	LOSS [training: 0.07661213175472062 | validation: 0.13589776803459008]
	TIME [epoch: 21 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09252370763463034		[learning rate: 0.00081283]
	Learning Rate: 0.000812831
	LOSS [training: 0.09252370763463034 | validation: 0.14364352161580518]
	TIME [epoch: 21 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08141077260917644		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.08141077260917644 | validation: 0.13812825790254282]
	TIME [epoch: 20.9 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07958504863054654		[learning rate: 0.00080566]
	Learning Rate: 0.000805664
	LOSS [training: 0.07958504863054654 | validation: 0.13537409502109526]
	TIME [epoch: 21 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07754547678868856		[learning rate: 0.0008021]
	Learning Rate: 0.000802104
	LOSS [training: 0.07754547678868856 | validation: 0.14449898846264517]
	TIME [epoch: 21 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0818184192038298		[learning rate: 0.00079856]
	Learning Rate: 0.00079856
	LOSS [training: 0.0818184192038298 | validation: 0.14152257569895507]
	TIME [epoch: 20.9 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08535918530611118		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.08535918530611118 | validation: 0.13763305588114297]
	TIME [epoch: 21 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0847126914186839		[learning rate: 0.00079152]
	Learning Rate: 0.000791519
	LOSS [training: 0.0847126914186839 | validation: 0.13398884360936952]
	TIME [epoch: 21 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07969597665018927		[learning rate: 0.00078802]
	Learning Rate: 0.000788022
	LOSS [training: 0.07969597665018927 | validation: 0.13250567926471984]
	TIME [epoch: 20.9 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07312407138171724		[learning rate: 0.00078454]
	Learning Rate: 0.000784541
	LOSS [training: 0.07312407138171724 | validation: 0.1442853724918427]
	TIME [epoch: 21 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08923394000690796		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.08923394000690796 | validation: 0.1418063881824052]
	TIME [epoch: 21 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09223588697516902		[learning rate: 0.00077762]
	Learning Rate: 0.000777623
	LOSS [training: 0.09223588697516902 | validation: 0.15416154581778305]
	TIME [epoch: 21 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08603365126568266		[learning rate: 0.00077419]
	Learning Rate: 0.000774188
	LOSS [training: 0.08603365126568266 | validation: 0.13475542357534842]
	TIME [epoch: 21 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08215628636332277		[learning rate: 0.00077077]
	Learning Rate: 0.000770767
	LOSS [training: 0.08215628636332277 | validation: 0.12699389762670227]
	TIME [epoch: 21 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08748853342092176		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.08748853342092176 | validation: 0.144366765266105]
	TIME [epoch: 21 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0911557314377363		[learning rate: 0.00076397]
	Learning Rate: 0.000763971
	LOSS [training: 0.0911557314377363 | validation: 0.13202807950533615]
	TIME [epoch: 21 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07898285969695351		[learning rate: 0.0007606]
	Learning Rate: 0.000760596
	LOSS [training: 0.07898285969695351 | validation: 0.1327492660719093]
	TIME [epoch: 20.9 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07909495018390782		[learning rate: 0.00075724]
	Learning Rate: 0.000757235
	LOSS [training: 0.07909495018390782 | validation: 0.13376637717166218]
	TIME [epoch: 21 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0775714481851654		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.0775714481851654 | validation: 0.1393417635599191]
	TIME [epoch: 20.9 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07965571532130131		[learning rate: 0.00075056]
	Learning Rate: 0.000750559
	LOSS [training: 0.07965571532130131 | validation: 0.1314721329891265]
	TIME [epoch: 21 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08451230900790956		[learning rate: 0.00074724]
	Learning Rate: 0.000747242
	LOSS [training: 0.08451230900790956 | validation: 0.1378245488495517]
	TIME [epoch: 21 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08693988308074056		[learning rate: 0.00074394]
	Learning Rate: 0.000743941
	LOSS [training: 0.08693988308074056 | validation: 0.1422007666213192]
	TIME [epoch: 20.8 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07914216143440483		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.07914216143440483 | validation: 0.14313719531519292]
	TIME [epoch: 20.8 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0804546508521035		[learning rate: 0.00073738]
	Learning Rate: 0.000737382
	LOSS [training: 0.0804546508521035 | validation: 0.1445730445828883]
	TIME [epoch: 20.8 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07896794054318299		[learning rate: 0.00073412]
	Learning Rate: 0.000734124
	LOSS [training: 0.07896794054318299 | validation: 0.14651224207928867]
	TIME [epoch: 20.8 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0857203087346698		[learning rate: 0.00073088]
	Learning Rate: 0.00073088
	LOSS [training: 0.0857203087346698 | validation: 0.13906784877732173]
	TIME [epoch: 20.8 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08052628538157203		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 0.08052628538157203 | validation: 0.13949303264541554]
	TIME [epoch: 20.8 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07779208848046294		[learning rate: 0.00072444]
	Learning Rate: 0.000724436
	LOSS [training: 0.07779208848046294 | validation: 0.13558980191933065]
	TIME [epoch: 20.8 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08783308454043234		[learning rate: 0.00072124]
	Learning Rate: 0.000721235
	LOSS [training: 0.08783308454043234 | validation: 0.13140955236940868]
	TIME [epoch: 20.8 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08310797733348954		[learning rate: 0.00071805]
	Learning Rate: 0.000718049
	LOSS [training: 0.08310797733348954 | validation: 0.1377414421837919]
	TIME [epoch: 20.8 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07665449632051227		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.07665449632051227 | validation: 0.13624728684573115]
	TIME [epoch: 20.8 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07931470343088003		[learning rate: 0.00071172]
	Learning Rate: 0.000711718
	LOSS [training: 0.07931470343088003 | validation: 0.13766637658723155]
	TIME [epoch: 20.8 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08965904263260897		[learning rate: 0.00070857]
	Learning Rate: 0.000708573
	LOSS [training: 0.08965904263260897 | validation: 0.13439721484860667]
	TIME [epoch: 20.8 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08705022907651502		[learning rate: 0.00070544]
	Learning Rate: 0.000705442
	LOSS [training: 0.08705022907651502 | validation: 0.12958122927681098]
	TIME [epoch: 20.8 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07781148465287412		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.07781148465287412 | validation: 0.1370094210331873]
	TIME [epoch: 20.8 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08413444322808102		[learning rate: 0.00069922]
	Learning Rate: 0.000699222
	LOSS [training: 0.08413444322808102 | validation: 0.12485917450124145]
	TIME [epoch: 20.8 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08177724910483763		[learning rate: 0.00069613]
	Learning Rate: 0.000696133
	LOSS [training: 0.08177724910483763 | validation: 0.13797116176001664]
	TIME [epoch: 20.8 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08195568970801145		[learning rate: 0.00069306]
	Learning Rate: 0.000693058
	LOSS [training: 0.08195568970801145 | validation: 0.14442491881373556]
	TIME [epoch: 20.8 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08062787791992634		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 0.08062787791992634 | validation: 0.13581735524904284]
	TIME [epoch: 20.8 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07742064515611716		[learning rate: 0.00068695]
	Learning Rate: 0.000686947
	LOSS [training: 0.07742064515611716 | validation: 0.1394238778945723]
	TIME [epoch: 20.8 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08176739901891186		[learning rate: 0.00068391]
	Learning Rate: 0.000683912
	LOSS [training: 0.08176739901891186 | validation: 0.1487075679390325]
	TIME [epoch: 20.8 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07912654868129068		[learning rate: 0.00068089]
	Learning Rate: 0.00068089
	LOSS [training: 0.07912654868129068 | validation: 0.13994037243969595]
	TIME [epoch: 20.8 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08360365746447158		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 0.08360365746447158 | validation: 0.13876714011158142]
	TIME [epoch: 20.8 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07909767685007435		[learning rate: 0.00067489]
	Learning Rate: 0.000674887
	LOSS [training: 0.07909767685007435 | validation: 0.1279495213116401]
	TIME [epoch: 20.8 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08098215780268617		[learning rate: 0.0006719]
	Learning Rate: 0.000671905
	LOSS [training: 0.08098215780268617 | validation: 0.1401626908343217]
	TIME [epoch: 20.8 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08580937822881116		[learning rate: 0.00066894]
	Learning Rate: 0.000668936
	LOSS [training: 0.08580937822881116 | validation: 0.13608955151517613]
	TIME [epoch: 20.8 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08356935275942624		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 0.08356935275942624 | validation: 0.1428601493843063]
	TIME [epoch: 20.8 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07652712889336047		[learning rate: 0.00066304]
	Learning Rate: 0.000663038
	LOSS [training: 0.07652712889336047 | validation: 0.13352150908835225]
	TIME [epoch: 20.8 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08793416778763734		[learning rate: 0.00066011]
	Learning Rate: 0.000660109
	LOSS [training: 0.08793416778763734 | validation: 0.1393144549781326]
	TIME [epoch: 20.8 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08782897418756878		[learning rate: 0.00065719]
	Learning Rate: 0.000657192
	LOSS [training: 0.08782897418756878 | validation: 0.1494020985976879]
	TIME [epoch: 20.8 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09192282676771624		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 0.09192282676771624 | validation: 0.13868111031471744]
	TIME [epoch: 20.8 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08154805698314435		[learning rate: 0.0006514]
	Learning Rate: 0.000651398
	LOSS [training: 0.08154805698314435 | validation: 0.1440800668470225]
	TIME [epoch: 20.8 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08360463612047918		[learning rate: 0.00064852]
	Learning Rate: 0.00064852
	LOSS [training: 0.08360463612047918 | validation: 0.13770270732025813]
	TIME [epoch: 20.8 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07823437204895015		[learning rate: 0.00064565]
	Learning Rate: 0.000645654
	LOSS [training: 0.07823437204895015 | validation: 0.1369096800022865]
	TIME [epoch: 20.8 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0790414992714765		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 0.0790414992714765 | validation: 0.13047743924291683]
	TIME [epoch: 20.8 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07546118915693034		[learning rate: 0.00063996]
	Learning Rate: 0.000639962
	LOSS [training: 0.07546118915693034 | validation: 0.14486211807871974]
	TIME [epoch: 20.8 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08706324248551514		[learning rate: 0.00063713]
	Learning Rate: 0.000637134
	LOSS [training: 0.08706324248551514 | validation: 0.13564814508770562]
	TIME [epoch: 20.8 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08147489951144184		[learning rate: 0.00063432]
	Learning Rate: 0.000634319
	LOSS [training: 0.08147489951144184 | validation: 0.13326133730532186]
	TIME [epoch: 20.8 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08462273076822474		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 0.08462273076822474 | validation: 0.145479295114739]
	TIME [epoch: 20.8 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08142766869280232		[learning rate: 0.00062873]
	Learning Rate: 0.000628726
	LOSS [training: 0.08142766869280232 | validation: 0.13702674431386339]
	TIME [epoch: 20.8 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07942804630455495		[learning rate: 0.00062595]
	Learning Rate: 0.000625948
	LOSS [training: 0.07942804630455495 | validation: 0.13900779558874396]
	TIME [epoch: 20.8 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08070726060930519		[learning rate: 0.00062318]
	Learning Rate: 0.000623183
	LOSS [training: 0.08070726060930519 | validation: 0.1362580262936464]
	TIME [epoch: 20.8 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08103313264402905		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 0.08103313264402905 | validation: 0.14292041399860736]
	TIME [epoch: 20.8 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08307604783507201		[learning rate: 0.00061769]
	Learning Rate: 0.000617688
	LOSS [training: 0.08307604783507201 | validation: 0.1321264033333739]
	TIME [epoch: 20.8 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07881521101324492		[learning rate: 0.00061496]
	Learning Rate: 0.000614959
	LOSS [training: 0.07881521101324492 | validation: 0.15309863408649582]
	TIME [epoch: 20.8 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0770327376851896		[learning rate: 0.00061224]
	Learning Rate: 0.000612242
	LOSS [training: 0.0770327376851896 | validation: 0.14544337385510692]
	TIME [epoch: 20.8 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07930110414567278		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 0.07930110414567278 | validation: 0.14522896817777523]
	TIME [epoch: 20.8 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08664707528839967		[learning rate: 0.00060684]
	Learning Rate: 0.000606844
	LOSS [training: 0.08664707528839967 | validation: 0.13559781381238015]
	TIME [epoch: 20.8 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08847143045218529		[learning rate: 0.00060416]
	Learning Rate: 0.000604163
	LOSS [training: 0.08847143045218529 | validation: 0.13506769663689247]
	TIME [epoch: 20.8 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08518492746087838		[learning rate: 0.00060149]
	Learning Rate: 0.000601493
	LOSS [training: 0.08518492746087838 | validation: 0.14057951632162483]
	TIME [epoch: 20.8 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08588226525231837		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.08588226525231837 | validation: 0.13851717059873103]
	TIME [epoch: 20.8 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08204827601873865		[learning rate: 0.00059619]
	Learning Rate: 0.00059619
	LOSS [training: 0.08204827601873865 | validation: 0.1452616706350666]
	TIME [epoch: 20.8 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07886036248487019		[learning rate: 0.00059356]
	Learning Rate: 0.000593556
	LOSS [training: 0.07886036248487019 | validation: 0.13037310599237759]
	TIME [epoch: 20.9 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07296931147874824		[learning rate: 0.00059093]
	Learning Rate: 0.000590933
	LOSS [training: 0.07296931147874824 | validation: 0.14278217270640783]
	TIME [epoch: 20.8 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08455071074246413		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 0.08455071074246413 | validation: 0.13834555520006608]
	TIME [epoch: 20.8 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08396601308210803		[learning rate: 0.00058572]
	Learning Rate: 0.000585723
	LOSS [training: 0.08396601308210803 | validation: 0.13965136771259196]
	TIME [epoch: 20.8 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08911729093170201		[learning rate: 0.00058314]
	Learning Rate: 0.000583135
	LOSS [training: 0.08911729093170201 | validation: 0.13328113753423068]
	TIME [epoch: 20.8 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08347182461353653		[learning rate: 0.00058056]
	Learning Rate: 0.000580559
	LOSS [training: 0.08347182461353653 | validation: 0.13412042961704737]
	TIME [epoch: 20.9 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08092292040590447		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 0.08092292040590447 | validation: 0.1493495552700067]
	TIME [epoch: 20.8 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0810464989115215		[learning rate: 0.00057544]
	Learning Rate: 0.00057544
	LOSS [training: 0.0810464989115215 | validation: 0.153671843527593]
	TIME [epoch: 20.8 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08566997215776676		[learning rate: 0.0005729]
	Learning Rate: 0.000572898
	LOSS [training: 0.08566997215776676 | validation: 0.13490995758683558]
	TIME [epoch: 20.8 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08798277831749181		[learning rate: 0.00057037]
	Learning Rate: 0.000570366
	LOSS [training: 0.08798277831749181 | validation: 0.13837923984868158]
	TIME [epoch: 20.8 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08881603225760051		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 0.08881603225760051 | validation: 0.13818356732467313]
	TIME [epoch: 20.8 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09105317302884311		[learning rate: 0.00056534]
	Learning Rate: 0.000565337
	LOSS [training: 0.09105317302884311 | validation: 0.13617216062100337]
	TIME [epoch: 20.8 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08271511787396582		[learning rate: 0.00056284]
	Learning Rate: 0.00056284
	LOSS [training: 0.08271511787396582 | validation: 0.13146617868796304]
	TIME [epoch: 20.8 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08816847268169199		[learning rate: 0.00056035]
	Learning Rate: 0.000560353
	LOSS [training: 0.08816847268169199 | validation: 0.1476789132076311]
	TIME [epoch: 20.8 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0811791531355948		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 0.0811791531355948 | validation: 0.13107266895974615]
	TIME [epoch: 20.8 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07612404394323884		[learning rate: 0.00055541]
	Learning Rate: 0.000555412
	LOSS [training: 0.07612404394323884 | validation: 0.1443518826049286]
	TIME [epoch: 20.8 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08366325211160458		[learning rate: 0.00055296]
	Learning Rate: 0.000552958
	LOSS [training: 0.08366325211160458 | validation: 0.13227376672558463]
	TIME [epoch: 20.8 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.086632401699545		[learning rate: 0.00055052]
	Learning Rate: 0.000550515
	LOSS [training: 0.086632401699545 | validation: 0.13269059182702553]
	TIME [epoch: 20.8 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08533651802811533		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 0.08533651802811533 | validation: 0.131769541144505]
	TIME [epoch: 20.8 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07755757247527942		[learning rate: 0.00054566]
	Learning Rate: 0.000545661
	LOSS [training: 0.07755757247527942 | validation: 0.1276785706800686]
	TIME [epoch: 20.8 sec]
	Saving model to: out/model_training/model_facs_dec2b_2d_v1_20240622_102153/states/model_facs_dec2b_2d_v1_697.pth
Halted early. No improvement in validation loss for 200 epochs.
Finished training in 14648.398 seconds.
