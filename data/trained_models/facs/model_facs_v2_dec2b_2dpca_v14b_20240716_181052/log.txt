Args:
Namespace(name='model_facs_v2_dec2b_2dpca_v14b', outdir='out/model_training/model_facs_v2_dec2b_2dpca_v14b', training_data='data/training_data/facs_v2/pca/dec2_fitonsubset/transition2_subset_ce_pn_m_pc12/training', validation_data='data/training_data/facs_v2/pca/dec2_fitonsubset/transition2_subset_ce_pn_m_pc12/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=10, batch_size=50, patience=200, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, quadratic_a=1.0, quadratic_b=1.0, ndims=2, nparams=2, nsigs=2, ncells=200, ncells_sample=200, model_do_sample=False, dt=0.005, dt_schedule='stepped', dt_schedule_bounds=[50, 100, 200, 300], dt_schedule_scales=[0.5, 0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', kernel='multiscale', bw_range=[0.2, 0.5, 0.9, 1.1, 1.3, 1.5, 2.0], optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 2347605774

Training model...

Saving initial model state to: out/model_training/model_facs_v2_dec2b_2dpca_v14b_20240716_181052/states/model_facs_v2_dec2b_2dpca_v14b_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9456130874735716		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9456130874735716 | validation: 1.0046585953629479]
	TIME [epoch: 31.6 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v14b_20240716_181052/states/model_facs_v2_dec2b_2dpca_v14b_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.737086100670949		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.737086100670949 | validation: 0.9263932227092694]
	TIME [epoch: 4.71 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v14b_20240716_181052/states/model_facs_v2_dec2b_2dpca_v14b_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6317543284158654		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6317543284158654 | validation: 0.7979864495562271]
	TIME [epoch: 4.68 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v14b_20240716_181052/states/model_facs_v2_dec2b_2dpca_v14b_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6369612817633588		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6369612817633588 | validation: 0.7834760269801636]
	TIME [epoch: 4.68 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v14b_20240716_181052/states/model_facs_v2_dec2b_2dpca_v14b_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5854473561526378		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5854473561526378 | validation: 0.7803846412268965]
	TIME [epoch: 4.7 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v14b_20240716_181052/states/model_facs_v2_dec2b_2dpca_v14b_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5584346194851367		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5584346194851367 | validation: 0.6587984573340183]
	TIME [epoch: 4.68 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v14b_20240716_181052/states/model_facs_v2_dec2b_2dpca_v14b_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5725567729813819		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5725567729813819 | validation: 0.9824405088525676]
	TIME [epoch: 4.69 sec]
EPOCH 8/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5223993665318083		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5223993665318083 | validation: 0.5914137978796977]
	TIME [epoch: 4.68 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v14b_20240716_181052/states/model_facs_v2_dec2b_2dpca_v14b_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.375447858675934		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.375447858675934 | validation: 0.6291017932107941]
	TIME [epoch: 4.68 sec]
EPOCH 10/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40264924081463116		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.40264924081463116 | validation: 0.5749839591251644]
	TIME [epoch: 4.67 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v14b_20240716_181052/states/model_facs_v2_dec2b_2dpca_v14b_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3488437858253491		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3488437858253491 | validation: 0.6015762518151401]
	TIME [epoch: 4.68 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3848054758618951		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3848054758618951 | validation: 0.7809286204308915]
	TIME [epoch: 4.68 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39402205847106725		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.39402205847106725 | validation: 0.5354586143580576]
	TIME [epoch: 4.69 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v14b_20240716_181052/states/model_facs_v2_dec2b_2dpca_v14b_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32905583186160997		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.32905583186160997 | validation: 0.5604254438648465]
	TIME [epoch: 4.69 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3305112115670702		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3305112115670702 | validation: 0.5734071219387419]
	TIME [epoch: 4.68 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36079286356078394		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.36079286356078394 | validation: 0.5822537798293438]
	TIME [epoch: 4.68 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33413216188821243		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.33413216188821243 | validation: 0.5148304011982017]
	TIME [epoch: 4.68 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v14b_20240716_181052/states/model_facs_v2_dec2b_2dpca_v14b_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35736013410545775		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.35736013410545775 | validation: 0.5287192390365094]
	TIME [epoch: 4.68 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3146068880812889		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3146068880812889 | validation: 0.5173186258101972]
	TIME [epoch: 4.68 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30022261635011926		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.30022261635011926 | validation: 0.4889038701292964]
	TIME [epoch: 4.69 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v14b_20240716_181052/states/model_facs_v2_dec2b_2dpca_v14b_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36965833027645867		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.36965833027645867 | validation: 0.5600097665224509]
	TIME [epoch: 4.69 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29616745470790223		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.29616745470790223 | validation: 0.5086155832646444]
	TIME [epoch: 4.68 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33881781005739076		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.33881781005739076 | validation: 0.4777591230492334]
	TIME [epoch: 4.68 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v14b_20240716_181052/states/model_facs_v2_dec2b_2dpca_v14b_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30131901942703354		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.30131901942703354 | validation: 0.481297607820925]
	TIME [epoch: 4.69 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30803737546432863		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.30803737546432863 | validation: 0.5106306096181692]
	TIME [epoch: 4.68 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28794077890772474		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.28794077890772474 | validation: 0.5026586272529532]
	TIME [epoch: 4.69 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3044361735006193		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3044361735006193 | validation: 0.4901866162921322]
	TIME [epoch: 4.69 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2925220365940728		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2925220365940728 | validation: 0.4702021209674169]
	TIME [epoch: 4.68 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v14b_20240716_181052/states/model_facs_v2_dec2b_2dpca_v14b_28.pth
	Model improved!!!
EPOCH 29/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3237499122618758		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3237499122618758 | validation: 0.6011008340534036]
	TIME [epoch: 4.68 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3252219820725343		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3252219820725343 | validation: 0.4797682418067361]
	TIME [epoch: 4.68 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2995053544751317		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2995053544751317 | validation: 0.4474436286286646]
	TIME [epoch: 4.68 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v14b_20240716_181052/states/model_facs_v2_dec2b_2dpca_v14b_31.pth
	Model improved!!!
EPOCH 32/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2941734504859832		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2941734504859832 | validation: 0.4734062995909246]
	TIME [epoch: 4.68 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2968426317208136		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2968426317208136 | validation: 0.4764347261075986]
	TIME [epoch: 4.69 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2744793308166111		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2744793308166111 | validation: 0.43605635841966534]
	TIME [epoch: 4.68 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v14b_20240716_181052/states/model_facs_v2_dec2b_2dpca_v14b_34.pth
	Model improved!!!
EPOCH 35/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3084751750348448		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3084751750348448 | validation: 0.5868831801554946]
	TIME [epoch: 4.68 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28462509364065064		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.28462509364065064 | validation: 0.440638641079727]
	TIME [epoch: 4.68 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2893410092142377		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2893410092142377 | validation: 0.42327941147771936]
	TIME [epoch: 4.68 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v14b_20240716_181052/states/model_facs_v2_dec2b_2dpca_v14b_37.pth
	Model improved!!!
EPOCH 38/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2703597386170633		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2703597386170633 | validation: 0.46865499791872417]
	TIME [epoch: 4.68 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30766519896425265		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.30766519896425265 | validation: 0.4532914200268017]
	TIME [epoch: 4.68 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2576433155445509		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2576433155445509 | validation: 0.4849248912317239]
	TIME [epoch: 4.69 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2830710126021972		[learning rate: 0.0099646]
	Learning Rate: 0.00996464
	LOSS [training: 0.2830710126021972 | validation: 0.4507640023747752]
	TIME [epoch: 4.69 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28573695578278036		[learning rate: 0.0099206]
	Learning Rate: 0.00992061
	LOSS [training: 0.28573695578278036 | validation: 0.4565463711070342]
	TIME [epoch: 4.68 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25715487467565284		[learning rate: 0.0098768]
	Learning Rate: 0.00987678
	LOSS [training: 0.25715487467565284 | validation: 0.4347272698986812]
	TIME [epoch: 4.68 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26886657591678437		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 0.26886657591678437 | validation: 0.46806127647134066]
	TIME [epoch: 4.68 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2920576912679345		[learning rate: 0.0097897]
	Learning Rate: 0.0097897
	LOSS [training: 0.2920576912679345 | validation: 0.4387969453628322]
	TIME [epoch: 4.68 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23791416782619185		[learning rate: 0.0097464]
	Learning Rate: 0.00974644
	LOSS [training: 0.23791416782619185 | validation: 0.38342429977145515]
	TIME [epoch: 4.68 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v14b_20240716_181052/states/model_facs_v2_dec2b_2dpca_v14b_46.pth
	Model improved!!!
EPOCH 47/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2517063744459202		[learning rate: 0.0097034]
	Learning Rate: 0.00970338
	LOSS [training: 0.2517063744459202 | validation: 0.42674266420495044]
	TIME [epoch: 4.69 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2421663590955046		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 0.2421663590955046 | validation: 0.47821814559567893]
	TIME [epoch: 4.69 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.279295473149041		[learning rate: 0.0096178]
	Learning Rate: 0.00961783
	LOSS [training: 0.279295473149041 | validation: 0.39720272962991754]
	TIME [epoch: 4.68 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24589105293740987		[learning rate: 0.0095753]
	Learning Rate: 0.00957533
	LOSS [training: 0.24589105293740987 | validation: 0.40304439722784424]
	TIME [epoch: 4.68 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29458319626421703		[learning rate: 0.009533]
	Learning Rate: 0.00953303
	LOSS [training: 0.29458319626421703 | validation: 0.593493596206241]
	TIME [epoch: 33.9 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25457066247241605		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 0.25457066247241605 | validation: 0.409254232787299]
	TIME [epoch: 9.02 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2572107133793799		[learning rate: 0.009449]
	Learning Rate: 0.00944897
	LOSS [training: 0.2572107133793799 | validation: 0.360270886954083]
	TIME [epoch: 9 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v14b_20240716_181052/states/model_facs_v2_dec2b_2dpca_v14b_53.pth
	Model improved!!!
EPOCH 54/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25826008718764815		[learning rate: 0.0094072]
	Learning Rate: 0.00940722
	LOSS [training: 0.25826008718764815 | validation: 0.3616152655222809]
	TIME [epoch: 9 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22645895403247676		[learning rate: 0.0093657]
	Learning Rate: 0.00936566
	LOSS [training: 0.22645895403247676 | validation: 0.37053107119820633]
	TIME [epoch: 9.01 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22231524959977916		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 0.22231524959977916 | validation: 0.3989781878920554]
	TIME [epoch: 9 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22039516104315462		[learning rate: 0.0092831]
	Learning Rate: 0.00928308
	LOSS [training: 0.22039516104315462 | validation: 0.5084394724463881]
	TIME [epoch: 9 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2777150840366566		[learning rate: 0.0092421]
	Learning Rate: 0.00924207
	LOSS [training: 0.2777150840366566 | validation: 0.4043649919913933]
	TIME [epoch: 9 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22599537267619846		[learning rate: 0.0092012]
	Learning Rate: 0.00920124
	LOSS [training: 0.22599537267619846 | validation: 0.3576027491784609]
	TIME [epoch: 9.01 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v14b_20240716_181052/states/model_facs_v2_dec2b_2dpca_v14b_59.pth
	Model improved!!!
EPOCH 60/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24992427108014112		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 0.24992427108014112 | validation: 0.36573547750730984]
	TIME [epoch: 9 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22244815749117958		[learning rate: 0.0091201]
	Learning Rate: 0.00912011
	LOSS [training: 0.22244815749117958 | validation: 0.3540451564449319]
	TIME [epoch: 9 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v14b_20240716_181052/states/model_facs_v2_dec2b_2dpca_v14b_61.pth
	Model improved!!!
EPOCH 62/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20345565868943724		[learning rate: 0.0090798]
	Learning Rate: 0.00907981
	LOSS [training: 0.20345565868943724 | validation: 0.3812976486359691]
	TIME [epoch: 9.01 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2746919501408875		[learning rate: 0.0090397]
	Learning Rate: 0.0090397
	LOSS [training: 0.2746919501408875 | validation: 0.4372854980765727]
	TIME [epoch: 9.02 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22219197428243204		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 0.22219197428243204 | validation: 0.4109731565038849]
	TIME [epoch: 9 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22205519217671985		[learning rate: 0.00896]
	Learning Rate: 0.00895999
	LOSS [training: 0.22205519217671985 | validation: 0.3737427234649424]
	TIME [epoch: 9 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23515587130870444		[learning rate: 0.0089204]
	Learning Rate: 0.00892041
	LOSS [training: 0.23515587130870444 | validation: 0.590135302349378]
	TIME [epoch: 9 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2634412554083158		[learning rate: 0.008881]
	Learning Rate: 0.00888099
	LOSS [training: 0.2634412554083158 | validation: 0.3716105591557244]
	TIME [epoch: 9.01 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21744759288341045		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 0.21744759288341045 | validation: 0.3609095348225134]
	TIME [epoch: 9.03 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23475201406973953		[learning rate: 0.0088027]
	Learning Rate: 0.00880269
	LOSS [training: 0.23475201406973953 | validation: 0.5596370534218658]
	TIME [epoch: 9 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2561253881826419		[learning rate: 0.0087638]
	Learning Rate: 0.0087638
	LOSS [training: 0.2561253881826419 | validation: 0.5116746006308532]
	TIME [epoch: 9 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2309669964493657		[learning rate: 0.0087251]
	Learning Rate: 0.00872508
	LOSS [training: 0.2309669964493657 | validation: 0.3915515676987573]
	TIME [epoch: 9.01 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2635682980567706		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 0.2635682980567706 | validation: 0.415475826305436]
	TIME [epoch: 9 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2254297172225462		[learning rate: 0.0086481]
	Learning Rate: 0.00864815
	LOSS [training: 0.2254297172225462 | validation: 0.4145997695613043]
	TIME [epoch: 9 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22075198276445387		[learning rate: 0.0086099]
	Learning Rate: 0.00860994
	LOSS [training: 0.22075198276445387 | validation: 0.331881344202019]
	TIME [epoch: 9 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v14b_20240716_181052/states/model_facs_v2_dec2b_2dpca_v14b_74.pth
	Model improved!!!
EPOCH 75/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21247302669263898		[learning rate: 0.0085719]
	Learning Rate: 0.0085719
	LOSS [training: 0.21247302669263898 | validation: 0.4236343202433873]
	TIME [epoch: 9 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24209655692338203		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 0.24209655692338203 | validation: 0.38697396730307165]
	TIME [epoch: 8.99 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2377098248693577		[learning rate: 0.0084963]
	Learning Rate: 0.00849632
	LOSS [training: 0.2377098248693577 | validation: 0.4517927394361038]
	TIME [epoch: 8.99 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24407859118888497		[learning rate: 0.0084588]
	Learning Rate: 0.00845878
	LOSS [training: 0.24407859118888497 | validation: 0.41749508339039576]
	TIME [epoch: 8.99 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2195208299144082		[learning rate: 0.0084214]
	Learning Rate: 0.00842141
	LOSS [training: 0.2195208299144082 | validation: 0.3935956725508778]
	TIME [epoch: 9 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20427662225918858		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 0.20427662225918858 | validation: 0.373384867442313]
	TIME [epoch: 8.99 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19905129338955388		[learning rate: 0.0083472]
	Learning Rate: 0.00834715
	LOSS [training: 0.19905129338955388 | validation: 0.32123108265853895]
	TIME [epoch: 8.99 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v14b_20240716_181052/states/model_facs_v2_dec2b_2dpca_v14b_81.pth
	Model improved!!!
EPOCH 82/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18684165548254827		[learning rate: 0.0083103]
	Learning Rate: 0.00831027
	LOSS [training: 0.18684165548254827 | validation: 0.3676661528950411]
	TIME [epoch: 9 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22838386334847272		[learning rate: 0.0082736]
	Learning Rate: 0.00827356
	LOSS [training: 0.22838386334847272 | validation: 0.456192224566814]
	TIME [epoch: 9.01 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24478529176180533		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 0.24478529176180533 | validation: 0.3438860185773624]
	TIME [epoch: 8.99 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22099918388978565		[learning rate: 0.0082006]
	Learning Rate: 0.00820061
	LOSS [training: 0.22099918388978565 | validation: 0.3289772819926258]
	TIME [epoch: 8.99 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21717983343327885		[learning rate: 0.0081644]
	Learning Rate: 0.00816438
	LOSS [training: 0.21717983343327885 | validation: 0.40604496234840326]
	TIME [epoch: 9 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20738784671342492		[learning rate: 0.0081283]
	Learning Rate: 0.0081283
	LOSS [training: 0.20738784671342492 | validation: 0.32955281719241813]
	TIME [epoch: 9.01 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23517709295146552		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 0.23517709295146552 | validation: 0.39248110237903594]
	TIME [epoch: 8.99 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20482771965781463		[learning rate: 0.0080566]
	Learning Rate: 0.00805664
	LOSS [training: 0.20482771965781463 | validation: 0.3518447989961247]
	TIME [epoch: 9 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21079172734030713		[learning rate: 0.008021]
	Learning Rate: 0.00802104
	LOSS [training: 0.21079172734030713 | validation: 0.34928954035697773]
	TIME [epoch: 8.99 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20230122707738235		[learning rate: 0.0079856]
	Learning Rate: 0.0079856
	LOSS [training: 0.20230122707738235 | validation: 0.458566309381794]
	TIME [epoch: 9.01 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2158503435797939		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 0.2158503435797939 | validation: 0.34980951572520835]
	TIME [epoch: 9 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18569123202117352		[learning rate: 0.0079152]
	Learning Rate: 0.00791519
	LOSS [training: 0.18569123202117352 | validation: 0.3582938146832882]
	TIME [epoch: 9 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19762971024685538		[learning rate: 0.0078802]
	Learning Rate: 0.00788022
	LOSS [training: 0.19762971024685538 | validation: 0.34023053481206106]
	TIME [epoch: 9 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2058187370396683		[learning rate: 0.0078454]
	Learning Rate: 0.00784541
	LOSS [training: 0.2058187370396683 | validation: 0.38392394091292714]
	TIME [epoch: 9.01 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2318980164026076		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 0.2318980164026076 | validation: 0.39666739826225583]
	TIME [epoch: 9 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22313081812440833		[learning rate: 0.0077762]
	Learning Rate: 0.00777623
	LOSS [training: 0.22313081812440833 | validation: 0.3672960244317184]
	TIME [epoch: 8.99 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18532670849579402		[learning rate: 0.0077419]
	Learning Rate: 0.00774188
	LOSS [training: 0.18532670849579402 | validation: 0.32018600789551943]
	TIME [epoch: 9 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v14b_20240716_181052/states/model_facs_v2_dec2b_2dpca_v14b_98.pth
	Model improved!!!
EPOCH 99/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20765012435900748		[learning rate: 0.0077077]
	Learning Rate: 0.00770767
	LOSS [training: 0.20765012435900748 | validation: 0.40210535532367553]
	TIME [epoch: 9.01 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2209198059674368		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 0.2209198059674368 | validation: 0.3550686137728814]
	TIME [epoch: 8.99 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21242630309194258		[learning rate: 0.0076397]
	Learning Rate: 0.00763971
	LOSS [training: 0.21242630309194258 | validation: 0.4405304879695422]
	TIME [epoch: 44.4 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2206012281966538		[learning rate: 0.007606]
	Learning Rate: 0.00760596
	LOSS [training: 0.2206012281966538 | validation: 0.3647691027316725]
	TIME [epoch: 19.6 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19114569855098323		[learning rate: 0.0075724]
	Learning Rate: 0.00757235
	LOSS [training: 0.19114569855098323 | validation: 0.3219020719855712]
	TIME [epoch: 19.5 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20210676977465525		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 0.20210676977465525 | validation: 0.3884764961354878]
	TIME [epoch: 19.5 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2215675730539699		[learning rate: 0.0075056]
	Learning Rate: 0.00750559
	LOSS [training: 0.2215675730539699 | validation: 0.3826314127182163]
	TIME [epoch: 19.5 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20747889394059754		[learning rate: 0.0074724]
	Learning Rate: 0.00747242
	LOSS [training: 0.20747889394059754 | validation: 0.3734429178500895]
	TIME [epoch: 19.5 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20086758162068605		[learning rate: 0.0074394]
	Learning Rate: 0.00743941
	LOSS [training: 0.20086758162068605 | validation: 0.3234501982939349]
	TIME [epoch: 19.5 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1883392905161992		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 0.1883392905161992 | validation: 0.35937072077081156]
	TIME [epoch: 19.6 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19601333651540878		[learning rate: 0.0073738]
	Learning Rate: 0.00737382
	LOSS [training: 0.19601333651540878 | validation: 0.3771939403241555]
	TIME [epoch: 19.5 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1923595946782098		[learning rate: 0.0073412]
	Learning Rate: 0.00734124
	LOSS [training: 0.1923595946782098 | validation: 0.3176119173601212]
	TIME [epoch: 19.5 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v14b_20240716_181052/states/model_facs_v2_dec2b_2dpca_v14b_110.pth
	Model improved!!!
EPOCH 111/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18468154345238927		[learning rate: 0.0073088]
	Learning Rate: 0.0073088
	LOSS [training: 0.18468154345238927 | validation: 0.30878885458064026]
	TIME [epoch: 19.5 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v14b_20240716_181052/states/model_facs_v2_dec2b_2dpca_v14b_111.pth
	Model improved!!!
EPOCH 112/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1903831484334738		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 0.1903831484334738 | validation: 0.37936909378053413]
	TIME [epoch: 19.5 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2110407937590563		[learning rate: 0.0072444]
	Learning Rate: 0.00724436
	LOSS [training: 0.2110407937590563 | validation: 0.34958285671728606]
	TIME [epoch: 19.5 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19077762446878824		[learning rate: 0.0072124]
	Learning Rate: 0.00721235
	LOSS [training: 0.19077762446878824 | validation: 0.3194510856032372]
	TIME [epoch: 19.5 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2083714659947174		[learning rate: 0.0071805]
	Learning Rate: 0.00718049
	LOSS [training: 0.2083714659947174 | validation: 0.33645851138772304]
	TIME [epoch: 19.5 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19002711529151345		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 0.19002711529151345 | validation: 0.3481453174419919]
	TIME [epoch: 19.5 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19171498162221573		[learning rate: 0.0071172]
	Learning Rate: 0.00711718
	LOSS [training: 0.19171498162221573 | validation: 0.40013152929943097]
	TIME [epoch: 19.5 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18324747516779263		[learning rate: 0.0070857]
	Learning Rate: 0.00708573
	LOSS [training: 0.18324747516779263 | validation: 0.34069934941968566]
	TIME [epoch: 19.5 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2021214210303869		[learning rate: 0.0070544]
	Learning Rate: 0.00705442
	LOSS [training: 0.2021214210303869 | validation: 0.3547589589162291]
	TIME [epoch: 19.5 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18058245461080488		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 0.18058245461080488 | validation: 0.34088062660545526]
	TIME [epoch: 19.5 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19798588815835325		[learning rate: 0.0069922]
	Learning Rate: 0.00699222
	LOSS [training: 0.19798588815835325 | validation: 0.30267769300768965]
	TIME [epoch: 19.5 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v14b_20240716_181052/states/model_facs_v2_dec2b_2dpca_v14b_121.pth
	Model improved!!!
EPOCH 122/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19340060731288808		[learning rate: 0.0069613]
	Learning Rate: 0.00696133
	LOSS [training: 0.19340060731288808 | validation: 0.34184477702360294]
	TIME [epoch: 19.5 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1853124711481154		[learning rate: 0.0069306]
	Learning Rate: 0.00693057
	LOSS [training: 0.1853124711481154 | validation: 0.4167389911911944]
	TIME [epoch: 19.5 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22263935213058192		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 0.22263935213058192 | validation: 0.4889238128826781]
	TIME [epoch: 19.5 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20359068591096205		[learning rate: 0.0068695]
	Learning Rate: 0.00686947
	LOSS [training: 0.20359068591096205 | validation: 0.35087787589822583]
	TIME [epoch: 19.5 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19076840423820535		[learning rate: 0.0068391]
	Learning Rate: 0.00683912
	LOSS [training: 0.19076840423820535 | validation: 0.32810208037077115]
	TIME [epoch: 19.5 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.189306949086889		[learning rate: 0.0068089]
	Learning Rate: 0.0068089
	LOSS [training: 0.189306949086889 | validation: 0.31451852793031354]
	TIME [epoch: 19.5 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17772378577011042		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 0.17772378577011042 | validation: 0.3781672380437056]
	TIME [epoch: 19.5 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18207253866628753		[learning rate: 0.0067489]
	Learning Rate: 0.00674887
	LOSS [training: 0.18207253866628753 | validation: 0.3425729417370045]
	TIME [epoch: 19.5 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1885201664744794		[learning rate: 0.006719]
	Learning Rate: 0.00671905
	LOSS [training: 0.1885201664744794 | validation: 0.31468753786248677]
	TIME [epoch: 19.5 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18766963201357514		[learning rate: 0.0066894]
	Learning Rate: 0.00668936
	LOSS [training: 0.18766963201357514 | validation: 0.32781725542206924]
	TIME [epoch: 19.5 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1981808897895209		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 0.1981808897895209 | validation: 0.30363217526375197]
	TIME [epoch: 19.5 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19237399938248842		[learning rate: 0.0066304]
	Learning Rate: 0.00663038
	LOSS [training: 0.19237399938248842 | validation: 0.28550566841133357]
	TIME [epoch: 19.5 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v14b_20240716_181052/states/model_facs_v2_dec2b_2dpca_v14b_133.pth
	Model improved!!!
EPOCH 134/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2023383135408523		[learning rate: 0.0066011]
	Learning Rate: 0.00660109
	LOSS [training: 0.2023383135408523 | validation: 0.3215676795052641]
	TIME [epoch: 19.6 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19800148069477036		[learning rate: 0.0065719]
	Learning Rate: 0.00657192
	LOSS [training: 0.19800148069477036 | validation: 0.35358223206516676]
	TIME [epoch: 19.5 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2031818811577209		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 0.2031818811577209 | validation: 0.3612229146255808]
	TIME [epoch: 19.5 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1975779916659432		[learning rate: 0.006514]
	Learning Rate: 0.00651398
	LOSS [training: 0.1975779916659432 | validation: 0.3412767918468989]
	TIME [epoch: 19.5 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1835699881898609		[learning rate: 0.0064852]
	Learning Rate: 0.00648519
	LOSS [training: 0.1835699881898609 | validation: 0.31448224945920056]
	TIME [epoch: 19.5 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1852012896633867		[learning rate: 0.0064565]
	Learning Rate: 0.00645654
	LOSS [training: 0.1852012896633867 | validation: 0.3280072600313359]
	TIME [epoch: 19.5 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18662386750321383		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 0.18662386750321383 | validation: 0.3271308503682271]
	TIME [epoch: 19.5 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17759952638806514		[learning rate: 0.0063996]
	Learning Rate: 0.00639961
	LOSS [training: 0.17759952638806514 | validation: 0.3864151348194785]
	TIME [epoch: 19.5 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18024355005071838		[learning rate: 0.0063713]
	Learning Rate: 0.00637134
	LOSS [training: 0.18024355005071838 | validation: 0.39291680482885427]
	TIME [epoch: 19.5 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19211648657355349		[learning rate: 0.0063432]
	Learning Rate: 0.00634319
	LOSS [training: 0.19211648657355349 | validation: 0.359106014256416]
	TIME [epoch: 19.5 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1893372575123745		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 0.1893372575123745 | validation: 0.3623885047207703]
	TIME [epoch: 19.5 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18458819730961457		[learning rate: 0.0062873]
	Learning Rate: 0.00628726
	LOSS [training: 0.18458819730961457 | validation: 0.3461482865054074]
	TIME [epoch: 19.5 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19900439909968623		[learning rate: 0.0062595]
	Learning Rate: 0.00625948
	LOSS [training: 0.19900439909968623 | validation: 0.3667148710512728]
	TIME [epoch: 19.5 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19005549659639337		[learning rate: 0.0062318]
	Learning Rate: 0.00623183
	LOSS [training: 0.19005549659639337 | validation: 0.3890093750854945]
	TIME [epoch: 19.5 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19018484792874318		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 0.19018484792874318 | validation: 0.30550274247418485]
	TIME [epoch: 19.5 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19886321957453207		[learning rate: 0.0061769]
	Learning Rate: 0.00617688
	LOSS [training: 0.19886321957453207 | validation: 0.30619797358241413]
	TIME [epoch: 19.5 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18531806019966496		[learning rate: 0.0061496]
	Learning Rate: 0.00614959
	LOSS [training: 0.18531806019966496 | validation: 0.31931301585088756]
	TIME [epoch: 19.5 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17613072553393994		[learning rate: 0.0061224]
	Learning Rate: 0.00612242
	LOSS [training: 0.17613072553393994 | validation: 0.33070444642443664]
	TIME [epoch: 19.5 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18312469103431844		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 0.18312469103431844 | validation: 0.3341488605645942]
	TIME [epoch: 19.5 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17547631261324112		[learning rate: 0.0060684]
	Learning Rate: 0.00606844
	LOSS [training: 0.17547631261324112 | validation: 0.3320514949228382]
	TIME [epoch: 19.6 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18475300236505837		[learning rate: 0.0060416]
	Learning Rate: 0.00604163
	LOSS [training: 0.18475300236505837 | validation: 0.3234419161247017]
	TIME [epoch: 19.5 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20600328444056215		[learning rate: 0.0060149]
	Learning Rate: 0.00601493
	LOSS [training: 0.20600328444056215 | validation: 0.33634187740802707]
	TIME [epoch: 19.5 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20154013637291826		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 0.20154013637291826 | validation: 0.30416183864959095]
	TIME [epoch: 19.5 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18553067757164748		[learning rate: 0.0059619]
	Learning Rate: 0.0059619
	LOSS [training: 0.18553067757164748 | validation: 0.33556471368345864]
	TIME [epoch: 19.5 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1805668707068191		[learning rate: 0.0059356]
	Learning Rate: 0.00593556
	LOSS [training: 0.1805668707068191 | validation: 0.3377246951605824]
	TIME [epoch: 19.5 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19675605070600743		[learning rate: 0.0059093]
	Learning Rate: 0.00590933
	LOSS [training: 0.19675605070600743 | validation: 0.35367447373824296]
	TIME [epoch: 19.5 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18694930195283596		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 0.18694930195283596 | validation: 0.33477456271192463]
	TIME [epoch: 19.5 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19522639871981567		[learning rate: 0.0058572]
	Learning Rate: 0.00585723
	LOSS [training: 0.19522639871981567 | validation: 0.333258344882548]
	TIME [epoch: 19.6 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1763044054256285		[learning rate: 0.0058314]
	Learning Rate: 0.00583135
	LOSS [training: 0.1763044054256285 | validation: 0.3193919380874023]
	TIME [epoch: 19.5 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19369275194505273		[learning rate: 0.0058056]
	Learning Rate: 0.00580559
	LOSS [training: 0.19369275194505273 | validation: 0.3237105934701133]
	TIME [epoch: 19.5 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18879119851168116		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 0.18879119851168116 | validation: 0.36285300382069435]
	TIME [epoch: 19.5 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20484582551299688		[learning rate: 0.0057544]
	Learning Rate: 0.0057544
	LOSS [training: 0.20484582551299688 | validation: 0.3155729774089227]
	TIME [epoch: 19.5 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18186493041695437		[learning rate: 0.005729]
	Learning Rate: 0.00572897
	LOSS [training: 0.18186493041695437 | validation: 0.33359656243070035]
	TIME [epoch: 19.5 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18360804476034517		[learning rate: 0.0057037]
	Learning Rate: 0.00570366
	LOSS [training: 0.18360804476034517 | validation: 0.3692313878880465]
	TIME [epoch: 19.5 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1793689338375936		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 0.1793689338375936 | validation: 0.3574798843350683]
	TIME [epoch: 19.6 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18350903071904973		[learning rate: 0.0056534]
	Learning Rate: 0.00565337
	LOSS [training: 0.18350903071904973 | validation: 0.36814504122851677]
	TIME [epoch: 19.5 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16778300451437111		[learning rate: 0.0056284]
	Learning Rate: 0.0056284
	LOSS [training: 0.16778300451437111 | validation: 0.3390615396437803]
	TIME [epoch: 19.6 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20385916028306522		[learning rate: 0.0056035]
	Learning Rate: 0.00560353
	LOSS [training: 0.20385916028306522 | validation: 0.41249367657636216]
	TIME [epoch: 19.5 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17743207854388512		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 0.17743207854388512 | validation: 0.3321998861418691]
	TIME [epoch: 19.5 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20530814385541815		[learning rate: 0.0055541]
	Learning Rate: 0.00555412
	LOSS [training: 0.20530814385541815 | validation: 0.3494437301984098]
	TIME [epoch: 19.5 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17425839721868752		[learning rate: 0.0055296]
	Learning Rate: 0.00552958
	LOSS [training: 0.17425839721868752 | validation: 0.32892662109150106]
	TIME [epoch: 19.5 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17652339106556297		[learning rate: 0.0055052]
	Learning Rate: 0.00550515
	LOSS [training: 0.17652339106556297 | validation: 0.3727016575367775]
	TIME [epoch: 19.6 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18394964488830712		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 0.18394964488830712 | validation: 0.2979280825038569]
	TIME [epoch: 19.5 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17828820798433717		[learning rate: 0.0054566]
	Learning Rate: 0.00545661
	LOSS [training: 0.17828820798433717 | validation: 0.3359666850622832]
	TIME [epoch: 19.5 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2004019362036785		[learning rate: 0.0054325]
	Learning Rate: 0.0054325
	LOSS [training: 0.2004019362036785 | validation: 0.30225383246631954]
	TIME [epoch: 19.5 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18009083929886205		[learning rate: 0.0054085]
	Learning Rate: 0.0054085
	LOSS [training: 0.18009083929886205 | validation: 0.3422576828299437]
	TIME [epoch: 19.5 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1696338664632851		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 0.1696338664632851 | validation: 0.3403789222263184]
	TIME [epoch: 19.6 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17166424634413727		[learning rate: 0.0053608]
	Learning Rate: 0.00536081
	LOSS [training: 0.17166424634413727 | validation: 0.31026961427567434]
	TIME [epoch: 19.5 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18248388506061222		[learning rate: 0.0053371]
	Learning Rate: 0.00533713
	LOSS [training: 0.18248388506061222 | validation: 0.3330417330137641]
	TIME [epoch: 19.5 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17610273144044425		[learning rate: 0.0053135]
	Learning Rate: 0.00531355
	LOSS [training: 0.17610273144044425 | validation: 0.31545077830393364]
	TIME [epoch: 19.5 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17771860802438413		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 0.17771860802438413 | validation: 0.3380573613119783]
	TIME [epoch: 19.5 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1793805872608115		[learning rate: 0.0052667]
	Learning Rate: 0.0052667
	LOSS [training: 0.1793805872608115 | validation: 0.3086063209247416]
	TIME [epoch: 19.6 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18377348935575985		[learning rate: 0.0052434]
	Learning Rate: 0.00524343
	LOSS [training: 0.18377348935575985 | validation: 0.31247319045575594]
	TIME [epoch: 19.5 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17585674310300536		[learning rate: 0.0052203]
	Learning Rate: 0.00522026
	LOSS [training: 0.17585674310300536 | validation: 0.3213023110322478]
	TIME [epoch: 19.5 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18061749976897493		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 0.18061749976897493 | validation: 0.3000421422488707]
	TIME [epoch: 19.5 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18673734890502827		[learning rate: 0.0051742]
	Learning Rate: 0.00517423
	LOSS [training: 0.18673734890502827 | validation: 0.3887222519699366]
	TIME [epoch: 19.5 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16993245442295674		[learning rate: 0.0051514]
	Learning Rate: 0.00515137
	LOSS [training: 0.16993245442295674 | validation: 0.37854004861493934]
	TIME [epoch: 19.5 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19913467925106104		[learning rate: 0.0051286]
	Learning Rate: 0.00512861
	LOSS [training: 0.19913467925106104 | validation: 0.37894643504948317]
	TIME [epoch: 19.5 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18602950588507658		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 0.18602950588507658 | validation: 0.3655148490420237]
	TIME [epoch: 19.6 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1841608015866699		[learning rate: 0.0050834]
	Learning Rate: 0.00508339
	LOSS [training: 0.1841608015866699 | validation: 0.31228811204272783]
	TIME [epoch: 19.5 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.181005411862281		[learning rate: 0.0050609]
	Learning Rate: 0.00506093
	LOSS [training: 0.181005411862281 | validation: 0.3176835258494027]
	TIME [epoch: 19.5 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1867197742848552		[learning rate: 0.0050386]
	Learning Rate: 0.00503857
	LOSS [training: 0.1867197742848552 | validation: 0.3027350050005392]
	TIME [epoch: 19.5 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17553732755918888		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 0.17553732755918888 | validation: 0.3141257517708595]
	TIME [epoch: 19.5 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17020936964360125		[learning rate: 0.0049941]
	Learning Rate: 0.00499415
	LOSS [training: 0.17020936964360125 | validation: 0.3390296739184655]
	TIME [epoch: 19.5 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.175131979228295		[learning rate: 0.0049721]
	Learning Rate: 0.00497208
	LOSS [training: 0.175131979228295 | validation: 0.3122116522973546]
	TIME [epoch: 19.5 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18220958447515007		[learning rate: 0.0049501]
	Learning Rate: 0.00495012
	LOSS [training: 0.18220958447515007 | validation: 0.3152679256269762]
	TIME [epoch: 19.5 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17868834515305504		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 0.17868834515305504 | validation: 0.35078902722226035]
	TIME [epoch: 19.5 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18633306024004234		[learning rate: 0.0049065]
	Learning Rate: 0.00490647
	LOSS [training: 0.18633306024004234 | validation: 0.32228699600332505]
	TIME [epoch: 66.7 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18996951561580533		[learning rate: 0.0048848]
	Learning Rate: 0.00488479
	LOSS [training: 0.18996951561580533 | validation: 0.3166580506013233]
	TIME [epoch: 42.1 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18178061807209356		[learning rate: 0.0048632]
	Learning Rate: 0.00486321
	LOSS [training: 0.18178061807209356 | validation: 0.3319311202566979]
	TIME [epoch: 42 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18258419168023432		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 0.18258419168023432 | validation: 0.31037432500286455]
	TIME [epoch: 42.1 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17629447876351478		[learning rate: 0.0048203]
	Learning Rate: 0.00482033
	LOSS [training: 0.17629447876351478 | validation: 0.34436429434141785]
	TIME [epoch: 42 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17178924046556138		[learning rate: 0.004799]
	Learning Rate: 0.00479903
	LOSS [training: 0.17178924046556138 | validation: 0.3955503766534849]
	TIME [epoch: 42 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16765177018630714		[learning rate: 0.0047778]
	Learning Rate: 0.00477783
	LOSS [training: 0.16765177018630714 | validation: 0.314317625428303]
	TIME [epoch: 42 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1755242498034821		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.1755242498034821 | validation: 0.43265030088259737]
	TIME [epoch: 42 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19717284442612987		[learning rate: 0.0047357]
	Learning Rate: 0.0047357
	LOSS [training: 0.19717284442612987 | validation: 0.34601307150753396]
	TIME [epoch: 42 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18621982359547967		[learning rate: 0.0047148]
	Learning Rate: 0.00471478
	LOSS [training: 0.18621982359547967 | validation: 0.3139647108695]
	TIME [epoch: 42 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18051299553584615		[learning rate: 0.0046939]
	Learning Rate: 0.00469395
	LOSS [training: 0.18051299553584615 | validation: 0.3923401413580106]
	TIME [epoch: 42 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16887018095275805		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 0.16887018095275805 | validation: 0.32496011946242576]
	TIME [epoch: 42 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1773210850077705		[learning rate: 0.0046526]
	Learning Rate: 0.00465256
	LOSS [training: 0.1773210850077705 | validation: 0.3062811811979876]
	TIME [epoch: 42 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17464623166138718		[learning rate: 0.004632]
	Learning Rate: 0.00463201
	LOSS [training: 0.17464623166138718 | validation: 0.3274681138885146]
	TIME [epoch: 42.1 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17404735538917643		[learning rate: 0.0046115]
	Learning Rate: 0.00461154
	LOSS [training: 0.17404735538917643 | validation: 0.33160351352712025]
	TIME [epoch: 42.1 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17459181501563048		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 0.17459181501563048 | validation: 0.31612695678891495]
	TIME [epoch: 42 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17447942200020514		[learning rate: 0.0045709]
	Learning Rate: 0.00457088
	LOSS [training: 0.17447942200020514 | validation: 0.34315883335383135]
	TIME [epoch: 42 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17111910784061815		[learning rate: 0.0045507]
	Learning Rate: 0.00455069
	LOSS [training: 0.17111910784061815 | validation: 0.3033471966398327]
	TIME [epoch: 42.1 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17410703423488025		[learning rate: 0.0045306]
	Learning Rate: 0.00453058
	LOSS [training: 0.17410703423488025 | validation: 0.3286393263166572]
	TIME [epoch: 42 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17148055311317448		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 0.17148055311317448 | validation: 0.32034981936772017]
	TIME [epoch: 42 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1748937882891812		[learning rate: 0.0044906]
	Learning Rate: 0.00449063
	LOSS [training: 0.1748937882891812 | validation: 0.32162129798805783]
	TIME [epoch: 42.1 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17322700000793517		[learning rate: 0.0044708]
	Learning Rate: 0.00447079
	LOSS [training: 0.17322700000793517 | validation: 0.31896252204944014]
	TIME [epoch: 42 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1655139859785877		[learning rate: 0.004451]
	Learning Rate: 0.00445104
	LOSS [training: 0.1655139859785877 | validation: 0.2942940874297715]
	TIME [epoch: 42 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1789663631672073		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 0.1789663631672073 | validation: 0.31695258885934124]
	TIME [epoch: 42.1 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18948178841117064		[learning rate: 0.0044118]
	Learning Rate: 0.0044118
	LOSS [training: 0.18948178841117064 | validation: 0.35057124118523264]
	TIME [epoch: 42 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17377131174682303		[learning rate: 0.0043923]
	Learning Rate: 0.0043923
	LOSS [training: 0.17377131174682303 | validation: 0.31606813656323524]
	TIME [epoch: 42 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18026163011574564		[learning rate: 0.0043729]
	Learning Rate: 0.0043729
	LOSS [training: 0.18026163011574564 | validation: 0.3597850851294174]
	TIME [epoch: 42 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18007242961638245		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 0.18007242961638245 | validation: 0.32638883343223124]
	TIME [epoch: 42 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17084504440649817		[learning rate: 0.0043343]
	Learning Rate: 0.00433434
	LOSS [training: 0.17084504440649817 | validation: 0.3587598653084453]
	TIME [epoch: 42 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16518135199153994		[learning rate: 0.0043152]
	Learning Rate: 0.00431519
	LOSS [training: 0.16518135199153994 | validation: 0.386070046353433]
	TIME [epoch: 42.1 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17147132087361072		[learning rate: 0.0042961]
	Learning Rate: 0.00429612
	LOSS [training: 0.17147132087361072 | validation: 0.35265976988366315]
	TIME [epoch: 42 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1669497450571226		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 0.1669497450571226 | validation: 0.3171894940374439]
	TIME [epoch: 42.1 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1721856057193318		[learning rate: 0.0042582]
	Learning Rate: 0.00425825
	LOSS [training: 0.1721856057193318 | validation: 0.3528018267882935]
	TIME [epoch: 42 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1866667282933066		[learning rate: 0.0042394]
	Learning Rate: 0.00423943
	LOSS [training: 0.1866667282933066 | validation: 0.3619265988784603]
	TIME [epoch: 42.1 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17863841670065528		[learning rate: 0.0042207]
	Learning Rate: 0.0042207
	LOSS [training: 0.17863841670065528 | validation: 0.3277513121052836]
	TIME [epoch: 42 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17195299785557358		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 0.17195299785557358 | validation: 0.31639008740256497]
	TIME [epoch: 42 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17765184224678476		[learning rate: 0.0041835]
	Learning Rate: 0.00418349
	LOSS [training: 0.17765184224678476 | validation: 0.29128002266543984]
	TIME [epoch: 42 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16936426701567708		[learning rate: 0.004165]
	Learning Rate: 0.004165
	LOSS [training: 0.16936426701567708 | validation: 0.30219943112624903]
	TIME [epoch: 42 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17884290453869808		[learning rate: 0.0041466]
	Learning Rate: 0.0041466
	LOSS [training: 0.17884290453869808 | validation: 0.2960810524749046]
	TIME [epoch: 42 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1675063688649479		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 0.1675063688649479 | validation: 0.34094556380360946]
	TIME [epoch: 42.1 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17478534455091094		[learning rate: 0.00411]
	Learning Rate: 0.00411004
	LOSS [training: 0.17478534455091094 | validation: 0.3248115643666778]
	TIME [epoch: 42 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16875946839951092		[learning rate: 0.0040919]
	Learning Rate: 0.00409188
	LOSS [training: 0.16875946839951092 | validation: 0.3006606419715655]
	TIME [epoch: 42.1 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16177377582365446		[learning rate: 0.0040738]
	Learning Rate: 0.0040738
	LOSS [training: 0.16177377582365446 | validation: 0.3897575656331865]
	TIME [epoch: 42 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17993072584715622		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.17993072584715622 | validation: 0.316591195124906]
	TIME [epoch: 42 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17410718346709586		[learning rate: 0.0040379]
	Learning Rate: 0.00403788
	LOSS [training: 0.17410718346709586 | validation: 0.33407720374186045]
	TIME [epoch: 42 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17720692585153547		[learning rate: 0.00402]
	Learning Rate: 0.00402004
	LOSS [training: 0.17720692585153547 | validation: 0.33279696432248973]
	TIME [epoch: 42.1 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17356355536785859		[learning rate: 0.0040023]
	Learning Rate: 0.00400228
	LOSS [training: 0.17356355536785859 | validation: 0.3234253706192945]
	TIME [epoch: 42.1 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17207663559451805		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 0.17207663559451805 | validation: 0.2906249584351207]
	TIME [epoch: 42 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16829772906538937		[learning rate: 0.003967]
	Learning Rate: 0.00396699
	LOSS [training: 0.16829772906538937 | validation: 0.3286018194485876]
	TIME [epoch: 42 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17660148953649168		[learning rate: 0.0039495]
	Learning Rate: 0.00394947
	LOSS [training: 0.17660148953649168 | validation: 0.30913479340636363]
	TIME [epoch: 42 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1835060186101473		[learning rate: 0.003932]
	Learning Rate: 0.00393202
	LOSS [training: 0.1835060186101473 | validation: 0.3849145825908691]
	TIME [epoch: 42.1 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17117093216190235		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 0.17117093216190235 | validation: 0.31379616040700714]
	TIME [epoch: 42 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1815617129376092		[learning rate: 0.0038973]
	Learning Rate: 0.00389735
	LOSS [training: 0.1815617129376092 | validation: 0.31898933080421116]
	TIME [epoch: 42 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16449815946416807		[learning rate: 0.0038801]
	Learning Rate: 0.00388013
	LOSS [training: 0.16449815946416807 | validation: 0.33339997242646285]
	TIME [epoch: 42 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17177798404757255		[learning rate: 0.003863]
	Learning Rate: 0.00386299
	LOSS [training: 0.17177798404757255 | validation: 0.38104880852195033]
	TIME [epoch: 42 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16957176737808416		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 0.16957176737808416 | validation: 0.3205842057679432]
	TIME [epoch: 42 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16938115820404342		[learning rate: 0.0038289]
	Learning Rate: 0.00382893
	LOSS [training: 0.16938115820404342 | validation: 0.30545087145720895]
	TIME [epoch: 42 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1717135420346542		[learning rate: 0.003812]
	Learning Rate: 0.00381201
	LOSS [training: 0.1717135420346542 | validation: 0.33740184227965675]
	TIME [epoch: 42 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17443433279133935		[learning rate: 0.0037952]
	Learning Rate: 0.00379517
	LOSS [training: 0.17443433279133935 | validation: 0.338345062334862]
	TIME [epoch: 42 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18270644765850833		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 0.18270644765850833 | validation: 0.29411789615355377]
	TIME [epoch: 42 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16868240453817315		[learning rate: 0.0037617]
	Learning Rate: 0.0037617
	LOSS [training: 0.16868240453817315 | validation: 0.318607768099864]
	TIME [epoch: 42 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16498545402559855		[learning rate: 0.0037451]
	Learning Rate: 0.00374508
	LOSS [training: 0.16498545402559855 | validation: 0.3171490225764481]
	TIME [epoch: 42 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17786458532757837		[learning rate: 0.0037285]
	Learning Rate: 0.00372854
	LOSS [training: 0.17786458532757837 | validation: 0.3163724259330135]
	TIME [epoch: 42 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15917752755019113		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 0.15917752755019113 | validation: 0.360593938765865]
	TIME [epoch: 42 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18294069524230092		[learning rate: 0.0036957]
	Learning Rate: 0.00369566
	LOSS [training: 0.18294069524230092 | validation: 0.300204194799861]
	TIME [epoch: 42 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16672003226843676		[learning rate: 0.0036793]
	Learning Rate: 0.00367933
	LOSS [training: 0.16672003226843676 | validation: 0.2961125201255881]
	TIME [epoch: 42 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16741714979664493		[learning rate: 0.0036631]
	Learning Rate: 0.00366308
	LOSS [training: 0.16741714979664493 | validation: 0.3363209599201631]
	TIME [epoch: 42 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16415786294168408		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 0.16415786294168408 | validation: 0.3409346332819357]
	TIME [epoch: 42 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1665428765072176		[learning rate: 0.0036308]
	Learning Rate: 0.00363078
	LOSS [training: 0.1665428765072176 | validation: 0.34231951900659396]
	TIME [epoch: 42 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16704555574513644		[learning rate: 0.0036147]
	Learning Rate: 0.00361474
	LOSS [training: 0.16704555574513644 | validation: 0.34109784491319456]
	TIME [epoch: 42 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1752068093198227		[learning rate: 0.0035988]
	Learning Rate: 0.00359877
	LOSS [training: 0.1752068093198227 | validation: 0.3070466797809536]
	TIME [epoch: 42 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16782141735339878		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 0.16782141735339878 | validation: 0.30282760613034726]
	TIME [epoch: 42.1 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16858835209958734		[learning rate: 0.003567]
	Learning Rate: 0.00356704
	LOSS [training: 0.16858835209958734 | validation: 0.31401995484991335]
	TIME [epoch: 42 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1760634248462796		[learning rate: 0.0035513]
	Learning Rate: 0.00355128
	LOSS [training: 0.1760634248462796 | validation: 0.3249815371676638]
	TIME [epoch: 42 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.174752095826168		[learning rate: 0.0035356]
	Learning Rate: 0.00353559
	LOSS [training: 0.174752095826168 | validation: 0.29018571733380105]
	TIME [epoch: 42 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16411415886894937		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 0.16411415886894937 | validation: 0.2930769881037401]
	TIME [epoch: 42 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17538382587707652		[learning rate: 0.0035044]
	Learning Rate: 0.00350441
	LOSS [training: 0.17538382587707652 | validation: 0.34518148676600036]
	TIME [epoch: 42 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16793774206653939		[learning rate: 0.0034889]
	Learning Rate: 0.00348893
	LOSS [training: 0.16793774206653939 | validation: 0.3181511825843798]
	TIME [epoch: 42.1 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17176476046406708		[learning rate: 0.0034735]
	Learning Rate: 0.00347352
	LOSS [training: 0.17176476046406708 | validation: 0.3161704860151181]
	TIME [epoch: 42 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17062529491860087		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.17062529491860087 | validation: 0.37983367235195487]
	TIME [epoch: 42.1 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1724129720884753		[learning rate: 0.0034429]
	Learning Rate: 0.00344289
	LOSS [training: 0.1724129720884753 | validation: 0.3027183791479956]
	TIME [epoch: 42 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15982809751945648		[learning rate: 0.0034277]
	Learning Rate: 0.00342768
	LOSS [training: 0.15982809751945648 | validation: 0.3118589035388714]
	TIME [epoch: 42 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16925962665689592		[learning rate: 0.0034125]
	Learning Rate: 0.00341253
	LOSS [training: 0.16925962665689592 | validation: 0.3030895795834364]
	TIME [epoch: 42 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1709428240802742		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 0.1709428240802742 | validation: 0.3125084188989526]
	TIME [epoch: 42 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16023305664313153		[learning rate: 0.0033824]
	Learning Rate: 0.00338245
	LOSS [training: 0.16023305664313153 | validation: 0.34453883822141307]
	TIME [epoch: 42 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16002329672868396		[learning rate: 0.0033675]
	Learning Rate: 0.0033675
	LOSS [training: 0.16002329672868396 | validation: 0.30329681396617747]
	TIME [epoch: 42.1 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16730163655462432		[learning rate: 0.0033526]
	Learning Rate: 0.00335262
	LOSS [training: 0.16730163655462432 | validation: 0.3145582093730142]
	TIME [epoch: 42 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1728726634774727		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 0.1728726634774727 | validation: 0.35281766703160766]
	TIME [epoch: 42 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1704629479617257		[learning rate: 0.0033231]
	Learning Rate: 0.00332306
	LOSS [training: 0.1704629479617257 | validation: 0.3153667871006581]
	TIME [epoch: 42 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16393763740758566		[learning rate: 0.0033084]
	Learning Rate: 0.00330838
	LOSS [training: 0.16393763740758566 | validation: 0.3282889376986546]
	TIME [epoch: 42 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17245703952491953		[learning rate: 0.0032938]
	Learning Rate: 0.00329376
	LOSS [training: 0.17245703952491953 | validation: 0.3575054112562365]
	TIME [epoch: 42 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18671818381567554		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 0.18671818381567554 | validation: 0.34676825187154836]
	TIME [epoch: 42.1 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17200265417239152		[learning rate: 0.0032647]
	Learning Rate: 0.00326472
	LOSS [training: 0.17200265417239152 | validation: 0.31646080728665205]
	TIME [epoch: 42 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17396231247857846		[learning rate: 0.0032503]
	Learning Rate: 0.0032503
	LOSS [training: 0.17396231247857846 | validation: 0.3410915514833052]
	TIME [epoch: 42 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1661697914758177		[learning rate: 0.0032359]
	Learning Rate: 0.00323594
	LOSS [training: 0.1661697914758177 | validation: 0.33493942536990634]
	TIME [epoch: 42 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16859220150050697		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 0.16859220150050697 | validation: 0.3119340039228876]
	TIME [epoch: 42 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16274112665372392		[learning rate: 0.0032074]
	Learning Rate: 0.00320741
	LOSS [training: 0.16274112665372392 | validation: 0.3138893779123118]
	TIME [epoch: 42.1 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16928477134770792		[learning rate: 0.0031932]
	Learning Rate: 0.00319323
	LOSS [training: 0.16928477134770792 | validation: 0.3212008753055968]
	TIME [epoch: 42.1 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16579292246243874		[learning rate: 0.0031791]
	Learning Rate: 0.00317913
	LOSS [training: 0.16579292246243874 | validation: 0.2954992871702032]
	TIME [epoch: 42 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1704491020171417		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 0.1704491020171417 | validation: 0.29238783643628813]
	TIME [epoch: 42 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18774812777105332		[learning rate: 0.0031511]
	Learning Rate: 0.0031511
	LOSS [training: 0.18774812777105332 | validation: 0.3208852275392447]
	TIME [epoch: 112 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16608839984510915		[learning rate: 0.0031372]
	Learning Rate: 0.00313717
	LOSS [training: 0.16608839984510915 | validation: 0.2954538144385438]
	TIME [epoch: 87.1 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17018203453185876		[learning rate: 0.0031233]
	Learning Rate: 0.00312331
	LOSS [training: 0.17018203453185876 | validation: 0.30068266157060597]
	TIME [epoch: 87.1 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15569080258317275		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 0.15569080258317275 | validation: 0.31752840568647706]
	TIME [epoch: 87.1 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1657953276939105		[learning rate: 0.0030958]
	Learning Rate: 0.00309577
	LOSS [training: 0.1657953276939105 | validation: 0.35485920100226104]
	TIME [epoch: 87 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1606461089855169		[learning rate: 0.0030821]
	Learning Rate: 0.0030821
	LOSS [training: 0.1606461089855169 | validation: 0.32622593160064606]
	TIME [epoch: 87.1 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1689341627792103		[learning rate: 0.0030685]
	Learning Rate: 0.00306848
	LOSS [training: 0.1689341627792103 | validation: 0.2897386797486713]
	TIME [epoch: 87.1 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16267032207344562		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 0.16267032207344562 | validation: 0.3165374115707038]
	TIME [epoch: 87.1 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16165522710880775		[learning rate: 0.0030414]
	Learning Rate: 0.00304142
	LOSS [training: 0.16165522710880775 | validation: 0.3100513371532754]
	TIME [epoch: 87.1 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16758404419223474		[learning rate: 0.003028]
	Learning Rate: 0.00302799
	LOSS [training: 0.16758404419223474 | validation: 0.3115092107827245]
	TIME [epoch: 87.1 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1658776630468485		[learning rate: 0.0030146]
	Learning Rate: 0.00301461
	LOSS [training: 0.1658776630468485 | validation: 0.29757159706554415]
	TIME [epoch: 87.1 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15709821322499665		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 0.15709821322499665 | validation: 0.320040208395714]
	TIME [epoch: 87.1 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16557667200332893		[learning rate: 0.002988]
	Learning Rate: 0.00298803
	LOSS [training: 0.16557667200332893 | validation: 0.3353911568107162]
	TIME [epoch: 87.1 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19015563204018868		[learning rate: 0.0029748]
	Learning Rate: 0.00297483
	LOSS [training: 0.19015563204018868 | validation: 0.3109115703108546]
	TIME [epoch: 87.1 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1715275666411023		[learning rate: 0.0029617]
	Learning Rate: 0.00296168
	LOSS [training: 0.1715275666411023 | validation: 0.3034095957164403]
	TIME [epoch: 87 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15843754262615464		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.15843754262615464 | validation: 0.3040838496848024]
	TIME [epoch: 87.1 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1608143308084233		[learning rate: 0.0029356]
	Learning Rate: 0.00293557
	LOSS [training: 0.1608143308084233 | validation: 0.3040790525705912]
	TIME [epoch: 87 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16511609634159896		[learning rate: 0.0029226]
	Learning Rate: 0.0029226
	LOSS [training: 0.16511609634159896 | validation: 0.29636069488378786]
	TIME [epoch: 87.1 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16644995202809804		[learning rate: 0.0029097]
	Learning Rate: 0.00290969
	LOSS [training: 0.16644995202809804 | validation: 0.3180632976613531]
	TIME [epoch: 87.1 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1675273102188905		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 0.1675273102188905 | validation: 0.3247017266323314]
	TIME [epoch: 87.1 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17530885143879643		[learning rate: 0.002884]
	Learning Rate: 0.00288403
	LOSS [training: 0.17530885143879643 | validation: 0.33622409214351723]
	TIME [epoch: 87.1 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17202010475460733		[learning rate: 0.0028713]
	Learning Rate: 0.00287129
	LOSS [training: 0.17202010475460733 | validation: 0.32430665645516127]
	TIME [epoch: 87.1 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1642558793358926		[learning rate: 0.0028586]
	Learning Rate: 0.0028586
	LOSS [training: 0.1642558793358926 | validation: 0.29215306261829593]
	TIME [epoch: 87.1 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17097734254313987		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 0.17097734254313987 | validation: 0.28367843935071524]
	TIME [epoch: 87.1 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v14b_20240716_181052/states/model_facs_v2_dec2b_2dpca_v14b_324.pth
	Model improved!!!
EPOCH 325/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16789604880573877		[learning rate: 0.0028334]
	Learning Rate: 0.0028334
	LOSS [training: 0.16789604880573877 | validation: 0.33472450347812444]
	TIME [epoch: 87.1 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17190662307616691		[learning rate: 0.0028209]
	Learning Rate: 0.00282088
	LOSS [training: 0.17190662307616691 | validation: 0.30775358329257213]
	TIME [epoch: 87.1 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15612393750418643		[learning rate: 0.0028084]
	Learning Rate: 0.00280842
	LOSS [training: 0.15612393750418643 | validation: 0.31746024078674695]
	TIME [epoch: 87.1 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16400868264352544		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 0.16400868264352544 | validation: 0.31875124557158546]
	TIME [epoch: 87.1 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17329236945533116		[learning rate: 0.0027837]
	Learning Rate: 0.00278366
	LOSS [training: 0.17329236945533116 | validation: 0.33496821630263124]
	TIME [epoch: 87.1 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.176311074906453		[learning rate: 0.0027714]
	Learning Rate: 0.00277136
	LOSS [training: 0.176311074906453 | validation: 0.30412229492026815]
	TIME [epoch: 87.1 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16816638654714086		[learning rate: 0.0027591]
	Learning Rate: 0.00275911
	LOSS [training: 0.16816638654714086 | validation: 0.2975041530372041]
	TIME [epoch: 87.1 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15806169319558747		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 0.15806169319558747 | validation: 0.2883342829361114]
	TIME [epoch: 87.1 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1653651158985468		[learning rate: 0.0027348]
	Learning Rate: 0.00273478
	LOSS [training: 0.1653651158985468 | validation: 0.30280315670961594]
	TIME [epoch: 87.1 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16649021555757487		[learning rate: 0.0027227]
	Learning Rate: 0.0027227
	LOSS [training: 0.16649021555757487 | validation: 0.3115877287824533]
	TIME [epoch: 87.1 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16356574785223707		[learning rate: 0.0027107]
	Learning Rate: 0.00271067
	LOSS [training: 0.16356574785223707 | validation: 0.38185498529843137]
	TIME [epoch: 87.1 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17350703440331003		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 0.17350703440331003 | validation: 0.30639854871397326]
	TIME [epoch: 87.1 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1646145256470441		[learning rate: 0.0026868]
	Learning Rate: 0.00268677
	LOSS [training: 0.1646145256470441 | validation: 0.3052237412960938]
	TIME [epoch: 87.1 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16277399139480545		[learning rate: 0.0026749]
	Learning Rate: 0.0026749
	LOSS [training: 0.16277399139480545 | validation: 0.30340677603816874]
	TIME [epoch: 87 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16682283586195737		[learning rate: 0.0026631]
	Learning Rate: 0.00266308
	LOSS [training: 0.16682283586195737 | validation: 0.3104961969180899]
	TIME [epoch: 87.1 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16644529949600945		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 0.16644529949600945 | validation: 0.2996803705322579]
	TIME [epoch: 87.1 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17604549783091605		[learning rate: 0.0026396]
	Learning Rate: 0.0026396
	LOSS [training: 0.17604549783091605 | validation: 0.2919611024300111]
	TIME [epoch: 87.1 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16260945608242244		[learning rate: 0.0026279]
	Learning Rate: 0.00262794
	LOSS [training: 0.16260945608242244 | validation: 0.31669796930406746]
	TIME [epoch: 87.1 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15829336003419958		[learning rate: 0.0026163]
	Learning Rate: 0.00261633
	LOSS [training: 0.15829336003419958 | validation: 0.34897197699638044]
	TIME [epoch: 87.1 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16981939736796328		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 0.16981939736796328 | validation: 0.32531762826337673]
	TIME [epoch: 87.1 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16812699928437608		[learning rate: 0.0025933]
	Learning Rate: 0.00259326
	LOSS [training: 0.16812699928437608 | validation: 0.30793089476011026]
	TIME [epoch: 87 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16369918843016712		[learning rate: 0.0025818]
	Learning Rate: 0.0025818
	LOSS [training: 0.16369918843016712 | validation: 0.3137319157302397]
	TIME [epoch: 87.1 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16076074061503778		[learning rate: 0.0025704]
	Learning Rate: 0.0025704
	LOSS [training: 0.16076074061503778 | validation: 0.29542654559322085]
	TIME [epoch: 87.1 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1600415645671968		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.1600415645671968 | validation: 0.31530511133680783]
	TIME [epoch: 87.1 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16949447324789985		[learning rate: 0.0025477]
	Learning Rate: 0.00254773
	LOSS [training: 0.16949447324789985 | validation: 0.2919990941644475]
	TIME [epoch: 87.1 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17257638642199477		[learning rate: 0.0025365]
	Learning Rate: 0.00253648
	LOSS [training: 0.17257638642199477 | validation: 0.3231395956273995]
	TIME [epoch: 87 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1611916753502827		[learning rate: 0.0025253]
	Learning Rate: 0.00252527
	LOSS [training: 0.1611916753502827 | validation: 0.2937202075014309]
	TIME [epoch: 87.1 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17126508725876793		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.17126508725876793 | validation: 0.29846054359529267]
	TIME [epoch: 87 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16235299059119357		[learning rate: 0.002503]
	Learning Rate: 0.002503
	LOSS [training: 0.16235299059119357 | validation: 0.34147286554568634]
	TIME [epoch: 87 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1627959458338249		[learning rate: 0.0024919]
	Learning Rate: 0.00249194
	LOSS [training: 0.1627959458338249 | validation: 0.3461418543807764]
	TIME [epoch: 87.1 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15670850338196193		[learning rate: 0.0024809]
	Learning Rate: 0.00248093
	LOSS [training: 0.15670850338196193 | validation: 0.3091927668135264]
	TIME [epoch: 87 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16135661444888896		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 0.16135661444888896 | validation: 0.3305651236589362]
	TIME [epoch: 87.1 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16891274035278464		[learning rate: 0.0024591]
	Learning Rate: 0.00245906
	LOSS [training: 0.16891274035278464 | validation: 0.3010249191198754]
	TIME [epoch: 87.1 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15743816116189968		[learning rate: 0.0024482]
	Learning Rate: 0.0024482
	LOSS [training: 0.15743816116189968 | validation: 0.29819286448927634]
	TIME [epoch: 87.1 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15476224732044327		[learning rate: 0.0024374]
	Learning Rate: 0.00243738
	LOSS [training: 0.15476224732044327 | validation: 0.3239363282358678]
	TIME [epoch: 87.1 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17110431291359607		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.17110431291359607 | validation: 0.30910849049294786]
	TIME [epoch: 87.1 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1639169607572163		[learning rate: 0.0024159]
	Learning Rate: 0.00241589
	LOSS [training: 0.1639169607572163 | validation: 0.35732668955569885]
	TIME [epoch: 87.1 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16579175935909587		[learning rate: 0.0024052]
	Learning Rate: 0.00240521
	LOSS [training: 0.16579175935909587 | validation: 0.310478324103573]
	TIME [epoch: 87.1 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16728768997454516		[learning rate: 0.0023946]
	Learning Rate: 0.00239459
	LOSS [training: 0.16728768997454516 | validation: 0.3362194427901097]
	TIME [epoch: 87.1 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1589638290528313		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 0.1589638290528313 | validation: 0.33855995892065605]
	TIME [epoch: 87.1 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16196581443192173		[learning rate: 0.0023735]
	Learning Rate: 0.00237347
	LOSS [training: 0.16196581443192173 | validation: 0.3353040814141061]
	TIME [epoch: 87.1 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15547024187769504		[learning rate: 0.002363]
	Learning Rate: 0.00236299
	LOSS [training: 0.15547024187769504 | validation: 0.3244442374649575]
	TIME [epoch: 87.1 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16865800900528066		[learning rate: 0.0023525]
	Learning Rate: 0.00235255
	LOSS [training: 0.16865800900528066 | validation: 0.2934851275715826]
	TIME [epoch: 87.1 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16052037429815152		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.16052037429815152 | validation: 0.3307334773867549]
	TIME [epoch: 87.1 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1623407563265437		[learning rate: 0.0023318]
	Learning Rate: 0.00233181
	LOSS [training: 0.1623407563265437 | validation: 0.29851453909207576]
	TIME [epoch: 87 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1645528219078612		[learning rate: 0.0023215]
	Learning Rate: 0.0023215
	LOSS [training: 0.1645528219078612 | validation: 0.29667429816419943]
	TIME [epoch: 87.1 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16326915624036437		[learning rate: 0.0023112]
	Learning Rate: 0.00231125
	LOSS [training: 0.16326915624036437 | validation: 0.3057789738046313]
	TIME [epoch: 87.1 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1730830914950176		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.1730830914950176 | validation: 0.3200516622220556]
	TIME [epoch: 87.1 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15597732812511061		[learning rate: 0.0022909]
	Learning Rate: 0.00229087
	LOSS [training: 0.15597732812511061 | validation: 0.31084620279200925]
	TIME [epoch: 87.1 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17070068772685545		[learning rate: 0.0022807]
	Learning Rate: 0.00228075
	LOSS [training: 0.17070068772685545 | validation: 0.3344875039546746]
	TIME [epoch: 87.1 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15793125106515488		[learning rate: 0.0022707]
	Learning Rate: 0.00227067
	LOSS [training: 0.15793125106515488 | validation: 0.3162258432444086]
	TIME [epoch: 87.1 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16468150716930102		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.16468150716930102 | validation: 0.28270521273483595]
	TIME [epoch: 87.1 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v14b_20240716_181052/states/model_facs_v2_dec2b_2dpca_v14b_376.pth
	Model improved!!!
EPOCH 377/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1600955877779498		[learning rate: 0.0022506]
	Learning Rate: 0.00225065
	LOSS [training: 0.1600955877779498 | validation: 0.32653931173122086]
	TIME [epoch: 87.1 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15841929710467553		[learning rate: 0.0022407]
	Learning Rate: 0.0022407
	LOSS [training: 0.15841929710467553 | validation: 0.32423410213305603]
	TIME [epoch: 87.1 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16089232224592123		[learning rate: 0.0022308]
	Learning Rate: 0.0022308
	LOSS [training: 0.16089232224592123 | validation: 0.32321805985939983]
	TIME [epoch: 87.1 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1583929192092572		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.1583929192092572 | validation: 0.3075810002631835]
	TIME [epoch: 87.1 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16798497805599677		[learning rate: 0.0022111]
	Learning Rate: 0.00221114
	LOSS [training: 0.16798497805599677 | validation: 0.3219891847068068]
	TIME [epoch: 87.1 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1664030262317489		[learning rate: 0.0022014]
	Learning Rate: 0.00220137
	LOSS [training: 0.1664030262317489 | validation: 0.30320752696439224]
	TIME [epoch: 87.1 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1641340795131213		[learning rate: 0.0021916]
	Learning Rate: 0.00219164
	LOSS [training: 0.1641340795131213 | validation: 0.2911605856829486]
	TIME [epoch: 87 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1605588867121532		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.1605588867121532 | validation: 0.35656939667475807]
	TIME [epoch: 87.1 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16553701548218855		[learning rate: 0.0021723]
	Learning Rate: 0.00217232
	LOSS [training: 0.16553701548218855 | validation: 0.28246323386432143]
	TIME [epoch: 87.1 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v14b_20240716_181052/states/model_facs_v2_dec2b_2dpca_v14b_385.pth
	Model improved!!!
EPOCH 386/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15799705635502598		[learning rate: 0.0021627]
	Learning Rate: 0.00216272
	LOSS [training: 0.15799705635502598 | validation: 0.3262966468256514]
	TIME [epoch: 87.1 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15732019287428503		[learning rate: 0.0021532]
	Learning Rate: 0.00215316
	LOSS [training: 0.15732019287428503 | validation: 0.3175987654608437]
	TIME [epoch: 87.1 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15648030608104885		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.15648030608104885 | validation: 0.29883179144827443]
	TIME [epoch: 87.1 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15080600596523558		[learning rate: 0.0021342]
	Learning Rate: 0.00213418
	LOSS [training: 0.15080600596523558 | validation: 0.29020141769962676]
	TIME [epoch: 87.1 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1674154117571475		[learning rate: 0.0021247]
	Learning Rate: 0.00212475
	LOSS [training: 0.1674154117571475 | validation: 0.3161136574932921]
	TIME [epoch: 87.1 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16776057835797858		[learning rate: 0.0021154]
	Learning Rate: 0.00211536
	LOSS [training: 0.16776057835797858 | validation: 0.3016475220762984]
	TIME [epoch: 87.1 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17139929486463068		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.17139929486463068 | validation: 0.2824949966760786]
	TIME [epoch: 87.1 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16168037765917898		[learning rate: 0.0020967]
	Learning Rate: 0.00209671
	LOSS [training: 0.16168037765917898 | validation: 0.3056109086193593]
	TIME [epoch: 87.1 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1651856910263271		[learning rate: 0.0020874]
	Learning Rate: 0.00208745
	LOSS [training: 0.1651856910263271 | validation: 0.3098983630173499]
	TIME [epoch: 87.1 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16155564316276166		[learning rate: 0.0020782]
	Learning Rate: 0.00207822
	LOSS [training: 0.16155564316276166 | validation: 0.29868414380814257]
	TIME [epoch: 87.1 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1525379587182272		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.1525379587182272 | validation: 0.28810285321615337]
	TIME [epoch: 87.1 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16102169989664117		[learning rate: 0.0020599]
	Learning Rate: 0.0020599
	LOSS [training: 0.16102169989664117 | validation: 0.2904338471193994]
	TIME [epoch: 87.1 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15681533973145473		[learning rate: 0.0020508]
	Learning Rate: 0.0020508
	LOSS [training: 0.15681533973145473 | validation: 0.27959683288496023]
	TIME [epoch: 87.1 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v14b_20240716_181052/states/model_facs_v2_dec2b_2dpca_v14b_398.pth
	Model improved!!!
EPOCH 399/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.154535849598735		[learning rate: 0.0020417]
	Learning Rate: 0.00204174
	LOSS [training: 0.154535849598735 | validation: 0.3211375740746074]
	TIME [epoch: 87.1 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17544198582878281		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.17544198582878281 | validation: 0.2948056730080182]
	TIME [epoch: 87 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16822411000269213		[learning rate: 0.0020237]
	Learning Rate: 0.00202374
	LOSS [training: 0.16822411000269213 | validation: 0.320838968753874]
	TIME [epoch: 87.1 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16426209902418426		[learning rate: 0.0020148]
	Learning Rate: 0.00201479
	LOSS [training: 0.16426209902418426 | validation: 0.3091740684112775]
	TIME [epoch: 87.1 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15885855367027993		[learning rate: 0.0020059]
	Learning Rate: 0.00200589
	LOSS [training: 0.15885855367027993 | validation: 0.3030416229890642]
	TIME [epoch: 87.1 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16195996016178488		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.16195996016178488 | validation: 0.2959283001707541]
	TIME [epoch: 87.1 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16286796168376075		[learning rate: 0.0019882]
	Learning Rate: 0.00198821
	LOSS [training: 0.16286796168376075 | validation: 0.3125998541517767]
	TIME [epoch: 87.1 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15910678349600205		[learning rate: 0.0019794]
	Learning Rate: 0.00197942
	LOSS [training: 0.15910678349600205 | validation: 0.32083486398305433]
	TIME [epoch: 87.1 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1577693412844125		[learning rate: 0.0019707]
	Learning Rate: 0.00197068
	LOSS [training: 0.1577693412844125 | validation: 0.34584812261961756]
	TIME [epoch: 87.1 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16768451154337138		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.16768451154337138 | validation: 0.31551688793022914]
	TIME [epoch: 87.1 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16498041923423862		[learning rate: 0.0019533]
	Learning Rate: 0.0019533
	LOSS [training: 0.16498041923423862 | validation: 0.31930983200884633]
	TIME [epoch: 87.1 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16066546246428082		[learning rate: 0.0019447]
	Learning Rate: 0.00194467
	LOSS [training: 0.16066546246428082 | validation: 0.30264778499031403]
	TIME [epoch: 87.1 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1588101577162599		[learning rate: 0.0019361]
	Learning Rate: 0.00193608
	LOSS [training: 0.1588101577162599 | validation: 0.28808950267658917]
	TIME [epoch: 87.1 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16047921510790794		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.16047921510790794 | validation: 0.31654342671053826]
	TIME [epoch: 87.1 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16340022736128051		[learning rate: 0.001919]
	Learning Rate: 0.00191901
	LOSS [training: 0.16340022736128051 | validation: 0.2914691258243187]
	TIME [epoch: 87.1 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16413696311518144		[learning rate: 0.0019105]
	Learning Rate: 0.00191053
	LOSS [training: 0.16413696311518144 | validation: 0.3506731144558064]
	TIME [epoch: 87.1 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15576004929851017		[learning rate: 0.0019021]
	Learning Rate: 0.00190209
	LOSS [training: 0.15576004929851017 | validation: 0.30075108431638764]
	TIME [epoch: 87.1 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1610945581660518		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.1610945581660518 | validation: 0.3014082808669465]
	TIME [epoch: 87.1 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16683187176368267		[learning rate: 0.0018853]
	Learning Rate: 0.00188532
	LOSS [training: 0.16683187176368267 | validation: 0.32864071803014633]
	TIME [epoch: 87.1 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1586292920034244		[learning rate: 0.001877]
	Learning Rate: 0.00187699
	LOSS [training: 0.1586292920034244 | validation: 0.31495391820931934]
	TIME [epoch: 87.1 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15964133106925965		[learning rate: 0.0018687]
	Learning Rate: 0.0018687
	LOSS [training: 0.15964133106925965 | validation: 0.3210461373457521]
	TIME [epoch: 87.1 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1671762106711886		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.1671762106711886 | validation: 0.3334117312700077]
	TIME [epoch: 87.1 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16034062740322486		[learning rate: 0.0018522]
	Learning Rate: 0.00185222
	LOSS [training: 0.16034062740322486 | validation: 0.30904570073775933]
	TIME [epoch: 87.1 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16369648814303334		[learning rate: 0.001844]
	Learning Rate: 0.00184404
	LOSS [training: 0.16369648814303334 | validation: 0.3050948288743606]
	TIME [epoch: 87.1 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15775362020592934		[learning rate: 0.0018359]
	Learning Rate: 0.00183589
	LOSS [training: 0.15775362020592934 | validation: 0.2891452056393882]
	TIME [epoch: 87.1 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15893188728273203		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.15893188728273203 | validation: 0.32246053843507316]
	TIME [epoch: 87.1 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16245335183880216		[learning rate: 0.0018197]
	Learning Rate: 0.0018197
	LOSS [training: 0.16245335183880216 | validation: 0.32817707968130266]
	TIME [epoch: 87.1 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16050237109657153		[learning rate: 0.0018117]
	Learning Rate: 0.00181166
	LOSS [training: 0.16050237109657153 | validation: 0.31727112910669913]
	TIME [epoch: 87.1 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16516380456108554		[learning rate: 0.0018037]
	Learning Rate: 0.00180366
	LOSS [training: 0.16516380456108554 | validation: 0.32958709007867976]
	TIME [epoch: 87.1 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16108811726641373		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.16108811726641373 | validation: 0.31482612341913896]
	TIME [epoch: 87.1 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14834630682771813		[learning rate: 0.0017878]
	Learning Rate: 0.00178775
	LOSS [training: 0.14834630682771813 | validation: 0.32514027252947686]
	TIME [epoch: 87.1 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1677156441417085		[learning rate: 0.0017799]
	Learning Rate: 0.00177985
	LOSS [training: 0.1677156441417085 | validation: 0.2875168955338599]
	TIME [epoch: 87.1 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15446844413530475		[learning rate: 0.001772]
	Learning Rate: 0.00177199
	LOSS [training: 0.15446844413530475 | validation: 0.29879341805733095]
	TIME [epoch: 87.1 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1614549117900978		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.1614549117900978 | validation: 0.3175840580576464]
	TIME [epoch: 87.1 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16210940196377085		[learning rate: 0.0017564]
	Learning Rate: 0.00175637
	LOSS [training: 0.16210940196377085 | validation: 0.2941755095005624]
	TIME [epoch: 87.1 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15496365169085236		[learning rate: 0.0017486]
	Learning Rate: 0.00174861
	LOSS [training: 0.15496365169085236 | validation: 0.31764865622100547]
	TIME [epoch: 87.1 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16019226840550652		[learning rate: 0.0017409]
	Learning Rate: 0.00174088
	LOSS [training: 0.16019226840550652 | validation: 0.30808276804895846]
	TIME [epoch: 87.1 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15646792782901459		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.15646792782901459 | validation: 0.2972096756141327]
	TIME [epoch: 87.1 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16211716823293584		[learning rate: 0.0017255]
	Learning Rate: 0.00172553
	LOSS [training: 0.16211716823293584 | validation: 0.3230787773230158]
	TIME [epoch: 87.1 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15871288919673157		[learning rate: 0.0017179]
	Learning Rate: 0.00171791
	LOSS [training: 0.15871288919673157 | validation: 0.29815055813214686]
	TIME [epoch: 87.1 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15201071053914644		[learning rate: 0.0017103]
	Learning Rate: 0.00171032
	LOSS [training: 0.15201071053914644 | validation: 0.3209528621165207]
	TIME [epoch: 87 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16137584883040892		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.16137584883040892 | validation: 0.2999130067225677]
	TIME [epoch: 87.1 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15345048980504253		[learning rate: 0.0016952]
	Learning Rate: 0.00169524
	LOSS [training: 0.15345048980504253 | validation: 0.3016241470646652]
	TIME [epoch: 87 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15646924470048762		[learning rate: 0.0016877]
	Learning Rate: 0.00168775
	LOSS [training: 0.15646924470048762 | validation: 0.30618259864982106]
	TIME [epoch: 87.1 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16271938611814946		[learning rate: 0.0016803]
	Learning Rate: 0.00168029
	LOSS [training: 0.16271938611814946 | validation: 0.3145418585490208]
	TIME [epoch: 87 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14700933588624643		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.14700933588624643 | validation: 0.3248909979847985]
	TIME [epoch: 87 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15288904394793823		[learning rate: 0.0016655]
	Learning Rate: 0.00166548
	LOSS [training: 0.15288904394793823 | validation: 0.3051013512594878]
	TIME [epoch: 87.1 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.157255006704633		[learning rate: 0.0016581]
	Learning Rate: 0.00165812
	LOSS [training: 0.157255006704633 | validation: 0.29447363156961376]
	TIME [epoch: 87 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15949894761123465		[learning rate: 0.0016508]
	Learning Rate: 0.00165079
	LOSS [training: 0.15949894761123465 | validation: 0.3263846683071777]
	TIME [epoch: 87.1 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1616537026375587		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.1616537026375587 | validation: 0.29214054510158943]
	TIME [epoch: 87 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1569498850089949		[learning rate: 0.0016362]
	Learning Rate: 0.00163624
	LOSS [training: 0.1569498850089949 | validation: 0.32382714068560864]
	TIME [epoch: 87 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15469100166326794		[learning rate: 0.001629]
	Learning Rate: 0.00162901
	LOSS [training: 0.15469100166326794 | validation: 0.29425653731391255]
	TIME [epoch: 87.1 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16236795968707193		[learning rate: 0.0016218]
	Learning Rate: 0.00162181
	LOSS [training: 0.16236795968707193 | validation: 0.32529856164252535]
	TIME [epoch: 87.1 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15879749016321762		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.15879749016321762 | validation: 0.2971681056992506]
	TIME [epoch: 87.1 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15816076206228943		[learning rate: 0.0016075]
	Learning Rate: 0.00160751
	LOSS [training: 0.15816076206228943 | validation: 0.2935962666557092]
	TIME [epoch: 87 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15882018119117963		[learning rate: 0.0016004]
	Learning Rate: 0.00160041
	LOSS [training: 0.15882018119117963 | validation: 0.2996909480641615]
	TIME [epoch: 87.1 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16142249998133149		[learning rate: 0.0015933]
	Learning Rate: 0.00159334
	LOSS [training: 0.16142249998133149 | validation: 0.33138052712897614]
	TIME [epoch: 87.1 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1589591968795105		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.1589591968795105 | validation: 0.31464796548089935]
	TIME [epoch: 87.1 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1542971109423979		[learning rate: 0.0015793]
	Learning Rate: 0.00157929
	LOSS [training: 0.1542971109423979 | validation: 0.31661205299927986]
	TIME [epoch: 87.1 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15620786277008886		[learning rate: 0.0015723]
	Learning Rate: 0.00157231
	LOSS [training: 0.15620786277008886 | validation: 0.30310142727644823]
	TIME [epoch: 87.1 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15428726037915402		[learning rate: 0.0015654]
	Learning Rate: 0.00156536
	LOSS [training: 0.15428726037915402 | validation: 0.30354184619500163]
	TIME [epoch: 87.2 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15150575982704897		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.15150575982704897 | validation: 0.29973487360202666]
	TIME [epoch: 87.1 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16193494355648408		[learning rate: 0.0015516]
	Learning Rate: 0.00155156
	LOSS [training: 0.16193494355648408 | validation: 0.279294183502416]
	TIME [epoch: 87.1 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v14b_20240716_181052/states/model_facs_v2_dec2b_2dpca_v14b_461.pth
	Model improved!!!
EPOCH 462/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16496839847982173		[learning rate: 0.0015447]
	Learning Rate: 0.00154471
	LOSS [training: 0.16496839847982173 | validation: 0.31870565403782947]
	TIME [epoch: 87.2 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15291394988175935		[learning rate: 0.0015379]
	Learning Rate: 0.00153788
	LOSS [training: 0.15291394988175935 | validation: 0.2984692588147821]
	TIME [epoch: 87.1 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15831208595620144		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.15831208595620144 | validation: 0.3094281832931465]
	TIME [epoch: 87.1 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16463262892551495		[learning rate: 0.0015243]
	Learning Rate: 0.00152432
	LOSS [training: 0.16463262892551495 | validation: 0.3166735521001264]
	TIME [epoch: 87.1 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1512080217892124		[learning rate: 0.0015176]
	Learning Rate: 0.00151759
	LOSS [training: 0.1512080217892124 | validation: 0.3323430853979712]
	TIME [epoch: 87.1 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15921406800510035		[learning rate: 0.0015109]
	Learning Rate: 0.00151088
	LOSS [training: 0.15921406800510035 | validation: 0.3004929876795838]
	TIME [epoch: 87.1 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15953728902595657		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.15953728902595657 | validation: 0.322236060099499]
	TIME [epoch: 87.1 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16104825495058328		[learning rate: 0.0014976]
	Learning Rate: 0.00149756
	LOSS [training: 0.16104825495058328 | validation: 0.30077401801092074]
	TIME [epoch: 87.2 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17027057411596036		[learning rate: 0.0014909]
	Learning Rate: 0.00149094
	LOSS [training: 0.17027057411596036 | validation: 0.32316279838432693]
	TIME [epoch: 87.1 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16001360595156844		[learning rate: 0.0014844]
	Learning Rate: 0.00148436
	LOSS [training: 0.16001360595156844 | validation: 0.3074779260402144]
	TIME [epoch: 87.1 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15796975193954305		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.15796975193954305 | validation: 0.3035100638563644]
	TIME [epoch: 87.2 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1575028557359019		[learning rate: 0.0014713]
	Learning Rate: 0.00147127
	LOSS [training: 0.1575028557359019 | validation: 0.29900067619293835]
	TIME [epoch: 87.1 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16196460274326907		[learning rate: 0.0014648]
	Learning Rate: 0.00146477
	LOSS [training: 0.16196460274326907 | validation: 0.32399458108897666]
	TIME [epoch: 87.1 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16343542818497905		[learning rate: 0.0014583]
	Learning Rate: 0.0014583
	LOSS [training: 0.16343542818497905 | validation: 0.2964445472886003]
	TIME [epoch: 87.1 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15911739128067603		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.15911739128067603 | validation: 0.33218614914714023]
	TIME [epoch: 87.1 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15523984621005144		[learning rate: 0.0014454]
	Learning Rate: 0.00144544
	LOSS [training: 0.15523984621005144 | validation: 0.29997181475084783]
	TIME [epoch: 87.1 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16104236012537199		[learning rate: 0.0014391]
	Learning Rate: 0.00143905
	LOSS [training: 0.16104236012537199 | validation: 0.3286100712708908]
	TIME [epoch: 87.1 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1627030750700556		[learning rate: 0.0014327]
	Learning Rate: 0.0014327
	LOSS [training: 0.1627030750700556 | validation: 0.2951535159176971]
	TIME [epoch: 87.1 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15708989326500233		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.15708989326500233 | validation: 0.29348581277865554]
	TIME [epoch: 87 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15773487072809023		[learning rate: 0.0014201]
	Learning Rate: 0.00142006
	LOSS [training: 0.15773487072809023 | validation: 0.29285744064437863]
	TIME [epoch: 87 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.160616272864661		[learning rate: 0.0014138]
	Learning Rate: 0.00141379
	LOSS [training: 0.160616272864661 | validation: 0.30974695676784647]
	TIME [epoch: 87.1 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15644985279715312		[learning rate: 0.0014075]
	Learning Rate: 0.00140754
	LOSS [training: 0.15644985279715312 | validation: 0.29956625704294465]
	TIME [epoch: 87.1 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15317074628235716		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.15317074628235716 | validation: 0.2985642061355874]
	TIME [epoch: 87.1 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1589059960917696		[learning rate: 0.0013951]
	Learning Rate: 0.00139513
	LOSS [training: 0.1589059960917696 | validation: 0.3151752989520219]
	TIME [epoch: 87 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1563014368168682		[learning rate: 0.001389]
	Learning Rate: 0.00138897
	LOSS [training: 0.1563014368168682 | validation: 0.32031524285542773]
	TIME [epoch: 87 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15211246015225965		[learning rate: 0.0013828]
	Learning Rate: 0.00138283
	LOSS [training: 0.15211246015225965 | validation: 0.2898753918567691]
	TIME [epoch: 87.1 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1610210988492428		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.1610210988492428 | validation: 0.31048951524062807]
	TIME [epoch: 87.1 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16872920472320746		[learning rate: 0.0013706]
	Learning Rate: 0.00137064
	LOSS [training: 0.16872920472320746 | validation: 0.2994857265347206]
	TIME [epoch: 87.1 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16500040367768914		[learning rate: 0.0013646]
	Learning Rate: 0.00136458
	LOSS [training: 0.16500040367768914 | validation: 0.3009553870881823]
	TIME [epoch: 87.1 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1600048208511735		[learning rate: 0.0013586]
	Learning Rate: 0.00135855
	LOSS [training: 0.1600048208511735 | validation: 0.2896786168947407]
	TIME [epoch: 87.1 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16397976688247956		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.16397976688247956 | validation: 0.3128590196202353]
	TIME [epoch: 87.1 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.152658885771397		[learning rate: 0.0013466]
	Learning Rate: 0.00134658
	LOSS [training: 0.152658885771397 | validation: 0.30571462827764573]
	TIME [epoch: 87.1 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15581379464718895		[learning rate: 0.0013406]
	Learning Rate: 0.00134063
	LOSS [training: 0.15581379464718895 | validation: 0.31524059422884015]
	TIME [epoch: 87 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16073657613246609		[learning rate: 0.0013347]
	Learning Rate: 0.0013347
	LOSS [training: 0.16073657613246609 | validation: 0.32800593548270973]
	TIME [epoch: 87.1 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1586611894613515		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.1586611894613515 | validation: 0.3016037425006604]
	TIME [epoch: 87.1 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14882635984946918		[learning rate: 0.0013229]
	Learning Rate: 0.00132293
	LOSS [training: 0.14882635984946918 | validation: 0.29316873723900244]
	TIME [epoch: 87.1 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15743409831107108		[learning rate: 0.0013171]
	Learning Rate: 0.00131709
	LOSS [training: 0.15743409831107108 | validation: 0.32006917123922046]
	TIME [epoch: 87.1 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16526510968722516		[learning rate: 0.0013113]
	Learning Rate: 0.00131127
	LOSS [training: 0.16526510968722516 | validation: 0.2986588063870052]
	TIME [epoch: 87.1 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15815840759523542		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.15815840759523542 | validation: 0.30150517389427944]
	TIME [epoch: 87.1 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16516314548939195		[learning rate: 0.0012997]
	Learning Rate: 0.00129971
	LOSS [training: 0.16516314548939195 | validation: 0.3006294180161489]
	TIME [epoch: 87.1 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15605521792634622		[learning rate: 0.001294]
	Learning Rate: 0.00129397
	LOSS [training: 0.15605521792634622 | validation: 0.3103931416313834]
	TIME [epoch: 87 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15902938020063967		[learning rate: 0.0012882]
	Learning Rate: 0.00128825
	LOSS [training: 0.15902938020063967 | validation: 0.29487201918586736]
	TIME [epoch: 87 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1582061018014704		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.1582061018014704 | validation: 0.35060393442390014]
	TIME [epoch: 87 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15184698458205223		[learning rate: 0.0012769]
	Learning Rate: 0.00127689
	LOSS [training: 0.15184698458205223 | validation: 0.3016291603163811]
	TIME [epoch: 87 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15876742539780925		[learning rate: 0.0012712]
	Learning Rate: 0.00127125
	LOSS [training: 0.15876742539780925 | validation: 0.29279962670492354]
	TIME [epoch: 87.1 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15843595742569078		[learning rate: 0.0012656]
	Learning Rate: 0.00126563
	LOSS [training: 0.15843595742569078 | validation: 0.29681553334282895]
	TIME [epoch: 87 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14898993973488994		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.14898993973488994 | validation: 0.30276575633101915]
	TIME [epoch: 87.1 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15515255117449248		[learning rate: 0.0012545]
	Learning Rate: 0.00125447
	LOSS [training: 0.15515255117449248 | validation: 0.30239360667319554]
	TIME [epoch: 87 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1671494760661069		[learning rate: 0.0012489]
	Learning Rate: 0.00124893
	LOSS [training: 0.1671494760661069 | validation: 0.31007065682517065]
	TIME [epoch: 87 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1601746988909501		[learning rate: 0.0012434]
	Learning Rate: 0.00124341
	LOSS [training: 0.1601746988909501 | validation: 0.3074254481303974]
	TIME [epoch: 87 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15933142238025047		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.15933142238025047 | validation: 0.2944749436998774]
	TIME [epoch: 87.1 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15152825433439782		[learning rate: 0.0012324]
	Learning Rate: 0.00123245
	LOSS [training: 0.15152825433439782 | validation: 0.3185317174777787]
	TIME [epoch: 87.1 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1615587148223054		[learning rate: 0.001227]
	Learning Rate: 0.001227
	LOSS [training: 0.1615587148223054 | validation: 0.3093019432283098]
	TIME [epoch: 87 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15639465363864297		[learning rate: 0.0012216]
	Learning Rate: 0.00122158
	LOSS [training: 0.15639465363864297 | validation: 0.2894897473450363]
	TIME [epoch: 87 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15784455038464557		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.15784455038464557 | validation: 0.3142560233655859]
	TIME [epoch: 87 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15290832512594704		[learning rate: 0.0012108]
	Learning Rate: 0.00121081
	LOSS [training: 0.15290832512594704 | validation: 0.2863862171184144]
	TIME [epoch: 87 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.159650224782395		[learning rate: 0.0012055]
	Learning Rate: 0.00120546
	LOSS [training: 0.159650224782395 | validation: 0.2999661554503403]
	TIME [epoch: 87.1 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16206495058411255		[learning rate: 0.0012001]
	Learning Rate: 0.00120014
	LOSS [training: 0.16206495058411255 | validation: 0.30937401912947543]
	TIME [epoch: 87 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15561636977448984		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.15561636977448984 | validation: 0.3186914230272675]
	TIME [epoch: 87.1 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15746068239407762		[learning rate: 0.0011896]
	Learning Rate: 0.00118956
	LOSS [training: 0.15746068239407762 | validation: 0.3223843062605887]
	TIME [epoch: 87 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15996450763151976		[learning rate: 0.0011843]
	Learning Rate: 0.0011843
	LOSS [training: 0.15996450763151976 | validation: 0.2846757473204337]
	TIME [epoch: 87.1 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16071634175731955		[learning rate: 0.0011791]
	Learning Rate: 0.00117907
	LOSS [training: 0.16071634175731955 | validation: 0.30974508802854567]
	TIME [epoch: 87.1 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1565528301922669		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.1565528301922669 | validation: 0.30823169112356263]
	TIME [epoch: 87.1 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15004712436443227		[learning rate: 0.0011687]
	Learning Rate: 0.00116867
	LOSS [training: 0.15004712436443227 | validation: 0.32552647633083376]
	TIME [epoch: 87.1 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15318227545739943		[learning rate: 0.0011635]
	Learning Rate: 0.00116351
	LOSS [training: 0.15318227545739943 | validation: 0.31270498041688166]
	TIME [epoch: 87.1 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1548059073078612		[learning rate: 0.0011584]
	Learning Rate: 0.00115837
	LOSS [training: 0.1548059073078612 | validation: 0.298877070326069]
	TIME [epoch: 87 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15588886643319383		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.15588886643319383 | validation: 0.30813446403550676]
	TIME [epoch: 87.1 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15222479910969075		[learning rate: 0.0011482]
	Learning Rate: 0.00114815
	LOSS [training: 0.15222479910969075 | validation: 0.2999661828132088]
	TIME [epoch: 87.1 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16066181180165		[learning rate: 0.0011431]
	Learning Rate: 0.00114308
	LOSS [training: 0.16066181180165 | validation: 0.29236602760830654]
	TIME [epoch: 87.1 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15445360334345226		[learning rate: 0.001138]
	Learning Rate: 0.00113803
	LOSS [training: 0.15445360334345226 | validation: 0.30243590725503866]
	TIME [epoch: 87.1 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14744608469023385		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.14744608469023385 | validation: 0.30221270508266984]
	TIME [epoch: 87.1 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15432316872911303		[learning rate: 0.001128]
	Learning Rate: 0.001128
	LOSS [training: 0.15432316872911303 | validation: 0.32505656694702817]
	TIME [epoch: 87.1 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15244165996039843		[learning rate: 0.001123]
	Learning Rate: 0.00112301
	LOSS [training: 0.15244165996039843 | validation: 0.30844570870409754]
	TIME [epoch: 87.1 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16077517676014325		[learning rate: 0.0011181]
	Learning Rate: 0.00111805
	LOSS [training: 0.16077517676014325 | validation: 0.302602866500912]
	TIME [epoch: 87 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15776580236152002		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.15776580236152002 | validation: 0.30280287769161746]
	TIME [epoch: 87 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1537458467428326		[learning rate: 0.0011082]
	Learning Rate: 0.00110819
	LOSS [training: 0.1537458467428326 | validation: 0.293747244734132]
	TIME [epoch: 87 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1611204945191862		[learning rate: 0.0011033]
	Learning Rate: 0.0011033
	LOSS [training: 0.1611204945191862 | validation: 0.2986751637611142]
	TIME [epoch: 87 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15658926866152584		[learning rate: 0.0010984]
	Learning Rate: 0.00109842
	LOSS [training: 0.15658926866152584 | validation: 0.3054401826075829]
	TIME [epoch: 87 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15799644431868587		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.15799644431868587 | validation: 0.3170043431412823]
	TIME [epoch: 87 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15668614603766287		[learning rate: 0.0010887]
	Learning Rate: 0.00108874
	LOSS [training: 0.15668614603766287 | validation: 0.3143864784947465]
	TIME [epoch: 87 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15108920214560376		[learning rate: 0.0010839]
	Learning Rate: 0.00108393
	LOSS [training: 0.15108920214560376 | validation: 0.2936581128632931]
	TIME [epoch: 87 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16234528077061722		[learning rate: 0.0010791]
	Learning Rate: 0.00107914
	LOSS [training: 0.16234528077061722 | validation: 0.29196973074607135]
	TIME [epoch: 87.1 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14967168999655053		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.14967168999655053 | validation: 0.3023523667431636]
	TIME [epoch: 87.1 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15285808749828372		[learning rate: 0.0010696]
	Learning Rate: 0.00106962
	LOSS [training: 0.15285808749828372 | validation: 0.31892910308286576]
	TIME [epoch: 87.1 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16147261061488308		[learning rate: 0.0010649]
	Learning Rate: 0.0010649
	LOSS [training: 0.16147261061488308 | validation: 0.31736614088074866]
	TIME [epoch: 87.1 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1522106447477051		[learning rate: 0.0010602]
	Learning Rate: 0.00106019
	LOSS [training: 0.1522106447477051 | validation: 0.2958077565421058]
	TIME [epoch: 87.1 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16361338247824025		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.16361338247824025 | validation: 0.29637909275508845]
	TIME [epoch: 87.1 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15955242689966304		[learning rate: 0.0010508]
	Learning Rate: 0.00105084
	LOSS [training: 0.15955242689966304 | validation: 0.2941076760797026]
	TIME [epoch: 87.1 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16131789417663622		[learning rate: 0.0010462]
	Learning Rate: 0.0010462
	LOSS [training: 0.16131789417663622 | validation: 0.29254174453035897]
	TIME [epoch: 87.1 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15834809863758273		[learning rate: 0.0010416]
	Learning Rate: 0.00104158
	LOSS [training: 0.15834809863758273 | validation: 0.31208584946930423]
	TIME [epoch: 87.1 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15638320274753886		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.15638320274753886 | validation: 0.31206967656718954]
	TIME [epoch: 87.1 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1517355471748335		[learning rate: 0.0010324]
	Learning Rate: 0.0010324
	LOSS [training: 0.1517355471748335 | validation: 0.31400359691005825]
	TIME [epoch: 87.1 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15381375643934736		[learning rate: 0.0010278]
	Learning Rate: 0.00102783
	LOSS [training: 0.15381375643934736 | validation: 0.29799711059638806]
	TIME [epoch: 87.1 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15711960371412173		[learning rate: 0.0010233]
	Learning Rate: 0.00102329
	LOSS [training: 0.15711960371412173 | validation: 0.3059963204870807]
	TIME [epoch: 87.1 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15687180319911512		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.15687180319911512 | validation: 0.2981377206819296]
	TIME [epoch: 87.1 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14783299375372064		[learning rate: 0.0010143]
	Learning Rate: 0.00101427
	LOSS [training: 0.14783299375372064 | validation: 0.29202594190613573]
	TIME [epoch: 87.1 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15509274519361407		[learning rate: 0.0010098]
	Learning Rate: 0.00100979
	LOSS [training: 0.15509274519361407 | validation: 0.3198948454695751]
	TIME [epoch: 87.1 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15316369441415306		[learning rate: 0.0010053]
	Learning Rate: 0.00100533
	LOSS [training: 0.15316369441415306 | validation: 0.3077593677658689]
	TIME [epoch: 87.1 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15390672751341442		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.15390672751341442 | validation: 0.29761786295863146]
	TIME [epoch: 87.1 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16004073657590479		[learning rate: 0.00099646]
	Learning Rate: 0.000996464
	LOSS [training: 0.16004073657590479 | validation: 0.3105560616700733]
	TIME [epoch: 87.1 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16051142160504808		[learning rate: 0.00099206]
	Learning Rate: 0.000992061
	LOSS [training: 0.16051142160504808 | validation: 0.315006852975721]
	TIME [epoch: 87.1 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16110605159138577		[learning rate: 0.00098768]
	Learning Rate: 0.000987678
	LOSS [training: 0.16110605159138577 | validation: 0.3325603941665926]
	TIME [epoch: 87.1 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15557614975850478		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.15557614975850478 | validation: 0.29698284902777083]
	TIME [epoch: 87.1 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14707541228975424		[learning rate: 0.00097897]
	Learning Rate: 0.00097897
	LOSS [training: 0.14707541228975424 | validation: 0.3141584176086909]
	TIME [epoch: 87.1 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1562394552440863		[learning rate: 0.00097464]
	Learning Rate: 0.000974644
	LOSS [training: 0.1562394552440863 | validation: 0.29096746517683003]
	TIME [epoch: 87.1 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15837084566360263		[learning rate: 0.00097034]
	Learning Rate: 0.000970338
	LOSS [training: 0.15837084566360263 | validation: 0.29990492626398607]
	TIME [epoch: 87.1 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15717496582879442		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.15717496582879442 | validation: 0.3193277519888308]
	TIME [epoch: 87.1 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15347705765402356		[learning rate: 0.00096178]
	Learning Rate: 0.000961783
	LOSS [training: 0.15347705765402356 | validation: 0.2865378324542415]
	TIME [epoch: 87.1 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1548735998065326		[learning rate: 0.00095753]
	Learning Rate: 0.000957533
	LOSS [training: 0.1548735998065326 | validation: 0.2974750558149869]
	TIME [epoch: 87.1 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15706637410991903		[learning rate: 0.0009533]
	Learning Rate: 0.000953303
	LOSS [training: 0.15706637410991903 | validation: 0.3006896709635155]
	TIME [epoch: 87.1 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1555233762708078		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.1555233762708078 | validation: 0.29561822279696004]
	TIME [epoch: 87.1 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15843989021515392		[learning rate: 0.0009449]
	Learning Rate: 0.000944897
	LOSS [training: 0.15843989021515392 | validation: 0.2855334128697314]
	TIME [epoch: 87.1 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1513070983882821		[learning rate: 0.00094072]
	Learning Rate: 0.000940723
	LOSS [training: 0.1513070983882821 | validation: 0.3165725999246897]
	TIME [epoch: 87.1 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15335843986367875		[learning rate: 0.00093657]
	Learning Rate: 0.000936566
	LOSS [training: 0.15335843986367875 | validation: 0.3121371185944648]
	TIME [epoch: 87.1 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1639606760540522		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.1639606760540522 | validation: 0.30934407570739597]
	TIME [epoch: 87.1 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15405074134571767		[learning rate: 0.00092831]
	Learning Rate: 0.000928309
	LOSS [training: 0.15405074134571767 | validation: 0.2948809633741637]
	TIME [epoch: 87.1 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16350368010480784		[learning rate: 0.00092421]
	Learning Rate: 0.000924207
	LOSS [training: 0.16350368010480784 | validation: 0.3014439021604931]
	TIME [epoch: 87.1 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1619828159463143		[learning rate: 0.00092012]
	Learning Rate: 0.000920124
	LOSS [training: 0.1619828159463143 | validation: 0.30473374737572917]
	TIME [epoch: 87.1 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15059462901992787		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.15059462901992787 | validation: 0.2936028547160589]
	TIME [epoch: 87.1 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16090856052197552		[learning rate: 0.00091201]
	Learning Rate: 0.000912011
	LOSS [training: 0.16090856052197552 | validation: 0.29419377152942383]
	TIME [epoch: 87.2 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16360838408314932		[learning rate: 0.00090798]
	Learning Rate: 0.000907981
	LOSS [training: 0.16360838408314932 | validation: 0.30426459454582144]
	TIME [epoch: 87.1 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.150182401822734		[learning rate: 0.00090397]
	Learning Rate: 0.00090397
	LOSS [training: 0.150182401822734 | validation: 0.3029476369725152]
	TIME [epoch: 87.1 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17282200957707253		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.17282200957707253 | validation: 0.3069029088209006]
	TIME [epoch: 87 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16797452160365767		[learning rate: 0.000896]
	Learning Rate: 0.000895999
	LOSS [training: 0.16797452160365767 | validation: 0.3058589270944832]
	TIME [epoch: 87.1 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16003328239005665		[learning rate: 0.00089204]
	Learning Rate: 0.000892041
	LOSS [training: 0.16003328239005665 | validation: 0.31038965509072636]
	TIME [epoch: 87.1 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14704199727353848		[learning rate: 0.0008881]
	Learning Rate: 0.000888099
	LOSS [training: 0.14704199727353848 | validation: 0.3219914634056619]
	TIME [epoch: 87 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16045317789729555		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.16045317789729555 | validation: 0.29762599643071125]
	TIME [epoch: 87 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15615808946147675		[learning rate: 0.00088027]
	Learning Rate: 0.000880269
	LOSS [training: 0.15615808946147675 | validation: 0.293495441884044]
	TIME [epoch: 87 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16117625553488474		[learning rate: 0.00087638]
	Learning Rate: 0.00087638
	LOSS [training: 0.16117625553488474 | validation: 0.29870657179524096]
	TIME [epoch: 87 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14885656970821087		[learning rate: 0.00087251]
	Learning Rate: 0.000872508
	LOSS [training: 0.14885656970821087 | validation: 0.31207589352533316]
	TIME [epoch: 87 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15108899310947602		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.15108899310947602 | validation: 0.29059980535272645]
	TIME [epoch: 87 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14920567451593075		[learning rate: 0.00086481]
	Learning Rate: 0.000864815
	LOSS [training: 0.14920567451593075 | validation: 0.29698657615889795]
	TIME [epoch: 87 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15809614518390278		[learning rate: 0.00086099]
	Learning Rate: 0.000860994
	LOSS [training: 0.15809614518390278 | validation: 0.3139490322212403]
	TIME [epoch: 87.1 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1574854947232634		[learning rate: 0.00085719]
	Learning Rate: 0.00085719
	LOSS [training: 0.1574854947232634 | validation: 0.30313193996836707]
	TIME [epoch: 87.1 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15643893113499163		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.15643893113499163 | validation: 0.30782903988818744]
	TIME [epoch: 87.1 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15845368118312245		[learning rate: 0.00084963]
	Learning Rate: 0.000849632
	LOSS [training: 0.15845368118312245 | validation: 0.30719312288449496]
	TIME [epoch: 87 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1583316622608713		[learning rate: 0.00084588]
	Learning Rate: 0.000845878
	LOSS [training: 0.1583316622608713 | validation: 0.30587278915601607]
	TIME [epoch: 87 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15124567457951782		[learning rate: 0.00084214]
	Learning Rate: 0.000842141
	LOSS [training: 0.15124567457951782 | validation: 0.3063356028269664]
	TIME [epoch: 87 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16014657796051082		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.16014657796051082 | validation: 0.31036429942535426]
	TIME [epoch: 87.1 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15496189639480526		[learning rate: 0.00083472]
	Learning Rate: 0.000834715
	LOSS [training: 0.15496189639480526 | validation: 0.3071498110721943]
	TIME [epoch: 87.1 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16024289508753187		[learning rate: 0.00083103]
	Learning Rate: 0.000831028
	LOSS [training: 0.16024289508753187 | validation: 0.30041306516266497]
	TIME [epoch: 87.1 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15376863568280585		[learning rate: 0.00082736]
	Learning Rate: 0.000827356
	LOSS [training: 0.15376863568280585 | validation: 0.2998728147054775]
	TIME [epoch: 87.1 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14841893584041904		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.14841893584041904 | validation: 0.3003663959003648]
	TIME [epoch: 87.1 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1598172310154065		[learning rate: 0.00082006]
	Learning Rate: 0.000820061
	LOSS [training: 0.1598172310154065 | validation: 0.3139925817856302]
	TIME [epoch: 87.1 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1526108694340098		[learning rate: 0.00081644]
	Learning Rate: 0.000816438
	LOSS [training: 0.1526108694340098 | validation: 0.2842491616194865]
	TIME [epoch: 87.1 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14869078516678438		[learning rate: 0.00081283]
	Learning Rate: 0.000812831
	LOSS [training: 0.14869078516678438 | validation: 0.31935528440511013]
	TIME [epoch: 87.1 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16163313539092808		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.16163313539092808 | validation: 0.29767635421829447]
	TIME [epoch: 87.1 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1537011916861387		[learning rate: 0.00080566]
	Learning Rate: 0.000805664
	LOSS [training: 0.1537011916861387 | validation: 0.3099274661628832]
	TIME [epoch: 87.1 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1550055441201837		[learning rate: 0.0008021]
	Learning Rate: 0.000802104
	LOSS [training: 0.1550055441201837 | validation: 0.291999879166886]
	TIME [epoch: 87.2 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16269703422242876		[learning rate: 0.00079856]
	Learning Rate: 0.00079856
	LOSS [training: 0.16269703422242876 | validation: 0.3138834883844602]
	TIME [epoch: 87.2 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14755526119178547		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.14755526119178547 | validation: 0.3106385672006904]
	TIME [epoch: 87.2 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15414381894316032		[learning rate: 0.00079152]
	Learning Rate: 0.000791519
	LOSS [training: 0.15414381894316032 | validation: 0.3264920793595527]
	TIME [epoch: 87.2 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1593889919702577		[learning rate: 0.00078802]
	Learning Rate: 0.000788022
	LOSS [training: 0.1593889919702577 | validation: 0.29482493199767723]
	TIME [epoch: 87.1 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15986550535066732		[learning rate: 0.00078454]
	Learning Rate: 0.000784541
	LOSS [training: 0.15986550535066732 | validation: 0.29570397478975247]
	TIME [epoch: 87.1 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1608322517916867		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.1608322517916867 | validation: 0.3251100615721647]
	TIME [epoch: 87.1 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15867555930419494		[learning rate: 0.00077762]
	Learning Rate: 0.000777623
	LOSS [training: 0.15867555930419494 | validation: 0.2929125290990224]
	TIME [epoch: 87.2 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15684069585929966		[learning rate: 0.00077419]
	Learning Rate: 0.000774188
	LOSS [training: 0.15684069585929966 | validation: 0.30209265961632537]
	TIME [epoch: 87.1 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15383253000406483		[learning rate: 0.00077077]
	Learning Rate: 0.000770767
	LOSS [training: 0.15383253000406483 | validation: 0.2962714675076573]
	TIME [epoch: 87.1 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15106904066921303		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.15106904066921303 | validation: 0.30646602851070687]
	TIME [epoch: 87.1 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15793602436368373		[learning rate: 0.00076397]
	Learning Rate: 0.000763971
	LOSS [training: 0.15793602436368373 | validation: 0.3011773657446356]
	TIME [epoch: 87.1 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15042120899829858		[learning rate: 0.0007606]
	Learning Rate: 0.000760596
	LOSS [training: 0.15042120899829858 | validation: 0.30754364220744446]
	TIME [epoch: 87.1 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1586395720143752		[learning rate: 0.00075724]
	Learning Rate: 0.000757235
	LOSS [training: 0.1586395720143752 | validation: 0.3102383031091236]
	TIME [epoch: 87.1 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15100337311619622		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.15100337311619622 | validation: 0.31901624491185127]
	TIME [epoch: 87 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1582121072843051		[learning rate: 0.00075056]
	Learning Rate: 0.000750559
	LOSS [training: 0.1582121072843051 | validation: 0.2939729252188045]
	TIME [epoch: 87.1 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1547521201159327		[learning rate: 0.00074724]
	Learning Rate: 0.000747242
	LOSS [training: 0.1547521201159327 | validation: 0.3017778272962014]
	TIME [epoch: 87.1 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15792978859444234		[learning rate: 0.00074394]
	Learning Rate: 0.000743941
	LOSS [training: 0.15792978859444234 | validation: 0.3190663895988016]
	TIME [epoch: 87.2 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15906943318724193		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.15906943318724193 | validation: 0.2971460474211937]
	TIME [epoch: 87.1 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15951332351954162		[learning rate: 0.00073738]
	Learning Rate: 0.000737382
	LOSS [training: 0.15951332351954162 | validation: 0.3097477175299698]
	TIME [epoch: 87.1 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15134429971835678		[learning rate: 0.00073412]
	Learning Rate: 0.000734124
	LOSS [training: 0.15134429971835678 | validation: 0.3074074650739689]
	TIME [epoch: 87.1 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16348203896902833		[learning rate: 0.00073088]
	Learning Rate: 0.00073088
	LOSS [training: 0.16348203896902833 | validation: 0.30856464501889946]
	TIME [epoch: 87.1 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16101021519490794		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 0.16101021519490794 | validation: 0.29934840601046014]
	TIME [epoch: 87.1 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15663144398370657		[learning rate: 0.00072444]
	Learning Rate: 0.000724436
	LOSS [training: 0.15663144398370657 | validation: 0.3032139821373316]
	TIME [epoch: 87.1 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1543644888952945		[learning rate: 0.00072124]
	Learning Rate: 0.000721235
	LOSS [training: 0.1543644888952945 | validation: 0.2909980547230794]
	TIME [epoch: 87.1 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15549238513627278		[learning rate: 0.00071805]
	Learning Rate: 0.000718049
	LOSS [training: 0.15549238513627278 | validation: 0.29138909647127054]
	TIME [epoch: 87.1 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15470318270361258		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.15470318270361258 | validation: 0.3132760479674181]
	TIME [epoch: 87.1 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15298770395004962		[learning rate: 0.00071172]
	Learning Rate: 0.000711718
	LOSS [training: 0.15298770395004962 | validation: 0.31039548732670535]
	TIME [epoch: 87.1 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15719057630836422		[learning rate: 0.00070857]
	Learning Rate: 0.000708573
	LOSS [training: 0.15719057630836422 | validation: 0.29729725617105524]
	TIME [epoch: 87.1 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15005323085263347		[learning rate: 0.00070544]
	Learning Rate: 0.000705442
	LOSS [training: 0.15005323085263347 | validation: 0.29319488278444394]
	TIME [epoch: 87.1 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1480604367119269		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.1480604367119269 | validation: 0.3264610310490025]
	TIME [epoch: 87.1 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1569463074677412		[learning rate: 0.00069922]
	Learning Rate: 0.000699222
	LOSS [training: 0.1569463074677412 | validation: 0.292113051877515]
	TIME [epoch: 87.2 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15136682129852633		[learning rate: 0.00069613]
	Learning Rate: 0.000696133
	LOSS [training: 0.15136682129852633 | validation: 0.30558116623978815]
	TIME [epoch: 87.1 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14718328257826702		[learning rate: 0.00069306]
	Learning Rate: 0.000693058
	LOSS [training: 0.14718328257826702 | validation: 0.30803236492471375]
	TIME [epoch: 87.1 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1583535322621036		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 0.1583535322621036 | validation: 0.30681021000643366]
	TIME [epoch: 87.1 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1553961310238186		[learning rate: 0.00068695]
	Learning Rate: 0.000686947
	LOSS [training: 0.1553961310238186 | validation: 0.3006287486853258]
	TIME [epoch: 87.1 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15166340962625097		[learning rate: 0.00068391]
	Learning Rate: 0.000683912
	LOSS [training: 0.15166340962625097 | validation: 0.31447787089402224]
	TIME [epoch: 87.1 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15788026344095324		[learning rate: 0.00068089]
	Learning Rate: 0.00068089
	LOSS [training: 0.15788026344095324 | validation: 0.3186230430120243]
	TIME [epoch: 87.1 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1592590571985753		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 0.1592590571985753 | validation: 0.3092681423936341]
	TIME [epoch: 87.1 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15850051285047542		[learning rate: 0.00067489]
	Learning Rate: 0.000674887
	LOSS [training: 0.15850051285047542 | validation: 0.31244644603778843]
	TIME [epoch: 87.1 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15790159503325513		[learning rate: 0.0006719]
	Learning Rate: 0.000671905
	LOSS [training: 0.15790159503325513 | validation: 0.3133425211171138]
	TIME [epoch: 87.1 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1570236915309293		[learning rate: 0.00066894]
	Learning Rate: 0.000668936
	LOSS [training: 0.1570236915309293 | validation: 0.2944913688226425]
	TIME [epoch: 87.1 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15452332030114532		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 0.15452332030114532 | validation: 0.3023724745047108]
	TIME [epoch: 87.1 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1554635713306805		[learning rate: 0.00066304]
	Learning Rate: 0.000663038
	LOSS [training: 0.1554635713306805 | validation: 0.29445400831156704]
	TIME [epoch: 87.1 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15194817820160628		[learning rate: 0.00066011]
	Learning Rate: 0.000660109
	LOSS [training: 0.15194817820160628 | validation: 0.3091687439191075]
	TIME [epoch: 87.2 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16911662274085032		[learning rate: 0.00065719]
	Learning Rate: 0.000657192
	LOSS [training: 0.16911662274085032 | validation: 0.2897118034232101]
	TIME [epoch: 87.1 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1508745348098502		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 0.1508745348098502 | validation: 0.30150519511397206]
	TIME [epoch: 87.1 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1520038458852158		[learning rate: 0.0006514]
	Learning Rate: 0.000651398
	LOSS [training: 0.1520038458852158 | validation: 0.3162534270275895]
	TIME [epoch: 87.1 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.161328812379018		[learning rate: 0.00064852]
	Learning Rate: 0.00064852
	LOSS [training: 0.161328812379018 | validation: 0.3055226282054961]
	TIME [epoch: 87.2 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1580564879432926		[learning rate: 0.00064565]
	Learning Rate: 0.000645654
	LOSS [training: 0.1580564879432926 | validation: 0.3030878269513639]
	TIME [epoch: 87.1 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14935988974123693		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 0.14935988974123693 | validation: 0.3057010992487291]
	TIME [epoch: 87.1 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15201720933747004		[learning rate: 0.00063996]
	Learning Rate: 0.000639962
	LOSS [training: 0.15201720933747004 | validation: 0.303271429088674]
	TIME [epoch: 87.1 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1536440057263125		[learning rate: 0.00063713]
	Learning Rate: 0.000637134
	LOSS [training: 0.1536440057263125 | validation: 0.31051588186798973]
	TIME [epoch: 87.1 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v14b_20240716_181052/states/model_facs_v2_dec2b_2dpca_v14b_662.pth
Halted early. No improvement in validation loss for 200 epochs.
Finished training in 38550.986 seconds.
