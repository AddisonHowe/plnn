Args:
Namespace(name='model_facs_v4_dec2b_2dpca_v15', outdir='out/model_training/model_facs_v4_dec2b_2dpca_v15', training_data='data/training_data/facs_v4/pca/dec2_fitonsubset/transition2_subset_ce_pn_m_pc12/training', validation_data='data/training_data/facs_v4/pca/dec2_fitonsubset/transition2_subset_ce_pn_m_pc12/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=10, batch_size=50, patience=200, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, quadratic_a=1.0, quadratic_b=1.0, ndims=2, nparams=2, nsigs=2, ncells=100, ncells_sample=100, model_do_sample=False, dt=0.005, dt_schedule='stepped', dt_schedule_bounds=[50, 500, 1000], dt_schedule_scales=[0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', kernel='multiscale', bw_range=[0.2, 0.5, 0.9, 1.1, 1.3, 1.5, 2.0], optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 2833743520

Training model...

Saving initial model state to: out/model_training/model_facs_v4_dec2b_2dpca_v15_20240719_004754/states/model_facs_v4_dec2b_2dpca_v15_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0317314284143104		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0317314284143104 | validation: 0.9392115055948334]
	TIME [epoch: 25.7 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v15_20240719_004754/states/model_facs_v4_dec2b_2dpca_v15_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6799931026752036		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6799931026752036 | validation: 0.8316332535599209]
	TIME [epoch: 3.55 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v15_20240719_004754/states/model_facs_v4_dec2b_2dpca_v15_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5619830387760263		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5619830387760263 | validation: 0.7946931914215952]
	TIME [epoch: 3.54 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v15_20240719_004754/states/model_facs_v4_dec2b_2dpca_v15_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5602640923510475		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5602640923510475 | validation: 0.8521411998361741]
	TIME [epoch: 3.54 sec]
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5653210531084096		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5653210531084096 | validation: 0.6924799776126326]
	TIME [epoch: 3.56 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v15_20240719_004754/states/model_facs_v4_dec2b_2dpca_v15_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.511086772573454		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.511086772573454 | validation: 0.6487214246625252]
	TIME [epoch: 3.54 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v15_20240719_004754/states/model_facs_v4_dec2b_2dpca_v15_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46067329832988124		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.46067329832988124 | validation: 0.7222457708173284]
	TIME [epoch: 3.56 sec]
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4479198002572896		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4479198002572896 | validation: 0.6051095346447544]
	TIME [epoch: 3.56 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v15_20240719_004754/states/model_facs_v4_dec2b_2dpca_v15_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41699471020653794		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.41699471020653794 | validation: 0.779775574934629]
	TIME [epoch: 3.56 sec]
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4991914794823976		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4991914794823976 | validation: 0.7593480940465472]
	TIME [epoch: 3.55 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4008758422335414		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4008758422335414 | validation: 0.6162914082695609]
	TIME [epoch: 3.55 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38899407534745783		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.38899407534745783 | validation: 0.5311670208108985]
	TIME [epoch: 3.54 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v15_20240719_004754/states/model_facs_v4_dec2b_2dpca_v15_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3726848351299821		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3726848351299821 | validation: 0.48661443764282497]
	TIME [epoch: 3.53 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v15_20240719_004754/states/model_facs_v4_dec2b_2dpca_v15_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3045001826705534		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3045001826705534 | validation: 0.5616553869354632]
	TIME [epoch: 3.54 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3675935926644095		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3675935926644095 | validation: 0.6195581791583678]
	TIME [epoch: 3.55 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.423885331295754		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.423885331295754 | validation: 0.47151524163547887]
	TIME [epoch: 3.57 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v15_20240719_004754/states/model_facs_v4_dec2b_2dpca_v15_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3185197397908637		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3185197397908637 | validation: 0.4458306723723663]
	TIME [epoch: 3.54 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v15_20240719_004754/states/model_facs_v4_dec2b_2dpca_v15_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2792126658532126		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2792126658532126 | validation: 0.47674805223674255]
	TIME [epoch: 3.54 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3162147734172425		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3162147734172425 | validation: 0.5778934542704505]
	TIME [epoch: 3.56 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3731209516682715		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3731209516682715 | validation: 0.5195349099682696]
	TIME [epoch: 3.54 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29386985956998823		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.29386985956998823 | validation: 0.4490700587840963]
	TIME [epoch: 3.54 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24964756279362965		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24964756279362965 | validation: 0.4463276804157908]
	TIME [epoch: 3.56 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2785938024339092		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2785938024339092 | validation: 0.40628612405954506]
	TIME [epoch: 3.54 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v15_20240719_004754/states/model_facs_v4_dec2b_2dpca_v15_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2933092684756023		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2933092684756023 | validation: 0.5725484391831065]
	TIME [epoch: 3.54 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2824373345661819		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2824373345661819 | validation: 0.4080309918219216]
	TIME [epoch: 3.55 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2639260957377179		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2639260957377179 | validation: 0.43162974284134714]
	TIME [epoch: 3.54 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3096341605107763		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3096341605107763 | validation: 0.4016073804214188]
	TIME [epoch: 3.54 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v15_20240719_004754/states/model_facs_v4_dec2b_2dpca_v15_27.pth
	Model improved!!!
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2748918538414121		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2748918538414121 | validation: 0.4180156856892895]
	TIME [epoch: 3.54 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23611274065370588		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23611274065370588 | validation: 0.4179955620414008]
	TIME [epoch: 3.54 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23595175747970007		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23595175747970007 | validation: 0.4999458175482933]
	TIME [epoch: 3.54 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2965420317182373		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2965420317182373 | validation: 0.4218688437682252]
	TIME [epoch: 3.55 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23546903749363754		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23546903749363754 | validation: 0.41023762458320207]
	TIME [epoch: 3.55 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25892969613253586		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.25892969613253586 | validation: 0.41443664752617965]
	TIME [epoch: 3.54 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25271328473796145		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.25271328473796145 | validation: 0.42470623164106985]
	TIME [epoch: 3.55 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22012978476946488		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22012978476946488 | validation: 0.4162504204114898]
	TIME [epoch: 3.54 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23337308241165017		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23337308241165017 | validation: 0.4489739938606755]
	TIME [epoch: 3.55 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2626361806709978		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2626361806709978 | validation: 0.404831306774556]
	TIME [epoch: 3.54 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25252788314469404		[learning rate: 0.0099882]
	Learning Rate: 0.0099882
	LOSS [training: 0.25252788314469404 | validation: 0.43280935974221907]
	TIME [epoch: 3.55 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25395140802326843		[learning rate: 0.0099411]
	Learning Rate: 0.00994113
	LOSS [training: 0.25395140802326843 | validation: 0.4025731874898111]
	TIME [epoch: 3.54 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2743940651105356		[learning rate: 0.0098943]
	Learning Rate: 0.00989429
	LOSS [training: 0.2743940651105356 | validation: 0.374189539333637]
	TIME [epoch: 3.54 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v15_20240719_004754/states/model_facs_v4_dec2b_2dpca_v15_40.pth
	Model improved!!!
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2348264279004061		[learning rate: 0.0098477]
	Learning Rate: 0.00984767
	LOSS [training: 0.2348264279004061 | validation: 0.3685033858589509]
	TIME [epoch: 3.53 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v15_20240719_004754/states/model_facs_v4_dec2b_2dpca_v15_41.pth
	Model improved!!!
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24877595333851432		[learning rate: 0.0098013]
	Learning Rate: 0.00980126
	LOSS [training: 0.24877595333851432 | validation: 0.42565981282235144]
	TIME [epoch: 3.55 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2610364125634831		[learning rate: 0.0097551]
	Learning Rate: 0.00975508
	LOSS [training: 0.2610364125634831 | validation: 0.41147170186247944]
	TIME [epoch: 3.54 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21484688517074646		[learning rate: 0.0097091]
	Learning Rate: 0.00970911
	LOSS [training: 0.21484688517074646 | validation: 0.3668189849613155]
	TIME [epoch: 3.53 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v15_20240719_004754/states/model_facs_v4_dec2b_2dpca_v15_44.pth
	Model improved!!!
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2168315369264761		[learning rate: 0.0096634]
	Learning Rate: 0.00966336
	LOSS [training: 0.2168315369264761 | validation: 0.36238053823074895]
	TIME [epoch: 3.66 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v15_20240719_004754/states/model_facs_v4_dec2b_2dpca_v15_45.pth
	Model improved!!!
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24784131687970393		[learning rate: 0.0096178]
	Learning Rate: 0.00961783
	LOSS [training: 0.24784131687970393 | validation: 0.38110166589211397]
	TIME [epoch: 3.54 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20180012053781365		[learning rate: 0.0095725]
	Learning Rate: 0.00957251
	LOSS [training: 0.20180012053781365 | validation: 0.3586895911734676]
	TIME [epoch: 3.56 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v15_20240719_004754/states/model_facs_v4_dec2b_2dpca_v15_47.pth
	Model improved!!!
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24601484743360322		[learning rate: 0.0095274]
	Learning Rate: 0.0095274
	LOSS [training: 0.24601484743360322 | validation: 0.3384335651802872]
	TIME [epoch: 3.57 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v15_20240719_004754/states/model_facs_v4_dec2b_2dpca_v15_48.pth
	Model improved!!!
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21573698055390822		[learning rate: 0.0094825]
	Learning Rate: 0.0094825
	LOSS [training: 0.21573698055390822 | validation: 0.46571201800190754]
	TIME [epoch: 3.55 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23406690846981093		[learning rate: 0.0094378]
	Learning Rate: 0.00943782
	LOSS [training: 0.23406690846981093 | validation: 0.39488989915673]
	TIME [epoch: 3.53 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20743055863693605		[learning rate: 0.0093933]
	Learning Rate: 0.00939335
	LOSS [training: 0.20743055863693605 | validation: 0.4042723050863475]
	TIME [epoch: 26.8 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2526463532453368		[learning rate: 0.0093491]
	Learning Rate: 0.00934909
	LOSS [training: 0.2526463532453368 | validation: 0.38520446017603965]
	TIME [epoch: 6.81 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21704065135560566		[learning rate: 0.009305]
	Learning Rate: 0.00930503
	LOSS [training: 0.21704065135560566 | validation: 0.48023087769887896]
	TIME [epoch: 6.77 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22447441313724917		[learning rate: 0.0092612]
	Learning Rate: 0.00926119
	LOSS [training: 0.22447441313724917 | validation: 0.48272810498528823]
	TIME [epoch: 6.79 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2551984842550697		[learning rate: 0.0092175]
	Learning Rate: 0.00921755
	LOSS [training: 0.2551984842550697 | validation: 0.3785830384623519]
	TIME [epoch: 6.79 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21691133295145196		[learning rate: 0.0091741]
	Learning Rate: 0.00917411
	LOSS [training: 0.21691133295145196 | validation: 0.3833829802622759]
	TIME [epoch: 6.76 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21882940933486322		[learning rate: 0.0091309]
	Learning Rate: 0.00913088
	LOSS [training: 0.21882940933486322 | validation: 0.45526537217439333]
	TIME [epoch: 6.76 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1947971393296722		[learning rate: 0.0090879]
	Learning Rate: 0.00908786
	LOSS [training: 0.1947971393296722 | validation: 0.32636781447964247]
	TIME [epoch: 6.77 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v15_20240719_004754/states/model_facs_v4_dec2b_2dpca_v15_58.pth
	Model improved!!!
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21082731346906836		[learning rate: 0.009045]
	Learning Rate: 0.00904503
	LOSS [training: 0.21082731346906836 | validation: 0.3488880608450162]
	TIME [epoch: 6.75 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1937611634725354		[learning rate: 0.0090024]
	Learning Rate: 0.00900241
	LOSS [training: 0.1937611634725354 | validation: 0.35625567281569315]
	TIME [epoch: 6.75 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2130018142738574		[learning rate: 0.00896]
	Learning Rate: 0.00895999
	LOSS [training: 0.2130018142738574 | validation: 0.47793618418933737]
	TIME [epoch: 6.75 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20336275700722972		[learning rate: 0.0089178]
	Learning Rate: 0.00891777
	LOSS [training: 0.20336275700722972 | validation: 0.3579932090013479]
	TIME [epoch: 6.75 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23425907668788387		[learning rate: 0.0088758]
	Learning Rate: 0.00887575
	LOSS [training: 0.23425907668788387 | validation: 0.4611090854363118]
	TIME [epoch: 6.75 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19798542810479125		[learning rate: 0.0088339]
	Learning Rate: 0.00883393
	LOSS [training: 0.19798542810479125 | validation: 0.3655234379828268]
	TIME [epoch: 6.81 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19591590367414888		[learning rate: 0.0087923]
	Learning Rate: 0.0087923
	LOSS [training: 0.19591590367414888 | validation: 0.41128127907212086]
	TIME [epoch: 6.73 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17015045126793413		[learning rate: 0.0087509]
	Learning Rate: 0.00875087
	LOSS [training: 0.17015045126793413 | validation: 0.4452730304594067]
	TIME [epoch: 6.75 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20696315939132076		[learning rate: 0.0087096]
	Learning Rate: 0.00870964
	LOSS [training: 0.20696315939132076 | validation: 0.6314333910811706]
	TIME [epoch: 6.73 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3223827263496661		[learning rate: 0.0086686]
	Learning Rate: 0.00866859
	LOSS [training: 0.3223827263496661 | validation: 0.5554019651661276]
	TIME [epoch: 6.77 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21649829091750195		[learning rate: 0.0086277]
	Learning Rate: 0.00862775
	LOSS [training: 0.21649829091750195 | validation: 0.46485203255955376]
	TIME [epoch: 6.74 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19975651293972907		[learning rate: 0.0085871]
	Learning Rate: 0.00858709
	LOSS [training: 0.19975651293972907 | validation: 0.3646945367079079]
	TIME [epoch: 6.75 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18077841455426036		[learning rate: 0.0085466]
	Learning Rate: 0.00854663
	LOSS [training: 0.18077841455426036 | validation: 0.36881979484757055]
	TIME [epoch: 6.75 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20539037825614226		[learning rate: 0.0085064]
	Learning Rate: 0.00850636
	LOSS [training: 0.20539037825614226 | validation: 0.3242665873512863]
	TIME [epoch: 6.72 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v15_20240719_004754/states/model_facs_v4_dec2b_2dpca_v15_72.pth
	Model improved!!!
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20083502307239792		[learning rate: 0.0084663]
	Learning Rate: 0.00846627
	LOSS [training: 0.20083502307239792 | validation: 0.4597550477434547]
	TIME [epoch: 6.77 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22104935549079252		[learning rate: 0.0084264]
	Learning Rate: 0.00842638
	LOSS [training: 0.22104935549079252 | validation: 0.3537145357216364]
	TIME [epoch: 6.77 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19680613834571792		[learning rate: 0.0083867]
	Learning Rate: 0.00838667
	LOSS [training: 0.19680613834571792 | validation: 0.5461026654039172]
	TIME [epoch: 6.75 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21212535026426838		[learning rate: 0.0083472]
	Learning Rate: 0.00834715
	LOSS [training: 0.21212535026426838 | validation: 0.3333421807601652]
	TIME [epoch: 6.74 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1855883217242686		[learning rate: 0.0083078]
	Learning Rate: 0.00830782
	LOSS [training: 0.1855883217242686 | validation: 0.32363738154446264]
	TIME [epoch: 6.75 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v15_20240719_004754/states/model_facs_v4_dec2b_2dpca_v15_77.pth
	Model improved!!!
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17046048314131212		[learning rate: 0.0082687]
	Learning Rate: 0.00826867
	LOSS [training: 0.17046048314131212 | validation: 0.4163481254349573]
	TIME [epoch: 6.74 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21124451933175128		[learning rate: 0.0082297]
	Learning Rate: 0.00822971
	LOSS [training: 0.21124451933175128 | validation: 0.3294998492284215]
	TIME [epoch: 6.74 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21306671169511507		[learning rate: 0.0081909]
	Learning Rate: 0.00819093
	LOSS [training: 0.21306671169511507 | validation: 0.3660710105080285]
	TIME [epoch: 6.74 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19510216973836275		[learning rate: 0.0081523]
	Learning Rate: 0.00815233
	LOSS [training: 0.19510216973836275 | validation: 0.3330228744868246]
	TIME [epoch: 6.75 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18261542456451765		[learning rate: 0.0081139]
	Learning Rate: 0.00811392
	LOSS [training: 0.18261542456451765 | validation: 0.43600517897332414]
	TIME [epoch: 6.74 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19889776950605528		[learning rate: 0.0080757]
	Learning Rate: 0.00807569
	LOSS [training: 0.19889776950605528 | validation: 0.49095975251721735]
	TIME [epoch: 6.76 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2042987577623094		[learning rate: 0.0080376]
	Learning Rate: 0.00803763
	LOSS [training: 0.2042987577623094 | validation: 0.33808625440673346]
	TIME [epoch: 6.75 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16001196962523795		[learning rate: 0.0079998]
	Learning Rate: 0.00799976
	LOSS [training: 0.16001196962523795 | validation: 0.4339006414674122]
	TIME [epoch: 6.75 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1986574459996649		[learning rate: 0.0079621]
	Learning Rate: 0.00796206
	LOSS [training: 0.1986574459996649 | validation: 0.4219106706608049]
	TIME [epoch: 6.75 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20268551129589396		[learning rate: 0.0079245]
	Learning Rate: 0.00792455
	LOSS [training: 0.20268551129589396 | validation: 0.38497428487742463]
	TIME [epoch: 6.75 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21792236385251884		[learning rate: 0.0078872]
	Learning Rate: 0.0078872
	LOSS [training: 0.21792236385251884 | validation: 0.3428919138561084]
	TIME [epoch: 6.73 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17517093700461128		[learning rate: 0.00785]
	Learning Rate: 0.00785004
	LOSS [training: 0.17517093700461128 | validation: 0.4992988549937708]
	TIME [epoch: 6.75 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20838149009355617		[learning rate: 0.007813]
	Learning Rate: 0.00781305
	LOSS [training: 0.20838149009355617 | validation: 0.3227148198366057]
	TIME [epoch: 6.75 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v15_20240719_004754/states/model_facs_v4_dec2b_2dpca_v15_90.pth
	Model improved!!!
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17596498784376796		[learning rate: 0.0077762]
	Learning Rate: 0.00777623
	LOSS [training: 0.17596498784376796 | validation: 0.4866989819904109]
	TIME [epoch: 6.75 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3197759701756296		[learning rate: 0.0077396]
	Learning Rate: 0.00773959
	LOSS [training: 0.3197759701756296 | validation: 0.41350820759188417]
	TIME [epoch: 6.73 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21341275475460883		[learning rate: 0.0077031]
	Learning Rate: 0.00770312
	LOSS [training: 0.21341275475460883 | validation: 0.3549548462283256]
	TIME [epoch: 6.74 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19949702976961475		[learning rate: 0.0076668]
	Learning Rate: 0.00766682
	LOSS [training: 0.19949702976961475 | validation: 0.3968680454612772]
	TIME [epoch: 6.74 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14769737522282683		[learning rate: 0.0076307]
	Learning Rate: 0.0076307
	LOSS [training: 0.14769737522282683 | validation: 0.34035798423664415]
	TIME [epoch: 6.77 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15962515756019763		[learning rate: 0.0075947]
	Learning Rate: 0.00759474
	LOSS [training: 0.15962515756019763 | validation: 0.3080079552291009]
	TIME [epoch: 6.77 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v15_20240719_004754/states/model_facs_v4_dec2b_2dpca_v15_96.pth
	Model improved!!!
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20077331062839035		[learning rate: 0.007559]
	Learning Rate: 0.00755895
	LOSS [training: 0.20077331062839035 | validation: 0.37297757393809533]
	TIME [epoch: 6.76 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20705868408514203		[learning rate: 0.0075233]
	Learning Rate: 0.00752333
	LOSS [training: 0.20705868408514203 | validation: 0.3678621004375091]
	TIME [epoch: 6.74 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15575486809035138		[learning rate: 0.0074879]
	Learning Rate: 0.00748788
	LOSS [training: 0.15575486809035138 | validation: 0.3930228482041681]
	TIME [epoch: 6.74 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18448873430176685		[learning rate: 0.0074526]
	Learning Rate: 0.0074526
	LOSS [training: 0.18448873430176685 | validation: 0.38621056473322757]
	TIME [epoch: 6.74 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15882004542746747		[learning rate: 0.0074175]
	Learning Rate: 0.00741748
	LOSS [training: 0.15882004542746747 | validation: 0.41476037812539435]
	TIME [epoch: 6.73 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15098442726421465		[learning rate: 0.0073825]
	Learning Rate: 0.00738253
	LOSS [training: 0.15098442726421465 | validation: 0.37236568575276774]
	TIME [epoch: 6.75 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1767807667098362		[learning rate: 0.0073477]
	Learning Rate: 0.00734774
	LOSS [training: 0.1767807667098362 | validation: 0.3414722071744443]
	TIME [epoch: 6.73 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15234212938503222		[learning rate: 0.0073131]
	Learning Rate: 0.00731312
	LOSS [training: 0.15234212938503222 | validation: 0.37683534242821914]
	TIME [epoch: 6.74 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1755113391701721		[learning rate: 0.0072787]
	Learning Rate: 0.00727866
	LOSS [training: 0.1755113391701721 | validation: 0.3273873010108015]
	TIME [epoch: 6.75 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17358677032114672		[learning rate: 0.0072444]
	Learning Rate: 0.00724436
	LOSS [training: 0.17358677032114672 | validation: 0.39790069752588075]
	TIME [epoch: 6.76 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19681395451950126		[learning rate: 0.0072102]
	Learning Rate: 0.00721022
	LOSS [training: 0.19681395451950126 | validation: 0.4220293598084436]
	TIME [epoch: 6.75 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2198329382535601		[learning rate: 0.0071762]
	Learning Rate: 0.00717625
	LOSS [training: 0.2198329382535601 | validation: 0.37644161605767534]
	TIME [epoch: 6.76 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1611494373106951		[learning rate: 0.0071424]
	Learning Rate: 0.00714243
	LOSS [training: 0.1611494373106951 | validation: 0.437840809277671]
	TIME [epoch: 6.77 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18851764581071104		[learning rate: 0.0071088]
	Learning Rate: 0.00710878
	LOSS [training: 0.18851764581071104 | validation: 0.3513815344673071]
	TIME [epoch: 6.77 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18845144702001965		[learning rate: 0.0070753]
	Learning Rate: 0.00707528
	LOSS [training: 0.18845144702001965 | validation: 0.3654131303318103]
	TIME [epoch: 6.75 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18550000740999933		[learning rate: 0.0070419]
	Learning Rate: 0.00704194
	LOSS [training: 0.18550000740999933 | validation: 0.5445693083429801]
	TIME [epoch: 6.75 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2544365505609957		[learning rate: 0.0070088]
	Learning Rate: 0.00700876
	LOSS [training: 0.2544365505609957 | validation: 0.42065165232828083]
	TIME [epoch: 6.76 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18873205832838963		[learning rate: 0.0069757]
	Learning Rate: 0.00697573
	LOSS [training: 0.18873205832838963 | validation: 0.4141564717635171]
	TIME [epoch: 6.72 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1730897492520515		[learning rate: 0.0069429]
	Learning Rate: 0.00694286
	LOSS [training: 0.1730897492520515 | validation: 0.4118540499233872]
	TIME [epoch: 6.77 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16822974954330414		[learning rate: 0.0069101]
	Learning Rate: 0.00691014
	LOSS [training: 0.16822974954330414 | validation: 0.34428146667673776]
	TIME [epoch: 6.77 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16060576140956453		[learning rate: 0.0068776]
	Learning Rate: 0.00687758
	LOSS [training: 0.16060576140956453 | validation: 0.3667079252862005]
	TIME [epoch: 6.76 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1718937027846733		[learning rate: 0.0068452]
	Learning Rate: 0.00684518
	LOSS [training: 0.1718937027846733 | validation: 0.4339796682205159]
	TIME [epoch: 6.76 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.181168359249149		[learning rate: 0.0068129]
	Learning Rate: 0.00681292
	LOSS [training: 0.181168359249149 | validation: 0.3617948206600831]
	TIME [epoch: 6.74 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16786041642934202		[learning rate: 0.0067808]
	Learning Rate: 0.00678082
	LOSS [training: 0.16786041642934202 | validation: 0.34941023571173835]
	TIME [epoch: 6.75 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16636323722541985		[learning rate: 0.0067489]
	Learning Rate: 0.00674887
	LOSS [training: 0.16636323722541985 | validation: 0.378484818717427]
	TIME [epoch: 6.76 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1774892186149851		[learning rate: 0.0067171]
	Learning Rate: 0.00671706
	LOSS [training: 0.1774892186149851 | validation: 0.36030042866368495]
	TIME [epoch: 6.76 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14814769604605613		[learning rate: 0.0066854]
	Learning Rate: 0.00668541
	LOSS [training: 0.14814769604605613 | validation: 0.3488566750384326]
	TIME [epoch: 6.78 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16101311093562432		[learning rate: 0.0066539]
	Learning Rate: 0.00665391
	LOSS [training: 0.16101311093562432 | validation: 0.41953145216416254]
	TIME [epoch: 6.76 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19153212191424412		[learning rate: 0.0066226]
	Learning Rate: 0.00662256
	LOSS [training: 0.19153212191424412 | validation: 0.3517244896153144]
	TIME [epoch: 6.76 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1438255315513295		[learning rate: 0.0065913]
	Learning Rate: 0.00659135
	LOSS [training: 0.1438255315513295 | validation: 0.36972619339741364]
	TIME [epoch: 6.76 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19225714046892572		[learning rate: 0.0065603]
	Learning Rate: 0.00656029
	LOSS [training: 0.19225714046892572 | validation: 0.39216778155068266]
	TIME [epoch: 6.77 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1706047776961031		[learning rate: 0.0065294]
	Learning Rate: 0.00652938
	LOSS [training: 0.1706047776961031 | validation: 0.37699961807962523]
	TIME [epoch: 6.76 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1421726681843783		[learning rate: 0.0064986]
	Learning Rate: 0.00649861
	LOSS [training: 0.1421726681843783 | validation: 0.40394240703737316]
	TIME [epoch: 6.76 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16968119602544132		[learning rate: 0.006468]
	Learning Rate: 0.00646799
	LOSS [training: 0.16968119602544132 | validation: 0.4206719485350072]
	TIME [epoch: 6.78 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17091046679465785		[learning rate: 0.0064375]
	Learning Rate: 0.00643751
	LOSS [training: 0.17091046679465785 | validation: 0.3386328884769781]
	TIME [epoch: 6.77 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1684985385246869		[learning rate: 0.0064072]
	Learning Rate: 0.00640718
	LOSS [training: 0.1684985385246869 | validation: 0.383500871947316]
	TIME [epoch: 6.77 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15060346999755644		[learning rate: 0.006377]
	Learning Rate: 0.00637698
	LOSS [training: 0.15060346999755644 | validation: 0.3829607696758369]
	TIME [epoch: 6.76 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2049646533906744		[learning rate: 0.0063469]
	Learning Rate: 0.00634694
	LOSS [training: 0.2049646533906744 | validation: 0.5929424586859188]
	TIME [epoch: 6.73 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2576338885504428		[learning rate: 0.006317]
	Learning Rate: 0.00631703
	LOSS [training: 0.2576338885504428 | validation: 0.4841972342903865]
	TIME [epoch: 6.75 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.204360437250971		[learning rate: 0.0062873]
	Learning Rate: 0.00628726
	LOSS [training: 0.204360437250971 | validation: 0.36061676251929137]
	TIME [epoch: 6.79 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1859960057664796		[learning rate: 0.0062576]
	Learning Rate: 0.00625764
	LOSS [training: 0.1859960057664796 | validation: 0.39501169099133704]
	TIME [epoch: 6.76 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17034184298770297		[learning rate: 0.0062281]
	Learning Rate: 0.00622815
	LOSS [training: 0.17034184298770297 | validation: 0.3312342836669958]
	TIME [epoch: 6.74 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17814532700298127		[learning rate: 0.0061988]
	Learning Rate: 0.0061988
	LOSS [training: 0.17814532700298127 | validation: 0.38604395017221993]
	TIME [epoch: 6.77 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1796792515171618		[learning rate: 0.0061696]
	Learning Rate: 0.00616959
	LOSS [training: 0.1796792515171618 | validation: 0.5479166998303361]
	TIME [epoch: 6.75 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22855600133021903		[learning rate: 0.0061405]
	Learning Rate: 0.00614052
	LOSS [training: 0.22855600133021903 | validation: 0.4208441374579518]
	TIME [epoch: 6.77 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19554719616061947		[learning rate: 0.0061116]
	Learning Rate: 0.00611158
	LOSS [training: 0.19554719616061947 | validation: 0.3615940698623632]
	TIME [epoch: 6.76 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17247657827143967		[learning rate: 0.0060828]
	Learning Rate: 0.00608279
	LOSS [training: 0.17247657827143967 | validation: 0.4449406923394344]
	TIME [epoch: 6.79 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2468634694902953		[learning rate: 0.0060541]
	Learning Rate: 0.00605412
	LOSS [training: 0.2468634694902953 | validation: 0.3948088645969624]
	TIME [epoch: 6.76 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1707429845408849		[learning rate: 0.0060256]
	Learning Rate: 0.0060256
	LOSS [training: 0.1707429845408849 | validation: 0.3738634902182657]
	TIME [epoch: 6.73 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17370422917267667		[learning rate: 0.0059972]
	Learning Rate: 0.0059972
	LOSS [training: 0.17370422917267667 | validation: 0.5097865693540984]
	TIME [epoch: 6.75 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19385649503009603		[learning rate: 0.0059689]
	Learning Rate: 0.00596894
	LOSS [training: 0.19385649503009603 | validation: 0.332774025551628]
	TIME [epoch: 6.77 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1614448369426734		[learning rate: 0.0059408]
	Learning Rate: 0.00594082
	LOSS [training: 0.1614448369426734 | validation: 0.33334226857315413]
	TIME [epoch: 6.75 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15714976385118787		[learning rate: 0.0059128]
	Learning Rate: 0.00591282
	LOSS [training: 0.15714976385118787 | validation: 0.39987832897703796]
	TIME [epoch: 6.76 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27468051856513764		[learning rate: 0.005885]
	Learning Rate: 0.00588496
	LOSS [training: 0.27468051856513764 | validation: 0.4006515807106688]
	TIME [epoch: 6.79 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1781598739614875		[learning rate: 0.0058572]
	Learning Rate: 0.00585723
	LOSS [training: 0.1781598739614875 | validation: 0.30621184021560083]
	TIME [epoch: 6.76 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v15_20240719_004754/states/model_facs_v4_dec2b_2dpca_v15_151.pth
	Model improved!!!
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15981643821766947		[learning rate: 0.0058296]
	Learning Rate: 0.00582963
	LOSS [training: 0.15981643821766947 | validation: 0.3784547279608828]
	TIME [epoch: 6.76 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1826593990471599		[learning rate: 0.0058022]
	Learning Rate: 0.00580216
	LOSS [training: 0.1826593990471599 | validation: 0.4220665048749612]
	TIME [epoch: 6.76 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22887515672040376		[learning rate: 0.0057748]
	Learning Rate: 0.00577482
	LOSS [training: 0.22887515672040376 | validation: 0.48785716491138253]
	TIME [epoch: 6.76 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20909517081445617		[learning rate: 0.0057476]
	Learning Rate: 0.00574761
	LOSS [training: 0.20909517081445617 | validation: 0.4656703577824952]
	TIME [epoch: 6.75 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17779737384861347		[learning rate: 0.0057205]
	Learning Rate: 0.00572052
	LOSS [training: 0.17779737384861347 | validation: 0.3753476622226626]
	TIME [epoch: 6.73 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15947263324526212		[learning rate: 0.0056936]
	Learning Rate: 0.00569357
	LOSS [training: 0.15947263324526212 | validation: 0.39876582333332716]
	TIME [epoch: 6.77 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16274060271309218		[learning rate: 0.0056667]
	Learning Rate: 0.00566674
	LOSS [training: 0.16274060271309218 | validation: 0.40085405974100485]
	TIME [epoch: 6.77 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1838554306688898		[learning rate: 0.00564]
	Learning Rate: 0.00564004
	LOSS [training: 0.1838554306688898 | validation: 0.3811460525000056]
	TIME [epoch: 6.76 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16520969107510575		[learning rate: 0.0056135]
	Learning Rate: 0.00561346
	LOSS [training: 0.16520969107510575 | validation: 0.33835175883440155]
	TIME [epoch: 6.76 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14215454158252877		[learning rate: 0.005587]
	Learning Rate: 0.00558701
	LOSS [training: 0.14215454158252877 | validation: 0.42116187440980335]
	TIME [epoch: 6.77 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19051881319865674		[learning rate: 0.0055607]
	Learning Rate: 0.00556068
	LOSS [training: 0.19051881319865674 | validation: 0.3996055826687781]
	TIME [epoch: 6.76 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1654517223545365		[learning rate: 0.0055345]
	Learning Rate: 0.00553448
	LOSS [training: 0.1654517223545365 | validation: 0.34383102940131405]
	TIME [epoch: 6.77 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15124977356652433		[learning rate: 0.0055084]
	Learning Rate: 0.0055084
	LOSS [training: 0.15124977356652433 | validation: 0.2832545927725975]
	TIME [epoch: 6.78 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v15_20240719_004754/states/model_facs_v4_dec2b_2dpca_v15_164.pth
	Model improved!!!
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17745642915467044		[learning rate: 0.0054824]
	Learning Rate: 0.00548245
	LOSS [training: 0.17745642915467044 | validation: 0.3195806168917684]
	TIME [epoch: 6.75 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14222653529290347		[learning rate: 0.0054566]
	Learning Rate: 0.00545661
	LOSS [training: 0.14222653529290347 | validation: 0.41461787051147003]
	TIME [epoch: 6.75 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1832213781426466		[learning rate: 0.0054309]
	Learning Rate: 0.0054309
	LOSS [training: 0.1832213781426466 | validation: 0.39430135126052174]
	TIME [epoch: 6.72 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15541979705870018		[learning rate: 0.0054053]
	Learning Rate: 0.00540531
	LOSS [training: 0.15541979705870018 | validation: 0.40488770712919125]
	TIME [epoch: 6.72 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1681505798487237		[learning rate: 0.0053798]
	Learning Rate: 0.00537984
	LOSS [training: 0.1681505798487237 | validation: 0.42016127845849477]
	TIME [epoch: 6.77 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14321028658434273		[learning rate: 0.0053545]
	Learning Rate: 0.00535449
	LOSS [training: 0.14321028658434273 | validation: 0.3567055385232891]
	TIME [epoch: 6.75 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1551025058071529		[learning rate: 0.0053293]
	Learning Rate: 0.00532926
	LOSS [training: 0.1551025058071529 | validation: 0.501951323624602]
	TIME [epoch: 6.76 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2152378930564916		[learning rate: 0.0053041]
	Learning Rate: 0.00530415
	LOSS [training: 0.2152378930564916 | validation: 0.3692172671012396]
	TIME [epoch: 6.76 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1616529705123193		[learning rate: 0.0052792]
	Learning Rate: 0.00527915
	LOSS [training: 0.1616529705123193 | validation: 0.29633646909123035]
	TIME [epoch: 6.75 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12882787774271487		[learning rate: 0.0052543]
	Learning Rate: 0.00525428
	LOSS [training: 0.12882787774271487 | validation: 0.33524476502659495]
	TIME [epoch: 6.75 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13946758715881985		[learning rate: 0.0052295]
	Learning Rate: 0.00522952
	LOSS [training: 0.13946758715881985 | validation: 0.31567189371263044]
	TIME [epoch: 6.75 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15876946306200307		[learning rate: 0.0052049]
	Learning Rate: 0.00520487
	LOSS [training: 0.15876946306200307 | validation: 0.3758856495402371]
	TIME [epoch: 6.71 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14447240266353556		[learning rate: 0.0051803]
	Learning Rate: 0.00518035
	LOSS [training: 0.14447240266353556 | validation: 0.3478140238068435]
	TIME [epoch: 6.75 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1427219267820424		[learning rate: 0.0051559]
	Learning Rate: 0.00515594
	LOSS [training: 0.1427219267820424 | validation: 0.31807586581721237]
	TIME [epoch: 6.73 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1467987331244855		[learning rate: 0.0051316]
	Learning Rate: 0.00513164
	LOSS [training: 0.1467987331244855 | validation: 0.3742574172482174]
	TIME [epoch: 6.73 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15271104569351154		[learning rate: 0.0051075]
	Learning Rate: 0.00510746
	LOSS [training: 0.15271104569351154 | validation: 0.3603360110819529]
	TIME [epoch: 6.73 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16986345305687267		[learning rate: 0.0050834]
	Learning Rate: 0.00508339
	LOSS [training: 0.16986345305687267 | validation: 0.3956561231808369]
	TIME [epoch: 6.73 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1564838650415143		[learning rate: 0.0050594]
	Learning Rate: 0.00505944
	LOSS [training: 0.1564838650415143 | validation: 0.3027801369707179]
	TIME [epoch: 6.73 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12959849515460747		[learning rate: 0.0050356]
	Learning Rate: 0.0050356
	LOSS [training: 0.12959849515460747 | validation: 0.33301779026101147]
	TIME [epoch: 6.74 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16990549407571393		[learning rate: 0.0050119]
	Learning Rate: 0.00501187
	LOSS [training: 0.16990549407571393 | validation: 0.31554024546757825]
	TIME [epoch: 6.74 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15470382150913892		[learning rate: 0.0049883]
	Learning Rate: 0.00498826
	LOSS [training: 0.15470382150913892 | validation: 0.30039455762530165]
	TIME [epoch: 6.74 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1523989967066639		[learning rate: 0.0049648]
	Learning Rate: 0.00496475
	LOSS [training: 0.1523989967066639 | validation: 0.33474847142487996]
	TIME [epoch: 6.73 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17089307358815026		[learning rate: 0.0049414]
	Learning Rate: 0.00494136
	LOSS [training: 0.17089307358815026 | validation: 0.31734938116938377]
	TIME [epoch: 6.72 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15940382676502785		[learning rate: 0.0049181]
	Learning Rate: 0.00491807
	LOSS [training: 0.15940382676502785 | validation: 0.33986069603635305]
	TIME [epoch: 6.72 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16469033517394555		[learning rate: 0.0048949]
	Learning Rate: 0.0048949
	LOSS [training: 0.16469033517394555 | validation: 0.3350924672405401]
	TIME [epoch: 6.74 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17793755877169148		[learning rate: 0.0048718]
	Learning Rate: 0.00487183
	LOSS [training: 0.17793755877169148 | validation: 0.36246696773796766]
	TIME [epoch: 6.74 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1650962934853179		[learning rate: 0.0048489]
	Learning Rate: 0.00484888
	LOSS [training: 0.1650962934853179 | validation: 0.3192186773530613]
	TIME [epoch: 6.73 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16402433703568414		[learning rate: 0.004826]
	Learning Rate: 0.00482603
	LOSS [training: 0.16402433703568414 | validation: 0.3698881471792103]
	TIME [epoch: 6.73 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17722763253388285		[learning rate: 0.0048033]
	Learning Rate: 0.00480329
	LOSS [training: 0.17722763253388285 | validation: 0.38664084410720034]
	TIME [epoch: 6.73 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1754259154877661		[learning rate: 0.0047807]
	Learning Rate: 0.00478065
	LOSS [training: 0.1754259154877661 | validation: 0.3882553492999363]
	TIME [epoch: 6.74 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13271805928784536		[learning rate: 0.0047581]
	Learning Rate: 0.00475813
	LOSS [training: 0.13271805928784536 | validation: 0.34310267296827834]
	TIME [epoch: 6.74 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16479649557799161		[learning rate: 0.0047357]
	Learning Rate: 0.0047357
	LOSS [training: 0.16479649557799161 | validation: 0.38602675330532377]
	TIME [epoch: 6.75 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19473713068778198		[learning rate: 0.0047134]
	Learning Rate: 0.00471339
	LOSS [training: 0.19473713068778198 | validation: 0.3181472596544456]
	TIME [epoch: 6.73 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16415990087463064		[learning rate: 0.0046912]
	Learning Rate: 0.00469118
	LOSS [training: 0.16415990087463064 | validation: 0.3398173340843798]
	TIME [epoch: 6.78 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16393430775604753		[learning rate: 0.0046691]
	Learning Rate: 0.00466907
	LOSS [training: 0.16393430775604753 | validation: 0.31943774762784655]
	TIME [epoch: 6.73 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15910037249191392		[learning rate: 0.0046471]
	Learning Rate: 0.00464707
	LOSS [training: 0.15910037249191392 | validation: 0.39019404939878977]
	TIME [epoch: 6.72 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19369017453013404		[learning rate: 0.0046252]
	Learning Rate: 0.00462518
	LOSS [training: 0.19369017453013404 | validation: 0.3909628420103456]
	TIME [epoch: 6.73 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15991139845643887		[learning rate: 0.0046034]
	Learning Rate: 0.00460338
	LOSS [training: 0.15991139845643887 | validation: 0.34090059741961953]
	TIME [epoch: 6.73 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15695826637372584		[learning rate: 0.0045817]
	Learning Rate: 0.00458169
	LOSS [training: 0.15695826637372584 | validation: 0.36917354016702175]
	TIME [epoch: 6.76 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15835160054983735		[learning rate: 0.0045601]
	Learning Rate: 0.0045601
	LOSS [training: 0.15835160054983735 | validation: 0.3499144740129461]
	TIME [epoch: 6.76 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1824650278304548		[learning rate: 0.0045386]
	Learning Rate: 0.00453861
	LOSS [training: 0.1824650278304548 | validation: 0.33699132843946145]
	TIME [epoch: 6.78 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1441523100483512		[learning rate: 0.0045172]
	Learning Rate: 0.00451723
	LOSS [training: 0.1441523100483512 | validation: 0.3363150958493688]
	TIME [epoch: 6.74 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15149985716192488		[learning rate: 0.0044959]
	Learning Rate: 0.00449594
	LOSS [training: 0.15149985716192488 | validation: 0.33739864551238485]
	TIME [epoch: 6.74 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13969189156331926		[learning rate: 0.0044748]
	Learning Rate: 0.00447475
	LOSS [training: 0.13969189156331926 | validation: 0.3382458249745794]
	TIME [epoch: 6.76 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1765522921116242		[learning rate: 0.0044537]
	Learning Rate: 0.00445367
	LOSS [training: 0.1765522921116242 | validation: 0.31688236103586664]
	TIME [epoch: 6.77 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1336434257503342		[learning rate: 0.0044327]
	Learning Rate: 0.00443268
	LOSS [training: 0.1336434257503342 | validation: 0.2914069222037192]
	TIME [epoch: 6.74 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14004573807525478		[learning rate: 0.0044118]
	Learning Rate: 0.0044118
	LOSS [training: 0.14004573807525478 | validation: 0.42119870314186875]
	TIME [epoch: 6.75 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17004228529474621		[learning rate: 0.004391]
	Learning Rate: 0.00439101
	LOSS [training: 0.17004228529474621 | validation: 0.3684331842570876]
	TIME [epoch: 6.76 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15287890571693805		[learning rate: 0.0043703]
	Learning Rate: 0.00437032
	LOSS [training: 0.15287890571693805 | validation: 0.3389838615167964]
	TIME [epoch: 6.76 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18170488854955802		[learning rate: 0.0043497]
	Learning Rate: 0.00434972
	LOSS [training: 0.18170488854955802 | validation: 0.3142753341374513]
	TIME [epoch: 6.76 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13700216664909026		[learning rate: 0.0043292]
	Learning Rate: 0.00432923
	LOSS [training: 0.13700216664909026 | validation: 0.30088949262809483]
	TIME [epoch: 6.76 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1628284959941029		[learning rate: 0.0043088]
	Learning Rate: 0.00430883
	LOSS [training: 0.1628284959941029 | validation: 0.33799535760185856]
	TIME [epoch: 6.76 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14298604534242612		[learning rate: 0.0042885]
	Learning Rate: 0.00428852
	LOSS [training: 0.14298604534242612 | validation: 0.33726619252055123]
	TIME [epoch: 6.74 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1453380835429318		[learning rate: 0.0042683]
	Learning Rate: 0.00426831
	LOSS [training: 0.1453380835429318 | validation: 0.3397534470195797]
	TIME [epoch: 6.74 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17363260207318504		[learning rate: 0.0042482]
	Learning Rate: 0.0042482
	LOSS [training: 0.17363260207318504 | validation: 0.35678365884853036]
	TIME [epoch: 6.72 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13405076807599323		[learning rate: 0.0042282]
	Learning Rate: 0.00422818
	LOSS [training: 0.13405076807599323 | validation: 0.33876050322115203]
	TIME [epoch: 6.78 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17962272610861504		[learning rate: 0.0042083]
	Learning Rate: 0.00420826
	LOSS [training: 0.17962272610861504 | validation: 0.3228580215082069]
	TIME [epoch: 6.73 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14823830954905792		[learning rate: 0.0041884]
	Learning Rate: 0.00418843
	LOSS [training: 0.14823830954905792 | validation: 0.3865311371087913]
	TIME [epoch: 6.75 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16109187983817636		[learning rate: 0.0041687]
	Learning Rate: 0.00416869
	LOSS [training: 0.16109187983817636 | validation: 0.36502143036496054]
	TIME [epoch: 6.74 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14739284843470712		[learning rate: 0.0041491]
	Learning Rate: 0.00414905
	LOSS [training: 0.14739284843470712 | validation: 0.32851114049773567]
	TIME [epoch: 6.74 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19316162213188737		[learning rate: 0.0041295]
	Learning Rate: 0.0041295
	LOSS [training: 0.19316162213188737 | validation: 0.3935457403562755]
	TIME [epoch: 6.77 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14962438014610402		[learning rate: 0.00411]
	Learning Rate: 0.00411004
	LOSS [training: 0.14962438014610402 | validation: 0.333311325384947]
	TIME [epoch: 6.73 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1498865102093312		[learning rate: 0.0040907]
	Learning Rate: 0.00409067
	LOSS [training: 0.1498865102093312 | validation: 0.3332409922311753]
	TIME [epoch: 6.74 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1535845556709659		[learning rate: 0.0040714]
	Learning Rate: 0.0040714
	LOSS [training: 0.1535845556709659 | validation: 0.30540531104502316]
	TIME [epoch: 6.74 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14565697319813967		[learning rate: 0.0040522]
	Learning Rate: 0.00405221
	LOSS [training: 0.14565697319813967 | validation: 0.32318610659254254]
	TIME [epoch: 6.76 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1435978561464566		[learning rate: 0.0040331]
	Learning Rate: 0.00403312
	LOSS [training: 0.1435978561464566 | validation: 0.31997633241386886]
	TIME [epoch: 6.75 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13219831719387926		[learning rate: 0.0040141]
	Learning Rate: 0.00401411
	LOSS [training: 0.13219831719387926 | validation: 0.3221450684658707]
	TIME [epoch: 6.77 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13118135615331972		[learning rate: 0.0039952]
	Learning Rate: 0.0039952
	LOSS [training: 0.13118135615331972 | validation: 0.30268617985231305]
	TIME [epoch: 6.76 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15111177089896588		[learning rate: 0.0039764]
	Learning Rate: 0.00397637
	LOSS [training: 0.15111177089896588 | validation: 0.3256710114676014]
	TIME [epoch: 6.76 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15388597053430342		[learning rate: 0.0039576]
	Learning Rate: 0.00395764
	LOSS [training: 0.15388597053430342 | validation: 0.29162874621481794]
	TIME [epoch: 6.76 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14684293651259644		[learning rate: 0.003939]
	Learning Rate: 0.00393899
	LOSS [training: 0.14684293651259644 | validation: 0.36955093344652035]
	TIME [epoch: 6.76 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1355437175679231		[learning rate: 0.0039204]
	Learning Rate: 0.00392043
	LOSS [training: 0.1355437175679231 | validation: 0.3158447471351171]
	TIME [epoch: 6.77 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15846868220067709		[learning rate: 0.003902]
	Learning Rate: 0.00390195
	LOSS [training: 0.15846868220067709 | validation: 0.3048196942172925]
	TIME [epoch: 6.76 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14432076592228316		[learning rate: 0.0038836]
	Learning Rate: 0.00388357
	LOSS [training: 0.14432076592228316 | validation: 0.3699077223486394]
	TIME [epoch: 6.71 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14944874168443334		[learning rate: 0.0038653]
	Learning Rate: 0.00386527
	LOSS [training: 0.14944874168443334 | validation: 0.41573484599846355]
	TIME [epoch: 6.78 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15952592818954842		[learning rate: 0.0038471]
	Learning Rate: 0.00384705
	LOSS [training: 0.15952592818954842 | validation: 0.3126548953080497]
	TIME [epoch: 6.76 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14785686929485267		[learning rate: 0.0038289]
	Learning Rate: 0.00382893
	LOSS [training: 0.14785686929485267 | validation: 0.31465611769788976]
	TIME [epoch: 6.75 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15284012389606988		[learning rate: 0.0038109]
	Learning Rate: 0.00381088
	LOSS [training: 0.15284012389606988 | validation: 0.3210687441174022]
	TIME [epoch: 6.72 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15228980624640612		[learning rate: 0.0037929]
	Learning Rate: 0.00379293
	LOSS [training: 0.15228980624640612 | validation: 0.3804389102767763]
	TIME [epoch: 6.75 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13709323480610722		[learning rate: 0.0037751]
	Learning Rate: 0.00377505
	LOSS [training: 0.13709323480610722 | validation: 0.32969233020730004]
	TIME [epoch: 6.74 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.162782162108788		[learning rate: 0.0037573]
	Learning Rate: 0.00375726
	LOSS [training: 0.162782162108788 | validation: 0.34412123465535605]
	TIME [epoch: 6.79 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12732318341122129		[learning rate: 0.0037396]
	Learning Rate: 0.00373956
	LOSS [training: 0.12732318341122129 | validation: 0.31574038865359627]
	TIME [epoch: 6.75 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16160009632883457		[learning rate: 0.0037219]
	Learning Rate: 0.00372194
	LOSS [training: 0.16160009632883457 | validation: 0.35687605137953077]
	TIME [epoch: 6.75 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14270999007727764		[learning rate: 0.0037044]
	Learning Rate: 0.0037044
	LOSS [training: 0.14270999007727764 | validation: 0.32656418725427855]
	TIME [epoch: 6.75 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16281884640519195		[learning rate: 0.0036869]
	Learning Rate: 0.00368695
	LOSS [training: 0.16281884640519195 | validation: 0.329352985585126]
	TIME [epoch: 6.75 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1562202639829415		[learning rate: 0.0036696]
	Learning Rate: 0.00366957
	LOSS [training: 0.1562202639829415 | validation: 0.369277221939872]
	TIME [epoch: 6.75 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1392155787559314		[learning rate: 0.0036523]
	Learning Rate: 0.00365228
	LOSS [training: 0.1392155787559314 | validation: 0.3577131874485521]
	TIME [epoch: 6.73 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15285433128355433		[learning rate: 0.0036351]
	Learning Rate: 0.00363507
	LOSS [training: 0.15285433128355433 | validation: 0.3161315644776608]
	TIME [epoch: 6.76 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13770404945382902		[learning rate: 0.0036179]
	Learning Rate: 0.00361794
	LOSS [training: 0.13770404945382902 | validation: 0.3290051515990218]
	TIME [epoch: 6.73 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14528803427035808		[learning rate: 0.0036009]
	Learning Rate: 0.00360089
	LOSS [training: 0.14528803427035808 | validation: 0.3646041866666571]
	TIME [epoch: 6.74 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15383384636384195		[learning rate: 0.0035839]
	Learning Rate: 0.00358393
	LOSS [training: 0.15383384636384195 | validation: 0.33728496624119264]
	TIME [epoch: 6.74 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16297408703690314		[learning rate: 0.003567]
	Learning Rate: 0.00356704
	LOSS [training: 0.16297408703690314 | validation: 0.3381027065328055]
	TIME [epoch: 6.76 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.134024546896088		[learning rate: 0.0035502]
	Learning Rate: 0.00355023
	LOSS [training: 0.134024546896088 | validation: 0.2917447792472036]
	TIME [epoch: 6.74 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11860011218491791		[learning rate: 0.0035335]
	Learning Rate: 0.0035335
	LOSS [training: 0.11860011218491791 | validation: 0.363887809542515]
	TIME [epoch: 6.74 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14984671956521395		[learning rate: 0.0035168]
	Learning Rate: 0.00351685
	LOSS [training: 0.14984671956521395 | validation: 0.35026998648633273]
	TIME [epoch: 6.75 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13286319803347874		[learning rate: 0.0035003]
	Learning Rate: 0.00350028
	LOSS [training: 0.13286319803347874 | validation: 0.32746004749020374]
	TIME [epoch: 6.78 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1317026509103391		[learning rate: 0.0034838]
	Learning Rate: 0.00348378
	LOSS [training: 0.1317026509103391 | validation: 0.31428717596391165]
	TIME [epoch: 6.73 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14396102000954364		[learning rate: 0.0034674]
	Learning Rate: 0.00346737
	LOSS [training: 0.14396102000954364 | validation: 0.2961392634502327]
	TIME [epoch: 6.73 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14152135515581538		[learning rate: 0.003451]
	Learning Rate: 0.00345103
	LOSS [training: 0.14152135515581538 | validation: 0.3565132541220327]
	TIME [epoch: 6.76 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17429018792375714		[learning rate: 0.0034348]
	Learning Rate: 0.00343477
	LOSS [training: 0.17429018792375714 | validation: 0.3886448111572527]
	TIME [epoch: 6.73 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1481505001068033		[learning rate: 0.0034186]
	Learning Rate: 0.00341858
	LOSS [training: 0.1481505001068033 | validation: 0.3585791372009433]
	TIME [epoch: 6.74 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18710953551605441		[learning rate: 0.0034025]
	Learning Rate: 0.00340247
	LOSS [training: 0.18710953551605441 | validation: 0.38131583575454914]
	TIME [epoch: 6.72 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1459638480814075		[learning rate: 0.0033864]
	Learning Rate: 0.00338644
	LOSS [training: 0.1459638480814075 | validation: 0.3176533987803623]
	TIME [epoch: 6.73 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13783348175951046		[learning rate: 0.0033705]
	Learning Rate: 0.00337048
	LOSS [training: 0.13783348175951046 | validation: 0.29689064540773824]
	TIME [epoch: 6.74 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.134757908783484		[learning rate: 0.0033546]
	Learning Rate: 0.0033546
	LOSS [training: 0.134757908783484 | validation: 0.34122153655024046]
	TIME [epoch: 6.72 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1312476951972978		[learning rate: 0.0033388]
	Learning Rate: 0.00333879
	LOSS [training: 0.1312476951972978 | validation: 0.3042966340282563]
	TIME [epoch: 6.74 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16433651325221926		[learning rate: 0.0033231]
	Learning Rate: 0.00332306
	LOSS [training: 0.16433651325221926 | validation: 0.34980913781798134]
	TIME [epoch: 6.74 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1591621384654349		[learning rate: 0.0033074]
	Learning Rate: 0.0033074
	LOSS [training: 0.1591621384654349 | validation: 0.3379857831253288]
	TIME [epoch: 6.76 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14164818925939093		[learning rate: 0.0032918]
	Learning Rate: 0.00329182
	LOSS [training: 0.14164818925939093 | validation: 0.28555057275391577]
	TIME [epoch: 6.75 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13729277764634043		[learning rate: 0.0032763]
	Learning Rate: 0.00327631
	LOSS [training: 0.13729277764634043 | validation: 0.2976424978068565]
	TIME [epoch: 6.74 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14219522268657253		[learning rate: 0.0032609]
	Learning Rate: 0.00326087
	LOSS [training: 0.14219522268657253 | validation: 0.3663370897782934]
	TIME [epoch: 6.75 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.153834782034845		[learning rate: 0.0032455]
	Learning Rate: 0.0032455
	LOSS [training: 0.153834782034845 | validation: 0.30411533964381277]
	TIME [epoch: 6.75 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14514864266950214		[learning rate: 0.0032302]
	Learning Rate: 0.00323021
	LOSS [training: 0.14514864266950214 | validation: 0.29102947838173815]
	TIME [epoch: 6.75 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12347853939428684		[learning rate: 0.003215]
	Learning Rate: 0.00321499
	LOSS [training: 0.12347853939428684 | validation: 0.35140848208699615]
	TIME [epoch: 6.76 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16210721506117193		[learning rate: 0.0031998]
	Learning Rate: 0.00319984
	LOSS [training: 0.16210721506117193 | validation: 0.30266935260239414]
	TIME [epoch: 6.77 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14399521591540634		[learning rate: 0.0031848]
	Learning Rate: 0.00318476
	LOSS [training: 0.14399521591540634 | validation: 0.3591894806170655]
	TIME [epoch: 6.76 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16434405836339053		[learning rate: 0.0031698]
	Learning Rate: 0.00316975
	LOSS [training: 0.16434405836339053 | validation: 0.3031178288207134]
	TIME [epoch: 6.76 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1302469468808216		[learning rate: 0.0031548]
	Learning Rate: 0.00315482
	LOSS [training: 0.1302469468808216 | validation: 0.3283357520549987]
	TIME [epoch: 6.74 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14870965700168434		[learning rate: 0.00314]
	Learning Rate: 0.00313995
	LOSS [training: 0.14870965700168434 | validation: 0.33366411172920096]
	TIME [epoch: 6.76 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12442366844551027		[learning rate: 0.0031252]
	Learning Rate: 0.00312516
	LOSS [training: 0.12442366844551027 | validation: 0.31471456638570444]
	TIME [epoch: 6.76 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20427920037802566		[learning rate: 0.0031104]
	Learning Rate: 0.00311043
	LOSS [training: 0.20427920037802566 | validation: 0.36929729540680045]
	TIME [epoch: 6.76 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16279250359896		[learning rate: 0.0030958]
	Learning Rate: 0.00309577
	LOSS [training: 0.16279250359896 | validation: 0.3276467536535904]
	TIME [epoch: 6.78 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14988485853108982		[learning rate: 0.0030812]
	Learning Rate: 0.00308119
	LOSS [training: 0.14988485853108982 | validation: 0.34822207519707205]
	TIME [epoch: 6.75 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14021311702106853		[learning rate: 0.0030667]
	Learning Rate: 0.00306667
	LOSS [training: 0.14021311702106853 | validation: 0.3802635975349572]
	TIME [epoch: 6.75 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14284234698563317		[learning rate: 0.0030522]
	Learning Rate: 0.00305222
	LOSS [training: 0.14284234698563317 | validation: 0.28840087188754226]
	TIME [epoch: 6.75 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13782910887016459		[learning rate: 0.0030378]
	Learning Rate: 0.00303783
	LOSS [training: 0.13782910887016459 | validation: 0.34424266713030416]
	TIME [epoch: 6.74 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12489101581734197		[learning rate: 0.0030235]
	Learning Rate: 0.00302352
	LOSS [training: 0.12489101581734197 | validation: 0.29859835790202405]
	TIME [epoch: 6.75 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1357419622021778		[learning rate: 0.0030093]
	Learning Rate: 0.00300927
	LOSS [training: 0.1357419622021778 | validation: 0.2887122529469712]
	TIME [epoch: 6.75 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12407352473543683		[learning rate: 0.0029951]
	Learning Rate: 0.00299509
	LOSS [training: 0.12407352473543683 | validation: 0.3112275498559918]
	TIME [epoch: 6.77 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1352280535215578		[learning rate: 0.002981]
	Learning Rate: 0.00298098
	LOSS [training: 0.1352280535215578 | validation: 0.3148179923371376]
	TIME [epoch: 6.8 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13413168851690038		[learning rate: 0.0029669]
	Learning Rate: 0.00296693
	LOSS [training: 0.13413168851690038 | validation: 0.3124885710668195]
	TIME [epoch: 6.74 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1354853604879766		[learning rate: 0.002953]
	Learning Rate: 0.00295295
	LOSS [training: 0.1354853604879766 | validation: 0.3011448785801062]
	TIME [epoch: 6.75 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.132550601286143		[learning rate: 0.002939]
	Learning Rate: 0.00293904
	LOSS [training: 0.132550601286143 | validation: 0.29294537210457167]
	TIME [epoch: 6.76 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12456995297815854		[learning rate: 0.0029252]
	Learning Rate: 0.00292519
	LOSS [training: 0.12456995297815854 | validation: 0.3095652798737587]
	TIME [epoch: 6.74 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1414632072893006		[learning rate: 0.0029114]
	Learning Rate: 0.0029114
	LOSS [training: 0.1414632072893006 | validation: 0.38406855381182503]
	TIME [epoch: 6.76 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15474984547991782		[learning rate: 0.0028977]
	Learning Rate: 0.00289769
	LOSS [training: 0.15474984547991782 | validation: 0.34156444804486474]
	TIME [epoch: 6.76 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15342474121776145		[learning rate: 0.002884]
	Learning Rate: 0.00288403
	LOSS [training: 0.15342474121776145 | validation: 0.37588203765569683]
	TIME [epoch: 6.75 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14966631836252361		[learning rate: 0.0028704]
	Learning Rate: 0.00287044
	LOSS [training: 0.14966631836252361 | validation: 0.3351314847142509]
	TIME [epoch: 6.76 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1184292731795808		[learning rate: 0.0028569]
	Learning Rate: 0.00285692
	LOSS [training: 0.1184292731795808 | validation: 0.32342454569475393]
	TIME [epoch: 6.77 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12746325237486308		[learning rate: 0.0028435]
	Learning Rate: 0.00284345
	LOSS [training: 0.12746325237486308 | validation: 0.3505511013707744]
	TIME [epoch: 6.76 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13781868180534235		[learning rate: 0.0028301]
	Learning Rate: 0.00283005
	LOSS [training: 0.13781868180534235 | validation: 0.3950475243086352]
	TIME [epoch: 6.8 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17492933780737532		[learning rate: 0.0028167]
	Learning Rate: 0.00281672
	LOSS [training: 0.17492933780737532 | validation: 0.3286975325902253]
	TIME [epoch: 6.76 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15668778567129396		[learning rate: 0.0028034]
	Learning Rate: 0.00280345
	LOSS [training: 0.15668778567129396 | validation: 0.3163226459981274]
	TIME [epoch: 6.78 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14249929841618766		[learning rate: 0.0027902]
	Learning Rate: 0.00279024
	LOSS [training: 0.14249929841618766 | validation: 0.3466933638721751]
	TIME [epoch: 6.76 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15462151244654188		[learning rate: 0.0027771]
	Learning Rate: 0.00277709
	LOSS [training: 0.15462151244654188 | validation: 0.31358373223360525]
	TIME [epoch: 6.77 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14868005193758865		[learning rate: 0.002764]
	Learning Rate: 0.002764
	LOSS [training: 0.14868005193758865 | validation: 0.3536325743508887]
	TIME [epoch: 6.75 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.140284971518376		[learning rate: 0.002751]
	Learning Rate: 0.00275098
	LOSS [training: 0.140284971518376 | validation: 0.3078764817897251]
	TIME [epoch: 6.77 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12109362344720583		[learning rate: 0.002738]
	Learning Rate: 0.00273802
	LOSS [training: 0.12109362344720583 | validation: 0.35319269959079946]
	TIME [epoch: 6.76 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14021476656819737		[learning rate: 0.0027251]
	Learning Rate: 0.00272511
	LOSS [training: 0.14021476656819737 | validation: 0.3275171009937211]
	TIME [epoch: 6.76 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12257200506885936		[learning rate: 0.0027123]
	Learning Rate: 0.00271227
	LOSS [training: 0.12257200506885936 | validation: 0.3501228402541981]
	TIME [epoch: 6.77 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11710479395698932		[learning rate: 0.0026995]
	Learning Rate: 0.00269949
	LOSS [training: 0.11710479395698932 | validation: 0.3317982328307412]
	TIME [epoch: 6.76 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14595518859405257		[learning rate: 0.0026868]
	Learning Rate: 0.00268677
	LOSS [training: 0.14595518859405257 | validation: 0.29887997132567673]
	TIME [epoch: 6.76 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1414742269482194		[learning rate: 0.0026741]
	Learning Rate: 0.00267411
	LOSS [training: 0.1414742269482194 | validation: 0.372519342717075]
	TIME [epoch: 6.77 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13659829396981632		[learning rate: 0.0026615]
	Learning Rate: 0.00266151
	LOSS [training: 0.13659829396981632 | validation: 0.2991243159356961]
	TIME [epoch: 6.76 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13975875004933813		[learning rate: 0.002649]
	Learning Rate: 0.00264897
	LOSS [training: 0.13975875004933813 | validation: 0.3120399482995432]
	TIME [epoch: 6.78 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1520287368311752		[learning rate: 0.0026365]
	Learning Rate: 0.00263649
	LOSS [training: 0.1520287368311752 | validation: 0.30785266563651753]
	TIME [epoch: 6.77 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1190201570239272		[learning rate: 0.0026241]
	Learning Rate: 0.00262406
	LOSS [training: 0.1190201570239272 | validation: 0.32305128340045375]
	TIME [epoch: 6.76 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11309224756206401		[learning rate: 0.0026117]
	Learning Rate: 0.0026117
	LOSS [training: 0.11309224756206401 | validation: 0.32147179518826147]
	TIME [epoch: 6.77 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12737926904998711		[learning rate: 0.0025994]
	Learning Rate: 0.00259939
	LOSS [training: 0.12737926904998711 | validation: 0.3456444318827572]
	TIME [epoch: 6.77 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12620335232763283		[learning rate: 0.0025871]
	Learning Rate: 0.00258714
	LOSS [training: 0.12620335232763283 | validation: 0.3159142158710976]
	TIME [epoch: 6.74 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13280885127290226		[learning rate: 0.002575]
	Learning Rate: 0.00257495
	LOSS [training: 0.13280885127290226 | validation: 0.3094348736689112]
	TIME [epoch: 6.75 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14841258924029044		[learning rate: 0.0025628]
	Learning Rate: 0.00256282
	LOSS [training: 0.14841258924029044 | validation: 0.31065065185793583]
	TIME [epoch: 6.77 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13672547764580167		[learning rate: 0.0025507]
	Learning Rate: 0.00255074
	LOSS [training: 0.13672547764580167 | validation: 0.39688285642668847]
	TIME [epoch: 6.77 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14966572621613602		[learning rate: 0.0025387]
	Learning Rate: 0.00253872
	LOSS [training: 0.14966572621613602 | validation: 0.3151552774033259]
	TIME [epoch: 6.76 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15213533513325922		[learning rate: 0.0025268]
	Learning Rate: 0.00252676
	LOSS [training: 0.15213533513325922 | validation: 0.31090897635456993]
	TIME [epoch: 6.77 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12820102763078933		[learning rate: 0.0025149]
	Learning Rate: 0.00251485
	LOSS [training: 0.12820102763078933 | validation: 0.32165903562746395]
	TIME [epoch: 6.74 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12532564708365948		[learning rate: 0.002503]
	Learning Rate: 0.002503
	LOSS [training: 0.12532564708365948 | validation: 0.37239941266125376]
	TIME [epoch: 6.77 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13754630539545412		[learning rate: 0.0024912]
	Learning Rate: 0.00249121
	LOSS [training: 0.13754630539545412 | validation: 0.31411044524933174]
	TIME [epoch: 6.73 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12522669999414177		[learning rate: 0.0024795]
	Learning Rate: 0.00247947
	LOSS [training: 0.12522669999414177 | validation: 0.33884003361900505]
	TIME [epoch: 6.76 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14567033733478094		[learning rate: 0.0024678]
	Learning Rate: 0.00246779
	LOSS [training: 0.14567033733478094 | validation: 0.30381492556902745]
	TIME [epoch: 6.76 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15268992835938056		[learning rate: 0.0024562]
	Learning Rate: 0.00245616
	LOSS [training: 0.15268992835938056 | validation: 0.3023375399086616]
	TIME [epoch: 6.74 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13181658124139525		[learning rate: 0.0024446]
	Learning Rate: 0.00244458
	LOSS [training: 0.13181658124139525 | validation: 0.3013746418548001]
	TIME [epoch: 6.71 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12873961536288553		[learning rate: 0.0024331]
	Learning Rate: 0.00243307
	LOSS [training: 0.12873961536288553 | validation: 0.3904846631827794]
	TIME [epoch: 6.73 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13352914568544857		[learning rate: 0.0024216]
	Learning Rate: 0.0024216
	LOSS [training: 0.13352914568544857 | validation: 0.29481046292313934]
	TIME [epoch: 6.73 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.124799700750615		[learning rate: 0.0024102]
	Learning Rate: 0.00241019
	LOSS [training: 0.124799700750615 | validation: 0.3154245152462641]
	TIME [epoch: 6.75 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1219461111249286		[learning rate: 0.0023988]
	Learning Rate: 0.00239883
	LOSS [training: 0.1219461111249286 | validation: 0.33158626516740614]
	TIME [epoch: 6.75 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13120715904147093		[learning rate: 0.0023875]
	Learning Rate: 0.00238753
	LOSS [training: 0.13120715904147093 | validation: 0.382450290644737]
	TIME [epoch: 6.75 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1286039000748672		[learning rate: 0.0023763]
	Learning Rate: 0.00237628
	LOSS [training: 0.1286039000748672 | validation: 0.2926900586236175]
	TIME [epoch: 6.72 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11616032339840135		[learning rate: 0.0023651]
	Learning Rate: 0.00236508
	LOSS [training: 0.11616032339840135 | validation: 0.2861633460538175]
	TIME [epoch: 6.76 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12018809318375481		[learning rate: 0.0023539]
	Learning Rate: 0.00235394
	LOSS [training: 0.12018809318375481 | validation: 0.3030946678224819]
	TIME [epoch: 6.72 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14908264604827043		[learning rate: 0.0023428]
	Learning Rate: 0.00234285
	LOSS [training: 0.14908264604827043 | validation: 0.31968774948274]
	TIME [epoch: 6.79 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1236397705046561		[learning rate: 0.0023318]
	Learning Rate: 0.00233181
	LOSS [training: 0.1236397705046561 | validation: 0.3104397853388007]
	TIME [epoch: 6.82 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12744341742384055		[learning rate: 0.0023208]
	Learning Rate: 0.00232082
	LOSS [training: 0.12744341742384055 | validation: 0.3185727577250097]
	TIME [epoch: 6.77 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14345900687785162		[learning rate: 0.0023099]
	Learning Rate: 0.00230988
	LOSS [training: 0.14345900687785162 | validation: 0.3767612396208067]
	TIME [epoch: 6.76 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15282045892921475		[learning rate: 0.002299]
	Learning Rate: 0.002299
	LOSS [training: 0.15282045892921475 | validation: 0.30291256785208176]
	TIME [epoch: 6.76 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13550560663468866		[learning rate: 0.0022882]
	Learning Rate: 0.00228816
	LOSS [training: 0.13550560663468866 | validation: 0.32022035910744484]
	TIME [epoch: 6.75 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1427829338354881		[learning rate: 0.0022774]
	Learning Rate: 0.00227738
	LOSS [training: 0.1427829338354881 | validation: 0.2803207232588058]
	TIME [epoch: 6.77 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v15_20240719_004754/states/model_facs_v4_dec2b_2dpca_v15_351.pth
	Model improved!!!
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13178195170230536		[learning rate: 0.0022667]
	Learning Rate: 0.00226665
	LOSS [training: 0.13178195170230536 | validation: 0.321587098169421]
	TIME [epoch: 6.76 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13199623779893802		[learning rate: 0.002256]
	Learning Rate: 0.00225597
	LOSS [training: 0.13199623779893802 | validation: 0.32757508537608926]
	TIME [epoch: 6.77 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11143384658731874		[learning rate: 0.0022453]
	Learning Rate: 0.00224534
	LOSS [training: 0.11143384658731874 | validation: 0.31128579549277363]
	TIME [epoch: 6.76 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14240235542097077		[learning rate: 0.0022348]
	Learning Rate: 0.00223476
	LOSS [training: 0.14240235542097077 | validation: 0.31586592240108363]
	TIME [epoch: 6.76 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14280415917951522		[learning rate: 0.0022242]
	Learning Rate: 0.00222423
	LOSS [training: 0.14280415917951522 | validation: 0.2985450120657776]
	TIME [epoch: 6.74 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1492293905092611		[learning rate: 0.0022137]
	Learning Rate: 0.00221375
	LOSS [training: 0.1492293905092611 | validation: 0.28729132804882973]
	TIME [epoch: 6.76 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12807240164468345		[learning rate: 0.0022033]
	Learning Rate: 0.00220332
	LOSS [training: 0.12807240164468345 | validation: 0.32681909844282103]
	TIME [epoch: 6.76 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14199778815273856		[learning rate: 0.0021929]
	Learning Rate: 0.00219293
	LOSS [training: 0.14199778815273856 | validation: 0.3218570709879264]
	TIME [epoch: 6.74 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15483344165174656		[learning rate: 0.0021826]
	Learning Rate: 0.0021826
	LOSS [training: 0.15483344165174656 | validation: 0.3469407351256095]
	TIME [epoch: 6.74 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14641162197163166		[learning rate: 0.0021723]
	Learning Rate: 0.00217232
	LOSS [training: 0.14641162197163166 | validation: 0.324724119506473]
	TIME [epoch: 6.76 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13404125225810393		[learning rate: 0.0021621]
	Learning Rate: 0.00216208
	LOSS [training: 0.13404125225810393 | validation: 0.3027961326544906]
	TIME [epoch: 6.74 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16321463599821218		[learning rate: 0.0021519]
	Learning Rate: 0.00215189
	LOSS [training: 0.16321463599821218 | validation: 0.31757462065557956]
	TIME [epoch: 6.75 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13471201450517745		[learning rate: 0.0021418]
	Learning Rate: 0.00214175
	LOSS [training: 0.13471201450517745 | validation: 0.2942505219004603]
	TIME [epoch: 6.73 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12266325691745969		[learning rate: 0.0021317]
	Learning Rate: 0.00213166
	LOSS [training: 0.12266325691745969 | validation: 0.3413177602955593]
	TIME [epoch: 6.74 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12734808071839912		[learning rate: 0.0021216]
	Learning Rate: 0.00212162
	LOSS [training: 0.12734808071839912 | validation: 0.30627149934418635]
	TIME [epoch: 6.73 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1270820632278624		[learning rate: 0.0021116]
	Learning Rate: 0.00211162
	LOSS [training: 0.1270820632278624 | validation: 0.3285243141024021]
	TIME [epoch: 6.76 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1262275961448127		[learning rate: 0.0021017]
	Learning Rate: 0.00210167
	LOSS [training: 0.1262275961448127 | validation: 0.34175355819469866]
	TIME [epoch: 6.74 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12288554515119915		[learning rate: 0.0020918]
	Learning Rate: 0.00209176
	LOSS [training: 0.12288554515119915 | validation: 0.34094584297414565]
	TIME [epoch: 6.76 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11775658552225207		[learning rate: 0.0020819]
	Learning Rate: 0.00208191
	LOSS [training: 0.11775658552225207 | validation: 0.3014549102718035]
	TIME [epoch: 6.74 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11966924437889709		[learning rate: 0.0020721]
	Learning Rate: 0.0020721
	LOSS [training: 0.11966924437889709 | validation: 0.29325383038081726]
	TIME [epoch: 6.75 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13555212238444747		[learning rate: 0.0020623]
	Learning Rate: 0.00206233
	LOSS [training: 0.13555212238444747 | validation: 0.2803793830872328]
	TIME [epoch: 6.75 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13370481362774975		[learning rate: 0.0020526]
	Learning Rate: 0.00205262
	LOSS [training: 0.13370481362774975 | validation: 0.29651470139147584]
	TIME [epoch: 6.75 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1383559344175904		[learning rate: 0.0020429]
	Learning Rate: 0.00204294
	LOSS [training: 0.1383559344175904 | validation: 0.36710036569384635]
	TIME [epoch: 6.75 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1270871419201858		[learning rate: 0.0020333]
	Learning Rate: 0.00203332
	LOSS [training: 0.1270871419201858 | validation: 0.2945321707093816]
	TIME [epoch: 6.77 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.138315792303202		[learning rate: 0.0020237]
	Learning Rate: 0.00202374
	LOSS [training: 0.138315792303202 | validation: 0.31001327579766086]
	TIME [epoch: 6.75 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13846406999405084		[learning rate: 0.0020142]
	Learning Rate: 0.0020142
	LOSS [training: 0.13846406999405084 | validation: 0.329031396667122]
	TIME [epoch: 6.74 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12135672668873812		[learning rate: 0.0020047]
	Learning Rate: 0.00200471
	LOSS [training: 0.12135672668873812 | validation: 0.3147540384782628]
	TIME [epoch: 6.75 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13051623963983286		[learning rate: 0.0019953]
	Learning Rate: 0.00199526
	LOSS [training: 0.13051623963983286 | validation: 0.286579225393041]
	TIME [epoch: 6.74 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13269016025561836		[learning rate: 0.0019859]
	Learning Rate: 0.00198586
	LOSS [training: 0.13269016025561836 | validation: 0.3131712309026994]
	TIME [epoch: 6.75 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11671723417137644		[learning rate: 0.0019765]
	Learning Rate: 0.0019765
	LOSS [training: 0.11671723417137644 | validation: 0.34354874934386564]
	TIME [epoch: 6.77 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12713470849731684		[learning rate: 0.0019672]
	Learning Rate: 0.00196719
	LOSS [training: 0.12713470849731684 | validation: 0.31762878182064963]
	TIME [epoch: 6.74 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13598645330769205		[learning rate: 0.0019579]
	Learning Rate: 0.00195792
	LOSS [training: 0.13598645330769205 | validation: 0.3007099693927371]
	TIME [epoch: 6.75 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1269328673082213		[learning rate: 0.0019487]
	Learning Rate: 0.00194869
	LOSS [training: 0.1269328673082213 | validation: 0.2988420436952831]
	TIME [epoch: 6.78 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13611055217910067		[learning rate: 0.0019395]
	Learning Rate: 0.00193951
	LOSS [training: 0.13611055217910067 | validation: 0.33254066359451556]
	TIME [epoch: 6.75 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14373149993802414		[learning rate: 0.0019304]
	Learning Rate: 0.00193037
	LOSS [training: 0.14373149993802414 | validation: 0.31072817155557203]
	TIME [epoch: 6.8 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12094658946294959		[learning rate: 0.0019213]
	Learning Rate: 0.00192128
	LOSS [training: 0.12094658946294959 | validation: 0.3127194172938844]
	TIME [epoch: 6.76 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.126941724663625		[learning rate: 0.0019122]
	Learning Rate: 0.00191222
	LOSS [training: 0.126941724663625 | validation: 0.3092836338534708]
	TIME [epoch: 6.76 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13306568994383564		[learning rate: 0.0019032]
	Learning Rate: 0.00190321
	LOSS [training: 0.13306568994383564 | validation: 0.31077021599226595]
	TIME [epoch: 6.79 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1353756143042949		[learning rate: 0.0018942]
	Learning Rate: 0.00189424
	LOSS [training: 0.1353756143042949 | validation: 0.298761323116372]
	TIME [epoch: 6.76 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1267805432285363		[learning rate: 0.0018853]
	Learning Rate: 0.00188532
	LOSS [training: 0.1267805432285363 | validation: 0.3660563425216475]
	TIME [epoch: 6.79 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1213143690859619		[learning rate: 0.0018764]
	Learning Rate: 0.00187643
	LOSS [training: 0.1213143690859619 | validation: 0.3460258770883365]
	TIME [epoch: 6.79 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12246642906577034		[learning rate: 0.0018676]
	Learning Rate: 0.00186759
	LOSS [training: 0.12246642906577034 | validation: 0.3433071194182997]
	TIME [epoch: 6.73 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14387574289099803		[learning rate: 0.0018588]
	Learning Rate: 0.00185879
	LOSS [training: 0.14387574289099803 | validation: 0.3143741674831805]
	TIME [epoch: 6.78 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1199628814501706		[learning rate: 0.00185]
	Learning Rate: 0.00185003
	LOSS [training: 0.1199628814501706 | validation: 0.32978903967945994]
	TIME [epoch: 6.76 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11951123059178148		[learning rate: 0.0018413]
	Learning Rate: 0.00184132
	LOSS [training: 0.11951123059178148 | validation: 0.35885627617318067]
	TIME [epoch: 6.73 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13853866920670882		[learning rate: 0.0018326]
	Learning Rate: 0.00183264
	LOSS [training: 0.13853866920670882 | validation: 0.31033827071335485]
	TIME [epoch: 6.75 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12296661478755662		[learning rate: 0.001824]
	Learning Rate: 0.001824
	LOSS [training: 0.12296661478755662 | validation: 0.2992653745365188]
	TIME [epoch: 6.76 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11351847293557962		[learning rate: 0.0018154]
	Learning Rate: 0.00181541
	LOSS [training: 0.11351847293557962 | validation: 0.34449968692805466]
	TIME [epoch: 6.73 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13077022025539653		[learning rate: 0.0018069]
	Learning Rate: 0.00180685
	LOSS [training: 0.13077022025539653 | validation: 0.30830319700053993]
	TIME [epoch: 6.74 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13376909317250052		[learning rate: 0.0017983]
	Learning Rate: 0.00179834
	LOSS [training: 0.13376909317250052 | validation: 0.3027106734863738]
	TIME [epoch: 6.8 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13335239196017148		[learning rate: 0.0017899]
	Learning Rate: 0.00178987
	LOSS [training: 0.13335239196017148 | validation: 0.36236386491378036]
	TIME [epoch: 6.75 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12196736866668027		[learning rate: 0.0017814]
	Learning Rate: 0.00178143
	LOSS [training: 0.12196736866668027 | validation: 0.3198878559638738]
	TIME [epoch: 6.76 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11968698493483476		[learning rate: 0.001773]
	Learning Rate: 0.00177304
	LOSS [training: 0.11968698493483476 | validation: 0.31639641292441506]
	TIME [epoch: 6.76 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11434694184839002		[learning rate: 0.0017647]
	Learning Rate: 0.00176468
	LOSS [training: 0.11434694184839002 | validation: 0.30368299007328453]
	TIME [epoch: 6.8 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11713459835033721		[learning rate: 0.0017564]
	Learning Rate: 0.00175637
	LOSS [training: 0.11713459835033721 | validation: 0.34165921674889566]
	TIME [epoch: 6.81 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11228795785964679		[learning rate: 0.0017481]
	Learning Rate: 0.00174809
	LOSS [training: 0.11228795785964679 | validation: 0.3130940362655955]
	TIME [epoch: 6.76 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13374547445385215		[learning rate: 0.0017399]
	Learning Rate: 0.00173985
	LOSS [training: 0.13374547445385215 | validation: 0.31152207008941324]
	TIME [epoch: 6.81 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12811837204257082		[learning rate: 0.0017317]
	Learning Rate: 0.00173166
	LOSS [training: 0.12811837204257082 | validation: 0.3382650994088531]
	TIME [epoch: 6.76 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15734956031386108		[learning rate: 0.0017235]
	Learning Rate: 0.0017235
	LOSS [training: 0.15734956031386108 | validation: 0.3269369874574381]
	TIME [epoch: 6.75 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12926076825182092		[learning rate: 0.0017154]
	Learning Rate: 0.00171537
	LOSS [training: 0.12926076825182092 | validation: 0.31562667880430256]
	TIME [epoch: 6.77 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1249300789394166		[learning rate: 0.0017073]
	Learning Rate: 0.00170729
	LOSS [training: 0.1249300789394166 | validation: 0.3381426163707346]
	TIME [epoch: 6.75 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13953003934039945		[learning rate: 0.0016992]
	Learning Rate: 0.00169925
	LOSS [training: 0.13953003934039945 | validation: 0.3155919011088245]
	TIME [epoch: 6.75 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1356717384638678		[learning rate: 0.0016912]
	Learning Rate: 0.00169124
	LOSS [training: 0.1356717384638678 | validation: 0.2895311678062922]
	TIME [epoch: 6.76 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11889830843440058		[learning rate: 0.0016833]
	Learning Rate: 0.00168327
	LOSS [training: 0.11889830843440058 | validation: 0.274885341982994]
	TIME [epoch: 6.79 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v15_20240719_004754/states/model_facs_v4_dec2b_2dpca_v15_415.pth
	Model improved!!!
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12792635118662166		[learning rate: 0.0016753]
	Learning Rate: 0.00167534
	LOSS [training: 0.12792635118662166 | validation: 0.3688609438887746]
	TIME [epoch: 6.75 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12349978227989974		[learning rate: 0.0016674]
	Learning Rate: 0.00166744
	LOSS [training: 0.12349978227989974 | validation: 0.3132723362605408]
	TIME [epoch: 6.73 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1386972568530958		[learning rate: 0.0016596]
	Learning Rate: 0.00165959
	LOSS [training: 0.1386972568530958 | validation: 0.3388037575284464]
	TIME [epoch: 6.78 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17591090098100953		[learning rate: 0.0016518]
	Learning Rate: 0.00165177
	LOSS [training: 0.17591090098100953 | validation: 0.32361440129172003]
	TIME [epoch: 6.78 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.139257753572509		[learning rate: 0.001644]
	Learning Rate: 0.00164398
	LOSS [training: 0.139257753572509 | validation: 0.31754258233254506]
	TIME [epoch: 6.75 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11974887705721536		[learning rate: 0.0016362]
	Learning Rate: 0.00163624
	LOSS [training: 0.11974887705721536 | validation: 0.3346238539689915]
	TIME [epoch: 6.75 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09236531886063476		[learning rate: 0.0016285]
	Learning Rate: 0.00162853
	LOSS [training: 0.09236531886063476 | validation: 0.3445747422827524]
	TIME [epoch: 6.79 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14392802342221153		[learning rate: 0.0016209]
	Learning Rate: 0.00162085
	LOSS [training: 0.14392802342221153 | validation: 0.29738273725357267]
	TIME [epoch: 6.79 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13359307253150302		[learning rate: 0.0016132]
	Learning Rate: 0.00161322
	LOSS [training: 0.13359307253150302 | validation: 0.3074041625711363]
	TIME [epoch: 6.76 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09252629214707682		[learning rate: 0.0016056]
	Learning Rate: 0.00160561
	LOSS [training: 0.09252629214707682 | validation: 0.32283370216937446]
	TIME [epoch: 6.78 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10416534381075601		[learning rate: 0.001598]
	Learning Rate: 0.00159805
	LOSS [training: 0.10416534381075601 | validation: 0.2999717089854851]
	TIME [epoch: 6.75 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15455306745249192		[learning rate: 0.0015905]
	Learning Rate: 0.00159052
	LOSS [training: 0.15455306745249192 | validation: 0.28799743641901027]
	TIME [epoch: 6.74 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1340663590314348		[learning rate: 0.001583]
	Learning Rate: 0.00158302
	LOSS [training: 0.1340663590314348 | validation: 0.33230590118124026]
	TIME [epoch: 6.76 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12502789868365705		[learning rate: 0.0015756]
	Learning Rate: 0.00157556
	LOSS [training: 0.12502789868365705 | validation: 0.3826776406848611]
	TIME [epoch: 6.79 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11737660232608953		[learning rate: 0.0015681]
	Learning Rate: 0.00156814
	LOSS [training: 0.11737660232608953 | validation: 0.3371781570680114]
	TIME [epoch: 6.77 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11552331959014189		[learning rate: 0.0015607]
	Learning Rate: 0.00156075
	LOSS [training: 0.11552331959014189 | validation: 0.35680166271608627]
	TIME [epoch: 6.75 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13663647831303852		[learning rate: 0.0015534]
	Learning Rate: 0.0015534
	LOSS [training: 0.13663647831303852 | validation: 0.3305413082421935]
	TIME [epoch: 6.78 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14871454691780797		[learning rate: 0.0015461]
	Learning Rate: 0.00154608
	LOSS [training: 0.14871454691780797 | validation: 0.32106791514550964]
	TIME [epoch: 6.76 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13812758332552216		[learning rate: 0.0015388]
	Learning Rate: 0.00153879
	LOSS [training: 0.13812758332552216 | validation: 0.3281444187443364]
	TIME [epoch: 6.77 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13209926064646588		[learning rate: 0.0015315]
	Learning Rate: 0.00153154
	LOSS [training: 0.13209926064646588 | validation: 0.2990657634846182]
	TIME [epoch: 6.8 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11673816259016534		[learning rate: 0.0015243]
	Learning Rate: 0.00152432
	LOSS [training: 0.11673816259016534 | validation: 0.346836163218295]
	TIME [epoch: 6.72 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12189295374390609		[learning rate: 0.0015171]
	Learning Rate: 0.00151714
	LOSS [training: 0.12189295374390609 | validation: 0.3189668545179103]
	TIME [epoch: 6.74 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1273605600706239		[learning rate: 0.00151]
	Learning Rate: 0.00150999
	LOSS [training: 0.1273605600706239 | validation: 0.32727079471160786]
	TIME [epoch: 6.78 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13565119286200503		[learning rate: 0.0015029]
	Learning Rate: 0.00150288
	LOSS [training: 0.13565119286200503 | validation: 0.2853250040612761]
	TIME [epoch: 6.83 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10531222746691055		[learning rate: 0.0014958]
	Learning Rate: 0.00149579
	LOSS [training: 0.10531222746691055 | validation: 0.3006212548978611]
	TIME [epoch: 6.74 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11294749381449495		[learning rate: 0.0014887]
	Learning Rate: 0.00148875
	LOSS [training: 0.11294749381449495 | validation: 0.3017414750082658]
	TIME [epoch: 6.78 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11914569136226867		[learning rate: 0.0014817]
	Learning Rate: 0.00148173
	LOSS [training: 0.11914569136226867 | validation: 0.2977109801259279]
	TIME [epoch: 6.8 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12202805272706749		[learning rate: 0.0014747]
	Learning Rate: 0.00147475
	LOSS [training: 0.12202805272706749 | validation: 0.3653743268089984]
	TIME [epoch: 6.77 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13673533362957277		[learning rate: 0.0014678]
	Learning Rate: 0.0014678
	LOSS [training: 0.13673533362957277 | validation: 0.3245405059171259]
	TIME [epoch: 6.74 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12466621423539823		[learning rate: 0.0014609]
	Learning Rate: 0.00146088
	LOSS [training: 0.12466621423539823 | validation: 0.3119127610838547]
	TIME [epoch: 6.79 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12945270268682935		[learning rate: 0.001454]
	Learning Rate: 0.001454
	LOSS [training: 0.12945270268682935 | validation: 0.3237337226655296]
	TIME [epoch: 6.78 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11773351237195474		[learning rate: 0.0014471]
	Learning Rate: 0.00144715
	LOSS [training: 0.11773351237195474 | validation: 0.3050768830468735]
	TIME [epoch: 6.75 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10514338934943342		[learning rate: 0.0014403]
	Learning Rate: 0.00144033
	LOSS [training: 0.10514338934943342 | validation: 0.2979413232914646]
	TIME [epoch: 6.75 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12596098953998391		[learning rate: 0.0014335]
	Learning Rate: 0.00143354
	LOSS [training: 0.12596098953998391 | validation: 0.2864651468181987]
	TIME [epoch: 6.8 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15056134973926655		[learning rate: 0.0014268]
	Learning Rate: 0.00142679
	LOSS [training: 0.15056134973926655 | validation: 0.34476543254770503]
	TIME [epoch: 6.77 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12660910938336206		[learning rate: 0.0014201]
	Learning Rate: 0.00142006
	LOSS [training: 0.12660910938336206 | validation: 0.31531701231328557]
	TIME [epoch: 6.74 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12750806934391307		[learning rate: 0.0014134]
	Learning Rate: 0.00141337
	LOSS [training: 0.12750806934391307 | validation: 0.32512064755822395]
	TIME [epoch: 6.72 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11491644690320535		[learning rate: 0.0014067]
	Learning Rate: 0.00140671
	LOSS [training: 0.11491644690320535 | validation: 0.2955350656611162]
	TIME [epoch: 6.77 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11239372463243597		[learning rate: 0.0014001]
	Learning Rate: 0.00140008
	LOSS [training: 0.11239372463243597 | validation: 0.310739331146749]
	TIME [epoch: 6.77 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11624261147196115		[learning rate: 0.0013935]
	Learning Rate: 0.00139349
	LOSS [training: 0.11624261147196115 | validation: 0.3008054950611421]
	TIME [epoch: 6.78 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13885299685702435		[learning rate: 0.0013869]
	Learning Rate: 0.00138692
	LOSS [training: 0.13885299685702435 | validation: 0.3406976339593676]
	TIME [epoch: 6.74 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12660083028944044		[learning rate: 0.0013804]
	Learning Rate: 0.00138038
	LOSS [training: 0.12660083028944044 | validation: 0.3087369821234537]
	TIME [epoch: 6.75 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1096603522881449		[learning rate: 0.0013739]
	Learning Rate: 0.00137388
	LOSS [training: 0.1096603522881449 | validation: 0.2958558758613053]
	TIME [epoch: 6.79 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12665016870689103		[learning rate: 0.0013674]
	Learning Rate: 0.00136741
	LOSS [training: 0.12665016870689103 | validation: 0.29413144692372617]
	TIME [epoch: 6.81 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1203164799869975		[learning rate: 0.001361]
	Learning Rate: 0.00136096
	LOSS [training: 0.1203164799869975 | validation: 0.30339962566925877]
	TIME [epoch: 6.74 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1347582154353544		[learning rate: 0.0013545]
	Learning Rate: 0.00135455
	LOSS [training: 0.1347582154353544 | validation: 0.3363456043616457]
	TIME [epoch: 6.73 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12829561035565523		[learning rate: 0.0013482]
	Learning Rate: 0.00134817
	LOSS [training: 0.12829561035565523 | validation: 0.3162067031958715]
	TIME [epoch: 6.77 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11090381544673597		[learning rate: 0.0013418]
	Learning Rate: 0.00134181
	LOSS [training: 0.11090381544673597 | validation: 0.3340360705761427]
	TIME [epoch: 6.75 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11322416358381157		[learning rate: 0.0013355]
	Learning Rate: 0.00133549
	LOSS [training: 0.11322416358381157 | validation: 0.3381899993523646]
	TIME [epoch: 6.78 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1255531567158107		[learning rate: 0.0013292]
	Learning Rate: 0.0013292
	LOSS [training: 0.1255531567158107 | validation: 0.3072559196405516]
	TIME [epoch: 6.77 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13404162113521875		[learning rate: 0.0013229]
	Learning Rate: 0.00132293
	LOSS [training: 0.13404162113521875 | validation: 0.31688282690386976]
	TIME [epoch: 6.75 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1408100272798761		[learning rate: 0.0013167]
	Learning Rate: 0.0013167
	LOSS [training: 0.1408100272798761 | validation: 0.3226970325591851]
	TIME [epoch: 6.75 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11758068194776819		[learning rate: 0.0013105]
	Learning Rate: 0.0013105
	LOSS [training: 0.11758068194776819 | validation: 0.3272574911533615]
	TIME [epoch: 6.73 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12261152086150288		[learning rate: 0.0013043]
	Learning Rate: 0.00130432
	LOSS [training: 0.12261152086150288 | validation: 0.32593782943309857]
	TIME [epoch: 6.77 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13069753627635947		[learning rate: 0.0012982]
	Learning Rate: 0.00129818
	LOSS [training: 0.13069753627635947 | validation: 0.3208239308285841]
	TIME [epoch: 6.76 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11978054805873581		[learning rate: 0.0012921]
	Learning Rate: 0.00129206
	LOSS [training: 0.11978054805873581 | validation: 0.31165378742398464]
	TIME [epoch: 6.75 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11285330460851357		[learning rate: 0.001286]
	Learning Rate: 0.00128597
	LOSS [training: 0.11285330460851357 | validation: 0.31511625469675875]
	TIME [epoch: 6.73 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13532574022942243		[learning rate: 0.0012799]
	Learning Rate: 0.00127991
	LOSS [training: 0.13532574022942243 | validation: 0.2871248543537777]
	TIME [epoch: 6.77 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12882221102558655		[learning rate: 0.0012739]
	Learning Rate: 0.00127388
	LOSS [training: 0.12882221102558655 | validation: 0.30918542097729645]
	TIME [epoch: 6.73 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0994906054449501		[learning rate: 0.0012679]
	Learning Rate: 0.00126788
	LOSS [training: 0.0994906054449501 | validation: 0.3105535952785061]
	TIME [epoch: 6.77 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11716298113752154		[learning rate: 0.0012619]
	Learning Rate: 0.0012619
	LOSS [training: 0.11716298113752154 | validation: 0.3234418671417626]
	TIME [epoch: 6.74 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1327577723296255		[learning rate: 0.001256]
	Learning Rate: 0.00125596
	LOSS [training: 0.1327577723296255 | validation: 0.31810594094221284]
	TIME [epoch: 6.71 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1299665402578059		[learning rate: 0.00125]
	Learning Rate: 0.00125004
	LOSS [training: 0.1299665402578059 | validation: 0.3149741999138479]
	TIME [epoch: 6.73 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11654199613973105		[learning rate: 0.0012441]
	Learning Rate: 0.00124415
	LOSS [training: 0.11654199613973105 | validation: 0.3153770012022436]
	TIME [epoch: 6.73 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10819066094738046		[learning rate: 0.0012383]
	Learning Rate: 0.00123828
	LOSS [training: 0.10819066094738046 | validation: 0.3233124539959161]
	TIME [epoch: 6.74 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11314277203257092		[learning rate: 0.0012324]
	Learning Rate: 0.00123245
	LOSS [training: 0.11314277203257092 | validation: 0.3236675651467719]
	TIME [epoch: 6.74 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1265702247506404		[learning rate: 0.0012266]
	Learning Rate: 0.00122664
	LOSS [training: 0.1265702247506404 | validation: 0.30823887141977857]
	TIME [epoch: 6.78 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10903229875657398		[learning rate: 0.0012209]
	Learning Rate: 0.00122086
	LOSS [training: 0.10903229875657398 | validation: 0.30166269625157577]
	TIME [epoch: 6.74 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1212724615269936		[learning rate: 0.0012151]
	Learning Rate: 0.00121511
	LOSS [training: 0.1212724615269936 | validation: 0.2953652046219485]
	TIME [epoch: 6.75 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12419235579994309		[learning rate: 0.0012094]
	Learning Rate: 0.00120938
	LOSS [training: 0.12419235579994309 | validation: 0.33243704755936315]
	TIME [epoch: 6.75 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14398033569500393		[learning rate: 0.0012037]
	Learning Rate: 0.00120368
	LOSS [training: 0.14398033569500393 | validation: 0.2945078884359562]
	TIME [epoch: 6.75 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1156387540664187		[learning rate: 0.001198]
	Learning Rate: 0.00119801
	LOSS [training: 0.1156387540664187 | validation: 0.27681457754719846]
	TIME [epoch: 6.75 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.131385204764486		[learning rate: 0.0011924]
	Learning Rate: 0.00119237
	LOSS [training: 0.131385204764486 | validation: 0.2921283574117223]
	TIME [epoch: 6.72 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13264317219974592		[learning rate: 0.0011867]
	Learning Rate: 0.00118675
	LOSS [training: 0.13264317219974592 | validation: 0.3361857683588901]
	TIME [epoch: 6.76 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1368548760015694		[learning rate: 0.0011812]
	Learning Rate: 0.00118116
	LOSS [training: 0.1368548760015694 | validation: 0.32125517870155373]
	TIME [epoch: 6.77 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09011978909936327		[learning rate: 0.0011756]
	Learning Rate: 0.00117559
	LOSS [training: 0.09011978909936327 | validation: 0.3054389600601998]
	TIME [epoch: 6.77 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11610934978170322		[learning rate: 0.0011701]
	Learning Rate: 0.00117005
	LOSS [training: 0.11610934978170322 | validation: 0.3142437282354442]
	TIME [epoch: 6.74 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12360473575628098		[learning rate: 0.0011645]
	Learning Rate: 0.00116454
	LOSS [training: 0.12360473575628098 | validation: 0.29959437218647283]
	TIME [epoch: 6.75 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11259403365342002		[learning rate: 0.0011591]
	Learning Rate: 0.00115905
	LOSS [training: 0.11259403365342002 | validation: 0.3314428304536893]
	TIME [epoch: 6.75 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10699093100888167		[learning rate: 0.0011536]
	Learning Rate: 0.00115359
	LOSS [training: 0.10699093100888167 | validation: 0.29443598928927606]
	TIME [epoch: 6.76 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12723529329976827		[learning rate: 0.0011482]
	Learning Rate: 0.00114815
	LOSS [training: 0.12723529329976827 | validation: 0.33204098929620784]
	TIME [epoch: 6.78 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12402511458849436		[learning rate: 0.0011427]
	Learning Rate: 0.00114274
	LOSS [training: 0.12402511458849436 | validation: 0.28764909856343207]
	TIME [epoch: 6.79 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12856608111358625		[learning rate: 0.0011374]
	Learning Rate: 0.00113736
	LOSS [training: 0.12856608111358625 | validation: 0.32522230123491147]
	TIME [epoch: 6.82 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12050948165592143		[learning rate: 0.001132]
	Learning Rate: 0.001132
	LOSS [training: 0.12050948165592143 | validation: 0.2992776476533552]
	TIME [epoch: 6.74 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1159156037632006		[learning rate: 0.0011267]
	Learning Rate: 0.00112667
	LOSS [training: 0.1159156037632006 | validation: 0.3260863474762838]
	TIME [epoch: 6.76 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11456458155499619		[learning rate: 0.0011214]
	Learning Rate: 0.00112136
	LOSS [training: 0.11456458155499619 | validation: 0.32011000217223873]
	TIME [epoch: 34.7 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11981601224507486		[learning rate: 0.0011161]
	Learning Rate: 0.00111607
	LOSS [training: 0.11981601224507486 | validation: 0.30592205556426366]
	TIME [epoch: 14.6 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1176502172494736		[learning rate: 0.0011108]
	Learning Rate: 0.00111081
	LOSS [training: 0.1176502172494736 | validation: 0.31440633351708974]
	TIME [epoch: 14.6 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10976764760842464		[learning rate: 0.0011056]
	Learning Rate: 0.00110558
	LOSS [training: 0.10976764760842464 | validation: 0.3606025401623968]
	TIME [epoch: 14.7 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11803077072855134		[learning rate: 0.0011004]
	Learning Rate: 0.00110037
	LOSS [training: 0.11803077072855134 | validation: 0.30445347062901185]
	TIME [epoch: 14.6 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12104171078125786		[learning rate: 0.0010952]
	Learning Rate: 0.00109518
	LOSS [training: 0.12104171078125786 | validation: 0.32111072592790724]
	TIME [epoch: 14.6 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11868546127072631		[learning rate: 0.00109]
	Learning Rate: 0.00109002
	LOSS [training: 0.11868546127072631 | validation: 0.3115694739508075]
	TIME [epoch: 14.6 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14036817769016263		[learning rate: 0.0010849]
	Learning Rate: 0.00108489
	LOSS [training: 0.14036817769016263 | validation: 0.29487457353430313]
	TIME [epoch: 14.5 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12072311289348804		[learning rate: 0.0010798]
	Learning Rate: 0.00107978
	LOSS [training: 0.12072311289348804 | validation: 0.32607514731815623]
	TIME [epoch: 14.6 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11993596967884476		[learning rate: 0.0010747]
	Learning Rate: 0.00107469
	LOSS [training: 0.11993596967884476 | validation: 0.3170051307734366]
	TIME [epoch: 14.7 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09845402834484782		[learning rate: 0.0010696]
	Learning Rate: 0.00106962
	LOSS [training: 0.09845402834484782 | validation: 0.3066906606364542]
	TIME [epoch: 14.6 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11520436190409675		[learning rate: 0.0010646]
	Learning Rate: 0.00106458
	LOSS [training: 0.11520436190409675 | validation: 0.3012306908325348]
	TIME [epoch: 14.7 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12868505743586484		[learning rate: 0.0010596]
	Learning Rate: 0.00105957
	LOSS [training: 0.12868505743586484 | validation: 0.3296347588014073]
	TIME [epoch: 14.6 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14586901328413174		[learning rate: 0.0010546]
	Learning Rate: 0.00105457
	LOSS [training: 0.14586901328413174 | validation: 0.2873391481365105]
	TIME [epoch: 14.6 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12147389765891926		[learning rate: 0.0010496]
	Learning Rate: 0.0010496
	LOSS [training: 0.12147389765891926 | validation: 0.3171811451037736]
	TIME [epoch: 14.6 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11711489738960759		[learning rate: 0.0010447]
	Learning Rate: 0.00104466
	LOSS [training: 0.11711489738960759 | validation: 0.2892000072655588]
	TIME [epoch: 14.6 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13434724928421493		[learning rate: 0.0010397]
	Learning Rate: 0.00103974
	LOSS [training: 0.13434724928421493 | validation: 0.3392534162939427]
	TIME [epoch: 14.6 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12486523863308119		[learning rate: 0.0010348]
	Learning Rate: 0.00103484
	LOSS [training: 0.12486523863308119 | validation: 0.32373280297984564]
	TIME [epoch: 14.6 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13898331436445885		[learning rate: 0.00103]
	Learning Rate: 0.00102996
	LOSS [training: 0.13898331436445885 | validation: 0.3069149059526635]
	TIME [epoch: 14.6 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12190082673599742		[learning rate: 0.0010251]
	Learning Rate: 0.00102511
	LOSS [training: 0.12190082673599742 | validation: 0.32720075592660547]
	TIME [epoch: 14.6 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11690094787936006		[learning rate: 0.0010203]
	Learning Rate: 0.00102028
	LOSS [training: 0.11690094787936006 | validation: 0.28991747890865893]
	TIME [epoch: 14.6 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11170069067841182		[learning rate: 0.0010155]
	Learning Rate: 0.00101547
	LOSS [training: 0.11170069067841182 | validation: 0.32674475654738905]
	TIME [epoch: 14.6 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11526266566641563		[learning rate: 0.0010107]
	Learning Rate: 0.00101068
	LOSS [training: 0.11526266566641563 | validation: 0.33896890721028694]
	TIME [epoch: 14.6 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11899507910536383		[learning rate: 0.0010059]
	Learning Rate: 0.00100592
	LOSS [training: 0.11899507910536383 | validation: 0.30125062326610386]
	TIME [epoch: 14.6 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12438198825802481		[learning rate: 0.0010012]
	Learning Rate: 0.00100118
	LOSS [training: 0.12438198825802481 | validation: 0.32384841920004903]
	TIME [epoch: 14.5 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12890087946561368		[learning rate: 0.00099646]
	Learning Rate: 0.000996464
	LOSS [training: 0.12890087946561368 | validation: 0.2978607604574276]
	TIME [epoch: 14.5 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09342542615174348		[learning rate: 0.00099177]
	Learning Rate: 0.000991768
	LOSS [training: 0.09342542615174348 | validation: 0.33173134146852856]
	TIME [epoch: 14.6 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13240878965748856		[learning rate: 0.0009871]
	Learning Rate: 0.000987095
	LOSS [training: 0.13240878965748856 | validation: 0.33540832582960645]
	TIME [epoch: 14.6 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11133186904249062		[learning rate: 0.00098244]
	Learning Rate: 0.000982444
	LOSS [training: 0.11133186904249062 | validation: 0.3056188177814984]
	TIME [epoch: 14.6 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1542483260882342		[learning rate: 0.00097781]
	Learning Rate: 0.000977814
	LOSS [training: 0.1542483260882342 | validation: 0.33413979362106616]
	TIME [epoch: 14.6 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11405349334981144		[learning rate: 0.00097321]
	Learning Rate: 0.000973207
	LOSS [training: 0.11405349334981144 | validation: 0.295093357328852]
	TIME [epoch: 14.6 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11648840082662439		[learning rate: 0.00096862]
	Learning Rate: 0.000968621
	LOSS [training: 0.11648840082662439 | validation: 0.31583279817828175]
	TIME [epoch: 14.6 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11189667471748407		[learning rate: 0.00096406]
	Learning Rate: 0.000964057
	LOSS [training: 0.11189667471748407 | validation: 0.312846669109951]
	TIME [epoch: 14.6 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1098328943438225		[learning rate: 0.00095951]
	Learning Rate: 0.000959514
	LOSS [training: 0.1098328943438225 | validation: 0.31284170133218764]
	TIME [epoch: 14.6 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11087818833889111		[learning rate: 0.00095499]
	Learning Rate: 0.000954993
	LOSS [training: 0.11087818833889111 | validation: 0.3348338445176189]
	TIME [epoch: 14.6 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.119737407935923		[learning rate: 0.00095049]
	Learning Rate: 0.000950493
	LOSS [training: 0.119737407935923 | validation: 0.33415562527771886]
	TIME [epoch: 14.6 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12853713731406746		[learning rate: 0.00094601]
	Learning Rate: 0.000946014
	LOSS [training: 0.12853713731406746 | validation: 0.2994196505764368]
	TIME [epoch: 14.6 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13177913635150212		[learning rate: 0.00094156]
	Learning Rate: 0.000941556
	LOSS [training: 0.13177913635150212 | validation: 0.32176655694926903]
	TIME [epoch: 14.6 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10936255020144629		[learning rate: 0.00093712]
	Learning Rate: 0.000937119
	LOSS [training: 0.10936255020144629 | validation: 0.2825769303779616]
	TIME [epoch: 14.6 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1208116617206545		[learning rate: 0.0009327]
	Learning Rate: 0.000932703
	LOSS [training: 0.1208116617206545 | validation: 0.29216873923223746]
	TIME [epoch: 14.6 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13221788733756878		[learning rate: 0.00092831]
	Learning Rate: 0.000928309
	LOSS [training: 0.13221788733756878 | validation: 0.3362259482638497]
	TIME [epoch: 14.6 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12980450739138533		[learning rate: 0.00092393]
	Learning Rate: 0.000923934
	LOSS [training: 0.12980450739138533 | validation: 0.3180336308870029]
	TIME [epoch: 14.6 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14538126857208553		[learning rate: 0.00091958]
	Learning Rate: 0.000919581
	LOSS [training: 0.14538126857208553 | validation: 0.28961288448126954]
	TIME [epoch: 14.6 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11011616536097502		[learning rate: 0.00091525]
	Learning Rate: 0.000915247
	LOSS [training: 0.11011616536097502 | validation: 0.30414606977053693]
	TIME [epoch: 14.6 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11788349729815732		[learning rate: 0.00091093]
	Learning Rate: 0.000910934
	LOSS [training: 0.11788349729815732 | validation: 0.3173307425746726]
	TIME [epoch: 14.6 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10102940616599698		[learning rate: 0.00090664]
	Learning Rate: 0.000906642
	LOSS [training: 0.10102940616599698 | validation: 0.36450214341957915]
	TIME [epoch: 14.6 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10652778101571807		[learning rate: 0.00090237]
	Learning Rate: 0.00090237
	LOSS [training: 0.10652778101571807 | validation: 0.2866180221899475]
	TIME [epoch: 14.6 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11334155020832842		[learning rate: 0.00089812]
	Learning Rate: 0.000898118
	LOSS [training: 0.11334155020832842 | validation: 0.32995083762195027]
	TIME [epoch: 14.6 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11090651263992812		[learning rate: 0.00089389]
	Learning Rate: 0.000893886
	LOSS [training: 0.11090651263992812 | validation: 0.30681555898036533]
	TIME [epoch: 14.7 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1276760070089477		[learning rate: 0.00088967]
	Learning Rate: 0.000889674
	LOSS [training: 0.1276760070089477 | validation: 0.3317976060621912]
	TIME [epoch: 14.6 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11242798486712362		[learning rate: 0.00088548]
	Learning Rate: 0.000885481
	LOSS [training: 0.11242798486712362 | validation: 0.29133633319713864]
	TIME [epoch: 14.6 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13210229432195839		[learning rate: 0.00088131]
	Learning Rate: 0.000881309
	LOSS [training: 0.13210229432195839 | validation: 0.3215787277843365]
	TIME [epoch: 14.6 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12204727873196591		[learning rate: 0.00087716]
	Learning Rate: 0.000877156
	LOSS [training: 0.12204727873196591 | validation: 0.2851629195512177]
	TIME [epoch: 14.6 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10746859621043563		[learning rate: 0.00087302]
	Learning Rate: 0.000873023
	LOSS [training: 0.10746859621043563 | validation: 0.29271703080140576]
	TIME [epoch: 14.6 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11721584449081268		[learning rate: 0.00086891]
	Learning Rate: 0.000868909
	LOSS [training: 0.11721584449081268 | validation: 0.2799406414832746]
	TIME [epoch: 14.7 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12763081590838302		[learning rate: 0.00086481]
	Learning Rate: 0.000864815
	LOSS [training: 0.12763081590838302 | validation: 0.30905044309411744]
	TIME [epoch: 14.7 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1300479869367938		[learning rate: 0.00086074]
	Learning Rate: 0.00086074
	LOSS [training: 0.1300479869367938 | validation: 0.3259026582533951]
	TIME [epoch: 14.6 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10585767913240192		[learning rate: 0.00085668]
	Learning Rate: 0.000856684
	LOSS [training: 0.10585767913240192 | validation: 0.30021115293804823]
	TIME [epoch: 14.6 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13229315294537097		[learning rate: 0.00085265]
	Learning Rate: 0.000852647
	LOSS [training: 0.13229315294537097 | validation: 0.2740749745963169]
	TIME [epoch: 14.6 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v15_20240719_004754/states/model_facs_v4_dec2b_2dpca_v15_559.pth
	Model improved!!!
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14056927614062167		[learning rate: 0.00084863]
	Learning Rate: 0.000848629
	LOSS [training: 0.14056927614062167 | validation: 0.284921665049233]
	TIME [epoch: 14.6 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1138502584705263		[learning rate: 0.00084463]
	Learning Rate: 0.00084463
	LOSS [training: 0.1138502584705263 | validation: 0.3041207512754984]
	TIME [epoch: 14.6 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12390432033037482		[learning rate: 0.00084065]
	Learning Rate: 0.00084065
	LOSS [training: 0.12390432033037482 | validation: 0.29813381729885186]
	TIME [epoch: 14.6 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12007797012492945		[learning rate: 0.00083669]
	Learning Rate: 0.000836689
	LOSS [training: 0.12007797012492945 | validation: 0.3396143107819592]
	TIME [epoch: 14.6 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12464666121773316		[learning rate: 0.00083275]
	Learning Rate: 0.000832746
	LOSS [training: 0.12464666121773316 | validation: 0.32237786978019606]
	TIME [epoch: 14.6 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11483157873641783		[learning rate: 0.00082882]
	Learning Rate: 0.000828822
	LOSS [training: 0.11483157873641783 | validation: 0.32948935136604374]
	TIME [epoch: 14.6 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12333394834364043		[learning rate: 0.00082492]
	Learning Rate: 0.000824917
	LOSS [training: 0.12333394834364043 | validation: 0.29728809224701047]
	TIME [epoch: 14.6 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12429916569299176		[learning rate: 0.00082103]
	Learning Rate: 0.00082103
	LOSS [training: 0.12429916569299176 | validation: 0.3372281853053268]
	TIME [epoch: 14.6 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1109879677834937		[learning rate: 0.00081716]
	Learning Rate: 0.000817161
	LOSS [training: 0.1109879677834937 | validation: 0.3168515723499907]
	TIME [epoch: 14.6 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11217729442897591		[learning rate: 0.00081331]
	Learning Rate: 0.000813311
	LOSS [training: 0.11217729442897591 | validation: 0.3313712868070908]
	TIME [epoch: 14.6 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11274435105512831		[learning rate: 0.00080948]
	Learning Rate: 0.000809478
	LOSS [training: 0.11274435105512831 | validation: 0.31264037635150954]
	TIME [epoch: 14.6 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10493780566849567		[learning rate: 0.00080566]
	Learning Rate: 0.000805664
	LOSS [training: 0.10493780566849567 | validation: 0.3304108619788916]
	TIME [epoch: 14.6 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11354758375431352		[learning rate: 0.00080187]
	Learning Rate: 0.000801868
	LOSS [training: 0.11354758375431352 | validation: 0.2937721985312706]
	TIME [epoch: 14.6 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12558932888976812		[learning rate: 0.00079809]
	Learning Rate: 0.000798089
	LOSS [training: 0.12558932888976812 | validation: 0.3043169906565691]
	TIME [epoch: 14.6 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.111051025100484		[learning rate: 0.00079433]
	Learning Rate: 0.000794328
	LOSS [training: 0.111051025100484 | validation: 0.30358486358019043]
	TIME [epoch: 14.6 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10130204053820704		[learning rate: 0.00079059]
	Learning Rate: 0.000790585
	LOSS [training: 0.10130204053820704 | validation: 0.3138140721948778]
	TIME [epoch: 14.6 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11735112127829515		[learning rate: 0.00078686]
	Learning Rate: 0.00078686
	LOSS [training: 0.11735112127829515 | validation: 0.3195837141403551]
	TIME [epoch: 14.6 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12062680795281036		[learning rate: 0.00078315]
	Learning Rate: 0.000783152
	LOSS [training: 0.12062680795281036 | validation: 0.32706819344699717]
	TIME [epoch: 14.7 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1033200720712946		[learning rate: 0.00077946]
	Learning Rate: 0.000779462
	LOSS [training: 0.1033200720712946 | validation: 0.2918259768238278]
	TIME [epoch: 14.6 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11741235394883509		[learning rate: 0.00077579]
	Learning Rate: 0.000775789
	LOSS [training: 0.11741235394883509 | validation: 0.32899758811348356]
	TIME [epoch: 14.7 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10086389620491659		[learning rate: 0.00077213]
	Learning Rate: 0.000772133
	LOSS [training: 0.10086389620491659 | validation: 0.2867538153081046]
	TIME [epoch: 14.6 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1519924440983914		[learning rate: 0.00076849]
	Learning Rate: 0.000768495
	LOSS [training: 0.1519924440983914 | validation: 0.30677960584475716]
	TIME [epoch: 14.6 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13169667939057533		[learning rate: 0.00076487]
	Learning Rate: 0.000764874
	LOSS [training: 0.13169667939057533 | validation: 0.28191594817337834]
	TIME [epoch: 14.6 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12274345890534491		[learning rate: 0.00076127]
	Learning Rate: 0.00076127
	LOSS [training: 0.12274345890534491 | validation: 0.2834228172141184]
	TIME [epoch: 14.6 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11275032438674346		[learning rate: 0.00075768]
	Learning Rate: 0.000757682
	LOSS [training: 0.11275032438674346 | validation: 0.3025154994921551]
	TIME [epoch: 14.6 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13035690125180305		[learning rate: 0.00075411]
	Learning Rate: 0.000754112
	LOSS [training: 0.13035690125180305 | validation: 0.34838532437598424]
	TIME [epoch: 14.6 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11413376881600149		[learning rate: 0.00075056]
	Learning Rate: 0.000750559
	LOSS [training: 0.11413376881600149 | validation: 0.2966048288942554]
	TIME [epoch: 14.6 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1324166431356979		[learning rate: 0.00074702]
	Learning Rate: 0.000747022
	LOSS [training: 0.1324166431356979 | validation: 0.2697557318861902]
	TIME [epoch: 14.6 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v15_20240719_004754/states/model_facs_v4_dec2b_2dpca_v15_587.pth
	Model improved!!!
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11438026666580342		[learning rate: 0.0007435]
	Learning Rate: 0.000743502
	LOSS [training: 0.11438026666580342 | validation: 0.313749990237424]
	TIME [epoch: 14.5 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11586676159469507		[learning rate: 0.00074]
	Learning Rate: 0.000739998
	LOSS [training: 0.11586676159469507 | validation: 0.2969401204725752]
	TIME [epoch: 14.6 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12991765268533942		[learning rate: 0.00073651]
	Learning Rate: 0.000736511
	LOSS [training: 0.12991765268533942 | validation: 0.3439509871481856]
	TIME [epoch: 14.6 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1245343965033808		[learning rate: 0.00073304]
	Learning Rate: 0.000733041
	LOSS [training: 0.1245343965033808 | validation: 0.2939079555573035]
	TIME [epoch: 14.6 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11548756164620375		[learning rate: 0.00072959]
	Learning Rate: 0.000729587
	LOSS [training: 0.11548756164620375 | validation: 0.31479383016074486]
	TIME [epoch: 14.6 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11503046186550134		[learning rate: 0.00072615]
	Learning Rate: 0.000726149
	LOSS [training: 0.11503046186550134 | validation: 0.3018112535576928]
	TIME [epoch: 14.6 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10726181771676509		[learning rate: 0.00072273]
	Learning Rate: 0.000722727
	LOSS [training: 0.10726181771676509 | validation: 0.28952195448733814]
	TIME [epoch: 14.6 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11401904488315626		[learning rate: 0.00071932]
	Learning Rate: 0.000719321
	LOSS [training: 0.11401904488315626 | validation: 0.3100887719476099]
	TIME [epoch: 14.6 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.128212654353817		[learning rate: 0.00071593]
	Learning Rate: 0.000715932
	LOSS [training: 0.128212654353817 | validation: 0.32825960938738863]
	TIME [epoch: 14.6 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12083694994202723		[learning rate: 0.00071256]
	Learning Rate: 0.000712558
	LOSS [training: 0.12083694994202723 | validation: 0.3012316301586003]
	TIME [epoch: 14.6 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10456897923958658		[learning rate: 0.0007092]
	Learning Rate: 0.000709201
	LOSS [training: 0.10456897923958658 | validation: 0.30507052994275163]
	TIME [epoch: 14.6 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11397829469894452		[learning rate: 0.00070586]
	Learning Rate: 0.000705859
	LOSS [training: 0.11397829469894452 | validation: 0.30204484948090715]
	TIME [epoch: 14.6 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12481607199457294		[learning rate: 0.00070253]
	Learning Rate: 0.000702533
	LOSS [training: 0.12481607199457294 | validation: 0.2820481615703715]
	TIME [epoch: 14.6 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10699117750893275		[learning rate: 0.00069922]
	Learning Rate: 0.000699222
	LOSS [training: 0.10699117750893275 | validation: 0.28755389680210586]
	TIME [epoch: 14.6 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1214519726667117		[learning rate: 0.00069593]
	Learning Rate: 0.000695928
	LOSS [training: 0.1214519726667117 | validation: 0.30686510019960184]
	TIME [epoch: 14.6 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13604010599136973		[learning rate: 0.00069265]
	Learning Rate: 0.000692648
	LOSS [training: 0.13604010599136973 | validation: 0.32485606442623266]
	TIME [epoch: 14.6 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1214605783234265		[learning rate: 0.00068938]
	Learning Rate: 0.000689385
	LOSS [training: 0.1214605783234265 | validation: 0.2931262146131184]
	TIME [epoch: 14.6 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12019532176979321		[learning rate: 0.00068614]
	Learning Rate: 0.000686136
	LOSS [training: 0.12019532176979321 | validation: 0.3183141881812382]
	TIME [epoch: 14.6 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10063603411973943		[learning rate: 0.0006829]
	Learning Rate: 0.000682903
	LOSS [training: 0.10063603411973943 | validation: 0.3149489085615912]
	TIME [epoch: 14.5 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10406321553298864		[learning rate: 0.00067969]
	Learning Rate: 0.000679685
	LOSS [training: 0.10406321553298864 | validation: 0.31060577121058536]
	TIME [epoch: 14.6 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12103216685398602		[learning rate: 0.00067648]
	Learning Rate: 0.000676482
	LOSS [training: 0.12103216685398602 | validation: 0.28158868352911404]
	TIME [epoch: 14.6 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10474630607872688		[learning rate: 0.00067329]
	Learning Rate: 0.000673295
	LOSS [training: 0.10474630607872688 | validation: 0.3117803629244656]
	TIME [epoch: 14.6 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10596142716805929		[learning rate: 0.00067012]
	Learning Rate: 0.000670122
	LOSS [training: 0.10596142716805929 | validation: 0.3183959967402913]
	TIME [epoch: 14.6 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1103619369038534		[learning rate: 0.00066696]
	Learning Rate: 0.000666964
	LOSS [training: 0.1103619369038534 | validation: 0.2995272839137618]
	TIME [epoch: 14.6 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1294936470480718		[learning rate: 0.00066382]
	Learning Rate: 0.000663821
	LOSS [training: 0.1294936470480718 | validation: 0.31430258364661023]
	TIME [epoch: 14.6 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12578440794781393		[learning rate: 0.00066069]
	Learning Rate: 0.000660694
	LOSS [training: 0.12578440794781393 | validation: 0.2953107190084169]
	TIME [epoch: 14.6 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10992015050874741		[learning rate: 0.00065758]
	Learning Rate: 0.00065758
	LOSS [training: 0.10992015050874741 | validation: 0.3299646484686092]
	TIME [epoch: 14.6 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10374863227889497		[learning rate: 0.00065448]
	Learning Rate: 0.000654482
	LOSS [training: 0.10374863227889497 | validation: 0.2991114883782602]
	TIME [epoch: 14.6 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10748229471917478		[learning rate: 0.0006514]
	Learning Rate: 0.000651398
	LOSS [training: 0.10748229471917478 | validation: 0.2885712316649464]
	TIME [epoch: 14.6 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11562049781827496		[learning rate: 0.00064833]
	Learning Rate: 0.000648328
	LOSS [training: 0.11562049781827496 | validation: 0.2807822003696077]
	TIME [epoch: 14.6 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10309314867288193		[learning rate: 0.00064527]
	Learning Rate: 0.000645273
	LOSS [training: 0.10309314867288193 | validation: 0.3027455966065752]
	TIME [epoch: 14.6 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12898607066371062		[learning rate: 0.00064223]
	Learning Rate: 0.000642232
	LOSS [training: 0.12898607066371062 | validation: 0.2955429908488054]
	TIME [epoch: 14.6 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10484702671755276		[learning rate: 0.00063921]
	Learning Rate: 0.000639206
	LOSS [training: 0.10484702671755276 | validation: 0.30686612353392134]
	TIME [epoch: 14.6 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0962682624114734		[learning rate: 0.00063619]
	Learning Rate: 0.000636194
	LOSS [training: 0.0962682624114734 | validation: 0.2877328749702113]
	TIME [epoch: 14.6 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1186876837389962		[learning rate: 0.0006332]
	Learning Rate: 0.000633196
	LOSS [training: 0.1186876837389962 | validation: 0.30006424499549356]
	TIME [epoch: 14.6 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11066928100531358		[learning rate: 0.00063021]
	Learning Rate: 0.000630213
	LOSS [training: 0.11066928100531358 | validation: 0.30347789013396176]
	TIME [epoch: 14.6 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1160455584230369		[learning rate: 0.00062724]
	Learning Rate: 0.000627243
	LOSS [training: 0.1160455584230369 | validation: 0.31314488145351627]
	TIME [epoch: 14.6 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12292464558011382		[learning rate: 0.00062429]
	Learning Rate: 0.000624287
	LOSS [training: 0.12292464558011382 | validation: 0.2931402950647124]
	TIME [epoch: 14.6 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12495390496398814		[learning rate: 0.00062135]
	Learning Rate: 0.000621346
	LOSS [training: 0.12495390496398814 | validation: 0.2869038498600797]
	TIME [epoch: 14.6 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1272239749901536		[learning rate: 0.00061842]
	Learning Rate: 0.000618418
	LOSS [training: 0.1272239749901536 | validation: 0.32085046116773946]
	TIME [epoch: 14.6 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11032505921330645		[learning rate: 0.0006155]
	Learning Rate: 0.000615504
	LOSS [training: 0.11032505921330645 | validation: 0.30340546129897106]
	TIME [epoch: 14.6 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11550672469112994		[learning rate: 0.0006126]
	Learning Rate: 0.000612604
	LOSS [training: 0.11550672469112994 | validation: 0.3159074105381943]
	TIME [epoch: 14.6 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11090858100458995		[learning rate: 0.00060972]
	Learning Rate: 0.000609717
	LOSS [training: 0.11090858100458995 | validation: 0.28488338803728436]
	TIME [epoch: 14.6 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13833344063826195		[learning rate: 0.00060684]
	Learning Rate: 0.000606844
	LOSS [training: 0.13833344063826195 | validation: 0.3414969329613059]
	TIME [epoch: 14.6 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.116451659436471		[learning rate: 0.00060398]
	Learning Rate: 0.000603984
	LOSS [training: 0.116451659436471 | validation: 0.3158771721195872]
	TIME [epoch: 14.6 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1099458855286595		[learning rate: 0.00060114]
	Learning Rate: 0.000601138
	LOSS [training: 0.1099458855286595 | validation: 0.2973220411164426]
	TIME [epoch: 14.6 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11606266772888424		[learning rate: 0.00059831]
	Learning Rate: 0.000598306
	LOSS [training: 0.11606266772888424 | validation: 0.3120311237137816]
	TIME [epoch: 14.6 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12176765497699604		[learning rate: 0.00059549]
	Learning Rate: 0.000595486
	LOSS [training: 0.12176765497699604 | validation: 0.2835296856619462]
	TIME [epoch: 14.6 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1110395847251908		[learning rate: 0.00059268]
	Learning Rate: 0.00059268
	LOSS [training: 0.1110395847251908 | validation: 0.2889607975613595]
	TIME [epoch: 14.6 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10532418229330348		[learning rate: 0.00058989]
	Learning Rate: 0.000589888
	LOSS [training: 0.10532418229330348 | validation: 0.2880920658705605]
	TIME [epoch: 14.6 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09793013185678043		[learning rate: 0.00058711]
	Learning Rate: 0.000587108
	LOSS [training: 0.09793013185678043 | validation: 0.3211943026330441]
	TIME [epoch: 14.7 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12557210302143423		[learning rate: 0.00058434]
	Learning Rate: 0.000584341
	LOSS [training: 0.12557210302143423 | validation: 0.31252273199910924]
	TIME [epoch: 14.6 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12352923302597144		[learning rate: 0.00058159]
	Learning Rate: 0.000581588
	LOSS [training: 0.12352923302597144 | validation: 0.2992583512964486]
	TIME [epoch: 14.6 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1158147199753079		[learning rate: 0.00057885]
	Learning Rate: 0.000578847
	LOSS [training: 0.1158147199753079 | validation: 0.3021444644439222]
	TIME [epoch: 14.7 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11807031406083955		[learning rate: 0.00057612]
	Learning Rate: 0.00057612
	LOSS [training: 0.11807031406083955 | validation: 0.2990366190140866]
	TIME [epoch: 14.6 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11523520316447555		[learning rate: 0.00057341]
	Learning Rate: 0.000573405
	LOSS [training: 0.11523520316447555 | validation: 0.27620303568486454]
	TIME [epoch: 14.7 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10871727753172165		[learning rate: 0.0005707]
	Learning Rate: 0.000570703
	LOSS [training: 0.10871727753172165 | validation: 0.3195112927013209]
	TIME [epoch: 14.7 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11335747374460511		[learning rate: 0.00056801]
	Learning Rate: 0.000568014
	LOSS [training: 0.11335747374460511 | validation: 0.2945390133859116]
	TIME [epoch: 14.7 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15066617262669485		[learning rate: 0.00056534]
	Learning Rate: 0.000565337
	LOSS [training: 0.15066617262669485 | validation: 0.3014995321743478]
	TIME [epoch: 14.6 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1119033093679727		[learning rate: 0.00056267]
	Learning Rate: 0.000562673
	LOSS [training: 0.1119033093679727 | validation: 0.3204923529715468]
	TIME [epoch: 14.7 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10671656038023972		[learning rate: 0.00056002]
	Learning Rate: 0.000560022
	LOSS [training: 0.10671656038023972 | validation: 0.28102377769764675]
	TIME [epoch: 14.7 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12082871445881552		[learning rate: 0.00055738]
	Learning Rate: 0.000557383
	LOSS [training: 0.12082871445881552 | validation: 0.2972388873811267]
	TIME [epoch: 14.6 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10490072526229978		[learning rate: 0.00055476]
	Learning Rate: 0.000554757
	LOSS [training: 0.10490072526229978 | validation: 0.3173372779697691]
	TIME [epoch: 14.5 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11294394837755647		[learning rate: 0.00055214]
	Learning Rate: 0.000552143
	LOSS [training: 0.11294394837755647 | validation: 0.30384452338923107]
	TIME [epoch: 14.7 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11674095509948583		[learning rate: 0.00054954]
	Learning Rate: 0.000549541
	LOSS [training: 0.11674095509948583 | validation: 0.3258774894119114]
	TIME [epoch: 14.6 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12841257871984235		[learning rate: 0.00054695]
	Learning Rate: 0.000546951
	LOSS [training: 0.12841257871984235 | validation: 0.3020518862642698]
	TIME [epoch: 14.7 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12759168936302992		[learning rate: 0.00054437]
	Learning Rate: 0.000544374
	LOSS [training: 0.12759168936302992 | validation: 0.30081347921031654]
	TIME [epoch: 14.7 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10525848437189617		[learning rate: 0.00054181]
	Learning Rate: 0.000541809
	LOSS [training: 0.10525848437189617 | validation: 0.3010498804325916]
	TIME [epoch: 14.7 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12966245333877777		[learning rate: 0.00053926]
	Learning Rate: 0.000539256
	LOSS [training: 0.12966245333877777 | validation: 0.3046458605791443]
	TIME [epoch: 14.6 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12183775990320815		[learning rate: 0.00053671]
	Learning Rate: 0.000536715
	LOSS [training: 0.12183775990320815 | validation: 0.29296589603512524]
	TIME [epoch: 14.7 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1305081216257937		[learning rate: 0.00053419]
	Learning Rate: 0.000534186
	LOSS [training: 0.1305081216257937 | validation: 0.3133907260736152]
	TIME [epoch: 14.6 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10175058656049515		[learning rate: 0.00053167]
	Learning Rate: 0.000531669
	LOSS [training: 0.10175058656049515 | validation: 0.30856123704365884]
	TIME [epoch: 14.7 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.121819797920472		[learning rate: 0.00052916]
	Learning Rate: 0.000529163
	LOSS [training: 0.121819797920472 | validation: 0.2908786502779635]
	TIME [epoch: 14.6 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10580120925647514		[learning rate: 0.00052667]
	Learning Rate: 0.00052667
	LOSS [training: 0.10580120925647514 | validation: 0.31881635051258705]
	TIME [epoch: 14.6 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11697282507991892		[learning rate: 0.00052419]
	Learning Rate: 0.000524188
	LOSS [training: 0.11697282507991892 | validation: 0.31894388141842966]
	TIME [epoch: 14.6 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10104564384404256		[learning rate: 0.00052172]
	Learning Rate: 0.000521718
	LOSS [training: 0.10104564384404256 | validation: 0.31866054873340255]
	TIME [epoch: 14.7 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09319147209717486		[learning rate: 0.00051926]
	Learning Rate: 0.00051926
	LOSS [training: 0.09319147209717486 | validation: 0.30560652351367545]
	TIME [epoch: 14.6 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12154855810800762		[learning rate: 0.00051681]
	Learning Rate: 0.000516813
	LOSS [training: 0.12154855810800762 | validation: 0.29289281862370303]
	TIME [epoch: 14.6 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11233457659275653		[learning rate: 0.00051438]
	Learning Rate: 0.000514378
	LOSS [training: 0.11233457659275653 | validation: 0.3204569054097441]
	TIME [epoch: 14.6 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.129793803438484		[learning rate: 0.00051195]
	Learning Rate: 0.000511954
	LOSS [training: 0.129793803438484 | validation: 0.26720392236327783]
	TIME [epoch: 14.6 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v15_20240719_004754/states/model_facs_v4_dec2b_2dpca_v15_667.pth
	Model improved!!!
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11983320997023231		[learning rate: 0.00050954]
	Learning Rate: 0.000509541
	LOSS [training: 0.11983320997023231 | validation: 0.31171661189119365]
	TIME [epoch: 14.6 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1003479471761549		[learning rate: 0.00050714]
	Learning Rate: 0.00050714
	LOSS [training: 0.1003479471761549 | validation: 0.2899059929756629]
	TIME [epoch: 14.6 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12245385019434685		[learning rate: 0.00050475]
	Learning Rate: 0.000504751
	LOSS [training: 0.12245385019434685 | validation: 0.32476231754763196]
	TIME [epoch: 14.6 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11634830715516223		[learning rate: 0.00050237]
	Learning Rate: 0.000502372
	LOSS [training: 0.11634830715516223 | validation: 0.2999201463094832]
	TIME [epoch: 14.6 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11097797193493285		[learning rate: 0.00050001]
	Learning Rate: 0.000500005
	LOSS [training: 0.11097797193493285 | validation: 0.2965635894805995]
	TIME [epoch: 14.7 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11138789223315057		[learning rate: 0.00049765]
	Learning Rate: 0.000497649
	LOSS [training: 0.11138789223315057 | validation: 0.3054576176618845]
	TIME [epoch: 14.6 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10499225491281952		[learning rate: 0.0004953]
	Learning Rate: 0.000495304
	LOSS [training: 0.10499225491281952 | validation: 0.30975358121680646]
	TIME [epoch: 14.6 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10588669579506618		[learning rate: 0.00049297]
	Learning Rate: 0.00049297
	LOSS [training: 0.10588669579506618 | validation: 0.33627562074611983]
	TIME [epoch: 14.6 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12191983274035852		[learning rate: 0.00049065]
	Learning Rate: 0.000490647
	LOSS [training: 0.12191983274035852 | validation: 0.28414921644144864]
	TIME [epoch: 14.6 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13062028555463157		[learning rate: 0.00048834]
	Learning Rate: 0.000488335
	LOSS [training: 0.13062028555463157 | validation: 0.3321406668761102]
	TIME [epoch: 14.7 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12022455439127044		[learning rate: 0.00048603]
	Learning Rate: 0.000486034
	LOSS [training: 0.12022455439127044 | validation: 0.3242478970523954]
	TIME [epoch: 14.6 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1318762381890087		[learning rate: 0.00048374]
	Learning Rate: 0.000483744
	LOSS [training: 0.1318762381890087 | validation: 0.2965235954167269]
	TIME [epoch: 14.6 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12566833278682937		[learning rate: 0.00048146]
	Learning Rate: 0.000481464
	LOSS [training: 0.12566833278682937 | validation: 0.31090962506203446]
	TIME [epoch: 14.6 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12242569606140347		[learning rate: 0.0004792]
	Learning Rate: 0.000479196
	LOSS [training: 0.12242569606140347 | validation: 0.3206943804390546]
	TIME [epoch: 14.6 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12668816242485184		[learning rate: 0.00047694]
	Learning Rate: 0.000476938
	LOSS [training: 0.12668816242485184 | validation: 0.3048080101816812]
	TIME [epoch: 14.6 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12168052757969897		[learning rate: 0.00047469]
	Learning Rate: 0.00047469
	LOSS [training: 0.12168052757969897 | validation: 0.29775611261120233]
	TIME [epoch: 14.6 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1205683268931837		[learning rate: 0.00047245]
	Learning Rate: 0.000472453
	LOSS [training: 0.1205683268931837 | validation: 0.3048665310425079]
	TIME [epoch: 14.6 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12590702700328166		[learning rate: 0.00047023]
	Learning Rate: 0.000470227
	LOSS [training: 0.12590702700328166 | validation: 0.3126343044459957]
	TIME [epoch: 14.6 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11634419967368936		[learning rate: 0.00046801]
	Learning Rate: 0.000468011
	LOSS [training: 0.11634419967368936 | validation: 0.3345914340100528]
	TIME [epoch: 14.6 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11151832543787354		[learning rate: 0.00046581]
	Learning Rate: 0.000465806
	LOSS [training: 0.11151832543787354 | validation: 0.3263889361560414]
	TIME [epoch: 14.7 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11279458885936372		[learning rate: 0.00046361]
	Learning Rate: 0.000463611
	LOSS [training: 0.11279458885936372 | validation: 0.29178647898676485]
	TIME [epoch: 14.6 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13806994667680267		[learning rate: 0.00046143]
	Learning Rate: 0.000461426
	LOSS [training: 0.13806994667680267 | validation: 0.2955413960354768]
	TIME [epoch: 14.6 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11145896315462366		[learning rate: 0.00045925]
	Learning Rate: 0.000459252
	LOSS [training: 0.11145896315462366 | validation: 0.32032736216836133]
	TIME [epoch: 14.6 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10099351116937952		[learning rate: 0.00045709]
	Learning Rate: 0.000457088
	LOSS [training: 0.10099351116937952 | validation: 0.30410363873899054]
	TIME [epoch: 14.6 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11567316672364332		[learning rate: 0.00045493]
	Learning Rate: 0.000454934
	LOSS [training: 0.11567316672364332 | validation: 0.30575833681650155]
	TIME [epoch: 14.6 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09716524862036556		[learning rate: 0.00045279]
	Learning Rate: 0.000452791
	LOSS [training: 0.09716524862036556 | validation: 0.31061664096029357]
	TIME [epoch: 14.7 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11523963353685017		[learning rate: 0.00045066]
	Learning Rate: 0.000450657
	LOSS [training: 0.11523963353685017 | validation: 0.32169397912287995]
	TIME [epoch: 14.6 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10748298793964128		[learning rate: 0.00044853]
	Learning Rate: 0.000448533
	LOSS [training: 0.10748298793964128 | validation: 0.33252516230777796]
	TIME [epoch: 14.6 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12419246242817127		[learning rate: 0.00044642]
	Learning Rate: 0.00044642
	LOSS [training: 0.12419246242817127 | validation: 0.2830466810666998]
	TIME [epoch: 14.6 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11865807167937606		[learning rate: 0.00044432]
	Learning Rate: 0.000444316
	LOSS [training: 0.11865807167937606 | validation: 0.29111349918910795]
	TIME [epoch: 14.6 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11042814703203249		[learning rate: 0.00044222]
	Learning Rate: 0.000442223
	LOSS [training: 0.11042814703203249 | validation: 0.31641492640024593]
	TIME [epoch: 14.6 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.113256247208682		[learning rate: 0.00044014]
	Learning Rate: 0.000440139
	LOSS [training: 0.113256247208682 | validation: 0.3053671503259728]
	TIME [epoch: 14.7 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11541518340666138		[learning rate: 0.00043806]
	Learning Rate: 0.000438065
	LOSS [training: 0.11541518340666138 | validation: 0.3123889600916932]
	TIME [epoch: 14.6 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11197567067655172		[learning rate: 0.000436]
	Learning Rate: 0.000436001
	LOSS [training: 0.11197567067655172 | validation: 0.31546417570337365]
	TIME [epoch: 14.6 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11505047745325117		[learning rate: 0.00043395]
	Learning Rate: 0.000433946
	LOSS [training: 0.11505047745325117 | validation: 0.30508115075042236]
	TIME [epoch: 14.6 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12012648992097993		[learning rate: 0.0004319]
	Learning Rate: 0.000431901
	LOSS [training: 0.12012648992097993 | validation: 0.3172056160305833]
	TIME [epoch: 14.7 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11081670656187154		[learning rate: 0.00042987]
	Learning Rate: 0.000429866
	LOSS [training: 0.11081670656187154 | validation: 0.31582736023463365]
	TIME [epoch: 14.6 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12150160149638184		[learning rate: 0.00042784]
	Learning Rate: 0.000427841
	LOSS [training: 0.12150160149638184 | validation: 0.30079957888422226]
	TIME [epoch: 14.7 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11024268789461014		[learning rate: 0.00042582]
	Learning Rate: 0.000425825
	LOSS [training: 0.11024268789461014 | validation: 0.31826157918135695]
	TIME [epoch: 14.7 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10667859679146074		[learning rate: 0.00042382]
	Learning Rate: 0.000423818
	LOSS [training: 0.10667859679146074 | validation: 0.3218823097218614]
	TIME [epoch: 14.6 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10669460203290657		[learning rate: 0.00042182]
	Learning Rate: 0.000421821
	LOSS [training: 0.10669460203290657 | validation: 0.3123704939444169]
	TIME [epoch: 14.7 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1051206077873181		[learning rate: 0.00041983]
	Learning Rate: 0.000419833
	LOSS [training: 0.1051206077873181 | validation: 0.3148317482491021]
	TIME [epoch: 14.6 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13696908923436898		[learning rate: 0.00041786]
	Learning Rate: 0.000417855
	LOSS [training: 0.13696908923436898 | validation: 0.3179954904888274]
	TIME [epoch: 14.6 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12387555722365977		[learning rate: 0.00041589]
	Learning Rate: 0.000415886
	LOSS [training: 0.12387555722365977 | validation: 0.3161967697693493]
	TIME [epoch: 14.6 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10204803230595134		[learning rate: 0.00041393]
	Learning Rate: 0.000413926
	LOSS [training: 0.10204803230595134 | validation: 0.31721689637535866]
	TIME [epoch: 14.6 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10482846612740031		[learning rate: 0.00041198]
	Learning Rate: 0.000411976
	LOSS [training: 0.10482846612740031 | validation: 0.3336549791751672]
	TIME [epoch: 14.6 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12001864632564674		[learning rate: 0.00041003]
	Learning Rate: 0.000410035
	LOSS [training: 0.12001864632564674 | validation: 0.28969758336381857]
	TIME [epoch: 14.6 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10281057815900381		[learning rate: 0.0004081]
	Learning Rate: 0.000408102
	LOSS [training: 0.10281057815900381 | validation: 0.3123745347692889]
	TIME [epoch: 14.6 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10808450016164822		[learning rate: 0.00040618]
	Learning Rate: 0.000406179
	LOSS [training: 0.10808450016164822 | validation: 0.3182238018603842]
	TIME [epoch: 14.6 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12072801445546776		[learning rate: 0.00040427]
	Learning Rate: 0.000404266
	LOSS [training: 0.12072801445546776 | validation: 0.3111605235169108]
	TIME [epoch: 14.7 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13279771910709043		[learning rate: 0.00040236]
	Learning Rate: 0.000402361
	LOSS [training: 0.13279771910709043 | validation: 0.2887489121324578]
	TIME [epoch: 14.6 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1122681450442363		[learning rate: 0.00040046]
	Learning Rate: 0.000400465
	LOSS [training: 0.1122681450442363 | validation: 0.3291679666263273]
	TIME [epoch: 14.6 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12024393915519134		[learning rate: 0.00039858]
	Learning Rate: 0.000398578
	LOSS [training: 0.12024393915519134 | validation: 0.3023587582480101]
	TIME [epoch: 14.6 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09908452421795177		[learning rate: 0.0003967]
	Learning Rate: 0.000396699
	LOSS [training: 0.09908452421795177 | validation: 0.2944019001231219]
	TIME [epoch: 14.7 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12394576881704689		[learning rate: 0.00039483]
	Learning Rate: 0.00039483
	LOSS [training: 0.12394576881704689 | validation: 0.3169612719222016]
	TIME [epoch: 14.6 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10410357720004984		[learning rate: 0.00039297]
	Learning Rate: 0.00039297
	LOSS [training: 0.10410357720004984 | validation: 0.3203327292217171]
	TIME [epoch: 14.7 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10554172641739296		[learning rate: 0.00039112]
	Learning Rate: 0.000391118
	LOSS [training: 0.10554172641739296 | validation: 0.2850619350502913]
	TIME [epoch: 14.7 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09634349492875582		[learning rate: 0.00038927]
	Learning Rate: 0.000389275
	LOSS [training: 0.09634349492875582 | validation: 0.32309961018191974]
	TIME [epoch: 14.6 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09727044746432104		[learning rate: 0.00038744]
	Learning Rate: 0.000387441
	LOSS [training: 0.09727044746432104 | validation: 0.3136383172656886]
	TIME [epoch: 14.6 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11986511429823682		[learning rate: 0.00038561]
	Learning Rate: 0.000385615
	LOSS [training: 0.11986511429823682 | validation: 0.3061876401506626]
	TIME [epoch: 14.6 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1113664237789449		[learning rate: 0.0003838]
	Learning Rate: 0.000383798
	LOSS [training: 0.1113664237789449 | validation: 0.3059265825281271]
	TIME [epoch: 14.6 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09523512513975861		[learning rate: 0.00038199]
	Learning Rate: 0.000381989
	LOSS [training: 0.09523512513975861 | validation: 0.314534815646378]
	TIME [epoch: 14.7 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12435384922071646		[learning rate: 0.00038019]
	Learning Rate: 0.000380189
	LOSS [training: 0.12435384922071646 | validation: 0.3147927968173654]
	TIME [epoch: 14.6 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09830824520222603		[learning rate: 0.0003784]
	Learning Rate: 0.000378398
	LOSS [training: 0.09830824520222603 | validation: 0.3244804509109321]
	TIME [epoch: 14.6 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12042812847263851		[learning rate: 0.00037661]
	Learning Rate: 0.000376615
	LOSS [training: 0.12042812847263851 | validation: 0.31586886459527075]
	TIME [epoch: 14.6 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10675168937940685		[learning rate: 0.00037484]
	Learning Rate: 0.00037484
	LOSS [training: 0.10675168937940685 | validation: 0.3165114934921288]
	TIME [epoch: 14.6 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12423510969808031		[learning rate: 0.00037307]
	Learning Rate: 0.000373074
	LOSS [training: 0.12423510969808031 | validation: 0.3183713537462074]
	TIME [epoch: 14.6 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1263988547839112		[learning rate: 0.00037132]
	Learning Rate: 0.000371316
	LOSS [training: 0.1263988547839112 | validation: 0.3115924142942153]
	TIME [epoch: 14.6 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11934279751301805		[learning rate: 0.00036957]
	Learning Rate: 0.000369566
	LOSS [training: 0.11934279751301805 | validation: 0.31121739379803187]
	TIME [epoch: 14.6 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11288846584453685		[learning rate: 0.00036782]
	Learning Rate: 0.000367825
	LOSS [training: 0.11288846584453685 | validation: 0.30951219912829403]
	TIME [epoch: 14.6 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11543899892295031		[learning rate: 0.00036609]
	Learning Rate: 0.000366092
	LOSS [training: 0.11543899892295031 | validation: 0.31573905809597413]
	TIME [epoch: 14.6 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1225493958597994		[learning rate: 0.00036437]
	Learning Rate: 0.000364367
	LOSS [training: 0.1225493958597994 | validation: 0.3034450594305533]
	TIME [epoch: 14.6 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13720504567205585		[learning rate: 0.00036265]
	Learning Rate: 0.00036265
	LOSS [training: 0.13720504567205585 | validation: 0.32039107382413834]
	TIME [epoch: 14.6 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12988261745800203		[learning rate: 0.00036094]
	Learning Rate: 0.000360941
	LOSS [training: 0.12988261745800203 | validation: 0.3031438995959416]
	TIME [epoch: 14.6 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11397053069220163		[learning rate: 0.00035924]
	Learning Rate: 0.00035924
	LOSS [training: 0.11397053069220163 | validation: 0.31023493278247855]
	TIME [epoch: 14.7 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11679018060690702		[learning rate: 0.00035755]
	Learning Rate: 0.000357547
	LOSS [training: 0.11679018060690702 | validation: 0.30517910827743666]
	TIME [epoch: 14.6 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1014689334168032		[learning rate: 0.00035586]
	Learning Rate: 0.000355862
	LOSS [training: 0.1014689334168032 | validation: 0.3221778603931177]
	TIME [epoch: 14.7 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11214102123538977		[learning rate: 0.00035419]
	Learning Rate: 0.000354185
	LOSS [training: 0.11214102123538977 | validation: 0.30415220108568936]
	TIME [epoch: 14.7 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1418689815761093		[learning rate: 0.00035252]
	Learning Rate: 0.000352517
	LOSS [training: 0.1418689815761093 | validation: 0.33334583411108853]
	TIME [epoch: 14.6 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09083487315999349		[learning rate: 0.00035086]
	Learning Rate: 0.000350855
	LOSS [training: 0.09083487315999349 | validation: 0.30423588361515735]
	TIME [epoch: 14.6 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12625297169639926		[learning rate: 0.0003492]
	Learning Rate: 0.000349202
	LOSS [training: 0.12625297169639926 | validation: 0.3093802141758717]
	TIME [epoch: 14.7 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11116533504941561		[learning rate: 0.00034756]
	Learning Rate: 0.000347557
	LOSS [training: 0.11116533504941561 | validation: 0.30992122601026634]
	TIME [epoch: 14.6 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12554997382910058		[learning rate: 0.00034592]
	Learning Rate: 0.000345919
	LOSS [training: 0.12554997382910058 | validation: 0.3047471753332144]
	TIME [epoch: 14.6 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10369474052674103		[learning rate: 0.00034429]
	Learning Rate: 0.000344289
	LOSS [training: 0.10369474052674103 | validation: 0.3109181916355491]
	TIME [epoch: 14.6 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12371731510765042		[learning rate: 0.00034267]
	Learning Rate: 0.000342667
	LOSS [training: 0.12371731510765042 | validation: 0.312528620791028]
	TIME [epoch: 14.6 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10533584311504854		[learning rate: 0.00034105]
	Learning Rate: 0.000341052
	LOSS [training: 0.10533584311504854 | validation: 0.3056282532092192]
	TIME [epoch: 14.6 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11870366710922749		[learning rate: 0.00033944]
	Learning Rate: 0.000339445
	LOSS [training: 0.11870366710922749 | validation: 0.31555436187525426]
	TIME [epoch: 14.6 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12200070841313868		[learning rate: 0.00033785]
	Learning Rate: 0.000337845
	LOSS [training: 0.12200070841313868 | validation: 0.3124825005956116]
	TIME [epoch: 14.6 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11793987304958925		[learning rate: 0.00033625]
	Learning Rate: 0.000336253
	LOSS [training: 0.11793987304958925 | validation: 0.2846256007187094]
	TIME [epoch: 14.6 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12411127659582114		[learning rate: 0.00033467]
	Learning Rate: 0.000334669
	LOSS [training: 0.12411127659582114 | validation: 0.3065707959772865]
	TIME [epoch: 14.6 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1126359389615803		[learning rate: 0.00033309]
	Learning Rate: 0.000333092
	LOSS [training: 0.1126359389615803 | validation: 0.3111340718818263]
	TIME [epoch: 14.6 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10688916412285995		[learning rate: 0.00033152]
	Learning Rate: 0.000331522
	LOSS [training: 0.10688916412285995 | validation: 0.3146433425537887]
	TIME [epoch: 14.6 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11356096848015883		[learning rate: 0.00032996]
	Learning Rate: 0.00032996
	LOSS [training: 0.11356096848015883 | validation: 0.3126926786286881]
	TIME [epoch: 14.6 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12323661334333519		[learning rate: 0.00032841]
	Learning Rate: 0.000328405
	LOSS [training: 0.12323661334333519 | validation: 0.28655396965318103]
	TIME [epoch: 14.6 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09899503186915011		[learning rate: 0.00032686]
	Learning Rate: 0.000326858
	LOSS [training: 0.09899503186915011 | validation: 0.3098051981485136]
	TIME [epoch: 14.6 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11405866037826931		[learning rate: 0.00032532]
	Learning Rate: 0.000325318
	LOSS [training: 0.11405866037826931 | validation: 0.29832012691738363]
	TIME [epoch: 14.6 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11484572188547634		[learning rate: 0.00032378]
	Learning Rate: 0.000323785
	LOSS [training: 0.11484572188547634 | validation: 0.300460934499693]
	TIME [epoch: 14.6 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10912344518664391		[learning rate: 0.00032226]
	Learning Rate: 0.000322259
	LOSS [training: 0.10912344518664391 | validation: 0.3065398873724248]
	TIME [epoch: 14.6 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1301251706399345		[learning rate: 0.00032074]
	Learning Rate: 0.000320741
	LOSS [training: 0.1301251706399345 | validation: 0.3073748344445901]
	TIME [epoch: 14.7 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.142544061550848		[learning rate: 0.00031923]
	Learning Rate: 0.000319229
	LOSS [training: 0.142544061550848 | validation: 0.31144569602854233]
	TIME [epoch: 14.6 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.106893745159179		[learning rate: 0.00031772]
	Learning Rate: 0.000317725
	LOSS [training: 0.106893745159179 | validation: 0.30319765280406263]
	TIME [epoch: 14.7 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11290776355456918		[learning rate: 0.00031623]
	Learning Rate: 0.000316228
	LOSS [training: 0.11290776355456918 | validation: 0.2901820584633967]
	TIME [epoch: 14.6 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10036568196963293		[learning rate: 0.00031474]
	Learning Rate: 0.000314738
	LOSS [training: 0.10036568196963293 | validation: 0.31880736436893525]
	TIME [epoch: 14.7 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09881126345272419		[learning rate: 0.00031325]
	Learning Rate: 0.000313255
	LOSS [training: 0.09881126345272419 | validation: 0.28665386751630917]
	TIME [epoch: 14.6 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11464470593401938		[learning rate: 0.00031178]
	Learning Rate: 0.000311778
	LOSS [training: 0.11464470593401938 | validation: 0.3065186997356133]
	TIME [epoch: 14.6 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09944233105029782		[learning rate: 0.00031031]
	Learning Rate: 0.000310309
	LOSS [training: 0.09944233105029782 | validation: 0.3196477038262856]
	TIME [epoch: 14.7 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10662989759595543		[learning rate: 0.00030885]
	Learning Rate: 0.000308847
	LOSS [training: 0.10662989759595543 | validation: 0.33196239481043743]
	TIME [epoch: 14.7 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09181460004233193		[learning rate: 0.00030739]
	Learning Rate: 0.000307392
	LOSS [training: 0.09181460004233193 | validation: 0.3063284676690136]
	TIME [epoch: 14.6 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12108280782611201		[learning rate: 0.00030594]
	Learning Rate: 0.000305943
	LOSS [training: 0.12108280782611201 | validation: 0.29885167628474657]
	TIME [epoch: 14.6 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11111881000799911		[learning rate: 0.0003045]
	Learning Rate: 0.000304502
	LOSS [training: 0.11111881000799911 | validation: 0.3077482074708161]
	TIME [epoch: 14.6 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1056299314092934		[learning rate: 0.00030307]
	Learning Rate: 0.000303067
	LOSS [training: 0.1056299314092934 | validation: 0.34472566685514816]
	TIME [epoch: 14.6 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11040861501372981		[learning rate: 0.00030164]
	Learning Rate: 0.000301639
	LOSS [training: 0.11040861501372981 | validation: 0.31475619058082227]
	TIME [epoch: 14.5 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1054296777246655		[learning rate: 0.00030022]
	Learning Rate: 0.000300217
	LOSS [training: 0.1054296777246655 | validation: 0.2977786466112372]
	TIME [epoch: 14.6 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1138833297327248		[learning rate: 0.0002988]
	Learning Rate: 0.000298803
	LOSS [training: 0.1138833297327248 | validation: 0.28918350928094905]
	TIME [epoch: 14.5 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11656893969998011		[learning rate: 0.00029739]
	Learning Rate: 0.000297395
	LOSS [training: 0.11656893969998011 | validation: 0.3005040836480565]
	TIME [epoch: 14.6 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10587614174458394		[learning rate: 0.00029599]
	Learning Rate: 0.000295993
	LOSS [training: 0.10587614174458394 | validation: 0.31052603841664606]
	TIME [epoch: 14.6 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10536354138666042		[learning rate: 0.0002946]
	Learning Rate: 0.000294599
	LOSS [training: 0.10536354138666042 | validation: 0.3016553410753636]
	TIME [epoch: 14.6 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14063723626771094		[learning rate: 0.00029321]
	Learning Rate: 0.00029321
	LOSS [training: 0.14063723626771094 | validation: 0.2853782220167557]
	TIME [epoch: 14.7 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15966561053962203		[learning rate: 0.00029183]
	Learning Rate: 0.000291829
	LOSS [training: 0.15966561053962203 | validation: 0.2783185904383076]
	TIME [epoch: 14.6 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1056052410031232		[learning rate: 0.00029045]
	Learning Rate: 0.000290454
	LOSS [training: 0.1056052410031232 | validation: 0.3089922072144452]
	TIME [epoch: 14.6 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11982619492997669		[learning rate: 0.00028909]
	Learning Rate: 0.000289085
	LOSS [training: 0.11982619492997669 | validation: 0.3055739411816581]
	TIME [epoch: 14.6 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11765667137082683		[learning rate: 0.00028772]
	Learning Rate: 0.000287723
	LOSS [training: 0.11765667137082683 | validation: 0.28637074448421124]
	TIME [epoch: 14.6 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10206001880048754		[learning rate: 0.00028637]
	Learning Rate: 0.000286367
	LOSS [training: 0.10206001880048754 | validation: 0.3015446427443462]
	TIME [epoch: 14.6 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10148480259394232		[learning rate: 0.00028502]
	Learning Rate: 0.000285018
	LOSS [training: 0.10148480259394232 | validation: 0.30373887879946]
	TIME [epoch: 14.7 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10607359255266746		[learning rate: 0.00028367]
	Learning Rate: 0.000283675
	LOSS [training: 0.10607359255266746 | validation: 0.3060651652158785]
	TIME [epoch: 14.6 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13003877811019512		[learning rate: 0.00028234]
	Learning Rate: 0.000282338
	LOSS [training: 0.13003877811019512 | validation: 0.2988016710109032]
	TIME [epoch: 14.6 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10550019458217269		[learning rate: 0.00028101]
	Learning Rate: 0.000281008
	LOSS [training: 0.10550019458217269 | validation: 0.3194624288704779]
	TIME [epoch: 14.7 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1221177282468137		[learning rate: 0.00027968]
	Learning Rate: 0.000279683
	LOSS [training: 0.1221177282468137 | validation: 0.2962338848560277]
	TIME [epoch: 14.6 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1200875531470709		[learning rate: 0.00027837]
	Learning Rate: 0.000278366
	LOSS [training: 0.1200875531470709 | validation: 0.308267228304853]
	TIME [epoch: 14.7 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09689107895033855		[learning rate: 0.00027705]
	Learning Rate: 0.000277054
	LOSS [training: 0.09689107895033855 | validation: 0.3020142124836772]
	TIME [epoch: 14.7 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11530059306744071		[learning rate: 0.00027575]
	Learning Rate: 0.000275748
	LOSS [training: 0.11530059306744071 | validation: 0.2932062967693939]
	TIME [epoch: 14.6 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11293833275728966		[learning rate: 0.00027445]
	Learning Rate: 0.000274449
	LOSS [training: 0.11293833275728966 | validation: 0.3125246607527613]
	TIME [epoch: 14.6 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.111033585143019		[learning rate: 0.00027316]
	Learning Rate: 0.000273156
	LOSS [training: 0.111033585143019 | validation: 0.31182138458195663]
	TIME [epoch: 14.6 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12281478484345441		[learning rate: 0.00027187]
	Learning Rate: 0.000271869
	LOSS [training: 0.12281478484345441 | validation: 0.3001055531993127]
	TIME [epoch: 14.6 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12617197759019425		[learning rate: 0.00027059]
	Learning Rate: 0.000270587
	LOSS [training: 0.12617197759019425 | validation: 0.3376727799360141]
	TIME [epoch: 14.6 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13310221268121883		[learning rate: 0.00026931]
	Learning Rate: 0.000269312
	LOSS [training: 0.13310221268121883 | validation: 0.295694300354531]
	TIME [epoch: 14.6 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11300956974580122		[learning rate: 0.00026804]
	Learning Rate: 0.000268043
	LOSS [training: 0.11300956974580122 | validation: 0.30411745749643615]
	TIME [epoch: 14.6 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12110584301618496		[learning rate: 0.00026678]
	Learning Rate: 0.00026678
	LOSS [training: 0.12110584301618496 | validation: 0.29945085611067773]
	TIME [epoch: 14.6 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1080396540247352		[learning rate: 0.00026552]
	Learning Rate: 0.000265523
	LOSS [training: 0.1080396540247352 | validation: 0.27652815482673887]
	TIME [epoch: 14.6 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13042282282782047		[learning rate: 0.00026427]
	Learning Rate: 0.000264272
	LOSS [training: 0.13042282282782047 | validation: 0.31449180500540747]
	TIME [epoch: 14.6 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1277141540724129		[learning rate: 0.00026303]
	Learning Rate: 0.000263027
	LOSS [training: 0.1277141540724129 | validation: 0.3269432086012916]
	TIME [epoch: 14.6 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1134618403067092		[learning rate: 0.00026179]
	Learning Rate: 0.000261787
	LOSS [training: 0.1134618403067092 | validation: 0.3107437343761824]
	TIME [epoch: 14.6 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11500625354788388		[learning rate: 0.00026055]
	Learning Rate: 0.000260554
	LOSS [training: 0.11500625354788388 | validation: 0.30753705136778936]
	TIME [epoch: 14.6 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11959017845672354		[learning rate: 0.00025933]
	Learning Rate: 0.000259326
	LOSS [training: 0.11959017845672354 | validation: 0.2986536590179292]
	TIME [epoch: 14.6 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1009658731583045		[learning rate: 0.0002581]
	Learning Rate: 0.000258104
	LOSS [training: 0.1009658731583045 | validation: 0.3075119596759461]
	TIME [epoch: 14.6 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11369645990035258		[learning rate: 0.00025689]
	Learning Rate: 0.000256888
	LOSS [training: 0.11369645990035258 | validation: 0.30659271673185295]
	TIME [epoch: 14.6 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1080355306676869		[learning rate: 0.00025568]
	Learning Rate: 0.000255677
	LOSS [training: 0.1080355306676869 | validation: 0.31588532669353375]
	TIME [epoch: 14.6 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11475532182196088		[learning rate: 0.00025447]
	Learning Rate: 0.000254473
	LOSS [training: 0.11475532182196088 | validation: 0.3176314764761264]
	TIME [epoch: 14.7 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10046371454284123		[learning rate: 0.00025327]
	Learning Rate: 0.000253274
	LOSS [training: 0.10046371454284123 | validation: 0.3053675675554553]
	TIME [epoch: 14.6 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10847252504538979		[learning rate: 0.00025208]
	Learning Rate: 0.00025208
	LOSS [training: 0.10847252504538979 | validation: 0.32295705929302465]
	TIME [epoch: 14.6 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11521424615739308		[learning rate: 0.00025089]
	Learning Rate: 0.000250892
	LOSS [training: 0.11521424615739308 | validation: 0.3136073389198324]
	TIME [epoch: 14.6 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09459739733215826		[learning rate: 0.00024971]
	Learning Rate: 0.00024971
	LOSS [training: 0.09459739733215826 | validation: 0.3197357602610562]
	TIME [epoch: 14.6 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1191599566725963		[learning rate: 0.00024853]
	Learning Rate: 0.000248533
	LOSS [training: 0.1191599566725963 | validation: 0.2833842619757804]
	TIME [epoch: 14.6 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12657975470540805		[learning rate: 0.00024736]
	Learning Rate: 0.000247362
	LOSS [training: 0.12657975470540805 | validation: 0.321967400617407]
	TIME [epoch: 14.6 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11246203419087834		[learning rate: 0.0002462]
	Learning Rate: 0.000246197
	LOSS [training: 0.11246203419087834 | validation: 0.33123243351855747]
	TIME [epoch: 14.6 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09797921395084654		[learning rate: 0.00024504]
	Learning Rate: 0.000245037
	LOSS [training: 0.09797921395084654 | validation: 0.3105822789113204]
	TIME [epoch: 14.6 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11573722268661665		[learning rate: 0.00024388]
	Learning Rate: 0.000243882
	LOSS [training: 0.11573722268661665 | validation: 0.3055768252667843]
	TIME [epoch: 14.6 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10842412934395161		[learning rate: 0.00024273]
	Learning Rate: 0.000242733
	LOSS [training: 0.10842412934395161 | validation: 0.2805245465008973]
	TIME [epoch: 14.6 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09966777044194833		[learning rate: 0.00024159]
	Learning Rate: 0.000241589
	LOSS [training: 0.09966777044194833 | validation: 0.29981880624171]
	TIME [epoch: 14.6 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12178871515054619		[learning rate: 0.00024045]
	Learning Rate: 0.00024045
	LOSS [training: 0.12178871515054619 | validation: 0.3055601473240879]
	TIME [epoch: 14.6 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10137832729110759		[learning rate: 0.00023932]
	Learning Rate: 0.000239317
	LOSS [training: 0.10137832729110759 | validation: 0.2921156143367116]
	TIME [epoch: 14.6 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11004534868222937		[learning rate: 0.00023819]
	Learning Rate: 0.00023819
	LOSS [training: 0.11004534868222937 | validation: 0.3213596112154366]
	TIME [epoch: 14.6 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1089033382645561		[learning rate: 0.00023707]
	Learning Rate: 0.000237067
	LOSS [training: 0.1089033382645561 | validation: 0.3108058847678931]
	TIME [epoch: 14.6 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1077690239372972		[learning rate: 0.00023595]
	Learning Rate: 0.00023595
	LOSS [training: 0.1077690239372972 | validation: 0.3155441857385601]
	TIME [epoch: 14.6 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10871584304652396		[learning rate: 0.00023484]
	Learning Rate: 0.000234838
	LOSS [training: 0.10871584304652396 | validation: 0.30831066990682127]
	TIME [epoch: 14.6 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10185699053499811		[learning rate: 0.00023373]
	Learning Rate: 0.000233732
	LOSS [training: 0.10185699053499811 | validation: 0.3010509680046712]
	TIME [epoch: 14.6 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09861308650176512		[learning rate: 0.00023263]
	Learning Rate: 0.00023263
	LOSS [training: 0.09861308650176512 | validation: 0.3178720923516156]
	TIME [epoch: 14.7 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1250087774482807		[learning rate: 0.00023153]
	Learning Rate: 0.000231534
	LOSS [training: 0.1250087774482807 | validation: 0.29923561857242087]
	TIME [epoch: 14.6 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1023512928060343		[learning rate: 0.00023044]
	Learning Rate: 0.000230443
	LOSS [training: 0.1023512928060343 | validation: 0.28240706007729394]
	TIME [epoch: 14.7 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1002927207765988		[learning rate: 0.00022936]
	Learning Rate: 0.000229357
	LOSS [training: 0.1002927207765988 | validation: 0.31051972269168343]
	TIME [epoch: 14.6 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11052560165558575		[learning rate: 0.00022828]
	Learning Rate: 0.000228277
	LOSS [training: 0.11052560165558575 | validation: 0.29950124265311323]
	TIME [epoch: 14.7 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1162233876670849		[learning rate: 0.0002272]
	Learning Rate: 0.000227201
	LOSS [training: 0.1162233876670849 | validation: 0.310033960888655]
	TIME [epoch: 14.6 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11298830703531951		[learning rate: 0.00022613]
	Learning Rate: 0.00022613
	LOSS [training: 0.11298830703531951 | validation: 0.30129670512701207]
	TIME [epoch: 14.7 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1080197995559969		[learning rate: 0.00022506]
	Learning Rate: 0.000225065
	LOSS [training: 0.1080197995559969 | validation: 0.2928143932961606]
	TIME [epoch: 14.6 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1053072476948545		[learning rate: 0.000224]
	Learning Rate: 0.000224004
	LOSS [training: 0.1053072476948545 | validation: 0.3078431035086581]
	TIME [epoch: 14.7 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10907858031333097		[learning rate: 0.00022295]
	Learning Rate: 0.000222949
	LOSS [training: 0.10907858031333097 | validation: 0.30783957776073667]
	TIME [epoch: 14.7 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1291439827988814		[learning rate: 0.0002219]
	Learning Rate: 0.000221898
	LOSS [training: 0.1291439827988814 | validation: 0.30816860827666787]
	TIME [epoch: 14.6 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10407024499552682		[learning rate: 0.00022085]
	Learning Rate: 0.000220853
	LOSS [training: 0.10407024499552682 | validation: 0.3046950667390209]
	TIME [epoch: 14.6 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11664703165970633		[learning rate: 0.00021981]
	Learning Rate: 0.000219812
	LOSS [training: 0.11664703165970633 | validation: 0.3118571666983388]
	TIME [epoch: 14.6 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1275417276644537		[learning rate: 0.00021878]
	Learning Rate: 0.000218776
	LOSS [training: 0.1275417276644537 | validation: 0.3011683174312152]
	TIME [epoch: 14.6 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10728283654830444		[learning rate: 0.00021775]
	Learning Rate: 0.000217745
	LOSS [training: 0.10728283654830444 | validation: 0.3285686256033079]
	TIME [epoch: 14.6 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.125689336783812		[learning rate: 0.00021672]
	Learning Rate: 0.000216719
	LOSS [training: 0.125689336783812 | validation: 0.30128731747667453]
	TIME [epoch: 14.6 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10764821738694888		[learning rate: 0.0002157]
	Learning Rate: 0.000215698
	LOSS [training: 0.10764821738694888 | validation: 0.31462493018922677]
	TIME [epoch: 14.6 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12375131838658382		[learning rate: 0.00021468]
	Learning Rate: 0.000214682
	LOSS [training: 0.12375131838658382 | validation: 0.30832827570639093]
	TIME [epoch: 14.6 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11012733324544405		[learning rate: 0.00021367]
	Learning Rate: 0.00021367
	LOSS [training: 0.11012733324544405 | validation: 0.28700208452464876]
	TIME [epoch: 14.6 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13788779456689035		[learning rate: 0.00021266]
	Learning Rate: 0.000212663
	LOSS [training: 0.13788779456689035 | validation: 0.2799142497731815]
	TIME [epoch: 14.6 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09941405211762437		[learning rate: 0.00021166]
	Learning Rate: 0.000211661
	LOSS [training: 0.09941405211762437 | validation: 0.29144533652563387]
	TIME [epoch: 14.5 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12290993539108587		[learning rate: 0.00021066]
	Learning Rate: 0.000210664
	LOSS [training: 0.12290993539108587 | validation: 0.3072808003864655]
	TIME [epoch: 14.6 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12441467586995861		[learning rate: 0.00020967]
	Learning Rate: 0.000209671
	LOSS [training: 0.12441467586995861 | validation: 0.30269782252339394]
	TIME [epoch: 14.6 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13665141068350373		[learning rate: 0.00020868]
	Learning Rate: 0.000208683
	LOSS [training: 0.13665141068350373 | validation: 0.29991473214695313]
	TIME [epoch: 14.6 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12079337090603089		[learning rate: 0.0002077]
	Learning Rate: 0.0002077
	LOSS [training: 0.12079337090603089 | validation: 0.3079493385769466]
	TIME [epoch: 14.6 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12733323310825317		[learning rate: 0.00020672]
	Learning Rate: 0.000206721
	LOSS [training: 0.12733323310825317 | validation: 0.3128178549039423]
	TIME [epoch: 14.6 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10568163889992688		[learning rate: 0.00020575]
	Learning Rate: 0.000205747
	LOSS [training: 0.10568163889992688 | validation: 0.30522685700723345]
	TIME [epoch: 14.6 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11615052174987175		[learning rate: 0.00020478]
	Learning Rate: 0.000204777
	LOSS [training: 0.11615052174987175 | validation: 0.2937122124499554]
	TIME [epoch: 14.6 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12057937549602685		[learning rate: 0.00020381]
	Learning Rate: 0.000203812
	LOSS [training: 0.12057937549602685 | validation: 0.30215416234388065]
	TIME [epoch: 14.6 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11427455370722789		[learning rate: 0.00020285]
	Learning Rate: 0.000202852
	LOSS [training: 0.11427455370722789 | validation: 0.29168558599848887]
	TIME [epoch: 14.6 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11151724754629422		[learning rate: 0.0002019]
	Learning Rate: 0.000201896
	LOSS [training: 0.11151724754629422 | validation: 0.3075364300883394]
	TIME [epoch: 14.6 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10318938823298388		[learning rate: 0.00020094]
	Learning Rate: 0.000200945
	LOSS [training: 0.10318938823298388 | validation: 0.31620767608117867]
	TIME [epoch: 14.6 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1031147079057219		[learning rate: 0.0002]
	Learning Rate: 0.000199998
	LOSS [training: 0.1031147079057219 | validation: 0.29791328837504905]
	TIME [epoch: 14.6 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12646730124486233		[learning rate: 0.00019906]
	Learning Rate: 0.000199056
	LOSS [training: 0.12646730124486233 | validation: 0.31559580396326886]
	TIME [epoch: 14.6 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12460060467560605		[learning rate: 0.00019812]
	Learning Rate: 0.000198118
	LOSS [training: 0.12460060467560605 | validation: 0.3051921057815415]
	TIME [epoch: 14.6 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v15_20240719_004754/states/model_facs_v4_dec2b_2dpca_v15_868.pth
Halted early. No improvement in validation loss for 200 epochs.
Finished training in 8713.811 seconds.
