Args:
Namespace(name='model_facs_v3_dec1b_2dpca_v13', outdir='out/model_training/model_facs_v3_dec1b_2dpca_v13', training_data='data/training_data/facs_v3/pca/dec1_fitonsubset/transition1_subset_epi_tr_ce_an_pc12/training', validation_data='data/training_data/facs_v3/pca/dec1_fitonsubset/transition1_subset_epi_tr_ce_an_pc12/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=10, batch_size=50, patience=200, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, quadratic_a=1.0, quadratic_b=1.0, ndims=2, nparams=2, nsigs=2, ncells=400, ncells_sample=400, model_do_sample=False, dt=0.005, dt_schedule='stepped', dt_schedule_bounds=[50, 500, 1000], dt_schedule_scales=[0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', kernel='multiscale', bw_range=[0.2, 0.5, 0.9, 1.1, 1.3, 1.5, 2.0], optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 2058091432

Training model...

Saving initial model state to: out/model_training/model_facs_v3_dec1b_2dpca_v13_20240719_005001/states/model_facs_v3_dec1b_2dpca_v13_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.5668646438241052		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5668646438241052 | validation: 1.2952530523371508]
	TIME [epoch: 23.3 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13_20240719_005001/states/model_facs_v3_dec1b_2dpca_v13_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.3284198958284856		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3284198958284856 | validation: 1.2340616854984858]
	TIME [epoch: 7.6 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13_20240719_005001/states/model_facs_v3_dec1b_2dpca_v13_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.304207785487013		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.304207785487013 | validation: 1.2042788118569734]
	TIME [epoch: 7.61 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13_20240719_005001/states/model_facs_v3_dec1b_2dpca_v13_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.245059974120658		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.245059974120658 | validation: 1.1908293347017571]
	TIME [epoch: 7.62 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13_20240719_005001/states/model_facs_v3_dec1b_2dpca_v13_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.216871098173112		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.216871098173112 | validation: 1.1599381071553485]
	TIME [epoch: 7.59 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13_20240719_005001/states/model_facs_v3_dec1b_2dpca_v13_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.1800152606372318		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1800152606372318 | validation: 1.1040773508501736]
	TIME [epoch: 7.59 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13_20240719_005001/states/model_facs_v3_dec1b_2dpca_v13_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.116706944049797		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.116706944049797 | validation: 1.0439637354190001]
	TIME [epoch: 7.54 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13_20240719_005001/states/model_facs_v3_dec1b_2dpca_v13_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.0331197422656946		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0331197422656946 | validation: 1.0463507132457184]
	TIME [epoch: 7.59 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.0066695058181618		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0066695058181618 | validation: 1.0446277253909104]
	TIME [epoch: 7.57 sec]
EPOCH 10/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.9966005506760464		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9966005506760464 | validation: 0.9793890498591056]
	TIME [epoch: 7.63 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13_20240719_005001/states/model_facs_v3_dec1b_2dpca_v13_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.9405873110680152		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9405873110680152 | validation: 0.8856463261497746]
	TIME [epoch: 7.58 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13_20240719_005001/states/model_facs_v3_dec1b_2dpca_v13_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.8602582824202534		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8602582824202534 | validation: 0.9821767600443906]
	TIME [epoch: 7.61 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.9069875219591172		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9069875219591172 | validation: 0.83477100186246]
	TIME [epoch: 7.57 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13_20240719_005001/states/model_facs_v3_dec1b_2dpca_v13_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.815464586180739		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.815464586180739 | validation: 0.8087294743937828]
	TIME [epoch: 7.59 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13_20240719_005001/states/model_facs_v3_dec1b_2dpca_v13_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.7806383826432528		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7806383826432528 | validation: 0.7369030078408233]
	TIME [epoch: 7.61 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13_20240719_005001/states/model_facs_v3_dec1b_2dpca_v13_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.7333866421824151		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7333866421824151 | validation: 0.6569153903716012]
	TIME [epoch: 7.61 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13_20240719_005001/states/model_facs_v3_dec1b_2dpca_v13_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.7114084510853685		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7114084510853685 | validation: 0.621310602104596]
	TIME [epoch: 7.55 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13_20240719_005001/states/model_facs_v3_dec1b_2dpca_v13_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.577375632610292		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.577375632610292 | validation: 0.5534025835414498]
	TIME [epoch: 7.51 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13_20240719_005001/states/model_facs_v3_dec1b_2dpca_v13_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.6269367862467088		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6269367862467088 | validation: 0.503143198079612]
	TIME [epoch: 7.61 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13_20240719_005001/states/model_facs_v3_dec1b_2dpca_v13_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5290858710172327		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5290858710172327 | validation: 0.5037445901860413]
	TIME [epoch: 7.58 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4880410641291331		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4880410641291331 | validation: 0.4237629151722924]
	TIME [epoch: 7.62 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13_20240719_005001/states/model_facs_v3_dec1b_2dpca_v13_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.49190732300444173		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.49190732300444173 | validation: 0.40466278604587425]
	TIME [epoch: 7.59 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13_20240719_005001/states/model_facs_v3_dec1b_2dpca_v13_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4782689003381087		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4782689003381087 | validation: 0.4315619203105866]
	TIME [epoch: 7.6 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.430157706124914		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.430157706124914 | validation: 0.3519028440956532]
	TIME [epoch: 7.58 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13_20240719_005001/states/model_facs_v3_dec1b_2dpca_v13_24.pth
	Model improved!!!
EPOCH 25/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.39472069324980535		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.39472069324980535 | validation: 0.37752374033531055]
	TIME [epoch: 7.57 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4082173132403002		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4082173132403002 | validation: 0.36872914892072395]
	TIME [epoch: 7.57 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4392918861059783		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4392918861059783 | validation: 0.3872298176351637]
	TIME [epoch: 7.57 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.394137486134112		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.394137486134112 | validation: 0.331422513158816]
	TIME [epoch: 7.55 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13_20240719_005001/states/model_facs_v3_dec1b_2dpca_v13_28.pth
	Model improved!!!
EPOCH 29/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3758914433641219		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3758914433641219 | validation: 0.32249617140651876]
	TIME [epoch: 7.58 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13_20240719_005001/states/model_facs_v3_dec1b_2dpca_v13_29.pth
	Model improved!!!
EPOCH 30/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.38461402523014704		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.38461402523014704 | validation: 0.3855234524031236]
	TIME [epoch: 7.58 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3848373008498978		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3848373008498978 | validation: 0.3031083030126335]
	TIME [epoch: 7.58 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13_20240719_005001/states/model_facs_v3_dec1b_2dpca_v13_31.pth
	Model improved!!!
EPOCH 32/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3755667252212571		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3755667252212571 | validation: 0.3206202827264622]
	TIME [epoch: 7.57 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3691332102091562		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3691332102091562 | validation: 0.29396263940658973]
	TIME [epoch: 7.57 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13_20240719_005001/states/model_facs_v3_dec1b_2dpca_v13_33.pth
	Model improved!!!
EPOCH 34/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3759494912286776		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3759494912286776 | validation: 0.3097311835281743]
	TIME [epoch: 7.53 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.35553363805671845		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.35553363805671845 | validation: 0.38642650535095235]
	TIME [epoch: 7.53 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.39038290154006705		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.39038290154006705 | validation: 0.2943951864178306]
	TIME [epoch: 7.53 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3524149966334525		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3524149966334525 | validation: 0.287047819601062]
	TIME [epoch: 7.55 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13_20240719_005001/states/model_facs_v3_dec1b_2dpca_v13_37.pth
	Model improved!!!
EPOCH 38/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.376639671210597		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.376639671210597 | validation: 0.3125862409327581]
	TIME [epoch: 7.59 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.34182975775247426		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.34182975775247426 | validation: 0.2775895077085931]
	TIME [epoch: 7.58 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13_20240719_005001/states/model_facs_v3_dec1b_2dpca_v13_39.pth
	Model improved!!!
EPOCH 40/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3496716470039602		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3496716470039602 | validation: 0.3112996180345466]
	TIME [epoch: 7.5 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3590259781089666		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3590259781089666 | validation: 0.29068951352487343]
	TIME [epoch: 7.59 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3607121464798106		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3607121464798106 | validation: 0.2813555884204722]
	TIME [epoch: 7.54 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3598533514153008		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3598533514153008 | validation: 0.2789775319874212]
	TIME [epoch: 7.58 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.33631570131046673		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.33631570131046673 | validation: 0.2942087673837205]
	TIME [epoch: 7.57 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3457375992595407		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3457375992595407 | validation: 0.2730708783258811]
	TIME [epoch: 7.57 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13_20240719_005001/states/model_facs_v3_dec1b_2dpca_v13_45.pth
	Model improved!!!
EPOCH 46/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3290158850050597		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3290158850050597 | validation: 0.27172862292505473]
	TIME [epoch: 7.58 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13_20240719_005001/states/model_facs_v3_dec1b_2dpca_v13_46.pth
	Model improved!!!
EPOCH 47/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3429928281451429		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3429928281451429 | validation: 0.27206086149518766]
	TIME [epoch: 7.54 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3447512226191043		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3447512226191043 | validation: 0.2607048447607831]
	TIME [epoch: 7.59 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13_20240719_005001/states/model_facs_v3_dec1b_2dpca_v13_48.pth
	Model improved!!!
EPOCH 49/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.34438799589096347		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.34438799589096347 | validation: 0.27870134919931944]
	TIME [epoch: 7.55 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3398034830657242		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3398034830657242 | validation: 0.41360083834687933]
	TIME [epoch: 7.57 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.36010309701760024		[learning rate: 0.0099705]
	Learning Rate: 0.00997052
	LOSS [training: 0.36010309701760024 | validation: 0.280509644616904]
	TIME [epoch: 28.2 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.33031069324814394		[learning rate: 0.0099353]
	Learning Rate: 0.00993527
	LOSS [training: 0.33031069324814394 | validation: 0.2814863810042506]
	TIME [epoch: 14.6 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3323181500048819		[learning rate: 0.0099001]
	Learning Rate: 0.00990013
	LOSS [training: 0.3323181500048819 | validation: 0.30106804515966984]
	TIME [epoch: 14.6 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3332038115161982		[learning rate: 0.0098651]
	Learning Rate: 0.00986512
	LOSS [training: 0.3332038115161982 | validation: 0.25809234134506204]
	TIME [epoch: 14.6 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13_20240719_005001/states/model_facs_v3_dec1b_2dpca_v13_54.pth
	Model improved!!!
EPOCH 55/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.325412401288136		[learning rate: 0.0098302]
	Learning Rate: 0.00983024
	LOSS [training: 0.325412401288136 | validation: 0.2839421584200482]
	TIME [epoch: 14.6 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3120456014091321		[learning rate: 0.0097955]
	Learning Rate: 0.00979548
	LOSS [training: 0.3120456014091321 | validation: 0.2566384342931529]
	TIME [epoch: 14.6 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13_20240719_005001/states/model_facs_v3_dec1b_2dpca_v13_56.pth
	Model improved!!!
EPOCH 57/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3290775578321791		[learning rate: 0.0097608]
	Learning Rate: 0.00976084
	LOSS [training: 0.3290775578321791 | validation: 0.25122354710838446]
	TIME [epoch: 14.6 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13_20240719_005001/states/model_facs_v3_dec1b_2dpca_v13_57.pth
	Model improved!!!
EPOCH 58/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3088015566039884		[learning rate: 0.0097263]
	Learning Rate: 0.00972632
	LOSS [training: 0.3088015566039884 | validation: 0.266484831631786]
	TIME [epoch: 14.6 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.32453478888687637		[learning rate: 0.0096919]
	Learning Rate: 0.00969193
	LOSS [training: 0.32453478888687637 | validation: 0.268867491549257]
	TIME [epoch: 14.6 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.32143085581636033		[learning rate: 0.0096577]
	Learning Rate: 0.00965766
	LOSS [training: 0.32143085581636033 | validation: 0.2669711123621255]
	TIME [epoch: 14.6 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3256995885626062		[learning rate: 0.0096235]
	Learning Rate: 0.00962351
	LOSS [training: 0.3256995885626062 | validation: 0.269084035020682]
	TIME [epoch: 14.6 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.30335998608890075		[learning rate: 0.0095895]
	Learning Rate: 0.00958948
	LOSS [training: 0.30335998608890075 | validation: 0.26812910820585734]
	TIME [epoch: 14.6 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.32574294640022367		[learning rate: 0.0095556]
	Learning Rate: 0.00955557
	LOSS [training: 0.32574294640022367 | validation: 0.2752800493577475]
	TIME [epoch: 14.6 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3081620625187436		[learning rate: 0.0095218]
	Learning Rate: 0.00952177
	LOSS [training: 0.3081620625187436 | validation: 0.2832645164314469]
	TIME [epoch: 14.7 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.30873799815843034		[learning rate: 0.0094881]
	Learning Rate: 0.0094881
	LOSS [training: 0.30873799815843034 | validation: 0.2660608949217577]
	TIME [epoch: 14.6 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29814805925450977		[learning rate: 0.0094546]
	Learning Rate: 0.00945455
	LOSS [training: 0.29814805925450977 | validation: 0.2757418848460885]
	TIME [epoch: 14.6 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.308430281190233		[learning rate: 0.0094211]
	Learning Rate: 0.00942112
	LOSS [training: 0.308430281190233 | validation: 0.2514224164866197]
	TIME [epoch: 14.6 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.33152949244084046		[learning rate: 0.0093878]
	Learning Rate: 0.00938781
	LOSS [training: 0.33152949244084046 | validation: 0.24807337049561445]
	TIME [epoch: 14.6 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13_20240719_005001/states/model_facs_v3_dec1b_2dpca_v13_68.pth
	Model improved!!!
EPOCH 69/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3008570561930162		[learning rate: 0.0093546]
	Learning Rate: 0.00935461
	LOSS [training: 0.3008570561930162 | validation: 0.24820413639353936]
	TIME [epoch: 14.6 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2954808207979792		[learning rate: 0.0093215]
	Learning Rate: 0.00932153
	LOSS [training: 0.2954808207979792 | validation: 0.2509456998698371]
	TIME [epoch: 14.6 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.30957281750917165		[learning rate: 0.0092886]
	Learning Rate: 0.00928857
	LOSS [training: 0.30957281750917165 | validation: 0.2634337685758271]
	TIME [epoch: 14.6 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28759399082789394		[learning rate: 0.0092557]
	Learning Rate: 0.00925572
	LOSS [training: 0.28759399082789394 | validation: 0.23953036737921146]
	TIME [epoch: 14.6 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13_20240719_005001/states/model_facs_v3_dec1b_2dpca_v13_72.pth
	Model improved!!!
EPOCH 73/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29755905465865673		[learning rate: 0.009223]
	Learning Rate: 0.00922299
	LOSS [training: 0.29755905465865673 | validation: 0.2501716342842355]
	TIME [epoch: 14.6 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2912064787655666		[learning rate: 0.0091904]
	Learning Rate: 0.00919038
	LOSS [training: 0.2912064787655666 | validation: 0.2594463609789221]
	TIME [epoch: 14.6 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28522986671759243		[learning rate: 0.0091579]
	Learning Rate: 0.00915788
	LOSS [training: 0.28522986671759243 | validation: 0.23176669536659378]
	TIME [epoch: 14.6 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13_20240719_005001/states/model_facs_v3_dec1b_2dpca_v13_75.pth
	Model improved!!!
EPOCH 76/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.30622915481785135		[learning rate: 0.0091255]
	Learning Rate: 0.00912549
	LOSS [training: 0.30622915481785135 | validation: 0.2295796952466457]
	TIME [epoch: 14.6 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13_20240719_005001/states/model_facs_v3_dec1b_2dpca_v13_76.pth
	Model improved!!!
EPOCH 77/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2925402111961394		[learning rate: 0.0090932]
	Learning Rate: 0.00909323
	LOSS [training: 0.2925402111961394 | validation: 0.2318799069937895]
	TIME [epoch: 14.6 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29496292497059967		[learning rate: 0.0090611]
	Learning Rate: 0.00906107
	LOSS [training: 0.29496292497059967 | validation: 0.27162413434129273]
	TIME [epoch: 14.6 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3009582693640586		[learning rate: 0.009029]
	Learning Rate: 0.00902903
	LOSS [training: 0.3009582693640586 | validation: 0.24530767675661608]
	TIME [epoch: 14.6 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29755442840490043		[learning rate: 0.0089971]
	Learning Rate: 0.0089971
	LOSS [training: 0.29755442840490043 | validation: 0.23420963185763685]
	TIME [epoch: 14.6 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3241410375142305		[learning rate: 0.0089653]
	Learning Rate: 0.00896528
	LOSS [training: 0.3241410375142305 | validation: 0.24552400250048584]
	TIME [epoch: 14.6 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29374511204812165		[learning rate: 0.0089336]
	Learning Rate: 0.00893358
	LOSS [training: 0.29374511204812165 | validation: 0.2244022700622958]
	TIME [epoch: 14.6 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13_20240719_005001/states/model_facs_v3_dec1b_2dpca_v13_82.pth
	Model improved!!!
EPOCH 83/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27469100558119874		[learning rate: 0.008902]
	Learning Rate: 0.00890199
	LOSS [training: 0.27469100558119874 | validation: 0.2531760139940348]
	TIME [epoch: 14.7 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29568396275355685		[learning rate: 0.0088705]
	Learning Rate: 0.00887051
	LOSS [training: 0.29568396275355685 | validation: 0.24359046029812204]
	TIME [epoch: 14.7 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29281567911805856		[learning rate: 0.0088391]
	Learning Rate: 0.00883914
	LOSS [training: 0.29281567911805856 | validation: 0.23856643643421815]
	TIME [epoch: 14.6 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2890572900199348		[learning rate: 0.0088079]
	Learning Rate: 0.00880789
	LOSS [training: 0.2890572900199348 | validation: 0.23151482184163225]
	TIME [epoch: 14.7 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29997353980636976		[learning rate: 0.0087767]
	Learning Rate: 0.00877674
	LOSS [training: 0.29997353980636976 | validation: 0.2263202887345198]
	TIME [epoch: 14.7 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28931722393872533		[learning rate: 0.0087457]
	Learning Rate: 0.00874571
	LOSS [training: 0.28931722393872533 | validation: 0.22463377046984428]
	TIME [epoch: 14.7 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28251342801565865		[learning rate: 0.0087148]
	Learning Rate: 0.00871478
	LOSS [training: 0.28251342801565865 | validation: 0.23199125656672487]
	TIME [epoch: 14.6 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29103498117897725		[learning rate: 0.008684]
	Learning Rate: 0.00868396
	LOSS [training: 0.29103498117897725 | validation: 0.23949183974532487]
	TIME [epoch: 14.6 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2785106372187186		[learning rate: 0.0086533]
	Learning Rate: 0.00865326
	LOSS [training: 0.2785106372187186 | validation: 0.22893260895314888]
	TIME [epoch: 14.6 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2893477904537047		[learning rate: 0.0086227]
	Learning Rate: 0.00862265
	LOSS [training: 0.2893477904537047 | validation: 0.22281700849601016]
	TIME [epoch: 14.6 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13_20240719_005001/states/model_facs_v3_dec1b_2dpca_v13_92.pth
	Model improved!!!
EPOCH 93/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2789909487593605		[learning rate: 0.0085922]
	Learning Rate: 0.00859216
	LOSS [training: 0.2789909487593605 | validation: 0.21964408879938344]
	TIME [epoch: 14.5 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13_20240719_005001/states/model_facs_v3_dec1b_2dpca_v13_93.pth
	Model improved!!!
EPOCH 94/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2853713020759821		[learning rate: 0.0085618]
	Learning Rate: 0.00856178
	LOSS [training: 0.2853713020759821 | validation: 0.22921326709072892]
	TIME [epoch: 14.6 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29128068617491404		[learning rate: 0.0085315]
	Learning Rate: 0.0085315
	LOSS [training: 0.29128068617491404 | validation: 0.2468233374498098]
	TIME [epoch: 14.6 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29450951480201537		[learning rate: 0.0085013]
	Learning Rate: 0.00850134
	LOSS [training: 0.29450951480201537 | validation: 0.22051775504947219]
	TIME [epoch: 14.6 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28101427877477		[learning rate: 0.0084713]
	Learning Rate: 0.00847127
	LOSS [training: 0.28101427877477 | validation: 0.22527460877288757]
	TIME [epoch: 14.6 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2889265317621503		[learning rate: 0.0084413]
	Learning Rate: 0.00844132
	LOSS [training: 0.2889265317621503 | validation: 0.22651105452920822]
	TIME [epoch: 14.5 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2841407906242501		[learning rate: 0.0084115]
	Learning Rate: 0.00841147
	LOSS [training: 0.2841407906242501 | validation: 0.2167946928199836]
	TIME [epoch: 14.4 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13_20240719_005001/states/model_facs_v3_dec1b_2dpca_v13_99.pth
	Model improved!!!
EPOCH 100/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2762474324998524		[learning rate: 0.0083817]
	Learning Rate: 0.00838172
	LOSS [training: 0.2762474324998524 | validation: 0.22027540519223746]
	TIME [epoch: 14.6 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28903388666499114		[learning rate: 0.0083521]
	Learning Rate: 0.00835208
	LOSS [training: 0.28903388666499114 | validation: 0.24951583166926422]
	TIME [epoch: 14.6 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28917368146642725		[learning rate: 0.0083225]
	Learning Rate: 0.00832255
	LOSS [training: 0.28917368146642725 | validation: 0.23634218023739145]
	TIME [epoch: 14.6 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2805888611409801		[learning rate: 0.0082931]
	Learning Rate: 0.00829312
	LOSS [training: 0.2805888611409801 | validation: 0.22457204226769173]
	TIME [epoch: 14.6 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.276434822315395		[learning rate: 0.0082638]
	Learning Rate: 0.00826379
	LOSS [training: 0.276434822315395 | validation: 0.21821567146873502]
	TIME [epoch: 14.7 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2866396794620348		[learning rate: 0.0082346]
	Learning Rate: 0.00823457
	LOSS [training: 0.2866396794620348 | validation: 0.22233265005130956]
	TIME [epoch: 14.6 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26732086315697584		[learning rate: 0.0082055]
	Learning Rate: 0.00820545
	LOSS [training: 0.26732086315697584 | validation: 0.20988929531559863]
	TIME [epoch: 14.7 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13_20240719_005001/states/model_facs_v3_dec1b_2dpca_v13_106.pth
	Model improved!!!
EPOCH 107/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27322017278114397		[learning rate: 0.0081764]
	Learning Rate: 0.00817644
	LOSS [training: 0.27322017278114397 | validation: 0.2232326681628043]
	TIME [epoch: 14.6 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.30071710615652886		[learning rate: 0.0081475]
	Learning Rate: 0.00814752
	LOSS [training: 0.30071710615652886 | validation: 0.22774166233237447]
	TIME [epoch: 14.6 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27758034541818566		[learning rate: 0.0081187]
	Learning Rate: 0.00811871
	LOSS [training: 0.27758034541818566 | validation: 0.23475499078224446]
	TIME [epoch: 14.6 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27329927483558364		[learning rate: 0.00809]
	Learning Rate: 0.00809
	LOSS [training: 0.27329927483558364 | validation: 0.22227907405350483]
	TIME [epoch: 14.6 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2657506876148921		[learning rate: 0.0080614]
	Learning Rate: 0.0080614
	LOSS [training: 0.2657506876148921 | validation: 0.23740275315248943]
	TIME [epoch: 14.6 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27059787356413884		[learning rate: 0.0080329]
	Learning Rate: 0.00803289
	LOSS [training: 0.27059787356413884 | validation: 0.23911487629149067]
	TIME [epoch: 14.6 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28445350100993355		[learning rate: 0.0080045]
	Learning Rate: 0.00800448
	LOSS [training: 0.28445350100993355 | validation: 0.23332226434369194]
	TIME [epoch: 14.6 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2828381440322777		[learning rate: 0.0079762]
	Learning Rate: 0.00797618
	LOSS [training: 0.2828381440322777 | validation: 0.21502781660254167]
	TIME [epoch: 14.6 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2830177676308972		[learning rate: 0.007948]
	Learning Rate: 0.00794797
	LOSS [training: 0.2830177676308972 | validation: 0.2270118522691868]
	TIME [epoch: 14.5 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2687800606040194		[learning rate: 0.0079199]
	Learning Rate: 0.00791987
	LOSS [training: 0.2687800606040194 | validation: 0.21504247616910988]
	TIME [epoch: 14.6 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28090437686100544		[learning rate: 0.0078919]
	Learning Rate: 0.00789186
	LOSS [training: 0.28090437686100544 | validation: 0.22288831235356682]
	TIME [epoch: 14.6 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.284124301202303		[learning rate: 0.007864]
	Learning Rate: 0.00786395
	LOSS [training: 0.284124301202303 | validation: 0.2199023567539363]
	TIME [epoch: 14.6 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2748956015803405		[learning rate: 0.0078361]
	Learning Rate: 0.00783615
	LOSS [training: 0.2748956015803405 | validation: 0.23168066172390814]
	TIME [epoch: 14.5 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2797243794124235		[learning rate: 0.0078084]
	Learning Rate: 0.00780844
	LOSS [training: 0.2797243794124235 | validation: 0.2163674540416701]
	TIME [epoch: 14.6 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.272916250852774		[learning rate: 0.0077808]
	Learning Rate: 0.00778083
	LOSS [training: 0.272916250852774 | validation: 0.21288328769384282]
	TIME [epoch: 14.6 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2616978079724483		[learning rate: 0.0077533]
	Learning Rate: 0.00775331
	LOSS [training: 0.2616978079724483 | validation: 0.21818804459252278]
	TIME [epoch: 14.5 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27132086461358634		[learning rate: 0.0077259]
	Learning Rate: 0.00772589
	LOSS [training: 0.27132086461358634 | validation: 0.24437188203954813]
	TIME [epoch: 14.6 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.304665268360758		[learning rate: 0.0076986]
	Learning Rate: 0.00769857
	LOSS [training: 0.304665268360758 | validation: 0.21801279380517932]
	TIME [epoch: 14.6 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27160697847864856		[learning rate: 0.0076714]
	Learning Rate: 0.00767135
	LOSS [training: 0.27160697847864856 | validation: 0.22222782570924374]
	TIME [epoch: 14.5 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.279283801383256		[learning rate: 0.0076442]
	Learning Rate: 0.00764422
	LOSS [training: 0.279283801383256 | validation: 0.21938322691150414]
	TIME [epoch: 14.5 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2652117736366239		[learning rate: 0.0076172]
	Learning Rate: 0.00761719
	LOSS [training: 0.2652117736366239 | validation: 0.21593820774114328]
	TIME [epoch: 14.5 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27509795627925854		[learning rate: 0.0075903]
	Learning Rate: 0.00759025
	LOSS [training: 0.27509795627925854 | validation: 0.23374747501425563]
	TIME [epoch: 14.5 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3123044185045285		[learning rate: 0.0075634]
	Learning Rate: 0.00756341
	LOSS [training: 0.3123044185045285 | validation: 0.21823722826976782]
	TIME [epoch: 14.5 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26893899570655194		[learning rate: 0.0075367]
	Learning Rate: 0.00753667
	LOSS [training: 0.26893899570655194 | validation: 0.22257460322039507]
	TIME [epoch: 14.6 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26632059099659383		[learning rate: 0.00751]
	Learning Rate: 0.00751002
	LOSS [training: 0.26632059099659383 | validation: 0.21188228043559612]
	TIME [epoch: 14.6 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27355755810475746		[learning rate: 0.0074835]
	Learning Rate: 0.00748346
	LOSS [training: 0.27355755810475746 | validation: 0.2467571957200378]
	TIME [epoch: 14.5 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28471130618863155		[learning rate: 0.007457]
	Learning Rate: 0.007457
	LOSS [training: 0.28471130618863155 | validation: 0.2231285961184885]
	TIME [epoch: 14.6 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.267627554008824		[learning rate: 0.0074306]
	Learning Rate: 0.00743063
	LOSS [training: 0.267627554008824 | validation: 0.2278768384814581]
	TIME [epoch: 14.4 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2727914345835794		[learning rate: 0.0074044]
	Learning Rate: 0.00740435
	LOSS [training: 0.2727914345835794 | validation: 0.2187765284795736]
	TIME [epoch: 14.5 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2887675491363883		[learning rate: 0.0073782]
	Learning Rate: 0.00737817
	LOSS [training: 0.2887675491363883 | validation: 0.21459128704591118]
	TIME [epoch: 14.5 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27319621320690507		[learning rate: 0.0073521]
	Learning Rate: 0.00735208
	LOSS [training: 0.27319621320690507 | validation: 0.22230832343273468]
	TIME [epoch: 14.6 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2773866712663877		[learning rate: 0.0073261]
	Learning Rate: 0.00732608
	LOSS [training: 0.2773866712663877 | validation: 0.21919996925635016]
	TIME [epoch: 14.6 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.34431060824509113		[learning rate: 0.0073002]
	Learning Rate: 0.00730018
	LOSS [training: 0.34431060824509113 | validation: 0.22936205669153903]
	TIME [epoch: 14.6 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2740446482063154		[learning rate: 0.0072744]
	Learning Rate: 0.00727436
	LOSS [training: 0.2740446482063154 | validation: 0.218634414075973]
	TIME [epoch: 14.6 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2641901204159402		[learning rate: 0.0072486]
	Learning Rate: 0.00724864
	LOSS [training: 0.2641901204159402 | validation: 0.22430757613245306]
	TIME [epoch: 14.6 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2858702055732625		[learning rate: 0.007223]
	Learning Rate: 0.007223
	LOSS [training: 0.2858702055732625 | validation: 0.222263296310952]
	TIME [epoch: 14.6 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27415647683139		[learning rate: 0.0071975]
	Learning Rate: 0.00719746
	LOSS [training: 0.27415647683139 | validation: 0.21511636554575125]
	TIME [epoch: 14.6 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26283559971814224		[learning rate: 0.007172]
	Learning Rate: 0.00717201
	LOSS [training: 0.26283559971814224 | validation: 0.21620265575255226]
	TIME [epoch: 14.6 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26327229384384127		[learning rate: 0.0071467]
	Learning Rate: 0.00714665
	LOSS [training: 0.26327229384384127 | validation: 0.22729276525965852]
	TIME [epoch: 14.6 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2854492121525167		[learning rate: 0.0071214]
	Learning Rate: 0.00712138
	LOSS [training: 0.2854492121525167 | validation: 0.2150992625829859]
	TIME [epoch: 14.5 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27563951736818243		[learning rate: 0.0070962]
	Learning Rate: 0.0070962
	LOSS [training: 0.27563951736818243 | validation: 0.21899620301628614]
	TIME [epoch: 14.6 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2797446015429333		[learning rate: 0.0070711]
	Learning Rate: 0.0070711
	LOSS [training: 0.2797446015429333 | validation: 0.22465009823103316]
	TIME [epoch: 14.5 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2794132379096563		[learning rate: 0.0070461]
	Learning Rate: 0.0070461
	LOSS [training: 0.2794132379096563 | validation: 0.21892569744079773]
	TIME [epoch: 14.6 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2743026290909191		[learning rate: 0.0070212]
	Learning Rate: 0.00702118
	LOSS [training: 0.2743026290909191 | validation: 0.21006341496917064]
	TIME [epoch: 14.6 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26966485237214		[learning rate: 0.0069964]
	Learning Rate: 0.00699635
	LOSS [training: 0.26966485237214 | validation: 0.22351901897705403]
	TIME [epoch: 14.6 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27314542444329076		[learning rate: 0.0069716]
	Learning Rate: 0.00697161
	LOSS [training: 0.27314542444329076 | validation: 0.22135858395841743]
	TIME [epoch: 14.5 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26351506408689035		[learning rate: 0.006947]
	Learning Rate: 0.00694696
	LOSS [training: 0.26351506408689035 | validation: 0.22203008269406813]
	TIME [epoch: 14.6 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27361904026285017		[learning rate: 0.0069224]
	Learning Rate: 0.00692239
	LOSS [training: 0.27361904026285017 | validation: 0.2175456594566878]
	TIME [epoch: 14.5 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2595153352459168		[learning rate: 0.0068979]
	Learning Rate: 0.00689792
	LOSS [training: 0.2595153352459168 | validation: 0.2172824977824884]
	TIME [epoch: 14.6 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26827338154144115		[learning rate: 0.0068735]
	Learning Rate: 0.00687352
	LOSS [training: 0.26827338154144115 | validation: 0.2229684545669421]
	TIME [epoch: 14.5 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27431127407265055		[learning rate: 0.0068492]
	Learning Rate: 0.00684922
	LOSS [training: 0.27431127407265055 | validation: 0.21286409021112504]
	TIME [epoch: 14.6 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2729184183545837		[learning rate: 0.006825]
	Learning Rate: 0.006825
	LOSS [training: 0.2729184183545837 | validation: 0.21643214922149853]
	TIME [epoch: 14.6 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26091274534462655		[learning rate: 0.0068009]
	Learning Rate: 0.00680086
	LOSS [training: 0.26091274534462655 | validation: 0.2241860117555063]
	TIME [epoch: 14.6 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.265062799102544		[learning rate: 0.0067768]
	Learning Rate: 0.00677681
	LOSS [training: 0.265062799102544 | validation: 0.21752764959227283]
	TIME [epoch: 14.5 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2637192609507614		[learning rate: 0.0067529]
	Learning Rate: 0.00675285
	LOSS [training: 0.2637192609507614 | validation: 0.2234624680695016]
	TIME [epoch: 14.6 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2709761613892398		[learning rate: 0.006729]
	Learning Rate: 0.00672897
	LOSS [training: 0.2709761613892398 | validation: 0.2183501116349383]
	TIME [epoch: 14.6 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2736552592681089		[learning rate: 0.0067052]
	Learning Rate: 0.00670518
	LOSS [training: 0.2736552592681089 | validation: 0.22247737213125415]
	TIME [epoch: 14.6 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2928368944196279		[learning rate: 0.0066815]
	Learning Rate: 0.00668147
	LOSS [training: 0.2928368944196279 | validation: 0.2170377786829137]
	TIME [epoch: 14.6 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26224030403917403		[learning rate: 0.0066578]
	Learning Rate: 0.00665784
	LOSS [training: 0.26224030403917403 | validation: 0.21428403992600292]
	TIME [epoch: 14.6 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26317989220402377		[learning rate: 0.0066343]
	Learning Rate: 0.0066343
	LOSS [training: 0.26317989220402377 | validation: 0.22189540533274316]
	TIME [epoch: 14.6 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26989451110320134		[learning rate: 0.0066108]
	Learning Rate: 0.00661084
	LOSS [training: 0.26989451110320134 | validation: 0.2277534923736299]
	TIME [epoch: 14.6 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2758520628912286		[learning rate: 0.0065875]
	Learning Rate: 0.00658746
	LOSS [training: 0.2758520628912286 | validation: 0.20954150035857194]
	TIME [epoch: 14.6 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13_20240719_005001/states/model_facs_v3_dec1b_2dpca_v13_168.pth
	Model improved!!!
EPOCH 169/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26474488820793374		[learning rate: 0.0065642]
	Learning Rate: 0.00656416
	LOSS [training: 0.26474488820793374 | validation: 0.21911737531135053]
	TIME [epoch: 14.6 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26653263802557753		[learning rate: 0.006541]
	Learning Rate: 0.00654095
	LOSS [training: 0.26653263802557753 | validation: 0.22053756385852505]
	TIME [epoch: 14.6 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.268093060780713		[learning rate: 0.0065178]
	Learning Rate: 0.00651782
	LOSS [training: 0.268093060780713 | validation: 0.2151559353872285]
	TIME [epoch: 14.6 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26906292354955813		[learning rate: 0.0064948]
	Learning Rate: 0.00649477
	LOSS [training: 0.26906292354955813 | validation: 0.2285746608904978]
	TIME [epoch: 14.6 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26502224693340126		[learning rate: 0.0064718]
	Learning Rate: 0.00647181
	LOSS [training: 0.26502224693340126 | validation: 0.21817603954070028]
	TIME [epoch: 14.6 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2648177040103635		[learning rate: 0.0064489]
	Learning Rate: 0.00644892
	LOSS [training: 0.2648177040103635 | validation: 0.22376735240664397]
	TIME [epoch: 14.6 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2671717847275146		[learning rate: 0.0064261]
	Learning Rate: 0.00642612
	LOSS [training: 0.2671717847275146 | validation: 0.22928473253392362]
	TIME [epoch: 14.6 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26711055446243787		[learning rate: 0.0064034]
	Learning Rate: 0.00640339
	LOSS [training: 0.26711055446243787 | validation: 0.2261326605975939]
	TIME [epoch: 14.6 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2837479439644813		[learning rate: 0.0063808]
	Learning Rate: 0.00638075
	LOSS [training: 0.2837479439644813 | validation: 0.22907674242232537]
	TIME [epoch: 14.6 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3051273516968311		[learning rate: 0.0063582]
	Learning Rate: 0.00635819
	LOSS [training: 0.3051273516968311 | validation: 0.22485117863298734]
	TIME [epoch: 14.6 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27229148774278084		[learning rate: 0.0063357]
	Learning Rate: 0.0063357
	LOSS [training: 0.27229148774278084 | validation: 0.23851585698100478]
	TIME [epoch: 14.6 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28875822038046645		[learning rate: 0.0063133]
	Learning Rate: 0.0063133
	LOSS [training: 0.28875822038046645 | validation: 0.2327798780339961]
	TIME [epoch: 14.6 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2858987723460717		[learning rate: 0.006291]
	Learning Rate: 0.00629097
	LOSS [training: 0.2858987723460717 | validation: 0.2163658177042727]
	TIME [epoch: 14.6 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26226523045734645		[learning rate: 0.0062687]
	Learning Rate: 0.00626873
	LOSS [training: 0.26226523045734645 | validation: 0.22053816520290054]
	TIME [epoch: 14.6 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2634897177409847		[learning rate: 0.0062466]
	Learning Rate: 0.00624656
	LOSS [training: 0.2634897177409847 | validation: 0.21337479707891333]
	TIME [epoch: 14.6 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2684596458767045		[learning rate: 0.0062245]
	Learning Rate: 0.00622447
	LOSS [training: 0.2684596458767045 | validation: 0.217342172452694]
	TIME [epoch: 14.6 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2681136789633305		[learning rate: 0.0062025]
	Learning Rate: 0.00620246
	LOSS [training: 0.2681136789633305 | validation: 0.22307857416943344]
	TIME [epoch: 14.6 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27658407727656714		[learning rate: 0.0061805]
	Learning Rate: 0.00618053
	LOSS [training: 0.27658407727656714 | validation: 0.22449954743527817]
	TIME [epoch: 14.6 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25940776268524696		[learning rate: 0.0061587]
	Learning Rate: 0.00615867
	LOSS [training: 0.25940776268524696 | validation: 0.23130913614553075]
	TIME [epoch: 14.6 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2678472159953963		[learning rate: 0.0061369]
	Learning Rate: 0.00613689
	LOSS [training: 0.2678472159953963 | validation: 0.21671966170388268]
	TIME [epoch: 14.6 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2719981900140064		[learning rate: 0.0061152]
	Learning Rate: 0.00611519
	LOSS [training: 0.2719981900140064 | validation: 0.21209964391074992]
	TIME [epoch: 14.6 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25890840793724007		[learning rate: 0.0060936]
	Learning Rate: 0.00609357
	LOSS [training: 0.25890840793724007 | validation: 0.2181073973211328]
	TIME [epoch: 14.6 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2619639734985811		[learning rate: 0.006072]
	Learning Rate: 0.00607202
	LOSS [training: 0.2619639734985811 | validation: 0.21544420241740686]
	TIME [epoch: 14.6 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26311287453800325		[learning rate: 0.0060505]
	Learning Rate: 0.00605055
	LOSS [training: 0.26311287453800325 | validation: 0.213511671633189]
	TIME [epoch: 14.6 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2610458228272901		[learning rate: 0.0060292]
	Learning Rate: 0.00602915
	LOSS [training: 0.2610458228272901 | validation: 0.22053698544034273]
	TIME [epoch: 14.6 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.265988353500004		[learning rate: 0.0060078]
	Learning Rate: 0.00600783
	LOSS [training: 0.265988353500004 | validation: 0.21090412978227283]
	TIME [epoch: 14.5 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26524265535467384		[learning rate: 0.0059866]
	Learning Rate: 0.00598659
	LOSS [training: 0.26524265535467384 | validation: 0.21572692884921546]
	TIME [epoch: 14.5 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26902171468269376		[learning rate: 0.0059654]
	Learning Rate: 0.00596542
	LOSS [training: 0.26902171468269376 | validation: 0.20617137297020513]
	TIME [epoch: 14.6 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13_20240719_005001/states/model_facs_v3_dec1b_2dpca_v13_196.pth
	Model improved!!!
EPOCH 197/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2676286647821982		[learning rate: 0.0059443]
	Learning Rate: 0.00594433
	LOSS [training: 0.2676286647821982 | validation: 0.21419369157105836]
	TIME [epoch: 14.6 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25597420360760537		[learning rate: 0.0059233]
	Learning Rate: 0.0059233
	LOSS [training: 0.25597420360760537 | validation: 0.22220530950059153]
	TIME [epoch: 14.6 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26870056134072523		[learning rate: 0.0059024]
	Learning Rate: 0.00590236
	LOSS [training: 0.26870056134072523 | validation: 0.23696235142096786]
	TIME [epoch: 14.6 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29878059654708294		[learning rate: 0.0058815]
	Learning Rate: 0.00588149
	LOSS [training: 0.29878059654708294 | validation: 0.22063868400085562]
	TIME [epoch: 14.6 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26620769758511015		[learning rate: 0.0058607]
	Learning Rate: 0.00586069
	LOSS [training: 0.26620769758511015 | validation: 0.21994475821070006]
	TIME [epoch: 14.6 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2683744636696943		[learning rate: 0.00584]
	Learning Rate: 0.00583996
	LOSS [training: 0.2683744636696943 | validation: 0.214072576599237]
	TIME [epoch: 14.7 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26288493677693164		[learning rate: 0.0058193]
	Learning Rate: 0.00581931
	LOSS [training: 0.26288493677693164 | validation: 0.2240867780313261]
	TIME [epoch: 14.6 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27141506668829307		[learning rate: 0.0057987]
	Learning Rate: 0.00579874
	LOSS [training: 0.27141506668829307 | validation: 0.22272403238679592]
	TIME [epoch: 14.6 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2731360272141828		[learning rate: 0.0057782]
	Learning Rate: 0.00577823
	LOSS [training: 0.2731360272141828 | validation: 0.2212457645847202]
	TIME [epoch: 14.6 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26728457056268123		[learning rate: 0.0057578]
	Learning Rate: 0.0057578
	LOSS [training: 0.26728457056268123 | validation: 0.21665026807481264]
	TIME [epoch: 14.6 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2679387823803719		[learning rate: 0.0057374]
	Learning Rate: 0.00573744
	LOSS [training: 0.2679387823803719 | validation: 0.22525949791699246]
	TIME [epoch: 14.6 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2703305017260828		[learning rate: 0.0057171]
	Learning Rate: 0.00571715
	LOSS [training: 0.2703305017260828 | validation: 0.2140368585986802]
	TIME [epoch: 14.6 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2557249428209066		[learning rate: 0.0056969]
	Learning Rate: 0.00569693
	LOSS [training: 0.2557249428209066 | validation: 0.2161771910901086]
	TIME [epoch: 14.7 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26606369493928816		[learning rate: 0.0056768]
	Learning Rate: 0.00567679
	LOSS [training: 0.26606369493928816 | validation: 0.2147995451115964]
	TIME [epoch: 14.6 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2642489905503021		[learning rate: 0.0056567]
	Learning Rate: 0.00565671
	LOSS [training: 0.2642489905503021 | validation: 0.22568475400971266]
	TIME [epoch: 14.6 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26018565416003664		[learning rate: 0.0056367]
	Learning Rate: 0.00563671
	LOSS [training: 0.26018565416003664 | validation: 0.2223393601486629]
	TIME [epoch: 14.6 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2671037055891206		[learning rate: 0.0056168]
	Learning Rate: 0.00561678
	LOSS [training: 0.2671037055891206 | validation: 0.21715754371971058]
	TIME [epoch: 14.6 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2767108471931392		[learning rate: 0.0055969]
	Learning Rate: 0.00559691
	LOSS [training: 0.2767108471931392 | validation: 0.2138921161214677]
	TIME [epoch: 14.6 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26583200470218665		[learning rate: 0.0055771]
	Learning Rate: 0.00557712
	LOSS [training: 0.26583200470218665 | validation: 0.21702017695022802]
	TIME [epoch: 14.6 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2617956899498722		[learning rate: 0.0055574]
	Learning Rate: 0.0055574
	LOSS [training: 0.2617956899498722 | validation: 0.22149858098790148]
	TIME [epoch: 14.6 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2624676990912121		[learning rate: 0.0055378]
	Learning Rate: 0.00553775
	LOSS [training: 0.2624676990912121 | validation: 0.2202354477136909]
	TIME [epoch: 14.6 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2683864774361724		[learning rate: 0.0055182]
	Learning Rate: 0.00551817
	LOSS [training: 0.2683864774361724 | validation: 0.21535423570222342]
	TIME [epoch: 14.6 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25524433186808015		[learning rate: 0.0054987]
	Learning Rate: 0.00549865
	LOSS [training: 0.25524433186808015 | validation: 0.22530005600952582]
	TIME [epoch: 14.6 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2669132492415655		[learning rate: 0.0054792]
	Learning Rate: 0.00547921
	LOSS [training: 0.2669132492415655 | validation: 0.20872013058246636]
	TIME [epoch: 14.7 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25708157756360245		[learning rate: 0.0054598]
	Learning Rate: 0.00545983
	LOSS [training: 0.25708157756360245 | validation: 0.21144978765437053]
	TIME [epoch: 14.6 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2666579530376632		[learning rate: 0.0054405]
	Learning Rate: 0.00544053
	LOSS [training: 0.2666579530376632 | validation: 0.21287868899529375]
	TIME [epoch: 14.6 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25988470500482796		[learning rate: 0.0054213]
	Learning Rate: 0.00542129
	LOSS [training: 0.25988470500482796 | validation: 0.21461775715131898]
	TIME [epoch: 14.6 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26265222277989636		[learning rate: 0.0054021]
	Learning Rate: 0.00540212
	LOSS [training: 0.26265222277989636 | validation: 0.2206149241853917]
	TIME [epoch: 14.6 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2638427526939654		[learning rate: 0.005383]
	Learning Rate: 0.00538302
	LOSS [training: 0.2638427526939654 | validation: 0.2164964421898236]
	TIME [epoch: 14.6 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26083613266782607		[learning rate: 0.005364]
	Learning Rate: 0.00536398
	LOSS [training: 0.26083613266782607 | validation: 0.20774284684463656]
	TIME [epoch: 14.6 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26077402827065904		[learning rate: 0.005345]
	Learning Rate: 0.00534501
	LOSS [training: 0.26077402827065904 | validation: 0.22293265910733417]
	TIME [epoch: 14.6 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25457812774722693		[learning rate: 0.0053261]
	Learning Rate: 0.00532611
	LOSS [training: 0.25457812774722693 | validation: 0.22371932650148318]
	TIME [epoch: 14.6 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2678134292124684		[learning rate: 0.0053073]
	Learning Rate: 0.00530728
	LOSS [training: 0.2678134292124684 | validation: 0.22942139207475737]
	TIME [epoch: 14.6 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28214034699051765		[learning rate: 0.0052885]
	Learning Rate: 0.00528851
	LOSS [training: 0.28214034699051765 | validation: 0.2158090746191287]
	TIME [epoch: 14.6 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26389603755356067		[learning rate: 0.0052698]
	Learning Rate: 0.00526981
	LOSS [training: 0.26389603755356067 | validation: 0.22395657821298318]
	TIME [epoch: 14.6 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25962910802843814		[learning rate: 0.0052512]
	Learning Rate: 0.00525117
	LOSS [training: 0.25962910802843814 | validation: 0.21195621747447785]
	TIME [epoch: 14.6 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2571071236524128		[learning rate: 0.0052326]
	Learning Rate: 0.0052326
	LOSS [training: 0.2571071236524128 | validation: 0.21680685372246505]
	TIME [epoch: 14.6 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2652254397173879		[learning rate: 0.0052141]
	Learning Rate: 0.0052141
	LOSS [training: 0.2652254397173879 | validation: 0.21413966777152157]
	TIME [epoch: 14.6 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2593244090590996		[learning rate: 0.0051957]
	Learning Rate: 0.00519566
	LOSS [training: 0.2593244090590996 | validation: 0.22135016246113418]
	TIME [epoch: 14.5 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2762214543660419		[learning rate: 0.0051773]
	Learning Rate: 0.00517729
	LOSS [training: 0.2762214543660419 | validation: 0.21239528940942023]
	TIME [epoch: 14.6 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2559878173663012		[learning rate: 0.005159]
	Learning Rate: 0.00515898
	LOSS [training: 0.2559878173663012 | validation: 0.22082647898350385]
	TIME [epoch: 14.6 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26352096656278706		[learning rate: 0.0051407]
	Learning Rate: 0.00514074
	LOSS [training: 0.26352096656278706 | validation: 0.23107025634951675]
	TIME [epoch: 14.6 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27122181875733603		[learning rate: 0.0051226]
	Learning Rate: 0.00512256
	LOSS [training: 0.27122181875733603 | validation: 0.2142002502129698]
	TIME [epoch: 14.6 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26085326526038144		[learning rate: 0.0051044]
	Learning Rate: 0.00510445
	LOSS [training: 0.26085326526038144 | validation: 0.20880804850634424]
	TIME [epoch: 14.6 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25574778584340446		[learning rate: 0.0050864]
	Learning Rate: 0.0050864
	LOSS [training: 0.25574778584340446 | validation: 0.2172479976241287]
	TIME [epoch: 14.6 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2598306074985482		[learning rate: 0.0050684]
	Learning Rate: 0.00506841
	LOSS [training: 0.2598306074985482 | validation: 0.21273840194302776]
	TIME [epoch: 14.6 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25477089720331175		[learning rate: 0.0050505]
	Learning Rate: 0.00505049
	LOSS [training: 0.25477089720331175 | validation: 0.22793557796806932]
	TIME [epoch: 14.6 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2623545092495257		[learning rate: 0.0050326]
	Learning Rate: 0.00503263
	LOSS [training: 0.2623545092495257 | validation: 0.21554255640326594]
	TIME [epoch: 14.6 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25291299955728186		[learning rate: 0.0050148]
	Learning Rate: 0.00501483
	LOSS [training: 0.25291299955728186 | validation: 0.21512496005790274]
	TIME [epoch: 14.6 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2613064307689114		[learning rate: 0.0049971]
	Learning Rate: 0.0049971
	LOSS [training: 0.2613064307689114 | validation: 0.22067912468503517]
	TIME [epoch: 14.6 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26713646360078597		[learning rate: 0.0049794]
	Learning Rate: 0.00497943
	LOSS [training: 0.26713646360078597 | validation: 0.21609386672116404]
	TIME [epoch: 14.6 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2605170608978593		[learning rate: 0.0049618]
	Learning Rate: 0.00496182
	LOSS [training: 0.2605170608978593 | validation: 0.21116470996254452]
	TIME [epoch: 14.6 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2598234966768765		[learning rate: 0.0049443]
	Learning Rate: 0.00494427
	LOSS [training: 0.2598234966768765 | validation: 0.2175411932961711]
	TIME [epoch: 14.6 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2595756556553289		[learning rate: 0.0049268]
	Learning Rate: 0.00492679
	LOSS [training: 0.2595756556553289 | validation: 0.22064628988992893]
	TIME [epoch: 14.6 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2637031354745065		[learning rate: 0.0049094]
	Learning Rate: 0.00490937
	LOSS [training: 0.2637031354745065 | validation: 0.22443655153956446]
	TIME [epoch: 14.6 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26175779754649714		[learning rate: 0.004892]
	Learning Rate: 0.00489201
	LOSS [training: 0.26175779754649714 | validation: 0.2108857236224166]
	TIME [epoch: 14.6 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25747836210430214		[learning rate: 0.0048747]
	Learning Rate: 0.00487471
	LOSS [training: 0.25747836210430214 | validation: 0.21098568388659142]
	TIME [epoch: 14.6 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26153294540296934		[learning rate: 0.0048575]
	Learning Rate: 0.00485747
	LOSS [training: 0.26153294540296934 | validation: 0.21989823743078524]
	TIME [epoch: 14.6 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2621398793399157		[learning rate: 0.0048403]
	Learning Rate: 0.00484029
	LOSS [training: 0.2621398793399157 | validation: 0.22603529438999015]
	TIME [epoch: 14.6 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2625974667607857		[learning rate: 0.0048232]
	Learning Rate: 0.00482318
	LOSS [training: 0.2625974667607857 | validation: 0.22548875950638014]
	TIME [epoch: 14.6 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26138668102434387		[learning rate: 0.0048061]
	Learning Rate: 0.00480612
	LOSS [training: 0.26138668102434387 | validation: 0.21177468277403017]
	TIME [epoch: 14.6 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.255289128967586		[learning rate: 0.0047891]
	Learning Rate: 0.00478913
	LOSS [training: 0.255289128967586 | validation: 0.21489620348319347]
	TIME [epoch: 14.6 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2593731687683592		[learning rate: 0.0047722]
	Learning Rate: 0.00477219
	LOSS [training: 0.2593731687683592 | validation: 0.216678475006781]
	TIME [epoch: 14.6 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25752994791740064		[learning rate: 0.0047553]
	Learning Rate: 0.00475532
	LOSS [training: 0.25752994791740064 | validation: 0.22362251619738865]
	TIME [epoch: 14.7 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2569736664301458		[learning rate: 0.0047385]
	Learning Rate: 0.0047385
	LOSS [training: 0.2569736664301458 | validation: 0.2173861132392733]
	TIME [epoch: 14.5 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25338752619055754		[learning rate: 0.0047217]
	Learning Rate: 0.00472175
	LOSS [training: 0.25338752619055754 | validation: 0.20903521760779137]
	TIME [epoch: 14.6 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2557834947317519		[learning rate: 0.004705]
	Learning Rate: 0.00470505
	LOSS [training: 0.2557834947317519 | validation: 0.21815752565293697]
	TIME [epoch: 14.6 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2600680735874588		[learning rate: 0.0046884]
	Learning Rate: 0.00468841
	LOSS [training: 0.2600680735874588 | validation: 0.20985179479488858]
	TIME [epoch: 14.6 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25382420620854784		[learning rate: 0.0046718]
	Learning Rate: 0.00467183
	LOSS [training: 0.25382420620854784 | validation: 0.2310720852620717]
	TIME [epoch: 14.5 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26925700561834104		[learning rate: 0.0046553]
	Learning Rate: 0.00465531
	LOSS [training: 0.26925700561834104 | validation: 0.20880222781448468]
	TIME [epoch: 14.6 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.255024655360968		[learning rate: 0.0046388]
	Learning Rate: 0.00463885
	LOSS [training: 0.255024655360968 | validation: 0.21300633420612541]
	TIME [epoch: 14.6 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25210767741526846		[learning rate: 0.0046224]
	Learning Rate: 0.00462245
	LOSS [training: 0.25210767741526846 | validation: 0.22254975219690792]
	TIME [epoch: 14.6 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2520058111880326		[learning rate: 0.0046061]
	Learning Rate: 0.0046061
	LOSS [training: 0.2520058111880326 | validation: 0.21522488615468954]
	TIME [epoch: 14.6 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26364439061508965		[learning rate: 0.0045898]
	Learning Rate: 0.00458981
	LOSS [training: 0.26364439061508965 | validation: 0.21611901793367805]
	TIME [epoch: 14.6 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2570928266797941		[learning rate: 0.0045736]
	Learning Rate: 0.00457358
	LOSS [training: 0.2570928266797941 | validation: 0.20982587956807425]
	TIME [epoch: 14.6 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25941551052778095		[learning rate: 0.0045574]
	Learning Rate: 0.00455741
	LOSS [training: 0.25941551052778095 | validation: 0.22045405635794446]
	TIME [epoch: 14.6 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3065661216630536		[learning rate: 0.0045413]
	Learning Rate: 0.00454129
	LOSS [training: 0.3065661216630536 | validation: 0.37487894243553677]
	TIME [epoch: 14.5 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.31726897717188995		[learning rate: 0.0045252]
	Learning Rate: 0.00452523
	LOSS [training: 0.31726897717188995 | validation: 0.2298593354296977]
	TIME [epoch: 14.6 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2716949015497198		[learning rate: 0.0045092]
	Learning Rate: 0.00450923
	LOSS [training: 0.2716949015497198 | validation: 0.21407121524117873]
	TIME [epoch: 14.5 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2613155245873377		[learning rate: 0.0044933]
	Learning Rate: 0.00449329
	LOSS [training: 0.2613155245873377 | validation: 0.20989072904506623]
	TIME [epoch: 14.5 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26033751382523346		[learning rate: 0.0044774]
	Learning Rate: 0.0044774
	LOSS [training: 0.26033751382523346 | validation: 0.21422054517306455]
	TIME [epoch: 14.5 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.258437992034064		[learning rate: 0.0044616]
	Learning Rate: 0.00446156
	LOSS [training: 0.258437992034064 | validation: 0.2138148258301702]
	TIME [epoch: 14.6 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2564435656775874		[learning rate: 0.0044458]
	Learning Rate: 0.00444579
	LOSS [training: 0.2564435656775874 | validation: 0.21054168812974047]
	TIME [epoch: 14.5 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2513600330649264		[learning rate: 0.0044301]
	Learning Rate: 0.00443007
	LOSS [training: 0.2513600330649264 | validation: 0.21843682565651515]
	TIME [epoch: 14.7 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25688246828088196		[learning rate: 0.0044144]
	Learning Rate: 0.0044144
	LOSS [training: 0.25688246828088196 | validation: 0.21411189109681644]
	TIME [epoch: 14.6 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2562224348666391		[learning rate: 0.0043988]
	Learning Rate: 0.00439879
	LOSS [training: 0.2562224348666391 | validation: 0.2107949006078445]
	TIME [epoch: 14.6 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2643736109825814		[learning rate: 0.0043832]
	Learning Rate: 0.00438324
	LOSS [training: 0.2643736109825814 | validation: 0.21257096549190907]
	TIME [epoch: 14.6 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2546801763239948		[learning rate: 0.0043677]
	Learning Rate: 0.00436774
	LOSS [training: 0.2546801763239948 | validation: 0.21504320895240747]
	TIME [epoch: 14.7 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2546001922727688		[learning rate: 0.0043523]
	Learning Rate: 0.00435229
	LOSS [training: 0.2546001922727688 | validation: 0.2206206262806004]
	TIME [epoch: 14.6 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25597344553605783		[learning rate: 0.0043369]
	Learning Rate: 0.0043369
	LOSS [training: 0.25597344553605783 | validation: 0.2099399002006619]
	TIME [epoch: 14.6 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2573961203398278		[learning rate: 0.0043216]
	Learning Rate: 0.00432156
	LOSS [training: 0.2573961203398278 | validation: 0.2151579415014344]
	TIME [epoch: 14.7 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25786712654167004		[learning rate: 0.0043063]
	Learning Rate: 0.00430628
	LOSS [training: 0.25786712654167004 | validation: 0.21137919598460736]
	TIME [epoch: 14.7 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26375286389240693		[learning rate: 0.0042911]
	Learning Rate: 0.00429106
	LOSS [training: 0.26375286389240693 | validation: 0.23258527471644125]
	TIME [epoch: 14.6 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.267965158034977		[learning rate: 0.0042759]
	Learning Rate: 0.00427588
	LOSS [training: 0.267965158034977 | validation: 0.21937505158590015]
	TIME [epoch: 14.6 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.279050642517438		[learning rate: 0.0042608]
	Learning Rate: 0.00426076
	LOSS [training: 0.279050642517438 | validation: 0.21977125498728914]
	TIME [epoch: 14.6 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2652847925590682		[learning rate: 0.0042457]
	Learning Rate: 0.00424569
	LOSS [training: 0.2652847925590682 | validation: 0.2065564001427315]
	TIME [epoch: 14.6 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2632652257451206		[learning rate: 0.0042307]
	Learning Rate: 0.00423068
	LOSS [training: 0.2632652257451206 | validation: 0.21110316426663028]
	TIME [epoch: 14.5 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2586320650919951		[learning rate: 0.0042157]
	Learning Rate: 0.00421572
	LOSS [training: 0.2586320650919951 | validation: 0.21805932763438057]
	TIME [epoch: 14.6 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25859817589660156		[learning rate: 0.0042008]
	Learning Rate: 0.00420081
	LOSS [training: 0.25859817589660156 | validation: 0.2120557079788997]
	TIME [epoch: 14.6 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2537624812281309		[learning rate: 0.004186]
	Learning Rate: 0.00418596
	LOSS [training: 0.2537624812281309 | validation: 0.20968876343742665]
	TIME [epoch: 14.6 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26035467188537953		[learning rate: 0.0041712]
	Learning Rate: 0.00417116
	LOSS [training: 0.26035467188537953 | validation: 0.21566606394823676]
	TIME [epoch: 14.6 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.254397565855368		[learning rate: 0.0041564]
	Learning Rate: 0.00415641
	LOSS [training: 0.254397565855368 | validation: 0.21221502701652098]
	TIME [epoch: 14.6 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25923019622550275		[learning rate: 0.0041417]
	Learning Rate: 0.00414171
	LOSS [training: 0.25923019622550275 | validation: 0.2131012086819876]
	TIME [epoch: 14.5 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25857721966795716		[learning rate: 0.0041271]
	Learning Rate: 0.00412706
	LOSS [training: 0.25857721966795716 | validation: 0.20652654023347283]
	TIME [epoch: 14.5 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25752574723797256		[learning rate: 0.0041125]
	Learning Rate: 0.00411247
	LOSS [training: 0.25752574723797256 | validation: 0.20619146643736164]
	TIME [epoch: 14.6 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26094944355855615		[learning rate: 0.0040979]
	Learning Rate: 0.00409793
	LOSS [training: 0.26094944355855615 | validation: 0.2126887745554425]
	TIME [epoch: 14.5 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2481851297631794		[learning rate: 0.0040834]
	Learning Rate: 0.00408344
	LOSS [training: 0.2481851297631794 | validation: 0.20435877908940178]
	TIME [epoch: 14.6 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13_20240719_005001/states/model_facs_v3_dec1b_2dpca_v13_303.pth
	Model improved!!!
EPOCH 304/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2568186134359702		[learning rate: 0.004069]
	Learning Rate: 0.004069
	LOSS [training: 0.2568186134359702 | validation: 0.21281034962555118]
	TIME [epoch: 14.6 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2589766187164719		[learning rate: 0.0040546]
	Learning Rate: 0.00405461
	LOSS [training: 0.2589766187164719 | validation: 0.21437674230616963]
	TIME [epoch: 14.6 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24999245177591722		[learning rate: 0.0040403]
	Learning Rate: 0.00404027
	LOSS [training: 0.24999245177591722 | validation: 0.20763319967249155]
	TIME [epoch: 14.6 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24871985635189872		[learning rate: 0.004026]
	Learning Rate: 0.00402598
	LOSS [training: 0.24871985635189872 | validation: 0.20619377704557923]
	TIME [epoch: 14.6 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2587948156819257		[learning rate: 0.0040117]
	Learning Rate: 0.00401175
	LOSS [training: 0.2587948156819257 | validation: 0.2094296075756274]
	TIME [epoch: 14.6 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26604638590293733		[learning rate: 0.0039976]
	Learning Rate: 0.00399756
	LOSS [training: 0.26604638590293733 | validation: 0.20764765901974566]
	TIME [epoch: 14.6 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25467109891428924		[learning rate: 0.0039834]
	Learning Rate: 0.00398342
	LOSS [training: 0.25467109891428924 | validation: 0.21279387969711436]
	TIME [epoch: 14.6 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2510646486565897		[learning rate: 0.0039693]
	Learning Rate: 0.00396934
	LOSS [training: 0.2510646486565897 | validation: 0.20670054878105026]
	TIME [epoch: 14.6 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25071439654128713		[learning rate: 0.0039553]
	Learning Rate: 0.0039553
	LOSS [training: 0.25071439654128713 | validation: 0.214091921523419]
	TIME [epoch: 14.6 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25735635668304907		[learning rate: 0.0039413]
	Learning Rate: 0.00394131
	LOSS [training: 0.25735635668304907 | validation: 0.21625346124743725]
	TIME [epoch: 14.6 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26222257607434624		[learning rate: 0.0039274]
	Learning Rate: 0.00392738
	LOSS [training: 0.26222257607434624 | validation: 0.21553463150353952]
	TIME [epoch: 14.5 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2616860842390701		[learning rate: 0.0039135]
	Learning Rate: 0.00391349
	LOSS [training: 0.2616860842390701 | validation: 0.20981906344908968]
	TIME [epoch: 14.6 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25199289912949224		[learning rate: 0.0038997]
	Learning Rate: 0.00389965
	LOSS [training: 0.25199289912949224 | validation: 0.21359175874574016]
	TIME [epoch: 14.6 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2551543313896388		[learning rate: 0.0038859]
	Learning Rate: 0.00388586
	LOSS [training: 0.2551543313896388 | validation: 0.21091411414728892]
	TIME [epoch: 14.6 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2599802125700295		[learning rate: 0.0038721]
	Learning Rate: 0.00387212
	LOSS [training: 0.2599802125700295 | validation: 0.21217270869786664]
	TIME [epoch: 14.5 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2520033625375067		[learning rate: 0.0038584]
	Learning Rate: 0.00385843
	LOSS [training: 0.2520033625375067 | validation: 0.2093417711537977]
	TIME [epoch: 14.6 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2520288581984537		[learning rate: 0.0038448]
	Learning Rate: 0.00384478
	LOSS [training: 0.2520288581984537 | validation: 0.21454906798345846]
	TIME [epoch: 14.5 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25725705295668444		[learning rate: 0.0038312]
	Learning Rate: 0.00383119
	LOSS [training: 0.25725705295668444 | validation: 0.21092089218443025]
	TIME [epoch: 14.6 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2565329343370883		[learning rate: 0.0038176]
	Learning Rate: 0.00381764
	LOSS [training: 0.2565329343370883 | validation: 0.2130890710076221]
	TIME [epoch: 14.5 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25653929216174565		[learning rate: 0.0038041]
	Learning Rate: 0.00380414
	LOSS [training: 0.25653929216174565 | validation: 0.21770876920594978]
	TIME [epoch: 14.6 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2569967020073097		[learning rate: 0.0037907]
	Learning Rate: 0.00379069
	LOSS [training: 0.2569967020073097 | validation: 0.21689160722819906]
	TIME [epoch: 14.6 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25908305365308676		[learning rate: 0.0037773]
	Learning Rate: 0.00377728
	LOSS [training: 0.25908305365308676 | validation: 0.2149852608891424]
	TIME [epoch: 14.6 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26396547655992725		[learning rate: 0.0037639]
	Learning Rate: 0.00376393
	LOSS [training: 0.26396547655992725 | validation: 0.2135055727375562]
	TIME [epoch: 14.6 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2533137782145505		[learning rate: 0.0037506]
	Learning Rate: 0.00375062
	LOSS [training: 0.2533137782145505 | validation: 0.21522174824695703]
	TIME [epoch: 14.6 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26123462487848065		[learning rate: 0.0037374]
	Learning Rate: 0.00373735
	LOSS [training: 0.26123462487848065 | validation: 0.21559270515843706]
	TIME [epoch: 14.6 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25903864356250983		[learning rate: 0.0037241]
	Learning Rate: 0.00372414
	LOSS [training: 0.25903864356250983 | validation: 0.2133198943761959]
	TIME [epoch: 14.6 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2533964511619307		[learning rate: 0.003711]
	Learning Rate: 0.00371097
	LOSS [training: 0.2533964511619307 | validation: 0.209028475131496]
	TIME [epoch: 14.6 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2632759052510161		[learning rate: 0.0036978]
	Learning Rate: 0.00369785
	LOSS [training: 0.2632759052510161 | validation: 0.21898860970724354]
	TIME [epoch: 14.6 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25295211743163487		[learning rate: 0.0036848]
	Learning Rate: 0.00368477
	LOSS [training: 0.25295211743163487 | validation: 0.2108446996624449]
	TIME [epoch: 14.6 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.261618942649665		[learning rate: 0.0036717]
	Learning Rate: 0.00367174
	LOSS [training: 0.261618942649665 | validation: 0.21487248627583638]
	TIME [epoch: 14.6 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2524227896495593		[learning rate: 0.0036588]
	Learning Rate: 0.00365875
	LOSS [training: 0.2524227896495593 | validation: 0.21633158099969182]
	TIME [epoch: 14.6 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2550390096545979		[learning rate: 0.0036458]
	Learning Rate: 0.00364582
	LOSS [training: 0.2550390096545979 | validation: 0.21554953599769583]
	TIME [epoch: 14.6 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.262477732803262		[learning rate: 0.0036329]
	Learning Rate: 0.00363292
	LOSS [training: 0.262477732803262 | validation: 0.21557032644592639]
	TIME [epoch: 14.6 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24807382433062444		[learning rate: 0.0036201]
	Learning Rate: 0.00362008
	LOSS [training: 0.24807382433062444 | validation: 0.21364986932699132]
	TIME [epoch: 14.6 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24990484819688574		[learning rate: 0.0036073]
	Learning Rate: 0.00360728
	LOSS [training: 0.24990484819688574 | validation: 0.21396360040084633]
	TIME [epoch: 14.6 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2577057007198425		[learning rate: 0.0035945]
	Learning Rate: 0.00359452
	LOSS [training: 0.2577057007198425 | validation: 0.21799726513746429]
	TIME [epoch: 14.5 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2504870276990978		[learning rate: 0.0035818]
	Learning Rate: 0.00358181
	LOSS [training: 0.2504870276990978 | validation: 0.21572147151159843]
	TIME [epoch: 14.6 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2554555864066516		[learning rate: 0.0035691]
	Learning Rate: 0.00356914
	LOSS [training: 0.2554555864066516 | validation: 0.20961159111090993]
	TIME [epoch: 14.6 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2515091070927864		[learning rate: 0.0035565]
	Learning Rate: 0.00355652
	LOSS [training: 0.2515091070927864 | validation: 0.21246206446168672]
	TIME [epoch: 14.6 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2584882895851663		[learning rate: 0.0035439]
	Learning Rate: 0.00354395
	LOSS [training: 0.2584882895851663 | validation: 0.21017887824686038]
	TIME [epoch: 14.6 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2539521297782225		[learning rate: 0.0035314]
	Learning Rate: 0.00353141
	LOSS [training: 0.2539521297782225 | validation: 0.2075028629768548]
	TIME [epoch: 14.6 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25970394996863827		[learning rate: 0.0035189]
	Learning Rate: 0.00351893
	LOSS [training: 0.25970394996863827 | validation: 0.21318851857280358]
	TIME [epoch: 14.6 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2586690683420412		[learning rate: 0.0035065]
	Learning Rate: 0.00350648
	LOSS [training: 0.2586690683420412 | validation: 0.21425063673869618]
	TIME [epoch: 14.6 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2524058873635061		[learning rate: 0.0034941]
	Learning Rate: 0.00349408
	LOSS [training: 0.2524058873635061 | validation: 0.20935324034346875]
	TIME [epoch: 14.6 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2617388644046556		[learning rate: 0.0034817]
	Learning Rate: 0.00348173
	LOSS [training: 0.2617388644046556 | validation: 0.22494436248129795]
	TIME [epoch: 14.6 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26108643224522915		[learning rate: 0.0034694]
	Learning Rate: 0.00346942
	LOSS [training: 0.26108643224522915 | validation: 0.21310309675431358]
	TIME [epoch: 14.6 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2531044071078989		[learning rate: 0.0034571]
	Learning Rate: 0.00345715
	LOSS [training: 0.2531044071078989 | validation: 0.21489771737657026]
	TIME [epoch: 14.6 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2577814601539307		[learning rate: 0.0034449]
	Learning Rate: 0.00344492
	LOSS [training: 0.2577814601539307 | validation: 0.2156320435669871]
	TIME [epoch: 14.5 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25229315840364513		[learning rate: 0.0034327]
	Learning Rate: 0.00343274
	LOSS [training: 0.25229315840364513 | validation: 0.22026687351021196]
	TIME [epoch: 14.6 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26353258227967225		[learning rate: 0.0034206]
	Learning Rate: 0.0034206
	LOSS [training: 0.26353258227967225 | validation: 0.21100216177803435]
	TIME [epoch: 14.6 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25500370059854244		[learning rate: 0.0034085]
	Learning Rate: 0.00340851
	LOSS [training: 0.25500370059854244 | validation: 0.218973243500663]
	TIME [epoch: 14.6 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2498502715719527		[learning rate: 0.0033965]
	Learning Rate: 0.00339645
	LOSS [training: 0.2498502715719527 | validation: 0.21596225656226958]
	TIME [epoch: 14.6 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25000235523205777		[learning rate: 0.0033844]
	Learning Rate: 0.00338444
	LOSS [training: 0.25000235523205777 | validation: 0.22006295189461483]
	TIME [epoch: 14.6 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2600642252787369		[learning rate: 0.0033725]
	Learning Rate: 0.00337247
	LOSS [training: 0.2600642252787369 | validation: 0.2063118808958214]
	TIME [epoch: 14.5 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2505538654204747		[learning rate: 0.0033605]
	Learning Rate: 0.00336055
	LOSS [training: 0.2505538654204747 | validation: 0.21043501989797858]
	TIME [epoch: 14.6 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26200124879070263		[learning rate: 0.0033487]
	Learning Rate: 0.00334867
	LOSS [training: 0.26200124879070263 | validation: 0.21712761682621876]
	TIME [epoch: 14.5 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25100659007943826		[learning rate: 0.0033368]
	Learning Rate: 0.00333682
	LOSS [training: 0.25100659007943826 | validation: 0.212663497176042]
	TIME [epoch: 14.6 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24935165023661596		[learning rate: 0.003325]
	Learning Rate: 0.00332502
	LOSS [training: 0.24935165023661596 | validation: 0.21173206157237295]
	TIME [epoch: 14.5 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25394912579786655		[learning rate: 0.0033133]
	Learning Rate: 0.00331327
	LOSS [training: 0.25394912579786655 | validation: 0.2078756157715686]
	TIME [epoch: 14.6 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25656188670487456		[learning rate: 0.0033016]
	Learning Rate: 0.00330155
	LOSS [training: 0.25656188670487456 | validation: 0.20838302362675165]
	TIME [epoch: 14.6 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2556806922891916		[learning rate: 0.0032899]
	Learning Rate: 0.00328988
	LOSS [training: 0.2556806922891916 | validation: 0.21278000989405776]
	TIME [epoch: 14.6 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2603682521455086		[learning rate: 0.0032782]
	Learning Rate: 0.00327824
	LOSS [training: 0.2603682521455086 | validation: 0.2130443291524727]
	TIME [epoch: 14.6 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24950294977524864		[learning rate: 0.0032666]
	Learning Rate: 0.00326665
	LOSS [training: 0.24950294977524864 | validation: 0.21735220518321788]
	TIME [epoch: 14.6 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25387728009702965		[learning rate: 0.0032551]
	Learning Rate: 0.0032551
	LOSS [training: 0.25387728009702965 | validation: 0.2083603068814453]
	TIME [epoch: 14.6 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2518271416802367		[learning rate: 0.0032436]
	Learning Rate: 0.00324359
	LOSS [training: 0.2518271416802367 | validation: 0.21702845243030228]
	TIME [epoch: 14.6 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2555755454259901		[learning rate: 0.0032321]
	Learning Rate: 0.00323212
	LOSS [training: 0.2555755454259901 | validation: 0.21571662394633204]
	TIME [epoch: 14.5 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2536572271741346		[learning rate: 0.0032207]
	Learning Rate: 0.00322069
	LOSS [training: 0.2536572271741346 | validation: 0.2221395704606801]
	TIME [epoch: 14.5 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2481908845923796		[learning rate: 0.0032093]
	Learning Rate: 0.0032093
	LOSS [training: 0.2481908845923796 | validation: 0.20894890567288513]
	TIME [epoch: 14.6 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2505380040308851		[learning rate: 0.003198]
	Learning Rate: 0.00319795
	LOSS [training: 0.2505380040308851 | validation: 0.21056803889342462]
	TIME [epoch: 14.6 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25563060069380195		[learning rate: 0.0031866]
	Learning Rate: 0.00318664
	LOSS [training: 0.25563060069380195 | validation: 0.21772655643326963]
	TIME [epoch: 14.5 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25493796361456383		[learning rate: 0.0031754]
	Learning Rate: 0.00317537
	LOSS [training: 0.25493796361456383 | validation: 0.21215508181099524]
	TIME [epoch: 14.6 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24746001652798624		[learning rate: 0.0031641]
	Learning Rate: 0.00316415
	LOSS [training: 0.24746001652798624 | validation: 0.20476076869918547]
	TIME [epoch: 14.6 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24980188533533054		[learning rate: 0.003153]
	Learning Rate: 0.00315296
	LOSS [training: 0.24980188533533054 | validation: 0.2048578950169441]
	TIME [epoch: 14.6 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2453930201419997		[learning rate: 0.0031418]
	Learning Rate: 0.00314181
	LOSS [training: 0.2453930201419997 | validation: 0.22292594093426468]
	TIME [epoch: 14.6 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2575626061851178		[learning rate: 0.0031307]
	Learning Rate: 0.0031307
	LOSS [training: 0.2575626061851178 | validation: 0.22027574951846662]
	TIME [epoch: 14.6 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2549772650688232		[learning rate: 0.0031196]
	Learning Rate: 0.00311963
	LOSS [training: 0.2549772650688232 | validation: 0.2132343769464431]
	TIME [epoch: 14.5 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24845882916028325		[learning rate: 0.0031086]
	Learning Rate: 0.00310859
	LOSS [training: 0.24845882916028325 | validation: 0.2099132313711745]
	TIME [epoch: 14.6 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2528509845782052		[learning rate: 0.0030976]
	Learning Rate: 0.0030976
	LOSS [training: 0.2528509845782052 | validation: 0.2124425615974479]
	TIME [epoch: 14.6 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2556898947289699		[learning rate: 0.0030866]
	Learning Rate: 0.00308665
	LOSS [training: 0.2556898947289699 | validation: 0.2128648053136663]
	TIME [epoch: 14.6 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25230909671071505		[learning rate: 0.0030757]
	Learning Rate: 0.00307573
	LOSS [training: 0.25230909671071505 | validation: 0.21124420174225428]
	TIME [epoch: 14.6 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2500547684262597		[learning rate: 0.0030649]
	Learning Rate: 0.00306486
	LOSS [training: 0.2500547684262597 | validation: 0.21018140585713158]
	TIME [epoch: 14.5 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24657851805224199		[learning rate: 0.003054]
	Learning Rate: 0.00305402
	LOSS [training: 0.24657851805224199 | validation: 0.2067103159082846]
	TIME [epoch: 14.6 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25375067647990074		[learning rate: 0.0030432]
	Learning Rate: 0.00304322
	LOSS [training: 0.25375067647990074 | validation: 0.21339701202780953]
	TIME [epoch: 14.6 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.258923528743011		[learning rate: 0.0030325]
	Learning Rate: 0.00303246
	LOSS [training: 0.258923528743011 | validation: 0.21494016875864785]
	TIME [epoch: 14.6 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25778452515981326		[learning rate: 0.0030217]
	Learning Rate: 0.00302174
	LOSS [training: 0.25778452515981326 | validation: 0.21594228023040613]
	TIME [epoch: 14.6 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24995673095882176		[learning rate: 0.003011]
	Learning Rate: 0.00301105
	LOSS [training: 0.24995673095882176 | validation: 0.21416242883734932]
	TIME [epoch: 14.6 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24926503962232407		[learning rate: 0.0030004]
	Learning Rate: 0.0030004
	LOSS [training: 0.24926503962232407 | validation: 0.21220791781298817]
	TIME [epoch: 14.6 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2512554889799729		[learning rate: 0.0029898]
	Learning Rate: 0.00298979
	LOSS [training: 0.2512554889799729 | validation: 0.21149114452892065]
	TIME [epoch: 14.6 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25221099407264197		[learning rate: 0.0029792]
	Learning Rate: 0.00297922
	LOSS [training: 0.25221099407264197 | validation: 0.21155553933871615]
	TIME [epoch: 14.6 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2601627278579235		[learning rate: 0.0029687]
	Learning Rate: 0.00296869
	LOSS [training: 0.2601627278579235 | validation: 0.21435277560877636]
	TIME [epoch: 14.6 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24751032322071168		[learning rate: 0.0029582]
	Learning Rate: 0.00295819
	LOSS [training: 0.24751032322071168 | validation: 0.20966687761052621]
	TIME [epoch: 14.6 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25832436560752814		[learning rate: 0.0029477]
	Learning Rate: 0.00294773
	LOSS [training: 0.25832436560752814 | validation: 0.21782048833795775]
	TIME [epoch: 14.5 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2543845556202871		[learning rate: 0.0029373]
	Learning Rate: 0.0029373
	LOSS [training: 0.2543845556202871 | validation: 0.2107515174680276]
	TIME [epoch: 14.6 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24987339917906892		[learning rate: 0.0029269]
	Learning Rate: 0.00292692
	LOSS [training: 0.24987339917906892 | validation: 0.21244778770286551]
	TIME [epoch: 14.6 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2497355747413814		[learning rate: 0.0029166]
	Learning Rate: 0.00291657
	LOSS [training: 0.2497355747413814 | validation: 0.21347133843553606]
	TIME [epoch: 14.6 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25472830803074586		[learning rate: 0.0029063]
	Learning Rate: 0.00290625
	LOSS [training: 0.25472830803074586 | validation: 0.21553303595163045]
	TIME [epoch: 14.6 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25236522947461887		[learning rate: 0.002896]
	Learning Rate: 0.00289598
	LOSS [training: 0.25236522947461887 | validation: 0.21252455719030605]
	TIME [epoch: 14.6 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25938647586165464		[learning rate: 0.0028857]
	Learning Rate: 0.00288573
	LOSS [training: 0.25938647586165464 | validation: 0.21061257014050389]
	TIME [epoch: 14.6 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24425292785961317		[learning rate: 0.0028755]
	Learning Rate: 0.00287553
	LOSS [training: 0.24425292785961317 | validation: 0.20200862638455078]
	TIME [epoch: 14.6 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13_20240719_005001/states/model_facs_v3_dec1b_2dpca_v13_402.pth
	Model improved!!!
EPOCH 403/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2553874354098278		[learning rate: 0.0028654]
	Learning Rate: 0.00286536
	LOSS [training: 0.2553874354098278 | validation: 0.2187318510154578]
	TIME [epoch: 14.6 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2500700285864674		[learning rate: 0.0028552]
	Learning Rate: 0.00285523
	LOSS [training: 0.2500700285864674 | validation: 0.20616014119064602]
	TIME [epoch: 14.6 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24333099502234876		[learning rate: 0.0028451]
	Learning Rate: 0.00284513
	LOSS [training: 0.24333099502234876 | validation: 0.2131479186909011]
	TIME [epoch: 14.5 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24822656575043434		[learning rate: 0.0028351]
	Learning Rate: 0.00283507
	LOSS [training: 0.24822656575043434 | validation: 0.21601335011853404]
	TIME [epoch: 14.6 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.252362139629202		[learning rate: 0.002825]
	Learning Rate: 0.00282505
	LOSS [training: 0.252362139629202 | validation: 0.21459111607495066]
	TIME [epoch: 14.5 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25000966324557633		[learning rate: 0.0028151]
	Learning Rate: 0.00281506
	LOSS [training: 0.25000966324557633 | validation: 0.20885910578051847]
	TIME [epoch: 14.6 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24918274653285546		[learning rate: 0.0028051]
	Learning Rate: 0.0028051
	LOSS [training: 0.24918274653285546 | validation: 0.20806438674744446]
	TIME [epoch: 14.6 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.252664314467911		[learning rate: 0.0027952]
	Learning Rate: 0.00279518
	LOSS [training: 0.252664314467911 | validation: 0.2095188512436586]
	TIME [epoch: 14.6 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2599474038916635		[learning rate: 0.0027853]
	Learning Rate: 0.0027853
	LOSS [training: 0.2599474038916635 | validation: 0.21480101642710184]
	TIME [epoch: 14.6 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25250821164039755		[learning rate: 0.0027754]
	Learning Rate: 0.00277545
	LOSS [training: 0.25250821164039755 | validation: 0.2139800893477231]
	TIME [epoch: 14.6 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25413416248502557		[learning rate: 0.0027656]
	Learning Rate: 0.00276564
	LOSS [training: 0.25413416248502557 | validation: 0.21388101716830726]
	TIME [epoch: 14.6 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25088173522117796		[learning rate: 0.0027559]
	Learning Rate: 0.00275586
	LOSS [training: 0.25088173522117796 | validation: 0.2065033309312335]
	TIME [epoch: 14.6 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25104306344518457		[learning rate: 0.0027461]
	Learning Rate: 0.00274611
	LOSS [training: 0.25104306344518457 | validation: 0.20767917880164113]
	TIME [epoch: 14.5 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2510814133999559		[learning rate: 0.0027364]
	Learning Rate: 0.0027364
	LOSS [training: 0.2510814133999559 | validation: 0.20993326728877015]
	TIME [epoch: 14.6 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2545752544214842		[learning rate: 0.0027267]
	Learning Rate: 0.00272672
	LOSS [training: 0.2545752544214842 | validation: 0.20882210226559042]
	TIME [epoch: 14.6 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25145029890528664		[learning rate: 0.0027171]
	Learning Rate: 0.00271708
	LOSS [training: 0.25145029890528664 | validation: 0.20739496879670463]
	TIME [epoch: 14.6 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25106989389394435		[learning rate: 0.0027075]
	Learning Rate: 0.00270747
	LOSS [training: 0.25106989389394435 | validation: 0.21012477682762176]
	TIME [epoch: 14.6 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2543401939539151		[learning rate: 0.0026979]
	Learning Rate: 0.0026979
	LOSS [training: 0.2543401939539151 | validation: 0.20386760997141168]
	TIME [epoch: 14.6 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25529423643139143		[learning rate: 0.0026884]
	Learning Rate: 0.00268836
	LOSS [training: 0.25529423643139143 | validation: 0.21141781597826123]
	TIME [epoch: 14.6 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2528097169301957		[learning rate: 0.0026789]
	Learning Rate: 0.00267885
	LOSS [training: 0.2528097169301957 | validation: 0.20984025888928884]
	TIME [epoch: 14.6 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24581581271920902		[learning rate: 0.0026694]
	Learning Rate: 0.00266938
	LOSS [training: 0.24581581271920902 | validation: 0.2048514165378216]
	TIME [epoch: 14.6 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2552868590088601		[learning rate: 0.0026599]
	Learning Rate: 0.00265994
	LOSS [training: 0.2552868590088601 | validation: 0.20488981241740428]
	TIME [epoch: 14.6 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25467270710701645		[learning rate: 0.0026505]
	Learning Rate: 0.00265053
	LOSS [training: 0.25467270710701645 | validation: 0.20540573282733243]
	TIME [epoch: 14.5 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25495937303471033		[learning rate: 0.0026412]
	Learning Rate: 0.00264116
	LOSS [training: 0.25495937303471033 | validation: 0.20808672738957218]
	TIME [epoch: 14.6 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24936545215926723		[learning rate: 0.0026318]
	Learning Rate: 0.00263182
	LOSS [training: 0.24936545215926723 | validation: 0.20747632740263247]
	TIME [epoch: 14.6 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24826114854194092		[learning rate: 0.0026225]
	Learning Rate: 0.00262251
	LOSS [training: 0.24826114854194092 | validation: 0.2156062537731666]
	TIME [epoch: 14.6 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24955525004733062		[learning rate: 0.0026132]
	Learning Rate: 0.00261324
	LOSS [training: 0.24955525004733062 | validation: 0.2122109476550514]
	TIME [epoch: 14.5 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25240524557400335		[learning rate: 0.002604]
	Learning Rate: 0.002604
	LOSS [training: 0.25240524557400335 | validation: 0.21282850062979297]
	TIME [epoch: 14.6 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25801521971051317		[learning rate: 0.0025948]
	Learning Rate: 0.00259479
	LOSS [training: 0.25801521971051317 | validation: 0.21236204607634085]
	TIME [epoch: 14.6 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2458361309333851		[learning rate: 0.0025856]
	Learning Rate: 0.00258562
	LOSS [training: 0.2458361309333851 | validation: 0.214791645138039]
	TIME [epoch: 14.6 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25716985411365534		[learning rate: 0.0025765]
	Learning Rate: 0.00257647
	LOSS [training: 0.25716985411365534 | validation: 0.2147762877458395]
	TIME [epoch: 14.6 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2543321583404529		[learning rate: 0.0025674]
	Learning Rate: 0.00256736
	LOSS [training: 0.2543321583404529 | validation: 0.21139160191586392]
	TIME [epoch: 14.6 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2561868219145928		[learning rate: 0.0025583]
	Learning Rate: 0.00255828
	LOSS [training: 0.2561868219145928 | validation: 0.21549462521112842]
	TIME [epoch: 14.6 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2509106956202382		[learning rate: 0.0025492]
	Learning Rate: 0.00254924
	LOSS [training: 0.2509106956202382 | validation: 0.21021743899063544]
	TIME [epoch: 14.6 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2530221630752733		[learning rate: 0.0025402]
	Learning Rate: 0.00254022
	LOSS [training: 0.2530221630752733 | validation: 0.2070091148782495]
	TIME [epoch: 14.6 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24960132426527956		[learning rate: 0.0025312]
	Learning Rate: 0.00253124
	LOSS [training: 0.24960132426527956 | validation: 0.20456031478894748]
	TIME [epoch: 14.6 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2513793712511693		[learning rate: 0.0025223]
	Learning Rate: 0.00252229
	LOSS [training: 0.2513793712511693 | validation: 0.20676051579557764]
	TIME [epoch: 14.6 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25385708197181484		[learning rate: 0.0025134]
	Learning Rate: 0.00251337
	LOSS [training: 0.25385708197181484 | validation: 0.21206089180948995]
	TIME [epoch: 14.6 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24986446480885974		[learning rate: 0.0025045]
	Learning Rate: 0.00250448
	LOSS [training: 0.24986446480885974 | validation: 0.2098377471916101]
	TIME [epoch: 14.6 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24532679024586193		[learning rate: 0.0024956]
	Learning Rate: 0.00249563
	LOSS [training: 0.24532679024586193 | validation: 0.21029212330560512]
	TIME [epoch: 14.5 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25062888154513274		[learning rate: 0.0024868]
	Learning Rate: 0.0024868
	LOSS [training: 0.25062888154513274 | validation: 0.20446223519797488]
	TIME [epoch: 14.5 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25238093148111423		[learning rate: 0.002478]
	Learning Rate: 0.00247801
	LOSS [training: 0.25238093148111423 | validation: 0.21102818841513354]
	TIME [epoch: 14.6 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2542555911155652		[learning rate: 0.0024692]
	Learning Rate: 0.00246924
	LOSS [training: 0.2542555911155652 | validation: 0.2116803733637898]
	TIME [epoch: 14.6 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24967587226745114		[learning rate: 0.0024605]
	Learning Rate: 0.00246051
	LOSS [training: 0.24967587226745114 | validation: 0.20941137999191387]
	TIME [epoch: 14.6 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2489179868480567		[learning rate: 0.0024518]
	Learning Rate: 0.00245181
	LOSS [training: 0.2489179868480567 | validation: 0.20784476206481065]
	TIME [epoch: 14.5 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24963449684726643		[learning rate: 0.0024431]
	Learning Rate: 0.00244314
	LOSS [training: 0.24963449684726643 | validation: 0.21614967651201367]
	TIME [epoch: 14.6 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2530681811383368		[learning rate: 0.0024345]
	Learning Rate: 0.0024345
	LOSS [training: 0.2530681811383368 | validation: 0.20756703976982846]
	TIME [epoch: 14.6 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2516073859437093		[learning rate: 0.0024259]
	Learning Rate: 0.00242589
	LOSS [training: 0.2516073859437093 | validation: 0.20799311156712275]
	TIME [epoch: 14.6 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2573200708985592		[learning rate: 0.0024173]
	Learning Rate: 0.00241732
	LOSS [training: 0.2573200708985592 | validation: 0.2116622814460122]
	TIME [epoch: 14.6 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24897390224094218		[learning rate: 0.0024088]
	Learning Rate: 0.00240877
	LOSS [training: 0.24897390224094218 | validation: 0.22409380123399475]
	TIME [epoch: 14.6 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24790054896820543		[learning rate: 0.0024002]
	Learning Rate: 0.00240025
	LOSS [training: 0.24790054896820543 | validation: 0.2113156365168461]
	TIME [epoch: 14.6 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2507105043368362		[learning rate: 0.0023918]
	Learning Rate: 0.00239176
	LOSS [training: 0.2507105043368362 | validation: 0.20738305113519875]
	TIME [epoch: 14.6 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2551959050572508		[learning rate: 0.0023833]
	Learning Rate: 0.0023833
	LOSS [training: 0.2551959050572508 | validation: 0.21354976962114622]
	TIME [epoch: 14.6 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24292738816845885		[learning rate: 0.0023749]
	Learning Rate: 0.00237488
	LOSS [training: 0.24292738816845885 | validation: 0.21285125689668333]
	TIME [epoch: 14.6 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25132480504930665		[learning rate: 0.0023665]
	Learning Rate: 0.00236648
	LOSS [training: 0.25132480504930665 | validation: 0.21546090749125865]
	TIME [epoch: 14.6 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2517215861180335		[learning rate: 0.0023581]
	Learning Rate: 0.00235811
	LOSS [training: 0.2517215861180335 | validation: 0.2062801728050879]
	TIME [epoch: 14.6 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25185601328412494		[learning rate: 0.0023498]
	Learning Rate: 0.00234977
	LOSS [training: 0.25185601328412494 | validation: 0.2083857460933153]
	TIME [epoch: 14.6 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25074751982949384		[learning rate: 0.0023415]
	Learning Rate: 0.00234146
	LOSS [training: 0.25074751982949384 | validation: 0.21369707403273175]
	TIME [epoch: 14.6 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25084406992753344		[learning rate: 0.0023332]
	Learning Rate: 0.00233318
	LOSS [training: 0.25084406992753344 | validation: 0.213204102262744]
	TIME [epoch: 14.6 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2502006899634285		[learning rate: 0.0023249]
	Learning Rate: 0.00232493
	LOSS [training: 0.2502006899634285 | validation: 0.21374838366194804]
	TIME [epoch: 14.6 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.245070895470931		[learning rate: 0.0023167]
	Learning Rate: 0.00231671
	LOSS [training: 0.245070895470931 | validation: 0.20759428386876352]
	TIME [epoch: 14.6 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2554679064214267		[learning rate: 0.0023085]
	Learning Rate: 0.00230852
	LOSS [training: 0.2554679064214267 | validation: 0.2107736127100456]
	TIME [epoch: 14.6 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24826460892840388		[learning rate: 0.0023004]
	Learning Rate: 0.00230035
	LOSS [training: 0.24826460892840388 | validation: 0.2106378722275747]
	TIME [epoch: 14.6 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2483370707752458		[learning rate: 0.0022922]
	Learning Rate: 0.00229222
	LOSS [training: 0.2483370707752458 | validation: 0.20935427559859013]
	TIME [epoch: 14.6 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25774406636862857		[learning rate: 0.0022841]
	Learning Rate: 0.00228411
	LOSS [training: 0.25774406636862857 | validation: 0.2157979655437215]
	TIME [epoch: 14.6 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25690484110089534		[learning rate: 0.002276]
	Learning Rate: 0.00227604
	LOSS [training: 0.25690484110089534 | validation: 0.2090538640776977]
	TIME [epoch: 14.5 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25300476063076155		[learning rate: 0.002268]
	Learning Rate: 0.00226799
	LOSS [training: 0.25300476063076155 | validation: 0.21270263723505756]
	TIME [epoch: 14.6 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24799087261837974		[learning rate: 0.00226]
	Learning Rate: 0.00225997
	LOSS [training: 0.24799087261837974 | validation: 0.20955780598061993]
	TIME [epoch: 14.6 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2479849529785637		[learning rate: 0.002252]
	Learning Rate: 0.00225198
	LOSS [training: 0.2479849529785637 | validation: 0.20979136619147773]
	TIME [epoch: 14.6 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2493049649318927		[learning rate: 0.002244]
	Learning Rate: 0.00224401
	LOSS [training: 0.2493049649318927 | validation: 0.20813041634208349]
	TIME [epoch: 14.6 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24569393550288185		[learning rate: 0.0022361]
	Learning Rate: 0.00223608
	LOSS [training: 0.24569393550288185 | validation: 0.20685047280507432]
	TIME [epoch: 14.6 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25184800447856365		[learning rate: 0.0022282]
	Learning Rate: 0.00222817
	LOSS [training: 0.25184800447856365 | validation: 0.20754267769317947]
	TIME [epoch: 14.6 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2537847878643958		[learning rate: 0.0022203]
	Learning Rate: 0.00222029
	LOSS [training: 0.2537847878643958 | validation: 0.20547248527826145]
	TIME [epoch: 14.6 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2481510249684399		[learning rate: 0.0022124]
	Learning Rate: 0.00221244
	LOSS [training: 0.2481510249684399 | validation: 0.2085588038645166]
	TIME [epoch: 14.6 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24671013356990087		[learning rate: 0.0022046]
	Learning Rate: 0.00220462
	LOSS [training: 0.24671013356990087 | validation: 0.2086109614234163]
	TIME [epoch: 14.6 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24489833263009986		[learning rate: 0.0021968]
	Learning Rate: 0.00219682
	LOSS [training: 0.24489833263009986 | validation: 0.21798574018737957]
	TIME [epoch: 14.6 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24874666977975948		[learning rate: 0.0021891]
	Learning Rate: 0.00218905
	LOSS [training: 0.24874666977975948 | validation: 0.2136166889056288]
	TIME [epoch: 14.6 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.259409842230607		[learning rate: 0.0021813]
	Learning Rate: 0.00218131
	LOSS [training: 0.259409842230607 | validation: 0.20865710508696128]
	TIME [epoch: 14.6 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24460021483152503		[learning rate: 0.0021736]
	Learning Rate: 0.0021736
	LOSS [training: 0.24460021483152503 | validation: 0.20478007137134918]
	TIME [epoch: 14.6 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2507230296075013		[learning rate: 0.0021659]
	Learning Rate: 0.00216591
	LOSS [training: 0.2507230296075013 | validation: 0.21348937503692156]
	TIME [epoch: 14.6 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24822159195410684		[learning rate: 0.0021583]
	Learning Rate: 0.00215825
	LOSS [training: 0.24822159195410684 | validation: 0.208585809951864]
	TIME [epoch: 14.6 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2482210829554825		[learning rate: 0.0021506]
	Learning Rate: 0.00215062
	LOSS [training: 0.2482210829554825 | validation: 0.20801031903186945]
	TIME [epoch: 14.6 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24420605869170076		[learning rate: 0.002143]
	Learning Rate: 0.00214302
	LOSS [training: 0.24420605869170076 | validation: 0.2125144555366926]
	TIME [epoch: 14.6 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24020405016225707		[learning rate: 0.0021354]
	Learning Rate: 0.00213544
	LOSS [training: 0.24020405016225707 | validation: 0.21140797072439396]
	TIME [epoch: 14.6 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25154473636751234		[learning rate: 0.0021279]
	Learning Rate: 0.00212789
	LOSS [training: 0.25154473636751234 | validation: 0.2083066719283439]
	TIME [epoch: 14.6 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25053989544004285		[learning rate: 0.0021204]
	Learning Rate: 0.00212036
	LOSS [training: 0.25053989544004285 | validation: 0.2119384966607119]
	TIME [epoch: 14.6 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25312985523435977		[learning rate: 0.0021129]
	Learning Rate: 0.00211287
	LOSS [training: 0.25312985523435977 | validation: 0.21119887880409918]
	TIME [epoch: 14.6 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24330590712441133		[learning rate: 0.0021054]
	Learning Rate: 0.00210539
	LOSS [training: 0.24330590712441133 | validation: 0.2110714618671984]
	TIME [epoch: 14.6 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25112134329482294		[learning rate: 0.0020979]
	Learning Rate: 0.00209795
	LOSS [training: 0.25112134329482294 | validation: 0.2102739483222781]
	TIME [epoch: 14.6 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25315632055712506		[learning rate: 0.0020905]
	Learning Rate: 0.00209053
	LOSS [training: 0.25315632055712506 | validation: 0.21033359304977645]
	TIME [epoch: 14.6 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25069967411170113		[learning rate: 0.0020831]
	Learning Rate: 0.00208314
	LOSS [training: 0.25069967411170113 | validation: 0.21852032281619377]
	TIME [epoch: 14.6 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2637711977726493		[learning rate: 0.0020758]
	Learning Rate: 0.00207577
	LOSS [training: 0.2637711977726493 | validation: 0.2047803973688314]
	TIME [epoch: 14.6 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24983598638142976		[learning rate: 0.0020684]
	Learning Rate: 0.00206843
	LOSS [training: 0.24983598638142976 | validation: 0.21067660224761936]
	TIME [epoch: 14.6 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24783148515526665		[learning rate: 0.0020611]
	Learning Rate: 0.00206112
	LOSS [training: 0.24783148515526665 | validation: 0.20455873244940337]
	TIME [epoch: 14.6 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2522663499549296		[learning rate: 0.0020538]
	Learning Rate: 0.00205383
	LOSS [training: 0.2522663499549296 | validation: 0.20929296616051665]
	TIME [epoch: 14.6 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25191450995850656		[learning rate: 0.0020466]
	Learning Rate: 0.00204657
	LOSS [training: 0.25191450995850656 | validation: 0.21043889056753465]
	TIME [epoch: 14.6 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24735109718050663		[learning rate: 0.0020393]
	Learning Rate: 0.00203933
	LOSS [training: 0.24735109718050663 | validation: 0.21046043265477737]
	TIME [epoch: 14.6 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24779434273520415		[learning rate: 0.0020321]
	Learning Rate: 0.00203212
	LOSS [training: 0.24779434273520415 | validation: 0.21333392124887424]
	TIME [epoch: 14.5 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25120649425572245		[learning rate: 0.0020249]
	Learning Rate: 0.00202493
	LOSS [training: 0.25120649425572245 | validation: 0.21451517930986386]
	TIME [epoch: 45.2 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24858213893807188		[learning rate: 0.0020178]
	Learning Rate: 0.00201777
	LOSS [training: 0.24858213893807188 | validation: 0.21138279675577215]
	TIME [epoch: 31.5 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24899842238470726		[learning rate: 0.0020106]
	Learning Rate: 0.00201064
	LOSS [training: 0.24899842238470726 | validation: 0.20818531492658635]
	TIME [epoch: 31.5 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24966344400494378		[learning rate: 0.0020035]
	Learning Rate: 0.00200353
	LOSS [training: 0.24966344400494378 | validation: 0.2128797813193343]
	TIME [epoch: 31.5 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24860289662557075		[learning rate: 0.0019964]
	Learning Rate: 0.00199644
	LOSS [training: 0.24860289662557075 | validation: 0.2027289319466216]
	TIME [epoch: 31.5 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25424921759262054		[learning rate: 0.0019894]
	Learning Rate: 0.00198938
	LOSS [training: 0.25424921759262054 | validation: 0.2100590224200146]
	TIME [epoch: 31.5 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24957595922455933		[learning rate: 0.0019823]
	Learning Rate: 0.00198235
	LOSS [training: 0.24957595922455933 | validation: 0.20607341270399485]
	TIME [epoch: 31.5 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2514785215033792		[learning rate: 0.0019753]
	Learning Rate: 0.00197534
	LOSS [training: 0.2514785215033792 | validation: 0.20152427994960248]
	TIME [epoch: 31.6 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13_20240719_005001/states/model_facs_v3_dec1b_2dpca_v13_508.pth
	Model improved!!!
EPOCH 509/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24650825609558202		[learning rate: 0.0019684]
	Learning Rate: 0.00196835
	LOSS [training: 0.24650825609558202 | validation: 0.20828854752449696]
	TIME [epoch: 31.5 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24719340655788502		[learning rate: 0.0019614]
	Learning Rate: 0.00196139
	LOSS [training: 0.24719340655788502 | validation: 0.20099565549093984]
	TIME [epoch: 31.5 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13_20240719_005001/states/model_facs_v3_dec1b_2dpca_v13_510.pth
	Model improved!!!
EPOCH 511/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2452917503483457		[learning rate: 0.0019545]
	Learning Rate: 0.00195445
	LOSS [training: 0.2452917503483457 | validation: 0.20926799684534184]
	TIME [epoch: 31.6 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24635162009203457		[learning rate: 0.0019475]
	Learning Rate: 0.00194754
	LOSS [training: 0.24635162009203457 | validation: 0.20331141780083506]
	TIME [epoch: 31.6 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24818800161317975		[learning rate: 0.0019407]
	Learning Rate: 0.00194066
	LOSS [training: 0.24818800161317975 | validation: 0.21137854894637648]
	TIME [epoch: 31.6 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2570197417057496		[learning rate: 0.0019338]
	Learning Rate: 0.00193379
	LOSS [training: 0.2570197417057496 | validation: 0.2057762979235486]
	TIME [epoch: 31.5 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24904357960486825		[learning rate: 0.001927]
	Learning Rate: 0.00192696
	LOSS [training: 0.24904357960486825 | validation: 0.21371944244405627]
	TIME [epoch: 31.4 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25443701975062055		[learning rate: 0.0019201]
	Learning Rate: 0.00192014
	LOSS [training: 0.25443701975062055 | validation: 0.20561685399350688]
	TIME [epoch: 31.6 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24398127879997322		[learning rate: 0.0019134]
	Learning Rate: 0.00191335
	LOSS [training: 0.24398127879997322 | validation: 0.20985088784890876]
	TIME [epoch: 31.5 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2522911694461301		[learning rate: 0.0019066]
	Learning Rate: 0.00190659
	LOSS [training: 0.2522911694461301 | validation: 0.2078151923829974]
	TIME [epoch: 31.6 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2556469222471611		[learning rate: 0.0018998]
	Learning Rate: 0.00189984
	LOSS [training: 0.2556469222471611 | validation: 0.2098440015595085]
	TIME [epoch: 31.6 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24577786747549676		[learning rate: 0.0018931]
	Learning Rate: 0.00189313
	LOSS [training: 0.24577786747549676 | validation: 0.2089591616805894]
	TIME [epoch: 31.5 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24581714399732937		[learning rate: 0.0018864]
	Learning Rate: 0.00188643
	LOSS [training: 0.24581714399732937 | validation: 0.20739189520553586]
	TIME [epoch: 31.5 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2448229304795416		[learning rate: 0.0018798]
	Learning Rate: 0.00187976
	LOSS [training: 0.2448229304795416 | validation: 0.2101779258441709]
	TIME [epoch: 31.6 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24222978190678388		[learning rate: 0.0018731]
	Learning Rate: 0.00187311
	LOSS [training: 0.24222978190678388 | validation: 0.2072192318812022]
	TIME [epoch: 31.6 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24838646132501196		[learning rate: 0.0018665]
	Learning Rate: 0.00186649
	LOSS [training: 0.24838646132501196 | validation: 0.20876698062390547]
	TIME [epoch: 31.5 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25503613041320156		[learning rate: 0.0018599]
	Learning Rate: 0.00185989
	LOSS [training: 0.25503613041320156 | validation: 0.21077254417042002]
	TIME [epoch: 31.6 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25136489085776315		[learning rate: 0.0018533]
	Learning Rate: 0.00185331
	LOSS [training: 0.25136489085776315 | validation: 0.20811602199405588]
	TIME [epoch: 31.6 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24833809214654143		[learning rate: 0.0018468]
	Learning Rate: 0.00184676
	LOSS [training: 0.24833809214654143 | validation: 0.20671293381097922]
	TIME [epoch: 31.6 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25090124703682837		[learning rate: 0.0018402]
	Learning Rate: 0.00184023
	LOSS [training: 0.25090124703682837 | validation: 0.20779117564565977]
	TIME [epoch: 31.6 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2540334979619928		[learning rate: 0.0018337]
	Learning Rate: 0.00183372
	LOSS [training: 0.2540334979619928 | validation: 0.20826463106038706]
	TIME [epoch: 31.6 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26286444755259364		[learning rate: 0.0018272]
	Learning Rate: 0.00182724
	LOSS [training: 0.26286444755259364 | validation: 0.23124153585712218]
	TIME [epoch: 31.6 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2623313136241858		[learning rate: 0.0018208]
	Learning Rate: 0.00182078
	LOSS [training: 0.2623313136241858 | validation: 0.20385077668125956]
	TIME [epoch: 31.6 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2502386742690462		[learning rate: 0.0018143]
	Learning Rate: 0.00181434
	LOSS [training: 0.2502386742690462 | validation: 0.20951737681887955]
	TIME [epoch: 31.6 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24745002310781083		[learning rate: 0.0018079]
	Learning Rate: 0.00180792
	LOSS [training: 0.24745002310781083 | validation: 0.21065379854870972]
	TIME [epoch: 31.5 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2488383270036345		[learning rate: 0.0018015]
	Learning Rate: 0.00180153
	LOSS [training: 0.2488383270036345 | validation: 0.2033053442174336]
	TIME [epoch: 31.5 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25255432359278		[learning rate: 0.0017952]
	Learning Rate: 0.00179516
	LOSS [training: 0.25255432359278 | validation: 0.2060591329913553]
	TIME [epoch: 31.5 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24963154537727447		[learning rate: 0.0017888]
	Learning Rate: 0.00178881
	LOSS [training: 0.24963154537727447 | validation: 0.20637625647104607]
	TIME [epoch: 31.4 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24623417540674997		[learning rate: 0.0017825]
	Learning Rate: 0.00178248
	LOSS [training: 0.24623417540674997 | validation: 0.20826628420983928]
	TIME [epoch: 31.5 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2524255101079512		[learning rate: 0.0017762]
	Learning Rate: 0.00177618
	LOSS [training: 0.2524255101079512 | validation: 0.20897706218877915]
	TIME [epoch: 31.5 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2503598311837234		[learning rate: 0.0017699]
	Learning Rate: 0.0017699
	LOSS [training: 0.2503598311837234 | validation: 0.2030504323561157]
	TIME [epoch: 31.4 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25297114251847347		[learning rate: 0.0017636]
	Learning Rate: 0.00176364
	LOSS [training: 0.25297114251847347 | validation: 0.2162347237722319]
	TIME [epoch: 31.6 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2532597129695524		[learning rate: 0.0017574]
	Learning Rate: 0.0017574
	LOSS [training: 0.2532597129695524 | validation: 0.2142828265914078]
	TIME [epoch: 31.6 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.250929789699269		[learning rate: 0.0017512]
	Learning Rate: 0.00175119
	LOSS [training: 0.250929789699269 | validation: 0.20490203722854333]
	TIME [epoch: 31.6 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23990674547407476		[learning rate: 0.001745]
	Learning Rate: 0.001745
	LOSS [training: 0.23990674547407476 | validation: 0.2081201497939059]
	TIME [epoch: 31.6 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24515250467094377		[learning rate: 0.0017388]
	Learning Rate: 0.00173883
	LOSS [training: 0.24515250467094377 | validation: 0.21211128819538608]
	TIME [epoch: 31.6 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2508169761784285		[learning rate: 0.0017327]
	Learning Rate: 0.00173268
	LOSS [training: 0.2508169761784285 | validation: 0.20841906445675767]
	TIME [epoch: 31.6 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24463539767184295		[learning rate: 0.0017266]
	Learning Rate: 0.00172655
	LOSS [training: 0.24463539767184295 | validation: 0.2104571507914348]
	TIME [epoch: 31.6 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25122480085470206		[learning rate: 0.0017204]
	Learning Rate: 0.00172045
	LOSS [training: 0.25122480085470206 | validation: 0.2095943122292791]
	TIME [epoch: 31.6 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25526436241094497		[learning rate: 0.0017144]
	Learning Rate: 0.00171436
	LOSS [training: 0.25526436241094497 | validation: 0.2118833470950853]
	TIME [epoch: 31.6 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24594751420546115		[learning rate: 0.0017083]
	Learning Rate: 0.0017083
	LOSS [training: 0.24594751420546115 | validation: 0.2095546600308932]
	TIME [epoch: 31.6 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25045205412688515		[learning rate: 0.0017023]
	Learning Rate: 0.00170226
	LOSS [training: 0.25045205412688515 | validation: 0.208394483417413]
	TIME [epoch: 31.5 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24685335508932718		[learning rate: 0.0016962]
	Learning Rate: 0.00169624
	LOSS [training: 0.24685335508932718 | validation: 0.21115160644358283]
	TIME [epoch: 31.5 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24724560992186487		[learning rate: 0.0016902]
	Learning Rate: 0.00169024
	LOSS [training: 0.24724560992186487 | validation: 0.20736371310114804]
	TIME [epoch: 31.5 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24961118689604064		[learning rate: 0.0016843]
	Learning Rate: 0.00168426
	LOSS [training: 0.24961118689604064 | validation: 0.20713575178089466]
	TIME [epoch: 31.6 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24642046784651397		[learning rate: 0.0016783]
	Learning Rate: 0.00167831
	LOSS [training: 0.24642046784651397 | validation: 0.21416614357461966]
	TIME [epoch: 31.5 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24912114165770438		[learning rate: 0.0016724]
	Learning Rate: 0.00167237
	LOSS [training: 0.24912114165770438 | validation: 0.20389940836382311]
	TIME [epoch: 31.5 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24727502223933007		[learning rate: 0.0016665]
	Learning Rate: 0.00166646
	LOSS [training: 0.24727502223933007 | validation: 0.20902385625080036]
	TIME [epoch: 31.6 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2439595137769869		[learning rate: 0.0016606]
	Learning Rate: 0.00166057
	LOSS [training: 0.2439595137769869 | validation: 0.21407495716054675]
	TIME [epoch: 31.6 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2456163340554159		[learning rate: 0.0016547]
	Learning Rate: 0.00165469
	LOSS [training: 0.2456163340554159 | validation: 0.2105985095322586]
	TIME [epoch: 31.4 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25076431218146217		[learning rate: 0.0016488]
	Learning Rate: 0.00164884
	LOSS [training: 0.25076431218146217 | validation: 0.21221121073342442]
	TIME [epoch: 31.6 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24579807306536813		[learning rate: 0.001643]
	Learning Rate: 0.00164301
	LOSS [training: 0.24579807306536813 | validation: 0.210060620674615]
	TIME [epoch: 31.6 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24978929423111587		[learning rate: 0.0016372]
	Learning Rate: 0.0016372
	LOSS [training: 0.24978929423111587 | validation: 0.20679619860995002]
	TIME [epoch: 31.5 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24907690591756756		[learning rate: 0.0016314]
	Learning Rate: 0.00163141
	LOSS [training: 0.24907690591756756 | validation: 0.2095034689774951]
	TIME [epoch: 31.6 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2523057395203147		[learning rate: 0.0016256]
	Learning Rate: 0.00162564
	LOSS [training: 0.2523057395203147 | validation: 0.20754781210445944]
	TIME [epoch: 31.6 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24430072945422157		[learning rate: 0.0016199]
	Learning Rate: 0.0016199
	LOSS [training: 0.24430072945422157 | validation: 0.21044733690352274]
	TIME [epoch: 31.6 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24084128226921006		[learning rate: 0.0016142]
	Learning Rate: 0.00161417
	LOSS [training: 0.24084128226921006 | validation: 0.20187605995363103]
	TIME [epoch: 31.6 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2474766750420193		[learning rate: 0.0016085]
	Learning Rate: 0.00160846
	LOSS [training: 0.2474766750420193 | validation: 0.20378803472100854]
	TIME [epoch: 31.6 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24772968115223173		[learning rate: 0.0016028]
	Learning Rate: 0.00160277
	LOSS [training: 0.24772968115223173 | validation: 0.20500111080175448]
	TIME [epoch: 31.6 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24654571056468869		[learning rate: 0.0015971]
	Learning Rate: 0.0015971
	LOSS [training: 0.24654571056468869 | validation: 0.20958221347673445]
	TIME [epoch: 31.5 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2505642956657541		[learning rate: 0.0015915]
	Learning Rate: 0.00159146
	LOSS [training: 0.2505642956657541 | validation: 0.21388258525770384]
	TIME [epoch: 31.5 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2513582339214699		[learning rate: 0.0015858]
	Learning Rate: 0.00158583
	LOSS [training: 0.2513582339214699 | validation: 0.20493081283525472]
	TIME [epoch: 31.5 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2461206427975435		[learning rate: 0.0015802]
	Learning Rate: 0.00158022
	LOSS [training: 0.2461206427975435 | validation: 0.215430519905925]
	TIME [epoch: 31.5 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24890697232646422		[learning rate: 0.0015746]
	Learning Rate: 0.00157463
	LOSS [training: 0.24890697232646422 | validation: 0.20526501439926706]
	TIME [epoch: 31.6 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24970291943085754		[learning rate: 0.0015691]
	Learning Rate: 0.00156907
	LOSS [training: 0.24970291943085754 | validation: 0.21495653206550341]
	TIME [epoch: 31.5 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24664105911842338		[learning rate: 0.0015635]
	Learning Rate: 0.00156352
	LOSS [training: 0.24664105911842338 | validation: 0.2153213670126818]
	TIME [epoch: 31.5 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24683381086781161		[learning rate: 0.001558]
	Learning Rate: 0.00155799
	LOSS [training: 0.24683381086781161 | validation: 0.210764434613659]
	TIME [epoch: 31.6 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2481555690452979		[learning rate: 0.0015525]
	Learning Rate: 0.00155248
	LOSS [training: 0.2481555690452979 | validation: 0.20987566059985227]
	TIME [epoch: 31.6 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2541703979600336		[learning rate: 0.001547]
	Learning Rate: 0.00154699
	LOSS [training: 0.2541703979600336 | validation: 0.20841870070397342]
	TIME [epoch: 31.6 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24497797025660464		[learning rate: 0.0015415]
	Learning Rate: 0.00154152
	LOSS [training: 0.24497797025660464 | validation: 0.20951318171962874]
	TIME [epoch: 31.5 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.251431130122537		[learning rate: 0.0015361]
	Learning Rate: 0.00153607
	LOSS [training: 0.251431130122537 | validation: 0.20259853463075134]
	TIME [epoch: 31.6 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24431251873349913		[learning rate: 0.0015306]
	Learning Rate: 0.00153064
	LOSS [training: 0.24431251873349913 | validation: 0.20651929513600567]
	TIME [epoch: 31.6 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.246536320861658		[learning rate: 0.0015252]
	Learning Rate: 0.00152522
	LOSS [training: 0.246536320861658 | validation: 0.21116471560558514]
	TIME [epoch: 31.6 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25017776261552854		[learning rate: 0.0015198]
	Learning Rate: 0.00151983
	LOSS [training: 0.25017776261552854 | validation: 0.20938462446582848]
	TIME [epoch: 31.6 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2507931763243105		[learning rate: 0.0015145]
	Learning Rate: 0.00151446
	LOSS [training: 0.2507931763243105 | validation: 0.20846371615181497]
	TIME [epoch: 31.6 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24896605204261554		[learning rate: 0.0015091]
	Learning Rate: 0.0015091
	LOSS [training: 0.24896605204261554 | validation: 0.2043982219156284]
	TIME [epoch: 31.6 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24477676731667886		[learning rate: 0.0015038]
	Learning Rate: 0.00150376
	LOSS [training: 0.24477676731667886 | validation: 0.2104851312252804]
	TIME [epoch: 31.6 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24765724015135823		[learning rate: 0.0014984]
	Learning Rate: 0.00149845
	LOSS [training: 0.24765724015135823 | validation: 0.20511982655611888]
	TIME [epoch: 31.6 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24615676184480295		[learning rate: 0.0014931]
	Learning Rate: 0.00149315
	LOSS [training: 0.24615676184480295 | validation: 0.2089373983428037]
	TIME [epoch: 31.6 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2516039468787789		[learning rate: 0.0014879]
	Learning Rate: 0.00148787
	LOSS [training: 0.2516039468787789 | validation: 0.21037899887776157]
	TIME [epoch: 31.6 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24560589702376534		[learning rate: 0.0014826]
	Learning Rate: 0.00148261
	LOSS [training: 0.24560589702376534 | validation: 0.2094834167117899]
	TIME [epoch: 31.6 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24711809664169634		[learning rate: 0.0014774]
	Learning Rate: 0.00147736
	LOSS [training: 0.24711809664169634 | validation: 0.20300337582614386]
	TIME [epoch: 31.6 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2448160866405795		[learning rate: 0.0014721]
	Learning Rate: 0.00147214
	LOSS [training: 0.2448160866405795 | validation: 0.20435016456291297]
	TIME [epoch: 31.5 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23915929445884787		[learning rate: 0.0014669]
	Learning Rate: 0.00146693
	LOSS [training: 0.23915929445884787 | validation: 0.2091265786392184]
	TIME [epoch: 31.5 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24418422462918518		[learning rate: 0.0014617]
	Learning Rate: 0.00146175
	LOSS [training: 0.24418422462918518 | validation: 0.20668190678957948]
	TIME [epoch: 31.5 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24522253965055196		[learning rate: 0.0014566]
	Learning Rate: 0.00145658
	LOSS [training: 0.24522253965055196 | validation: 0.2040457259923024]
	TIME [epoch: 31.5 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24959341127319		[learning rate: 0.0014514]
	Learning Rate: 0.00145143
	LOSS [training: 0.24959341127319 | validation: 0.20681149064312523]
	TIME [epoch: 31.6 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25011314598321016		[learning rate: 0.0014463]
	Learning Rate: 0.00144629
	LOSS [training: 0.25011314598321016 | validation: 0.20187525239587178]
	TIME [epoch: 31.6 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24689189000117073		[learning rate: 0.0014412]
	Learning Rate: 0.00144118
	LOSS [training: 0.24689189000117073 | validation: 0.20631176229563047]
	TIME [epoch: 31.5 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24370860486755705		[learning rate: 0.0014361]
	Learning Rate: 0.00143608
	LOSS [training: 0.24370860486755705 | validation: 0.20641565612036517]
	TIME [epoch: 31.5 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24547567069443457		[learning rate: 0.001431]
	Learning Rate: 0.001431
	LOSS [training: 0.24547567069443457 | validation: 0.2089186938331867]
	TIME [epoch: 31.6 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24407392028752906		[learning rate: 0.0014259]
	Learning Rate: 0.00142594
	LOSS [training: 0.24407392028752906 | validation: 0.21074424582081558]
	TIME [epoch: 31.6 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24897439947669175		[learning rate: 0.0014209]
	Learning Rate: 0.0014209
	LOSS [training: 0.24897439947669175 | validation: 0.19830129576674474]
	TIME [epoch: 31.4 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13_20240719_005001/states/model_facs_v3_dec1b_2dpca_v13_601.pth
	Model improved!!!
EPOCH 602/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25203828733590167		[learning rate: 0.0014159]
	Learning Rate: 0.00141588
	LOSS [training: 0.25203828733590167 | validation: 0.20735061422720552]
	TIME [epoch: 31.4 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24373434757050072		[learning rate: 0.0014109]
	Learning Rate: 0.00141087
	LOSS [training: 0.24373434757050072 | validation: 0.20946808109113166]
	TIME [epoch: 31.4 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24855289142420225		[learning rate: 0.0014059]
	Learning Rate: 0.00140588
	LOSS [training: 0.24855289142420225 | validation: 0.20709808534797203]
	TIME [epoch: 31.4 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24801131717982952		[learning rate: 0.0014009]
	Learning Rate: 0.00140091
	LOSS [training: 0.24801131717982952 | validation: 0.20932199462760437]
	TIME [epoch: 31.3 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2470402887782246		[learning rate: 0.001396]
	Learning Rate: 0.00139596
	LOSS [training: 0.2470402887782246 | validation: 0.21042747222146357]
	TIME [epoch: 31.4 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.247593468727779		[learning rate: 0.001391]
	Learning Rate: 0.00139102
	LOSS [training: 0.247593468727779 | validation: 0.21179605495839052]
	TIME [epoch: 31.4 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24494651666736364		[learning rate: 0.0013861]
	Learning Rate: 0.0013861
	LOSS [training: 0.24494651666736364 | validation: 0.21304412066127867]
	TIME [epoch: 31.5 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24501085822214938		[learning rate: 0.0013812]
	Learning Rate: 0.0013812
	LOSS [training: 0.24501085822214938 | validation: 0.20236966844905185]
	TIME [epoch: 31.4 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24450917871550948		[learning rate: 0.0013763]
	Learning Rate: 0.00137632
	LOSS [training: 0.24450917871550948 | validation: 0.21073801180742224]
	TIME [epoch: 31.5 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2413943275137428		[learning rate: 0.0013714]
	Learning Rate: 0.00137145
	LOSS [training: 0.2413943275137428 | validation: 0.20892834097286705]
	TIME [epoch: 31.4 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24629064186316338		[learning rate: 0.0013666]
	Learning Rate: 0.0013666
	LOSS [training: 0.24629064186316338 | validation: 0.20774411125515407]
	TIME [epoch: 31.4 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24362388155252127		[learning rate: 0.0013618]
	Learning Rate: 0.00136177
	LOSS [training: 0.24362388155252127 | validation: 0.20641700558219483]
	TIME [epoch: 31.4 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24477589521957968		[learning rate: 0.001357]
	Learning Rate: 0.00135695
	LOSS [training: 0.24477589521957968 | validation: 0.2067563024960765]
	TIME [epoch: 31.5 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24837675980519558		[learning rate: 0.0013522]
	Learning Rate: 0.00135215
	LOSS [training: 0.24837675980519558 | validation: 0.20821481223789523]
	TIME [epoch: 31.5 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24830566532949108		[learning rate: 0.0013474]
	Learning Rate: 0.00134737
	LOSS [training: 0.24830566532949108 | validation: 0.209805267837509]
	TIME [epoch: 31.5 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2487001761703591		[learning rate: 0.0013426]
	Learning Rate: 0.00134261
	LOSS [training: 0.2487001761703591 | validation: 0.20770155176141464]
	TIME [epoch: 31.5 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25554915202399026		[learning rate: 0.0013379]
	Learning Rate: 0.00133786
	LOSS [training: 0.25554915202399026 | validation: 0.21043812242675813]
	TIME [epoch: 31.4 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23873301800315264		[learning rate: 0.0013331]
	Learning Rate: 0.00133313
	LOSS [training: 0.23873301800315264 | validation: 0.21114145942109008]
	TIME [epoch: 31.5 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.247079091507778		[learning rate: 0.0013284]
	Learning Rate: 0.00132841
	LOSS [training: 0.247079091507778 | validation: 0.20506656417249008]
	TIME [epoch: 31.4 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2467183453782689		[learning rate: 0.0013237]
	Learning Rate: 0.00132372
	LOSS [training: 0.2467183453782689 | validation: 0.20632550690767237]
	TIME [epoch: 31.4 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24087986217257576		[learning rate: 0.001319]
	Learning Rate: 0.00131904
	LOSS [training: 0.24087986217257576 | validation: 0.20462042718347648]
	TIME [epoch: 31.5 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24308964977659353		[learning rate: 0.0013144]
	Learning Rate: 0.00131437
	LOSS [training: 0.24308964977659353 | validation: 0.20558574578305508]
	TIME [epoch: 31.4 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24999751352202804		[learning rate: 0.0013097]
	Learning Rate: 0.00130972
	LOSS [training: 0.24999751352202804 | validation: 0.20909699671799986]
	TIME [epoch: 31.5 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24544419583621424		[learning rate: 0.0013051]
	Learning Rate: 0.00130509
	LOSS [training: 0.24544419583621424 | validation: 0.20908913890051006]
	TIME [epoch: 31.4 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24360174207588167		[learning rate: 0.0013005]
	Learning Rate: 0.00130048
	LOSS [training: 0.24360174207588167 | validation: 0.21243677807375666]
	TIME [epoch: 31.5 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2571438895077909		[learning rate: 0.0012959]
	Learning Rate: 0.00129588
	LOSS [training: 0.2571438895077909 | validation: 0.21182946223806504]
	TIME [epoch: 31.4 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24460840014466123		[learning rate: 0.0012913]
	Learning Rate: 0.0012913
	LOSS [training: 0.24460840014466123 | validation: 0.21265175157416638]
	TIME [epoch: 31.4 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24327812854576425		[learning rate: 0.0012867]
	Learning Rate: 0.00128673
	LOSS [training: 0.24327812854576425 | validation: 0.2068122343385299]
	TIME [epoch: 31.3 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24473241491765627		[learning rate: 0.0012822]
	Learning Rate: 0.00128218
	LOSS [training: 0.24473241491765627 | validation: 0.20828333296965978]
	TIME [epoch: 31.4 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24304976107741952		[learning rate: 0.0012776]
	Learning Rate: 0.00127765
	LOSS [training: 0.24304976107741952 | validation: 0.2096905160969909]
	TIME [epoch: 31.4 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24964663306542736		[learning rate: 0.0012731]
	Learning Rate: 0.00127313
	LOSS [training: 0.24964663306542736 | validation: 0.2047073393701116]
	TIME [epoch: 31.4 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24710416636020807		[learning rate: 0.0012686]
	Learning Rate: 0.00126863
	LOSS [training: 0.24710416636020807 | validation: 0.213695179266404]
	TIME [epoch: 31.3 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24865752466658023		[learning rate: 0.0012641]
	Learning Rate: 0.00126414
	LOSS [training: 0.24865752466658023 | validation: 0.20879280421639868]
	TIME [epoch: 31.4 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2483444751420667		[learning rate: 0.0012597]
	Learning Rate: 0.00125967
	LOSS [training: 0.2483444751420667 | validation: 0.20991716854315462]
	TIME [epoch: 31.4 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2480203152727211		[learning rate: 0.0012552]
	Learning Rate: 0.00125521
	LOSS [training: 0.2480203152727211 | validation: 0.21040684629888365]
	TIME [epoch: 31.5 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2420736337017767		[learning rate: 0.0012508]
	Learning Rate: 0.00125078
	LOSS [training: 0.2420736337017767 | validation: 0.20349785108917282]
	TIME [epoch: 31.3 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2503408561615883		[learning rate: 0.0012464]
	Learning Rate: 0.00124635
	LOSS [training: 0.2503408561615883 | validation: 0.20863031311362118]
	TIME [epoch: 31.5 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24107921611576974		[learning rate: 0.0012419]
	Learning Rate: 0.00124195
	LOSS [training: 0.24107921611576974 | validation: 0.2037880560716971]
	TIME [epoch: 31.4 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24918824041905882		[learning rate: 0.0012376]
	Learning Rate: 0.00123755
	LOSS [training: 0.24918824041905882 | validation: 0.2079954770986511]
	TIME [epoch: 31.5 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24483541107544948		[learning rate: 0.0012332]
	Learning Rate: 0.00123318
	LOSS [training: 0.24483541107544948 | validation: 0.20421737398990816]
	TIME [epoch: 31.5 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2483381150275805		[learning rate: 0.0012288]
	Learning Rate: 0.00122882
	LOSS [training: 0.2483381150275805 | validation: 0.20928686930953333]
	TIME [epoch: 31.5 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24540007945021877		[learning rate: 0.0012245]
	Learning Rate: 0.00122447
	LOSS [training: 0.24540007945021877 | validation: 0.20562829833325763]
	TIME [epoch: 31.5 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24667699168251833		[learning rate: 0.0012201]
	Learning Rate: 0.00122014
	LOSS [training: 0.24667699168251833 | validation: 0.21094178674487862]
	TIME [epoch: 31.5 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2437287120940125		[learning rate: 0.0012158]
	Learning Rate: 0.00121583
	LOSS [training: 0.2437287120940125 | validation: 0.2085513362904531]
	TIME [epoch: 31.5 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24734829312403236		[learning rate: 0.0012115]
	Learning Rate: 0.00121153
	LOSS [training: 0.24734829312403236 | validation: 0.2094585052381639]
	TIME [epoch: 31.5 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2538185797625927		[learning rate: 0.0012072]
	Learning Rate: 0.00120724
	LOSS [training: 0.2538185797625927 | validation: 0.2038562329129502]
	TIME [epoch: 31.5 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24455195635681734		[learning rate: 0.001203]
	Learning Rate: 0.00120297
	LOSS [training: 0.24455195635681734 | validation: 0.2063990145233388]
	TIME [epoch: 31.5 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24984396176331192		[learning rate: 0.0011987]
	Learning Rate: 0.00119872
	LOSS [training: 0.24984396176331192 | validation: 0.2083300020272712]
	TIME [epoch: 31.4 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24939002074379146		[learning rate: 0.0011945]
	Learning Rate: 0.00119448
	LOSS [training: 0.24939002074379146 | validation: 0.2025547634092369]
	TIME [epoch: 31.4 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23979189283848293		[learning rate: 0.0011903]
	Learning Rate: 0.00119026
	LOSS [training: 0.23979189283848293 | validation: 0.20639386651662547]
	TIME [epoch: 31.3 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24802803318062253		[learning rate: 0.001186]
	Learning Rate: 0.00118605
	LOSS [training: 0.24802803318062253 | validation: 0.20815456112858258]
	TIME [epoch: 31.5 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25181141055580386		[learning rate: 0.0011819]
	Learning Rate: 0.00118185
	LOSS [training: 0.25181141055580386 | validation: 0.2072884032137045]
	TIME [epoch: 31.4 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.245307714040886		[learning rate: 0.0011777]
	Learning Rate: 0.00117768
	LOSS [training: 0.245307714040886 | validation: 0.19915438568989127]
	TIME [epoch: 31.4 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2440711187487077		[learning rate: 0.0011735]
	Learning Rate: 0.00117351
	LOSS [training: 0.2440711187487077 | validation: 0.20969897392032447]
	TIME [epoch: 31.4 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.254258566814688		[learning rate: 0.0011694]
	Learning Rate: 0.00116936
	LOSS [training: 0.254258566814688 | validation: 0.20779790560528086]
	TIME [epoch: 31.5 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2480726109374203		[learning rate: 0.0011652]
	Learning Rate: 0.00116523
	LOSS [training: 0.2480726109374203 | validation: 0.20728943367024635]
	TIME [epoch: 31.4 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24670920773294033		[learning rate: 0.0011611]
	Learning Rate: 0.00116111
	LOSS [training: 0.24670920773294033 | validation: 0.20825167592783284]
	TIME [epoch: 31.5 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24791914906391446		[learning rate: 0.001157]
	Learning Rate: 0.001157
	LOSS [training: 0.24791914906391446 | validation: 0.214020769533222]
	TIME [epoch: 31.3 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24833653224464605		[learning rate: 0.0011529]
	Learning Rate: 0.00115291
	LOSS [training: 0.24833653224464605 | validation: 0.2012095794661875]
	TIME [epoch: 31.5 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24705848297701463		[learning rate: 0.0011488]
	Learning Rate: 0.00114883
	LOSS [training: 0.24705848297701463 | validation: 0.20545009274252912]
	TIME [epoch: 31.4 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24265485719594163		[learning rate: 0.0011448]
	Learning Rate: 0.00114477
	LOSS [training: 0.24265485719594163 | validation: 0.20310059742124675]
	TIME [epoch: 31.5 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24702764430053903		[learning rate: 0.0011407]
	Learning Rate: 0.00114072
	LOSS [training: 0.24702764430053903 | validation: 0.20410361034543797]
	TIME [epoch: 31.4 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.246939648077916		[learning rate: 0.0011367]
	Learning Rate: 0.00113669
	LOSS [training: 0.246939648077916 | validation: 0.2032672609285379]
	TIME [epoch: 31.5 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24450773739684292		[learning rate: 0.0011327]
	Learning Rate: 0.00113267
	LOSS [training: 0.24450773739684292 | validation: 0.20875834578831517]
	TIME [epoch: 31.5 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24713545333974576		[learning rate: 0.0011287]
	Learning Rate: 0.00112866
	LOSS [training: 0.24713545333974576 | validation: 0.21271400018154404]
	TIME [epoch: 31.5 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2449182077154732		[learning rate: 0.0011247]
	Learning Rate: 0.00112467
	LOSS [training: 0.2449182077154732 | validation: 0.20523753711967307]
	TIME [epoch: 31.5 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2440044824872933		[learning rate: 0.0011207]
	Learning Rate: 0.00112069
	LOSS [training: 0.2440044824872933 | validation: 0.2122354354006481]
	TIME [epoch: 31.5 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2502942615784582		[learning rate: 0.0011167]
	Learning Rate: 0.00111673
	LOSS [training: 0.2502942615784582 | validation: 0.20325287295076455]
	TIME [epoch: 31.4 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2462684319574285		[learning rate: 0.0011128]
	Learning Rate: 0.00111278
	LOSS [training: 0.2462684319574285 | validation: 0.1997945398166733]
	TIME [epoch: 31.5 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2448372736061899		[learning rate: 0.0011088]
	Learning Rate: 0.00110885
	LOSS [training: 0.2448372736061899 | validation: 0.2077896533540451]
	TIME [epoch: 31.4 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24370349205725358		[learning rate: 0.0011049]
	Learning Rate: 0.00110493
	LOSS [training: 0.24370349205725358 | validation: 0.20876091756236198]
	TIME [epoch: 31.4 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24168686291392638		[learning rate: 0.001101]
	Learning Rate: 0.00110102
	LOSS [training: 0.24168686291392638 | validation: 0.20848380686926138]
	TIME [epoch: 31.5 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2537492102245356		[learning rate: 0.0010971]
	Learning Rate: 0.00109713
	LOSS [training: 0.2537492102245356 | validation: 0.2115165254159682]
	TIME [epoch: 31.5 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24302967082805452		[learning rate: 0.0010932]
	Learning Rate: 0.00109325
	LOSS [training: 0.24302967082805452 | validation: 0.20531512270961721]
	TIME [epoch: 31.4 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2462828853616699		[learning rate: 0.0010894]
	Learning Rate: 0.00108938
	LOSS [training: 0.2462828853616699 | validation: 0.20622709294950203]
	TIME [epoch: 31.4 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24896837786324277		[learning rate: 0.0010855]
	Learning Rate: 0.00108553
	LOSS [training: 0.24896837786324277 | validation: 0.20362203397101872]
	TIME [epoch: 31.3 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2485823129166144		[learning rate: 0.0010817]
	Learning Rate: 0.00108169
	LOSS [training: 0.2485823129166144 | validation: 0.2060520790413737]
	TIME [epoch: 31.4 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24810155356162156		[learning rate: 0.0010779]
	Learning Rate: 0.00107786
	LOSS [training: 0.24810155356162156 | validation: 0.21037133912834988]
	TIME [epoch: 31.3 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25235437639262276		[learning rate: 0.0010741]
	Learning Rate: 0.00107405
	LOSS [training: 0.25235437639262276 | validation: 0.20572947340576744]
	TIME [epoch: 31.4 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24897138077282924		[learning rate: 0.0010703]
	Learning Rate: 0.00107025
	LOSS [training: 0.24897138077282924 | validation: 0.2050348694872469]
	TIME [epoch: 31.3 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24596971246869268		[learning rate: 0.0010665]
	Learning Rate: 0.00106647
	LOSS [training: 0.24596971246869268 | validation: 0.20556918489853074]
	TIME [epoch: 31.4 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24234067586942384		[learning rate: 0.0010627]
	Learning Rate: 0.0010627
	LOSS [training: 0.24234067586942384 | validation: 0.20427041164457113]
	TIME [epoch: 31.3 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24329120862005174		[learning rate: 0.0010589]
	Learning Rate: 0.00105894
	LOSS [training: 0.24329120862005174 | validation: 0.20797133466675266]
	TIME [epoch: 31.5 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24367240061323256		[learning rate: 0.0010552]
	Learning Rate: 0.0010552
	LOSS [training: 0.24367240061323256 | validation: 0.2138207768730982]
	TIME [epoch: 31.4 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2414965837763122		[learning rate: 0.0010515]
	Learning Rate: 0.00105147
	LOSS [training: 0.2414965837763122 | validation: 0.20978911166185849]
	TIME [epoch: 31.5 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24797031170209652		[learning rate: 0.0010477]
	Learning Rate: 0.00104775
	LOSS [training: 0.24797031170209652 | validation: 0.20683205795801451]
	TIME [epoch: 31.5 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24582856435980963		[learning rate: 0.001044]
	Learning Rate: 0.00104404
	LOSS [training: 0.24582856435980963 | validation: 0.20877742564089824]
	TIME [epoch: 31.5 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24623245894216636		[learning rate: 0.0010404]
	Learning Rate: 0.00104035
	LOSS [training: 0.24623245894216636 | validation: 0.2098995378060014]
	TIME [epoch: 31.5 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25006461203750313		[learning rate: 0.0010367]
	Learning Rate: 0.00103667
	LOSS [training: 0.25006461203750313 | validation: 0.20944453718977143]
	TIME [epoch: 31.5 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.240164551138453		[learning rate: 0.001033]
	Learning Rate: 0.00103301
	LOSS [training: 0.240164551138453 | validation: 0.20832324187167345]
	TIME [epoch: 31.4 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2438690425519142		[learning rate: 0.0010294]
	Learning Rate: 0.00102935
	LOSS [training: 0.2438690425519142 | validation: 0.20984334083309036]
	TIME [epoch: 31.4 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24432160699470828		[learning rate: 0.0010257]
	Learning Rate: 0.00102571
	LOSS [training: 0.24432160699470828 | validation: 0.20690565361973734]
	TIME [epoch: 31.5 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24707822673664556		[learning rate: 0.0010221]
	Learning Rate: 0.00102209
	LOSS [training: 0.24707822673664556 | validation: 0.20548783015301333]
	TIME [epoch: 31.5 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2507458036737924		[learning rate: 0.0010185]
	Learning Rate: 0.00101847
	LOSS [training: 0.2507458036737924 | validation: 0.20874051309250546]
	TIME [epoch: 31.4 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24420467109843846		[learning rate: 0.0010149]
	Learning Rate: 0.00101487
	LOSS [training: 0.24420467109843846 | validation: 0.21238106877670285]
	TIME [epoch: 31.5 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24478802001243208		[learning rate: 0.0010113]
	Learning Rate: 0.00101128
	LOSS [training: 0.24478802001243208 | validation: 0.2049617715929787]
	TIME [epoch: 31.4 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24712032478383647		[learning rate: 0.0010077]
	Learning Rate: 0.0010077
	LOSS [training: 0.24712032478383647 | validation: 0.20643742536539106]
	TIME [epoch: 31.4 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24313228412558105		[learning rate: 0.0010041]
	Learning Rate: 0.00100414
	LOSS [training: 0.24313228412558105 | validation: 0.20915169711396814]
	TIME [epoch: 31.3 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2401267127399113		[learning rate: 0.0010006]
	Learning Rate: 0.00100059
	LOSS [training: 0.2401267127399113 | validation: 0.2033681042537323]
	TIME [epoch: 31.4 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24594617187461132		[learning rate: 0.00099705]
	Learning Rate: 0.000997052
	LOSS [training: 0.24594617187461132 | validation: 0.20891129251751353]
	TIME [epoch: 31.4 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24615031738081491		[learning rate: 0.00099353]
	Learning Rate: 0.000993527
	LOSS [training: 0.24615031738081491 | validation: 0.20724288393760162]
	TIME [epoch: 31.2 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24220685709205877		[learning rate: 0.00099001]
	Learning Rate: 0.000990013
	LOSS [training: 0.24220685709205877 | validation: 0.2105309398069294]
	TIME [epoch: 31.4 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24786729686844222		[learning rate: 0.00098651]
	Learning Rate: 0.000986513
	LOSS [training: 0.24786729686844222 | validation: 0.21600365971422483]
	TIME [epoch: 31.3 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2417330295088033		[learning rate: 0.00098302]
	Learning Rate: 0.000983024
	LOSS [training: 0.2417330295088033 | validation: 0.20401370487407217]
	TIME [epoch: 31.4 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2473892277627607		[learning rate: 0.00097955]
	Learning Rate: 0.000979548
	LOSS [training: 0.2473892277627607 | validation: 0.20600253563968823]
	TIME [epoch: 31.3 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25048159861930724		[learning rate: 0.00097608]
	Learning Rate: 0.000976084
	LOSS [training: 0.25048159861930724 | validation: 0.20088270997503493]
	TIME [epoch: 31.3 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24676141928339188		[learning rate: 0.00097263]
	Learning Rate: 0.000972632
	LOSS [training: 0.24676141928339188 | validation: 0.20883590914250183]
	TIME [epoch: 31.3 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24924580728917015		[learning rate: 0.00096919]
	Learning Rate: 0.000969193
	LOSS [training: 0.24924580728917015 | validation: 0.20544719896180172]
	TIME [epoch: 31.3 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24803781239331332		[learning rate: 0.00096577]
	Learning Rate: 0.000965766
	LOSS [training: 0.24803781239331332 | validation: 0.20704664275100226]
	TIME [epoch: 31.3 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24751784974041224		[learning rate: 0.00096235]
	Learning Rate: 0.000962351
	LOSS [training: 0.24751784974041224 | validation: 0.21039898576903626]
	TIME [epoch: 31.4 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24443420243398303		[learning rate: 0.00095895]
	Learning Rate: 0.000958948
	LOSS [training: 0.24443420243398303 | validation: 0.20925656307571416]
	TIME [epoch: 31.3 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2477129214890262		[learning rate: 0.00095556]
	Learning Rate: 0.000955557
	LOSS [training: 0.2477129214890262 | validation: 0.20965702877013387]
	TIME [epoch: 31.4 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24603992506034736		[learning rate: 0.00095218]
	Learning Rate: 0.000952178
	LOSS [training: 0.24603992506034736 | validation: 0.2062453371291162]
	TIME [epoch: 31.3 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24669594924781757		[learning rate: 0.00094881]
	Learning Rate: 0.00094881
	LOSS [training: 0.24669594924781757 | validation: 0.21369012965054018]
	TIME [epoch: 31.4 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24271549169785234		[learning rate: 0.00094546]
	Learning Rate: 0.000945455
	LOSS [training: 0.24271549169785234 | validation: 0.2087003456111546]
	TIME [epoch: 31.3 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2460817131459659		[learning rate: 0.00094211]
	Learning Rate: 0.000942112
	LOSS [training: 0.2460817131459659 | validation: 0.2101733849292569]
	TIME [epoch: 31.3 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24586180126844828		[learning rate: 0.00093878]
	Learning Rate: 0.000938781
	LOSS [training: 0.24586180126844828 | validation: 0.20160575186558147]
	TIME [epoch: 31.3 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2457007659750903		[learning rate: 0.00093546]
	Learning Rate: 0.000935461
	LOSS [training: 0.2457007659750903 | validation: 0.21489322484746873]
	TIME [epoch: 31.4 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24107643080012678		[learning rate: 0.00093215]
	Learning Rate: 0.000932153
	LOSS [training: 0.24107643080012678 | validation: 0.20659953050181742]
	TIME [epoch: 31.3 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23971899909151426		[learning rate: 0.00092886]
	Learning Rate: 0.000928857
	LOSS [training: 0.23971899909151426 | validation: 0.2091731879019632]
	TIME [epoch: 31.4 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24601896237852217		[learning rate: 0.00092557]
	Learning Rate: 0.000925572
	LOSS [training: 0.24601896237852217 | validation: 0.21195069526477367]
	TIME [epoch: 31.2 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24966744858652		[learning rate: 0.0009223]
	Learning Rate: 0.000922299
	LOSS [training: 0.24966744858652 | validation: 0.20948095552717003]
	TIME [epoch: 31.4 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24671865346757527		[learning rate: 0.00091904]
	Learning Rate: 0.000919038
	LOSS [training: 0.24671865346757527 | validation: 0.21033905086127644]
	TIME [epoch: 31.3 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2473757057842297		[learning rate: 0.00091579]
	Learning Rate: 0.000915788
	LOSS [training: 0.2473757057842297 | validation: 0.20903989405941997]
	TIME [epoch: 31.3 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2484825740127489		[learning rate: 0.00091255]
	Learning Rate: 0.000912549
	LOSS [training: 0.2484825740127489 | validation: 0.20404022616940348]
	TIME [epoch: 31.4 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24978437232200223		[learning rate: 0.00090932]
	Learning Rate: 0.000909323
	LOSS [training: 0.24978437232200223 | validation: 0.208873244138279]
	TIME [epoch: 31.5 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24177033116680244		[learning rate: 0.00090611]
	Learning Rate: 0.000906107
	LOSS [training: 0.24177033116680244 | validation: 0.20526454098823152]
	TIME [epoch: 31.3 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2466513255188814		[learning rate: 0.0009029]
	Learning Rate: 0.000902903
	LOSS [training: 0.2466513255188814 | validation: 0.20306601623843248]
	TIME [epoch: 31.2 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2475348618046048		[learning rate: 0.00089971]
	Learning Rate: 0.00089971
	LOSS [training: 0.2475348618046048 | validation: 0.20787310486501792]
	TIME [epoch: 31.2 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2504153185314161		[learning rate: 0.00089653]
	Learning Rate: 0.000896529
	LOSS [training: 0.2504153185314161 | validation: 0.20991611509788574]
	TIME [epoch: 31.2 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2410696845542264		[learning rate: 0.00089336]
	Learning Rate: 0.000893358
	LOSS [training: 0.2410696845542264 | validation: 0.2100497090010264]
	TIME [epoch: 31.3 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24805681234668944		[learning rate: 0.0008902]
	Learning Rate: 0.000890199
	LOSS [training: 0.24805681234668944 | validation: 0.20488044870485478]
	TIME [epoch: 31.3 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2427001178272299		[learning rate: 0.00088705]
	Learning Rate: 0.000887051
	LOSS [training: 0.2427001178272299 | validation: 0.20924530265807412]
	TIME [epoch: 31.3 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2496890954920046		[learning rate: 0.00088391]
	Learning Rate: 0.000883914
	LOSS [training: 0.2496890954920046 | validation: 0.20966272998472318]
	TIME [epoch: 31.4 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24456263223888589		[learning rate: 0.00088079]
	Learning Rate: 0.000880789
	LOSS [training: 0.24456263223888589 | validation: 0.20591780825287706]
	TIME [epoch: 31.4 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24579433287162303		[learning rate: 0.00087767]
	Learning Rate: 0.000877674
	LOSS [training: 0.24579433287162303 | validation: 0.20669267814583706]
	TIME [epoch: 31.5 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2471661882360344		[learning rate: 0.00087457]
	Learning Rate: 0.000874571
	LOSS [training: 0.2471661882360344 | validation: 0.20903082540879173]
	TIME [epoch: 31.4 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24642576712627606		[learning rate: 0.00087148]
	Learning Rate: 0.000871478
	LOSS [training: 0.24642576712627606 | validation: 0.20787122422891285]
	TIME [epoch: 31.5 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24600611524098437		[learning rate: 0.0008684]
	Learning Rate: 0.000868396
	LOSS [training: 0.24600611524098437 | validation: 0.21035965012766322]
	TIME [epoch: 31.4 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24801054027459135		[learning rate: 0.00086533]
	Learning Rate: 0.000865326
	LOSS [training: 0.24801054027459135 | validation: 0.20881812065995872]
	TIME [epoch: 31.4 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2381479769653425		[learning rate: 0.00086227]
	Learning Rate: 0.000862266
	LOSS [training: 0.2381479769653425 | validation: 0.20795035566084458]
	TIME [epoch: 31.4 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24349966933336523		[learning rate: 0.00085922]
	Learning Rate: 0.000859216
	LOSS [training: 0.24349966933336523 | validation: 0.2060300233704766]
	TIME [epoch: 31.4 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2426178901509287		[learning rate: 0.00085618]
	Learning Rate: 0.000856178
	LOSS [training: 0.2426178901509287 | validation: 0.20251505505300607]
	TIME [epoch: 31.3 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24512102987260756		[learning rate: 0.00085315]
	Learning Rate: 0.00085315
	LOSS [training: 0.24512102987260756 | validation: 0.2030779466587629]
	TIME [epoch: 31.4 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2442577707986611		[learning rate: 0.00085013]
	Learning Rate: 0.000850134
	LOSS [training: 0.2442577707986611 | validation: 0.20091495850341987]
	TIME [epoch: 31.5 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2440967655045904		[learning rate: 0.00084713]
	Learning Rate: 0.000847127
	LOSS [training: 0.2440967655045904 | validation: 0.20872865506653798]
	TIME [epoch: 31.5 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24682434207380125		[learning rate: 0.00084413]
	Learning Rate: 0.000844132
	LOSS [training: 0.24682434207380125 | validation: 0.20776971859868323]
	TIME [epoch: 31.4 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24482918330590495		[learning rate: 0.00084115]
	Learning Rate: 0.000841147
	LOSS [training: 0.24482918330590495 | validation: 0.20481927164217195]
	TIME [epoch: 31.5 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24850897950233905		[learning rate: 0.00083817]
	Learning Rate: 0.000838172
	LOSS [training: 0.24850897950233905 | validation: 0.20137817642824496]
	TIME [epoch: 31.3 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24386511152322435		[learning rate: 0.00083521]
	Learning Rate: 0.000835209
	LOSS [training: 0.24386511152322435 | validation: 0.2029110248184073]
	TIME [epoch: 31.4 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24891140196438374		[learning rate: 0.00083225]
	Learning Rate: 0.000832255
	LOSS [training: 0.24891140196438374 | validation: 0.20176387519360342]
	TIME [epoch: 31.5 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24393930386125554		[learning rate: 0.00082931]
	Learning Rate: 0.000829312
	LOSS [training: 0.24393930386125554 | validation: 0.2073192747675955]
	TIME [epoch: 31.4 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24696206890213893		[learning rate: 0.00082638]
	Learning Rate: 0.000826379
	LOSS [training: 0.24696206890213893 | validation: 0.20593640302842742]
	TIME [epoch: 31.4 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.243480880087654		[learning rate: 0.00082346]
	Learning Rate: 0.000823457
	LOSS [training: 0.243480880087654 | validation: 0.20941724184442193]
	TIME [epoch: 31.5 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24615907530215378		[learning rate: 0.00082055]
	Learning Rate: 0.000820545
	LOSS [training: 0.24615907530215378 | validation: 0.20262193117400912]
	TIME [epoch: 31.5 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24484383865395556		[learning rate: 0.00081764]
	Learning Rate: 0.000817644
	LOSS [training: 0.24484383865395556 | validation: 0.2064366693062129]
	TIME [epoch: 31.4 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.246533409654183		[learning rate: 0.00081475]
	Learning Rate: 0.000814752
	LOSS [training: 0.246533409654183 | validation: 0.20825791141945613]
	TIME [epoch: 31.4 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24620540419330297		[learning rate: 0.00081187]
	Learning Rate: 0.000811871
	LOSS [training: 0.24620540419330297 | validation: 0.20841754452452696]
	TIME [epoch: 31.4 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2450649296619968		[learning rate: 0.000809]
	Learning Rate: 0.000809
	LOSS [training: 0.2450649296619968 | validation: 0.20513976443563667]
	TIME [epoch: 31.4 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24153926280910876		[learning rate: 0.00080614]
	Learning Rate: 0.00080614
	LOSS [training: 0.24153926280910876 | validation: 0.2064495084946043]
	TIME [epoch: 31.5 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2373791511263591		[learning rate: 0.00080329]
	Learning Rate: 0.000803289
	LOSS [training: 0.2373791511263591 | validation: 0.20662725114247574]
	TIME [epoch: 31.4 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24824105214047165		[learning rate: 0.00080045]
	Learning Rate: 0.000800448
	LOSS [training: 0.24824105214047165 | validation: 0.20684444245430397]
	TIME [epoch: 31.4 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24394158226337803		[learning rate: 0.00079762]
	Learning Rate: 0.000797618
	LOSS [training: 0.24394158226337803 | validation: 0.2028714100677909]
	TIME [epoch: 31.3 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2452150401621281		[learning rate: 0.0007948]
	Learning Rate: 0.000794797
	LOSS [training: 0.2452150401621281 | validation: 0.2100954059922755]
	TIME [epoch: 31.4 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24383008501981274		[learning rate: 0.00079199]
	Learning Rate: 0.000791987
	LOSS [training: 0.24383008501981274 | validation: 0.21006712369466046]
	TIME [epoch: 31.4 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2454400537038354		[learning rate: 0.00078919]
	Learning Rate: 0.000789186
	LOSS [training: 0.2454400537038354 | validation: 0.21176127802931063]
	TIME [epoch: 31.5 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24396990460535217		[learning rate: 0.0007864]
	Learning Rate: 0.000786396
	LOSS [training: 0.24396990460535217 | validation: 0.20450872681698434]
	TIME [epoch: 31.2 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24265492993091095		[learning rate: 0.00078361]
	Learning Rate: 0.000783615
	LOSS [training: 0.24265492993091095 | validation: 0.20727384205746996]
	TIME [epoch: 31.4 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24863551607019263		[learning rate: 0.00078084]
	Learning Rate: 0.000780844
	LOSS [training: 0.24863551607019263 | validation: 0.20724042380325763]
	TIME [epoch: 31.5 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24422006315777547		[learning rate: 0.00077808]
	Learning Rate: 0.000778082
	LOSS [training: 0.24422006315777547 | validation: 0.2053376729139696]
	TIME [epoch: 31.3 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24877467860282143		[learning rate: 0.00077533]
	Learning Rate: 0.000775331
	LOSS [training: 0.24877467860282143 | validation: 0.21193458889634603]
	TIME [epoch: 31.5 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24251122737618477		[learning rate: 0.00077259]
	Learning Rate: 0.000772589
	LOSS [training: 0.24251122737618477 | validation: 0.21092815160577297]
	TIME [epoch: 31.4 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2427862201611888		[learning rate: 0.00076986]
	Learning Rate: 0.000769857
	LOSS [training: 0.2427862201611888 | validation: 0.21399475513028737]
	TIME [epoch: 31.4 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24040550539605954		[learning rate: 0.00076714]
	Learning Rate: 0.000767135
	LOSS [training: 0.24040550539605954 | validation: 0.20429054220498158]
	TIME [epoch: 31.4 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24240458163642672		[learning rate: 0.00076442]
	Learning Rate: 0.000764422
	LOSS [training: 0.24240458163642672 | validation: 0.21039909435812523]
	TIME [epoch: 31.5 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24332398742056227		[learning rate: 0.00076172]
	Learning Rate: 0.000761719
	LOSS [training: 0.24332398742056227 | validation: 0.20883602347486246]
	TIME [epoch: 31.4 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24692347340636533		[learning rate: 0.00075903]
	Learning Rate: 0.000759026
	LOSS [training: 0.24692347340636533 | validation: 0.20935957122002297]
	TIME [epoch: 31.5 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24740483956388748		[learning rate: 0.00075634]
	Learning Rate: 0.000756342
	LOSS [training: 0.24740483956388748 | validation: 0.21017361982264196]
	TIME [epoch: 31.4 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24789124411532792		[learning rate: 0.00075367]
	Learning Rate: 0.000753667
	LOSS [training: 0.24789124411532792 | validation: 0.20563280528081637]
	TIME [epoch: 31.5 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24052175670037268		[learning rate: 0.000751]
	Learning Rate: 0.000751002
	LOSS [training: 0.24052175670037268 | validation: 0.2065664345224821]
	TIME [epoch: 31.4 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2417095834942026		[learning rate: 0.00074835]
	Learning Rate: 0.000748346
	LOSS [training: 0.2417095834942026 | validation: 0.20870778106861473]
	TIME [epoch: 31.5 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24809885461869094		[learning rate: 0.0007457]
	Learning Rate: 0.0007457
	LOSS [training: 0.24809885461869094 | validation: 0.20806774783931975]
	TIME [epoch: 31.3 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24313331530357654		[learning rate: 0.00074306]
	Learning Rate: 0.000743063
	LOSS [training: 0.24313331530357654 | validation: 0.21181967866033244]
	TIME [epoch: 31.5 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24241919819278557		[learning rate: 0.00074044]
	Learning Rate: 0.000740435
	LOSS [training: 0.24241919819278557 | validation: 0.20901947067055043]
	TIME [epoch: 31.3 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23905831612545458		[learning rate: 0.00073782]
	Learning Rate: 0.000737817
	LOSS [training: 0.23905831612545458 | validation: 0.20830000122818065]
	TIME [epoch: 31.4 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24537083872203314		[learning rate: 0.00073521]
	Learning Rate: 0.000735208
	LOSS [training: 0.24537083872203314 | validation: 0.2045372012391724]
	TIME [epoch: 31.2 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24051874289631217		[learning rate: 0.00073261]
	Learning Rate: 0.000732608
	LOSS [training: 0.24051874289631217 | validation: 0.20666532402098065]
	TIME [epoch: 31.6 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2448353682061698		[learning rate: 0.00073002]
	Learning Rate: 0.000730018
	LOSS [training: 0.2448353682061698 | validation: 0.21302433218215536]
	TIME [epoch: 31.2 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23976774501438688		[learning rate: 0.00072744]
	Learning Rate: 0.000727436
	LOSS [training: 0.23976774501438688 | validation: 0.2109020237745738]
	TIME [epoch: 31.5 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24497769007155332		[learning rate: 0.00072486]
	Learning Rate: 0.000724864
	LOSS [training: 0.24497769007155332 | validation: 0.20409060367540438]
	TIME [epoch: 31.2 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24308267595792243		[learning rate: 0.0007223]
	Learning Rate: 0.000722301
	LOSS [training: 0.24308267595792243 | validation: 0.20773823357689566]
	TIME [epoch: 31.5 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24488324021433674		[learning rate: 0.00071975]
	Learning Rate: 0.000719746
	LOSS [training: 0.24488324021433674 | validation: 0.20933103418413826]
	TIME [epoch: 31.4 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24714164737447844		[learning rate: 0.0007172]
	Learning Rate: 0.000717201
	LOSS [training: 0.24714164737447844 | validation: 0.21462736902149593]
	TIME [epoch: 31.4 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24631184530196015		[learning rate: 0.00071467]
	Learning Rate: 0.000714665
	LOSS [training: 0.24631184530196015 | validation: 0.20814358754921275]
	TIME [epoch: 31.5 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24112156287554085		[learning rate: 0.00071214]
	Learning Rate: 0.000712138
	LOSS [training: 0.24112156287554085 | validation: 0.20700587341403764]
	TIME [epoch: 31.5 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24728232045825418		[learning rate: 0.00070962]
	Learning Rate: 0.00070962
	LOSS [training: 0.24728232045825418 | validation: 0.2011999466955186]
	TIME [epoch: 31.4 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2453860227638908		[learning rate: 0.00070711]
	Learning Rate: 0.00070711
	LOSS [training: 0.2453860227638908 | validation: 0.20362216803618213]
	TIME [epoch: 31.6 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23953117356179335		[learning rate: 0.00070461]
	Learning Rate: 0.00070461
	LOSS [training: 0.23953117356179335 | validation: 0.20806999903865514]
	TIME [epoch: 31.5 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24496193842696987		[learning rate: 0.00070212]
	Learning Rate: 0.000702118
	LOSS [training: 0.24496193842696987 | validation: 0.2063754796431946]
	TIME [epoch: 31.5 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24204249244112452		[learning rate: 0.00069964]
	Learning Rate: 0.000699635
	LOSS [training: 0.24204249244112452 | validation: 0.20728628812352284]
	TIME [epoch: 31.6 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2424645750709583		[learning rate: 0.00069716]
	Learning Rate: 0.000697161
	LOSS [training: 0.2424645750709583 | validation: 0.20758179229343968]
	TIME [epoch: 31.7 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13_20240719_005001/states/model_facs_v3_dec1b_2dpca_v13_802.pth
Halted early. No improvement in validation loss for 200 epochs.
Finished training in 16576.865 seconds.
