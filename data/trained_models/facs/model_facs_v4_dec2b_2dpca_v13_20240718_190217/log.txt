Args:
Namespace(name='model_facs_v4_dec2b_2dpca_v13', outdir='out/model_training/model_facs_v4_dec2b_2dpca_v13', training_data='data/training_data/facs_v4/pca/dec2_fitonsubset/transition2_subset_ce_pn_m_pc12/training', validation_data='data/training_data/facs_v4/pca/dec2_fitonsubset/transition2_subset_ce_pn_m_pc12/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=10, batch_size=50, patience=200, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, quadratic_a=1.0, quadratic_b=1.0, ndims=2, nparams=2, nsigs=2, ncells=400, ncells_sample=400, model_do_sample=False, dt=0.005, dt_schedule='stepped', dt_schedule_bounds=[50, 500, 1000], dt_schedule_scales=[0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', kernel='multiscale', bw_range=[0.2, 0.5, 0.9, 1.1, 1.3, 1.5, 2.0], optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 4124235848

Training model...

Saving initial model state to: out/model_training/model_facs_v4_dec2b_2dpca_v13_20240718_190217/states/model_facs_v4_dec2b_2dpca_v13_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8536394604238613		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8536394604238613 | validation: 0.8577818438598097]
	TIME [epoch: 31.7 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13_20240718_190217/states/model_facs_v4_dec2b_2dpca_v13_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6897787932424873		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6897787932424873 | validation: 0.8492245928481996]
	TIME [epoch: 4.52 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13_20240718_190217/states/model_facs_v4_dec2b_2dpca_v13_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6090507034393527		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6090507034393527 | validation: 0.8295432266293413]
	TIME [epoch: 4.5 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13_20240718_190217/states/model_facs_v4_dec2b_2dpca_v13_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6520294364787796		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6520294364787796 | validation: 0.7748536603166992]
	TIME [epoch: 4.5 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13_20240718_190217/states/model_facs_v4_dec2b_2dpca_v13_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5552942068008127		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5552942068008127 | validation: 0.754956649136977]
	TIME [epoch: 4.5 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13_20240718_190217/states/model_facs_v4_dec2b_2dpca_v13_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43413379107215017		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.43413379107215017 | validation: 0.8036457088155906]
	TIME [epoch: 4.51 sec]
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4727650147647283		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4727650147647283 | validation: 0.5367731782150175]
	TIME [epoch: 4.52 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13_20240718_190217/states/model_facs_v4_dec2b_2dpca_v13_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3764516715950205		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3764516715950205 | validation: 0.6091172509364807]
	TIME [epoch: 4.51 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39153254972319046		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.39153254972319046 | validation: 0.5041694793495821]
	TIME [epoch: 4.5 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13_20240718_190217/states/model_facs_v4_dec2b_2dpca_v13_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30756940797419674		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.30756940797419674 | validation: 0.5119956551716153]
	TIME [epoch: 4.5 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2907772154341689		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2907772154341689 | validation: 0.48478376770723214]
	TIME [epoch: 4.49 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13_20240718_190217/states/model_facs_v4_dec2b_2dpca_v13_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33794142640109126		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.33794142640109126 | validation: 0.4720865948890233]
	TIME [epoch: 4.51 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13_20240718_190217/states/model_facs_v4_dec2b_2dpca_v13_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3211954709982375		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3211954709982375 | validation: 0.4859458449368351]
	TIME [epoch: 4.5 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30606615127093384		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.30606615127093384 | validation: 0.517264365914816]
	TIME [epoch: 4.52 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30548121511710036		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.30548121511710036 | validation: 0.44373118851757776]
	TIME [epoch: 4.5 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13_20240718_190217/states/model_facs_v4_dec2b_2dpca_v13_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28043778965910454		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.28043778965910454 | validation: 0.47913430593899187]
	TIME [epoch: 4.51 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28019010840834135		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.28019010840834135 | validation: 0.4174786749701679]
	TIME [epoch: 4.5 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13_20240718_190217/states/model_facs_v4_dec2b_2dpca_v13_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2639978053833418		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2639978053833418 | validation: 0.4818919941837495]
	TIME [epoch: 4.51 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2926401949298708		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2926401949298708 | validation: 0.5227025610890844]
	TIME [epoch: 4.51 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28032074180316113		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.28032074180316113 | validation: 0.49940418349917204]
	TIME [epoch: 4.5 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2903657746733034		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2903657746733034 | validation: 0.42391222053369476]
	TIME [epoch: 4.51 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25714957267579164		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.25714957267579164 | validation: 0.3837313677354396]
	TIME [epoch: 4.51 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13_20240718_190217/states/model_facs_v4_dec2b_2dpca_v13_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3103785501754778		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3103785501754778 | validation: 0.5891075115879223]
	TIME [epoch: 4.51 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30959216426746683		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.30959216426746683 | validation: 0.4737720228950012]
	TIME [epoch: 4.51 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29312869659662366		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.29312869659662366 | validation: 0.3972544731964958]
	TIME [epoch: 4.51 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2605251684189109		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2605251684189109 | validation: 0.5285967965707673]
	TIME [epoch: 4.51 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25531506466888043		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.25531506466888043 | validation: 0.4226560778221169]
	TIME [epoch: 4.51 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24364097576159993		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24364097576159993 | validation: 0.3840829899220558]
	TIME [epoch: 4.5 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23536883996117894		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23536883996117894 | validation: 0.42028582704751305]
	TIME [epoch: 4.52 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2356728566429027		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2356728566429027 | validation: 0.4024929560176205]
	TIME [epoch: 4.51 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2607373140099722		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2607373140099722 | validation: 0.37361688294187134]
	TIME [epoch: 4.5 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13_20240718_190217/states/model_facs_v4_dec2b_2dpca_v13_31.pth
	Model improved!!!
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23288040923857312		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23288040923857312 | validation: 0.4445177882875737]
	TIME [epoch: 4.51 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26738998840594386		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.26738998840594386 | validation: 0.47663290019175714]
	TIME [epoch: 4.51 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2821861926701466		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2821861926701466 | validation: 0.36757761568615765]
	TIME [epoch: 4.51 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13_20240718_190217/states/model_facs_v4_dec2b_2dpca_v13_34.pth
	Model improved!!!
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2166268961158932		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2166268961158932 | validation: 0.40398820803905916]
	TIME [epoch: 4.51 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20991442799010804		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20991442799010804 | validation: 0.40683722184664595]
	TIME [epoch: 4.51 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2973702593890539		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2973702593890539 | validation: 0.4553216036124741]
	TIME [epoch: 4.52 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22713851924997655		[learning rate: 0.0099882]
	Learning Rate: 0.0099882
	LOSS [training: 0.22713851924997655 | validation: 0.38668196383213493]
	TIME [epoch: 4.51 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20438739861248517		[learning rate: 0.0099411]
	Learning Rate: 0.00994113
	LOSS [training: 0.20438739861248517 | validation: 0.42388695989547853]
	TIME [epoch: 4.51 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2747897696708947		[learning rate: 0.0098943]
	Learning Rate: 0.00989429
	LOSS [training: 0.2747897696708947 | validation: 0.4463600842910067]
	TIME [epoch: 4.51 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2374978481901565		[learning rate: 0.0098477]
	Learning Rate: 0.00984767
	LOSS [training: 0.2374978481901565 | validation: 0.36271995804420626]
	TIME [epoch: 4.51 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13_20240718_190217/states/model_facs_v4_dec2b_2dpca_v13_41.pth
	Model improved!!!
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2155824288457045		[learning rate: 0.0098013]
	Learning Rate: 0.00980126
	LOSS [training: 0.2155824288457045 | validation: 0.3885811208351141]
	TIME [epoch: 4.51 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23434334619132546		[learning rate: 0.0097551]
	Learning Rate: 0.00975508
	LOSS [training: 0.23434334619132546 | validation: 0.4245235016253169]
	TIME [epoch: 4.51 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22077155981727037		[learning rate: 0.0097091]
	Learning Rate: 0.00970911
	LOSS [training: 0.22077155981727037 | validation: 0.40364458460882835]
	TIME [epoch: 4.51 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2141546586538071		[learning rate: 0.0096634]
	Learning Rate: 0.00966336
	LOSS [training: 0.2141546586538071 | validation: 0.36584615884999355]
	TIME [epoch: 4.52 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20375259188283146		[learning rate: 0.0096178]
	Learning Rate: 0.00961783
	LOSS [training: 0.20375259188283146 | validation: 0.43205688941237075]
	TIME [epoch: 4.51 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23304424128832069		[learning rate: 0.0095725]
	Learning Rate: 0.00957251
	LOSS [training: 0.23304424128832069 | validation: 0.3531812403796277]
	TIME [epoch: 4.5 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13_20240718_190217/states/model_facs_v4_dec2b_2dpca_v13_47.pth
	Model improved!!!
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21543437439064717		[learning rate: 0.0095274]
	Learning Rate: 0.0095274
	LOSS [training: 0.21543437439064717 | validation: 0.4213505868528291]
	TIME [epoch: 4.5 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23185503992585127		[learning rate: 0.0094825]
	Learning Rate: 0.0094825
	LOSS [training: 0.23185503992585127 | validation: 0.38703425213897114]
	TIME [epoch: 4.5 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22136421252113186		[learning rate: 0.0094378]
	Learning Rate: 0.00943782
	LOSS [training: 0.22136421252113186 | validation: 0.38160193906270073]
	TIME [epoch: 4.5 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22053441835369672		[learning rate: 0.0093933]
	Learning Rate: 0.00939335
	LOSS [training: 0.22053441835369672 | validation: 0.3962666082612727]
	TIME [epoch: 33.9 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2493226200980181		[learning rate: 0.0093491]
	Learning Rate: 0.00934909
	LOSS [training: 0.2493226200980181 | validation: 0.4158386549595542]
	TIME [epoch: 8.68 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18087833757390978		[learning rate: 0.009305]
	Learning Rate: 0.00930503
	LOSS [training: 0.18087833757390978 | validation: 0.3967742047933799]
	TIME [epoch: 8.7 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2100926633819089		[learning rate: 0.0092612]
	Learning Rate: 0.00926119
	LOSS [training: 0.2100926633819089 | validation: 0.4459711152200502]
	TIME [epoch: 8.7 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23805214780759362		[learning rate: 0.0092175]
	Learning Rate: 0.00921755
	LOSS [training: 0.23805214780759362 | validation: 0.3496483996294961]
	TIME [epoch: 8.69 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13_20240718_190217/states/model_facs_v4_dec2b_2dpca_v13_55.pth
	Model improved!!!
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20710165500229352		[learning rate: 0.0091741]
	Learning Rate: 0.00917411
	LOSS [training: 0.20710165500229352 | validation: 0.42335797907391837]
	TIME [epoch: 8.7 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22560077536064582		[learning rate: 0.0091309]
	Learning Rate: 0.00913088
	LOSS [training: 0.22560077536064582 | validation: 0.4030600349857048]
	TIME [epoch: 8.69 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20506865593708112		[learning rate: 0.0090879]
	Learning Rate: 0.00908786
	LOSS [training: 0.20506865593708112 | validation: 0.35641452961376263]
	TIME [epoch: 8.7 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21091503202814763		[learning rate: 0.009045]
	Learning Rate: 0.00904503
	LOSS [training: 0.21091503202814763 | validation: 0.39406719975867066]
	TIME [epoch: 8.69 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19048737467124516		[learning rate: 0.0090024]
	Learning Rate: 0.00900241
	LOSS [training: 0.19048737467124516 | validation: 0.4545306545175775]
	TIME [epoch: 8.69 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2304658404760306		[learning rate: 0.00896]
	Learning Rate: 0.00895999
	LOSS [training: 0.2304658404760306 | validation: 0.3870561098858818]
	TIME [epoch: 8.69 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2243463675026012		[learning rate: 0.0089178]
	Learning Rate: 0.00891777
	LOSS [training: 0.2243463675026012 | validation: 0.37007521840373586]
	TIME [epoch: 8.7 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24206776198615865		[learning rate: 0.0088758]
	Learning Rate: 0.00887575
	LOSS [training: 0.24206776198615865 | validation: 0.369662434117921]
	TIME [epoch: 8.7 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18816011588287604		[learning rate: 0.0088339]
	Learning Rate: 0.00883393
	LOSS [training: 0.18816011588287604 | validation: 0.3902852303826508]
	TIME [epoch: 8.69 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18669078896311292		[learning rate: 0.0087923]
	Learning Rate: 0.0087923
	LOSS [training: 0.18669078896311292 | validation: 0.42417093522105226]
	TIME [epoch: 8.69 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2508207378605236		[learning rate: 0.0087509]
	Learning Rate: 0.00875087
	LOSS [training: 0.2508207378605236 | validation: 0.4284930896804389]
	TIME [epoch: 8.71 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21034661875684332		[learning rate: 0.0087096]
	Learning Rate: 0.00870964
	LOSS [training: 0.21034661875684332 | validation: 0.39531254783709285]
	TIME [epoch: 8.7 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2215222371376463		[learning rate: 0.0086686]
	Learning Rate: 0.00866859
	LOSS [training: 0.2215222371376463 | validation: 0.35961338642232205]
	TIME [epoch: 8.68 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19154742287864088		[learning rate: 0.0086277]
	Learning Rate: 0.00862775
	LOSS [training: 0.19154742287864088 | validation: 0.36382596353194124]
	TIME [epoch: 8.69 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18130574800442598		[learning rate: 0.0085871]
	Learning Rate: 0.00858709
	LOSS [training: 0.18130574800442598 | validation: 0.31363180281763425]
	TIME [epoch: 8.71 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13_20240718_190217/states/model_facs_v4_dec2b_2dpca_v13_70.pth
	Model improved!!!
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17496362773978943		[learning rate: 0.0085466]
	Learning Rate: 0.00854663
	LOSS [training: 0.17496362773978943 | validation: 0.42038399431595386]
	TIME [epoch: 8.7 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23129501971478816		[learning rate: 0.0085064]
	Learning Rate: 0.00850636
	LOSS [training: 0.23129501971478816 | validation: 0.35650075018835525]
	TIME [epoch: 8.69 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23706366991178962		[learning rate: 0.0084663]
	Learning Rate: 0.00846627
	LOSS [training: 0.23706366991178962 | validation: 0.4225342437956007]
	TIME [epoch: 8.69 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19133810691775066		[learning rate: 0.0084264]
	Learning Rate: 0.00842638
	LOSS [training: 0.19133810691775066 | validation: 0.38608213690221654]
	TIME [epoch: 8.7 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2042592778307107		[learning rate: 0.0083867]
	Learning Rate: 0.00838667
	LOSS [training: 0.2042592778307107 | validation: 0.33194085249445765]
	TIME [epoch: 8.69 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22046325193136176		[learning rate: 0.0083472]
	Learning Rate: 0.00834715
	LOSS [training: 0.22046325193136176 | validation: 0.36961686006906874]
	TIME [epoch: 8.69 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15330427495648224		[learning rate: 0.0083078]
	Learning Rate: 0.00830782
	LOSS [training: 0.15330427495648224 | validation: 0.46303020627182173]
	TIME [epoch: 8.69 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20414223716416546		[learning rate: 0.0082687]
	Learning Rate: 0.00826867
	LOSS [training: 0.20414223716416546 | validation: 0.4234469609375531]
	TIME [epoch: 8.7 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28461337179699714		[learning rate: 0.0082297]
	Learning Rate: 0.00822971
	LOSS [training: 0.28461337179699714 | validation: 0.3717684525816098]
	TIME [epoch: 8.7 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16807046340207138		[learning rate: 0.0081909]
	Learning Rate: 0.00819093
	LOSS [training: 0.16807046340207138 | validation: 0.41497708844092346]
	TIME [epoch: 8.69 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18510892399435705		[learning rate: 0.0081523]
	Learning Rate: 0.00815233
	LOSS [training: 0.18510892399435705 | validation: 0.4980099548352995]
	TIME [epoch: 8.69 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20220509795610805		[learning rate: 0.0081139]
	Learning Rate: 0.00811392
	LOSS [training: 0.20220509795610805 | validation: 0.44000463729978073]
	TIME [epoch: 8.68 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1975843090550672		[learning rate: 0.0080757]
	Learning Rate: 0.00807569
	LOSS [training: 0.1975843090550672 | validation: 0.32764022888087885]
	TIME [epoch: 8.7 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1769189281350561		[learning rate: 0.0080376]
	Learning Rate: 0.00803763
	LOSS [training: 0.1769189281350561 | validation: 0.30632228595984534]
	TIME [epoch: 8.69 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13_20240718_190217/states/model_facs_v4_dec2b_2dpca_v13_84.pth
	Model improved!!!
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14880115580413172		[learning rate: 0.0079998]
	Learning Rate: 0.00799976
	LOSS [training: 0.14880115580413172 | validation: 0.5217529727338056]
	TIME [epoch: 8.7 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23775749739508661		[learning rate: 0.0079621]
	Learning Rate: 0.00796206
	LOSS [training: 0.23775749739508661 | validation: 0.3478134261558047]
	TIME [epoch: 8.7 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17360577846969416		[learning rate: 0.0079245]
	Learning Rate: 0.00792455
	LOSS [training: 0.17360577846969416 | validation: 0.38906311549760664]
	TIME [epoch: 8.71 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20909219765797588		[learning rate: 0.0078872]
	Learning Rate: 0.0078872
	LOSS [training: 0.20909219765797588 | validation: 0.45232895367137144]
	TIME [epoch: 8.69 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18749402102399415		[learning rate: 0.00785]
	Learning Rate: 0.00785004
	LOSS [training: 0.18749402102399415 | validation: 0.3238855752816011]
	TIME [epoch: 8.69 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17443742357744757		[learning rate: 0.007813]
	Learning Rate: 0.00781305
	LOSS [training: 0.17443742357744757 | validation: 0.37426729982130125]
	TIME [epoch: 8.69 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18174084578274563		[learning rate: 0.0077762]
	Learning Rate: 0.00777623
	LOSS [training: 0.18174084578274563 | validation: 0.37711985420969674]
	TIME [epoch: 8.7 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21599657021275923		[learning rate: 0.0077396]
	Learning Rate: 0.00773959
	LOSS [training: 0.21599657021275923 | validation: 0.33708459177507855]
	TIME [epoch: 8.69 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17988829376559484		[learning rate: 0.0077031]
	Learning Rate: 0.00770312
	LOSS [training: 0.17988829376559484 | validation: 0.34321459402960613]
	TIME [epoch: 8.69 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1691800729969912		[learning rate: 0.0076668]
	Learning Rate: 0.00766682
	LOSS [training: 0.1691800729969912 | validation: 0.43521726922458204]
	TIME [epoch: 8.69 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18689366323727735		[learning rate: 0.0076307]
	Learning Rate: 0.0076307
	LOSS [training: 0.18689366323727735 | validation: 0.3845852062808135]
	TIME [epoch: 8.7 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17200274818275843		[learning rate: 0.0075947]
	Learning Rate: 0.00759474
	LOSS [training: 0.17200274818275843 | validation: 0.31385069609428606]
	TIME [epoch: 8.69 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1665501540870617		[learning rate: 0.007559]
	Learning Rate: 0.00755895
	LOSS [training: 0.1665501540870617 | validation: 0.3748622331082131]
	TIME [epoch: 8.69 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17702181081795695		[learning rate: 0.0075233]
	Learning Rate: 0.00752333
	LOSS [training: 0.17702181081795695 | validation: 0.3315220300848852]
	TIME [epoch: 8.69 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1553186208197741		[learning rate: 0.0074879]
	Learning Rate: 0.00748788
	LOSS [training: 0.1553186208197741 | validation: 0.30309581761393817]
	TIME [epoch: 8.7 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13_20240718_190217/states/model_facs_v4_dec2b_2dpca_v13_99.pth
	Model improved!!!
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17612051829439795		[learning rate: 0.0074526]
	Learning Rate: 0.0074526
	LOSS [training: 0.17612051829439795 | validation: 0.3180614829422318]
	TIME [epoch: 8.7 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15908309438795057		[learning rate: 0.0074175]
	Learning Rate: 0.00741748
	LOSS [training: 0.15908309438795057 | validation: 0.39576645284739276]
	TIME [epoch: 8.7 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1830038121298608		[learning rate: 0.0073825]
	Learning Rate: 0.00738253
	LOSS [training: 0.1830038121298608 | validation: 0.3474140473623943]
	TIME [epoch: 8.69 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18702141717023335		[learning rate: 0.0073477]
	Learning Rate: 0.00734774
	LOSS [training: 0.18702141717023335 | validation: 0.3447132776790317]
	TIME [epoch: 8.7 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19944289933523213		[learning rate: 0.0073131]
	Learning Rate: 0.00731312
	LOSS [training: 0.19944289933523213 | validation: 0.3563567253239023]
	TIME [epoch: 8.69 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17591675169335289		[learning rate: 0.0072787]
	Learning Rate: 0.00727866
	LOSS [training: 0.17591675169335289 | validation: 0.30074125486129694]
	TIME [epoch: 8.69 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13_20240718_190217/states/model_facs_v4_dec2b_2dpca_v13_105.pth
	Model improved!!!
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14997139018681124		[learning rate: 0.0072444]
	Learning Rate: 0.00724436
	LOSS [training: 0.14997139018681124 | validation: 0.4574696120082793]
	TIME [epoch: 8.69 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17856860113000245		[learning rate: 0.0072102]
	Learning Rate: 0.00721022
	LOSS [training: 0.17856860113000245 | validation: 0.3321495595613493]
	TIME [epoch: 8.69 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1705848769605611		[learning rate: 0.0071762]
	Learning Rate: 0.00717625
	LOSS [training: 0.1705848769605611 | validation: 0.39248124375874094]
	TIME [epoch: 8.69 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20279832656876157		[learning rate: 0.0071424]
	Learning Rate: 0.00714243
	LOSS [training: 0.20279832656876157 | validation: 0.3887573467939656]
	TIME [epoch: 8.68 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1957833763194919		[learning rate: 0.0071088]
	Learning Rate: 0.00710878
	LOSS [training: 0.1957833763194919 | validation: 0.6090392242732561]
	TIME [epoch: 8.68 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23676240234434287		[learning rate: 0.0070753]
	Learning Rate: 0.00707528
	LOSS [training: 0.23676240234434287 | validation: 0.38067375786407764]
	TIME [epoch: 8.68 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17962232189370683		[learning rate: 0.0070419]
	Learning Rate: 0.00704194
	LOSS [training: 0.17962232189370683 | validation: 0.3608593869748451]
	TIME [epoch: 8.7 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16509878535819164		[learning rate: 0.0070088]
	Learning Rate: 0.00700876
	LOSS [training: 0.16509878535819164 | validation: 0.326003874200698]
	TIME [epoch: 8.68 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15703861795274207		[learning rate: 0.0069757]
	Learning Rate: 0.00697573
	LOSS [training: 0.15703861795274207 | validation: 0.3433439411132987]
	TIME [epoch: 8.68 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.167044698222448		[learning rate: 0.0069429]
	Learning Rate: 0.00694286
	LOSS [training: 0.167044698222448 | validation: 0.3203156949831479]
	TIME [epoch: 8.69 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1555267819496962		[learning rate: 0.0069101]
	Learning Rate: 0.00691014
	LOSS [training: 0.1555267819496962 | validation: 0.3049734019543938]
	TIME [epoch: 8.69 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1480210712396314		[learning rate: 0.0068776]
	Learning Rate: 0.00687758
	LOSS [training: 0.1480210712396314 | validation: 0.3654432353934149]
	TIME [epoch: 8.69 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18007394420189168		[learning rate: 0.0068452]
	Learning Rate: 0.00684518
	LOSS [training: 0.18007394420189168 | validation: 0.32605191022634333]
	TIME [epoch: 8.69 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15439211724471913		[learning rate: 0.0068129]
	Learning Rate: 0.00681292
	LOSS [training: 0.15439211724471913 | validation: 0.43005233683878485]
	TIME [epoch: 8.68 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1501272703136705		[learning rate: 0.0067808]
	Learning Rate: 0.00678082
	LOSS [training: 0.1501272703136705 | validation: 0.3141550336054084]
	TIME [epoch: 8.68 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16188495477534798		[learning rate: 0.0067489]
	Learning Rate: 0.00674887
	LOSS [training: 0.16188495477534798 | validation: 0.3663288809648794]
	TIME [epoch: 8.7 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1903499366741158		[learning rate: 0.0067171]
	Learning Rate: 0.00671706
	LOSS [training: 0.1903499366741158 | validation: 0.3106190663998194]
	TIME [epoch: 8.69 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15063614552241122		[learning rate: 0.0066854]
	Learning Rate: 0.00668541
	LOSS [training: 0.15063614552241122 | validation: 0.3039486103109714]
	TIME [epoch: 8.68 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18487996951477823		[learning rate: 0.0066539]
	Learning Rate: 0.00665391
	LOSS [training: 0.18487996951477823 | validation: 0.3698249012742927]
	TIME [epoch: 8.72 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.198195434759338		[learning rate: 0.0066226]
	Learning Rate: 0.00662256
	LOSS [training: 0.198195434759338 | validation: 0.32342051257058674]
	TIME [epoch: 8.7 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1495983380184327		[learning rate: 0.0065913]
	Learning Rate: 0.00659135
	LOSS [training: 0.1495983380184327 | validation: 0.33030892239947623]
	TIME [epoch: 8.69 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13404782506546406		[learning rate: 0.0065603]
	Learning Rate: 0.00656029
	LOSS [training: 0.13404782506546406 | validation: 0.36141511906953616]
	TIME [epoch: 8.69 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20427451095179816		[learning rate: 0.0065294]
	Learning Rate: 0.00652938
	LOSS [training: 0.20427451095179816 | validation: 0.35864043685946534]
	TIME [epoch: 8.69 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1901511912619994		[learning rate: 0.0064986]
	Learning Rate: 0.00649861
	LOSS [training: 0.1901511912619994 | validation: 0.3227034622824911]
	TIME [epoch: 8.69 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14885881013431515		[learning rate: 0.006468]
	Learning Rate: 0.00646799
	LOSS [training: 0.14885881013431515 | validation: 0.3529728755982973]
	TIME [epoch: 8.7 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1778641895873323		[learning rate: 0.0064375]
	Learning Rate: 0.00643751
	LOSS [training: 0.1778641895873323 | validation: 0.29948889357752084]
	TIME [epoch: 8.68 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13_20240718_190217/states/model_facs_v4_dec2b_2dpca_v13_131.pth
	Model improved!!!
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1456634109076948		[learning rate: 0.0064072]
	Learning Rate: 0.00640718
	LOSS [training: 0.1456634109076948 | validation: 0.319200177996407]
	TIME [epoch: 8.69 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1502258485525926		[learning rate: 0.006377]
	Learning Rate: 0.00637698
	LOSS [training: 0.1502258485525926 | validation: 0.33203933392689]
	TIME [epoch: 8.69 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12636424867960788		[learning rate: 0.0063469]
	Learning Rate: 0.00634694
	LOSS [training: 0.12636424867960788 | validation: 0.3737935452831134]
	TIME [epoch: 8.7 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17077130852846878		[learning rate: 0.006317]
	Learning Rate: 0.00631703
	LOSS [training: 0.17077130852846878 | validation: 0.34182711274646804]
	TIME [epoch: 8.7 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17400125710288855		[learning rate: 0.0062873]
	Learning Rate: 0.00628726
	LOSS [training: 0.17400125710288855 | validation: 0.3239154981328198]
	TIME [epoch: 8.69 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15981571771783426		[learning rate: 0.0062576]
	Learning Rate: 0.00625764
	LOSS [training: 0.15981571771783426 | validation: 0.3467940856925138]
	TIME [epoch: 8.69 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1690293885800368		[learning rate: 0.0062281]
	Learning Rate: 0.00622815
	LOSS [training: 0.1690293885800368 | validation: 0.33254140498237933]
	TIME [epoch: 8.7 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14402448841300095		[learning rate: 0.0061988]
	Learning Rate: 0.0061988
	LOSS [training: 0.14402448841300095 | validation: 0.31333589738269807]
	TIME [epoch: 8.7 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14263822692283937		[learning rate: 0.0061696]
	Learning Rate: 0.00616959
	LOSS [training: 0.14263822692283937 | validation: 0.3234953007243837]
	TIME [epoch: 8.69 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15646438487503364		[learning rate: 0.0061405]
	Learning Rate: 0.00614052
	LOSS [training: 0.15646438487503364 | validation: 0.4141487368241686]
	TIME [epoch: 8.69 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20588729499743563		[learning rate: 0.0061116]
	Learning Rate: 0.00611158
	LOSS [training: 0.20588729499743563 | validation: 0.4968750758690854]
	TIME [epoch: 8.69 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16191392253728454		[learning rate: 0.0060828]
	Learning Rate: 0.00608279
	LOSS [training: 0.16191392253728454 | validation: 0.3995846375610666]
	TIME [epoch: 8.7 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18548650246386547		[learning rate: 0.0060541]
	Learning Rate: 0.00605412
	LOSS [training: 0.18548650246386547 | validation: 0.3726047166187268]
	TIME [epoch: 8.68 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16095275538697407		[learning rate: 0.0060256]
	Learning Rate: 0.0060256
	LOSS [training: 0.16095275538697407 | validation: 0.33751001035484174]
	TIME [epoch: 8.68 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14134069430111212		[learning rate: 0.0059972]
	Learning Rate: 0.0059972
	LOSS [training: 0.14134069430111212 | validation: 0.30002947426431825]
	TIME [epoch: 8.69 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1554023943840415		[learning rate: 0.0059689]
	Learning Rate: 0.00596894
	LOSS [training: 0.1554023943840415 | validation: 0.32562769256142443]
	TIME [epoch: 8.7 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14247859142253974		[learning rate: 0.0059408]
	Learning Rate: 0.00594082
	LOSS [training: 0.14247859142253974 | validation: 0.32983809313384127]
	TIME [epoch: 8.7 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16351673171293987		[learning rate: 0.0059128]
	Learning Rate: 0.00591282
	LOSS [training: 0.16351673171293987 | validation: 0.3579591700409944]
	TIME [epoch: 8.7 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15004799182372464		[learning rate: 0.005885]
	Learning Rate: 0.00588496
	LOSS [training: 0.15004799182372464 | validation: 0.3091539831452535]
	TIME [epoch: 8.69 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14777416074091543		[learning rate: 0.0058572]
	Learning Rate: 0.00585723
	LOSS [training: 0.14777416074091543 | validation: 0.2855442083424632]
	TIME [epoch: 8.69 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13_20240718_190217/states/model_facs_v4_dec2b_2dpca_v13_151.pth
	Model improved!!!
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12819007889845851		[learning rate: 0.0058296]
	Learning Rate: 0.00582963
	LOSS [training: 0.12819007889845851 | validation: 0.333738085090175]
	TIME [epoch: 8.71 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14928087882011792		[learning rate: 0.0058022]
	Learning Rate: 0.00580216
	LOSS [training: 0.14928087882011792 | validation: 0.500168299525988]
	TIME [epoch: 8.69 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19633898639040132		[learning rate: 0.0057748]
	Learning Rate: 0.00577482
	LOSS [training: 0.19633898639040132 | validation: 0.35931808787879743]
	TIME [epoch: 8.69 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1758109339681951		[learning rate: 0.0057476]
	Learning Rate: 0.00574761
	LOSS [training: 0.1758109339681951 | validation: 0.34581943306327495]
	TIME [epoch: 8.69 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15994538328913138		[learning rate: 0.0057205]
	Learning Rate: 0.00572052
	LOSS [training: 0.15994538328913138 | validation: 0.3352388909365804]
	TIME [epoch: 8.7 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15451144974099001		[learning rate: 0.0056936]
	Learning Rate: 0.00569357
	LOSS [training: 0.15451144974099001 | validation: 0.42421428874612205]
	TIME [epoch: 8.69 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16345009104643415		[learning rate: 0.0056667]
	Learning Rate: 0.00566674
	LOSS [training: 0.16345009104643415 | validation: 0.32860901745855364]
	TIME [epoch: 8.69 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14168728951236798		[learning rate: 0.00564]
	Learning Rate: 0.00564004
	LOSS [training: 0.14168728951236798 | validation: 0.3754626679288308]
	TIME [epoch: 8.69 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1505850519668136		[learning rate: 0.0056135]
	Learning Rate: 0.00561346
	LOSS [training: 0.1505850519668136 | validation: 0.3277981746455759]
	TIME [epoch: 8.7 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15026986392410352		[learning rate: 0.005587]
	Learning Rate: 0.00558701
	LOSS [training: 0.15026986392410352 | validation: 0.3449883338150537]
	TIME [epoch: 8.7 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1405374952115419		[learning rate: 0.0055607]
	Learning Rate: 0.00556068
	LOSS [training: 0.1405374952115419 | validation: 0.38130489717543403]
	TIME [epoch: 8.69 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18085903316960195		[learning rate: 0.0055345]
	Learning Rate: 0.00553448
	LOSS [training: 0.18085903316960195 | validation: 0.3069099686382122]
	TIME [epoch: 8.69 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17717596468996		[learning rate: 0.0055084]
	Learning Rate: 0.0055084
	LOSS [training: 0.17717596468996 | validation: 0.34202493373099097]
	TIME [epoch: 8.69 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12357852836443445		[learning rate: 0.0054824]
	Learning Rate: 0.00548245
	LOSS [training: 0.12357852836443445 | validation: 0.29564093371607636]
	TIME [epoch: 8.7 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1359712820511571		[learning rate: 0.0054566]
	Learning Rate: 0.00545661
	LOSS [training: 0.1359712820511571 | validation: 0.3002672673079748]
	TIME [epoch: 8.69 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1750106160816895		[learning rate: 0.0054309]
	Learning Rate: 0.0054309
	LOSS [training: 0.1750106160816895 | validation: 0.40907241983522147]
	TIME [epoch: 8.69 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12525867023788131		[learning rate: 0.0054053]
	Learning Rate: 0.00540531
	LOSS [training: 0.12525867023788131 | validation: 0.35165086332447776]
	TIME [epoch: 8.69 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13566887321342785		[learning rate: 0.0053798]
	Learning Rate: 0.00537984
	LOSS [training: 0.13566887321342785 | validation: 0.4422966526558421]
	TIME [epoch: 8.69 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1845555786856904		[learning rate: 0.0053545]
	Learning Rate: 0.00535449
	LOSS [training: 0.1845555786856904 | validation: 0.33745405642450416]
	TIME [epoch: 8.7 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13844812578507187		[learning rate: 0.0053293]
	Learning Rate: 0.00532926
	LOSS [training: 0.13844812578507187 | validation: 0.302943405755743]
	TIME [epoch: 8.69 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13799260184570683		[learning rate: 0.0053041]
	Learning Rate: 0.00530415
	LOSS [training: 0.13799260184570683 | validation: 0.30810067414236075]
	TIME [epoch: 8.69 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14182504494726783		[learning rate: 0.0052792]
	Learning Rate: 0.00527915
	LOSS [training: 0.14182504494726783 | validation: 0.3487968104977718]
	TIME [epoch: 8.69 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14300660977584442		[learning rate: 0.0052543]
	Learning Rate: 0.00525428
	LOSS [training: 0.14300660977584442 | validation: 0.34564598117381407]
	TIME [epoch: 8.7 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14397243134306234		[learning rate: 0.0052295]
	Learning Rate: 0.00522952
	LOSS [training: 0.14397243134306234 | validation: 0.3541858501558785]
	TIME [epoch: 8.69 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17290522857464724		[learning rate: 0.0052049]
	Learning Rate: 0.00520487
	LOSS [training: 0.17290522857464724 | validation: 0.37531847207577596]
	TIME [epoch: 8.69 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15436257520176205		[learning rate: 0.0051803]
	Learning Rate: 0.00518035
	LOSS [training: 0.15436257520176205 | validation: 0.5754067049337895]
	TIME [epoch: 8.69 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14323367157982053		[learning rate: 0.0051559]
	Learning Rate: 0.00515594
	LOSS [training: 0.14323367157982053 | validation: 0.31853774260517675]
	TIME [epoch: 8.7 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14434630065735413		[learning rate: 0.0051316]
	Learning Rate: 0.00513164
	LOSS [training: 0.14434630065735413 | validation: 0.33432340293593]
	TIME [epoch: 8.69 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13700839041394292		[learning rate: 0.0051075]
	Learning Rate: 0.00510746
	LOSS [training: 0.13700839041394292 | validation: 0.3021524613684724]
	TIME [epoch: 8.69 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1508656517957715		[learning rate: 0.0050834]
	Learning Rate: 0.00508339
	LOSS [training: 0.1508656517957715 | validation: 0.4021770143647898]
	TIME [epoch: 8.69 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1432095111012302		[learning rate: 0.0050594]
	Learning Rate: 0.00505944
	LOSS [training: 0.1432095111012302 | validation: 0.4765627229961372]
	TIME [epoch: 8.7 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16883928849389115		[learning rate: 0.0050356]
	Learning Rate: 0.0050356
	LOSS [training: 0.16883928849389115 | validation: 0.3276562540908653]
	TIME [epoch: 8.7 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14411498567370246		[learning rate: 0.0050119]
	Learning Rate: 0.00501187
	LOSS [training: 0.14411498567370246 | validation: 0.301509248071907]
	TIME [epoch: 8.7 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1572038002459478		[learning rate: 0.0049883]
	Learning Rate: 0.00498826
	LOSS [training: 0.1572038002459478 | validation: 0.356662957227853]
	TIME [epoch: 8.69 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14465944854502083		[learning rate: 0.0049648]
	Learning Rate: 0.00496475
	LOSS [training: 0.14465944854502083 | validation: 0.3241757735936312]
	TIME [epoch: 8.69 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14428746170008594		[learning rate: 0.0049414]
	Learning Rate: 0.00494136
	LOSS [training: 0.14428746170008594 | validation: 0.2952368242044311]
	TIME [epoch: 8.7 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14998900158988313		[learning rate: 0.0049181]
	Learning Rate: 0.00491807
	LOSS [training: 0.14998900158988313 | validation: 0.33371620171511557]
	TIME [epoch: 8.69 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1314152192303796		[learning rate: 0.0048949]
	Learning Rate: 0.0048949
	LOSS [training: 0.1314152192303796 | validation: 0.3335555961062418]
	TIME [epoch: 8.69 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1561310660444107		[learning rate: 0.0048718]
	Learning Rate: 0.00487183
	LOSS [training: 0.1561310660444107 | validation: 0.3268479084314077]
	TIME [epoch: 8.69 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15153276578068298		[learning rate: 0.0048489]
	Learning Rate: 0.00484888
	LOSS [training: 0.15153276578068298 | validation: 0.32378926775281525]
	TIME [epoch: 8.69 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13491564182649035		[learning rate: 0.004826]
	Learning Rate: 0.00482603
	LOSS [training: 0.13491564182649035 | validation: 0.34478023746344055]
	TIME [epoch: 8.69 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13856308547964963		[learning rate: 0.0048033]
	Learning Rate: 0.00480329
	LOSS [training: 0.13856308547964963 | validation: 0.4191759737318709]
	TIME [epoch: 8.69 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13716011883619275		[learning rate: 0.0047807]
	Learning Rate: 0.00478065
	LOSS [training: 0.13716011883619275 | validation: 0.34760706163799543]
	TIME [epoch: 8.68 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14323569709367617		[learning rate: 0.0047581]
	Learning Rate: 0.00475813
	LOSS [training: 0.14323569709367617 | validation: 0.2758097899751242]
	TIME [epoch: 8.69 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13_20240718_190217/states/model_facs_v4_dec2b_2dpca_v13_195.pth
	Model improved!!!
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13814592008862062		[learning rate: 0.0047357]
	Learning Rate: 0.0047357
	LOSS [training: 0.13814592008862062 | validation: 0.36518834762914604]
	TIME [epoch: 8.68 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14841561560119504		[learning rate: 0.0047134]
	Learning Rate: 0.00471339
	LOSS [training: 0.14841561560119504 | validation: 0.3243913195097923]
	TIME [epoch: 8.66 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13233872768776284		[learning rate: 0.0046912]
	Learning Rate: 0.00469118
	LOSS [training: 0.13233872768776284 | validation: 0.3585942113172537]
	TIME [epoch: 8.66 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12005310147759883		[learning rate: 0.0046691]
	Learning Rate: 0.00466907
	LOSS [training: 0.12005310147759883 | validation: 0.3405230700867827]
	TIME [epoch: 8.66 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14410898988031692		[learning rate: 0.0046471]
	Learning Rate: 0.00464707
	LOSS [training: 0.14410898988031692 | validation: 0.33818446186389733]
	TIME [epoch: 8.7 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12647859950088575		[learning rate: 0.0046252]
	Learning Rate: 0.00462518
	LOSS [training: 0.12647859950088575 | validation: 0.32079107393512224]
	TIME [epoch: 8.68 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13671831262863948		[learning rate: 0.0046034]
	Learning Rate: 0.00460338
	LOSS [training: 0.13671831262863948 | validation: 0.3063473680701525]
	TIME [epoch: 8.67 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11619522146272435		[learning rate: 0.0045817]
	Learning Rate: 0.00458169
	LOSS [training: 0.11619522146272435 | validation: 0.3443118857399131]
	TIME [epoch: 8.67 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13124583357790073		[learning rate: 0.0045601]
	Learning Rate: 0.0045601
	LOSS [training: 0.13124583357790073 | validation: 0.3589598791732659]
	TIME [epoch: 8.67 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14985344026851563		[learning rate: 0.0045386]
	Learning Rate: 0.00453861
	LOSS [training: 0.14985344026851563 | validation: 0.39853878998574555]
	TIME [epoch: 8.67 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1390913689303576		[learning rate: 0.0045172]
	Learning Rate: 0.00451723
	LOSS [training: 0.1390913689303576 | validation: 0.32592642595195975]
	TIME [epoch: 8.67 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12015576198912237		[learning rate: 0.0044959]
	Learning Rate: 0.00449594
	LOSS [training: 0.12015576198912237 | validation: 0.3416563234219498]
	TIME [epoch: 8.67 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14486793987538252		[learning rate: 0.0044748]
	Learning Rate: 0.00447475
	LOSS [training: 0.14486793987538252 | validation: 0.3333116753063595]
	TIME [epoch: 8.67 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15110188330820484		[learning rate: 0.0044537]
	Learning Rate: 0.00445367
	LOSS [training: 0.15110188330820484 | validation: 0.3352791180735075]
	TIME [epoch: 8.68 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12793844661731996		[learning rate: 0.0044327]
	Learning Rate: 0.00443268
	LOSS [training: 0.12793844661731996 | validation: 0.3003823970045432]
	TIME [epoch: 8.67 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14652785235551105		[learning rate: 0.0044118]
	Learning Rate: 0.0044118
	LOSS [training: 0.14652785235551105 | validation: 0.3550889627686786]
	TIME [epoch: 8.66 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18018419413184775		[learning rate: 0.004391]
	Learning Rate: 0.00439101
	LOSS [training: 0.18018419413184775 | validation: 0.3250044255090442]
	TIME [epoch: 8.66 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.150456622242811		[learning rate: 0.0043703]
	Learning Rate: 0.00437032
	LOSS [training: 0.150456622242811 | validation: 0.4317363840937283]
	TIME [epoch: 8.67 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15726191486670965		[learning rate: 0.0043497]
	Learning Rate: 0.00434972
	LOSS [training: 0.15726191486670965 | validation: 0.3026443463172731]
	TIME [epoch: 8.68 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1433407220938718		[learning rate: 0.0043292]
	Learning Rate: 0.00432923
	LOSS [training: 0.1433407220938718 | validation: 0.36696336100636046]
	TIME [epoch: 8.67 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1410378044446274		[learning rate: 0.0043088]
	Learning Rate: 0.00430883
	LOSS [training: 0.1410378044446274 | validation: 0.32527645843184594]
	TIME [epoch: 8.66 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11818826522861504		[learning rate: 0.0042885]
	Learning Rate: 0.00428852
	LOSS [training: 0.11818826522861504 | validation: 0.32415119573882034]
	TIME [epoch: 8.66 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13886091064771838		[learning rate: 0.0042683]
	Learning Rate: 0.00426831
	LOSS [training: 0.13886091064771838 | validation: 0.40809492144644266]
	TIME [epoch: 8.67 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12624196465631088		[learning rate: 0.0042482]
	Learning Rate: 0.0042482
	LOSS [training: 0.12624196465631088 | validation: 0.35210690840193215]
	TIME [epoch: 8.66 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20546646575038918		[learning rate: 0.0042282]
	Learning Rate: 0.00422818
	LOSS [training: 0.20546646575038918 | validation: 0.35213857319358133]
	TIME [epoch: 8.67 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1459087834312889		[learning rate: 0.0042083]
	Learning Rate: 0.00420826
	LOSS [training: 0.1459087834312889 | validation: 0.2839949024632199]
	TIME [epoch: 8.66 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1494880184968541		[learning rate: 0.0041884]
	Learning Rate: 0.00418843
	LOSS [training: 0.1494880184968541 | validation: 0.32797685447698777]
	TIME [epoch: 8.67 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14175477886728222		[learning rate: 0.0041687]
	Learning Rate: 0.00416869
	LOSS [training: 0.14175477886728222 | validation: 0.3531784193374355]
	TIME [epoch: 8.68 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1253829982328735		[learning rate: 0.0041491]
	Learning Rate: 0.00414905
	LOSS [training: 0.1253829982328735 | validation: 0.31554202668714615]
	TIME [epoch: 8.66 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12319714954975046		[learning rate: 0.0041295]
	Learning Rate: 0.0041295
	LOSS [training: 0.12319714954975046 | validation: 0.3344494030146711]
	TIME [epoch: 8.66 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12765373179183798		[learning rate: 0.00411]
	Learning Rate: 0.00411004
	LOSS [training: 0.12765373179183798 | validation: 0.2820404350602543]
	TIME [epoch: 8.66 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12542019952145778		[learning rate: 0.0040907]
	Learning Rate: 0.00409067
	LOSS [training: 0.12542019952145778 | validation: 0.3585515105468993]
	TIME [epoch: 8.68 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15183632671934855		[learning rate: 0.0040714]
	Learning Rate: 0.0040714
	LOSS [training: 0.15183632671934855 | validation: 0.3172194489943777]
	TIME [epoch: 8.67 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.132522456714453		[learning rate: 0.0040522]
	Learning Rate: 0.00405221
	LOSS [training: 0.132522456714453 | validation: 0.3440328197553277]
	TIME [epoch: 8.67 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13439070235239073		[learning rate: 0.0040331]
	Learning Rate: 0.00403312
	LOSS [training: 0.13439070235239073 | validation: 0.315368591239101]
	TIME [epoch: 8.67 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12962609164055305		[learning rate: 0.0040141]
	Learning Rate: 0.00401411
	LOSS [training: 0.12962609164055305 | validation: 0.41378703016804064]
	TIME [epoch: 8.67 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14883695837367572		[learning rate: 0.0039952]
	Learning Rate: 0.0039952
	LOSS [training: 0.14883695837367572 | validation: 0.34641156840018233]
	TIME [epoch: 8.67 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1206146591697461		[learning rate: 0.0039764]
	Learning Rate: 0.00397637
	LOSS [training: 0.1206146591697461 | validation: 0.3580302788719678]
	TIME [epoch: 8.67 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14176506469245737		[learning rate: 0.0039576]
	Learning Rate: 0.00395764
	LOSS [training: 0.14176506469245737 | validation: 0.2891414064390136]
	TIME [epoch: 11.2 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1169887960109735		[learning rate: 0.003939]
	Learning Rate: 0.00393899
	LOSS [training: 0.1169887960109735 | validation: 0.270123422205528]
	TIME [epoch: 8.7 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13_20240718_190217/states/model_facs_v4_dec2b_2dpca_v13_235.pth
	Model improved!!!
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12427902984407685		[learning rate: 0.0039204]
	Learning Rate: 0.00392043
	LOSS [training: 0.12427902984407685 | validation: 0.3548241000701005]
	TIME [epoch: 8.7 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12869965384736584		[learning rate: 0.003902]
	Learning Rate: 0.00390195
	LOSS [training: 0.12869965384736584 | validation: 0.3492173510301558]
	TIME [epoch: 8.68 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14438691759459787		[learning rate: 0.0038836]
	Learning Rate: 0.00388357
	LOSS [training: 0.14438691759459787 | validation: 0.29072641840797203]
	TIME [epoch: 8.68 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12585026845412875		[learning rate: 0.0038653]
	Learning Rate: 0.00386527
	LOSS [training: 0.12585026845412875 | validation: 0.33288324816590065]
	TIME [epoch: 8.69 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12855574490767474		[learning rate: 0.0038471]
	Learning Rate: 0.00384705
	LOSS [training: 0.12855574490767474 | validation: 0.3329480149500192]
	TIME [epoch: 8.69 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12877090526441737		[learning rate: 0.0038289]
	Learning Rate: 0.00382893
	LOSS [training: 0.12877090526441737 | validation: 0.31864528716223084]
	TIME [epoch: 8.69 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1279810829476032		[learning rate: 0.0038109]
	Learning Rate: 0.00381088
	LOSS [training: 0.1279810829476032 | validation: 0.3546365275184208]
	TIME [epoch: 8.68 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11829048834441705		[learning rate: 0.0037929]
	Learning Rate: 0.00379293
	LOSS [training: 0.11829048834441705 | validation: 0.3723080371643422]
	TIME [epoch: 8.68 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13049822744043668		[learning rate: 0.0037751]
	Learning Rate: 0.00377505
	LOSS [training: 0.13049822744043668 | validation: 0.2954388875192323]
	TIME [epoch: 8.69 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1325890630340245		[learning rate: 0.0037573]
	Learning Rate: 0.00375726
	LOSS [training: 0.1325890630340245 | validation: 0.38245101636358125]
	TIME [epoch: 8.69 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13649865669296968		[learning rate: 0.0037396]
	Learning Rate: 0.00373956
	LOSS [training: 0.13649865669296968 | validation: 0.4514776898678138]
	TIME [epoch: 8.68 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1489516658601479		[learning rate: 0.0037219]
	Learning Rate: 0.00372194
	LOSS [training: 0.1489516658601479 | validation: 0.32119561124981755]
	TIME [epoch: 8.68 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12328419536931284		[learning rate: 0.0037044]
	Learning Rate: 0.0037044
	LOSS [training: 0.12328419536931284 | validation: 0.3214147653528372]
	TIME [epoch: 8.69 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12276664180221952		[learning rate: 0.0036869]
	Learning Rate: 0.00368695
	LOSS [training: 0.12276664180221952 | validation: 0.35722879656198114]
	TIME [epoch: 8.69 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27045712641558756		[learning rate: 0.0036696]
	Learning Rate: 0.00366957
	LOSS [training: 0.27045712641558756 | validation: 0.43382243546145594]
	TIME [epoch: 8.68 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22361797585011534		[learning rate: 0.0036523]
	Learning Rate: 0.00365228
	LOSS [training: 0.22361797585011534 | validation: 0.4051254031430546]
	TIME [epoch: 8.69 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16654893501009194		[learning rate: 0.0036351]
	Learning Rate: 0.00363507
	LOSS [training: 0.16654893501009194 | validation: 0.32395530449481363]
	TIME [epoch: 8.68 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13931834222864198		[learning rate: 0.0036179]
	Learning Rate: 0.00361794
	LOSS [training: 0.13931834222864198 | validation: 0.359976417895802]
	TIME [epoch: 8.7 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13934359505503197		[learning rate: 0.0036009]
	Learning Rate: 0.00360089
	LOSS [training: 0.13934359505503197 | validation: 0.3442221194282512]
	TIME [epoch: 8.69 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14132299367536746		[learning rate: 0.0035839]
	Learning Rate: 0.00358393
	LOSS [training: 0.14132299367536746 | validation: 0.32838699971667373]
	TIME [epoch: 8.69 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13919492591952554		[learning rate: 0.003567]
	Learning Rate: 0.00356704
	LOSS [training: 0.13919492591952554 | validation: 0.3389153722836476]
	TIME [epoch: 8.69 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13237848723535192		[learning rate: 0.0035502]
	Learning Rate: 0.00355023
	LOSS [training: 0.13237848723535192 | validation: 0.3207112853161248]
	TIME [epoch: 8.69 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.127244933639473		[learning rate: 0.0035335]
	Learning Rate: 0.0035335
	LOSS [training: 0.127244933639473 | validation: 0.31453108355476517]
	TIME [epoch: 8.69 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1491121383898834		[learning rate: 0.0035168]
	Learning Rate: 0.00351685
	LOSS [training: 0.1491121383898834 | validation: 0.3611409656054536]
	TIME [epoch: 8.69 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13681314438038608		[learning rate: 0.0035003]
	Learning Rate: 0.00350028
	LOSS [training: 0.13681314438038608 | validation: 0.3140667697605595]
	TIME [epoch: 8.68 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12225452020443496		[learning rate: 0.0034838]
	Learning Rate: 0.00348378
	LOSS [training: 0.12225452020443496 | validation: 0.3908049001929592]
	TIME [epoch: 8.69 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14746354848542748		[learning rate: 0.0034674]
	Learning Rate: 0.00346737
	LOSS [training: 0.14746354848542748 | validation: 0.33379378358584066]
	TIME [epoch: 8.68 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15160009824645937		[learning rate: 0.003451]
	Learning Rate: 0.00345103
	LOSS [training: 0.15160009824645937 | validation: 0.3118275453891005]
	TIME [epoch: 8.68 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14265151382903754		[learning rate: 0.0034348]
	Learning Rate: 0.00343477
	LOSS [training: 0.14265151382903754 | validation: 0.38260576984013883]
	TIME [epoch: 8.68 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13532513557668835		[learning rate: 0.0034186]
	Learning Rate: 0.00341858
	LOSS [training: 0.13532513557668835 | validation: 0.3117603313450803]
	TIME [epoch: 8.69 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13559993463982234		[learning rate: 0.0034025]
	Learning Rate: 0.00340247
	LOSS [training: 0.13559993463982234 | validation: 0.3305834859586753]
	TIME [epoch: 8.69 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12408207601463946		[learning rate: 0.0033864]
	Learning Rate: 0.00338644
	LOSS [training: 0.12408207601463946 | validation: 0.3658213517031634]
	TIME [epoch: 8.68 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13912812433558072		[learning rate: 0.0033705]
	Learning Rate: 0.00337048
	LOSS [training: 0.13912812433558072 | validation: 0.2882108859148992]
	TIME [epoch: 8.68 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12764065700981247		[learning rate: 0.0033546]
	Learning Rate: 0.0033546
	LOSS [training: 0.12764065700981247 | validation: 0.27632419493089905]
	TIME [epoch: 8.69 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1230786074332279		[learning rate: 0.0033388]
	Learning Rate: 0.00333879
	LOSS [training: 0.1230786074332279 | validation: 0.39301753362585873]
	TIME [epoch: 8.69 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1339707962771604		[learning rate: 0.0033231]
	Learning Rate: 0.00332306
	LOSS [training: 0.1339707962771604 | validation: 0.410834051855532]
	TIME [epoch: 8.69 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13511215060871917		[learning rate: 0.0033074]
	Learning Rate: 0.0033074
	LOSS [training: 0.13511215060871917 | validation: 0.3533747389235689]
	TIME [epoch: 8.69 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1387998432963251		[learning rate: 0.0032918]
	Learning Rate: 0.00329182
	LOSS [training: 0.1387998432963251 | validation: 0.2951042175525887]
	TIME [epoch: 8.69 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13174504118143399		[learning rate: 0.0032763]
	Learning Rate: 0.00327631
	LOSS [training: 0.13174504118143399 | validation: 0.2910250879716706]
	TIME [epoch: 8.69 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12800147492326228		[learning rate: 0.0032609]
	Learning Rate: 0.00326087
	LOSS [training: 0.12800147492326228 | validation: 0.28845000624618194]
	TIME [epoch: 8.69 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11920510934276873		[learning rate: 0.0032455]
	Learning Rate: 0.0032455
	LOSS [training: 0.11920510934276873 | validation: 0.29897177003112047]
	TIME [epoch: 8.69 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12157955381595825		[learning rate: 0.0032302]
	Learning Rate: 0.00323021
	LOSS [training: 0.12157955381595825 | validation: 0.40945337870958853]
	TIME [epoch: 8.67 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14262229404883525		[learning rate: 0.003215]
	Learning Rate: 0.00321499
	LOSS [training: 0.14262229404883525 | validation: 0.3139253216755354]
	TIME [epoch: 8.68 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12213916456920794		[learning rate: 0.0031998]
	Learning Rate: 0.00319984
	LOSS [training: 0.12213916456920794 | validation: 0.2940291017031723]
	TIME [epoch: 8.67 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12488806069702957		[learning rate: 0.0031848]
	Learning Rate: 0.00318476
	LOSS [training: 0.12488806069702957 | validation: 0.27312205616122914]
	TIME [epoch: 8.67 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12265772955160129		[learning rate: 0.0031698]
	Learning Rate: 0.00316975
	LOSS [training: 0.12265772955160129 | validation: 0.35613439850687595]
	TIME [epoch: 8.69 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11947896314252776		[learning rate: 0.0031548]
	Learning Rate: 0.00315482
	LOSS [training: 0.11947896314252776 | validation: 0.2762798201384375]
	TIME [epoch: 8.68 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12854167113328702		[learning rate: 0.00314]
	Learning Rate: 0.00313995
	LOSS [training: 0.12854167113328702 | validation: 0.3099165749720688]
	TIME [epoch: 8.69 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11864737009797478		[learning rate: 0.0031252]
	Learning Rate: 0.00312516
	LOSS [training: 0.11864737009797478 | validation: 0.2762294926757336]
	TIME [epoch: 8.68 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12515244871937128		[learning rate: 0.0031104]
	Learning Rate: 0.00311043
	LOSS [training: 0.12515244871937128 | validation: 0.2994941492953643]
	TIME [epoch: 8.69 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12171299444155582		[learning rate: 0.0030958]
	Learning Rate: 0.00309577
	LOSS [training: 0.12171299444155582 | validation: 0.33285263665610587]
	TIME [epoch: 8.7 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1137859594880302		[learning rate: 0.0030812]
	Learning Rate: 0.00308119
	LOSS [training: 0.1137859594880302 | validation: 0.3110606580106695]
	TIME [epoch: 8.68 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12190737952835483		[learning rate: 0.0030667]
	Learning Rate: 0.00306667
	LOSS [training: 0.12190737952835483 | validation: 0.2932016820700888]
	TIME [epoch: 8.69 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10685748740596597		[learning rate: 0.0030522]
	Learning Rate: 0.00305222
	LOSS [training: 0.10685748740596597 | validation: 0.3493345901302541]
	TIME [epoch: 8.7 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12189542183658586		[learning rate: 0.0030378]
	Learning Rate: 0.00303783
	LOSS [training: 0.12189542183658586 | validation: 0.35308083695154835]
	TIME [epoch: 8.69 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12699013476925558		[learning rate: 0.0030235]
	Learning Rate: 0.00302352
	LOSS [training: 0.12699013476925558 | validation: 0.3635712120751522]
	TIME [epoch: 8.7 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13026455793445627		[learning rate: 0.0030093]
	Learning Rate: 0.00300927
	LOSS [training: 0.13026455793445627 | validation: 0.2990552367154288]
	TIME [epoch: 8.69 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12685944848837052		[learning rate: 0.0029951]
	Learning Rate: 0.00299509
	LOSS [training: 0.12685944848837052 | validation: 0.3765278157949292]
	TIME [epoch: 8.69 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14436215641493336		[learning rate: 0.002981]
	Learning Rate: 0.00298098
	LOSS [training: 0.14436215641493336 | validation: 0.34817521925401074]
	TIME [epoch: 8.69 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13514610082753403		[learning rate: 0.0029669]
	Learning Rate: 0.00296693
	LOSS [training: 0.13514610082753403 | validation: 0.31461644215136964]
	TIME [epoch: 8.7 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11678427969452976		[learning rate: 0.002953]
	Learning Rate: 0.00295295
	LOSS [training: 0.11678427969452976 | validation: 0.31153191924153995]
	TIME [epoch: 8.68 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12014776136201549		[learning rate: 0.002939]
	Learning Rate: 0.00293904
	LOSS [training: 0.12014776136201549 | validation: 0.31987927712603487]
	TIME [epoch: 8.69 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14544237239209826		[learning rate: 0.0029252]
	Learning Rate: 0.00292519
	LOSS [training: 0.14544237239209826 | validation: 0.33221484250540645]
	TIME [epoch: 8.67 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12800207608532194		[learning rate: 0.0029114]
	Learning Rate: 0.0029114
	LOSS [training: 0.12800207608532194 | validation: 0.4339742876481142]
	TIME [epoch: 8.7 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13237139610813506		[learning rate: 0.0028977]
	Learning Rate: 0.00289769
	LOSS [training: 0.13237139610813506 | validation: 0.3339592836172782]
	TIME [epoch: 8.67 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11242959710589391		[learning rate: 0.002884]
	Learning Rate: 0.00288403
	LOSS [training: 0.11242959710589391 | validation: 0.30819767674495024]
	TIME [epoch: 8.69 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11563682353247628		[learning rate: 0.0028704]
	Learning Rate: 0.00287044
	LOSS [training: 0.11563682353247628 | validation: 0.29334150862090397]
	TIME [epoch: 8.69 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1342682187351048		[learning rate: 0.0028569]
	Learning Rate: 0.00285692
	LOSS [training: 0.1342682187351048 | validation: 0.31047467255597855]
	TIME [epoch: 8.68 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11783338252265048		[learning rate: 0.0028435]
	Learning Rate: 0.00284345
	LOSS [training: 0.11783338252265048 | validation: 0.2930410537834088]
	TIME [epoch: 8.7 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12285917941801794		[learning rate: 0.0028301]
	Learning Rate: 0.00283005
	LOSS [training: 0.12285917941801794 | validation: 0.3347759033522194]
	TIME [epoch: 8.69 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12249097154016889		[learning rate: 0.0028167]
	Learning Rate: 0.00281672
	LOSS [training: 0.12249097154016889 | validation: 0.3347616037984789]
	TIME [epoch: 8.69 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1152686733057037		[learning rate: 0.0028034]
	Learning Rate: 0.00280345
	LOSS [training: 0.1152686733057037 | validation: 0.38332488001762743]
	TIME [epoch: 8.7 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12239914102508806		[learning rate: 0.0027902]
	Learning Rate: 0.00279024
	LOSS [training: 0.12239914102508806 | validation: 0.28894969409619736]
	TIME [epoch: 8.68 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1230453946608859		[learning rate: 0.0027771]
	Learning Rate: 0.00277709
	LOSS [training: 0.1230453946608859 | validation: 0.2946658499498737]
	TIME [epoch: 8.68 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11825178839339234		[learning rate: 0.002764]
	Learning Rate: 0.002764
	LOSS [training: 0.11825178839339234 | validation: 0.3319968797002945]
	TIME [epoch: 8.68 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11422603235852206		[learning rate: 0.002751]
	Learning Rate: 0.00275098
	LOSS [training: 0.11422603235852206 | validation: 0.3357400317190799]
	TIME [epoch: 8.67 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11991397300311188		[learning rate: 0.002738]
	Learning Rate: 0.00273802
	LOSS [training: 0.11991397300311188 | validation: 0.33296395249955874]
	TIME [epoch: 8.69 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12564493640199315		[learning rate: 0.0027251]
	Learning Rate: 0.00272511
	LOSS [training: 0.12564493640199315 | validation: 0.3272395510092883]
	TIME [epoch: 8.68 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10918552363456857		[learning rate: 0.0027123]
	Learning Rate: 0.00271227
	LOSS [training: 0.10918552363456857 | validation: 0.33650357870311903]
	TIME [epoch: 8.68 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12390490779515051		[learning rate: 0.0026995]
	Learning Rate: 0.00269949
	LOSS [training: 0.12390490779515051 | validation: 0.3000241503734548]
	TIME [epoch: 8.67 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12161552615551088		[learning rate: 0.0026868]
	Learning Rate: 0.00268677
	LOSS [training: 0.12161552615551088 | validation: 0.2984900953636912]
	TIME [epoch: 8.69 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11146629811625804		[learning rate: 0.0026741]
	Learning Rate: 0.00267411
	LOSS [training: 0.11146629811625804 | validation: 0.3244234256220831]
	TIME [epoch: 8.68 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12766116067163136		[learning rate: 0.0026615]
	Learning Rate: 0.00266151
	LOSS [training: 0.12766116067163136 | validation: 0.29249558147880017]
	TIME [epoch: 8.68 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12613611167590785		[learning rate: 0.002649]
	Learning Rate: 0.00264897
	LOSS [training: 0.12613611167590785 | validation: 0.3144194033370414]
	TIME [epoch: 8.69 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1318007945336453		[learning rate: 0.0026365]
	Learning Rate: 0.00263649
	LOSS [training: 0.1318007945336453 | validation: 0.3216227135852964]
	TIME [epoch: 8.69 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1152901461310029		[learning rate: 0.0026241]
	Learning Rate: 0.00262406
	LOSS [training: 0.1152901461310029 | validation: 0.31237799406663685]
	TIME [epoch: 8.68 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13178219380290185		[learning rate: 0.0026117]
	Learning Rate: 0.0026117
	LOSS [training: 0.13178219380290185 | validation: 0.28486904718386297]
	TIME [epoch: 8.68 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10844822986931252		[learning rate: 0.0025994]
	Learning Rate: 0.00259939
	LOSS [training: 0.10844822986931252 | validation: 0.2901455937158672]
	TIME [epoch: 8.68 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12770268407888544		[learning rate: 0.0025871]
	Learning Rate: 0.00258714
	LOSS [training: 0.12770268407888544 | validation: 0.3117121949518687]
	TIME [epoch: 8.71 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1329923750906153		[learning rate: 0.002575]
	Learning Rate: 0.00257495
	LOSS [training: 0.1329923750906153 | validation: 0.32114476045517537]
	TIME [epoch: 8.69 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1298123403721948		[learning rate: 0.0025628]
	Learning Rate: 0.00256282
	LOSS [training: 0.1298123403721948 | validation: 0.35742380058444506]
	TIME [epoch: 8.69 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1252893952167841		[learning rate: 0.0025507]
	Learning Rate: 0.00255074
	LOSS [training: 0.1252893952167841 | validation: 0.3147555256175104]
	TIME [epoch: 8.67 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1280803607515562		[learning rate: 0.0025387]
	Learning Rate: 0.00253872
	LOSS [training: 0.1280803607515562 | validation: 0.29642138161270276]
	TIME [epoch: 8.69 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11476367470940116		[learning rate: 0.0025268]
	Learning Rate: 0.00252676
	LOSS [training: 0.11476367470940116 | validation: 0.29294360354101756]
	TIME [epoch: 8.69 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1316265810755261		[learning rate: 0.0025149]
	Learning Rate: 0.00251485
	LOSS [training: 0.1316265810755261 | validation: 0.338549329148707]
	TIME [epoch: 8.69 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14815437425940586		[learning rate: 0.002503]
	Learning Rate: 0.002503
	LOSS [training: 0.14815437425940586 | validation: 0.3301013485238174]
	TIME [epoch: 8.67 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1308575738302103		[learning rate: 0.0024912]
	Learning Rate: 0.00249121
	LOSS [training: 0.1308575738302103 | validation: 0.3148878042194226]
	TIME [epoch: 8.7 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12102377855482463		[learning rate: 0.0024795]
	Learning Rate: 0.00247947
	LOSS [training: 0.12102377855482463 | validation: 0.29595629417256747]
	TIME [epoch: 8.7 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11220223359544089		[learning rate: 0.0024678]
	Learning Rate: 0.00246779
	LOSS [training: 0.11220223359544089 | validation: 0.2970345807770678]
	TIME [epoch: 8.69 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1215202025791767		[learning rate: 0.0024562]
	Learning Rate: 0.00245616
	LOSS [training: 0.1215202025791767 | validation: 0.30950819836203913]
	TIME [epoch: 8.68 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13973203412602328		[learning rate: 0.0024446]
	Learning Rate: 0.00244458
	LOSS [training: 0.13973203412602328 | validation: 0.327373363140962]
	TIME [epoch: 8.69 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11570619806240338		[learning rate: 0.0024331]
	Learning Rate: 0.00243307
	LOSS [training: 0.11570619806240338 | validation: 0.30619314483443294]
	TIME [epoch: 8.7 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11434300113125614		[learning rate: 0.0024216]
	Learning Rate: 0.0024216
	LOSS [training: 0.11434300113125614 | validation: 0.3040452825035925]
	TIME [epoch: 8.69 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1163485706810843		[learning rate: 0.0024102]
	Learning Rate: 0.00241019
	LOSS [training: 0.1163485706810843 | validation: 0.3171054916783307]
	TIME [epoch: 8.67 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10837849523105143		[learning rate: 0.0023988]
	Learning Rate: 0.00239883
	LOSS [training: 0.10837849523105143 | validation: 0.32208987978475234]
	TIME [epoch: 8.69 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12927794561921885		[learning rate: 0.0023875]
	Learning Rate: 0.00238753
	LOSS [training: 0.12927794561921885 | validation: 0.3957491008128817]
	TIME [epoch: 8.7 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1331935603953151		[learning rate: 0.0023763]
	Learning Rate: 0.00237628
	LOSS [training: 0.1331935603953151 | validation: 0.31942707134188203]
	TIME [epoch: 8.69 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11004497725289221		[learning rate: 0.0023651]
	Learning Rate: 0.00236508
	LOSS [training: 0.11004497725289221 | validation: 0.32618622288864985]
	TIME [epoch: 8.67 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1212127335037512		[learning rate: 0.0023539]
	Learning Rate: 0.00235394
	LOSS [training: 0.1212127335037512 | validation: 0.3052321466114286]
	TIME [epoch: 8.69 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12375907102769376		[learning rate: 0.0023428]
	Learning Rate: 0.00234285
	LOSS [training: 0.12375907102769376 | validation: 0.2917697930352283]
	TIME [epoch: 8.69 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11208921206786071		[learning rate: 0.0023318]
	Learning Rate: 0.00233181
	LOSS [training: 0.11208921206786071 | validation: 0.3038556976161098]
	TIME [epoch: 8.7 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1217898770108258		[learning rate: 0.0023208]
	Learning Rate: 0.00232082
	LOSS [training: 0.1217898770108258 | validation: 0.3275845417492502]
	TIME [epoch: 8.67 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13165244246987703		[learning rate: 0.0023099]
	Learning Rate: 0.00230988
	LOSS [training: 0.13165244246987703 | validation: 0.2872898034808548]
	TIME [epoch: 8.69 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1137058649942497		[learning rate: 0.002299]
	Learning Rate: 0.002299
	LOSS [training: 0.1137058649942497 | validation: 0.3171974379629312]
	TIME [epoch: 8.69 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11005960544172633		[learning rate: 0.0022882]
	Learning Rate: 0.00228816
	LOSS [training: 0.11005960544172633 | validation: 0.323868122708499]
	TIME [epoch: 8.69 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12287749930895424		[learning rate: 0.0022774]
	Learning Rate: 0.00227738
	LOSS [training: 0.12287749930895424 | validation: 0.30411913835807697]
	TIME [epoch: 8.68 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12004356635188958		[learning rate: 0.0022667]
	Learning Rate: 0.00226665
	LOSS [training: 0.12004356635188958 | validation: 0.29558853057886786]
	TIME [epoch: 8.69 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11528500887694697		[learning rate: 0.002256]
	Learning Rate: 0.00225597
	LOSS [training: 0.11528500887694697 | validation: 0.3031316360225139]
	TIME [epoch: 8.69 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.106343942666939		[learning rate: 0.0022453]
	Learning Rate: 0.00224534
	LOSS [training: 0.106343942666939 | validation: 0.319415579260133]
	TIME [epoch: 8.7 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1091439062998826		[learning rate: 0.0022348]
	Learning Rate: 0.00223476
	LOSS [training: 0.1091439062998826 | validation: 0.30800764933276564]
	TIME [epoch: 8.68 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12057966392901893		[learning rate: 0.0022242]
	Learning Rate: 0.00222423
	LOSS [training: 0.12057966392901893 | validation: 0.2904062765429638]
	TIME [epoch: 8.69 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12474981267905225		[learning rate: 0.0022137]
	Learning Rate: 0.00221375
	LOSS [training: 0.12474981267905225 | validation: 0.3194421843551163]
	TIME [epoch: 8.69 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11122078156772497		[learning rate: 0.0022033]
	Learning Rate: 0.00220332
	LOSS [training: 0.11122078156772497 | validation: 0.30814011861944457]
	TIME [epoch: 8.7 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1146699935134621		[learning rate: 0.0021929]
	Learning Rate: 0.00219293
	LOSS [training: 0.1146699935134621 | validation: 0.2870698455091663]
	TIME [epoch: 8.68 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11526270620707674		[learning rate: 0.0021826]
	Learning Rate: 0.0021826
	LOSS [training: 0.11526270620707674 | validation: 0.32670123458723377]
	TIME [epoch: 8.69 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12984880994197867		[learning rate: 0.0021723]
	Learning Rate: 0.00217232
	LOSS [training: 0.12984880994197867 | validation: 0.31441103936758147]
	TIME [epoch: 8.69 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11741045311525469		[learning rate: 0.0021621]
	Learning Rate: 0.00216208
	LOSS [training: 0.11741045311525469 | validation: 0.28242332245162516]
	TIME [epoch: 8.7 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11616150780327561		[learning rate: 0.0021519]
	Learning Rate: 0.00215189
	LOSS [training: 0.11616150780327561 | validation: 0.3171197852488153]
	TIME [epoch: 8.68 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10724136715336571		[learning rate: 0.0021418]
	Learning Rate: 0.00214175
	LOSS [training: 0.10724136715336571 | validation: 0.32634433656956896]
	TIME [epoch: 8.69 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11233576293990914		[learning rate: 0.0021317]
	Learning Rate: 0.00213166
	LOSS [training: 0.11233576293990914 | validation: 0.28589404833363957]
	TIME [epoch: 8.68 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11879451410748257		[learning rate: 0.0021216]
	Learning Rate: 0.00212162
	LOSS [training: 0.11879451410748257 | validation: 0.3172231481981167]
	TIME [epoch: 8.69 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1286511888210442		[learning rate: 0.0021116]
	Learning Rate: 0.00211162
	LOSS [training: 0.1286511888210442 | validation: 0.3010875242282073]
	TIME [epoch: 8.69 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12467543309898452		[learning rate: 0.0021017]
	Learning Rate: 0.00210167
	LOSS [training: 0.12467543309898452 | validation: 0.33499433536852574]
	TIME [epoch: 8.7 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11433530187731367		[learning rate: 0.0020918]
	Learning Rate: 0.00209176
	LOSS [training: 0.11433530187731367 | validation: 0.2920460525049291]
	TIME [epoch: 8.69 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10901385336659442		[learning rate: 0.0020819]
	Learning Rate: 0.00208191
	LOSS [training: 0.10901385336659442 | validation: 0.3285874692074476]
	TIME [epoch: 8.69 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10896034670410955		[learning rate: 0.0020721]
	Learning Rate: 0.0020721
	LOSS [training: 0.10896034670410955 | validation: 0.31446254626576076]
	TIME [epoch: 8.68 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12063589509731404		[learning rate: 0.0020623]
	Learning Rate: 0.00206233
	LOSS [training: 0.12063589509731404 | validation: 0.2993409582085479]
	TIME [epoch: 8.69 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11692646197810727		[learning rate: 0.0020526]
	Learning Rate: 0.00205262
	LOSS [training: 0.11692646197810727 | validation: 0.30875033540924546]
	TIME [epoch: 8.69 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1178304262473857		[learning rate: 0.0020429]
	Learning Rate: 0.00204294
	LOSS [training: 0.1178304262473857 | validation: 0.30848251460292564]
	TIME [epoch: 8.69 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1229539396275301		[learning rate: 0.0020333]
	Learning Rate: 0.00203332
	LOSS [training: 0.1229539396275301 | validation: 0.3230819178540901]
	TIME [epoch: 8.68 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1192044632429445		[learning rate: 0.0020237]
	Learning Rate: 0.00202374
	LOSS [training: 0.1192044632429445 | validation: 0.2894788610818303]
	TIME [epoch: 8.69 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12094265197846787		[learning rate: 0.0020142]
	Learning Rate: 0.0020142
	LOSS [training: 0.12094265197846787 | validation: 0.32139848124424997]
	TIME [epoch: 8.69 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11935709978392761		[learning rate: 0.0020047]
	Learning Rate: 0.00200471
	LOSS [training: 0.11935709978392761 | validation: 0.3038479597471904]
	TIME [epoch: 8.69 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1078286774404392		[learning rate: 0.0019953]
	Learning Rate: 0.00199526
	LOSS [training: 0.1078286774404392 | validation: 0.3148852853569959]
	TIME [epoch: 8.68 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12223170786218344		[learning rate: 0.0019859]
	Learning Rate: 0.00198586
	LOSS [training: 0.12223170786218344 | validation: 0.32780676428667893]
	TIME [epoch: 8.69 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11288078341656499		[learning rate: 0.0019765]
	Learning Rate: 0.0019765
	LOSS [training: 0.11288078341656499 | validation: 0.2878448313502678]
	TIME [epoch: 8.68 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1188518621799671		[learning rate: 0.0019672]
	Learning Rate: 0.00196719
	LOSS [training: 0.1188518621799671 | validation: 0.3049465425514871]
	TIME [epoch: 8.68 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11154086292116576		[learning rate: 0.0019579]
	Learning Rate: 0.00195792
	LOSS [training: 0.11154086292116576 | validation: 0.3521330937213051]
	TIME [epoch: 8.69 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1250180761878431		[learning rate: 0.0019487]
	Learning Rate: 0.00194869
	LOSS [training: 0.1250180761878431 | validation: 0.3226073243965469]
	TIME [epoch: 8.69 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12498710558331032		[learning rate: 0.0019395]
	Learning Rate: 0.00193951
	LOSS [training: 0.12498710558331032 | validation: 0.2963466881563539]
	TIME [epoch: 8.69 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1148032244342768		[learning rate: 0.0019304]
	Learning Rate: 0.00193037
	LOSS [training: 0.1148032244342768 | validation: 0.33871896798729584]
	TIME [epoch: 8.69 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11655166907415025		[learning rate: 0.0019213]
	Learning Rate: 0.00192128
	LOSS [training: 0.11655166907415025 | validation: 0.301215547891352]
	TIME [epoch: 8.68 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11819979494615078		[learning rate: 0.0019122]
	Learning Rate: 0.00191222
	LOSS [training: 0.11819979494615078 | validation: 0.32943492421340065]
	TIME [epoch: 8.7 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11101755283546388		[learning rate: 0.0019032]
	Learning Rate: 0.00190321
	LOSS [training: 0.11101755283546388 | validation: 0.2839284687689422]
	TIME [epoch: 8.69 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10623804067237358		[learning rate: 0.0018942]
	Learning Rate: 0.00189424
	LOSS [training: 0.10623804067237358 | validation: 0.3364077187145993]
	TIME [epoch: 8.69 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11063878637118021		[learning rate: 0.0018853]
	Learning Rate: 0.00188532
	LOSS [training: 0.11063878637118021 | validation: 0.33698114627761605]
	TIME [epoch: 8.68 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11632804300784169		[learning rate: 0.0018764]
	Learning Rate: 0.00187643
	LOSS [training: 0.11632804300784169 | validation: 0.29698357099085904]
	TIME [epoch: 8.7 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11305775216126551		[learning rate: 0.0018676]
	Learning Rate: 0.00186759
	LOSS [training: 0.11305775216126551 | validation: 0.300546071782824]
	TIME [epoch: 8.69 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11603374640589596		[learning rate: 0.0018588]
	Learning Rate: 0.00185879
	LOSS [training: 0.11603374640589596 | validation: 0.3382458999394285]
	TIME [epoch: 8.69 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1189291894536667		[learning rate: 0.00185]
	Learning Rate: 0.00185003
	LOSS [training: 0.1189291894536667 | validation: 0.28680525975487875]
	TIME [epoch: 8.67 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11984847018325037		[learning rate: 0.0018413]
	Learning Rate: 0.00184132
	LOSS [training: 0.11984847018325037 | validation: 0.2980065964599114]
	TIME [epoch: 8.7 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1165410728124038		[learning rate: 0.0018326]
	Learning Rate: 0.00183264
	LOSS [training: 0.1165410728124038 | validation: 0.30859088903074466]
	TIME [epoch: 8.69 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14440026811705564		[learning rate: 0.001824]
	Learning Rate: 0.001824
	LOSS [training: 0.14440026811705564 | validation: 0.3083101126122203]
	TIME [epoch: 8.69 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13564237316270206		[learning rate: 0.0018154]
	Learning Rate: 0.00181541
	LOSS [training: 0.13564237316270206 | validation: 0.36544621380164105]
	TIME [epoch: 8.68 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1253532956702584		[learning rate: 0.0018069]
	Learning Rate: 0.00180685
	LOSS [training: 0.1253532956702584 | validation: 0.32166647477096094]
	TIME [epoch: 8.71 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12045963147518549		[learning rate: 0.0017983]
	Learning Rate: 0.00179834
	LOSS [training: 0.12045963147518549 | validation: 0.2943166253075008]
	TIME [epoch: 8.69 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1034692371067467		[learning rate: 0.0017899]
	Learning Rate: 0.00178987
	LOSS [training: 0.1034692371067467 | validation: 0.30262551452971487]
	TIME [epoch: 8.68 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11288091694022752		[learning rate: 0.0017814]
	Learning Rate: 0.00178143
	LOSS [training: 0.11288091694022752 | validation: 0.2814617323440618]
	TIME [epoch: 8.68 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11689823493554793		[learning rate: 0.001773]
	Learning Rate: 0.00177304
	LOSS [training: 0.11689823493554793 | validation: 0.30377048136149937]
	TIME [epoch: 8.69 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11173611362792506		[learning rate: 0.0017647]
	Learning Rate: 0.00176468
	LOSS [training: 0.11173611362792506 | validation: 0.2976225393045346]
	TIME [epoch: 8.68 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11312357550342207		[learning rate: 0.0017564]
	Learning Rate: 0.00175637
	LOSS [training: 0.11312357550342207 | validation: 0.32773251653496116]
	TIME [epoch: 8.68 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11258964380622438		[learning rate: 0.0017481]
	Learning Rate: 0.00174809
	LOSS [training: 0.11258964380622438 | validation: 0.3018382043110771]
	TIME [epoch: 8.67 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1328938626806333		[learning rate: 0.0017399]
	Learning Rate: 0.00173985
	LOSS [training: 0.1328938626806333 | validation: 0.32235565908940866]
	TIME [epoch: 8.68 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12480546336396636		[learning rate: 0.0017317]
	Learning Rate: 0.00173166
	LOSS [training: 0.12480546336396636 | validation: 0.29169481758855076]
	TIME [epoch: 8.69 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14090823891140464		[learning rate: 0.0017235]
	Learning Rate: 0.0017235
	LOSS [training: 0.14090823891140464 | validation: 0.33322698145368884]
	TIME [epoch: 8.68 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12189276820478864		[learning rate: 0.0017154]
	Learning Rate: 0.00171537
	LOSS [training: 0.12189276820478864 | validation: 0.3026775612756315]
	TIME [epoch: 8.68 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10872844461323582		[learning rate: 0.0017073]
	Learning Rate: 0.00170729
	LOSS [training: 0.10872844461323582 | validation: 0.30864237597943883]
	TIME [epoch: 8.68 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11208393229614967		[learning rate: 0.0016992]
	Learning Rate: 0.00169925
	LOSS [training: 0.11208393229614967 | validation: 0.31802596682980944]
	TIME [epoch: 8.69 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12906574302063772		[learning rate: 0.0016912]
	Learning Rate: 0.00169124
	LOSS [training: 0.12906574302063772 | validation: 0.32664663096338065]
	TIME [epoch: 8.68 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12828922590414507		[learning rate: 0.0016833]
	Learning Rate: 0.00168327
	LOSS [training: 0.12828922590414507 | validation: 0.2890965247950835]
	TIME [epoch: 8.68 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11645362886495852		[learning rate: 0.0016753]
	Learning Rate: 0.00167534
	LOSS [training: 0.11645362886495852 | validation: 0.29573913275877484]
	TIME [epoch: 8.68 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11829499420483679		[learning rate: 0.0016674]
	Learning Rate: 0.00166744
	LOSS [training: 0.11829499420483679 | validation: 0.3093337179369897]
	TIME [epoch: 8.69 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1140090838296611		[learning rate: 0.0016596]
	Learning Rate: 0.00165959
	LOSS [training: 0.1140090838296611 | validation: 0.3047220234712463]
	TIME [epoch: 8.68 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11163885525891527		[learning rate: 0.0016518]
	Learning Rate: 0.00165177
	LOSS [training: 0.11163885525891527 | validation: 0.30140618817286774]
	TIME [epoch: 8.68 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10645971274689464		[learning rate: 0.001644]
	Learning Rate: 0.00164398
	LOSS [training: 0.10645971274689464 | validation: 0.30957061863927954]
	TIME [epoch: 8.68 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11353218054150578		[learning rate: 0.0016362]
	Learning Rate: 0.00163624
	LOSS [training: 0.11353218054150578 | validation: 0.2934212714829122]
	TIME [epoch: 8.69 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13147321288584057		[learning rate: 0.0016285]
	Learning Rate: 0.00162853
	LOSS [training: 0.13147321288584057 | validation: 0.3785443790915948]
	TIME [epoch: 8.68 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11652905631113476		[learning rate: 0.0016209]
	Learning Rate: 0.00162085
	LOSS [training: 0.11652905631113476 | validation: 0.2930886628117698]
	TIME [epoch: 8.68 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10918501789716195		[learning rate: 0.0016132]
	Learning Rate: 0.00161322
	LOSS [training: 0.10918501789716195 | validation: 0.3067098416782885]
	TIME [epoch: 8.68 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1234969054950791		[learning rate: 0.0016056]
	Learning Rate: 0.00160561
	LOSS [training: 0.1234969054950791 | validation: 0.3132227690605789]
	TIME [epoch: 8.69 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.118940724602334		[learning rate: 0.001598]
	Learning Rate: 0.00159805
	LOSS [training: 0.118940724602334 | validation: 0.330676606454434]
	TIME [epoch: 8.68 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10694914318361007		[learning rate: 0.0015905]
	Learning Rate: 0.00159052
	LOSS [training: 0.10694914318361007 | validation: 0.2807142418560854]
	TIME [epoch: 8.69 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10870198243027505		[learning rate: 0.001583]
	Learning Rate: 0.00158302
	LOSS [training: 0.10870198243027505 | validation: 0.31310461764024616]
	TIME [epoch: 8.69 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1098459913709382		[learning rate: 0.0015756]
	Learning Rate: 0.00157556
	LOSS [training: 0.1098459913709382 | validation: 0.2902335220589418]
	TIME [epoch: 8.69 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12597362279734461		[learning rate: 0.0015681]
	Learning Rate: 0.00156814
	LOSS [training: 0.12597362279734461 | validation: 0.3194208902450818]
	TIME [epoch: 8.69 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13439890767341872		[learning rate: 0.0015607]
	Learning Rate: 0.00156075
	LOSS [training: 0.13439890767341872 | validation: 0.31993022089705414]
	TIME [epoch: 8.68 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11156900440981368		[learning rate: 0.0015534]
	Learning Rate: 0.0015534
	LOSS [training: 0.11156900440981368 | validation: 0.33078761223415487]
	TIME [epoch: 8.68 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12182548452950397		[learning rate: 0.0015461]
	Learning Rate: 0.00154608
	LOSS [training: 0.12182548452950397 | validation: 0.30866151263773456]
	TIME [epoch: 8.68 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1192602288759389		[learning rate: 0.0015388]
	Learning Rate: 0.00153879
	LOSS [training: 0.1192602288759389 | validation: 0.2801218066718044]
	TIME [epoch: 8.69 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11415570110999614		[learning rate: 0.0015315]
	Learning Rate: 0.00153154
	LOSS [training: 0.11415570110999614 | validation: 0.30097375700076584]
	TIME [epoch: 8.67 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11760750000176595		[learning rate: 0.0015243]
	Learning Rate: 0.00152432
	LOSS [training: 0.11760750000176595 | validation: 0.28479317763049505]
	TIME [epoch: 8.69 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v13_20240718_190217/states/model_facs_v4_dec2b_2dpca_v13_436.pth
Halted early. No improvement in validation loss for 200 epochs.
Finished training in 3668.070 seconds.
