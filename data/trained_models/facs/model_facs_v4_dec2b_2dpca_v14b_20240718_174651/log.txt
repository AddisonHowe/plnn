Args:
Namespace(name='model_facs_v4_dec2b_2dpca_v14b', outdir='out/model_training/model_facs_v4_dec2b_2dpca_v14b', training_data='data/training_data/facs_v4/pca/dec2_fitonsubset/transition2_subset_ce_pn_m_pc12/training', validation_data='data/training_data/facs_v4/pca/dec2_fitonsubset/transition2_subset_ce_pn_m_pc12/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=10, batch_size=50, patience=200, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, quadratic_a=1.0, quadratic_b=1.0, ndims=2, nparams=2, nsigs=2, ncells=200, ncells_sample=200, model_do_sample=False, dt=0.005, dt_schedule='stepped', dt_schedule_bounds=[50, 100, 200, 300], dt_schedule_scales=[0.5, 0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', kernel='multiscale', bw_range=[0.2, 0.5, 0.9, 1.1, 1.3, 1.5, 2.0], optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 2456444379

Training model...

Saving initial model state to: out/model_training/model_facs_v4_dec2b_2dpca_v14b_20240718_174651/states/model_facs_v4_dec2b_2dpca_v14b_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0532976247590882		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0532976247590882 | validation: 0.9855928958480464]
	TIME [epoch: 30.7 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v14b_20240718_174651/states/model_facs_v4_dec2b_2dpca_v14b_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7805485036717603		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7805485036717603 | validation: 0.9129565736606022]
	TIME [epoch: 4 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v14b_20240718_174651/states/model_facs_v4_dec2b_2dpca_v14b_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7096723753244231		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7096723753244231 | validation: 0.9191389906082157]
	TIME [epoch: 3.98 sec]
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6985852782410396		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6985852782410396 | validation: 0.8578168665399196]
	TIME [epoch: 3.98 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v14b_20240718_174651/states/model_facs_v4_dec2b_2dpca_v14b_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.619253495311782		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.619253495311782 | validation: 0.7927498194714757]
	TIME [epoch: 3.98 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v14b_20240718_174651/states/model_facs_v4_dec2b_2dpca_v14b_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6457260357929322		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6457260357929322 | validation: 0.7378525554681141]
	TIME [epoch: 3.98 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v14b_20240718_174651/states/model_facs_v4_dec2b_2dpca_v14b_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5461205192115897		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5461205192115897 | validation: 0.6810638344993032]
	TIME [epoch: 3.97 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v14b_20240718_174651/states/model_facs_v4_dec2b_2dpca_v14b_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5165895887236992		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5165895887236992 | validation: 0.7381512087742673]
	TIME [epoch: 3.99 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5573605099785965		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5573605099785965 | validation: 0.6349227943566216]
	TIME [epoch: 3.97 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v14b_20240718_174651/states/model_facs_v4_dec2b_2dpca_v14b_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4517744100645865		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4517744100645865 | validation: 0.5549577948618888]
	TIME [epoch: 3.98 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v14b_20240718_174651/states/model_facs_v4_dec2b_2dpca_v14b_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4352688495379578		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4352688495379578 | validation: 0.5436787311814577]
	TIME [epoch: 3.98 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v14b_20240718_174651/states/model_facs_v4_dec2b_2dpca_v14b_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35501750861281856		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.35501750861281856 | validation: 0.5392932540294769]
	TIME [epoch: 3.98 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v14b_20240718_174651/states/model_facs_v4_dec2b_2dpca_v14b_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4005637566520262		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4005637566520262 | validation: 0.6769030041419636]
	TIME [epoch: 3.98 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38266499204395626		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.38266499204395626 | validation: 0.46871277396329786]
	TIME [epoch: 3.99 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v14b_20240718_174651/states/model_facs_v4_dec2b_2dpca_v14b_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32156571166235404		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.32156571166235404 | validation: 0.42905791991887443]
	TIME [epoch: 3.99 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v14b_20240718_174651/states/model_facs_v4_dec2b_2dpca_v14b_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2972322243351174		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2972322243351174 | validation: 0.4296739331272892]
	TIME [epoch: 3.98 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29844278241834976		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.29844278241834976 | validation: 0.3995751829703092]
	TIME [epoch: 3.98 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v14b_20240718_174651/states/model_facs_v4_dec2b_2dpca_v14b_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34056189791111396		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.34056189791111396 | validation: 0.43726120367951365]
	TIME [epoch: 3.98 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2776995677170907		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2776995677170907 | validation: 0.41488227831210944]
	TIME [epoch: 3.98 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2695265483454883		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2695265483454883 | validation: 0.42614744432058654]
	TIME [epoch: 3.98 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26432873443723376		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.26432873443723376 | validation: 0.3945621011251681]
	TIME [epoch: 3.98 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v14b_20240718_174651/states/model_facs_v4_dec2b_2dpca_v14b_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2835973991619114		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2835973991619114 | validation: 0.44497996235025594]
	TIME [epoch: 3.99 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2691445789514802		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2691445789514802 | validation: 0.43466956310058075]
	TIME [epoch: 3.97 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2633118501359243		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2633118501359243 | validation: 0.4716241898719517]
	TIME [epoch: 3.97 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27367465187283785		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.27367465187283785 | validation: 0.42421236561631565]
	TIME [epoch: 3.97 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26004678844071605		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.26004678844071605 | validation: 0.423600616437414]
	TIME [epoch: 3.97 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2338393121106207		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2338393121106207 | validation: 0.4234518620294332]
	TIME [epoch: 3.97 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28054945844861134		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.28054945844861134 | validation: 0.4201049631811685]
	TIME [epoch: 3.97 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2543577893575877		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2543577893575877 | validation: 0.37872404593245157]
	TIME [epoch: 3.97 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v14b_20240718_174651/states/model_facs_v4_dec2b_2dpca_v14b_29.pth
	Model improved!!!
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23940831073346688		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23940831073346688 | validation: 0.4654391585296316]
	TIME [epoch: 4 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2603076686930449		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2603076686930449 | validation: 0.4160180314131832]
	TIME [epoch: 3.97 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22619205632905198		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22619205632905198 | validation: 0.37859134514519777]
	TIME [epoch: 3.97 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v14b_20240718_174651/states/model_facs_v4_dec2b_2dpca_v14b_32.pth
	Model improved!!!
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23450127711533836		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23450127711533836 | validation: 0.4200782515495507]
	TIME [epoch: 3.98 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2303893273439195		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2303893273439195 | validation: 0.4533462143563551]
	TIME [epoch: 3.97 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24317360155060805		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24317360155060805 | validation: 0.41172224602828195]
	TIME [epoch: 3.97 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21385494437439084		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.21385494437439084 | validation: 0.4594596484952556]
	TIME [epoch: 3.97 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26122654181126403		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.26122654181126403 | validation: 0.3615780710682323]
	TIME [epoch: 3.97 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v14b_20240718_174651/states/model_facs_v4_dec2b_2dpca_v14b_37.pth
	Model improved!!!
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20212284085168272		[learning rate: 0.0099882]
	Learning Rate: 0.0099882
	LOSS [training: 0.20212284085168272 | validation: 0.388179103957401]
	TIME [epoch: 4 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26555198640004785		[learning rate: 0.0099411]
	Learning Rate: 0.00994113
	LOSS [training: 0.26555198640004785 | validation: 0.3810655665304752]
	TIME [epoch: 3.98 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27303739329975074		[learning rate: 0.0098943]
	Learning Rate: 0.00989429
	LOSS [training: 0.27303739329975074 | validation: 0.36785154384845176]
	TIME [epoch: 3.98 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21679300961291328		[learning rate: 0.0098477]
	Learning Rate: 0.00984767
	LOSS [training: 0.21679300961291328 | validation: 0.378759384782433]
	TIME [epoch: 3.98 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19075951914244046		[learning rate: 0.0098013]
	Learning Rate: 0.00980126
	LOSS [training: 0.19075951914244046 | validation: 0.3669895151725259]
	TIME [epoch: 3.97 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19521056960866856		[learning rate: 0.0097551]
	Learning Rate: 0.00975508
	LOSS [training: 0.19521056960866856 | validation: 0.4390844050355541]
	TIME [epoch: 3.98 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2591835110707194		[learning rate: 0.0097091]
	Learning Rate: 0.00970911
	LOSS [training: 0.2591835110707194 | validation: 0.38426590602621064]
	TIME [epoch: 3.98 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1839670008298123		[learning rate: 0.0096634]
	Learning Rate: 0.00966336
	LOSS [training: 0.1839670008298123 | validation: 0.4047505028425839]
	TIME [epoch: 3.97 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20933323007835006		[learning rate: 0.0096178]
	Learning Rate: 0.00961783
	LOSS [training: 0.20933323007835006 | validation: 0.4289624512531952]
	TIME [epoch: 3.99 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22800618025648492		[learning rate: 0.0095725]
	Learning Rate: 0.00957251
	LOSS [training: 0.22800618025648492 | validation: 0.36327014737229796]
	TIME [epoch: 3.97 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22059191344365198		[learning rate: 0.0095274]
	Learning Rate: 0.0095274
	LOSS [training: 0.22059191344365198 | validation: 0.38756885569592436]
	TIME [epoch: 3.97 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23140475210726674		[learning rate: 0.0094825]
	Learning Rate: 0.0094825
	LOSS [training: 0.23140475210726674 | validation: 0.45184290988026643]
	TIME [epoch: 3.97 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25749778354198427		[learning rate: 0.0094378]
	Learning Rate: 0.00943782
	LOSS [training: 0.25749778354198427 | validation: 0.6104997408818579]
	TIME [epoch: 3.97 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2911883282523392		[learning rate: 0.0093933]
	Learning Rate: 0.00939335
	LOSS [training: 0.2911883282523392 | validation: 0.32697118721137336]
	TIME [epoch: 32 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v14b_20240718_174651/states/model_facs_v4_dec2b_2dpca_v14b_51.pth
	Model improved!!!
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17598129070732088		[learning rate: 0.0093491]
	Learning Rate: 0.00934909
	LOSS [training: 0.17598129070732088 | validation: 0.6966327102232119]
	TIME [epoch: 7.66 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2897998929249683		[learning rate: 0.009305]
	Learning Rate: 0.00930503
	LOSS [training: 0.2897998929249683 | validation: 0.33174275002638964]
	TIME [epoch: 7.64 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19742688246325216		[learning rate: 0.0092612]
	Learning Rate: 0.00926119
	LOSS [training: 0.19742688246325216 | validation: 0.43671203167366324]
	TIME [epoch: 7.65 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2868326033181781		[learning rate: 0.0092175]
	Learning Rate: 0.00921755
	LOSS [training: 0.2868326033181781 | validation: 0.4145087924870199]
	TIME [epoch: 7.66 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25210995293295835		[learning rate: 0.0091741]
	Learning Rate: 0.00917411
	LOSS [training: 0.25210995293295835 | validation: 0.4422684892357581]
	TIME [epoch: 7.65 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27837231598917767		[learning rate: 0.0091309]
	Learning Rate: 0.00913088
	LOSS [training: 0.27837231598917767 | validation: 0.39828466201426604]
	TIME [epoch: 7.65 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24157579652975736		[learning rate: 0.0090879]
	Learning Rate: 0.00908786
	LOSS [training: 0.24157579652975736 | validation: 0.41392566972201317]
	TIME [epoch: 7.64 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2021904116804307		[learning rate: 0.009045]
	Learning Rate: 0.00904503
	LOSS [training: 0.2021904116804307 | validation: 0.41834719489458694]
	TIME [epoch: 7.65 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.234476933404415		[learning rate: 0.0090024]
	Learning Rate: 0.00900241
	LOSS [training: 0.234476933404415 | validation: 0.3872626070180484]
	TIME [epoch: 7.65 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23196047841815434		[learning rate: 0.00896]
	Learning Rate: 0.00895999
	LOSS [training: 0.23196047841815434 | validation: 0.35756282824114166]
	TIME [epoch: 7.65 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21316963052859728		[learning rate: 0.0089178]
	Learning Rate: 0.00891777
	LOSS [training: 0.21316963052859728 | validation: 0.36188491873072437]
	TIME [epoch: 7.64 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1767584567740537		[learning rate: 0.0088758]
	Learning Rate: 0.00887575
	LOSS [training: 0.1767584567740537 | validation: 0.38808324318326504]
	TIME [epoch: 7.64 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22182096719056218		[learning rate: 0.0088339]
	Learning Rate: 0.00883393
	LOSS [training: 0.22182096719056218 | validation: 0.39794910734778866]
	TIME [epoch: 7.65 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23373986974772992		[learning rate: 0.0087923]
	Learning Rate: 0.0087923
	LOSS [training: 0.23373986974772992 | validation: 0.39362407421249634]
	TIME [epoch: 7.65 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22171734717596822		[learning rate: 0.0087509]
	Learning Rate: 0.00875087
	LOSS [training: 0.22171734717596822 | validation: 0.3641719230387024]
	TIME [epoch: 7.64 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17601680483652002		[learning rate: 0.0087096]
	Learning Rate: 0.00870964
	LOSS [training: 0.17601680483652002 | validation: 0.46987715306230443]
	TIME [epoch: 7.64 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2184355615576418		[learning rate: 0.0086686]
	Learning Rate: 0.00866859
	LOSS [training: 0.2184355615576418 | validation: 0.35283580573853646]
	TIME [epoch: 7.64 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18647400475620993		[learning rate: 0.0086277]
	Learning Rate: 0.00862775
	LOSS [training: 0.18647400475620993 | validation: 0.3616987733470366]
	TIME [epoch: 7.65 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.211349026357664		[learning rate: 0.0085871]
	Learning Rate: 0.00858709
	LOSS [training: 0.211349026357664 | validation: 0.49710825616333537]
	TIME [epoch: 7.64 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20353464133830151		[learning rate: 0.0085466]
	Learning Rate: 0.00854663
	LOSS [training: 0.20353464133830151 | validation: 0.366364752525699]
	TIME [epoch: 7.64 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20433979530832475		[learning rate: 0.0085064]
	Learning Rate: 0.00850636
	LOSS [training: 0.20433979530832475 | validation: 0.3036174457093209]
	TIME [epoch: 7.64 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v14b_20240718_174651/states/model_facs_v4_dec2b_2dpca_v14b_72.pth
	Model improved!!!
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1811542402808822		[learning rate: 0.0084663]
	Learning Rate: 0.00846627
	LOSS [training: 0.1811542402808822 | validation: 0.3176840264399546]
	TIME [epoch: 7.64 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1849432634521073		[learning rate: 0.0084264]
	Learning Rate: 0.00842638
	LOSS [training: 0.1849432634521073 | validation: 0.38099022455531767]
	TIME [epoch: 7.65 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2077611517654931		[learning rate: 0.0083867]
	Learning Rate: 0.00838667
	LOSS [training: 0.2077611517654931 | validation: 0.31709356520444654]
	TIME [epoch: 7.64 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16579100295613702		[learning rate: 0.0083472]
	Learning Rate: 0.00834715
	LOSS [training: 0.16579100295613702 | validation: 0.45483110101924124]
	TIME [epoch: 7.63 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21997512598745908		[learning rate: 0.0083078]
	Learning Rate: 0.00830782
	LOSS [training: 0.21997512598745908 | validation: 0.36128983514250157]
	TIME [epoch: 7.64 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21085137555897954		[learning rate: 0.0082687]
	Learning Rate: 0.00826867
	LOSS [training: 0.21085137555897954 | validation: 0.38438053682001155]
	TIME [epoch: 7.64 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16679858135371844		[learning rate: 0.0082297]
	Learning Rate: 0.00822971
	LOSS [training: 0.16679858135371844 | validation: 0.36917788834778603]
	TIME [epoch: 7.66 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1605563591962365		[learning rate: 0.0081909]
	Learning Rate: 0.00819093
	LOSS [training: 0.1605563591962365 | validation: 0.31564831142615063]
	TIME [epoch: 7.64 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15185404178376877		[learning rate: 0.0081523]
	Learning Rate: 0.00815233
	LOSS [training: 0.15185404178376877 | validation: 0.3017348664685802]
	TIME [epoch: 7.64 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v14b_20240718_174651/states/model_facs_v4_dec2b_2dpca_v14b_81.pth
	Model improved!!!
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17651920066240873		[learning rate: 0.0081139]
	Learning Rate: 0.00811392
	LOSS [training: 0.17651920066240873 | validation: 0.35134965789639383]
	TIME [epoch: 7.64 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1702579032089353		[learning rate: 0.0080757]
	Learning Rate: 0.00807569
	LOSS [training: 0.1702579032089353 | validation: 0.354788918743594]
	TIME [epoch: 7.64 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16855765354706856		[learning rate: 0.0080376]
	Learning Rate: 0.00803763
	LOSS [training: 0.16855765354706856 | validation: 0.3685360947284729]
	TIME [epoch: 7.65 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1844146714141107		[learning rate: 0.0079998]
	Learning Rate: 0.00799976
	LOSS [training: 0.1844146714141107 | validation: 0.6203884966601168]
	TIME [epoch: 7.64 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17419920361357075		[learning rate: 0.0079621]
	Learning Rate: 0.00796206
	LOSS [training: 0.17419920361357075 | validation: 0.43948694997101234]
	TIME [epoch: 7.64 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18763728806671942		[learning rate: 0.0079245]
	Learning Rate: 0.00792455
	LOSS [training: 0.18763728806671942 | validation: 0.3241138744977131]
	TIME [epoch: 7.64 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15631346498881538		[learning rate: 0.0078872]
	Learning Rate: 0.0078872
	LOSS [training: 0.15631346498881538 | validation: 0.3646541609710732]
	TIME [epoch: 7.64 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18132527305294724		[learning rate: 0.00785]
	Learning Rate: 0.00785004
	LOSS [training: 0.18132527305294724 | validation: 0.3201166016345065]
	TIME [epoch: 7.64 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15285402296012615		[learning rate: 0.007813]
	Learning Rate: 0.00781305
	LOSS [training: 0.15285402296012615 | validation: 0.35683198074384515]
	TIME [epoch: 7.64 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16857010931443445		[learning rate: 0.0077762]
	Learning Rate: 0.00777623
	LOSS [training: 0.16857010931443445 | validation: 0.3282786898887665]
	TIME [epoch: 7.64 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16219971339153574		[learning rate: 0.0077396]
	Learning Rate: 0.00773959
	LOSS [training: 0.16219971339153574 | validation: 0.37080535970704126]
	TIME [epoch: 7.64 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17289841068876455		[learning rate: 0.0077031]
	Learning Rate: 0.00770312
	LOSS [training: 0.17289841068876455 | validation: 0.30197285767789855]
	TIME [epoch: 7.65 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17943060367898347		[learning rate: 0.0076668]
	Learning Rate: 0.00766682
	LOSS [training: 0.17943060367898347 | validation: 0.3402323085246039]
	TIME [epoch: 7.64 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19619728349066384		[learning rate: 0.0076307]
	Learning Rate: 0.0076307
	LOSS [training: 0.19619728349066384 | validation: 0.5658763680771947]
	TIME [epoch: 7.64 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2068648287087396		[learning rate: 0.0075947]
	Learning Rate: 0.00759474
	LOSS [training: 0.2068648287087396 | validation: 0.4909787061024938]
	TIME [epoch: 7.64 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17682715646957778		[learning rate: 0.007559]
	Learning Rate: 0.00755895
	LOSS [training: 0.17682715646957778 | validation: 0.36053232832192683]
	TIME [epoch: 7.63 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1505545708066115		[learning rate: 0.0075233]
	Learning Rate: 0.00752333
	LOSS [training: 0.1505545708066115 | validation: 0.3470630023392169]
	TIME [epoch: 7.65 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15471272791071225		[learning rate: 0.0074879]
	Learning Rate: 0.00748788
	LOSS [training: 0.15471272791071225 | validation: 0.34917883033331765]
	TIME [epoch: 7.64 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17188039749177886		[learning rate: 0.0074526]
	Learning Rate: 0.0074526
	LOSS [training: 0.17188039749177886 | validation: 0.34557185732760853]
	TIME [epoch: 7.63 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17558667742930176		[learning rate: 0.0074175]
	Learning Rate: 0.00741748
	LOSS [training: 0.17558667742930176 | validation: 0.3017641090371081]
	TIME [epoch: 41.1 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15580933927250354		[learning rate: 0.0073825]
	Learning Rate: 0.00738253
	LOSS [training: 0.15580933927250354 | validation: 0.3013090038209074]
	TIME [epoch: 16.6 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v14b_20240718_174651/states/model_facs_v4_dec2b_2dpca_v14b_102.pth
	Model improved!!!
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14452962493854776		[learning rate: 0.0073477]
	Learning Rate: 0.00734774
	LOSS [training: 0.14452962493854776 | validation: 0.3874298651498945]
	TIME [epoch: 16.6 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1582470518859464		[learning rate: 0.0073131]
	Learning Rate: 0.00731312
	LOSS [training: 0.1582470518859464 | validation: 0.4019422596889679]
	TIME [epoch: 16.6 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18340338119323535		[learning rate: 0.0072787]
	Learning Rate: 0.00727866
	LOSS [training: 0.18340338119323535 | validation: 0.31934820178770257]
	TIME [epoch: 16.6 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1610635787136032		[learning rate: 0.0072444]
	Learning Rate: 0.00724436
	LOSS [training: 0.1610635787136032 | validation: 0.3578852978445898]
	TIME [epoch: 16.6 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15702856567266027		[learning rate: 0.0072102]
	Learning Rate: 0.00721022
	LOSS [training: 0.15702856567266027 | validation: 0.3063622140600424]
	TIME [epoch: 16.6 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16864723267369497		[learning rate: 0.0071762]
	Learning Rate: 0.00717625
	LOSS [training: 0.16864723267369497 | validation: 0.34851297278208554]
	TIME [epoch: 16.6 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13475280749646035		[learning rate: 0.0071424]
	Learning Rate: 0.00714243
	LOSS [training: 0.13475280749646035 | validation: 0.48698364147871814]
	TIME [epoch: 16.6 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19688233266188904		[learning rate: 0.0071088]
	Learning Rate: 0.00710878
	LOSS [training: 0.19688233266188904 | validation: 0.3771338477217057]
	TIME [epoch: 16.6 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1837452692986225		[learning rate: 0.0070753]
	Learning Rate: 0.00707528
	LOSS [training: 0.1837452692986225 | validation: 0.3416352689807816]
	TIME [epoch: 16.6 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19921871902267105		[learning rate: 0.0070419]
	Learning Rate: 0.00704194
	LOSS [training: 0.19921871902267105 | validation: 0.4368047807043121]
	TIME [epoch: 16.6 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2173980384725871		[learning rate: 0.0070088]
	Learning Rate: 0.00700876
	LOSS [training: 0.2173980384725871 | validation: 0.3042496443493332]
	TIME [epoch: 16.6 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16940613121378367		[learning rate: 0.0069757]
	Learning Rate: 0.00697573
	LOSS [training: 0.16940613121378367 | validation: 0.3546746724785612]
	TIME [epoch: 16.6 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14721807064702097		[learning rate: 0.0069429]
	Learning Rate: 0.00694286
	LOSS [training: 0.14721807064702097 | validation: 0.3587795313794454]
	TIME [epoch: 16.6 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16067340581921363		[learning rate: 0.0069101]
	Learning Rate: 0.00691014
	LOSS [training: 0.16067340581921363 | validation: 0.3279466475412397]
	TIME [epoch: 16.6 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14600422440480884		[learning rate: 0.0068776]
	Learning Rate: 0.00687758
	LOSS [training: 0.14600422440480884 | validation: 0.3566454213107284]
	TIME [epoch: 16.6 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16918740626945175		[learning rate: 0.0068452]
	Learning Rate: 0.00684518
	LOSS [training: 0.16918740626945175 | validation: 0.29780460186212043]
	TIME [epoch: 16.6 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v14b_20240718_174651/states/model_facs_v4_dec2b_2dpca_v14b_118.pth
	Model improved!!!
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1674659588421128		[learning rate: 0.0068129]
	Learning Rate: 0.00681292
	LOSS [training: 0.1674659588421128 | validation: 0.46414592229896245]
	TIME [epoch: 16.5 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16298290670283738		[learning rate: 0.0067808]
	Learning Rate: 0.00678082
	LOSS [training: 0.16298290670283738 | validation: 0.3350462824788595]
	TIME [epoch: 16.5 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16629250161214848		[learning rate: 0.0067489]
	Learning Rate: 0.00674887
	LOSS [training: 0.16629250161214848 | validation: 0.3900782626953171]
	TIME [epoch: 16.6 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1729846999100831		[learning rate: 0.0067171]
	Learning Rate: 0.00671706
	LOSS [training: 0.1729846999100831 | validation: 0.34870280363119827]
	TIME [epoch: 16.5 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17303991814653066		[learning rate: 0.0066854]
	Learning Rate: 0.00668541
	LOSS [training: 0.17303991814653066 | validation: 0.29423433159372125]
	TIME [epoch: 16.6 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v14b_20240718_174651/states/model_facs_v4_dec2b_2dpca_v14b_123.pth
	Model improved!!!
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1644609766113817		[learning rate: 0.0066539]
	Learning Rate: 0.00665391
	LOSS [training: 0.1644609766113817 | validation: 0.4296691441898155]
	TIME [epoch: 16.5 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23371887321870902		[learning rate: 0.0066226]
	Learning Rate: 0.00662256
	LOSS [training: 0.23371887321870902 | validation: 0.33519119284202836]
	TIME [epoch: 16.6 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16594398769413649		[learning rate: 0.0065913]
	Learning Rate: 0.00659135
	LOSS [training: 0.16594398769413649 | validation: 0.3339267956045462]
	TIME [epoch: 16.5 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14244687014349017		[learning rate: 0.0065603]
	Learning Rate: 0.00656029
	LOSS [training: 0.14244687014349017 | validation: 0.3658746417044806]
	TIME [epoch: 16.5 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17324973190781534		[learning rate: 0.0065294]
	Learning Rate: 0.00652938
	LOSS [training: 0.17324973190781534 | validation: 0.3034617384635747]
	TIME [epoch: 16.5 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1689275515944042		[learning rate: 0.0064986]
	Learning Rate: 0.00649861
	LOSS [training: 0.1689275515944042 | validation: 0.3282810430618762]
	TIME [epoch: 16.5 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1507170433855219		[learning rate: 0.006468]
	Learning Rate: 0.00646799
	LOSS [training: 0.1507170433855219 | validation: 0.4551144359172319]
	TIME [epoch: 16.5 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15909855688738744		[learning rate: 0.0064375]
	Learning Rate: 0.00643751
	LOSS [training: 0.15909855688738744 | validation: 0.37022210181183535]
	TIME [epoch: 16.5 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15438499267426703		[learning rate: 0.0064072]
	Learning Rate: 0.00640718
	LOSS [training: 0.15438499267426703 | validation: 0.3642702583868579]
	TIME [epoch: 16.5 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16199530434692125		[learning rate: 0.006377]
	Learning Rate: 0.00637698
	LOSS [training: 0.16199530434692125 | validation: 0.3118942495620216]
	TIME [epoch: 16.5 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14769255999282632		[learning rate: 0.0063469]
	Learning Rate: 0.00634694
	LOSS [training: 0.14769255999282632 | validation: 0.30780873034968215]
	TIME [epoch: 16.5 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15618187114575593		[learning rate: 0.006317]
	Learning Rate: 0.00631703
	LOSS [training: 0.15618187114575593 | validation: 0.37148493790739967]
	TIME [epoch: 16.5 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1843973936430338		[learning rate: 0.0062873]
	Learning Rate: 0.00628726
	LOSS [training: 0.1843973936430338 | validation: 0.4613800594325033]
	TIME [epoch: 16.6 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3125638701919196		[learning rate: 0.0062576]
	Learning Rate: 0.00625764
	LOSS [training: 0.3125638701919196 | validation: 0.41840954341894077]
	TIME [epoch: 16.5 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2227981840864788		[learning rate: 0.0062281]
	Learning Rate: 0.00622815
	LOSS [training: 0.2227981840864788 | validation: 0.35165732883407275]
	TIME [epoch: 16.6 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22882942437315706		[learning rate: 0.0061988]
	Learning Rate: 0.0061988
	LOSS [training: 0.22882942437315706 | validation: 0.36847146425765653]
	TIME [epoch: 16.5 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18902690442652695		[learning rate: 0.0061696]
	Learning Rate: 0.00616959
	LOSS [training: 0.18902690442652695 | validation: 0.45415024739726445]
	TIME [epoch: 16.6 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1597201424529232		[learning rate: 0.0061405]
	Learning Rate: 0.00614052
	LOSS [training: 0.1597201424529232 | validation: 0.3970919595509092]
	TIME [epoch: 16.5 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16839850490539918		[learning rate: 0.0061116]
	Learning Rate: 0.00611158
	LOSS [training: 0.16839850490539918 | validation: 0.3313368698852198]
	TIME [epoch: 16.6 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15119849185943743		[learning rate: 0.0060828]
	Learning Rate: 0.00608279
	LOSS [training: 0.15119849185943743 | validation: 0.3627821775223939]
	TIME [epoch: 16.6 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14700689829848393		[learning rate: 0.0060541]
	Learning Rate: 0.00605412
	LOSS [training: 0.14700689829848393 | validation: 0.32777773710613345]
	TIME [epoch: 16.6 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14041249184976745		[learning rate: 0.0060256]
	Learning Rate: 0.0060256
	LOSS [training: 0.14041249184976745 | validation: 0.3058468214850204]
	TIME [epoch: 16.6 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15030955673739438		[learning rate: 0.0059972]
	Learning Rate: 0.0059972
	LOSS [training: 0.15030955673739438 | validation: 0.3023723495204075]
	TIME [epoch: 16.5 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13920448986038328		[learning rate: 0.0059689]
	Learning Rate: 0.00596894
	LOSS [training: 0.13920448986038328 | validation: 0.4401701157619031]
	TIME [epoch: 16.6 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16044074565393712		[learning rate: 0.0059408]
	Learning Rate: 0.00594082
	LOSS [training: 0.16044074565393712 | validation: 0.34100267986223304]
	TIME [epoch: 16.5 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1524917006529095		[learning rate: 0.0059128]
	Learning Rate: 0.00591282
	LOSS [training: 0.1524917006529095 | validation: 0.3400792558628183]
	TIME [epoch: 16.6 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15356161102416077		[learning rate: 0.005885]
	Learning Rate: 0.00588496
	LOSS [training: 0.15356161102416077 | validation: 0.311161853864715]
	TIME [epoch: 16.5 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14709195509655948		[learning rate: 0.0058572]
	Learning Rate: 0.00585723
	LOSS [training: 0.14709195509655948 | validation: 0.5189070774420875]
	TIME [epoch: 16.6 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.148802435759292		[learning rate: 0.0058296]
	Learning Rate: 0.00582963
	LOSS [training: 0.148802435759292 | validation: 0.3188689380990798]
	TIME [epoch: 16.5 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14164009743802314		[learning rate: 0.0058022]
	Learning Rate: 0.00580216
	LOSS [training: 0.14164009743802314 | validation: 0.36886736974763884]
	TIME [epoch: 16.6 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1375883135851553		[learning rate: 0.0057748]
	Learning Rate: 0.00577482
	LOSS [training: 0.1375883135851553 | validation: 0.2954751943371446]
	TIME [epoch: 16.5 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14614396062533552		[learning rate: 0.0057476]
	Learning Rate: 0.00574761
	LOSS [training: 0.14614396062533552 | validation: 0.3094908882533324]
	TIME [epoch: 16.5 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1415956616596507		[learning rate: 0.0057205]
	Learning Rate: 0.00572052
	LOSS [training: 0.1415956616596507 | validation: 0.3053582216177717]
	TIME [epoch: 16.5 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15878633539764483		[learning rate: 0.0056936]
	Learning Rate: 0.00569357
	LOSS [training: 0.15878633539764483 | validation: 0.32422718941091594]
	TIME [epoch: 16.5 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15671396666259182		[learning rate: 0.0056667]
	Learning Rate: 0.00566674
	LOSS [training: 0.15671396666259182 | validation: 0.32123216014370615]
	TIME [epoch: 16.6 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17142437273317118		[learning rate: 0.00564]
	Learning Rate: 0.00564004
	LOSS [training: 0.17142437273317118 | validation: 0.3145497906431721]
	TIME [epoch: 16.5 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15765333430354014		[learning rate: 0.0056135]
	Learning Rate: 0.00561346
	LOSS [training: 0.15765333430354014 | validation: 0.34183320373165654]
	TIME [epoch: 16.6 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14203202788698893		[learning rate: 0.005587]
	Learning Rate: 0.00558701
	LOSS [training: 0.14203202788698893 | validation: 0.30360233297483397]
	TIME [epoch: 16.5 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15749788977749318		[learning rate: 0.0055607]
	Learning Rate: 0.00556068
	LOSS [training: 0.15749788977749318 | validation: 0.33070292547247837]
	TIME [epoch: 16.6 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1541718802462404		[learning rate: 0.0055345]
	Learning Rate: 0.00553448
	LOSS [training: 0.1541718802462404 | validation: 0.4519685568216125]
	TIME [epoch: 16.5 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1553240088347979		[learning rate: 0.0055084]
	Learning Rate: 0.0055084
	LOSS [training: 0.1553240088347979 | validation: 0.31573314028521005]
	TIME [epoch: 16.6 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14443457349001745		[learning rate: 0.0054824]
	Learning Rate: 0.00548245
	LOSS [training: 0.14443457349001745 | validation: 0.37527885790120785]
	TIME [epoch: 16.6 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14021157897098574		[learning rate: 0.0054566]
	Learning Rate: 0.00545661
	LOSS [training: 0.14021157897098574 | validation: 0.39680138747746324]
	TIME [epoch: 16.5 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14531404145855967		[learning rate: 0.0054309]
	Learning Rate: 0.0054309
	LOSS [training: 0.14531404145855967 | validation: 0.35139839498331216]
	TIME [epoch: 16.5 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13799058722387886		[learning rate: 0.0054053]
	Learning Rate: 0.00540531
	LOSS [training: 0.13799058722387886 | validation: 0.3534380883536177]
	TIME [epoch: 16.5 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13815245967062892		[learning rate: 0.0053798]
	Learning Rate: 0.00537984
	LOSS [training: 0.13815245967062892 | validation: 0.3788420732665535]
	TIME [epoch: 16.6 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21762469760233472		[learning rate: 0.0053545]
	Learning Rate: 0.00535449
	LOSS [training: 0.21762469760233472 | validation: 0.4529049293005851]
	TIME [epoch: 16.5 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1739326755784336		[learning rate: 0.0053293]
	Learning Rate: 0.00532926
	LOSS [training: 0.1739326755784336 | validation: 0.38289058118266084]
	TIME [epoch: 16.5 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15150231518236884		[learning rate: 0.0053041]
	Learning Rate: 0.00530415
	LOSS [training: 0.15150231518236884 | validation: 0.3477663515187871]
	TIME [epoch: 16.5 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14514366358538555		[learning rate: 0.0052792]
	Learning Rate: 0.00527915
	LOSS [training: 0.14514366358538555 | validation: 0.30798395335117756]
	TIME [epoch: 16.6 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15546778775156		[learning rate: 0.0052543]
	Learning Rate: 0.00525428
	LOSS [training: 0.15546778775156 | validation: 0.3206486090433137]
	TIME [epoch: 16.5 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13500870881295735		[learning rate: 0.0052295]
	Learning Rate: 0.00522952
	LOSS [training: 0.13500870881295735 | validation: 0.31125484522575775]
	TIME [epoch: 16.5 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1557060629198298		[learning rate: 0.0052049]
	Learning Rate: 0.00520487
	LOSS [training: 0.1557060629198298 | validation: 0.3675103747888785]
	TIME [epoch: 16.5 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14528641633803638		[learning rate: 0.0051803]
	Learning Rate: 0.00518035
	LOSS [training: 0.14528641633803638 | validation: 0.35903026111575503]
	TIME [epoch: 16.5 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16848445685446561		[learning rate: 0.0051559]
	Learning Rate: 0.00515594
	LOSS [training: 0.16848445685446561 | validation: 0.541131824101098]
	TIME [epoch: 16.5 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1864818834716066		[learning rate: 0.0051316]
	Learning Rate: 0.00513164
	LOSS [training: 0.1864818834716066 | validation: 0.36889724794893786]
	TIME [epoch: 16.5 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1480673925116865		[learning rate: 0.0051075]
	Learning Rate: 0.00510746
	LOSS [training: 0.1480673925116865 | validation: 0.32002146820699107]
	TIME [epoch: 16.6 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13818894544537735		[learning rate: 0.0050834]
	Learning Rate: 0.00508339
	LOSS [training: 0.13818894544537735 | validation: 0.3411476045339572]
	TIME [epoch: 16.5 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13946303610426244		[learning rate: 0.0050594]
	Learning Rate: 0.00505944
	LOSS [training: 0.13946303610426244 | validation: 0.4140343844374553]
	TIME [epoch: 16.5 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1508377280024259		[learning rate: 0.0050356]
	Learning Rate: 0.0050356
	LOSS [training: 0.1508377280024259 | validation: 0.3847781809155607]
	TIME [epoch: 16.5 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1663411488570047		[learning rate: 0.0050119]
	Learning Rate: 0.00501187
	LOSS [training: 0.1663411488570047 | validation: 0.3552060844773979]
	TIME [epoch: 16.6 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13577230574857696		[learning rate: 0.0049883]
	Learning Rate: 0.00498826
	LOSS [training: 0.13577230574857696 | validation: 0.37503689484676006]
	TIME [epoch: 16.5 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13627244638577773		[learning rate: 0.0049648]
	Learning Rate: 0.00496475
	LOSS [training: 0.13627244638577773 | validation: 0.37108976178024]
	TIME [epoch: 16.6 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15257254369473822		[learning rate: 0.0049414]
	Learning Rate: 0.00494136
	LOSS [training: 0.15257254369473822 | validation: 0.30006212521786507]
	TIME [epoch: 16.5 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1308482137174482		[learning rate: 0.0049181]
	Learning Rate: 0.00491807
	LOSS [training: 0.1308482137174482 | validation: 0.3049412769920565]
	TIME [epoch: 16.5 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15064740522625636		[learning rate: 0.0048949]
	Learning Rate: 0.0048949
	LOSS [training: 0.15064740522625636 | validation: 0.341976358076967]
	TIME [epoch: 16.5 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16044668123187802		[learning rate: 0.0048718]
	Learning Rate: 0.00487183
	LOSS [training: 0.16044668123187802 | validation: 0.3691308817283771]
	TIME [epoch: 16.5 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17539162529552638		[learning rate: 0.0048489]
	Learning Rate: 0.00484888
	LOSS [training: 0.17539162529552638 | validation: 0.35868023634352275]
	TIME [epoch: 16.5 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12939024813754788		[learning rate: 0.004826]
	Learning Rate: 0.00482603
	LOSS [training: 0.12939024813754788 | validation: 0.3648849304099948]
	TIME [epoch: 16.5 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.146051652403329		[learning rate: 0.0048033]
	Learning Rate: 0.00480329
	LOSS [training: 0.146051652403329 | validation: 0.45737286434648045]
	TIME [epoch: 16.5 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17395231727961336		[learning rate: 0.0047807]
	Learning Rate: 0.00478065
	LOSS [training: 0.17395231727961336 | validation: 0.30808157834933814]
	TIME [epoch: 16.5 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1401330445282743		[learning rate: 0.0047581]
	Learning Rate: 0.00475813
	LOSS [training: 0.1401330445282743 | validation: 0.33421470823838684]
	TIME [epoch: 16.5 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11241972185415243		[learning rate: 0.0047357]
	Learning Rate: 0.0047357
	LOSS [training: 0.11241972185415243 | validation: 0.32239967726735663]
	TIME [epoch: 16.5 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13108539831945576		[learning rate: 0.0047134]
	Learning Rate: 0.00471339
	LOSS [training: 0.13108539831945576 | validation: 0.31599282029354114]
	TIME [epoch: 16.6 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13727344524317162		[learning rate: 0.0046912]
	Learning Rate: 0.00469118
	LOSS [training: 0.13727344524317162 | validation: 0.35976534801847615]
	TIME [epoch: 16.5 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15881858748271138		[learning rate: 0.0046691]
	Learning Rate: 0.00466907
	LOSS [training: 0.15881858748271138 | validation: 0.33186546736350486]
	TIME [epoch: 16.6 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13997284944706365		[learning rate: 0.0046471]
	Learning Rate: 0.00464707
	LOSS [training: 0.13997284944706365 | validation: 0.3818427263941538]
	TIME [epoch: 16.6 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14224185105050774		[learning rate: 0.0046252]
	Learning Rate: 0.00462518
	LOSS [training: 0.14224185105050774 | validation: 0.3235064866652941]
	TIME [epoch: 60 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1484753638216796		[learning rate: 0.0046034]
	Learning Rate: 0.00460338
	LOSS [training: 0.1484753638216796 | validation: 0.33046883662301135]
	TIME [epoch: 35.6 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1979555870717521		[learning rate: 0.0045817]
	Learning Rate: 0.00458169
	LOSS [training: 0.1979555870717521 | validation: 0.33591584824804643]
	TIME [epoch: 35.6 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13786912400022047		[learning rate: 0.0045601]
	Learning Rate: 0.0045601
	LOSS [training: 0.13786912400022047 | validation: 0.3653549249846064]
	TIME [epoch: 35.6 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1467835483062096		[learning rate: 0.0045386]
	Learning Rate: 0.00453861
	LOSS [training: 0.1467835483062096 | validation: 0.3073580481502024]
	TIME [epoch: 35.6 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12773463502674973		[learning rate: 0.0045172]
	Learning Rate: 0.00451723
	LOSS [training: 0.12773463502674973 | validation: 0.36281392687821734]
	TIME [epoch: 35.6 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15034517274276832		[learning rate: 0.0044959]
	Learning Rate: 0.00449594
	LOSS [training: 0.15034517274276832 | validation: 0.318686863972093]
	TIME [epoch: 35.6 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1354514746687106		[learning rate: 0.0044748]
	Learning Rate: 0.00447475
	LOSS [training: 0.1354514746687106 | validation: 0.3497318061701178]
	TIME [epoch: 35.6 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15135453463544415		[learning rate: 0.0044537]
	Learning Rate: 0.00445367
	LOSS [training: 0.15135453463544415 | validation: 0.29570545460015873]
	TIME [epoch: 35.6 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13201537878162503		[learning rate: 0.0044327]
	Learning Rate: 0.00443268
	LOSS [training: 0.13201537878162503 | validation: 0.31223779217483827]
	TIME [epoch: 35.6 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13491904236607877		[learning rate: 0.0044118]
	Learning Rate: 0.0044118
	LOSS [training: 0.13491904236607877 | validation: 0.3324719292042342]
	TIME [epoch: 35.6 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1462625757931317		[learning rate: 0.004391]
	Learning Rate: 0.00439101
	LOSS [training: 0.1462625757931317 | validation: 0.30486800565445243]
	TIME [epoch: 35.6 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17043985481943266		[learning rate: 0.0043703]
	Learning Rate: 0.00437032
	LOSS [training: 0.17043985481943266 | validation: 0.31791910174591254]
	TIME [epoch: 35.6 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1536687844608039		[learning rate: 0.0043497]
	Learning Rate: 0.00434972
	LOSS [training: 0.1536687844608039 | validation: 0.3079753160046558]
	TIME [epoch: 35.6 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1468808392404896		[learning rate: 0.0043292]
	Learning Rate: 0.00432923
	LOSS [training: 0.1468808392404896 | validation: 0.33716172734783145]
	TIME [epoch: 35.6 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14628333517804115		[learning rate: 0.0043088]
	Learning Rate: 0.00430883
	LOSS [training: 0.14628333517804115 | validation: 0.3486528518009181]
	TIME [epoch: 35.6 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12178575582940952		[learning rate: 0.0042885]
	Learning Rate: 0.00428852
	LOSS [training: 0.12178575582940952 | validation: 0.31847623469547337]
	TIME [epoch: 35.6 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18033548921115272		[learning rate: 0.0042683]
	Learning Rate: 0.00426831
	LOSS [training: 0.18033548921115272 | validation: 0.3027323505724189]
	TIME [epoch: 35.6 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14183283692780024		[learning rate: 0.0042482]
	Learning Rate: 0.0042482
	LOSS [training: 0.14183283692780024 | validation: 0.3006841210488749]
	TIME [epoch: 35.5 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13477568972255968		[learning rate: 0.0042282]
	Learning Rate: 0.00422818
	LOSS [training: 0.13477568972255968 | validation: 0.3487469523843423]
	TIME [epoch: 35.6 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14486761237824988		[learning rate: 0.0042083]
	Learning Rate: 0.00420826
	LOSS [training: 0.14486761237824988 | validation: 0.3885297375330303]
	TIME [epoch: 35.6 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12992902524756023		[learning rate: 0.0041884]
	Learning Rate: 0.00418843
	LOSS [training: 0.12992902524756023 | validation: 0.33662737342837384]
	TIME [epoch: 35.6 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13408134753541365		[learning rate: 0.0041687]
	Learning Rate: 0.00416869
	LOSS [training: 0.13408134753541365 | validation: 0.2903867182314955]
	TIME [epoch: 35.6 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v14b_20240718_174651/states/model_facs_v4_dec2b_2dpca_v14b_223.pth
	Model improved!!!
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12487082100497521		[learning rate: 0.0041491]
	Learning Rate: 0.00414905
	LOSS [training: 0.12487082100497521 | validation: 0.3182016031562843]
	TIME [epoch: 35.6 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12231234049957906		[learning rate: 0.0041295]
	Learning Rate: 0.0041295
	LOSS [training: 0.12231234049957906 | validation: 0.3353642418541407]
	TIME [epoch: 35.6 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1520307337807531		[learning rate: 0.00411]
	Learning Rate: 0.00411004
	LOSS [training: 0.1520307337807531 | validation: 0.3807563581208252]
	TIME [epoch: 35.6 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1452815818543367		[learning rate: 0.0040907]
	Learning Rate: 0.00409067
	LOSS [training: 0.1452815818543367 | validation: 0.3668857373042025]
	TIME [epoch: 35.6 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16181214770065863		[learning rate: 0.0040714]
	Learning Rate: 0.0040714
	LOSS [training: 0.16181214770065863 | validation: 0.3806982956791386]
	TIME [epoch: 35.6 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14614407357473766		[learning rate: 0.0040522]
	Learning Rate: 0.00405221
	LOSS [training: 0.14614407357473766 | validation: 0.3316261874062544]
	TIME [epoch: 35.6 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1584785354619185		[learning rate: 0.0040331]
	Learning Rate: 0.00403312
	LOSS [training: 0.1584785354619185 | validation: 0.3634763824996003]
	TIME [epoch: 35.6 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18668479321637588		[learning rate: 0.0040141]
	Learning Rate: 0.00401411
	LOSS [training: 0.18668479321637588 | validation: 0.3101297009818116]
	TIME [epoch: 35.6 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15425303752080383		[learning rate: 0.0039952]
	Learning Rate: 0.0039952
	LOSS [training: 0.15425303752080383 | validation: 0.291862523611618]
	TIME [epoch: 35.6 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15202372011579696		[learning rate: 0.0039764]
	Learning Rate: 0.00397637
	LOSS [training: 0.15202372011579696 | validation: 0.3519022182202858]
	TIME [epoch: 35.6 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16584564638015337		[learning rate: 0.0039576]
	Learning Rate: 0.00395764
	LOSS [training: 0.16584564638015337 | validation: 0.307163426100886]
	TIME [epoch: 35.6 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16827083336677623		[learning rate: 0.003939]
	Learning Rate: 0.00393899
	LOSS [training: 0.16827083336677623 | validation: 0.31459394889790254]
	TIME [epoch: 35.6 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13834088966811448		[learning rate: 0.0039204]
	Learning Rate: 0.00392043
	LOSS [training: 0.13834088966811448 | validation: 0.34457394933914753]
	TIME [epoch: 35.6 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12640916102527097		[learning rate: 0.003902]
	Learning Rate: 0.00390195
	LOSS [training: 0.12640916102527097 | validation: 0.3938691750414015]
	TIME [epoch: 35.6 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12857450087525263		[learning rate: 0.0038836]
	Learning Rate: 0.00388357
	LOSS [training: 0.12857450087525263 | validation: 0.33385059017998653]
	TIME [epoch: 35.6 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16326137953816472		[learning rate: 0.0038653]
	Learning Rate: 0.00386527
	LOSS [training: 0.16326137953816472 | validation: 0.32101537230984456]
	TIME [epoch: 35.6 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16179313591825198		[learning rate: 0.0038471]
	Learning Rate: 0.00384705
	LOSS [training: 0.16179313591825198 | validation: 0.3069400364300853]
	TIME [epoch: 35.6 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1370720314116138		[learning rate: 0.0038289]
	Learning Rate: 0.00382893
	LOSS [training: 0.1370720314116138 | validation: 0.29975526089747473]
	TIME [epoch: 35.6 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17324225397440823		[learning rate: 0.0038109]
	Learning Rate: 0.00381088
	LOSS [training: 0.17324225397440823 | validation: 0.3222576701485412]
	TIME [epoch: 35.6 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13200280034260176		[learning rate: 0.0037929]
	Learning Rate: 0.00379293
	LOSS [training: 0.13200280034260176 | validation: 0.2973549282177803]
	TIME [epoch: 35.6 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13325108816229136		[learning rate: 0.0037751]
	Learning Rate: 0.00377505
	LOSS [training: 0.13325108816229136 | validation: 0.3342735719335233]
	TIME [epoch: 35.6 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14630825966268143		[learning rate: 0.0037573]
	Learning Rate: 0.00375726
	LOSS [training: 0.14630825966268143 | validation: 0.38091384031106185]
	TIME [epoch: 35.6 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1346314421594894		[learning rate: 0.0037396]
	Learning Rate: 0.00373956
	LOSS [training: 0.1346314421594894 | validation: 0.3351599048053163]
	TIME [epoch: 35.6 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1420815465508432		[learning rate: 0.0037219]
	Learning Rate: 0.00372194
	LOSS [training: 0.1420815465508432 | validation: 0.3286290651906326]
	TIME [epoch: 35.6 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12396509585056185		[learning rate: 0.0037044]
	Learning Rate: 0.0037044
	LOSS [training: 0.12396509585056185 | validation: 0.3031201481657096]
	TIME [epoch: 35.6 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1270428858080235		[learning rate: 0.0036869]
	Learning Rate: 0.00368695
	LOSS [training: 0.1270428858080235 | validation: 0.31893642226694974]
	TIME [epoch: 35.6 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13507770888257503		[learning rate: 0.0036696]
	Learning Rate: 0.00366957
	LOSS [training: 0.13507770888257503 | validation: 0.30178296724659875]
	TIME [epoch: 35.6 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13378836106098602		[learning rate: 0.0036523]
	Learning Rate: 0.00365228
	LOSS [training: 0.13378836106098602 | validation: 0.3427101181918945]
	TIME [epoch: 35.6 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13419387422034976		[learning rate: 0.0036351]
	Learning Rate: 0.00363507
	LOSS [training: 0.13419387422034976 | validation: 0.4043904862435121]
	TIME [epoch: 35.6 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14301643551666435		[learning rate: 0.0036179]
	Learning Rate: 0.00361794
	LOSS [training: 0.14301643551666435 | validation: 0.2933512369625945]
	TIME [epoch: 35.6 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12313827190833383		[learning rate: 0.0036009]
	Learning Rate: 0.00360089
	LOSS [training: 0.12313827190833383 | validation: 0.36249854074693433]
	TIME [epoch: 35.6 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1287119744325348		[learning rate: 0.0035839]
	Learning Rate: 0.00358393
	LOSS [training: 0.1287119744325348 | validation: 0.3137445615506106]
	TIME [epoch: 35.6 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12176760190415806		[learning rate: 0.003567]
	Learning Rate: 0.00356704
	LOSS [training: 0.12176760190415806 | validation: 0.3001156199543159]
	TIME [epoch: 35.6 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1234051635588507		[learning rate: 0.0035502]
	Learning Rate: 0.00355023
	LOSS [training: 0.1234051635588507 | validation: 0.3267427100609052]
	TIME [epoch: 35.6 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12422168775529654		[learning rate: 0.0035335]
	Learning Rate: 0.0035335
	LOSS [training: 0.12422168775529654 | validation: 0.36754518878326664]
	TIME [epoch: 35.6 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12702429526883863		[learning rate: 0.0035168]
	Learning Rate: 0.00351685
	LOSS [training: 0.12702429526883863 | validation: 0.3592391781695425]
	TIME [epoch: 35.6 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12143382489612388		[learning rate: 0.0035003]
	Learning Rate: 0.00350028
	LOSS [training: 0.12143382489612388 | validation: 0.35039177294254975]
	TIME [epoch: 35.6 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11223733271044442		[learning rate: 0.0034838]
	Learning Rate: 0.00348378
	LOSS [training: 0.11223733271044442 | validation: 0.32761244920916416]
	TIME [epoch: 35.6 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12392808842610789		[learning rate: 0.0034674]
	Learning Rate: 0.00346737
	LOSS [training: 0.12392808842610789 | validation: 0.3055704386603275]
	TIME [epoch: 35.6 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1410989172959886		[learning rate: 0.003451]
	Learning Rate: 0.00345103
	LOSS [training: 0.1410989172959886 | validation: 0.3089720973641473]
	TIME [epoch: 35.6 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12617038022878133		[learning rate: 0.0034348]
	Learning Rate: 0.00343477
	LOSS [training: 0.12617038022878133 | validation: 0.3335818838247305]
	TIME [epoch: 35.6 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1647532803797837		[learning rate: 0.0034186]
	Learning Rate: 0.00341858
	LOSS [training: 0.1647532803797837 | validation: 0.31127881841773086]
	TIME [epoch: 35.6 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11775022639735958		[learning rate: 0.0034025]
	Learning Rate: 0.00340247
	LOSS [training: 0.11775022639735958 | validation: 0.3256528228056901]
	TIME [epoch: 35.6 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11956103008115952		[learning rate: 0.0033864]
	Learning Rate: 0.00338644
	LOSS [training: 0.11956103008115952 | validation: 0.3219693703467774]
	TIME [epoch: 35.6 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11984978217686812		[learning rate: 0.0033705]
	Learning Rate: 0.00337048
	LOSS [training: 0.11984978217686812 | validation: 0.34696518934624304]
	TIME [epoch: 35.6 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13555955297765335		[learning rate: 0.0033546]
	Learning Rate: 0.0033546
	LOSS [training: 0.13555955297765335 | validation: 0.30458078317336107]
	TIME [epoch: 35.6 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11987263526348799		[learning rate: 0.0033388]
	Learning Rate: 0.00333879
	LOSS [training: 0.11987263526348799 | validation: 0.30767259821795473]
	TIME [epoch: 35.6 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11489760329787607		[learning rate: 0.0033231]
	Learning Rate: 0.00332306
	LOSS [training: 0.11489760329787607 | validation: 0.2805373193374622]
	TIME [epoch: 35.6 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v14b_20240718_174651/states/model_facs_v4_dec2b_2dpca_v14b_271.pth
	Model improved!!!
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12659884070439556		[learning rate: 0.0033074]
	Learning Rate: 0.0033074
	LOSS [training: 0.12659884070439556 | validation: 0.28281514696623605]
	TIME [epoch: 35.6 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11622513222368641		[learning rate: 0.0032918]
	Learning Rate: 0.00329182
	LOSS [training: 0.11622513222368641 | validation: 0.31147245293590836]
	TIME [epoch: 35.6 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12886649871131367		[learning rate: 0.0032763]
	Learning Rate: 0.00327631
	LOSS [training: 0.12886649871131367 | validation: 0.31781993753341786]
	TIME [epoch: 35.5 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13040168776861696		[learning rate: 0.0032609]
	Learning Rate: 0.00326087
	LOSS [training: 0.13040168776861696 | validation: 0.3203095910198686]
	TIME [epoch: 35.6 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11040733869397579		[learning rate: 0.0032455]
	Learning Rate: 0.0032455
	LOSS [training: 0.11040733869397579 | validation: 0.3278745838940193]
	TIME [epoch: 35.6 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1338953102143689		[learning rate: 0.0032302]
	Learning Rate: 0.00323021
	LOSS [training: 0.1338953102143689 | validation: 0.37518511631903323]
	TIME [epoch: 35.6 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15940840392081246		[learning rate: 0.003215]
	Learning Rate: 0.00321499
	LOSS [training: 0.15940840392081246 | validation: 0.3864104215122947]
	TIME [epoch: 35.5 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13714615502362387		[learning rate: 0.0031998]
	Learning Rate: 0.00319984
	LOSS [training: 0.13714615502362387 | validation: 0.2953204346224422]
	TIME [epoch: 35.6 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14304101173639033		[learning rate: 0.0031848]
	Learning Rate: 0.00318476
	LOSS [training: 0.14304101173639033 | validation: 0.31103547712466867]
	TIME [epoch: 35.6 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12490876313377408		[learning rate: 0.0031698]
	Learning Rate: 0.00316975
	LOSS [training: 0.12490876313377408 | validation: 0.35180795578898877]
	TIME [epoch: 35.5 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12387861560150852		[learning rate: 0.0031548]
	Learning Rate: 0.00315482
	LOSS [training: 0.12387861560150852 | validation: 0.30230058308362495]
	TIME [epoch: 35.5 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15550862068345786		[learning rate: 0.00314]
	Learning Rate: 0.00313995
	LOSS [training: 0.15550862068345786 | validation: 0.3054682189900849]
	TIME [epoch: 35.6 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1576417642937		[learning rate: 0.0031252]
	Learning Rate: 0.00312516
	LOSS [training: 0.1576417642937 | validation: 0.3759520175765157]
	TIME [epoch: 35.5 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13327882167093083		[learning rate: 0.0031104]
	Learning Rate: 0.00311043
	LOSS [training: 0.13327882167093083 | validation: 0.3444174870804593]
	TIME [epoch: 35.6 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13271967320092262		[learning rate: 0.0030958]
	Learning Rate: 0.00309577
	LOSS [training: 0.13271967320092262 | validation: 0.343686550637048]
	TIME [epoch: 35.6 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12308881239762083		[learning rate: 0.0030812]
	Learning Rate: 0.00308119
	LOSS [training: 0.12308881239762083 | validation: 0.29064970705445203]
	TIME [epoch: 35.6 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13182167015622254		[learning rate: 0.0030667]
	Learning Rate: 0.00306667
	LOSS [training: 0.13182167015622254 | validation: 0.34298437691687406]
	TIME [epoch: 35.6 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14574423014741733		[learning rate: 0.0030522]
	Learning Rate: 0.00305222
	LOSS [training: 0.14574423014741733 | validation: 0.3516448645541288]
	TIME [epoch: 35.6 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13176323563555284		[learning rate: 0.0030378]
	Learning Rate: 0.00303783
	LOSS [training: 0.13176323563555284 | validation: 0.2868848383366342]
	TIME [epoch: 35.6 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14961623264801868		[learning rate: 0.0030235]
	Learning Rate: 0.00302352
	LOSS [training: 0.14961623264801868 | validation: 0.32276378239371745]
	TIME [epoch: 35.6 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12766944921651763		[learning rate: 0.0030093]
	Learning Rate: 0.00300927
	LOSS [training: 0.12766944921651763 | validation: 0.3670162632541841]
	TIME [epoch: 35.5 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13854370670964503		[learning rate: 0.0029951]
	Learning Rate: 0.00299509
	LOSS [training: 0.13854370670964503 | validation: 0.32759260507209054]
	TIME [epoch: 35.5 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11360907299007009		[learning rate: 0.002981]
	Learning Rate: 0.00298098
	LOSS [training: 0.11360907299007009 | validation: 0.2963182411855845]
	TIME [epoch: 35.6 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11917119823395284		[learning rate: 0.0029669]
	Learning Rate: 0.00296693
	LOSS [training: 0.11917119823395284 | validation: 0.34628702958800384]
	TIME [epoch: 35.6 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14949637257980758		[learning rate: 0.002953]
	Learning Rate: 0.00295295
	LOSS [training: 0.14949637257980758 | validation: 0.3645491378156975]
	TIME [epoch: 35.5 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11834405141564767		[learning rate: 0.002939]
	Learning Rate: 0.00293904
	LOSS [training: 0.11834405141564767 | validation: 0.3358133529655218]
	TIME [epoch: 35.6 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14567424515617727		[learning rate: 0.0029252]
	Learning Rate: 0.00292519
	LOSS [training: 0.14567424515617727 | validation: 0.31310216230967425]
	TIME [epoch: 35.6 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15984770246675128		[learning rate: 0.0029114]
	Learning Rate: 0.0029114
	LOSS [training: 0.15984770246675128 | validation: 0.31471637766150307]
	TIME [epoch: 35.6 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1303961003434531		[learning rate: 0.0028977]
	Learning Rate: 0.00289769
	LOSS [training: 0.1303961003434531 | validation: 0.2876452660517631]
	TIME [epoch: 35.6 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1264906267129863		[learning rate: 0.002884]
	Learning Rate: 0.00288403
	LOSS [training: 0.1264906267129863 | validation: 0.2946144512223332]
	TIME [epoch: 98.1 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13654859933379404		[learning rate: 0.0028704]
	Learning Rate: 0.00287044
	LOSS [training: 0.13654859933379404 | validation: 0.3343004328819851]
	TIME [epoch: 73.6 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12359391198802111		[learning rate: 0.0028569]
	Learning Rate: 0.00285692
	LOSS [training: 0.12359391198802111 | validation: 0.3171722805597223]
	TIME [epoch: 73.6 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12355622390557826		[learning rate: 0.0028435]
	Learning Rate: 0.00284345
	LOSS [training: 0.12355622390557826 | validation: 0.3341860490521795]
	TIME [epoch: 73.6 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14571611374527094		[learning rate: 0.0028301]
	Learning Rate: 0.00283005
	LOSS [training: 0.14571611374527094 | validation: 0.33810078231831764]
	TIME [epoch: 73.6 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14022558662632206		[learning rate: 0.0028167]
	Learning Rate: 0.00281672
	LOSS [training: 0.14022558662632206 | validation: 0.3083973198014183]
	TIME [epoch: 73.6 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11830672410631007		[learning rate: 0.0028034]
	Learning Rate: 0.00280345
	LOSS [training: 0.11830672410631007 | validation: 0.2919338898716468]
	TIME [epoch: 73.6 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1268951097250488		[learning rate: 0.0027902]
	Learning Rate: 0.00279024
	LOSS [training: 0.1268951097250488 | validation: 0.32927884482664294]
	TIME [epoch: 73.6 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13059651194968924		[learning rate: 0.0027771]
	Learning Rate: 0.00277709
	LOSS [training: 0.13059651194968924 | validation: 0.3466253096647347]
	TIME [epoch: 73.6 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.136172708588288		[learning rate: 0.002764]
	Learning Rate: 0.002764
	LOSS [training: 0.136172708588288 | validation: 0.33887396324355196]
	TIME [epoch: 73.6 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1442941732125629		[learning rate: 0.002751]
	Learning Rate: 0.00275098
	LOSS [training: 0.1442941732125629 | validation: 0.2940422776461732]
	TIME [epoch: 73.6 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12175820923655031		[learning rate: 0.002738]
	Learning Rate: 0.00273802
	LOSS [training: 0.12175820923655031 | validation: 0.27528591699120253]
	TIME [epoch: 73.6 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v14b_20240718_174651/states/model_facs_v4_dec2b_2dpca_v14b_312.pth
	Model improved!!!
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1335887128745372		[learning rate: 0.0027251]
	Learning Rate: 0.00272511
	LOSS [training: 0.1335887128745372 | validation: 0.3370306917414277]
	TIME [epoch: 73.6 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12615702841450344		[learning rate: 0.0027123]
	Learning Rate: 0.00271227
	LOSS [training: 0.12615702841450344 | validation: 0.2944225555345779]
	TIME [epoch: 73.5 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1322954447204733		[learning rate: 0.0026995]
	Learning Rate: 0.00269949
	LOSS [training: 0.1322954447204733 | validation: 0.3169818507308977]
	TIME [epoch: 73.5 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13339095550838478		[learning rate: 0.0026868]
	Learning Rate: 0.00268677
	LOSS [training: 0.13339095550838478 | validation: 0.30038995718122247]
	TIME [epoch: 73.5 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12754118027693478		[learning rate: 0.0026741]
	Learning Rate: 0.00267411
	LOSS [training: 0.12754118027693478 | validation: 0.3380248614476894]
	TIME [epoch: 73.5 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11989392818773173		[learning rate: 0.0026615]
	Learning Rate: 0.00266151
	LOSS [training: 0.11989392818773173 | validation: 0.333012169630515]
	TIME [epoch: 73.5 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12510564592549459		[learning rate: 0.002649]
	Learning Rate: 0.00264897
	LOSS [training: 0.12510564592549459 | validation: 0.387757349125459]
	TIME [epoch: 73.5 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13746887582863693		[learning rate: 0.0026365]
	Learning Rate: 0.00263649
	LOSS [training: 0.13746887582863693 | validation: 0.3647724327575319]
	TIME [epoch: 73.5 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13098497289815306		[learning rate: 0.0026241]
	Learning Rate: 0.00262406
	LOSS [training: 0.13098497289815306 | validation: 0.3015886506480943]
	TIME [epoch: 73.5 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15492449290864635		[learning rate: 0.0026117]
	Learning Rate: 0.0026117
	LOSS [training: 0.15492449290864635 | validation: 0.3190078236269747]
	TIME [epoch: 73.5 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13063644614231942		[learning rate: 0.0025994]
	Learning Rate: 0.00259939
	LOSS [training: 0.13063644614231942 | validation: 0.33416546084620374]
	TIME [epoch: 73.5 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12100427639917465		[learning rate: 0.0025871]
	Learning Rate: 0.00258714
	LOSS [training: 0.12100427639917465 | validation: 0.3232178475011058]
	TIME [epoch: 73.5 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12369276939640378		[learning rate: 0.002575]
	Learning Rate: 0.00257495
	LOSS [training: 0.12369276939640378 | validation: 0.3487200360823492]
	TIME [epoch: 73.5 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12396657929972785		[learning rate: 0.0025628]
	Learning Rate: 0.00256282
	LOSS [training: 0.12396657929972785 | validation: 0.33441572747814197]
	TIME [epoch: 73.5 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14693887640367878		[learning rate: 0.0025507]
	Learning Rate: 0.00255074
	LOSS [training: 0.14693887640367878 | validation: 0.3300563620130645]
	TIME [epoch: 73.5 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12054455845153364		[learning rate: 0.0025387]
	Learning Rate: 0.00253872
	LOSS [training: 0.12054455845153364 | validation: 0.35895525440353093]
	TIME [epoch: 73.5 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1148080228626266		[learning rate: 0.0025268]
	Learning Rate: 0.00252676
	LOSS [training: 0.1148080228626266 | validation: 0.3142707296896575]
	TIME [epoch: 73.5 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13964280960504377		[learning rate: 0.0025149]
	Learning Rate: 0.00251485
	LOSS [training: 0.13964280960504377 | validation: 0.2996492863572399]
	TIME [epoch: 73.5 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1189061208638328		[learning rate: 0.002503]
	Learning Rate: 0.002503
	LOSS [training: 0.1189061208638328 | validation: 0.3060224392104864]
	TIME [epoch: 73.5 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1422804530804074		[learning rate: 0.0024912]
	Learning Rate: 0.00249121
	LOSS [training: 0.1422804530804074 | validation: 0.3082464281121199]
	TIME [epoch: 73.5 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13859539760780665		[learning rate: 0.0024795]
	Learning Rate: 0.00247947
	LOSS [training: 0.13859539760780665 | validation: 0.3010106307428383]
	TIME [epoch: 73.5 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12132844462288256		[learning rate: 0.0024678]
	Learning Rate: 0.00246779
	LOSS [training: 0.12132844462288256 | validation: 0.3432152986043395]
	TIME [epoch: 73.5 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12887683164688452		[learning rate: 0.0024562]
	Learning Rate: 0.00245616
	LOSS [training: 0.12887683164688452 | validation: 0.2893117170970801]
	TIME [epoch: 73.5 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12060310960637273		[learning rate: 0.0024446]
	Learning Rate: 0.00244458
	LOSS [training: 0.12060310960637273 | validation: 0.30328537978433995]
	TIME [epoch: 73.5 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11994627445636111		[learning rate: 0.0024331]
	Learning Rate: 0.00243307
	LOSS [training: 0.11994627445636111 | validation: 0.27571899405368855]
	TIME [epoch: 73.6 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12532991007246386		[learning rate: 0.0024216]
	Learning Rate: 0.0024216
	LOSS [training: 0.12532991007246386 | validation: 0.33932021976679627]
	TIME [epoch: 73.6 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1385773621067069		[learning rate: 0.0024102]
	Learning Rate: 0.00241019
	LOSS [training: 0.1385773621067069 | validation: 0.33552631006471256]
	TIME [epoch: 73.5 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12722511706822795		[learning rate: 0.0023988]
	Learning Rate: 0.00239883
	LOSS [training: 0.12722511706822795 | validation: 0.3677432772469415]
	TIME [epoch: 73.6 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12571375559944262		[learning rate: 0.0023875]
	Learning Rate: 0.00238753
	LOSS [training: 0.12571375559944262 | validation: 0.30787694859773873]
	TIME [epoch: 73.6 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11335246821874972		[learning rate: 0.0023763]
	Learning Rate: 0.00237628
	LOSS [training: 0.11335246821874972 | validation: 0.35475451430916527]
	TIME [epoch: 73.6 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12267821436167702		[learning rate: 0.0023651]
	Learning Rate: 0.00236508
	LOSS [training: 0.12267821436167702 | validation: 0.289770378103147]
	TIME [epoch: 73.5 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13131198690713108		[learning rate: 0.0023539]
	Learning Rate: 0.00235394
	LOSS [training: 0.13131198690713108 | validation: 0.3416972030714182]
	TIME [epoch: 73.6 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12500157911497395		[learning rate: 0.0023428]
	Learning Rate: 0.00234285
	LOSS [training: 0.12500157911497395 | validation: 0.33901912225696074]
	TIME [epoch: 73.6 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1420200070267611		[learning rate: 0.0023318]
	Learning Rate: 0.00233181
	LOSS [training: 0.1420200070267611 | validation: 0.34942998213276627]
	TIME [epoch: 73.6 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13796558526323535		[learning rate: 0.0023208]
	Learning Rate: 0.00232082
	LOSS [training: 0.13796558526323535 | validation: 0.3197738523947813]
	TIME [epoch: 73.6 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13387511163886553		[learning rate: 0.0023099]
	Learning Rate: 0.00230988
	LOSS [training: 0.13387511163886553 | validation: 0.2705797972957923]
	TIME [epoch: 73.6 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v14b_20240718_174651/states/model_facs_v4_dec2b_2dpca_v14b_348.pth
	Model improved!!!
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12373015542688712		[learning rate: 0.002299]
	Learning Rate: 0.002299
	LOSS [training: 0.12373015542688712 | validation: 0.338965638808339]
	TIME [epoch: 73.6 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12940149694825342		[learning rate: 0.0022882]
	Learning Rate: 0.00228816
	LOSS [training: 0.12940149694825342 | validation: 0.3235428637856565]
	TIME [epoch: 73.6 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13947252796335746		[learning rate: 0.0022774]
	Learning Rate: 0.00227738
	LOSS [training: 0.13947252796335746 | validation: 0.2982414208464387]
	TIME [epoch: 73.7 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1125264457318309		[learning rate: 0.0022667]
	Learning Rate: 0.00226665
	LOSS [training: 0.1125264457318309 | validation: 0.343471621698656]
	TIME [epoch: 73.6 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1263850248326504		[learning rate: 0.002256]
	Learning Rate: 0.00225597
	LOSS [training: 0.1263850248326504 | validation: 0.37459610539716603]
	TIME [epoch: 73.6 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11624113674830766		[learning rate: 0.0022453]
	Learning Rate: 0.00224534
	LOSS [training: 0.11624113674830766 | validation: 0.30996227036314056]
	TIME [epoch: 73.6 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1147947476007172		[learning rate: 0.0022348]
	Learning Rate: 0.00223476
	LOSS [training: 0.1147947476007172 | validation: 0.29673451745971896]
	TIME [epoch: 73.6 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14714173776985207		[learning rate: 0.0022242]
	Learning Rate: 0.00222423
	LOSS [training: 0.14714173776985207 | validation: 0.316757558192089]
	TIME [epoch: 73.5 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14233565625367733		[learning rate: 0.0022137]
	Learning Rate: 0.00221375
	LOSS [training: 0.14233565625367733 | validation: 0.33244184173213737]
	TIME [epoch: 73.5 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11610738551614432		[learning rate: 0.0022033]
	Learning Rate: 0.00220332
	LOSS [training: 0.11610738551614432 | validation: 0.2965049023629751]
	TIME [epoch: 73.6 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11051955285808587		[learning rate: 0.0021929]
	Learning Rate: 0.00219293
	LOSS [training: 0.11051955285808587 | validation: 0.2863179954051745]
	TIME [epoch: 73.6 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11400818649289726		[learning rate: 0.0021826]
	Learning Rate: 0.0021826
	LOSS [training: 0.11400818649289726 | validation: 0.3719252528033935]
	TIME [epoch: 73.6 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1290390603848859		[learning rate: 0.0021723]
	Learning Rate: 0.00217232
	LOSS [training: 0.1290390603848859 | validation: 0.31799977842801325]
	TIME [epoch: 73.6 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11009240831068179		[learning rate: 0.0021621]
	Learning Rate: 0.00216208
	LOSS [training: 0.11009240831068179 | validation: 0.29380003713411057]
	TIME [epoch: 73.7 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13001830424573535		[learning rate: 0.0021519]
	Learning Rate: 0.00215189
	LOSS [training: 0.13001830424573535 | validation: 0.29622182591290397]
	TIME [epoch: 73.6 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12834427138377383		[learning rate: 0.0021418]
	Learning Rate: 0.00214175
	LOSS [training: 0.12834427138377383 | validation: 0.3117147566871399]
	TIME [epoch: 73.6 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11894118690332008		[learning rate: 0.0021317]
	Learning Rate: 0.00213166
	LOSS [training: 0.11894118690332008 | validation: 0.29655332655380845]
	TIME [epoch: 73.6 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11228132435174495		[learning rate: 0.0021216]
	Learning Rate: 0.00212162
	LOSS [training: 0.11228132435174495 | validation: 0.2886921795464892]
	TIME [epoch: 73.6 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11457378034662641		[learning rate: 0.0021116]
	Learning Rate: 0.00211162
	LOSS [training: 0.11457378034662641 | validation: 0.2899019736359724]
	TIME [epoch: 73.6 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12916192293297105		[learning rate: 0.0021017]
	Learning Rate: 0.00210167
	LOSS [training: 0.12916192293297105 | validation: 0.3646756310103203]
	TIME [epoch: 73.6 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13956435645273363		[learning rate: 0.0020918]
	Learning Rate: 0.00209176
	LOSS [training: 0.13956435645273363 | validation: 0.3113309023770078]
	TIME [epoch: 73.6 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1397851985683613		[learning rate: 0.0020819]
	Learning Rate: 0.00208191
	LOSS [training: 0.1397851985683613 | validation: 0.30451012893990187]
	TIME [epoch: 73.6 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11552772449895812		[learning rate: 0.0020721]
	Learning Rate: 0.0020721
	LOSS [training: 0.11552772449895812 | validation: 0.28675910835687773]
	TIME [epoch: 73.7 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1420703344074112		[learning rate: 0.0020623]
	Learning Rate: 0.00206233
	LOSS [training: 0.1420703344074112 | validation: 0.31859441097364216]
	TIME [epoch: 73.6 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12350498333622076		[learning rate: 0.0020526]
	Learning Rate: 0.00205262
	LOSS [training: 0.12350498333622076 | validation: 0.3093852742315735]
	TIME [epoch: 73.7 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1275633304285809		[learning rate: 0.0020429]
	Learning Rate: 0.00204294
	LOSS [training: 0.1275633304285809 | validation: 0.28680732802355285]
	TIME [epoch: 73.7 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1291535319355811		[learning rate: 0.0020333]
	Learning Rate: 0.00203332
	LOSS [training: 0.1291535319355811 | validation: 0.28626121175708846]
	TIME [epoch: 73.6 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12705042802935418		[learning rate: 0.0020237]
	Learning Rate: 0.00202374
	LOSS [training: 0.12705042802935418 | validation: 0.320628532191497]
	TIME [epoch: 73.6 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16217620554206774		[learning rate: 0.0020142]
	Learning Rate: 0.0020142
	LOSS [training: 0.16217620554206774 | validation: 0.3314371013475428]
	TIME [epoch: 73.7 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1391508665367923		[learning rate: 0.0020047]
	Learning Rate: 0.00200471
	LOSS [training: 0.1391508665367923 | validation: 0.31931195784424327]
	TIME [epoch: 73.6 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12388202783967106		[learning rate: 0.0019953]
	Learning Rate: 0.00199526
	LOSS [training: 0.12388202783967106 | validation: 0.33137527386722454]
	TIME [epoch: 73.6 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11153724604427037		[learning rate: 0.0019859]
	Learning Rate: 0.00198586
	LOSS [training: 0.11153724604427037 | validation: 0.3870269488317225]
	TIME [epoch: 73.6 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13906383148690832		[learning rate: 0.0019765]
	Learning Rate: 0.0019765
	LOSS [training: 0.13906383148690832 | validation: 0.31969403937132884]
	TIME [epoch: 73.7 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13163152231714728		[learning rate: 0.0019672]
	Learning Rate: 0.00196719
	LOSS [training: 0.13163152231714728 | validation: 0.31504200447940023]
	TIME [epoch: 73.7 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1207080138404542		[learning rate: 0.0019579]
	Learning Rate: 0.00195792
	LOSS [training: 0.1207080138404542 | validation: 0.306751845283834]
	TIME [epoch: 73.7 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12848985151836226		[learning rate: 0.0019487]
	Learning Rate: 0.00194869
	LOSS [training: 0.12848985151836226 | validation: 0.3434115539510392]
	TIME [epoch: 73.6 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11128838135128322		[learning rate: 0.0019395]
	Learning Rate: 0.00193951
	LOSS [training: 0.11128838135128322 | validation: 0.31068413710541176]
	TIME [epoch: 73.6 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11909530059887168		[learning rate: 0.0019304]
	Learning Rate: 0.00193037
	LOSS [training: 0.11909530059887168 | validation: 0.37829646673740247]
	TIME [epoch: 73.6 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.123808452024715		[learning rate: 0.0019213]
	Learning Rate: 0.00192128
	LOSS [training: 0.123808452024715 | validation: 0.28557387344909907]
	TIME [epoch: 73.5 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13019725288998207		[learning rate: 0.0019122]
	Learning Rate: 0.00191222
	LOSS [training: 0.13019725288998207 | validation: 0.33885178423296736]
	TIME [epoch: 73.6 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11286100808960785		[learning rate: 0.0019032]
	Learning Rate: 0.00190321
	LOSS [training: 0.11286100808960785 | validation: 0.3227816225175084]
	TIME [epoch: 73.6 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12675325199363324		[learning rate: 0.0018942]
	Learning Rate: 0.00189424
	LOSS [training: 0.12675325199363324 | validation: 0.28880086388151294]
	TIME [epoch: 73.6 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11551799846788001		[learning rate: 0.0018853]
	Learning Rate: 0.00188532
	LOSS [training: 0.11551799846788001 | validation: 0.3174534898248258]
	TIME [epoch: 73.6 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11987062029036108		[learning rate: 0.0018764]
	Learning Rate: 0.00187643
	LOSS [training: 0.11987062029036108 | validation: 0.29392709314751875]
	TIME [epoch: 73.6 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13552652203060644		[learning rate: 0.0018676]
	Learning Rate: 0.00186759
	LOSS [training: 0.13552652203060644 | validation: 0.3131790824455445]
	TIME [epoch: 73.7 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11316593560942063		[learning rate: 0.0018588]
	Learning Rate: 0.00185879
	LOSS [training: 0.11316593560942063 | validation: 0.29523697599023935]
	TIME [epoch: 73.7 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12023595652756244		[learning rate: 0.00185]
	Learning Rate: 0.00185003
	LOSS [training: 0.12023595652756244 | validation: 0.3460834931090567]
	TIME [epoch: 73.6 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11761160116825375		[learning rate: 0.0018413]
	Learning Rate: 0.00184132
	LOSS [training: 0.11761160116825375 | validation: 0.32476622509360814]
	TIME [epoch: 73.6 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12726786790979702		[learning rate: 0.0018326]
	Learning Rate: 0.00183264
	LOSS [training: 0.12726786790979702 | validation: 0.30866944096529697]
	TIME [epoch: 73.5 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12372218525773115		[learning rate: 0.001824]
	Learning Rate: 0.001824
	LOSS [training: 0.12372218525773115 | validation: 0.3117724197231216]
	TIME [epoch: 73.7 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11966121360027489		[learning rate: 0.0018154]
	Learning Rate: 0.00181541
	LOSS [training: 0.11966121360027489 | validation: 0.30536021697336235]
	TIME [epoch: 73.5 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11822964482287689		[learning rate: 0.0018069]
	Learning Rate: 0.00180685
	LOSS [training: 0.11822964482287689 | validation: 0.30626293136638344]
	TIME [epoch: 73.6 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13432826427927638		[learning rate: 0.0017983]
	Learning Rate: 0.00179834
	LOSS [training: 0.13432826427927638 | validation: 0.28560714668533654]
	TIME [epoch: 73.6 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13967508379749768		[learning rate: 0.0017899]
	Learning Rate: 0.00178987
	LOSS [training: 0.13967508379749768 | validation: 0.3143604097432294]
	TIME [epoch: 73.6 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11445558787832377		[learning rate: 0.0017814]
	Learning Rate: 0.00178143
	LOSS [training: 0.11445558787832377 | validation: 0.3035508265216726]
	TIME [epoch: 73.6 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11209728174566395		[learning rate: 0.001773]
	Learning Rate: 0.00177304
	LOSS [training: 0.11209728174566395 | validation: 0.29686669236423857]
	TIME [epoch: 73.7 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12508042728399144		[learning rate: 0.0017647]
	Learning Rate: 0.00176468
	LOSS [training: 0.12508042728399144 | validation: 0.3486250372917006]
	TIME [epoch: 73.7 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11063274217832754		[learning rate: 0.0017564]
	Learning Rate: 0.00175637
	LOSS [training: 0.11063274217832754 | validation: 0.3211571539259949]
	TIME [epoch: 73.6 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12411044983279199		[learning rate: 0.0017481]
	Learning Rate: 0.00174809
	LOSS [training: 0.12411044983279199 | validation: 0.291838901934065]
	TIME [epoch: 73.6 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12733213310543748		[learning rate: 0.0017399]
	Learning Rate: 0.00173985
	LOSS [training: 0.12733213310543748 | validation: 0.3104772926190211]
	TIME [epoch: 73.6 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11594449380902068		[learning rate: 0.0017317]
	Learning Rate: 0.00173166
	LOSS [training: 0.11594449380902068 | validation: 0.3190875435237236]
	TIME [epoch: 73.6 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1042124753166508		[learning rate: 0.0017235]
	Learning Rate: 0.0017235
	LOSS [training: 0.1042124753166508 | validation: 0.3023730926392119]
	TIME [epoch: 73.6 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11700452262387806		[learning rate: 0.0017154]
	Learning Rate: 0.00171537
	LOSS [training: 0.11700452262387806 | validation: 0.30347893163006573]
	TIME [epoch: 73.6 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10587634319863752		[learning rate: 0.0017073]
	Learning Rate: 0.00170729
	LOSS [training: 0.10587634319863752 | validation: 0.2814305916116281]
	TIME [epoch: 73.6 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13641357707458815		[learning rate: 0.0016992]
	Learning Rate: 0.00169925
	LOSS [training: 0.13641357707458815 | validation: 0.29603608919748686]
	TIME [epoch: 73.6 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12281549070441966		[learning rate: 0.0016912]
	Learning Rate: 0.00169124
	LOSS [training: 0.12281549070441966 | validation: 0.3105843541305439]
	TIME [epoch: 73.6 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1303451495375616		[learning rate: 0.0016833]
	Learning Rate: 0.00168327
	LOSS [training: 0.1303451495375616 | validation: 0.2960605493487854]
	TIME [epoch: 73.6 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12998140253076962		[learning rate: 0.0016753]
	Learning Rate: 0.00167534
	LOSS [training: 0.12998140253076962 | validation: 0.3436074287064475]
	TIME [epoch: 73.6 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11655375836019599		[learning rate: 0.0016674]
	Learning Rate: 0.00166744
	LOSS [training: 0.11655375836019599 | validation: 0.309692354724301]
	TIME [epoch: 73.5 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13854394134351422		[learning rate: 0.0016596]
	Learning Rate: 0.00165959
	LOSS [training: 0.13854394134351422 | validation: 0.31958118180909906]
	TIME [epoch: 73.6 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1288529532390844		[learning rate: 0.0016518]
	Learning Rate: 0.00165177
	LOSS [training: 0.1288529532390844 | validation: 0.33743113899819477]
	TIME [epoch: 73.6 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11204920076708136		[learning rate: 0.001644]
	Learning Rate: 0.00164398
	LOSS [training: 0.11204920076708136 | validation: 0.30045233040277286]
	TIME [epoch: 73.5 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1428538573047602		[learning rate: 0.0016362]
	Learning Rate: 0.00163624
	LOSS [training: 0.1428538573047602 | validation: 0.327684086752864]
	TIME [epoch: 73.5 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11851884976246377		[learning rate: 0.0016285]
	Learning Rate: 0.00162853
	LOSS [training: 0.11851884976246377 | validation: 0.3227065336337204]
	TIME [epoch: 73.5 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1204780477513642		[learning rate: 0.0016209]
	Learning Rate: 0.00162085
	LOSS [training: 0.1204780477513642 | validation: 0.283811659837787]
	TIME [epoch: 73.6 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10968365805309403		[learning rate: 0.0016132]
	Learning Rate: 0.00161322
	LOSS [training: 0.10968365805309403 | validation: 0.3061399250921952]
	TIME [epoch: 73.6 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10246864606708993		[learning rate: 0.0016056]
	Learning Rate: 0.00160561
	LOSS [training: 0.10246864606708993 | validation: 0.30370004123989913]
	TIME [epoch: 73.6 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10861099131653748		[learning rate: 0.001598]
	Learning Rate: 0.00159805
	LOSS [training: 0.10861099131653748 | validation: 0.29427153291889674]
	TIME [epoch: 73.6 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11914347953659325		[learning rate: 0.0015905]
	Learning Rate: 0.00159052
	LOSS [training: 0.11914347953659325 | validation: 0.290572554088617]
	TIME [epoch: 73.7 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12012277838668037		[learning rate: 0.001583]
	Learning Rate: 0.00158302
	LOSS [training: 0.12012277838668037 | validation: 0.2953928708771263]
	TIME [epoch: 73.7 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11806832651364065		[learning rate: 0.0015756]
	Learning Rate: 0.00157556
	LOSS [training: 0.11806832651364065 | validation: 0.2917220352074517]
	TIME [epoch: 73.6 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1323218261658831		[learning rate: 0.0015681]
	Learning Rate: 0.00156814
	LOSS [training: 0.1323218261658831 | validation: 0.32576762589342806]
	TIME [epoch: 73.6 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10871920609150433		[learning rate: 0.0015607]
	Learning Rate: 0.00156075
	LOSS [training: 0.10871920609150433 | validation: 0.3398036994314469]
	TIME [epoch: 73.6 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12693071084395288		[learning rate: 0.0015534]
	Learning Rate: 0.0015534
	LOSS [training: 0.12693071084395288 | validation: 0.31035151084753304]
	TIME [epoch: 73.7 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11785705975425217		[learning rate: 0.0015461]
	Learning Rate: 0.00154608
	LOSS [training: 0.11785705975425217 | validation: 0.3278346516801891]
	TIME [epoch: 73.6 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10876381563091822		[learning rate: 0.0015388]
	Learning Rate: 0.00153879
	LOSS [training: 0.10876381563091822 | validation: 0.32160046439331574]
	TIME [epoch: 73.6 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11024097188094382		[learning rate: 0.0015315]
	Learning Rate: 0.00153154
	LOSS [training: 0.11024097188094382 | validation: 0.33167389122812496]
	TIME [epoch: 73.6 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11650689461439452		[learning rate: 0.0015243]
	Learning Rate: 0.00152432
	LOSS [training: 0.11650689461439452 | validation: 0.3451144816988888]
	TIME [epoch: 73.6 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1163620663340453		[learning rate: 0.0015171]
	Learning Rate: 0.00151714
	LOSS [training: 0.1163620663340453 | validation: 0.29328115671557403]
	TIME [epoch: 73.6 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1065284195326088		[learning rate: 0.00151]
	Learning Rate: 0.00150999
	LOSS [training: 0.1065284195326088 | validation: 0.3119995426607848]
	TIME [epoch: 73.6 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.110119812861401		[learning rate: 0.0015029]
	Learning Rate: 0.00150288
	LOSS [training: 0.110119812861401 | validation: 0.3191989042641087]
	TIME [epoch: 73.6 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14011957882833978		[learning rate: 0.0014958]
	Learning Rate: 0.00149579
	LOSS [training: 0.14011957882833978 | validation: 0.3173561198073552]
	TIME [epoch: 73.6 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12081164493494889		[learning rate: 0.0014887]
	Learning Rate: 0.00148875
	LOSS [training: 0.12081164493494889 | validation: 0.31723778438222733]
	TIME [epoch: 73.5 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11542907288089116		[learning rate: 0.0014817]
	Learning Rate: 0.00148173
	LOSS [training: 0.11542907288089116 | validation: 0.2944521189998219]
	TIME [epoch: 73.6 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12373342929294612		[learning rate: 0.0014747]
	Learning Rate: 0.00147475
	LOSS [training: 0.12373342929294612 | validation: 0.2941169743683212]
	TIME [epoch: 73.6 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11477033167714142		[learning rate: 0.0014678]
	Learning Rate: 0.0014678
	LOSS [training: 0.11477033167714142 | validation: 0.294667928892876]
	TIME [epoch: 73.6 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11088171123515345		[learning rate: 0.0014609]
	Learning Rate: 0.00146088
	LOSS [training: 0.11088171123515345 | validation: 0.3067303899143813]
	TIME [epoch: 73.7 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10387418617395364		[learning rate: 0.001454]
	Learning Rate: 0.001454
	LOSS [training: 0.10387418617395364 | validation: 0.3331782145882614]
	TIME [epoch: 73.6 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11186250820090357		[learning rate: 0.0014471]
	Learning Rate: 0.00144715
	LOSS [training: 0.11186250820090357 | validation: 0.31394044526629145]
	TIME [epoch: 73.7 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11180591975147128		[learning rate: 0.0014403]
	Learning Rate: 0.00144033
	LOSS [training: 0.11180591975147128 | validation: 0.3015044279332596]
	TIME [epoch: 73.6 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11216219495470407		[learning rate: 0.0014335]
	Learning Rate: 0.00143354
	LOSS [training: 0.11216219495470407 | validation: 0.29574180744004064]
	TIME [epoch: 73.7 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11958217743663149		[learning rate: 0.0014268]
	Learning Rate: 0.00142679
	LOSS [training: 0.11958217743663149 | validation: 0.39427510429488033]
	TIME [epoch: 73.7 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10759215620281685		[learning rate: 0.0014201]
	Learning Rate: 0.00142006
	LOSS [training: 0.10759215620281685 | validation: 0.2981681061002699]
	TIME [epoch: 73.5 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10827550159669136		[learning rate: 0.0014134]
	Learning Rate: 0.00141337
	LOSS [training: 0.10827550159669136 | validation: 0.28919059675091113]
	TIME [epoch: 73.6 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11309696974117556		[learning rate: 0.0014067]
	Learning Rate: 0.00140671
	LOSS [training: 0.11309696974117556 | validation: 0.3056090996945561]
	TIME [epoch: 73.6 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10903694481431724		[learning rate: 0.0014001]
	Learning Rate: 0.00140008
	LOSS [training: 0.10903694481431724 | validation: 0.30484563822166494]
	TIME [epoch: 73.6 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10936516761433945		[learning rate: 0.0013935]
	Learning Rate: 0.00139349
	LOSS [training: 0.10936516761433945 | validation: 0.3155426411715747]
	TIME [epoch: 73.6 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12749093774118123		[learning rate: 0.0013869]
	Learning Rate: 0.00138692
	LOSS [training: 0.12749093774118123 | validation: 0.2921910062237732]
	TIME [epoch: 73.6 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10967854999775258		[learning rate: 0.0013804]
	Learning Rate: 0.00138038
	LOSS [training: 0.10967854999775258 | validation: 0.2901274330978436]
	TIME [epoch: 73.6 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1337013587706253		[learning rate: 0.0013739]
	Learning Rate: 0.00137388
	LOSS [training: 0.1337013587706253 | validation: 0.3248803984020434]
	TIME [epoch: 73.6 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13279039270330617		[learning rate: 0.0013674]
	Learning Rate: 0.00136741
	LOSS [training: 0.13279039270330617 | validation: 0.30873230875606295]
	TIME [epoch: 73.6 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11889750860288793		[learning rate: 0.001361]
	Learning Rate: 0.00136096
	LOSS [training: 0.11889750860288793 | validation: 0.30757060081806026]
	TIME [epoch: 73.7 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1401173561219246		[learning rate: 0.0013545]
	Learning Rate: 0.00135455
	LOSS [training: 0.1401173561219246 | validation: 0.3034821441620136]
	TIME [epoch: 73.6 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1210305178045962		[learning rate: 0.0013482]
	Learning Rate: 0.00134817
	LOSS [training: 0.1210305178045962 | validation: 0.30264974701942404]
	TIME [epoch: 73.6 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10999927935759125		[learning rate: 0.0013418]
	Learning Rate: 0.00134181
	LOSS [training: 0.10999927935759125 | validation: 0.32990260523342524]
	TIME [epoch: 73.6 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1250418624248483		[learning rate: 0.0013355]
	Learning Rate: 0.00133549
	LOSS [training: 0.1250418624248483 | validation: 0.3183118008424134]
	TIME [epoch: 73.7 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12325130973856982		[learning rate: 0.0013292]
	Learning Rate: 0.0013292
	LOSS [training: 0.12325130973856982 | validation: 0.27053528852214415]
	TIME [epoch: 73.6 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v14b_20240718_174651/states/model_facs_v4_dec2b_2dpca_v14b_465.pth
	Model improved!!!
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.103982541177161		[learning rate: 0.0013229]
	Learning Rate: 0.00132293
	LOSS [training: 0.103982541177161 | validation: 0.32634674922506557]
	TIME [epoch: 73.6 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11391961891848068		[learning rate: 0.0013167]
	Learning Rate: 0.0013167
	LOSS [training: 0.11391961891848068 | validation: 0.31849321709233275]
	TIME [epoch: 73.6 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12336972335020205		[learning rate: 0.0013105]
	Learning Rate: 0.0013105
	LOSS [training: 0.12336972335020205 | validation: 0.30848040025440154]
	TIME [epoch: 73.6 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.114302632627121		[learning rate: 0.0013043]
	Learning Rate: 0.00130432
	LOSS [training: 0.114302632627121 | validation: 0.31005671003936275]
	TIME [epoch: 73.7 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10142956812305072		[learning rate: 0.0012982]
	Learning Rate: 0.00129818
	LOSS [training: 0.10142956812305072 | validation: 0.284011720546971]
	TIME [epoch: 73.6 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11114215572457908		[learning rate: 0.0012921]
	Learning Rate: 0.00129206
	LOSS [training: 0.11114215572457908 | validation: 0.31633355084832465]
	TIME [epoch: 73.7 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11041410071444493		[learning rate: 0.001286]
	Learning Rate: 0.00128597
	LOSS [training: 0.11041410071444493 | validation: 0.3020361756700389]
	TIME [epoch: 73.6 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.118211331184796		[learning rate: 0.0012799]
	Learning Rate: 0.00127991
	LOSS [training: 0.118211331184796 | validation: 0.29511043738844944]
	TIME [epoch: 73.6 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10774613821958644		[learning rate: 0.0012739]
	Learning Rate: 0.00127388
	LOSS [training: 0.10774613821958644 | validation: 0.3179101567064168]
	TIME [epoch: 73.6 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12083857653153646		[learning rate: 0.0012679]
	Learning Rate: 0.00126788
	LOSS [training: 0.12083857653153646 | validation: 0.32799848738586135]
	TIME [epoch: 73.6 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12327602349887047		[learning rate: 0.0012619]
	Learning Rate: 0.0012619
	LOSS [training: 0.12327602349887047 | validation: 0.3216044787769365]
	TIME [epoch: 73.7 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1131804884863597		[learning rate: 0.001256]
	Learning Rate: 0.00125596
	LOSS [training: 0.1131804884863597 | validation: 0.29944357489575985]
	TIME [epoch: 73.5 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1119051165269725		[learning rate: 0.00125]
	Learning Rate: 0.00125004
	LOSS [training: 0.1119051165269725 | validation: 0.2879655242273956]
	TIME [epoch: 73.6 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10852035404333722		[learning rate: 0.0012441]
	Learning Rate: 0.00124415
	LOSS [training: 0.10852035404333722 | validation: 0.3589574187961854]
	TIME [epoch: 73.6 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10980655612025768		[learning rate: 0.0012383]
	Learning Rate: 0.00123828
	LOSS [training: 0.10980655612025768 | validation: 0.292437747243477]
	TIME [epoch: 73.6 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1180049140945486		[learning rate: 0.0012324]
	Learning Rate: 0.00123245
	LOSS [training: 0.1180049140945486 | validation: 0.32735664834084816]
	TIME [epoch: 73.6 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12699525756012495		[learning rate: 0.0012266]
	Learning Rate: 0.00122664
	LOSS [training: 0.12699525756012495 | validation: 0.29245268138633296]
	TIME [epoch: 73.6 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11283642562489213		[learning rate: 0.0012209]
	Learning Rate: 0.00122086
	LOSS [training: 0.11283642562489213 | validation: 0.2821756672716458]
	TIME [epoch: 73.6 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14611103148176766		[learning rate: 0.0012151]
	Learning Rate: 0.00121511
	LOSS [training: 0.14611103148176766 | validation: 0.3035619658555003]
	TIME [epoch: 73.7 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10466077748223103		[learning rate: 0.0012094]
	Learning Rate: 0.00120938
	LOSS [training: 0.10466077748223103 | validation: 0.31940343215298295]
	TIME [epoch: 73.7 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13707493961634307		[learning rate: 0.0012037]
	Learning Rate: 0.00120368
	LOSS [training: 0.13707493961634307 | validation: 0.29383690271228824]
	TIME [epoch: 73.7 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11767689488019786		[learning rate: 0.001198]
	Learning Rate: 0.00119801
	LOSS [training: 0.11767689488019786 | validation: 0.29858296233510906]
	TIME [epoch: 73.6 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12213766052031719		[learning rate: 0.0011924]
	Learning Rate: 0.00119237
	LOSS [training: 0.12213766052031719 | validation: 0.3039267729983438]
	TIME [epoch: 73.7 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11382203040694867		[learning rate: 0.0011867]
	Learning Rate: 0.00118675
	LOSS [training: 0.11382203040694867 | validation: 0.3192630794231577]
	TIME [epoch: 73.7 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11238901327886504		[learning rate: 0.0011812]
	Learning Rate: 0.00118116
	LOSS [training: 0.11238901327886504 | validation: 0.2885466393638974]
	TIME [epoch: 73.7 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12238624754132704		[learning rate: 0.0011756]
	Learning Rate: 0.00117559
	LOSS [training: 0.12238624754132704 | validation: 0.3072596001267737]
	TIME [epoch: 73.6 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11180135303630231		[learning rate: 0.0011701]
	Learning Rate: 0.00117005
	LOSS [training: 0.11180135303630231 | validation: 0.29754091982370634]
	TIME [epoch: 73.7 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11738933833543413		[learning rate: 0.0011645]
	Learning Rate: 0.00116454
	LOSS [training: 0.11738933833543413 | validation: 0.2924116489860312]
	TIME [epoch: 73.6 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11335223288880503		[learning rate: 0.0011591]
	Learning Rate: 0.00115905
	LOSS [training: 0.11335223288880503 | validation: 0.3009906075243157]
	TIME [epoch: 73.7 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12238739181131839		[learning rate: 0.0011536]
	Learning Rate: 0.00115359
	LOSS [training: 0.12238739181131839 | validation: 0.2995600070168162]
	TIME [epoch: 73.6 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12796334799416223		[learning rate: 0.0011482]
	Learning Rate: 0.00114815
	LOSS [training: 0.12796334799416223 | validation: 0.3133844986037694]
	TIME [epoch: 73.6 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12489608510312522		[learning rate: 0.0011427]
	Learning Rate: 0.00114274
	LOSS [training: 0.12489608510312522 | validation: 0.3077115082029971]
	TIME [epoch: 73.6 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1194922695579348		[learning rate: 0.0011374]
	Learning Rate: 0.00113736
	LOSS [training: 0.1194922695579348 | validation: 0.32694275466278166]
	TIME [epoch: 73.6 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1168279492501717		[learning rate: 0.001132]
	Learning Rate: 0.001132
	LOSS [training: 0.1168279492501717 | validation: 0.32626856061249293]
	TIME [epoch: 73.7 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11265922479324249		[learning rate: 0.0011267]
	Learning Rate: 0.00112667
	LOSS [training: 0.11265922479324249 | validation: 0.294652377399808]
	TIME [epoch: 73.6 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10379839267112059		[learning rate: 0.0011214]
	Learning Rate: 0.00112136
	LOSS [training: 0.10379839267112059 | validation: 0.31384225055207954]
	TIME [epoch: 73.7 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1277360460918327		[learning rate: 0.0011161]
	Learning Rate: 0.00111607
	LOSS [training: 0.1277360460918327 | validation: 0.3162516961767666]
	TIME [epoch: 73.7 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11597646896892713		[learning rate: 0.0011108]
	Learning Rate: 0.00111081
	LOSS [training: 0.11597646896892713 | validation: 0.30190822428993586]
	TIME [epoch: 73.7 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12015747912556395		[learning rate: 0.0011056]
	Learning Rate: 0.00110558
	LOSS [training: 0.12015747912556395 | validation: 0.3143211190638832]
	TIME [epoch: 73.7 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10515186504336349		[learning rate: 0.0011004]
	Learning Rate: 0.00110037
	LOSS [training: 0.10515186504336349 | validation: 0.3025081984517998]
	TIME [epoch: 73.7 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11644027552546798		[learning rate: 0.0010952]
	Learning Rate: 0.00109518
	LOSS [training: 0.11644027552546798 | validation: 0.29468146479973933]
	TIME [epoch: 73.7 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10900630706361576		[learning rate: 0.00109]
	Learning Rate: 0.00109002
	LOSS [training: 0.10900630706361576 | validation: 0.34415813023120434]
	TIME [epoch: 73.7 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10849953996973018		[learning rate: 0.0010849]
	Learning Rate: 0.00108489
	LOSS [training: 0.10849953996973018 | validation: 0.29936247516626113]
	TIME [epoch: 73.7 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12347609499378909		[learning rate: 0.0010798]
	Learning Rate: 0.00107978
	LOSS [training: 0.12347609499378909 | validation: 0.29771843528355657]
	TIME [epoch: 73.7 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1357181253610633		[learning rate: 0.0010747]
	Learning Rate: 0.00107469
	LOSS [training: 0.1357181253610633 | validation: 0.3194810207232145]
	TIME [epoch: 73.7 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11639748548863982		[learning rate: 0.0010696]
	Learning Rate: 0.00106962
	LOSS [training: 0.11639748548863982 | validation: 0.31284269533158693]
	TIME [epoch: 73.7 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10451869664568786		[learning rate: 0.0010646]
	Learning Rate: 0.00106458
	LOSS [training: 0.10451869664568786 | validation: 0.2904240140413765]
	TIME [epoch: 73.7 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11216475342299753		[learning rate: 0.0010596]
	Learning Rate: 0.00105957
	LOSS [training: 0.11216475342299753 | validation: 0.34022521005906226]
	TIME [epoch: 73.7 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13970701412703207		[learning rate: 0.0010546]
	Learning Rate: 0.00105457
	LOSS [training: 0.13970701412703207 | validation: 0.3079290646193849]
	TIME [epoch: 73.7 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11681474515789346		[learning rate: 0.0010496]
	Learning Rate: 0.0010496
	LOSS [training: 0.11681474515789346 | validation: 0.3118611131989363]
	TIME [epoch: 73.6 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11873564293576422		[learning rate: 0.0010447]
	Learning Rate: 0.00104466
	LOSS [training: 0.11873564293576422 | validation: 0.27927412741409025]
	TIME [epoch: 73.7 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10056324429278181		[learning rate: 0.0010397]
	Learning Rate: 0.00103974
	LOSS [training: 0.10056324429278181 | validation: 0.2829682076432751]
	TIME [epoch: 73.6 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10956536191080377		[learning rate: 0.0010348]
	Learning Rate: 0.00103484
	LOSS [training: 0.10956536191080377 | validation: 0.3051660590401992]
	TIME [epoch: 73.6 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10613043120682895		[learning rate: 0.00103]
	Learning Rate: 0.00102996
	LOSS [training: 0.10613043120682895 | validation: 0.33114525619629337]
	TIME [epoch: 73.5 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11073898284977902		[learning rate: 0.0010251]
	Learning Rate: 0.00102511
	LOSS [training: 0.11073898284977902 | validation: 0.3139798748973249]
	TIME [epoch: 73.6 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.107367486816937		[learning rate: 0.0010203]
	Learning Rate: 0.00102028
	LOSS [training: 0.107367486816937 | validation: 0.28076906985071004]
	TIME [epoch: 73.6 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12284175969192887		[learning rate: 0.0010155]
	Learning Rate: 0.00101547
	LOSS [training: 0.12284175969192887 | validation: 0.3114982467521884]
	TIME [epoch: 73.6 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11217537912669068		[learning rate: 0.0010107]
	Learning Rate: 0.00101068
	LOSS [training: 0.11217537912669068 | validation: 0.3083184307529402]
	TIME [epoch: 73.6 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09847023130870913		[learning rate: 0.0010059]
	Learning Rate: 0.00100592
	LOSS [training: 0.09847023130870913 | validation: 0.28752365208440633]
	TIME [epoch: 73.6 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10691002542605092		[learning rate: 0.0010012]
	Learning Rate: 0.00100118
	LOSS [training: 0.10691002542605092 | validation: 0.34210131964255036]
	TIME [epoch: 73.6 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10635475674345174		[learning rate: 0.00099646]
	Learning Rate: 0.000996464
	LOSS [training: 0.10635475674345174 | validation: 0.2872748599499835]
	TIME [epoch: 73.6 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1092010991573998		[learning rate: 0.00099177]
	Learning Rate: 0.000991768
	LOSS [training: 0.1092010991573998 | validation: 0.31719736266411075]
	TIME [epoch: 73.6 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1209481349903546		[learning rate: 0.0009871]
	Learning Rate: 0.000987095
	LOSS [training: 0.1209481349903546 | validation: 0.2845160888575366]
	TIME [epoch: 73.6 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1261102276727709		[learning rate: 0.00098244]
	Learning Rate: 0.000982444
	LOSS [training: 0.1261102276727709 | validation: 0.3102499849637215]
	TIME [epoch: 73.6 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11769021633388083		[learning rate: 0.00097781]
	Learning Rate: 0.000977814
	LOSS [training: 0.11769021633388083 | validation: 0.32948314036075077]
	TIME [epoch: 73.6 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11184568567666299		[learning rate: 0.00097321]
	Learning Rate: 0.000973207
	LOSS [training: 0.11184568567666299 | validation: 0.31393076980243706]
	TIME [epoch: 73.6 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10290568430188696		[learning rate: 0.00096862]
	Learning Rate: 0.000968621
	LOSS [training: 0.10290568430188696 | validation: 0.31105373811558545]
	TIME [epoch: 73.6 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10656800753550733		[learning rate: 0.00096406]
	Learning Rate: 0.000964057
	LOSS [training: 0.10656800753550733 | validation: 0.305746095167493]
	TIME [epoch: 73.7 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11492713705111837		[learning rate: 0.00095951]
	Learning Rate: 0.000959514
	LOSS [training: 0.11492713705111837 | validation: 0.28957844065288324]
	TIME [epoch: 73.6 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12549692986814315		[learning rate: 0.00095499]
	Learning Rate: 0.000954993
	LOSS [training: 0.12549692986814315 | validation: 0.29475583837236263]
	TIME [epoch: 73.6 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10983459628064465		[learning rate: 0.00095049]
	Learning Rate: 0.000950493
	LOSS [training: 0.10983459628064465 | validation: 0.301629058351849]
	TIME [epoch: 73.7 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10472227676892697		[learning rate: 0.00094601]
	Learning Rate: 0.000946014
	LOSS [training: 0.10472227676892697 | validation: 0.28290444310683677]
	TIME [epoch: 73.6 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11147215850399547		[learning rate: 0.00094156]
	Learning Rate: 0.000941556
	LOSS [training: 0.11147215850399547 | validation: 0.33711847752304924]
	TIME [epoch: 73.6 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11391584631336593		[learning rate: 0.00093712]
	Learning Rate: 0.000937119
	LOSS [training: 0.11391584631336593 | validation: 0.3377419411447543]
	TIME [epoch: 73.6 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10467929274775466		[learning rate: 0.0009327]
	Learning Rate: 0.000932703
	LOSS [training: 0.10467929274775466 | validation: 0.3125598854285421]
	TIME [epoch: 73.7 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11188800239557747		[learning rate: 0.00092831]
	Learning Rate: 0.000928309
	LOSS [training: 0.11188800239557747 | validation: 0.295719425786573]
	TIME [epoch: 73.6 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11614732422947956		[learning rate: 0.00092393]
	Learning Rate: 0.000923934
	LOSS [training: 0.11614732422947956 | validation: 0.33064849695424753]
	TIME [epoch: 73.6 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10322337174729787		[learning rate: 0.00091958]
	Learning Rate: 0.000919581
	LOSS [training: 0.10322337174729787 | validation: 0.29187304435323475]
	TIME [epoch: 73.7 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11511752497719571		[learning rate: 0.00091525]
	Learning Rate: 0.000915247
	LOSS [training: 0.11511752497719571 | validation: 0.31176370365031836]
	TIME [epoch: 73.7 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11393100113776805		[learning rate: 0.00091093]
	Learning Rate: 0.000910934
	LOSS [training: 0.11393100113776805 | validation: 0.3195622490175382]
	TIME [epoch: 73.6 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12217175811699388		[learning rate: 0.00090664]
	Learning Rate: 0.000906642
	LOSS [training: 0.12217175811699388 | validation: 0.305342753098329]
	TIME [epoch: 73.6 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11178931942761945		[learning rate: 0.00090237]
	Learning Rate: 0.00090237
	LOSS [training: 0.11178931942761945 | validation: 0.3162178941741308]
	TIME [epoch: 73.7 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11802425623216982		[learning rate: 0.00089812]
	Learning Rate: 0.000898118
	LOSS [training: 0.11802425623216982 | validation: 0.2910831808441944]
	TIME [epoch: 73.6 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13115205127565063		[learning rate: 0.00089389]
	Learning Rate: 0.000893886
	LOSS [training: 0.13115205127565063 | validation: 0.3079518442031206]
	TIME [epoch: 73.6 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10724943813356817		[learning rate: 0.00088967]
	Learning Rate: 0.000889674
	LOSS [training: 0.10724943813356817 | validation: 0.3601260094688584]
	TIME [epoch: 73.5 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11134568596156422		[learning rate: 0.00088548]
	Learning Rate: 0.000885481
	LOSS [training: 0.11134568596156422 | validation: 0.30105345671462364]
	TIME [epoch: 73.6 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10862226468569094		[learning rate: 0.00088131]
	Learning Rate: 0.000881309
	LOSS [training: 0.10862226468569094 | validation: 0.30516199408894873]
	TIME [epoch: 73.6 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11976873512046529		[learning rate: 0.00087716]
	Learning Rate: 0.000877156
	LOSS [training: 0.11976873512046529 | validation: 0.3226755773545431]
	TIME [epoch: 73.6 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11748991364384376		[learning rate: 0.00087302]
	Learning Rate: 0.000873023
	LOSS [training: 0.11748991364384376 | validation: 0.3098513167361553]
	TIME [epoch: 73.6 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10048734954734653		[learning rate: 0.00086891]
	Learning Rate: 0.000868909
	LOSS [training: 0.10048734954734653 | validation: 0.29985111721796526]
	TIME [epoch: 73.7 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.126644485445936		[learning rate: 0.00086481]
	Learning Rate: 0.000864815
	LOSS [training: 0.126644485445936 | validation: 0.2959158344824927]
	TIME [epoch: 73.7 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10311347159375343		[learning rate: 0.00086074]
	Learning Rate: 0.00086074
	LOSS [training: 0.10311347159375343 | validation: 0.3248217737014206]
	TIME [epoch: 73.5 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10971087364351498		[learning rate: 0.00085668]
	Learning Rate: 0.000856684
	LOSS [training: 0.10971087364351498 | validation: 0.2925190239276409]
	TIME [epoch: 73.5 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12469990542329111		[learning rate: 0.00085265]
	Learning Rate: 0.000852647
	LOSS [training: 0.12469990542329111 | validation: 0.32502565076814116]
	TIME [epoch: 73.6 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10989331478412387		[learning rate: 0.00084863]
	Learning Rate: 0.000848629
	LOSS [training: 0.10989331478412387 | validation: 0.2958060266603411]
	TIME [epoch: 73.7 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10397583513415666		[learning rate: 0.00084463]
	Learning Rate: 0.00084463
	LOSS [training: 0.10397583513415666 | validation: 0.3337975190526037]
	TIME [epoch: 73.6 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12539898677466288		[learning rate: 0.00084065]
	Learning Rate: 0.00084065
	LOSS [training: 0.12539898677466288 | validation: 0.32266694650768585]
	TIME [epoch: 73.6 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11021381363985096		[learning rate: 0.00083669]
	Learning Rate: 0.000836689
	LOSS [training: 0.11021381363985096 | validation: 0.3156347487842066]
	TIME [epoch: 73.6 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11038836655358825		[learning rate: 0.00083275]
	Learning Rate: 0.000832746
	LOSS [training: 0.11038836655358825 | validation: 0.3029780270343049]
	TIME [epoch: 73.6 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11469446226129057		[learning rate: 0.00082882]
	Learning Rate: 0.000828822
	LOSS [training: 0.11469446226129057 | validation: 0.3019674614678329]
	TIME [epoch: 73.6 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10983948676285026		[learning rate: 0.00082492]
	Learning Rate: 0.000824917
	LOSS [training: 0.10983948676285026 | validation: 0.28992594421932294]
	TIME [epoch: 73.6 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11345443061135596		[learning rate: 0.00082103]
	Learning Rate: 0.00082103
	LOSS [training: 0.11345443061135596 | validation: 0.3019817398804687]
	TIME [epoch: 73.6 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14294950363936465		[learning rate: 0.00081716]
	Learning Rate: 0.000817161
	LOSS [training: 0.14294950363936465 | validation: 0.3109505117749813]
	TIME [epoch: 73.6 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10592609952801628		[learning rate: 0.00081331]
	Learning Rate: 0.000813311
	LOSS [training: 0.10592609952801628 | validation: 0.2986219785371453]
	TIME [epoch: 73.6 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10357185456974666		[learning rate: 0.00080948]
	Learning Rate: 0.000809478
	LOSS [training: 0.10357185456974666 | validation: 0.31337257515130656]
	TIME [epoch: 73.6 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11775166286439531		[learning rate: 0.00080566]
	Learning Rate: 0.000805664
	LOSS [training: 0.11775166286439531 | validation: 0.3186580813475771]
	TIME [epoch: 73.6 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10023958327229052		[learning rate: 0.00080187]
	Learning Rate: 0.000801868
	LOSS [training: 0.10023958327229052 | validation: 0.3225685302760779]
	TIME [epoch: 73.7 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09993797425866666		[learning rate: 0.00079809]
	Learning Rate: 0.000798089
	LOSS [training: 0.09993797425866666 | validation: 0.33842735696071]
	TIME [epoch: 73.6 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1353207672112836		[learning rate: 0.00079433]
	Learning Rate: 0.000794328
	LOSS [training: 0.1353207672112836 | validation: 0.3034325285855564]
	TIME [epoch: 73.6 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10741311973647907		[learning rate: 0.00079059]
	Learning Rate: 0.000790585
	LOSS [training: 0.10741311973647907 | validation: 0.30160918031918005]
	TIME [epoch: 73.6 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12428631303229598		[learning rate: 0.00078686]
	Learning Rate: 0.00078686
	LOSS [training: 0.12428631303229598 | validation: 0.29197852183608863]
	TIME [epoch: 73.6 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11324161616887457		[learning rate: 0.00078315]
	Learning Rate: 0.000783152
	LOSS [training: 0.11324161616887457 | validation: 0.29515544124117643]
	TIME [epoch: 73.6 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12673421111825364		[learning rate: 0.00077946]
	Learning Rate: 0.000779462
	LOSS [training: 0.12673421111825364 | validation: 0.3240469627385861]
	TIME [epoch: 73.5 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1060926748907826		[learning rate: 0.00077579]
	Learning Rate: 0.000775789
	LOSS [training: 0.1060926748907826 | validation: 0.30744674852079246]
	TIME [epoch: 73.5 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10640131459164748		[learning rate: 0.00077213]
	Learning Rate: 0.000772133
	LOSS [training: 0.10640131459164748 | validation: 0.3355854948505463]
	TIME [epoch: 73.6 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1181854426604058		[learning rate: 0.00076849]
	Learning Rate: 0.000768495
	LOSS [training: 0.1181854426604058 | validation: 0.3111667120597297]
	TIME [epoch: 73.6 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1081079504000821		[learning rate: 0.00076487]
	Learning Rate: 0.000764874
	LOSS [training: 0.1081079504000821 | validation: 0.30449762253076246]
	TIME [epoch: 73.6 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12757299417351647		[learning rate: 0.00076127]
	Learning Rate: 0.00076127
	LOSS [training: 0.12757299417351647 | validation: 0.31521271550003815]
	TIME [epoch: 73.6 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10432223445646745		[learning rate: 0.00075768]
	Learning Rate: 0.000757682
	LOSS [training: 0.10432223445646745 | validation: 0.30283011648320884]
	TIME [epoch: 73.6 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10749996810834148		[learning rate: 0.00075411]
	Learning Rate: 0.000754112
	LOSS [training: 0.10749996810834148 | validation: 0.3282616780372852]
	TIME [epoch: 73.5 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11132914260461954		[learning rate: 0.00075056]
	Learning Rate: 0.000750559
	LOSS [training: 0.11132914260461954 | validation: 0.3141115075548881]
	TIME [epoch: 73.6 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1271461983554366		[learning rate: 0.00074702]
	Learning Rate: 0.000747022
	LOSS [training: 0.1271461983554366 | validation: 0.27655400616920156]
	TIME [epoch: 73.6 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11568222947148689		[learning rate: 0.0007435]
	Learning Rate: 0.000743502
	LOSS [training: 0.11568222947148689 | validation: 0.3251250640986527]
	TIME [epoch: 73.6 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12045146633210041		[learning rate: 0.00074]
	Learning Rate: 0.000739998
	LOSS [training: 0.12045146633210041 | validation: 0.33792637966594474]
	TIME [epoch: 73.6 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11792214856205763		[learning rate: 0.00073651]
	Learning Rate: 0.000736511
	LOSS [training: 0.11792214856205763 | validation: 0.3060362503060862]
	TIME [epoch: 73.6 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10220048076016898		[learning rate: 0.00073304]
	Learning Rate: 0.000733041
	LOSS [training: 0.10220048076016898 | validation: 0.3219582913730582]
	TIME [epoch: 73.5 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11909434609484365		[learning rate: 0.00072959]
	Learning Rate: 0.000729587
	LOSS [training: 0.11909434609484365 | validation: 0.30559798802136035]
	TIME [epoch: 73.7 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11553080469857663		[learning rate: 0.00072615]
	Learning Rate: 0.000726149
	LOSS [training: 0.11553080469857663 | validation: 0.3082453278239936]
	TIME [epoch: 73.6 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10744558220561867		[learning rate: 0.00072273]
	Learning Rate: 0.000722727
	LOSS [training: 0.10744558220561867 | validation: 0.301136634053102]
	TIME [epoch: 73.6 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12524867967200892		[learning rate: 0.00071932]
	Learning Rate: 0.000719321
	LOSS [training: 0.12524867967200892 | validation: 0.3101772870150653]
	TIME [epoch: 73.6 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1238745999072667		[learning rate: 0.00071593]
	Learning Rate: 0.000715932
	LOSS [training: 0.1238745999072667 | validation: 0.3001580712048375]
	TIME [epoch: 73.6 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12149930001167888		[learning rate: 0.00071256]
	Learning Rate: 0.000712558
	LOSS [training: 0.12149930001167888 | validation: 0.3124635206934879]
	TIME [epoch: 73.6 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11241581291136711		[learning rate: 0.0007092]
	Learning Rate: 0.000709201
	LOSS [training: 0.11241581291136711 | validation: 0.3077379613454035]
	TIME [epoch: 73.6 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10519742598547088		[learning rate: 0.00070586]
	Learning Rate: 0.000705859
	LOSS [training: 0.10519742598547088 | validation: 0.3275211200745786]
	TIME [epoch: 73.6 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11940152993682508		[learning rate: 0.00070253]
	Learning Rate: 0.000702533
	LOSS [training: 0.11940152993682508 | validation: 0.2923554181339717]
	TIME [epoch: 73.6 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1123655724632241		[learning rate: 0.00069922]
	Learning Rate: 0.000699222
	LOSS [training: 0.1123655724632241 | validation: 0.3170162870515569]
	TIME [epoch: 73.6 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10604841396214966		[learning rate: 0.00069593]
	Learning Rate: 0.000695928
	LOSS [training: 0.10604841396214966 | validation: 0.30643797510427384]
	TIME [epoch: 73.6 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1182228818408648		[learning rate: 0.00069265]
	Learning Rate: 0.000692648
	LOSS [training: 0.1182228818408648 | validation: 0.31042738957056]
	TIME [epoch: 73.6 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12299234143977578		[learning rate: 0.00068938]
	Learning Rate: 0.000689385
	LOSS [training: 0.12299234143977578 | validation: 0.311875274038235]
	TIME [epoch: 73.6 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10981157347687467		[learning rate: 0.00068614]
	Learning Rate: 0.000686136
	LOSS [training: 0.10981157347687467 | validation: 0.3105834795512147]
	TIME [epoch: 73.6 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1072460821539708		[learning rate: 0.0006829]
	Learning Rate: 0.000682903
	LOSS [training: 0.1072460821539708 | validation: 0.2996125714838018]
	TIME [epoch: 73.5 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11406624641481508		[learning rate: 0.00067969]
	Learning Rate: 0.000679685
	LOSS [training: 0.11406624641481508 | validation: 0.31509966918112203]
	TIME [epoch: 73.6 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10454640710007809		[learning rate: 0.00067648]
	Learning Rate: 0.000676482
	LOSS [training: 0.10454640710007809 | validation: 0.29726243012436215]
	TIME [epoch: 73.6 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12320793993267817		[learning rate: 0.00067329]
	Learning Rate: 0.000673295
	LOSS [training: 0.12320793993267817 | validation: 0.3086259010309121]
	TIME [epoch: 73.6 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11352373941845026		[learning rate: 0.00067012]
	Learning Rate: 0.000670122
	LOSS [training: 0.11352373941845026 | validation: 0.3175529851025358]
	TIME [epoch: 73.6 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11841421546547104		[learning rate: 0.00066696]
	Learning Rate: 0.000666964
	LOSS [training: 0.11841421546547104 | validation: 0.3262979041722706]
	TIME [epoch: 73.6 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12351294782936728		[learning rate: 0.00066382]
	Learning Rate: 0.000663821
	LOSS [training: 0.12351294782936728 | validation: 0.29400259615162383]
	TIME [epoch: 73.6 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09833410314087812		[learning rate: 0.00066069]
	Learning Rate: 0.000660694
	LOSS [training: 0.09833410314087812 | validation: 0.305403768825533]
	TIME [epoch: 73.6 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11170928703191908		[learning rate: 0.00065758]
	Learning Rate: 0.00065758
	LOSS [training: 0.11170928703191908 | validation: 0.3111466043333895]
	TIME [epoch: 73.5 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09998654390230993		[learning rate: 0.00065448]
	Learning Rate: 0.000654482
	LOSS [training: 0.09998654390230993 | validation: 0.3144884680908502]
	TIME [epoch: 73.6 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10826545215863687		[learning rate: 0.0006514]
	Learning Rate: 0.000651398
	LOSS [training: 0.10826545215863687 | validation: 0.29557029911950267]
	TIME [epoch: 73.6 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09890249281768915		[learning rate: 0.00064833]
	Learning Rate: 0.000648328
	LOSS [training: 0.09890249281768915 | validation: 0.306368101048766]
	TIME [epoch: 73.6 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11036330220848556		[learning rate: 0.00064527]
	Learning Rate: 0.000645273
	LOSS [training: 0.11036330220848556 | validation: 0.29921240257471254]
	TIME [epoch: 73.6 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1266356513043212		[learning rate: 0.00064223]
	Learning Rate: 0.000642232
	LOSS [training: 0.1266356513043212 | validation: 0.30759765576834086]
	TIME [epoch: 73.6 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10861705760634546		[learning rate: 0.00063921]
	Learning Rate: 0.000639206
	LOSS [training: 0.10861705760634546 | validation: 0.3032232311216351]
	TIME [epoch: 73.6 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1153520768635101		[learning rate: 0.00063619]
	Learning Rate: 0.000636194
	LOSS [training: 0.1153520768635101 | validation: 0.3133211583584432]
	TIME [epoch: 73.6 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10316364645400913		[learning rate: 0.0006332]
	Learning Rate: 0.000633196
	LOSS [training: 0.10316364645400913 | validation: 0.3014777515246297]
	TIME [epoch: 73.6 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11292600360171964		[learning rate: 0.00063021]
	Learning Rate: 0.000630213
	LOSS [training: 0.11292600360171964 | validation: 0.3149469756027775]
	TIME [epoch: 73.7 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10826929682516376		[learning rate: 0.00062724]
	Learning Rate: 0.000627243
	LOSS [training: 0.10826929682516376 | validation: 0.29971439867190863]
	TIME [epoch: 73.5 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10899531578113905		[learning rate: 0.00062429]
	Learning Rate: 0.000624287
	LOSS [training: 0.10899531578113905 | validation: 0.28826701657084414]
	TIME [epoch: 73.6 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.115000373654355		[learning rate: 0.00062135]
	Learning Rate: 0.000621346
	LOSS [training: 0.115000373654355 | validation: 0.3045461134027392]
	TIME [epoch: 73.6 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11825617469264621		[learning rate: 0.00061842]
	Learning Rate: 0.000618418
	LOSS [training: 0.11825617469264621 | validation: 0.29418356114982214]
	TIME [epoch: 73.6 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11135091385039136		[learning rate: 0.0006155]
	Learning Rate: 0.000615504
	LOSS [training: 0.11135091385039136 | validation: 0.3181109896563919]
	TIME [epoch: 73.6 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10839891392019313		[learning rate: 0.0006126]
	Learning Rate: 0.000612604
	LOSS [training: 0.10839891392019313 | validation: 0.2942128040048237]
	TIME [epoch: 73.6 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10368270929332582		[learning rate: 0.00060972]
	Learning Rate: 0.000609717
	LOSS [training: 0.10368270929332582 | validation: 0.3200939326059445]
	TIME [epoch: 73.6 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11272869325222903		[learning rate: 0.00060684]
	Learning Rate: 0.000606844
	LOSS [training: 0.11272869325222903 | validation: 0.309857523405543]
	TIME [epoch: 73.6 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12185642946308228		[learning rate: 0.00060398]
	Learning Rate: 0.000603984
	LOSS [training: 0.12185642946308228 | validation: 0.34203422545245815]
	TIME [epoch: 73.6 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.117375576964874		[learning rate: 0.00060114]
	Learning Rate: 0.000601138
	LOSS [training: 0.117375576964874 | validation: 0.31098466495646676]
	TIME [epoch: 73.6 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11009194001200907		[learning rate: 0.00059831]
	Learning Rate: 0.000598306
	LOSS [training: 0.11009194001200907 | validation: 0.3202772659314483]
	TIME [epoch: 73.6 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10834278726960805		[learning rate: 0.00059549]
	Learning Rate: 0.000595486
	LOSS [training: 0.10834278726960805 | validation: 0.3045425678469389]
	TIME [epoch: 73.6 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11460267009977708		[learning rate: 0.00059268]
	Learning Rate: 0.00059268
	LOSS [training: 0.11460267009977708 | validation: 0.2990101376083036]
	TIME [epoch: 73.7 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14605219866630062		[learning rate: 0.00058989]
	Learning Rate: 0.000589888
	LOSS [training: 0.14605219866630062 | validation: 0.3056784212960436]
	TIME [epoch: 73.6 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11597796446111368		[learning rate: 0.00058711]
	Learning Rate: 0.000587108
	LOSS [training: 0.11597796446111368 | validation: 0.3139431294997578]
	TIME [epoch: 73.6 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11387839322093266		[learning rate: 0.00058434]
	Learning Rate: 0.000584341
	LOSS [training: 0.11387839322093266 | validation: 0.29317963391453944]
	TIME [epoch: 73.6 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10931481734786805		[learning rate: 0.00058159]
	Learning Rate: 0.000581588
	LOSS [training: 0.10931481734786805 | validation: 0.32437190761507745]
	TIME [epoch: 73.6 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11216581916860686		[learning rate: 0.00057885]
	Learning Rate: 0.000578847
	LOSS [training: 0.11216581916860686 | validation: 0.31764858196568335]
	TIME [epoch: 73.6 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11220917173028065		[learning rate: 0.00057612]
	Learning Rate: 0.00057612
	LOSS [training: 0.11220917173028065 | validation: 0.2994994888428099]
	TIME [epoch: 73.6 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12453189888932573		[learning rate: 0.00057341]
	Learning Rate: 0.000573405
	LOSS [training: 0.12453189888932573 | validation: 0.3230397032663652]
	TIME [epoch: 73.5 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11260269018443472		[learning rate: 0.0005707]
	Learning Rate: 0.000570703
	LOSS [training: 0.11260269018443472 | validation: 0.33734624210420455]
	TIME [epoch: 73.6 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10105520054266555		[learning rate: 0.00056801]
	Learning Rate: 0.000568014
	LOSS [training: 0.10105520054266555 | validation: 0.29848056752633306]
	TIME [epoch: 73.6 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1037078408236319		[learning rate: 0.00056534]
	Learning Rate: 0.000565337
	LOSS [training: 0.1037078408236319 | validation: 0.30786194407804635]
	TIME [epoch: 73.6 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1179305348678798		[learning rate: 0.00056267]
	Learning Rate: 0.000562673
	LOSS [training: 0.1179305348678798 | validation: 0.2872787244153492]
	TIME [epoch: 73.6 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12274765964299342		[learning rate: 0.00056002]
	Learning Rate: 0.000560022
	LOSS [training: 0.12274765964299342 | validation: 0.3191017993481813]
	TIME [epoch: 73.6 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11235213057033727		[learning rate: 0.00055738]
	Learning Rate: 0.000557383
	LOSS [training: 0.11235213057033727 | validation: 0.3122511335635792]
	TIME [epoch: 73.6 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1347591459276437		[learning rate: 0.00055476]
	Learning Rate: 0.000554757
	LOSS [training: 0.1347591459276437 | validation: 0.29202370401859196]
	TIME [epoch: 73.6 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11968006355543237		[learning rate: 0.00055214]
	Learning Rate: 0.000552143
	LOSS [training: 0.11968006355543237 | validation: 0.3051467178053327]
	TIME [epoch: 73.6 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10087713093732417		[learning rate: 0.00054954]
	Learning Rate: 0.000549541
	LOSS [training: 0.10087713093732417 | validation: 0.302746927064121]
	TIME [epoch: 73.6 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11882974654748565		[learning rate: 0.00054695]
	Learning Rate: 0.000546951
	LOSS [training: 0.11882974654748565 | validation: 0.2852901320430985]
	TIME [epoch: 73.6 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11014039463470529		[learning rate: 0.00054437]
	Learning Rate: 0.000544374
	LOSS [training: 0.11014039463470529 | validation: 0.30617401290333845]
	TIME [epoch: 73.6 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1178578672227799		[learning rate: 0.00054181]
	Learning Rate: 0.000541809
	LOSS [training: 0.1178578672227799 | validation: 0.3096152135110575]
	TIME [epoch: 73.6 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11313122578124933		[learning rate: 0.00053926]
	Learning Rate: 0.000539256
	LOSS [training: 0.11313122578124933 | validation: 0.2946148694728746]
	TIME [epoch: 73.6 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12034286330989238		[learning rate: 0.00053671]
	Learning Rate: 0.000536715
	LOSS [training: 0.12034286330989238 | validation: 0.3227998941745549]
	TIME [epoch: 73.6 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10230878899469306		[learning rate: 0.00053419]
	Learning Rate: 0.000534186
	LOSS [training: 0.10230878899469306 | validation: 0.29042303848914375]
	TIME [epoch: 73.6 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13060848404983894		[learning rate: 0.00053167]
	Learning Rate: 0.000531669
	LOSS [training: 0.13060848404983894 | validation: 0.3037283429646339]
	TIME [epoch: 73.5 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09826278812917807		[learning rate: 0.00052916]
	Learning Rate: 0.000529163
	LOSS [training: 0.09826278812917807 | validation: 0.3303210457782209]
	TIME [epoch: 73.6 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09668048351652768		[learning rate: 0.00052667]
	Learning Rate: 0.00052667
	LOSS [training: 0.09668048351652768 | validation: 0.32234485931809564]
	TIME [epoch: 73.7 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1094444697717736		[learning rate: 0.00052419]
	Learning Rate: 0.000524188
	LOSS [training: 0.1094444697717736 | validation: 0.3092501151471685]
	TIME [epoch: 73.6 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11298298047427098		[learning rate: 0.00052172]
	Learning Rate: 0.000521718
	LOSS [training: 0.11298298047427098 | validation: 0.32219971768759065]
	TIME [epoch: 73.6 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10505307881607402		[learning rate: 0.00051926]
	Learning Rate: 0.00051926
	LOSS [training: 0.10505307881607402 | validation: 0.3052058827386206]
	TIME [epoch: 73.7 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1080797549237971		[learning rate: 0.00051681]
	Learning Rate: 0.000516813
	LOSS [training: 0.1080797549237971 | validation: 0.29170457127883187]
	TIME [epoch: 73.6 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11230058391524309		[learning rate: 0.00051438]
	Learning Rate: 0.000514378
	LOSS [training: 0.11230058391524309 | validation: 0.3204229050575304]
	TIME [epoch: 73.6 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v14b_20240718_174651/states/model_facs_v4_dec2b_2dpca_v14b_666.pth
Halted early. No improvement in validation loss for 200 epochs.
Finished training in 32904.367 seconds.
