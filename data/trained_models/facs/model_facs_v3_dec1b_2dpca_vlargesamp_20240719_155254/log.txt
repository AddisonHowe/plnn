Args:
Namespace(name='model_facs_v3_dec1b_2dpca_vlargesamp', outdir='out/model_training/model_facs_v3_dec1b_2dpca_vlargesamp', training_data='data/training_data/facs_v3/pca/dec1_fitonsubset/transition1_subset_epi_tr_ce_an_pc12/training', validation_data='data/training_data/facs_v3/pca/dec1_fitonsubset/transition1_subset_epi_tr_ce_an_pc12/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=10, batch_size=50, patience=200, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, quadratic_a=1.0, quadratic_b=1.0, ndims=2, nparams=2, nsigs=2, ncells=2000, ncells_sample=2000, model_do_sample=False, dt=0.005, dt_schedule='stepped', dt_schedule_bounds=[150, 250, 350, 450], dt_schedule_scales=[0.8, 0.8, 0.8, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', kernel='multiscale', bw_range=[0.2, 0.5, 0.9, 1.1, 1.3, 1.5, 2.0], optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=0.0001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 1242359879

Training model...

Saving initial model state to: out/model_training/model_facs_v3_dec1b_2dpca_vlargesamp_20240719_155254/states/model_facs_v3_dec1b_2dpca_vlargesamp_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.3816184818670203		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3816184818670203 | validation: 0.9951077603363565]
	TIME [epoch: 39.4 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_vlargesamp_20240719_155254/states/model_facs_v3_dec1b_2dpca_vlargesamp_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.2214632491668123		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2214632491668123 | validation: 1.0632361855121069]
	TIME [epoch: 18.8 sec]
EPOCH 3/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.1694571073274884		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1694571073274884 | validation: 1.1311959959686266]
	TIME [epoch: 18.8 sec]
EPOCH 4/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.1965334506923908		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1965334506923908 | validation: 0.9136558302969439]
	TIME [epoch: 18.8 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_vlargesamp_20240719_155254/states/model_facs_v3_dec1b_2dpca_vlargesamp_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.1174809552552403		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1174809552552403 | validation: 0.8969001940982988]
	TIME [epoch: 18.8 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_vlargesamp_20240719_155254/states/model_facs_v3_dec1b_2dpca_vlargesamp_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.0786296848484864		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0786296848484864 | validation: 0.8484464236686795]
	TIME [epoch: 18.8 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_vlargesamp_20240719_155254/states/model_facs_v3_dec1b_2dpca_vlargesamp_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.021131600753525		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.021131600753525 | validation: 0.8158016934372506]
	TIME [epoch: 18.8 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_vlargesamp_20240719_155254/states/model_facs_v3_dec1b_2dpca_vlargesamp_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.9657899682648973		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9657899682648973 | validation: 0.7727547421603462]
	TIME [epoch: 18.8 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_vlargesamp_20240719_155254/states/model_facs_v3_dec1b_2dpca_vlargesamp_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.9342300781692016		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9342300781692016 | validation: 0.7818448678682729]
	TIME [epoch: 18.8 sec]
EPOCH 10/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.9301666507413805		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9301666507413805 | validation: 0.7463877082787201]
	TIME [epoch: 18.8 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_vlargesamp_20240719_155254/states/model_facs_v3_dec1b_2dpca_vlargesamp_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.7999406591748118		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7999406591748118 | validation: 0.6563045997979587]
	TIME [epoch: 18.8 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_vlargesamp_20240719_155254/states/model_facs_v3_dec1b_2dpca_vlargesamp_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.762545735137275		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.762545735137275 | validation: 0.718743900512854]
	TIME [epoch: 18.8 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.7140952714600374		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7140952714600374 | validation: 0.5732777459320684]
	TIME [epoch: 18.8 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_vlargesamp_20240719_155254/states/model_facs_v3_dec1b_2dpca_vlargesamp_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.6192971727021145		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6192971727021145 | validation: 0.6857500175327378]
	TIME [epoch: 18.8 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.6613766172463245		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6613766172463245 | validation: 0.5139394130583674]
	TIME [epoch: 18.8 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_vlargesamp_20240719_155254/states/model_facs_v3_dec1b_2dpca_vlargesamp_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5553088910110532		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5553088910110532 | validation: 0.452927330433056]
	TIME [epoch: 18.8 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_vlargesamp_20240719_155254/states/model_facs_v3_dec1b_2dpca_vlargesamp_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5476185364109311		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5476185364109311 | validation: 0.4501743146567862]
	TIME [epoch: 18.8 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_vlargesamp_20240719_155254/states/model_facs_v3_dec1b_2dpca_vlargesamp_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5499092933321614		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5499092933321614 | validation: 0.3885753033746679]
	TIME [epoch: 18.8 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_vlargesamp_20240719_155254/states/model_facs_v3_dec1b_2dpca_vlargesamp_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4531646328220092		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4531646328220092 | validation: 0.38410032794581495]
	TIME [epoch: 18.8 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_vlargesamp_20240719_155254/states/model_facs_v3_dec1b_2dpca_vlargesamp_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4212817371490054		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4212817371490054 | validation: 0.38189907604569595]
	TIME [epoch: 18.8 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_vlargesamp_20240719_155254/states/model_facs_v3_dec1b_2dpca_vlargesamp_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.420941041345825		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.420941041345825 | validation: 0.34269941226742023]
	TIME [epoch: 18.8 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_vlargesamp_20240719_155254/states/model_facs_v3_dec1b_2dpca_vlargesamp_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.38768459656343107		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.38768459656343107 | validation: 0.3524596389747667]
	TIME [epoch: 18.8 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.37956348120584		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.37956348120584 | validation: 0.349445177072352]
	TIME [epoch: 18.8 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3770855077879223		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3770855077879223 | validation: 0.3127574543218604]
	TIME [epoch: 18.8 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_vlargesamp_20240719_155254/states/model_facs_v3_dec1b_2dpca_vlargesamp_24.pth
	Model improved!!!
EPOCH 25/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.356419326171829		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.356419326171829 | validation: 0.29985567397985874]
	TIME [epoch: 18.9 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_vlargesamp_20240719_155254/states/model_facs_v3_dec1b_2dpca_vlargesamp_25.pth
	Model improved!!!
EPOCH 26/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.35871741977499094		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.35871741977499094 | validation: 0.2753247285412793]
	TIME [epoch: 18.8 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_vlargesamp_20240719_155254/states/model_facs_v3_dec1b_2dpca_vlargesamp_26.pth
	Model improved!!!
EPOCH 27/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.34785203100449347		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.34785203100449347 | validation: 0.2872607348377496]
	TIME [epoch: 18.8 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.338701002460227		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.338701002460227 | validation: 0.2961558852392872]
	TIME [epoch: 18.8 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3340087086443008		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3340087086443008 | validation: 0.321819498945716]
	TIME [epoch: 18.8 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.32834186546945077		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.32834186546945077 | validation: 0.30097934058662806]
	TIME [epoch: 18.8 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.33354244804789457		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.33354244804789457 | validation: 0.2849107458477077]
	TIME [epoch: 18.8 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3284885280124176		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3284885280124176 | validation: 0.2957889007522655]
	TIME [epoch: 18.8 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.32081733880969887		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.32081733880969887 | validation: 0.25724339548849057]
	TIME [epoch: 18.8 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_vlargesamp_20240719_155254/states/model_facs_v3_dec1b_2dpca_vlargesamp_33.pth
	Model improved!!!
EPOCH 34/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3185164498398224		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3185164498398224 | validation: 0.2609768788706549]
	TIME [epoch: 18.8 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3208398262349885		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3208398262349885 | validation: 0.2760669491584362]
	TIME [epoch: 18.8 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.31316483788330973		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.31316483788330973 | validation: 0.2630178468955333]
	TIME [epoch: 18.8 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.32133610791828876		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.32133610791828876 | validation: 0.2672642012354463]
	TIME [epoch: 18.8 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.31113405434673114		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.31113405434673114 | validation: 0.24281939442813724]
	TIME [epoch: 18.8 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_vlargesamp_20240719_155254/states/model_facs_v3_dec1b_2dpca_vlargesamp_38.pth
	Model improved!!!
EPOCH 39/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.304719846659036		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.304719846659036 | validation: 0.2627943432255716]
	TIME [epoch: 18.8 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.30468166332204644		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.30468166332204644 | validation: 0.24048622505319805]
	TIME [epoch: 18.8 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_vlargesamp_20240719_155254/states/model_facs_v3_dec1b_2dpca_vlargesamp_40.pth
	Model improved!!!
EPOCH 41/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.31604286826813094		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.31604286826813094 | validation: 0.2891877457543132]
	TIME [epoch: 18.8 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3038691201783371		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3038691201783371 | validation: 0.25750063277789903]
	TIME [epoch: 18.8 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.30823382815610656		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.30823382815610656 | validation: 0.2439379559069224]
	TIME [epoch: 18.8 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29928989474317186		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.29928989474317186 | validation: 0.23609451309844856]
	TIME [epoch: 18.8 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_vlargesamp_20240719_155254/states/model_facs_v3_dec1b_2dpca_vlargesamp_44.pth
	Model improved!!!
EPOCH 45/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3173339055324724		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3173339055324724 | validation: 0.2692604731061049]
	TIME [epoch: 18.9 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.302393167625061		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.302393167625061 | validation: 0.2771137295385582]
	TIME [epoch: 18.9 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.30378147986552423		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.30378147986552423 | validation: 0.23397078416448558]
	TIME [epoch: 18.9 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_vlargesamp_20240719_155254/states/model_facs_v3_dec1b_2dpca_vlargesamp_47.pth
	Model improved!!!
EPOCH 48/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2855720341654961		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2855720341654961 | validation: 0.2727322604229673]
	TIME [epoch: 18.8 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.30198041476196436		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.30198041476196436 | validation: 0.22780814790469858]
	TIME [epoch: 18.8 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_vlargesamp_20240719_155254/states/model_facs_v3_dec1b_2dpca_vlargesamp_49.pth
	Model improved!!!
EPOCH 50/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2975840313894298		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2975840313894298 | validation: 0.23141356448614245]
	TIME [epoch: 18.8 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2922786121804622		[learning rate: 0.0099803]
	Learning Rate: 0.00998034
	LOSS [training: 0.2922786121804622 | validation: 0.2310667600221749]
	TIME [epoch: 18.8 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3082718593648281		[learning rate: 0.0099568]
	Learning Rate: 0.0099568
	LOSS [training: 0.3082718593648281 | validation: 0.23210943850457885]
	TIME [epoch: 18.8 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2970025403711421		[learning rate: 0.0099333]
	Learning Rate: 0.00993331
	LOSS [training: 0.2970025403711421 | validation: 0.2628358300571463]
	TIME [epoch: 18.8 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2944867393320652		[learning rate: 0.0099099]
	Learning Rate: 0.00990988
	LOSS [training: 0.2944867393320652 | validation: 0.24092316770153072]
	TIME [epoch: 18.8 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3089985618831922		[learning rate: 0.0098865]
	Learning Rate: 0.0098865
	LOSS [training: 0.3089985618831922 | validation: 0.22840481191787934]
	TIME [epoch: 18.8 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2799231553517368		[learning rate: 0.0098632]
	Learning Rate: 0.00986318
	LOSS [training: 0.2799231553517368 | validation: 0.24280094348558867]
	TIME [epoch: 18.8 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3055009637316814		[learning rate: 0.0098399]
	Learning Rate: 0.00983992
	LOSS [training: 0.3055009637316814 | validation: 0.24332828359529518]
	TIME [epoch: 18.8 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3166268272479467		[learning rate: 0.0098167]
	Learning Rate: 0.00981671
	LOSS [training: 0.3166268272479467 | validation: 0.24395060892774328]
	TIME [epoch: 18.8 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3016694842594907		[learning rate: 0.0097935]
	Learning Rate: 0.00979355
	LOSS [training: 0.3016694842594907 | validation: 0.2498989137293141]
	TIME [epoch: 18.8 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2790161152265255		[learning rate: 0.0097704]
	Learning Rate: 0.00977045
	LOSS [training: 0.2790161152265255 | validation: 0.23354497935336455]
	TIME [epoch: 18.8 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2946554665312787		[learning rate: 0.0097474]
	Learning Rate: 0.0097474
	LOSS [training: 0.2946554665312787 | validation: 0.22935016789067833]
	TIME [epoch: 18.8 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28173744066055817		[learning rate: 0.0097244]
	Learning Rate: 0.00972441
	LOSS [training: 0.28173744066055817 | validation: 0.21969710803144255]
	TIME [epoch: 18.8 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_vlargesamp_20240719_155254/states/model_facs_v3_dec1b_2dpca_vlargesamp_62.pth
	Model improved!!!
EPOCH 63/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28360285271574454		[learning rate: 0.0097015]
	Learning Rate: 0.00970147
	LOSS [training: 0.28360285271574454 | validation: 0.22416382136751017]
	TIME [epoch: 18.8 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29661366189077626		[learning rate: 0.0096786]
	Learning Rate: 0.00967859
	LOSS [training: 0.29661366189077626 | validation: 0.2279847906435767]
	TIME [epoch: 18.8 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2891699802293542		[learning rate: 0.0096558]
	Learning Rate: 0.00965576
	LOSS [training: 0.2891699802293542 | validation: 0.24799449177048868]
	TIME [epoch: 18.8 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28703773260916515		[learning rate: 0.009633]
	Learning Rate: 0.00963298
	LOSS [training: 0.28703773260916515 | validation: 0.2235666624103101]
	TIME [epoch: 18.8 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2877014270530055		[learning rate: 0.0096103]
	Learning Rate: 0.00961026
	LOSS [training: 0.2877014270530055 | validation: 0.25934752343757284]
	TIME [epoch: 18.8 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28869096784836173		[learning rate: 0.0095876]
	Learning Rate: 0.00958759
	LOSS [training: 0.28869096784836173 | validation: 0.22403130158436327]
	TIME [epoch: 18.8 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28476157281854003		[learning rate: 0.009565]
	Learning Rate: 0.00956497
	LOSS [training: 0.28476157281854003 | validation: 0.21817205255213498]
	TIME [epoch: 18.8 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_vlargesamp_20240719_155254/states/model_facs_v3_dec1b_2dpca_vlargesamp_69.pth
	Model improved!!!
EPOCH 70/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2830998032528144		[learning rate: 0.0095424]
	Learning Rate: 0.00954241
	LOSS [training: 0.2830998032528144 | validation: 0.2256422929289839]
	TIME [epoch: 18.8 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29881640396347053		[learning rate: 0.0095199]
	Learning Rate: 0.0095199
	LOSS [training: 0.29881640396347053 | validation: 0.226751642452467]
	TIME [epoch: 18.8 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29347217145497323		[learning rate: 0.0094974]
	Learning Rate: 0.00949745
	LOSS [training: 0.29347217145497323 | validation: 0.22279065464345668]
	TIME [epoch: 18.8 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2794620503310015		[learning rate: 0.009475]
	Learning Rate: 0.00947504
	LOSS [training: 0.2794620503310015 | validation: 0.21597698554616337]
	TIME [epoch: 18.8 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_vlargesamp_20240719_155254/states/model_facs_v3_dec1b_2dpca_vlargesamp_73.pth
	Model improved!!!
EPOCH 74/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28691511332605596		[learning rate: 0.0094527]
	Learning Rate: 0.00945269
	LOSS [training: 0.28691511332605596 | validation: 0.2225286131891795]
	TIME [epoch: 18.8 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27557939780712154		[learning rate: 0.0094304]
	Learning Rate: 0.0094304
	LOSS [training: 0.27557939780712154 | validation: 0.22242267812384417]
	TIME [epoch: 18.8 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27671401325134154		[learning rate: 0.0094082]
	Learning Rate: 0.00940815
	LOSS [training: 0.27671401325134154 | validation: 0.2217528713179549]
	TIME [epoch: 18.8 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2852552049908175		[learning rate: 0.009386]
	Learning Rate: 0.00938596
	LOSS [training: 0.2852552049908175 | validation: 0.22915548392802113]
	TIME [epoch: 18.8 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28524829440241595		[learning rate: 0.0093638]
	Learning Rate: 0.00936382
	LOSS [training: 0.28524829440241595 | validation: 0.22895991990362666]
	TIME [epoch: 18.8 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2805833623754283		[learning rate: 0.0093417]
	Learning Rate: 0.00934173
	LOSS [training: 0.2805833623754283 | validation: 0.21867589348516908]
	TIME [epoch: 18.8 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2804434691489845		[learning rate: 0.0093197]
	Learning Rate: 0.00931969
	LOSS [training: 0.2804434691489845 | validation: 0.22038492990979922]
	TIME [epoch: 18.8 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27618361706862743		[learning rate: 0.0092977]
	Learning Rate: 0.00929771
	LOSS [training: 0.27618361706862743 | validation: 0.2328830187964764]
	TIME [epoch: 18.8 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28027676883559455		[learning rate: 0.0092758]
	Learning Rate: 0.00927578
	LOSS [training: 0.28027676883559455 | validation: 0.22428198016154943]
	TIME [epoch: 18.8 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.284883790195493		[learning rate: 0.0092539]
	Learning Rate: 0.0092539
	LOSS [training: 0.284883790195493 | validation: 0.22577166684485633]
	TIME [epoch: 18.8 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2927377808268233		[learning rate: 0.0092321]
	Learning Rate: 0.00923207
	LOSS [training: 0.2927377808268233 | validation: 0.2183349764156345]
	TIME [epoch: 18.8 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2700565845886112		[learning rate: 0.0092103]
	Learning Rate: 0.00921029
	LOSS [training: 0.2700565845886112 | validation: 0.2242688264409826]
	TIME [epoch: 18.8 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27137893229781646		[learning rate: 0.0091886]
	Learning Rate: 0.00918857
	LOSS [training: 0.27137893229781646 | validation: 0.22589643417955002]
	TIME [epoch: 18.8 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28431799448989425		[learning rate: 0.0091669]
	Learning Rate: 0.00916689
	LOSS [training: 0.28431799448989425 | validation: 0.23414853500064173]
	TIME [epoch: 18.8 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2901538151456487		[learning rate: 0.0091453]
	Learning Rate: 0.00914527
	LOSS [training: 0.2901538151456487 | validation: 0.21954736072995354]
	TIME [epoch: 18.8 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27804913783198093		[learning rate: 0.0091237]
	Learning Rate: 0.0091237
	LOSS [training: 0.27804913783198093 | validation: 0.23066041076700144]
	TIME [epoch: 18.8 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27459666640741515		[learning rate: 0.0091022]
	Learning Rate: 0.00910218
	LOSS [training: 0.27459666640741515 | validation: 0.21477215317975737]
	TIME [epoch: 18.8 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_vlargesamp_20240719_155254/states/model_facs_v3_dec1b_2dpca_vlargesamp_90.pth
	Model improved!!!
EPOCH 91/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28296199659387383		[learning rate: 0.0090807]
	Learning Rate: 0.00908071
	LOSS [training: 0.28296199659387383 | validation: 0.22898627762601986]
	TIME [epoch: 18.8 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2752161601654755		[learning rate: 0.0090593]
	Learning Rate: 0.00905929
	LOSS [training: 0.2752161601654755 | validation: 0.2213971170330317]
	TIME [epoch: 18.8 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27479088541906815		[learning rate: 0.0090379]
	Learning Rate: 0.00903792
	LOSS [training: 0.27479088541906815 | validation: 0.2201488053361353]
	TIME [epoch: 18.8 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28770543534184156		[learning rate: 0.0090166]
	Learning Rate: 0.0090166
	LOSS [training: 0.28770543534184156 | validation: 0.22764643552783678]
	TIME [epoch: 18.8 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27583339604558754		[learning rate: 0.0089953]
	Learning Rate: 0.00899533
	LOSS [training: 0.27583339604558754 | validation: 0.22288172962903388]
	TIME [epoch: 18.8 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2768414863678445		[learning rate: 0.0089741]
	Learning Rate: 0.00897411
	LOSS [training: 0.2768414863678445 | validation: 0.21578097534682397]
	TIME [epoch: 18.8 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27044536861769114		[learning rate: 0.0089529]
	Learning Rate: 0.00895294
	LOSS [training: 0.27044536861769114 | validation: 0.21411110801934868]
	TIME [epoch: 18.8 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_vlargesamp_20240719_155254/states/model_facs_v3_dec1b_2dpca_vlargesamp_97.pth
	Model improved!!!
EPOCH 98/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27633636916730864		[learning rate: 0.0089318]
	Learning Rate: 0.00893182
	LOSS [training: 0.27633636916730864 | validation: 0.22375294014190117]
	TIME [epoch: 18.8 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27652573792481755		[learning rate: 0.0089108]
	Learning Rate: 0.00891076
	LOSS [training: 0.27652573792481755 | validation: 0.21786426362188127]
	TIME [epoch: 18.8 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.276985271387221		[learning rate: 0.0088897]
	Learning Rate: 0.00888974
	LOSS [training: 0.276985271387221 | validation: 0.21648683240365124]
	TIME [epoch: 18.8 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27299634932386896		[learning rate: 0.0088688]
	Learning Rate: 0.00886877
	LOSS [training: 0.27299634932386896 | validation: 0.21083373453169832]
	TIME [epoch: 18.8 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_vlargesamp_20240719_155254/states/model_facs_v3_dec1b_2dpca_vlargesamp_101.pth
	Model improved!!!
EPOCH 102/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2871990715131834		[learning rate: 0.0088478]
	Learning Rate: 0.00884785
	LOSS [training: 0.2871990715131834 | validation: 0.21972494621874833]
	TIME [epoch: 18.8 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.266558559015124		[learning rate: 0.008827]
	Learning Rate: 0.00882698
	LOSS [training: 0.266558559015124 | validation: 0.22277632558861046]
	TIME [epoch: 18.8 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28494247332247286		[learning rate: 0.0088062]
	Learning Rate: 0.00880615
	LOSS [training: 0.28494247332247286 | validation: 0.24021009136385402]
	TIME [epoch: 18.8 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2665461052312749		[learning rate: 0.0087854]
	Learning Rate: 0.00878538
	LOSS [training: 0.2665461052312749 | validation: 0.21440591478752644]
	TIME [epoch: 18.8 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2692534397872196		[learning rate: 0.0087647]
	Learning Rate: 0.00876466
	LOSS [training: 0.2692534397872196 | validation: 0.21903522607488252]
	TIME [epoch: 18.8 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2691850989799381		[learning rate: 0.008744]
	Learning Rate: 0.00874398
	LOSS [training: 0.2691850989799381 | validation: 0.21389978504663923]
	TIME [epoch: 18.8 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2674606268688563		[learning rate: 0.0087234]
	Learning Rate: 0.00872336
	LOSS [training: 0.2674606268688563 | validation: 0.23527985067528787]
	TIME [epoch: 18.8 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.30500092124803163		[learning rate: 0.0087028]
	Learning Rate: 0.00870278
	LOSS [training: 0.30500092124803163 | validation: 0.2242824358905346]
	TIME [epoch: 18.8 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2837561334171546		[learning rate: 0.0086823]
	Learning Rate: 0.00868225
	LOSS [training: 0.2837561334171546 | validation: 0.21572088654261923]
	TIME [epoch: 18.8 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2755655057607531		[learning rate: 0.0086618]
	Learning Rate: 0.00866177
	LOSS [training: 0.2755655057607531 | validation: 0.2170197110552023]
	TIME [epoch: 18.8 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2795362354538536		[learning rate: 0.0086413]
	Learning Rate: 0.00864134
	LOSS [training: 0.2795362354538536 | validation: 0.21833771466642196]
	TIME [epoch: 18.8 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26742083021599133		[learning rate: 0.008621]
	Learning Rate: 0.00862096
	LOSS [training: 0.26742083021599133 | validation: 0.21373718917893783]
	TIME [epoch: 18.8 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27625141037137974		[learning rate: 0.0086006]
	Learning Rate: 0.00860062
	LOSS [training: 0.27625141037137974 | validation: 0.21193132163945197]
	TIME [epoch: 18.8 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2679016113944908		[learning rate: 0.0085803]
	Learning Rate: 0.00858034
	LOSS [training: 0.2679016113944908 | validation: 0.22717524614284734]
	TIME [epoch: 18.8 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27863771812429744		[learning rate: 0.0085601]
	Learning Rate: 0.00856009
	LOSS [training: 0.27863771812429744 | validation: 0.21747217221147594]
	TIME [epoch: 18.8 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2691898804285936		[learning rate: 0.0085399]
	Learning Rate: 0.0085399
	LOSS [training: 0.2691898804285936 | validation: 0.23494392484869628]
	TIME [epoch: 18.8 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2684047797013349		[learning rate: 0.0085198]
	Learning Rate: 0.00851976
	LOSS [training: 0.2684047797013349 | validation: 0.21510416746438063]
	TIME [epoch: 18.8 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2668906649653043		[learning rate: 0.0084997]
	Learning Rate: 0.00849966
	LOSS [training: 0.2668906649653043 | validation: 0.2178259606254432]
	TIME [epoch: 18.8 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2652488784385489		[learning rate: 0.0084796]
	Learning Rate: 0.00847961
	LOSS [training: 0.2652488784385489 | validation: 0.22047772494952794]
	TIME [epoch: 18.8 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2769746435556217		[learning rate: 0.0084596]
	Learning Rate: 0.00845961
	LOSS [training: 0.2769746435556217 | validation: 0.2198195072877413]
	TIME [epoch: 18.8 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2711285315095838		[learning rate: 0.0084397]
	Learning Rate: 0.00843966
	LOSS [training: 0.2711285315095838 | validation: 0.21781259322937885]
	TIME [epoch: 18.8 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27181239798121587		[learning rate: 0.0084197]
	Learning Rate: 0.00841975
	LOSS [training: 0.27181239798121587 | validation: 0.2159084772509626]
	TIME [epoch: 18.8 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26874721738678203		[learning rate: 0.0083999]
	Learning Rate: 0.00839989
	LOSS [training: 0.26874721738678203 | validation: 0.2136131607711861]
	TIME [epoch: 18.8 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2677518024279448		[learning rate: 0.0083801]
	Learning Rate: 0.00838007
	LOSS [training: 0.2677518024279448 | validation: 0.21705513025749976]
	TIME [epoch: 18.8 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2758652747063443		[learning rate: 0.0083603]
	Learning Rate: 0.00836031
	LOSS [training: 0.2758652747063443 | validation: 0.22104680671098667]
	TIME [epoch: 18.8 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2664229181258082		[learning rate: 0.0083406]
	Learning Rate: 0.00834059
	LOSS [training: 0.2664229181258082 | validation: 0.22390010046738085]
	TIME [epoch: 18.8 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2647498922871959		[learning rate: 0.0083209]
	Learning Rate: 0.00832091
	LOSS [training: 0.2647498922871959 | validation: 0.2133037573596582]
	TIME [epoch: 18.8 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26077491585058193		[learning rate: 0.0083013]
	Learning Rate: 0.00830128
	LOSS [training: 0.26077491585058193 | validation: 0.2383956303694042]
	TIME [epoch: 18.8 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28227062206338865		[learning rate: 0.0082817]
	Learning Rate: 0.0082817
	LOSS [training: 0.28227062206338865 | validation: 0.21238557014811826]
	TIME [epoch: 18.8 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2604326259798109		[learning rate: 0.0082622]
	Learning Rate: 0.00826217
	LOSS [training: 0.2604326259798109 | validation: 0.2166315250706475]
	TIME [epoch: 18.8 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2678071874655343		[learning rate: 0.0082427]
	Learning Rate: 0.00824268
	LOSS [training: 0.2678071874655343 | validation: 0.21261829977182223]
	TIME [epoch: 18.8 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26164816100792276		[learning rate: 0.0082232]
	Learning Rate: 0.00822324
	LOSS [training: 0.26164816100792276 | validation: 0.22512498154937374]
	TIME [epoch: 18.8 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2731974958669731		[learning rate: 0.0082038]
	Learning Rate: 0.00820384
	LOSS [training: 0.2731974958669731 | validation: 0.21710159831797218]
	TIME [epoch: 18.8 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27338108535345756		[learning rate: 0.0081845]
	Learning Rate: 0.00818449
	LOSS [training: 0.27338108535345756 | validation: 0.22624514318815975]
	TIME [epoch: 18.8 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2740189493924381		[learning rate: 0.0081652]
	Learning Rate: 0.00816518
	LOSS [training: 0.2740189493924381 | validation: 0.21659795422447892]
	TIME [epoch: 18.8 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2674052470187139		[learning rate: 0.0081459]
	Learning Rate: 0.00814592
	LOSS [training: 0.2674052470187139 | validation: 0.21780642722613225]
	TIME [epoch: 18.8 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27530028103566323		[learning rate: 0.0081267]
	Learning Rate: 0.00812671
	LOSS [training: 0.27530028103566323 | validation: 0.21838835938532314]
	TIME [epoch: 18.8 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27263776454579663		[learning rate: 0.0081075]
	Learning Rate: 0.00810754
	LOSS [training: 0.27263776454579663 | validation: 0.2163257025432171]
	TIME [epoch: 18.8 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2630488127260115		[learning rate: 0.0080884]
	Learning Rate: 0.00808841
	LOSS [training: 0.2630488127260115 | validation: 0.21100720059326417]
	TIME [epoch: 18.8 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26344829473161374		[learning rate: 0.0080693]
	Learning Rate: 0.00806933
	LOSS [training: 0.26344829473161374 | validation: 0.218012042848229]
	TIME [epoch: 18.8 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26017292520018925		[learning rate: 0.0080503]
	Learning Rate: 0.0080503
	LOSS [training: 0.26017292520018925 | validation: 0.22201836253707863]
	TIME [epoch: 18.8 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26251907979605044		[learning rate: 0.0080313]
	Learning Rate: 0.00803131
	LOSS [training: 0.26251907979605044 | validation: 0.21370033615924297]
	TIME [epoch: 18.8 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2670589551559294		[learning rate: 0.0080124]
	Learning Rate: 0.00801236
	LOSS [training: 0.2670589551559294 | validation: 0.21611110202643374]
	TIME [epoch: 18.8 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2684647669466707		[learning rate: 0.0079935]
	Learning Rate: 0.00799346
	LOSS [training: 0.2684647669466707 | validation: 0.21052267894868945]
	TIME [epoch: 18.8 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_vlargesamp_20240719_155254/states/model_facs_v3_dec1b_2dpca_vlargesamp_145.pth
	Model improved!!!
EPOCH 146/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2586721306833468		[learning rate: 0.0079746]
	Learning Rate: 0.00797461
	LOSS [training: 0.2586721306833468 | validation: 0.21161017631490422]
	TIME [epoch: 18.8 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2633140682896411		[learning rate: 0.0079558]
	Learning Rate: 0.0079558
	LOSS [training: 0.2633140682896411 | validation: 0.20711475275740748]
	TIME [epoch: 18.8 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_vlargesamp_20240719_155254/states/model_facs_v3_dec1b_2dpca_vlargesamp_147.pth
	Model improved!!!
EPOCH 148/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25625535465097476		[learning rate: 0.007937]
	Learning Rate: 0.00793703
	LOSS [training: 0.25625535465097476 | validation: 0.21652868870710495]
	TIME [epoch: 18.8 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2807859898069998		[learning rate: 0.0079183]
	Learning Rate: 0.00791831
	LOSS [training: 0.2807859898069998 | validation: 0.2182800029579388]
	TIME [epoch: 18.8 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2653469906637232		[learning rate: 0.0078996]
	Learning Rate: 0.00789963
	LOSS [training: 0.2653469906637232 | validation: 0.2170449016191603]
	TIME [epoch: 18.8 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26618834067203323		[learning rate: 0.007881]
	Learning Rate: 0.007881
	LOSS [training: 0.26618834067203323 | validation: 0.22069625457316594]
	TIME [epoch: 40.3 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2680843026695276		[learning rate: 0.0078624]
	Learning Rate: 0.00786241
	LOSS [training: 0.2680843026695276 | validation: 0.21690094963413764]
	TIME [epoch: 23 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2597883002979131		[learning rate: 0.0078439]
	Learning Rate: 0.00784386
	LOSS [training: 0.2597883002979131 | validation: 0.21007012483209925]
	TIME [epoch: 23 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25855192000312277		[learning rate: 0.0078254]
	Learning Rate: 0.00782536
	LOSS [training: 0.25855192000312277 | validation: 0.2143730463480802]
	TIME [epoch: 23 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2600351894341569		[learning rate: 0.0078069]
	Learning Rate: 0.0078069
	LOSS [training: 0.2600351894341569 | validation: 0.2143469143981657]
	TIME [epoch: 23 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2720344545062895		[learning rate: 0.0077885]
	Learning Rate: 0.00778848
	LOSS [training: 0.2720344545062895 | validation: 0.21167619979878025]
	TIME [epoch: 23 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2607218609544276		[learning rate: 0.0077701]
	Learning Rate: 0.00777011
	LOSS [training: 0.2607218609544276 | validation: 0.2109935564104227]
	TIME [epoch: 23 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2650330823366623		[learning rate: 0.0077518]
	Learning Rate: 0.00775178
	LOSS [training: 0.2650330823366623 | validation: 0.21220454390675364]
	TIME [epoch: 23 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26039253892016273		[learning rate: 0.0077335]
	Learning Rate: 0.0077335
	LOSS [training: 0.26039253892016273 | validation: 0.21148262357071285]
	TIME [epoch: 23 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2589758068854164		[learning rate: 0.0077153]
	Learning Rate: 0.00771526
	LOSS [training: 0.2589758068854164 | validation: 0.22007196240244378]
	TIME [epoch: 23 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2619301451387738		[learning rate: 0.0076971]
	Learning Rate: 0.00769706
	LOSS [training: 0.2619301451387738 | validation: 0.21945698477075154]
	TIME [epoch: 23 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2628068115291936		[learning rate: 0.0076789]
	Learning Rate: 0.0076789
	LOSS [training: 0.2628068115291936 | validation: 0.21746375211277505]
	TIME [epoch: 23 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2593452002152254		[learning rate: 0.0076608]
	Learning Rate: 0.00766079
	LOSS [training: 0.2593452002152254 | validation: 0.21036814081773772]
	TIME [epoch: 23 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2621582959595965		[learning rate: 0.0076427]
	Learning Rate: 0.00764272
	LOSS [training: 0.2621582959595965 | validation: 0.21067258943815897]
	TIME [epoch: 23 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2536208523755106		[learning rate: 0.0076247]
	Learning Rate: 0.00762469
	LOSS [training: 0.2536208523755106 | validation: 0.2239862582515138]
	TIME [epoch: 23 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25908155613061973		[learning rate: 0.0076067]
	Learning Rate: 0.0076067
	LOSS [training: 0.25908155613061973 | validation: 0.23022905989241438]
	TIME [epoch: 23 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2641251745333315		[learning rate: 0.0075888]
	Learning Rate: 0.00758876
	LOSS [training: 0.2641251745333315 | validation: 0.21576736579366923]
	TIME [epoch: 23 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25950429714098944		[learning rate: 0.0075709]
	Learning Rate: 0.00757086
	LOSS [training: 0.25950429714098944 | validation: 0.2116029863311954]
	TIME [epoch: 23 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2614966240377469		[learning rate: 0.007553]
	Learning Rate: 0.007553
	LOSS [training: 0.2614966240377469 | validation: 0.21733223526119566]
	TIME [epoch: 23 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2561709186689166		[learning rate: 0.0075352]
	Learning Rate: 0.00753519
	LOSS [training: 0.2561709186689166 | validation: 0.21947426516143925]
	TIME [epoch: 23 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25990569565103494		[learning rate: 0.0075174]
	Learning Rate: 0.00751741
	LOSS [training: 0.25990569565103494 | validation: 0.20959845545787376]
	TIME [epoch: 23 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.264104264856822		[learning rate: 0.0074997]
	Learning Rate: 0.00749968
	LOSS [training: 0.264104264856822 | validation: 0.21421455194022085]
	TIME [epoch: 23 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26426128722770476		[learning rate: 0.007482]
	Learning Rate: 0.00748199
	LOSS [training: 0.26426128722770476 | validation: 0.21057570884560667]
	TIME [epoch: 23 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25335285012913494		[learning rate: 0.0074643]
	Learning Rate: 0.00746434
	LOSS [training: 0.25335285012913494 | validation: 0.22256467179422224]
	TIME [epoch: 23 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2611147919428843		[learning rate: 0.0074467]
	Learning Rate: 0.00744673
	LOSS [training: 0.2611147919428843 | validation: 0.22066703095789114]
	TIME [epoch: 23 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26966540637625874		[learning rate: 0.0074292]
	Learning Rate: 0.00742917
	LOSS [training: 0.26966540637625874 | validation: 0.21055112316117333]
	TIME [epoch: 23 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25581118810127895		[learning rate: 0.0074116]
	Learning Rate: 0.00741164
	LOSS [training: 0.25581118810127895 | validation: 0.21567170873629932]
	TIME [epoch: 23 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2549113931288839		[learning rate: 0.0073942]
	Learning Rate: 0.00739416
	LOSS [training: 0.2549113931288839 | validation: 0.21471269400171217]
	TIME [epoch: 23 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25816010578414766		[learning rate: 0.0073767]
	Learning Rate: 0.00737672
	LOSS [training: 0.25816010578414766 | validation: 0.21623251760593645]
	TIME [epoch: 23 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2579710880265837		[learning rate: 0.0073593]
	Learning Rate: 0.00735932
	LOSS [training: 0.2579710880265837 | validation: 0.2218698809024195]
	TIME [epoch: 23 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26900816161381186		[learning rate: 0.007342]
	Learning Rate: 0.00734196
	LOSS [training: 0.26900816161381186 | validation: 0.21503108221489936]
	TIME [epoch: 23 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2691573445030814		[learning rate: 0.0073246]
	Learning Rate: 0.00732464
	LOSS [training: 0.2691573445030814 | validation: 0.2122952705393252]
	TIME [epoch: 23 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25806312995553		[learning rate: 0.0073074]
	Learning Rate: 0.00730736
	LOSS [training: 0.25806312995553 | validation: 0.21697846602727094]
	TIME [epoch: 23 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26622998667745545		[learning rate: 0.0072901]
	Learning Rate: 0.00729013
	LOSS [training: 0.26622998667745545 | validation: 0.21576551745795486]
	TIME [epoch: 23 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.260199560233581		[learning rate: 0.0072729]
	Learning Rate: 0.00727293
	LOSS [training: 0.260199560233581 | validation: 0.21199784875484484]
	TIME [epoch: 23 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2654170538154534		[learning rate: 0.0072558]
	Learning Rate: 0.00725577
	LOSS [training: 0.2654170538154534 | validation: 0.21014905132828793]
	TIME [epoch: 23 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2598304990778307		[learning rate: 0.0072387]
	Learning Rate: 0.00723866
	LOSS [training: 0.2598304990778307 | validation: 0.21276037041343607]
	TIME [epoch: 23 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26120277240712725		[learning rate: 0.0072216]
	Learning Rate: 0.00722158
	LOSS [training: 0.26120277240712725 | validation: 0.2094632423489589]
	TIME [epoch: 23.1 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2727165002387926		[learning rate: 0.0072045]
	Learning Rate: 0.00720455
	LOSS [training: 0.2727165002387926 | validation: 0.21659728048144986]
	TIME [epoch: 23 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27305660826054473		[learning rate: 0.0071876]
	Learning Rate: 0.00718756
	LOSS [training: 0.27305660826054473 | validation: 0.2098736276062268]
	TIME [epoch: 23 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2572617454030374		[learning rate: 0.0071706]
	Learning Rate: 0.0071706
	LOSS [training: 0.2572617454030374 | validation: 0.20867807514638853]
	TIME [epoch: 23 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2598522803742161		[learning rate: 0.0071537]
	Learning Rate: 0.00715369
	LOSS [training: 0.2598522803742161 | validation: 0.2145020820731009]
	TIME [epoch: 23 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2581644993605566		[learning rate: 0.0071368]
	Learning Rate: 0.00713681
	LOSS [training: 0.2581644993605566 | validation: 0.21398012660941626]
	TIME [epoch: 23 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2559189949285798		[learning rate: 0.00712]
	Learning Rate: 0.00711998
	LOSS [training: 0.2559189949285798 | validation: 0.21617245916719652]
	TIME [epoch: 23 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26659281675763696		[learning rate: 0.0071032]
	Learning Rate: 0.00710318
	LOSS [training: 0.26659281675763696 | validation: 0.21526569258186723]
	TIME [epoch: 23.3 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26889159851894595		[learning rate: 0.0070864]
	Learning Rate: 0.00708643
	LOSS [training: 0.26889159851894595 | validation: 0.21300377196045278]
	TIME [epoch: 23 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26052209874562376		[learning rate: 0.0070697]
	Learning Rate: 0.00706971
	LOSS [training: 0.26052209874562376 | validation: 0.20960934224885114]
	TIME [epoch: 23 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25541912769709213		[learning rate: 0.007053]
	Learning Rate: 0.00705303
	LOSS [training: 0.25541912769709213 | validation: 0.21229920118210793]
	TIME [epoch: 23.1 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26607929543857545		[learning rate: 0.0070364]
	Learning Rate: 0.0070364
	LOSS [training: 0.26607929543857545 | validation: 0.21139553735593694]
	TIME [epoch: 23 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2586706250522048		[learning rate: 0.0070198]
	Learning Rate: 0.0070198
	LOSS [training: 0.2586706250522048 | validation: 0.21738439643912977]
	TIME [epoch: 23 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2520649763505848		[learning rate: 0.0070032]
	Learning Rate: 0.00700324
	LOSS [training: 0.2520649763505848 | validation: 0.21489462093223316]
	TIME [epoch: 23 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26392868676908626		[learning rate: 0.0069867]
	Learning Rate: 0.00698672
	LOSS [training: 0.26392868676908626 | validation: 0.214118807584961]
	TIME [epoch: 23 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25696059367615737		[learning rate: 0.0069702]
	Learning Rate: 0.00697024
	LOSS [training: 0.25696059367615737 | validation: 0.2154314084157977]
	TIME [epoch: 23 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25669255120546913		[learning rate: 0.0069538]
	Learning Rate: 0.0069538
	LOSS [training: 0.25669255120546913 | validation: 0.2094409581562584]
	TIME [epoch: 23 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26630859273750734		[learning rate: 0.0069374]
	Learning Rate: 0.0069374
	LOSS [training: 0.26630859273750734 | validation: 0.2110944933360029]
	TIME [epoch: 23 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25575705251671155		[learning rate: 0.006921]
	Learning Rate: 0.00692103
	LOSS [training: 0.25575705251671155 | validation: 0.20924061452093023]
	TIME [epoch: 23 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.257723976591241		[learning rate: 0.0069047]
	Learning Rate: 0.00690471
	LOSS [training: 0.257723976591241 | validation: 0.20942677734888648]
	TIME [epoch: 23 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.250413563393414		[learning rate: 0.0068884]
	Learning Rate: 0.00688842
	LOSS [training: 0.250413563393414 | validation: 0.21858977543034142]
	TIME [epoch: 23 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2608006830549039		[learning rate: 0.0068722]
	Learning Rate: 0.00687217
	LOSS [training: 0.2608006830549039 | validation: 0.2102992533759492]
	TIME [epoch: 23 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24967366518050207		[learning rate: 0.006856]
	Learning Rate: 0.00685596
	LOSS [training: 0.24967366518050207 | validation: 0.21572334677306976]
	TIME [epoch: 23 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25598365293364317		[learning rate: 0.0068398]
	Learning Rate: 0.00683979
	LOSS [training: 0.25598365293364317 | validation: 0.2085438006104871]
	TIME [epoch: 23 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25704251818926094		[learning rate: 0.0068237]
	Learning Rate: 0.00682366
	LOSS [training: 0.25704251818926094 | validation: 0.21998573275091213]
	TIME [epoch: 23 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2559547635365926		[learning rate: 0.0068076]
	Learning Rate: 0.00680756
	LOSS [training: 0.2559547635365926 | validation: 0.2226823493816923]
	TIME [epoch: 23 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26529011045457435		[learning rate: 0.0067915]
	Learning Rate: 0.0067915
	LOSS [training: 0.26529011045457435 | validation: 0.21685085579089836]
	TIME [epoch: 23 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2528112740777783		[learning rate: 0.0067755]
	Learning Rate: 0.00677548
	LOSS [training: 0.2528112740777783 | validation: 0.21108338720437728]
	TIME [epoch: 23 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26260118414146394		[learning rate: 0.0067595]
	Learning Rate: 0.0067595
	LOSS [training: 0.26260118414146394 | validation: 0.2202176676150751]
	TIME [epoch: 23 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25191066455054695		[learning rate: 0.0067436]
	Learning Rate: 0.00674355
	LOSS [training: 0.25191066455054695 | validation: 0.21112890456886121]
	TIME [epoch: 23 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2511798752164665		[learning rate: 0.0067276]
	Learning Rate: 0.00672765
	LOSS [training: 0.2511798752164665 | validation: 0.21867459980762907]
	TIME [epoch: 23 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2548844300655166		[learning rate: 0.0067118]
	Learning Rate: 0.00671178
	LOSS [training: 0.2548844300655166 | validation: 0.21692966669045863]
	TIME [epoch: 23 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2632386055182947		[learning rate: 0.0066959]
	Learning Rate: 0.00669595
	LOSS [training: 0.2632386055182947 | validation: 0.21903106882743656]
	TIME [epoch: 23 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2690734969331268		[learning rate: 0.0066802]
	Learning Rate: 0.00668015
	LOSS [training: 0.2690734969331268 | validation: 0.21468544284599728]
	TIME [epoch: 23 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2561181730907349		[learning rate: 0.0066644]
	Learning Rate: 0.00666439
	LOSS [training: 0.2561181730907349 | validation: 0.21665046055849926]
	TIME [epoch: 23 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25435060555632577		[learning rate: 0.0066487]
	Learning Rate: 0.00664867
	LOSS [training: 0.25435060555632577 | validation: 0.20973707345464448]
	TIME [epoch: 23 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25551312479312205		[learning rate: 0.006633]
	Learning Rate: 0.00663299
	LOSS [training: 0.25551312479312205 | validation: 0.2147511960396617]
	TIME [epoch: 23 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2683141504309296		[learning rate: 0.0066173]
	Learning Rate: 0.00661734
	LOSS [training: 0.2683141504309296 | validation: 0.2085915420332892]
	TIME [epoch: 23 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25363357665860214		[learning rate: 0.0066017]
	Learning Rate: 0.00660174
	LOSS [training: 0.25363357665860214 | validation: 0.21639511889834012]
	TIME [epoch: 23 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2617051347262971		[learning rate: 0.0065862]
	Learning Rate: 0.00658616
	LOSS [training: 0.2617051347262971 | validation: 0.2115479535910026]
	TIME [epoch: 23 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25205602082924017		[learning rate: 0.0065706]
	Learning Rate: 0.00657063
	LOSS [training: 0.25205602082924017 | validation: 0.20767857504286452]
	TIME [epoch: 23 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2504391574052646		[learning rate: 0.0065551]
	Learning Rate: 0.00655513
	LOSS [training: 0.2504391574052646 | validation: 0.20793024027206028]
	TIME [epoch: 23 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25711525416185443		[learning rate: 0.0065397]
	Learning Rate: 0.00653967
	LOSS [training: 0.25711525416185443 | validation: 0.2121016304656044]
	TIME [epoch: 23 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2626011066491918		[learning rate: 0.0065242]
	Learning Rate: 0.00652424
	LOSS [training: 0.2626011066491918 | validation: 0.2128697683583717]
	TIME [epoch: 23 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25681733221661784		[learning rate: 0.0065088]
	Learning Rate: 0.00650885
	LOSS [training: 0.25681733221661784 | validation: 0.2135053790764858]
	TIME [epoch: 23 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2507394266646306		[learning rate: 0.0064935]
	Learning Rate: 0.0064935
	LOSS [training: 0.2507394266646306 | validation: 0.218715112989836]
	TIME [epoch: 23 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26749121695382705		[learning rate: 0.0064782]
	Learning Rate: 0.00647818
	LOSS [training: 0.26749121695382705 | validation: 0.20801346153580152]
	TIME [epoch: 23 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2551083039463226		[learning rate: 0.0064629]
	Learning Rate: 0.0064629
	LOSS [training: 0.2551083039463226 | validation: 0.21143922204508314]
	TIME [epoch: 23.9 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.255196440892541		[learning rate: 0.0064477]
	Learning Rate: 0.00644765
	LOSS [training: 0.255196440892541 | validation: 0.21058771406550295]
	TIME [epoch: 23 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2569079451282559		[learning rate: 0.0064324]
	Learning Rate: 0.00643244
	LOSS [training: 0.2569079451282559 | validation: 0.2097211988868255]
	TIME [epoch: 23 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25001146671978813		[learning rate: 0.0064173]
	Learning Rate: 0.00641727
	LOSS [training: 0.25001146671978813 | validation: 0.22067344089617108]
	TIME [epoch: 23 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2610576471402675		[learning rate: 0.0064021]
	Learning Rate: 0.00640213
	LOSS [training: 0.2610576471402675 | validation: 0.2123454819339407]
	TIME [epoch: 23 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25310622389450815		[learning rate: 0.006387]
	Learning Rate: 0.00638703
	LOSS [training: 0.25310622389450815 | validation: 0.218386380156082]
	TIME [epoch: 23 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25738672445581595		[learning rate: 0.006372]
	Learning Rate: 0.00637197
	LOSS [training: 0.25738672445581595 | validation: 0.21078560433446386]
	TIME [epoch: 23 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2618459923387143		[learning rate: 0.0063569]
	Learning Rate: 0.00635694
	LOSS [training: 0.2618459923387143 | validation: 0.20890869817138863]
	TIME [epoch: 23 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24838944638943253		[learning rate: 0.0063419]
	Learning Rate: 0.00634194
	LOSS [training: 0.24838944638943253 | validation: 0.2132098882486741]
	TIME [epoch: 23 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25695954692061446		[learning rate: 0.006327]
	Learning Rate: 0.00632698
	LOSS [training: 0.25695954692061446 | validation: 0.21269800349454115]
	TIME [epoch: 23 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25961226591857584		[learning rate: 0.0063121]
	Learning Rate: 0.00631206
	LOSS [training: 0.25961226591857584 | validation: 0.21409269190880303]
	TIME [epoch: 23 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2586574301392543		[learning rate: 0.0062972]
	Learning Rate: 0.00629717
	LOSS [training: 0.2586574301392543 | validation: 0.20886500854872017]
	TIME [epoch: 23 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25252998721329883		[learning rate: 0.0062823]
	Learning Rate: 0.00628231
	LOSS [training: 0.25252998721329883 | validation: 0.21556480604117506]
	TIME [epoch: 23 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25095427561832934		[learning rate: 0.0062675]
	Learning Rate: 0.00626749
	LOSS [training: 0.25095427561832934 | validation: 0.21471401511950688]
	TIME [epoch: 23 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2615398496609318		[learning rate: 0.0062527]
	Learning Rate: 0.00625271
	LOSS [training: 0.2615398496609318 | validation: 0.21051464129506386]
	TIME [epoch: 23 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25433476456329385		[learning rate: 0.006238]
	Learning Rate: 0.00623796
	LOSS [training: 0.25433476456329385 | validation: 0.21273636808637636]
	TIME [epoch: 23 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26823726972678436		[learning rate: 0.0062232]
	Learning Rate: 0.00622325
	LOSS [training: 0.26823726972678436 | validation: 0.2151850138467148]
	TIME [epoch: 45.6 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2607882076484445		[learning rate: 0.0062086]
	Learning Rate: 0.00620857
	LOSS [training: 0.2607882076484445 | validation: 0.2178432825879743]
	TIME [epoch: 28.4 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25367301185837365		[learning rate: 0.0061939]
	Learning Rate: 0.00619392
	LOSS [training: 0.25367301185837365 | validation: 0.21144052579359815]
	TIME [epoch: 28.4 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25356445352490425		[learning rate: 0.0061793]
	Learning Rate: 0.00617931
	LOSS [training: 0.25356445352490425 | validation: 0.21912591210402255]
	TIME [epoch: 28.4 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2573070643781195		[learning rate: 0.0061647]
	Learning Rate: 0.00616474
	LOSS [training: 0.2573070643781195 | validation: 0.21129191138612313]
	TIME [epoch: 28.4 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25402163215477164		[learning rate: 0.0061502]
	Learning Rate: 0.00615019
	LOSS [training: 0.25402163215477164 | validation: 0.20738166610537875]
	TIME [epoch: 28.4 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2534931712213429		[learning rate: 0.0061357]
	Learning Rate: 0.00613569
	LOSS [training: 0.2534931712213429 | validation: 0.2145837184531078]
	TIME [epoch: 28.4 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2636347009050202		[learning rate: 0.0061212]
	Learning Rate: 0.00612121
	LOSS [training: 0.2636347009050202 | validation: 0.21605631068223996]
	TIME [epoch: 28.4 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25955406500774436		[learning rate: 0.0061068]
	Learning Rate: 0.00610678
	LOSS [training: 0.25955406500774436 | validation: 0.20599404011926842]
	TIME [epoch: 28.4 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_vlargesamp_20240719_155254/states/model_facs_v3_dec1b_2dpca_vlargesamp_259.pth
	Model improved!!!
EPOCH 260/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.254854579543312		[learning rate: 0.0060924]
	Learning Rate: 0.00609237
	LOSS [training: 0.254854579543312 | validation: 0.20938833715438623]
	TIME [epoch: 28.4 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25336491910945		[learning rate: 0.006078]
	Learning Rate: 0.006078
	LOSS [training: 0.25336491910945 | validation: 0.20782592115644344]
	TIME [epoch: 28.4 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2502076092813386		[learning rate: 0.0060637]
	Learning Rate: 0.00606366
	LOSS [training: 0.2502076092813386 | validation: 0.20965731042367083]
	TIME [epoch: 28.4 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2545590032511668		[learning rate: 0.0060494]
	Learning Rate: 0.00604936
	LOSS [training: 0.2545590032511668 | validation: 0.21569408621697517]
	TIME [epoch: 28.4 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25857444819890135		[learning rate: 0.0060351]
	Learning Rate: 0.00603509
	LOSS [training: 0.25857444819890135 | validation: 0.2159817837677714]
	TIME [epoch: 28.4 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26217816438247027		[learning rate: 0.0060209]
	Learning Rate: 0.00602085
	LOSS [training: 0.26217816438247027 | validation: 0.21125365803096954]
	TIME [epoch: 28.4 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2603804481524889		[learning rate: 0.0060067]
	Learning Rate: 0.00600665
	LOSS [training: 0.2603804481524889 | validation: 0.21249168102269614]
	TIME [epoch: 28.4 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2538017193562327		[learning rate: 0.0059925]
	Learning Rate: 0.00599248
	LOSS [training: 0.2538017193562327 | validation: 0.208334356123295]
	TIME [epoch: 28.4 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25529046160697216		[learning rate: 0.0059783]
	Learning Rate: 0.00597835
	LOSS [training: 0.25529046160697216 | validation: 0.22332653381403905]
	TIME [epoch: 28.4 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25403995675973684		[learning rate: 0.0059642]
	Learning Rate: 0.00596425
	LOSS [training: 0.25403995675973684 | validation: 0.20878548894154977]
	TIME [epoch: 28.4 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25010008279317714		[learning rate: 0.0059502]
	Learning Rate: 0.00595018
	LOSS [training: 0.25010008279317714 | validation: 0.21004381993462165]
	TIME [epoch: 28.4 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2523591870632631		[learning rate: 0.0059361]
	Learning Rate: 0.00593614
	LOSS [training: 0.2523591870632631 | validation: 0.22072164119951432]
	TIME [epoch: 28.4 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25422884463009454		[learning rate: 0.0059221]
	Learning Rate: 0.00592214
	LOSS [training: 0.25422884463009454 | validation: 0.21677075652100575]
	TIME [epoch: 28.4 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2602313067848082		[learning rate: 0.0059082]
	Learning Rate: 0.00590817
	LOSS [training: 0.2602313067848082 | validation: 0.21187723477391626]
	TIME [epoch: 28.4 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2477387744390633		[learning rate: 0.0058942]
	Learning Rate: 0.00589423
	LOSS [training: 0.2477387744390633 | validation: 0.20936764883058698]
	TIME [epoch: 28.4 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24686722048433865		[learning rate: 0.0058803]
	Learning Rate: 0.00588033
	LOSS [training: 0.24686722048433865 | validation: 0.20690118974091165]
	TIME [epoch: 28.4 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2526608743330681		[learning rate: 0.0058665]
	Learning Rate: 0.00586646
	LOSS [training: 0.2526608743330681 | validation: 0.2115804368152277]
	TIME [epoch: 28.4 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2572357550481491		[learning rate: 0.0058526]
	Learning Rate: 0.00585262
	LOSS [training: 0.2572357550481491 | validation: 0.21603548740465736]
	TIME [epoch: 28.4 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2512929563835559		[learning rate: 0.0058388]
	Learning Rate: 0.00583882
	LOSS [training: 0.2512929563835559 | validation: 0.21230289454285578]
	TIME [epoch: 28.4 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2506494294395501		[learning rate: 0.005825]
	Learning Rate: 0.00582504
	LOSS [training: 0.2506494294395501 | validation: 0.21306936641495783]
	TIME [epoch: 28.4 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2507848204965335		[learning rate: 0.0058113]
	Learning Rate: 0.0058113
	LOSS [training: 0.2507848204965335 | validation: 0.2219274337347359]
	TIME [epoch: 28.4 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2549436375660068		[learning rate: 0.0057976]
	Learning Rate: 0.00579759
	LOSS [training: 0.2549436375660068 | validation: 0.21192718456654563]
	TIME [epoch: 28.4 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26197847876351893		[learning rate: 0.0057839]
	Learning Rate: 0.00578392
	LOSS [training: 0.26197847876351893 | validation: 0.21741184872625058]
	TIME [epoch: 28.4 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2586883215734323		[learning rate: 0.0057703]
	Learning Rate: 0.00577028
	LOSS [training: 0.2586883215734323 | validation: 0.205488800841636]
	TIME [epoch: 28.4 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_vlargesamp_20240719_155254/states/model_facs_v3_dec1b_2dpca_vlargesamp_283.pth
	Model improved!!!
EPOCH 284/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24620610223663317		[learning rate: 0.0057567]
	Learning Rate: 0.00575666
	LOSS [training: 0.24620610223663317 | validation: 0.21979348335370186]
	TIME [epoch: 28.4 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24977744057357212		[learning rate: 0.0057431]
	Learning Rate: 0.00574309
	LOSS [training: 0.24977744057357212 | validation: 0.21300702707219968]
	TIME [epoch: 28.4 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24817287254861775		[learning rate: 0.0057295]
	Learning Rate: 0.00572954
	LOSS [training: 0.24817287254861775 | validation: 0.21290494485117453]
	TIME [epoch: 28.4 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2504850600116615		[learning rate: 0.005716]
	Learning Rate: 0.00571602
	LOSS [training: 0.2504850600116615 | validation: 0.208439337073981]
	TIME [epoch: 28.4 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2578075751613437		[learning rate: 0.0057025]
	Learning Rate: 0.00570254
	LOSS [training: 0.2578075751613437 | validation: 0.21435073068152893]
	TIME [epoch: 28.4 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2616668107665551		[learning rate: 0.0056891]
	Learning Rate: 0.00568909
	LOSS [training: 0.2616668107665551 | validation: 0.20719274007752314]
	TIME [epoch: 28.4 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25932748941895206		[learning rate: 0.0056757]
	Learning Rate: 0.00567567
	LOSS [training: 0.25932748941895206 | validation: 0.20753285905625382]
	TIME [epoch: 28.4 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25151629131039305		[learning rate: 0.0056623]
	Learning Rate: 0.00566228
	LOSS [training: 0.25151629131039305 | validation: 0.21292955409378034]
	TIME [epoch: 28.4 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25392844907668916		[learning rate: 0.0056489]
	Learning Rate: 0.00564892
	LOSS [training: 0.25392844907668916 | validation: 0.21628303204201432]
	TIME [epoch: 28.4 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2475168095155161		[learning rate: 0.0056356]
	Learning Rate: 0.0056356
	LOSS [training: 0.2475168095155161 | validation: 0.21252913838764687]
	TIME [epoch: 28.4 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25227172256103914		[learning rate: 0.0056223]
	Learning Rate: 0.00562231
	LOSS [training: 0.25227172256103914 | validation: 0.20965504189076425]
	TIME [epoch: 28.4 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2595523904331443		[learning rate: 0.005609]
	Learning Rate: 0.00560904
	LOSS [training: 0.2595523904331443 | validation: 0.2109434461138807]
	TIME [epoch: 28.4 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2550104113867769		[learning rate: 0.0055958]
	Learning Rate: 0.00559581
	LOSS [training: 0.2550104113867769 | validation: 0.2088776022890125]
	TIME [epoch: 28.4 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2537872985873575		[learning rate: 0.0055826]
	Learning Rate: 0.00558261
	LOSS [training: 0.2537872985873575 | validation: 0.21503874101178194]
	TIME [epoch: 28.4 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2496720597108094		[learning rate: 0.0055694]
	Learning Rate: 0.00556945
	LOSS [training: 0.2496720597108094 | validation: 0.21049124269527483]
	TIME [epoch: 28.4 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2562215303423055		[learning rate: 0.0055563]
	Learning Rate: 0.00555631
	LOSS [training: 0.2562215303423055 | validation: 0.21270358297531203]
	TIME [epoch: 28.4 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2494604680551654		[learning rate: 0.0055432]
	Learning Rate: 0.0055432
	LOSS [training: 0.2494604680551654 | validation: 0.21531044818455541]
	TIME [epoch: 28.4 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24843498220537655		[learning rate: 0.0055301]
	Learning Rate: 0.00553013
	LOSS [training: 0.24843498220537655 | validation: 0.2172339654584036]
	TIME [epoch: 28.5 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24660823575786392		[learning rate: 0.0055171]
	Learning Rate: 0.00551708
	LOSS [training: 0.24660823575786392 | validation: 0.21963553095777116]
	TIME [epoch: 28.4 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25036763962505354		[learning rate: 0.0055041]
	Learning Rate: 0.00550407
	LOSS [training: 0.25036763962505354 | validation: 0.21416345487780228]
	TIME [epoch: 28.4 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24995943400090867		[learning rate: 0.0054911]
	Learning Rate: 0.00549108
	LOSS [training: 0.24995943400090867 | validation: 0.2129657130368389]
	TIME [epoch: 28.4 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26030454457721963		[learning rate: 0.0054781]
	Learning Rate: 0.00547813
	LOSS [training: 0.26030454457721963 | validation: 0.20746459301191505]
	TIME [epoch: 28.4 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25632880501305655		[learning rate: 0.0054652]
	Learning Rate: 0.00546521
	LOSS [training: 0.25632880501305655 | validation: 0.20809251611854176]
	TIME [epoch: 28.4 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2501082327831096		[learning rate: 0.0054523]
	Learning Rate: 0.00545232
	LOSS [training: 0.2501082327831096 | validation: 0.21210659810863186]
	TIME [epoch: 28.4 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2580158768262985		[learning rate: 0.0054395]
	Learning Rate: 0.00543946
	LOSS [training: 0.2580158768262985 | validation: 0.21894402319541864]
	TIME [epoch: 28.4 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2595931351497542		[learning rate: 0.0054266]
	Learning Rate: 0.00542663
	LOSS [training: 0.2595931351497542 | validation: 0.208986549997628]
	TIME [epoch: 28.4 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2445903703593003		[learning rate: 0.0054138]
	Learning Rate: 0.00541383
	LOSS [training: 0.2445903703593003 | validation: 0.20945653008748438]
	TIME [epoch: 28.4 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24718950174709278		[learning rate: 0.0054011]
	Learning Rate: 0.00540106
	LOSS [training: 0.24718950174709278 | validation: 0.2116556388069344]
	TIME [epoch: 28.4 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2471733871215024		[learning rate: 0.0053883]
	Learning Rate: 0.00538832
	LOSS [training: 0.2471733871215024 | validation: 0.21015633083244753]
	TIME [epoch: 28.4 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24735192551011295		[learning rate: 0.0053756]
	Learning Rate: 0.00537561
	LOSS [training: 0.24735192551011295 | validation: 0.21222425107901866]
	TIME [epoch: 28.4 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25067940780518555		[learning rate: 0.0053629]
	Learning Rate: 0.00536292
	LOSS [training: 0.25067940780518555 | validation: 0.2232527335809496]
	TIME [epoch: 28.4 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25592959291762235		[learning rate: 0.0053503]
	Learning Rate: 0.00535027
	LOSS [training: 0.25592959291762235 | validation: 0.21283887822127157]
	TIME [epoch: 28.4 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2469842949086257		[learning rate: 0.0053377]
	Learning Rate: 0.00533765
	LOSS [training: 0.2469842949086257 | validation: 0.21236436864254432]
	TIME [epoch: 28.4 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24880743927122984		[learning rate: 0.0053251]
	Learning Rate: 0.00532506
	LOSS [training: 0.24880743927122984 | validation: 0.21057435287198606]
	TIME [epoch: 28.4 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25046747705223443		[learning rate: 0.0053125]
	Learning Rate: 0.0053125
	LOSS [training: 0.25046747705223443 | validation: 0.20902371593037788]
	TIME [epoch: 28.4 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25691102653026704		[learning rate: 0.0053]
	Learning Rate: 0.00529997
	LOSS [training: 0.25691102653026704 | validation: 0.21099644417759628]
	TIME [epoch: 28.4 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2504403953768652		[learning rate: 0.0052875]
	Learning Rate: 0.00528747
	LOSS [training: 0.2504403953768652 | validation: 0.20916815867865526]
	TIME [epoch: 28.4 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2488790959245998		[learning rate: 0.005275]
	Learning Rate: 0.005275
	LOSS [training: 0.2488790959245998 | validation: 0.21733363510424764]
	TIME [epoch: 28.4 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25272285261251953		[learning rate: 0.0052626]
	Learning Rate: 0.00526255
	LOSS [training: 0.25272285261251953 | validation: 0.20865925859216988]
	TIME [epoch: 28.4 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2512172720899677		[learning rate: 0.0052501]
	Learning Rate: 0.00525014
	LOSS [training: 0.2512172720899677 | validation: 0.20559602140440153]
	TIME [epoch: 28.4 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25302133569801466		[learning rate: 0.0052378]
	Learning Rate: 0.00523776
	LOSS [training: 0.25302133569801466 | validation: 0.20885902534533626]
	TIME [epoch: 28.4 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2587105024595501		[learning rate: 0.0052254]
	Learning Rate: 0.0052254
	LOSS [training: 0.2587105024595501 | validation: 0.21163116595408712]
	TIME [epoch: 28.4 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25143441001436884		[learning rate: 0.0052131]
	Learning Rate: 0.00521308
	LOSS [training: 0.25143441001436884 | validation: 0.20949786163345308]
	TIME [epoch: 28.4 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24585040933008087		[learning rate: 0.0052008]
	Learning Rate: 0.00520078
	LOSS [training: 0.24585040933008087 | validation: 0.21011415808122513]
	TIME [epoch: 28.4 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24799546901892502		[learning rate: 0.0051885]
	Learning Rate: 0.00518851
	LOSS [training: 0.24799546901892502 | validation: 0.21171263717295802]
	TIME [epoch: 28.4 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25363919787862127		[learning rate: 0.0051763]
	Learning Rate: 0.00517627
	LOSS [training: 0.25363919787862127 | validation: 0.21277677280556145]
	TIME [epoch: 28.4 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24878610654723576		[learning rate: 0.0051641]
	Learning Rate: 0.00516406
	LOSS [training: 0.24878610654723576 | validation: 0.21529036912419972]
	TIME [epoch: 28.4 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2564481927929973		[learning rate: 0.0051519]
	Learning Rate: 0.00515188
	LOSS [training: 0.2564481927929973 | validation: 0.20633397369647283]
	TIME [epoch: 28.4 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25624927730484437		[learning rate: 0.0051397]
	Learning Rate: 0.00513973
	LOSS [training: 0.25624927730484437 | validation: 0.21947789940519286]
	TIME [epoch: 28.4 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25917188190164975		[learning rate: 0.0051276]
	Learning Rate: 0.0051276
	LOSS [training: 0.25917188190164975 | validation: 0.21586255877824922]
	TIME [epoch: 28.4 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24528971118380738		[learning rate: 0.0051155]
	Learning Rate: 0.00511551
	LOSS [training: 0.24528971118380738 | validation: 0.21177032100749082]
	TIME [epoch: 28.4 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25039880804715514		[learning rate: 0.0051034]
	Learning Rate: 0.00510344
	LOSS [training: 0.25039880804715514 | validation: 0.2233293688020034]
	TIME [epoch: 28.4 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2545410079654805		[learning rate: 0.0050914]
	Learning Rate: 0.0050914
	LOSS [training: 0.2545410079654805 | validation: 0.2114624516608033]
	TIME [epoch: 28.4 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24769579051749455		[learning rate: 0.0050794]
	Learning Rate: 0.00507939
	LOSS [training: 0.24769579051749455 | validation: 0.21089345362506684]
	TIME [epoch: 28.4 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25501775949871597		[learning rate: 0.0050674]
	Learning Rate: 0.00506741
	LOSS [training: 0.25501775949871597 | validation: 0.20563242432167422]
	TIME [epoch: 28.4 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.252015382365021		[learning rate: 0.0050555]
	Learning Rate: 0.00505546
	LOSS [training: 0.252015382365021 | validation: 0.2128449060214595]
	TIME [epoch: 28.4 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24962510810189265		[learning rate: 0.0050435]
	Learning Rate: 0.00504354
	LOSS [training: 0.24962510810189265 | validation: 0.21581120287367353]
	TIME [epoch: 28.4 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.251890393220685		[learning rate: 0.0050316]
	Learning Rate: 0.00503164
	LOSS [training: 0.251890393220685 | validation: 0.2112917181185859]
	TIME [epoch: 28.4 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2492890035701479		[learning rate: 0.0050198]
	Learning Rate: 0.00501977
	LOSS [training: 0.2492890035701479 | validation: 0.2106460014388878]
	TIME [epoch: 28.4 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2524612367390115		[learning rate: 0.0050079]
	Learning Rate: 0.00500793
	LOSS [training: 0.2524612367390115 | validation: 0.20595379178787038]
	TIME [epoch: 28.4 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25267072205527397		[learning rate: 0.0049961]
	Learning Rate: 0.00499612
	LOSS [training: 0.25267072205527397 | validation: 0.20577497619162247]
	TIME [epoch: 28.4 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24834607169980805		[learning rate: 0.0049843]
	Learning Rate: 0.00498433
	LOSS [training: 0.24834607169980805 | validation: 0.20941700901564192]
	TIME [epoch: 28.4 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2507971895934847		[learning rate: 0.0049726]
	Learning Rate: 0.00497257
	LOSS [training: 0.2507971895934847 | validation: 0.2224978324383804]
	TIME [epoch: 28.4 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2512458609012107		[learning rate: 0.0049608]
	Learning Rate: 0.00496084
	LOSS [training: 0.2512458609012107 | validation: 0.21445034420427422]
	TIME [epoch: 28.4 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2537810745439209		[learning rate: 0.0049491]
	Learning Rate: 0.00494914
	LOSS [training: 0.2537810745439209 | validation: 0.20943266129858157]
	TIME [epoch: 28.4 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24616624504110385		[learning rate: 0.0049375]
	Learning Rate: 0.00493747
	LOSS [training: 0.24616624504110385 | validation: 0.20561832189124968]
	TIME [epoch: 28.4 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2458821771748189		[learning rate: 0.0049258]
	Learning Rate: 0.00492582
	LOSS [training: 0.2458821771748189 | validation: 0.20769735983985255]
	TIME [epoch: 28.4 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2511883084939628		[learning rate: 0.0049142]
	Learning Rate: 0.0049142
	LOSS [training: 0.2511883084939628 | validation: 0.21898047146440916]
	TIME [epoch: 52.7 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.251993556745878		[learning rate: 0.0049026]
	Learning Rate: 0.00490261
	LOSS [training: 0.251993556745878 | validation: 0.2091983780799604]
	TIME [epoch: 35 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24761415890707064		[learning rate: 0.004891]
	Learning Rate: 0.00489105
	LOSS [training: 0.24761415890707064 | validation: 0.21217735177742392]
	TIME [epoch: 35 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2554197596873525		[learning rate: 0.0048795]
	Learning Rate: 0.00487951
	LOSS [training: 0.2554197596873525 | validation: 0.2166960094445812]
	TIME [epoch: 35 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25053167763583384		[learning rate: 0.004868]
	Learning Rate: 0.004868
	LOSS [training: 0.25053167763583384 | validation: 0.2166852929901574]
	TIME [epoch: 35 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24954900121227994		[learning rate: 0.0048565]
	Learning Rate: 0.00485652
	LOSS [training: 0.24954900121227994 | validation: 0.21984753490428113]
	TIME [epoch: 35 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27275330572758666		[learning rate: 0.0048451]
	Learning Rate: 0.00484506
	LOSS [training: 0.27275330572758666 | validation: 0.20149052744791848]
	TIME [epoch: 35 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_vlargesamp_20240719_155254/states/model_facs_v3_dec1b_2dpca_vlargesamp_357.pth
	Model improved!!!
EPOCH 358/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25206664539867135		[learning rate: 0.0048336]
	Learning Rate: 0.00483363
	LOSS [training: 0.25206664539867135 | validation: 0.2007199752230357]
	TIME [epoch: 35 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_vlargesamp_20240719_155254/states/model_facs_v3_dec1b_2dpca_vlargesamp_358.pth
	Model improved!!!
EPOCH 359/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2466020849928142		[learning rate: 0.0048222]
	Learning Rate: 0.00482223
	LOSS [training: 0.2466020849928142 | validation: 0.20546070593970606]
	TIME [epoch: 34.9 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2535708343381194		[learning rate: 0.0048109]
	Learning Rate: 0.00481085
	LOSS [training: 0.2535708343381194 | validation: 0.205408666722415]
	TIME [epoch: 34.9 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25112534516438084		[learning rate: 0.0047995]
	Learning Rate: 0.00479951
	LOSS [training: 0.25112534516438084 | validation: 0.20984679846250504]
	TIME [epoch: 34.9 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25059076361203053		[learning rate: 0.0047882]
	Learning Rate: 0.00478819
	LOSS [training: 0.25059076361203053 | validation: 0.2085290121035245]
	TIME [epoch: 34.9 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24676957852042106		[learning rate: 0.0047769]
	Learning Rate: 0.00477689
	LOSS [training: 0.24676957852042106 | validation: 0.20921406937248385]
	TIME [epoch: 34.9 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25168547952036363		[learning rate: 0.0047656]
	Learning Rate: 0.00476562
	LOSS [training: 0.25168547952036363 | validation: 0.2370642256033088]
	TIME [epoch: 34.9 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.252081504050682		[learning rate: 0.0047544]
	Learning Rate: 0.00475438
	LOSS [training: 0.252081504050682 | validation: 0.20482731611917862]
	TIME [epoch: 34.9 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2459694629460549		[learning rate: 0.0047432]
	Learning Rate: 0.00474317
	LOSS [training: 0.2459694629460549 | validation: 0.2067273050037856]
	TIME [epoch: 34.9 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24540447105584332		[learning rate: 0.004732]
	Learning Rate: 0.00473198
	LOSS [training: 0.24540447105584332 | validation: 0.20829327760906188]
	TIME [epoch: 34.9 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2566065880919844		[learning rate: 0.0047208]
	Learning Rate: 0.00472082
	LOSS [training: 0.2566065880919844 | validation: 0.21134332695994792]
	TIME [epoch: 34.9 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24657772821515		[learning rate: 0.0047097]
	Learning Rate: 0.00470968
	LOSS [training: 0.24657772821515 | validation: 0.2149477344118707]
	TIME [epoch: 34.9 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2455681653865142		[learning rate: 0.0046986]
	Learning Rate: 0.00469857
	LOSS [training: 0.2455681653865142 | validation: 0.20896996412448693]
	TIME [epoch: 34.9 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2478295010037602		[learning rate: 0.0046875]
	Learning Rate: 0.00468749
	LOSS [training: 0.2478295010037602 | validation: 0.21516525893815125]
	TIME [epoch: 34.9 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2515101206712072		[learning rate: 0.0046764]
	Learning Rate: 0.00467643
	LOSS [training: 0.2515101206712072 | validation: 0.21000792746028724]
	TIME [epoch: 34.9 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2536052417818942		[learning rate: 0.0046654]
	Learning Rate: 0.0046654
	LOSS [training: 0.2536052417818942 | validation: 0.20666146227128723]
	TIME [epoch: 34.9 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24474102528703143		[learning rate: 0.0046544]
	Learning Rate: 0.00465439
	LOSS [training: 0.24474102528703143 | validation: 0.20514383737595038]
	TIME [epoch: 34.9 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24483700997399513		[learning rate: 0.0046434]
	Learning Rate: 0.00464342
	LOSS [training: 0.24483700997399513 | validation: 0.21686821428367348]
	TIME [epoch: 34.9 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2521500500462646		[learning rate: 0.0046325]
	Learning Rate: 0.00463246
	LOSS [training: 0.2521500500462646 | validation: 0.20886166263297495]
	TIME [epoch: 34.9 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24581468046874236		[learning rate: 0.0046215]
	Learning Rate: 0.00462154
	LOSS [training: 0.24581468046874236 | validation: 0.21082132648235827]
	TIME [epoch: 34.9 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2560625209873112		[learning rate: 0.0046106]
	Learning Rate: 0.00461063
	LOSS [training: 0.2560625209873112 | validation: 0.2080740621018445]
	TIME [epoch: 34.9 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2534325507279452		[learning rate: 0.0045998]
	Learning Rate: 0.00459976
	LOSS [training: 0.2534325507279452 | validation: 0.2137605142216336]
	TIME [epoch: 34.9 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2493583164070509		[learning rate: 0.0045889]
	Learning Rate: 0.00458891
	LOSS [training: 0.2493583164070509 | validation: 0.21042959282133405]
	TIME [epoch: 34.9 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24584315396812653		[learning rate: 0.0045781]
	Learning Rate: 0.00457808
	LOSS [training: 0.24584315396812653 | validation: 0.22072505208625132]
	TIME [epoch: 34.9 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24803542182369206		[learning rate: 0.0045673]
	Learning Rate: 0.00456729
	LOSS [training: 0.24803542182369206 | validation: 0.20987899984097974]
	TIME [epoch: 34.9 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24717908409649303		[learning rate: 0.0045565]
	Learning Rate: 0.00455651
	LOSS [training: 0.24717908409649303 | validation: 0.20554993478345374]
	TIME [epoch: 34.9 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2519521630787277		[learning rate: 0.0045458]
	Learning Rate: 0.00454576
	LOSS [training: 0.2519521630787277 | validation: 0.20500166982038479]
	TIME [epoch: 34.9 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24675585282399012		[learning rate: 0.004535]
	Learning Rate: 0.00453504
	LOSS [training: 0.24675585282399012 | validation: 0.21216027676665972]
	TIME [epoch: 34.9 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2466533926063886		[learning rate: 0.0045243]
	Learning Rate: 0.00452434
	LOSS [training: 0.2466533926063886 | validation: 0.21098629533697671]
	TIME [epoch: 34.9 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25140227945603516		[learning rate: 0.0045137]
	Learning Rate: 0.00451367
	LOSS [training: 0.25140227945603516 | validation: 0.20468229532690127]
	TIME [epoch: 34.9 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2540878739652473		[learning rate: 0.004503]
	Learning Rate: 0.00450302
	LOSS [training: 0.2540878739652473 | validation: 0.20889252317963541]
	TIME [epoch: 34.9 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24798860350495752		[learning rate: 0.0044924]
	Learning Rate: 0.0044924
	LOSS [training: 0.24798860350495752 | validation: 0.20947551832100708]
	TIME [epoch: 34.9 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24721806307450786		[learning rate: 0.0044818]
	Learning Rate: 0.00448181
	LOSS [training: 0.24721806307450786 | validation: 0.20946128956703935]
	TIME [epoch: 34.9 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2526951383280405		[learning rate: 0.0044712]
	Learning Rate: 0.00447123
	LOSS [training: 0.2526951383280405 | validation: 0.20392489958607532]
	TIME [epoch: 34.9 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24591527553783546		[learning rate: 0.0044607]
	Learning Rate: 0.00446069
	LOSS [training: 0.24591527553783546 | validation: 0.21127703041059903]
	TIME [epoch: 34.9 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24876284071481428		[learning rate: 0.0044502]
	Learning Rate: 0.00445016
	LOSS [training: 0.24876284071481428 | validation: 0.20816914610514195]
	TIME [epoch: 34.9 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24842424794798737		[learning rate: 0.0044397]
	Learning Rate: 0.00443967
	LOSS [training: 0.24842424794798737 | validation: 0.2043065795164567]
	TIME [epoch: 34.9 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24745967141310965		[learning rate: 0.0044292]
	Learning Rate: 0.00442919
	LOSS [training: 0.24745967141310965 | validation: 0.2081695434399018]
	TIME [epoch: 34.9 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2510181332584315		[learning rate: 0.0044187]
	Learning Rate: 0.00441875
	LOSS [training: 0.2510181332584315 | validation: 0.20590214510494054]
	TIME [epoch: 34.9 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25219263628275196		[learning rate: 0.0044083]
	Learning Rate: 0.00440832
	LOSS [training: 0.25219263628275196 | validation: 0.2045436127208037]
	TIME [epoch: 34.9 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24660879513071418		[learning rate: 0.0043979]
	Learning Rate: 0.00439793
	LOSS [training: 0.24660879513071418 | validation: 0.20769836444317985]
	TIME [epoch: 34.9 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24849472785385837		[learning rate: 0.0043876]
	Learning Rate: 0.00438755
	LOSS [training: 0.24849472785385837 | validation: 0.2059667952744281]
	TIME [epoch: 34.9 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24531795993061187		[learning rate: 0.0043772]
	Learning Rate: 0.0043772
	LOSS [training: 0.24531795993061187 | validation: 0.20909501348145146]
	TIME [epoch: 34.9 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24656365427837076		[learning rate: 0.0043669]
	Learning Rate: 0.00436688
	LOSS [training: 0.24656365427837076 | validation: 0.21017065696767273]
	TIME [epoch: 35 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2530499588034781		[learning rate: 0.0043566]
	Learning Rate: 0.00435658
	LOSS [training: 0.2530499588034781 | validation: 0.21363649606238386]
	TIME [epoch: 34.9 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2547095361174962		[learning rate: 0.0043463]
	Learning Rate: 0.0043463
	LOSS [training: 0.2547095361174962 | validation: 0.2114181000354939]
	TIME [epoch: 34.9 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24653098227162426		[learning rate: 0.004336]
	Learning Rate: 0.00433605
	LOSS [training: 0.24653098227162426 | validation: 0.2124837493578881]
	TIME [epoch: 34.9 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25058533572095637		[learning rate: 0.0043258]
	Learning Rate: 0.00432582
	LOSS [training: 0.25058533572095637 | validation: 0.21281392415369074]
	TIME [epoch: 34.9 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2506270079992862		[learning rate: 0.0043156]
	Learning Rate: 0.00431562
	LOSS [training: 0.2506270079992862 | validation: 0.2101569962106938]
	TIME [epoch: 34.9 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25791224852907885		[learning rate: 0.0043054]
	Learning Rate: 0.00430544
	LOSS [training: 0.25791224852907885 | validation: 0.20499301973311068]
	TIME [epoch: 34.9 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2490952282304568		[learning rate: 0.0042953]
	Learning Rate: 0.00429528
	LOSS [training: 0.2490952282304568 | validation: 0.20964042443165445]
	TIME [epoch: 34.9 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24405890291877852		[learning rate: 0.0042851]
	Learning Rate: 0.00428515
	LOSS [training: 0.24405890291877852 | validation: 0.21287427823195673]
	TIME [epoch: 34.9 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24873496812488582		[learning rate: 0.004275]
	Learning Rate: 0.00427504
	LOSS [training: 0.24873496812488582 | validation: 0.20750258726658766]
	TIME [epoch: 34.9 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2536408790591536		[learning rate: 0.004265]
	Learning Rate: 0.00426496
	LOSS [training: 0.2536408790591536 | validation: 0.21023042302407324]
	TIME [epoch: 34.9 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24421627096010146		[learning rate: 0.0042549]
	Learning Rate: 0.0042549
	LOSS [training: 0.24421627096010146 | validation: 0.21066165954447302]
	TIME [epoch: 34.9 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25243845389024006		[learning rate: 0.0042449]
	Learning Rate: 0.00424486
	LOSS [training: 0.25243845389024006 | validation: 0.20672252903566957]
	TIME [epoch: 34.9 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24592273856757577		[learning rate: 0.0042348]
	Learning Rate: 0.00423485
	LOSS [training: 0.24592273856757577 | validation: 0.20557774023362868]
	TIME [epoch: 34.9 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24218604339648753		[learning rate: 0.0042249]
	Learning Rate: 0.00422486
	LOSS [training: 0.24218604339648753 | validation: 0.20736845993724]
	TIME [epoch: 34.9 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25150843946869644		[learning rate: 0.0042149]
	Learning Rate: 0.00421489
	LOSS [training: 0.25150843946869644 | validation: 0.21190560708181172]
	TIME [epoch: 34.9 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24725593415834854		[learning rate: 0.0042049]
	Learning Rate: 0.00420495
	LOSS [training: 0.24725593415834854 | validation: 0.20863516499307852]
	TIME [epoch: 34.9 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24591435677752652		[learning rate: 0.004195]
	Learning Rate: 0.00419503
	LOSS [training: 0.24591435677752652 | validation: 0.20363401739877207]
	TIME [epoch: 34.9 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25755500287968097		[learning rate: 0.0041851]
	Learning Rate: 0.00418513
	LOSS [training: 0.25755500287968097 | validation: 0.21219273509615108]
	TIME [epoch: 34.9 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24844413806386811		[learning rate: 0.0041753]
	Learning Rate: 0.00417526
	LOSS [training: 0.24844413806386811 | validation: 0.20987637257847283]
	TIME [epoch: 34.9 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24914638504385778		[learning rate: 0.0041654]
	Learning Rate: 0.00416541
	LOSS [training: 0.24914638504385778 | validation: 0.20493079758712493]
	TIME [epoch: 34.9 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24655124252623659		[learning rate: 0.0041556]
	Learning Rate: 0.00415559
	LOSS [training: 0.24655124252623659 | validation: 0.2066320054153286]
	TIME [epoch: 34.9 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24567859690945126		[learning rate: 0.0041458]
	Learning Rate: 0.00414579
	LOSS [training: 0.24567859690945126 | validation: 0.2094220113775299]
	TIME [epoch: 34.9 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24427951409333848		[learning rate: 0.004136]
	Learning Rate: 0.00413601
	LOSS [training: 0.24427951409333848 | validation: 0.2054092915508857]
	TIME [epoch: 35 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24768584548513237		[learning rate: 0.0041263]
	Learning Rate: 0.00412625
	LOSS [training: 0.24768584548513237 | validation: 0.20781793897439474]
	TIME [epoch: 34.9 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24794315835070324		[learning rate: 0.0041165]
	Learning Rate: 0.00411652
	LOSS [training: 0.24794315835070324 | validation: 0.20965355816737033]
	TIME [epoch: 34.9 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24947726471808854		[learning rate: 0.0041068]
	Learning Rate: 0.00410681
	LOSS [training: 0.24947726471808854 | validation: 0.20866426630847817]
	TIME [epoch: 35 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24926309641049071		[learning rate: 0.0040971]
	Learning Rate: 0.00409712
	LOSS [training: 0.24926309641049071 | validation: 0.22792900452244194]
	TIME [epoch: 35 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2640671930921147		[learning rate: 0.0040875]
	Learning Rate: 0.00408745
	LOSS [training: 0.2640671930921147 | validation: 0.21486593320011932]
	TIME [epoch: 34.9 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24559431847380217		[learning rate: 0.0040778]
	Learning Rate: 0.00407781
	LOSS [training: 0.24559431847380217 | validation: 0.20275057322929024]
	TIME [epoch: 34.9 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24395858703033393		[learning rate: 0.0040682]
	Learning Rate: 0.00406819
	LOSS [training: 0.24395858703033393 | validation: 0.21439944749185852]
	TIME [epoch: 35 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24868463663859827		[learning rate: 0.0040586]
	Learning Rate: 0.0040586
	LOSS [training: 0.24868463663859827 | validation: 0.2066757162926122]
	TIME [epoch: 34.9 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2478299428321191		[learning rate: 0.004049]
	Learning Rate: 0.00404903
	LOSS [training: 0.2478299428321191 | validation: 0.2049105152288763]
	TIME [epoch: 34.9 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24466771411236032		[learning rate: 0.0040395]
	Learning Rate: 0.00403947
	LOSS [training: 0.24466771411236032 | validation: 0.20715217269853978]
	TIME [epoch: 34.9 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24463087060517744		[learning rate: 0.0040299]
	Learning Rate: 0.00402995
	LOSS [training: 0.24463087060517744 | validation: 0.20911493879114484]
	TIME [epoch: 34.9 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24469779413135453		[learning rate: 0.0040204]
	Learning Rate: 0.00402044
	LOSS [training: 0.24469779413135453 | validation: 0.20898741007026161]
	TIME [epoch: 34.9 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24682121645719154		[learning rate: 0.004011]
	Learning Rate: 0.00401096
	LOSS [training: 0.24682121645719154 | validation: 0.20931612584477444]
	TIME [epoch: 35 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24612854227072048		[learning rate: 0.0040015]
	Learning Rate: 0.00400149
	LOSS [training: 0.24612854227072048 | validation: 0.21225045046054322]
	TIME [epoch: 34.9 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2505860823469474		[learning rate: 0.0039921]
	Learning Rate: 0.00399206
	LOSS [training: 0.2505860823469474 | validation: 0.20901589174463756]
	TIME [epoch: 34.9 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24419968117313517		[learning rate: 0.0039826]
	Learning Rate: 0.00398264
	LOSS [training: 0.24419968117313517 | validation: 0.20692245295282907]
	TIME [epoch: 34.9 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2527693633086377		[learning rate: 0.0039732]
	Learning Rate: 0.00397324
	LOSS [training: 0.2527693633086377 | validation: 0.23572617092912446]
	TIME [epoch: 35 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2718208951861267		[learning rate: 0.0039639]
	Learning Rate: 0.00396387
	LOSS [training: 0.2718208951861267 | validation: 0.2203875783033901]
	TIME [epoch: 35 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2479924009135762		[learning rate: 0.0039545]
	Learning Rate: 0.00395452
	LOSS [training: 0.2479924009135762 | validation: 0.2191890947021821]
	TIME [epoch: 35 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2504043560278888		[learning rate: 0.0039452]
	Learning Rate: 0.00394519
	LOSS [training: 0.2504043560278888 | validation: 0.21289538031071484]
	TIME [epoch: 34.9 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2435932920103203		[learning rate: 0.0039359]
	Learning Rate: 0.00393589
	LOSS [training: 0.2435932920103203 | validation: 0.2083369258301234]
	TIME [epoch: 34.9 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24853965748855963		[learning rate: 0.0039266]
	Learning Rate: 0.0039266
	LOSS [training: 0.24853965748855963 | validation: 0.2089156990352313]
	TIME [epoch: 34.9 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24365535049404863		[learning rate: 0.0039173]
	Learning Rate: 0.00391734
	LOSS [training: 0.24365535049404863 | validation: 0.20935476802541847]
	TIME [epoch: 35 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2445412011447979		[learning rate: 0.0039081]
	Learning Rate: 0.0039081
	LOSS [training: 0.2445412011447979 | validation: 0.2106963666163646]
	TIME [epoch: 35 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24239429889579278		[learning rate: 0.0038989]
	Learning Rate: 0.00389888
	LOSS [training: 0.24239429889579278 | validation: 0.20925439508831284]
	TIME [epoch: 35 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24751782902098787		[learning rate: 0.0038897]
	Learning Rate: 0.00388969
	LOSS [training: 0.24751782902098787 | validation: 0.2092787493841382]
	TIME [epoch: 34.9 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24925021427139404		[learning rate: 0.0038805]
	Learning Rate: 0.00388051
	LOSS [training: 0.24925021427139404 | validation: 0.21465456794320592]
	TIME [epoch: 89.8 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25071540723758395		[learning rate: 0.0038714]
	Learning Rate: 0.00387136
	LOSS [training: 0.25071540723758395 | validation: 0.21059870601303973]
	TIME [epoch: 72.2 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24851833593963754		[learning rate: 0.0038622]
	Learning Rate: 0.00386222
	LOSS [training: 0.24851833593963754 | validation: 0.20346945492507534]
	TIME [epoch: 72.4 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24770339514650067		[learning rate: 0.0038531]
	Learning Rate: 0.00385311
	LOSS [training: 0.24770339514650067 | validation: 0.20906542568670816]
	TIME [epoch: 72.2 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24797273221213434		[learning rate: 0.003844]
	Learning Rate: 0.00384403
	LOSS [training: 0.24797273221213434 | validation: 0.20513043824108107]
	TIME [epoch: 72.2 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24685327135525192		[learning rate: 0.003835]
	Learning Rate: 0.00383496
	LOSS [training: 0.24685327135525192 | validation: 0.20792608602660265]
	TIME [epoch: 72.2 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25653443933845954		[learning rate: 0.0038259]
	Learning Rate: 0.00382591
	LOSS [training: 0.25653443933845954 | validation: 0.20672198553573304]
	TIME [epoch: 72.2 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24379009226704387		[learning rate: 0.0038169]
	Learning Rate: 0.00381689
	LOSS [training: 0.24379009226704387 | validation: 0.2159715910589949]
	TIME [epoch: 72.2 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2465620696799775		[learning rate: 0.0038079]
	Learning Rate: 0.00380788
	LOSS [training: 0.2465620696799775 | validation: 0.21037051617805852]
	TIME [epoch: 72.2 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2464090500012507		[learning rate: 0.0037989]
	Learning Rate: 0.0037989
	LOSS [training: 0.2464090500012507 | validation: 0.21096714849469125]
	TIME [epoch: 72.2 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2464096620444399		[learning rate: 0.0037899]
	Learning Rate: 0.00378994
	LOSS [training: 0.2464096620444399 | validation: 0.21480559077012643]
	TIME [epoch: 72.2 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2572151946548436		[learning rate: 0.003781]
	Learning Rate: 0.003781
	LOSS [training: 0.2572151946548436 | validation: 0.22621223577083177]
	TIME [epoch: 72.2 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2581254205982398		[learning rate: 0.0037721]
	Learning Rate: 0.00377208
	LOSS [training: 0.2581254205982398 | validation: 0.21262201279745235]
	TIME [epoch: 72.2 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24722875261415087		[learning rate: 0.0037632]
	Learning Rate: 0.00376318
	LOSS [training: 0.24722875261415087 | validation: 0.2086888819575569]
	TIME [epoch: 72.2 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27226736281840574		[learning rate: 0.0037543]
	Learning Rate: 0.00375431
	LOSS [training: 0.27226736281840574 | validation: 0.21353425302775003]
	TIME [epoch: 72.2 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25099765868627955		[learning rate: 0.0037455]
	Learning Rate: 0.00374545
	LOSS [training: 0.25099765868627955 | validation: 0.2055633369140807]
	TIME [epoch: 72.2 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25467301066436043		[learning rate: 0.0037366]
	Learning Rate: 0.00373662
	LOSS [training: 0.25467301066436043 | validation: 0.20614833249412395]
	TIME [epoch: 72.2 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24531203693694437		[learning rate: 0.0037278]
	Learning Rate: 0.0037278
	LOSS [training: 0.24531203693694437 | validation: 0.20499528737009007]
	TIME [epoch: 72.2 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2442402807501246		[learning rate: 0.003719]
	Learning Rate: 0.00371901
	LOSS [training: 0.2442402807501246 | validation: 0.20208761251712892]
	TIME [epoch: 72.2 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24870385901903258		[learning rate: 0.0037102]
	Learning Rate: 0.00371024
	LOSS [training: 0.24870385901903258 | validation: 0.20891624711359755]
	TIME [epoch: 72.2 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24639302924351117		[learning rate: 0.0037015]
	Learning Rate: 0.00370149
	LOSS [training: 0.24639302924351117 | validation: 0.20548082084235847]
	TIME [epoch: 72.2 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24826308493455537		[learning rate: 0.0036928]
	Learning Rate: 0.00369275
	LOSS [training: 0.24826308493455537 | validation: 0.20423564799811134]
	TIME [epoch: 72.2 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24877646371914877		[learning rate: 0.003684]
	Learning Rate: 0.00368404
	LOSS [training: 0.24877646371914877 | validation: 0.2074936416250293]
	TIME [epoch: 72.2 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24669587261417694		[learning rate: 0.0036754]
	Learning Rate: 0.00367535
	LOSS [training: 0.24669587261417694 | validation: 0.21051307036622582]
	TIME [epoch: 72.2 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25035087777680987		[learning rate: 0.0036667]
	Learning Rate: 0.00366668
	LOSS [training: 0.25035087777680987 | validation: 0.20461385815728478]
	TIME [epoch: 72.2 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24958736328282424		[learning rate: 0.003658]
	Learning Rate: 0.00365803
	LOSS [training: 0.24958736328282424 | validation: 0.2005216609977253]
	TIME [epoch: 72.2 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_vlargesamp_20240719_155254/states/model_facs_v3_dec1b_2dpca_vlargesamp_476.pth
	Model improved!!!
EPOCH 477/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24606404301783935		[learning rate: 0.0036494]
	Learning Rate: 0.00364941
	LOSS [training: 0.24606404301783935 | validation: 0.20596568971686816]
	TIME [epoch: 72.2 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24588358232388294		[learning rate: 0.0036408]
	Learning Rate: 0.0036408
	LOSS [training: 0.24588358232388294 | validation: 0.20904480578959966]
	TIME [epoch: 72.2 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24735725717677293		[learning rate: 0.0036322]
	Learning Rate: 0.00363221
	LOSS [training: 0.24735725717677293 | validation: 0.2066860687849597]
	TIME [epoch: 72.2 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24913323172481927		[learning rate: 0.0036236]
	Learning Rate: 0.00362364
	LOSS [training: 0.24913323172481927 | validation: 0.22424645441932123]
	TIME [epoch: 72.2 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2596106703230843		[learning rate: 0.0036151]
	Learning Rate: 0.00361509
	LOSS [training: 0.2596106703230843 | validation: 0.20536506424825635]
	TIME [epoch: 72.2 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24703603521843498		[learning rate: 0.0036066]
	Learning Rate: 0.00360657
	LOSS [training: 0.24703603521843498 | validation: 0.2064610854187793]
	TIME [epoch: 72.2 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24486941403260928		[learning rate: 0.0035981]
	Learning Rate: 0.00359806
	LOSS [training: 0.24486941403260928 | validation: 0.20674544551619647]
	TIME [epoch: 72.2 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24686569062754762		[learning rate: 0.0035896]
	Learning Rate: 0.00358957
	LOSS [training: 0.24686569062754762 | validation: 0.21068579419010947]
	TIME [epoch: 72.2 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24400233946368502		[learning rate: 0.0035811]
	Learning Rate: 0.00358111
	LOSS [training: 0.24400233946368502 | validation: 0.20363921313743413]
	TIME [epoch: 72.2 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2514144390505862		[learning rate: 0.0035727]
	Learning Rate: 0.00357266
	LOSS [training: 0.2514144390505862 | validation: 0.22289128794533153]
	TIME [epoch: 72.2 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2594584745377531		[learning rate: 0.0035642]
	Learning Rate: 0.00356423
	LOSS [training: 0.2594584745377531 | validation: 0.21294729032303011]
	TIME [epoch: 72.2 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2503865022661875		[learning rate: 0.0035558]
	Learning Rate: 0.00355582
	LOSS [training: 0.2503865022661875 | validation: 0.20624939272686604]
	TIME [epoch: 72.2 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26991326186343073		[learning rate: 0.0035474]
	Learning Rate: 0.00354744
	LOSS [training: 0.26991326186343073 | validation: 0.21171965560262523]
	TIME [epoch: 72.2 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25159502550953633		[learning rate: 0.0035391]
	Learning Rate: 0.00353907
	LOSS [training: 0.25159502550953633 | validation: 0.2062423540290555]
	TIME [epoch: 72.2 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2463278879841252		[learning rate: 0.0035307]
	Learning Rate: 0.00353072
	LOSS [training: 0.2463278879841252 | validation: 0.20851891301671976]
	TIME [epoch: 72.2 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2458830344000522		[learning rate: 0.0035224]
	Learning Rate: 0.00352239
	LOSS [training: 0.2458830344000522 | validation: 0.20673136741198556]
	TIME [epoch: 72.2 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2448777150738052		[learning rate: 0.0035141]
	Learning Rate: 0.00351408
	LOSS [training: 0.2448777150738052 | validation: 0.20743114244788902]
	TIME [epoch: 72.2 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24374537881501593		[learning rate: 0.0035058]
	Learning Rate: 0.00350579
	LOSS [training: 0.24374537881501593 | validation: 0.2106805377326597]
	TIME [epoch: 72.2 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24579611111122113		[learning rate: 0.0034975]
	Learning Rate: 0.00349752
	LOSS [training: 0.24579611111122113 | validation: 0.20551386957427825]
	TIME [epoch: 72.2 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25391454394485385		[learning rate: 0.0034893]
	Learning Rate: 0.00348927
	LOSS [training: 0.25391454394485385 | validation: 0.21024986205838236]
	TIME [epoch: 72.2 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2410538748500878		[learning rate: 0.003481]
	Learning Rate: 0.00348104
	LOSS [training: 0.2410538748500878 | validation: 0.20671985562834322]
	TIME [epoch: 72.2 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24269561531549724		[learning rate: 0.0034728]
	Learning Rate: 0.00347283
	LOSS [training: 0.24269561531549724 | validation: 0.21003774583174314]
	TIME [epoch: 72.2 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24381166270591392		[learning rate: 0.0034646]
	Learning Rate: 0.00346464
	LOSS [training: 0.24381166270591392 | validation: 0.2091867017275324]
	TIME [epoch: 72.2 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24741615576184425		[learning rate: 0.0034565]
	Learning Rate: 0.00345647
	LOSS [training: 0.24741615576184425 | validation: 0.2082854193713271]
	TIME [epoch: 72.2 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2487222744627937		[learning rate: 0.0034483]
	Learning Rate: 0.00344831
	LOSS [training: 0.2487222744627937 | validation: 0.20758381749966742]
	TIME [epoch: 72.5 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24504100254945735		[learning rate: 0.0034402]
	Learning Rate: 0.00344018
	LOSS [training: 0.24504100254945735 | validation: 0.20686815359466135]
	TIME [epoch: 72.5 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2478910047313846		[learning rate: 0.0034321]
	Learning Rate: 0.00343207
	LOSS [training: 0.2478910047313846 | validation: 0.21092408812207583]
	TIME [epoch: 72.5 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24628946403779364		[learning rate: 0.003424]
	Learning Rate: 0.00342397
	LOSS [training: 0.24628946403779364 | validation: 0.20510189315450322]
	TIME [epoch: 72.5 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24540636484779135		[learning rate: 0.0034159]
	Learning Rate: 0.00341589
	LOSS [training: 0.24540636484779135 | validation: 0.2088586896597861]
	TIME [epoch: 72.5 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24470563724725405		[learning rate: 0.0034078]
	Learning Rate: 0.00340784
	LOSS [training: 0.24470563724725405 | validation: 0.20476993085025877]
	TIME [epoch: 72.5 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24766310461533825		[learning rate: 0.0033998]
	Learning Rate: 0.0033998
	LOSS [training: 0.24766310461533825 | validation: 0.21448590759088232]
	TIME [epoch: 72.5 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24273311135456518		[learning rate: 0.0033918]
	Learning Rate: 0.00339178
	LOSS [training: 0.24273311135456518 | validation: 0.2071632715110158]
	TIME [epoch: 72.5 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2438332466806337		[learning rate: 0.0033838]
	Learning Rate: 0.00338378
	LOSS [training: 0.2438332466806337 | validation: 0.20828304071127796]
	TIME [epoch: 72.5 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24375129658742167		[learning rate: 0.0033758]
	Learning Rate: 0.0033758
	LOSS [training: 0.24375129658742167 | validation: 0.20977812923457934]
	TIME [epoch: 72.2 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2450339008482684		[learning rate: 0.0033678]
	Learning Rate: 0.00336783
	LOSS [training: 0.2450339008482684 | validation: 0.20721729327737942]
	TIME [epoch: 72.4 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24383677489709174		[learning rate: 0.0033599]
	Learning Rate: 0.00335989
	LOSS [training: 0.24383677489709174 | validation: 0.20785971105501327]
	TIME [epoch: 72.3 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24520098120043535		[learning rate: 0.003352]
	Learning Rate: 0.00335196
	LOSS [training: 0.24520098120043535 | validation: 0.2084974038150019]
	TIME [epoch: 72.4 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24991599081611535		[learning rate: 0.0033441]
	Learning Rate: 0.00334406
	LOSS [training: 0.24991599081611535 | validation: 0.2033581236070404]
	TIME [epoch: 72.3 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24404850650570417		[learning rate: 0.0033362]
	Learning Rate: 0.00333617
	LOSS [training: 0.24404850650570417 | validation: 0.20776096302369487]
	TIME [epoch: 72.4 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2448442859482657		[learning rate: 0.0033283]
	Learning Rate: 0.0033283
	LOSS [training: 0.2448442859482657 | validation: 0.20548380812519987]
	TIME [epoch: 72.4 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24777711101888503		[learning rate: 0.0033204]
	Learning Rate: 0.00332045
	LOSS [training: 0.24777711101888503 | validation: 0.2055894996188042]
	TIME [epoch: 72.3 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24886550049651976		[learning rate: 0.0033126]
	Learning Rate: 0.00331261
	LOSS [training: 0.24886550049651976 | validation: 0.20714540579382082]
	TIME [epoch: 72.3 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2426626586803691		[learning rate: 0.0033048]
	Learning Rate: 0.0033048
	LOSS [training: 0.2426626586803691 | validation: 0.2092943413605517]
	TIME [epoch: 72.4 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24396463220263695		[learning rate: 0.003297]
	Learning Rate: 0.00329701
	LOSS [training: 0.24396463220263695 | validation: 0.2088688924126565]
	TIME [epoch: 72.4 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24397484684136458		[learning rate: 0.0032892]
	Learning Rate: 0.00328923
	LOSS [training: 0.24397484684136458 | validation: 0.2101561590716114]
	TIME [epoch: 72.4 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2509438751932273		[learning rate: 0.0032815]
	Learning Rate: 0.00328147
	LOSS [training: 0.2509438751932273 | validation: 0.2090006849190124]
	TIME [epoch: 72.3 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24453898394043497		[learning rate: 0.0032737]
	Learning Rate: 0.00327373
	LOSS [training: 0.24453898394043497 | validation: 0.20505930854564763]
	TIME [epoch: 72.4 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24607697252972108		[learning rate: 0.003266]
	Learning Rate: 0.00326601
	LOSS [training: 0.24607697252972108 | validation: 0.2044249633712154]
	TIME [epoch: 72.4 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24343685823166086		[learning rate: 0.0032583]
	Learning Rate: 0.0032583
	LOSS [training: 0.24343685823166086 | validation: 0.20711694438182954]
	TIME [epoch: 72.3 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2445948363303653		[learning rate: 0.0032506]
	Learning Rate: 0.00325062
	LOSS [training: 0.2445948363303653 | validation: 0.20963654459252035]
	TIME [epoch: 72.4 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24622157475113673		[learning rate: 0.0032429]
	Learning Rate: 0.00324295
	LOSS [training: 0.24622157475113673 | validation: 0.20837692770037103]
	TIME [epoch: 72.3 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2450040016727452		[learning rate: 0.0032353]
	Learning Rate: 0.0032353
	LOSS [training: 0.2450040016727452 | validation: 0.20520782138022922]
	TIME [epoch: 72.4 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24563557761210264		[learning rate: 0.0032277]
	Learning Rate: 0.00322767
	LOSS [training: 0.24563557761210264 | validation: 0.2074771136844845]
	TIME [epoch: 72.4 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2448070363827648		[learning rate: 0.0032201]
	Learning Rate: 0.00322005
	LOSS [training: 0.2448070363827648 | validation: 0.204137399523498]
	TIME [epoch: 72.3 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24519320716695805		[learning rate: 0.0032125]
	Learning Rate: 0.00321246
	LOSS [training: 0.24519320716695805 | validation: 0.2112509800787067]
	TIME [epoch: 72.3 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2437924529904706		[learning rate: 0.0032049]
	Learning Rate: 0.00320488
	LOSS [training: 0.2437924529904706 | validation: 0.20364750702353182]
	TIME [epoch: 72.3 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2430437240803737		[learning rate: 0.0031973]
	Learning Rate: 0.00319732
	LOSS [training: 0.2430437240803737 | validation: 0.21095467531647652]
	TIME [epoch: 72.3 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24770448917929497		[learning rate: 0.0031898]
	Learning Rate: 0.00318978
	LOSS [training: 0.24770448917929497 | validation: 0.21190780637890994]
	TIME [epoch: 72.3 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24249984701368044		[learning rate: 0.0031823]
	Learning Rate: 0.00318226
	LOSS [training: 0.24249984701368044 | validation: 0.20786610386750412]
	TIME [epoch: 72.4 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24616828000280477		[learning rate: 0.0031747]
	Learning Rate: 0.00317475
	LOSS [training: 0.24616828000280477 | validation: 0.2072327711898577]
	TIME [epoch: 72.4 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2441029366563987		[learning rate: 0.0031673]
	Learning Rate: 0.00316726
	LOSS [training: 0.2441029366563987 | validation: 0.20710746946820202]
	TIME [epoch: 72.3 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24269400336512223		[learning rate: 0.0031598]
	Learning Rate: 0.00315979
	LOSS [training: 0.24269400336512223 | validation: 0.20483484043075126]
	TIME [epoch: 72.4 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24553857279360533		[learning rate: 0.0031523]
	Learning Rate: 0.00315234
	LOSS [training: 0.24553857279360533 | validation: 0.20618390372668488]
	TIME [epoch: 72.4 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24652982850821636		[learning rate: 0.0031449]
	Learning Rate: 0.0031449
	LOSS [training: 0.24652982850821636 | validation: 0.20816952810311892]
	TIME [epoch: 72.4 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2545558839253748		[learning rate: 0.0031375]
	Learning Rate: 0.00313748
	LOSS [training: 0.2545558839253748 | validation: 0.20558804289256555]
	TIME [epoch: 72.4 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2515880187136233		[learning rate: 0.0031301]
	Learning Rate: 0.00313008
	LOSS [training: 0.2515880187136233 | validation: 0.20707372060220042]
	TIME [epoch: 72.4 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2506386866092646		[learning rate: 0.0031227]
	Learning Rate: 0.0031227
	LOSS [training: 0.2506386866092646 | validation: 0.21844203728205036]
	TIME [epoch: 72.4 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2505712561035917		[learning rate: 0.0031153]
	Learning Rate: 0.00311533
	LOSS [training: 0.2505712561035917 | validation: 0.20943440997339974]
	TIME [epoch: 72.3 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24247142420282797		[learning rate: 0.003108]
	Learning Rate: 0.00310798
	LOSS [training: 0.24247142420282797 | validation: 0.2081468245719928]
	TIME [epoch: 72.3 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2450305730149803		[learning rate: 0.0031007]
	Learning Rate: 0.00310065
	LOSS [training: 0.2450305730149803 | validation: 0.2074568145364421]
	TIME [epoch: 72.3 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24523018598314575		[learning rate: 0.0030933]
	Learning Rate: 0.00309334
	LOSS [training: 0.24523018598314575 | validation: 0.21835591932848133]
	TIME [epoch: 72.3 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25018253080513075		[learning rate: 0.003086]
	Learning Rate: 0.00308604
	LOSS [training: 0.25018253080513075 | validation: 0.2081882545748462]
	TIME [epoch: 72.3 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24785747866480434		[learning rate: 0.0030788]
	Learning Rate: 0.00307876
	LOSS [training: 0.24785747866480434 | validation: 0.20382625196738852]
	TIME [epoch: 72.4 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2450225952652092		[learning rate: 0.0030715]
	Learning Rate: 0.0030715
	LOSS [training: 0.2450225952652092 | validation: 0.20848697251898685]
	TIME [epoch: 72.3 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24212190594680924		[learning rate: 0.0030643]
	Learning Rate: 0.00306425
	LOSS [training: 0.24212190594680924 | validation: 0.20829408235232946]
	TIME [epoch: 72.3 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24765509760571072		[learning rate: 0.003057]
	Learning Rate: 0.00305703
	LOSS [training: 0.24765509760571072 | validation: 0.21958749851168693]
	TIME [epoch: 72.2 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2486420652897994		[learning rate: 0.0030498]
	Learning Rate: 0.00304981
	LOSS [training: 0.2486420652897994 | validation: 0.21308751482121407]
	TIME [epoch: 72.2 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2467947660493435		[learning rate: 0.0030426]
	Learning Rate: 0.00304262
	LOSS [training: 0.2467947660493435 | validation: 0.21222833994794893]
	TIME [epoch: 72.3 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24351704310700148		[learning rate: 0.0030354]
	Learning Rate: 0.00303544
	LOSS [training: 0.24351704310700148 | validation: 0.21088153403269688]
	TIME [epoch: 72.3 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24646976486788685		[learning rate: 0.0030283]
	Learning Rate: 0.00302828
	LOSS [training: 0.24646976486788685 | validation: 0.2056276927365462]
	TIME [epoch: 72.3 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2434821698089212		[learning rate: 0.0030211]
	Learning Rate: 0.00302114
	LOSS [training: 0.2434821698089212 | validation: 0.2078257543170139]
	TIME [epoch: 72.2 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24479340340847164		[learning rate: 0.003014]
	Learning Rate: 0.00301401
	LOSS [training: 0.24479340340847164 | validation: 0.20602206863110378]
	TIME [epoch: 72.3 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2427778123249551		[learning rate: 0.0030069]
	Learning Rate: 0.0030069
	LOSS [training: 0.2427778123249551 | validation: 0.20629866037664707]
	TIME [epoch: 72.3 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.247203679884364		[learning rate: 0.0029998]
	Learning Rate: 0.00299981
	LOSS [training: 0.247203679884364 | validation: 0.2223685298385941]
	TIME [epoch: 72.3 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24402075823216032		[learning rate: 0.0029927]
	Learning Rate: 0.00299274
	LOSS [training: 0.24402075823216032 | validation: 0.20865946055806023]
	TIME [epoch: 72.3 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2396373653529983		[learning rate: 0.0029857]
	Learning Rate: 0.00298568
	LOSS [training: 0.2396373653529983 | validation: 0.20690840171757804]
	TIME [epoch: 72.4 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24550015012826157		[learning rate: 0.0029786]
	Learning Rate: 0.00297863
	LOSS [training: 0.24550015012826157 | validation: 0.20806839646489425]
	TIME [epoch: 72.3 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2512875233836121		[learning rate: 0.0029716]
	Learning Rate: 0.00297161
	LOSS [training: 0.2512875233836121 | validation: 0.21366576297444378]
	TIME [epoch: 72.3 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2462769744500589		[learning rate: 0.0029646]
	Learning Rate: 0.0029646
	LOSS [training: 0.2462769744500589 | validation: 0.20931372518253485]
	TIME [epoch: 72.3 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24266513249245722		[learning rate: 0.0029576]
	Learning Rate: 0.00295761
	LOSS [training: 0.24266513249245722 | validation: 0.21020378409017199]
	TIME [epoch: 72.2 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24683663597922037		[learning rate: 0.0029506]
	Learning Rate: 0.00295063
	LOSS [training: 0.24683663597922037 | validation: 0.20699892746964163]
	TIME [epoch: 72.3 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2429774258522102		[learning rate: 0.0029437]
	Learning Rate: 0.00294367
	LOSS [training: 0.2429774258522102 | validation: 0.21097604684723265]
	TIME [epoch: 72.3 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.245872098886057		[learning rate: 0.0029367]
	Learning Rate: 0.00293673
	LOSS [training: 0.245872098886057 | validation: 0.21286970768816676]
	TIME [epoch: 72.3 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2480705927379797		[learning rate: 0.0029298]
	Learning Rate: 0.0029298
	LOSS [training: 0.2480705927379797 | validation: 0.21049204180243178]
	TIME [epoch: 72.3 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24774259421069567		[learning rate: 0.0029229]
	Learning Rate: 0.00292289
	LOSS [training: 0.24774259421069567 | validation: 0.211302210181886]
	TIME [epoch: 72.3 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24654217922760702		[learning rate: 0.002916]
	Learning Rate: 0.00291599
	LOSS [training: 0.24654217922760702 | validation: 0.21040248352920363]
	TIME [epoch: 72.3 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24235592653317797		[learning rate: 0.0029091]
	Learning Rate: 0.00290911
	LOSS [training: 0.24235592653317797 | validation: 0.2114011461757636]
	TIME [epoch: 72.3 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24263619562278782		[learning rate: 0.0029023]
	Learning Rate: 0.00290225
	LOSS [training: 0.24263619562278782 | validation: 0.20842643145791695]
	TIME [epoch: 72.3 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2415626109385848		[learning rate: 0.0028954]
	Learning Rate: 0.00289541
	LOSS [training: 0.2415626109385848 | validation: 0.20452952642600214]
	TIME [epoch: 72.3 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2494900220952955		[learning rate: 0.0028886]
	Learning Rate: 0.00288858
	LOSS [training: 0.2494900220952955 | validation: 0.21056162755830327]
	TIME [epoch: 72.3 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24538031241984748		[learning rate: 0.0028818]
	Learning Rate: 0.00288176
	LOSS [training: 0.24538031241984748 | validation: 0.21332479476568955]
	TIME [epoch: 72.3 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24956433650584509		[learning rate: 0.002875]
	Learning Rate: 0.00287496
	LOSS [training: 0.24956433650584509 | validation: 0.21183488858190716]
	TIME [epoch: 72.3 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24694339825822587		[learning rate: 0.0028682]
	Learning Rate: 0.00286818
	LOSS [training: 0.24694339825822587 | validation: 0.20856937421084804]
	TIME [epoch: 72.3 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24022924655704445		[learning rate: 0.0028614]
	Learning Rate: 0.00286142
	LOSS [training: 0.24022924655704445 | validation: 0.21365741882212125]
	TIME [epoch: 72.3 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2516590001776522		[learning rate: 0.0028547]
	Learning Rate: 0.00285467
	LOSS [training: 0.2516590001776522 | validation: 0.21013724708371312]
	TIME [epoch: 72.3 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24458196717983763		[learning rate: 0.0028479]
	Learning Rate: 0.00284793
	LOSS [training: 0.24458196717983763 | validation: 0.21049474032049909]
	TIME [epoch: 72.3 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24319114331947858		[learning rate: 0.0028412]
	Learning Rate: 0.00284122
	LOSS [training: 0.24319114331947858 | validation: 0.20697635300279088]
	TIME [epoch: 72.3 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24682728403870893		[learning rate: 0.0028345]
	Learning Rate: 0.00283451
	LOSS [training: 0.24682728403870893 | validation: 0.20431211955399947]
	TIME [epoch: 72.3 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.247624450700036		[learning rate: 0.0028278]
	Learning Rate: 0.00282783
	LOSS [training: 0.247624450700036 | validation: 0.20799411586352182]
	TIME [epoch: 72.3 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25050894785508665		[learning rate: 0.0028212]
	Learning Rate: 0.00282116
	LOSS [training: 0.25050894785508665 | validation: 0.20237241021943758]
	TIME [epoch: 72.3 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24375415529117916		[learning rate: 0.0028145]
	Learning Rate: 0.0028145
	LOSS [training: 0.24375415529117916 | validation: 0.2058900323918344]
	TIME [epoch: 72.3 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2417114746207315		[learning rate: 0.0028079]
	Learning Rate: 0.00280786
	LOSS [training: 0.2417114746207315 | validation: 0.2093681803899899]
	TIME [epoch: 72.3 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24083773701184752		[learning rate: 0.0028012]
	Learning Rate: 0.00280124
	LOSS [training: 0.24083773701184752 | validation: 0.20731153792803889]
	TIME [epoch: 72.3 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2431752753125632		[learning rate: 0.0027946]
	Learning Rate: 0.00279463
	LOSS [training: 0.2431752753125632 | validation: 0.21906942673711902]
	TIME [epoch: 72.3 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24582639450530944		[learning rate: 0.002788]
	Learning Rate: 0.00278804
	LOSS [training: 0.24582639450530944 | validation: 0.2118332031572861]
	TIME [epoch: 72.3 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2429551545542276		[learning rate: 0.0027815]
	Learning Rate: 0.00278146
	LOSS [training: 0.2429551545542276 | validation: 0.20885957797754343]
	TIME [epoch: 72.3 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23942742769497807		[learning rate: 0.0027749]
	Learning Rate: 0.0027749
	LOSS [training: 0.23942742769497807 | validation: 0.20772758518656181]
	TIME [epoch: 72.3 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24124714292697705		[learning rate: 0.0027684]
	Learning Rate: 0.00276836
	LOSS [training: 0.24124714292697705 | validation: 0.2101879926979032]
	TIME [epoch: 72.3 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24387336082637667		[learning rate: 0.0027618]
	Learning Rate: 0.00276183
	LOSS [training: 0.24387336082637667 | validation: 0.20942419234846826]
	TIME [epoch: 72.3 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24307429164177985		[learning rate: 0.0027553]
	Learning Rate: 0.00275531
	LOSS [training: 0.24307429164177985 | validation: 0.21167008942777565]
	TIME [epoch: 72.3 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2401508081310438		[learning rate: 0.0027488]
	Learning Rate: 0.00274881
	LOSS [training: 0.2401508081310438 | validation: 0.206207548435499]
	TIME [epoch: 72.2 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24354949517895838		[learning rate: 0.0027423]
	Learning Rate: 0.00274233
	LOSS [training: 0.24354949517895838 | validation: 0.20523166842706536]
	TIME [epoch: 72.2 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24142875222079505		[learning rate: 0.0027359]
	Learning Rate: 0.00273586
	LOSS [training: 0.24142875222079505 | validation: 0.20873137487812493]
	TIME [epoch: 72.3 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24224488305803837		[learning rate: 0.0027294]
	Learning Rate: 0.00272941
	LOSS [training: 0.24224488305803837 | validation: 0.2096071518151191]
	TIME [epoch: 72.4 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24389603362476595		[learning rate: 0.002723]
	Learning Rate: 0.00272297
	LOSS [training: 0.24389603362476595 | validation: 0.20307783092982482]
	TIME [epoch: 72.5 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2420375238642969		[learning rate: 0.0027165]
	Learning Rate: 0.00271655
	LOSS [training: 0.2420375238642969 | validation: 0.2049003174113971]
	TIME [epoch: 72.1 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2501424399922492		[learning rate: 0.0027101]
	Learning Rate: 0.00271014
	LOSS [training: 0.2501424399922492 | validation: 0.20193588267091292]
	TIME [epoch: 72.2 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2503245464157761		[learning rate: 0.0027037]
	Learning Rate: 0.00270375
	LOSS [training: 0.2503245464157761 | validation: 0.19977132037319545]
	TIME [epoch: 72.1 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_vlargesamp_20240719_155254/states/model_facs_v3_dec1b_2dpca_vlargesamp_604.pth
	Model improved!!!
EPOCH 605/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24444080921388908		[learning rate: 0.0026974]
	Learning Rate: 0.00269737
	LOSS [training: 0.24444080921388908 | validation: 0.2020889949466913]
	TIME [epoch: 72.4 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24533052805288946		[learning rate: 0.002691]
	Learning Rate: 0.002691
	LOSS [training: 0.24533052805288946 | validation: 0.2024913489082656]
	TIME [epoch: 72.4 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24325109113223772		[learning rate: 0.0026847]
	Learning Rate: 0.00268466
	LOSS [training: 0.24325109113223772 | validation: 0.20410518256630641]
	TIME [epoch: 72.4 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24061446731941682		[learning rate: 0.0026783]
	Learning Rate: 0.00267832
	LOSS [training: 0.24061446731941682 | validation: 0.20241829408058715]
	TIME [epoch: 72.4 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25619339789410644		[learning rate: 0.002672]
	Learning Rate: 0.00267201
	LOSS [training: 0.25619339789410644 | validation: 0.20206749509663924]
	TIME [epoch: 72.4 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2448864988988199		[learning rate: 0.0026657]
	Learning Rate: 0.0026657
	LOSS [training: 0.2448864988988199 | validation: 0.20439728764407783]
	TIME [epoch: 72.4 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24540708493118882		[learning rate: 0.0026594]
	Learning Rate: 0.00265942
	LOSS [training: 0.24540708493118882 | validation: 0.2066357526781925]
	TIME [epoch: 72.4 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24177335012293563		[learning rate: 0.0026531]
	Learning Rate: 0.00265314
	LOSS [training: 0.24177335012293563 | validation: 0.20847323870640522]
	TIME [epoch: 72.4 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2396485000460836		[learning rate: 0.0026469]
	Learning Rate: 0.00264688
	LOSS [training: 0.2396485000460836 | validation: 0.2092717041057354]
	TIME [epoch: 72.4 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24723393428433668		[learning rate: 0.0026406]
	Learning Rate: 0.00264064
	LOSS [training: 0.24723393428433668 | validation: 0.20786203050744265]
	TIME [epoch: 72.4 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24139271771241919		[learning rate: 0.0026344]
	Learning Rate: 0.00263441
	LOSS [training: 0.24139271771241919 | validation: 0.20389224414702828]
	TIME [epoch: 72.4 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2386081411227242		[learning rate: 0.0026282]
	Learning Rate: 0.0026282
	LOSS [training: 0.2386081411227242 | validation: 0.21073373573495466]
	TIME [epoch: 72.4 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2441769769802049		[learning rate: 0.002622]
	Learning Rate: 0.002622
	LOSS [training: 0.2441769769802049 | validation: 0.20459721306865544]
	TIME [epoch: 72.4 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2472857739993969		[learning rate: 0.0026158]
	Learning Rate: 0.00261581
	LOSS [training: 0.2472857739993969 | validation: 0.22378479033750093]
	TIME [epoch: 72.4 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2473427102269683		[learning rate: 0.0026096]
	Learning Rate: 0.00260964
	LOSS [training: 0.2473427102269683 | validation: 0.20954957353976694]
	TIME [epoch: 72.4 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2404647708704302		[learning rate: 0.0026035]
	Learning Rate: 0.00260349
	LOSS [training: 0.2404647708704302 | validation: 0.2082102685939078]
	TIME [epoch: 72.4 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24365114288143533		[learning rate: 0.0025973]
	Learning Rate: 0.00259735
	LOSS [training: 0.24365114288143533 | validation: 0.20170281220059666]
	TIME [epoch: 72.4 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24370712809602		[learning rate: 0.0025912]
	Learning Rate: 0.00259122
	LOSS [training: 0.24370712809602 | validation: 0.20780891754735062]
	TIME [epoch: 72.4 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2412499023229602		[learning rate: 0.0025851]
	Learning Rate: 0.00258511
	LOSS [training: 0.2412499023229602 | validation: 0.20233107102832593]
	TIME [epoch: 72.4 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24168365540767325		[learning rate: 0.002579]
	Learning Rate: 0.00257901
	LOSS [training: 0.24168365540767325 | validation: 0.20617651102584075]
	TIME [epoch: 72.3 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24305319782118726		[learning rate: 0.0025729]
	Learning Rate: 0.00257293
	LOSS [training: 0.24305319782118726 | validation: 0.21502170717756117]
	TIME [epoch: 72.3 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24553377768109166		[learning rate: 0.0025669]
	Learning Rate: 0.00256686
	LOSS [training: 0.24553377768109166 | validation: 0.20867875646337025]
	TIME [epoch: 72.3 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24641234160451042		[learning rate: 0.0025608]
	Learning Rate: 0.0025608
	LOSS [training: 0.24641234160451042 | validation: 0.2089779081302726]
	TIME [epoch: 72.4 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24588954408783295		[learning rate: 0.0025548]
	Learning Rate: 0.00255476
	LOSS [training: 0.24588954408783295 | validation: 0.20873782264241658]
	TIME [epoch: 72.3 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24928259936848454		[learning rate: 0.0025487]
	Learning Rate: 0.00254874
	LOSS [training: 0.24928259936848454 | validation: 0.22729618641734933]
	TIME [epoch: 72.3 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25249807128975554		[learning rate: 0.0025427]
	Learning Rate: 0.00254272
	LOSS [training: 0.25249807128975554 | validation: 0.21650965837826058]
	TIME [epoch: 72.3 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24410820858490556		[learning rate: 0.0025367]
	Learning Rate: 0.00253673
	LOSS [training: 0.24410820858490556 | validation: 0.21388103534852937]
	TIME [epoch: 72.3 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24110336741597924		[learning rate: 0.0025307]
	Learning Rate: 0.00253074
	LOSS [training: 0.24110336741597924 | validation: 0.21264188079827293]
	TIME [epoch: 72.3 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24827105644895128		[learning rate: 0.0025248]
	Learning Rate: 0.00252477
	LOSS [training: 0.24827105644895128 | validation: 0.20916315057499263]
	TIME [epoch: 72.3 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24249673379551737		[learning rate: 0.0025188]
	Learning Rate: 0.00251882
	LOSS [training: 0.24249673379551737 | validation: 0.21100655878625485]
	TIME [epoch: 72.3 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24474342297573007		[learning rate: 0.0025129]
	Learning Rate: 0.00251288
	LOSS [training: 0.24474342297573007 | validation: 0.21015827909778043]
	TIME [epoch: 72.3 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2489797617222211		[learning rate: 0.0025069]
	Learning Rate: 0.00250695
	LOSS [training: 0.2489797617222211 | validation: 0.2060857620893352]
	TIME [epoch: 72.3 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24256215488327826		[learning rate: 0.002501]
	Learning Rate: 0.00250103
	LOSS [training: 0.24256215488327826 | validation: 0.2071002191845376]
	TIME [epoch: 72.4 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24218823978192958		[learning rate: 0.0024951]
	Learning Rate: 0.00249513
	LOSS [training: 0.24218823978192958 | validation: 0.20486707610765711]
	TIME [epoch: 72.3 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2400119312666402		[learning rate: 0.0024892]
	Learning Rate: 0.00248925
	LOSS [training: 0.2400119312666402 | validation: 0.20776624860977008]
	TIME [epoch: 72.3 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24489649185653728		[learning rate: 0.0024834]
	Learning Rate: 0.00248338
	LOSS [training: 0.24489649185653728 | validation: 0.21841146762826336]
	TIME [epoch: 72.3 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24773860558578295		[learning rate: 0.0024775]
	Learning Rate: 0.00247752
	LOSS [training: 0.24773860558578295 | validation: 0.20640354108927794]
	TIME [epoch: 72.3 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24568189795851988		[learning rate: 0.0024717]
	Learning Rate: 0.00247168
	LOSS [training: 0.24568189795851988 | validation: 0.20490559280305565]
	TIME [epoch: 72.2 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24045614766151494		[learning rate: 0.0024658]
	Learning Rate: 0.00246585
	LOSS [training: 0.24045614766151494 | validation: 0.20428801211494335]
	TIME [epoch: 72.3 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23838456035718525		[learning rate: 0.00246]
	Learning Rate: 0.00246003
	LOSS [training: 0.23838456035718525 | validation: 0.20915696272752884]
	TIME [epoch: 72.2 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24408571842583057		[learning rate: 0.0024542]
	Learning Rate: 0.00245423
	LOSS [training: 0.24408571842583057 | validation: 0.21062520088786574]
	TIME [epoch: 72.2 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2391658879192818		[learning rate: 0.0024484]
	Learning Rate: 0.00244844
	LOSS [training: 0.2391658879192818 | validation: 0.2015584533961265]
	TIME [epoch: 72.3 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23935715253389842		[learning rate: 0.0024427]
	Learning Rate: 0.00244266
	LOSS [training: 0.23935715253389842 | validation: 0.2028124330005608]
	TIME [epoch: 72.3 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23881717054584717		[learning rate: 0.0024369]
	Learning Rate: 0.0024369
	LOSS [training: 0.23881717054584717 | validation: 0.20534564944560843]
	TIME [epoch: 72.3 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24099761112141507		[learning rate: 0.0024312]
	Learning Rate: 0.00243115
	LOSS [training: 0.24099761112141507 | validation: 0.2016802695228988]
	TIME [epoch: 72.3 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.242719413188224		[learning rate: 0.0024254]
	Learning Rate: 0.00242542
	LOSS [training: 0.242719413188224 | validation: 0.20809335485748265]
	TIME [epoch: 72.3 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2467627464141305		[learning rate: 0.0024197]
	Learning Rate: 0.0024197
	LOSS [training: 0.2467627464141305 | validation: 0.20310999421438675]
	TIME [epoch: 72.3 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2428599831451144		[learning rate: 0.002414]
	Learning Rate: 0.00241399
	LOSS [training: 0.2428599831451144 | validation: 0.20138813266495773]
	TIME [epoch: 72.3 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24217049908184796		[learning rate: 0.0024083]
	Learning Rate: 0.00240829
	LOSS [training: 0.24217049908184796 | validation: 0.20287592225250553]
	TIME [epoch: 72.3 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23901861636051094		[learning rate: 0.0024026]
	Learning Rate: 0.00240261
	LOSS [training: 0.23901861636051094 | validation: 0.20245004609745337]
	TIME [epoch: 72.3 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23888643779240493		[learning rate: 0.0023969]
	Learning Rate: 0.00239694
	LOSS [training: 0.23888643779240493 | validation: 0.2138512335557718]
	TIME [epoch: 72.3 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24596678436368558		[learning rate: 0.0023913]
	Learning Rate: 0.00239129
	LOSS [training: 0.24596678436368558 | validation: 0.20424848811542834]
	TIME [epoch: 72.3 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23987262811494037		[learning rate: 0.0023857]
	Learning Rate: 0.00238565
	LOSS [training: 0.23987262811494037 | validation: 0.20650822422211376]
	TIME [epoch: 72.3 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24394094152109477		[learning rate: 0.00238]
	Learning Rate: 0.00238002
	LOSS [training: 0.24394094152109477 | validation: 0.20264449227992887]
	TIME [epoch: 72.3 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2375564429674241		[learning rate: 0.0023744]
	Learning Rate: 0.00237441
	LOSS [training: 0.2375564429674241 | validation: 0.20594663893834358]
	TIME [epoch: 72.3 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23808473013508194		[learning rate: 0.0023688]
	Learning Rate: 0.00236881
	LOSS [training: 0.23808473013508194 | validation: 0.20049456241688715]
	TIME [epoch: 72.4 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23984294458963495		[learning rate: 0.0023632]
	Learning Rate: 0.00236322
	LOSS [training: 0.23984294458963495 | validation: 0.2037108949112778]
	TIME [epoch: 72.3 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2433383205440176		[learning rate: 0.0023576]
	Learning Rate: 0.00235765
	LOSS [training: 0.2433383205440176 | validation: 0.21102276478277657]
	TIME [epoch: 72.3 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24578413736346286		[learning rate: 0.0023521]
	Learning Rate: 0.00235208
	LOSS [training: 0.24578413736346286 | validation: 0.20329614432382076]
	TIME [epoch: 72.3 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2377475402778959		[learning rate: 0.0023465]
	Learning Rate: 0.00234654
	LOSS [training: 0.2377475402778959 | validation: 0.19951363298475258]
	TIME [epoch: 72.3 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_vlargesamp_20240719_155254/states/model_facs_v3_dec1b_2dpca_vlargesamp_664.pth
	Model improved!!!
EPOCH 665/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23899196318215055		[learning rate: 0.002341]
	Learning Rate: 0.002341
	LOSS [training: 0.23899196318215055 | validation: 0.2065262582222332]
	TIME [epoch: 72.2 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2469740858584545		[learning rate: 0.0023355]
	Learning Rate: 0.00233548
	LOSS [training: 0.2469740858584545 | validation: 0.19945760292406373]
	TIME [epoch: 72.1 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_vlargesamp_20240719_155254/states/model_facs_v3_dec1b_2dpca_vlargesamp_666.pth
	Model improved!!!
EPOCH 667/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2440224290366266		[learning rate: 0.00233]
	Learning Rate: 0.00232997
	LOSS [training: 0.2440224290366266 | validation: 0.20461761705091516]
	TIME [epoch: 72.2 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25240503670437814		[learning rate: 0.0023245]
	Learning Rate: 0.00232447
	LOSS [training: 0.25240503670437814 | validation: 0.21449832785281067]
	TIME [epoch: 72.2 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2476010496577572		[learning rate: 0.002319]
	Learning Rate: 0.00231899
	LOSS [training: 0.2476010496577572 | validation: 0.20178680530993293]
	TIME [epoch: 72.2 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24278369608767977		[learning rate: 0.0023135]
	Learning Rate: 0.00231352
	LOSS [training: 0.24278369608767977 | validation: 0.20733801774424726]
	TIME [epoch: 72.2 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2414141185115167		[learning rate: 0.0023081]
	Learning Rate: 0.00230806
	LOSS [training: 0.2414141185115167 | validation: 0.21140566818883463]
	TIME [epoch: 72.2 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2431337272028271		[learning rate: 0.0023026]
	Learning Rate: 0.00230262
	LOSS [training: 0.2431337272028271 | validation: 0.20621892081907706]
	TIME [epoch: 72.2 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24459246381994978		[learning rate: 0.0022972]
	Learning Rate: 0.00229719
	LOSS [training: 0.24459246381994978 | validation: 0.2005876434020782]
	TIME [epoch: 72.2 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24217777537949733		[learning rate: 0.0022918]
	Learning Rate: 0.00229177
	LOSS [training: 0.24217777537949733 | validation: 0.20540360069228364]
	TIME [epoch: 72.2 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2456119784281204		[learning rate: 0.0022864]
	Learning Rate: 0.00228636
	LOSS [training: 0.2456119784281204 | validation: 0.207911006533731]
	TIME [epoch: 72.2 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23855676373922377		[learning rate: 0.002281]
	Learning Rate: 0.00228097
	LOSS [training: 0.23855676373922377 | validation: 0.2027208910761757]
	TIME [epoch: 72.2 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24137154952626946		[learning rate: 0.0022756]
	Learning Rate: 0.00227559
	LOSS [training: 0.24137154952626946 | validation: 0.20314853046416098]
	TIME [epoch: 72.2 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2371129921451773		[learning rate: 0.0022702]
	Learning Rate: 0.00227022
	LOSS [training: 0.2371129921451773 | validation: 0.20763982867113512]
	TIME [epoch: 72.2 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24078914496080284		[learning rate: 0.0022649]
	Learning Rate: 0.00226487
	LOSS [training: 0.24078914496080284 | validation: 0.20328055358459843]
	TIME [epoch: 72.2 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2435900204714182		[learning rate: 0.0022595]
	Learning Rate: 0.00225952
	LOSS [training: 0.2435900204714182 | validation: 0.20740626863690234]
	TIME [epoch: 72.3 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24745503413915482		[learning rate: 0.0022542]
	Learning Rate: 0.00225419
	LOSS [training: 0.24745503413915482 | validation: 0.20376100035430408]
	TIME [epoch: 72.2 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24851798468324912		[learning rate: 0.0022489]
	Learning Rate: 0.00224888
	LOSS [training: 0.24851798468324912 | validation: 0.22371151307829718]
	TIME [epoch: 72.3 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2681904620075501		[learning rate: 0.0022436]
	Learning Rate: 0.00224357
	LOSS [training: 0.2681904620075501 | validation: 0.21895780415626614]
	TIME [epoch: 72.3 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2603644942616408		[learning rate: 0.0022383]
	Learning Rate: 0.00223828
	LOSS [training: 0.2603644942616408 | validation: 0.20968419663630794]
	TIME [epoch: 72.3 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25049027107525984		[learning rate: 0.002233]
	Learning Rate: 0.002233
	LOSS [training: 0.25049027107525984 | validation: 0.20608542168714544]
	TIME [epoch: 72.3 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24710823234888993		[learning rate: 0.0022277]
	Learning Rate: 0.00222773
	LOSS [training: 0.24710823234888993 | validation: 0.20704770280294765]
	TIME [epoch: 72.3 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2451198048106197		[learning rate: 0.0022225]
	Learning Rate: 0.00222248
	LOSS [training: 0.2451198048106197 | validation: 0.20582161289783762]
	TIME [epoch: 72.2 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24259178084230168		[learning rate: 0.0022172]
	Learning Rate: 0.00221724
	LOSS [training: 0.24259178084230168 | validation: 0.202099767017351]
	TIME [epoch: 72.3 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24292902665574767		[learning rate: 0.002212]
	Learning Rate: 0.00221201
	LOSS [training: 0.24292902665574767 | validation: 0.20014639794057637]
	TIME [epoch: 72.2 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24172593090868433		[learning rate: 0.0022068]
	Learning Rate: 0.00220679
	LOSS [training: 0.24172593090868433 | validation: 0.20039511742012883]
	TIME [epoch: 72.3 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24473141553546748		[learning rate: 0.0022016]
	Learning Rate: 0.00220158
	LOSS [training: 0.24473141553546748 | validation: 0.20447931114884446]
	TIME [epoch: 72.3 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23995698679557687		[learning rate: 0.0021964]
	Learning Rate: 0.00219639
	LOSS [training: 0.23995698679557687 | validation: 0.20078751691795332]
	TIME [epoch: 72.3 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23974550900386793		[learning rate: 0.0021912]
	Learning Rate: 0.00219121
	LOSS [training: 0.23974550900386793 | validation: 0.19843591348692124]
	TIME [epoch: 72.3 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_vlargesamp_20240719_155254/states/model_facs_v3_dec1b_2dpca_vlargesamp_693.pth
	Model improved!!!
EPOCH 694/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24136983347971455		[learning rate: 0.002186]
	Learning Rate: 0.00218604
	LOSS [training: 0.24136983347971455 | validation: 0.20075564120057363]
	TIME [epoch: 72.2 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2418378302027401		[learning rate: 0.0021809]
	Learning Rate: 0.00218088
	LOSS [training: 0.2418378302027401 | validation: 0.20388772263072602]
	TIME [epoch: 72.2 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24255539450296706		[learning rate: 0.0021757]
	Learning Rate: 0.00217574
	LOSS [training: 0.24255539450296706 | validation: 0.21465024770429703]
	TIME [epoch: 72.2 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25007043156368064		[learning rate: 0.0021706]
	Learning Rate: 0.00217061
	LOSS [training: 0.25007043156368064 | validation: 0.20531169268383173]
	TIME [epoch: 72.2 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24558104965335945		[learning rate: 0.0021655]
	Learning Rate: 0.00216549
	LOSS [training: 0.24558104965335945 | validation: 0.20366747945427938]
	TIME [epoch: 72.2 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2414019590857344		[learning rate: 0.0021604]
	Learning Rate: 0.00216038
	LOSS [training: 0.2414019590857344 | validation: 0.20671369628275768]
	TIME [epoch: 72.2 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24345871609758948		[learning rate: 0.0021553]
	Learning Rate: 0.00215528
	LOSS [training: 0.24345871609758948 | validation: 0.20775034695113845]
	TIME [epoch: 72.2 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2389163662123894		[learning rate: 0.0021502]
	Learning Rate: 0.0021502
	LOSS [training: 0.2389163662123894 | validation: 0.2117370258099379]
	TIME [epoch: 72 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23771322608868695		[learning rate: 0.0021451]
	Learning Rate: 0.00214513
	LOSS [training: 0.23771322608868695 | validation: 0.2018471923007689]
	TIME [epoch: 72 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23659892460583262		[learning rate: 0.0021401]
	Learning Rate: 0.00214007
	LOSS [training: 0.23659892460583262 | validation: 0.19965506853101306]
	TIME [epoch: 72 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24215983047749465		[learning rate: 0.002135]
	Learning Rate: 0.00213502
	LOSS [training: 0.24215983047749465 | validation: 0.20482637550975463]
	TIME [epoch: 72.2 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2389222824360169		[learning rate: 0.00213]
	Learning Rate: 0.00212998
	LOSS [training: 0.2389222824360169 | validation: 0.2009652856099097]
	TIME [epoch: 72.2 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2375148155008223		[learning rate: 0.002125]
	Learning Rate: 0.00212496
	LOSS [training: 0.2375148155008223 | validation: 0.2093090307682744]
	TIME [epoch: 72.1 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24889820656259287		[learning rate: 0.0021199]
	Learning Rate: 0.00211995
	LOSS [training: 0.24889820656259287 | validation: 0.20723268744061576]
	TIME [epoch: 72.2 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24818445922084886		[learning rate: 0.0021149]
	Learning Rate: 0.00211495
	LOSS [training: 0.24818445922084886 | validation: 0.20736415846730663]
	TIME [epoch: 72.2 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25074385986600906		[learning rate: 0.00211]
	Learning Rate: 0.00210996
	LOSS [training: 0.25074385986600906 | validation: 0.1987272459839459]
	TIME [epoch: 72.2 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24584365562852087		[learning rate: 0.002105]
	Learning Rate: 0.00210498
	LOSS [training: 0.24584365562852087 | validation: 0.20011586515189017]
	TIME [epoch: 72.2 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24074484538989585		[learning rate: 0.0021]
	Learning Rate: 0.00210001
	LOSS [training: 0.24074484538989585 | validation: 0.20197212428674596]
	TIME [epoch: 72.2 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24066640774925027		[learning rate: 0.0020951]
	Learning Rate: 0.00209506
	LOSS [training: 0.24066640774925027 | validation: 0.20225335268466632]
	TIME [epoch: 72.2 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23974323394616182		[learning rate: 0.0020901]
	Learning Rate: 0.00209012
	LOSS [training: 0.23974323394616182 | validation: 0.20248116026893279]
	TIME [epoch: 72.2 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23990900492094966		[learning rate: 0.0020852]
	Learning Rate: 0.00208519
	LOSS [training: 0.23990900492094966 | validation: 0.2003729164176311]
	TIME [epoch: 72.2 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.239402259942911		[learning rate: 0.0020803]
	Learning Rate: 0.00208027
	LOSS [training: 0.239402259942911 | validation: 0.19893130543496865]
	TIME [epoch: 72.2 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2361204082822347		[learning rate: 0.0020754]
	Learning Rate: 0.00207536
	LOSS [training: 0.2361204082822347 | validation: 0.2030298359762764]
	TIME [epoch: 72.2 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23974122872421041		[learning rate: 0.0020705]
	Learning Rate: 0.00207047
	LOSS [training: 0.23974122872421041 | validation: 0.20320620233546896]
	TIME [epoch: 72.3 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23966045640265163		[learning rate: 0.0020656]
	Learning Rate: 0.00206558
	LOSS [training: 0.23966045640265163 | validation: 0.20243829623749834]
	TIME [epoch: 72.2 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24099284656281558		[learning rate: 0.0020607]
	Learning Rate: 0.00206071
	LOSS [training: 0.24099284656281558 | validation: 0.20560661777418754]
	TIME [epoch: 72.2 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24020834112507786		[learning rate: 0.0020558]
	Learning Rate: 0.00205585
	LOSS [training: 0.24020834112507786 | validation: 0.20252326020410485]
	TIME [epoch: 72.2 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24091402542425844		[learning rate: 0.002051]
	Learning Rate: 0.002051
	LOSS [training: 0.24091402542425844 | validation: 0.20807106690513572]
	TIME [epoch: 72.1 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24458552904276412		[learning rate: 0.0020462]
	Learning Rate: 0.00204616
	LOSS [training: 0.24458552904276412 | validation: 0.20114280679777946]
	TIME [epoch: 72.2 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24308579516385012		[learning rate: 0.0020413]
	Learning Rate: 0.00204134
	LOSS [training: 0.24308579516385012 | validation: 0.20119660114060137]
	TIME [epoch: 72.2 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2492857770854322		[learning rate: 0.0020365]
	Learning Rate: 0.00203652
	LOSS [training: 0.2492857770854322 | validation: 0.20153572232206804]
	TIME [epoch: 72.2 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24313467898713326		[learning rate: 0.0020317]
	Learning Rate: 0.00203172
	LOSS [training: 0.24313467898713326 | validation: 0.2029075690905481]
	TIME [epoch: 72.2 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24354960147408475		[learning rate: 0.0020269]
	Learning Rate: 0.00202692
	LOSS [training: 0.24354960147408475 | validation: 0.20507226626677647]
	TIME [epoch: 72.3 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24433677512367905		[learning rate: 0.0020221]
	Learning Rate: 0.00202214
	LOSS [training: 0.24433677512367905 | validation: 0.1980457443490548]
	TIME [epoch: 72.2 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_vlargesamp_20240719_155254/states/model_facs_v3_dec1b_2dpca_vlargesamp_727.pth
	Model improved!!!
EPOCH 728/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26320461250676247		[learning rate: 0.0020174]
	Learning Rate: 0.00201737
	LOSS [training: 0.26320461250676247 | validation: 0.21768242482343653]
	TIME [epoch: 72.1 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25211372069667903		[learning rate: 0.0020126]
	Learning Rate: 0.00201261
	LOSS [training: 0.25211372069667903 | validation: 0.21076188934891898]
	TIME [epoch: 72.1 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.254832042790519		[learning rate: 0.0020079]
	Learning Rate: 0.00200787
	LOSS [training: 0.254832042790519 | validation: 0.21661337245489815]
	TIME [epoch: 72.1 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25224359516181244		[learning rate: 0.0020031]
	Learning Rate: 0.00200313
	LOSS [training: 0.25224359516181244 | validation: 0.21071682398869598]
	TIME [epoch: 72.2 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24634256420780024		[learning rate: 0.0019984]
	Learning Rate: 0.00199841
	LOSS [training: 0.24634256420780024 | validation: 0.2111579130938098]
	TIME [epoch: 72.1 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25086615774276977		[learning rate: 0.0019937]
	Learning Rate: 0.00199369
	LOSS [training: 0.25086615774276977 | validation: 0.2120664372705648]
	TIME [epoch: 72.2 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2486111326341213		[learning rate: 0.001989]
	Learning Rate: 0.00198899
	LOSS [training: 0.2486111326341213 | validation: 0.21840331889457976]
	TIME [epoch: 72.2 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24886126430602432		[learning rate: 0.0019843]
	Learning Rate: 0.0019843
	LOSS [training: 0.24886126430602432 | validation: 0.20910869052351982]
	TIME [epoch: 72.2 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24262712809183237		[learning rate: 0.0019796]
	Learning Rate: 0.00197962
	LOSS [training: 0.24262712809183237 | validation: 0.20853345956035546]
	TIME [epoch: 72.2 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2417053798943296		[learning rate: 0.0019749]
	Learning Rate: 0.00197495
	LOSS [training: 0.2417053798943296 | validation: 0.20536583636075773]
	TIME [epoch: 72.1 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24287715677830665		[learning rate: 0.0019703]
	Learning Rate: 0.00197029
	LOSS [training: 0.24287715677830665 | validation: 0.20283106101260923]
	TIME [epoch: 72.2 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2401214637704234		[learning rate: 0.0019656]
	Learning Rate: 0.00196564
	LOSS [training: 0.2401214637704234 | validation: 0.20314904813528067]
	TIME [epoch: 72.1 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2387051801678732		[learning rate: 0.001961]
	Learning Rate: 0.001961
	LOSS [training: 0.2387051801678732 | validation: 0.20065249057771273]
	TIME [epoch: 72.2 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23893345762151896		[learning rate: 0.0019564]
	Learning Rate: 0.00195638
	LOSS [training: 0.23893345762151896 | validation: 0.199253810185268]
	TIME [epoch: 72.2 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24047962063323233		[learning rate: 0.0019518]
	Learning Rate: 0.00195176
	LOSS [training: 0.24047962063323233 | validation: 0.2027193480509367]
	TIME [epoch: 72.2 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23958823851837616		[learning rate: 0.0019472]
	Learning Rate: 0.00194716
	LOSS [training: 0.23958823851837616 | validation: 0.2014651219889934]
	TIME [epoch: 72.2 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24341209918633103		[learning rate: 0.0019426]
	Learning Rate: 0.00194257
	LOSS [training: 0.24341209918633103 | validation: 0.20393757616591449]
	TIME [epoch: 72.2 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2406115377167237		[learning rate: 0.001938]
	Learning Rate: 0.00193798
	LOSS [training: 0.2406115377167237 | validation: 0.2030483759492639]
	TIME [epoch: 72.2 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24053249902655907		[learning rate: 0.0019334]
	Learning Rate: 0.00193341
	LOSS [training: 0.24053249902655907 | validation: 0.2027180099876614]
	TIME [epoch: 72.2 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2379661238376974		[learning rate: 0.0019289]
	Learning Rate: 0.00192885
	LOSS [training: 0.2379661238376974 | validation: 0.20338776120137436]
	TIME [epoch: 72.1 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23906077928208672		[learning rate: 0.0019243]
	Learning Rate: 0.0019243
	LOSS [training: 0.23906077928208672 | validation: 0.20035913273843664]
	TIME [epoch: 72.2 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23784206041257783		[learning rate: 0.0019198]
	Learning Rate: 0.00191976
	LOSS [training: 0.23784206041257783 | validation: 0.20557560907994418]
	TIME [epoch: 72.2 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23888270529636124		[learning rate: 0.0019152]
	Learning Rate: 0.00191524
	LOSS [training: 0.23888270529636124 | validation: 0.20387663233581127]
	TIME [epoch: 72.2 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24047440029237688		[learning rate: 0.0019107]
	Learning Rate: 0.00191072
	LOSS [training: 0.24047440029237688 | validation: 0.20777588738964922]
	TIME [epoch: 72.2 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24618573831283994		[learning rate: 0.0019062]
	Learning Rate: 0.00190621
	LOSS [training: 0.24618573831283994 | validation: 0.20906176964891282]
	TIME [epoch: 72.2 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24447585189563215		[learning rate: 0.0019017]
	Learning Rate: 0.00190171
	LOSS [training: 0.24447585189563215 | validation: 0.20437368581217794]
	TIME [epoch: 72.2 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23987414254633474		[learning rate: 0.0018972]
	Learning Rate: 0.00189723
	LOSS [training: 0.23987414254633474 | validation: 0.20092403572764925]
	TIME [epoch: 72.2 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24100131912228984		[learning rate: 0.0018928]
	Learning Rate: 0.00189275
	LOSS [training: 0.24100131912228984 | validation: 0.20222304494726084]
	TIME [epoch: 72.2 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24373642826707662		[learning rate: 0.0018883]
	Learning Rate: 0.00188829
	LOSS [training: 0.24373642826707662 | validation: 0.20619439094873432]
	TIME [epoch: 72.2 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24695784708906146		[learning rate: 0.0018838]
	Learning Rate: 0.00188383
	LOSS [training: 0.24695784708906146 | validation: 0.20417793203063458]
	TIME [epoch: 72.2 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2456869119192848		[learning rate: 0.0018794]
	Learning Rate: 0.00187939
	LOSS [training: 0.2456869119192848 | validation: 0.204736091064536]
	TIME [epoch: 72.3 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24306555834798863		[learning rate: 0.001875]
	Learning Rate: 0.00187496
	LOSS [training: 0.24306555834798863 | validation: 0.20328870607917474]
	TIME [epoch: 72.2 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23632438866919203		[learning rate: 0.0018705]
	Learning Rate: 0.00187053
	LOSS [training: 0.23632438866919203 | validation: 0.20069176045921547]
	TIME [epoch: 72.2 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2399978273428114		[learning rate: 0.0018661]
	Learning Rate: 0.00186612
	LOSS [training: 0.2399978273428114 | validation: 0.1981829098446976]
	TIME [epoch: 72.2 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2441029591695484		[learning rate: 0.0018617]
	Learning Rate: 0.00186172
	LOSS [training: 0.2441029591695484 | validation: 0.21317516531723676]
	TIME [epoch: 72.1 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25411853639433807		[learning rate: 0.0018573]
	Learning Rate: 0.00185733
	LOSS [training: 0.25411853639433807 | validation: 0.20756570531133695]
	TIME [epoch: 72.1 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24181545597970158		[learning rate: 0.0018529]
	Learning Rate: 0.00185295
	LOSS [training: 0.24181545597970158 | validation: 0.20480626756668957]
	TIME [epoch: 72.2 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24050000109803574		[learning rate: 0.0018486]
	Learning Rate: 0.00184858
	LOSS [training: 0.24050000109803574 | validation: 0.2001844678253578]
	TIME [epoch: 72.2 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23870571336806412		[learning rate: 0.0018442]
	Learning Rate: 0.00184422
	LOSS [training: 0.23870571336806412 | validation: 0.20407300940367495]
	TIME [epoch: 72.1 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24182505304183147		[learning rate: 0.0018399]
	Learning Rate: 0.00183987
	LOSS [training: 0.24182505304183147 | validation: 0.20070721594346744]
	TIME [epoch: 72.2 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2425843619072059		[learning rate: 0.0018355]
	Learning Rate: 0.00183553
	LOSS [training: 0.2425843619072059 | validation: 0.19915676972739085]
	TIME [epoch: 72.2 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24106494969361972		[learning rate: 0.0018312]
	Learning Rate: 0.0018312
	LOSS [training: 0.24106494969361972 | validation: 0.20136691643075616]
	TIME [epoch: 72.1 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24181487352365838		[learning rate: 0.0018269]
	Learning Rate: 0.00182688
	LOSS [training: 0.24181487352365838 | validation: 0.20020450112561528]
	TIME [epoch: 72.1 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24281687978705105		[learning rate: 0.0018226]
	Learning Rate: 0.00182257
	LOSS [training: 0.24281687978705105 | validation: 0.19992823791574604]
	TIME [epoch: 72.2 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2392330482861659		[learning rate: 0.0018183]
	Learning Rate: 0.00181827
	LOSS [training: 0.2392330482861659 | validation: 0.19784888711734294]
	TIME [epoch: 72.2 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_vlargesamp_20240719_155254/states/model_facs_v3_dec1b_2dpca_vlargesamp_772.pth
	Model improved!!!
EPOCH 773/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24058872541815055		[learning rate: 0.001814]
	Learning Rate: 0.00181398
	LOSS [training: 0.24058872541815055 | validation: 0.19945397869069253]
	TIME [epoch: 72 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2413174138202654		[learning rate: 0.0018097]
	Learning Rate: 0.0018097
	LOSS [training: 0.2413174138202654 | validation: 0.20228409421881333]
	TIME [epoch: 72 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2372978859268511		[learning rate: 0.0018054]
	Learning Rate: 0.00180543
	LOSS [training: 0.2372978859268511 | validation: 0.2019332982918713]
	TIME [epoch: 72 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2408830350586678		[learning rate: 0.0018012]
	Learning Rate: 0.00180117
	LOSS [training: 0.2408830350586678 | validation: 0.19941953639532412]
	TIME [epoch: 72 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23873047771139375		[learning rate: 0.0017969]
	Learning Rate: 0.00179692
	LOSS [training: 0.23873047771139375 | validation: 0.20107029711909105]
	TIME [epoch: 72 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.237319378624634		[learning rate: 0.0017927]
	Learning Rate: 0.00179269
	LOSS [training: 0.237319378624634 | validation: 0.20374364381709772]
	TIME [epoch: 72 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2405099693690145		[learning rate: 0.0017885]
	Learning Rate: 0.00178846
	LOSS [training: 0.2405099693690145 | validation: 0.2047210849550832]
	TIME [epoch: 72 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2532038177842705		[learning rate: 0.0017842]
	Learning Rate: 0.00178424
	LOSS [training: 0.2532038177842705 | validation: 0.2206155620734326]
	TIME [epoch: 72 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2527356561877994		[learning rate: 0.00178]
	Learning Rate: 0.00178003
	LOSS [training: 0.2527356561877994 | validation: 0.21273096483770826]
	TIME [epoch: 72 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25161625705423113		[learning rate: 0.0017758]
	Learning Rate: 0.00177583
	LOSS [training: 0.25161625705423113 | validation: 0.20924797172983833]
	TIME [epoch: 72 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24305567558147292		[learning rate: 0.0017716]
	Learning Rate: 0.00177164
	LOSS [training: 0.24305567558147292 | validation: 0.2044932565633336]
	TIME [epoch: 72 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23654745845605663		[learning rate: 0.0017675]
	Learning Rate: 0.00176746
	LOSS [training: 0.23654745845605663 | validation: 0.20659306733569033]
	TIME [epoch: 72 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23769833183696973		[learning rate: 0.0017633]
	Learning Rate: 0.00176329
	LOSS [training: 0.23769833183696973 | validation: 0.20260422887301552]
	TIME [epoch: 72 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23825221428382234		[learning rate: 0.0017591]
	Learning Rate: 0.00175913
	LOSS [training: 0.23825221428382234 | validation: 0.20025413145645396]
	TIME [epoch: 72.1 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23625374769232368		[learning rate: 0.001755]
	Learning Rate: 0.00175499
	LOSS [training: 0.23625374769232368 | validation: 0.2026586545891805]
	TIME [epoch: 72.1 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23699787963335847		[learning rate: 0.0017508]
	Learning Rate: 0.00175085
	LOSS [training: 0.23699787963335847 | validation: 0.2092320471119188]
	TIME [epoch: 72.1 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23738495313919658		[learning rate: 0.0017467]
	Learning Rate: 0.00174672
	LOSS [training: 0.23738495313919658 | validation: 0.2036893897315156]
	TIME [epoch: 72.1 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2372403406287361		[learning rate: 0.0017426]
	Learning Rate: 0.0017426
	LOSS [training: 0.2372403406287361 | validation: 0.2035224470513433]
	TIME [epoch: 72.1 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23908677603311743		[learning rate: 0.0017385]
	Learning Rate: 0.00173849
	LOSS [training: 0.23908677603311743 | validation: 0.20178174825201212]
	TIME [epoch: 72.1 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23903384246815018		[learning rate: 0.0017344]
	Learning Rate: 0.00173438
	LOSS [training: 0.23903384246815018 | validation: 0.2118133840898575]
	TIME [epoch: 72.1 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24172317262523915		[learning rate: 0.0017303]
	Learning Rate: 0.00173029
	LOSS [training: 0.24172317262523915 | validation: 0.20967183719834637]
	TIME [epoch: 72.1 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23823945439177316		[learning rate: 0.0017262]
	Learning Rate: 0.00172621
	LOSS [training: 0.23823945439177316 | validation: 0.1999610539296986]
	TIME [epoch: 72.1 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24001221645113935		[learning rate: 0.0017221]
	Learning Rate: 0.00172214
	LOSS [training: 0.24001221645113935 | validation: 0.20280191424091285]
	TIME [epoch: 72.1 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23814028004361365		[learning rate: 0.0017181]
	Learning Rate: 0.00171808
	LOSS [training: 0.23814028004361365 | validation: 0.20283089075540275]
	TIME [epoch: 72.1 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23671400397683814		[learning rate: 0.001714]
	Learning Rate: 0.00171402
	LOSS [training: 0.23671400397683814 | validation: 0.20786016321445483]
	TIME [epoch: 72 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24611697146053768		[learning rate: 0.00171]
	Learning Rate: 0.00170998
	LOSS [training: 0.24611697146053768 | validation: 0.2054314997988631]
	TIME [epoch: 72.1 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23990891568073702		[learning rate: 0.0017059]
	Learning Rate: 0.00170595
	LOSS [training: 0.23990891568073702 | validation: 0.20363781961097277]
	TIME [epoch: 72.1 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23892280354378614		[learning rate: 0.0017019]
	Learning Rate: 0.00170192
	LOSS [training: 0.23892280354378614 | validation: 0.20326243373834035]
	TIME [epoch: 72.1 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23811957684551066		[learning rate: 0.0016979]
	Learning Rate: 0.00169791
	LOSS [training: 0.23811957684551066 | validation: 0.2008882158692329]
	TIME [epoch: 72.3 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24020409516153884		[learning rate: 0.0016939]
	Learning Rate: 0.0016939
	LOSS [training: 0.24020409516153884 | validation: 0.20198100433123942]
	TIME [epoch: 72.3 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.236676587280949		[learning rate: 0.0016899]
	Learning Rate: 0.00168991
	LOSS [training: 0.236676587280949 | validation: 0.2066395180210145]
	TIME [epoch: 72.3 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23979341220692152		[learning rate: 0.0016859]
	Learning Rate: 0.00168592
	LOSS [training: 0.23979341220692152 | validation: 0.20537058822217916]
	TIME [epoch: 72.2 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24092051186593377		[learning rate: 0.0016819]
	Learning Rate: 0.00168195
	LOSS [training: 0.24092051186593377 | validation: 0.20876076372054767]
	TIME [epoch: 72.3 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24021503423470758		[learning rate: 0.001678]
	Learning Rate: 0.00167798
	LOSS [training: 0.24021503423470758 | validation: 0.21473438504027548]
	TIME [epoch: 72.3 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25054876067220144		[learning rate: 0.001674]
	Learning Rate: 0.00167402
	LOSS [training: 0.25054876067220144 | validation: 0.2045998545090088]
	TIME [epoch: 72.3 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24296875149494637		[learning rate: 0.0016701]
	Learning Rate: 0.00167007
	LOSS [training: 0.24296875149494637 | validation: 0.20204637905628736]
	TIME [epoch: 72.3 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23903512507877134		[learning rate: 0.0016661]
	Learning Rate: 0.00166613
	LOSS [training: 0.23903512507877134 | validation: 0.2030755717306934]
	TIME [epoch: 72.3 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23943249919541984		[learning rate: 0.0016622]
	Learning Rate: 0.0016622
	LOSS [training: 0.23943249919541984 | validation: 0.20161455470556366]
	TIME [epoch: 72.3 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2378700460762446		[learning rate: 0.0016583]
	Learning Rate: 0.00165828
	LOSS [training: 0.2378700460762446 | validation: 0.20436923397381596]
	TIME [epoch: 72.3 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23979745336062		[learning rate: 0.0016544]
	Learning Rate: 0.00165437
	LOSS [training: 0.23979745336062 | validation: 0.1996860246156121]
	TIME [epoch: 72.3 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23971723477711648		[learning rate: 0.0016505]
	Learning Rate: 0.00165047
	LOSS [training: 0.23971723477711648 | validation: 0.20721730656808704]
	TIME [epoch: 72.3 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23964803111153574		[learning rate: 0.0016466]
	Learning Rate: 0.00164657
	LOSS [training: 0.23964803111153574 | validation: 0.20270780941290162]
	TIME [epoch: 72.3 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24000842382597667		[learning rate: 0.0016427]
	Learning Rate: 0.00164269
	LOSS [training: 0.24000842382597667 | validation: 0.20363789223659215]
	TIME [epoch: 72.3 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24102789300333802		[learning rate: 0.0016388]
	Learning Rate: 0.00163881
	LOSS [training: 0.24102789300333802 | validation: 0.20111085239742024]
	TIME [epoch: 72.3 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23919570919198452		[learning rate: 0.0016349]
	Learning Rate: 0.00163495
	LOSS [training: 0.23919570919198452 | validation: 0.20133916088094272]
	TIME [epoch: 72.3 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2420811135877512		[learning rate: 0.0016311]
	Learning Rate: 0.00163109
	LOSS [training: 0.2420811135877512 | validation: 0.2095122918763937]
	TIME [epoch: 72.3 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24113835738668646		[learning rate: 0.0016272]
	Learning Rate: 0.00162725
	LOSS [training: 0.24113835738668646 | validation: 0.20413703353419033]
	TIME [epoch: 72.3 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2366347644293109		[learning rate: 0.0016234]
	Learning Rate: 0.00162341
	LOSS [training: 0.2366347644293109 | validation: 0.20277908458663235]
	TIME [epoch: 72.3 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2369420235760632		[learning rate: 0.0016196]
	Learning Rate: 0.00161958
	LOSS [training: 0.2369420235760632 | validation: 0.20072784339930042]
	TIME [epoch: 72.3 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24626370459827074		[learning rate: 0.0016158]
	Learning Rate: 0.00161576
	LOSS [training: 0.24626370459827074 | validation: 0.21067922426428284]
	TIME [epoch: 72.3 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24765932250571673		[learning rate: 0.0016119]
	Learning Rate: 0.00161195
	LOSS [training: 0.24765932250571673 | validation: 0.2193375638822633]
	TIME [epoch: 72.2 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25604634281667704		[learning rate: 0.0016081]
	Learning Rate: 0.00160814
	LOSS [training: 0.25604634281667704 | validation: 0.22025609141028896]
	TIME [epoch: 72.2 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2522057591387239		[learning rate: 0.0016043]
	Learning Rate: 0.00160435
	LOSS [training: 0.2522057591387239 | validation: 0.21402122152021227]
	TIME [epoch: 72.2 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2494768772264374		[learning rate: 0.0016006]
	Learning Rate: 0.00160057
	LOSS [training: 0.2494768772264374 | validation: 0.2118638037230068]
	TIME [epoch: 72.2 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2493574937581379		[learning rate: 0.0015968]
	Learning Rate: 0.00159679
	LOSS [training: 0.2493574937581379 | validation: 0.22973680355713996]
	TIME [epoch: 72.2 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2522995611839463		[learning rate: 0.001593]
	Learning Rate: 0.00159302
	LOSS [training: 0.2522995611839463 | validation: 0.20643398331470825]
	TIME [epoch: 72.1 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2408747726667477		[learning rate: 0.0015893]
	Learning Rate: 0.00158927
	LOSS [training: 0.2408747726667477 | validation: 0.2049631780827641]
	TIME [epoch: 72.2 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23894169751703473		[learning rate: 0.0015855]
	Learning Rate: 0.00158552
	LOSS [training: 0.23894169751703473 | validation: 0.20178585993958764]
	TIME [epoch: 72.2 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23759724619053346		[learning rate: 0.0015818]
	Learning Rate: 0.00158178
	LOSS [training: 0.23759724619053346 | validation: 0.20112953992077814]
	TIME [epoch: 72.2 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23754628199681796		[learning rate: 0.001578]
	Learning Rate: 0.00157805
	LOSS [training: 0.23754628199681796 | validation: 0.20028441091374277]
	TIME [epoch: 72.2 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23736755855424851		[learning rate: 0.0015743]
	Learning Rate: 0.00157432
	LOSS [training: 0.23736755855424851 | validation: 0.20017316358307963]
	TIME [epoch: 72.2 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24061558626321947		[learning rate: 0.0015706]
	Learning Rate: 0.00157061
	LOSS [training: 0.24061558626321947 | validation: 0.20424688727500268]
	TIME [epoch: 72.2 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23990346447118094		[learning rate: 0.0015669]
	Learning Rate: 0.00156691
	LOSS [training: 0.23990346447118094 | validation: 0.20730753306363878]
	TIME [epoch: 72.2 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24245621080094495		[learning rate: 0.0015632]
	Learning Rate: 0.00156321
	LOSS [training: 0.24245621080094495 | validation: 0.20830315503337404]
	TIME [epoch: 72.2 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23990013280679398		[learning rate: 0.0015595]
	Learning Rate: 0.00155952
	LOSS [training: 0.23990013280679398 | validation: 0.2087143207769973]
	TIME [epoch: 72.2 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24122110029661048		[learning rate: 0.0015558]
	Learning Rate: 0.00155584
	LOSS [training: 0.24122110029661048 | validation: 0.20665135702754936]
	TIME [epoch: 72.2 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24210570548470567		[learning rate: 0.0015522]
	Learning Rate: 0.00155217
	LOSS [training: 0.24210570548470567 | validation: 0.20543797500357605]
	TIME [epoch: 72.2 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23833961786670613		[learning rate: 0.0015485]
	Learning Rate: 0.00154851
	LOSS [training: 0.23833961786670613 | validation: 0.20842140399311065]
	TIME [epoch: 72.2 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23839536619076687		[learning rate: 0.0015449]
	Learning Rate: 0.00154486
	LOSS [training: 0.23839536619076687 | validation: 0.21138925565856637]
	TIME [epoch: 72.2 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2419064746413433		[learning rate: 0.0015412]
	Learning Rate: 0.00154121
	LOSS [training: 0.2419064746413433 | validation: 0.2121963503970287]
	TIME [epoch: 72.2 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2420310035280467		[learning rate: 0.0015376]
	Learning Rate: 0.00153758
	LOSS [training: 0.2420310035280467 | validation: 0.21384626477432028]
	TIME [epoch: 72.3 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24142612630147897		[learning rate: 0.001534]
	Learning Rate: 0.00153395
	LOSS [training: 0.24142612630147897 | validation: 0.21153304703258136]
	TIME [epoch: 72.3 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2434559438839883		[learning rate: 0.0015303]
	Learning Rate: 0.00153033
	LOSS [training: 0.2434559438839883 | validation: 0.2154507293070258]
	TIME [epoch: 72.3 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24531801792725916		[learning rate: 0.0015267]
	Learning Rate: 0.00152672
	LOSS [training: 0.24531801792725916 | validation: 0.21455402944888569]
	TIME [epoch: 72.3 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24717396980953707		[learning rate: 0.0015231]
	Learning Rate: 0.00152312
	LOSS [training: 0.24717396980953707 | validation: 0.2110185032587708]
	TIME [epoch: 72.3 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24466693824227626		[learning rate: 0.0015195]
	Learning Rate: 0.00151953
	LOSS [training: 0.24466693824227626 | validation: 0.22089765400165948]
	TIME [epoch: 72.3 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25311758570013015		[learning rate: 0.0015159]
	Learning Rate: 0.00151595
	LOSS [training: 0.25311758570013015 | validation: 0.221659535073295]
	TIME [epoch: 72.3 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2519906756510766		[learning rate: 0.0015124]
	Learning Rate: 0.00151237
	LOSS [training: 0.2519906756510766 | validation: 0.21750494926144892]
	TIME [epoch: 72.3 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24862930095958072		[learning rate: 0.0015088]
	Learning Rate: 0.0015088
	LOSS [training: 0.24862930095958072 | validation: 0.21377032587582073]
	TIME [epoch: 72.3 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2443310663410286		[learning rate: 0.0015052]
	Learning Rate: 0.00150524
	LOSS [training: 0.2443310663410286 | validation: 0.21400674548342608]
	TIME [epoch: 72.3 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24712448353516922		[learning rate: 0.0015017]
	Learning Rate: 0.00150169
	LOSS [training: 0.24712448353516922 | validation: 0.21267870000681288]
	TIME [epoch: 72.3 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24555142711593517		[learning rate: 0.0014982]
	Learning Rate: 0.00149815
	LOSS [training: 0.24555142711593517 | validation: 0.21225912881681247]
	TIME [epoch: 72.4 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24481752698344705		[learning rate: 0.0014946]
	Learning Rate: 0.00149462
	LOSS [training: 0.24481752698344705 | validation: 0.21031845784687184]
	TIME [epoch: 72.3 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2435136627017125		[learning rate: 0.0014911]
	Learning Rate: 0.00149109
	LOSS [training: 0.2435136627017125 | validation: 0.21532963494738294]
	TIME [epoch: 72.3 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2427986539127872		[learning rate: 0.0014876]
	Learning Rate: 0.00148757
	LOSS [training: 0.2427986539127872 | validation: 0.2079934183798559]
	TIME [epoch: 72.3 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2398984076078046		[learning rate: 0.0014841]
	Learning Rate: 0.00148407
	LOSS [training: 0.2398984076078046 | validation: 0.20623172166017664]
	TIME [epoch: 72.3 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24208679006931297		[learning rate: 0.0014806]
	Learning Rate: 0.00148056
	LOSS [training: 0.24208679006931297 | validation: 0.2029344119173606]
	TIME [epoch: 72.3 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.243347833447236		[learning rate: 0.0014771]
	Learning Rate: 0.00147707
	LOSS [training: 0.243347833447236 | validation: 0.20377633079704532]
	TIME [epoch: 72.3 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24125139023856215		[learning rate: 0.0014736]
	Learning Rate: 0.00147359
	LOSS [training: 0.24125139023856215 | validation: 0.20044054867431296]
	TIME [epoch: 72.3 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24238313896698324		[learning rate: 0.0014701]
	Learning Rate: 0.00147011
	LOSS [training: 0.24238313896698324 | validation: 0.2014967174339244]
	TIME [epoch: 72.4 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2427313393595555		[learning rate: 0.0014666]
	Learning Rate: 0.00146664
	LOSS [training: 0.2427313393595555 | validation: 0.2019158638827081]
	TIME [epoch: 72.3 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24333744015485115		[learning rate: 0.0014632]
	Learning Rate: 0.00146318
	LOSS [training: 0.24333744015485115 | validation: 0.19926267481539145]
	TIME [epoch: 72.3 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2443169010980899		[learning rate: 0.0014597]
	Learning Rate: 0.00145973
	LOSS [training: 0.2443169010980899 | validation: 0.20110625105902705]
	TIME [epoch: 72.3 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2431544235581559		[learning rate: 0.0014563]
	Learning Rate: 0.00145629
	LOSS [training: 0.2431544235581559 | validation: 0.2028968496770301]
	TIME [epoch: 72.3 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24121298948411551		[learning rate: 0.0014529]
	Learning Rate: 0.00145285
	LOSS [training: 0.24121298948411551 | validation: 0.20244494832045326]
	TIME [epoch: 72.3 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24175333143732725		[learning rate: 0.0014494]
	Learning Rate: 0.00144943
	LOSS [training: 0.24175333143732725 | validation: 0.20208264580722082]
	TIME [epoch: 72.3 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24439817855239096		[learning rate: 0.001446]
	Learning Rate: 0.00144601
	LOSS [training: 0.24439817855239096 | validation: 0.20317295714401107]
	TIME [epoch: 72.4 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2421458754991558		[learning rate: 0.0014426]
	Learning Rate: 0.0014426
	LOSS [training: 0.2421458754991558 | validation: 0.2028266802707473]
	TIME [epoch: 72.3 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2466572662790687		[learning rate: 0.0014392]
	Learning Rate: 0.0014392
	LOSS [training: 0.2466572662790687 | validation: 0.20912907388789428]
	TIME [epoch: 72.3 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25021950369003837		[learning rate: 0.0014358]
	Learning Rate: 0.0014358
	LOSS [training: 0.25021950369003837 | validation: 0.20219593511911288]
	TIME [epoch: 72.3 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24455142847937186		[learning rate: 0.0014324]
	Learning Rate: 0.00143241
	LOSS [training: 0.24455142847937186 | validation: 0.2029082398371455]
	TIME [epoch: 72.3 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2436052066462753		[learning rate: 0.001429]
	Learning Rate: 0.00142903
	LOSS [training: 0.2436052066462753 | validation: 0.20259309467594794]
	TIME [epoch: 72.3 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2432858849577387		[learning rate: 0.0014257]
	Learning Rate: 0.00142566
	LOSS [training: 0.2432858849577387 | validation: 0.20205015126281553]
	TIME [epoch: 72.4 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2427431226209856		[learning rate: 0.0014223]
	Learning Rate: 0.0014223
	LOSS [training: 0.2427431226209856 | validation: 0.20069094375121996]
	TIME [epoch: 72.3 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2453383523162943		[learning rate: 0.0014189]
	Learning Rate: 0.00141895
	LOSS [training: 0.2453383523162943 | validation: 0.2003120317718981]
	TIME [epoch: 72.3 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24189337515649115		[learning rate: 0.0014156]
	Learning Rate: 0.0014156
	LOSS [training: 0.24189337515649115 | validation: 0.20081581192694378]
	TIME [epoch: 72.4 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24242404872008583		[learning rate: 0.0014123]
	Learning Rate: 0.00141226
	LOSS [training: 0.24242404872008583 | validation: 0.2010326607165948]
	TIME [epoch: 72.3 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24535226221813047		[learning rate: 0.0014089]
	Learning Rate: 0.00140893
	LOSS [training: 0.24535226221813047 | validation: 0.2003961386548474]
	TIME [epoch: 72.3 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2448020291491332		[learning rate: 0.0014056]
	Learning Rate: 0.0014056
	LOSS [training: 0.2448020291491332 | validation: 0.20166827221347772]
	TIME [epoch: 72.3 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24613931140669124		[learning rate: 0.0014023]
	Learning Rate: 0.00140229
	LOSS [training: 0.24613931140669124 | validation: 0.20127487196367358]
	TIME [epoch: 72.4 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24457540888833207		[learning rate: 0.001399]
	Learning Rate: 0.00139898
	LOSS [training: 0.24457540888833207 | validation: 0.20182831341324606]
	TIME [epoch: 72.3 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2443166302029067		[learning rate: 0.0013957]
	Learning Rate: 0.00139568
	LOSS [training: 0.2443166302029067 | validation: 0.2033877637566921]
	TIME [epoch: 72.3 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24130398681597978		[learning rate: 0.0013924]
	Learning Rate: 0.00139239
	LOSS [training: 0.24130398681597978 | validation: 0.20521264872257117]
	TIME [epoch: 72.3 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24358360182390879		[learning rate: 0.0013891]
	Learning Rate: 0.0013891
	LOSS [training: 0.24358360182390879 | validation: 0.20446095451821583]
	TIME [epoch: 72.3 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24217895961798744		[learning rate: 0.0013858]
	Learning Rate: 0.00138583
	LOSS [training: 0.24217895961798744 | validation: 0.2033020613181104]
	TIME [epoch: 72.3 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2440474643936895		[learning rate: 0.0013826]
	Learning Rate: 0.00138256
	LOSS [training: 0.2440474643936895 | validation: 0.20432840431384797]
	TIME [epoch: 72.3 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2442228677374683		[learning rate: 0.0013793]
	Learning Rate: 0.0013793
	LOSS [training: 0.2442228677374683 | validation: 0.20780757655735646]
	TIME [epoch: 72.3 sec]
EPOCH 890/2000:
	Training over batches...
