Args:
Namespace(name='model_facs_v3_dec1b_2dpca_v15', outdir='out/model_training/model_facs_v3_dec1b_2dpca_v15', training_data='data/training_data/facs_v3/pca/dec1_fitonsubset/transition1_subset_epi_tr_ce_an_pc12/training', validation_data='data/training_data/facs_v3/pca/dec1_fitonsubset/transition1_subset_epi_tr_ce_an_pc12/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=10, batch_size=50, patience=200, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, quadratic_a=1.0, quadratic_b=1.0, ndims=2, nparams=2, nsigs=2, ncells=100, ncells_sample=100, model_do_sample=False, dt=0.005, dt_schedule='stepped', dt_schedule_bounds=[50, 500, 1000], dt_schedule_scales=[0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', kernel='multiscale', bw_range=[0.2, 0.5, 0.9, 1.1, 1.3, 1.5, 2.0], optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 3958960996

Training model...

Saving initial model state to: out/model_training/model_facs_v3_dec1b_2dpca_v15_20240716_142138/states/model_facs_v3_dec1b_2dpca_v15_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.467884347477286		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.467884347477286 | validation: 1.1148703035450733]
	TIME [epoch: 20.1 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15_20240716_142138/states/model_facs_v3_dec1b_2dpca_v15_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.2740274783936496		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2740274783936496 | validation: 1.0354951748325432]
	TIME [epoch: 5.12 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15_20240716_142138/states/model_facs_v3_dec1b_2dpca_v15_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.2072147801107638		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2072147801107638 | validation: 0.9838353634607243]
	TIME [epoch: 5.11 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15_20240716_142138/states/model_facs_v3_dec1b_2dpca_v15_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.204901785145141		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.204901785145141 | validation: 0.9907130301331977]
	TIME [epoch: 5.14 sec]
EPOCH 5/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.147085969179218		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.147085969179218 | validation: 1.015277591845289]
	TIME [epoch: 5.14 sec]
EPOCH 6/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.1665252515769857		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1665252515769857 | validation: 0.9298249281718913]
	TIME [epoch: 5.15 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15_20240716_142138/states/model_facs_v3_dec1b_2dpca_v15_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.0970692049809962		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0970692049809962 | validation: 0.9298311331340422]
	TIME [epoch: 5.13 sec]
EPOCH 8/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.0492804374916764		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0492804374916764 | validation: 0.9036023463335269]
	TIME [epoch: 5.12 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15_20240716_142138/states/model_facs_v3_dec1b_2dpca_v15_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.0240091691270352		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0240091691270352 | validation: 0.9013497697500906]
	TIME [epoch: 5.11 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15_20240716_142138/states/model_facs_v3_dec1b_2dpca_v15_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.9886816566193996		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9886816566193996 | validation: 0.8666739499021416]
	TIME [epoch: 5.11 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15_20240716_142138/states/model_facs_v3_dec1b_2dpca_v15_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.0095119701535265		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0095119701535265 | validation: 0.8657797750717429]
	TIME [epoch: 5.11 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15_20240716_142138/states/model_facs_v3_dec1b_2dpca_v15_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.8746227271722341		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8746227271722341 | validation: 0.7872559845766842]
	TIME [epoch: 5.13 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15_20240716_142138/states/model_facs_v3_dec1b_2dpca_v15_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.8125890468965581		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8125890468965581 | validation: 0.7540548367417902]
	TIME [epoch: 5.14 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15_20240716_142138/states/model_facs_v3_dec1b_2dpca_v15_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.7650823229013425		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7650823229013425 | validation: 0.6220973374760769]
	TIME [epoch: 5.12 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15_20240716_142138/states/model_facs_v3_dec1b_2dpca_v15_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.6245994413179142		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6245994413179142 | validation: 0.7072119731814515]
	TIME [epoch: 5.09 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.6522981470216246		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6522981470216246 | validation: 0.48792387656686903]
	TIME [epoch: 5.14 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15_20240716_142138/states/model_facs_v3_dec1b_2dpca_v15_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5835477116661452		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5835477116661452 | validation: 0.4572296661095411]
	TIME [epoch: 5.13 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15_20240716_142138/states/model_facs_v3_dec1b_2dpca_v15_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5226979157855326		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5226979157855326 | validation: 0.4511390437916954]
	TIME [epoch: 5.13 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15_20240716_142138/states/model_facs_v3_dec1b_2dpca_v15_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.6169518969155509		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6169518969155509 | validation: 0.46796160731405834]
	TIME [epoch: 5.14 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5050469741822058		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5050469741822058 | validation: 0.38193618197872636]
	TIME [epoch: 5.15 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15_20240716_142138/states/model_facs_v3_dec1b_2dpca_v15_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.43107457387590914		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.43107457387590914 | validation: 0.3774383592260981]
	TIME [epoch: 5.1 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15_20240716_142138/states/model_facs_v3_dec1b_2dpca_v15_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.42884328770339875		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.42884328770339875 | validation: 0.38125708121728846]
	TIME [epoch: 5.11 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4525579644890112		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4525579644890112 | validation: 0.32388174672299586]
	TIME [epoch: 5.1 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15_20240716_142138/states/model_facs_v3_dec1b_2dpca_v15_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3960667594454834		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3960667594454834 | validation: 0.37706644591824434]
	TIME [epoch: 5.12 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4292758733921143		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4292758733921143 | validation: 0.3214158515524935]
	TIME [epoch: 5.12 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15_20240716_142138/states/model_facs_v3_dec1b_2dpca_v15_25.pth
	Model improved!!!
EPOCH 26/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.38396440671593274		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.38396440671593274 | validation: 0.307788329750529]
	TIME [epoch: 5.13 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15_20240716_142138/states/model_facs_v3_dec1b_2dpca_v15_26.pth
	Model improved!!!
EPOCH 27/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3643610925652356		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3643610925652356 | validation: 0.3015802292139023]
	TIME [epoch: 5.15 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15_20240716_142138/states/model_facs_v3_dec1b_2dpca_v15_27.pth
	Model improved!!!
EPOCH 28/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.38954735711446414		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.38954735711446414 | validation: 0.42019433563177244]
	TIME [epoch: 5.12 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3986148257224176		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3986148257224176 | validation: 0.29701238402371305]
	TIME [epoch: 5.13 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15_20240716_142138/states/model_facs_v3_dec1b_2dpca_v15_29.pth
	Model improved!!!
EPOCH 30/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3525923047308614		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3525923047308614 | validation: 0.3148302853630242]
	TIME [epoch: 5.13 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.35576978538780174		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.35576978538780174 | validation: 0.3166610543445077]
	TIME [epoch: 5.13 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3674709968001831		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3674709968001831 | validation: 0.26537192104964424]
	TIME [epoch: 5.13 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15_20240716_142138/states/model_facs_v3_dec1b_2dpca_v15_32.pth
	Model improved!!!
EPOCH 33/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.320814450650681		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.320814450650681 | validation: 0.30004331359954967]
	TIME [epoch: 5.15 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.36630931301738884		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.36630931301738884 | validation: 0.26831324028582026]
	TIME [epoch: 5.17 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3473597270603089		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3473597270603089 | validation: 0.26110179078623236]
	TIME [epoch: 5.17 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15_20240716_142138/states/model_facs_v3_dec1b_2dpca_v15_35.pth
	Model improved!!!
EPOCH 36/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3389334035021274		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3389334035021274 | validation: 0.2752007941456308]
	TIME [epoch: 5.12 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.32624078296882436		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.32624078296882436 | validation: 0.30837158482417426]
	TIME [epoch: 5.13 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3241368858152154		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3241368858152154 | validation: 0.2824820388817583]
	TIME [epoch: 5.12 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3123237724695231		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3123237724695231 | validation: 0.2622205257016466]
	TIME [epoch: 5.12 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3778153780363853		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3778153780363853 | validation: 0.2589636104859908]
	TIME [epoch: 5.12 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15_20240716_142138/states/model_facs_v3_dec1b_2dpca_v15_40.pth
	Model improved!!!
EPOCH 41/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.33045932834478603		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.33045932834478603 | validation: 0.2941462251999883]
	TIME [epoch: 5.12 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.332906700734391		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.332906700734391 | validation: 0.23865087049744388]
	TIME [epoch: 5.16 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15_20240716_142138/states/model_facs_v3_dec1b_2dpca_v15_42.pth
	Model improved!!!
EPOCH 43/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28822600818624666		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.28822600818624666 | validation: 0.290091972593154]
	TIME [epoch: 5.1 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3150369795013351		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3150369795013351 | validation: 0.26039151222080636]
	TIME [epoch: 5.11 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.31226345980350834		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.31226345980350834 | validation: 0.2495124020353058]
	TIME [epoch: 5.1 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.32158620402228444		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.32158620402228444 | validation: 0.2836857146071097]
	TIME [epoch: 5.16 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3208914980453582		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3208914980453582 | validation: 0.2597197094209485]
	TIME [epoch: 5.1 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.30106200716154874		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.30106200716154874 | validation: 0.26943324292408344]
	TIME [epoch: 5.11 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3207213848867944		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3207213848867944 | validation: 0.2871067395915792]
	TIME [epoch: 5.13 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.317407543181137		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.317407543181137 | validation: 0.25162395813710586]
	TIME [epoch: 5.16 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29758760036272464		[learning rate: 0.0099705]
	Learning Rate: 0.00997052
	LOSS [training: 0.29758760036272464 | validation: 0.26518312529575716]
	TIME [epoch: 22.3 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29748287745069385		[learning rate: 0.0099353]
	Learning Rate: 0.00993527
	LOSS [training: 0.29748287745069385 | validation: 0.2666332743495152]
	TIME [epoch: 9.8 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3078954463283869		[learning rate: 0.0099001]
	Learning Rate: 0.00990013
	LOSS [training: 0.3078954463283869 | validation: 0.2650811659045445]
	TIME [epoch: 9.8 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3109228775053772		[learning rate: 0.0098651]
	Learning Rate: 0.00986512
	LOSS [training: 0.3109228775053772 | validation: 0.2389735257999414]
	TIME [epoch: 9.8 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3082160767166193		[learning rate: 0.0098302]
	Learning Rate: 0.00983024
	LOSS [training: 0.3082160767166193 | validation: 0.2352018411624866]
	TIME [epoch: 9.79 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15_20240716_142138/states/model_facs_v3_dec1b_2dpca_v15_55.pth
	Model improved!!!
EPOCH 56/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.300714676481542		[learning rate: 0.0097955]
	Learning Rate: 0.00979548
	LOSS [training: 0.300714676481542 | validation: 0.2547256415885463]
	TIME [epoch: 9.8 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3008168542350147		[learning rate: 0.0097608]
	Learning Rate: 0.00976084
	LOSS [training: 0.3008168542350147 | validation: 0.23655349373660672]
	TIME [epoch: 9.81 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.30620791300361233		[learning rate: 0.0097263]
	Learning Rate: 0.00972632
	LOSS [training: 0.30620791300361233 | validation: 0.2297072863585715]
	TIME [epoch: 9.8 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15_20240716_142138/states/model_facs_v3_dec1b_2dpca_v15_58.pth
	Model improved!!!
EPOCH 59/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29509239680049704		[learning rate: 0.0096919]
	Learning Rate: 0.00969193
	LOSS [training: 0.29509239680049704 | validation: 0.25107244925986105]
	TIME [epoch: 9.79 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.31304317372172613		[learning rate: 0.0096577]
	Learning Rate: 0.00965766
	LOSS [training: 0.31304317372172613 | validation: 0.23511631298695823]
	TIME [epoch: 9.79 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28449863495965294		[learning rate: 0.0096235]
	Learning Rate: 0.00962351
	LOSS [training: 0.28449863495965294 | validation: 0.22800802328757577]
	TIME [epoch: 9.79 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15_20240716_142138/states/model_facs_v3_dec1b_2dpca_v15_61.pth
	Model improved!!!
EPOCH 62/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2773544476453626		[learning rate: 0.0095895]
	Learning Rate: 0.00958948
	LOSS [training: 0.2773544476453626 | validation: 0.23513584501130308]
	TIME [epoch: 9.8 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.300629903031575		[learning rate: 0.0095556]
	Learning Rate: 0.00955557
	LOSS [training: 0.300629903031575 | validation: 0.22409015197033014]
	TIME [epoch: 9.81 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15_20240716_142138/states/model_facs_v3_dec1b_2dpca_v15_63.pth
	Model improved!!!
EPOCH 64/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27773370621136056		[learning rate: 0.0095218]
	Learning Rate: 0.00952177
	LOSS [training: 0.27773370621136056 | validation: 0.25649142703944183]
	TIME [epoch: 9.82 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29649412458586427		[learning rate: 0.0094881]
	Learning Rate: 0.0094881
	LOSS [training: 0.29649412458586427 | validation: 0.22037644140817111]
	TIME [epoch: 9.83 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15_20240716_142138/states/model_facs_v3_dec1b_2dpca_v15_65.pth
	Model improved!!!
EPOCH 66/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3068437324785559		[learning rate: 0.0094546]
	Learning Rate: 0.00945455
	LOSS [training: 0.3068437324785559 | validation: 0.24960458072103192]
	TIME [epoch: 9.81 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28224157230836594		[learning rate: 0.0094211]
	Learning Rate: 0.00942112
	LOSS [training: 0.28224157230836594 | validation: 0.23932892540536183]
	TIME [epoch: 9.77 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29000517834457923		[learning rate: 0.0093878]
	Learning Rate: 0.00938781
	LOSS [training: 0.29000517834457923 | validation: 0.23488771062035602]
	TIME [epoch: 9.81 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.30875236607359596		[learning rate: 0.0093546]
	Learning Rate: 0.00935461
	LOSS [training: 0.30875236607359596 | validation: 0.23369539973947853]
	TIME [epoch: 9.8 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2883161833723182		[learning rate: 0.0093215]
	Learning Rate: 0.00932153
	LOSS [training: 0.2883161833723182 | validation: 0.23967566786968525]
	TIME [epoch: 9.81 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28690640902682646		[learning rate: 0.0092886]
	Learning Rate: 0.00928857
	LOSS [training: 0.28690640902682646 | validation: 0.270667574788768]
	TIME [epoch: 9.79 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2797907327260698		[learning rate: 0.0092557]
	Learning Rate: 0.00925572
	LOSS [training: 0.2797907327260698 | validation: 0.24607247303841723]
	TIME [epoch: 9.81 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2848157049957407		[learning rate: 0.009223]
	Learning Rate: 0.00922299
	LOSS [training: 0.2848157049957407 | validation: 0.23403621880234451]
	TIME [epoch: 9.81 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2721949192909983		[learning rate: 0.0091904]
	Learning Rate: 0.00919038
	LOSS [training: 0.2721949192909983 | validation: 0.23939107237655408]
	TIME [epoch: 9.81 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.30678020958389585		[learning rate: 0.0091579]
	Learning Rate: 0.00915788
	LOSS [training: 0.30678020958389585 | validation: 0.28458079038050366]
	TIME [epoch: 9.78 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2963966049260947		[learning rate: 0.0091255]
	Learning Rate: 0.00912549
	LOSS [training: 0.2963966049260947 | validation: 0.23412446654245667]
	TIME [epoch: 9.78 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2791674512555957		[learning rate: 0.0090932]
	Learning Rate: 0.00909323
	LOSS [training: 0.2791674512555957 | validation: 0.22197323235146368]
	TIME [epoch: 9.77 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28744350199919744		[learning rate: 0.0090611]
	Learning Rate: 0.00906107
	LOSS [training: 0.28744350199919744 | validation: 0.24632970532756332]
	TIME [epoch: 9.77 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.278243920554247		[learning rate: 0.009029]
	Learning Rate: 0.00902903
	LOSS [training: 0.278243920554247 | validation: 0.2207866516789284]
	TIME [epoch: 9.78 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26659037320002876		[learning rate: 0.0089971]
	Learning Rate: 0.0089971
	LOSS [training: 0.26659037320002876 | validation: 0.22777364120068447]
	TIME [epoch: 9.77 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2822166505397306		[learning rate: 0.0089653]
	Learning Rate: 0.00896528
	LOSS [training: 0.2822166505397306 | validation: 0.2376558954545594]
	TIME [epoch: 9.71 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.279355659120007		[learning rate: 0.0089336]
	Learning Rate: 0.00893358
	LOSS [training: 0.279355659120007 | validation: 0.21817082757207112]
	TIME [epoch: 9.78 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15_20240716_142138/states/model_facs_v3_dec1b_2dpca_v15_82.pth
	Model improved!!!
EPOCH 83/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27239339975439464		[learning rate: 0.008902]
	Learning Rate: 0.00890199
	LOSS [training: 0.27239339975439464 | validation: 0.20706900331025407]
	TIME [epoch: 9.77 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15_20240716_142138/states/model_facs_v3_dec1b_2dpca_v15_83.pth
	Model improved!!!
EPOCH 84/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2852148839442429		[learning rate: 0.0088705]
	Learning Rate: 0.00887051
	LOSS [training: 0.2852148839442429 | validation: 0.25479721576918746]
	TIME [epoch: 9.77 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2851458688017439		[learning rate: 0.0088391]
	Learning Rate: 0.00883914
	LOSS [training: 0.2851458688017439 | validation: 0.21799748836727714]
	TIME [epoch: 9.79 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.30891826466564143		[learning rate: 0.0088079]
	Learning Rate: 0.00880789
	LOSS [training: 0.30891826466564143 | validation: 0.22052700751798424]
	TIME [epoch: 9.79 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26591216507188564		[learning rate: 0.0087767]
	Learning Rate: 0.00877674
	LOSS [training: 0.26591216507188564 | validation: 0.23035555507220157]
	TIME [epoch: 9.78 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29160534371287067		[learning rate: 0.0087457]
	Learning Rate: 0.00874571
	LOSS [training: 0.29160534371287067 | validation: 0.2523724107439072]
	TIME [epoch: 9.77 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28935336685223123		[learning rate: 0.0087148]
	Learning Rate: 0.00871478
	LOSS [training: 0.28935336685223123 | validation: 0.2654440888680945]
	TIME [epoch: 9.75 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2908246809217784		[learning rate: 0.008684]
	Learning Rate: 0.00868396
	LOSS [training: 0.2908246809217784 | validation: 0.230937716376651]
	TIME [epoch: 9.79 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2699092016048457		[learning rate: 0.0086533]
	Learning Rate: 0.00865326
	LOSS [training: 0.2699092016048457 | validation: 0.23515399895315578]
	TIME [epoch: 9.8 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28201092665083677		[learning rate: 0.0086227]
	Learning Rate: 0.00862265
	LOSS [training: 0.28201092665083677 | validation: 0.23193232984359988]
	TIME [epoch: 9.79 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29275091419093685		[learning rate: 0.0085922]
	Learning Rate: 0.00859216
	LOSS [training: 0.29275091419093685 | validation: 0.22858674183256378]
	TIME [epoch: 9.82 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27742607056827645		[learning rate: 0.0085618]
	Learning Rate: 0.00856178
	LOSS [training: 0.27742607056827645 | validation: 0.22662105016070505]
	TIME [epoch: 9.82 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26992888422489475		[learning rate: 0.0085315]
	Learning Rate: 0.0085315
	LOSS [training: 0.26992888422489475 | validation: 0.22324327172949854]
	TIME [epoch: 9.82 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2787940525820384		[learning rate: 0.0085013]
	Learning Rate: 0.00850134
	LOSS [training: 0.2787940525820384 | validation: 0.2270689003505717]
	TIME [epoch: 9.79 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.272555935622591		[learning rate: 0.0084713]
	Learning Rate: 0.00847127
	LOSS [training: 0.272555935622591 | validation: 0.21533798574735358]
	TIME [epoch: 9.83 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2861184563294354		[learning rate: 0.0084413]
	Learning Rate: 0.00844132
	LOSS [training: 0.2861184563294354 | validation: 0.25671930420297345]
	TIME [epoch: 9.74 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2770388488335421		[learning rate: 0.0084115]
	Learning Rate: 0.00841147
	LOSS [training: 0.2770388488335421 | validation: 0.22570970436179988]
	TIME [epoch: 9.81 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2722883396921038		[learning rate: 0.0083817]
	Learning Rate: 0.00838172
	LOSS [training: 0.2722883396921038 | validation: 0.20998195477807866]
	TIME [epoch: 9.81 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2801603005803334		[learning rate: 0.0083521]
	Learning Rate: 0.00835208
	LOSS [training: 0.2801603005803334 | validation: 0.2285830233865636]
	TIME [epoch: 9.77 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27862836871855373		[learning rate: 0.0083225]
	Learning Rate: 0.00832255
	LOSS [training: 0.27862836871855373 | validation: 0.23122290736224724]
	TIME [epoch: 9.78 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2604370556972807		[learning rate: 0.0082931]
	Learning Rate: 0.00829312
	LOSS [training: 0.2604370556972807 | validation: 0.2454247471730538]
	TIME [epoch: 9.83 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25709730989241997		[learning rate: 0.0082638]
	Learning Rate: 0.00826379
	LOSS [training: 0.25709730989241997 | validation: 0.20740471897716456]
	TIME [epoch: 9.78 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28814366161212596		[learning rate: 0.0082346]
	Learning Rate: 0.00823457
	LOSS [training: 0.28814366161212596 | validation: 0.2294581434261697]
	TIME [epoch: 9.81 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2697272204743204		[learning rate: 0.0082055]
	Learning Rate: 0.00820545
	LOSS [training: 0.2697272204743204 | validation: 0.22289068100708637]
	TIME [epoch: 9.78 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26477312217117677		[learning rate: 0.0081764]
	Learning Rate: 0.00817644
	LOSS [training: 0.26477312217117677 | validation: 0.22756103807374223]
	TIME [epoch: 9.79 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2672743871152707		[learning rate: 0.0081475]
	Learning Rate: 0.00814752
	LOSS [training: 0.2672743871152707 | validation: 0.22676970825796755]
	TIME [epoch: 9.79 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2698282374695416		[learning rate: 0.0081187]
	Learning Rate: 0.00811871
	LOSS [training: 0.2698282374695416 | validation: 0.2335358089759195]
	TIME [epoch: 9.81 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28288746252032		[learning rate: 0.00809]
	Learning Rate: 0.00809
	LOSS [training: 0.28288746252032 | validation: 0.218741407422598]
	TIME [epoch: 9.79 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2740664456643373		[learning rate: 0.0080614]
	Learning Rate: 0.0080614
	LOSS [training: 0.2740664456643373 | validation: 0.21463405440858052]
	TIME [epoch: 9.81 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27070765068696645		[learning rate: 0.0080329]
	Learning Rate: 0.00803289
	LOSS [training: 0.27070765068696645 | validation: 0.21596522145664682]
	TIME [epoch: 9.82 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.264294775844732		[learning rate: 0.0080045]
	Learning Rate: 0.00800448
	LOSS [training: 0.264294775844732 | validation: 0.22077506098895236]
	TIME [epoch: 9.81 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2733214197245588		[learning rate: 0.0079762]
	Learning Rate: 0.00797618
	LOSS [training: 0.2733214197245588 | validation: 0.23695648037687275]
	TIME [epoch: 9.77 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2852260649013139		[learning rate: 0.007948]
	Learning Rate: 0.00794797
	LOSS [training: 0.2852260649013139 | validation: 0.2072120857419344]
	TIME [epoch: 9.79 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2661896562178776		[learning rate: 0.0079199]
	Learning Rate: 0.00791987
	LOSS [training: 0.2661896562178776 | validation: 0.2100627133857389]
	TIME [epoch: 9.83 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2718980656240539		[learning rate: 0.0078919]
	Learning Rate: 0.00789186
	LOSS [training: 0.2718980656240539 | validation: 0.22318771567057497]
	TIME [epoch: 9.77 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2677288180137304		[learning rate: 0.007864]
	Learning Rate: 0.00786395
	LOSS [training: 0.2677288180137304 | validation: 0.23078052774912766]
	TIME [epoch: 9.75 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2534306763089124		[learning rate: 0.0078361]
	Learning Rate: 0.00783615
	LOSS [training: 0.2534306763089124 | validation: 0.2101614404048268]
	TIME [epoch: 9.82 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2605001441692539		[learning rate: 0.0078084]
	Learning Rate: 0.00780844
	LOSS [training: 0.2605001441692539 | validation: 0.25403096837741723]
	TIME [epoch: 9.8 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.30567724424696446		[learning rate: 0.0077808]
	Learning Rate: 0.00778083
	LOSS [training: 0.30567724424696446 | validation: 0.22243025115289497]
	TIME [epoch: 9.81 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25353561356373994		[learning rate: 0.0077533]
	Learning Rate: 0.00775331
	LOSS [training: 0.25353561356373994 | validation: 0.21377797395508122]
	TIME [epoch: 9.8 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2638333985482931		[learning rate: 0.0077259]
	Learning Rate: 0.00772589
	LOSS [training: 0.2638333985482931 | validation: 0.26496886741008757]
	TIME [epoch: 9.82 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28643264711597965		[learning rate: 0.0076986]
	Learning Rate: 0.00769857
	LOSS [training: 0.28643264711597965 | validation: 0.2178992810065595]
	TIME [epoch: 9.81 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27337239132172303		[learning rate: 0.0076714]
	Learning Rate: 0.00767135
	LOSS [training: 0.27337239132172303 | validation: 0.22541513024519383]
	TIME [epoch: 9.8 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2735444169995265		[learning rate: 0.0076442]
	Learning Rate: 0.00764422
	LOSS [training: 0.2735444169995265 | validation: 0.22296033039823127]
	TIME [epoch: 9.78 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2767630852049017		[learning rate: 0.0076172]
	Learning Rate: 0.00761719
	LOSS [training: 0.2767630852049017 | validation: 0.21976720393630514]
	TIME [epoch: 9.81 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2632420088974878		[learning rate: 0.0075903]
	Learning Rate: 0.00759025
	LOSS [training: 0.2632420088974878 | validation: 0.22445169561947095]
	TIME [epoch: 9.81 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28400153109364507		[learning rate: 0.0075634]
	Learning Rate: 0.00756341
	LOSS [training: 0.28400153109364507 | validation: 0.21765506207980687]
	TIME [epoch: 9.8 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28045940288428917		[learning rate: 0.0075367]
	Learning Rate: 0.00753667
	LOSS [training: 0.28045940288428917 | validation: 0.22784121635989502]
	TIME [epoch: 9.81 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2692307627047062		[learning rate: 0.00751]
	Learning Rate: 0.00751002
	LOSS [training: 0.2692307627047062 | validation: 0.21652612390683562]
	TIME [epoch: 9.79 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26534722334977373		[learning rate: 0.0074835]
	Learning Rate: 0.00748346
	LOSS [training: 0.26534722334977373 | validation: 0.20076364459428436]
	TIME [epoch: 9.84 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15_20240716_142138/states/model_facs_v3_dec1b_2dpca_v15_132.pth
	Model improved!!!
EPOCH 133/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26638893976427075		[learning rate: 0.007457]
	Learning Rate: 0.007457
	LOSS [training: 0.26638893976427075 | validation: 0.23232120696858]
	TIME [epoch: 9.78 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2632022637107729		[learning rate: 0.0074306]
	Learning Rate: 0.00743063
	LOSS [training: 0.2632022637107729 | validation: 0.21327735190450187]
	TIME [epoch: 9.81 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26465183186304747		[learning rate: 0.0074044]
	Learning Rate: 0.00740435
	LOSS [training: 0.26465183186304747 | validation: 0.22369340032546486]
	TIME [epoch: 9.81 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.261380189430703		[learning rate: 0.0073782]
	Learning Rate: 0.00737817
	LOSS [training: 0.261380189430703 | validation: 0.22168099012758224]
	TIME [epoch: 9.82 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2829463268936094		[learning rate: 0.0073521]
	Learning Rate: 0.00735208
	LOSS [training: 0.2829463268936094 | validation: 0.2128688314480776]
	TIME [epoch: 9.78 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2677740993784305		[learning rate: 0.0073261]
	Learning Rate: 0.00732608
	LOSS [training: 0.2677740993784305 | validation: 0.22154404247480447]
	TIME [epoch: 9.81 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26788801388069916		[learning rate: 0.0073002]
	Learning Rate: 0.00730018
	LOSS [training: 0.26788801388069916 | validation: 0.22341617635177288]
	TIME [epoch: 9.8 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2867811193342789		[learning rate: 0.0072744]
	Learning Rate: 0.00727436
	LOSS [training: 0.2867811193342789 | validation: 0.21234068382951904]
	TIME [epoch: 9.82 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2667651200561248		[learning rate: 0.0072486]
	Learning Rate: 0.00724864
	LOSS [training: 0.2667651200561248 | validation: 0.22286186586764217]
	TIME [epoch: 9.81 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.249371263953754		[learning rate: 0.007223]
	Learning Rate: 0.007223
	LOSS [training: 0.249371263953754 | validation: 0.2220020618443947]
	TIME [epoch: 9.78 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2890426986805718		[learning rate: 0.0071975]
	Learning Rate: 0.00719746
	LOSS [training: 0.2890426986805718 | validation: 0.21400111590486648]
	TIME [epoch: 9.8 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2538390637075692		[learning rate: 0.007172]
	Learning Rate: 0.00717201
	LOSS [training: 0.2538390637075692 | validation: 0.20731290871112154]
	TIME [epoch: 9.8 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2605741901831619		[learning rate: 0.0071467]
	Learning Rate: 0.00714665
	LOSS [training: 0.2605741901831619 | validation: 0.20335601379804852]
	TIME [epoch: 9.8 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26618801333987885		[learning rate: 0.0071214]
	Learning Rate: 0.00712138
	LOSS [training: 0.26618801333987885 | validation: 0.2173107282573326]
	TIME [epoch: 9.83 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24825814666656823		[learning rate: 0.0070962]
	Learning Rate: 0.0070962
	LOSS [training: 0.24825814666656823 | validation: 0.21667665777403725]
	TIME [epoch: 9.79 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2673443845366446		[learning rate: 0.0070711]
	Learning Rate: 0.0070711
	LOSS [training: 0.2673443845366446 | validation: 0.22237846759265772]
	TIME [epoch: 9.81 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28047149997246373		[learning rate: 0.0070461]
	Learning Rate: 0.0070461
	LOSS [training: 0.28047149997246373 | validation: 0.22167882595063468]
	TIME [epoch: 9.8 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25405421304668413		[learning rate: 0.0070212]
	Learning Rate: 0.00702118
	LOSS [training: 0.25405421304668413 | validation: 0.21652991041323172]
	TIME [epoch: 9.78 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2493206689670953		[learning rate: 0.0069964]
	Learning Rate: 0.00699635
	LOSS [training: 0.2493206689670953 | validation: 0.21136202221208453]
	TIME [epoch: 9.81 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2599876241165698		[learning rate: 0.0069716]
	Learning Rate: 0.00697161
	LOSS [training: 0.2599876241165698 | validation: 0.22975588787491175]
	TIME [epoch: 9.79 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2634754905951869		[learning rate: 0.006947]
	Learning Rate: 0.00694696
	LOSS [training: 0.2634754905951869 | validation: 0.21777646798171305]
	TIME [epoch: 9.81 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2630446432469017		[learning rate: 0.0069224]
	Learning Rate: 0.00692239
	LOSS [training: 0.2630446432469017 | validation: 0.21125919254846054]
	TIME [epoch: 9.8 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2630436380134701		[learning rate: 0.0068979]
	Learning Rate: 0.00689792
	LOSS [training: 0.2630436380134701 | validation: 0.23151027769511226]
	TIME [epoch: 9.79 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2665112195547165		[learning rate: 0.0068735]
	Learning Rate: 0.00687352
	LOSS [training: 0.2665112195547165 | validation: 0.21365381177877615]
	TIME [epoch: 9.79 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25947567341650773		[learning rate: 0.0068492]
	Learning Rate: 0.00684922
	LOSS [training: 0.25947567341650773 | validation: 0.2132076682927932]
	TIME [epoch: 9.82 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2624910897128481		[learning rate: 0.006825]
	Learning Rate: 0.006825
	LOSS [training: 0.2624910897128481 | validation: 0.2210943728238804]
	TIME [epoch: 9.79 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2585055688962559		[learning rate: 0.0068009]
	Learning Rate: 0.00680086
	LOSS [training: 0.2585055688962559 | validation: 0.22025428469757619]
	TIME [epoch: 9.81 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27657349494726285		[learning rate: 0.0067768]
	Learning Rate: 0.00677681
	LOSS [training: 0.27657349494726285 | validation: 0.21803969169814758]
	TIME [epoch: 9.79 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2588507943037126		[learning rate: 0.0067529]
	Learning Rate: 0.00675285
	LOSS [training: 0.2588507943037126 | validation: 0.2124368495113468]
	TIME [epoch: 9.8 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2875525459089162		[learning rate: 0.006729]
	Learning Rate: 0.00672897
	LOSS [training: 0.2875525459089162 | validation: 0.2149301068926174]
	TIME [epoch: 9.8 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2562354337041631		[learning rate: 0.0067052]
	Learning Rate: 0.00670518
	LOSS [training: 0.2562354337041631 | validation: 0.2010654724880378]
	TIME [epoch: 9.82 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26222774160505996		[learning rate: 0.0066815]
	Learning Rate: 0.00668147
	LOSS [training: 0.26222774160505996 | validation: 0.22167218162854585]
	TIME [epoch: 9.83 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2616717407389773		[learning rate: 0.0066578]
	Learning Rate: 0.00665784
	LOSS [training: 0.2616717407389773 | validation: 0.21033116158829418]
	TIME [epoch: 9.82 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25167785803723125		[learning rate: 0.0066343]
	Learning Rate: 0.0066343
	LOSS [training: 0.25167785803723125 | validation: 0.20281070087654332]
	TIME [epoch: 9.82 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.259427719825445		[learning rate: 0.0066108]
	Learning Rate: 0.00661084
	LOSS [training: 0.259427719825445 | validation: 0.20164791813596167]
	TIME [epoch: 9.81 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27334182928453243		[learning rate: 0.0065875]
	Learning Rate: 0.00658746
	LOSS [training: 0.27334182928453243 | validation: 0.2102538946865254]
	TIME [epoch: 9.81 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27109894393806816		[learning rate: 0.0065642]
	Learning Rate: 0.00656416
	LOSS [training: 0.27109894393806816 | validation: 0.2240490397761755]
	TIME [epoch: 9.81 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25588425680800847		[learning rate: 0.006541]
	Learning Rate: 0.00654095
	LOSS [training: 0.25588425680800847 | validation: 0.21082638975356627]
	TIME [epoch: 9.81 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2627341418227778		[learning rate: 0.0065178]
	Learning Rate: 0.00651782
	LOSS [training: 0.2627341418227778 | validation: 0.2421951305329948]
	TIME [epoch: 9.8 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2732062195037184		[learning rate: 0.0064948]
	Learning Rate: 0.00649477
	LOSS [training: 0.2732062195037184 | validation: 0.23033737900242537]
	TIME [epoch: 9.81 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2575990460836597		[learning rate: 0.0064718]
	Learning Rate: 0.00647181
	LOSS [training: 0.2575990460836597 | validation: 0.21793258800622226]
	TIME [epoch: 9.83 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25155945375293126		[learning rate: 0.0064489]
	Learning Rate: 0.00644892
	LOSS [training: 0.25155945375293126 | validation: 0.21625338784663875]
	TIME [epoch: 9.82 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2709207124306879		[learning rate: 0.0064261]
	Learning Rate: 0.00642612
	LOSS [training: 0.2709207124306879 | validation: 0.22281363593587358]
	TIME [epoch: 9.8 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28824005740704256		[learning rate: 0.0064034]
	Learning Rate: 0.00640339
	LOSS [training: 0.28824005740704256 | validation: 0.20742665882385508]
	TIME [epoch: 9.81 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24908568306912096		[learning rate: 0.0063808]
	Learning Rate: 0.00638075
	LOSS [training: 0.24908568306912096 | validation: 0.2211591401904592]
	TIME [epoch: 9.81 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26287447320734403		[learning rate: 0.0063582]
	Learning Rate: 0.00635819
	LOSS [training: 0.26287447320734403 | validation: 0.21792548193554223]
	TIME [epoch: 9.81 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.255617375975225		[learning rate: 0.0063357]
	Learning Rate: 0.0063357
	LOSS [training: 0.255617375975225 | validation: 0.21631315011797417]
	TIME [epoch: 9.79 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25590414759380337		[learning rate: 0.0063133]
	Learning Rate: 0.0063133
	LOSS [training: 0.25590414759380337 | validation: 0.22190580481065933]
	TIME [epoch: 9.81 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2571513811769232		[learning rate: 0.006291]
	Learning Rate: 0.00629097
	LOSS [training: 0.2571513811769232 | validation: 0.20226205214996446]
	TIME [epoch: 9.8 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24417070429255724		[learning rate: 0.0062687]
	Learning Rate: 0.00626873
	LOSS [training: 0.24417070429255724 | validation: 0.21775556861070347]
	TIME [epoch: 9.84 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2610827043642342		[learning rate: 0.0062466]
	Learning Rate: 0.00624656
	LOSS [training: 0.2610827043642342 | validation: 0.23106769625721357]
	TIME [epoch: 9.83 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2688462448285753		[learning rate: 0.0062245]
	Learning Rate: 0.00622447
	LOSS [training: 0.2688462448285753 | validation: 0.22495592050447763]
	TIME [epoch: 9.81 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27827689286689683		[learning rate: 0.0062025]
	Learning Rate: 0.00620246
	LOSS [training: 0.27827689286689683 | validation: 0.21416746333544262]
	TIME [epoch: 9.82 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2644241791221658		[learning rate: 0.0061805]
	Learning Rate: 0.00618053
	LOSS [training: 0.2644241791221658 | validation: 0.2130820004204061]
	TIME [epoch: 9.82 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26423346466756953		[learning rate: 0.0061587]
	Learning Rate: 0.00615867
	LOSS [training: 0.26423346466756953 | validation: 0.22596504073197315]
	TIME [epoch: 9.82 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25707529367735144		[learning rate: 0.0061369]
	Learning Rate: 0.00613689
	LOSS [training: 0.25707529367735144 | validation: 0.2295273864694015]
	TIME [epoch: 9.81 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2644042687189492		[learning rate: 0.0061152]
	Learning Rate: 0.00611519
	LOSS [training: 0.2644042687189492 | validation: 0.22052919085634595]
	TIME [epoch: 9.82 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27094028344796994		[learning rate: 0.0060936]
	Learning Rate: 0.00609357
	LOSS [training: 0.27094028344796994 | validation: 0.2232980339294291]
	TIME [epoch: 9.82 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2643304422051293		[learning rate: 0.006072]
	Learning Rate: 0.00607202
	LOSS [training: 0.2643304422051293 | validation: 0.22425259395674754]
	TIME [epoch: 9.81 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.276789370821991		[learning rate: 0.0060505]
	Learning Rate: 0.00605055
	LOSS [training: 0.276789370821991 | validation: 0.2238567195014914]
	TIME [epoch: 9.8 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25452779244926016		[learning rate: 0.0060292]
	Learning Rate: 0.00602915
	LOSS [training: 0.25452779244926016 | validation: 0.21976987969263018]
	TIME [epoch: 9.8 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2521409833719344		[learning rate: 0.0060078]
	Learning Rate: 0.00600783
	LOSS [training: 0.2521409833719344 | validation: 0.2101290703118215]
	TIME [epoch: 9.81 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2705979138903957		[learning rate: 0.0059866]
	Learning Rate: 0.00598659
	LOSS [training: 0.2705979138903957 | validation: 0.2029864585392061]
	TIME [epoch: 9.78 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26626089136665226		[learning rate: 0.0059654]
	Learning Rate: 0.00596542
	LOSS [training: 0.26626089136665226 | validation: 0.2186697846947036]
	TIME [epoch: 9.79 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24729385095056935		[learning rate: 0.0059443]
	Learning Rate: 0.00594433
	LOSS [training: 0.24729385095056935 | validation: 0.21708574382327722]
	TIME [epoch: 9.8 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.252229778612636		[learning rate: 0.0059233]
	Learning Rate: 0.0059233
	LOSS [training: 0.252229778612636 | validation: 0.21426515081010908]
	TIME [epoch: 9.79 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25967876455141653		[learning rate: 0.0059024]
	Learning Rate: 0.00590236
	LOSS [training: 0.25967876455141653 | validation: 0.21454341013263195]
	TIME [epoch: 9.82 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25576801840126084		[learning rate: 0.0058815]
	Learning Rate: 0.00588149
	LOSS [training: 0.25576801840126084 | validation: 0.23450970330678142]
	TIME [epoch: 9.79 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26586273757033324		[learning rate: 0.0058607]
	Learning Rate: 0.00586069
	LOSS [training: 0.26586273757033324 | validation: 0.2289743594092311]
	TIME [epoch: 9.73 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.245318665128087		[learning rate: 0.00584]
	Learning Rate: 0.00583996
	LOSS [training: 0.245318665128087 | validation: 0.21991610890556243]
	TIME [epoch: 9.75 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2509897479960682		[learning rate: 0.0058193]
	Learning Rate: 0.00581931
	LOSS [training: 0.2509897479960682 | validation: 0.21843505235970245]
	TIME [epoch: 9.73 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26389306305225385		[learning rate: 0.0057987]
	Learning Rate: 0.00579874
	LOSS [training: 0.26389306305225385 | validation: 0.20520413911596366]
	TIME [epoch: 9.75 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2556451126514284		[learning rate: 0.0057782]
	Learning Rate: 0.00577823
	LOSS [training: 0.2556451126514284 | validation: 0.21704024466659116]
	TIME [epoch: 9.74 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2702699183415056		[learning rate: 0.0057578]
	Learning Rate: 0.0057578
	LOSS [training: 0.2702699183415056 | validation: 0.2161598298734942]
	TIME [epoch: 9.75 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2509152368094974		[learning rate: 0.0057374]
	Learning Rate: 0.00573744
	LOSS [training: 0.2509152368094974 | validation: 0.219899705380134]
	TIME [epoch: 9.73 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25638975134292		[learning rate: 0.0057171]
	Learning Rate: 0.00571715
	LOSS [training: 0.25638975134292 | validation: 0.22717707587982114]
	TIME [epoch: 9.74 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2660897531174205		[learning rate: 0.0056969]
	Learning Rate: 0.00569693
	LOSS [training: 0.2660897531174205 | validation: 0.21430471000187662]
	TIME [epoch: 9.72 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24836589382245425		[learning rate: 0.0056768]
	Learning Rate: 0.00567679
	LOSS [training: 0.24836589382245425 | validation: 0.2143004369406877]
	TIME [epoch: 9.74 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25450848267159115		[learning rate: 0.0056567]
	Learning Rate: 0.00565671
	LOSS [training: 0.25450848267159115 | validation: 0.223476664903797]
	TIME [epoch: 9.76 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24493943263198226		[learning rate: 0.0056367]
	Learning Rate: 0.00563671
	LOSS [training: 0.24493943263198226 | validation: 0.22075134502934998]
	TIME [epoch: 9.75 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26399586253208707		[learning rate: 0.0056168]
	Learning Rate: 0.00561678
	LOSS [training: 0.26399586253208707 | validation: 0.21264221391583665]
	TIME [epoch: 9.75 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2629828637964725		[learning rate: 0.0055969]
	Learning Rate: 0.00559691
	LOSS [training: 0.2629828637964725 | validation: 0.21093553834553722]
	TIME [epoch: 9.74 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2617187977649337		[learning rate: 0.0055771]
	Learning Rate: 0.00557712
	LOSS [training: 0.2617187977649337 | validation: 0.22126946189953065]
	TIME [epoch: 9.76 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2703243793157875		[learning rate: 0.0055574]
	Learning Rate: 0.0055574
	LOSS [training: 0.2703243793157875 | validation: 0.21540784754341966]
	TIME [epoch: 9.76 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24528263009934548		[learning rate: 0.0055378]
	Learning Rate: 0.00553775
	LOSS [training: 0.24528263009934548 | validation: 0.21018793457014712]
	TIME [epoch: 9.73 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2625710926221451		[learning rate: 0.0055182]
	Learning Rate: 0.00551817
	LOSS [training: 0.2625710926221451 | validation: 0.22210131564118046]
	TIME [epoch: 9.74 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2574101420551036		[learning rate: 0.0054987]
	Learning Rate: 0.00549865
	LOSS [training: 0.2574101420551036 | validation: 0.2242756041858045]
	TIME [epoch: 9.75 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24796261358075625		[learning rate: 0.0054792]
	Learning Rate: 0.00547921
	LOSS [training: 0.24796261358075625 | validation: 0.2133590757630024]
	TIME [epoch: 9.75 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27177893905703204		[learning rate: 0.0054598]
	Learning Rate: 0.00545983
	LOSS [training: 0.27177893905703204 | validation: 0.21595482405853766]
	TIME [epoch: 9.72 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25762109669459504		[learning rate: 0.0054405]
	Learning Rate: 0.00544053
	LOSS [training: 0.25762109669459504 | validation: 0.20883626036597006]
	TIME [epoch: 9.75 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.252585510275737		[learning rate: 0.0054213]
	Learning Rate: 0.00542129
	LOSS [training: 0.252585510275737 | validation: 0.2138595937463766]
	TIME [epoch: 9.74 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26542461618009955		[learning rate: 0.0054021]
	Learning Rate: 0.00540212
	LOSS [training: 0.26542461618009955 | validation: 0.21439726500582532]
	TIME [epoch: 9.75 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25723584830225876		[learning rate: 0.005383]
	Learning Rate: 0.00538302
	LOSS [training: 0.25723584830225876 | validation: 0.2154728422185559]
	TIME [epoch: 9.75 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25512474309694144		[learning rate: 0.005364]
	Learning Rate: 0.00536398
	LOSS [training: 0.25512474309694144 | validation: 0.20109199026196495]
	TIME [epoch: 9.75 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27074588334183075		[learning rate: 0.005345]
	Learning Rate: 0.00534501
	LOSS [training: 0.27074588334183075 | validation: 0.22206549216502286]
	TIME [epoch: 9.76 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26241587182302234		[learning rate: 0.0053261]
	Learning Rate: 0.00532611
	LOSS [training: 0.26241587182302234 | validation: 0.21431728218678234]
	TIME [epoch: 9.76 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26598928701207813		[learning rate: 0.0053073]
	Learning Rate: 0.00530728
	LOSS [training: 0.26598928701207813 | validation: 0.2201841121877075]
	TIME [epoch: 9.73 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25265131421908743		[learning rate: 0.0052885]
	Learning Rate: 0.00528851
	LOSS [training: 0.25265131421908743 | validation: 0.21700259697477126]
	TIME [epoch: 9.76 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2683446326210847		[learning rate: 0.0052698]
	Learning Rate: 0.00526981
	LOSS [training: 0.2683446326210847 | validation: 0.21234540887687295]
	TIME [epoch: 9.74 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25710672035044263		[learning rate: 0.0052512]
	Learning Rate: 0.00525117
	LOSS [training: 0.25710672035044263 | validation: 0.2179372888739207]
	TIME [epoch: 9.75 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26802753265310003		[learning rate: 0.0052326]
	Learning Rate: 0.0052326
	LOSS [training: 0.26802753265310003 | validation: 0.21317546351368302]
	TIME [epoch: 9.73 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25166861415872477		[learning rate: 0.0052141]
	Learning Rate: 0.0052141
	LOSS [training: 0.25166861415872477 | validation: 0.21030589294531485]
	TIME [epoch: 9.75 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2428695609147117		[learning rate: 0.0051957]
	Learning Rate: 0.00519566
	LOSS [training: 0.2428695609147117 | validation: 0.21329882647898296]
	TIME [epoch: 9.74 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24473457048288394		[learning rate: 0.0051773]
	Learning Rate: 0.00517729
	LOSS [training: 0.24473457048288394 | validation: 0.2245758552581713]
	TIME [epoch: 9.75 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25104898934151504		[learning rate: 0.005159]
	Learning Rate: 0.00515898
	LOSS [training: 0.25104898934151504 | validation: 0.22511842580246463]
	TIME [epoch: 9.74 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25507891599088367		[learning rate: 0.0051407]
	Learning Rate: 0.00514074
	LOSS [training: 0.25507891599088367 | validation: 0.22239565270413295]
	TIME [epoch: 9.74 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24421393271739214		[learning rate: 0.0051226]
	Learning Rate: 0.00512256
	LOSS [training: 0.24421393271739214 | validation: 0.23158491757382377]
	TIME [epoch: 9.73 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.260910235969995		[learning rate: 0.0051044]
	Learning Rate: 0.00510445
	LOSS [training: 0.260910235969995 | validation: 0.21277958108876915]
	TIME [epoch: 9.75 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25256595299484635		[learning rate: 0.0050864]
	Learning Rate: 0.0050864
	LOSS [training: 0.25256595299484635 | validation: 0.21339264991254395]
	TIME [epoch: 9.75 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25050761571088037		[learning rate: 0.0050684]
	Learning Rate: 0.00506841
	LOSS [training: 0.25050761571088037 | validation: 0.21956018863643378]
	TIME [epoch: 9.73 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26311702835807654		[learning rate: 0.0050505]
	Learning Rate: 0.00505049
	LOSS [training: 0.26311702835807654 | validation: 0.21160096337574305]
	TIME [epoch: 9.72 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24660221300675392		[learning rate: 0.0050326]
	Learning Rate: 0.00503263
	LOSS [training: 0.24660221300675392 | validation: 0.21030292630593767]
	TIME [epoch: 9.75 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.245783913566056		[learning rate: 0.0050148]
	Learning Rate: 0.00501483
	LOSS [training: 0.245783913566056 | validation: 0.20935309593010937]
	TIME [epoch: 9.75 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2626899190598959		[learning rate: 0.0049971]
	Learning Rate: 0.0049971
	LOSS [training: 0.2626899190598959 | validation: 0.22460300651812326]
	TIME [epoch: 9.76 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27363386124673456		[learning rate: 0.0049794]
	Learning Rate: 0.00497943
	LOSS [training: 0.27363386124673456 | validation: 0.22816731412133867]
	TIME [epoch: 9.74 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26290822204833325		[learning rate: 0.0049618]
	Learning Rate: 0.00496182
	LOSS [training: 0.26290822204833325 | validation: 0.21441649191614315]
	TIME [epoch: 9.78 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24751051905564794		[learning rate: 0.0049443]
	Learning Rate: 0.00494427
	LOSS [training: 0.24751051905564794 | validation: 0.2178632936898512]
	TIME [epoch: 9.78 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2616052607665573		[learning rate: 0.0049268]
	Learning Rate: 0.00492679
	LOSS [training: 0.2616052607665573 | validation: 0.20881492868144863]
	TIME [epoch: 9.76 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2576337905707898		[learning rate: 0.0049094]
	Learning Rate: 0.00490937
	LOSS [training: 0.2576337905707898 | validation: 0.22294300660134553]
	TIME [epoch: 9.75 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25606027129896397		[learning rate: 0.004892]
	Learning Rate: 0.00489201
	LOSS [training: 0.25606027129896397 | validation: 0.2277660284619551]
	TIME [epoch: 9.79 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24091404873430924		[learning rate: 0.0048747]
	Learning Rate: 0.00487471
	LOSS [training: 0.24091404873430924 | validation: 0.22170641763134546]
	TIME [epoch: 9.77 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2531869818139117		[learning rate: 0.0048575]
	Learning Rate: 0.00485747
	LOSS [training: 0.2531869818139117 | validation: 0.215643124776427]
	TIME [epoch: 9.77 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2623776184992748		[learning rate: 0.0048403]
	Learning Rate: 0.00484029
	LOSS [training: 0.2623776184992748 | validation: 0.2130789169683859]
	TIME [epoch: 9.75 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25989954549504113		[learning rate: 0.0048232]
	Learning Rate: 0.00482318
	LOSS [training: 0.25989954549504113 | validation: 0.21669590822772106]
	TIME [epoch: 9.75 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2563757483397886		[learning rate: 0.0048061]
	Learning Rate: 0.00480612
	LOSS [training: 0.2563757483397886 | validation: 0.2153477916791302]
	TIME [epoch: 9.79 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2524345217410406		[learning rate: 0.0047891]
	Learning Rate: 0.00478913
	LOSS [training: 0.2524345217410406 | validation: 0.21179139169617667]
	TIME [epoch: 9.76 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24997360698396495		[learning rate: 0.0047722]
	Learning Rate: 0.00477219
	LOSS [training: 0.24997360698396495 | validation: 0.21395240710401137]
	TIME [epoch: 9.76 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.255180226407819		[learning rate: 0.0047553]
	Learning Rate: 0.00475532
	LOSS [training: 0.255180226407819 | validation: 0.21656892040930664]
	TIME [epoch: 9.77 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2660220298723877		[learning rate: 0.0047385]
	Learning Rate: 0.0047385
	LOSS [training: 0.2660220298723877 | validation: 0.21665310016228237]
	TIME [epoch: 9.75 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2437646038468009		[learning rate: 0.0047217]
	Learning Rate: 0.00472175
	LOSS [training: 0.2437646038468009 | validation: 0.21212011608577575]
	TIME [epoch: 9.75 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2632650067263587		[learning rate: 0.004705]
	Learning Rate: 0.00470505
	LOSS [training: 0.2632650067263587 | validation: 0.20590731951770813]
	TIME [epoch: 9.72 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25102429906050455		[learning rate: 0.0046884]
	Learning Rate: 0.00468841
	LOSS [training: 0.25102429906050455 | validation: 0.21572418281673905]
	TIME [epoch: 9.76 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2605212436967859		[learning rate: 0.0046718]
	Learning Rate: 0.00467183
	LOSS [training: 0.2605212436967859 | validation: 0.20582613819663012]
	TIME [epoch: 9.74 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2510194552939515		[learning rate: 0.0046553]
	Learning Rate: 0.00465531
	LOSS [training: 0.2510194552939515 | validation: 0.2082648400522073]
	TIME [epoch: 9.76 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24523010858698904		[learning rate: 0.0046388]
	Learning Rate: 0.00463885
	LOSS [training: 0.24523010858698904 | validation: 0.199325300928012]
	TIME [epoch: 9.77 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15_20240716_142138/states/model_facs_v3_dec1b_2dpca_v15_267.pth
	Model improved!!!
EPOCH 268/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2708359663447366		[learning rate: 0.0046224]
	Learning Rate: 0.00462245
	LOSS [training: 0.2708359663447366 | validation: 0.21641841672446116]
	TIME [epoch: 9.8 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2607256863668015		[learning rate: 0.0046061]
	Learning Rate: 0.0046061
	LOSS [training: 0.2607256863668015 | validation: 0.21649025924937565]
	TIME [epoch: 9.83 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25990164773794866		[learning rate: 0.0045898]
	Learning Rate: 0.00458981
	LOSS [training: 0.25990164773794866 | validation: 0.20944727068240768]
	TIME [epoch: 9.81 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25627106126904725		[learning rate: 0.0045736]
	Learning Rate: 0.00457358
	LOSS [training: 0.25627106126904725 | validation: 0.2204271768659319]
	TIME [epoch: 9.78 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.255380354306727		[learning rate: 0.0045574]
	Learning Rate: 0.00455741
	LOSS [training: 0.255380354306727 | validation: 0.2215951214962612]
	TIME [epoch: 9.83 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25226696482582506		[learning rate: 0.0045413]
	Learning Rate: 0.00454129
	LOSS [training: 0.25226696482582506 | validation: 0.21396680311714653]
	TIME [epoch: 9.81 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2589123236865629		[learning rate: 0.0045252]
	Learning Rate: 0.00452523
	LOSS [training: 0.2589123236865629 | validation: 0.2057259873651997]
	TIME [epoch: 9.83 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25931904844829606		[learning rate: 0.0045092]
	Learning Rate: 0.00450923
	LOSS [training: 0.25931904844829606 | validation: 0.20730278647482167]
	TIME [epoch: 9.84 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2506519818071711		[learning rate: 0.0044933]
	Learning Rate: 0.00449329
	LOSS [training: 0.2506519818071711 | validation: 0.2183799138524793]
	TIME [epoch: 9.83 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2631690421497904		[learning rate: 0.0044774]
	Learning Rate: 0.0044774
	LOSS [training: 0.2631690421497904 | validation: 0.20752504428397828]
	TIME [epoch: 9.83 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25010572468427567		[learning rate: 0.0044616]
	Learning Rate: 0.00446156
	LOSS [training: 0.25010572468427567 | validation: 0.19923016369401264]
	TIME [epoch: 9.86 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15_20240716_142138/states/model_facs_v3_dec1b_2dpca_v15_278.pth
	Model improved!!!
EPOCH 279/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25598742847081196		[learning rate: 0.0044458]
	Learning Rate: 0.00444579
	LOSS [training: 0.25598742847081196 | validation: 0.22777857955643305]
	TIME [epoch: 9.84 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25062695188321465		[learning rate: 0.0044301]
	Learning Rate: 0.00443007
	LOSS [training: 0.25062695188321465 | validation: 0.20417100217316633]
	TIME [epoch: 9.85 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24527703110425605		[learning rate: 0.0044144]
	Learning Rate: 0.0044144
	LOSS [training: 0.24527703110425605 | validation: 0.2174450897974812]
	TIME [epoch: 9.86 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25598092357179736		[learning rate: 0.0043988]
	Learning Rate: 0.00439879
	LOSS [training: 0.25598092357179736 | validation: 0.21205571330394674]
	TIME [epoch: 9.85 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2616430795301127		[learning rate: 0.0043832]
	Learning Rate: 0.00438324
	LOSS [training: 0.2616430795301127 | validation: 0.20075925794481303]
	TIME [epoch: 9.74 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2545393052880099		[learning rate: 0.0043677]
	Learning Rate: 0.00436774
	LOSS [training: 0.2545393052880099 | validation: 0.20063208204346958]
	TIME [epoch: 9.86 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.256457882509789		[learning rate: 0.0043523]
	Learning Rate: 0.00435229
	LOSS [training: 0.256457882509789 | validation: 0.20614917348511486]
	TIME [epoch: 9.85 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2451910128001399		[learning rate: 0.0043369]
	Learning Rate: 0.0043369
	LOSS [training: 0.2451910128001399 | validation: 0.2047364180990156]
	TIME [epoch: 9.87 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2477588733443052		[learning rate: 0.0043216]
	Learning Rate: 0.00432156
	LOSS [training: 0.2477588733443052 | validation: 0.22763354106378295]
	TIME [epoch: 9.84 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2486067611394338		[learning rate: 0.0043063]
	Learning Rate: 0.00430628
	LOSS [training: 0.2486067611394338 | validation: 0.20840724113587453]
	TIME [epoch: 9.86 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24695149170097644		[learning rate: 0.0042911]
	Learning Rate: 0.00429106
	LOSS [training: 0.24695149170097644 | validation: 0.20071904673305946]
	TIME [epoch: 9.84 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25056646158438		[learning rate: 0.0042759]
	Learning Rate: 0.00427588
	LOSS [training: 0.25056646158438 | validation: 0.21466283449623305]
	TIME [epoch: 9.87 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2661773434085438		[learning rate: 0.0042608]
	Learning Rate: 0.00426076
	LOSS [training: 0.2661773434085438 | validation: 0.21849470502697618]
	TIME [epoch: 9.85 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25172684325104133		[learning rate: 0.0042457]
	Learning Rate: 0.00424569
	LOSS [training: 0.25172684325104133 | validation: 0.21262366421763898]
	TIME [epoch: 9.85 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24505618555578465		[learning rate: 0.0042307]
	Learning Rate: 0.00423068
	LOSS [training: 0.24505618555578465 | validation: 0.2032449472514016]
	TIME [epoch: 9.81 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2543817948043994		[learning rate: 0.0042157]
	Learning Rate: 0.00421572
	LOSS [training: 0.2543817948043994 | validation: 0.19755317792934324]
	TIME [epoch: 9.85 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15_20240716_142138/states/model_facs_v3_dec1b_2dpca_v15_294.pth
	Model improved!!!
EPOCH 295/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2527124531615214		[learning rate: 0.0042008]
	Learning Rate: 0.00420081
	LOSS [training: 0.2527124531615214 | validation: 0.2166487474830025]
	TIME [epoch: 9.83 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2529074926826229		[learning rate: 0.004186]
	Learning Rate: 0.00418596
	LOSS [training: 0.2529074926826229 | validation: 0.21175510997636077]
	TIME [epoch: 9.8 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25689918117264604		[learning rate: 0.0041712]
	Learning Rate: 0.00417116
	LOSS [training: 0.25689918117264604 | validation: 0.2059821801936203]
	TIME [epoch: 9.8 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25389139743164413		[learning rate: 0.0041564]
	Learning Rate: 0.00415641
	LOSS [training: 0.25389139743164413 | validation: 0.20934151480536872]
	TIME [epoch: 9.81 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26146831605126514		[learning rate: 0.0041417]
	Learning Rate: 0.00414171
	LOSS [training: 0.26146831605126514 | validation: 0.21471973682017617]
	TIME [epoch: 9.76 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2675496384543688		[learning rate: 0.0041271]
	Learning Rate: 0.00412706
	LOSS [training: 0.2675496384543688 | validation: 0.22704365494957252]
	TIME [epoch: 9.78 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26435685205806175		[learning rate: 0.0041125]
	Learning Rate: 0.00411247
	LOSS [training: 0.26435685205806175 | validation: 0.2170392823601805]
	TIME [epoch: 9.83 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25187877531768327		[learning rate: 0.0040979]
	Learning Rate: 0.00409793
	LOSS [training: 0.25187877531768327 | validation: 0.20292422606295757]
	TIME [epoch: 9.85 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24869319756174846		[learning rate: 0.0040834]
	Learning Rate: 0.00408344
	LOSS [training: 0.24869319756174846 | validation: 0.21016030653946194]
	TIME [epoch: 9.77 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24346329564316463		[learning rate: 0.004069]
	Learning Rate: 0.004069
	LOSS [training: 0.24346329564316463 | validation: 0.2009685185028623]
	TIME [epoch: 9.79 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24944279492155189		[learning rate: 0.0040546]
	Learning Rate: 0.00405461
	LOSS [training: 0.24944279492155189 | validation: 0.21967744830797434]
	TIME [epoch: 9.79 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24960364872206173		[learning rate: 0.0040403]
	Learning Rate: 0.00404027
	LOSS [training: 0.24960364872206173 | validation: 0.217204937008451]
	TIME [epoch: 9.75 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24574991918049816		[learning rate: 0.004026]
	Learning Rate: 0.00402598
	LOSS [training: 0.24574991918049816 | validation: 0.20726784219764943]
	TIME [epoch: 9.77 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2486652447722839		[learning rate: 0.0040117]
	Learning Rate: 0.00401175
	LOSS [training: 0.2486652447722839 | validation: 0.2162336598783423]
	TIME [epoch: 9.75 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23905986127066595		[learning rate: 0.0039976]
	Learning Rate: 0.00399756
	LOSS [training: 0.23905986127066595 | validation: 0.22110489765911753]
	TIME [epoch: 9.74 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2524374320701033		[learning rate: 0.0039834]
	Learning Rate: 0.00398342
	LOSS [training: 0.2524374320701033 | validation: 0.20877448876624066]
	TIME [epoch: 9.75 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2560181751497722		[learning rate: 0.0039693]
	Learning Rate: 0.00396934
	LOSS [training: 0.2560181751497722 | validation: 0.1996048450493463]
	TIME [epoch: 9.8 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2473852194217733		[learning rate: 0.0039553]
	Learning Rate: 0.0039553
	LOSS [training: 0.2473852194217733 | validation: 0.19641919279032755]
	TIME [epoch: 9.79 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15_20240716_142138/states/model_facs_v3_dec1b_2dpca_v15_312.pth
	Model improved!!!
EPOCH 313/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25043094936599286		[learning rate: 0.0039413]
	Learning Rate: 0.00394131
	LOSS [training: 0.25043094936599286 | validation: 0.20040989966061576]
	TIME [epoch: 9.85 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24210158937691176		[learning rate: 0.0039274]
	Learning Rate: 0.00392738
	LOSS [training: 0.24210158937691176 | validation: 0.2025032297293495]
	TIME [epoch: 9.84 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2501811860974994		[learning rate: 0.0039135]
	Learning Rate: 0.00391349
	LOSS [training: 0.2501811860974994 | validation: 0.22196201344603939]
	TIME [epoch: 9.86 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2632676219738677		[learning rate: 0.0038997]
	Learning Rate: 0.00389965
	LOSS [training: 0.2632676219738677 | validation: 0.20901374211714163]
	TIME [epoch: 9.83 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25497645298026395		[learning rate: 0.0038859]
	Learning Rate: 0.00388586
	LOSS [training: 0.25497645298026395 | validation: 0.2023960010829379]
	TIME [epoch: 9.86 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.255054526837768		[learning rate: 0.0038721]
	Learning Rate: 0.00387212
	LOSS [training: 0.255054526837768 | validation: 0.22034305098116086]
	TIME [epoch: 9.85 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2622496875047338		[learning rate: 0.0038584]
	Learning Rate: 0.00385843
	LOSS [training: 0.2622496875047338 | validation: 0.20772578817536752]
	TIME [epoch: 9.85 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24706759560011174		[learning rate: 0.0038448]
	Learning Rate: 0.00384478
	LOSS [training: 0.24706759560011174 | validation: 0.20675915942969275]
	TIME [epoch: 9.85 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2518465336501869		[learning rate: 0.0038312]
	Learning Rate: 0.00383119
	LOSS [training: 0.2518465336501869 | validation: 0.21686471371215518]
	TIME [epoch: 9.82 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25151689169327485		[learning rate: 0.0038176]
	Learning Rate: 0.00381764
	LOSS [training: 0.25151689169327485 | validation: 0.21364779786445087]
	TIME [epoch: 9.8 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2538436315794444		[learning rate: 0.0038041]
	Learning Rate: 0.00380414
	LOSS [training: 0.2538436315794444 | validation: 0.20960415007465683]
	TIME [epoch: 9.8 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2509560999788452		[learning rate: 0.0037907]
	Learning Rate: 0.00379069
	LOSS [training: 0.2509560999788452 | validation: 0.2182691080596133]
	TIME [epoch: 9.8 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2344717722094519		[learning rate: 0.0037773]
	Learning Rate: 0.00377728
	LOSS [training: 0.2344717722094519 | validation: 0.20885514265834218]
	TIME [epoch: 9.8 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26054967148755503		[learning rate: 0.0037639]
	Learning Rate: 0.00376393
	LOSS [training: 0.26054967148755503 | validation: 0.21652373795365482]
	TIME [epoch: 9.81 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26505789960076703		[learning rate: 0.0037506]
	Learning Rate: 0.00375062
	LOSS [training: 0.26505789960076703 | validation: 0.2101407677787094]
	TIME [epoch: 9.8 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2590286680750082		[learning rate: 0.0037374]
	Learning Rate: 0.00373735
	LOSS [training: 0.2590286680750082 | validation: 0.21741702948499522]
	TIME [epoch: 9.8 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2539663370158421		[learning rate: 0.0037241]
	Learning Rate: 0.00372414
	LOSS [training: 0.2539663370158421 | validation: 0.22718144532256446]
	TIME [epoch: 9.81 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24952188149107726		[learning rate: 0.003711]
	Learning Rate: 0.00371097
	LOSS [training: 0.24952188149107726 | validation: 0.20727333000721143]
	TIME [epoch: 9.8 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2680794901786715		[learning rate: 0.0036978]
	Learning Rate: 0.00369785
	LOSS [training: 0.2680794901786715 | validation: 0.20945638004196426]
	TIME [epoch: 9.8 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26851949088515953		[learning rate: 0.0036848]
	Learning Rate: 0.00368477
	LOSS [training: 0.26851949088515953 | validation: 0.2143113455458034]
	TIME [epoch: 9.71 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24625862366953724		[learning rate: 0.0036717]
	Learning Rate: 0.00367174
	LOSS [training: 0.24625862366953724 | validation: 0.20529051242641697]
	TIME [epoch: 9.78 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25233645009717387		[learning rate: 0.0036588]
	Learning Rate: 0.00365875
	LOSS [training: 0.25233645009717387 | validation: 0.2210391452212134]
	TIME [epoch: 9.8 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2519172866202747		[learning rate: 0.0036458]
	Learning Rate: 0.00364582
	LOSS [training: 0.2519172866202747 | validation: 0.20796358970181955]
	TIME [epoch: 9.8 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2534524369959703		[learning rate: 0.0036329]
	Learning Rate: 0.00363292
	LOSS [training: 0.2534524369959703 | validation: 0.20481821588865978]
	TIME [epoch: 9.81 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24779301372169282		[learning rate: 0.0036201]
	Learning Rate: 0.00362008
	LOSS [training: 0.24779301372169282 | validation: 0.21039183790955115]
	TIME [epoch: 9.79 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24386892040234162		[learning rate: 0.0036073]
	Learning Rate: 0.00360728
	LOSS [training: 0.24386892040234162 | validation: 0.2143041386916808]
	TIME [epoch: 9.82 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24281122495521335		[learning rate: 0.0035945]
	Learning Rate: 0.00359452
	LOSS [training: 0.24281122495521335 | validation: 0.2210800091982899]
	TIME [epoch: 9.82 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27841668430581273		[learning rate: 0.0035818]
	Learning Rate: 0.00358181
	LOSS [training: 0.27841668430581273 | validation: 0.20699094276244479]
	TIME [epoch: 9.81 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2585909684219284		[learning rate: 0.0035691]
	Learning Rate: 0.00356914
	LOSS [training: 0.2585909684219284 | validation: 0.20093090814936887]
	TIME [epoch: 9.78 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2574855535525293		[learning rate: 0.0035565]
	Learning Rate: 0.00355652
	LOSS [training: 0.2574855535525293 | validation: 0.21424674969518936]
	TIME [epoch: 9.81 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24925918011838497		[learning rate: 0.0035439]
	Learning Rate: 0.00354395
	LOSS [training: 0.24925918011838497 | validation: 0.2095640108630168]
	TIME [epoch: 9.8 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25324246373542153		[learning rate: 0.0035314]
	Learning Rate: 0.00353141
	LOSS [training: 0.25324246373542153 | validation: 0.21030444025777548]
	TIME [epoch: 9.81 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26424371034877875		[learning rate: 0.0035189]
	Learning Rate: 0.00351893
	LOSS [training: 0.26424371034877875 | validation: 0.2107717900128577]
	TIME [epoch: 9.79 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2451525988045309		[learning rate: 0.0035065]
	Learning Rate: 0.00350648
	LOSS [training: 0.2451525988045309 | validation: 0.2167663765143474]
	TIME [epoch: 9.82 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23845250831539008		[learning rate: 0.0034941]
	Learning Rate: 0.00349408
	LOSS [training: 0.23845250831539008 | validation: 0.20753327316304543]
	TIME [epoch: 9.81 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24665779191763368		[learning rate: 0.0034817]
	Learning Rate: 0.00348173
	LOSS [training: 0.24665779191763368 | validation: 0.21514619731627377]
	TIME [epoch: 9.82 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2453263630691084		[learning rate: 0.0034694]
	Learning Rate: 0.00346942
	LOSS [training: 0.2453263630691084 | validation: 0.21364841668210502]
	TIME [epoch: 9.8 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24740790283746902		[learning rate: 0.0034571]
	Learning Rate: 0.00345715
	LOSS [training: 0.24740790283746902 | validation: 0.20132430513119165]
	TIME [epoch: 9.8 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2316972094244122		[learning rate: 0.0034449]
	Learning Rate: 0.00344492
	LOSS [training: 0.2316972094244122 | validation: 0.20747399151842721]
	TIME [epoch: 9.8 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2591027407001216		[learning rate: 0.0034327]
	Learning Rate: 0.00343274
	LOSS [training: 0.2591027407001216 | validation: 0.21025170150410194]
	TIME [epoch: 9.8 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24946486553921196		[learning rate: 0.0034206]
	Learning Rate: 0.0034206
	LOSS [training: 0.24946486553921196 | validation: 0.2072882679377542]
	TIME [epoch: 9.82 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24846228945707874		[learning rate: 0.0034085]
	Learning Rate: 0.00340851
	LOSS [training: 0.24846228945707874 | validation: 0.2017110254820887]
	TIME [epoch: 9.82 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2520952789871113		[learning rate: 0.0033965]
	Learning Rate: 0.00339645
	LOSS [training: 0.2520952789871113 | validation: 0.21541469463717428]
	TIME [epoch: 9.81 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24527254506124893		[learning rate: 0.0033844]
	Learning Rate: 0.00338444
	LOSS [training: 0.24527254506124893 | validation: 0.20553137953766304]
	TIME [epoch: 9.83 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26134899323417626		[learning rate: 0.0033725]
	Learning Rate: 0.00337247
	LOSS [training: 0.26134899323417626 | validation: 0.21196902053176325]
	TIME [epoch: 9.84 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24315310393490674		[learning rate: 0.0033605]
	Learning Rate: 0.00336055
	LOSS [training: 0.24315310393490674 | validation: 0.21329770848126345]
	TIME [epoch: 9.8 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25480067828332537		[learning rate: 0.0033487]
	Learning Rate: 0.00334867
	LOSS [training: 0.25480067828332537 | validation: 0.20710789809839936]
	TIME [epoch: 9.85 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2663556232305858		[learning rate: 0.0033368]
	Learning Rate: 0.00333682
	LOSS [training: 0.2663556232305858 | validation: 0.21296191873708792]
	TIME [epoch: 9.82 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2426352607867757		[learning rate: 0.003325]
	Learning Rate: 0.00332502
	LOSS [training: 0.2426352607867757 | validation: 0.21327218386683783]
	TIME [epoch: 9.84 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24518389235649596		[learning rate: 0.0033133]
	Learning Rate: 0.00331327
	LOSS [training: 0.24518389235649596 | validation: 0.21999091977970514]
	TIME [epoch: 9.79 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.263200281527003		[learning rate: 0.0033016]
	Learning Rate: 0.00330155
	LOSS [training: 0.263200281527003 | validation: 0.22107435765376468]
	TIME [epoch: 9.8 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25312040921366846		[learning rate: 0.0032899]
	Learning Rate: 0.00328988
	LOSS [training: 0.25312040921366846 | validation: 0.20052438776302473]
	TIME [epoch: 9.8 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24533141540886658		[learning rate: 0.0032782]
	Learning Rate: 0.00327824
	LOSS [training: 0.24533141540886658 | validation: 0.20404141336951911]
	TIME [epoch: 9.8 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2503152497413022		[learning rate: 0.0032666]
	Learning Rate: 0.00326665
	LOSS [training: 0.2503152497413022 | validation: 0.20830515695469595]
	TIME [epoch: 9.79 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25383654668282724		[learning rate: 0.0032551]
	Learning Rate: 0.0032551
	LOSS [training: 0.25383654668282724 | validation: 0.20499436663653672]
	TIME [epoch: 9.79 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23821713951910464		[learning rate: 0.0032436]
	Learning Rate: 0.00324359
	LOSS [training: 0.23821713951910464 | validation: 0.2074856965855913]
	TIME [epoch: 9.82 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2687821817002848		[learning rate: 0.0032321]
	Learning Rate: 0.00323212
	LOSS [training: 0.2687821817002848 | validation: 0.20065289589092378]
	TIME [epoch: 9.82 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24668024339946773		[learning rate: 0.0032207]
	Learning Rate: 0.00322069
	LOSS [training: 0.24668024339946773 | validation: 0.20530065956439855]
	TIME [epoch: 9.79 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2500432058542697		[learning rate: 0.0032093]
	Learning Rate: 0.0032093
	LOSS [training: 0.2500432058542697 | validation: 0.20198949457846765]
	TIME [epoch: 9.8 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26774022958762006		[learning rate: 0.003198]
	Learning Rate: 0.00319795
	LOSS [training: 0.26774022958762006 | validation: 0.20868166403884086]
	TIME [epoch: 9.81 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2560907431512725		[learning rate: 0.0031866]
	Learning Rate: 0.00318664
	LOSS [training: 0.2560907431512725 | validation: 0.20643613666652402]
	TIME [epoch: 9.82 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25295658706345403		[learning rate: 0.0031754]
	Learning Rate: 0.00317537
	LOSS [training: 0.25295658706345403 | validation: 0.20676684371133397]
	TIME [epoch: 9.77 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24669697994702253		[learning rate: 0.0031641]
	Learning Rate: 0.00316415
	LOSS [training: 0.24669697994702253 | validation: 0.208363690455969]
	TIME [epoch: 9.8 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2486387323479479		[learning rate: 0.003153]
	Learning Rate: 0.00315296
	LOSS [training: 0.2486387323479479 | validation: 0.21342827713144857]
	TIME [epoch: 9.79 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25660530432332396		[learning rate: 0.0031418]
	Learning Rate: 0.00314181
	LOSS [training: 0.25660530432332396 | validation: 0.2293367801175588]
	TIME [epoch: 9.81 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24872111888257387		[learning rate: 0.0031307]
	Learning Rate: 0.0031307
	LOSS [training: 0.24872111888257387 | validation: 0.20287763458119962]
	TIME [epoch: 9.8 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25713767603535603		[learning rate: 0.0031196]
	Learning Rate: 0.00311963
	LOSS [training: 0.25713767603535603 | validation: 0.21088116814262578]
	TIME [epoch: 9.79 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25233021610735634		[learning rate: 0.0031086]
	Learning Rate: 0.00310859
	LOSS [training: 0.25233021610735634 | validation: 0.21867595428540704]
	TIME [epoch: 9.78 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25775562670700386		[learning rate: 0.0030976]
	Learning Rate: 0.0030976
	LOSS [training: 0.25775562670700386 | validation: 0.20441382987318102]
	TIME [epoch: 9.81 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.256926467584308		[learning rate: 0.0030866]
	Learning Rate: 0.00308665
	LOSS [training: 0.256926467584308 | validation: 0.2155503649568596]
	TIME [epoch: 9.81 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2471781877022893		[learning rate: 0.0030757]
	Learning Rate: 0.00307573
	LOSS [training: 0.2471781877022893 | validation: 0.21672857381784033]
	TIME [epoch: 9.8 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2472697825666796		[learning rate: 0.0030649]
	Learning Rate: 0.00306486
	LOSS [training: 0.2472697825666796 | validation: 0.2036346308169993]
	TIME [epoch: 9.82 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2516697510293919		[learning rate: 0.003054]
	Learning Rate: 0.00305402
	LOSS [training: 0.2516697510293919 | validation: 0.22195201910074291]
	TIME [epoch: 9.8 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2554747484228996		[learning rate: 0.0030432]
	Learning Rate: 0.00304322
	LOSS [training: 0.2554747484228996 | validation: 0.22226241667872032]
	TIME [epoch: 9.82 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2576237083622034		[learning rate: 0.0030325]
	Learning Rate: 0.00303246
	LOSS [training: 0.2576237083622034 | validation: 0.22232298566460473]
	TIME [epoch: 9.8 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2522959160610532		[learning rate: 0.0030217]
	Learning Rate: 0.00302174
	LOSS [training: 0.2522959160610532 | validation: 0.21519528595941365]
	TIME [epoch: 9.8 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24420779634131007		[learning rate: 0.003011]
	Learning Rate: 0.00301105
	LOSS [training: 0.24420779634131007 | validation: 0.21343916847396552]
	TIME [epoch: 9.79 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25758500730287154		[learning rate: 0.0030004]
	Learning Rate: 0.0030004
	LOSS [training: 0.25758500730287154 | validation: 0.2084968511893252]
	TIME [epoch: 9.79 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26374657305874877		[learning rate: 0.0029898]
	Learning Rate: 0.00298979
	LOSS [training: 0.26374657305874877 | validation: 0.2052243328588605]
	TIME [epoch: 9.81 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24855921032313835		[learning rate: 0.0029792]
	Learning Rate: 0.00297922
	LOSS [training: 0.24855921032313835 | validation: 0.2123139806715916]
	TIME [epoch: 9.76 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24986624819128592		[learning rate: 0.0029687]
	Learning Rate: 0.00296869
	LOSS [training: 0.24986624819128592 | validation: 0.2179022882324829]
	TIME [epoch: 9.8 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2458093598302852		[learning rate: 0.0029582]
	Learning Rate: 0.00295819
	LOSS [training: 0.2458093598302852 | validation: 0.21451759651810914]
	TIME [epoch: 9.8 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2493346800463975		[learning rate: 0.0029477]
	Learning Rate: 0.00294773
	LOSS [training: 0.2493346800463975 | validation: 0.19749164262683372]
	TIME [epoch: 9.8 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24561691493737445		[learning rate: 0.0029373]
	Learning Rate: 0.0029373
	LOSS [training: 0.24561691493737445 | validation: 0.22122599178350527]
	TIME [epoch: 9.79 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24733031463597244		[learning rate: 0.0029269]
	Learning Rate: 0.00292692
	LOSS [training: 0.24733031463597244 | validation: 0.21458124611418133]
	TIME [epoch: 9.82 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2536222828780094		[learning rate: 0.0029166]
	Learning Rate: 0.00291657
	LOSS [training: 0.2536222828780094 | validation: 0.20749263745105767]
	TIME [epoch: 9.79 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2602110366040714		[learning rate: 0.0029063]
	Learning Rate: 0.00290625
	LOSS [training: 0.2602110366040714 | validation: 0.20119274343437277]
	TIME [epoch: 9.82 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2401999549874075		[learning rate: 0.002896]
	Learning Rate: 0.00289598
	LOSS [training: 0.2401999549874075 | validation: 0.21037940111384543]
	TIME [epoch: 9.81 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24311082613155224		[learning rate: 0.0028857]
	Learning Rate: 0.00288573
	LOSS [training: 0.24311082613155224 | validation: 0.21443541323441545]
	TIME [epoch: 9.84 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24609313454712348		[learning rate: 0.0028755]
	Learning Rate: 0.00287553
	LOSS [training: 0.24609313454712348 | validation: 0.2130433659460534]
	TIME [epoch: 9.86 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25183192234646395		[learning rate: 0.0028654]
	Learning Rate: 0.00286536
	LOSS [training: 0.25183192234646395 | validation: 0.21340659228247497]
	TIME [epoch: 9.84 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24795222468641706		[learning rate: 0.0028552]
	Learning Rate: 0.00285523
	LOSS [training: 0.24795222468641706 | validation: 0.20172949014284303]
	TIME [epoch: 9.85 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24439943712350884		[learning rate: 0.0028451]
	Learning Rate: 0.00284513
	LOSS [training: 0.24439943712350884 | validation: 0.21741423009247168]
	TIME [epoch: 9.84 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.244864315727495		[learning rate: 0.0028351]
	Learning Rate: 0.00283507
	LOSS [training: 0.244864315727495 | validation: 0.21129189032734183]
	TIME [epoch: 9.87 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2512112405658126		[learning rate: 0.002825]
	Learning Rate: 0.00282505
	LOSS [training: 0.2512112405658126 | validation: 0.22048957077569048]
	TIME [epoch: 9.83 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24814963241490715		[learning rate: 0.0028151]
	Learning Rate: 0.00281506
	LOSS [training: 0.24814963241490715 | validation: 0.2172917683366265]
	TIME [epoch: 9.85 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2544892371583329		[learning rate: 0.0028051]
	Learning Rate: 0.0028051
	LOSS [training: 0.2544892371583329 | validation: 0.19939474360045656]
	TIME [epoch: 9.84 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24796517140206062		[learning rate: 0.0027952]
	Learning Rate: 0.00279518
	LOSS [training: 0.24796517140206062 | validation: 0.20902331014734737]
	TIME [epoch: 9.86 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2469300873602881		[learning rate: 0.0027853]
	Learning Rate: 0.0027853
	LOSS [training: 0.2469300873602881 | validation: 0.20386169479915664]
	TIME [epoch: 9.85 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24273619615110983		[learning rate: 0.0027754]
	Learning Rate: 0.00277545
	LOSS [training: 0.24273619615110983 | validation: 0.21425169018211668]
	TIME [epoch: 9.84 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2492477726470407		[learning rate: 0.0027656]
	Learning Rate: 0.00276564
	LOSS [training: 0.2492477726470407 | validation: 0.205498721430527]
	TIME [epoch: 9.84 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25758716447973545		[learning rate: 0.0027559]
	Learning Rate: 0.00275586
	LOSS [training: 0.25758716447973545 | validation: 0.21635468733878488]
	TIME [epoch: 9.86 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25963152344886054		[learning rate: 0.0027461]
	Learning Rate: 0.00274611
	LOSS [training: 0.25963152344886054 | validation: 0.20544407096430017]
	TIME [epoch: 9.85 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24861413813908947		[learning rate: 0.0027364]
	Learning Rate: 0.0027364
	LOSS [training: 0.24861413813908947 | validation: 0.19856536135800826]
	TIME [epoch: 9.85 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24090090480580928		[learning rate: 0.0027267]
	Learning Rate: 0.00272672
	LOSS [training: 0.24090090480580928 | validation: 0.21049117004157178]
	TIME [epoch: 9.84 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24249113548419832		[learning rate: 0.0027171]
	Learning Rate: 0.00271708
	LOSS [training: 0.24249113548419832 | validation: 0.22110862100015116]
	TIME [epoch: 9.81 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24824161699588063		[learning rate: 0.0027075]
	Learning Rate: 0.00270747
	LOSS [training: 0.24824161699588063 | validation: 0.2063092634386617]
	TIME [epoch: 9.77 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24875858430289363		[learning rate: 0.0026979]
	Learning Rate: 0.0026979
	LOSS [training: 0.24875858430289363 | validation: 0.20343368182742977]
	TIME [epoch: 9.82 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2507367297084544		[learning rate: 0.0026884]
	Learning Rate: 0.00268836
	LOSS [training: 0.2507367297084544 | validation: 0.2056613960408661]
	TIME [epoch: 9.83 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24371348528339765		[learning rate: 0.0026789]
	Learning Rate: 0.00267885
	LOSS [training: 0.24371348528339765 | validation: 0.20539929174194]
	TIME [epoch: 9.81 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24732512160009176		[learning rate: 0.0026694]
	Learning Rate: 0.00266938
	LOSS [training: 0.24732512160009176 | validation: 0.20669950358691022]
	TIME [epoch: 9.84 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24449361269943715		[learning rate: 0.0026599]
	Learning Rate: 0.00265994
	LOSS [training: 0.24449361269943715 | validation: 0.21350435304965493]
	TIME [epoch: 9.85 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25527296857514836		[learning rate: 0.0026505]
	Learning Rate: 0.00265053
	LOSS [training: 0.25527296857514836 | validation: 0.21176973585451844]
	TIME [epoch: 9.78 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2483356341965657		[learning rate: 0.0026412]
	Learning Rate: 0.00264116
	LOSS [training: 0.2483356341965657 | validation: 0.22069236908919043]
	TIME [epoch: 9.83 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2583480426967032		[learning rate: 0.0026318]
	Learning Rate: 0.00263182
	LOSS [training: 0.2583480426967032 | validation: 0.21840075941453171]
	TIME [epoch: 9.83 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23977382095403074		[learning rate: 0.0026225]
	Learning Rate: 0.00262251
	LOSS [training: 0.23977382095403074 | validation: 0.20985887775637443]
	TIME [epoch: 9.79 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25006423103330566		[learning rate: 0.0026132]
	Learning Rate: 0.00261324
	LOSS [training: 0.25006423103330566 | validation: 0.2160885616262606]
	TIME [epoch: 9.78 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24563475938373178		[learning rate: 0.002604]
	Learning Rate: 0.002604
	LOSS [training: 0.24563475938373178 | validation: 0.2147933887087213]
	TIME [epoch: 9.79 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23959599363729764		[learning rate: 0.0025948]
	Learning Rate: 0.00259479
	LOSS [training: 0.23959599363729764 | validation: 0.2088778449258771]
	TIME [epoch: 9.81 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24787276040932218		[learning rate: 0.0025856]
	Learning Rate: 0.00258562
	LOSS [training: 0.24787276040932218 | validation: 0.21979205562618861]
	TIME [epoch: 9.78 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2526851203369631		[learning rate: 0.0025765]
	Learning Rate: 0.00257647
	LOSS [training: 0.2526851203369631 | validation: 0.2142461456598172]
	TIME [epoch: 9.78 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2474733864097588		[learning rate: 0.0025674]
	Learning Rate: 0.00256736
	LOSS [training: 0.2474733864097588 | validation: 0.21922680326681201]
	TIME [epoch: 9.79 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2564229360969144		[learning rate: 0.0025583]
	Learning Rate: 0.00255828
	LOSS [training: 0.2564229360969144 | validation: 0.21342231252761273]
	TIME [epoch: 9.78 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2405341435559263		[learning rate: 0.0025492]
	Learning Rate: 0.00254924
	LOSS [training: 0.2405341435559263 | validation: 0.22333166824900436]
	TIME [epoch: 9.79 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2540034257927784		[learning rate: 0.0025402]
	Learning Rate: 0.00254022
	LOSS [training: 0.2540034257927784 | validation: 0.20869976620513567]
	TIME [epoch: 9.77 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2544450386130363		[learning rate: 0.0025312]
	Learning Rate: 0.00253124
	LOSS [training: 0.2544450386130363 | validation: 0.21407077143979852]
	TIME [epoch: 9.79 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.249988689886582		[learning rate: 0.0025223]
	Learning Rate: 0.00252229
	LOSS [training: 0.249988689886582 | validation: 0.20711920284963795]
	TIME [epoch: 9.79 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24833568670708836		[learning rate: 0.0025134]
	Learning Rate: 0.00251337
	LOSS [training: 0.24833568670708836 | validation: 0.21118872575873215]
	TIME [epoch: 9.8 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24534423185274964		[learning rate: 0.0025045]
	Learning Rate: 0.00250448
	LOSS [training: 0.24534423185274964 | validation: 0.20310724917397502]
	TIME [epoch: 9.78 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24804767395478322		[learning rate: 0.0024956]
	Learning Rate: 0.00249563
	LOSS [training: 0.24804767395478322 | validation: 0.20917418446341318]
	TIME [epoch: 9.8 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2564687578024456		[learning rate: 0.0024868]
	Learning Rate: 0.0024868
	LOSS [training: 0.2564687578024456 | validation: 0.21951093352854137]
	TIME [epoch: 9.77 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24533379486059503		[learning rate: 0.002478]
	Learning Rate: 0.00247801
	LOSS [training: 0.24533379486059503 | validation: 0.21905676091729429]
	TIME [epoch: 9.84 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2514673159632726		[learning rate: 0.0024692]
	Learning Rate: 0.00246924
	LOSS [training: 0.2514673159632726 | validation: 0.2114468005985687]
	TIME [epoch: 9.81 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24149729397810885		[learning rate: 0.0024605]
	Learning Rate: 0.00246051
	LOSS [training: 0.24149729397810885 | validation: 0.21957267898731433]
	TIME [epoch: 9.82 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24884915406178645		[learning rate: 0.0024518]
	Learning Rate: 0.00245181
	LOSS [training: 0.24884915406178645 | validation: 0.2198392652547782]
	TIME [epoch: 9.8 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2614205545688738		[learning rate: 0.0024431]
	Learning Rate: 0.00244314
	LOSS [training: 0.2614205545688738 | validation: 0.2058245019319565]
	TIME [epoch: 9.82 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25585341112582727		[learning rate: 0.0024345]
	Learning Rate: 0.0024345
	LOSS [training: 0.25585341112582727 | validation: 0.20270083681240703]
	TIME [epoch: 9.8 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2568504887693777		[learning rate: 0.0024259]
	Learning Rate: 0.00242589
	LOSS [training: 0.2568504887693777 | validation: 0.2085558069722297]
	TIME [epoch: 9.82 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24883482250802955		[learning rate: 0.0024173]
	Learning Rate: 0.00241732
	LOSS [training: 0.24883482250802955 | validation: 0.20653891873410574]
	TIME [epoch: 9.81 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.255705920035447		[learning rate: 0.0024088]
	Learning Rate: 0.00240877
	LOSS [training: 0.255705920035447 | validation: 0.2008647793050457]
	TIME [epoch: 9.78 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25538982681780337		[learning rate: 0.0024002]
	Learning Rate: 0.00240025
	LOSS [training: 0.25538982681780337 | validation: 0.21094562013684243]
	TIME [epoch: 9.79 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24748191624258783		[learning rate: 0.0023918]
	Learning Rate: 0.00239176
	LOSS [training: 0.24748191624258783 | validation: 0.21221795362445423]
	TIME [epoch: 9.79 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23590169228100985		[learning rate: 0.0023833]
	Learning Rate: 0.0023833
	LOSS [training: 0.23590169228100985 | validation: 0.2163991411955394]
	TIME [epoch: 9.8 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24241746931936425		[learning rate: 0.0023749]
	Learning Rate: 0.00237488
	LOSS [training: 0.24241746931936425 | validation: 0.2122257056691029]
	TIME [epoch: 9.88 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2477868544966589		[learning rate: 0.0023665]
	Learning Rate: 0.00236648
	LOSS [training: 0.2477868544966589 | validation: 0.20596392306716355]
	TIME [epoch: 9.74 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24173243159590208		[learning rate: 0.0023581]
	Learning Rate: 0.00235811
	LOSS [training: 0.24173243159590208 | validation: 0.22518910230383898]
	TIME [epoch: 9.8 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.244166511025538		[learning rate: 0.0023498]
	Learning Rate: 0.00234977
	LOSS [training: 0.244166511025538 | validation: 0.20310659503528433]
	TIME [epoch: 9.8 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24592037838828917		[learning rate: 0.0023415]
	Learning Rate: 0.00234146
	LOSS [training: 0.24592037838828917 | validation: 0.20140191771953062]
	TIME [epoch: 9.8 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24387121017081245		[learning rate: 0.0023332]
	Learning Rate: 0.00233318
	LOSS [training: 0.24387121017081245 | validation: 0.20381063488710288]
	TIME [epoch: 9.78 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24760637155211326		[learning rate: 0.0023249]
	Learning Rate: 0.00232493
	LOSS [training: 0.24760637155211326 | validation: 0.20034964145991094]
	TIME [epoch: 9.79 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25227553683211185		[learning rate: 0.0023167]
	Learning Rate: 0.00231671
	LOSS [training: 0.25227553683211185 | validation: 0.20586478785702278]
	TIME [epoch: 9.74 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.257240462824946		[learning rate: 0.0023085]
	Learning Rate: 0.00230852
	LOSS [training: 0.257240462824946 | validation: 0.21444287688094454]
	TIME [epoch: 9.79 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24149826973858024		[learning rate: 0.0023004]
	Learning Rate: 0.00230035
	LOSS [training: 0.24149826973858024 | validation: 0.20928664264370883]
	TIME [epoch: 9.77 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25723116325192874		[learning rate: 0.0022922]
	Learning Rate: 0.00229222
	LOSS [training: 0.25723116325192874 | validation: 0.20214115442718023]
	TIME [epoch: 9.76 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25008600143284565		[learning rate: 0.0022841]
	Learning Rate: 0.00228411
	LOSS [training: 0.25008600143284565 | validation: 0.21721158378885086]
	TIME [epoch: 9.77 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25129869756631834		[learning rate: 0.002276]
	Learning Rate: 0.00227604
	LOSS [training: 0.25129869756631834 | validation: 0.21663596457400183]
	TIME [epoch: 9.78 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2612164253557461		[learning rate: 0.002268]
	Learning Rate: 0.00226799
	LOSS [training: 0.2612164253557461 | validation: 0.2230304697108089]
	TIME [epoch: 9.76 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25530721036563875		[learning rate: 0.00226]
	Learning Rate: 0.00225997
	LOSS [training: 0.25530721036563875 | validation: 0.2141173096947925]
	TIME [epoch: 9.77 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24085303137821126		[learning rate: 0.002252]
	Learning Rate: 0.00225198
	LOSS [training: 0.24085303137821126 | validation: 0.21437104880302066]
	TIME [epoch: 9.81 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23843543784769827		[learning rate: 0.002244]
	Learning Rate: 0.00224401
	LOSS [training: 0.23843543784769827 | validation: 0.21046550577695006]
	TIME [epoch: 9.75 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23961928429007726		[learning rate: 0.0022361]
	Learning Rate: 0.00223608
	LOSS [training: 0.23961928429007726 | validation: 0.21555066377437546]
	TIME [epoch: 9.82 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24344670396007187		[learning rate: 0.0022282]
	Learning Rate: 0.00222817
	LOSS [training: 0.24344670396007187 | validation: 0.20679482296697133]
	TIME [epoch: 9.73 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.251847142994585		[learning rate: 0.0022203]
	Learning Rate: 0.00222029
	LOSS [training: 0.251847142994585 | validation: 0.21630044363140816]
	TIME [epoch: 9.75 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2387486211060127		[learning rate: 0.0022124]
	Learning Rate: 0.00221244
	LOSS [training: 0.2387486211060127 | validation: 0.203406124803066]
	TIME [epoch: 9.78 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24149454060650177		[learning rate: 0.0022046]
	Learning Rate: 0.00220462
	LOSS [training: 0.24149454060650177 | validation: 0.2143003976213887]
	TIME [epoch: 9.76 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2355102447294779		[learning rate: 0.0021968]
	Learning Rate: 0.00219682
	LOSS [training: 0.2355102447294779 | validation: 0.2098759802482148]
	TIME [epoch: 9.8 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26133855559339025		[learning rate: 0.0021891]
	Learning Rate: 0.00218905
	LOSS [training: 0.26133855559339025 | validation: 0.213733464014016]
	TIME [epoch: 9.78 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23648747512556378		[learning rate: 0.0021813]
	Learning Rate: 0.00218131
	LOSS [training: 0.23648747512556378 | validation: 0.2099855453303321]
	TIME [epoch: 9.8 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24157303381952508		[learning rate: 0.0021736]
	Learning Rate: 0.0021736
	LOSS [training: 0.24157303381952508 | validation: 0.2148474766100473]
	TIME [epoch: 9.76 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23423982635903648		[learning rate: 0.0021659]
	Learning Rate: 0.00216591
	LOSS [training: 0.23423982635903648 | validation: 0.20780025743365932]
	TIME [epoch: 9.8 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25039380389031357		[learning rate: 0.0021583]
	Learning Rate: 0.00215825
	LOSS [training: 0.25039380389031357 | validation: 0.22242223152323434]
	TIME [epoch: 9.79 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24749898299668605		[learning rate: 0.0021506]
	Learning Rate: 0.00215062
	LOSS [training: 0.24749898299668605 | validation: 0.21665194924745018]
	TIME [epoch: 9.76 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2484583081019038		[learning rate: 0.002143]
	Learning Rate: 0.00214302
	LOSS [training: 0.2484583081019038 | validation: 0.2031843298335471]
	TIME [epoch: 9.78 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24782876027111508		[learning rate: 0.0021354]
	Learning Rate: 0.00213544
	LOSS [training: 0.24782876027111508 | validation: 0.21556782314724998]
	TIME [epoch: 9.78 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2389619483771854		[learning rate: 0.0021279]
	Learning Rate: 0.00212789
	LOSS [training: 0.2389619483771854 | validation: 0.2211978940412727]
	TIME [epoch: 9.78 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24682586427602263		[learning rate: 0.0021204]
	Learning Rate: 0.00212036
	LOSS [training: 0.24682586427602263 | validation: 0.20693496582119897]
	TIME [epoch: 9.79 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2500745355898279		[learning rate: 0.0021129]
	Learning Rate: 0.00211287
	LOSS [training: 0.2500745355898279 | validation: 0.20215889552662664]
	TIME [epoch: 9.81 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24593185119733826		[learning rate: 0.0021054]
	Learning Rate: 0.00210539
	LOSS [training: 0.24593185119733826 | validation: 0.2250676378002904]
	TIME [epoch: 9.84 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2514161023117712		[learning rate: 0.0020979]
	Learning Rate: 0.00209795
	LOSS [training: 0.2514161023117712 | validation: 0.21524255225374622]
	TIME [epoch: 9.78 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2506408925010612		[learning rate: 0.0020905]
	Learning Rate: 0.00209053
	LOSS [training: 0.2506408925010612 | validation: 0.20699972024279378]
	TIME [epoch: 9.8 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24229189652702854		[learning rate: 0.0020831]
	Learning Rate: 0.00208314
	LOSS [training: 0.24229189652702854 | validation: 0.19753576621226812]
	TIME [epoch: 9.78 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24399212865998596		[learning rate: 0.0020758]
	Learning Rate: 0.00207577
	LOSS [training: 0.24399212865998596 | validation: 0.21668608875352652]
	TIME [epoch: 9.85 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2339541476524906		[learning rate: 0.0020684]
	Learning Rate: 0.00206843
	LOSS [training: 0.2339541476524906 | validation: 0.21590771480482127]
	TIME [epoch: 9.8 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23852502335659576		[learning rate: 0.0020611]
	Learning Rate: 0.00206112
	LOSS [training: 0.23852502335659576 | validation: 0.214176606350761]
	TIME [epoch: 9.8 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2510885089303952		[learning rate: 0.0020538]
	Learning Rate: 0.00205383
	LOSS [training: 0.2510885089303952 | validation: 0.20285984871012044]
	TIME [epoch: 9.75 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24718791615752958		[learning rate: 0.0020466]
	Learning Rate: 0.00204657
	LOSS [training: 0.24718791615752958 | validation: 0.21351953868468437]
	TIME [epoch: 9.87 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24456578554270944		[learning rate: 0.0020393]
	Learning Rate: 0.00203933
	LOSS [training: 0.24456578554270944 | validation: 0.21173621323319108]
	TIME [epoch: 9.8 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2538940166078357		[learning rate: 0.0020321]
	Learning Rate: 0.00203212
	LOSS [training: 0.2538940166078357 | validation: 0.21439257942710252]
	TIME [epoch: 9.8 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2539818671518353		[learning rate: 0.0020249]
	Learning Rate: 0.00202493
	LOSS [training: 0.2539818671518353 | validation: 0.21883965929720878]
	TIME [epoch: 33.6 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2424097690565774		[learning rate: 0.0020178]
	Learning Rate: 0.00201777
	LOSS [training: 0.2424097690565774 | validation: 0.20930512654910247]
	TIME [epoch: 21.1 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23571273538548573		[learning rate: 0.0020106]
	Learning Rate: 0.00201064
	LOSS [training: 0.23571273538548573 | validation: 0.20755829164251707]
	TIME [epoch: 21.2 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25086647253539573		[learning rate: 0.0020035]
	Learning Rate: 0.00200353
	LOSS [training: 0.25086647253539573 | validation: 0.21225656194212691]
	TIME [epoch: 21.2 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24451482496626853		[learning rate: 0.0019964]
	Learning Rate: 0.00199644
	LOSS [training: 0.24451482496626853 | validation: 0.1957014197998317]
	TIME [epoch: 21.2 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15_20240716_142138/states/model_facs_v3_dec1b_2dpca_v15_505.pth
	Model improved!!!
EPOCH 506/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23865723607919595		[learning rate: 0.0019894]
	Learning Rate: 0.00198938
	LOSS [training: 0.23865723607919595 | validation: 0.21429096942814302]
	TIME [epoch: 21.2 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25168177949460097		[learning rate: 0.0019823]
	Learning Rate: 0.00198235
	LOSS [training: 0.25168177949460097 | validation: 0.20897488031934533]
	TIME [epoch: 21.2 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24686142076182246		[learning rate: 0.0019753]
	Learning Rate: 0.00197534
	LOSS [training: 0.24686142076182246 | validation: 0.21272537308622264]
	TIME [epoch: 21.2 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24767140980044386		[learning rate: 0.0019684]
	Learning Rate: 0.00196835
	LOSS [training: 0.24767140980044386 | validation: 0.21803782670174301]
	TIME [epoch: 21.2 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2507458553001855		[learning rate: 0.0019614]
	Learning Rate: 0.00196139
	LOSS [training: 0.2507458553001855 | validation: 0.213455084923272]
	TIME [epoch: 21.2 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24690050098076258		[learning rate: 0.0019545]
	Learning Rate: 0.00195445
	LOSS [training: 0.24690050098076258 | validation: 0.21964344050048346]
	TIME [epoch: 21.2 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2452840363648956		[learning rate: 0.0019475]
	Learning Rate: 0.00194754
	LOSS [training: 0.2452840363648956 | validation: 0.21749496755487865]
	TIME [epoch: 21.2 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24870545507711883		[learning rate: 0.0019407]
	Learning Rate: 0.00194066
	LOSS [training: 0.24870545507711883 | validation: 0.21107740311050066]
	TIME [epoch: 21.2 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23661061404929973		[learning rate: 0.0019338]
	Learning Rate: 0.00193379
	LOSS [training: 0.23661061404929973 | validation: 0.20902210676042285]
	TIME [epoch: 21.3 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24203915960506758		[learning rate: 0.001927]
	Learning Rate: 0.00192696
	LOSS [training: 0.24203915960506758 | validation: 0.2112110797375662]
	TIME [epoch: 21.2 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24132572644818365		[learning rate: 0.0019201]
	Learning Rate: 0.00192014
	LOSS [training: 0.24132572644818365 | validation: 0.2167787513860247]
	TIME [epoch: 21.2 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2401061313387931		[learning rate: 0.0019134]
	Learning Rate: 0.00191335
	LOSS [training: 0.2401061313387931 | validation: 0.19361340794215037]
	TIME [epoch: 21.2 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15_20240716_142138/states/model_facs_v3_dec1b_2dpca_v15_517.pth
	Model improved!!!
EPOCH 518/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.251934121005248		[learning rate: 0.0019066]
	Learning Rate: 0.00190659
	LOSS [training: 0.251934121005248 | validation: 0.21758129065324616]
	TIME [epoch: 21.2 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2438113489013344		[learning rate: 0.0018998]
	Learning Rate: 0.00189984
	LOSS [training: 0.2438113489013344 | validation: 0.22223962796901073]
	TIME [epoch: 21.2 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24780867482793326		[learning rate: 0.0018931]
	Learning Rate: 0.00189313
	LOSS [training: 0.24780867482793326 | validation: 0.2158688476187672]
	TIME [epoch: 21.2 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24253343518943193		[learning rate: 0.0018864]
	Learning Rate: 0.00188643
	LOSS [training: 0.24253343518943193 | validation: 0.20562648483713844]
	TIME [epoch: 21.3 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24695128691369284		[learning rate: 0.0018798]
	Learning Rate: 0.00187976
	LOSS [training: 0.24695128691369284 | validation: 0.21181736240703697]
	TIME [epoch: 21.2 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24042802756765877		[learning rate: 0.0018731]
	Learning Rate: 0.00187311
	LOSS [training: 0.24042802756765877 | validation: 0.20756846314622912]
	TIME [epoch: 21.2 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24635033898891012		[learning rate: 0.0018665]
	Learning Rate: 0.00186649
	LOSS [training: 0.24635033898891012 | validation: 0.2151964332275389]
	TIME [epoch: 21.2 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2493322528421106		[learning rate: 0.0018599]
	Learning Rate: 0.00185989
	LOSS [training: 0.2493322528421106 | validation: 0.22458594820538083]
	TIME [epoch: 21.2 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24853844680840861		[learning rate: 0.0018533]
	Learning Rate: 0.00185331
	LOSS [training: 0.24853844680840861 | validation: 0.2206166976125675]
	TIME [epoch: 21.2 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24404745305488565		[learning rate: 0.0018468]
	Learning Rate: 0.00184676
	LOSS [training: 0.24404745305488565 | validation: 0.20696741356690493]
	TIME [epoch: 21.2 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24409756795241502		[learning rate: 0.0018402]
	Learning Rate: 0.00184023
	LOSS [training: 0.24409756795241502 | validation: 0.21166896156590648]
	TIME [epoch: 21.2 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2489277059899785		[learning rate: 0.0018337]
	Learning Rate: 0.00183372
	LOSS [training: 0.2489277059899785 | validation: 0.2080224987351143]
	TIME [epoch: 21.2 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25077003706473355		[learning rate: 0.0018272]
	Learning Rate: 0.00182724
	LOSS [training: 0.25077003706473355 | validation: 0.22189035184919734]
	TIME [epoch: 21.3 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2503750994027821		[learning rate: 0.0018208]
	Learning Rate: 0.00182078
	LOSS [training: 0.2503750994027821 | validation: 0.21168234412230502]
	TIME [epoch: 21.2 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23950338419901332		[learning rate: 0.0018143]
	Learning Rate: 0.00181434
	LOSS [training: 0.23950338419901332 | validation: 0.21022106898362475]
	TIME [epoch: 21.2 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.246858180848588		[learning rate: 0.0018079]
	Learning Rate: 0.00180792
	LOSS [training: 0.246858180848588 | validation: 0.2100185702685767]
	TIME [epoch: 21.2 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24043975071587664		[learning rate: 0.0018015]
	Learning Rate: 0.00180153
	LOSS [training: 0.24043975071587664 | validation: 0.20142146026629168]
	TIME [epoch: 21.3 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24776052499687196		[learning rate: 0.0017952]
	Learning Rate: 0.00179516
	LOSS [training: 0.24776052499687196 | validation: 0.20441715846620764]
	TIME [epoch: 21.2 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24352062035817978		[learning rate: 0.0017888]
	Learning Rate: 0.00178881
	LOSS [training: 0.24352062035817978 | validation: 0.21201859732384926]
	TIME [epoch: 21.2 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24278506989061532		[learning rate: 0.0017825]
	Learning Rate: 0.00178248
	LOSS [training: 0.24278506989061532 | validation: 0.21414195144183162]
	TIME [epoch: 21.2 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25636116528849934		[learning rate: 0.0017762]
	Learning Rate: 0.00177618
	LOSS [training: 0.25636116528849934 | validation: 0.2059845107472022]
	TIME [epoch: 21.2 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2484688487527258		[learning rate: 0.0017699]
	Learning Rate: 0.0017699
	LOSS [training: 0.2484688487527258 | validation: 0.2116835659012608]
	TIME [epoch: 21.2 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23792321044802056		[learning rate: 0.0017636]
	Learning Rate: 0.00176364
	LOSS [training: 0.23792321044802056 | validation: 0.21154823643467932]
	TIME [epoch: 21.2 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24771021396736484		[learning rate: 0.0017574]
	Learning Rate: 0.0017574
	LOSS [training: 0.24771021396736484 | validation: 0.2067693389123197]
	TIME [epoch: 21.2 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24898014314533637		[learning rate: 0.0017512]
	Learning Rate: 0.00175119
	LOSS [training: 0.24898014314533637 | validation: 0.20326761163017312]
	TIME [epoch: 21.2 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24001200270071332		[learning rate: 0.001745]
	Learning Rate: 0.001745
	LOSS [training: 0.24001200270071332 | validation: 0.22090019242596687]
	TIME [epoch: 21.2 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.238878986360489		[learning rate: 0.0017388]
	Learning Rate: 0.00173883
	LOSS [training: 0.238878986360489 | validation: 0.20223180843939917]
	TIME [epoch: 21.3 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23407970085445615		[learning rate: 0.0017327]
	Learning Rate: 0.00173268
	LOSS [training: 0.23407970085445615 | validation: 0.20486153510235425]
	TIME [epoch: 21.3 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2423820167777999		[learning rate: 0.0017266]
	Learning Rate: 0.00172655
	LOSS [training: 0.2423820167777999 | validation: 0.21193597106165893]
	TIME [epoch: 21.2 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23814105357028567		[learning rate: 0.0017204]
	Learning Rate: 0.00172045
	LOSS [training: 0.23814105357028567 | validation: 0.21455075594316653]
	TIME [epoch: 21.2 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24092757332393502		[learning rate: 0.0017144]
	Learning Rate: 0.00171436
	LOSS [training: 0.24092757332393502 | validation: 0.20410867108454456]
	TIME [epoch: 21.3 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2468351059283441		[learning rate: 0.0017083]
	Learning Rate: 0.0017083
	LOSS [training: 0.2468351059283441 | validation: 0.20107805746400348]
	TIME [epoch: 21.3 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24358512449928096		[learning rate: 0.0017023]
	Learning Rate: 0.00170226
	LOSS [training: 0.24358512449928096 | validation: 0.21251802215337318]
	TIME [epoch: 21.2 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2565060483362618		[learning rate: 0.0016962]
	Learning Rate: 0.00169624
	LOSS [training: 0.2565060483362618 | validation: 0.19995371673988674]
	TIME [epoch: 21.2 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24688302465403886		[learning rate: 0.0016902]
	Learning Rate: 0.00169024
	LOSS [training: 0.24688302465403886 | validation: 0.2064806909900347]
	TIME [epoch: 21.2 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23780762750894713		[learning rate: 0.0016843]
	Learning Rate: 0.00168426
	LOSS [training: 0.23780762750894713 | validation: 0.20258661973791656]
	TIME [epoch: 21.2 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25078767101057586		[learning rate: 0.0016783]
	Learning Rate: 0.00167831
	LOSS [training: 0.25078767101057586 | validation: 0.20319048567058498]
	TIME [epoch: 21.2 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2383009103501651		[learning rate: 0.0016724]
	Learning Rate: 0.00167237
	LOSS [training: 0.2383009103501651 | validation: 0.21691542110752055]
	TIME [epoch: 21.3 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25083727628721086		[learning rate: 0.0016665]
	Learning Rate: 0.00166646
	LOSS [training: 0.25083727628721086 | validation: 0.2169222746559595]
	TIME [epoch: 21.2 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23851750167837962		[learning rate: 0.0016606]
	Learning Rate: 0.00166057
	LOSS [training: 0.23851750167837962 | validation: 0.20816106729699246]
	TIME [epoch: 21.2 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25803645321283936		[learning rate: 0.0016547]
	Learning Rate: 0.00165469
	LOSS [training: 0.25803645321283936 | validation: 0.2164176390508381]
	TIME [epoch: 21.1 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2469344011734597		[learning rate: 0.0016488]
	Learning Rate: 0.00164884
	LOSS [training: 0.2469344011734597 | validation: 0.20213246272066604]
	TIME [epoch: 21 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23538868512234803		[learning rate: 0.001643]
	Learning Rate: 0.00164301
	LOSS [training: 0.23538868512234803 | validation: 0.20493854422253074]
	TIME [epoch: 21 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24934583633984905		[learning rate: 0.0016372]
	Learning Rate: 0.0016372
	LOSS [training: 0.24934583633984905 | validation: 0.19992088361480043]
	TIME [epoch: 21.1 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24933083746820192		[learning rate: 0.0016314]
	Learning Rate: 0.00163141
	LOSS [training: 0.24933083746820192 | validation: 0.21175958351412402]
	TIME [epoch: 21 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25008547530648595		[learning rate: 0.0016256]
	Learning Rate: 0.00162564
	LOSS [training: 0.25008547530648595 | validation: 0.2213663136624912]
	TIME [epoch: 21 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2434552470704742		[learning rate: 0.0016199]
	Learning Rate: 0.0016199
	LOSS [training: 0.2434552470704742 | validation: 0.21129258218531075]
	TIME [epoch: 21.2 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2557723783199391		[learning rate: 0.0016142]
	Learning Rate: 0.00161417
	LOSS [training: 0.2557723783199391 | validation: 0.196754252674118]
	TIME [epoch: 21.3 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24317649631688987		[learning rate: 0.0016085]
	Learning Rate: 0.00160846
	LOSS [training: 0.24317649631688987 | validation: 0.21670954051485775]
	TIME [epoch: 21.3 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25115945840912307		[learning rate: 0.0016028]
	Learning Rate: 0.00160277
	LOSS [training: 0.25115945840912307 | validation: 0.20232269277366904]
	TIME [epoch: 21.2 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24341258841393162		[learning rate: 0.0015971]
	Learning Rate: 0.0015971
	LOSS [training: 0.24341258841393162 | validation: 0.2118989008673143]
	TIME [epoch: 21.2 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23140767956247654		[learning rate: 0.0015915]
	Learning Rate: 0.00159146
	LOSS [training: 0.23140767956247654 | validation: 0.20555741139511077]
	TIME [epoch: 21.2 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2546488271432546		[learning rate: 0.0015858]
	Learning Rate: 0.00158583
	LOSS [training: 0.2546488271432546 | validation: 0.20903700539000672]
	TIME [epoch: 21.2 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23863932210763925		[learning rate: 0.0015802]
	Learning Rate: 0.00158022
	LOSS [training: 0.23863932210763925 | validation: 0.1979746143124339]
	TIME [epoch: 21.2 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24213928216723804		[learning rate: 0.0015746]
	Learning Rate: 0.00157463
	LOSS [training: 0.24213928216723804 | validation: 0.22250681408746495]
	TIME [epoch: 21.2 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2586184762897342		[learning rate: 0.0015691]
	Learning Rate: 0.00156907
	LOSS [training: 0.2586184762897342 | validation: 0.21757357662082044]
	TIME [epoch: 21.3 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2426637777944087		[learning rate: 0.0015635]
	Learning Rate: 0.00156352
	LOSS [training: 0.2426637777944087 | validation: 0.21219190359263526]
	TIME [epoch: 21.2 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2420479348469676		[learning rate: 0.001558]
	Learning Rate: 0.00155799
	LOSS [training: 0.2420479348469676 | validation: 0.2029261699424006]
	TIME [epoch: 21.3 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23958817825687215		[learning rate: 0.0015525]
	Learning Rate: 0.00155248
	LOSS [training: 0.23958817825687215 | validation: 0.1999399459171965]
	TIME [epoch: 21.2 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2449414371988147		[learning rate: 0.001547]
	Learning Rate: 0.00154699
	LOSS [training: 0.2449414371988147 | validation: 0.20761370343162794]
	TIME [epoch: 21.2 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25069631390758884		[learning rate: 0.0015415]
	Learning Rate: 0.00154152
	LOSS [training: 0.25069631390758884 | validation: 0.21559579193920655]
	TIME [epoch: 21.2 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24178300444797537		[learning rate: 0.0015361]
	Learning Rate: 0.00153607
	LOSS [training: 0.24178300444797537 | validation: 0.20888312902457656]
	TIME [epoch: 21.3 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2507091453017794		[learning rate: 0.0015306]
	Learning Rate: 0.00153064
	LOSS [training: 0.2507091453017794 | validation: 0.2081797434221186]
	TIME [epoch: 21.2 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25374985853347226		[learning rate: 0.0015252]
	Learning Rate: 0.00152522
	LOSS [training: 0.25374985853347226 | validation: 0.19351551129219746]
	TIME [epoch: 21.2 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15_20240716_142138/states/model_facs_v3_dec1b_2dpca_v15_581.pth
	Model improved!!!
EPOCH 582/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24768637073579428		[learning rate: 0.0015198]
	Learning Rate: 0.00151983
	LOSS [training: 0.24768637073579428 | validation: 0.2202351321205657]
	TIME [epoch: 21.2 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24911017891331813		[learning rate: 0.0015145]
	Learning Rate: 0.00151446
	LOSS [training: 0.24911017891331813 | validation: 0.21881852171495492]
	TIME [epoch: 21.2 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24896874953229206		[learning rate: 0.0015091]
	Learning Rate: 0.0015091
	LOSS [training: 0.24896874953229206 | validation: 0.20528702236382515]
	TIME [epoch: 21.2 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23993596759543612		[learning rate: 0.0015038]
	Learning Rate: 0.00150376
	LOSS [training: 0.23993596759543612 | validation: 0.21377045446732718]
	TIME [epoch: 21.3 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25301682110039503		[learning rate: 0.0014984]
	Learning Rate: 0.00149845
	LOSS [training: 0.25301682110039503 | validation: 0.20742853142656364]
	TIME [epoch: 21.2 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24435066630211355		[learning rate: 0.0014931]
	Learning Rate: 0.00149315
	LOSS [training: 0.24435066630211355 | validation: 0.1968231886022866]
	TIME [epoch: 21.2 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24950982088068427		[learning rate: 0.0014879]
	Learning Rate: 0.00148787
	LOSS [training: 0.24950982088068427 | validation: 0.20499176444566455]
	TIME [epoch: 21.3 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24655190904407812		[learning rate: 0.0014826]
	Learning Rate: 0.00148261
	LOSS [training: 0.24655190904407812 | validation: 0.20409722876974828]
	TIME [epoch: 21.3 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24378811029858172		[learning rate: 0.0014774]
	Learning Rate: 0.00147736
	LOSS [training: 0.24378811029858172 | validation: 0.1986378772451899]
	TIME [epoch: 21.3 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2531216421050258		[learning rate: 0.0014721]
	Learning Rate: 0.00147214
	LOSS [training: 0.2531216421050258 | validation: 0.21167662162065642]
	TIME [epoch: 21.2 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2389485402222984		[learning rate: 0.0014669]
	Learning Rate: 0.00146693
	LOSS [training: 0.2389485402222984 | validation: 0.20166027109743342]
	TIME [epoch: 21.2 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23564131457395154		[learning rate: 0.0014617]
	Learning Rate: 0.00146175
	LOSS [training: 0.23564131457395154 | validation: 0.20023825055583844]
	TIME [epoch: 21.3 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24339168777771877		[learning rate: 0.0014566]
	Learning Rate: 0.00145658
	LOSS [training: 0.24339168777771877 | validation: 0.2116958093997227]
	TIME [epoch: 21.2 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2500550668182859		[learning rate: 0.0014514]
	Learning Rate: 0.00145143
	LOSS [training: 0.2500550668182859 | validation: 0.215598057668754]
	TIME [epoch: 21.2 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2508542492991159		[learning rate: 0.0014463]
	Learning Rate: 0.00144629
	LOSS [training: 0.2508542492991159 | validation: 0.2062860943906361]
	TIME [epoch: 21.3 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2372843850974373		[learning rate: 0.0014412]
	Learning Rate: 0.00144118
	LOSS [training: 0.2372843850974373 | validation: 0.2069759212910789]
	TIME [epoch: 21.3 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25709138128542613		[learning rate: 0.0014361]
	Learning Rate: 0.00143608
	LOSS [training: 0.25709138128542613 | validation: 0.20679059003392694]
	TIME [epoch: 21.3 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23835314351851936		[learning rate: 0.001431]
	Learning Rate: 0.001431
	LOSS [training: 0.23835314351851936 | validation: 0.2065953850497828]
	TIME [epoch: 21.2 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.236218223238169		[learning rate: 0.0014259]
	Learning Rate: 0.00142594
	LOSS [training: 0.236218223238169 | validation: 0.21079286635302052]
	TIME [epoch: 21.3 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23401291239350455		[learning rate: 0.0014209]
	Learning Rate: 0.0014209
	LOSS [training: 0.23401291239350455 | validation: 0.2133761854413246]
	TIME [epoch: 21.3 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2506529374957164		[learning rate: 0.0014159]
	Learning Rate: 0.00141588
	LOSS [training: 0.2506529374957164 | validation: 0.2062063044993371]
	TIME [epoch: 21.3 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24332662280463535		[learning rate: 0.0014109]
	Learning Rate: 0.00141087
	LOSS [training: 0.24332662280463535 | validation: 0.2159319829631877]
	TIME [epoch: 21.3 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.256932352122444		[learning rate: 0.0014059]
	Learning Rate: 0.00140588
	LOSS [training: 0.256932352122444 | validation: 0.21441934487692285]
	TIME [epoch: 21.3 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24211048175077876		[learning rate: 0.0014009]
	Learning Rate: 0.00140091
	LOSS [training: 0.24211048175077876 | validation: 0.20024310444385898]
	TIME [epoch: 21.3 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.251414190155541		[learning rate: 0.001396]
	Learning Rate: 0.00139596
	LOSS [training: 0.251414190155541 | validation: 0.19147794831917414]
	TIME [epoch: 21.3 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15_20240716_142138/states/model_facs_v3_dec1b_2dpca_v15_606.pth
	Model improved!!!
EPOCH 607/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23821383231495738		[learning rate: 0.001391]
	Learning Rate: 0.00139102
	LOSS [training: 0.23821383231495738 | validation: 0.20813449287715557]
	TIME [epoch: 21.2 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23835686773821432		[learning rate: 0.0013861]
	Learning Rate: 0.0013861
	LOSS [training: 0.23835686773821432 | validation: 0.21151304903690357]
	TIME [epoch: 21.2 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23796745042396672		[learning rate: 0.0013812]
	Learning Rate: 0.0013812
	LOSS [training: 0.23796745042396672 | validation: 0.2134342781590548]
	TIME [epoch: 21.2 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24369483568506078		[learning rate: 0.0013763]
	Learning Rate: 0.00137632
	LOSS [training: 0.24369483568506078 | validation: 0.2101572738874918]
	TIME [epoch: 21.2 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24315217132203207		[learning rate: 0.0013714]
	Learning Rate: 0.00137145
	LOSS [training: 0.24315217132203207 | validation: 0.2134411327104737]
	TIME [epoch: 21.2 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24918103938256786		[learning rate: 0.0013666]
	Learning Rate: 0.0013666
	LOSS [training: 0.24918103938256786 | validation: 0.21419186402381948]
	TIME [epoch: 21.2 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2354742611268623		[learning rate: 0.0013618]
	Learning Rate: 0.00136177
	LOSS [training: 0.2354742611268623 | validation: 0.2088460367750821]
	TIME [epoch: 21.2 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23644450917202317		[learning rate: 0.001357]
	Learning Rate: 0.00135695
	LOSS [training: 0.23644450917202317 | validation: 0.21402798734401998]
	TIME [epoch: 21.2 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24750434778278985		[learning rate: 0.0013522]
	Learning Rate: 0.00135215
	LOSS [training: 0.24750434778278985 | validation: 0.21257877925138646]
	TIME [epoch: 21.2 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24604096642257664		[learning rate: 0.0013474]
	Learning Rate: 0.00134737
	LOSS [training: 0.24604096642257664 | validation: 0.20930236067413133]
	TIME [epoch: 21.1 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2402903274292103		[learning rate: 0.0013426]
	Learning Rate: 0.00134261
	LOSS [training: 0.2402903274292103 | validation: 0.2066092825288166]
	TIME [epoch: 21.2 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24962427342207757		[learning rate: 0.0013379]
	Learning Rate: 0.00133786
	LOSS [training: 0.24962427342207757 | validation: 0.21304907608985107]
	TIME [epoch: 21.3 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2364782275431586		[learning rate: 0.0013331]
	Learning Rate: 0.00133313
	LOSS [training: 0.2364782275431586 | validation: 0.19473077322855098]
	TIME [epoch: 21.2 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25166947239844667		[learning rate: 0.0013284]
	Learning Rate: 0.00132841
	LOSS [training: 0.25166947239844667 | validation: 0.2032732264855852]
	TIME [epoch: 21.2 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23567879684459603		[learning rate: 0.0013237]
	Learning Rate: 0.00132372
	LOSS [training: 0.23567879684459603 | validation: 0.20369971466610712]
	TIME [epoch: 21.2 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2526305970685061		[learning rate: 0.001319]
	Learning Rate: 0.00131904
	LOSS [training: 0.2526305970685061 | validation: 0.20629959239429105]
	TIME [epoch: 21.3 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2446886447842426		[learning rate: 0.0013144]
	Learning Rate: 0.00131437
	LOSS [training: 0.2446886447842426 | validation: 0.20009232779030692]
	TIME [epoch: 21.3 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23970767379999233		[learning rate: 0.0013097]
	Learning Rate: 0.00130972
	LOSS [training: 0.23970767379999233 | validation: 0.19772024612963818]
	TIME [epoch: 21.3 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23603667033556272		[learning rate: 0.0013051]
	Learning Rate: 0.00130509
	LOSS [training: 0.23603667033556272 | validation: 0.2134718193994944]
	TIME [epoch: 21.2 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2435718064649397		[learning rate: 0.0013005]
	Learning Rate: 0.00130048
	LOSS [training: 0.2435718064649397 | validation: 0.21936702765095012]
	TIME [epoch: 21.2 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25086950100327815		[learning rate: 0.0012959]
	Learning Rate: 0.00129588
	LOSS [training: 0.25086950100327815 | validation: 0.2162451518422246]
	TIME [epoch: 21.2 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2338317877602257		[learning rate: 0.0012913]
	Learning Rate: 0.0012913
	LOSS [training: 0.2338317877602257 | validation: 0.22249467585425958]
	TIME [epoch: 21.2 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24776628229584943		[learning rate: 0.0012867]
	Learning Rate: 0.00128673
	LOSS [training: 0.24776628229584943 | validation: 0.2066729885850543]
	TIME [epoch: 21.1 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24219771600096296		[learning rate: 0.0012822]
	Learning Rate: 0.00128218
	LOSS [training: 0.24219771600096296 | validation: 0.19627801265654915]
	TIME [epoch: 21.2 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24258931371970482		[learning rate: 0.0012776]
	Learning Rate: 0.00127765
	LOSS [training: 0.24258931371970482 | validation: 0.223115196447709]
	TIME [epoch: 21.2 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24816516068969005		[learning rate: 0.0012731]
	Learning Rate: 0.00127313
	LOSS [training: 0.24816516068969005 | validation: 0.20628918248191502]
	TIME [epoch: 21.2 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23373877784106734		[learning rate: 0.0012686]
	Learning Rate: 0.00126863
	LOSS [training: 0.23373877784106734 | validation: 0.20420887564416135]
	TIME [epoch: 21.1 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.22763759586144547		[learning rate: 0.0012641]
	Learning Rate: 0.00126414
	LOSS [training: 0.22763759586144547 | validation: 0.20106235216982887]
	TIME [epoch: 21.2 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23785978862505386		[learning rate: 0.0012597]
	Learning Rate: 0.00125967
	LOSS [training: 0.23785978862505386 | validation: 0.21803229554364179]
	TIME [epoch: 21.2 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23983811429824362		[learning rate: 0.0012552]
	Learning Rate: 0.00125521
	LOSS [training: 0.23983811429824362 | validation: 0.22133618838273]
	TIME [epoch: 21.1 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2445978022797386		[learning rate: 0.0012508]
	Learning Rate: 0.00125078
	LOSS [training: 0.2445978022797386 | validation: 0.20938149563904754]
	TIME [epoch: 21.1 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24692758892164088		[learning rate: 0.0012464]
	Learning Rate: 0.00124635
	LOSS [training: 0.24692758892164088 | validation: 0.2109850024947443]
	TIME [epoch: 21.1 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2362763359087012		[learning rate: 0.0012419]
	Learning Rate: 0.00124195
	LOSS [training: 0.2362763359087012 | validation: 0.20894065587697427]
	TIME [epoch: 21.2 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24045420004755455		[learning rate: 0.0012376]
	Learning Rate: 0.00123755
	LOSS [training: 0.24045420004755455 | validation: 0.2045739155777148]
	TIME [epoch: 21.2 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2530027713357767		[learning rate: 0.0012332]
	Learning Rate: 0.00123318
	LOSS [training: 0.2530027713357767 | validation: 0.20491759083280942]
	TIME [epoch: 21.2 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2448769637142095		[learning rate: 0.0012288]
	Learning Rate: 0.00122882
	LOSS [training: 0.2448769637142095 | validation: 0.19730675642289588]
	TIME [epoch: 21.2 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2288143997677009		[learning rate: 0.0012245]
	Learning Rate: 0.00122447
	LOSS [training: 0.2288143997677009 | validation: 0.2065375883896957]
	TIME [epoch: 21.2 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24165687701469904		[learning rate: 0.0012201]
	Learning Rate: 0.00122014
	LOSS [training: 0.24165687701469904 | validation: 0.20595351469276882]
	TIME [epoch: 21.2 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.251231898770687		[learning rate: 0.0012158]
	Learning Rate: 0.00121583
	LOSS [training: 0.251231898770687 | validation: 0.20779875660794472]
	TIME [epoch: 21.2 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2489140722580675		[learning rate: 0.0012115]
	Learning Rate: 0.00121153
	LOSS [training: 0.2489140722580675 | validation: 0.20348238122418114]
	TIME [epoch: 21.1 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25237000549467054		[learning rate: 0.0012072]
	Learning Rate: 0.00120724
	LOSS [training: 0.25237000549467054 | validation: 0.20822797493407705]
	TIME [epoch: 21.2 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24113632476270522		[learning rate: 0.001203]
	Learning Rate: 0.00120297
	LOSS [training: 0.24113632476270522 | validation: 0.21187732319342803]
	TIME [epoch: 21.1 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24200232600785143		[learning rate: 0.0011987]
	Learning Rate: 0.00119872
	LOSS [training: 0.24200232600785143 | validation: 0.19870995466712177]
	TIME [epoch: 21.1 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23446812104564863		[learning rate: 0.0011945]
	Learning Rate: 0.00119448
	LOSS [training: 0.23446812104564863 | validation: 0.20865277804703938]
	TIME [epoch: 21.1 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24804333851631885		[learning rate: 0.0011903]
	Learning Rate: 0.00119026
	LOSS [training: 0.24804333851631885 | validation: 0.2120915578199604]
	TIME [epoch: 21.1 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2459429816076828		[learning rate: 0.001186]
	Learning Rate: 0.00118605
	LOSS [training: 0.2459429816076828 | validation: 0.21244443761588155]
	TIME [epoch: 21.2 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24954894273483116		[learning rate: 0.0011819]
	Learning Rate: 0.00118185
	LOSS [training: 0.24954894273483116 | validation: 0.20382585845048898]
	TIME [epoch: 21.1 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2522213571796909		[learning rate: 0.0011777]
	Learning Rate: 0.00117768
	LOSS [training: 0.2522213571796909 | validation: 0.21030158950702466]
	TIME [epoch: 21.2 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24140552042142946		[learning rate: 0.0011735]
	Learning Rate: 0.00117351
	LOSS [training: 0.24140552042142946 | validation: 0.2017664593045989]
	TIME [epoch: 21.1 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24096369432852457		[learning rate: 0.0011694]
	Learning Rate: 0.00116936
	LOSS [training: 0.24096369432852457 | validation: 0.22032029530311675]
	TIME [epoch: 21.1 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24132912957496666		[learning rate: 0.0011652]
	Learning Rate: 0.00116523
	LOSS [training: 0.24132912957496666 | validation: 0.2098450030262292]
	TIME [epoch: 21.1 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25031598861748044		[learning rate: 0.0011611]
	Learning Rate: 0.00116111
	LOSS [training: 0.25031598861748044 | validation: 0.2103442050870436]
	TIME [epoch: 21.1 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.239888268507129		[learning rate: 0.001157]
	Learning Rate: 0.001157
	LOSS [training: 0.239888268507129 | validation: 0.20896458635887377]
	TIME [epoch: 21.1 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24631914854939327		[learning rate: 0.0011529]
	Learning Rate: 0.00115291
	LOSS [training: 0.24631914854939327 | validation: 0.20521942387172812]
	TIME [epoch: 21 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24589192643492264		[learning rate: 0.0011488]
	Learning Rate: 0.00114883
	LOSS [training: 0.24589192643492264 | validation: 0.2195459412459893]
	TIME [epoch: 21.1 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23910481058680133		[learning rate: 0.0011448]
	Learning Rate: 0.00114477
	LOSS [training: 0.23910481058680133 | validation: 0.19977352037250765]
	TIME [epoch: 21 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24629358445491378		[learning rate: 0.0011407]
	Learning Rate: 0.00114072
	LOSS [training: 0.24629358445491378 | validation: 0.2180196079373636]
	TIME [epoch: 21.1 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2363944462665427		[learning rate: 0.0011367]
	Learning Rate: 0.00113669
	LOSS [training: 0.2363944462665427 | validation: 0.20565377725257267]
	TIME [epoch: 21.1 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24420453844162002		[learning rate: 0.0011327]
	Learning Rate: 0.00113267
	LOSS [training: 0.24420453844162002 | validation: 0.20633749831338716]
	TIME [epoch: 21.1 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2454049062271114		[learning rate: 0.0011287]
	Learning Rate: 0.00112866
	LOSS [training: 0.2454049062271114 | validation: 0.2108873865606397]
	TIME [epoch: 21.2 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23647378621465642		[learning rate: 0.0011247]
	Learning Rate: 0.00112467
	LOSS [training: 0.23647378621465642 | validation: 0.21178248902511765]
	TIME [epoch: 21.2 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25125139962719034		[learning rate: 0.0011207]
	Learning Rate: 0.00112069
	LOSS [training: 0.25125139962719034 | validation: 0.20278315396596153]
	TIME [epoch: 21.2 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25292538119256686		[learning rate: 0.0011167]
	Learning Rate: 0.00111673
	LOSS [training: 0.25292538119256686 | validation: 0.20504646444550562]
	TIME [epoch: 21.1 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24686048074642697		[learning rate: 0.0011128]
	Learning Rate: 0.00111278
	LOSS [training: 0.24686048074642697 | validation: 0.21234411837342324]
	TIME [epoch: 21.2 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2411302040614064		[learning rate: 0.0011088]
	Learning Rate: 0.00110885
	LOSS [training: 0.2411302040614064 | validation: 0.20596623430765398]
	TIME [epoch: 21.2 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23660451909511318		[learning rate: 0.0011049]
	Learning Rate: 0.00110493
	LOSS [training: 0.23660451909511318 | validation: 0.20999602697374695]
	TIME [epoch: 21.2 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2490776650965729		[learning rate: 0.001101]
	Learning Rate: 0.00110102
	LOSS [training: 0.2490776650965729 | validation: 0.21091177939873482]
	TIME [epoch: 21.2 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24997954092417232		[learning rate: 0.0010971]
	Learning Rate: 0.00109713
	LOSS [training: 0.24997954092417232 | validation: 0.20835433436994427]
	TIME [epoch: 21.2 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24202911647120262		[learning rate: 0.0010932]
	Learning Rate: 0.00109325
	LOSS [training: 0.24202911647120262 | validation: 0.20806583905109832]
	TIME [epoch: 21.2 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24566280285123496		[learning rate: 0.0010894]
	Learning Rate: 0.00108938
	LOSS [training: 0.24566280285123496 | validation: 0.217980286997031]
	TIME [epoch: 21.1 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24833475036015454		[learning rate: 0.0010855]
	Learning Rate: 0.00108553
	LOSS [training: 0.24833475036015454 | validation: 0.20430972541258008]
	TIME [epoch: 21.1 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24407590544766086		[learning rate: 0.0010817]
	Learning Rate: 0.00108169
	LOSS [training: 0.24407590544766086 | validation: 0.2059156992552505]
	TIME [epoch: 21.2 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2528028468389208		[learning rate: 0.0010779]
	Learning Rate: 0.00107786
	LOSS [training: 0.2528028468389208 | validation: 0.21134099770498133]
	TIME [epoch: 21.1 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2437176290042836		[learning rate: 0.0010741]
	Learning Rate: 0.00107405
	LOSS [training: 0.2437176290042836 | validation: 0.19934455934945258]
	TIME [epoch: 21.2 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24374007060145206		[learning rate: 0.0010703]
	Learning Rate: 0.00107025
	LOSS [training: 0.24374007060145206 | validation: 0.2061072973296286]
	TIME [epoch: 21.2 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23672321884509082		[learning rate: 0.0010665]
	Learning Rate: 0.00106647
	LOSS [training: 0.23672321884509082 | validation: 0.20894098621770163]
	TIME [epoch: 21.2 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.241974381874515		[learning rate: 0.0010627]
	Learning Rate: 0.0010627
	LOSS [training: 0.241974381874515 | validation: 0.20917930105250418]
	TIME [epoch: 21.2 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25391268171540116		[learning rate: 0.0010589]
	Learning Rate: 0.00105894
	LOSS [training: 0.25391268171540116 | validation: 0.21699947195000568]
	TIME [epoch: 21.2 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2527772396779899		[learning rate: 0.0010552]
	Learning Rate: 0.0010552
	LOSS [training: 0.2527772396779899 | validation: 0.21850893927837065]
	TIME [epoch: 21.2 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23852818533163464		[learning rate: 0.0010515]
	Learning Rate: 0.00105147
	LOSS [training: 0.23852818533163464 | validation: 0.21213834355569716]
	TIME [epoch: 21.2 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24058183745817097		[learning rate: 0.0010477]
	Learning Rate: 0.00104775
	LOSS [training: 0.24058183745817097 | validation: 0.20778803038398977]
	TIME [epoch: 21.2 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24854059200450673		[learning rate: 0.001044]
	Learning Rate: 0.00104404
	LOSS [training: 0.24854059200450673 | validation: 0.20137147860915042]
	TIME [epoch: 21.2 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24087589140003987		[learning rate: 0.0010404]
	Learning Rate: 0.00104035
	LOSS [training: 0.24087589140003987 | validation: 0.1996209087207596]
	TIME [epoch: 21.1 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2413149585194059		[learning rate: 0.0010367]
	Learning Rate: 0.00103667
	LOSS [training: 0.2413149585194059 | validation: 0.1943017635980227]
	TIME [epoch: 21.1 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24126169211965243		[learning rate: 0.001033]
	Learning Rate: 0.00103301
	LOSS [training: 0.24126169211965243 | validation: 0.20688527728719103]
	TIME [epoch: 21.2 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24142661225571363		[learning rate: 0.0010294]
	Learning Rate: 0.00102935
	LOSS [training: 0.24142661225571363 | validation: 0.20255157649590352]
	TIME [epoch: 21.1 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2521650398590238		[learning rate: 0.0010257]
	Learning Rate: 0.00102571
	LOSS [training: 0.2521650398590238 | validation: 0.20002900532971185]
	TIME [epoch: 21.1 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23876198308733998		[learning rate: 0.0010221]
	Learning Rate: 0.00102209
	LOSS [training: 0.23876198308733998 | validation: 0.20739932544126397]
	TIME [epoch: 21.1 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24081354876953678		[learning rate: 0.0010185]
	Learning Rate: 0.00101847
	LOSS [training: 0.24081354876953678 | validation: 0.2135678382247468]
	TIME [epoch: 21.1 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2469261124006845		[learning rate: 0.0010149]
	Learning Rate: 0.00101487
	LOSS [training: 0.2469261124006845 | validation: 0.19871297334444227]
	TIME [epoch: 21.1 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2478286795928191		[learning rate: 0.0010113]
	Learning Rate: 0.00101128
	LOSS [training: 0.2478286795928191 | validation: 0.20849295931830913]
	TIME [epoch: 21.1 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23872019043949974		[learning rate: 0.0010077]
	Learning Rate: 0.0010077
	LOSS [training: 0.23872019043949974 | validation: 0.20130769439037297]
	TIME [epoch: 21.1 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23347090939305248		[learning rate: 0.0010041]
	Learning Rate: 0.00100414
	LOSS [training: 0.23347090939305248 | validation: 0.21727220797861202]
	TIME [epoch: 21.2 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24468179716160887		[learning rate: 0.0010006]
	Learning Rate: 0.00100059
	LOSS [training: 0.24468179716160887 | validation: 0.20580629250801968]
	TIME [epoch: 21.1 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24134797620083479		[learning rate: 0.00099705]
	Learning Rate: 0.000997052
	LOSS [training: 0.24134797620083479 | validation: 0.22133963946850993]
	TIME [epoch: 21.1 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23762853071649406		[learning rate: 0.00099353]
	Learning Rate: 0.000993527
	LOSS [training: 0.23762853071649406 | validation: 0.21004677174106007]
	TIME [epoch: 21.1 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24901026405112883		[learning rate: 0.00099001]
	Learning Rate: 0.000990013
	LOSS [training: 0.24901026405112883 | validation: 0.20421954149292917]
	TIME [epoch: 21.1 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24201506673120474		[learning rate: 0.00098651]
	Learning Rate: 0.000986513
	LOSS [training: 0.24201506673120474 | validation: 0.2079665621987718]
	TIME [epoch: 21.1 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2315524801981865		[learning rate: 0.00098302]
	Learning Rate: 0.000983024
	LOSS [training: 0.2315524801981865 | validation: 0.20358292872523207]
	TIME [epoch: 21.1 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24595765510914835		[learning rate: 0.00097955]
	Learning Rate: 0.000979548
	LOSS [training: 0.24595765510914835 | validation: 0.20937560722744122]
	TIME [epoch: 21.1 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2471650642244614		[learning rate: 0.00097608]
	Learning Rate: 0.000976084
	LOSS [training: 0.2471650642244614 | validation: 0.2048697654325812]
	TIME [epoch: 21.1 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2400972797430115		[learning rate: 0.00097263]
	Learning Rate: 0.000972632
	LOSS [training: 0.2400972797430115 | validation: 0.20354885898212297]
	TIME [epoch: 21.2 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2523795563592838		[learning rate: 0.00096919]
	Learning Rate: 0.000969193
	LOSS [training: 0.2523795563592838 | validation: 0.2096362275367885]
	TIME [epoch: 21.1 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24536628503495117		[learning rate: 0.00096577]
	Learning Rate: 0.000965766
	LOSS [training: 0.24536628503495117 | validation: 0.20728481614758154]
	TIME [epoch: 21.1 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24725622349454782		[learning rate: 0.00096235]
	Learning Rate: 0.000962351
	LOSS [training: 0.24725622349454782 | validation: 0.19343072267512634]
	TIME [epoch: 21.2 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2402964646886437		[learning rate: 0.00095895]
	Learning Rate: 0.000958948
	LOSS [training: 0.2402964646886437 | validation: 0.20586106088471606]
	TIME [epoch: 21 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2536559514890854		[learning rate: 0.00095556]
	Learning Rate: 0.000955557
	LOSS [training: 0.2536559514890854 | validation: 0.20382940428890306]
	TIME [epoch: 21.1 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.22974632193653685		[learning rate: 0.00095218]
	Learning Rate: 0.000952178
	LOSS [training: 0.22974632193653685 | validation: 0.20322263877227434]
	TIME [epoch: 21.2 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24636840695758797		[learning rate: 0.00094881]
	Learning Rate: 0.00094881
	LOSS [training: 0.24636840695758797 | validation: 0.21876358342810648]
	TIME [epoch: 21.2 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23957126652573504		[learning rate: 0.00094546]
	Learning Rate: 0.000945455
	LOSS [training: 0.23957126652573504 | validation: 0.20638220794052167]
	TIME [epoch: 21.1 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24086128543172292		[learning rate: 0.00094211]
	Learning Rate: 0.000942112
	LOSS [training: 0.24086128543172292 | validation: 0.21307827962429018]
	TIME [epoch: 21.1 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2407853750732225		[learning rate: 0.00093878]
	Learning Rate: 0.000938781
	LOSS [training: 0.2407853750732225 | validation: 0.20811720279621498]
	TIME [epoch: 21.3 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.236101180393382		[learning rate: 0.00093546]
	Learning Rate: 0.000935461
	LOSS [training: 0.236101180393382 | validation: 0.19731222871149684]
	TIME [epoch: 21.1 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24408581935278828		[learning rate: 0.00093215]
	Learning Rate: 0.000932153
	LOSS [training: 0.24408581935278828 | validation: 0.2125975150068992]
	TIME [epoch: 21.2 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24421117277661122		[learning rate: 0.00092886]
	Learning Rate: 0.000928857
	LOSS [training: 0.24421117277661122 | validation: 0.20812996757865312]
	TIME [epoch: 21.2 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24442425365073464		[learning rate: 0.00092557]
	Learning Rate: 0.000925572
	LOSS [training: 0.24442425365073464 | validation: 0.21421450986759974]
	TIME [epoch: 21.2 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24685325582078663		[learning rate: 0.0009223]
	Learning Rate: 0.000922299
	LOSS [training: 0.24685325582078663 | validation: 0.20901340423135442]
	TIME [epoch: 21.2 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24529323337124395		[learning rate: 0.00091904]
	Learning Rate: 0.000919038
	LOSS [training: 0.24529323337124395 | validation: 0.2126686117143774]
	TIME [epoch: 21.1 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24431320740980347		[learning rate: 0.00091579]
	Learning Rate: 0.000915788
	LOSS [training: 0.24431320740980347 | validation: 0.22789385148142877]
	TIME [epoch: 21.4 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23387702425269677		[learning rate: 0.00091255]
	Learning Rate: 0.000912549
	LOSS [training: 0.23387702425269677 | validation: 0.21511778094488304]
	TIME [epoch: 21.3 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2378120823426262		[learning rate: 0.00090932]
	Learning Rate: 0.000909323
	LOSS [training: 0.2378120823426262 | validation: 0.20722536425074325]
	TIME [epoch: 21.1 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23891918556214634		[learning rate: 0.00090611]
	Learning Rate: 0.000906107
	LOSS [training: 0.23891918556214634 | validation: 0.21621755049644223]
	TIME [epoch: 21.3 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23444113081077264		[learning rate: 0.0009029]
	Learning Rate: 0.000902903
	LOSS [training: 0.23444113081077264 | validation: 0.2053562333625945]
	TIME [epoch: 21.2 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24275401437688027		[learning rate: 0.00089971]
	Learning Rate: 0.00089971
	LOSS [training: 0.24275401437688027 | validation: 0.2140765801130283]
	TIME [epoch: 21.2 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24615937490250858		[learning rate: 0.00089653]
	Learning Rate: 0.000896529
	LOSS [training: 0.24615937490250858 | validation: 0.21121830764435798]
	TIME [epoch: 21.2 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24929846928377708		[learning rate: 0.00089336]
	Learning Rate: 0.000893358
	LOSS [training: 0.24929846928377708 | validation: 0.20045061600271907]
	TIME [epoch: 21.2 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24204147239096152		[learning rate: 0.0008902]
	Learning Rate: 0.000890199
	LOSS [training: 0.24204147239096152 | validation: 0.20870022232359972]
	TIME [epoch: 21.3 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.241090906184298		[learning rate: 0.00088705]
	Learning Rate: 0.000887051
	LOSS [training: 0.241090906184298 | validation: 0.21430195241221178]
	TIME [epoch: 21.2 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23656663620285448		[learning rate: 0.00088391]
	Learning Rate: 0.000883914
	LOSS [training: 0.23656663620285448 | validation: 0.2045317659565396]
	TIME [epoch: 21.3 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24149542631556983		[learning rate: 0.00088079]
	Learning Rate: 0.000880789
	LOSS [training: 0.24149542631556983 | validation: 0.21303800196232975]
	TIME [epoch: 21.1 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2377862318966196		[learning rate: 0.00087767]
	Learning Rate: 0.000877674
	LOSS [training: 0.2377862318966196 | validation: 0.22538137547234155]
	TIME [epoch: 21.1 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2407289226173015		[learning rate: 0.00087457]
	Learning Rate: 0.000874571
	LOSS [training: 0.2407289226173015 | validation: 0.208184680503768]
	TIME [epoch: 21.2 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24888262334355526		[learning rate: 0.00087148]
	Learning Rate: 0.000871478
	LOSS [training: 0.24888262334355526 | validation: 0.20718661322013845]
	TIME [epoch: 21.2 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24864128459198329		[learning rate: 0.0008684]
	Learning Rate: 0.000868396
	LOSS [training: 0.24864128459198329 | validation: 0.21020564264545222]
	TIME [epoch: 21.2 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23879788953905248		[learning rate: 0.00086533]
	Learning Rate: 0.000865326
	LOSS [training: 0.23879788953905248 | validation: 0.20491151713132716]
	TIME [epoch: 21.2 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24604169336981316		[learning rate: 0.00086227]
	Learning Rate: 0.000862266
	LOSS [training: 0.24604169336981316 | validation: 0.21131733267455993]
	TIME [epoch: 21.2 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.22915135246008767		[learning rate: 0.00085922]
	Learning Rate: 0.000859216
	LOSS [training: 0.22915135246008767 | validation: 0.22105831225219302]
	TIME [epoch: 21.2 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24492024997624662		[learning rate: 0.00085618]
	Learning Rate: 0.000856178
	LOSS [training: 0.24492024997624662 | validation: 0.20892154460874127]
	TIME [epoch: 21.1 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24014802730920723		[learning rate: 0.00085315]
	Learning Rate: 0.00085315
	LOSS [training: 0.24014802730920723 | validation: 0.21587536296758475]
	TIME [epoch: 21.2 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25092792018471205		[learning rate: 0.00085013]
	Learning Rate: 0.000850134
	LOSS [training: 0.25092792018471205 | validation: 0.2116650686714138]
	TIME [epoch: 21.2 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2503594457328915		[learning rate: 0.00084713]
	Learning Rate: 0.000847127
	LOSS [training: 0.2503594457328915 | validation: 0.20805618035505077]
	TIME [epoch: 21.2 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23363034861758206		[learning rate: 0.00084413]
	Learning Rate: 0.000844132
	LOSS [training: 0.23363034861758206 | validation: 0.19780151301298082]
	TIME [epoch: 21.3 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23256484033212824		[learning rate: 0.00084115]
	Learning Rate: 0.000841147
	LOSS [training: 0.23256484033212824 | validation: 0.21032398865758406]
	TIME [epoch: 21.2 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23473737355432137		[learning rate: 0.00083817]
	Learning Rate: 0.000838172
	LOSS [training: 0.23473737355432137 | validation: 0.21624588313723433]
	TIME [epoch: 21.2 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24756821736891352		[learning rate: 0.00083521]
	Learning Rate: 0.000835209
	LOSS [training: 0.24756821736891352 | validation: 0.2050499457941018]
	TIME [epoch: 21.2 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24847543404013828		[learning rate: 0.00083225]
	Learning Rate: 0.000832255
	LOSS [training: 0.24847543404013828 | validation: 0.2098304618174871]
	TIME [epoch: 21.2 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24708033025732065		[learning rate: 0.00082931]
	Learning Rate: 0.000829312
	LOSS [training: 0.24708033025732065 | validation: 0.20054675784054576]
	TIME [epoch: 21.2 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.231835548851094		[learning rate: 0.00082638]
	Learning Rate: 0.000826379
	LOSS [training: 0.231835548851094 | validation: 0.21937038996044117]
	TIME [epoch: 21.2 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2521540106505143		[learning rate: 0.00082346]
	Learning Rate: 0.000823457
	LOSS [training: 0.2521540106505143 | validation: 0.21164070244913868]
	TIME [epoch: 21 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2532737639151547		[learning rate: 0.00082055]
	Learning Rate: 0.000820545
	LOSS [training: 0.2532737639151547 | validation: 0.2078063968741708]
	TIME [epoch: 21.2 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2421387532716672		[learning rate: 0.00081764]
	Learning Rate: 0.000817644
	LOSS [training: 0.2421387532716672 | validation: 0.2030394353304656]
	TIME [epoch: 21.2 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24226742320893735		[learning rate: 0.00081475]
	Learning Rate: 0.000814752
	LOSS [training: 0.24226742320893735 | validation: 0.207753853196811]
	TIME [epoch: 21.2 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2439335817421827		[learning rate: 0.00081187]
	Learning Rate: 0.000811871
	LOSS [training: 0.2439335817421827 | validation: 0.2192417953894122]
	TIME [epoch: 21.2 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24187147540830609		[learning rate: 0.000809]
	Learning Rate: 0.000809
	LOSS [training: 0.24187147540830609 | validation: 0.21042334368781992]
	TIME [epoch: 21.2 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24701773133790825		[learning rate: 0.00080614]
	Learning Rate: 0.00080614
	LOSS [training: 0.24701773133790825 | validation: 0.2096322996753414]
	TIME [epoch: 21.2 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24933617964032292		[learning rate: 0.00080329]
	Learning Rate: 0.000803289
	LOSS [training: 0.24933617964032292 | validation: 0.19746122353157924]
	TIME [epoch: 21.2 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24133492194810868		[learning rate: 0.00080045]
	Learning Rate: 0.000800448
	LOSS [training: 0.24133492194810868 | validation: 0.20703244992173636]
	TIME [epoch: 21.1 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24492328154999812		[learning rate: 0.00079762]
	Learning Rate: 0.000797618
	LOSS [training: 0.24492328154999812 | validation: 0.2053849421496828]
	TIME [epoch: 21.2 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24545453060551092		[learning rate: 0.0007948]
	Learning Rate: 0.000794797
	LOSS [training: 0.24545453060551092 | validation: 0.20027636135776103]
	TIME [epoch: 21.3 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23732238256660496		[learning rate: 0.00079199]
	Learning Rate: 0.000791987
	LOSS [training: 0.23732238256660496 | validation: 0.20446386165057037]
	TIME [epoch: 21.2 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2373911854727854		[learning rate: 0.00078919]
	Learning Rate: 0.000789186
	LOSS [training: 0.2373911854727854 | validation: 0.21041976625251763]
	TIME [epoch: 21.3 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24616346322792546		[learning rate: 0.0007864]
	Learning Rate: 0.000786396
	LOSS [training: 0.24616346322792546 | validation: 0.21199909849850213]
	TIME [epoch: 21.3 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23525885633382185		[learning rate: 0.00078361]
	Learning Rate: 0.000783615
	LOSS [training: 0.23525885633382185 | validation: 0.21141294237800787]
	TIME [epoch: 21.3 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23521279437673745		[learning rate: 0.00078084]
	Learning Rate: 0.000780844
	LOSS [training: 0.23521279437673745 | validation: 0.223471158628967]
	TIME [epoch: 21.3 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23719249628503403		[learning rate: 0.00077808]
	Learning Rate: 0.000778082
	LOSS [training: 0.23719249628503403 | validation: 0.20271547910677862]
	TIME [epoch: 21.3 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2340994191349468		[learning rate: 0.00077533]
	Learning Rate: 0.000775331
	LOSS [training: 0.2340994191349468 | validation: 0.2114619420647203]
	TIME [epoch: 21.3 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24761302164811447		[learning rate: 0.00077259]
	Learning Rate: 0.000772589
	LOSS [training: 0.24761302164811447 | validation: 0.1944282904534263]
	TIME [epoch: 21.3 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24302291848538252		[learning rate: 0.00076986]
	Learning Rate: 0.000769857
	LOSS [training: 0.24302291848538252 | validation: 0.19327954513704784]
	TIME [epoch: 21.2 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2508391765914923		[learning rate: 0.00076714]
	Learning Rate: 0.000767135
	LOSS [training: 0.2508391765914923 | validation: 0.20076765598152485]
	TIME [epoch: 21.2 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24036390429783797		[learning rate: 0.00076442]
	Learning Rate: 0.000764422
	LOSS [training: 0.24036390429783797 | validation: 0.2213325804104091]
	TIME [epoch: 21.2 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23844348721216735		[learning rate: 0.00076172]
	Learning Rate: 0.000761719
	LOSS [training: 0.23844348721216735 | validation: 0.20873558879815962]
	TIME [epoch: 21.2 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.255468499929894		[learning rate: 0.00075903]
	Learning Rate: 0.000759026
	LOSS [training: 0.255468499929894 | validation: 0.2022857234599444]
	TIME [epoch: 21.1 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24721899655047927		[learning rate: 0.00075634]
	Learning Rate: 0.000756342
	LOSS [training: 0.24721899655047927 | validation: 0.21581464889056717]
	TIME [epoch: 21.1 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24322815712337664		[learning rate: 0.00075367]
	Learning Rate: 0.000753667
	LOSS [training: 0.24322815712337664 | validation: 0.2055158504017432]
	TIME [epoch: 21.1 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23173207004566665		[learning rate: 0.000751]
	Learning Rate: 0.000751002
	LOSS [training: 0.23173207004566665 | validation: 0.2145195358037723]
	TIME [epoch: 21.1 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23919715472175343		[learning rate: 0.00074835]
	Learning Rate: 0.000748346
	LOSS [training: 0.23919715472175343 | validation: 0.20787029686524425]
	TIME [epoch: 21.1 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2508934807563353		[learning rate: 0.0007457]
	Learning Rate: 0.0007457
	LOSS [training: 0.2508934807563353 | validation: 0.2067699437366362]
	TIME [epoch: 21.1 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23649986533522674		[learning rate: 0.00074306]
	Learning Rate: 0.000743063
	LOSS [training: 0.23649986533522674 | validation: 0.21141360729272485]
	TIME [epoch: 21.1 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23454425859013828		[learning rate: 0.00074044]
	Learning Rate: 0.000740435
	LOSS [training: 0.23454425859013828 | validation: 0.21045607000236366]
	TIME [epoch: 21.1 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2389836375186222		[learning rate: 0.00073782]
	Learning Rate: 0.000737817
	LOSS [training: 0.2389836375186222 | validation: 0.2086560351411828]
	TIME [epoch: 21.1 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23290089943785244		[learning rate: 0.00073521]
	Learning Rate: 0.000735208
	LOSS [training: 0.23290089943785244 | validation: 0.2088435998906478]
	TIME [epoch: 21.1 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24613109349552295		[learning rate: 0.00073261]
	Learning Rate: 0.000732608
	LOSS [training: 0.24613109349552295 | validation: 0.21089516828769678]
	TIME [epoch: 21.2 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25105811822080143		[learning rate: 0.00073002]
	Learning Rate: 0.000730018
	LOSS [training: 0.25105811822080143 | validation: 0.19953647638065447]
	TIME [epoch: 21.1 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2368630442243519		[learning rate: 0.00072744]
	Learning Rate: 0.000727436
	LOSS [training: 0.2368630442243519 | validation: 0.2080930139165889]
	TIME [epoch: 21.2 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24637756635231098		[learning rate: 0.00072486]
	Learning Rate: 0.000724864
	LOSS [training: 0.24637756635231098 | validation: 0.2086552311132046]
	TIME [epoch: 21.3 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23794579019419446		[learning rate: 0.0007223]
	Learning Rate: 0.000722301
	LOSS [training: 0.23794579019419446 | validation: 0.21119508864438052]
	TIME [epoch: 21.2 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23424239040224218		[learning rate: 0.00071975]
	Learning Rate: 0.000719746
	LOSS [training: 0.23424239040224218 | validation: 0.21725102589394987]
	TIME [epoch: 21.2 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2463763856173525		[learning rate: 0.0007172]
	Learning Rate: 0.000717201
	LOSS [training: 0.2463763856173525 | validation: 0.21312549563236655]
	TIME [epoch: 21.2 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24564328080191444		[learning rate: 0.00071467]
	Learning Rate: 0.000714665
	LOSS [training: 0.24564328080191444 | validation: 0.21478153680374548]
	TIME [epoch: 21.2 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24602867504563267		[learning rate: 0.00071214]
	Learning Rate: 0.000712138
	LOSS [training: 0.24602867504563267 | validation: 0.20680466632422964]
	TIME [epoch: 21.2 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24077470534120626		[learning rate: 0.00070962]
	Learning Rate: 0.00070962
	LOSS [training: 0.24077470534120626 | validation: 0.21883155206001317]
	TIME [epoch: 21.2 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.232443794646869		[learning rate: 0.00070711]
	Learning Rate: 0.00070711
	LOSS [training: 0.232443794646869 | validation: 0.20867440864627804]
	TIME [epoch: 21.2 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24220416998694427		[learning rate: 0.00070461]
	Learning Rate: 0.00070461
	LOSS [training: 0.24220416998694427 | validation: 0.20868002961539908]
	TIME [epoch: 21.2 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25021585109817795		[learning rate: 0.00070212]
	Learning Rate: 0.000702118
	LOSS [training: 0.25021585109817795 | validation: 0.21866323266558324]
	TIME [epoch: 21.2 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2450762336005888		[learning rate: 0.00069964]
	Learning Rate: 0.000699635
	LOSS [training: 0.2450762336005888 | validation: 0.20641469661115003]
	TIME [epoch: 21 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24479750637389444		[learning rate: 0.00069716]
	Learning Rate: 0.000697161
	LOSS [training: 0.24479750637389444 | validation: 0.20972706450117093]
	TIME [epoch: 21.2 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23128724920569974		[learning rate: 0.0006947]
	Learning Rate: 0.000694696
	LOSS [training: 0.23128724920569974 | validation: 0.1983312857381964]
	TIME [epoch: 21.2 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24196278337212065		[learning rate: 0.00069224]
	Learning Rate: 0.00069224
	LOSS [training: 0.24196278337212065 | validation: 0.20955200288863046]
	TIME [epoch: 21.2 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2517347354853939		[learning rate: 0.00068979]
	Learning Rate: 0.000689792
	LOSS [training: 0.2517347354853939 | validation: 0.2065819778831413]
	TIME [epoch: 21.1 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24641407872183985		[learning rate: 0.00068735]
	Learning Rate: 0.000687352
	LOSS [training: 0.24641407872183985 | validation: 0.19795625450096233]
	TIME [epoch: 21.2 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2287681570467862		[learning rate: 0.00068492]
	Learning Rate: 0.000684922
	LOSS [training: 0.2287681570467862 | validation: 0.20280367957946993]
	TIME [epoch: 21.1 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15_20240716_142138/states/model_facs_v3_dec1b_2dpca_v15_807.pth
Halted early. No improvement in validation loss for 200 epochs.
Finished training in 11322.453 seconds.
