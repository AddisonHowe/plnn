Args:
Namespace(name='model_facs_v4_dec2b_2dpca_v15', outdir='out/model_training/model_facs_v4_dec2b_2dpca_v15', training_data='data/training_data/facs_v4/pca/dec2_fitonsubset/transition2_subset_ce_pn_m_pc12/training', validation_data='data/training_data/facs_v4/pca/dec2_fitonsubset/transition2_subset_ce_pn_m_pc12/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=10, batch_size=50, patience=200, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, quadratic_a=1.0, quadratic_b=1.0, ndims=2, nparams=2, nsigs=2, ncells=100, ncells_sample=100, model_do_sample=False, dt=0.005, dt_schedule='stepped', dt_schedule_bounds=[50, 500, 1000], dt_schedule_scales=[0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', kernel='multiscale', bw_range=[0.2, 0.5, 0.9, 1.1, 1.3, 1.5, 2.0], optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 722447941

Training model...

Saving initial model state to: out/model_training/model_facs_v4_dec2b_2dpca_v15_20240718_190304/states/model_facs_v4_dec2b_2dpca_v15_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8354150530121288		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8354150530121288 | validation: 0.9270980990557613]
	TIME [epoch: 25.7 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v15_20240718_190304/states/model_facs_v4_dec2b_2dpca_v15_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6651310485270531		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6651310485270531 | validation: 0.8308335150654256]
	TIME [epoch: 3.52 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v15_20240718_190304/states/model_facs_v4_dec2b_2dpca_v15_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6177015246621115		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6177015246621115 | validation: 0.807349194601046]
	TIME [epoch: 3.54 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v15_20240718_190304/states/model_facs_v4_dec2b_2dpca_v15_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4895139608050614		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4895139608050614 | validation: 0.7828163334298612]
	TIME [epoch: 3.48 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v15_20240718_190304/states/model_facs_v4_dec2b_2dpca_v15_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5359609830901505		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5359609830901505 | validation: 0.6935832309556393]
	TIME [epoch: 3.52 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v15_20240718_190304/states/model_facs_v4_dec2b_2dpca_v15_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49694537040679776		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.49694537040679776 | validation: 0.6786898852573088]
	TIME [epoch: 3.54 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v15_20240718_190304/states/model_facs_v4_dec2b_2dpca_v15_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41876757787950875		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.41876757787950875 | validation: 0.6298661868506341]
	TIME [epoch: 3.51 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v15_20240718_190304/states/model_facs_v4_dec2b_2dpca_v15_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40460822678048813		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.40460822678048813 | validation: 0.6850965218239407]
	TIME [epoch: 3.54 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42261381033681567		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.42261381033681567 | validation: 0.5751946687084435]
	TIME [epoch: 3.53 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v15_20240718_190304/states/model_facs_v4_dec2b_2dpca_v15_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3623564998941524		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3623564998941524 | validation: 0.5751739926673167]
	TIME [epoch: 3.52 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v15_20240718_190304/states/model_facs_v4_dec2b_2dpca_v15_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3540348792106083		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3540348792106083 | validation: 0.5929232612277099]
	TIME [epoch: 3.5 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3215523011941377		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3215523011941377 | validation: 0.5286943531179912]
	TIME [epoch: 3.48 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v15_20240718_190304/states/model_facs_v4_dec2b_2dpca_v15_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29732936444277125		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.29732936444277125 | validation: 0.5501462682342664]
	TIME [epoch: 3.54 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3162574235218499		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3162574235218499 | validation: 0.5495161326021435]
	TIME [epoch: 3.54 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3152207675081719		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3152207675081719 | validation: 0.49399364874315976]
	TIME [epoch: 3.52 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v15_20240718_190304/states/model_facs_v4_dec2b_2dpca_v15_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28579718090516304		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.28579718090516304 | validation: 0.4604441972163683]
	TIME [epoch: 3.55 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v15_20240718_190304/states/model_facs_v4_dec2b_2dpca_v15_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3033643955734326		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3033643955734326 | validation: 0.5012969767164791]
	TIME [epoch: 3.51 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2674439614303039		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2674439614303039 | validation: 0.5794740213422237]
	TIME [epoch: 3.52 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3261534998267552		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3261534998267552 | validation: 0.5305433460945241]
	TIME [epoch: 3.5 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2947556989214365		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2947556989214365 | validation: 0.4446391372256664]
	TIME [epoch: 3.48 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v15_20240718_190304/states/model_facs_v4_dec2b_2dpca_v15_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26166390121326866		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.26166390121326866 | validation: 0.46656844631250405]
	TIME [epoch: 3.54 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2551627900802691		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2551627900802691 | validation: 0.4770138425515258]
	TIME [epoch: 3.54 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26000664733141166		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.26000664733141166 | validation: 0.44714999795814764]
	TIME [epoch: 3.51 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2187374486006276		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2187374486006276 | validation: 0.41621849742392275]
	TIME [epoch: 3.54 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v15_20240718_190304/states/model_facs_v4_dec2b_2dpca_v15_24.pth
	Model improved!!!
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20878440566364656		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20878440566364656 | validation: 0.5332533159651337]
	TIME [epoch: 3.52 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2343225652180733		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2343225652180733 | validation: 0.4702162265113269]
	TIME [epoch: 3.51 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22765659540646593		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22765659540646593 | validation: 0.3891115492428361]
	TIME [epoch: 3.51 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v15_20240718_190304/states/model_facs_v4_dec2b_2dpca_v15_27.pth
	Model improved!!!
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.292039741560059		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.292039741560059 | validation: 0.5897109933351219]
	TIME [epoch: 3.49 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26354206665225094		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.26354206665225094 | validation: 0.42396176000728786]
	TIME [epoch: 3.53 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19450479593831635		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.19450479593831635 | validation: 0.44624180766071503]
	TIME [epoch: 3.54 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21687148015303953		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.21687148015303953 | validation: 0.4476506352644444]
	TIME [epoch: 3.51 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2497094836600937		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2497094836600937 | validation: 0.5345316203708932]
	TIME [epoch: 3.54 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31294024076343574		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.31294024076343574 | validation: 0.45981324070410734]
	TIME [epoch: 3.49 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23825679106329667		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23825679106329667 | validation: 0.47476222968317505]
	TIME [epoch: 3.49 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2789152755235839		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2789152755235839 | validation: 0.6794353336888856]
	TIME [epoch: 3.52 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3067435880742766		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3067435880742766 | validation: 0.43571440430739017]
	TIME [epoch: 3.48 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21706136607980306		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.21706136607980306 | validation: 0.46402931799235336]
	TIME [epoch: 3.5 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2834824121232818		[learning rate: 0.0099882]
	Learning Rate: 0.0099882
	LOSS [training: 0.2834824121232818 | validation: 0.3806733507656633]
	TIME [epoch: 3.53 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v15_20240718_190304/states/model_facs_v4_dec2b_2dpca_v15_38.pth
	Model improved!!!
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2128080604865099		[learning rate: 0.0099411]
	Learning Rate: 0.00994113
	LOSS [training: 0.2128080604865099 | validation: 0.396840186059359]
	TIME [epoch: 3.5 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22371800760233987		[learning rate: 0.0098943]
	Learning Rate: 0.00989429
	LOSS [training: 0.22371800760233987 | validation: 0.39896805926868734]
	TIME [epoch: 3.52 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18063314620768245		[learning rate: 0.0098477]
	Learning Rate: 0.00984767
	LOSS [training: 0.18063314620768245 | validation: 0.49202633629111064]
	TIME [epoch: 3.51 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23060880028633618		[learning rate: 0.0098013]
	Learning Rate: 0.00980126
	LOSS [training: 0.23060880028633618 | validation: 0.4108931370960466]
	TIME [epoch: 3.48 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1898422163450067		[learning rate: 0.0097551]
	Learning Rate: 0.00975508
	LOSS [training: 0.1898422163450067 | validation: 0.5093889898887423]
	TIME [epoch: 3.52 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24751001741910172		[learning rate: 0.0097091]
	Learning Rate: 0.00970911
	LOSS [training: 0.24751001741910172 | validation: 0.4534368036659488]
	TIME [epoch: 3.49 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2438302247631623		[learning rate: 0.0096634]
	Learning Rate: 0.00966336
	LOSS [training: 0.2438302247631623 | validation: 0.41392863766231797]
	TIME [epoch: 3.48 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24518837970210033		[learning rate: 0.0096178]
	Learning Rate: 0.00961783
	LOSS [training: 0.24518837970210033 | validation: 0.47425885000669354]
	TIME [epoch: 3.53 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24948446630393528		[learning rate: 0.0095725]
	Learning Rate: 0.00957251
	LOSS [training: 0.24948446630393528 | validation: 0.4028185812353787]
	TIME [epoch: 3.51 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19942907169759877		[learning rate: 0.0095274]
	Learning Rate: 0.0095274
	LOSS [training: 0.19942907169759877 | validation: 0.3499706467844296]
	TIME [epoch: 3.48 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v15_20240718_190304/states/model_facs_v4_dec2b_2dpca_v15_48.pth
	Model improved!!!
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1993380223465563		[learning rate: 0.0094825]
	Learning Rate: 0.0094825
	LOSS [training: 0.1993380223465563 | validation: 0.5246432019757581]
	TIME [epoch: 3.54 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23685905689679942		[learning rate: 0.0094378]
	Learning Rate: 0.00943782
	LOSS [training: 0.23685905689679942 | validation: 0.447553823686563]
	TIME [epoch: 3.48 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25028572783480485		[learning rate: 0.0093933]
	Learning Rate: 0.00939335
	LOSS [training: 0.25028572783480485 | validation: 0.3707520916405421]
	TIME [epoch: 27 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18664687252962794		[learning rate: 0.0093491]
	Learning Rate: 0.00934909
	LOSS [training: 0.18664687252962794 | validation: 0.3582825419650799]
	TIME [epoch: 6.72 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1797205973105572		[learning rate: 0.009305]
	Learning Rate: 0.00930503
	LOSS [training: 0.1797205973105572 | validation: 0.33655127531237433]
	TIME [epoch: 6.69 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v15_20240718_190304/states/model_facs_v4_dec2b_2dpca_v15_53.pth
	Model improved!!!
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2199333052570481		[learning rate: 0.0092612]
	Learning Rate: 0.00926119
	LOSS [training: 0.2199333052570481 | validation: 0.4410070703504161]
	TIME [epoch: 6.71 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19785888355413078		[learning rate: 0.0092175]
	Learning Rate: 0.00921755
	LOSS [training: 0.19785888355413078 | validation: 0.3882312437699423]
	TIME [epoch: 6.7 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22582290635293256		[learning rate: 0.0091741]
	Learning Rate: 0.00917411
	LOSS [training: 0.22582290635293256 | validation: 0.38369556042400493]
	TIME [epoch: 6.7 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22673006282658686		[learning rate: 0.0091309]
	Learning Rate: 0.00913088
	LOSS [training: 0.22673006282658686 | validation: 0.435222856742278]
	TIME [epoch: 6.71 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2217116151561002		[learning rate: 0.0090879]
	Learning Rate: 0.00908786
	LOSS [training: 0.2217116151561002 | validation: 0.3539832755316867]
	TIME [epoch: 6.72 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21261688764361564		[learning rate: 0.009045]
	Learning Rate: 0.00904503
	LOSS [training: 0.21261688764361564 | validation: 0.40369592625967043]
	TIME [epoch: 6.69 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19808279680641508		[learning rate: 0.0090024]
	Learning Rate: 0.00900241
	LOSS [training: 0.19808279680641508 | validation: 0.5201797082096501]
	TIME [epoch: 6.7 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19626590529350607		[learning rate: 0.00896]
	Learning Rate: 0.00895999
	LOSS [training: 0.19626590529350607 | validation: 0.34046647938058594]
	TIME [epoch: 6.72 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20588363682137797		[learning rate: 0.0089178]
	Learning Rate: 0.00891777
	LOSS [training: 0.20588363682137797 | validation: 0.48433936453806004]
	TIME [epoch: 6.69 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20563452375353428		[learning rate: 0.0088758]
	Learning Rate: 0.00887575
	LOSS [training: 0.20563452375353428 | validation: 0.37587873494509993]
	TIME [epoch: 6.71 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17878238883150907		[learning rate: 0.0088339]
	Learning Rate: 0.00883393
	LOSS [training: 0.17878238883150907 | validation: 0.41788776606302896]
	TIME [epoch: 6.73 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20760126850525917		[learning rate: 0.0087923]
	Learning Rate: 0.0087923
	LOSS [training: 0.20760126850525917 | validation: 0.3853290835938615]
	TIME [epoch: 6.68 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20938099341896738		[learning rate: 0.0087509]
	Learning Rate: 0.00875087
	LOSS [training: 0.20938099341896738 | validation: 0.4054147541900746]
	TIME [epoch: 6.7 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20181642545980094		[learning rate: 0.0087096]
	Learning Rate: 0.00870964
	LOSS [training: 0.20181642545980094 | validation: 0.48627757498506025]
	TIME [epoch: 6.72 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19464482633603278		[learning rate: 0.0086686]
	Learning Rate: 0.00866859
	LOSS [training: 0.19464482633603278 | validation: 0.41130288497320133]
	TIME [epoch: 6.68 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20079642892225522		[learning rate: 0.0086277]
	Learning Rate: 0.00862775
	LOSS [training: 0.20079642892225522 | validation: 0.3284002172844015]
	TIME [epoch: 6.7 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v15_20240718_190304/states/model_facs_v4_dec2b_2dpca_v15_69.pth
	Model improved!!!
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.180917479641048		[learning rate: 0.0085871]
	Learning Rate: 0.00858709
	LOSS [training: 0.180917479641048 | validation: 0.4636881549969918]
	TIME [epoch: 6.73 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20952990747600936		[learning rate: 0.0085466]
	Learning Rate: 0.00854663
	LOSS [training: 0.20952990747600936 | validation: 0.33707560230559297]
	TIME [epoch: 6.7 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18706205665412473		[learning rate: 0.0085064]
	Learning Rate: 0.00850636
	LOSS [training: 0.18706205665412473 | validation: 0.3444909354150979]
	TIME [epoch: 6.69 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19377064690189338		[learning rate: 0.0084663]
	Learning Rate: 0.00846627
	LOSS [training: 0.19377064690189338 | validation: 0.4294602598546894]
	TIME [epoch: 6.69 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2014366962647514		[learning rate: 0.0084264]
	Learning Rate: 0.00842638
	LOSS [training: 0.2014366962647514 | validation: 0.36332730457621737]
	TIME [epoch: 6.69 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19569856722941312		[learning rate: 0.0083867]
	Learning Rate: 0.00838667
	LOSS [training: 0.19569856722941312 | validation: 0.41261302925380416]
	TIME [epoch: 6.69 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17324614819012282		[learning rate: 0.0083472]
	Learning Rate: 0.00834715
	LOSS [training: 0.17324614819012282 | validation: 0.4024701957855614]
	TIME [epoch: 6.68 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22934198618795115		[learning rate: 0.0083078]
	Learning Rate: 0.00830782
	LOSS [training: 0.22934198618795115 | validation: 0.6768906205424373]
	TIME [epoch: 6.69 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2066504771590522		[learning rate: 0.0082687]
	Learning Rate: 0.00826867
	LOSS [training: 0.2066504771590522 | validation: 0.3461690503474753]
	TIME [epoch: 6.69 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19208169358408833		[learning rate: 0.0082297]
	Learning Rate: 0.00822971
	LOSS [training: 0.19208169358408833 | validation: 0.4426706116894132]
	TIME [epoch: 6.7 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22136216933782327		[learning rate: 0.0081909]
	Learning Rate: 0.00819093
	LOSS [training: 0.22136216933782327 | validation: 0.4911208243270124]
	TIME [epoch: 6.69 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19686089853406233		[learning rate: 0.0081523]
	Learning Rate: 0.00815233
	LOSS [training: 0.19686089853406233 | validation: 0.3409299959113934]
	TIME [epoch: 6.68 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15288093908398942		[learning rate: 0.0081139]
	Learning Rate: 0.00811392
	LOSS [training: 0.15288093908398942 | validation: 0.3365176482874884]
	TIME [epoch: 6.68 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17113712611381052		[learning rate: 0.0080757]
	Learning Rate: 0.00807569
	LOSS [training: 0.17113712611381052 | validation: 0.33168281778967124]
	TIME [epoch: 6.68 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14438048999408037		[learning rate: 0.0080376]
	Learning Rate: 0.00803763
	LOSS [training: 0.14438048999408037 | validation: 0.45215669010308623]
	TIME [epoch: 6.71 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.252542432562851		[learning rate: 0.0079998]
	Learning Rate: 0.00799976
	LOSS [training: 0.252542432562851 | validation: 0.40759191444111414]
	TIME [epoch: 6.73 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1915394722521915		[learning rate: 0.0079621]
	Learning Rate: 0.00796206
	LOSS [training: 0.1915394722521915 | validation: 0.5086958179837068]
	TIME [epoch: 6.69 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21962736076364694		[learning rate: 0.0079245]
	Learning Rate: 0.00792455
	LOSS [training: 0.21962736076364694 | validation: 0.3187243814542876]
	TIME [epoch: 6.7 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v15_20240718_190304/states/model_facs_v4_dec2b_2dpca_v15_87.pth
	Model improved!!!
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14658082204047415		[learning rate: 0.0078872]
	Learning Rate: 0.0078872
	LOSS [training: 0.14658082204047415 | validation: 0.41159472981065987]
	TIME [epoch: 6.72 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17757322939678444		[learning rate: 0.00785]
	Learning Rate: 0.00785004
	LOSS [training: 0.17757322939678444 | validation: 0.44962894518018814]
	TIME [epoch: 6.7 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1887532789100356		[learning rate: 0.007813]
	Learning Rate: 0.00781305
	LOSS [training: 0.1887532789100356 | validation: 0.34680231688386615]
	TIME [epoch: 6.7 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14890502022251711		[learning rate: 0.0077762]
	Learning Rate: 0.00777623
	LOSS [training: 0.14890502022251711 | validation: 0.3979258313443441]
	TIME [epoch: 6.72 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.158847531553014		[learning rate: 0.0077396]
	Learning Rate: 0.00773959
	LOSS [training: 0.158847531553014 | validation: 0.37502772071860724]
	TIME [epoch: 6.71 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19014341601428697		[learning rate: 0.0077031]
	Learning Rate: 0.00770312
	LOSS [training: 0.19014341601428697 | validation: 0.6201340624130627]
	TIME [epoch: 6.69 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16947462670242144		[learning rate: 0.0076668]
	Learning Rate: 0.00766682
	LOSS [training: 0.16947462670242144 | validation: 0.3775263617014573]
	TIME [epoch: 6.71 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15062750308641448		[learning rate: 0.0076307]
	Learning Rate: 0.0076307
	LOSS [training: 0.15062750308641448 | validation: 0.40786381844714215]
	TIME [epoch: 6.71 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17509651070138782		[learning rate: 0.0075947]
	Learning Rate: 0.00759474
	LOSS [training: 0.17509651070138782 | validation: 0.38609244526665687]
	TIME [epoch: 6.69 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16030488085992567		[learning rate: 0.007559]
	Learning Rate: 0.00755895
	LOSS [training: 0.16030488085992567 | validation: 0.31660431703515574]
	TIME [epoch: 6.71 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v15_20240718_190304/states/model_facs_v4_dec2b_2dpca_v15_97.pth
	Model improved!!!
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19210015143193643		[learning rate: 0.0075233]
	Learning Rate: 0.00752333
	LOSS [training: 0.19210015143193643 | validation: 0.4319479816042119]
	TIME [epoch: 6.72 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17419430310458361		[learning rate: 0.0074879]
	Learning Rate: 0.00748788
	LOSS [training: 0.17419430310458361 | validation: 0.3810474649649498]
	TIME [epoch: 6.69 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2024737199569311		[learning rate: 0.0074526]
	Learning Rate: 0.0074526
	LOSS [training: 0.2024737199569311 | validation: 0.3819853415385116]
	TIME [epoch: 6.72 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17075791627736003		[learning rate: 0.0074175]
	Learning Rate: 0.00741748
	LOSS [training: 0.17075791627736003 | validation: 0.345447233354201]
	TIME [epoch: 6.71 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1704404271759159		[learning rate: 0.0073825]
	Learning Rate: 0.00738253
	LOSS [training: 0.1704404271759159 | validation: 0.38290117534323365]
	TIME [epoch: 6.69 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.205405858327538		[learning rate: 0.0073477]
	Learning Rate: 0.00734774
	LOSS [training: 0.205405858327538 | validation: 0.3102021392219344]
	TIME [epoch: 6.72 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v15_20240718_190304/states/model_facs_v4_dec2b_2dpca_v15_103.pth
	Model improved!!!
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19893832297939318		[learning rate: 0.0073131]
	Learning Rate: 0.00731312
	LOSS [training: 0.19893832297939318 | validation: 0.33423708655540174]
	TIME [epoch: 6.71 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19323495445672284		[learning rate: 0.0072787]
	Learning Rate: 0.00727866
	LOSS [training: 0.19323495445672284 | validation: 0.4513911222299046]
	TIME [epoch: 6.7 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23592579247955733		[learning rate: 0.0072444]
	Learning Rate: 0.00724436
	LOSS [training: 0.23592579247955733 | validation: 0.5390676819075918]
	TIME [epoch: 6.72 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1808043936282125		[learning rate: 0.0072102]
	Learning Rate: 0.00721022
	LOSS [training: 0.1808043936282125 | validation: 0.308334291567047]
	TIME [epoch: 6.7 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v15_20240718_190304/states/model_facs_v4_dec2b_2dpca_v15_107.pth
	Model improved!!!
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1651049215351787		[learning rate: 0.0071762]
	Learning Rate: 0.00717625
	LOSS [training: 0.1651049215351787 | validation: 0.35650635412488113]
	TIME [epoch: 6.7 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16804432399491434		[learning rate: 0.0071424]
	Learning Rate: 0.00714243
	LOSS [training: 0.16804432399491434 | validation: 0.3385179002535999]
	TIME [epoch: 6.71 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17011622785663724		[learning rate: 0.0071088]
	Learning Rate: 0.00710878
	LOSS [training: 0.17011622785663724 | validation: 0.5136350962769857]
	TIME [epoch: 6.71 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19211264912450987		[learning rate: 0.0070753]
	Learning Rate: 0.00707528
	LOSS [training: 0.19211264912450987 | validation: 0.3491193962009184]
	TIME [epoch: 6.7 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18220918355832327		[learning rate: 0.0070419]
	Learning Rate: 0.00704194
	LOSS [training: 0.18220918355832327 | validation: 0.3457931365313176]
	TIME [epoch: 6.7 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21763052246816575		[learning rate: 0.0070088]
	Learning Rate: 0.00700876
	LOSS [training: 0.21763052246816575 | validation: 0.4369180806424906]
	TIME [epoch: 6.7 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19306472920144474		[learning rate: 0.0069757]
	Learning Rate: 0.00697573
	LOSS [training: 0.19306472920144474 | validation: 0.4402202529910218]
	TIME [epoch: 6.7 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1856331140140634		[learning rate: 0.0069429]
	Learning Rate: 0.00694286
	LOSS [training: 0.1856331140140634 | validation: 0.34747611106985005]
	TIME [epoch: 6.7 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16748415104559936		[learning rate: 0.0069101]
	Learning Rate: 0.00691014
	LOSS [training: 0.16748415104559936 | validation: 0.2971260595206759]
	TIME [epoch: 6.7 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v15_20240718_190304/states/model_facs_v4_dec2b_2dpca_v15_116.pth
	Model improved!!!
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16323035338398278		[learning rate: 0.0068776]
	Learning Rate: 0.00687758
	LOSS [training: 0.16323035338398278 | validation: 0.31201041977540667]
	TIME [epoch: 6.72 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.158291630344351		[learning rate: 0.0068452]
	Learning Rate: 0.00684518
	LOSS [training: 0.158291630344351 | validation: 0.28405425713761506]
	TIME [epoch: 6.69 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v15_20240718_190304/states/model_facs_v4_dec2b_2dpca_v15_118.pth
	Model improved!!!
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1603402386532799		[learning rate: 0.0068129]
	Learning Rate: 0.00681292
	LOSS [training: 0.1603402386532799 | validation: 0.3123735722514504]
	TIME [epoch: 6.72 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1291286528418441		[learning rate: 0.0067808]
	Learning Rate: 0.00678082
	LOSS [training: 0.1291286528418441 | validation: 0.37841632417235277]
	TIME [epoch: 6.72 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1619921492966499		[learning rate: 0.0067489]
	Learning Rate: 0.00674887
	LOSS [training: 0.1619921492966499 | validation: 0.35882489872444245]
	TIME [epoch: 6.69 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15182478060184257		[learning rate: 0.0067171]
	Learning Rate: 0.00671706
	LOSS [training: 0.15182478060184257 | validation: 0.36549431551624556]
	TIME [epoch: 6.7 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1621016240442827		[learning rate: 0.0066854]
	Learning Rate: 0.00668541
	LOSS [training: 0.1621016240442827 | validation: 0.3833670546281067]
	TIME [epoch: 6.72 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1509119470468383		[learning rate: 0.0066539]
	Learning Rate: 0.00665391
	LOSS [training: 0.1509119470468383 | validation: 0.3588509938411383]
	TIME [epoch: 6.68 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18894275154134033		[learning rate: 0.0066226]
	Learning Rate: 0.00662256
	LOSS [training: 0.18894275154134033 | validation: 0.32854714802184093]
	TIME [epoch: 6.69 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16493456044676613		[learning rate: 0.0065913]
	Learning Rate: 0.00659135
	LOSS [training: 0.16493456044676613 | validation: 0.3464583616466846]
	TIME [epoch: 6.72 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1968412337715314		[learning rate: 0.0065603]
	Learning Rate: 0.00656029
	LOSS [training: 0.1968412337715314 | validation: 0.35602027631483324]
	TIME [epoch: 6.69 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15367216567528424		[learning rate: 0.0065294]
	Learning Rate: 0.00652938
	LOSS [training: 0.15367216567528424 | validation: 0.322222118236957]
	TIME [epoch: 6.7 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15391551031113443		[learning rate: 0.0064986]
	Learning Rate: 0.00649861
	LOSS [training: 0.15391551031113443 | validation: 0.42177602224324706]
	TIME [epoch: 6.71 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19084518555341565		[learning rate: 0.006468]
	Learning Rate: 0.00646799
	LOSS [training: 0.19084518555341565 | validation: 0.3340613827522361]
	TIME [epoch: 6.68 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12724132879081698		[learning rate: 0.0064375]
	Learning Rate: 0.00643751
	LOSS [training: 0.12724132879081698 | validation: 0.34827014282708163]
	TIME [epoch: 6.7 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14693459594929092		[learning rate: 0.0064072]
	Learning Rate: 0.00640718
	LOSS [training: 0.14693459594929092 | validation: 0.35059015103575436]
	TIME [epoch: 6.73 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1510293458112016		[learning rate: 0.006377]
	Learning Rate: 0.00637698
	LOSS [training: 0.1510293458112016 | validation: 0.3855152069039621]
	TIME [epoch: 6.69 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15293689837587351		[learning rate: 0.0063469]
	Learning Rate: 0.00634694
	LOSS [training: 0.15293689837587351 | validation: 0.32466633173723447]
	TIME [epoch: 6.71 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16700954881111013		[learning rate: 0.006317]
	Learning Rate: 0.00631703
	LOSS [training: 0.16700954881111013 | validation: 0.40900643537500186]
	TIME [epoch: 6.72 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1294244754938145		[learning rate: 0.0062873]
	Learning Rate: 0.00628726
	LOSS [training: 0.1294244754938145 | validation: 0.40771537306208416]
	TIME [epoch: 6.68 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14694975050266873		[learning rate: 0.0062576]
	Learning Rate: 0.00625764
	LOSS [training: 0.14694975050266873 | validation: 0.30324542984885705]
	TIME [epoch: 6.7 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15700445841122368		[learning rate: 0.0062281]
	Learning Rate: 0.00622815
	LOSS [training: 0.15700445841122368 | validation: 0.45178245587969695]
	TIME [epoch: 6.71 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1778073191936782		[learning rate: 0.0061988]
	Learning Rate: 0.0061988
	LOSS [training: 0.1778073191936782 | validation: 0.2976173830758261]
	TIME [epoch: 6.69 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1666543752142003		[learning rate: 0.0061696]
	Learning Rate: 0.00616959
	LOSS [training: 0.1666543752142003 | validation: 0.44172233924463933]
	TIME [epoch: 6.7 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19309529566045083		[learning rate: 0.0061405]
	Learning Rate: 0.00614052
	LOSS [training: 0.19309529566045083 | validation: 0.4018580570291851]
	TIME [epoch: 6.71 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18254837878452473		[learning rate: 0.0061116]
	Learning Rate: 0.00611158
	LOSS [training: 0.18254837878452473 | validation: 0.35797488431799496]
	TIME [epoch: 6.68 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16258005364617775		[learning rate: 0.0060828]
	Learning Rate: 0.00608279
	LOSS [training: 0.16258005364617775 | validation: 0.3637343772092254]
	TIME [epoch: 6.7 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17547019522243523		[learning rate: 0.0060541]
	Learning Rate: 0.00605412
	LOSS [training: 0.17547019522243523 | validation: 0.45088652603351653]
	TIME [epoch: 6.73 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14785811051968695		[learning rate: 0.0060256]
	Learning Rate: 0.0060256
	LOSS [training: 0.14785811051968695 | validation: 0.3218493679658444]
	TIME [epoch: 6.69 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14545521827721053		[learning rate: 0.0059972]
	Learning Rate: 0.0059972
	LOSS [training: 0.14545521827721053 | validation: 0.3212614381459713]
	TIME [epoch: 6.7 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16032750312182245		[learning rate: 0.0059689]
	Learning Rate: 0.00596894
	LOSS [training: 0.16032750312182245 | validation: 0.35449412341031006]
	TIME [epoch: 6.71 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15483031304074896		[learning rate: 0.0059408]
	Learning Rate: 0.00594082
	LOSS [training: 0.15483031304074896 | validation: 0.39808671336001755]
	TIME [epoch: 6.69 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1838072609415729		[learning rate: 0.0059128]
	Learning Rate: 0.00591282
	LOSS [training: 0.1838072609415729 | validation: 0.3303952088840677]
	TIME [epoch: 6.7 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1771347769992177		[learning rate: 0.005885]
	Learning Rate: 0.00588496
	LOSS [training: 0.1771347769992177 | validation: 0.3115624821640166]
	TIME [epoch: 6.71 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18201927739605983		[learning rate: 0.0058572]
	Learning Rate: 0.00585723
	LOSS [training: 0.18201927739605983 | validation: 0.3254334004290069]
	TIME [epoch: 6.68 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15996318768289		[learning rate: 0.0058296]
	Learning Rate: 0.00582963
	LOSS [training: 0.15996318768289 | validation: 0.3196643132599294]
	TIME [epoch: 6.7 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1681232749133802		[learning rate: 0.0058022]
	Learning Rate: 0.00580216
	LOSS [training: 0.1681232749133802 | validation: 0.3139006031752762]
	TIME [epoch: 6.73 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15062638436842024		[learning rate: 0.0057748]
	Learning Rate: 0.00577482
	LOSS [training: 0.15062638436842024 | validation: 0.3689839935587011]
	TIME [epoch: 6.69 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1544394496145569		[learning rate: 0.0057476]
	Learning Rate: 0.00574761
	LOSS [training: 0.1544394496145569 | validation: 0.28058247783536033]
	TIME [epoch: 6.7 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v15_20240718_190304/states/model_facs_v4_dec2b_2dpca_v15_155.pth
	Model improved!!!
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15995602376538817		[learning rate: 0.0057205]
	Learning Rate: 0.00572052
	LOSS [training: 0.15995602376538817 | validation: 0.3761828814196895]
	TIME [epoch: 6.72 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.171463904795545		[learning rate: 0.0056936]
	Learning Rate: 0.00569357
	LOSS [training: 0.171463904795545 | validation: 0.32206743018642076]
	TIME [epoch: 6.71 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13651589809234643		[learning rate: 0.0056667]
	Learning Rate: 0.00566674
	LOSS [training: 0.13651589809234643 | validation: 0.3150749372888081]
	TIME [epoch: 6.68 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14350019963659336		[learning rate: 0.00564]
	Learning Rate: 0.00564004
	LOSS [training: 0.14350019963659336 | validation: 0.29832102579893083]
	TIME [epoch: 6.73 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1359742589838251		[learning rate: 0.0056135]
	Learning Rate: 0.00561346
	LOSS [training: 0.1359742589838251 | validation: 0.37424796345319233]
	TIME [epoch: 6.71 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14097956276040208		[learning rate: 0.005587]
	Learning Rate: 0.00558701
	LOSS [training: 0.14097956276040208 | validation: 0.48575752634100805]
	TIME [epoch: 6.68 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14837368137422652		[learning rate: 0.0055607]
	Learning Rate: 0.00556068
	LOSS [training: 0.14837368137422652 | validation: 0.44844227926401325]
	TIME [epoch: 6.7 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16408157553504255		[learning rate: 0.0055345]
	Learning Rate: 0.00553448
	LOSS [training: 0.16408157553504255 | validation: 0.29640966250614253]
	TIME [epoch: 6.7 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14125273686425482		[learning rate: 0.0055084]
	Learning Rate: 0.0055084
	LOSS [training: 0.14125273686425482 | validation: 0.3272602603106315]
	TIME [epoch: 6.7 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19661125151749137		[learning rate: 0.0054824]
	Learning Rate: 0.00548245
	LOSS [training: 0.19661125151749137 | validation: 0.30621623727442787]
	TIME [epoch: 6.75 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18099640073643553		[learning rate: 0.0054566]
	Learning Rate: 0.00545661
	LOSS [training: 0.18099640073643553 | validation: 0.34756810662116533]
	TIME [epoch: 6.75 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15478319320118128		[learning rate: 0.0054309]
	Learning Rate: 0.0054309
	LOSS [training: 0.15478319320118128 | validation: 0.3666540250018374]
	TIME [epoch: 6.74 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14887239204601743		[learning rate: 0.0054053]
	Learning Rate: 0.00540531
	LOSS [training: 0.14887239204601743 | validation: 0.3407899451932982]
	TIME [epoch: 6.72 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14672128749275226		[learning rate: 0.0053798]
	Learning Rate: 0.00537984
	LOSS [training: 0.14672128749275226 | validation: 0.39963648054068707]
	TIME [epoch: 6.71 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1688268336627497		[learning rate: 0.0053545]
	Learning Rate: 0.00535449
	LOSS [training: 0.1688268336627497 | validation: 0.3236277766651785]
	TIME [epoch: 6.76 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1598770948693835		[learning rate: 0.0053293]
	Learning Rate: 0.00532926
	LOSS [training: 0.1598770948693835 | validation: 0.29066596638364894]
	TIME [epoch: 6.75 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14824558572699675		[learning rate: 0.0053041]
	Learning Rate: 0.00530415
	LOSS [training: 0.14824558572699675 | validation: 0.3481229339293292]
	TIME [epoch: 6.75 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15364405207410164		[learning rate: 0.0052792]
	Learning Rate: 0.00527915
	LOSS [training: 0.15364405207410164 | validation: 0.43216305592004944]
	TIME [epoch: 6.7 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1526054056478257		[learning rate: 0.0052543]
	Learning Rate: 0.00525428
	LOSS [training: 0.1526054056478257 | validation: 0.2821249149829682]
	TIME [epoch: 6.77 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1438290356278854		[learning rate: 0.0052295]
	Learning Rate: 0.00522952
	LOSS [training: 0.1438290356278854 | validation: 0.3075066762089686]
	TIME [epoch: 6.74 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13782108123569436		[learning rate: 0.0052049]
	Learning Rate: 0.00520487
	LOSS [training: 0.13782108123569436 | validation: 0.40700701979935466]
	TIME [epoch: 6.77 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15423054760758076		[learning rate: 0.0051803]
	Learning Rate: 0.00518035
	LOSS [training: 0.15423054760758076 | validation: 0.3446137826677736]
	TIME [epoch: 6.72 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1508415512516852		[learning rate: 0.0051559]
	Learning Rate: 0.00515594
	LOSS [training: 0.1508415512516852 | validation: 0.34854094901885796]
	TIME [epoch: 6.72 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1259630372083443		[learning rate: 0.0051316]
	Learning Rate: 0.00513164
	LOSS [training: 0.1259630372083443 | validation: 0.35737560286916453]
	TIME [epoch: 6.75 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13596243102035008		[learning rate: 0.0051075]
	Learning Rate: 0.00510746
	LOSS [training: 0.13596243102035008 | validation: 0.5148779507546385]
	TIME [epoch: 6.77 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14969218311413995		[learning rate: 0.0050834]
	Learning Rate: 0.00508339
	LOSS [training: 0.14969218311413995 | validation: 0.3200306797858705]
	TIME [epoch: 6.75 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16681239163901448		[learning rate: 0.0050594]
	Learning Rate: 0.00505944
	LOSS [training: 0.16681239163901448 | validation: 0.29717069091882425]
	TIME [epoch: 6.68 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17051075173861147		[learning rate: 0.0050356]
	Learning Rate: 0.0050356
	LOSS [training: 0.17051075173861147 | validation: 0.32932371607257804]
	TIME [epoch: 6.77 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17118250655202494		[learning rate: 0.0050119]
	Learning Rate: 0.00501187
	LOSS [training: 0.17118250655202494 | validation: 0.5790619081155766]
	TIME [epoch: 6.73 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2114833762512667		[learning rate: 0.0049883]
	Learning Rate: 0.00498826
	LOSS [training: 0.2114833762512667 | validation: 0.39396215849391414]
	TIME [epoch: 6.76 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13734865941423963		[learning rate: 0.0049648]
	Learning Rate: 0.00496475
	LOSS [training: 0.13734865941423963 | validation: 0.3235781375231641]
	TIME [epoch: 6.72 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1312860669742945		[learning rate: 0.0049414]
	Learning Rate: 0.00494136
	LOSS [training: 0.1312860669742945 | validation: 0.40113831312942827]
	TIME [epoch: 6.73 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11956729841271661		[learning rate: 0.0049181]
	Learning Rate: 0.00491807
	LOSS [training: 0.11956729841271661 | validation: 0.33881711795328984]
	TIME [epoch: 6.74 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18277039306251067		[learning rate: 0.0048949]
	Learning Rate: 0.0048949
	LOSS [training: 0.18277039306251067 | validation: 0.35537007065830284]
	TIME [epoch: 6.78 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15913054610207625		[learning rate: 0.0048718]
	Learning Rate: 0.00487183
	LOSS [training: 0.15913054610207625 | validation: 0.35869393890557183]
	TIME [epoch: 6.73 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19048753399787552		[learning rate: 0.0048489]
	Learning Rate: 0.00484888
	LOSS [training: 0.19048753399787552 | validation: 0.42928762937054843]
	TIME [epoch: 6.69 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2092174806912968		[learning rate: 0.004826]
	Learning Rate: 0.00482603
	LOSS [training: 0.2092174806912968 | validation: 0.3184855823738757]
	TIME [epoch: 6.78 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16638190925531537		[learning rate: 0.0048033]
	Learning Rate: 0.00480329
	LOSS [training: 0.16638190925531537 | validation: 0.4248891470044161]
	TIME [epoch: 6.74 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14866244150613203		[learning rate: 0.0047807]
	Learning Rate: 0.00478065
	LOSS [training: 0.14866244150613203 | validation: 0.32244379286910685]
	TIME [epoch: 6.76 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17288285732358902		[learning rate: 0.0047581]
	Learning Rate: 0.00475813
	LOSS [training: 0.17288285732358902 | validation: 0.40263442370702174]
	TIME [epoch: 6.71 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15329670326979905		[learning rate: 0.0047357]
	Learning Rate: 0.0047357
	LOSS [training: 0.15329670326979905 | validation: 0.2937955104722084]
	TIME [epoch: 6.73 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13659855460472786		[learning rate: 0.0047134]
	Learning Rate: 0.00471339
	LOSS [training: 0.13659855460472786 | validation: 0.3831084089254899]
	TIME [epoch: 6.74 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15079663846749114		[learning rate: 0.0046912]
	Learning Rate: 0.00469118
	LOSS [training: 0.15079663846749114 | validation: 0.31112204964389967]
	TIME [epoch: 6.78 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15561336852736718		[learning rate: 0.0046691]
	Learning Rate: 0.00466907
	LOSS [training: 0.15561336852736718 | validation: 0.3574777076165763]
	TIME [epoch: 6.72 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15458570011068884		[learning rate: 0.0046471]
	Learning Rate: 0.00464707
	LOSS [training: 0.15458570011068884 | validation: 0.33162026862718347]
	TIME [epoch: 6.69 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16106830460429752		[learning rate: 0.0046252]
	Learning Rate: 0.00462518
	LOSS [training: 0.16106830460429752 | validation: 0.5213408839655431]
	TIME [epoch: 6.78 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1885921453152776		[learning rate: 0.0046034]
	Learning Rate: 0.00460338
	LOSS [training: 0.1885921453152776 | validation: 0.3095064545094178]
	TIME [epoch: 6.75 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14209909224423273		[learning rate: 0.0045817]
	Learning Rate: 0.00458169
	LOSS [training: 0.14209909224423273 | validation: 0.301913301749047]
	TIME [epoch: 6.76 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1450851158120507		[learning rate: 0.0045601]
	Learning Rate: 0.0045601
	LOSS [training: 0.1450851158120507 | validation: 0.3427677478688978]
	TIME [epoch: 6.69 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15370400137491297		[learning rate: 0.0045386]
	Learning Rate: 0.00453861
	LOSS [training: 0.15370400137491297 | validation: 0.3127346833066773]
	TIME [epoch: 6.75 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16222649916424298		[learning rate: 0.0045172]
	Learning Rate: 0.00451723
	LOSS [training: 0.16222649916424298 | validation: 0.443757914376691]
	TIME [epoch: 6.74 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.140957156539303		[learning rate: 0.0044959]
	Learning Rate: 0.00449594
	LOSS [training: 0.140957156539303 | validation: 0.32299782325703097]
	TIME [epoch: 6.78 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1803473450162315		[learning rate: 0.0044748]
	Learning Rate: 0.00447475
	LOSS [training: 0.1803473450162315 | validation: 0.42901655727560406]
	TIME [epoch: 6.72 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1854542353698091		[learning rate: 0.0044537]
	Learning Rate: 0.00445367
	LOSS [training: 0.1854542353698091 | validation: 0.3350422655511117]
	TIME [epoch: 6.71 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17000863101415944		[learning rate: 0.0044327]
	Learning Rate: 0.00443268
	LOSS [training: 0.17000863101415944 | validation: 0.3519644970649251]
	TIME [epoch: 6.75 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14884710093888195		[learning rate: 0.0044118]
	Learning Rate: 0.0044118
	LOSS [training: 0.14884710093888195 | validation: 0.331939743574473]
	TIME [epoch: 6.76 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14902577599730782		[learning rate: 0.004391]
	Learning Rate: 0.00439101
	LOSS [training: 0.14902577599730782 | validation: 0.34638876070360913]
	TIME [epoch: 6.75 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1351300619443458		[learning rate: 0.0043703]
	Learning Rate: 0.00437032
	LOSS [training: 0.1351300619443458 | validation: 0.327993348193078]
	TIME [epoch: 6.68 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14379515024544332		[learning rate: 0.0043497]
	Learning Rate: 0.00434972
	LOSS [training: 0.14379515024544332 | validation: 0.3751426384171301]
	TIME [epoch: 6.77 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14912720330843837		[learning rate: 0.0043292]
	Learning Rate: 0.00432923
	LOSS [training: 0.14912720330843837 | validation: 0.3967524989328841]
	TIME [epoch: 6.74 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16372292458070972		[learning rate: 0.0043088]
	Learning Rate: 0.00430883
	LOSS [training: 0.16372292458070972 | validation: 0.33463880249555483]
	TIME [epoch: 6.76 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14220292458570574		[learning rate: 0.0042885]
	Learning Rate: 0.00428852
	LOSS [training: 0.14220292458570574 | validation: 0.43674270064348164]
	TIME [epoch: 6.71 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1387315810793584		[learning rate: 0.0042683]
	Learning Rate: 0.00426831
	LOSS [training: 0.1387315810793584 | validation: 0.29103843293022225]
	TIME [epoch: 6.71 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13850483724032853		[learning rate: 0.0042482]
	Learning Rate: 0.0042482
	LOSS [training: 0.13850483724032853 | validation: 0.35151217969005094]
	TIME [epoch: 6.74 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13351345985584254		[learning rate: 0.0042282]
	Learning Rate: 0.00422818
	LOSS [training: 0.13351345985584254 | validation: 0.34646811818496687]
	TIME [epoch: 6.77 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16183418825656984		[learning rate: 0.0042083]
	Learning Rate: 0.00420826
	LOSS [training: 0.16183418825656984 | validation: 0.3219093071658738]
	TIME [epoch: 6.75 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15147355371280027		[learning rate: 0.0041884]
	Learning Rate: 0.00418843
	LOSS [training: 0.15147355371280027 | validation: 0.2996673687239521]
	TIME [epoch: 6.69 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1543034376337412		[learning rate: 0.0041687]
	Learning Rate: 0.00416869
	LOSS [training: 0.1543034376337412 | validation: 0.39173235710868415]
	TIME [epoch: 6.77 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1334209773694542		[learning rate: 0.0041491]
	Learning Rate: 0.00414905
	LOSS [training: 0.1334209773694542 | validation: 0.2929888698494969]
	TIME [epoch: 6.73 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13178604972576446		[learning rate: 0.0041295]
	Learning Rate: 0.0041295
	LOSS [training: 0.13178604972576446 | validation: 0.2887709788177487]
	TIME [epoch: 6.75 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12994484491416697		[learning rate: 0.00411]
	Learning Rate: 0.00411004
	LOSS [training: 0.12994484491416697 | validation: 0.46035426871706764]
	TIME [epoch: 6.7 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1428058324424836		[learning rate: 0.0040907]
	Learning Rate: 0.00409067
	LOSS [training: 0.1428058324424836 | validation: 0.3463834562032654]
	TIME [epoch: 6.73 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13750409138328112		[learning rate: 0.0040714]
	Learning Rate: 0.0040714
	LOSS [training: 0.13750409138328112 | validation: 0.2673037927463811]
	TIME [epoch: 6.75 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v15_20240718_190304/states/model_facs_v4_dec2b_2dpca_v15_228.pth
	Model improved!!!
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12351677300966975		[learning rate: 0.0040522]
	Learning Rate: 0.00405221
	LOSS [training: 0.12351677300966975 | validation: 0.36903728820794685]
	TIME [epoch: 6.79 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15957914477485366		[learning rate: 0.0040331]
	Learning Rate: 0.00403312
	LOSS [training: 0.15957914477485366 | validation: 0.3472079565706925]
	TIME [epoch: 6.75 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17327900260463858		[learning rate: 0.0040141]
	Learning Rate: 0.00401411
	LOSS [training: 0.17327900260463858 | validation: 0.3101263309816135]
	TIME [epoch: 6.69 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14446120809660642		[learning rate: 0.0039952]
	Learning Rate: 0.0039952
	LOSS [training: 0.14446120809660642 | validation: 0.31276125336311195]
	TIME [epoch: 6.77 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11347571798138001		[learning rate: 0.0039764]
	Learning Rate: 0.00397637
	LOSS [training: 0.11347571798138001 | validation: 0.43727903824807235]
	TIME [epoch: 6.74 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12622011805466277		[learning rate: 0.0039576]
	Learning Rate: 0.00395764
	LOSS [training: 0.12622011805466277 | validation: 0.2928468211718156]
	TIME [epoch: 6.76 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1387301581785691		[learning rate: 0.003939]
	Learning Rate: 0.00393899
	LOSS [training: 0.1387301581785691 | validation: 0.30217851215114916]
	TIME [epoch: 6.73 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15318750492705668		[learning rate: 0.0039204]
	Learning Rate: 0.00392043
	LOSS [training: 0.15318750492705668 | validation: 0.3699359185923126]
	TIME [epoch: 6.75 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1386418968198969		[learning rate: 0.003902]
	Learning Rate: 0.00390195
	LOSS [training: 0.1386418968198969 | validation: 0.3544603993907112]
	TIME [epoch: 6.74 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15443690434639565		[learning rate: 0.0038836]
	Learning Rate: 0.00388357
	LOSS [training: 0.15443690434639565 | validation: 0.32048778932568983]
	TIME [epoch: 6.78 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12726659323671316		[learning rate: 0.0038653]
	Learning Rate: 0.00386527
	LOSS [training: 0.12726659323671316 | validation: 0.36674093633906096]
	TIME [epoch: 6.71 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12593529113450633		[learning rate: 0.0038471]
	Learning Rate: 0.00384705
	LOSS [training: 0.12593529113450633 | validation: 0.3330311493268006]
	TIME [epoch: 6.7 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1538123989975707		[learning rate: 0.0038289]
	Learning Rate: 0.00382893
	LOSS [training: 0.1538123989975707 | validation: 0.3757641619470017]
	TIME [epoch: 6.76 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15132978873834516		[learning rate: 0.0038109]
	Learning Rate: 0.00381088
	LOSS [training: 0.15132978873834516 | validation: 0.321899819908147]
	TIME [epoch: 6.76 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15427262895036492		[learning rate: 0.0037929]
	Learning Rate: 0.00379293
	LOSS [training: 0.15427262895036492 | validation: 0.3083204271257107]
	TIME [epoch: 6.76 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12329614305687078		[learning rate: 0.0037751]
	Learning Rate: 0.00377505
	LOSS [training: 0.12329614305687078 | validation: 0.37153018955172995]
	TIME [epoch: 6.71 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1553630997190742		[learning rate: 0.0037573]
	Learning Rate: 0.00375726
	LOSS [training: 0.1553630997190742 | validation: 0.3629669397204532]
	TIME [epoch: 6.75 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15496841703196615		[learning rate: 0.0037396]
	Learning Rate: 0.00373956
	LOSS [training: 0.15496841703196615 | validation: 0.2708835225516578]
	TIME [epoch: 6.73 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13994367049745876		[learning rate: 0.0037219]
	Learning Rate: 0.00372194
	LOSS [training: 0.13994367049745876 | validation: 0.3700839785989495]
	TIME [epoch: 6.77 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13635968173397242		[learning rate: 0.0037044]
	Learning Rate: 0.0037044
	LOSS [training: 0.13635968173397242 | validation: 0.3283730483651389]
	TIME [epoch: 6.72 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12476084987079089		[learning rate: 0.0036869]
	Learning Rate: 0.00368695
	LOSS [training: 0.12476084987079089 | validation: 0.3964854850338234]
	TIME [epoch: 6.72 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14189451783123602		[learning rate: 0.0036696]
	Learning Rate: 0.00366957
	LOSS [training: 0.14189451783123602 | validation: 0.3111761597771839]
	TIME [epoch: 6.75 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14080941054840382		[learning rate: 0.0036523]
	Learning Rate: 0.00365228
	LOSS [training: 0.14080941054840382 | validation: 0.28421966123856457]
	TIME [epoch: 6.76 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11532707641831762		[learning rate: 0.0036351]
	Learning Rate: 0.00363507
	LOSS [training: 0.11532707641831762 | validation: 0.3459937430735826]
	TIME [epoch: 6.75 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12699409712855486		[learning rate: 0.0036179]
	Learning Rate: 0.00361794
	LOSS [training: 0.12699409712855486 | validation: 0.3162172500035877]
	TIME [epoch: 6.7 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12256435116985927		[learning rate: 0.0036009]
	Learning Rate: 0.00360089
	LOSS [training: 0.12256435116985927 | validation: 0.33706196401256094]
	TIME [epoch: 6.76 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1332065970914062		[learning rate: 0.0035839]
	Learning Rate: 0.00358393
	LOSS [training: 0.1332065970914062 | validation: 0.35290916372916153]
	TIME [epoch: 6.74 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13531406015226763		[learning rate: 0.003567]
	Learning Rate: 0.00356704
	LOSS [training: 0.13531406015226763 | validation: 0.3916059750194455]
	TIME [epoch: 6.75 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14780809976599507		[learning rate: 0.0035502]
	Learning Rate: 0.00355023
	LOSS [training: 0.14780809976599507 | validation: 0.33915319700522956]
	TIME [epoch: 6.7 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13010877453188496		[learning rate: 0.0035335]
	Learning Rate: 0.0035335
	LOSS [training: 0.13010877453188496 | validation: 0.3809198311796631]
	TIME [epoch: 6.72 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1516359887506214		[learning rate: 0.0035168]
	Learning Rate: 0.00351685
	LOSS [training: 0.1516359887506214 | validation: 0.2986665849722529]
	TIME [epoch: 6.73 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12538508368558943		[learning rate: 0.0035003]
	Learning Rate: 0.00350028
	LOSS [training: 0.12538508368558943 | validation: 0.41059421172454125]
	TIME [epoch: 6.77 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16092595889465183		[learning rate: 0.0034838]
	Learning Rate: 0.00348378
	LOSS [training: 0.16092595889465183 | validation: 0.43590636806229976]
	TIME [epoch: 6.73 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14650611472244032		[learning rate: 0.0034674]
	Learning Rate: 0.00346737
	LOSS [training: 0.14650611472244032 | validation: 0.29187589663670105]
	TIME [epoch: 6.7 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12660873569452122		[learning rate: 0.003451]
	Learning Rate: 0.00345103
	LOSS [training: 0.12660873569452122 | validation: 0.3315476635388658]
	TIME [epoch: 6.77 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15555581665735935		[learning rate: 0.0034348]
	Learning Rate: 0.00343477
	LOSS [training: 0.15555581665735935 | validation: 0.44365000108126207]
	TIME [epoch: 6.73 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15337601414449042		[learning rate: 0.0034186]
	Learning Rate: 0.00341858
	LOSS [training: 0.15337601414449042 | validation: 0.3176742896115168]
	TIME [epoch: 6.74 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15561820249418679		[learning rate: 0.0034025]
	Learning Rate: 0.00340247
	LOSS [training: 0.15561820249418679 | validation: 0.2888172007843151]
	TIME [epoch: 6.71 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15858425511733565		[learning rate: 0.0033864]
	Learning Rate: 0.00338644
	LOSS [training: 0.15858425511733565 | validation: 0.30613484278078296]
	TIME [epoch: 6.73 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1500746219335596		[learning rate: 0.0033705]
	Learning Rate: 0.00337048
	LOSS [training: 0.1500746219335596 | validation: 0.44669053043122464]
	TIME [epoch: 6.73 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20496081548742145		[learning rate: 0.0033546]
	Learning Rate: 0.0033546
	LOSS [training: 0.20496081548742145 | validation: 0.3908099724913712]
	TIME [epoch: 6.79 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.143691594521012		[learning rate: 0.0033388]
	Learning Rate: 0.00333879
	LOSS [training: 0.143691594521012 | validation: 0.30341942544709016]
	TIME [epoch: 6.74 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1263728469090415		[learning rate: 0.0033231]
	Learning Rate: 0.00332306
	LOSS [training: 0.1263728469090415 | validation: 0.3347921804754298]
	TIME [epoch: 6.68 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13927503698894084		[learning rate: 0.0033074]
	Learning Rate: 0.0033074
	LOSS [training: 0.13927503698894084 | validation: 0.326953734737816]
	TIME [epoch: 6.77 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1326590365750286		[learning rate: 0.0032918]
	Learning Rate: 0.00329182
	LOSS [training: 0.1326590365750286 | validation: 0.2800555572774488]
	TIME [epoch: 6.73 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15535769187384335		[learning rate: 0.0032763]
	Learning Rate: 0.00327631
	LOSS [training: 0.15535769187384335 | validation: 0.3298406674418694]
	TIME [epoch: 6.75 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14687673388514058		[learning rate: 0.0032609]
	Learning Rate: 0.00326087
	LOSS [training: 0.14687673388514058 | validation: 0.3154868889266159]
	TIME [epoch: 6.7 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15028723035493982		[learning rate: 0.0032455]
	Learning Rate: 0.0032455
	LOSS [training: 0.15028723035493982 | validation: 0.2997460421579862]
	TIME [epoch: 6.74 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14192915449806848		[learning rate: 0.0032302]
	Learning Rate: 0.00323021
	LOSS [training: 0.14192915449806848 | validation: 0.3141756816021972]
	TIME [epoch: 6.72 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1494380168893969		[learning rate: 0.003215]
	Learning Rate: 0.00321499
	LOSS [training: 0.1494380168893969 | validation: 0.30665734307044645]
	TIME [epoch: 6.78 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14781884768487652		[learning rate: 0.0031998]
	Learning Rate: 0.00319984
	LOSS [training: 0.14781884768487652 | validation: 0.31659820860990656]
	TIME [epoch: 6.73 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15557118617536458		[learning rate: 0.0031848]
	Learning Rate: 0.00318476
	LOSS [training: 0.15557118617536458 | validation: 0.31195556597023816]
	TIME [epoch: 6.7 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1380075029134183		[learning rate: 0.0031698]
	Learning Rate: 0.00316975
	LOSS [training: 0.1380075029134183 | validation: 0.3730947577300128]
	TIME [epoch: 6.76 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15219796577732098		[learning rate: 0.0031548]
	Learning Rate: 0.00315482
	LOSS [training: 0.15219796577732098 | validation: 0.4013285218988368]
	TIME [epoch: 6.75 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1474349913980377		[learning rate: 0.00314]
	Learning Rate: 0.00313995
	LOSS [training: 0.1474349913980377 | validation: 0.34971124871777015]
	TIME [epoch: 6.79 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13401183517199605		[learning rate: 0.0031252]
	Learning Rate: 0.00312516
	LOSS [training: 0.13401183517199605 | validation: 0.3095621847542182]
	TIME [epoch: 6.68 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1286764516572743		[learning rate: 0.0031104]
	Learning Rate: 0.00311043
	LOSS [training: 0.1286764516572743 | validation: 0.33194955566162104]
	TIME [epoch: 6.75 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1062532306939166		[learning rate: 0.0030958]
	Learning Rate: 0.00309577
	LOSS [training: 0.1062532306939166 | validation: 0.3233388715078904]
	TIME [epoch: 6.72 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1406615333399337		[learning rate: 0.0030812]
	Learning Rate: 0.00308119
	LOSS [training: 0.1406615333399337 | validation: 0.32554392244017616]
	TIME [epoch: 6.77 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13212603388156072		[learning rate: 0.0030667]
	Learning Rate: 0.00306667
	LOSS [training: 0.13212603388156072 | validation: 0.28988686083758297]
	TIME [epoch: 6.72 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14038567508682226		[learning rate: 0.0030522]
	Learning Rate: 0.00305222
	LOSS [training: 0.14038567508682226 | validation: 0.35019864230309655]
	TIME [epoch: 6.72 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20658569432362595		[learning rate: 0.0030378]
	Learning Rate: 0.00303783
	LOSS [training: 0.20658569432362595 | validation: 0.36204541737582296]
	TIME [epoch: 6.75 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13332820611593005		[learning rate: 0.0030235]
	Learning Rate: 0.00302352
	LOSS [training: 0.13332820611593005 | validation: 0.32316353310869317]
	TIME [epoch: 6.76 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12364639885104653		[learning rate: 0.0030093]
	Learning Rate: 0.00300927
	LOSS [training: 0.12364639885104653 | validation: 0.3171132376021118]
	TIME [epoch: 6.77 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13285437728755822		[learning rate: 0.0029951]
	Learning Rate: 0.00299509
	LOSS [training: 0.13285437728755822 | validation: 0.29686998320145846]
	TIME [epoch: 6.68 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13205865699171787		[learning rate: 0.002981]
	Learning Rate: 0.00298098
	LOSS [training: 0.13205865699171787 | validation: 0.3708972958593431]
	TIME [epoch: 6.76 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11866247487410336		[learning rate: 0.0029669]
	Learning Rate: 0.00296693
	LOSS [training: 0.11866247487410336 | validation: 0.32448365847485366]
	TIME [epoch: 6.73 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1427023673813807		[learning rate: 0.002953]
	Learning Rate: 0.00295295
	LOSS [training: 0.1427023673813807 | validation: 0.3266468816827772]
	TIME [epoch: 6.79 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1397733274433128		[learning rate: 0.002939]
	Learning Rate: 0.00293904
	LOSS [training: 0.1397733274433128 | validation: 0.31327211085801615]
	TIME [epoch: 6.72 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11113881012884887		[learning rate: 0.0029252]
	Learning Rate: 0.00292519
	LOSS [training: 0.11113881012884887 | validation: 0.32319178249632724]
	TIME [epoch: 6.72 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11905456357765931		[learning rate: 0.0029114]
	Learning Rate: 0.0029114
	LOSS [training: 0.11905456357765931 | validation: 0.315486742757802]
	TIME [epoch: 6.74 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13860770086900054		[learning rate: 0.0028977]
	Learning Rate: 0.00289769
	LOSS [training: 0.13860770086900054 | validation: 0.3730110343600473]
	TIME [epoch: 6.77 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15578785956868843		[learning rate: 0.002884]
	Learning Rate: 0.00288403
	LOSS [training: 0.15578785956868843 | validation: 0.36254315407983256]
	TIME [epoch: 6.75 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.123021908091356		[learning rate: 0.0028704]
	Learning Rate: 0.00287044
	LOSS [training: 0.123021908091356 | validation: 0.3067923981661229]
	TIME [epoch: 6.69 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12286856705690323		[learning rate: 0.0028569]
	Learning Rate: 0.00285692
	LOSS [training: 0.12286856705690323 | validation: 0.34845191511675344]
	TIME [epoch: 6.78 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13816414634550486		[learning rate: 0.0028435]
	Learning Rate: 0.00284345
	LOSS [training: 0.13816414634550486 | validation: 0.3233870535933676]
	TIME [epoch: 6.73 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.150809576597547		[learning rate: 0.0028301]
	Learning Rate: 0.00283005
	LOSS [training: 0.150809576597547 | validation: 0.29514789217201354]
	TIME [epoch: 6.76 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13755736130442908		[learning rate: 0.0028167]
	Learning Rate: 0.00281672
	LOSS [training: 0.13755736130442908 | validation: 0.41029436876852665]
	TIME [epoch: 6.7 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13893153773838524		[learning rate: 0.0028034]
	Learning Rate: 0.00280345
	LOSS [training: 0.13893153773838524 | validation: 0.28800479881763075]
	TIME [epoch: 6.73 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13375289443167415		[learning rate: 0.0027902]
	Learning Rate: 0.00279024
	LOSS [training: 0.13375289443167415 | validation: 0.30469815255988014]
	TIME [epoch: 6.73 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1356034434027785		[learning rate: 0.0027771]
	Learning Rate: 0.00277709
	LOSS [training: 0.1356034434027785 | validation: 0.34211070188339493]
	TIME [epoch: 6.79 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10829601895190437		[learning rate: 0.002764]
	Learning Rate: 0.002764
	LOSS [training: 0.10829601895190437 | validation: 0.30718702660966524]
	TIME [epoch: 6.76 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1382472582687832		[learning rate: 0.002751]
	Learning Rate: 0.00275098
	LOSS [training: 0.1382472582687832 | validation: 0.3186443804611009]
	TIME [epoch: 6.7 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14068983325677278		[learning rate: 0.002738]
	Learning Rate: 0.00273802
	LOSS [training: 0.14068983325677278 | validation: 0.40582387197523895]
	TIME [epoch: 6.76 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15789960762733768		[learning rate: 0.0027251]
	Learning Rate: 0.00272511
	LOSS [training: 0.15789960762733768 | validation: 0.309571485486397]
	TIME [epoch: 6.75 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13231471265561529		[learning rate: 0.0027123]
	Learning Rate: 0.00271227
	LOSS [training: 0.13231471265561529 | validation: 0.3267550044428975]
	TIME [epoch: 6.76 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13820222612507682		[learning rate: 0.0026995]
	Learning Rate: 0.00269949
	LOSS [training: 0.13820222612507682 | validation: 0.32402681355014373]
	TIME [epoch: 6.69 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13886175738499898		[learning rate: 0.0026868]
	Learning Rate: 0.00268677
	LOSS [training: 0.13886175738499898 | validation: 0.3170608004872197]
	TIME [epoch: 6.75 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13169990940044018		[learning rate: 0.0026741]
	Learning Rate: 0.00267411
	LOSS [training: 0.13169990940044018 | validation: 0.3494469227036918]
	TIME [epoch: 6.73 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13495996879536737		[learning rate: 0.0026615]
	Learning Rate: 0.00266151
	LOSS [training: 0.13495996879536737 | validation: 0.28845729427329464]
	TIME [epoch: 6.78 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11377053449181718		[learning rate: 0.002649]
	Learning Rate: 0.00264897
	LOSS [training: 0.11377053449181718 | validation: 0.3094539341521729]
	TIME [epoch: 6.73 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12822783771208407		[learning rate: 0.0026365]
	Learning Rate: 0.00263649
	LOSS [training: 0.12822783771208407 | validation: 0.32135860502060826]
	TIME [epoch: 6.71 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11765966712663023		[learning rate: 0.0026241]
	Learning Rate: 0.00262406
	LOSS [training: 0.11765966712663023 | validation: 0.31048307892873594]
	TIME [epoch: 6.75 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1388940646602354		[learning rate: 0.0026117]
	Learning Rate: 0.0026117
	LOSS [training: 0.1388940646602354 | validation: 0.32104997809435903]
	TIME [epoch: 6.76 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11679297235632352		[learning rate: 0.0025994]
	Learning Rate: 0.00259939
	LOSS [training: 0.11679297235632352 | validation: 0.32957969744961024]
	TIME [epoch: 6.77 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12228893997211698		[learning rate: 0.0025871]
	Learning Rate: 0.00258714
	LOSS [training: 0.12228893997211698 | validation: 0.30838163184982675]
	TIME [epoch: 6.69 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12995630038465275		[learning rate: 0.002575]
	Learning Rate: 0.00257495
	LOSS [training: 0.12995630038465275 | validation: 0.2939848192828848]
	TIME [epoch: 6.75 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12117087385141366		[learning rate: 0.0025628]
	Learning Rate: 0.00256282
	LOSS [training: 0.12117087385141366 | validation: 0.33486313130771006]
	TIME [epoch: 6.72 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12201122511947642		[learning rate: 0.0025507]
	Learning Rate: 0.00255074
	LOSS [training: 0.12201122511947642 | validation: 0.3047867656394863]
	TIME [epoch: 6.78 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12923328673360146		[learning rate: 0.0025387]
	Learning Rate: 0.00253872
	LOSS [training: 0.12923328673360146 | validation: 0.3430721780747819]
	TIME [epoch: 6.72 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12462584015455574		[learning rate: 0.0025268]
	Learning Rate: 0.00252676
	LOSS [training: 0.12462584015455574 | validation: 0.30760440839835324]
	TIME [epoch: 6.75 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13532612670320032		[learning rate: 0.0025149]
	Learning Rate: 0.00251485
	LOSS [training: 0.13532612670320032 | validation: 0.3397318197170649]
	TIME [epoch: 6.75 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12140121062468791		[learning rate: 0.002503]
	Learning Rate: 0.002503
	LOSS [training: 0.12140121062468791 | validation: 0.3377007640470618]
	TIME [epoch: 6.78 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12593160123064434		[learning rate: 0.0024912]
	Learning Rate: 0.00249121
	LOSS [training: 0.12593160123064434 | validation: 0.32434482476425014]
	TIME [epoch: 6.74 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13110336292669866		[learning rate: 0.0024795]
	Learning Rate: 0.00247947
	LOSS [training: 0.13110336292669866 | validation: 0.3078290016287857]
	TIME [epoch: 6.69 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14213487366731736		[learning rate: 0.0024678]
	Learning Rate: 0.00246779
	LOSS [training: 0.14213487366731736 | validation: 0.2857529051264029]
	TIME [epoch: 6.78 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16568650217493985		[learning rate: 0.0024562]
	Learning Rate: 0.00245616
	LOSS [training: 0.16568650217493985 | validation: 0.30448762434655735]
	TIME [epoch: 6.72 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11051343910615138		[learning rate: 0.0024446]
	Learning Rate: 0.00244458
	LOSS [training: 0.11051343910615138 | validation: 0.2789530891273665]
	TIME [epoch: 6.79 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1335759810402348		[learning rate: 0.0024331]
	Learning Rate: 0.00243307
	LOSS [training: 0.1335759810402348 | validation: 0.3151654760489483]
	TIME [epoch: 6.72 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12286344562372617		[learning rate: 0.0024216]
	Learning Rate: 0.0024216
	LOSS [training: 0.12286344562372617 | validation: 0.3541718289187022]
	TIME [epoch: 6.72 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11595957613702969		[learning rate: 0.0024102]
	Learning Rate: 0.00241019
	LOSS [training: 0.11595957613702969 | validation: 0.30602935804131426]
	TIME [epoch: 6.73 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1063390928615397		[learning rate: 0.0023988]
	Learning Rate: 0.00239883
	LOSS [training: 0.1063390928615397 | validation: 0.3220941921563404]
	TIME [epoch: 6.78 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1172573912883644		[learning rate: 0.0023875]
	Learning Rate: 0.00238753
	LOSS [training: 0.1172573912883644 | validation: 0.35475712821821687]
	TIME [epoch: 6.73 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1473438955967557		[learning rate: 0.0023763]
	Learning Rate: 0.00237628
	LOSS [training: 0.1473438955967557 | validation: 0.3267777507025893]
	TIME [epoch: 6.71 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12725603132004237		[learning rate: 0.0023651]
	Learning Rate: 0.00236508
	LOSS [training: 0.12725603132004237 | validation: 0.3189089482523506]
	TIME [epoch: 6.77 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13730526275496552		[learning rate: 0.0023539]
	Learning Rate: 0.00235394
	LOSS [training: 0.13730526275496552 | validation: 0.3613433778012377]
	TIME [epoch: 6.74 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1368277419051522		[learning rate: 0.0023428]
	Learning Rate: 0.00234285
	LOSS [training: 0.1368277419051522 | validation: 0.2855320254026361]
	TIME [epoch: 6.73 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14479900425369902		[learning rate: 0.0023318]
	Learning Rate: 0.00233181
	LOSS [training: 0.14479900425369902 | validation: 0.3077477139283805]
	TIME [epoch: 6.7 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10757062399889658		[learning rate: 0.0023208]
	Learning Rate: 0.00232082
	LOSS [training: 0.10757062399889658 | validation: 0.3111522443925137]
	TIME [epoch: 6.73 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13794007304337375		[learning rate: 0.0023099]
	Learning Rate: 0.00230988
	LOSS [training: 0.13794007304337375 | validation: 0.3354855946496582]
	TIME [epoch: 6.72 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1427536000464906		[learning rate: 0.002299]
	Learning Rate: 0.002299
	LOSS [training: 0.1427536000464906 | validation: 0.333647516326465]
	TIME [epoch: 6.78 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13931953705458477		[learning rate: 0.0022882]
	Learning Rate: 0.00228816
	LOSS [training: 0.13931953705458477 | validation: 0.2846434332355414]
	TIME [epoch: 6.72 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1397796053508052		[learning rate: 0.0022774]
	Learning Rate: 0.00227738
	LOSS [training: 0.1397796053508052 | validation: 0.44939258943213983]
	TIME [epoch: 6.7 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13768112193929294		[learning rate: 0.0022667]
	Learning Rate: 0.00226665
	LOSS [training: 0.13768112193929294 | validation: 0.3153170093918769]
	TIME [epoch: 6.75 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14386861176057822		[learning rate: 0.002256]
	Learning Rate: 0.00225597
	LOSS [training: 0.14386861176057822 | validation: 0.3247543740680061]
	TIME [epoch: 6.73 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12427796541747732		[learning rate: 0.0022453]
	Learning Rate: 0.00224534
	LOSS [training: 0.12427796541747732 | validation: 0.3418465126230742]
	TIME [epoch: 6.78 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1357794949740808		[learning rate: 0.0022348]
	Learning Rate: 0.00223476
	LOSS [training: 0.1357794949740808 | validation: 0.359734039667329]
	TIME [epoch: 6.68 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13435105061496155		[learning rate: 0.0022242]
	Learning Rate: 0.00222423
	LOSS [training: 0.13435105061496155 | validation: 0.3136857409788014]
	TIME [epoch: 6.74 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12050488725437486		[learning rate: 0.0022137]
	Learning Rate: 0.00221375
	LOSS [training: 0.12050488725437486 | validation: 0.2944388646894367]
	TIME [epoch: 6.73 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10960556769199602		[learning rate: 0.0022033]
	Learning Rate: 0.00220332
	LOSS [training: 0.10960556769199602 | validation: 0.30687241128952353]
	TIME [epoch: 6.78 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12412403365049467		[learning rate: 0.0021929]
	Learning Rate: 0.00219293
	LOSS [training: 0.12412403365049467 | validation: 0.2713122055689815]
	TIME [epoch: 6.71 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13778298684737153		[learning rate: 0.0021826]
	Learning Rate: 0.0021826
	LOSS [training: 0.13778298684737153 | validation: 0.32557946675121163]
	TIME [epoch: 6.7 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13107297355947167		[learning rate: 0.0021723]
	Learning Rate: 0.00217232
	LOSS [training: 0.13107297355947167 | validation: 0.33343035585383274]
	TIME [epoch: 6.75 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1268501927163367		[learning rate: 0.0021621]
	Learning Rate: 0.00216208
	LOSS [training: 0.1268501927163367 | validation: 0.30091893362385447]
	TIME [epoch: 6.74 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1131340066231462		[learning rate: 0.0021519]
	Learning Rate: 0.00215189
	LOSS [training: 0.1131340066231462 | validation: 0.31589723250472945]
	TIME [epoch: 6.77 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11885563503353326		[learning rate: 0.0021418]
	Learning Rate: 0.00214175
	LOSS [training: 0.11885563503353326 | validation: 0.3529840919430823]
	TIME [epoch: 6.7 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11594843881432934		[learning rate: 0.0021317]
	Learning Rate: 0.00213166
	LOSS [training: 0.11594843881432934 | validation: 0.3251548230522005]
	TIME [epoch: 6.74 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10985832333180261		[learning rate: 0.0021216]
	Learning Rate: 0.00212162
	LOSS [training: 0.10985832333180261 | validation: 0.3304736431917341]
	TIME [epoch: 6.72 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1400849207665875		[learning rate: 0.0021116]
	Learning Rate: 0.00211162
	LOSS [training: 0.1400849207665875 | validation: 0.31458615601612927]
	TIME [epoch: 6.78 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12752373254431515		[learning rate: 0.0021017]
	Learning Rate: 0.00210167
	LOSS [training: 0.12752373254431515 | validation: 0.34387003751232614]
	TIME [epoch: 6.7 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15066617491542386		[learning rate: 0.0020918]
	Learning Rate: 0.00209176
	LOSS [training: 0.15066617491542386 | validation: 0.30802881654750425]
	TIME [epoch: 6.71 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12289100638004366		[learning rate: 0.0020819]
	Learning Rate: 0.00208191
	LOSS [training: 0.12289100638004366 | validation: 0.32086341598363405]
	TIME [epoch: 6.74 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1456447544007477		[learning rate: 0.0020721]
	Learning Rate: 0.0020721
	LOSS [training: 0.1456447544007477 | validation: 0.3103703676347239]
	TIME [epoch: 6.77 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13937175458000423		[learning rate: 0.0020623]
	Learning Rate: 0.00206233
	LOSS [training: 0.13937175458000423 | validation: 0.32228228729614067]
	TIME [epoch: 6.76 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16087990015822273		[learning rate: 0.0020526]
	Learning Rate: 0.00205262
	LOSS [training: 0.16087990015822273 | validation: 0.2927606475985623]
	TIME [epoch: 6.69 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11569451640379912		[learning rate: 0.0020429]
	Learning Rate: 0.00204294
	LOSS [training: 0.11569451640379912 | validation: 0.3512577155685818]
	TIME [epoch: 6.76 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1085324359352809		[learning rate: 0.0020333]
	Learning Rate: 0.00203332
	LOSS [training: 0.1085324359352809 | validation: 0.298202075048407]
	TIME [epoch: 6.72 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13772177373450567		[learning rate: 0.0020237]
	Learning Rate: 0.00202374
	LOSS [training: 0.13772177373450567 | validation: 0.287312973299199]
	TIME [epoch: 6.77 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15550016239162406		[learning rate: 0.0020142]
	Learning Rate: 0.0020142
	LOSS [training: 0.15550016239162406 | validation: 0.3354007137949209]
	TIME [epoch: 6.71 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12084220687578673		[learning rate: 0.0020047]
	Learning Rate: 0.00200471
	LOSS [training: 0.12084220687578673 | validation: 0.29794542039035155]
	TIME [epoch: 6.72 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1301295423796093		[learning rate: 0.0019953]
	Learning Rate: 0.00199526
	LOSS [training: 0.1301295423796093 | validation: 0.32023847690943147]
	TIME [epoch: 6.72 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12468652100638408		[learning rate: 0.0019859]
	Learning Rate: 0.00198586
	LOSS [training: 0.12468652100638408 | validation: 0.3042890586466343]
	TIME [epoch: 6.77 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12040893482324416		[learning rate: 0.0019765]
	Learning Rate: 0.0019765
	LOSS [training: 0.12040893482324416 | validation: 0.2731250622199866]
	TIME [epoch: 6.75 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1303628471987847		[learning rate: 0.0019672]
	Learning Rate: 0.00196719
	LOSS [training: 0.1303628471987847 | validation: 0.30650342912707196]
	TIME [epoch: 6.68 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.157144543949764		[learning rate: 0.0019579]
	Learning Rate: 0.00195792
	LOSS [training: 0.157144543949764 | validation: 0.3298229648735812]
	TIME [epoch: 6.76 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14312902774782546		[learning rate: 0.0019487]
	Learning Rate: 0.00194869
	LOSS [training: 0.14312902774782546 | validation: 0.31981490590765554]
	TIME [epoch: 6.73 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14518873301318008		[learning rate: 0.0019395]
	Learning Rate: 0.00193951
	LOSS [training: 0.14518873301318008 | validation: 0.30845324544393526]
	TIME [epoch: 6.78 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12251042537621101		[learning rate: 0.0019304]
	Learning Rate: 0.00193037
	LOSS [training: 0.12251042537621101 | validation: 0.28326764478968514]
	TIME [epoch: 6.71 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11066863111584542		[learning rate: 0.0019213]
	Learning Rate: 0.00192128
	LOSS [training: 0.11066863111584542 | validation: 0.3247114266400283]
	TIME [epoch: 6.72 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1170838988025431		[learning rate: 0.0019122]
	Learning Rate: 0.00191222
	LOSS [training: 0.1170838988025431 | validation: 0.38839713026884615]
	TIME [epoch: 6.72 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15172296308148803		[learning rate: 0.0019032]
	Learning Rate: 0.00190321
	LOSS [training: 0.15172296308148803 | validation: 0.3109894189729049]
	TIME [epoch: 6.77 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13012255639086584		[learning rate: 0.0018942]
	Learning Rate: 0.00189424
	LOSS [training: 0.13012255639086584 | validation: 0.3435210775625352]
	TIME [epoch: 6.69 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1489973782420183		[learning rate: 0.0018853]
	Learning Rate: 0.00188532
	LOSS [training: 0.1489973782420183 | validation: 0.2776748507152338]
	TIME [epoch: 6.69 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12708028218596235		[learning rate: 0.0018764]
	Learning Rate: 0.00187643
	LOSS [training: 0.12708028218596235 | validation: 0.3507226674730346]
	TIME [epoch: 6.76 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13186164496867075		[learning rate: 0.0018676]
	Learning Rate: 0.00186759
	LOSS [training: 0.13186164496867075 | validation: 0.3182376374883168]
	TIME [epoch: 6.73 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12995782643450793		[learning rate: 0.0018588]
	Learning Rate: 0.00185879
	LOSS [training: 0.12995782643450793 | validation: 0.3135068954975371]
	TIME [epoch: 6.75 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10614722527730737		[learning rate: 0.00185]
	Learning Rate: 0.00185003
	LOSS [training: 0.10614722527730737 | validation: 0.3143515571905149]
	TIME [epoch: 6.7 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11453889700634226		[learning rate: 0.0018413]
	Learning Rate: 0.00184132
	LOSS [training: 0.11453889700634226 | validation: 0.3224673715680099]
	TIME [epoch: 6.73 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12154005134257014		[learning rate: 0.0018326]
	Learning Rate: 0.00183264
	LOSS [training: 0.12154005134257014 | validation: 0.33122153495385787]
	TIME [epoch: 6.71 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13660356462640555		[learning rate: 0.001824]
	Learning Rate: 0.001824
	LOSS [training: 0.13660356462640555 | validation: 0.28974728697711694]
	TIME [epoch: 6.79 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11639458538727097		[learning rate: 0.0018154]
	Learning Rate: 0.00181541
	LOSS [training: 0.11639458538727097 | validation: 0.326077270263623]
	TIME [epoch: 6.73 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11847107932965105		[learning rate: 0.0018069]
	Learning Rate: 0.00180685
	LOSS [training: 0.11847107932965105 | validation: 0.3344585453447163]
	TIME [epoch: 6.69 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1087406910138258		[learning rate: 0.0017983]
	Learning Rate: 0.00179834
	LOSS [training: 0.1087406910138258 | validation: 0.30730465733000784]
	TIME [epoch: 6.75 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11435623294068856		[learning rate: 0.0017899]
	Learning Rate: 0.00178987
	LOSS [training: 0.11435623294068856 | validation: 0.28300023300845917]
	TIME [epoch: 6.76 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13008737723465305		[learning rate: 0.0017814]
	Learning Rate: 0.00178143
	LOSS [training: 0.13008737723465305 | validation: 0.33296312160059466]
	TIME [epoch: 6.76 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11592727509497147		[learning rate: 0.001773]
	Learning Rate: 0.00177304
	LOSS [training: 0.11592727509497147 | validation: 0.3262678864766173]
	TIME [epoch: 6.71 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09839834244718443		[learning rate: 0.0017647]
	Learning Rate: 0.00176468
	LOSS [training: 0.09839834244718443 | validation: 0.28391624038289465]
	TIME [epoch: 6.78 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12056523901425803		[learning rate: 0.0017564]
	Learning Rate: 0.00175637
	LOSS [training: 0.12056523901425803 | validation: 0.34208949426992874]
	TIME [epoch: 6.73 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1262783193185527		[learning rate: 0.0017481]
	Learning Rate: 0.00174809
	LOSS [training: 0.1262783193185527 | validation: 0.29660903778098013]
	TIME [epoch: 6.79 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14811152241373482		[learning rate: 0.0017399]
	Learning Rate: 0.00173985
	LOSS [training: 0.14811152241373482 | validation: 0.38946800175275925]
	TIME [epoch: 6.72 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12343088128214405		[learning rate: 0.0017317]
	Learning Rate: 0.00173166
	LOSS [training: 0.12343088128214405 | validation: 0.3124924113344687]
	TIME [epoch: 6.73 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12230481096302012		[learning rate: 0.0017235]
	Learning Rate: 0.0017235
	LOSS [training: 0.12230481096302012 | validation: 0.28369249275025527]
	TIME [epoch: 6.74 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12006866607558689		[learning rate: 0.0017154]
	Learning Rate: 0.00171537
	LOSS [training: 0.12006866607558689 | validation: 0.3609412936283045]
	TIME [epoch: 6.71 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12034606712510461		[learning rate: 0.0017073]
	Learning Rate: 0.00170729
	LOSS [training: 0.12034606712510461 | validation: 0.3410884659428215]
	TIME [epoch: 6.71 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10958818441570276		[learning rate: 0.0016992]
	Learning Rate: 0.00169925
	LOSS [training: 0.10958818441570276 | validation: 0.33518057169555443]
	TIME [epoch: 6.7 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12974656887426508		[learning rate: 0.0016912]
	Learning Rate: 0.00169124
	LOSS [training: 0.12974656887426508 | validation: 0.32001051336797653]
	TIME [epoch: 6.73 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1437869323764393		[learning rate: 0.0016833]
	Learning Rate: 0.00168327
	LOSS [training: 0.1437869323764393 | validation: 0.323691282445673]
	TIME [epoch: 6.72 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13602173593753253		[learning rate: 0.0016753]
	Learning Rate: 0.00167534
	LOSS [training: 0.13602173593753253 | validation: 0.3051068996807731]
	TIME [epoch: 6.7 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13764283293116036		[learning rate: 0.0016674]
	Learning Rate: 0.00166744
	LOSS [training: 0.13764283293116036 | validation: 0.33874782137059756]
	TIME [epoch: 6.7 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11648921749099053		[learning rate: 0.0016596]
	Learning Rate: 0.00165959
	LOSS [training: 0.11648921749099053 | validation: 0.3106671996758458]
	TIME [epoch: 6.73 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13483046301095752		[learning rate: 0.0016518]
	Learning Rate: 0.00165177
	LOSS [training: 0.13483046301095752 | validation: 0.3060094333864808]
	TIME [epoch: 6.7 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11897096839962415		[learning rate: 0.001644]
	Learning Rate: 0.00164398
	LOSS [training: 0.11897096839962415 | validation: 0.33209584097222045]
	TIME [epoch: 6.73 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12594045888264424		[learning rate: 0.0016362]
	Learning Rate: 0.00163624
	LOSS [training: 0.12594045888264424 | validation: 0.30491544351764915]
	TIME [epoch: 6.72 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1056030311568139		[learning rate: 0.0016285]
	Learning Rate: 0.00162853
	LOSS [training: 0.1056030311568139 | validation: 0.3395047605603791]
	TIME [epoch: 6.7 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1069525358270566		[learning rate: 0.0016209]
	Learning Rate: 0.00162085
	LOSS [training: 0.1069525358270566 | validation: 0.27566268065168525]
	TIME [epoch: 6.75 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10894788761936877		[learning rate: 0.0016132]
	Learning Rate: 0.00161322
	LOSS [training: 0.10894788761936877 | validation: 0.334694883486151]
	TIME [epoch: 6.74 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11671461890887794		[learning rate: 0.0016056]
	Learning Rate: 0.00160561
	LOSS [training: 0.11671461890887794 | validation: 0.3179178956671395]
	TIME [epoch: 6.8 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11947145752103998		[learning rate: 0.001598]
	Learning Rate: 0.00159805
	LOSS [training: 0.11947145752103998 | validation: 0.3381848438239779]
	TIME [epoch: 6.72 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14527335563591962		[learning rate: 0.0015905]
	Learning Rate: 0.00159052
	LOSS [training: 0.14527335563591962 | validation: 0.2978341079711968]
	TIME [epoch: 6.74 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12240096939761796		[learning rate: 0.001583]
	Learning Rate: 0.00158302
	LOSS [training: 0.12240096939761796 | validation: 0.2771798611334965]
	TIME [epoch: 6.72 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10299335336620431		[learning rate: 0.0015756]
	Learning Rate: 0.00157556
	LOSS [training: 0.10299335336620431 | validation: 0.3076266499572837]
	TIME [epoch: 6.79 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v15_20240718_190304/states/model_facs_v4_dec2b_2dpca_v15_429.pth
Halted early. No improvement in validation loss for 200 epochs.
Finished training in 2794.156 seconds.
