Args:
Namespace(name='model_facs_v2_dec1b_2dpca_v4', outdir='out/model_training/model_facs_v2_dec1b_2dpca_v4', training_data='data/training_data/facs_v2/pca/dec1_fitonsubset/transition1_subset_epi_tr_ce_an_pc12/training', validation_data='data/training_data/facs_v2/pca/dec1_fitonsubset/transition1_subset_epi_tr_ce_an_pc12/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=10, batch_size=50, patience=200, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, quadratic_a=1.0, quadratic_b=1.0, ndims=2, nparams=2, nsigs=2, ncells=1000, ncells_sample=1000, model_do_sample=False, dt=0.001, dt_schedule='stepped', dt_schedule_bounds=[200, 500, 1000], dt_schedule_scales=[0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=True, sigma=0.1, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', kernel='multiscale', bw_range=[0.2, 0.5, 0.9, 1.1, 1.3, 1.5, 2.0], optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 2505769679

Training model...

Saving initial model state to: out/model_training/model_facs_v2_dec1b_2dpca_v4_20240711_145314/states/model_facs_v2_dec1b_2dpca_v4_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.4253386810912525		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4253386810912525 | validation: 1.1535345505045829]
	TIME [epoch: 136 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v4_20240711_145314/states/model_facs_v2_dec1b_2dpca_v4_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.1716520569967273		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1716520569967273 | validation: 1.0555134305162917]
	TIME [epoch: 99 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v4_20240711_145314/states/model_facs_v2_dec1b_2dpca_v4_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.1157398735504223		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1157398735504223 | validation: 1.076390991667655]
	TIME [epoch: 99 sec]
EPOCH 4/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.0768302035442412		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0768302035442412 | validation: 0.9118645351247997]
	TIME [epoch: 99 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v4_20240711_145314/states/model_facs_v2_dec1b_2dpca_v4_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.9881948677493892		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9881948677493892 | validation: 0.8157652129023407]
	TIME [epoch: 99 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v4_20240711_145314/states/model_facs_v2_dec1b_2dpca_v4_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.9648482814556922		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9648482814556922 | validation: 0.7945576948195996]
	TIME [epoch: 99 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v4_20240711_145314/states/model_facs_v2_dec1b_2dpca_v4_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.8963208275236203		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8963208275236203 | validation: 0.751987132873145]
	TIME [epoch: 99 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v4_20240711_145314/states/model_facs_v2_dec1b_2dpca_v4_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.8630839623420608		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8630839623420608 | validation: 0.7097420119079064]
	TIME [epoch: 98.9 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v4_20240711_145314/states/model_facs_v2_dec1b_2dpca_v4_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.8344514446375184		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8344514446375184 | validation: 0.7073543345085253]
	TIME [epoch: 98.9 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v4_20240711_145314/states/model_facs_v2_dec1b_2dpca_v4_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7359797605971621		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7359797605971621 | validation: 0.7421973160887791]
	TIME [epoch: 99 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7289669191127393		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7289669191127393 | validation: 0.6126161393283044]
	TIME [epoch: 98.9 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v4_20240711_145314/states/model_facs_v2_dec1b_2dpca_v4_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6664272165124083		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6664272165124083 | validation: 0.6111742828234087]
	TIME [epoch: 99 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v4_20240711_145314/states/model_facs_v2_dec1b_2dpca_v4_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7948583134673064		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7948583134673064 | validation: 0.570057847626271]
	TIME [epoch: 99 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v4_20240711_145314/states/model_facs_v2_dec1b_2dpca_v4_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6074385468912017		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6074385468912017 | validation: 0.5013789238410487]
	TIME [epoch: 98.9 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v4_20240711_145314/states/model_facs_v2_dec1b_2dpca_v4_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6045517816737096		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6045517816737096 | validation: 0.5791711870352814]
	TIME [epoch: 99 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6524632592916523		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6524632592916523 | validation: 0.49060390419934696]
	TIME [epoch: 99 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v4_20240711_145314/states/model_facs_v2_dec1b_2dpca_v4_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6390871168268023		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6390871168268023 | validation: 0.597539806104828]
	TIME [epoch: 98.9 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5955642726941497		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5955642726941497 | validation: 0.49357647906146296]
	TIME [epoch: 99 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.616570624799149		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.616570624799149 | validation: 0.9051306643703672]
	TIME [epoch: 99.1 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6024206532063509		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6024206532063509 | validation: 0.5026690819169832]
	TIME [epoch: 99 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5645413360090258		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5645413360090258 | validation: 0.44875247191979106]
	TIME [epoch: 98.9 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v4_20240711_145314/states/model_facs_v2_dec1b_2dpca_v4_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5851227026495567		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5851227026495567 | validation: 0.5119300132155375]
	TIME [epoch: 98.9 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5953053172090864		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5953053172090864 | validation: 0.47863981870304634]
	TIME [epoch: 98.9 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5648970900229744		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5648970900229744 | validation: 0.5036993100485005]
	TIME [epoch: 98.9 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5064387287748099		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5064387287748099 | validation: 0.4612022661908677]
	TIME [epoch: 99 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5502062170041088		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5502062170041088 | validation: 0.5377112656300151]
	TIME [epoch: 99 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7033636127631561		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7033636127631561 | validation: 0.6065328018463936]
	TIME [epoch: 99 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6622937582783016		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6622937582783016 | validation: 0.5624469562151222]
	TIME [epoch: 99 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5828291698427277		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5828291698427277 | validation: 0.4884971006095338]
	TIME [epoch: 99 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5655561173700533		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5655561173700533 | validation: 0.5110933609269086]
	TIME [epoch: 99 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5344866104150875		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5344866104150875 | validation: 0.5256917805980965]
	TIME [epoch: 99 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5240309355861739		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5240309355861739 | validation: 0.4421325557291655]
	TIME [epoch: 98.9 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v4_20240711_145314/states/model_facs_v2_dec1b_2dpca_v4_32.pth
	Model improved!!!
EPOCH 33/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.49498185823733476		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.49498185823733476 | validation: 0.5976827920675926]
	TIME [epoch: 98.9 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5308506389163333		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5308506389163333 | validation: 0.45491543091721953]
	TIME [epoch: 98.9 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5466784618021224		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5466784618021224 | validation: 0.5200748316413533]
	TIME [epoch: 98.9 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5178074895215485		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5178074895215485 | validation: 0.5276742574547743]
	TIME [epoch: 98.9 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.44570314311922643		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.44570314311922643 | validation: 0.43201232208229223]
	TIME [epoch: 98.9 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v4_20240711_145314/states/model_facs_v2_dec1b_2dpca_v4_37.pth
	Model improved!!!
EPOCH 38/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4249626142883847		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4249626142883847 | validation: 0.5829585167860479]
	TIME [epoch: 98.9 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5549521737962487		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5549521737962487 | validation: 0.5475438534760083]
	TIME [epoch: 98.9 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5895482044362219		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5895482044362219 | validation: 0.46469911185897084]
	TIME [epoch: 98.9 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.588856346714174		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.588856346714174 | validation: 0.4606841027156764]
	TIME [epoch: 98.9 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4538294257752076		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4538294257752076 | validation: 0.56289987213095]
	TIME [epoch: 98.9 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.535621049709056		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.535621049709056 | validation: 0.4472763990129174]
	TIME [epoch: 99 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4791040111456304		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4791040111456304 | validation: 0.6141173600012458]
	TIME [epoch: 98.9 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.564697668506136		[learning rate: 0.0099823]
	Learning Rate: 0.0099823
	LOSS [training: 0.564697668506136 | validation: 0.5054655010270118]
	TIME [epoch: 98.9 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5467338293082306		[learning rate: 0.0099426]
	Learning Rate: 0.0099426
	LOSS [training: 0.5467338293082306 | validation: 0.43675969997016484]
	TIME [epoch: 99 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5044681535276985		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 0.5044681535276985 | validation: 0.5437866925365253]
	TIME [epoch: 99 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4360540460317286		[learning rate: 0.0098637]
	Learning Rate: 0.00986367
	LOSS [training: 0.4360540460317286 | validation: 0.3786882829955597]
	TIME [epoch: 98.9 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v4_20240711_145314/states/model_facs_v2_dec1b_2dpca_v4_48.pth
	Model improved!!!
EPOCH 49/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.525522875622953		[learning rate: 0.0098244]
	Learning Rate: 0.00982444
	LOSS [training: 0.525522875622953 | validation: 0.42296603039590347]
	TIME [epoch: 99 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.46209521018525546		[learning rate: 0.0097854]
	Learning Rate: 0.00978536
	LOSS [training: 0.46209521018525546 | validation: 0.41039580446040763]
	TIME [epoch: 99 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.41990079246658923		[learning rate: 0.0097464]
	Learning Rate: 0.00974644
	LOSS [training: 0.41990079246658923 | validation: 0.5967480590478219]
	TIME [epoch: 99 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.46645098722248474		[learning rate: 0.0097077]
	Learning Rate: 0.00970768
	LOSS [training: 0.46645098722248474 | validation: 0.3974573613901687]
	TIME [epoch: 99 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.419513573891883		[learning rate: 0.0096691]
	Learning Rate: 0.00966907
	LOSS [training: 0.419513573891883 | validation: 0.5426937679156606]
	TIME [epoch: 99 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.45386907249587793		[learning rate: 0.0096306]
	Learning Rate: 0.00963061
	LOSS [training: 0.45386907249587793 | validation: 0.5801915851368162]
	TIME [epoch: 98.9 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4820790723674816		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 0.4820790723674816 | validation: 0.43940988092586303]
	TIME [epoch: 98.9 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4042435152388896		[learning rate: 0.0095542]
	Learning Rate: 0.00955415
	LOSS [training: 0.4042435152388896 | validation: 0.4199229989721191]
	TIME [epoch: 98.9 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.45349676368790554		[learning rate: 0.0095162]
	Learning Rate: 0.00951616
	LOSS [training: 0.45349676368790554 | validation: 0.5367801424987613]
	TIME [epoch: 98.9 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4291472943794752		[learning rate: 0.0094783]
	Learning Rate: 0.00947831
	LOSS [training: 0.4291472943794752 | validation: 0.41400144514059545]
	TIME [epoch: 99 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.40160875222820935		[learning rate: 0.0094406]
	Learning Rate: 0.00944061
	LOSS [training: 0.40160875222820935 | validation: 0.37555415796776837]
	TIME [epoch: 98.9 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v4_20240711_145314/states/model_facs_v2_dec1b_2dpca_v4_59.pth
	Model improved!!!
EPOCH 60/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.43922452417652147		[learning rate: 0.0094031]
	Learning Rate: 0.00940306
	LOSS [training: 0.43922452417652147 | validation: 0.5161179344208034]
	TIME [epoch: 98.9 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4280532335800674		[learning rate: 0.0093657]
	Learning Rate: 0.00936566
	LOSS [training: 0.4280532335800674 | validation: 0.45202243040544665]
	TIME [epoch: 98.9 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4189034294027312		[learning rate: 0.0093284]
	Learning Rate: 0.00932841
	LOSS [training: 0.4189034294027312 | validation: 0.3983409327034414]
	TIME [epoch: 98.9 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4358372173937052		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 0.4358372173937052 | validation: 0.385962329267408]
	TIME [epoch: 98.9 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.44398283663782045		[learning rate: 0.0092544]
	Learning Rate: 0.00925435
	LOSS [training: 0.44398283663782045 | validation: 0.38333920315957515]
	TIME [epoch: 98.9 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.39976988617173953		[learning rate: 0.0092175]
	Learning Rate: 0.00921755
	LOSS [training: 0.39976988617173953 | validation: 0.441075544218737]
	TIME [epoch: 98.9 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.39290682466601945		[learning rate: 0.0091809]
	Learning Rate: 0.00918089
	LOSS [training: 0.39290682466601945 | validation: 0.45318420456075365]
	TIME [epoch: 98.9 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.42526554873401035		[learning rate: 0.0091444]
	Learning Rate: 0.00914437
	LOSS [training: 0.42526554873401035 | validation: 0.39715880817900134]
	TIME [epoch: 98.9 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4095831212661698		[learning rate: 0.009108]
	Learning Rate: 0.009108
	LOSS [training: 0.4095831212661698 | validation: 0.47009011565391096]
	TIME [epoch: 98.9 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.40802435209663535		[learning rate: 0.0090718]
	Learning Rate: 0.00907178
	LOSS [training: 0.40802435209663535 | validation: 0.37316929377033775]
	TIME [epoch: 98.9 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v4_20240711_145314/states/model_facs_v2_dec1b_2dpca_v4_69.pth
	Model improved!!!
EPOCH 70/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.42446926061304635		[learning rate: 0.0090357]
	Learning Rate: 0.00903569
	LOSS [training: 0.42446926061304635 | validation: 0.4202473149733185]
	TIME [epoch: 99 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.42953572735902606		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 0.42953572735902606 | validation: 0.3577480871314421]
	TIME [epoch: 98.9 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v4_20240711_145314/states/model_facs_v2_dec1b_2dpca_v4_71.pth
	Model improved!!!
EPOCH 72/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.39333888152938784		[learning rate: 0.008964]
	Learning Rate: 0.00896396
	LOSS [training: 0.39333888152938784 | validation: 0.3918359088942547]
	TIME [epoch: 99 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.44867912691222084		[learning rate: 0.0089283]
	Learning Rate: 0.00892831
	LOSS [training: 0.44867912691222084 | validation: 0.3790686396857285]
	TIME [epoch: 99 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.36337456574836335		[learning rate: 0.0088928]
	Learning Rate: 0.0088928
	LOSS [training: 0.36337456574836335 | validation: 0.35515897772363497]
	TIME [epoch: 99 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v4_20240711_145314/states/model_facs_v2_dec1b_2dpca_v4_74.pth
	Model improved!!!
EPOCH 75/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.41576778314135227		[learning rate: 0.0088574]
	Learning Rate: 0.00885743
	LOSS [training: 0.41576778314135227 | validation: 0.41609139273949125]
	TIME [epoch: 99.2 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3947607040200335		[learning rate: 0.0088222]
	Learning Rate: 0.0088222
	LOSS [training: 0.3947607040200335 | validation: 0.42063928432548475]
	TIME [epoch: 99 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.38255418734212854		[learning rate: 0.0087871]
	Learning Rate: 0.00878711
	LOSS [training: 0.38255418734212854 | validation: 0.3512714470329101]
	TIME [epoch: 99 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v4_20240711_145314/states/model_facs_v2_dec1b_2dpca_v4_77.pth
	Model improved!!!
EPOCH 78/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.42480655410944623		[learning rate: 0.0087522]
	Learning Rate: 0.00875216
	LOSS [training: 0.42480655410944623 | validation: 0.3481427820238758]
	TIME [epoch: 98.9 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v4_20240711_145314/states/model_facs_v2_dec1b_2dpca_v4_78.pth
	Model improved!!!
EPOCH 79/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.362016908537427		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 0.362016908537427 | validation: 0.3638658782085697]
	TIME [epoch: 98.9 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3933072982666669		[learning rate: 0.0086827]
	Learning Rate: 0.00868268
	LOSS [training: 0.3933072982666669 | validation: 0.4368679733140374]
	TIME [epoch: 98.9 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4236338920113416		[learning rate: 0.0086481]
	Learning Rate: 0.00864815
	LOSS [training: 0.4236338920113416 | validation: 0.39612537270600445]
	TIME [epoch: 98.9 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.38582137182548226		[learning rate: 0.0086138]
	Learning Rate: 0.00861375
	LOSS [training: 0.38582137182548226 | validation: 0.4404919639179267]
	TIME [epoch: 98.9 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4435806644537078		[learning rate: 0.0085795]
	Learning Rate: 0.00857949
	LOSS [training: 0.4435806644537078 | validation: 0.36732958670403415]
	TIME [epoch: 98.9 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3617676232102565		[learning rate: 0.0085454]
	Learning Rate: 0.00854537
	LOSS [training: 0.3617676232102565 | validation: 0.3853636765024518]
	TIME [epoch: 99 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3580554639530721		[learning rate: 0.0085114]
	Learning Rate: 0.00851138
	LOSS [training: 0.3580554639530721 | validation: 0.3625816889506813]
	TIME [epoch: 99 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.40199809540977754		[learning rate: 0.0084775]
	Learning Rate: 0.00847753
	LOSS [training: 0.40199809540977754 | validation: 0.37925942066527124]
	TIME [epoch: 98.9 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.37781856146693094		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 0.37781856146693094 | validation: 0.434325318929594]
	TIME [epoch: 99 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3802728161739691		[learning rate: 0.0084102]
	Learning Rate: 0.00841023
	LOSS [training: 0.3802728161739691 | validation: 0.8110832156171034]
	TIME [epoch: 99 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4525048373117093		[learning rate: 0.0083768]
	Learning Rate: 0.00837678
	LOSS [training: 0.4525048373117093 | validation: 0.34018975734283224]
	TIME [epoch: 99 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v4_20240711_145314/states/model_facs_v2_dec1b_2dpca_v4_89.pth
	Model improved!!!
EPOCH 90/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3574668270641071		[learning rate: 0.0083435]
	Learning Rate: 0.00834346
	LOSS [training: 0.3574668270641071 | validation: 0.43597741959802977]
	TIME [epoch: 99 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.38073451267486746		[learning rate: 0.0083103]
	Learning Rate: 0.00831027
	LOSS [training: 0.38073451267486746 | validation: 0.35173708725505803]
	TIME [epoch: 99 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4075273867759243		[learning rate: 0.0082772]
	Learning Rate: 0.00827722
	LOSS [training: 0.4075273867759243 | validation: 0.37635404135538175]
	TIME [epoch: 99 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.37552509724261024		[learning rate: 0.0082443]
	Learning Rate: 0.0082443
	LOSS [training: 0.37552509724261024 | validation: 0.3377057726283287]
	TIME [epoch: 99 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v4_20240711_145314/states/model_facs_v2_dec1b_2dpca_v4_93.pth
	Model improved!!!
EPOCH 94/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3518746526222352		[learning rate: 0.0082115]
	Learning Rate: 0.00821151
	LOSS [training: 0.3518746526222352 | validation: 0.3761087699141067]
	TIME [epoch: 99 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3933803631996533		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 0.3933803631996533 | validation: 0.3356174282377784]
	TIME [epoch: 98.9 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v4_20240711_145314/states/model_facs_v2_dec1b_2dpca_v4_95.pth
	Model improved!!!
EPOCH 96/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.42169149533100075		[learning rate: 0.0081463]
	Learning Rate: 0.00814632
	LOSS [training: 0.42169149533100075 | validation: 0.3990635055005201]
	TIME [epoch: 99 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3647091032498235		[learning rate: 0.0081139]
	Learning Rate: 0.00811392
	LOSS [training: 0.3647091032498235 | validation: 0.3639043795091324]
	TIME [epoch: 98.9 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.36104072358770395		[learning rate: 0.0080816]
	Learning Rate: 0.00808165
	LOSS [training: 0.36104072358770395 | validation: 0.351412821798339]
	TIME [epoch: 98.9 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.38685361778084604		[learning rate: 0.0080495]
	Learning Rate: 0.00804951
	LOSS [training: 0.38685361778084604 | validation: 0.3427980524707418]
	TIME [epoch: 98.9 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.34865057404283295		[learning rate: 0.0080175]
	Learning Rate: 0.00801749
	LOSS [training: 0.34865057404283295 | validation: 0.3824159914480637]
	TIME [epoch: 98.9 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3587961977441528		[learning rate: 0.0079856]
	Learning Rate: 0.0079856
	LOSS [training: 0.3587961977441528 | validation: 0.38973992828553783]
	TIME [epoch: 98.9 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4005803691558622		[learning rate: 0.0079538]
	Learning Rate: 0.00795384
	LOSS [training: 0.4005803691558622 | validation: 0.40828286679155995]
	TIME [epoch: 98.9 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3958415172516073		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 0.3958415172516073 | validation: 0.42006517804247956]
	TIME [epoch: 98.9 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.36249641200464466		[learning rate: 0.0078907]
	Learning Rate: 0.0078907
	LOSS [training: 0.36249641200464466 | validation: 0.33321150585110215]
	TIME [epoch: 98.9 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v4_20240711_145314/states/model_facs_v2_dec1b_2dpca_v4_104.pth
	Model improved!!!
EPOCH 105/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.34966133352450574		[learning rate: 0.0078593]
	Learning Rate: 0.00785931
	LOSS [training: 0.34966133352450574 | validation: 0.4397011610658364]
	TIME [epoch: 98.9 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3638132341884675		[learning rate: 0.0078281]
	Learning Rate: 0.00782805
	LOSS [training: 0.3638132341884675 | validation: 0.340578603726973]
	TIME [epoch: 98.9 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3675528289532368		[learning rate: 0.0077969]
	Learning Rate: 0.00779692
	LOSS [training: 0.3675528289532368 | validation: 0.4055363910396094]
	TIME [epoch: 98.9 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.37781996938425644		[learning rate: 0.0077659]
	Learning Rate: 0.00776591
	LOSS [training: 0.37781996938425644 | validation: 0.3733498270136274]
	TIME [epoch: 98.9 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3582232109305086		[learning rate: 0.007735]
	Learning Rate: 0.00773502
	LOSS [training: 0.3582232109305086 | validation: 0.3609696020290587]
	TIME [epoch: 98.8 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3484302894469669		[learning rate: 0.0077043]
	Learning Rate: 0.00770426
	LOSS [training: 0.3484302894469669 | validation: 0.3508536901441782]
	TIME [epoch: 98.9 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.37227419882642204		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 0.37227419882642204 | validation: 0.3382692428058592]
	TIME [epoch: 98.8 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.35753001735777473		[learning rate: 0.0076431]
	Learning Rate: 0.00764309
	LOSS [training: 0.35753001735777473 | validation: 0.4018691650362708]
	TIME [epoch: 98.9 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3654152666924254		[learning rate: 0.0076127]
	Learning Rate: 0.00761269
	LOSS [training: 0.3654152666924254 | validation: 0.378158229415948]
	TIME [epoch: 98.9 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.35981707571271343		[learning rate: 0.0075824]
	Learning Rate: 0.00758242
	LOSS [training: 0.35981707571271343 | validation: 0.36783057617167425]
	TIME [epoch: 98.8 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3591131952341746		[learning rate: 0.0075523]
	Learning Rate: 0.00755226
	LOSS [training: 0.3591131952341746 | validation: 0.4335040439329257]
	TIME [epoch: 98.9 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3679446022746371		[learning rate: 0.0075222]
	Learning Rate: 0.00752222
	LOSS [training: 0.3679446022746371 | validation: 0.3180315725191272]
	TIME [epoch: 98.8 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v4_20240711_145314/states/model_facs_v2_dec1b_2dpca_v4_116.pth
	Model improved!!!
EPOCH 117/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.35012698967592754		[learning rate: 0.0074923]
	Learning Rate: 0.0074923
	LOSS [training: 0.35012698967592754 | validation: 0.3822692904561334]
	TIME [epoch: 99 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3711708828661051		[learning rate: 0.0074625]
	Learning Rate: 0.0074625
	LOSS [training: 0.3711708828661051 | validation: 0.38828348423322356]
	TIME [epoch: 98.9 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.34882228353673717		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 0.34882228353673717 | validation: 0.3220471247386082]
	TIME [epoch: 99 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.34738828250502346		[learning rate: 0.0074033]
	Learning Rate: 0.00740326
	LOSS [training: 0.34738828250502346 | validation: 0.38264029915185904]
	TIME [epoch: 99 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3512881952123728		[learning rate: 0.0073738]
	Learning Rate: 0.00737382
	LOSS [training: 0.3512881952123728 | validation: 0.379080397168748]
	TIME [epoch: 99 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3628603717513449		[learning rate: 0.0073445]
	Learning Rate: 0.00734449
	LOSS [training: 0.3628603717513449 | validation: 0.33489804633243436]
	TIME [epoch: 99 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.33601845379630224		[learning rate: 0.0073153]
	Learning Rate: 0.00731528
	LOSS [training: 0.33601845379630224 | validation: 0.4447344293908847]
	TIME [epoch: 98.9 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3777467959784887		[learning rate: 0.0072862]
	Learning Rate: 0.00728618
	LOSS [training: 0.3777467959784887 | validation: 0.3797579920027537]
	TIME [epoch: 98.9 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4197664008755828		[learning rate: 0.0072572]
	Learning Rate: 0.0072572
	LOSS [training: 0.4197664008755828 | validation: 0.3598996670468433]
	TIME [epoch: 99 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.35955615166728755		[learning rate: 0.0072283]
	Learning Rate: 0.00722834
	LOSS [training: 0.35955615166728755 | validation: 0.32398581823728057]
	TIME [epoch: 99 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3403087210484921		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 0.3403087210484921 | validation: 0.43730019806730774]
	TIME [epoch: 99 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4807771196582289		[learning rate: 0.007171]
	Learning Rate: 0.00717095
	LOSS [training: 0.4807771196582289 | validation: 0.4676104796176812]
	TIME [epoch: 99 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.45775711831731897		[learning rate: 0.0071424]
	Learning Rate: 0.00714243
	LOSS [training: 0.45775711831731897 | validation: 0.39893974464011717]
	TIME [epoch: 98.9 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3725617889018815		[learning rate: 0.007114]
	Learning Rate: 0.00711403
	LOSS [training: 0.3725617889018815 | validation: 0.4229979928986981]
	TIME [epoch: 99 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.36690407582882245		[learning rate: 0.0070857]
	Learning Rate: 0.00708573
	LOSS [training: 0.36690407582882245 | validation: 0.4018943336854002]
	TIME [epoch: 98.9 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.38849801417054125		[learning rate: 0.0070575]
	Learning Rate: 0.00705755
	LOSS [training: 0.38849801417054125 | validation: 0.3986478510520781]
	TIME [epoch: 98.9 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3518895023628003		[learning rate: 0.0070295]
	Learning Rate: 0.00702948
	LOSS [training: 0.3518895023628003 | validation: 0.4091193995720892]
	TIME [epoch: 98.9 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3461623247855283		[learning rate: 0.0070015]
	Learning Rate: 0.00700152
	LOSS [training: 0.3461623247855283 | validation: 0.3254400169831559]
	TIME [epoch: 99 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4381420289747359		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 0.4381420289747359 | validation: 0.3852129653883826]
	TIME [epoch: 98.9 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3449066618661175		[learning rate: 0.0069459]
	Learning Rate: 0.00694594
	LOSS [training: 0.3449066618661175 | validation: 0.3494827454928149]
	TIME [epoch: 99 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4516047122028913		[learning rate: 0.0069183]
	Learning Rate: 0.00691831
	LOSS [training: 0.4516047122028913 | validation: 0.3972594461351724]
	TIME [epoch: 99 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4701473753419174		[learning rate: 0.0068908]
	Learning Rate: 0.00689079
	LOSS [training: 0.4701473753419174 | validation: 0.38529610233617556]
	TIME [epoch: 99 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3660664048570517		[learning rate: 0.0068634]
	Learning Rate: 0.00686339
	LOSS [training: 0.3660664048570517 | validation: 0.3590585688915711]
	TIME [epoch: 99 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.35656862234684605		[learning rate: 0.0068361]
	Learning Rate: 0.00683609
	LOSS [training: 0.35656862234684605 | validation: 0.45206472400454895]
	TIME [epoch: 99 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3488591633083342		[learning rate: 0.0068089]
	Learning Rate: 0.0068089
	LOSS [training: 0.3488591633083342 | validation: 0.31994345176850447]
	TIME [epoch: 99 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3328798568331966		[learning rate: 0.0067818]
	Learning Rate: 0.00678182
	LOSS [training: 0.3328798568331966 | validation: 0.3230216165952037]
	TIME [epoch: 99 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3420747614360604		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 0.3420747614360604 | validation: 0.3703975595944183]
	TIME [epoch: 99 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.34495958997138526		[learning rate: 0.006728]
	Learning Rate: 0.00672798
	LOSS [training: 0.34495958997138526 | validation: 0.37137552896719084]
	TIME [epoch: 98.9 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3520582282142275		[learning rate: 0.0067012]
	Learning Rate: 0.00670122
	LOSS [training: 0.3520582282142275 | validation: 0.36237696175200645]
	TIME [epoch: 99 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3564358462228355		[learning rate: 0.0066746]
	Learning Rate: 0.00667457
	LOSS [training: 0.3564358462228355 | validation: 0.35499097164306825]
	TIME [epoch: 99 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3347984497234229		[learning rate: 0.006648]
	Learning Rate: 0.00664802
	LOSS [training: 0.3347984497234229 | validation: 0.3135011355775]
	TIME [epoch: 99 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v4_20240711_145314/states/model_facs_v2_dec1b_2dpca_v4_147.pth
	Model improved!!!
EPOCH 148/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.33538090575178914		[learning rate: 0.0066216]
	Learning Rate: 0.00662158
	LOSS [training: 0.33538090575178914 | validation: 0.33037515406943]
	TIME [epoch: 98.9 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4015678706090999		[learning rate: 0.0065952]
	Learning Rate: 0.00659524
	LOSS [training: 0.4015678706090999 | validation: 0.3500943993173455]
	TIME [epoch: 98.9 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3399468819731033		[learning rate: 0.006569]
	Learning Rate: 0.00656901
	LOSS [training: 0.3399468819731033 | validation: 0.3983073771865279]
	TIME [epoch: 98.9 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3447439994877145		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 0.3447439994877145 | validation: 0.3182733922643288]
	TIME [epoch: 98.9 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32692408133152523		[learning rate: 0.0065169]
	Learning Rate: 0.00651686
	LOSS [training: 0.32692408133152523 | validation: 0.3617873493125442]
	TIME [epoch: 98.9 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.35164402790338634		[learning rate: 0.0064909]
	Learning Rate: 0.00649094
	LOSS [training: 0.35164402790338634 | validation: 0.3273210665270921]
	TIME [epoch: 98.9 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32162982323382416		[learning rate: 0.0064651]
	Learning Rate: 0.00646512
	LOSS [training: 0.32162982323382416 | validation: 0.32449918471309275]
	TIME [epoch: 98.9 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3689910997511329		[learning rate: 0.0064394]
	Learning Rate: 0.00643941
	LOSS [training: 0.3689910997511329 | validation: 0.3527755632410579]
	TIME [epoch: 98.9 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3319659681915751		[learning rate: 0.0064138]
	Learning Rate: 0.0064138
	LOSS [training: 0.3319659681915751 | validation: 0.323685234258948]
	TIME [epoch: 99 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.33237892604902675		[learning rate: 0.0063883]
	Learning Rate: 0.00638829
	LOSS [training: 0.33237892604902675 | validation: 0.3451665809124817]
	TIME [epoch: 98.9 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3266193750271927		[learning rate: 0.0063629]
	Learning Rate: 0.00636288
	LOSS [training: 0.3266193750271927 | validation: 0.37548314944395095]
	TIME [epoch: 98.9 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.36839472895595987		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 0.36839472895595987 | validation: 0.34608421307397463]
	TIME [epoch: 98.9 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.34869942729497944		[learning rate: 0.0063124]
	Learning Rate: 0.00631237
	LOSS [training: 0.34869942729497944 | validation: 0.3867483329530126]
	TIME [epoch: 98.9 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.38149723730668444		[learning rate: 0.0062873]
	Learning Rate: 0.00628726
	LOSS [training: 0.38149723730668444 | validation: 0.3392582539752994]
	TIME [epoch: 98.9 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32250250551188714		[learning rate: 0.0062623]
	Learning Rate: 0.00626226
	LOSS [training: 0.32250250551188714 | validation: 0.3263703299338935]
	TIME [epoch: 98.9 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32619342688413794		[learning rate: 0.0062373]
	Learning Rate: 0.00623735
	LOSS [training: 0.32619342688413794 | validation: 0.36305787730946737]
	TIME [epoch: 98.9 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3385956359100408		[learning rate: 0.0062125]
	Learning Rate: 0.00621254
	LOSS [training: 0.3385956359100408 | validation: 0.3521823332357429]
	TIME [epoch: 98.9 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.33510046271763355		[learning rate: 0.0061878]
	Learning Rate: 0.00618783
	LOSS [training: 0.33510046271763355 | validation: 0.3906411806699023]
	TIME [epoch: 98.9 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3373154864646496		[learning rate: 0.0061632]
	Learning Rate: 0.00616322
	LOSS [training: 0.3373154864646496 | validation: 0.3488487027856101]
	TIME [epoch: 98.9 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3288410923746165		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 0.3288410923746165 | validation: 0.3158681944824425]
	TIME [epoch: 98.9 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3261538537610095		[learning rate: 0.0061143]
	Learning Rate: 0.00611429
	LOSS [training: 0.3261538537610095 | validation: 0.32299874348576024]
	TIME [epoch: 98.9 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3214053663371437		[learning rate: 0.00609]
	Learning Rate: 0.00608997
	LOSS [training: 0.3214053663371437 | validation: 0.3660065101662762]
	TIME [epoch: 98.9 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3400666220319752		[learning rate: 0.0060658]
	Learning Rate: 0.00606575
	LOSS [training: 0.3400666220319752 | validation: 0.34323474854318503]
	TIME [epoch: 98.9 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.33068164869609984		[learning rate: 0.0060416]
	Learning Rate: 0.00604163
	LOSS [training: 0.33068164869609984 | validation: 0.34225752731119635]
	TIME [epoch: 98.9 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3248249532077179		[learning rate: 0.0060176]
	Learning Rate: 0.0060176
	LOSS [training: 0.3248249532077179 | validation: 0.31832391774824786]
	TIME [epoch: 98.9 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3163972797797841		[learning rate: 0.0059937]
	Learning Rate: 0.00599366
	LOSS [training: 0.3163972797797841 | validation: 0.4082415806581097]
	TIME [epoch: 98.9 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4101993220866075		[learning rate: 0.0059698]
	Learning Rate: 0.00596982
	LOSS [training: 0.4101993220866075 | validation: 0.361894558702057]
	TIME [epoch: 98.9 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.345485931442542		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 0.345485931442542 | validation: 0.36993728972851364]
	TIME [epoch: 98.9 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.33622560530854134		[learning rate: 0.0059224]
	Learning Rate: 0.00592243
	LOSS [training: 0.33622560530854134 | validation: 0.3552049032127561]
	TIME [epoch: 99 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.34822231615348465		[learning rate: 0.0058989]
	Learning Rate: 0.00589888
	LOSS [training: 0.34822231615348465 | validation: 0.3196453853835653]
	TIME [epoch: 98.9 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.31926658278813175		[learning rate: 0.0058754]
	Learning Rate: 0.00587541
	LOSS [training: 0.31926658278813175 | validation: 0.33607197902927854]
	TIME [epoch: 99 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3216799784776205		[learning rate: 0.005852]
	Learning Rate: 0.00585205
	LOSS [training: 0.3216799784776205 | validation: 0.33584398206941724]
	TIME [epoch: 98.9 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3255248245978383		[learning rate: 0.0058288]
	Learning Rate: 0.00582877
	LOSS [training: 0.3255248245978383 | validation: 0.3261314944487733]
	TIME [epoch: 98.9 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3289076756661407		[learning rate: 0.0058056]
	Learning Rate: 0.00580559
	LOSS [training: 0.3289076756661407 | validation: 0.31721972761105743]
	TIME [epoch: 98.9 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3245937888719673		[learning rate: 0.0057825]
	Learning Rate: 0.0057825
	LOSS [training: 0.3245937888719673 | validation: 0.3390498202094737]
	TIME [epoch: 98.9 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3268831075538046		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 0.3268831075538046 | validation: 0.3291793883205189]
	TIME [epoch: 98.9 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.33813785302753036		[learning rate: 0.0057366]
	Learning Rate: 0.00573659
	LOSS [training: 0.33813785302753036 | validation: 0.3115835674141828]
	TIME [epoch: 98.9 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v4_20240711_145314/states/model_facs_v2_dec1b_2dpca_v4_184.pth
	Model improved!!!
EPOCH 185/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32391360267845476		[learning rate: 0.0057138]
	Learning Rate: 0.00571377
	LOSS [training: 0.32391360267845476 | validation: 0.31569941465603385]
	TIME [epoch: 98.9 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3161984897496919		[learning rate: 0.005691]
	Learning Rate: 0.00569105
	LOSS [training: 0.3161984897496919 | validation: 0.3325461325654398]
	TIME [epoch: 99 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32836316148429484		[learning rate: 0.0056684]
	Learning Rate: 0.00566841
	LOSS [training: 0.32836316148429484 | validation: 0.3446264080204751]
	TIME [epoch: 99 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3386435211065207		[learning rate: 0.0056459]
	Learning Rate: 0.00564587
	LOSS [training: 0.3386435211065207 | validation: 0.36066816524473494]
	TIME [epoch: 99 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.33005448383462194		[learning rate: 0.0056234]
	Learning Rate: 0.00562341
	LOSS [training: 0.33005448383462194 | validation: 0.3529775711654478]
	TIME [epoch: 98.9 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.35553752471033634		[learning rate: 0.005601]
	Learning Rate: 0.00560105
	LOSS [training: 0.35553752471033634 | validation: 0.45893516014275654]
	TIME [epoch: 99 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5572672729135526		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 0.5572672729135526 | validation: 0.366040700143724]
	TIME [epoch: 98.9 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.42579009754052644		[learning rate: 0.0055566]
	Learning Rate: 0.00555658
	LOSS [training: 0.42579009754052644 | validation: 0.33725333763858434]
	TIME [epoch: 99 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.44804651644430904		[learning rate: 0.0055345]
	Learning Rate: 0.00553448
	LOSS [training: 0.44804651644430904 | validation: 0.3672615233740583]
	TIME [epoch: 98.9 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.39080292732871524		[learning rate: 0.0055125]
	Learning Rate: 0.00551247
	LOSS [training: 0.39080292732871524 | validation: 0.3337559049019476]
	TIME [epoch: 99 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.36080808156581085		[learning rate: 0.0054905]
	Learning Rate: 0.00549054
	LOSS [training: 0.36080808156581085 | validation: 0.33532619310460887]
	TIME [epoch: 99 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3398944380761947		[learning rate: 0.0054687]
	Learning Rate: 0.00546871
	LOSS [training: 0.3398944380761947 | validation: 0.32750178505120353]
	TIME [epoch: 99 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3472197277883047		[learning rate: 0.005447]
	Learning Rate: 0.00544696
	LOSS [training: 0.3472197277883047 | validation: 0.32405080484872434]
	TIME [epoch: 98.9 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.33910263612380365		[learning rate: 0.0054253]
	Learning Rate: 0.00542529
	LOSS [training: 0.33910263612380365 | validation: 0.3657841968819794]
	TIME [epoch: 99 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3406342077673746		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 0.3406342077673746 | validation: 0.4370325783741712]
	TIME [epoch: 99 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3583898068585906		[learning rate: 0.0053822]
	Learning Rate: 0.00538222
	LOSS [training: 0.3583898068585906 | validation: 0.33014122424817677]
	TIME [epoch: 99 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3365243385436625		[learning rate: 0.0053608]
	Learning Rate: 0.00536081
	LOSS [training: 0.3365243385436625 | validation: 0.33805551645007514]
	TIME [epoch: 233 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.34729665901587065		[learning rate: 0.0053395]
	Learning Rate: 0.00533949
	LOSS [training: 0.34729665901587065 | validation: 0.3913285972088774]
	TIME [epoch: 206 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.34239532768488945		[learning rate: 0.0053183]
	Learning Rate: 0.00531826
	LOSS [training: 0.34239532768488945 | validation: 0.36793922095656384]
	TIME [epoch: 206 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3278714934663786		[learning rate: 0.0052971]
	Learning Rate: 0.0052971
	LOSS [training: 0.3278714934663786 | validation: 0.31419391325814316]
	TIME [epoch: 206 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3374742681732819		[learning rate: 0.005276]
	Learning Rate: 0.00527604
	LOSS [training: 0.3374742681732819 | validation: 0.3814850928416108]
	TIME [epoch: 206 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.35376363243049896		[learning rate: 0.0052551]
	Learning Rate: 0.00525505
	LOSS [training: 0.35376363243049896 | validation: 0.3436989067134948]
	TIME [epoch: 206 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3481173747465861		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 0.3481173747465861 | validation: 0.3201834672156569]
	TIME [epoch: 206 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.311862620760547		[learning rate: 0.0052133]
	Learning Rate: 0.00521333
	LOSS [training: 0.311862620760547 | validation: 0.3177144557408223]
	TIME [epoch: 206 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3524676435951141		[learning rate: 0.0051926]
	Learning Rate: 0.0051926
	LOSS [training: 0.3524676435951141 | validation: 0.31300861185542467]
	TIME [epoch: 206 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.31645052058143974		[learning rate: 0.0051719]
	Learning Rate: 0.00517194
	LOSS [training: 0.31645052058143974 | validation: 0.3256504117860053]
	TIME [epoch: 206 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32724416634150333		[learning rate: 0.0051514]
	Learning Rate: 0.00515137
	LOSS [training: 0.32724416634150333 | validation: 0.34279979333990307]
	TIME [epoch: 206 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3305232645429543		[learning rate: 0.0051309]
	Learning Rate: 0.00513089
	LOSS [training: 0.3305232645429543 | validation: 0.3501669692858058]
	TIME [epoch: 206 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.33231042768707486		[learning rate: 0.0051105]
	Learning Rate: 0.00511048
	LOSS [training: 0.33231042768707486 | validation: 0.38785624150125086]
	TIME [epoch: 206 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3282828510911639		[learning rate: 0.0050902]
	Learning Rate: 0.00509015
	LOSS [training: 0.3282828510911639 | validation: 0.33432826771233637]
	TIME [epoch: 206 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.30896299719686166		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 0.30896299719686166 | validation: 0.3365423319412221]
	TIME [epoch: 206 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3185061603058892		[learning rate: 0.0050497]
	Learning Rate: 0.00504974
	LOSS [training: 0.3185061603058892 | validation: 0.3243764428014547]
	TIME [epoch: 206 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3409733753228719		[learning rate: 0.0050297]
	Learning Rate: 0.00502966
	LOSS [training: 0.3409733753228719 | validation: 0.3090811175319477]
	TIME [epoch: 206 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v4_20240711_145314/states/model_facs_v2_dec1b_2dpca_v4_217.pth
	Model improved!!!
EPOCH 218/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3079751314397583		[learning rate: 0.0050097]
	Learning Rate: 0.00500965
	LOSS [training: 0.3079751314397583 | validation: 0.3293442732312583]
	TIME [epoch: 206 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3209931070553282		[learning rate: 0.0049897]
	Learning Rate: 0.00498973
	LOSS [training: 0.3209931070553282 | validation: 0.31973343674386]
	TIME [epoch: 206 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3060638879033337		[learning rate: 0.0049699]
	Learning Rate: 0.00496988
	LOSS [training: 0.3060638879033337 | validation: 0.3331008271738732]
	TIME [epoch: 206 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.336577134533412		[learning rate: 0.0049501]
	Learning Rate: 0.00495012
	LOSS [training: 0.336577134533412 | validation: 0.3106625745910473]
	TIME [epoch: 206 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.310348142984875		[learning rate: 0.0049304]
	Learning Rate: 0.00493043
	LOSS [training: 0.310348142984875 | validation: 0.3366998315246935]
	TIME [epoch: 206 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3309850310545791		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 0.3309850310545791 | validation: 0.3224602773923264]
	TIME [epoch: 206 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32256457554827783		[learning rate: 0.0048913]
	Learning Rate: 0.00489129
	LOSS [training: 0.32256457554827783 | validation: 0.315756417186564]
	TIME [epoch: 206 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.30766969687426204		[learning rate: 0.0048718]
	Learning Rate: 0.00487183
	LOSS [training: 0.30766969687426204 | validation: 0.3182271895557123]
	TIME [epoch: 206 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32705082800380986		[learning rate: 0.0048525]
	Learning Rate: 0.00485245
	LOSS [training: 0.32705082800380986 | validation: 0.33091625980649747]
	TIME [epoch: 206 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3074451539432632		[learning rate: 0.0048332]
	Learning Rate: 0.00483316
	LOSS [training: 0.3074451539432632 | validation: 0.3161157261892994]
	TIME [epoch: 206 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.30188408251615995		[learning rate: 0.0048139]
	Learning Rate: 0.00481393
	LOSS [training: 0.30188408251615995 | validation: 0.34730667900094997]
	TIME [epoch: 206 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.33434548287827043		[learning rate: 0.0047948]
	Learning Rate: 0.00479479
	LOSS [training: 0.33434548287827043 | validation: 0.29995899661136194]
	TIME [epoch: 206 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v4_20240711_145314/states/model_facs_v2_dec1b_2dpca_v4_229.pth
	Model improved!!!
EPOCH 230/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.311783789740966		[learning rate: 0.0047757]
	Learning Rate: 0.00477572
	LOSS [training: 0.311783789740966 | validation: 0.33794534316705804]
	TIME [epoch: 206 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.316856362241509		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.316856362241509 | validation: 0.342889750068606]
	TIME [epoch: 206 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3122560904956774		[learning rate: 0.0047378]
	Learning Rate: 0.0047378
	LOSS [training: 0.3122560904956774 | validation: 0.3035892581639142]
	TIME [epoch: 206 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3329953622744605		[learning rate: 0.004719]
	Learning Rate: 0.00471896
	LOSS [training: 0.3329953622744605 | validation: 0.3120025144043728]
	TIME [epoch: 206 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.30560937110104464		[learning rate: 0.0047002]
	Learning Rate: 0.00470019
	LOSS [training: 0.30560937110104464 | validation: 0.34331696573957693]
	TIME [epoch: 206 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3152816762518815		[learning rate: 0.0046815]
	Learning Rate: 0.0046815
	LOSS [training: 0.3152816762518815 | validation: 0.3828690679157442]
	TIME [epoch: 206 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32416479972506534		[learning rate: 0.0046629]
	Learning Rate: 0.00466288
	LOSS [training: 0.32416479972506534 | validation: 0.3487941641417896]
	TIME [epoch: 206 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3252041635427733		[learning rate: 0.0046443]
	Learning Rate: 0.00464433
	LOSS [training: 0.3252041635427733 | validation: 0.3220218908769957]
	TIME [epoch: 206 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.31184594362439444		[learning rate: 0.0046259]
	Learning Rate: 0.00462586
	LOSS [training: 0.31184594362439444 | validation: 0.33516964625159007]
	TIME [epoch: 206 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.33164033043025903		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 0.33164033043025903 | validation: 0.31418315290101795]
	TIME [epoch: 206 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3179946358121321		[learning rate: 0.0045891]
	Learning Rate: 0.00458913
	LOSS [training: 0.3179946358121321 | validation: 0.29214177759383986]
	TIME [epoch: 206 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v4_20240711_145314/states/model_facs_v2_dec1b_2dpca_v4_240.pth
	Model improved!!!
EPOCH 241/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.297931145525762		[learning rate: 0.0045709]
	Learning Rate: 0.00457088
	LOSS [training: 0.297931145525762 | validation: 0.2958185574987545]
	TIME [epoch: 206 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3210212319535771		[learning rate: 0.0045527]
	Learning Rate: 0.0045527
	LOSS [training: 0.3210212319535771 | validation: 0.3966543621399414]
	TIME [epoch: 206 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3315456498032764		[learning rate: 0.0045346]
	Learning Rate: 0.00453459
	LOSS [training: 0.3315456498032764 | validation: 0.29912886538956374]
	TIME [epoch: 206 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.29613489959272193		[learning rate: 0.0045166]
	Learning Rate: 0.00451656
	LOSS [training: 0.29613489959272193 | validation: 0.32173589385644286]
	TIME [epoch: 206 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.31201208753417065		[learning rate: 0.0044986]
	Learning Rate: 0.0044986
	LOSS [training: 0.31201208753417065 | validation: 0.34856506353532785]
	TIME [epoch: 206 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.306973295902953		[learning rate: 0.0044807]
	Learning Rate: 0.0044807
	LOSS [training: 0.306973295902953 | validation: 0.3021717402478885]
	TIME [epoch: 206 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.29730988708469985		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 0.29730988708469985 | validation: 0.3269474006635886]
	TIME [epoch: 206 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3180680836458649		[learning rate: 0.0044451]
	Learning Rate: 0.00444513
	LOSS [training: 0.3180680836458649 | validation: 0.3000800762738087]
	TIME [epoch: 206 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2985101813547615		[learning rate: 0.0044275]
	Learning Rate: 0.00442745
	LOSS [training: 0.2985101813547615 | validation: 0.33433031024540566]
	TIME [epoch: 206 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.31079209867209756		[learning rate: 0.0044098]
	Learning Rate: 0.00440984
	LOSS [training: 0.31079209867209756 | validation: 0.3167578389836505]
	TIME [epoch: 206 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32144710075612626		[learning rate: 0.0043923]
	Learning Rate: 0.0043923
	LOSS [training: 0.32144710075612626 | validation: 0.30624193972787545]
	TIME [epoch: 206 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.29441653386848876		[learning rate: 0.0043748]
	Learning Rate: 0.00437483
	LOSS [training: 0.29441653386848876 | validation: 0.305043404570871]
	TIME [epoch: 206 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.30493676605202885		[learning rate: 0.0043574]
	Learning Rate: 0.00435743
	LOSS [training: 0.30493676605202885 | validation: 0.41016946710990904]
	TIME [epoch: 206 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.35366318564836224		[learning rate: 0.0043401]
	Learning Rate: 0.0043401
	LOSS [training: 0.35366318564836224 | validation: 0.31275505485456545]
	TIME [epoch: 206 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.29972658354603315		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 0.29972658354603315 | validation: 0.30959232341143667]
	TIME [epoch: 206 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3175821229943858		[learning rate: 0.0043056]
	Learning Rate: 0.00430565
	LOSS [training: 0.3175821229943858 | validation: 0.2997492756627637]
	TIME [epoch: 206 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.29727242389172515		[learning rate: 0.0042885]
	Learning Rate: 0.00428852
	LOSS [training: 0.29727242389172515 | validation: 0.317780893571038]
	TIME [epoch: 206 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3014833621000823		[learning rate: 0.0042715]
	Learning Rate: 0.00427147
	LOSS [training: 0.3014833621000823 | validation: 0.3137343864370589]
	TIME [epoch: 206 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.30195599772797377		[learning rate: 0.0042545]
	Learning Rate: 0.00425448
	LOSS [training: 0.30195599772797377 | validation: 0.30922561298323065]
	TIME [epoch: 206 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.29275937572850697		[learning rate: 0.0042376]
	Learning Rate: 0.00423756
	LOSS [training: 0.29275937572850697 | validation: 0.3483569987339964]
	TIME [epoch: 206 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3104867864706524		[learning rate: 0.0042207]
	Learning Rate: 0.0042207
	LOSS [training: 0.3104867864706524 | validation: 0.31113225128071875]
	TIME [epoch: 206 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3065313718558032		[learning rate: 0.0042039]
	Learning Rate: 0.00420391
	LOSS [training: 0.3065313718558032 | validation: 0.3036748496629528]
	TIME [epoch: 206 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2986860817236713		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 0.2986860817236713 | validation: 0.3069133986993787]
	TIME [epoch: 206 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2930225605293752		[learning rate: 0.0041705]
	Learning Rate: 0.00417054
	LOSS [training: 0.2930225605293752 | validation: 0.3228845597578134]
	TIME [epoch: 206 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3123759320302414		[learning rate: 0.004154]
	Learning Rate: 0.00415395
	LOSS [training: 0.3123759320302414 | validation: 0.31518204243180564]
	TIME [epoch: 206 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2948444483413788		[learning rate: 0.0041374]
	Learning Rate: 0.00413743
	LOSS [training: 0.2948444483413788 | validation: 0.3162686455097686]
	TIME [epoch: 206 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3021182586748886		[learning rate: 0.004121]
	Learning Rate: 0.00412098
	LOSS [training: 0.3021182586748886 | validation: 0.3348885779103008]
	TIME [epoch: 206 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3047991058407639		[learning rate: 0.0041046]
	Learning Rate: 0.00410458
	LOSS [training: 0.3047991058407639 | validation: 0.30240820429876186]
	TIME [epoch: 206 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.29697966316729413		[learning rate: 0.0040883]
	Learning Rate: 0.00408826
	LOSS [training: 0.29697966316729413 | validation: 0.3326884536396223]
	TIME [epoch: 206 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.30443348766540607		[learning rate: 0.004072]
	Learning Rate: 0.004072
	LOSS [training: 0.30443348766540607 | validation: 0.3293316725961236]
	TIME [epoch: 206 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.30213370935134226		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.30213370935134226 | validation: 0.31650357713595795]
	TIME [epoch: 206 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3051506908612116		[learning rate: 0.0040397]
	Learning Rate: 0.00403967
	LOSS [training: 0.3051506908612116 | validation: 0.40845967095283103]
	TIME [epoch: 206 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3123598852530722		[learning rate: 0.0040236]
	Learning Rate: 0.00402361
	LOSS [training: 0.3123598852530722 | validation: 0.31359696200509163]
	TIME [epoch: 206 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3069832398082505		[learning rate: 0.0040076]
	Learning Rate: 0.0040076
	LOSS [training: 0.3069832398082505 | validation: 0.3537394784212403]
	TIME [epoch: 206 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3002711393282211		[learning rate: 0.0039917]
	Learning Rate: 0.00399166
	LOSS [training: 0.3002711393282211 | validation: 0.3187760265741202]
	TIME [epoch: 206 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2993385960166194		[learning rate: 0.0039758]
	Learning Rate: 0.00397579
	LOSS [training: 0.2993385960166194 | validation: 0.3168006813620373]
	TIME [epoch: 206 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.31170578275499233		[learning rate: 0.00396]
	Learning Rate: 0.00395997
	LOSS [training: 0.31170578275499233 | validation: 0.3018716587463316]
	TIME [epoch: 206 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.30826876717699286		[learning rate: 0.0039442]
	Learning Rate: 0.00394422
	LOSS [training: 0.30826876717699286 | validation: 0.2918651291719848]
	TIME [epoch: 206 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v4_20240711_145314/states/model_facs_v2_dec1b_2dpca_v4_278.pth
	Model improved!!!
EPOCH 279/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.289444657439896		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 0.289444657439896 | validation: 0.29970385864447974]
	TIME [epoch: 206 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3138126880166019		[learning rate: 0.0039129]
	Learning Rate: 0.00391291
	LOSS [training: 0.3138126880166019 | validation: 0.3150792134065954]
	TIME [epoch: 206 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2958967413402778		[learning rate: 0.0038973]
	Learning Rate: 0.00389735
	LOSS [training: 0.2958967413402778 | validation: 0.3017147010132519]
	TIME [epoch: 206 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.30647427726979326		[learning rate: 0.0038818]
	Learning Rate: 0.00388185
	LOSS [training: 0.30647427726979326 | validation: 0.31717984825617046]
	TIME [epoch: 206 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.29544177412173955		[learning rate: 0.0038664]
	Learning Rate: 0.00386641
	LOSS [training: 0.29544177412173955 | validation: 0.297744906023634]
	TIME [epoch: 206 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3140170090798413		[learning rate: 0.003851]
	Learning Rate: 0.00385103
	LOSS [training: 0.3140170090798413 | validation: 0.3094814721633378]
	TIME [epoch: 206 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.30417283572291515		[learning rate: 0.0038357]
	Learning Rate: 0.00383571
	LOSS [training: 0.30417283572291515 | validation: 0.29481194200832966]
	TIME [epoch: 206 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2982020466402975		[learning rate: 0.0038205]
	Learning Rate: 0.00382046
	LOSS [training: 0.2982020466402975 | validation: 0.3120113907152093]
	TIME [epoch: 206 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3018805488136306		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 0.3018805488136306 | validation: 0.30328585119623797]
	TIME [epoch: 206 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2942363802086709		[learning rate: 0.0037901]
	Learning Rate: 0.00379013
	LOSS [training: 0.2942363802086709 | validation: 0.29693058146365875]
	TIME [epoch: 206 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2840355239518517		[learning rate: 0.0037751]
	Learning Rate: 0.00377505
	LOSS [training: 0.2840355239518517 | validation: 0.30591390398310137]
	TIME [epoch: 206 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2959635692000516		[learning rate: 0.00376]
	Learning Rate: 0.00376004
	LOSS [training: 0.2959635692000516 | validation: 0.32263585302595243]
	TIME [epoch: 206 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.30688938774480073		[learning rate: 0.0037451]
	Learning Rate: 0.00374508
	LOSS [training: 0.30688938774480073 | validation: 0.3402998697713258]
	TIME [epoch: 206 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2988914646095591		[learning rate: 0.0037302]
	Learning Rate: 0.00373019
	LOSS [training: 0.2988914646095591 | validation: 0.3219306447012197]
	TIME [epoch: 206 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2870240880390909		[learning rate: 0.0037154]
	Learning Rate: 0.00371535
	LOSS [training: 0.2870240880390909 | validation: 0.30036678194699257]
	TIME [epoch: 206 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.30192752339431705		[learning rate: 0.0037006]
	Learning Rate: 0.00370058
	LOSS [training: 0.30192752339431705 | validation: 0.2989922921538256]
	TIME [epoch: 206 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.30042867502830434		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 0.30042867502830434 | validation: 0.3145012437482251]
	TIME [epoch: 206 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2916030766996861		[learning rate: 0.0036712]
	Learning Rate: 0.0036712
	LOSS [training: 0.2916030766996861 | validation: 0.29483272943887157]
	TIME [epoch: 206 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.29496576910755506		[learning rate: 0.0036566]
	Learning Rate: 0.0036566
	LOSS [training: 0.29496576910755506 | validation: 0.3147523418913528]
	TIME [epoch: 206 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2867744323633008		[learning rate: 0.0036421]
	Learning Rate: 0.00364205
	LOSS [training: 0.2867744323633008 | validation: 0.3016322837879004]
	TIME [epoch: 206 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.30331626490827795		[learning rate: 0.0036276]
	Learning Rate: 0.00362757
	LOSS [training: 0.30331626490827795 | validation: 0.29245856961924455]
	TIME [epoch: 206 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.29012096162336615		[learning rate: 0.0036131]
	Learning Rate: 0.00361314
	LOSS [training: 0.29012096162336615 | validation: 0.30609273026673206]
	TIME [epoch: 206 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2942750884237566		[learning rate: 0.0035988]
	Learning Rate: 0.00359877
	LOSS [training: 0.2942750884237566 | validation: 0.2976863152028696]
	TIME [epoch: 206 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32737630734655626		[learning rate: 0.0035845]
	Learning Rate: 0.00358445
	LOSS [training: 0.32737630734655626 | validation: 0.3277042464066816]
	TIME [epoch: 206 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.30394440394923566		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 0.30394440394923566 | validation: 0.2978522136978621]
	TIME [epoch: 206 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.29511013075115383		[learning rate: 0.003556]
	Learning Rate: 0.003556
	LOSS [training: 0.29511013075115383 | validation: 0.30784619038216426]
	TIME [epoch: 206 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.30300012793377357		[learning rate: 0.0035419]
	Learning Rate: 0.00354185
	LOSS [training: 0.30300012793377357 | validation: 0.2996134844815086]
	TIME [epoch: 206 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.28837437490025364		[learning rate: 0.0035278]
	Learning Rate: 0.00352777
	LOSS [training: 0.28837437490025364 | validation: 0.2953504596572029]
	TIME [epoch: 207 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2981479818145534		[learning rate: 0.0035137]
	Learning Rate: 0.00351374
	LOSS [training: 0.2981479818145534 | validation: 0.2915640739551088]
	TIME [epoch: 206 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v4_20240711_145314/states/model_facs_v2_dec1b_2dpca_v4_307.pth
	Model improved!!!
EPOCH 308/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.28603617668203324		[learning rate: 0.0034998]
	Learning Rate: 0.00349976
	LOSS [training: 0.28603617668203324 | validation: 0.29171342487505075]
	TIME [epoch: 206 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3068028159533238		[learning rate: 0.0034858]
	Learning Rate: 0.00348584
	LOSS [training: 0.3068028159533238 | validation: 0.31158107659764894]
	TIME [epoch: 206 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.29921762136089103		[learning rate: 0.003472]
	Learning Rate: 0.00347198
	LOSS [training: 0.29921762136089103 | validation: 0.3066430614604428]
	TIME [epoch: 206 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.29403663223771753		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.29403663223771753 | validation: 0.3063775795483821]
	TIME [epoch: 206 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.28975833678909685		[learning rate: 0.0034444]
	Learning Rate: 0.00344441
	LOSS [training: 0.28975833678909685 | validation: 0.30341353454381037]
	TIME [epoch: 206 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.29146762737204646		[learning rate: 0.0034307]
	Learning Rate: 0.00343071
	LOSS [training: 0.29146762737204646 | validation: 0.2919555702789879]
	TIME [epoch: 206 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.29488952450826467		[learning rate: 0.0034171]
	Learning Rate: 0.00341707
	LOSS [training: 0.29488952450826467 | validation: 0.3343081771542229]
	TIME [epoch: 206 sec]
EPOCH 315/2000:
	Training over batches...
