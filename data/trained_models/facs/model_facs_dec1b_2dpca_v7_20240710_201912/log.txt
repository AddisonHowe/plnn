Args:
Namespace(name='model_facs_dec1b_2dpca_v7', outdir='out/model_training/model_facs_dec1b_2dpca_v7', training_data='data/training_data/facs/pca/dec1_fitonsubset/transition1_subset_epi_tr_ce_an_pc12/training', validation_data='data/training_data/facs/pca/dec1_fitonsubset/transition1_subset_epi_tr_ce_an_pc12/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=10, batch_size=50, patience=200, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=200, ncells_sample=200, model_do_sample=False, dt=0.005, dt_schedule='stepped', dt_schedule_bounds=[500, 1000, 1500], dt_schedule_scales=[0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=True, sigma=0.02, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', kernel='multiscale', bw_range=[0.2, 0.5, 0.9, 1.1, 1.3, 1.5, 2.0], optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 3865289629

Training model...

Saving initial model state to: out/model_training/model_facs_dec1b_2dpca_v7_20240710_201912/states/model_facs_dec1b_2dpca_v7_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.752787521161528		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.752787521161528 | validation: 1.2937983038990755]
	TIME [epoch: 41.8 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v7_20240710_201912/states/model_facs_dec1b_2dpca_v7_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.303760736873074		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.303760736873074 | validation: 1.1827094923543109]
	TIME [epoch: 7.96 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v7_20240710_201912/states/model_facs_dec1b_2dpca_v7_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.252181835845782		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.252181835845782 | validation: 1.060296471157584]
	TIME [epoch: 7.93 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v7_20240710_201912/states/model_facs_dec1b_2dpca_v7_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.1417029768773463		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1417029768773463 | validation: 1.0881305663257288]
	TIME [epoch: 7.96 sec]
EPOCH 5/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.117966096381621		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.117966096381621 | validation: 0.9302656438073168]
	TIME [epoch: 7.92 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v7_20240710_201912/states/model_facs_dec1b_2dpca_v7_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.063313348714521		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.063313348714521 | validation: 1.0480529307464628]
	TIME [epoch: 7.94 sec]
EPOCH 7/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.9918933235572103		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9918933235572103 | validation: 0.9947772444265779]
	TIME [epoch: 7.94 sec]
EPOCH 8/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.990458599793341		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.990458599793341 | validation: 0.8741607137488637]
	TIME [epoch: 7.94 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v7_20240710_201912/states/model_facs_dec1b_2dpca_v7_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.9574586739762077		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9574586739762077 | validation: 0.8004938528234085]
	TIME [epoch: 7.93 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v7_20240710_201912/states/model_facs_dec1b_2dpca_v7_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.8574963797786707		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8574963797786707 | validation: 0.8893949300074953]
	TIME [epoch: 7.93 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.883956043965552		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.883956043965552 | validation: 0.7922302617263519]
	TIME [epoch: 7.93 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v7_20240710_201912/states/model_facs_dec1b_2dpca_v7_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.8001087747399963		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8001087747399963 | validation: 0.9145413460211229]
	TIME [epoch: 7.94 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.87930129679958		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.87930129679958 | validation: 0.7171191476241014]
	TIME [epoch: 7.93 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v7_20240710_201912/states/model_facs_dec1b_2dpca_v7_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.736811638905625		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.736811638905625 | validation: 0.870643907471672]
	TIME [epoch: 7.93 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6906760350711703		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6906760350711703 | validation: 0.6317473428340834]
	TIME [epoch: 7.94 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v7_20240710_201912/states/model_facs_dec1b_2dpca_v7_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7352495579137508		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7352495579137508 | validation: 0.8205665241006349]
	TIME [epoch: 7.94 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6206814139987352		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6206814139987352 | validation: 0.49434605085443256]
	TIME [epoch: 7.93 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v7_20240710_201912/states/model_facs_dec1b_2dpca_v7_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.8359782042397378		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8359782042397378 | validation: 0.6800732155157455]
	TIME [epoch: 7.93 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6489853835425958		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6489853835425958 | validation: 0.5599744671122487]
	TIME [epoch: 7.93 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5402455263860722		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5402455263860722 | validation: 0.4994716511746802]
	TIME [epoch: 7.94 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5302952463064989		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5302952463064989 | validation: 0.5841451212149215]
	TIME [epoch: 7.93 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5681804979240515		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5681804979240515 | validation: 0.5329639153812644]
	TIME [epoch: 7.93 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.48301022780368125		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.48301022780368125 | validation: 0.45264948296323543]
	TIME [epoch: 7.93 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v7_20240710_201912/states/model_facs_dec1b_2dpca_v7_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6208362840113487		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6208362840113487 | validation: 0.597231869920451]
	TIME [epoch: 7.95 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5751066470033811		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5751066470033811 | validation: 0.5260103696723959]
	TIME [epoch: 7.93 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4989055239139844		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4989055239139844 | validation: 0.48505373838932975]
	TIME [epoch: 7.93 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5132229258072903		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5132229258072903 | validation: 0.47916545876297373]
	TIME [epoch: 7.94 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5316034472724139		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5316034472724139 | validation: 0.5381429240123519]
	TIME [epoch: 7.95 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5071002879767094		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5071002879767094 | validation: 0.5487342563846616]
	TIME [epoch: 7.93 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.46775314719536204		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.46775314719536204 | validation: 0.5728903216070461]
	TIME [epoch: 7.93 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.42329593707060614		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.42329593707060614 | validation: 0.6369058771788298]
	TIME [epoch: 7.93 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.510800760944571		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.510800760944571 | validation: 0.6675321539380559]
	TIME [epoch: 7.94 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4843219538600454		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4843219538600454 | validation: 0.5863264812335378]
	TIME [epoch: 7.94 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4653405269757218		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4653405269757218 | validation: 0.4533099139452331]
	TIME [epoch: 7.93 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.47559037938775933		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.47559037938775933 | validation: 0.39789370393730916]
	TIME [epoch: 7.93 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v7_20240710_201912/states/model_facs_dec1b_2dpca_v7_35.pth
	Model improved!!!
EPOCH 36/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.38870425141286785		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.38870425141286785 | validation: 0.4105044330482442]
	TIME [epoch: 7.94 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.45220533356957937		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.45220533356957937 | validation: 0.4499276710377905]
	TIME [epoch: 7.95 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.41049310462246386		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.41049310462246386 | validation: 0.46529614810639125]
	TIME [epoch: 7.93 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.45937752861533987		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.45937752861533987 | validation: 0.553190530914428]
	TIME [epoch: 7.95 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4082294947947356		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4082294947947356 | validation: 0.41737697678903674]
	TIME [epoch: 7.93 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.39097581066178033		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.39097581066178033 | validation: 0.3894720353511034]
	TIME [epoch: 7.95 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v7_20240710_201912/states/model_facs_dec1b_2dpca_v7_41.pth
	Model improved!!!
EPOCH 42/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4529763489948372		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4529763489948372 | validation: 0.4556172105550534]
	TIME [epoch: 7.93 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3835425266809382		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3835425266809382 | validation: 0.5770223670037453]
	TIME [epoch: 7.99 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4520843278810237		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4520843278810237 | validation: 0.3792566084981516]
	TIME [epoch: 7.93 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v7_20240710_201912/states/model_facs_dec1b_2dpca_v7_44.pth
	Model improved!!!
EPOCH 45/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4287041970545696		[learning rate: 0.0099823]
	Learning Rate: 0.0099823
	LOSS [training: 0.4287041970545696 | validation: 0.4197648384783624]
	TIME [epoch: 7.94 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.411702186455291		[learning rate: 0.0099426]
	Learning Rate: 0.0099426
	LOSS [training: 0.411702186455291 | validation: 0.4320322626425711]
	TIME [epoch: 7.92 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.39994530831099		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 0.39994530831099 | validation: 0.4985540596701922]
	TIME [epoch: 7.92 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.47319288066494547		[learning rate: 0.0098637]
	Learning Rate: 0.00986367
	LOSS [training: 0.47319288066494547 | validation: 0.446192454946799]
	TIME [epoch: 7.92 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3684664447441299		[learning rate: 0.0098244]
	Learning Rate: 0.00982444
	LOSS [training: 0.3684664447441299 | validation: 0.37540543078103805]
	TIME [epoch: 7.93 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v7_20240710_201912/states/model_facs_dec1b_2dpca_v7_49.pth
	Model improved!!!
EPOCH 50/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3669158655017748		[learning rate: 0.0097854]
	Learning Rate: 0.00978536
	LOSS [training: 0.3669158655017748 | validation: 0.35603780862970846]
	TIME [epoch: 7.94 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v7_20240710_201912/states/model_facs_dec1b_2dpca_v7_50.pth
	Model improved!!!
EPOCH 51/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.36979997488024424		[learning rate: 0.0097464]
	Learning Rate: 0.00974644
	LOSS [training: 0.36979997488024424 | validation: 0.42611981847274916]
	TIME [epoch: 7.93 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.37991359708318834		[learning rate: 0.0097077]
	Learning Rate: 0.00970768
	LOSS [training: 0.37991359708318834 | validation: 0.43660970686296763]
	TIME [epoch: 7.93 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3931826086294361		[learning rate: 0.0096691]
	Learning Rate: 0.00966907
	LOSS [training: 0.3931826086294361 | validation: 0.3952082749229079]
	TIME [epoch: 7.95 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3658953421566441		[learning rate: 0.0096306]
	Learning Rate: 0.00963061
	LOSS [training: 0.3658953421566441 | validation: 0.3524581204273162]
	TIME [epoch: 7.94 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v7_20240710_201912/states/model_facs_dec1b_2dpca_v7_54.pth
	Model improved!!!
EPOCH 55/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.358868049275225		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 0.358868049275225 | validation: 0.3934041824696727]
	TIME [epoch: 7.93 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.39690980164495615		[learning rate: 0.0095542]
	Learning Rate: 0.00955415
	LOSS [training: 0.39690980164495615 | validation: 0.5439560864866291]
	TIME [epoch: 7.94 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.45690183734663		[learning rate: 0.0095162]
	Learning Rate: 0.00951616
	LOSS [training: 0.45690183734663 | validation: 0.37921689102419365]
	TIME [epoch: 7.93 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.36278985562936233		[learning rate: 0.0094783]
	Learning Rate: 0.00947831
	LOSS [training: 0.36278985562936233 | validation: 0.4818421745253346]
	TIME [epoch: 7.95 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.354953701358386		[learning rate: 0.0094406]
	Learning Rate: 0.00944061
	LOSS [training: 0.354953701358386 | validation: 0.39721290622146394]
	TIME [epoch: 7.93 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.35360529373326594		[learning rate: 0.0094031]
	Learning Rate: 0.00940306
	LOSS [training: 0.35360529373326594 | validation: 0.406178353921114]
	TIME [epoch: 7.93 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3707017585140806		[learning rate: 0.0093657]
	Learning Rate: 0.00936566
	LOSS [training: 0.3707017585140806 | validation: 0.38180093982750657]
	TIME [epoch: 7.92 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3679811426687012		[learning rate: 0.0093284]
	Learning Rate: 0.00932841
	LOSS [training: 0.3679811426687012 | validation: 0.3709539560111083]
	TIME [epoch: 7.95 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3635636591337889		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 0.3635636591337889 | validation: 0.3968503847175156]
	TIME [epoch: 7.93 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.38235311164894503		[learning rate: 0.0092544]
	Learning Rate: 0.00925435
	LOSS [training: 0.38235311164894503 | validation: 0.34632161375955317]
	TIME [epoch: 7.93 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v7_20240710_201912/states/model_facs_dec1b_2dpca_v7_64.pth
	Model improved!!!
EPOCH 65/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.363006330239733		[learning rate: 0.0092175]
	Learning Rate: 0.00921755
	LOSS [training: 0.363006330239733 | validation: 0.3543762089929436]
	TIME [epoch: 7.94 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3341600149843061		[learning rate: 0.0091809]
	Learning Rate: 0.00918089
	LOSS [training: 0.3341600149843061 | validation: 0.3946437123936379]
	TIME [epoch: 7.95 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.34118948965747675		[learning rate: 0.0091444]
	Learning Rate: 0.00914437
	LOSS [training: 0.34118948965747675 | validation: 0.4286019981901045]
	TIME [epoch: 7.93 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.39838165143012816		[learning rate: 0.009108]
	Learning Rate: 0.009108
	LOSS [training: 0.39838165143012816 | validation: 0.33811477741953155]
	TIME [epoch: 7.93 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v7_20240710_201912/states/model_facs_dec1b_2dpca_v7_68.pth
	Model improved!!!
EPOCH 69/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.34548659066275195		[learning rate: 0.0090718]
	Learning Rate: 0.00907178
	LOSS [training: 0.34548659066275195 | validation: 0.4959577090536418]
	TIME [epoch: 7.93 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.37435972156664526		[learning rate: 0.0090357]
	Learning Rate: 0.00903569
	LOSS [training: 0.37435972156664526 | validation: 0.35958068580379854]
	TIME [epoch: 7.94 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.35519300180011126		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 0.35519300180011126 | validation: 0.42719488431233277]
	TIME [epoch: 7.93 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.340390159933215		[learning rate: 0.008964]
	Learning Rate: 0.00896396
	LOSS [training: 0.340390159933215 | validation: 0.35772298723903184]
	TIME [epoch: 7.93 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.33763035940358055		[learning rate: 0.0089283]
	Learning Rate: 0.00892831
	LOSS [training: 0.33763035940358055 | validation: 0.37345570744175033]
	TIME [epoch: 7.93 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3738260353477646		[learning rate: 0.0088928]
	Learning Rate: 0.0088928
	LOSS [training: 0.3738260353477646 | validation: 0.4114343133584436]
	TIME [epoch: 7.94 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3521705743645318		[learning rate: 0.0088574]
	Learning Rate: 0.00885743
	LOSS [training: 0.3521705743645318 | validation: 0.5103669452506102]
	TIME [epoch: 7.93 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3705019905021556		[learning rate: 0.0088222]
	Learning Rate: 0.0088222
	LOSS [training: 0.3705019905021556 | validation: 0.3513718399703794]
	TIME [epoch: 7.93 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.38635942748640006		[learning rate: 0.0087871]
	Learning Rate: 0.00878711
	LOSS [training: 0.38635942748640006 | validation: 0.3411606208625639]
	TIME [epoch: 7.93 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3224493377379032		[learning rate: 0.0087522]
	Learning Rate: 0.00875216
	LOSS [training: 0.3224493377379032 | validation: 0.3465454355230543]
	TIME [epoch: 7.93 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3538558121810913		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 0.3538558121810913 | validation: 0.3829715717407426]
	TIME [epoch: 7.95 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.31292955908746145		[learning rate: 0.0086827]
	Learning Rate: 0.00868268
	LOSS [training: 0.31292955908746145 | validation: 0.34317482952947115]
	TIME [epoch: 7.96 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.31941277817387714		[learning rate: 0.0086481]
	Learning Rate: 0.00864815
	LOSS [training: 0.31941277817387714 | validation: 0.35534161048777974]
	TIME [epoch: 7.94 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3281338439445759		[learning rate: 0.0086138]
	Learning Rate: 0.00861375
	LOSS [training: 0.3281338439445759 | validation: 0.3594515201499377]
	TIME [epoch: 7.93 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.36820455788555784		[learning rate: 0.0085795]
	Learning Rate: 0.00857949
	LOSS [training: 0.36820455788555784 | validation: 0.3473870666746526]
	TIME [epoch: 7.94 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32860263459130234		[learning rate: 0.0085454]
	Learning Rate: 0.00854537
	LOSS [training: 0.32860263459130234 | validation: 0.3553352045948486]
	TIME [epoch: 7.94 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.31188072868440364		[learning rate: 0.0085114]
	Learning Rate: 0.00851138
	LOSS [training: 0.31188072868440364 | validation: 0.31329068840376667]
	TIME [epoch: 7.93 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v7_20240710_201912/states/model_facs_dec1b_2dpca_v7_85.pth
	Model improved!!!
EPOCH 86/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32228442101609905		[learning rate: 0.0084775]
	Learning Rate: 0.00847753
	LOSS [training: 0.32228442101609905 | validation: 0.3502733108720807]
	TIME [epoch: 7.93 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.36775273033098027		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 0.36775273033098027 | validation: 0.3390738100866388]
	TIME [epoch: 7.93 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32934804710306503		[learning rate: 0.0084102]
	Learning Rate: 0.00841023
	LOSS [training: 0.32934804710306503 | validation: 0.35538115586109453]
	TIME [epoch: 7.94 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3337335505507567		[learning rate: 0.0083768]
	Learning Rate: 0.00837678
	LOSS [training: 0.3337335505507567 | validation: 0.3846117727185344]
	TIME [epoch: 7.93 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.39520740614251554		[learning rate: 0.0083435]
	Learning Rate: 0.00834346
	LOSS [training: 0.39520740614251554 | validation: 1.489066213822346]
	TIME [epoch: 7.92 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5842846334738963		[learning rate: 0.0083103]
	Learning Rate: 0.00831027
	LOSS [training: 0.5842846334738963 | validation: 0.3634534231229662]
	TIME [epoch: 7.93 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.33446268001132007		[learning rate: 0.0082772]
	Learning Rate: 0.00827722
	LOSS [training: 0.33446268001132007 | validation: 0.33932569184255623]
	TIME [epoch: 7.94 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.31201090888199784		[learning rate: 0.0082443]
	Learning Rate: 0.0082443
	LOSS [training: 0.31201090888199784 | validation: 0.3108405605575854]
	TIME [epoch: 7.92 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v7_20240710_201912/states/model_facs_dec1b_2dpca_v7_93.pth
	Model improved!!!
EPOCH 94/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.30429650389349505		[learning rate: 0.0082115]
	Learning Rate: 0.00821151
	LOSS [training: 0.30429650389349505 | validation: 0.3189747192544941]
	TIME [epoch: 7.93 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32074203615585284		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 0.32074203615585284 | validation: 0.3744960995714009]
	TIME [epoch: 7.92 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.33747857110287216		[learning rate: 0.0081463]
	Learning Rate: 0.00814632
	LOSS [training: 0.33747857110287216 | validation: 0.31778543990424024]
	TIME [epoch: 7.94 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5453348853644988		[learning rate: 0.0081139]
	Learning Rate: 0.00811392
	LOSS [training: 0.5453348853644988 | validation: 0.4010357107761807]
	TIME [epoch: 7.94 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.33672168348665443		[learning rate: 0.0080816]
	Learning Rate: 0.00808165
	LOSS [training: 0.33672168348665443 | validation: 0.30687576199445366]
	TIME [epoch: 7.93 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v7_20240710_201912/states/model_facs_dec1b_2dpca_v7_98.pth
	Model improved!!!
EPOCH 99/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3004271784506767		[learning rate: 0.0080495]
	Learning Rate: 0.00804951
	LOSS [training: 0.3004271784506767 | validation: 0.3447074035352934]
	TIME [epoch: 7.93 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32648389159145824		[learning rate: 0.0080175]
	Learning Rate: 0.00801749
	LOSS [training: 0.32648389159145824 | validation: 0.4184404180736346]
	TIME [epoch: 7.94 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.34257036366840743		[learning rate: 0.0079856]
	Learning Rate: 0.0079856
	LOSS [training: 0.34257036366840743 | validation: 0.40692507727417804]
	TIME [epoch: 7.94 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3268985487066783		[learning rate: 0.0079538]
	Learning Rate: 0.00795384
	LOSS [training: 0.3268985487066783 | validation: 0.34892844682705804]
	TIME [epoch: 7.94 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.351743137259685		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 0.351743137259685 | validation: 0.37240883000502656]
	TIME [epoch: 7.94 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.33290362793086486		[learning rate: 0.0078907]
	Learning Rate: 0.0078907
	LOSS [training: 0.33290362793086486 | validation: 0.33831020971475845]
	TIME [epoch: 7.94 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5147305454843695		[learning rate: 0.0078593]
	Learning Rate: 0.00785931
	LOSS [training: 0.5147305454843695 | validation: 0.3805664838122782]
	TIME [epoch: 7.95 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3744160915783557		[learning rate: 0.0078281]
	Learning Rate: 0.00782805
	LOSS [training: 0.3744160915783557 | validation: 0.33248887925757215]
	TIME [epoch: 7.93 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.31714543988414434		[learning rate: 0.0077969]
	Learning Rate: 0.00779692
	LOSS [training: 0.31714543988414434 | validation: 0.3293282286505904]
	TIME [epoch: 7.93 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3157797846628862		[learning rate: 0.0077659]
	Learning Rate: 0.00776591
	LOSS [training: 0.3157797846628862 | validation: 0.34948867714910664]
	TIME [epoch: 7.93 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.31056190959302277		[learning rate: 0.007735]
	Learning Rate: 0.00773502
	LOSS [training: 0.31056190959302277 | validation: 0.31187532181378624]
	TIME [epoch: 7.95 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3155103414211056		[learning rate: 0.0077043]
	Learning Rate: 0.00770426
	LOSS [training: 0.3155103414211056 | validation: 0.4262838269517788]
	TIME [epoch: 7.94 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.354460833155484		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 0.354460833155484 | validation: 0.4390734128860842]
	TIME [epoch: 7.93 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3177886835617346		[learning rate: 0.0076431]
	Learning Rate: 0.00764309
	LOSS [training: 0.3177886835617346 | validation: 0.3277550626644101]
	TIME [epoch: 7.93 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3347163859399609		[learning rate: 0.0076127]
	Learning Rate: 0.00761269
	LOSS [training: 0.3347163859399609 | validation: 0.3103824273107323]
	TIME [epoch: 7.93 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3364196629491381		[learning rate: 0.0075824]
	Learning Rate: 0.00758242
	LOSS [training: 0.3364196629491381 | validation: 0.35356811494659957]
	TIME [epoch: 7.95 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.31408026461204525		[learning rate: 0.0075523]
	Learning Rate: 0.00755226
	LOSS [training: 0.31408026461204525 | validation: 0.3832308729510221]
	TIME [epoch: 7.93 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.44215487226996913		[learning rate: 0.0075222]
	Learning Rate: 0.00752222
	LOSS [training: 0.44215487226996913 | validation: 0.3241809628622648]
	TIME [epoch: 7.93 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.30434449551691023		[learning rate: 0.0074923]
	Learning Rate: 0.0074923
	LOSS [training: 0.30434449551691023 | validation: 0.349433440753073]
	TIME [epoch: 7.93 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6923419098273155		[learning rate: 0.0074625]
	Learning Rate: 0.0074625
	LOSS [training: 0.6923419098273155 | validation: 0.4026497489091483]
	TIME [epoch: 7.95 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3679086039137834		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 0.3679086039137834 | validation: 0.36629470010269644]
	TIME [epoch: 7.93 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3243340069286917		[learning rate: 0.0074033]
	Learning Rate: 0.00740326
	LOSS [training: 0.3243340069286917 | validation: 0.3397180609150826]
	TIME [epoch: 7.93 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32699321869091835		[learning rate: 0.0073738]
	Learning Rate: 0.00737382
	LOSS [training: 0.32699321869091835 | validation: 0.333462372310414]
	TIME [epoch: 7.93 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3148402376577436		[learning rate: 0.0073445]
	Learning Rate: 0.00734449
	LOSS [training: 0.3148402376577436 | validation: 0.36071266138224234]
	TIME [epoch: 7.93 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3245771339822662		[learning rate: 0.0073153]
	Learning Rate: 0.00731528
	LOSS [training: 0.3245771339822662 | validation: 0.33999042441841176]
	TIME [epoch: 7.94 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3069765180401055		[learning rate: 0.0072862]
	Learning Rate: 0.00728618
	LOSS [training: 0.3069765180401055 | validation: 0.5523022800918634]
	TIME [epoch: 7.93 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4785073122637886		[learning rate: 0.0072572]
	Learning Rate: 0.0072572
	LOSS [training: 0.4785073122637886 | validation: 0.3498520039298298]
	TIME [epoch: 7.92 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3070196889312845		[learning rate: 0.0072283]
	Learning Rate: 0.00722834
	LOSS [training: 0.3070196889312845 | validation: 0.33000967710701673]
	TIME [epoch: 7.92 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2970322567827186		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 0.2970322567827186 | validation: 0.34292029576920546]
	TIME [epoch: 7.94 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.31478318421651647		[learning rate: 0.007171]
	Learning Rate: 0.00717095
	LOSS [training: 0.31478318421651647 | validation: 0.3658923824422316]
	TIME [epoch: 7.94 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.30788094637025887		[learning rate: 0.0071424]
	Learning Rate: 0.00714243
	LOSS [training: 0.30788094637025887 | validation: 0.31939592043505904]
	TIME [epoch: 7.93 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3087218490975173		[learning rate: 0.007114]
	Learning Rate: 0.00711403
	LOSS [training: 0.3087218490975173 | validation: 0.3212663970247353]
	TIME [epoch: 7.93 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.334163435521228		[learning rate: 0.0070857]
	Learning Rate: 0.00708573
	LOSS [training: 0.334163435521228 | validation: 0.29685519395234705]
	TIME [epoch: 7.93 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v7_20240710_201912/states/model_facs_dec1b_2dpca_v7_131.pth
	Model improved!!!
EPOCH 132/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3426934364481294		[learning rate: 0.0070575]
	Learning Rate: 0.00705755
	LOSS [training: 0.3426934364481294 | validation: 0.8332743218069008]
	TIME [epoch: 7.94 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4772125026784572		[learning rate: 0.0070295]
	Learning Rate: 0.00702948
	LOSS [training: 0.4772125026784572 | validation: 0.3608453402516196]
	TIME [epoch: 7.92 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.33103954395072627		[learning rate: 0.0070015]
	Learning Rate: 0.00700152
	LOSS [training: 0.33103954395072627 | validation: 0.3465341074239043]
	TIME [epoch: 7.92 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3334420521152186		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 0.3334420521152186 | validation: 0.3171918190064475]
	TIME [epoch: 7.92 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.31406748332433077		[learning rate: 0.0069459]
	Learning Rate: 0.00694594
	LOSS [training: 0.31406748332433077 | validation: 0.36048526651969903]
	TIME [epoch: 7.94 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.46114273301160374		[learning rate: 0.0069183]
	Learning Rate: 0.00691831
	LOSS [training: 0.46114273301160374 | validation: 0.4151718754818184]
	TIME [epoch: 7.93 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4032566375032602		[learning rate: 0.0068908]
	Learning Rate: 0.00689079
	LOSS [training: 0.4032566375032602 | validation: 0.3754355271403118]
	TIME [epoch: 7.92 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.39107660089183494		[learning rate: 0.0068634]
	Learning Rate: 0.00686339
	LOSS [training: 0.39107660089183494 | validation: 0.37006582574443503]
	TIME [epoch: 7.93 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.34071353768856366		[learning rate: 0.0068361]
	Learning Rate: 0.00683609
	LOSS [training: 0.34071353768856366 | validation: 0.3633578112008099]
	TIME [epoch: 7.94 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3652477542650161		[learning rate: 0.0068089]
	Learning Rate: 0.0068089
	LOSS [training: 0.3652477542650161 | validation: 0.3663480846858624]
	TIME [epoch: 7.93 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3449123143407589		[learning rate: 0.0067818]
	Learning Rate: 0.00678182
	LOSS [training: 0.3449123143407589 | validation: 0.34709861388354685]
	TIME [epoch: 7.93 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.2615720051492227		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 1.2615720051492227 | validation: 3.0017168385434383]
	TIME [epoch: 7.93 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 9/9] avg loss: 3.9732921829111234		[learning rate: 0.006728]
	Learning Rate: 0.00672798
	LOSS [training: 3.9732921829111234 | validation: 3.0004240980588754]
	TIME [epoch: 7.93 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 9/9] avg loss: 2.60056739032169		[learning rate: 0.0067012]
	Learning Rate: 0.00670122
	LOSS [training: 2.60056739032169 | validation: 3.6598318559901246]
	TIME [epoch: 7.94 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 9/9] avg loss: 3.1138113733182036		[learning rate: 0.0066746]
	Learning Rate: 0.00667457
	LOSS [training: 3.1138113733182036 | validation: 3.14706312728289]
	TIME [epoch: 7.92 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 9/9] avg loss: 2.4136905001852296		[learning rate: 0.006648]
	Learning Rate: 0.00664802
	LOSS [training: 2.4136905001852296 | validation: 2.5174398153110458]
	TIME [epoch: 7.92 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 9/9] avg loss: 4.553671346432259		[learning rate: 0.0066216]
	Learning Rate: 0.00662158
	LOSS [training: 4.553671346432259 | validation: 5.978973522221848]
	TIME [epoch: 7.92 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 9/9] avg loss: 5.442739513935589		[learning rate: 0.0065952]
	Learning Rate: 0.00659524
	LOSS [training: 5.442739513935589 | validation: 5.775973110077656]
	TIME [epoch: 7.94 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 9/9] avg loss: 5.9205166057148215		[learning rate: 0.006569]
	Learning Rate: 0.00656901
	LOSS [training: 5.9205166057148215 | validation: 6.1142589597742]
	TIME [epoch: 7.93 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 9/9] avg loss: 5.657886666795843		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 5.657886666795843 | validation: 4.929132845380685]
	TIME [epoch: 7.92 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 9/9] avg loss: 4.162192226839277		[learning rate: 0.0065169]
	Learning Rate: 0.00651686
	LOSS [training: 4.162192226839277 | validation: 3.3792821441181777]
	TIME [epoch: 7.92 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 9/9] avg loss: 3.3295438517204614		[learning rate: 0.0064909]
	Learning Rate: 0.00649094
	LOSS [training: 3.3295438517204614 | validation: 3.126041719877133]
	TIME [epoch: 7.93 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 9/9] avg loss: 3.443589117010141		[learning rate: 0.0064651]
	Learning Rate: 0.00646512
	LOSS [training: 3.443589117010141 | validation: 3.4276946343584695]
	TIME [epoch: 7.94 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 9/9] avg loss: 3.5841745533189533		[learning rate: 0.0064394]
	Learning Rate: 0.00643941
	LOSS [training: 3.5841745533189533 | validation: 3.585131885201683]
	TIME [epoch: 7.93 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 9/9] avg loss: 3.943532597384302		[learning rate: 0.0064138]
	Learning Rate: 0.0064138
	LOSS [training: 3.943532597384302 | validation: 3.8822934803208837]
	TIME [epoch: 7.93 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 9/9] avg loss: 3.208478657312011		[learning rate: 0.0063883]
	Learning Rate: 0.00638829
	LOSS [training: 3.208478657312011 | validation: 1.6892091207454414]
	TIME [epoch: 7.93 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.6751043725216084		[learning rate: 0.0063629]
	Learning Rate: 0.00636288
	LOSS [training: 1.6751043725216084 | validation: 1.4492800961797185]
	TIME [epoch: 7.93 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.5369931777778876		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 1.5369931777778876 | validation: 1.4552822794525642]
	TIME [epoch: 7.92 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.4791182536691823		[learning rate: 0.0063124]
	Learning Rate: 0.00631237
	LOSS [training: 1.4791182536691823 | validation: 1.4206423937767299]
	TIME [epoch: 7.92 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.4670995225322203		[learning rate: 0.0062873]
	Learning Rate: 0.00628726
	LOSS [training: 1.4670995225322203 | validation: 1.3563421497849926]
	TIME [epoch: 7.92 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.4324436260805793		[learning rate: 0.0062623]
	Learning Rate: 0.00626226
	LOSS [training: 1.4324436260805793 | validation: 1.3757999634910107]
	TIME [epoch: 7.92 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.386400584322398		[learning rate: 0.0062373]
	Learning Rate: 0.00623735
	LOSS [training: 1.386400584322398 | validation: 1.3676663141151368]
	TIME [epoch: 7.94 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.2279700684271648		[learning rate: 0.0062125]
	Learning Rate: 0.00621254
	LOSS [training: 1.2279700684271648 | validation: 1.0991112232763485]
	TIME [epoch: 7.92 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.0835018907931873		[learning rate: 0.0061878]
	Learning Rate: 0.00618783
	LOSS [training: 1.0835018907931873 | validation: 0.7816033808154277]
	TIME [epoch: 7.92 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6753120302807265		[learning rate: 0.0061632]
	Learning Rate: 0.00616322
	LOSS [training: 0.6753120302807265 | validation: 0.5057835795300402]
	TIME [epoch: 7.92 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5546082624886426		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 0.5546082624886426 | validation: 0.5715339271722846]
	TIME [epoch: 7.94 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5178376298484234		[learning rate: 0.0061143]
	Learning Rate: 0.00611429
	LOSS [training: 0.5178376298484234 | validation: 0.5694186616256524]
	TIME [epoch: 7.93 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.48946245809291816		[learning rate: 0.00609]
	Learning Rate: 0.00608997
	LOSS [training: 0.48946245809291816 | validation: 0.5090677404872059]
	TIME [epoch: 7.92 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6372215353092605		[learning rate: 0.0060658]
	Learning Rate: 0.00606575
	LOSS [training: 0.6372215353092605 | validation: 0.6235292139481717]
	TIME [epoch: 7.92 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7264956520680099		[learning rate: 0.0060416]
	Learning Rate: 0.00604163
	LOSS [training: 0.7264956520680099 | validation: 0.6000174197787972]
	TIME [epoch: 7.93 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6739967593549461		[learning rate: 0.0060176]
	Learning Rate: 0.0060176
	LOSS [training: 0.6739967593549461 | validation: 0.5350697838530133]
	TIME [epoch: 7.94 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.514018739252096		[learning rate: 0.0059937]
	Learning Rate: 0.00599366
	LOSS [training: 0.514018739252096 | validation: 0.5073288476070239]
	TIME [epoch: 7.92 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4687143813850167		[learning rate: 0.0059698]
	Learning Rate: 0.00596982
	LOSS [training: 0.4687143813850167 | validation: 0.490316776312516]
	TIME [epoch: 7.92 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.48309146790825114		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 0.48309146790825114 | validation: 0.424724738624219]
	TIME [epoch: 7.93 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4648980982795315		[learning rate: 0.0059224]
	Learning Rate: 0.00592243
	LOSS [training: 0.4648980982795315 | validation: 0.4091914236035561]
	TIME [epoch: 7.94 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.43929682523923613		[learning rate: 0.0058989]
	Learning Rate: 0.00589888
	LOSS [training: 0.43929682523923613 | validation: 0.4838633196085689]
	TIME [epoch: 7.93 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4427628226631465		[learning rate: 0.0058754]
	Learning Rate: 0.00587541
	LOSS [training: 0.4427628226631465 | validation: 0.4251865860371836]
	TIME [epoch: 7.93 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4115661920874947		[learning rate: 0.005852]
	Learning Rate: 0.00585205
	LOSS [training: 0.4115661920874947 | validation: 0.45630172567297356]
	TIME [epoch: 7.93 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5026785881006693		[learning rate: 0.0058288]
	Learning Rate: 0.00582877
	LOSS [training: 0.5026785881006693 | validation: 0.5216876865939519]
	TIME [epoch: 7.93 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.46182853334402235		[learning rate: 0.0058056]
	Learning Rate: 0.00580559
	LOSS [training: 0.46182853334402235 | validation: 0.4239987555699173]
	TIME [epoch: 7.94 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.41510864674493436		[learning rate: 0.0057825]
	Learning Rate: 0.0057825
	LOSS [training: 0.41510864674493436 | validation: 0.3825221494032236]
	TIME [epoch: 7.93 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4079311401020472		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 0.4079311401020472 | validation: 0.3874236912797956]
	TIME [epoch: 7.93 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.37325701524849414		[learning rate: 0.0057366]
	Learning Rate: 0.00573659
	LOSS [training: 0.37325701524849414 | validation: 0.391768531811744]
	TIME [epoch: 7.93 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3828411311883062		[learning rate: 0.0057138]
	Learning Rate: 0.00571377
	LOSS [training: 0.3828411311883062 | validation: 0.3960420085385955]
	TIME [epoch: 7.94 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.37482366516331633		[learning rate: 0.005691]
	Learning Rate: 0.00569105
	LOSS [training: 0.37482366516331633 | validation: 0.3652223783615445]
	TIME [epoch: 7.93 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.42359651411833155		[learning rate: 0.0056684]
	Learning Rate: 0.00566841
	LOSS [training: 0.42359651411833155 | validation: 0.37995705629576004]
	TIME [epoch: 7.93 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5934581285202949		[learning rate: 0.0056459]
	Learning Rate: 0.00564587
	LOSS [training: 0.5934581285202949 | validation: 0.3954502646855428]
	TIME [epoch: 7.92 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.37030767429871025		[learning rate: 0.0056234]
	Learning Rate: 0.00562341
	LOSS [training: 0.37030767429871025 | validation: 0.3511657655548727]
	TIME [epoch: 7.93 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.8976748003831386		[learning rate: 0.005601]
	Learning Rate: 0.00560105
	LOSS [training: 0.8976748003831386 | validation: 2.730230730585981]
	TIME [epoch: 7.95 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 9/9] avg loss: 2.1684964372934314		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 2.1684964372934314 | validation: 3.434165508101249]
	TIME [epoch: 7.93 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 9/9] avg loss: 3.7985071311461827		[learning rate: 0.0055566]
	Learning Rate: 0.00555658
	LOSS [training: 3.7985071311461827 | validation: 4.278537166965215]
	TIME [epoch: 7.93 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 9/9] avg loss: 3.562216812344979		[learning rate: 0.0055345]
	Learning Rate: 0.00553448
	LOSS [training: 3.562216812344979 | validation: 3.4319328977521066]
	TIME [epoch: 7.93 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 9/9] avg loss: 3.432797936855814		[learning rate: 0.0055125]
	Learning Rate: 0.00551247
	LOSS [training: 3.432797936855814 | validation: 3.6439184401149527]
	TIME [epoch: 7.94 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 9/9] avg loss: 2.173668630434691		[learning rate: 0.0054905]
	Learning Rate: 0.00549054
	LOSS [training: 2.173668630434691 | validation: 3.120015430699373]
	TIME [epoch: 7.93 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 9/9] avg loss: 3.1782321633165234		[learning rate: 0.0054687]
	Learning Rate: 0.00546871
	LOSS [training: 3.1782321633165234 | validation: 1.9289066956808338]
	TIME [epoch: 7.93 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 9/9] avg loss: 2.1566284195641954		[learning rate: 0.005447]
	Learning Rate: 0.00544696
	LOSS [training: 2.1566284195641954 | validation: 2.9409367177092984]
	TIME [epoch: 7.93 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 9/9] avg loss: 3.8104371959147594		[learning rate: 0.0054253]
	Learning Rate: 0.00542529
	LOSS [training: 3.8104371959147594 | validation: 5.242801115491359]
	TIME [epoch: 7.93 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 9/9] avg loss: 5.530611591387684		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 5.530611591387684 | validation: 5.9341381647070905]
	TIME [epoch: 7.94 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 9/9] avg loss: 5.7470351191147		[learning rate: 0.0053822]
	Learning Rate: 0.00538222
	LOSS [training: 5.7470351191147 | validation: 5.388016667652183]
	TIME [epoch: 7.92 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 9/9] avg loss: 4.957915695939322		[learning rate: 0.0053608]
	Learning Rate: 0.00536081
	LOSS [training: 4.957915695939322 | validation: 4.746326960913764]
	TIME [epoch: 7.93 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 9/9] avg loss: 4.693584246826912		[learning rate: 0.0053395]
	Learning Rate: 0.00533949
	LOSS [training: 4.693584246826912 | validation: 6.541804658150864]
	TIME [epoch: 7.92 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 9/9] avg loss: 6.121171253891599		[learning rate: 0.0053183]
	Learning Rate: 0.00531826
	LOSS [training: 6.121171253891599 | validation: 4.686479816498257]
	TIME [epoch: 7.93 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 9/9] avg loss: 4.301341646785706		[learning rate: 0.0052971]
	Learning Rate: 0.0052971
	LOSS [training: 4.301341646785706 | validation: 4.514652488418491]
	TIME [epoch: 7.93 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 9/9] avg loss: 3.8099470321330466		[learning rate: 0.005276]
	Learning Rate: 0.00527604
	LOSS [training: 3.8099470321330466 | validation: 4.363377632077862]
	TIME [epoch: 7.93 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 9/9] avg loss: 4.277552673947541		[learning rate: 0.0052551]
	Learning Rate: 0.00525505
	LOSS [training: 4.277552673947541 | validation: 5.2645739178674145]
	TIME [epoch: 7.92 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 9/9] avg loss: 5.20161903047643		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 5.20161903047643 | validation: 4.168070284380797]
	TIME [epoch: 7.93 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 9/9] avg loss: 4.034123306651875		[learning rate: 0.0052133]
	Learning Rate: 0.00521333
	LOSS [training: 4.034123306651875 | validation: 3.285944688562643]
	TIME [epoch: 7.92 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 9/9] avg loss: 3.2392776289317706		[learning rate: 0.0051926]
	Learning Rate: 0.0051926
	LOSS [training: 3.2392776289317706 | validation: 2.530823375160452]
	TIME [epoch: 7.92 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 9/9] avg loss: 3.374062045991748		[learning rate: 0.0051719]
	Learning Rate: 0.00517194
	LOSS [training: 3.374062045991748 | validation: 6.67187914478594]
	TIME [epoch: 7.92 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 9/9] avg loss: 5.7187855089325685		[learning rate: 0.0051514]
	Learning Rate: 0.00515137
	LOSS [training: 5.7187855089325685 | validation: 3.1236096777400193]
	TIME [epoch: 7.92 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 9/9] avg loss: 4.065057786257606		[learning rate: 0.0051309]
	Learning Rate: 0.00513089
	LOSS [training: 4.065057786257606 | validation: 5.250250471665675]
	TIME [epoch: 7.94 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 9/9] avg loss: 5.216840125613047		[learning rate: 0.0051105]
	Learning Rate: 0.00511048
	LOSS [training: 5.216840125613047 | validation: 4.351601491763413]
	TIME [epoch: 7.93 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 9/9] avg loss: 4.294136495607099		[learning rate: 0.0050902]
	Learning Rate: 0.00509015
	LOSS [training: 4.294136495607099 | validation: 3.8453616939085675]
	TIME [epoch: 7.92 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 9/9] avg loss: 3.9692353198727943		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 3.9692353198727943 | validation: 4.053821547807348]
	TIME [epoch: 7.92 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 9/9] avg loss: 4.164065728072999		[learning rate: 0.0050497]
	Learning Rate: 0.00504974
	LOSS [training: 4.164065728072999 | validation: 3.9472257375061104]
	TIME [epoch: 7.93 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 9/9] avg loss: 4.537931409649758		[learning rate: 0.0050297]
	Learning Rate: 0.00502966
	LOSS [training: 4.537931409649758 | validation: 4.540693451583276]
	TIME [epoch: 7.93 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 9/9] avg loss: 4.873247085462564		[learning rate: 0.0050097]
	Learning Rate: 0.00500965
	LOSS [training: 4.873247085462564 | validation: 4.249571712395836]
	TIME [epoch: 7.92 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 9/9] avg loss: 4.424383430884248		[learning rate: 0.0049897]
	Learning Rate: 0.00498973
	LOSS [training: 4.424383430884248 | validation: 4.3713721444538525]
	TIME [epoch: 7.92 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 9/9] avg loss: 4.640651278739154		[learning rate: 0.0049699]
	Learning Rate: 0.00496988
	LOSS [training: 4.640651278739154 | validation: 4.240279219787932]
	TIME [epoch: 7.92 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 9/9] avg loss: 4.439706828123818		[learning rate: 0.0049501]
	Learning Rate: 0.00495012
	LOSS [training: 4.439706828123818 | validation: 4.134671299236081]
	TIME [epoch: 7.94 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 9/9] avg loss: 4.596750948113459		[learning rate: 0.0049304]
	Learning Rate: 0.00493043
	LOSS [training: 4.596750948113459 | validation: 4.5942180117469285]
	TIME [epoch: 7.91 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 9/9] avg loss: 4.685381304925548		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 4.685381304925548 | validation: 4.320387418736623]
	TIME [epoch: 7.92 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 9/9] avg loss: 5.240729136848327		[learning rate: 0.0048913]
	Learning Rate: 0.00489129
	LOSS [training: 5.240729136848327 | validation: 6.129425969634723]
	TIME [epoch: 7.92 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 9/9] avg loss: 6.535486203556766		[learning rate: 0.0048718]
	Learning Rate: 0.00487183
	LOSS [training: 6.535486203556766 | validation: 6.067864167863883]
	TIME [epoch: 7.93 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 9/9] avg loss: 6.55574197758188		[learning rate: 0.0048525]
	Learning Rate: 0.00485245
	LOSS [training: 6.55574197758188 | validation: 6.145100723633963]
	TIME [epoch: 7.92 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 9/9] avg loss: 6.5100683083707445		[learning rate: 0.0048332]
	Learning Rate: 0.00483316
	LOSS [training: 6.5100683083707445 | validation: 6.50350809398971]
	TIME [epoch: 7.92 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 9/9] avg loss: 7.805112370878514		[learning rate: 0.0048139]
	Learning Rate: 0.00481393
	LOSS [training: 7.805112370878514 | validation: 8.714151215628103]
	TIME [epoch: 7.92 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 9/9] avg loss: 8.217617535007838		[learning rate: 0.0047948]
	Learning Rate: 0.00479479
	LOSS [training: 8.217617535007838 | validation: 6.8287387187957105]
	TIME [epoch: 7.92 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 9/9] avg loss: 7.4232014319293445		[learning rate: 0.0047757]
	Learning Rate: 0.00477572
	LOSS [training: 7.4232014319293445 | validation: 7.257544976967765]
	TIME [epoch: 7.94 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 9/9] avg loss: 8.256431175793187		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 8.256431175793187 | validation: 9.19248323393048]
	TIME [epoch: 7.92 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 9/9] avg loss: 9.210267951860704		[learning rate: 0.0047378]
	Learning Rate: 0.0047378
	LOSS [training: 9.210267951860704 | validation: 8.263990877781207]
	TIME [epoch: 7.92 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 9/9] avg loss: 8.151775010511665		[learning rate: 0.004719]
	Learning Rate: 0.00471896
	LOSS [training: 8.151775010511665 | validation: 8.268758575875273]
	TIME [epoch: 7.92 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 9/9] avg loss: 8.71611199115376		[learning rate: 0.0047002]
	Learning Rate: 0.00470019
	LOSS [training: 8.71611199115376 | validation: 8.181319627790142]
	TIME [epoch: 7.92 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 9/9] avg loss: 7.662171358682345		[learning rate: 0.0046815]
	Learning Rate: 0.0046815
	LOSS [training: 7.662171358682345 | validation: 6.894957849107871]
	TIME [epoch: 7.92 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 9/9] avg loss: 7.185820909470855		[learning rate: 0.0046629]
	Learning Rate: 0.00466288
	LOSS [training: 7.185820909470855 | validation: 6.926601245434258]
	TIME [epoch: 7.91 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 9/9] avg loss: 6.672367874781072		[learning rate: 0.0046443]
	Learning Rate: 0.00464433
	LOSS [training: 6.672367874781072 | validation: 5.885618605565656]
	TIME [epoch: 7.92 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 9/9] avg loss: 7.2575055091698175		[learning rate: 0.0046259]
	Learning Rate: 0.00462586
	LOSS [training: 7.2575055091698175 | validation: 7.386856765745902]
	TIME [epoch: 7.92 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 9/9] avg loss: 7.617630004745615		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 7.617630004745615 | validation: 7.037656644495013]
	TIME [epoch: 7.94 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 9/9] avg loss: 7.096559288099219		[learning rate: 0.0045891]
	Learning Rate: 0.00458913
	LOSS [training: 7.096559288099219 | validation: 6.913094334691982]
	TIME [epoch: 7.92 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 9/9] avg loss: 6.829694007292093		[learning rate: 0.0045709]
	Learning Rate: 0.00457088
	LOSS [training: 6.829694007292093 | validation: 6.593718770386073]
	TIME [epoch: 7.92 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 9/9] avg loss: 6.518700919016915		[learning rate: 0.0045527]
	Learning Rate: 0.0045527
	LOSS [training: 6.518700919016915 | validation: 6.176057037295758]
	TIME [epoch: 7.92 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 9/9] avg loss: 6.464052135944531		[learning rate: 0.0045346]
	Learning Rate: 0.00453459
	LOSS [training: 6.464052135944531 | validation: 6.272154422626742]
	TIME [epoch: 7.93 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 9/9] avg loss: 6.6601660729127765		[learning rate: 0.0045166]
	Learning Rate: 0.00451656
	LOSS [training: 6.6601660729127765 | validation: 6.824334677617976]
	TIME [epoch: 7.92 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 9/9] avg loss: 8.721062478563335		[learning rate: 0.0044986]
	Learning Rate: 0.0044986
	LOSS [training: 8.721062478563335 | validation: 9.453493388686056]
	TIME [epoch: 7.91 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 9/9] avg loss: 9.566284158018794		[learning rate: 0.0044807]
	Learning Rate: 0.0044807
	LOSS [training: 9.566284158018794 | validation: 9.448546024795906]
	TIME [epoch: 7.92 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 9/9] avg loss: 9.555585036568168		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 9.555585036568168 | validation: 9.448229090521352]
	TIME [epoch: 7.92 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 9/9] avg loss: 9.550109436829418		[learning rate: 0.0044451]
	Learning Rate: 0.00444513
	LOSS [training: 9.550109436829418 | validation: 9.447206474754292]
	TIME [epoch: 7.93 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 9/9] avg loss: 9.524319219177904		[learning rate: 0.0044275]
	Learning Rate: 0.00442745
	LOSS [training: 9.524319219177904 | validation: 9.421310970820823]
	TIME [epoch: 7.91 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 9/9] avg loss: 9.499694111032943		[learning rate: 0.0044098]
	Learning Rate: 0.00440984
	LOSS [training: 9.499694111032943 | validation: 9.370198860387514]
	TIME [epoch: 7.91 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 9/9] avg loss: 9.188279900825162		[learning rate: 0.0043923]
	Learning Rate: 0.0043923
	LOSS [training: 9.188279900825162 | validation: 7.062197542753047]
	TIME [epoch: 7.91 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 9/9] avg loss: 7.833161629459784		[learning rate: 0.0043748]
	Learning Rate: 0.00437483
	LOSS [training: 7.833161629459784 | validation: 7.454266447082143]
	TIME [epoch: 7.92 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 9/9] avg loss: 7.465400301739335		[learning rate: 0.0043574]
	Learning Rate: 0.00435743
	LOSS [training: 7.465400301739335 | validation: 6.586420923483469]
	TIME [epoch: 7.92 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 9/9] avg loss: 7.137159490957263		[learning rate: 0.0043401]
	Learning Rate: 0.0043401
	LOSS [training: 7.137159490957263 | validation: 6.888045511227345]
	TIME [epoch: 7.91 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 9/9] avg loss: 6.971809563255329		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 6.971809563255329 | validation: 6.278312036442808]
	TIME [epoch: 7.92 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 9/9] avg loss: 5.888787285832051		[learning rate: 0.0043056]
	Learning Rate: 0.00430565
	LOSS [training: 5.888787285832051 | validation: 4.39197850440355]
	TIME [epoch: 7.91 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 9/9] avg loss: 3.741501926488673		[learning rate: 0.0042885]
	Learning Rate: 0.00428852
	LOSS [training: 3.741501926488673 | validation: 2.9179704830827835]
	TIME [epoch: 7.93 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 9/9] avg loss: 2.9064064063459267		[learning rate: 0.0042715]
	Learning Rate: 0.00427147
	LOSS [training: 2.9064064063459267 | validation: 2.86085548042709]
	TIME [epoch: 7.92 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 9/9] avg loss: 2.6805257109536833		[learning rate: 0.0042545]
	Learning Rate: 0.00425448
	LOSS [training: 2.6805257109536833 | validation: 2.1319917877379018]
	TIME [epoch: 7.91 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 9/9] avg loss: 2.188697697142496		[learning rate: 0.0042376]
	Learning Rate: 0.00423756
	LOSS [training: 2.188697697142496 | validation: 1.8425717901255438]
	TIME [epoch: 7.91 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.9933475161295524		[learning rate: 0.0042207]
	Learning Rate: 0.0042207
	LOSS [training: 1.9933475161295524 | validation: 1.455680594021245]
	TIME [epoch: 7.92 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.7289003041191833		[learning rate: 0.0042039]
	Learning Rate: 0.00420391
	LOSS [training: 1.7289003041191833 | validation: 1.2051116252291947]
	TIME [epoch: 7.92 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.714871053139821		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 1.714871053139821 | validation: 1.555421973237819]
	TIME [epoch: 7.92 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.8951584728674378		[learning rate: 0.0041705]
	Learning Rate: 0.00417054
	LOSS [training: 1.8951584728674378 | validation: 1.5915366148251497]
	TIME [epoch: 7.92 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 9/9] avg loss: 2.1432787534722104		[learning rate: 0.004154]
	Learning Rate: 0.00415395
	LOSS [training: 2.1432787534722104 | validation: 2.5680297956820963]
	TIME [epoch: 7.92 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 9/9] avg loss: 2.303350921334724		[learning rate: 0.0041374]
	Learning Rate: 0.00413743
	LOSS [training: 2.303350921334724 | validation: 2.0188504299977263]
	TIME [epoch: 7.94 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 9/9] avg loss: 2.368295871459253		[learning rate: 0.004121]
	Learning Rate: 0.00412098
	LOSS [training: 2.368295871459253 | validation: 1.6232433822609635]
	TIME [epoch: 7.92 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.926386588313675		[learning rate: 0.0041046]
	Learning Rate: 0.00410458
	LOSS [training: 1.926386588313675 | validation: 1.636982463795301]
	TIME [epoch: 7.91 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.8950872523215598		[learning rate: 0.0040883]
	Learning Rate: 0.00408826
	LOSS [training: 1.8950872523215598 | validation: 1.5452592120849897]
	TIME [epoch: 7.91 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.7244947928563077		[learning rate: 0.004072]
	Learning Rate: 0.004072
	LOSS [training: 1.7244947928563077 | validation: 1.759467132234701]
	TIME [epoch: 7.92 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.6735972077945733		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 1.6735972077945733 | validation: 1.2780873681371516]
	TIME [epoch: 7.93 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.3259177383716603		[learning rate: 0.0040397]
	Learning Rate: 0.00403967
	LOSS [training: 1.3259177383716603 | validation: 1.3739980260727696]
	TIME [epoch: 7.91 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.2509880923818542		[learning rate: 0.0040236]
	Learning Rate: 0.00402361
	LOSS [training: 1.2509880923818542 | validation: 1.5519107388268503]
	TIME [epoch: 7.91 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.305934062152465		[learning rate: 0.0040076]
	Learning Rate: 0.0040076
	LOSS [training: 1.305934062152465 | validation: 1.1183042344036436]
	TIME [epoch: 7.92 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.0093478482842824		[learning rate: 0.0039917]
	Learning Rate: 0.00399166
	LOSS [training: 1.0093478482842824 | validation: 1.0256513643746044]
	TIME [epoch: 7.93 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.9720627951220693		[learning rate: 0.0039758]
	Learning Rate: 0.00397579
	LOSS [training: 0.9720627951220693 | validation: 1.1801843235029976]
	TIME [epoch: 7.91 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.9720247254623148		[learning rate: 0.00396]
	Learning Rate: 0.00395997
	LOSS [training: 0.9720247254623148 | validation: 1.3319858173821921]
	TIME [epoch: 7.92 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.9657842302855659		[learning rate: 0.0039442]
	Learning Rate: 0.00394422
	LOSS [training: 0.9657842302855659 | validation: 0.9733950808938043]
	TIME [epoch: 7.92 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.972889356459588		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 0.972889356459588 | validation: 1.094591080225364]
	TIME [epoch: 7.92 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.9255551451830668		[learning rate: 0.0039129]
	Learning Rate: 0.00391291
	LOSS [training: 0.9255551451830668 | validation: 1.0623174074864097]
	TIME [epoch: 7.94 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.919895926292477		[learning rate: 0.0038973]
	Learning Rate: 0.00389735
	LOSS [training: 0.919895926292477 | validation: 1.0134713239878042]
	TIME [epoch: 7.92 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.9289558914421409		[learning rate: 0.0038818]
	Learning Rate: 0.00388185
	LOSS [training: 0.9289558914421409 | validation: 1.1121043681814706]
	TIME [epoch: 7.92 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.8991495475509537		[learning rate: 0.0038664]
	Learning Rate: 0.00386641
	LOSS [training: 0.8991495475509537 | validation: 0.8837317294737869]
	TIME [epoch: 7.92 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.8163463707336164		[learning rate: 0.003851]
	Learning Rate: 0.00385103
	LOSS [training: 0.8163463707336164 | validation: 0.8541752223647799]
	TIME [epoch: 7.93 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.8379957081386473		[learning rate: 0.0038357]
	Learning Rate: 0.00383571
	LOSS [training: 0.8379957081386473 | validation: 0.9886717381332503]
	TIME [epoch: 7.92 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.0276456926935411		[learning rate: 0.0038205]
	Learning Rate: 0.00382046
	LOSS [training: 1.0276456926935411 | validation: 0.8958049833998347]
	TIME [epoch: 7.92 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.9059430834690487		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 0.9059430834690487 | validation: 0.8487610010343921]
	TIME [epoch: 7.92 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.9584610618831874		[learning rate: 0.0037901]
	Learning Rate: 0.00379013
	LOSS [training: 0.9584610618831874 | validation: 0.9135651732192661]
	TIME [epoch: 7.92 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.924419920549989		[learning rate: 0.0037751]
	Learning Rate: 0.00377505
	LOSS [training: 0.924419920549989 | validation: 0.8994519435677567]
	TIME [epoch: 7.93 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.9079183643818494		[learning rate: 0.00376]
	Learning Rate: 0.00376004
	LOSS [training: 0.9079183643818494 | validation: 0.9529659785330808]
	TIME [epoch: 7.91 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.8486518499693618		[learning rate: 0.0037451]
	Learning Rate: 0.00374508
	LOSS [training: 0.8486518499693618 | validation: 0.7886367943532002]
	TIME [epoch: 7.92 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.9330881719525514		[learning rate: 0.0037302]
	Learning Rate: 0.00373019
	LOSS [training: 0.9330881719525514 | validation: 0.7144434118635725]
	TIME [epoch: 7.92 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.0641476551039735		[learning rate: 0.0037154]
	Learning Rate: 0.00371535
	LOSS [training: 1.0641476551039735 | validation: 0.8958945817966587]
	TIME [epoch: 7.93 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.9755473248293778		[learning rate: 0.0037006]
	Learning Rate: 0.00370058
	LOSS [training: 0.9755473248293778 | validation: 0.811799165393901]
	TIME [epoch: 7.92 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.9372529262907214		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 0.9372529262907214 | validation: 0.6925776771576477]
	TIME [epoch: 8 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.728607299062706		[learning rate: 0.0036712]
	Learning Rate: 0.0036712
	LOSS [training: 0.728607299062706 | validation: 0.6483760832712718]
	TIME [epoch: 7.92 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6839779377057877		[learning rate: 0.0036566]
	Learning Rate: 0.0036566
	LOSS [training: 0.6839779377057877 | validation: 0.6061911705762515]
	TIME [epoch: 7.92 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6413597988609282		[learning rate: 0.0036421]
	Learning Rate: 0.00364205
	LOSS [training: 0.6413597988609282 | validation: 0.5398183656154039]
	TIME [epoch: 7.93 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6168187647475806		[learning rate: 0.0036276]
	Learning Rate: 0.00362757
	LOSS [training: 0.6168187647475806 | validation: 0.6119741648413597]
	TIME [epoch: 7.92 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.639893301113036		[learning rate: 0.0036131]
	Learning Rate: 0.00361314
	LOSS [training: 0.639893301113036 | validation: 1.8515396773151398]
	TIME [epoch: 7.92 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7734365507474892		[learning rate: 0.0035988]
	Learning Rate: 0.00359877
	LOSS [training: 0.7734365507474892 | validation: 0.5885834958472168]
	TIME [epoch: 7.92 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6366164970255771		[learning rate: 0.0035845]
	Learning Rate: 0.00358445
	LOSS [training: 0.6366164970255771 | validation: 0.5196449992661745]
	TIME [epoch: 7.94 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5916069204799977		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 0.5916069204799977 | validation: 0.5677552924062532]
	TIME [epoch: 7.92 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5605069100841464		[learning rate: 0.003556]
	Learning Rate: 0.003556
	LOSS [training: 0.5605069100841464 | validation: 0.4929718961369106]
	TIME [epoch: 7.92 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5858801443369295		[learning rate: 0.0035419]
	Learning Rate: 0.00354185
	LOSS [training: 0.5858801443369295 | validation: 0.4705180055841399]
	TIME [epoch: 7.91 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.1304834539329318		[learning rate: 0.0035278]
	Learning Rate: 0.00352777
	LOSS [training: 1.1304834539329318 | validation: 0.56069032543171]
	TIME [epoch: 7.93 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.582324586207801		[learning rate: 0.0035137]
	Learning Rate: 0.00351374
	LOSS [training: 0.582324586207801 | validation: 0.4522636197695875]
	TIME [epoch: 7.93 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.512928391406872		[learning rate: 0.0034998]
	Learning Rate: 0.00349976
	LOSS [training: 0.512928391406872 | validation: 0.4554741890057598]
	TIME [epoch: 7.92 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5309723704067656		[learning rate: 0.0034858]
	Learning Rate: 0.00348584
	LOSS [training: 0.5309723704067656 | validation: 0.5540010471896615]
	TIME [epoch: 7.92 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7816273949981465		[learning rate: 0.003472]
	Learning Rate: 0.00347198
	LOSS [training: 0.7816273949981465 | validation: 0.5932160561595176]
	TIME [epoch: 7.92 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6211285235232042		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.6211285235232042 | validation: 0.4899051081992526]
	TIME [epoch: 7.94 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5838235814124042		[learning rate: 0.0034444]
	Learning Rate: 0.00344441
	LOSS [training: 0.5838235814124042 | validation: 0.47512076162811195]
	TIME [epoch: 7.92 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5566482531009624		[learning rate: 0.0034307]
	Learning Rate: 0.00343071
	LOSS [training: 0.5566482531009624 | validation: 0.5521774502975579]
	TIME [epoch: 7.92 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5546817868275262		[learning rate: 0.0034171]
	Learning Rate: 0.00341707
	LOSS [training: 0.5546817868275262 | validation: 0.6887962405092001]
	TIME [epoch: 7.92 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5949230813059777		[learning rate: 0.0034035]
	Learning Rate: 0.00340348
	LOSS [training: 0.5949230813059777 | validation: 0.45264229720788124]
	TIME [epoch: 7.93 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5629055890642398		[learning rate: 0.0033899]
	Learning Rate: 0.00338994
	LOSS [training: 0.5629055890642398 | validation: 0.553895281097281]
	TIME [epoch: 7.92 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6222215611857721		[learning rate: 0.0033765]
	Learning Rate: 0.00337646
	LOSS [training: 0.6222215611857721 | validation: 0.6069010404599288]
	TIME [epoch: 7.92 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5263977221028412		[learning rate: 0.003363]
	Learning Rate: 0.00336303
	LOSS [training: 0.5263977221028412 | validation: 0.4265741673169428]
	TIME [epoch: 7.92 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4862329841128332		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 0.4862329841128332 | validation: 0.46467811731930303]
	TIME [epoch: 7.92 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4911580526391213		[learning rate: 0.0033363]
	Learning Rate: 0.00333633
	LOSS [training: 0.4911580526391213 | validation: 0.4360442445781204]
	TIME [epoch: 7.94 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5252491138174888		[learning rate: 0.0033231]
	Learning Rate: 0.00332306
	LOSS [training: 0.5252491138174888 | validation: 0.4565531083449431]
	TIME [epoch: 7.92 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5013001533323824		[learning rate: 0.0033098]
	Learning Rate: 0.00330985
	LOSS [training: 0.5013001533323824 | validation: 0.3888838488250742]
	TIME [epoch: 7.92 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4755094939882725		[learning rate: 0.0032967]
	Learning Rate: 0.00329668
	LOSS [training: 0.4755094939882725 | validation: 0.5937206078714625]
	TIME [epoch: 7.91 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5249316724299927		[learning rate: 0.0032836]
	Learning Rate: 0.00328357
	LOSS [training: 0.5249316724299927 | validation: 0.4193063720611823]
	TIME [epoch: 7.93 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4679205517463717		[learning rate: 0.0032705]
	Learning Rate: 0.00327051
	LOSS [training: 0.4679205517463717 | validation: 0.4172040925963321]
	TIME [epoch: 7.92 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5056130968128395		[learning rate: 0.0032575]
	Learning Rate: 0.0032575
	LOSS [training: 0.5056130968128395 | validation: 0.39679774654313155]
	TIME [epoch: 7.92 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.43532314833660324		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 0.43532314833660324 | validation: 0.45759446084788175]
	TIME [epoch: 7.92 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5399535254521021		[learning rate: 0.0032316]
	Learning Rate: 0.00323164
	LOSS [training: 0.5399535254521021 | validation: 0.5538844203194795]
	TIME [epoch: 7.92 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.46307476209701703		[learning rate: 0.0032188]
	Learning Rate: 0.00321879
	LOSS [training: 0.46307476209701703 | validation: 0.4838133190134751]
	TIME [epoch: 7.92 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.459831878459885		[learning rate: 0.003206]
	Learning Rate: 0.00320599
	LOSS [training: 0.459831878459885 | validation: 0.4131135118014077]
	TIME [epoch: 7.92 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.451482421706723		[learning rate: 0.0031932]
	Learning Rate: 0.00319323
	LOSS [training: 0.451482421706723 | validation: 0.4628934552322351]
	TIME [epoch: 7.91 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4926672263730469		[learning rate: 0.0031805]
	Learning Rate: 0.00318053
	LOSS [training: 0.4926672263730469 | validation: 0.4121805561660949]
	TIME [epoch: 7.91 sec]
	Saving model to: out/model_training/model_facs_dec1b_2dpca_v7_20240710_201912/states/model_facs_dec1b_2dpca_v7_332.pth
Halted early. No improvement in validation loss for 200 epochs.
Finished training in 2692.766 seconds.
