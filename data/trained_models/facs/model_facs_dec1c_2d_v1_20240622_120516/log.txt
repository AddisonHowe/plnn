Args:
Namespace(name='model_facs_dec1c_2d_v1', outdir='out/model_training/model_facs_dec1c_2d_v1', training_data='data/training_data/facs/dec1_varnorm_fitonsubset/transition1_subset_epi_tr_ce_an_pc12/training', validation_data='data/training_data/facs/dec1_varnorm_fitonsubset/transition1_subset_epi_tr_ce_an_pc12/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=5, patience=200, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, dt=0.001, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 2581947692

Training model...

Saving initial model state to: out/model_training/model_facs_dec1c_2d_v1_20240622_120516/states/model_facs_dec1c_2d_v1_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6525565054304593		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6525565054304593 | validation: 0.5424478793316979]
	TIME [epoch: 64.8 sec]
	Saving model to: out/model_training/model_facs_dec1c_2d_v1_20240622_120516/states/model_facs_dec1c_2d_v1_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6008630107477332		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6008630107477332 | validation: 0.48374223885682976]
	TIME [epoch: 36 sec]
	Saving model to: out/model_training/model_facs_dec1c_2d_v1_20240622_120516/states/model_facs_dec1c_2d_v1_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5307429110722821		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5307429110722821 | validation: 0.5199578811550423]
	TIME [epoch: 36.1 sec]
EPOCH 4/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5232386252501794		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5232386252501794 | validation: 0.49674117749412466]
	TIME [epoch: 36 sec]
EPOCH 5/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5304445557834485		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5304445557834485 | validation: 0.469369091200877]
	TIME [epoch: 36.1 sec]
	Saving model to: out/model_training/model_facs_dec1c_2d_v1_20240622_120516/states/model_facs_dec1c_2d_v1_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4839854166636503		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4839854166636503 | validation: 0.4756159240426512]
	TIME [epoch: 36 sec]
EPOCH 7/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.522118406715757		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.522118406715757 | validation: 0.46543711384817854]
	TIME [epoch: 36.1 sec]
	Saving model to: out/model_training/model_facs_dec1c_2d_v1_20240622_120516/states/model_facs_dec1c_2d_v1_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5013602674703768		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5013602674703768 | validation: 0.5168556733401756]
	TIME [epoch: 36.1 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4838107561572562		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4838107561572562 | validation: 0.40686574899247685]
	TIME [epoch: 36.1 sec]
	Saving model to: out/model_training/model_facs_dec1c_2d_v1_20240622_120516/states/model_facs_dec1c_2d_v1_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4715383103385313		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4715383103385313 | validation: 0.410086625721651]
	TIME [epoch: 36.1 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.41292853704776106		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.41292853704776106 | validation: 0.38876298981701823]
	TIME [epoch: 36.1 sec]
	Saving model to: out/model_training/model_facs_dec1c_2d_v1_20240622_120516/states/model_facs_dec1c_2d_v1_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4545866662188635		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4545866662188635 | validation: 0.37010633246490665]
	TIME [epoch: 36.1 sec]
	Saving model to: out/model_training/model_facs_dec1c_2d_v1_20240622_120516/states/model_facs_dec1c_2d_v1_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3621945411545535		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3621945411545535 | validation: 0.32028461512332995]
	TIME [epoch: 36.1 sec]
	Saving model to: out/model_training/model_facs_dec1c_2d_v1_20240622_120516/states/model_facs_dec1c_2d_v1_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3249744677463358		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3249744677463358 | validation: 0.30108406545691807]
	TIME [epoch: 36.1 sec]
	Saving model to: out/model_training/model_facs_dec1c_2d_v1_20240622_120516/states/model_facs_dec1c_2d_v1_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3521395649908288		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3521395649908288 | validation: 0.28797049777243217]
	TIME [epoch: 36.1 sec]
	Saving model to: out/model_training/model_facs_dec1c_2d_v1_20240622_120516/states/model_facs_dec1c_2d_v1_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.29202083458860584		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.29202083458860584 | validation: 0.2774089067963198]
	TIME [epoch: 36.1 sec]
	Saving model to: out/model_training/model_facs_dec1c_2d_v1_20240622_120516/states/model_facs_dec1c_2d_v1_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2691086259906556		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2691086259906556 | validation: 0.25228770305085674]
	TIME [epoch: 36.1 sec]
	Saving model to: out/model_training/model_facs_dec1c_2d_v1_20240622_120516/states/model_facs_dec1c_2d_v1_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2759940584091046		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2759940584091046 | validation: 0.24452051807673053]
	TIME [epoch: 36.1 sec]
	Saving model to: out/model_training/model_facs_dec1c_2d_v1_20240622_120516/states/model_facs_dec1c_2d_v1_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.27385853864032783		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.27385853864032783 | validation: 0.2281466001033246]
	TIME [epoch: 36.1 sec]
	Saving model to: out/model_training/model_facs_dec1c_2d_v1_20240622_120516/states/model_facs_dec1c_2d_v1_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2696742255369881		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2696742255369881 | validation: 0.21970559420520092]
	TIME [epoch: 36 sec]
	Saving model to: out/model_training/model_facs_dec1c_2d_v1_20240622_120516/states/model_facs_dec1c_2d_v1_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23801260334891802		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23801260334891802 | validation: 0.222317837025573]
	TIME [epoch: 36.1 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2260017371764643		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2260017371764643 | validation: 0.23281144929523334]
	TIME [epoch: 36 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2331539117903595		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2331539117903595 | validation: 0.22143771544871904]
	TIME [epoch: 36.1 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2334289641329682		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2334289641329682 | validation: 0.20196756316215608]
	TIME [epoch: 36 sec]
	Saving model to: out/model_training/model_facs_dec1c_2d_v1_20240622_120516/states/model_facs_dec1c_2d_v1_24.pth
	Model improved!!!
EPOCH 25/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23323211787678805		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23323211787678805 | validation: 0.1984985316036611]
	TIME [epoch: 36.1 sec]
	Saving model to: out/model_training/model_facs_dec1c_2d_v1_20240622_120516/states/model_facs_dec1c_2d_v1_25.pth
	Model improved!!!
EPOCH 26/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22618149604300924		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22618149604300924 | validation: 0.2007885419248164]
	TIME [epoch: 36.1 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2520576621457669		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2520576621457669 | validation: 0.1968414537295126]
	TIME [epoch: 36.1 sec]
	Saving model to: out/model_training/model_facs_dec1c_2d_v1_20240622_120516/states/model_facs_dec1c_2d_v1_27.pth
	Model improved!!!
EPOCH 28/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.210175180385446		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.210175180385446 | validation: 0.2098864484142915]
	TIME [epoch: 36.1 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2178529707950963		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2178529707950963 | validation: 0.18505214802285108]
	TIME [epoch: 36.1 sec]
	Saving model to: out/model_training/model_facs_dec1c_2d_v1_20240622_120516/states/model_facs_dec1c_2d_v1_29.pth
	Model improved!!!
EPOCH 30/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.20612933540929312		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20612933540929312 | validation: 0.1923695259010553]
	TIME [epoch: 36.1 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.21640828416453844		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.21640828416453844 | validation: 0.20158153253560268]
	TIME [epoch: 36.1 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.21648339524979315		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.21648339524979315 | validation: 0.18373246475416805]
	TIME [epoch: 36 sec]
	Saving model to: out/model_training/model_facs_dec1c_2d_v1_20240622_120516/states/model_facs_dec1c_2d_v1_32.pth
	Model improved!!!
EPOCH 33/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2067044974794211		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2067044974794211 | validation: 0.20081829833723647]
	TIME [epoch: 36.1 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22471562763524475		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22471562763524475 | validation: 0.2330932175823409]
	TIME [epoch: 36 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.21730644396004933		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.21730644396004933 | validation: 0.18338613696765926]
	TIME [epoch: 36 sec]
	Saving model to: out/model_training/model_facs_dec1c_2d_v1_20240622_120516/states/model_facs_dec1c_2d_v1_35.pth
	Model improved!!!
EPOCH 36/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.20015903111013508		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20015903111013508 | validation: 0.18480527984494924]
	TIME [epoch: 36.1 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.19290523190684328		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.19290523190684328 | validation: 0.19377980718378868]
	TIME [epoch: 36.1 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.20884781666481		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20884781666481 | validation: 0.184267112022551]
	TIME [epoch: 36.1 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.20007764927834362		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20007764927834362 | validation: 0.1929275741019802]
	TIME [epoch: 36.1 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.20954943568676196		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20954943568676196 | validation: 0.20718842954493688]
	TIME [epoch: 36 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2229963071569678		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2229963071569678 | validation: 0.18777959085820245]
	TIME [epoch: 36.1 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2011529071942942		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2011529071942942 | validation: 0.1866802511613314]
	TIME [epoch: 36.1 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.20173696420683576		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20173696420683576 | validation: 0.1908839707742293]
	TIME [epoch: 36.1 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2042109459674455		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2042109459674455 | validation: 0.18656110420757976]
	TIME [epoch: 36.1 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1910117880443163		[learning rate: 0.0099823]
	Learning Rate: 0.0099823
	LOSS [training: 0.1910117880443163 | validation: 0.18455870093801813]
	TIME [epoch: 36 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.19517435849068349		[learning rate: 0.0099426]
	Learning Rate: 0.0099426
	LOSS [training: 0.19517435849068349 | validation: 0.18119118099441578]
	TIME [epoch: 36 sec]
	Saving model to: out/model_training/model_facs_dec1c_2d_v1_20240622_120516/states/model_facs_dec1c_2d_v1_46.pth
	Model improved!!!
EPOCH 47/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.19394872928679938		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 0.19394872928679938 | validation: 0.1974629688097201]
	TIME [epoch: 36.1 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1996265920360075		[learning rate: 0.0098637]
	Learning Rate: 0.00986367
	LOSS [training: 0.1996265920360075 | validation: 0.1883767692600406]
	TIME [epoch: 36.1 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2018850687394379		[learning rate: 0.0098244]
	Learning Rate: 0.00982444
	LOSS [training: 0.2018850687394379 | validation: 0.20021120587506766]
	TIME [epoch: 36.1 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1959494491702369		[learning rate: 0.0097854]
	Learning Rate: 0.00978536
	LOSS [training: 0.1959494491702369 | validation: 0.1829101527692923]
	TIME [epoch: 36 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.20959088065890916		[learning rate: 0.0097464]
	Learning Rate: 0.00974644
	LOSS [training: 0.20959088065890916 | validation: 0.17625724960557815]
	TIME [epoch: 36.1 sec]
	Saving model to: out/model_training/model_facs_dec1c_2d_v1_20240622_120516/states/model_facs_dec1c_2d_v1_51.pth
	Model improved!!!
EPOCH 52/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1908785908473679		[learning rate: 0.0097077]
	Learning Rate: 0.00970768
	LOSS [training: 0.1908785908473679 | validation: 0.17957083797887305]
	TIME [epoch: 36 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.19251545579163698		[learning rate: 0.0096691]
	Learning Rate: 0.00966907
	LOSS [training: 0.19251545579163698 | validation: 0.18473203911010866]
	TIME [epoch: 36 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1938455248204964		[learning rate: 0.0096306]
	Learning Rate: 0.00963061
	LOSS [training: 0.1938455248204964 | validation: 0.17978107519269632]
	TIME [epoch: 36 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1919261341281565		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 0.1919261341281565 | validation: 0.18498145149744416]
	TIME [epoch: 36 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.19594392931616098		[learning rate: 0.0095542]
	Learning Rate: 0.00955415
	LOSS [training: 0.19594392931616098 | validation: 0.1802431922260344]
	TIME [epoch: 36 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1962910116594293		[learning rate: 0.0095162]
	Learning Rate: 0.00951616
	LOSS [training: 0.1962910116594293 | validation: 0.18902193364203249]
	TIME [epoch: 36 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.20095043731688728		[learning rate: 0.0094783]
	Learning Rate: 0.00947831
	LOSS [training: 0.20095043731688728 | validation: 0.19376343329324217]
	TIME [epoch: 36.1 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.19987257486173338		[learning rate: 0.0094406]
	Learning Rate: 0.00944061
	LOSS [training: 0.19987257486173338 | validation: 0.18608171781071478]
	TIME [epoch: 36 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2013563086980676		[learning rate: 0.0094031]
	Learning Rate: 0.00940306
	LOSS [training: 0.2013563086980676 | validation: 0.18870625004812122]
	TIME [epoch: 36.1 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1931247280841967		[learning rate: 0.0093657]
	Learning Rate: 0.00936566
	LOSS [training: 0.1931247280841967 | validation: 0.18406747928746148]
	TIME [epoch: 36 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.18912335843098552		[learning rate: 0.0093284]
	Learning Rate: 0.00932841
	LOSS [training: 0.18912335843098552 | validation: 0.19322411238255544]
	TIME [epoch: 36 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.19339616660897196		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 0.19339616660897196 | validation: 0.17109356866854936]
	TIME [epoch: 36 sec]
	Saving model to: out/model_training/model_facs_dec1c_2d_v1_20240622_120516/states/model_facs_dec1c_2d_v1_63.pth
	Model improved!!!
EPOCH 64/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.19142193052574713		[learning rate: 0.0092544]
	Learning Rate: 0.00925435
	LOSS [training: 0.19142193052574713 | validation: 0.17314338433165996]
	TIME [epoch: 36 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.19331385223160882		[learning rate: 0.0092175]
	Learning Rate: 0.00921755
	LOSS [training: 0.19331385223160882 | validation: 0.1769904565818295]
	TIME [epoch: 36 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.19012088016074033		[learning rate: 0.0091809]
	Learning Rate: 0.00918089
	LOSS [training: 0.19012088016074033 | validation: 0.1714414360074116]
	TIME [epoch: 36 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.18254762436265443		[learning rate: 0.0091444]
	Learning Rate: 0.00914437
	LOSS [training: 0.18254762436265443 | validation: 0.17376970866407743]
	TIME [epoch: 36.1 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.187105820997159		[learning rate: 0.009108]
	Learning Rate: 0.009108
	LOSS [training: 0.187105820997159 | validation: 0.16479207725660766]
	TIME [epoch: 36.1 sec]
	Saving model to: out/model_training/model_facs_dec1c_2d_v1_20240622_120516/states/model_facs_dec1c_2d_v1_68.pth
	Model improved!!!
EPOCH 69/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.18741287384700447		[learning rate: 0.0090718]
	Learning Rate: 0.00907178
	LOSS [training: 0.18741287384700447 | validation: 0.1813246022175067]
	TIME [epoch: 36.1 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1874968132279729		[learning rate: 0.0090357]
	Learning Rate: 0.00903569
	LOSS [training: 0.1874968132279729 | validation: 0.17856016475222475]
	TIME [epoch: 36 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1896994368752775		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 0.1896994368752775 | validation: 0.1749944222194176]
	TIME [epoch: 36.1 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1767483760699762		[learning rate: 0.008964]
	Learning Rate: 0.00896396
	LOSS [training: 0.1767483760699762 | validation: 0.1846055573333544]
	TIME [epoch: 36.1 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1879319985433816		[learning rate: 0.0089283]
	Learning Rate: 0.00892831
	LOSS [training: 0.1879319985433816 | validation: 0.18097584568769923]
	TIME [epoch: 36 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.18804259322740405		[learning rate: 0.0088928]
	Learning Rate: 0.0088928
	LOSS [training: 0.18804259322740405 | validation: 0.1722913117432059]
	TIME [epoch: 36 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.18251422800138636		[learning rate: 0.0088574]
	Learning Rate: 0.00885743
	LOSS [training: 0.18251422800138636 | validation: 0.1738957002335272]
	TIME [epoch: 36 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.18439916476572474		[learning rate: 0.0088222]
	Learning Rate: 0.0088222
	LOSS [training: 0.18439916476572474 | validation: 0.1701608794330835]
	TIME [epoch: 36 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17392847861445937		[learning rate: 0.0087871]
	Learning Rate: 0.00878711
	LOSS [training: 0.17392847861445937 | validation: 0.1842869269744251]
	TIME [epoch: 36.1 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1851400370058628		[learning rate: 0.0087522]
	Learning Rate: 0.00875216
	LOSS [training: 0.1851400370058628 | validation: 0.17281628518148334]
	TIME [epoch: 36.1 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17990011335014922		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 0.17990011335014922 | validation: 0.18459012317211226]
	TIME [epoch: 36 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1887031979767304		[learning rate: 0.0086827]
	Learning Rate: 0.00868268
	LOSS [training: 0.1887031979767304 | validation: 0.17800279930602675]
	TIME [epoch: 36 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.19252429035140026		[learning rate: 0.0086481]
	Learning Rate: 0.00864815
	LOSS [training: 0.19252429035140026 | validation: 0.17679335700062385]
	TIME [epoch: 36 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1821578780163268		[learning rate: 0.0086138]
	Learning Rate: 0.00861375
	LOSS [training: 0.1821578780163268 | validation: 0.16265563559559254]
	TIME [epoch: 36 sec]
	Saving model to: out/model_training/model_facs_dec1c_2d_v1_20240622_120516/states/model_facs_dec1c_2d_v1_82.pth
	Model improved!!!
EPOCH 83/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17411528899670975		[learning rate: 0.0085795]
	Learning Rate: 0.00857949
	LOSS [training: 0.17411528899670975 | validation: 0.1769346076608574]
	TIME [epoch: 36 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1795834534452306		[learning rate: 0.0085454]
	Learning Rate: 0.00854537
	LOSS [training: 0.1795834534452306 | validation: 0.17828062546325024]
	TIME [epoch: 36.1 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.19220516630006498		[learning rate: 0.0085114]
	Learning Rate: 0.00851138
	LOSS [training: 0.19220516630006498 | validation: 0.17135107917311712]
	TIME [epoch: 36 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.20023308356159816		[learning rate: 0.0084775]
	Learning Rate: 0.00847753
	LOSS [training: 0.20023308356159816 | validation: 0.18711419560698064]
	TIME [epoch: 36.1 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2016398093518687		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 0.2016398093518687 | validation: 0.17065358714602524]
	TIME [epoch: 36.1 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.18507017546544965		[learning rate: 0.0084102]
	Learning Rate: 0.00841023
	LOSS [training: 0.18507017546544965 | validation: 0.16717275315818458]
	TIME [epoch: 36.1 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.18920660928060182		[learning rate: 0.0083768]
	Learning Rate: 0.00837678
	LOSS [training: 0.18920660928060182 | validation: 0.16407230037709206]
	TIME [epoch: 36.1 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.18319038953881986		[learning rate: 0.0083435]
	Learning Rate: 0.00834346
	LOSS [training: 0.18319038953881986 | validation: 0.17701872632737117]
	TIME [epoch: 36.1 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.18351735565599256		[learning rate: 0.0083103]
	Learning Rate: 0.00831027
	LOSS [training: 0.18351735565599256 | validation: 0.18640833176832708]
	TIME [epoch: 36.1 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.19389234100734767		[learning rate: 0.0082772]
	Learning Rate: 0.00827722
	LOSS [training: 0.19389234100734767 | validation: 0.17219435209623474]
	TIME [epoch: 36.1 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.18569728166541064		[learning rate: 0.0082443]
	Learning Rate: 0.0082443
	LOSS [training: 0.18569728166541064 | validation: 0.1798566699969292]
	TIME [epoch: 36 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.19441828365526587		[learning rate: 0.0082115]
	Learning Rate: 0.00821151
	LOSS [training: 0.19441828365526587 | validation: 0.16833432235705986]
	TIME [epoch: 36.1 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1794691578181182		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 0.1794691578181182 | validation: 0.16952571865164065]
	TIME [epoch: 36.1 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.18248035618181166		[learning rate: 0.0081463]
	Learning Rate: 0.00814632
	LOSS [training: 0.18248035618181166 | validation: 0.17933017743410193]
	TIME [epoch: 36.1 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1787899645645157		[learning rate: 0.0081139]
	Learning Rate: 0.00811392
	LOSS [training: 0.1787899645645157 | validation: 0.16646269418077292]
	TIME [epoch: 36 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.19882023237061525		[learning rate: 0.0080816]
	Learning Rate: 0.00808165
	LOSS [training: 0.19882023237061525 | validation: 0.1710653607580062]
	TIME [epoch: 36 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.18322452608324724		[learning rate: 0.0080495]
	Learning Rate: 0.00804951
	LOSS [training: 0.18322452608324724 | validation: 0.16377065188243317]
	TIME [epoch: 36 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.18598219048109463		[learning rate: 0.0080175]
	Learning Rate: 0.00801749
	LOSS [training: 0.18598219048109463 | validation: 0.16978370933010903]
	TIME [epoch: 36 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.18401771027469002		[learning rate: 0.0079856]
	Learning Rate: 0.0079856
	LOSS [training: 0.18401771027469002 | validation: 0.18371644913234703]
	TIME [epoch: 36.1 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.18832027255668868		[learning rate: 0.0079538]
	Learning Rate: 0.00795384
	LOSS [training: 0.18832027255668868 | validation: 0.16587715322146696]
	TIME [epoch: 36.1 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.20172205287801515		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 0.20172205287801515 | validation: 0.17224647772758706]
	TIME [epoch: 36.1 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.18546553540146332		[learning rate: 0.0078907]
	Learning Rate: 0.0078907
	LOSS [training: 0.18546553540146332 | validation: 0.1709158213023693]
	TIME [epoch: 36.1 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1873193855350961		[learning rate: 0.0078593]
	Learning Rate: 0.00785931
	LOSS [training: 0.1873193855350961 | validation: 0.17154771616994324]
	TIME [epoch: 36.1 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1950876200007265		[learning rate: 0.0078281]
	Learning Rate: 0.00782805
	LOSS [training: 0.1950876200007265 | validation: 0.15348635445260522]
	TIME [epoch: 36.1 sec]
	Saving model to: out/model_training/model_facs_dec1c_2d_v1_20240622_120516/states/model_facs_dec1c_2d_v1_106.pth
	Model improved!!!
EPOCH 107/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.175465420718233		[learning rate: 0.0077969]
	Learning Rate: 0.00779692
	LOSS [training: 0.175465420718233 | validation: 0.1812784598699308]
	TIME [epoch: 36.1 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17181839649072092		[learning rate: 0.0077659]
	Learning Rate: 0.00776591
	LOSS [training: 0.17181839649072092 | validation: 0.17867117882008227]
	TIME [epoch: 36.1 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1818850853818337		[learning rate: 0.007735]
	Learning Rate: 0.00773502
	LOSS [training: 0.1818850853818337 | validation: 0.18026909380027875]
	TIME [epoch: 36.1 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1970197615804336		[learning rate: 0.0077043]
	Learning Rate: 0.00770426
	LOSS [training: 0.1970197615804336 | validation: 0.16160871546827763]
	TIME [epoch: 36.1 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.18196725855725157		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 0.18196725855725157 | validation: 0.1576935439021882]
	TIME [epoch: 36.1 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.19176696022396908		[learning rate: 0.0076431]
	Learning Rate: 0.00764309
	LOSS [training: 0.19176696022396908 | validation: 0.1681299879460339]
	TIME [epoch: 36.1 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.18390212705190193		[learning rate: 0.0076127]
	Learning Rate: 0.00761269
	LOSS [training: 0.18390212705190193 | validation: 0.1885837683089502]
	TIME [epoch: 36.1 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.18961632639183593		[learning rate: 0.0075824]
	Learning Rate: 0.00758242
	LOSS [training: 0.18961632639183593 | validation: 0.1655055180218603]
	TIME [epoch: 36.1 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.18712558305915442		[learning rate: 0.0075523]
	Learning Rate: 0.00755226
	LOSS [training: 0.18712558305915442 | validation: 0.17361513038394866]
	TIME [epoch: 36.1 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.19139598729401708		[learning rate: 0.0075222]
	Learning Rate: 0.00752222
	LOSS [training: 0.19139598729401708 | validation: 0.17355143234801418]
	TIME [epoch: 36.1 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.19109642615051706		[learning rate: 0.0074923]
	Learning Rate: 0.0074923
	LOSS [training: 0.19109642615051706 | validation: 0.17251458911956397]
	TIME [epoch: 36.1 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17281994271861623		[learning rate: 0.0074625]
	Learning Rate: 0.0074625
	LOSS [training: 0.17281994271861623 | validation: 0.1654703837634828]
	TIME [epoch: 36.1 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.182868781810203		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 0.182868781810203 | validation: 0.17256758082443469]
	TIME [epoch: 36.1 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17636121211675915		[learning rate: 0.0074033]
	Learning Rate: 0.00740326
	LOSS [training: 0.17636121211675915 | validation: 0.16408433781976223]
	TIME [epoch: 36 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17566440675297343		[learning rate: 0.0073738]
	Learning Rate: 0.00737382
	LOSS [training: 0.17566440675297343 | validation: 0.17767648390741647]
	TIME [epoch: 36.1 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1875681538988233		[learning rate: 0.0073445]
	Learning Rate: 0.00734449
	LOSS [training: 0.1875681538988233 | validation: 0.173325754154055]
	TIME [epoch: 36 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.18394559846818553		[learning rate: 0.0073153]
	Learning Rate: 0.00731528
	LOSS [training: 0.18394559846818553 | validation: 0.16580654098763203]
	TIME [epoch: 36 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.18224346483037848		[learning rate: 0.0072862]
	Learning Rate: 0.00728618
	LOSS [training: 0.18224346483037848 | validation: 0.17419184952367067]
	TIME [epoch: 36 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17705700511708333		[learning rate: 0.0072572]
	Learning Rate: 0.0072572
	LOSS [training: 0.17705700511708333 | validation: 0.16404039623358163]
	TIME [epoch: 36 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17245980696669372		[learning rate: 0.0072283]
	Learning Rate: 0.00722834
	LOSS [training: 0.17245980696669372 | validation: 0.17682662686530834]
	TIME [epoch: 36.1 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1875808423285148		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 0.1875808423285148 | validation: 0.17471932226811893]
	TIME [epoch: 36.1 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.19128346631664617		[learning rate: 0.007171]
	Learning Rate: 0.00717095
	LOSS [training: 0.19128346631664617 | validation: 0.1833119588759267]
	TIME [epoch: 36.1 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.18281771373165512		[learning rate: 0.0071424]
	Learning Rate: 0.00714243
	LOSS [training: 0.18281771373165512 | validation: 0.15865757349744064]
	TIME [epoch: 36.1 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.18075688922728633		[learning rate: 0.007114]
	Learning Rate: 0.00711403
	LOSS [training: 0.18075688922728633 | validation: 0.1612687237516109]
	TIME [epoch: 36.1 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17885277759051985		[learning rate: 0.0070857]
	Learning Rate: 0.00708573
	LOSS [training: 0.17885277759051985 | validation: 0.16300599585107114]
	TIME [epoch: 36.1 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.18404983258897584		[learning rate: 0.0070575]
	Learning Rate: 0.00705755
	LOSS [training: 0.18404983258897584 | validation: 0.16487111796840961]
	TIME [epoch: 36.1 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1705090512732731		[learning rate: 0.0070295]
	Learning Rate: 0.00702948
	LOSS [training: 0.1705090512732731 | validation: 0.1658071573789046]
	TIME [epoch: 36 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1725320584282509		[learning rate: 0.0070015]
	Learning Rate: 0.00700152
	LOSS [training: 0.1725320584282509 | validation: 0.1632011411040088]
	TIME [epoch: 36 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1872114098896478		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 0.1872114098896478 | validation: 0.16387286442779164]
	TIME [epoch: 36.1 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.18373041760741454		[learning rate: 0.0069459]
	Learning Rate: 0.00694594
	LOSS [training: 0.18373041760741454 | validation: 0.17310444112086196]
	TIME [epoch: 36.1 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1667930514987472		[learning rate: 0.0069183]
	Learning Rate: 0.00691831
	LOSS [training: 0.1667930514987472 | validation: 0.1715019821621802]
	TIME [epoch: 36.1 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.18104999446078873		[learning rate: 0.0068908]
	Learning Rate: 0.00689079
	LOSS [training: 0.18104999446078873 | validation: 0.16671715344481763]
	TIME [epoch: 36.1 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.19350283378250752		[learning rate: 0.0068634]
	Learning Rate: 0.00686339
	LOSS [training: 0.19350283378250752 | validation: 0.16366570573880948]
	TIME [epoch: 36 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17317744399409143		[learning rate: 0.0068361]
	Learning Rate: 0.00683609
	LOSS [training: 0.17317744399409143 | validation: 0.16933942058370752]
	TIME [epoch: 36.1 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17341634941087275		[learning rate: 0.0068089]
	Learning Rate: 0.0068089
	LOSS [training: 0.17341634941087275 | validation: 0.17729357546879895]
	TIME [epoch: 36 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17481083244824333		[learning rate: 0.0067818]
	Learning Rate: 0.00678182
	LOSS [training: 0.17481083244824333 | validation: 0.16563693844572946]
	TIME [epoch: 36 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.18072370184912487		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 0.18072370184912487 | validation: 0.1664912004644855]
	TIME [epoch: 36 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.19449092871442467		[learning rate: 0.006728]
	Learning Rate: 0.00672798
	LOSS [training: 0.19449092871442467 | validation: 0.17258254420466348]
	TIME [epoch: 36 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.18034938682378224		[learning rate: 0.0067012]
	Learning Rate: 0.00670122
	LOSS [training: 0.18034938682378224 | validation: 0.16580630323176299]
	TIME [epoch: 36 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17737185314852247		[learning rate: 0.0066746]
	Learning Rate: 0.00667457
	LOSS [training: 0.17737185314852247 | validation: 0.16849701148555973]
	TIME [epoch: 36 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.19350244655167467		[learning rate: 0.006648]
	Learning Rate: 0.00664802
	LOSS [training: 0.19350244655167467 | validation: 0.15959930017026644]
	TIME [epoch: 36 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1854930594697752		[learning rate: 0.0066216]
	Learning Rate: 0.00662158
	LOSS [training: 0.1854930594697752 | validation: 0.18596672796506464]
	TIME [epoch: 36 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1873533557350087		[learning rate: 0.0065952]
	Learning Rate: 0.00659524
	LOSS [training: 0.1873533557350087 | validation: 0.16770508235656562]
	TIME [epoch: 36 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.18202506447660763		[learning rate: 0.006569]
	Learning Rate: 0.00656901
	LOSS [training: 0.18202506447660763 | validation: 0.16516348109862175]
	TIME [epoch: 36.1 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1751361201461263		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 0.1751361201461263 | validation: 0.1708554224828783]
	TIME [epoch: 36 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.18103359010377687		[learning rate: 0.0065169]
	Learning Rate: 0.00651686
	LOSS [training: 0.18103359010377687 | validation: 0.16480336212438124]
	TIME [epoch: 36.1 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.18049565965359898		[learning rate: 0.0064909]
	Learning Rate: 0.00649094
	LOSS [training: 0.18049565965359898 | validation: 0.17622388284156312]
	TIME [epoch: 36.1 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1838227093779788		[learning rate: 0.0064651]
	Learning Rate: 0.00646512
	LOSS [training: 0.1838227093779788 | validation: 0.1651832804963908]
	TIME [epoch: 36.1 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17462701381283907		[learning rate: 0.0064394]
	Learning Rate: 0.00643941
	LOSS [training: 0.17462701381283907 | validation: 0.15582998703548173]
	TIME [epoch: 36.1 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1757603748338586		[learning rate: 0.0064138]
	Learning Rate: 0.0064138
	LOSS [training: 0.1757603748338586 | validation: 0.16729556768405476]
	TIME [epoch: 36.1 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.19642316320785225		[learning rate: 0.0063883]
	Learning Rate: 0.00638829
	LOSS [training: 0.19642316320785225 | validation: 0.15907909950368138]
	TIME [epoch: 36 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.18113637170859798		[learning rate: 0.0063629]
	Learning Rate: 0.00636288
	LOSS [training: 0.18113637170859798 | validation: 0.16787695731077887]
	TIME [epoch: 36.1 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.19007984298940753		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 0.19007984298940753 | validation: 0.1592242220816971]
	TIME [epoch: 36 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1712491133349775		[learning rate: 0.0063124]
	Learning Rate: 0.00631237
	LOSS [training: 0.1712491133349775 | validation: 0.1627021985644879]
	TIME [epoch: 36 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.18478398284397748		[learning rate: 0.0062873]
	Learning Rate: 0.00628726
	LOSS [training: 0.18478398284397748 | validation: 0.1608224970712603]
	TIME [epoch: 36.1 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.18690321454367645		[learning rate: 0.0062623]
	Learning Rate: 0.00626226
	LOSS [training: 0.18690321454367645 | validation: 0.15868272442626238]
	TIME [epoch: 36.1 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.18571860476245908		[learning rate: 0.0062373]
	Learning Rate: 0.00623735
	LOSS [training: 0.18571860476245908 | validation: 0.15844750063926732]
	TIME [epoch: 36.1 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17861966462433282		[learning rate: 0.0062125]
	Learning Rate: 0.00621254
	LOSS [training: 0.17861966462433282 | validation: 0.16041374376053627]
	TIME [epoch: 36.1 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.18708208690348999		[learning rate: 0.0061878]
	Learning Rate: 0.00618783
	LOSS [training: 0.18708208690348999 | validation: 0.1702857375513731]
	TIME [epoch: 36.1 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1852009975405216		[learning rate: 0.0061632]
	Learning Rate: 0.00616322
	LOSS [training: 0.1852009975405216 | validation: 0.16192386084862959]
	TIME [epoch: 36.1 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1781010185231086		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 0.1781010185231086 | validation: 0.16043867033893938]
	TIME [epoch: 36.1 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1830501868582085		[learning rate: 0.0061143]
	Learning Rate: 0.00611429
	LOSS [training: 0.1830501868582085 | validation: 0.1535605586307332]
	TIME [epoch: 36.1 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.18464971831917165		[learning rate: 0.00609]
	Learning Rate: 0.00608997
	LOSS [training: 0.18464971831917165 | validation: 0.1596724594628728]
	TIME [epoch: 36 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1732749518445051		[learning rate: 0.0060658]
	Learning Rate: 0.00606575
	LOSS [training: 0.1732749518445051 | validation: 0.16629383089138222]
	TIME [epoch: 36.1 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16107776718436811		[learning rate: 0.0060416]
	Learning Rate: 0.00604163
	LOSS [training: 0.16107776718436811 | validation: 0.1642107439234343]
	TIME [epoch: 36.1 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.18418022598080425		[learning rate: 0.0060176]
	Learning Rate: 0.0060176
	LOSS [training: 0.18418022598080425 | validation: 0.16378303641778497]
	TIME [epoch: 36.1 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17349559676608506		[learning rate: 0.0059937]
	Learning Rate: 0.00599366
	LOSS [training: 0.17349559676608506 | validation: 0.16623453918765266]
	TIME [epoch: 36 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.18005407702910192		[learning rate: 0.0059698]
	Learning Rate: 0.00596982
	LOSS [training: 0.18005407702910192 | validation: 0.15962515792105797]
	TIME [epoch: 36.1 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.18309471638883723		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 0.18309471638883723 | validation: 0.16200821467474066]
	TIME [epoch: 36.1 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17228981558084194		[learning rate: 0.0059224]
	Learning Rate: 0.00592243
	LOSS [training: 0.17228981558084194 | validation: 0.15681214223833517]
	TIME [epoch: 36.1 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1716461311930295		[learning rate: 0.0058989]
	Learning Rate: 0.00589888
	LOSS [training: 0.1716461311930295 | validation: 0.16118339238878918]
	TIME [epoch: 36 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.19096556412612017		[learning rate: 0.0058754]
	Learning Rate: 0.00587541
	LOSS [training: 0.19096556412612017 | validation: 0.17297576568387835]
	TIME [epoch: 36.1 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1894009241394207		[learning rate: 0.005852]
	Learning Rate: 0.00585205
	LOSS [training: 0.1894009241394207 | validation: 0.1641630498570092]
	TIME [epoch: 36.1 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.18257022114891647		[learning rate: 0.0058288]
	Learning Rate: 0.00582877
	LOSS [training: 0.18257022114891647 | validation: 0.16459655229392545]
	TIME [epoch: 36 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17570437317560864		[learning rate: 0.0058056]
	Learning Rate: 0.00580559
	LOSS [training: 0.17570437317560864 | validation: 0.1647391354168986]
	TIME [epoch: 36.1 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16722317053966235		[learning rate: 0.0057825]
	Learning Rate: 0.0057825
	LOSS [training: 0.16722317053966235 | validation: 0.16970297175264987]
	TIME [epoch: 36 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17635932850529548		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 0.17635932850529548 | validation: 0.17085909548114175]
	TIME [epoch: 36.1 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1810939579201006		[learning rate: 0.0057366]
	Learning Rate: 0.00573659
	LOSS [training: 0.1810939579201006 | validation: 0.1636984410625039]
	TIME [epoch: 36 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1943232813339941		[learning rate: 0.0057138]
	Learning Rate: 0.00571377
	LOSS [training: 0.1943232813339941 | validation: 0.1583028688498705]
	TIME [epoch: 36 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.18523138297808397		[learning rate: 0.005691]
	Learning Rate: 0.00569105
	LOSS [training: 0.18523138297808397 | validation: 0.15550907839693068]
	TIME [epoch: 36.1 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1801234218910483		[learning rate: 0.0056684]
	Learning Rate: 0.00566841
	LOSS [training: 0.1801234218910483 | validation: 0.16594590661624953]
	TIME [epoch: 36.1 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17451394540829807		[learning rate: 0.0056459]
	Learning Rate: 0.00564587
	LOSS [training: 0.17451394540829807 | validation: 0.1526854120633121]
	TIME [epoch: 36 sec]
	Saving model to: out/model_training/model_facs_dec1c_2d_v1_20240622_120516/states/model_facs_dec1c_2d_v1_188.pth
	Model improved!!!
EPOCH 189/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17050867597363834		[learning rate: 0.0056234]
	Learning Rate: 0.00562341
	LOSS [training: 0.17050867597363834 | validation: 0.16639920121564225]
	TIME [epoch: 36.1 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.18291657543180131		[learning rate: 0.005601]
	Learning Rate: 0.00560105
	LOSS [training: 0.18291657543180131 | validation: 0.15705270052094]
	TIME [epoch: 36.1 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1714037888943543		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 0.1714037888943543 | validation: 0.1632543943704539]
	TIME [epoch: 36 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17236880863888893		[learning rate: 0.0055566]
	Learning Rate: 0.00555658
	LOSS [training: 0.17236880863888893 | validation: 0.15987372776159742]
	TIME [epoch: 36.1 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.18141926638494757		[learning rate: 0.0055345]
	Learning Rate: 0.00553448
	LOSS [training: 0.18141926638494757 | validation: 0.16331029181380502]
	TIME [epoch: 36.1 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.168711339710657		[learning rate: 0.0055125]
	Learning Rate: 0.00551247
	LOSS [training: 0.168711339710657 | validation: 0.16509610149989634]
	TIME [epoch: 36 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1934584126671387		[learning rate: 0.0054905]
	Learning Rate: 0.00549054
	LOSS [training: 0.1934584126671387 | validation: 0.16413791286991114]
	TIME [epoch: 36.1 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.18935448191279652		[learning rate: 0.0054687]
	Learning Rate: 0.00546871
	LOSS [training: 0.18935448191279652 | validation: 0.14916084883829422]
	TIME [epoch: 36 sec]
	Saving model to: out/model_training/model_facs_dec1c_2d_v1_20240622_120516/states/model_facs_dec1c_2d_v1_196.pth
	Model improved!!!
EPOCH 197/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.19548911957413978		[learning rate: 0.005447]
	Learning Rate: 0.00544696
	LOSS [training: 0.19548911957413978 | validation: 0.1649208525209401]
	TIME [epoch: 36.1 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1799147370568236		[learning rate: 0.0054253]
	Learning Rate: 0.00542529
	LOSS [training: 0.1799147370568236 | validation: 0.16739754173729998]
	TIME [epoch: 36.1 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16866104885885175		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 0.16866104885885175 | validation: 0.16186609708424723]
	TIME [epoch: 36.1 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1766042997769288		[learning rate: 0.0053822]
	Learning Rate: 0.00538222
	LOSS [training: 0.1766042997769288 | validation: 0.16977868227148818]
	TIME [epoch: 36 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17664207106872762		[learning rate: 0.0053608]
	Learning Rate: 0.00536081
	LOSS [training: 0.17664207106872762 | validation: 0.16401177848538911]
	TIME [epoch: 36.1 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1787060308323609		[learning rate: 0.0053395]
	Learning Rate: 0.00533949
	LOSS [training: 0.1787060308323609 | validation: 0.15811577644711944]
	TIME [epoch: 36 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.19393835005686824		[learning rate: 0.0053183]
	Learning Rate: 0.00531826
	LOSS [training: 0.19393835005686824 | validation: 0.1609394403632419]
	TIME [epoch: 36 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1830611275277273		[learning rate: 0.0052971]
	Learning Rate: 0.0052971
	LOSS [training: 0.1830611275277273 | validation: 0.16571470687225487]
	TIME [epoch: 36 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17996347224160536		[learning rate: 0.005276]
	Learning Rate: 0.00527604
	LOSS [training: 0.17996347224160536 | validation: 0.16368522235035238]
	TIME [epoch: 36 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.18700025409258705		[learning rate: 0.0052551]
	Learning Rate: 0.00525505
	LOSS [training: 0.18700025409258705 | validation: 0.15610840351430627]
	TIME [epoch: 36 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1646824592210413		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 0.1646824592210413 | validation: 0.16108221885272916]
	TIME [epoch: 36 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17692877954804886		[learning rate: 0.0052133]
	Learning Rate: 0.00521333
	LOSS [training: 0.17692877954804886 | validation: 0.16507967471318244]
	TIME [epoch: 36.1 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1761441290336005		[learning rate: 0.0051926]
	Learning Rate: 0.0051926
	LOSS [training: 0.1761441290336005 | validation: 0.1562956881550473]
	TIME [epoch: 36 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17369022337132395		[learning rate: 0.0051719]
	Learning Rate: 0.00517194
	LOSS [training: 0.17369022337132395 | validation: 0.16562328320704317]
	TIME [epoch: 36 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1852096728139159		[learning rate: 0.0051514]
	Learning Rate: 0.00515137
	LOSS [training: 0.1852096728139159 | validation: 0.16010624729515327]
	TIME [epoch: 36 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1741459213518035		[learning rate: 0.0051309]
	Learning Rate: 0.00513089
	LOSS [training: 0.1741459213518035 | validation: 0.16361467476446528]
	TIME [epoch: 36 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.18393683575707667		[learning rate: 0.0051105]
	Learning Rate: 0.00511048
	LOSS [training: 0.18393683575707667 | validation: 0.1691842666211274]
	TIME [epoch: 36 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.19579862044642193		[learning rate: 0.0050902]
	Learning Rate: 0.00509015
	LOSS [training: 0.19579862044642193 | validation: 0.16582495260963784]
	TIME [epoch: 36 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.18277419268307485		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 0.18277419268307485 | validation: 0.1588236643268735]
	TIME [epoch: 36 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16724762114393962		[learning rate: 0.0050497]
	Learning Rate: 0.00504974
	LOSS [training: 0.16724762114393962 | validation: 0.1668684382862769]
	TIME [epoch: 36.1 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.18304497871668174		[learning rate: 0.0050297]
	Learning Rate: 0.00502966
	LOSS [training: 0.18304497871668174 | validation: 0.15093049813041975]
	TIME [epoch: 36 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17359370323660797		[learning rate: 0.0050097]
	Learning Rate: 0.00500965
	LOSS [training: 0.17359370323660797 | validation: 0.16073251408644862]
	TIME [epoch: 36.1 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1828457213833702		[learning rate: 0.0049897]
	Learning Rate: 0.00498973
	LOSS [training: 0.1828457213833702 | validation: 0.15575281528668075]
	TIME [epoch: 36 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16481014763460763		[learning rate: 0.0049699]
	Learning Rate: 0.00496988
	LOSS [training: 0.16481014763460763 | validation: 0.14926800988614883]
	TIME [epoch: 36.1 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1717510875461244		[learning rate: 0.0049501]
	Learning Rate: 0.00495012
	LOSS [training: 0.1717510875461244 | validation: 0.16468136341346853]
	TIME [epoch: 36 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16718529146559408		[learning rate: 0.0049304]
	Learning Rate: 0.00493043
	LOSS [training: 0.16718529146559408 | validation: 0.1615671414851267]
	TIME [epoch: 36.1 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17206015755233242		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 0.17206015755233242 | validation: 0.1673279801105963]
	TIME [epoch: 36 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.18524984129834815		[learning rate: 0.0048913]
	Learning Rate: 0.00489129
	LOSS [training: 0.18524984129834815 | validation: 0.15954465897725895]
	TIME [epoch: 36 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16451296163799783		[learning rate: 0.0048718]
	Learning Rate: 0.00487183
	LOSS [training: 0.16451296163799783 | validation: 0.1687908884103503]
	TIME [epoch: 36 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17047705671598298		[learning rate: 0.0048525]
	Learning Rate: 0.00485245
	LOSS [training: 0.17047705671598298 | validation: 0.16042872603137195]
	TIME [epoch: 36.1 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1824447623960818		[learning rate: 0.0048332]
	Learning Rate: 0.00483316
	LOSS [training: 0.1824447623960818 | validation: 0.16206728299429768]
	TIME [epoch: 36 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1954915321297443		[learning rate: 0.0048139]
	Learning Rate: 0.00481393
	LOSS [training: 0.1954915321297443 | validation: 0.16488962960714876]
	TIME [epoch: 36 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17786566540580517		[learning rate: 0.0047948]
	Learning Rate: 0.00479479
	LOSS [training: 0.17786566540580517 | validation: 0.17087838531858285]
	TIME [epoch: 36 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16900433381876714		[learning rate: 0.0047757]
	Learning Rate: 0.00477572
	LOSS [training: 0.16900433381876714 | validation: 0.15645484351977307]
	TIME [epoch: 36.1 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17028933825803289		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.17028933825803289 | validation: 0.16667783990471335]
	TIME [epoch: 36 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17253564116335415		[learning rate: 0.0047378]
	Learning Rate: 0.0047378
	LOSS [training: 0.17253564116335415 | validation: 0.16300681767407732]
	TIME [epoch: 36 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17365454708368497		[learning rate: 0.004719]
	Learning Rate: 0.00471896
	LOSS [training: 0.17365454708368497 | validation: 0.15450013909435678]
	TIME [epoch: 36 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17723272120830513		[learning rate: 0.0047002]
	Learning Rate: 0.00470019
	LOSS [training: 0.17723272120830513 | validation: 0.16527632505199583]
	TIME [epoch: 36 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17737867661325385		[learning rate: 0.0046815]
	Learning Rate: 0.0046815
	LOSS [training: 0.17737867661325385 | validation: 0.16957849964932725]
	TIME [epoch: 36 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.18410385204274454		[learning rate: 0.0046629]
	Learning Rate: 0.00466288
	LOSS [training: 0.18410385204274454 | validation: 0.16015746975111406]
	TIME [epoch: 36 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17834231664410302		[learning rate: 0.0046443]
	Learning Rate: 0.00464433
	LOSS [training: 0.17834231664410302 | validation: 0.1593041590660082]
	TIME [epoch: 36 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17602576289871824		[learning rate: 0.0046259]
	Learning Rate: 0.00462586
	LOSS [training: 0.17602576289871824 | validation: 0.16401339661928444]
	TIME [epoch: 36.1 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17430200994200198		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 0.17430200994200198 | validation: 0.16232724384730476]
	TIME [epoch: 36 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17323362319238578		[learning rate: 0.0045891]
	Learning Rate: 0.00458913
	LOSS [training: 0.17323362319238578 | validation: 0.17096113196443996]
	TIME [epoch: 36.1 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16338997283807166		[learning rate: 0.0045709]
	Learning Rate: 0.00457088
	LOSS [training: 0.16338997283807166 | validation: 0.1555595402681463]
	TIME [epoch: 36 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1708182496849516		[learning rate: 0.0045527]
	Learning Rate: 0.0045527
	LOSS [training: 0.1708182496849516 | validation: 0.16896086100825675]
	TIME [epoch: 36.1 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.18187166426668		[learning rate: 0.0045346]
	Learning Rate: 0.00453459
	LOSS [training: 0.18187166426668 | validation: 0.16773260713818045]
	TIME [epoch: 36 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17540188796467224		[learning rate: 0.0045166]
	Learning Rate: 0.00451656
	LOSS [training: 0.17540188796467224 | validation: 0.15809448306282084]
	TIME [epoch: 36 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.161983005765276		[learning rate: 0.0044986]
	Learning Rate: 0.0044986
	LOSS [training: 0.161983005765276 | validation: 0.1589060625911174]
	TIME [epoch: 36 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1990941888003227		[learning rate: 0.0044807]
	Learning Rate: 0.0044807
	LOSS [training: 0.1990941888003227 | validation: 0.15647887970913532]
	TIME [epoch: 36 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17618768101435112		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 0.17618768101435112 | validation: 0.1548059286821485]
	TIME [epoch: 36 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1831454219636771		[learning rate: 0.0044451]
	Learning Rate: 0.00444513
	LOSS [training: 0.1831454219636771 | validation: 0.15916500403826606]
	TIME [epoch: 36 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16804006277152986		[learning rate: 0.0044275]
	Learning Rate: 0.00442745
	LOSS [training: 0.16804006277152986 | validation: 0.15715229710414208]
	TIME [epoch: 36 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17919860162709428		[learning rate: 0.0044098]
	Learning Rate: 0.00440984
	LOSS [training: 0.17919860162709428 | validation: 0.15497797611405023]
	TIME [epoch: 36.1 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16866514427924903		[learning rate: 0.0043923]
	Learning Rate: 0.0043923
	LOSS [training: 0.16866514427924903 | validation: 0.16140558271104907]
	TIME [epoch: 36 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17742399089578656		[learning rate: 0.0043748]
	Learning Rate: 0.00437483
	LOSS [training: 0.17742399089578656 | validation: 0.1589335744415668]
	TIME [epoch: 36.1 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.18307628958882446		[learning rate: 0.0043574]
	Learning Rate: 0.00435743
	LOSS [training: 0.18307628958882446 | validation: 0.17168830885182426]
	TIME [epoch: 36 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1652251344082955		[learning rate: 0.0043401]
	Learning Rate: 0.0043401
	LOSS [training: 0.1652251344082955 | validation: 0.15914708145282522]
	TIME [epoch: 36 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1802587816466725		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 0.1802587816466725 | validation: 0.16327117496092752]
	TIME [epoch: 36 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16891478987907804		[learning rate: 0.0043056]
	Learning Rate: 0.00430565
	LOSS [training: 0.16891478987907804 | validation: 0.16729505484983678]
	TIME [epoch: 36 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17266139960338223		[learning rate: 0.0042885]
	Learning Rate: 0.00428852
	LOSS [training: 0.17266139960338223 | validation: 0.1625151694200148]
	TIME [epoch: 36.1 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17611230981297274		[learning rate: 0.0042715]
	Learning Rate: 0.00427147
	LOSS [training: 0.17611230981297274 | validation: 0.15418199105772687]
	TIME [epoch: 36.1 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16350267784325215		[learning rate: 0.0042545]
	Learning Rate: 0.00425448
	LOSS [training: 0.16350267784325215 | validation: 0.1641505580325012]
	TIME [epoch: 36.1 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16385576611487002		[learning rate: 0.0042376]
	Learning Rate: 0.00423756
	LOSS [training: 0.16385576611487002 | validation: 0.15581202120964494]
	TIME [epoch: 36 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1743395850320129		[learning rate: 0.0042207]
	Learning Rate: 0.0042207
	LOSS [training: 0.1743395850320129 | validation: 0.15574789952383628]
	TIME [epoch: 36.1 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17439343998403475		[learning rate: 0.0042039]
	Learning Rate: 0.00420391
	LOSS [training: 0.17439343998403475 | validation: 0.15928905413750172]
	TIME [epoch: 36 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17591477787806123		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 0.17591477787806123 | validation: 0.16511130789384582]
	TIME [epoch: 36 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17001401319154674		[learning rate: 0.0041705]
	Learning Rate: 0.00417054
	LOSS [training: 0.17001401319154674 | validation: 0.1541794778509276]
	TIME [epoch: 36 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16820726526837446		[learning rate: 0.004154]
	Learning Rate: 0.00415395
	LOSS [training: 0.16820726526837446 | validation: 0.16194492353427042]
	TIME [epoch: 36.1 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1679043252437072		[learning rate: 0.0041374]
	Learning Rate: 0.00413743
	LOSS [training: 0.1679043252437072 | validation: 0.1676278417485165]
	TIME [epoch: 36 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17193679442111587		[learning rate: 0.004121]
	Learning Rate: 0.00412098
	LOSS [training: 0.17193679442111587 | validation: 0.15968733687563602]
	TIME [epoch: 36 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17038692508330197		[learning rate: 0.0041046]
	Learning Rate: 0.00410458
	LOSS [training: 0.17038692508330197 | validation: 0.15382275577162569]
	TIME [epoch: 36 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16811806671415827		[learning rate: 0.0040883]
	Learning Rate: 0.00408826
	LOSS [training: 0.16811806671415827 | validation: 0.15894345319214095]
	TIME [epoch: 36 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17050978435644273		[learning rate: 0.004072]
	Learning Rate: 0.004072
	LOSS [training: 0.17050978435644273 | validation: 0.16469732252608682]
	TIME [epoch: 36 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16269006064316235		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.16269006064316235 | validation: 0.16500857727852547]
	TIME [epoch: 36 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17035045588414466		[learning rate: 0.0040397]
	Learning Rate: 0.00403967
	LOSS [training: 0.17035045588414466 | validation: 0.17140442976752618]
	TIME [epoch: 36 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.18454932639837182		[learning rate: 0.0040236]
	Learning Rate: 0.00402361
	LOSS [training: 0.18454932639837182 | validation: 0.16065438940926458]
	TIME [epoch: 36 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16473317630091772		[learning rate: 0.0040076]
	Learning Rate: 0.0040076
	LOSS [training: 0.16473317630091772 | validation: 0.1593799665092709]
	TIME [epoch: 36 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1718875363077905		[learning rate: 0.0039917]
	Learning Rate: 0.00399166
	LOSS [training: 0.1718875363077905 | validation: 0.15920684176309113]
	TIME [epoch: 36 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1634846908111594		[learning rate: 0.0039758]
	Learning Rate: 0.00397579
	LOSS [training: 0.1634846908111594 | validation: 0.1568723466543882]
	TIME [epoch: 36 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1740947854194227		[learning rate: 0.00396]
	Learning Rate: 0.00395997
	LOSS [training: 0.1740947854194227 | validation: 0.15255109337249387]
	TIME [epoch: 36 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1631838398222882		[learning rate: 0.0039442]
	Learning Rate: 0.00394422
	LOSS [training: 0.1631838398222882 | validation: 0.1538523928591277]
	TIME [epoch: 36 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16912333370034066		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 0.16912333370034066 | validation: 0.15403920994251716]
	TIME [epoch: 36 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17009623356384568		[learning rate: 0.0039129]
	Learning Rate: 0.00391291
	LOSS [training: 0.17009623356384568 | validation: 0.15268857596378815]
	TIME [epoch: 36 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17233285190924116		[learning rate: 0.0038973]
	Learning Rate: 0.00389735
	LOSS [training: 0.17233285190924116 | validation: 0.1605619668903811]
	TIME [epoch: 36 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1913671229008732		[learning rate: 0.0038818]
	Learning Rate: 0.00388185
	LOSS [training: 0.1913671229008732 | validation: 0.15989820944018412]
	TIME [epoch: 36 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.18492397734987234		[learning rate: 0.0038664]
	Learning Rate: 0.00386641
	LOSS [training: 0.18492397734987234 | validation: 0.16342549278702823]
	TIME [epoch: 36 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16468283745064025		[learning rate: 0.003851]
	Learning Rate: 0.00385103
	LOSS [training: 0.16468283745064025 | validation: 0.16472117172290268]
	TIME [epoch: 36 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1814620067633777		[learning rate: 0.0038357]
	Learning Rate: 0.00383571
	LOSS [training: 0.1814620067633777 | validation: 0.15471579742431568]
	TIME [epoch: 36 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17681491551954326		[learning rate: 0.0038205]
	Learning Rate: 0.00382046
	LOSS [training: 0.17681491551954326 | validation: 0.16375255661975022]
	TIME [epoch: 36 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17872978793727234		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 0.17872978793727234 | validation: 0.15800675942099812]
	TIME [epoch: 36 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1679576877224133		[learning rate: 0.0037901]
	Learning Rate: 0.00379013
	LOSS [training: 0.1679576877224133 | validation: 0.15895081664932825]
	TIME [epoch: 36 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17171758950892374		[learning rate: 0.0037751]
	Learning Rate: 0.00377505
	LOSS [training: 0.17171758950892374 | validation: 0.16228683553523734]
	TIME [epoch: 36 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.166237710372569		[learning rate: 0.00376]
	Learning Rate: 0.00376004
	LOSS [training: 0.166237710372569 | validation: 0.15560549393497267]
	TIME [epoch: 36 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.178525832239012		[learning rate: 0.0037451]
	Learning Rate: 0.00374508
	LOSS [training: 0.178525832239012 | validation: 0.15962635042256174]
	TIME [epoch: 36 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1719599854901134		[learning rate: 0.0037302]
	Learning Rate: 0.00373019
	LOSS [training: 0.1719599854901134 | validation: 0.15235650489527863]
	TIME [epoch: 36 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1718158131569233		[learning rate: 0.0037154]
	Learning Rate: 0.00371535
	LOSS [training: 0.1718158131569233 | validation: 0.16369999516306227]
	TIME [epoch: 36 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17281226889832985		[learning rate: 0.0037006]
	Learning Rate: 0.00370058
	LOSS [training: 0.17281226889832985 | validation: 0.15991902218345985]
	TIME [epoch: 36 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.18019991840164973		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 0.18019991840164973 | validation: 0.1547197055424506]
	TIME [epoch: 36 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17753563741169245		[learning rate: 0.0036712]
	Learning Rate: 0.0036712
	LOSS [training: 0.17753563741169245 | validation: 0.15827157853702642]
	TIME [epoch: 36 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1622509625670524		[learning rate: 0.0036566]
	Learning Rate: 0.0036566
	LOSS [training: 0.1622509625670524 | validation: 0.15951480695824757]
	TIME [epoch: 36 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16625875285195407		[learning rate: 0.0036421]
	Learning Rate: 0.00364205
	LOSS [training: 0.16625875285195407 | validation: 0.16969402246083526]
	TIME [epoch: 36 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16874582579781625		[learning rate: 0.0036276]
	Learning Rate: 0.00362757
	LOSS [training: 0.16874582579781625 | validation: 0.15361146178504392]
	TIME [epoch: 36 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16822101733227598		[learning rate: 0.0036131]
	Learning Rate: 0.00361314
	LOSS [training: 0.16822101733227598 | validation: 0.151966963534569]
	TIME [epoch: 36 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.18238858855284318		[learning rate: 0.0035988]
	Learning Rate: 0.00359877
	LOSS [training: 0.18238858855284318 | validation: 0.15694583275976132]
	TIME [epoch: 36 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17119949378056118		[learning rate: 0.0035845]
	Learning Rate: 0.00358445
	LOSS [training: 0.17119949378056118 | validation: 0.15648490352414934]
	TIME [epoch: 36 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.18764167785857672		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 0.18764167785857672 | validation: 0.15086217962434223]
	TIME [epoch: 36 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1826522488936135		[learning rate: 0.003556]
	Learning Rate: 0.003556
	LOSS [training: 0.1826522488936135 | validation: 0.15734549495456993]
	TIME [epoch: 36 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.18144789954266477		[learning rate: 0.0035419]
	Learning Rate: 0.00354185
	LOSS [training: 0.18144789954266477 | validation: 0.1558611993946523]
	TIME [epoch: 36 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17759763602842582		[learning rate: 0.0035278]
	Learning Rate: 0.00352777
	LOSS [training: 0.17759763602842582 | validation: 0.15359984884141584]
	TIME [epoch: 36 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.18197103450262003		[learning rate: 0.0035137]
	Learning Rate: 0.00351374
	LOSS [training: 0.18197103450262003 | validation: 0.16047541721383937]
	TIME [epoch: 36 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16867950647729824		[learning rate: 0.0034998]
	Learning Rate: 0.00349976
	LOSS [training: 0.16867950647729824 | validation: 0.15980558628159133]
	TIME [epoch: 36 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16837435208079451		[learning rate: 0.0034858]
	Learning Rate: 0.00348584
	LOSS [training: 0.16837435208079451 | validation: 0.15608840220676873]
	TIME [epoch: 36 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16784716146423218		[learning rate: 0.003472]
	Learning Rate: 0.00347198
	LOSS [training: 0.16784716146423218 | validation: 0.15928444577537876]
	TIME [epoch: 36 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.160576304044146		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.160576304044146 | validation: 0.15549260579657662]
	TIME [epoch: 36 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1655701008113032		[learning rate: 0.0034444]
	Learning Rate: 0.00344441
	LOSS [training: 0.1655701008113032 | validation: 0.15740723424442582]
	TIME [epoch: 36 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1562003966240593		[learning rate: 0.0034307]
	Learning Rate: 0.00343071
	LOSS [training: 0.1562003966240593 | validation: 0.15195684312408367]
	TIME [epoch: 36 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.18600359101470038		[learning rate: 0.0034171]
	Learning Rate: 0.00341707
	LOSS [training: 0.18600359101470038 | validation: 0.1528633038266008]
	TIME [epoch: 36 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17468801317802354		[learning rate: 0.0034035]
	Learning Rate: 0.00340348
	LOSS [training: 0.17468801317802354 | validation: 0.1531229300535427]
	TIME [epoch: 36 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17648927586687777		[learning rate: 0.0033899]
	Learning Rate: 0.00338994
	LOSS [training: 0.17648927586687777 | validation: 0.15494769091642713]
	TIME [epoch: 36 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1689986582407974		[learning rate: 0.0033765]
	Learning Rate: 0.00337646
	LOSS [training: 0.1689986582407974 | validation: 0.15339127181463746]
	TIME [epoch: 36.1 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1636080324251499		[learning rate: 0.003363]
	Learning Rate: 0.00336303
	LOSS [training: 0.1636080324251499 | validation: 0.1533657863620886]
	TIME [epoch: 36 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.18278201142890255		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 0.18278201142890255 | validation: 0.1615480784682445]
	TIME [epoch: 36 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17283510579607964		[learning rate: 0.0033363]
	Learning Rate: 0.00333633
	LOSS [training: 0.17283510579607964 | validation: 0.15763495559390403]
	TIME [epoch: 36 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17885890727927156		[learning rate: 0.0033231]
	Learning Rate: 0.00332306
	LOSS [training: 0.17885890727927156 | validation: 0.16403164521592212]
	TIME [epoch: 36 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17268511194017971		[learning rate: 0.0033098]
	Learning Rate: 0.00330985
	LOSS [training: 0.17268511194017971 | validation: 0.1598192100791317]
	TIME [epoch: 36 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1680405709147593		[learning rate: 0.0032967]
	Learning Rate: 0.00329668
	LOSS [training: 0.1680405709147593 | validation: 0.15514524628144877]
	TIME [epoch: 36 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16276103484867094		[learning rate: 0.0032836]
	Learning Rate: 0.00328357
	LOSS [training: 0.16276103484867094 | validation: 0.15934940914150397]
	TIME [epoch: 36 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1740985008493479		[learning rate: 0.0032705]
	Learning Rate: 0.00327051
	LOSS [training: 0.1740985008493479 | validation: 0.15138393313663917]
	TIME [epoch: 36 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16202395143482415		[learning rate: 0.0032575]
	Learning Rate: 0.0032575
	LOSS [training: 0.16202395143482415 | validation: 0.15038102300824244]
	TIME [epoch: 36 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16669519614288267		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 0.16669519614288267 | validation: 0.15310168862191664]
	TIME [epoch: 36.1 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16878382763743616		[learning rate: 0.0032316]
	Learning Rate: 0.00323164
	LOSS [training: 0.16878382763743616 | validation: 0.16520348618896658]
	TIME [epoch: 36 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.18584810830607829		[learning rate: 0.0032188]
	Learning Rate: 0.00321879
	LOSS [training: 0.18584810830607829 | validation: 0.16188710273430737]
	TIME [epoch: 36 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17611663301358627		[learning rate: 0.003206]
	Learning Rate: 0.00320599
	LOSS [training: 0.17611663301358627 | validation: 0.15740033279894308]
	TIME [epoch: 36 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.169231534100641		[learning rate: 0.0031932]
	Learning Rate: 0.00319323
	LOSS [training: 0.169231534100641 | validation: 0.14868460333827524]
	TIME [epoch: 36 sec]
	Saving model to: out/model_training/model_facs_dec1c_2d_v1_20240622_120516/states/model_facs_dec1c_2d_v1_331.pth
	Model improved!!!
EPOCH 332/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16642952591497107		[learning rate: 0.0031805]
	Learning Rate: 0.00318053
	LOSS [training: 0.16642952591497107 | validation: 0.1587156093036612]
	TIME [epoch: 36.1 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16630412467382444		[learning rate: 0.0031679]
	Learning Rate: 0.00316788
	LOSS [training: 0.16630412467382444 | validation: 0.1635635878613524]
	TIME [epoch: 36.1 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1754496601632427		[learning rate: 0.0031553]
	Learning Rate: 0.00315528
	LOSS [training: 0.1754496601632427 | validation: 0.15864733377086876]
	TIME [epoch: 36 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17128094916651515		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 0.17128094916651515 | validation: 0.1576080375908642]
	TIME [epoch: 36 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15964140143701538		[learning rate: 0.0031302]
	Learning Rate: 0.00313023
	LOSS [training: 0.15964140143701538 | validation: 0.15807203862627744]
	TIME [epoch: 36 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17336494571157587		[learning rate: 0.0031178]
	Learning Rate: 0.00311779
	LOSS [training: 0.17336494571157587 | validation: 0.1521105268288173]
	TIME [epoch: 36.1 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16167463677272748		[learning rate: 0.0031054]
	Learning Rate: 0.00310538
	LOSS [training: 0.16167463677272748 | validation: 0.15083415654888213]
	TIME [epoch: 36 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1610188909607244		[learning rate: 0.003093]
	Learning Rate: 0.00309303
	LOSS [training: 0.1610188909607244 | validation: 0.1642087160083157]
	TIME [epoch: 36 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17693059933957192		[learning rate: 0.0030807]
	Learning Rate: 0.00308073
	LOSS [training: 0.17693059933957192 | validation: 0.15117350320873765]
	TIME [epoch: 36 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1631469496046728		[learning rate: 0.0030685]
	Learning Rate: 0.00306848
	LOSS [training: 0.1631469496046728 | validation: 0.16012088202547325]
	TIME [epoch: 36 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17456801161859187		[learning rate: 0.0030563]
	Learning Rate: 0.00305627
	LOSS [training: 0.17456801161859187 | validation: 0.15258530265097248]
	TIME [epoch: 36 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17464904223331262		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 0.17464904223331262 | validation: 0.15368403187545937]
	TIME [epoch: 36 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16431746967807637		[learning rate: 0.003032]
	Learning Rate: 0.00303201
	LOSS [training: 0.16431746967807637 | validation: 0.15861691241683246]
	TIME [epoch: 36 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16446167897502062		[learning rate: 0.00302]
	Learning Rate: 0.00301995
	LOSS [training: 0.16446167897502062 | validation: 0.14542195582751696]
	TIME [epoch: 36 sec]
	Saving model to: out/model_training/model_facs_dec1c_2d_v1_20240622_120516/states/model_facs_dec1c_2d_v1_345.pth
	Model improved!!!
EPOCH 346/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15926106601603282		[learning rate: 0.0030079]
	Learning Rate: 0.00300794
	LOSS [training: 0.15926106601603282 | validation: 0.14606228923794656]
	TIME [epoch: 36 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16032005566327823		[learning rate: 0.002996]
	Learning Rate: 0.00299598
	LOSS [training: 0.16032005566327823 | validation: 0.15395085339750406]
	TIME [epoch: 36 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15877796614380615		[learning rate: 0.0029841]
	Learning Rate: 0.00298406
	LOSS [training: 0.15877796614380615 | validation: 0.15770464006237808]
	TIME [epoch: 36 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1649528150244025		[learning rate: 0.0029722]
	Learning Rate: 0.00297219
	LOSS [training: 0.1649528150244025 | validation: 0.1566535911307766]
	TIME [epoch: 36 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16839856752635363		[learning rate: 0.0029604]
	Learning Rate: 0.00296037
	LOSS [training: 0.16839856752635363 | validation: 0.15948849094994194]
	TIME [epoch: 36 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1727529022065451		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.1727529022065451 | validation: 0.15266055895005856]
	TIME [epoch: 36 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17045398168373335		[learning rate: 0.0029369]
	Learning Rate: 0.00293687
	LOSS [training: 0.17045398168373335 | validation: 0.1580112315524652]
	TIME [epoch: 36 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1648490531772787		[learning rate: 0.0029252]
	Learning Rate: 0.00292519
	LOSS [training: 0.1648490531772787 | validation: 0.15197238308361471]
	TIME [epoch: 36 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16027319461694534		[learning rate: 0.0029136]
	Learning Rate: 0.00291355
	LOSS [training: 0.16027319461694534 | validation: 0.15929371058545833]
	TIME [epoch: 36 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17936276488688804		[learning rate: 0.002902]
	Learning Rate: 0.00290197
	LOSS [training: 0.17936276488688804 | validation: 0.1524081157236345]
	TIME [epoch: 36 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1612521972522992		[learning rate: 0.0028904]
	Learning Rate: 0.00289042
	LOSS [training: 0.1612521972522992 | validation: 0.15146759768527254]
	TIME [epoch: 36 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1695249479699473		[learning rate: 0.0028789]
	Learning Rate: 0.00287893
	LOSS [training: 0.1695249479699473 | validation: 0.1584033330420946]
	TIME [epoch: 36 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16703969983441974		[learning rate: 0.0028675]
	Learning Rate: 0.00286748
	LOSS [training: 0.16703969983441974 | validation: 0.16386017807099335]
	TIME [epoch: 36 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1651005515139217		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 0.1651005515139217 | validation: 0.15000712508415698]
	TIME [epoch: 36 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1710231985593303		[learning rate: 0.0028447]
	Learning Rate: 0.00284471
	LOSS [training: 0.1710231985593303 | validation: 0.15659296023892616]
	TIME [epoch: 36 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16504076729403333		[learning rate: 0.0028334]
	Learning Rate: 0.0028334
	LOSS [training: 0.16504076729403333 | validation: 0.1520290238811768]
	TIME [epoch: 36.1 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16084355433613565		[learning rate: 0.0028221]
	Learning Rate: 0.00282213
	LOSS [training: 0.16084355433613565 | validation: 0.1477317214934223]
	TIME [epoch: 36 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1736765543021811		[learning rate: 0.0028109]
	Learning Rate: 0.00281091
	LOSS [training: 0.1736765543021811 | validation: 0.14408950065151432]
	TIME [epoch: 36 sec]
	Saving model to: out/model_training/model_facs_dec1c_2d_v1_20240622_120516/states/model_facs_dec1c_2d_v1_363.pth
	Model improved!!!
EPOCH 364/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16836609249648712		[learning rate: 0.0027997]
	Learning Rate: 0.00279973
	LOSS [training: 0.16836609249648712 | validation: 0.1525558504541346]
	TIME [epoch: 36 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17308462391436163		[learning rate: 0.0027886]
	Learning Rate: 0.00278859
	LOSS [training: 0.17308462391436163 | validation: 0.15508416800337116]
	TIME [epoch: 36 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1738776376192922		[learning rate: 0.0027775]
	Learning Rate: 0.0027775
	LOSS [training: 0.1738776376192922 | validation: 0.14486635489620694]
	TIME [epoch: 36 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1658837359593252		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 0.1658837359593252 | validation: 0.1621981493473253]
	TIME [epoch: 36 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1675416016899383		[learning rate: 0.0027554]
	Learning Rate: 0.00275545
	LOSS [training: 0.1675416016899383 | validation: 0.15730463954005533]
	TIME [epoch: 36 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16340832323880206		[learning rate: 0.0027445]
	Learning Rate: 0.00274449
	LOSS [training: 0.16340832323880206 | validation: 0.14958449777917365]
	TIME [epoch: 36 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17751343521594784		[learning rate: 0.0027336]
	Learning Rate: 0.00273357
	LOSS [training: 0.17751343521594784 | validation: 0.15081774126793598]
	TIME [epoch: 36 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17405073392409737		[learning rate: 0.0027227]
	Learning Rate: 0.0027227
	LOSS [training: 0.17405073392409737 | validation: 0.15365302940366107]
	TIME [epoch: 36 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1637403903453803		[learning rate: 0.0027119]
	Learning Rate: 0.00271187
	LOSS [training: 0.1637403903453803 | validation: 0.16800718573136494]
	TIME [epoch: 36 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.18222792611315577		[learning rate: 0.0027011]
	Learning Rate: 0.00270109
	LOSS [training: 0.18222792611315577 | validation: 0.15440771270696454]
	TIME [epoch: 36 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1682719404160556		[learning rate: 0.0026903]
	Learning Rate: 0.00269034
	LOSS [training: 0.1682719404160556 | validation: 0.15531772122842238]
	TIME [epoch: 36 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17939483780163015		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 0.17939483780163015 | validation: 0.1468880705986753]
	TIME [epoch: 36 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1600894178214299		[learning rate: 0.002669]
	Learning Rate: 0.00266899
	LOSS [training: 0.1600894178214299 | validation: 0.1496437815622098]
	TIME [epoch: 36 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17167367034663072		[learning rate: 0.0026584]
	Learning Rate: 0.00265837
	LOSS [training: 0.17167367034663072 | validation: 0.15305714654947694]
	TIME [epoch: 36 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17207696825121008		[learning rate: 0.0026478]
	Learning Rate: 0.0026478
	LOSS [training: 0.17207696825121008 | validation: 0.15689503183380363]
	TIME [epoch: 36 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17306943657188778		[learning rate: 0.0026373]
	Learning Rate: 0.00263727
	LOSS [training: 0.17306943657188778 | validation: 0.16237581813590052]
	TIME [epoch: 36 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17562331953643556		[learning rate: 0.0026268]
	Learning Rate: 0.00262678
	LOSS [training: 0.17562331953643556 | validation: 0.1515036632806869]
	TIME [epoch: 36 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.164437537755149		[learning rate: 0.0026163]
	Learning Rate: 0.00261633
	LOSS [training: 0.164437537755149 | validation: 0.15517099267227824]
	TIME [epoch: 36 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.18172236298345912		[learning rate: 0.0026059]
	Learning Rate: 0.00260592
	LOSS [training: 0.18172236298345912 | validation: 0.15267156595710082]
	TIME [epoch: 36 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16481151589636006		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 0.16481151589636006 | validation: 0.1507614211256349]
	TIME [epoch: 36 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1756582487392844		[learning rate: 0.0025852]
	Learning Rate: 0.00258523
	LOSS [training: 0.1756582487392844 | validation: 0.15191147054323198]
	TIME [epoch: 36 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.18052761423802674		[learning rate: 0.002575]
	Learning Rate: 0.00257495
	LOSS [training: 0.18052761423802674 | validation: 0.14660295805677878]
	TIME [epoch: 36 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16052244968919108		[learning rate: 0.0025647]
	Learning Rate: 0.00256471
	LOSS [training: 0.16052244968919108 | validation: 0.15430608903485935]
	TIME [epoch: 36 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1636313918987784		[learning rate: 0.0025545]
	Learning Rate: 0.00255451
	LOSS [training: 0.1636313918987784 | validation: 0.15584366827372975]
	TIME [epoch: 36 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16722789275295633		[learning rate: 0.0025444]
	Learning Rate: 0.00254435
	LOSS [training: 0.16722789275295633 | validation: 0.15403096223330168]
	TIME [epoch: 36 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1630949364223523		[learning rate: 0.0025342]
	Learning Rate: 0.00253423
	LOSS [training: 0.1630949364223523 | validation: 0.14750937969879105]
	TIME [epoch: 36 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15493248293343298		[learning rate: 0.0025242]
	Learning Rate: 0.00252415
	LOSS [training: 0.15493248293343298 | validation: 0.1603015148519819]
	TIME [epoch: 36 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1687645906860714		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.1687645906860714 | validation: 0.15713056716164325]
	TIME [epoch: 36 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17380876037797038		[learning rate: 0.0025041]
	Learning Rate: 0.00250411
	LOSS [training: 0.17380876037797038 | validation: 0.15375085514150547]
	TIME [epoch: 36 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1623880243648236		[learning rate: 0.0024942]
	Learning Rate: 0.00249415
	LOSS [training: 0.1623880243648236 | validation: 0.14983341868774383]
	TIME [epoch: 36 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.19045274119318817		[learning rate: 0.0024842]
	Learning Rate: 0.00248423
	LOSS [training: 0.19045274119318817 | validation: 0.15089236478658166]
	TIME [epoch: 36 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16525033982209847		[learning rate: 0.0024744]
	Learning Rate: 0.00247435
	LOSS [training: 0.16525033982209847 | validation: 0.14978330099239448]
	TIME [epoch: 36 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16611876904999756		[learning rate: 0.0024645]
	Learning Rate: 0.00246451
	LOSS [training: 0.16611876904999756 | validation: 0.1563002200939799]
	TIME [epoch: 36 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17499705472560653		[learning rate: 0.0024547]
	Learning Rate: 0.00245471
	LOSS [training: 0.17499705472560653 | validation: 0.1610846101360282]
	TIME [epoch: 36 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.19670057324124568		[learning rate: 0.0024449]
	Learning Rate: 0.00244495
	LOSS [training: 0.19670057324124568 | validation: 0.15449266794043567]
	TIME [epoch: 36 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17678538819523032		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 0.17678538819523032 | validation: 0.1467611112448881]
	TIME [epoch: 36 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16061301221932073		[learning rate: 0.0024255]
	Learning Rate: 0.00242554
	LOSS [training: 0.16061301221932073 | validation: 0.14789716205944892]
	TIME [epoch: 36 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.163727117146253		[learning rate: 0.0024159]
	Learning Rate: 0.00241589
	LOSS [training: 0.163727117146253 | validation: 0.14731942480791754]
	TIME [epoch: 36 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16658186544637715		[learning rate: 0.0024063]
	Learning Rate: 0.00240628
	LOSS [training: 0.16658186544637715 | validation: 0.1507544531691029]
	TIME [epoch: 36 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17180073881435975		[learning rate: 0.0023967]
	Learning Rate: 0.00239671
	LOSS [training: 0.17180073881435975 | validation: 0.14535894570618987]
	TIME [epoch: 36 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1660832575715825		[learning rate: 0.0023872]
	Learning Rate: 0.00238718
	LOSS [training: 0.1660832575715825 | validation: 0.15082727876943877]
	TIME [epoch: 36 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1694152151714573		[learning rate: 0.0023777]
	Learning Rate: 0.00237768
	LOSS [training: 0.1694152151714573 | validation: 0.16954108339905155]
	TIME [epoch: 36 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.18084684207007967		[learning rate: 0.0023682]
	Learning Rate: 0.00236823
	LOSS [training: 0.18084684207007967 | validation: 0.14961552127545652]
	TIME [epoch: 36 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16123764397977244		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 0.16123764397977244 | validation: 0.15139858065989933]
	TIME [epoch: 36 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17652204539797486		[learning rate: 0.0023494]
	Learning Rate: 0.00234942
	LOSS [training: 0.17652204539797486 | validation: 0.15535969606527747]
	TIME [epoch: 36 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16417756594659727		[learning rate: 0.0023401]
	Learning Rate: 0.00234008
	LOSS [training: 0.16417756594659727 | validation: 0.15552011279941166]
	TIME [epoch: 36 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15872747367136605		[learning rate: 0.0023308]
	Learning Rate: 0.00233077
	LOSS [training: 0.15872747367136605 | validation: 0.1686362414772876]
	TIME [epoch: 36 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17326964135862022		[learning rate: 0.0023215]
	Learning Rate: 0.0023215
	LOSS [training: 0.17326964135862022 | validation: 0.15366782078874108]
	TIME [epoch: 36 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1631944147079124		[learning rate: 0.0023123]
	Learning Rate: 0.00231227
	LOSS [training: 0.1631944147079124 | validation: 0.1463177885356107]
	TIME [epoch: 36 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1714260143205349		[learning rate: 0.0023031]
	Learning Rate: 0.00230307
	LOSS [training: 0.1714260143205349 | validation: 0.15673752345565067]
	TIME [epoch: 36 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17145246064552425		[learning rate: 0.0022939]
	Learning Rate: 0.00229391
	LOSS [training: 0.17145246064552425 | validation: 0.15643171582958076]
	TIME [epoch: 36 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16426351777499532		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 0.16426351777499532 | validation: 0.15025218858290773]
	TIME [epoch: 36 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1621396250681386		[learning rate: 0.0022757]
	Learning Rate: 0.0022757
	LOSS [training: 0.1621396250681386 | validation: 0.1581294552518318]
	TIME [epoch: 36 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17640579236329124		[learning rate: 0.0022667]
	Learning Rate: 0.00226665
	LOSS [training: 0.17640579236329124 | validation: 0.14627768807109115]
	TIME [epoch: 36 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.160268279888791		[learning rate: 0.0022576]
	Learning Rate: 0.00225764
	LOSS [training: 0.160268279888791 | validation: 0.150251076604864]
	TIME [epoch: 36 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15998142543228283		[learning rate: 0.0022487]
	Learning Rate: 0.00224866
	LOSS [training: 0.15998142543228283 | validation: 0.1548104556267085]
	TIME [epoch: 36.1 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16811812226475636		[learning rate: 0.0022397]
	Learning Rate: 0.00223971
	LOSS [training: 0.16811812226475636 | validation: 0.14410691783064397]
	TIME [epoch: 36 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15895420596339116		[learning rate: 0.0022308]
	Learning Rate: 0.0022308
	LOSS [training: 0.15895420596339116 | validation: 0.1465393022926173]
	TIME [epoch: 36 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1572094474114421		[learning rate: 0.0022219]
	Learning Rate: 0.00222193
	LOSS [training: 0.1572094474114421 | validation: 0.14579872043221212]
	TIME [epoch: 36 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1692577470952511		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.1692577470952511 | validation: 0.14701026806783038]
	TIME [epoch: 36 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16757680129798835		[learning rate: 0.0022043]
	Learning Rate: 0.00220429
	LOSS [training: 0.16757680129798835 | validation: 0.15566778165954678]
	TIME [epoch: 36 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16001986476086463		[learning rate: 0.0021955]
	Learning Rate: 0.00219553
	LOSS [training: 0.16001986476086463 | validation: 0.1478687855641256]
	TIME [epoch: 36 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17951620266413812		[learning rate: 0.0021868]
	Learning Rate: 0.00218679
	LOSS [training: 0.17951620266413812 | validation: 0.15042261055043915]
	TIME [epoch: 36 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16333368149306252		[learning rate: 0.0021781]
	Learning Rate: 0.0021781
	LOSS [training: 0.16333368149306252 | validation: 0.154453076250719]
	TIME [epoch: 36 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17213649880268148		[learning rate: 0.0021694]
	Learning Rate: 0.00216943
	LOSS [training: 0.17213649880268148 | validation: 0.16116455333583665]
	TIME [epoch: 36 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17087317401439162		[learning rate: 0.0021608]
	Learning Rate: 0.0021608
	LOSS [training: 0.17087317401439162 | validation: 0.15139675643592537]
	TIME [epoch: 36 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16712924795069156		[learning rate: 0.0021522]
	Learning Rate: 0.00215221
	LOSS [training: 0.16712924795069156 | validation: 0.1488630784958413]
	TIME [epoch: 36 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16096976357181386		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.16096976357181386 | validation: 0.15274526744593248]
	TIME [epoch: 36 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1709107988528311		[learning rate: 0.0021351]
	Learning Rate: 0.00213512
	LOSS [training: 0.1709107988528311 | validation: 0.1524153292959572]
	TIME [epoch: 36 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1733343444142147		[learning rate: 0.0021266]
	Learning Rate: 0.00212663
	LOSS [training: 0.1733343444142147 | validation: 0.15862286700779343]
	TIME [epoch: 36 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1729125964383729		[learning rate: 0.0021182]
	Learning Rate: 0.00211817
	LOSS [training: 0.1729125964383729 | validation: 0.16457550977933474]
	TIME [epoch: 36 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1722773676845203		[learning rate: 0.0021097]
	Learning Rate: 0.00210975
	LOSS [training: 0.1722773676845203 | validation: 0.15494190538705638]
	TIME [epoch: 36 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16162154146743452		[learning rate: 0.0021014]
	Learning Rate: 0.00210136
	LOSS [training: 0.16162154146743452 | validation: 0.15599103768224093]
	TIME [epoch: 36 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17227262581251096		[learning rate: 0.002093]
	Learning Rate: 0.002093
	LOSS [training: 0.17227262581251096 | validation: 0.14970114626094272]
	TIME [epoch: 36 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15655272909686707		[learning rate: 0.0020847]
	Learning Rate: 0.00208468
	LOSS [training: 0.15655272909686707 | validation: 0.14978197697436132]
	TIME [epoch: 36 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16225969660546438		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.16225969660546438 | validation: 0.15092076160409057]
	TIME [epoch: 36 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16744061411815198		[learning rate: 0.0020681]
	Learning Rate: 0.00206813
	LOSS [training: 0.16744061411815198 | validation: 0.14665882210797543]
	TIME [epoch: 36 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1928130655557159		[learning rate: 0.0020599]
	Learning Rate: 0.0020599
	LOSS [training: 0.1928130655557159 | validation: 0.14930088296516034]
	TIME [epoch: 36 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1686454364205786		[learning rate: 0.0020517]
	Learning Rate: 0.00205171
	LOSS [training: 0.1686454364205786 | validation: 0.14814607572795394]
	TIME [epoch: 36 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17291079663802852		[learning rate: 0.0020435]
	Learning Rate: 0.00204355
	LOSS [training: 0.17291079663802852 | validation: 0.15074560084236457]
	TIME [epoch: 36 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16366401089018676		[learning rate: 0.0020354]
	Learning Rate: 0.00203542
	LOSS [training: 0.16366401089018676 | validation: 0.14785885594113796]
	TIME [epoch: 36 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16338922903858555		[learning rate: 0.0020273]
	Learning Rate: 0.00202732
	LOSS [training: 0.16338922903858555 | validation: 0.15231085259539967]
	TIME [epoch: 36 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15774913704052082		[learning rate: 0.0020193]
	Learning Rate: 0.00201926
	LOSS [training: 0.15774913704052082 | validation: 0.14892406774435643]
	TIME [epoch: 36.1 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17389287187707395		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 0.17389287187707395 | validation: 0.1506795008070328]
	TIME [epoch: 36 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1573188341087241		[learning rate: 0.0020032]
	Learning Rate: 0.00200323
	LOSS [training: 0.1573188341087241 | validation: 0.14577306925491088]
	TIME [epoch: 36 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1597588039592078		[learning rate: 0.0019953]
	Learning Rate: 0.00199526
	LOSS [training: 0.1597588039592078 | validation: 0.1485032592375088]
	TIME [epoch: 36 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1770092881862179		[learning rate: 0.0019873]
	Learning Rate: 0.00198733
	LOSS [training: 0.1770092881862179 | validation: 0.1429541419752611]
	TIME [epoch: 36 sec]
	Saving model to: out/model_training/model_facs_dec1c_2d_v1_20240622_120516/states/model_facs_dec1c_2d_v1_450.pth
	Model improved!!!
EPOCH 451/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16505536772869311		[learning rate: 0.0019794]
	Learning Rate: 0.00197942
	LOSS [training: 0.16505536772869311 | validation: 0.14240250275006772]
	TIME [epoch: 36.1 sec]
	Saving model to: out/model_training/model_facs_dec1c_2d_v1_20240622_120516/states/model_facs_dec1c_2d_v1_451.pth
	Model improved!!!
EPOCH 452/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.19458553414023325		[learning rate: 0.0019715]
	Learning Rate: 0.00197155
	LOSS [training: 0.19458553414023325 | validation: 0.14882877151265075]
	TIME [epoch: 36.1 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17004949784946233		[learning rate: 0.0019637]
	Learning Rate: 0.00196371
	LOSS [training: 0.17004949784946233 | validation: 0.1442889426912644]
	TIME [epoch: 36.2 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16181131838763915		[learning rate: 0.0019559]
	Learning Rate: 0.0019559
	LOSS [training: 0.16181131838763915 | validation: 0.15335986068290514]
	TIME [epoch: 36 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16005353157507557		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 0.16005353157507557 | validation: 0.14772536627349248]
	TIME [epoch: 36 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1582457003295854		[learning rate: 0.0019404]
	Learning Rate: 0.00194037
	LOSS [training: 0.1582457003295854 | validation: 0.14674511989236433]
	TIME [epoch: 36.1 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.18384101400946923		[learning rate: 0.0019327]
	Learning Rate: 0.00193265
	LOSS [training: 0.18384101400946923 | validation: 0.1501826912200304]
	TIME [epoch: 36 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16270250142073073		[learning rate: 0.001925]
	Learning Rate: 0.00192497
	LOSS [training: 0.16270250142073073 | validation: 0.15330795253692325]
	TIME [epoch: 36 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15879698918396		[learning rate: 0.0019173]
	Learning Rate: 0.00191731
	LOSS [training: 0.15879698918396 | validation: 0.14742928992631815]
	TIME [epoch: 36 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16375480652111715		[learning rate: 0.0019097]
	Learning Rate: 0.00190968
	LOSS [training: 0.16375480652111715 | validation: 0.1515968827371905]
	TIME [epoch: 36.1 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1658297731131571		[learning rate: 0.0019021]
	Learning Rate: 0.00190209
	LOSS [training: 0.1658297731131571 | validation: 0.14855810707309297]
	TIME [epoch: 36.1 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17436513782778654		[learning rate: 0.0018945]
	Learning Rate: 0.00189452
	LOSS [training: 0.17436513782778654 | validation: 0.1447713909132389]
	TIME [epoch: 36.1 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1656060379772348		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.1656060379772348 | validation: 0.1512426774138445]
	TIME [epoch: 36.1 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17750474938694447		[learning rate: 0.0018795]
	Learning Rate: 0.00187948
	LOSS [training: 0.17750474938694447 | validation: 0.1450693359490238]
	TIME [epoch: 36.1 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15270957792563652		[learning rate: 0.001872]
	Learning Rate: 0.00187201
	LOSS [training: 0.15270957792563652 | validation: 0.1426532441190344]
	TIME [epoch: 36 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16923298840228776		[learning rate: 0.0018646]
	Learning Rate: 0.00186456
	LOSS [training: 0.16923298840228776 | validation: 0.14648589935670792]
	TIME [epoch: 36 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17050522005236066		[learning rate: 0.0018571]
	Learning Rate: 0.00185715
	LOSS [training: 0.17050522005236066 | validation: 0.14185499647397218]
	TIME [epoch: 36 sec]
	Saving model to: out/model_training/model_facs_dec1c_2d_v1_20240622_120516/states/model_facs_dec1c_2d_v1_467.pth
	Model improved!!!
EPOCH 468/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16296973754126465		[learning rate: 0.0018498]
	Learning Rate: 0.00184976
	LOSS [training: 0.16296973754126465 | validation: 0.15094989443925821]
	TIME [epoch: 36 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1712062375073039		[learning rate: 0.0018424]
	Learning Rate: 0.0018424
	LOSS [training: 0.1712062375073039 | validation: 0.15099317096322382]
	TIME [epoch: 36 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16143066287103125		[learning rate: 0.0018351]
	Learning Rate: 0.00183508
	LOSS [training: 0.16143066287103125 | validation: 0.1437924901474144]
	TIME [epoch: 36 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1662390799984659		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.1662390799984659 | validation: 0.14917359436084365]
	TIME [epoch: 36 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17105713061129876		[learning rate: 0.0018205]
	Learning Rate: 0.00182051
	LOSS [training: 0.17105713061129876 | validation: 0.1467499720225295]
	TIME [epoch: 36 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1672229320859815		[learning rate: 0.0018133]
	Learning Rate: 0.00181327
	LOSS [training: 0.1672229320859815 | validation: 0.141195297971755]
	TIME [epoch: 36 sec]
	Saving model to: out/model_training/model_facs_dec1c_2d_v1_20240622_120516/states/model_facs_dec1c_2d_v1_473.pth
	Model improved!!!
EPOCH 474/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15736858900560724		[learning rate: 0.0018061]
	Learning Rate: 0.00180605
	LOSS [training: 0.15736858900560724 | validation: 0.14592807633139507]
	TIME [epoch: 36.1 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16003590486189523		[learning rate: 0.0017989]
	Learning Rate: 0.00179887
	LOSS [training: 0.16003590486189523 | validation: 0.1475200361090649]
	TIME [epoch: 36.1 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1514526097866951		[learning rate: 0.0017917]
	Learning Rate: 0.00179172
	LOSS [training: 0.1514526097866951 | validation: 0.1483101127584198]
	TIME [epoch: 36.1 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16586148700708822		[learning rate: 0.0017846]
	Learning Rate: 0.00178459
	LOSS [training: 0.16586148700708822 | validation: 0.15220870339872022]
	TIME [epoch: 36.1 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.156836422352031		[learning rate: 0.0017775]
	Learning Rate: 0.00177749
	LOSS [training: 0.156836422352031 | validation: 0.15061972145783709]
	TIME [epoch: 36.1 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16971378951009006		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.16971378951009006 | validation: 0.15035479982492383]
	TIME [epoch: 36.1 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16075135872476615		[learning rate: 0.0017634]
	Learning Rate: 0.00176338
	LOSS [training: 0.16075135872476615 | validation: 0.1491153745464076]
	TIME [epoch: 36 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1833074063841474		[learning rate: 0.0017564]
	Learning Rate: 0.00175637
	LOSS [training: 0.1833074063841474 | validation: 0.15819583791476888]
	TIME [epoch: 36 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15840485702320795		[learning rate: 0.0017494]
	Learning Rate: 0.00174938
	LOSS [training: 0.15840485702320795 | validation: 0.14744088243966927]
	TIME [epoch: 36 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1696594313704118		[learning rate: 0.0017424]
	Learning Rate: 0.00174242
	LOSS [training: 0.1696594313704118 | validation: 0.1440155655857822]
	TIME [epoch: 36 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15876061586577958		[learning rate: 0.0017355]
	Learning Rate: 0.00173549
	LOSS [training: 0.15876061586577958 | validation: 0.14135035891799613]
	TIME [epoch: 36.1 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16309084304601315		[learning rate: 0.0017286]
	Learning Rate: 0.00172859
	LOSS [training: 0.16309084304601315 | validation: 0.14464147609534267]
	TIME [epoch: 36 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1623648171005411		[learning rate: 0.0017217]
	Learning Rate: 0.00172172
	LOSS [training: 0.1623648171005411 | validation: 0.14756400461203695]
	TIME [epoch: 36 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16978808577472748		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 0.16978808577472748 | validation: 0.15043931156074966]
	TIME [epoch: 36.1 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1683972417756451		[learning rate: 0.001708]
	Learning Rate: 0.00170805
	LOSS [training: 0.1683972417756451 | validation: 0.1453798930712146]
	TIME [epoch: 36.1 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.174258786599725		[learning rate: 0.0017013]
	Learning Rate: 0.00170125
	LOSS [training: 0.174258786599725 | validation: 0.13870834589932257]
	TIME [epoch: 36.1 sec]
	Saving model to: out/model_training/model_facs_dec1c_2d_v1_20240622_120516/states/model_facs_dec1c_2d_v1_489.pth
	Model improved!!!
EPOCH 490/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1706595345166263		[learning rate: 0.0016945]
	Learning Rate: 0.00169449
	LOSS [training: 0.1706595345166263 | validation: 0.15214313873592125]
	TIME [epoch: 36.1 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16964356525516577		[learning rate: 0.0016877]
	Learning Rate: 0.00168775
	LOSS [training: 0.16964356525516577 | validation: 0.14445479458237676]
	TIME [epoch: 36.1 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16039822461061526		[learning rate: 0.001681]
	Learning Rate: 0.00168104
	LOSS [training: 0.16039822461061526 | validation: 0.14517313549096286]
	TIME [epoch: 36 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1534055057622249		[learning rate: 0.0016743]
	Learning Rate: 0.00167435
	LOSS [training: 0.1534055057622249 | validation: 0.14205772120179086]
	TIME [epoch: 36.1 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16537242605801689		[learning rate: 0.0016677]
	Learning Rate: 0.00166769
	LOSS [training: 0.16537242605801689 | validation: 0.14971350706242242]
	TIME [epoch: 36.1 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1757709704786032		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.1757709704786032 | validation: 0.15537204642659455]
	TIME [epoch: 36 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1607371387709344		[learning rate: 0.0016545]
	Learning Rate: 0.00165445
	LOSS [training: 0.1607371387709344 | validation: 0.143807879507201]
	TIME [epoch: 36 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15713170485924502		[learning rate: 0.0016479]
	Learning Rate: 0.00164787
	LOSS [training: 0.15713170485924502 | validation: 0.13983752326906213]
	TIME [epoch: 36 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15858582569659252		[learning rate: 0.0016413]
	Learning Rate: 0.00164132
	LOSS [training: 0.15858582569659252 | validation: 0.14293810129212475]
	TIME [epoch: 36.1 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.182500376523148		[learning rate: 0.0016348]
	Learning Rate: 0.00163479
	LOSS [training: 0.182500376523148 | validation: 0.14695964319728458]
	TIME [epoch: 36.1 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16174566381480016		[learning rate: 0.0016283]
	Learning Rate: 0.00162829
	LOSS [training: 0.16174566381480016 | validation: 0.14511314140867668]
	TIME [epoch: 36.1 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17634124450850372		[learning rate: 0.0016218]
	Learning Rate: 0.00162181
	LOSS [training: 0.17634124450850372 | validation: 0.14705135966615795]
	TIME [epoch: 36.1 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1772664019640694		[learning rate: 0.0016154]
	Learning Rate: 0.00161536
	LOSS [training: 0.1772664019640694 | validation: 0.1419416095743719]
	TIME [epoch: 36.1 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16328448025439715		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 0.16328448025439715 | validation: 0.15168701824422184]
	TIME [epoch: 36 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1660154513969939		[learning rate: 0.0016025]
	Learning Rate: 0.00160254
	LOSS [training: 0.1660154513969939 | validation: 0.14520181918358158]
	TIME [epoch: 36 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17379212858837195		[learning rate: 0.0015962]
	Learning Rate: 0.00159616
	LOSS [training: 0.17379212858837195 | validation: 0.14478840310322647]
	TIME [epoch: 36 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1641569605436325		[learning rate: 0.0015898]
	Learning Rate: 0.00158981
	LOSS [training: 0.1641569605436325 | validation: 0.14390438595016966]
	TIME [epoch: 36 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1662100234938624		[learning rate: 0.0015835]
	Learning Rate: 0.00158349
	LOSS [training: 0.1662100234938624 | validation: 0.14389256231348616]
	TIME [epoch: 36 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1638365065736236		[learning rate: 0.0015772]
	Learning Rate: 0.00157719
	LOSS [training: 0.1638365065736236 | validation: 0.14334074519362267]
	TIME [epoch: 36.1 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1713499167122394		[learning rate: 0.0015709]
	Learning Rate: 0.00157092
	LOSS [training: 0.1713499167122394 | validation: 0.14635859677176571]
	TIME [epoch: 36 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17406549577657643		[learning rate: 0.0015647]
	Learning Rate: 0.00156467
	LOSS [training: 0.17406549577657643 | validation: 0.14197677007524492]
	TIME [epoch: 36.1 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16928862445876025		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.16928862445876025 | validation: 0.1468847114975044]
	TIME [epoch: 36 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15909790423149073		[learning rate: 0.0015522]
	Learning Rate: 0.00155225
	LOSS [training: 0.15909790423149073 | validation: 0.14805125099540223]
	TIME [epoch: 36 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15935091797826603		[learning rate: 0.0015461]
	Learning Rate: 0.00154608
	LOSS [training: 0.15935091797826603 | validation: 0.14354143726842566]
	TIME [epoch: 36 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15219762880315132		[learning rate: 0.0015399]
	Learning Rate: 0.00153993
	LOSS [training: 0.15219762880315132 | validation: 0.1534899293541074]
	TIME [epoch: 36 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16662212202150348		[learning rate: 0.0015338]
	Learning Rate: 0.0015338
	LOSS [training: 0.16662212202150348 | validation: 0.16403291979483198]
	TIME [epoch: 36.1 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17102402972534145		[learning rate: 0.0015277]
	Learning Rate: 0.0015277
	LOSS [training: 0.17102402972534145 | validation: 0.15856170064163128]
	TIME [epoch: 36.1 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15944166998957682		[learning rate: 0.0015216]
	Learning Rate: 0.00152163
	LOSS [training: 0.15944166998957682 | validation: 0.14588705768246496]
	TIME [epoch: 36.1 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16049496349178793		[learning rate: 0.0015156]
	Learning Rate: 0.00151557
	LOSS [training: 0.16049496349178793 | validation: 0.15155439417525848]
	TIME [epoch: 36 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.18991687023215567		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.18991687023215567 | validation: 0.15121912769441317]
	TIME [epoch: 36 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17016684375530608		[learning rate: 0.0015035]
	Learning Rate: 0.00150354
	LOSS [training: 0.17016684375530608 | validation: 0.1547892767440195]
	TIME [epoch: 36 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16988218158537258		[learning rate: 0.0014976]
	Learning Rate: 0.00149756
	LOSS [training: 0.16988218158537258 | validation: 0.14940515119455924]
	TIME [epoch: 36 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17196014213020158		[learning rate: 0.0014916]
	Learning Rate: 0.00149161
	LOSS [training: 0.17196014213020158 | validation: 0.14557800116982383]
	TIME [epoch: 36 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15807657474257983		[learning rate: 0.0014857]
	Learning Rate: 0.00148567
	LOSS [training: 0.15807657474257983 | validation: 0.14547145938108938]
	TIME [epoch: 36.1 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16072988260692794		[learning rate: 0.0014798]
	Learning Rate: 0.00147976
	LOSS [training: 0.16072988260692794 | validation: 0.14811749475155453]
	TIME [epoch: 36 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17051419709116228		[learning rate: 0.0014739]
	Learning Rate: 0.00147388
	LOSS [training: 0.17051419709116228 | validation: 0.14648208535828225]
	TIME [epoch: 36 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16164804736673863		[learning rate: 0.001468]
	Learning Rate: 0.00146802
	LOSS [training: 0.16164804736673863 | validation: 0.14344446186440316]
	TIME [epoch: 36.1 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16946299340440765		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.16946299340440765 | validation: 0.14699332540617782]
	TIME [epoch: 36 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16052185266644628		[learning rate: 0.0014564]
	Learning Rate: 0.00145636
	LOSS [training: 0.16052185266644628 | validation: 0.154138805928969]
	TIME [epoch: 36 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1526047625371654		[learning rate: 0.0014506]
	Learning Rate: 0.00145057
	LOSS [training: 0.1526047625371654 | validation: 0.14175442913930664]
	TIME [epoch: 36 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17271605100858864		[learning rate: 0.0014448]
	Learning Rate: 0.0014448
	LOSS [training: 0.17271605100858864 | validation: 0.1445104179565439]
	TIME [epoch: 36 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15977889707283513		[learning rate: 0.0014391]
	Learning Rate: 0.00143905
	LOSS [training: 0.15977889707283513 | validation: 0.14481921394812267]
	TIME [epoch: 36 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15724387794428		[learning rate: 0.0014333]
	Learning Rate: 0.00143333
	LOSS [training: 0.15724387794428 | validation: 0.14237363046840504]
	TIME [epoch: 36 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.167047224513438		[learning rate: 0.0014276]
	Learning Rate: 0.00142763
	LOSS [training: 0.167047224513438 | validation: 0.1480751802116318]
	TIME [epoch: 36.1 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15801405431470553		[learning rate: 0.001422]
	Learning Rate: 0.00142195
	LOSS [training: 0.15801405431470553 | validation: 0.14392953008227907]
	TIME [epoch: 36 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16387905652021006		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.16387905652021006 | validation: 0.14128238505503934]
	TIME [epoch: 36.1 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1658159526723123		[learning rate: 0.0014107]
	Learning Rate: 0.00141066
	LOSS [training: 0.1658159526723123 | validation: 0.1447773867517914]
	TIME [epoch: 36 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1622313340253325		[learning rate: 0.0014051]
	Learning Rate: 0.00140505
	LOSS [training: 0.1622313340253325 | validation: 0.149900060809092]
	TIME [epoch: 36.1 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1663977148710739		[learning rate: 0.0013995]
	Learning Rate: 0.00139946
	LOSS [training: 0.1663977148710739 | validation: 0.13717428324090097]
	TIME [epoch: 36 sec]
	Saving model to: out/model_training/model_facs_dec1c_2d_v1_20240622_120516/states/model_facs_dec1c_2d_v1_538.pth
	Model improved!!!
EPOCH 539/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17359722360045374		[learning rate: 0.0013939]
	Learning Rate: 0.0013939
	LOSS [training: 0.17359722360045374 | validation: 0.14855359805088703]
	TIME [epoch: 36.1 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16331684648276498		[learning rate: 0.0013884]
	Learning Rate: 0.00138835
	LOSS [training: 0.16331684648276498 | validation: 0.13990041090782662]
	TIME [epoch: 36 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16925101838866644		[learning rate: 0.0013828]
	Learning Rate: 0.00138283
	LOSS [training: 0.16925101838866644 | validation: 0.14684447474195222]
	TIME [epoch: 36.1 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1494545541927167		[learning rate: 0.0013773]
	Learning Rate: 0.00137733
	LOSS [training: 0.1494545541927167 | validation: 0.14259947548397836]
	TIME [epoch: 36 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1528084800610657		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 0.1528084800610657 | validation: 0.14777539792481567]
	TIME [epoch: 36 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1534311572474946		[learning rate: 0.0013664]
	Learning Rate: 0.0013664
	LOSS [training: 0.1534311572474946 | validation: 0.1430845556847892]
	TIME [epoch: 36 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1592572564037503		[learning rate: 0.001361]
	Learning Rate: 0.00136096
	LOSS [training: 0.1592572564037503 | validation: 0.15018411892406158]
	TIME [epoch: 36.1 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16549593273691648		[learning rate: 0.0013555]
	Learning Rate: 0.00135555
	LOSS [training: 0.16549593273691648 | validation: 0.14472782400481052]
	TIME [epoch: 36 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17588918618321112		[learning rate: 0.0013502]
	Learning Rate: 0.00135016
	LOSS [training: 0.17588918618321112 | validation: 0.1444924331154312]
	TIME [epoch: 36 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16231552832429166		[learning rate: 0.0013448]
	Learning Rate: 0.00134479
	LOSS [training: 0.16231552832429166 | validation: 0.15101230617760358]
	TIME [epoch: 36 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15921621433498695		[learning rate: 0.0013394]
	Learning Rate: 0.00133944
	LOSS [training: 0.15921621433498695 | validation: 0.14966081063854722]
	TIME [epoch: 36.1 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16451165821249206		[learning rate: 0.0013341]
	Learning Rate: 0.00133411
	LOSS [training: 0.16451165821249206 | validation: 0.14149449837799058]
	TIME [epoch: 36 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17100124727425423		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.17100124727425423 | validation: 0.14099382666888086]
	TIME [epoch: 36 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16704278930540925		[learning rate: 0.0013235]
	Learning Rate: 0.00132352
	LOSS [training: 0.16704278930540925 | validation: 0.15002540938216874]
	TIME [epoch: 36 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15677492858755776		[learning rate: 0.0013183]
	Learning Rate: 0.00131826
	LOSS [training: 0.15677492858755776 | validation: 0.15153086216056746]
	TIME [epoch: 36.1 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16628902661117606		[learning rate: 0.001313]
	Learning Rate: 0.00131301
	LOSS [training: 0.16628902661117606 | validation: 0.1414303435180461]
	TIME [epoch: 36 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1607859125001642		[learning rate: 0.0013078]
	Learning Rate: 0.00130779
	LOSS [training: 0.1607859125001642 | validation: 0.14664410065563238]
	TIME [epoch: 36 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16383207373482347		[learning rate: 0.0013026]
	Learning Rate: 0.00130259
	LOSS [training: 0.16383207373482347 | validation: 0.1440317372459424]
	TIME [epoch: 36 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15760957419267155		[learning rate: 0.0012974]
	Learning Rate: 0.00129741
	LOSS [training: 0.15760957419267155 | validation: 0.13981730363160733]
	TIME [epoch: 36 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1603261947992372		[learning rate: 0.0012922]
	Learning Rate: 0.00129225
	LOSS [training: 0.1603261947992372 | validation: 0.1429548796178486]
	TIME [epoch: 36 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16694612255271302		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 0.16694612255271302 | validation: 0.1430102391853585]
	TIME [epoch: 36.1 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17895859872985398		[learning rate: 0.001282]
	Learning Rate: 0.00128199
	LOSS [training: 0.17895859872985398 | validation: 0.14013615468706758]
	TIME [epoch: 36 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1633478881979527		[learning rate: 0.0012769]
	Learning Rate: 0.00127689
	LOSS [training: 0.1633478881979527 | validation: 0.14826215007186216]
	TIME [epoch: 36 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15569661403743676		[learning rate: 0.0012718]
	Learning Rate: 0.00127181
	LOSS [training: 0.15569661403743676 | validation: 0.14301347327658478]
	TIME [epoch: 36 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15518680686780872		[learning rate: 0.0012668]
	Learning Rate: 0.00126675
	LOSS [training: 0.15518680686780872 | validation: 0.1487614085976358]
	TIME [epoch: 36 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16005049548283867		[learning rate: 0.0012617]
	Learning Rate: 0.00126172
	LOSS [training: 0.16005049548283867 | validation: 0.1416206515085935]
	TIME [epoch: 36 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16064508099273078		[learning rate: 0.0012567]
	Learning Rate: 0.0012567
	LOSS [training: 0.16064508099273078 | validation: 0.14628389684846654]
	TIME [epoch: 36 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16491607763519445		[learning rate: 0.0012517]
	Learning Rate: 0.0012517
	LOSS [training: 0.16491607763519445 | validation: 0.14664601469972252]
	TIME [epoch: 36 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17208126298534285		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 0.17208126298534285 | validation: 0.15425829698742233]
	TIME [epoch: 36 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1698189286999771		[learning rate: 0.0012418]
	Learning Rate: 0.00124176
	LOSS [training: 0.1698189286999771 | validation: 0.15308789525903538]
	TIME [epoch: 36 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15580609035730114		[learning rate: 0.0012368]
	Learning Rate: 0.00123682
	LOSS [training: 0.15580609035730114 | validation: 0.14964345669478324]
	TIME [epoch: 36 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15916395896044794		[learning rate: 0.0012319]
	Learning Rate: 0.0012319
	LOSS [training: 0.15916395896044794 | validation: 0.14412207156415396]
	TIME [epoch: 36 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1709209574189737		[learning rate: 0.001227]
	Learning Rate: 0.001227
	LOSS [training: 0.1709209574189737 | validation: 0.14859497542835448]
	TIME [epoch: 36 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16533924844928588		[learning rate: 0.0012221]
	Learning Rate: 0.00122212
	LOSS [training: 0.16533924844928588 | validation: 0.14845165509293684]
	TIME [epoch: 36 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16195932817280653		[learning rate: 0.0012173]
	Learning Rate: 0.00121726
	LOSS [training: 0.16195932817280653 | validation: 0.14276965978412393]
	TIME [epoch: 36 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16088583563472897		[learning rate: 0.0012124]
	Learning Rate: 0.00121242
	LOSS [training: 0.16088583563472897 | validation: 0.15184479686416555]
	TIME [epoch: 36 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15817434104931832		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 0.15817434104931832 | validation: 0.14555789547526704]
	TIME [epoch: 36 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15940820833817157		[learning rate: 0.0012028]
	Learning Rate: 0.0012028
	LOSS [training: 0.15940820833817157 | validation: 0.14794136905511676]
	TIME [epoch: 36 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16738485070739792		[learning rate: 0.001198]
	Learning Rate: 0.00119801
	LOSS [training: 0.16738485070739792 | validation: 0.14156555075211194]
	TIME [epoch: 36 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1661975528779479		[learning rate: 0.0011932]
	Learning Rate: 0.00119325
	LOSS [training: 0.1661975528779479 | validation: 0.14685370580982055]
	TIME [epoch: 36 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17276832927078337		[learning rate: 0.0011885]
	Learning Rate: 0.0011885
	LOSS [training: 0.17276832927078337 | validation: 0.14520229478436836]
	TIME [epoch: 36 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15568888922802138		[learning rate: 0.0011838]
	Learning Rate: 0.00118378
	LOSS [training: 0.15568888922802138 | validation: 0.1481729024483918]
	TIME [epoch: 36 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16495064132045012		[learning rate: 0.0011791]
	Learning Rate: 0.00117907
	LOSS [training: 0.16495064132045012 | validation: 0.13512405275339845]
	TIME [epoch: 36 sec]
	Saving model to: out/model_training/model_facs_dec1c_2d_v1_20240622_120516/states/model_facs_dec1c_2d_v1_581.pth
	Model improved!!!
EPOCH 582/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1665136266762811		[learning rate: 0.0011744]
	Learning Rate: 0.00117438
	LOSS [training: 0.1665136266762811 | validation: 0.14012168686669657]
	TIME [epoch: 36 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17099807082975796		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 0.17099807082975796 | validation: 0.13953404773331823]
	TIME [epoch: 36 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15332278183157713		[learning rate: 0.0011651]
	Learning Rate: 0.00116505
	LOSS [training: 0.15332278183157713 | validation: 0.13872349649115862]
	TIME [epoch: 36 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1589722193506182		[learning rate: 0.0011604]
	Learning Rate: 0.00116042
	LOSS [training: 0.1589722193506182 | validation: 0.1395057089098307]
	TIME [epoch: 36 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16727611436759257		[learning rate: 0.0011558]
	Learning Rate: 0.00115581
	LOSS [training: 0.16727611436759257 | validation: 0.14005581008814827]
	TIME [epoch: 36 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15386409734819909		[learning rate: 0.0011512]
	Learning Rate: 0.00115121
	LOSS [training: 0.15386409734819909 | validation: 0.15017310038474313]
	TIME [epoch: 36 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17475190708026733		[learning rate: 0.0011466]
	Learning Rate: 0.00114663
	LOSS [training: 0.17475190708026733 | validation: 0.1451983222040842]
	TIME [epoch: 36 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1536928490058619		[learning rate: 0.0011421]
	Learning Rate: 0.00114207
	LOSS [training: 0.1536928490058619 | validation: 0.1403327369166204]
	TIME [epoch: 36 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17712090137085715		[learning rate: 0.0011375]
	Learning Rate: 0.00113753
	LOSS [training: 0.17712090137085715 | validation: 0.14882776500210954]
	TIME [epoch: 36 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16802156993790868		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.16802156993790868 | validation: 0.14603297390673006]
	TIME [epoch: 36 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15767826082042072		[learning rate: 0.0011285]
	Learning Rate: 0.0011285
	LOSS [training: 0.15767826082042072 | validation: 0.1399747211052224]
	TIME [epoch: 36 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17314350317253552		[learning rate: 0.001124]
	Learning Rate: 0.00112401
	LOSS [training: 0.17314350317253552 | validation: 0.14049221762722494]
	TIME [epoch: 36 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15694593542420682		[learning rate: 0.0011195]
	Learning Rate: 0.00111954
	LOSS [training: 0.15694593542420682 | validation: 0.14456988338580318]
	TIME [epoch: 36 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15261067578349047		[learning rate: 0.0011151]
	Learning Rate: 0.00111508
	LOSS [training: 0.15261067578349047 | validation: 0.1368238957817805]
	TIME [epoch: 36 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17085076336937088		[learning rate: 0.0011106]
	Learning Rate: 0.00111065
	LOSS [training: 0.17085076336937088 | validation: 0.13913177053179462]
	TIME [epoch: 36 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16379398514490595		[learning rate: 0.0011062]
	Learning Rate: 0.00110623
	LOSS [training: 0.16379398514490595 | validation: 0.14681582053426942]
	TIME [epoch: 36 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15328228356556642		[learning rate: 0.0011018]
	Learning Rate: 0.00110183
	LOSS [training: 0.15328228356556642 | validation: 0.14677768731379287]
	TIME [epoch: 36 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16246040790730776		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 0.16246040790730776 | validation: 0.14677138139503312]
	TIME [epoch: 36 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1656817271291363		[learning rate: 0.0010931]
	Learning Rate: 0.00109309
	LOSS [training: 0.1656817271291363 | validation: 0.14563234436461872]
	TIME [epoch: 36 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1653674106951749		[learning rate: 0.0010887]
	Learning Rate: 0.00108874
	LOSS [training: 0.1653674106951749 | validation: 0.14630026994284565]
	TIME [epoch: 36.1 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17078707981257538		[learning rate: 0.0010844]
	Learning Rate: 0.00108441
	LOSS [training: 0.17078707981257538 | validation: 0.1442359532294339]
	TIME [epoch: 36 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17228458854606027		[learning rate: 0.0010801]
	Learning Rate: 0.00108009
	LOSS [training: 0.17228458854606027 | validation: 0.14289208659322875]
	TIME [epoch: 36 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1625755620829181		[learning rate: 0.0010758]
	Learning Rate: 0.0010758
	LOSS [training: 0.1625755620829181 | validation: 0.14074861954343712]
	TIME [epoch: 36.1 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15616160088072786		[learning rate: 0.0010715]
	Learning Rate: 0.00107152
	LOSS [training: 0.15616160088072786 | validation: 0.1513758040717001]
	TIME [epoch: 36 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16750633413054916		[learning rate: 0.0010673]
	Learning Rate: 0.00106726
	LOSS [training: 0.16750633413054916 | validation: 0.1481816514883168]
	TIME [epoch: 36 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16389616322646436		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 0.16389616322646436 | validation: 0.13857963254767086]
	TIME [epoch: 36 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16588741843197022		[learning rate: 0.0010588]
	Learning Rate: 0.00105878
	LOSS [training: 0.16588741843197022 | validation: 0.14402848749489933]
	TIME [epoch: 36.1 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15646064575738525		[learning rate: 0.0010546]
	Learning Rate: 0.00105457
	LOSS [training: 0.15646064575738525 | validation: 0.1580091594304045]
	TIME [epoch: 36 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15947967001053354		[learning rate: 0.0010504]
	Learning Rate: 0.00105038
	LOSS [training: 0.15947967001053354 | validation: 0.14055874044662342]
	TIME [epoch: 36.1 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16072730652664324		[learning rate: 0.0010462]
	Learning Rate: 0.0010462
	LOSS [training: 0.16072730652664324 | validation: 0.14283587393908775]
	TIME [epoch: 36 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16236148417108917		[learning rate: 0.001042]
	Learning Rate: 0.00104204
	LOSS [training: 0.16236148417108917 | validation: 0.15116752569525244]
	TIME [epoch: 36.1 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17663406428050923		[learning rate: 0.0010379]
	Learning Rate: 0.0010379
	LOSS [training: 0.17663406428050923 | validation: 0.1364732652713247]
	TIME [epoch: 36 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17593229869155402		[learning rate: 0.0010338]
	Learning Rate: 0.00103377
	LOSS [training: 0.17593229869155402 | validation: 0.14469631095621424]
	TIME [epoch: 36.1 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16911823112876245		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 0.16911823112876245 | validation: 0.13805731692478257]
	TIME [epoch: 36 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1604865116207341		[learning rate: 0.0010256]
	Learning Rate: 0.00102556
	LOSS [training: 0.1604865116207341 | validation: 0.1461050113823471]
	TIME [epoch: 36.1 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16826788137590207		[learning rate: 0.0010215]
	Learning Rate: 0.00102148
	LOSS [training: 0.16826788137590207 | validation: 0.14305659773753165]
	TIME [epoch: 36.1 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17048903358834744		[learning rate: 0.0010174]
	Learning Rate: 0.00101742
	LOSS [training: 0.17048903358834744 | validation: 0.14701853136935755]
	TIME [epoch: 36.1 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1696705818158103		[learning rate: 0.0010134]
	Learning Rate: 0.00101337
	LOSS [training: 0.1696705818158103 | validation: 0.15497193771326864]
	TIME [epoch: 36.1 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16599975685637702		[learning rate: 0.0010093]
	Learning Rate: 0.00100934
	LOSS [training: 0.16599975685637702 | validation: 0.14855029214329873]
	TIME [epoch: 36.1 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16734497050687652		[learning rate: 0.0010053]
	Learning Rate: 0.00100533
	LOSS [training: 0.16734497050687652 | validation: 0.13525192945728487]
	TIME [epoch: 36 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1590276266874636		[learning rate: 0.0010013]
	Learning Rate: 0.00100133
	LOSS [training: 0.1590276266874636 | validation: 0.14432142965742328]
	TIME [epoch: 36.1 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1579779613749197		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 0.1579779613749197 | validation: 0.14881514884665661]
	TIME [epoch: 36.1 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15807836237683628		[learning rate: 0.00099338]
	Learning Rate: 0.00099338
	LOSS [training: 0.15807836237683628 | validation: 0.1422395596112857]
	TIME [epoch: 36 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15753288885609018		[learning rate: 0.00098943]
	Learning Rate: 0.000989429
	LOSS [training: 0.15753288885609018 | validation: 0.14098070712454822]
	TIME [epoch: 36 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15922043674922193		[learning rate: 0.00098549]
	Learning Rate: 0.000985494
	LOSS [training: 0.15922043674922193 | validation: 0.1424646009311587]
	TIME [epoch: 36 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1557979669440216		[learning rate: 0.00098157]
	Learning Rate: 0.000981574
	LOSS [training: 0.1557979669440216 | validation: 0.14715735890782644]
	TIME [epoch: 36 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15390839475162058		[learning rate: 0.00097767]
	Learning Rate: 0.00097767
	LOSS [training: 0.15390839475162058 | validation: 0.14257025324353748]
	TIME [epoch: 36 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17333383610387196		[learning rate: 0.00097378]
	Learning Rate: 0.000973782
	LOSS [training: 0.17333383610387196 | validation: 0.1419075843967131]
	TIME [epoch: 36.1 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15846456868742276		[learning rate: 0.00096991]
	Learning Rate: 0.000969909
	LOSS [training: 0.15846456868742276 | validation: 0.14689696155035192]
	TIME [epoch: 36 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16103358571539403		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.16103358571539403 | validation: 0.14591928896239695]
	TIME [epoch: 36 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1635153950751496		[learning rate: 0.00096221]
	Learning Rate: 0.000962209
	LOSS [training: 0.1635153950751496 | validation: 0.14807716178316652]
	TIME [epoch: 36 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16060420721124075		[learning rate: 0.00095838]
	Learning Rate: 0.000958382
	LOSS [training: 0.16060420721124075 | validation: 0.1437643465793555]
	TIME [epoch: 36.1 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.157828078682272		[learning rate: 0.00095457]
	Learning Rate: 0.00095457
	LOSS [training: 0.157828078682272 | validation: 0.14814175954581724]
	TIME [epoch: 36 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15631839095613712		[learning rate: 0.00095077]
	Learning Rate: 0.000950773
	LOSS [training: 0.15631839095613712 | validation: 0.1422535956115675]
	TIME [epoch: 36 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1654248001191393		[learning rate: 0.00094699]
	Learning Rate: 0.000946992
	LOSS [training: 0.1654248001191393 | validation: 0.14068058759163002]
	TIME [epoch: 36 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16260891403317843		[learning rate: 0.00094323]
	Learning Rate: 0.000943225
	LOSS [training: 0.16260891403317843 | validation: 0.14391891186529038]
	TIME [epoch: 36 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1677131134793819		[learning rate: 0.00093947]
	Learning Rate: 0.000939474
	LOSS [training: 0.1677131134793819 | validation: 0.1330947353377198]
	TIME [epoch: 36 sec]
	Saving model to: out/model_training/model_facs_dec1c_2d_v1_20240622_120516/states/model_facs_dec1c_2d_v1_638.pth
	Model improved!!!
EPOCH 639/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16107385571412547		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.16107385571412547 | validation: 0.14144778992990528]
	TIME [epoch: 36 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1587837245548109		[learning rate: 0.00093202]
	Learning Rate: 0.000932015
	LOSS [training: 0.1587837245548109 | validation: 0.1423524694911441]
	TIME [epoch: 36 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16781236564365987		[learning rate: 0.00092831]
	Learning Rate: 0.000928309
	LOSS [training: 0.16781236564365987 | validation: 0.13889426722458192]
	TIME [epoch: 36 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15757918357290437		[learning rate: 0.00092462]
	Learning Rate: 0.000924616
	LOSS [training: 0.15757918357290437 | validation: 0.14071670393023866]
	TIME [epoch: 36 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15881781582877785		[learning rate: 0.00092094]
	Learning Rate: 0.000920939
	LOSS [training: 0.15881781582877785 | validation: 0.15012280514753246]
	TIME [epoch: 36 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1572781702912126		[learning rate: 0.00091728]
	Learning Rate: 0.000917276
	LOSS [training: 0.1572781702912126 | validation: 0.13743757641353907]
	TIME [epoch: 36 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1731919896418298		[learning rate: 0.00091363]
	Learning Rate: 0.000913628
	LOSS [training: 0.1731919896418298 | validation: 0.14101515496970296]
	TIME [epoch: 36 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1562752387680444		[learning rate: 0.00090999]
	Learning Rate: 0.000909994
	LOSS [training: 0.1562752387680444 | validation: 0.14969239023949962]
	TIME [epoch: 36 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1652101547935312		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.1652101547935312 | validation: 0.14028087168228304]
	TIME [epoch: 36 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16544708901850985		[learning rate: 0.00090277]
	Learning Rate: 0.00090277
	LOSS [training: 0.16544708901850985 | validation: 0.13978067162643212]
	TIME [epoch: 36 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17617855913547342		[learning rate: 0.00089918]
	Learning Rate: 0.000899179
	LOSS [training: 0.17617855913547342 | validation: 0.14417335415133908]
	TIME [epoch: 36 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1557542149395925		[learning rate: 0.0008956]
	Learning Rate: 0.000895603
	LOSS [training: 0.1557542149395925 | validation: 0.14616287949100842]
	TIME [epoch: 36 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16895977640447965		[learning rate: 0.00089204]
	Learning Rate: 0.000892041
	LOSS [training: 0.16895977640447965 | validation: 0.14707196783316873]
	TIME [epoch: 36 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16601558127841265		[learning rate: 0.00088849]
	Learning Rate: 0.000888493
	LOSS [training: 0.16601558127841265 | validation: 0.1435214529727306]
	TIME [epoch: 36 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16737762073507725		[learning rate: 0.00088496]
	Learning Rate: 0.000884959
	LOSS [training: 0.16737762073507725 | validation: 0.14230045120309381]
	TIME [epoch: 36 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1601563176094825		[learning rate: 0.00088144]
	Learning Rate: 0.000881439
	LOSS [training: 0.1601563176094825 | validation: 0.14027261699521107]
	TIME [epoch: 36 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16202106375281672		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 0.16202106375281672 | validation: 0.14398750263322593]
	TIME [epoch: 36 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16899391138273173		[learning rate: 0.00087444]
	Learning Rate: 0.000874441
	LOSS [training: 0.16899391138273173 | validation: 0.15340959345101238]
	TIME [epoch: 36 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16459036927418727		[learning rate: 0.00087096]
	Learning Rate: 0.000870964
	LOSS [training: 0.16459036927418727 | validation: 0.14439510576305276]
	TIME [epoch: 36 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17145132307529906		[learning rate: 0.0008675]
	Learning Rate: 0.0008675
	LOSS [training: 0.17145132307529906 | validation: 0.15407327799940215]
	TIME [epoch: 36 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15543991835633475		[learning rate: 0.00086405]
	Learning Rate: 0.000864049
	LOSS [training: 0.15543991835633475 | validation: 0.14262731957505614]
	TIME [epoch: 36 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1589655456390482		[learning rate: 0.00086061]
	Learning Rate: 0.000860613
	LOSS [training: 0.1589655456390482 | validation: 0.14791222249587707]
	TIME [epoch: 36 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16608998954871287		[learning rate: 0.00085719]
	Learning Rate: 0.00085719
	LOSS [training: 0.16608998954871287 | validation: 0.14889070991654982]
	TIME [epoch: 36 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16043757677855688		[learning rate: 0.00085378]
	Learning Rate: 0.00085378
	LOSS [training: 0.16043757677855688 | validation: 0.1479644035004131]
	TIME [epoch: 36 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16377669938719425		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 0.16377669938719425 | validation: 0.15300915756913303]
	TIME [epoch: 36 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17676406396641245		[learning rate: 0.000847]
	Learning Rate: 0.000847002
	LOSS [training: 0.17676406396641245 | validation: 0.14915654688510624]
	TIME [epoch: 36 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1663536905004229		[learning rate: 0.00084363]
	Learning Rate: 0.000843634
	LOSS [training: 0.1663536905004229 | validation: 0.14482537867309228]
	TIME [epoch: 36 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15970855485648425		[learning rate: 0.00084028]
	Learning Rate: 0.000840278
	LOSS [training: 0.15970855485648425 | validation: 0.14041961577428422]
	TIME [epoch: 36 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16542934150866925		[learning rate: 0.00083694]
	Learning Rate: 0.000836936
	LOSS [training: 0.16542934150866925 | validation: 0.14651452540886628]
	TIME [epoch: 36 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15543890190907483		[learning rate: 0.00083361]
	Learning Rate: 0.000833608
	LOSS [training: 0.15543890190907483 | validation: 0.1464234523436763]
	TIME [epoch: 36 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15698435505967162		[learning rate: 0.00083029]
	Learning Rate: 0.000830292
	LOSS [training: 0.15698435505967162 | validation: 0.14437221356930854]
	TIME [epoch: 36 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15918775085829115		[learning rate: 0.00082699]
	Learning Rate: 0.00082699
	LOSS [training: 0.15918775085829115 | validation: 0.14181336779670095]
	TIME [epoch: 36 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17153417077643943		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.17153417077643943 | validation: 0.14707273143304672]
	TIME [epoch: 36 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15909622591492947		[learning rate: 0.00082042]
	Learning Rate: 0.000820424
	LOSS [training: 0.15909622591492947 | validation: 0.14428901629403876]
	TIME [epoch: 36 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16555030510705324		[learning rate: 0.00081716]
	Learning Rate: 0.000817161
	LOSS [training: 0.16555030510705324 | validation: 0.14138828833995948]
	TIME [epoch: 36 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16221764322565171		[learning rate: 0.00081391]
	Learning Rate: 0.000813911
	LOSS [training: 0.16221764322565171 | validation: 0.14749064229463016]
	TIME [epoch: 36 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15696185453499928		[learning rate: 0.00081067]
	Learning Rate: 0.000810674
	LOSS [training: 0.15696185453499928 | validation: 0.14115221730234997]
	TIME [epoch: 36 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.18108897006164187		[learning rate: 0.00080745]
	Learning Rate: 0.00080745
	LOSS [training: 0.18108897006164187 | validation: 0.15049693785696214]
	TIME [epoch: 36 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15634509739026012		[learning rate: 0.00080424]
	Learning Rate: 0.000804238
	LOSS [training: 0.15634509739026012 | validation: 0.135468504979338]
	TIME [epoch: 36 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16230409453922828		[learning rate: 0.00080104]
	Learning Rate: 0.000801039
	LOSS [training: 0.16230409453922828 | validation: 0.1422506669654781]
	TIME [epoch: 36 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1666598866688862		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 0.1666598866688862 | validation: 0.13977433759909902]
	TIME [epoch: 36 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16528833162143822		[learning rate: 0.00079468]
	Learning Rate: 0.00079468
	LOSS [training: 0.16528833162143822 | validation: 0.143310458279645]
	TIME [epoch: 36 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17122156008938622		[learning rate: 0.00079152]
	Learning Rate: 0.000791519
	LOSS [training: 0.17122156008938622 | validation: 0.14197563818389036]
	TIME [epoch: 36 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15818132435515336		[learning rate: 0.00078837]
	Learning Rate: 0.000788371
	LOSS [training: 0.15818132435515336 | validation: 0.15061516561608457]
	TIME [epoch: 36 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15613418780615979		[learning rate: 0.00078524]
	Learning Rate: 0.000785236
	LOSS [training: 0.15613418780615979 | validation: 0.14667644107134975]
	TIME [epoch: 36 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1658368837348658		[learning rate: 0.00078211]
	Learning Rate: 0.000782113
	LOSS [training: 0.1658368837348658 | validation: 0.14193402133045893]
	TIME [epoch: 36 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1662923077143924		[learning rate: 0.000779]
	Learning Rate: 0.000779002
	LOSS [training: 0.1662923077143924 | validation: 0.14567645292108616]
	TIME [epoch: 36 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1596254243933632		[learning rate: 0.0007759]
	Learning Rate: 0.000775904
	LOSS [training: 0.1596254243933632 | validation: 0.14163886229962924]
	TIME [epoch: 36 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15553169980383627		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 0.15553169980383627 | validation: 0.14919728563526444]
	TIME [epoch: 36 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15634944576167234		[learning rate: 0.00076974]
	Learning Rate: 0.000769744
	LOSS [training: 0.15634944576167234 | validation: 0.14268140329395346]
	TIME [epoch: 36 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15365476565560798		[learning rate: 0.00076668]
	Learning Rate: 0.000766682
	LOSS [training: 0.15365476565560798 | validation: 0.14303003225103436]
	TIME [epoch: 36 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16851494393091201		[learning rate: 0.00076363]
	Learning Rate: 0.000763633
	LOSS [training: 0.16851494393091201 | validation: 0.13762396378820016]
	TIME [epoch: 36 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15555666869236928		[learning rate: 0.0007606]
	Learning Rate: 0.000760596
	LOSS [training: 0.15555666869236928 | validation: 0.14652477854882934]
	TIME [epoch: 36 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16846995149332442		[learning rate: 0.00075757]
	Learning Rate: 0.000757571
	LOSS [training: 0.16846995149332442 | validation: 0.1385636228295429]
	TIME [epoch: 36 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16838518215593468		[learning rate: 0.00075456]
	Learning Rate: 0.000754557
	LOSS [training: 0.16838518215593468 | validation: 0.148124307180202]
	TIME [epoch: 36 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16291917890128021		[learning rate: 0.00075156]
	Learning Rate: 0.000751556
	LOSS [training: 0.16291917890128021 | validation: 0.14271896638377804]
	TIME [epoch: 36 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16417441382309234		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 0.16417441382309234 | validation: 0.13728033061596062]
	TIME [epoch: 36.1 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16774440265265847		[learning rate: 0.00074559]
	Learning Rate: 0.00074559
	LOSS [training: 0.16774440265265847 | validation: 0.14954490069550794]
	TIME [epoch: 36 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16517561488899885		[learning rate: 0.00074262]
	Learning Rate: 0.000742624
	LOSS [training: 0.16517561488899885 | validation: 0.13567476487872354]
	TIME [epoch: 36 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15645223736636021		[learning rate: 0.00073967]
	Learning Rate: 0.000739671
	LOSS [training: 0.15645223736636021 | validation: 0.14225159025641312]
	TIME [epoch: 36 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1739425878185255		[learning rate: 0.00073673]
	Learning Rate: 0.000736729
	LOSS [training: 0.1739425878185255 | validation: 0.14559669945170964]
	TIME [epoch: 36 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16237742471095995		[learning rate: 0.0007338]
	Learning Rate: 0.000733799
	LOSS [training: 0.16237742471095995 | validation: 0.1414743590681108]
	TIME [epoch: 36 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1562947351864566		[learning rate: 0.00073088]
	Learning Rate: 0.00073088
	LOSS [training: 0.1562947351864566 | validation: 0.14688221032237203]
	TIME [epoch: 36.1 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16130531970990594		[learning rate: 0.00072797]
	Learning Rate: 0.000727973
	LOSS [training: 0.16130531970990594 | validation: 0.1440271512827326]
	TIME [epoch: 36 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1613903558572528		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 0.1613903558572528 | validation: 0.148419818398873]
	TIME [epoch: 36 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15277413634051162		[learning rate: 0.00072219]
	Learning Rate: 0.000722194
	LOSS [training: 0.15277413634051162 | validation: 0.14112347423305865]
	TIME [epoch: 36 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15973342454248737		[learning rate: 0.00071932]
	Learning Rate: 0.000719322
	LOSS [training: 0.15973342454248737 | validation: 0.14183315207134756]
	TIME [epoch: 36 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17489735192170192		[learning rate: 0.00071646]
	Learning Rate: 0.000716461
	LOSS [training: 0.17489735192170192 | validation: 0.1442824077416721]
	TIME [epoch: 36 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15419145260783107		[learning rate: 0.00071361]
	Learning Rate: 0.000713611
	LOSS [training: 0.15419145260783107 | validation: 0.14996887810334691]
	TIME [epoch: 36 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16785592306177605		[learning rate: 0.00071077]
	Learning Rate: 0.000710773
	LOSS [training: 0.16785592306177605 | validation: 0.1458666230618957]
	TIME [epoch: 36 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16456307885574986		[learning rate: 0.00070795]
	Learning Rate: 0.000707946
	LOSS [training: 0.16456307885574986 | validation: 0.14748705756242556]
	TIME [epoch: 36 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15600870948219386		[learning rate: 0.00070513]
	Learning Rate: 0.00070513
	LOSS [training: 0.15600870948219386 | validation: 0.14709200400228178]
	TIME [epoch: 36 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16033970655799007		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.16033970655799007 | validation: 0.1436953037503101]
	TIME [epoch: 36 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15272216277540654		[learning rate: 0.00069953]
	Learning Rate: 0.000699532
	LOSS [training: 0.15272216277540654 | validation: 0.14587691542409303]
	TIME [epoch: 36 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16154868031472683		[learning rate: 0.00069675]
	Learning Rate: 0.00069675
	LOSS [training: 0.16154868031472683 | validation: 0.1391003344169494]
	TIME [epoch: 36 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1663961553576469		[learning rate: 0.00069398]
	Learning Rate: 0.000693979
	LOSS [training: 0.1663961553576469 | validation: 0.14498658732735786]
	TIME [epoch: 36 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16989174574412635		[learning rate: 0.00069122]
	Learning Rate: 0.000691219
	LOSS [training: 0.16989174574412635 | validation: 0.14555732228478255]
	TIME [epoch: 36 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16191511698920869		[learning rate: 0.00068847]
	Learning Rate: 0.000688469
	LOSS [training: 0.16191511698920869 | validation: 0.13992364961147966]
	TIME [epoch: 36 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1801707583634556		[learning rate: 0.00068573]
	Learning Rate: 0.000685731
	LOSS [training: 0.1801707583634556 | validation: 0.14355270807394446]
	TIME [epoch: 36 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16540177660354835		[learning rate: 0.000683]
	Learning Rate: 0.000683004
	LOSS [training: 0.16540177660354835 | validation: 0.14796210966239762]
	TIME [epoch: 36 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15506579091412653		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 0.15506579091412653 | validation: 0.13751524316795058]
	TIME [epoch: 36.1 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16953706867026366		[learning rate: 0.00067758]
	Learning Rate: 0.000677582
	LOSS [training: 0.16953706867026366 | validation: 0.13809225165083291]
	TIME [epoch: 36 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15226968289716314		[learning rate: 0.00067489]
	Learning Rate: 0.000674887
	LOSS [training: 0.15226968289716314 | validation: 0.14126465578606645]
	TIME [epoch: 36 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17399613557229865		[learning rate: 0.0006722]
	Learning Rate: 0.000672202
	LOSS [training: 0.17399613557229865 | validation: 0.13615243491098036]
	TIME [epoch: 36 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17138574602268442		[learning rate: 0.00066953]
	Learning Rate: 0.000669529
	LOSS [training: 0.17138574602268442 | validation: 0.14997392675750806]
	TIME [epoch: 36 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15892171775577837		[learning rate: 0.00066687]
	Learning Rate: 0.000666866
	LOSS [training: 0.15892171775577837 | validation: 0.1513957399378892]
	TIME [epoch: 36 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17211710501207947		[learning rate: 0.00066421]
	Learning Rate: 0.000664213
	LOSS [training: 0.17211710501207947 | validation: 0.13820081935762724]
	TIME [epoch: 36 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.18663155682527882		[learning rate: 0.00066157]
	Learning Rate: 0.000661572
	LOSS [training: 0.18663155682527882 | validation: 0.14681084065051567]
	TIME [epoch: 36 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17879612963108263		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 0.17879612963108263 | validation: 0.13795361708282944]
	TIME [epoch: 36 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17591682460647476		[learning rate: 0.00065632]
	Learning Rate: 0.00065632
	LOSS [training: 0.17591682460647476 | validation: 0.13679736724869557]
	TIME [epoch: 36 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16437233107481855		[learning rate: 0.00065371]
	Learning Rate: 0.000653709
	LOSS [training: 0.16437233107481855 | validation: 0.15038588066344288]
	TIME [epoch: 36 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15719509833212886		[learning rate: 0.00065111]
	Learning Rate: 0.000651109
	LOSS [training: 0.15719509833212886 | validation: 0.1487308919520059]
	TIME [epoch: 36 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16057155735389506		[learning rate: 0.00064852]
	Learning Rate: 0.00064852
	LOSS [training: 0.16057155735389506 | validation: 0.14424944483808752]
	TIME [epoch: 36 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16786667233163222		[learning rate: 0.00064594]
	Learning Rate: 0.00064594
	LOSS [training: 0.16786667233163222 | validation: 0.14654142286891453]
	TIME [epoch: 36 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16791952111219174		[learning rate: 0.00064337]
	Learning Rate: 0.000643371
	LOSS [training: 0.16791952111219174 | validation: 0.14587964434512027]
	TIME [epoch: 36 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15189986760483756		[learning rate: 0.00064081]
	Learning Rate: 0.000640812
	LOSS [training: 0.15189986760483756 | validation: 0.1397158163901765]
	TIME [epoch: 36.1 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.182947114339028		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 0.182947114339028 | validation: 0.14810176225410582]
	TIME [epoch: 36 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1586488488063998		[learning rate: 0.00063572]
	Learning Rate: 0.000635725
	LOSS [training: 0.1586488488063998 | validation: 0.14094894179118342]
	TIME [epoch: 36 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16530701876111167		[learning rate: 0.0006332]
	Learning Rate: 0.000633196
	LOSS [training: 0.16530701876111167 | validation: 0.13972578827132562]
	TIME [epoch: 36.1 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16027412406450528		[learning rate: 0.00063068]
	Learning Rate: 0.000630678
	LOSS [training: 0.16027412406450528 | validation: 0.14311045921926366]
	TIME [epoch: 36 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17822027940804236		[learning rate: 0.00062817]
	Learning Rate: 0.00062817
	LOSS [training: 0.17822027940804236 | validation: 0.1416701988859974]
	TIME [epoch: 36.1 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16092459640298276		[learning rate: 0.00062567]
	Learning Rate: 0.000625671
	LOSS [training: 0.16092459640298276 | validation: 0.13939608691251687]
	TIME [epoch: 36.1 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15809281135105693		[learning rate: 0.00062318]
	Learning Rate: 0.000623183
	LOSS [training: 0.15809281135105693 | validation: 0.14375591235500623]
	TIME [epoch: 36.1 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1609207048654494		[learning rate: 0.0006207]
	Learning Rate: 0.000620704
	LOSS [training: 0.1609207048654494 | validation: 0.14601431623296235]
	TIME [epoch: 36 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15780518058408843		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 0.15780518058408843 | validation: 0.14052898873874162]
	TIME [epoch: 36.1 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16087261839761682		[learning rate: 0.00061578]
	Learning Rate: 0.000615777
	LOSS [training: 0.16087261839761682 | validation: 0.13679217699752075]
	TIME [epoch: 36.1 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14544600778297612		[learning rate: 0.00061333]
	Learning Rate: 0.000613327
	LOSS [training: 0.14544600778297612 | validation: 0.13921815192380677]
	TIME [epoch: 36.1 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1616230603903883		[learning rate: 0.00061089]
	Learning Rate: 0.000610888
	LOSS [training: 0.1616230603903883 | validation: 0.14185937092284734]
	TIME [epoch: 36 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1660626655627987		[learning rate: 0.00060846]
	Learning Rate: 0.000608458
	LOSS [training: 0.1660626655627987 | validation: 0.14878461131320442]
	TIME [epoch: 36.1 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1673489986230875		[learning rate: 0.00060604]
	Learning Rate: 0.000606038
	LOSS [training: 0.1673489986230875 | validation: 0.14105157189214537]
	TIME [epoch: 36 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16731984579660278		[learning rate: 0.00060363]
	Learning Rate: 0.000603628
	LOSS [training: 0.16731984579660278 | validation: 0.14023654352874315]
	TIME [epoch: 36 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1527623650963345		[learning rate: 0.00060123]
	Learning Rate: 0.000601227
	LOSS [training: 0.1527623650963345 | validation: 0.14155326051206188]
	TIME [epoch: 36 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16713392756916987		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.16713392756916987 | validation: 0.13211837430392817]
	TIME [epoch: 36 sec]
	Saving model to: out/model_training/model_facs_dec1c_2d_v1_20240622_120516/states/model_facs_dec1c_2d_v1_751.pth
	Model improved!!!
EPOCH 752/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1526560165925763		[learning rate: 0.00059645]
	Learning Rate: 0.000596454
	LOSS [training: 0.1526560165925763 | validation: 0.14413930977465175]
	TIME [epoch: 36.1 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15624127806849414		[learning rate: 0.00059408]
	Learning Rate: 0.000594082
	LOSS [training: 0.15624127806849414 | validation: 0.1453214879797993]
	TIME [epoch: 36 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16178994766033566		[learning rate: 0.00059172]
	Learning Rate: 0.000591719
	LOSS [training: 0.16178994766033566 | validation: 0.13900388797017613]
	TIME [epoch: 36 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1670207150266864		[learning rate: 0.00058937]
	Learning Rate: 0.000589365
	LOSS [training: 0.1670207150266864 | validation: 0.14500082405679204]
	TIME [epoch: 36.1 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15520343824131		[learning rate: 0.00058702]
	Learning Rate: 0.000587021
	LOSS [training: 0.15520343824131 | validation: 0.13861815288565302]
	TIME [epoch: 36.1 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.18247368305061196		[learning rate: 0.00058469]
	Learning Rate: 0.000584687
	LOSS [training: 0.18247368305061196 | validation: 0.1459705364392781]
	TIME [epoch: 36.1 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1610494403470149		[learning rate: 0.00058236]
	Learning Rate: 0.000582361
	LOSS [training: 0.1610494403470149 | validation: 0.1430575325400199]
	TIME [epoch: 36 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16621462902914882		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 0.16621462902914882 | validation: 0.14557784822567355]
	TIME [epoch: 36 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15982230996386246		[learning rate: 0.00057774]
	Learning Rate: 0.000577738
	LOSS [training: 0.15982230996386246 | validation: 0.14307904194867646]
	TIME [epoch: 36 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15132225265871618		[learning rate: 0.00057544]
	Learning Rate: 0.00057544
	LOSS [training: 0.15132225265871618 | validation: 0.14474942744980296]
	TIME [epoch: 36 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16518936029235842		[learning rate: 0.00057315]
	Learning Rate: 0.000573151
	LOSS [training: 0.16518936029235842 | validation: 0.14145358543659575]
	TIME [epoch: 36 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17411561839860978		[learning rate: 0.00057087]
	Learning Rate: 0.000570872
	LOSS [training: 0.17411561839860978 | validation: 0.14713239312255208]
	TIME [epoch: 36 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15886418384444456		[learning rate: 0.0005686]
	Learning Rate: 0.000568601
	LOSS [training: 0.15886418384444456 | validation: 0.1443130425531148]
	TIME [epoch: 36 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16289807480805493		[learning rate: 0.00056634]
	Learning Rate: 0.00056634
	LOSS [training: 0.16289807480805493 | validation: 0.14286211548772831]
	TIME [epoch: 36 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14923196791103718		[learning rate: 0.00056409]
	Learning Rate: 0.000564087
	LOSS [training: 0.14923196791103718 | validation: 0.13989035290064855]
	TIME [epoch: 36 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1581628130557823		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 0.1581628130557823 | validation: 0.14566885948274128]
	TIME [epoch: 36.1 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1756876224414594		[learning rate: 0.00055961]
	Learning Rate: 0.000559609
	LOSS [training: 0.1756876224414594 | validation: 0.1552156755543579]
	TIME [epoch: 36 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16268801185457488		[learning rate: 0.00055738]
	Learning Rate: 0.000557383
	LOSS [training: 0.16268801185457488 | validation: 0.145953652250806]
	TIME [epoch: 36.1 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16173534602313192		[learning rate: 0.00055517]
	Learning Rate: 0.000555166
	LOSS [training: 0.16173534602313192 | validation: 0.14105488718761378]
	TIME [epoch: 36 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17441881048687957		[learning rate: 0.00055296]
	Learning Rate: 0.000552958
	LOSS [training: 0.17441881048687957 | validation: 0.1494607672685302]
	TIME [epoch: 36.1 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17546743132450954		[learning rate: 0.00055076]
	Learning Rate: 0.000550759
	LOSS [training: 0.17546743132450954 | validation: 0.14044576962924654]
	TIME [epoch: 36.1 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16158516788850794		[learning rate: 0.00054857]
	Learning Rate: 0.000548568
	LOSS [training: 0.16158516788850794 | validation: 0.1425392405357]
	TIME [epoch: 36 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.18112366521207865		[learning rate: 0.00054639]
	Learning Rate: 0.000546387
	LOSS [training: 0.18112366521207865 | validation: 0.1370379337327885]
	TIME [epoch: 36 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1591489149479866		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 0.1591489149479866 | validation: 0.142716767333888]
	TIME [epoch: 36 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.18107153277841123		[learning rate: 0.00054205]
	Learning Rate: 0.000542049
	LOSS [training: 0.18107153277841123 | validation: 0.14516578058586385]
	TIME [epoch: 36.1 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16061464585987772		[learning rate: 0.00053989]
	Learning Rate: 0.000539893
	LOSS [training: 0.16061464585987772 | validation: 0.14208992791371558]
	TIME [epoch: 36.1 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15329235232842875		[learning rate: 0.00053775]
	Learning Rate: 0.000537746
	LOSS [training: 0.15329235232842875 | validation: 0.14372085680446878]
	TIME [epoch: 36 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15553893285122483		[learning rate: 0.00053561]
	Learning Rate: 0.000535607
	LOSS [training: 0.15553893285122483 | validation: 0.13581221023306722]
	TIME [epoch: 36.1 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16348418558915134		[learning rate: 0.00053348]
	Learning Rate: 0.000533477
	LOSS [training: 0.16348418558915134 | validation: 0.14217252674535863]
	TIME [epoch: 36 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15799853746066728		[learning rate: 0.00053135]
	Learning Rate: 0.000531355
	LOSS [training: 0.15799853746066728 | validation: 0.14410031456727107]
	TIME [epoch: 36 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15464888558361345		[learning rate: 0.00052924]
	Learning Rate: 0.000529241
	LOSS [training: 0.15464888558361345 | validation: 0.13570707596370174]
	TIME [epoch: 36 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16279273227062818		[learning rate: 0.00052714]
	Learning Rate: 0.000527136
	LOSS [training: 0.16279273227062818 | validation: 0.14663030947034242]
	TIME [epoch: 36 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15401565253484825		[learning rate: 0.00052504]
	Learning Rate: 0.00052504
	LOSS [training: 0.15401565253484825 | validation: 0.15019768074576642]
	TIME [epoch: 36.1 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15667306766459643		[learning rate: 0.00052295]
	Learning Rate: 0.000522952
	LOSS [training: 0.15667306766459643 | validation: 0.14375307927543424]
	TIME [epoch: 36.1 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1557518998185394		[learning rate: 0.00052087]
	Learning Rate: 0.000520872
	LOSS [training: 0.1557518998185394 | validation: 0.14292952371553372]
	TIME [epoch: 36.1 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15595735465788682		[learning rate: 0.0005188]
	Learning Rate: 0.0005188
	LOSS [training: 0.15595735465788682 | validation: 0.1380647729688025]
	TIME [epoch: 36.1 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16735422763746255		[learning rate: 0.00051674]
	Learning Rate: 0.000516737
	LOSS [training: 0.16735422763746255 | validation: 0.1429088436048652]
	TIME [epoch: 36.1 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1651518944744274		[learning rate: 0.00051468]
	Learning Rate: 0.000514681
	LOSS [training: 0.1651518944744274 | validation: 0.14031438771889154]
	TIME [epoch: 36.1 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1591341159775697		[learning rate: 0.00051263]
	Learning Rate: 0.000512634
	LOSS [training: 0.1591341159775697 | validation: 0.14252824462610325]
	TIME [epoch: 36.1 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17326471435388952		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 0.17326471435388952 | validation: 0.13780840770662844]
	TIME [epoch: 36.1 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1490975048201031		[learning rate: 0.00050856]
	Learning Rate: 0.000508565
	LOSS [training: 0.1490975048201031 | validation: 0.1429967075765497]
	TIME [epoch: 36 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15459571296420213		[learning rate: 0.00050654]
	Learning Rate: 0.000506542
	LOSS [training: 0.15459571296420213 | validation: 0.14217445865301584]
	TIME [epoch: 36.1 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16998787600313803		[learning rate: 0.00050453]
	Learning Rate: 0.000504527
	LOSS [training: 0.16998787600313803 | validation: 0.13711557933550664]
	TIME [epoch: 36.1 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1572537920300428		[learning rate: 0.00050252]
	Learning Rate: 0.000502521
	LOSS [training: 0.1572537920300428 | validation: 0.1457691430948372]
	TIME [epoch: 36.1 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16172756201834307		[learning rate: 0.00050052]
	Learning Rate: 0.000500522
	LOSS [training: 0.16172756201834307 | validation: 0.13421937060235845]
	TIME [epoch: 36 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1541606003905286		[learning rate: 0.00049853]
	Learning Rate: 0.000498531
	LOSS [training: 0.1541606003905286 | validation: 0.14238807545400237]
	TIME [epoch: 36 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1653201258266426		[learning rate: 0.00049655]
	Learning Rate: 0.000496548
	LOSS [training: 0.1653201258266426 | validation: 0.14197439752826085]
	TIME [epoch: 36 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16482892474213362		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 0.16482892474213362 | validation: 0.14155452298399765]
	TIME [epoch: 36.1 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16619517707370315		[learning rate: 0.00049261]
	Learning Rate: 0.000492606
	LOSS [training: 0.16619517707370315 | validation: 0.15240877216209217]
	TIME [epoch: 36 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16095181218208826		[learning rate: 0.00049065]
	Learning Rate: 0.000490647
	LOSS [training: 0.16095181218208826 | validation: 0.14509356636552]
	TIME [epoch: 36.1 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15787039856753018		[learning rate: 0.0004887]
	Learning Rate: 0.000488696
	LOSS [training: 0.15787039856753018 | validation: 0.14197368596788956]
	TIME [epoch: 36 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15564812280603554		[learning rate: 0.00048675]
	Learning Rate: 0.000486752
	LOSS [training: 0.15564812280603554 | validation: 0.1449518579372943]
	TIME [epoch: 36.1 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16067796762296657		[learning rate: 0.00048482]
	Learning Rate: 0.000484816
	LOSS [training: 0.16067796762296657 | validation: 0.1476946001155106]
	TIME [epoch: 36.1 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1566732796681439		[learning rate: 0.00048289]
	Learning Rate: 0.000482888
	LOSS [training: 0.1566732796681439 | validation: 0.14011930961004931]
	TIME [epoch: 36.1 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15406701187672373		[learning rate: 0.00048097]
	Learning Rate: 0.000480967
	LOSS [training: 0.15406701187672373 | validation: 0.1444464135131365]
	TIME [epoch: 36 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16167475233780063		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 0.16167475233780063 | validation: 0.1389028726457034]
	TIME [epoch: 36.1 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15847191591932885		[learning rate: 0.00047715]
	Learning Rate: 0.000477149
	LOSS [training: 0.15847191591932885 | validation: 0.14252407320722393]
	TIME [epoch: 36 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17098998939454313		[learning rate: 0.00047525]
	Learning Rate: 0.000475251
	LOSS [training: 0.17098998939454313 | validation: 0.14022112095701497]
	TIME [epoch: 36.1 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15575865468732658		[learning rate: 0.00047336]
	Learning Rate: 0.000473361
	LOSS [training: 0.15575865468732658 | validation: 0.13920852584039003]
	TIME [epoch: 36 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16078667507364847		[learning rate: 0.00047148]
	Learning Rate: 0.000471478
	LOSS [training: 0.16078667507364847 | validation: 0.13876369960197707]
	TIME [epoch: 36.1 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15850681032920397		[learning rate: 0.0004696]
	Learning Rate: 0.000469603
	LOSS [training: 0.15850681032920397 | validation: 0.1486466582259514]
	TIME [epoch: 36.1 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15489333036450625		[learning rate: 0.00046774]
	Learning Rate: 0.000467735
	LOSS [training: 0.15489333036450625 | validation: 0.142401405625582]
	TIME [epoch: 36.1 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15543277986292814		[learning rate: 0.00046587]
	Learning Rate: 0.000465875
	LOSS [training: 0.15543277986292814 | validation: 0.142791070654751]
	TIME [epoch: 36.1 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17586933868645357		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 0.17586933868645357 | validation: 0.14450504528533234]
	TIME [epoch: 36.1 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1716356138302555		[learning rate: 0.00046218]
	Learning Rate: 0.000462176
	LOSS [training: 0.1716356138302555 | validation: 0.13989026794290704]
	TIME [epoch: 36.1 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15731193647216676		[learning rate: 0.00046034]
	Learning Rate: 0.000460338
	LOSS [training: 0.15731193647216676 | validation: 0.1407427026342523]
	TIME [epoch: 36.1 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1544238967948046		[learning rate: 0.00045851]
	Learning Rate: 0.000458507
	LOSS [training: 0.1544238967948046 | validation: 0.14648144882513664]
	TIME [epoch: 36 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1582798014913804		[learning rate: 0.00045668]
	Learning Rate: 0.000456684
	LOSS [training: 0.1582798014913804 | validation: 0.14687830318433692]
	TIME [epoch: 36.1 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1656256558349217		[learning rate: 0.00045487]
	Learning Rate: 0.000454867
	LOSS [training: 0.1656256558349217 | validation: 0.14170471581743643]
	TIME [epoch: 36 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15508762643499813		[learning rate: 0.00045306]
	Learning Rate: 0.000453058
	LOSS [training: 0.15508762643499813 | validation: 0.14484392629351897]
	TIME [epoch: 36.1 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15645153175108767		[learning rate: 0.00045126]
	Learning Rate: 0.000451256
	LOSS [training: 0.15645153175108767 | validation: 0.1391380147267875]
	TIME [epoch: 36 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17449226457002584		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 0.17449226457002584 | validation: 0.14448393026593587]
	TIME [epoch: 36.1 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16297505611881238		[learning rate: 0.00044767]
	Learning Rate: 0.000447674
	LOSS [training: 0.16297505611881238 | validation: 0.1476988940391047]
	TIME [epoch: 36 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16593389404342174		[learning rate: 0.00044589]
	Learning Rate: 0.000445893
	LOSS [training: 0.16593389404342174 | validation: 0.1415848982042697]
	TIME [epoch: 36 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1613815243999056		[learning rate: 0.00044412]
	Learning Rate: 0.00044412
	LOSS [training: 0.1613815243999056 | validation: 0.14454636051605868]
	TIME [epoch: 36.1 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1523201359444963		[learning rate: 0.00044235]
	Learning Rate: 0.000442353
	LOSS [training: 0.1523201359444963 | validation: 0.13881144663680983]
	TIME [epoch: 36.1 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17058049859030464		[learning rate: 0.00044059]
	Learning Rate: 0.000440594
	LOSS [training: 0.17058049859030464 | validation: 0.14662880029613748]
	TIME [epoch: 36 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1580563462922158		[learning rate: 0.00043884]
	Learning Rate: 0.000438842
	LOSS [training: 0.1580563462922158 | validation: 0.13903930616016275]
	TIME [epoch: 36 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16682025902580977		[learning rate: 0.0004371]
	Learning Rate: 0.000437096
	LOSS [training: 0.16682025902580977 | validation: 0.14254849144991424]
	TIME [epoch: 36 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16219885883652355		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 0.16219885883652355 | validation: 0.1370470135418122]
	TIME [epoch: 36.1 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.167857512083225		[learning rate: 0.00043363]
	Learning Rate: 0.000433626
	LOSS [training: 0.167857512083225 | validation: 0.14258009061726484]
	TIME [epoch: 36.1 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16076972264824438		[learning rate: 0.0004319]
	Learning Rate: 0.000431901
	LOSS [training: 0.16076972264824438 | validation: 0.14761480535443794]
	TIME [epoch: 36.1 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15206835364294344		[learning rate: 0.00043018]
	Learning Rate: 0.000430184
	LOSS [training: 0.15206835364294344 | validation: 0.1392141160937692]
	TIME [epoch: 36 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.18144173579021425		[learning rate: 0.00042847]
	Learning Rate: 0.000428473
	LOSS [training: 0.18144173579021425 | validation: 0.14147175801936623]
	TIME [epoch: 36 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15569072135866657		[learning rate: 0.00042677]
	Learning Rate: 0.000426768
	LOSS [training: 0.15569072135866657 | validation: 0.1486361532653011]
	TIME [epoch: 36 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15426994096548569		[learning rate: 0.00042507]
	Learning Rate: 0.000425071
	LOSS [training: 0.15426994096548569 | validation: 0.14795772481790517]
	TIME [epoch: 36.1 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1582427655679203		[learning rate: 0.00042338]
	Learning Rate: 0.00042338
	LOSS [training: 0.1582427655679203 | validation: 0.14245006628583706]
	TIME [epoch: 36 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1546017557656449		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 0.1546017557656449 | validation: 0.13961603469053788]
	TIME [epoch: 36.1 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15526533860188002		[learning rate: 0.00042002]
	Learning Rate: 0.000420019
	LOSS [training: 0.15526533860188002 | validation: 0.13771590469825504]
	TIME [epoch: 36 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15603964306661222		[learning rate: 0.00041835]
	Learning Rate: 0.000418349
	LOSS [training: 0.15603964306661222 | validation: 0.14227826993530743]
	TIME [epoch: 36.1 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15732673135899053		[learning rate: 0.00041668]
	Learning Rate: 0.000416685
	LOSS [training: 0.15732673135899053 | validation: 0.14194706349729586]
	TIME [epoch: 36 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1644033044744901		[learning rate: 0.00041503]
	Learning Rate: 0.000415028
	LOSS [training: 0.1644033044744901 | validation: 0.1454855282394875]
	TIME [epoch: 36 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15358667193003728		[learning rate: 0.00041338]
	Learning Rate: 0.000413377
	LOSS [training: 0.15358667193003728 | validation: 0.139665566797395]
	TIME [epoch: 36 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16576239197865747		[learning rate: 0.00041173]
	Learning Rate: 0.000411733
	LOSS [training: 0.16576239197865747 | validation: 0.14210128533373528]
	TIME [epoch: 36.1 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1714342685085039		[learning rate: 0.0004101]
	Learning Rate: 0.000410095
	LOSS [training: 0.1714342685085039 | validation: 0.1441256141708176]
	TIME [epoch: 36 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16234912998234957		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 0.16234912998234957 | validation: 0.14340490981147008]
	TIME [epoch: 36 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16057574041604436		[learning rate: 0.00040684]
	Learning Rate: 0.00040684
	LOSS [training: 0.16057574041604436 | validation: 0.14449093261021903]
	TIME [epoch: 36.1 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15151940424517046		[learning rate: 0.00040522]
	Learning Rate: 0.000405221
	LOSS [training: 0.15151940424517046 | validation: 0.14656854713826684]
	TIME [epoch: 36 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16667809851946258		[learning rate: 0.00040361]
	Learning Rate: 0.00040361
	LOSS [training: 0.16667809851946258 | validation: 0.14720832582516205]
	TIME [epoch: 36 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17638722420693187		[learning rate: 0.000402]
	Learning Rate: 0.000402004
	LOSS [training: 0.17638722420693187 | validation: 0.14581371398335388]
	TIME [epoch: 36 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15488924667684717		[learning rate: 0.00040041]
	Learning Rate: 0.000400406
	LOSS [training: 0.15488924667684717 | validation: 0.14384843403786945]
	TIME [epoch: 36 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17000245028012223		[learning rate: 0.00039881]
	Learning Rate: 0.000398813
	LOSS [training: 0.17000245028012223 | validation: 0.13831656672350118]
	TIME [epoch: 36 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1636429931052017		[learning rate: 0.00039723]
	Learning Rate: 0.000397227
	LOSS [training: 0.1636429931052017 | validation: 0.13816866358415386]
	TIME [epoch: 36 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1582711890332399		[learning rate: 0.00039565]
	Learning Rate: 0.000395647
	LOSS [training: 0.1582711890332399 | validation: 0.14143198089888603]
	TIME [epoch: 36.1 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15591065199954438		[learning rate: 0.00039407]
	Learning Rate: 0.000394073
	LOSS [training: 0.15591065199954438 | validation: 0.14257331782421584]
	TIME [epoch: 36.1 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14982885197276097		[learning rate: 0.00039251]
	Learning Rate: 0.000392506
	LOSS [training: 0.14982885197276097 | validation: 0.1394932955094178]
	TIME [epoch: 36 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.152534015663189		[learning rate: 0.00039094]
	Learning Rate: 0.000390945
	LOSS [training: 0.152534015663189 | validation: 0.14265779402968687]
	TIME [epoch: 36.1 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16244161755765604		[learning rate: 0.00038939]
	Learning Rate: 0.00038939
	LOSS [training: 0.16244161755765604 | validation: 0.14039231124742105]
	TIME [epoch: 36 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1774117837982821		[learning rate: 0.00038784]
	Learning Rate: 0.000387841
	LOSS [training: 0.1774117837982821 | validation: 0.14610348580861682]
	TIME [epoch: 36 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1603488275235962		[learning rate: 0.0003863]
	Learning Rate: 0.000386299
	LOSS [training: 0.1603488275235962 | validation: 0.1421704215431913]
	TIME [epoch: 36.1 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1639142537122752		[learning rate: 0.00038476]
	Learning Rate: 0.000384762
	LOSS [training: 0.1639142537122752 | validation: 0.14306960055268042]
	TIME [epoch: 36 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1735987978452634		[learning rate: 0.00038323]
	Learning Rate: 0.000383232
	LOSS [training: 0.1735987978452634 | validation: 0.13487322637681784]
	TIME [epoch: 36 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1557950662015421		[learning rate: 0.00038171]
	Learning Rate: 0.000381708
	LOSS [training: 0.1557950662015421 | validation: 0.138234447486609]
	TIME [epoch: 36 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17553208238787596		[learning rate: 0.00038019]
	Learning Rate: 0.000380189
	LOSS [training: 0.17553208238787596 | validation: 0.14327487818030718]
	TIME [epoch: 36 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17004294072986312		[learning rate: 0.00037868]
	Learning Rate: 0.000378677
	LOSS [training: 0.17004294072986312 | validation: 0.14494156008755132]
	TIME [epoch: 36 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15565963724831033		[learning rate: 0.00037717]
	Learning Rate: 0.000377171
	LOSS [training: 0.15565963724831033 | validation: 0.1414544705015138]
	TIME [epoch: 36 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1597713534840111		[learning rate: 0.00037567]
	Learning Rate: 0.000375671
	LOSS [training: 0.1597713534840111 | validation: 0.14353000233114632]
	TIME [epoch: 36 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15438453431085566		[learning rate: 0.00037418]
	Learning Rate: 0.000374177
	LOSS [training: 0.15438453431085566 | validation: 0.1468289224736428]
	TIME [epoch: 36 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1594755440881188		[learning rate: 0.00037269]
	Learning Rate: 0.000372689
	LOSS [training: 0.1594755440881188 | validation: 0.13955933065886864]
	TIME [epoch: 36 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16082200268023827		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 0.16082200268023827 | validation: 0.14177540807917074]
	TIME [epoch: 36 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17434209036592832		[learning rate: 0.00036973]
	Learning Rate: 0.00036973
	LOSS [training: 0.17434209036592832 | validation: 0.14388153159845135]
	TIME [epoch: 36 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16381550582947527		[learning rate: 0.00036826]
	Learning Rate: 0.000368259
	LOSS [training: 0.16381550582947527 | validation: 0.1411113672513699]
	TIME [epoch: 36 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1594044150152007		[learning rate: 0.00036679]
	Learning Rate: 0.000366795
	LOSS [training: 0.1594044150152007 | validation: 0.14968294358817041]
	TIME [epoch: 36 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16411846554308646		[learning rate: 0.00036534]
	Learning Rate: 0.000365336
	LOSS [training: 0.16411846554308646 | validation: 0.13602259748762377]
	TIME [epoch: 36 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15997610775917792		[learning rate: 0.00036388]
	Learning Rate: 0.000363883
	LOSS [training: 0.15997610775917792 | validation: 0.1390701859825226]
	TIME [epoch: 36 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15499408187810376		[learning rate: 0.00036244]
	Learning Rate: 0.000362436
	LOSS [training: 0.15499408187810376 | validation: 0.1371248702487782]
	TIME [epoch: 36.1 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15487588208220793		[learning rate: 0.00036099]
	Learning Rate: 0.000360994
	LOSS [training: 0.15487588208220793 | validation: 0.1311483189043684]
	TIME [epoch: 36 sec]
	Saving model to: out/model_training/model_facs_dec1c_2d_v1_20240622_120516/states/model_facs_dec1c_2d_v1_878.pth
	Model improved!!!
EPOCH 879/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16273281537239434		[learning rate: 0.00035956]
	Learning Rate: 0.000359558
	LOSS [training: 0.16273281537239434 | validation: 0.13376579806166572]
	TIME [epoch: 36.1 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1522236244299609		[learning rate: 0.00035813]
	Learning Rate: 0.000358128
	LOSS [training: 0.1522236244299609 | validation: 0.14207967334208726]
	TIME [epoch: 36 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16915936725615766		[learning rate: 0.0003567]
	Learning Rate: 0.000356704
	LOSS [training: 0.16915936725615766 | validation: 0.13690460790912923]
	TIME [epoch: 36 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16277816038254367		[learning rate: 0.00035529]
	Learning Rate: 0.000355285
	LOSS [training: 0.16277816038254367 | validation: 0.14350286691997186]
	TIME [epoch: 36 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1602942766825108		[learning rate: 0.00035387]
	Learning Rate: 0.000353872
	LOSS [training: 0.1602942766825108 | validation: 0.13686950969368547]
	TIME [epoch: 36.1 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16144559019076485		[learning rate: 0.00035246]
	Learning Rate: 0.000352465
	LOSS [training: 0.16144559019076485 | validation: 0.14521671139389092]
	TIME [epoch: 36.1 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16450842975895952		[learning rate: 0.00035106]
	Learning Rate: 0.000351063
	LOSS [training: 0.16450842975895952 | validation: 0.14300019750659435]
	TIME [epoch: 36 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15937741049806378		[learning rate: 0.00034967]
	Learning Rate: 0.000349666
	LOSS [training: 0.15937741049806378 | validation: 0.14151470290761808]
	TIME [epoch: 36.1 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1581841937932497		[learning rate: 0.00034828]
	Learning Rate: 0.000348276
	LOSS [training: 0.1581841937932497 | validation: 0.14620259291097262]
	TIME [epoch: 36.1 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15705300688930424		[learning rate: 0.00034689]
	Learning Rate: 0.000346891
	LOSS [training: 0.15705300688930424 | validation: 0.13941812914714055]
	TIME [epoch: 36.1 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15239309321363467		[learning rate: 0.00034551]
	Learning Rate: 0.000345511
	LOSS [training: 0.15239309321363467 | validation: 0.1445237805390736]
	TIME [epoch: 36.1 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15318080749467605		[learning rate: 0.00034414]
	Learning Rate: 0.000344137
	LOSS [training: 0.15318080749467605 | validation: 0.1378130179507088]
	TIME [epoch: 36.1 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16294486802619443		[learning rate: 0.00034277]
	Learning Rate: 0.000342768
	LOSS [training: 0.16294486802619443 | validation: 0.14558514349213816]
	TIME [epoch: 36 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15206927768038936		[learning rate: 0.0003414]
	Learning Rate: 0.000341405
	LOSS [training: 0.15206927768038936 | validation: 0.14461946770308004]
	TIME [epoch: 36 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16356113543406664		[learning rate: 0.00034005]
	Learning Rate: 0.000340047
	LOSS [training: 0.16356113543406664 | validation: 0.14333958401439356]
	TIME [epoch: 36.1 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15545617113632446		[learning rate: 0.00033869]
	Learning Rate: 0.000338694
	LOSS [training: 0.15545617113632446 | validation: 0.14148577169453136]
	TIME [epoch: 36 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15817181456540752		[learning rate: 0.00033735]
	Learning Rate: 0.000337347
	LOSS [training: 0.15817181456540752 | validation: 0.1447685903231861]
	TIME [epoch: 36 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16477459449199547		[learning rate: 0.00033601]
	Learning Rate: 0.000336005
	LOSS [training: 0.16477459449199547 | validation: 0.1477432318620268]
	TIME [epoch: 36 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15566242749001774		[learning rate: 0.00033467]
	Learning Rate: 0.000334669
	LOSS [training: 0.15566242749001774 | validation: 0.14135482024432838]
	TIME [epoch: 36 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1623247012612145		[learning rate: 0.00033334]
	Learning Rate: 0.000333338
	LOSS [training: 0.1623247012612145 | validation: 0.13696120586449503]
	TIME [epoch: 36 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15413635705048825		[learning rate: 0.00033201]
	Learning Rate: 0.000332012
	LOSS [training: 0.15413635705048825 | validation: 0.14280354682227978]
	TIME [epoch: 36.1 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16285348656734008		[learning rate: 0.00033069]
	Learning Rate: 0.000330692
	LOSS [training: 0.16285348656734008 | validation: 0.13801063359533394]
	TIME [epoch: 36.1 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15344796964290072		[learning rate: 0.00032938]
	Learning Rate: 0.000329376
	LOSS [training: 0.15344796964290072 | validation: 0.13984043157297543]
	TIME [epoch: 36.1 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16825637046562492		[learning rate: 0.00032807]
	Learning Rate: 0.000328066
	LOSS [training: 0.16825637046562492 | validation: 0.14785154752169596]
	TIME [epoch: 36.1 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15806089907170093		[learning rate: 0.00032676]
	Learning Rate: 0.000326761
	LOSS [training: 0.15806089907170093 | validation: 0.1437344852188663]
	TIME [epoch: 36.1 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15742551924913897		[learning rate: 0.00032546]
	Learning Rate: 0.000325462
	LOSS [training: 0.15742551924913897 | validation: 0.14344590089880252]
	TIME [epoch: 36 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16205707911653539		[learning rate: 0.00032417]
	Learning Rate: 0.000324167
	LOSS [training: 0.16205707911653539 | validation: 0.14362776789195936]
	TIME [epoch: 36 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1695633144688994		[learning rate: 0.00032288]
	Learning Rate: 0.000322878
	LOSS [training: 0.1695633144688994 | validation: 0.13975452672470684]
	TIME [epoch: 36.1 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1616917051142984		[learning rate: 0.00032159]
	Learning Rate: 0.000321594
	LOSS [training: 0.1616917051142984 | validation: 0.1347063102474047]
	TIME [epoch: 36 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16696959386331922		[learning rate: 0.00032031]
	Learning Rate: 0.000320315
	LOSS [training: 0.16696959386331922 | validation: 0.14296108541302396]
	TIME [epoch: 36 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17019378263969065		[learning rate: 0.00031904]
	Learning Rate: 0.000319041
	LOSS [training: 0.17019378263969065 | validation: 0.14228034755165925]
	TIME [epoch: 36 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.163522803155593		[learning rate: 0.00031777]
	Learning Rate: 0.000317772
	LOSS [training: 0.163522803155593 | validation: 0.14283266848170878]
	TIME [epoch: 36 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15707941870355036		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 0.15707941870355036 | validation: 0.13852590648570423]
	TIME [epoch: 36 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15702247551649684		[learning rate: 0.00031525]
	Learning Rate: 0.000315249
	LOSS [training: 0.15702247551649684 | validation: 0.14378616682442463]
	TIME [epoch: 36 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16653592832516206		[learning rate: 0.000314]
	Learning Rate: 0.000313995
	LOSS [training: 0.16653592832516206 | validation: 0.1405071691958593]
	TIME [epoch: 36 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15806228898025132		[learning rate: 0.00031275]
	Learning Rate: 0.000312746
	LOSS [training: 0.15806228898025132 | validation: 0.13665413841330692]
	TIME [epoch: 36 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16136451420087583		[learning rate: 0.0003115]
	Learning Rate: 0.000311503
	LOSS [training: 0.16136451420087583 | validation: 0.14598652575744295]
	TIME [epoch: 36 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15529756163671563		[learning rate: 0.00031026]
	Learning Rate: 0.000310264
	LOSS [training: 0.15529756163671563 | validation: 0.1404061033902495]
	TIME [epoch: 36 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1562009567069068		[learning rate: 0.00030903]
	Learning Rate: 0.00030903
	LOSS [training: 0.1562009567069068 | validation: 0.1446206688128155]
	TIME [epoch: 36 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15804867384517593		[learning rate: 0.0003078]
	Learning Rate: 0.0003078
	LOSS [training: 0.15804867384517593 | validation: 0.134940358513885]
	TIME [epoch: 36 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15736409174864438		[learning rate: 0.00030658]
	Learning Rate: 0.000306576
	LOSS [training: 0.15736409174864438 | validation: 0.1391621394455016]
	TIME [epoch: 36 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16873632964342222		[learning rate: 0.00030536]
	Learning Rate: 0.000305357
	LOSS [training: 0.16873632964342222 | validation: 0.1393815268811563]
	TIME [epoch: 36.1 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15424353629580323		[learning rate: 0.00030414]
	Learning Rate: 0.000304142
	LOSS [training: 0.15424353629580323 | validation: 0.13983580030538917]
	TIME [epoch: 36.1 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16195490612633331		[learning rate: 0.00030293]
	Learning Rate: 0.000302933
	LOSS [training: 0.16195490612633331 | validation: 0.13814339412824111]
	TIME [epoch: 36.1 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16692836326989724		[learning rate: 0.00030173]
	Learning Rate: 0.000301728
	LOSS [training: 0.16692836326989724 | validation: 0.13682098122852587]
	TIME [epoch: 36 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15703259428571867		[learning rate: 0.00030053]
	Learning Rate: 0.000300528
	LOSS [training: 0.15703259428571867 | validation: 0.14649458130730533]
	TIME [epoch: 36 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16284258121851822		[learning rate: 0.00029933]
	Learning Rate: 0.000299333
	LOSS [training: 0.16284258121851822 | validation: 0.14104502916789025]
	TIME [epoch: 36 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16073698756763363		[learning rate: 0.00029814]
	Learning Rate: 0.000298142
	LOSS [training: 0.16073698756763363 | validation: 0.14940426949417024]
	TIME [epoch: 36 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1564119569046244		[learning rate: 0.00029696]
	Learning Rate: 0.000296956
	LOSS [training: 0.1564119569046244 | validation: 0.14058310621593528]
	TIME [epoch: 36 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15716551430475223		[learning rate: 0.00029578]
	Learning Rate: 0.000295775
	LOSS [training: 0.15716551430475223 | validation: 0.14049990267706147]
	TIME [epoch: 36 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15959504484392195		[learning rate: 0.0002946]
	Learning Rate: 0.000294599
	LOSS [training: 0.15959504484392195 | validation: 0.14366633731106448]
	TIME [epoch: 36 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16263231018298333		[learning rate: 0.00029343]
	Learning Rate: 0.000293427
	LOSS [training: 0.16263231018298333 | validation: 0.14034872298998313]
	TIME [epoch: 36 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1592581620829344		[learning rate: 0.00029226]
	Learning Rate: 0.00029226
	LOSS [training: 0.1592581620829344 | validation: 0.13383066951577946]
	TIME [epoch: 36 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15968402454841865		[learning rate: 0.0002911]
	Learning Rate: 0.000291098
	LOSS [training: 0.15968402454841865 | validation: 0.13603327375548452]
	TIME [epoch: 36 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16249031862160634		[learning rate: 0.00028994]
	Learning Rate: 0.00028994
	LOSS [training: 0.16249031862160634 | validation: 0.14535287517116458]
	TIME [epoch: 36 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16454012440797997		[learning rate: 0.00028879]
	Learning Rate: 0.000288786
	LOSS [training: 0.16454012440797997 | validation: 0.1435980602773824]
	TIME [epoch: 36 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15857135646974374		[learning rate: 0.00028764]
	Learning Rate: 0.000287638
	LOSS [training: 0.15857135646974374 | validation: 0.1377227921704452]
	TIME [epoch: 36 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16774478994192174		[learning rate: 0.00028649]
	Learning Rate: 0.000286494
	LOSS [training: 0.16774478994192174 | validation: 0.14555526482202613]
	TIME [epoch: 36 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1691961541094461		[learning rate: 0.00028535]
	Learning Rate: 0.000285354
	LOSS [training: 0.1691961541094461 | validation: 0.1425803454594158]
	TIME [epoch: 36 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16764761072575327		[learning rate: 0.00028422]
	Learning Rate: 0.00028422
	LOSS [training: 0.16764761072575327 | validation: 0.14498045309355154]
	TIME [epoch: 36 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15043518279648393		[learning rate: 0.00028309]
	Learning Rate: 0.000283089
	LOSS [training: 0.15043518279648393 | validation: 0.13366503965767584]
	TIME [epoch: 36 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16166837004498438		[learning rate: 0.00028196]
	Learning Rate: 0.000281963
	LOSS [training: 0.16166837004498438 | validation: 0.1427151143371626]
	TIME [epoch: 36 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1589508978712463		[learning rate: 0.00028084]
	Learning Rate: 0.000280842
	LOSS [training: 0.1589508978712463 | validation: 0.13847237246901872]
	TIME [epoch: 36 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17268897864820085		[learning rate: 0.00027972]
	Learning Rate: 0.000279725
	LOSS [training: 0.17268897864820085 | validation: 0.13929245810737462]
	TIME [epoch: 36 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15650579789858		[learning rate: 0.00027861]
	Learning Rate: 0.000278612
	LOSS [training: 0.15650579789858 | validation: 0.14402238981749219]
	TIME [epoch: 36 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16378298233213118		[learning rate: 0.0002775]
	Learning Rate: 0.000277504
	LOSS [training: 0.16378298233213118 | validation: 0.13757203365536144]
	TIME [epoch: 36 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16804214524752856		[learning rate: 0.0002764]
	Learning Rate: 0.0002764
	LOSS [training: 0.16804214524752856 | validation: 0.1448236702844064]
	TIME [epoch: 36.1 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1547850462814458		[learning rate: 0.0002753]
	Learning Rate: 0.000275301
	LOSS [training: 0.1547850462814458 | validation: 0.142871660271284]
	TIME [epoch: 36 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16788315222730102		[learning rate: 0.00027421]
	Learning Rate: 0.000274206
	LOSS [training: 0.16788315222730102 | validation: 0.13394410350431765]
	TIME [epoch: 36 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17145953434626654		[learning rate: 0.00027312]
	Learning Rate: 0.000273115
	LOSS [training: 0.17145953434626654 | validation: 0.141064620654671]
	TIME [epoch: 36 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16107965997612117		[learning rate: 0.00027203]
	Learning Rate: 0.000272029
	LOSS [training: 0.16107965997612117 | validation: 0.13891553667473333]
	TIME [epoch: 36 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1603967637413703		[learning rate: 0.00027095]
	Learning Rate: 0.000270947
	LOSS [training: 0.1603967637413703 | validation: 0.13544364061356]
	TIME [epoch: 36 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16096035424386373		[learning rate: 0.00026987]
	Learning Rate: 0.00026987
	LOSS [training: 0.16096035424386373 | validation: 0.1432475705418173]
	TIME [epoch: 36 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.18841234678385751		[learning rate: 0.0002688]
	Learning Rate: 0.000268796
	LOSS [training: 0.18841234678385751 | validation: 0.14020710791926635]
	TIME [epoch: 36 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16266069450350037		[learning rate: 0.00026773]
	Learning Rate: 0.000267727
	LOSS [training: 0.16266069450350037 | validation: 0.14276489999143632]
	TIME [epoch: 36.1 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15929854433482116		[learning rate: 0.00026666]
	Learning Rate: 0.000266662
	LOSS [training: 0.15929854433482116 | validation: 0.13895337561062943]
	TIME [epoch: 36 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16498235096898167		[learning rate: 0.0002656]
	Learning Rate: 0.000265602
	LOSS [training: 0.16498235096898167 | validation: 0.13563479822691976]
	TIME [epoch: 36 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15258528292864934		[learning rate: 0.00026455]
	Learning Rate: 0.000264545
	LOSS [training: 0.15258528292864934 | validation: 0.1401532561379854]
	TIME [epoch: 36 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17929700660361925		[learning rate: 0.00026349]
	Learning Rate: 0.000263493
	LOSS [training: 0.17929700660361925 | validation: 0.1394009563009785]
	TIME [epoch: 36 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.166288814564697		[learning rate: 0.00026245]
	Learning Rate: 0.000262445
	LOSS [training: 0.166288814564697 | validation: 0.14061369448970923]
	TIME [epoch: 36 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15430403877806398		[learning rate: 0.0002614]
	Learning Rate: 0.000261401
	LOSS [training: 0.15430403877806398 | validation: 0.1432642560570945]
	TIME [epoch: 36 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15324904003891424		[learning rate: 0.00026036]
	Learning Rate: 0.000260362
	LOSS [training: 0.15324904003891424 | validation: 0.13182814640778354]
	TIME [epoch: 36 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15385218618474303		[learning rate: 0.00025933]
	Learning Rate: 0.000259326
	LOSS [training: 0.15385218618474303 | validation: 0.13883036743642468]
	TIME [epoch: 36 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17568005615731835		[learning rate: 0.00025829]
	Learning Rate: 0.000258295
	LOSS [training: 0.17568005615731835 | validation: 0.14100905040523143]
	TIME [epoch: 36 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16992583619635973		[learning rate: 0.00025727]
	Learning Rate: 0.000257267
	LOSS [training: 0.16992583619635973 | validation: 0.13224151340521698]
	TIME [epoch: 36 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16396068039906556		[learning rate: 0.00025624]
	Learning Rate: 0.000256244
	LOSS [training: 0.16396068039906556 | validation: 0.14300591352505204]
	TIME [epoch: 36 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15788499666563022		[learning rate: 0.00025522]
	Learning Rate: 0.000255225
	LOSS [training: 0.15788499666563022 | validation: 0.14393331817095417]
	TIME [epoch: 36 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16331064326955763		[learning rate: 0.00025421]
	Learning Rate: 0.00025421
	LOSS [training: 0.16331064326955763 | validation: 0.14199111988127078]
	TIME [epoch: 36 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1584919292351754		[learning rate: 0.0002532]
	Learning Rate: 0.000253199
	LOSS [training: 0.1584919292351754 | validation: 0.13693844140966224]
	TIME [epoch: 36.1 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1589267536915095		[learning rate: 0.00025219]
	Learning Rate: 0.000252192
	LOSS [training: 0.1589267536915095 | validation: 0.14439223840033835]
	TIME [epoch: 36.1 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16348698076365759		[learning rate: 0.00025119]
	Learning Rate: 0.000251189
	LOSS [training: 0.16348698076365759 | validation: 0.14096801331948097]
	TIME [epoch: 36 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15419448836739963		[learning rate: 0.00025019]
	Learning Rate: 0.00025019
	LOSS [training: 0.15419448836739963 | validation: 0.14131983145428886]
	TIME [epoch: 36.1 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1603172279701088		[learning rate: 0.00024919]
	Learning Rate: 0.000249195
	LOSS [training: 0.1603172279701088 | validation: 0.13716400212766183]
	TIME [epoch: 36.1 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15158029449764313		[learning rate: 0.0002482]
	Learning Rate: 0.000248203
	LOSS [training: 0.15158029449764313 | validation: 0.14701616718728985]
	TIME [epoch: 36.1 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1471080596505538		[learning rate: 0.00024722]
	Learning Rate: 0.000247216
	LOSS [training: 0.1471080596505538 | validation: 0.13915122287728326]
	TIME [epoch: 36.1 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16820402357685363		[learning rate: 0.00024623]
	Learning Rate: 0.000246233
	LOSS [training: 0.16820402357685363 | validation: 0.14392899355816827]
	TIME [epoch: 36 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15817948466413412		[learning rate: 0.00024525]
	Learning Rate: 0.000245254
	LOSS [training: 0.15817948466413412 | validation: 0.1360915160357101]
	TIME [epoch: 36 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15318941921801127		[learning rate: 0.00024428]
	Learning Rate: 0.000244278
	LOSS [training: 0.15318941921801127 | validation: 0.143126142266525]
	TIME [epoch: 36 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15997506779685888		[learning rate: 0.00024331]
	Learning Rate: 0.000243307
	LOSS [training: 0.15997506779685888 | validation: 0.14152187529485452]
	TIME [epoch: 36 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1565930084143004		[learning rate: 0.00024234]
	Learning Rate: 0.000242339
	LOSS [training: 0.1565930084143004 | validation: 0.13704610253420801]
	TIME [epoch: 36 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17496637267776666		[learning rate: 0.00024138]
	Learning Rate: 0.000241375
	LOSS [training: 0.17496637267776666 | validation: 0.14099087733586485]
	TIME [epoch: 36 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1550949292794229		[learning rate: 0.00024042]
	Learning Rate: 0.000240415
	LOSS [training: 0.1550949292794229 | validation: 0.14940179088703695]
	TIME [epoch: 36.1 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15115231508562804		[learning rate: 0.00023946]
	Learning Rate: 0.000239459
	LOSS [training: 0.15115231508562804 | validation: 0.14249953816380237]
	TIME [epoch: 36.1 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15541358218402246		[learning rate: 0.00023851]
	Learning Rate: 0.000238506
	LOSS [training: 0.15541358218402246 | validation: 0.14141700795972653]
	TIME [epoch: 36 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1592995158181275		[learning rate: 0.00023756]
	Learning Rate: 0.000237558
	LOSS [training: 0.1592995158181275 | validation: 0.14453078099606587]
	TIME [epoch: 36 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15914563333917414		[learning rate: 0.00023661]
	Learning Rate: 0.000236613
	LOSS [training: 0.15914563333917414 | validation: 0.14405085809009896]
	TIME [epoch: 36 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17059831841485998		[learning rate: 0.00023567]
	Learning Rate: 0.000235672
	LOSS [training: 0.17059831841485998 | validation: 0.14492471085227307]
	TIME [epoch: 36 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15676415909783672		[learning rate: 0.00023473]
	Learning Rate: 0.000234735
	LOSS [training: 0.15676415909783672 | validation: 0.1514562771419571]
	TIME [epoch: 36 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1517171890446292		[learning rate: 0.0002338]
	Learning Rate: 0.000233801
	LOSS [training: 0.1517171890446292 | validation: 0.13539812053721573]
	TIME [epoch: 36 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16143778952670626		[learning rate: 0.00023287]
	Learning Rate: 0.000232871
	LOSS [training: 0.16143778952670626 | validation: 0.1389527048357494]
	TIME [epoch: 36 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1648632211333519		[learning rate: 0.00023194]
	Learning Rate: 0.000231945
	LOSS [training: 0.1648632211333519 | validation: 0.14093803198869387]
	TIME [epoch: 36.1 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17738281188318217		[learning rate: 0.00023102]
	Learning Rate: 0.000231022
	LOSS [training: 0.17738281188318217 | validation: 0.14776189314243324]
	TIME [epoch: 36 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16930244864728622		[learning rate: 0.0002301]
	Learning Rate: 0.000230103
	LOSS [training: 0.16930244864728622 | validation: 0.14153422477268865]
	TIME [epoch: 36.1 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1593228821338101		[learning rate: 0.00022919]
	Learning Rate: 0.000229188
	LOSS [training: 0.1593228821338101 | validation: 0.1487770973710323]
	TIME [epoch: 36 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16483130554215616		[learning rate: 0.00022828]
	Learning Rate: 0.000228277
	LOSS [training: 0.16483130554215616 | validation: 0.14468820718506106]
	TIME [epoch: 36.1 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16434955312885477		[learning rate: 0.00022737]
	Learning Rate: 0.000227369
	LOSS [training: 0.16434955312885477 | validation: 0.1485082772397791]
	TIME [epoch: 36 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1554854594560589		[learning rate: 0.00022646]
	Learning Rate: 0.000226464
	LOSS [training: 0.1554854594560589 | validation: 0.14932319579029862]
	TIME [epoch: 36 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1589029943547986		[learning rate: 0.00022556]
	Learning Rate: 0.000225564
	LOSS [training: 0.1589029943547986 | validation: 0.13908205431333193]
	TIME [epoch: 36.1 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16170520268939034		[learning rate: 0.00022467]
	Learning Rate: 0.000224667
	LOSS [training: 0.16170520268939034 | validation: 0.14196011292794658]
	TIME [epoch: 36.1 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15551190737569415		[learning rate: 0.00022377]
	Learning Rate: 0.000223773
	LOSS [training: 0.15551190737569415 | validation: 0.14195624584302208]
	TIME [epoch: 36.1 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1713448639823311		[learning rate: 0.00022288]
	Learning Rate: 0.000222883
	LOSS [training: 0.1713448639823311 | validation: 0.14355584231817647]
	TIME [epoch: 36 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1599207508672903		[learning rate: 0.000222]
	Learning Rate: 0.000221997
	LOSS [training: 0.1599207508672903 | validation: 0.14097511225922266]
	TIME [epoch: 36 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16138064781527736		[learning rate: 0.00022111]
	Learning Rate: 0.000221114
	LOSS [training: 0.16138064781527736 | validation: 0.14385666875787712]
	TIME [epoch: 36.1 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16244109097570553		[learning rate: 0.00022023]
	Learning Rate: 0.000220234
	LOSS [training: 0.16244109097570553 | validation: 0.1401977011592931]
	TIME [epoch: 36 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15940321062012566		[learning rate: 0.00021936]
	Learning Rate: 0.000219358
	LOSS [training: 0.15940321062012566 | validation: 0.1416092946350785]
	TIME [epoch: 36.1 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16976420970117523		[learning rate: 0.00021849]
	Learning Rate: 0.000218486
	LOSS [training: 0.16976420970117523 | validation: 0.13933914571942213]
	TIME [epoch: 36.1 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15829601823240058		[learning rate: 0.00021762]
	Learning Rate: 0.000217617
	LOSS [training: 0.15829601823240058 | validation: 0.13876615455390723]
	TIME [epoch: 36.1 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16886449220488414		[learning rate: 0.00021675]
	Learning Rate: 0.000216751
	LOSS [training: 0.16886449220488414 | validation: 0.14418504831074694]
	TIME [epoch: 36.1 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16525678894413154		[learning rate: 0.00021589]
	Learning Rate: 0.000215889
	LOSS [training: 0.16525678894413154 | validation: 0.14949006429971046]
	TIME [epoch: 36.1 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16380679805341816		[learning rate: 0.00021503]
	Learning Rate: 0.00021503
	LOSS [training: 0.16380679805341816 | validation: 0.14002243822773072]
	TIME [epoch: 36.1 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15475925882244365		[learning rate: 0.00021418]
	Learning Rate: 0.000214175
	LOSS [training: 0.15475925882244365 | validation: 0.1382672947428904]
	TIME [epoch: 36.1 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16126700959386187		[learning rate: 0.00021332]
	Learning Rate: 0.000213323
	LOSS [training: 0.16126700959386187 | validation: 0.14896350055335417]
	TIME [epoch: 36 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1599965726881757		[learning rate: 0.00021247]
	Learning Rate: 0.000212475
	LOSS [training: 0.1599965726881757 | validation: 0.1359445056381129]
	TIME [epoch: 36.1 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15496914383080942		[learning rate: 0.00021163]
	Learning Rate: 0.00021163
	LOSS [training: 0.15496914383080942 | validation: 0.13663922797057237]
	TIME [epoch: 36.1 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16519280696310146		[learning rate: 0.00021079]
	Learning Rate: 0.000210788
	LOSS [training: 0.16519280696310146 | validation: 0.13265768949780904]
	TIME [epoch: 36.1 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16974463348273197		[learning rate: 0.00020995]
	Learning Rate: 0.00020995
	LOSS [training: 0.16974463348273197 | validation: 0.14362417570072697]
	TIME [epoch: 36 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1686115804508922		[learning rate: 0.00020911]
	Learning Rate: 0.000209115
	LOSS [training: 0.1686115804508922 | validation: 0.13620792907825052]
	TIME [epoch: 36 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1619986669021871		[learning rate: 0.00020828]
	Learning Rate: 0.000208283
	LOSS [training: 0.1619986669021871 | validation: 0.13750631647805514]
	TIME [epoch: 36 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16042322857957225		[learning rate: 0.00020745]
	Learning Rate: 0.000207455
	LOSS [training: 0.16042322857957225 | validation: 0.146175380510728]
	TIME [epoch: 36.1 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.157065694398173		[learning rate: 0.00020663]
	Learning Rate: 0.00020663
	LOSS [training: 0.157065694398173 | validation: 0.13521919434122803]
	TIME [epoch: 36.1 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15592746374898064		[learning rate: 0.00020581]
	Learning Rate: 0.000205808
	LOSS [training: 0.15592746374898064 | validation: 0.1294028021527102]
	TIME [epoch: 36.1 sec]
	Saving model to: out/model_training/model_facs_dec1c_2d_v1_20240622_120516/states/model_facs_dec1c_2d_v1_1019.pth
	Model improved!!!
EPOCH 1020/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15918552607454928		[learning rate: 0.00020499]
	Learning Rate: 0.000204989
	LOSS [training: 0.15918552607454928 | validation: 0.13303160512234494]
	TIME [epoch: 36.1 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1645180875693092		[learning rate: 0.00020417]
	Learning Rate: 0.000204174
	LOSS [training: 0.1645180875693092 | validation: 0.13881183722158635]
	TIME [epoch: 36 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16425211684982474		[learning rate: 0.00020336]
	Learning Rate: 0.000203362
	LOSS [training: 0.16425211684982474 | validation: 0.14410351979260194]
	TIME [epoch: 36 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16155489324404712		[learning rate: 0.00020255]
	Learning Rate: 0.000202553
	LOSS [training: 0.16155489324404712 | validation: 0.13607550970547835]
	TIME [epoch: 36 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17098660368277716		[learning rate: 0.00020175]
	Learning Rate: 0.000201747
	LOSS [training: 0.17098660368277716 | validation: 0.1399481760283942]
	TIME [epoch: 36 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16161398849796316		[learning rate: 0.00020094]
	Learning Rate: 0.000200945
	LOSS [training: 0.16161398849796316 | validation: 0.14193033977409958]
	TIME [epoch: 36 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16054297299823878		[learning rate: 0.00020015]
	Learning Rate: 0.000200146
	LOSS [training: 0.16054297299823878 | validation: 0.1438195236690198]
	TIME [epoch: 36.1 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15686291119379936		[learning rate: 0.00019935]
	Learning Rate: 0.00019935
	LOSS [training: 0.15686291119379936 | validation: 0.14582186943161027]
	TIME [epoch: 36 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17077133118723878		[learning rate: 0.00019856]
	Learning Rate: 0.000198557
	LOSS [training: 0.17077133118723878 | validation: 0.1394070318675939]
	TIME [epoch: 36 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15703664259662237		[learning rate: 0.00019777]
	Learning Rate: 0.000197767
	LOSS [training: 0.15703664259662237 | validation: 0.14086661921029792]
	TIME [epoch: 36 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16607781484573683		[learning rate: 0.00019698]
	Learning Rate: 0.00019698
	LOSS [training: 0.16607781484573683 | validation: 0.13763275867684568]
	TIME [epoch: 36 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16345180673560294		[learning rate: 0.0001962]
	Learning Rate: 0.000196197
	LOSS [training: 0.16345180673560294 | validation: 0.1360593963653724]
	TIME [epoch: 36 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15808633243353473		[learning rate: 0.00019542]
	Learning Rate: 0.000195417
	LOSS [training: 0.15808633243353473 | validation: 0.13835468118513156]
	TIME [epoch: 36 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1605971813226229		[learning rate: 0.00019464]
	Learning Rate: 0.000194639
	LOSS [training: 0.1605971813226229 | validation: 0.13892118760344857]
	TIME [epoch: 36 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16030536649000904		[learning rate: 0.00019387]
	Learning Rate: 0.000193865
	LOSS [training: 0.16030536649000904 | validation: 0.13560415175297558]
	TIME [epoch: 36 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16661638010039473		[learning rate: 0.00019309]
	Learning Rate: 0.000193094
	LOSS [training: 0.16661638010039473 | validation: 0.14670259022955487]
	TIME [epoch: 36 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17240846738654061		[learning rate: 0.00019233]
	Learning Rate: 0.000192326
	LOSS [training: 0.17240846738654061 | validation: 0.14219275745111148]
	TIME [epoch: 36 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15734501480421306		[learning rate: 0.00019156]
	Learning Rate: 0.000191561
	LOSS [training: 0.15734501480421306 | validation: 0.14570390829559127]
	TIME [epoch: 36 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16458504020683762		[learning rate: 0.0001908]
	Learning Rate: 0.000190799
	LOSS [training: 0.16458504020683762 | validation: 0.14248716260350291]
	TIME [epoch: 36 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1676825199162069		[learning rate: 0.00019004]
	Learning Rate: 0.00019004
	LOSS [training: 0.1676825199162069 | validation: 0.13814300965948798]
	TIME [epoch: 36 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15767896982336924		[learning rate: 0.00018928]
	Learning Rate: 0.000189285
	LOSS [training: 0.15767896982336924 | validation: 0.13840151517858593]
	TIME [epoch: 36 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15476098838261546		[learning rate: 0.00018853]
	Learning Rate: 0.000188532
	LOSS [training: 0.15476098838261546 | validation: 0.14263802546687882]
	TIME [epoch: 36 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1666822183008475		[learning rate: 0.00018778]
	Learning Rate: 0.000187782
	LOSS [training: 0.1666822183008475 | validation: 0.1464268452386012]
	TIME [epoch: 36.1 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15663743528171084		[learning rate: 0.00018704]
	Learning Rate: 0.000187035
	LOSS [training: 0.15663743528171084 | validation: 0.13640962011385574]
	TIME [epoch: 36 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16482833246809475		[learning rate: 0.00018629]
	Learning Rate: 0.000186291
	LOSS [training: 0.16482833246809475 | validation: 0.13737111634797017]
	TIME [epoch: 36 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1526264147911379		[learning rate: 0.00018555]
	Learning Rate: 0.00018555
	LOSS [training: 0.1526264147911379 | validation: 0.14176044158752055]
	TIME [epoch: 36 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15167702440329742		[learning rate: 0.00018481]
	Learning Rate: 0.000184812
	LOSS [training: 0.15167702440329742 | validation: 0.1372919048653775]
	TIME [epoch: 36 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16420002766631192		[learning rate: 0.00018408]
	Learning Rate: 0.000184077
	LOSS [training: 0.16420002766631192 | validation: 0.140321800101753]
	TIME [epoch: 36 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15526808405235887		[learning rate: 0.00018335]
	Learning Rate: 0.000183345
	LOSS [training: 0.15526808405235887 | validation: 0.1420577450601487]
	TIME [epoch: 36 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17085598230292423		[learning rate: 0.00018262]
	Learning Rate: 0.000182616
	LOSS [training: 0.17085598230292423 | validation: 0.1396506349620047]
	TIME [epoch: 36 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17650001095806467		[learning rate: 0.00018189]
	Learning Rate: 0.00018189
	LOSS [training: 0.17650001095806467 | validation: 0.13830334587660237]
	TIME [epoch: 36 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17223868780574922		[learning rate: 0.00018117]
	Learning Rate: 0.000181166
	LOSS [training: 0.17223868780574922 | validation: 0.14761222820793612]
	TIME [epoch: 36 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1638515780734413		[learning rate: 0.00018045]
	Learning Rate: 0.000180446
	LOSS [training: 0.1638515780734413 | validation: 0.13389291786459848]
	TIME [epoch: 36 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15549673147389315		[learning rate: 0.00017973]
	Learning Rate: 0.000179728
	LOSS [training: 0.15549673147389315 | validation: 0.14078549981971616]
	TIME [epoch: 36 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16625065082100537		[learning rate: 0.00017901]
	Learning Rate: 0.000179013
	LOSS [training: 0.16625065082100537 | validation: 0.13595354200917295]
	TIME [epoch: 36 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15176460822014978		[learning rate: 0.0001783]
	Learning Rate: 0.000178301
	LOSS [training: 0.15176460822014978 | validation: 0.14098405241166206]
	TIME [epoch: 36 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1598765233804383		[learning rate: 0.00017759]
	Learning Rate: 0.000177592
	LOSS [training: 0.1598765233804383 | validation: 0.13565963410128876]
	TIME [epoch: 36 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16676885924373036		[learning rate: 0.00017689]
	Learning Rate: 0.000176886
	LOSS [training: 0.16676885924373036 | validation: 0.13643985794277994]
	TIME [epoch: 36 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1554652093934582		[learning rate: 0.00017618]
	Learning Rate: 0.000176182
	LOSS [training: 0.1554652093934582 | validation: 0.13673385559786289]
	TIME [epoch: 36 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15322018341799806		[learning rate: 0.00017548]
	Learning Rate: 0.000175481
	LOSS [training: 0.15322018341799806 | validation: 0.14306454452477219]
	TIME [epoch: 36 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16007355288286124		[learning rate: 0.00017478]
	Learning Rate: 0.000174783
	LOSS [training: 0.16007355288286124 | validation: 0.13786721015822986]
	TIME [epoch: 36 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16450680188996364		[learning rate: 0.00017409]
	Learning Rate: 0.000174088
	LOSS [training: 0.16450680188996364 | validation: 0.14078052684862297]
	TIME [epoch: 36 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15535596611902924		[learning rate: 0.0001734]
	Learning Rate: 0.000173396
	LOSS [training: 0.15535596611902924 | validation: 0.14002463897911913]
	TIME [epoch: 36 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15418367983225034		[learning rate: 0.00017271]
	Learning Rate: 0.000172706
	LOSS [training: 0.15418367983225034 | validation: 0.13454043408063346]
	TIME [epoch: 36 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15651576944924572		[learning rate: 0.00017202]
	Learning Rate: 0.000172019
	LOSS [training: 0.15651576944924572 | validation: 0.14490116087572086]
	TIME [epoch: 36 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1486015802109356		[learning rate: 0.00017134]
	Learning Rate: 0.000171335
	LOSS [training: 0.1486015802109356 | validation: 0.14136721548410433]
	TIME [epoch: 36 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15790826090965812		[learning rate: 0.00017065]
	Learning Rate: 0.000170654
	LOSS [training: 0.15790826090965812 | validation: 0.13654905046811008]
	TIME [epoch: 36 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1582568003141395		[learning rate: 0.00016997]
	Learning Rate: 0.000169975
	LOSS [training: 0.1582568003141395 | validation: 0.1371158844688027]
	TIME [epoch: 36 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16245146876103272		[learning rate: 0.0001693]
	Learning Rate: 0.000169299
	LOSS [training: 0.16245146876103272 | validation: 0.1411893525292189]
	TIME [epoch: 36 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1629944283938752		[learning rate: 0.00016863]
	Learning Rate: 0.000168625
	LOSS [training: 0.1629944283938752 | validation: 0.13632944123713228]
	TIME [epoch: 36 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15882941059319608		[learning rate: 0.00016795]
	Learning Rate: 0.000167955
	LOSS [training: 0.15882941059319608 | validation: 0.14233461886369608]
	TIME [epoch: 36 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1551341010418944		[learning rate: 0.00016729]
	Learning Rate: 0.000167287
	LOSS [training: 0.1551341010418944 | validation: 0.1414327782565624]
	TIME [epoch: 36 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16586441458132023		[learning rate: 0.00016662]
	Learning Rate: 0.000166621
	LOSS [training: 0.16586441458132023 | validation: 0.14379711943918397]
	TIME [epoch: 36 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16262290086412523		[learning rate: 0.00016596]
	Learning Rate: 0.000165959
	LOSS [training: 0.16262290086412523 | validation: 0.14087447809696085]
	TIME [epoch: 36 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16083013530918489		[learning rate: 0.0001653]
	Learning Rate: 0.000165299
	LOSS [training: 0.16083013530918489 | validation: 0.142461310699936]
	TIME [epoch: 36 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15840612443433677		[learning rate: 0.00016464]
	Learning Rate: 0.000164641
	LOSS [training: 0.15840612443433677 | validation: 0.13456838380702713]
	TIME [epoch: 36 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16080421305522707		[learning rate: 0.00016399]
	Learning Rate: 0.000163986
	LOSS [training: 0.16080421305522707 | validation: 0.13878655655546648]
	TIME [epoch: 36 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15893396162183457		[learning rate: 0.00016333]
	Learning Rate: 0.000163334
	LOSS [training: 0.15893396162183457 | validation: 0.14389933057744989]
	TIME [epoch: 36 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16960296404125333		[learning rate: 0.00016268]
	Learning Rate: 0.000162685
	LOSS [training: 0.16960296404125333 | validation: 0.13806699112359605]
	TIME [epoch: 36 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1661829124765689		[learning rate: 0.00016204]
	Learning Rate: 0.000162037
	LOSS [training: 0.1661829124765689 | validation: 0.1456775689146325]
	TIME [epoch: 36 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1740333377831073		[learning rate: 0.00016139]
	Learning Rate: 0.000161393
	LOSS [training: 0.1740333377831073 | validation: 0.14244196281219895]
	TIME [epoch: 36 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15858076616138048		[learning rate: 0.00016075]
	Learning Rate: 0.000160751
	LOSS [training: 0.15858076616138048 | validation: 0.14429623781985873]
	TIME [epoch: 36 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1540350962919976		[learning rate: 0.00016011]
	Learning Rate: 0.000160112
	LOSS [training: 0.1540350962919976 | validation: 0.14462092125022238]
	TIME [epoch: 36 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16270453817386354		[learning rate: 0.00015947]
	Learning Rate: 0.000159475
	LOSS [training: 0.16270453817386354 | validation: 0.14168308518175085]
	TIME [epoch: 36 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15999893799160392		[learning rate: 0.00015884]
	Learning Rate: 0.000158841
	LOSS [training: 0.15999893799160392 | validation: 0.13977656486622392]
	TIME [epoch: 36 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16298962159623326		[learning rate: 0.00015821]
	Learning Rate: 0.000158209
	LOSS [training: 0.16298962159623326 | validation: 0.14056367852296242]
	TIME [epoch: 36 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16009241641278243		[learning rate: 0.00015758]
	Learning Rate: 0.00015758
	LOSS [training: 0.16009241641278243 | validation: 0.14750911792588356]
	TIME [epoch: 36 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16242179930793582		[learning rate: 0.00015695]
	Learning Rate: 0.000156953
	LOSS [training: 0.16242179930793582 | validation: 0.14359833707944764]
	TIME [epoch: 36 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1655470816472939		[learning rate: 0.00015633]
	Learning Rate: 0.000156329
	LOSS [training: 0.1655470816472939 | validation: 0.1426009394151963]
	TIME [epoch: 36 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15986755064280034		[learning rate: 0.00015571]
	Learning Rate: 0.000155707
	LOSS [training: 0.15986755064280034 | validation: 0.15086064471189625]
	TIME [epoch: 36 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16292151117988826		[learning rate: 0.00015509]
	Learning Rate: 0.000155088
	LOSS [training: 0.16292151117988826 | validation: 0.13270172949998052]
	TIME [epoch: 36 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1666649566817383		[learning rate: 0.00015447]
	Learning Rate: 0.000154471
	LOSS [training: 0.1666649566817383 | validation: 0.1401350616658908]
	TIME [epoch: 36 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16533529608429542		[learning rate: 0.00015386]
	Learning Rate: 0.000153856
	LOSS [training: 0.16533529608429542 | validation: 0.13713404836003326]
	TIME [epoch: 36 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15673399730585333		[learning rate: 0.00015324]
	Learning Rate: 0.000153244
	LOSS [training: 0.15673399730585333 | validation: 0.14200476416086444]
	TIME [epoch: 36 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1521137427867746		[learning rate: 0.00015263]
	Learning Rate: 0.000152635
	LOSS [training: 0.1521137427867746 | validation: 0.13765177994765526]
	TIME [epoch: 36 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14870672910543756		[learning rate: 0.00015203]
	Learning Rate: 0.000152028
	LOSS [training: 0.14870672910543756 | validation: 0.13486232572568652]
	TIME [epoch: 36 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15653746559955894		[learning rate: 0.00015142]
	Learning Rate: 0.000151423
	LOSS [training: 0.15653746559955894 | validation: 0.13857479517685345]
	TIME [epoch: 36 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15893480607445154		[learning rate: 0.00015082]
	Learning Rate: 0.000150821
	LOSS [training: 0.15893480607445154 | validation: 0.1338313874723152]
	TIME [epoch: 36 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15889793306924435		[learning rate: 0.00015022]
	Learning Rate: 0.000150221
	LOSS [training: 0.15889793306924435 | validation: 0.1439968664001698]
	TIME [epoch: 36 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16163724844122074		[learning rate: 0.00014962]
	Learning Rate: 0.000149624
	LOSS [training: 0.16163724844122074 | validation: 0.14300755217112635]
	TIME [epoch: 36 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1580089424226641		[learning rate: 0.00014903]
	Learning Rate: 0.000149028
	LOSS [training: 0.1580089424226641 | validation: 0.13903829721519995]
	TIME [epoch: 36 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17682994218280024		[learning rate: 0.00014844]
	Learning Rate: 0.000148436
	LOSS [training: 0.17682994218280024 | validation: 0.13631774190072565]
	TIME [epoch: 36 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16033541261970596		[learning rate: 0.00014785]
	Learning Rate: 0.000147845
	LOSS [training: 0.16033541261970596 | validation: 0.13505989506249338]
	TIME [epoch: 36 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16381785698531104		[learning rate: 0.00014726]
	Learning Rate: 0.000147257
	LOSS [training: 0.16381785698531104 | validation: 0.1345286463351681]
	TIME [epoch: 36 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1605838582961596		[learning rate: 0.00014667]
	Learning Rate: 0.000146672
	LOSS [training: 0.1605838582961596 | validation: 0.13646694148124813]
	TIME [epoch: 36 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16416571805962263		[learning rate: 0.00014609]
	Learning Rate: 0.000146088
	LOSS [training: 0.16416571805962263 | validation: 0.14772268784986278]
	TIME [epoch: 36 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16024786005533997		[learning rate: 0.00014551]
	Learning Rate: 0.000145507
	LOSS [training: 0.16024786005533997 | validation: 0.14023711699464697]
	TIME [epoch: 36 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15642273679799154		[learning rate: 0.00014493]
	Learning Rate: 0.000144929
	LOSS [training: 0.15642273679799154 | validation: 0.13852645655788978]
	TIME [epoch: 36 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15165923998572053		[learning rate: 0.00014435]
	Learning Rate: 0.000144352
	LOSS [training: 0.15165923998572053 | validation: 0.1410110804157224]
	TIME [epoch: 36 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1621586127787609		[learning rate: 0.00014378]
	Learning Rate: 0.000143778
	LOSS [training: 0.1621586127787609 | validation: 0.13295101464324216]
	TIME [epoch: 36 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15940438810755714		[learning rate: 0.00014321]
	Learning Rate: 0.000143206
	LOSS [training: 0.15940438810755714 | validation: 0.13461517233443088]
	TIME [epoch: 36 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16465156250553492		[learning rate: 0.00014264]
	Learning Rate: 0.000142637
	LOSS [training: 0.16465156250553492 | validation: 0.1403133616602376]
	TIME [epoch: 36 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1616350481908488		[learning rate: 0.00014207]
	Learning Rate: 0.000142069
	LOSS [training: 0.1616350481908488 | validation: 0.14276868108214963]
	TIME [epoch: 36 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1579094015659971		[learning rate: 0.0001415]
	Learning Rate: 0.000141504
	LOSS [training: 0.1579094015659971 | validation: 0.1489089970628697]
	TIME [epoch: 36 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16104951257909494		[learning rate: 0.00014094]
	Learning Rate: 0.000140941
	LOSS [training: 0.16104951257909494 | validation: 0.13896172081616376]
	TIME [epoch: 36 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15853452981546623		[learning rate: 0.00014038]
	Learning Rate: 0.000140381
	LOSS [training: 0.15853452981546623 | validation: 0.14290679687742153]
	TIME [epoch: 36 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16922885104474744		[learning rate: 0.00013982]
	Learning Rate: 0.000139822
	LOSS [training: 0.16922885104474744 | validation: 0.14215165721046819]
	TIME [epoch: 36 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1630460381270438		[learning rate: 0.00013927]
	Learning Rate: 0.000139266
	LOSS [training: 0.1630460381270438 | validation: 0.13642513431251527]
	TIME [epoch: 36 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16007302726573996		[learning rate: 0.00013871]
	Learning Rate: 0.000138712
	LOSS [training: 0.16007302726573996 | validation: 0.1452973071379706]
	TIME [epoch: 36 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16163754981823644		[learning rate: 0.00013816]
	Learning Rate: 0.000138161
	LOSS [training: 0.16163754981823644 | validation: 0.14100824756868313]
	TIME [epoch: 36 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15572533582171552		[learning rate: 0.00013761]
	Learning Rate: 0.000137611
	LOSS [training: 0.15572533582171552 | validation: 0.1347917709204652]
	TIME [epoch: 36 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15670709389324033		[learning rate: 0.00013706]
	Learning Rate: 0.000137064
	LOSS [training: 0.15670709389324033 | validation: 0.14288686808936227]
	TIME [epoch: 36 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16161485554638363		[learning rate: 0.00013652]
	Learning Rate: 0.000136519
	LOSS [training: 0.16161485554638363 | validation: 0.14139866029429413]
	TIME [epoch: 36 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15968455127106498		[learning rate: 0.00013598]
	Learning Rate: 0.000135976
	LOSS [training: 0.15968455127106498 | validation: 0.14722081692295735]
	TIME [epoch: 36 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16135200912894726		[learning rate: 0.00013543]
	Learning Rate: 0.000135435
	LOSS [training: 0.16135200912894726 | validation: 0.13749253553964524]
	TIME [epoch: 36 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15510697891899886		[learning rate: 0.0001349]
	Learning Rate: 0.000134896
	LOSS [training: 0.15510697891899886 | validation: 0.1421183257401824]
	TIME [epoch: 36 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1576581365564937		[learning rate: 0.00013436]
	Learning Rate: 0.00013436
	LOSS [training: 0.1576581365564937 | validation: 0.13669511088196173]
	TIME [epoch: 36 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16208577927910076		[learning rate: 0.00013383]
	Learning Rate: 0.000133825
	LOSS [training: 0.16208577927910076 | validation: 0.13234673472390823]
	TIME [epoch: 36 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1679432303988915		[learning rate: 0.00013329]
	Learning Rate: 0.000133293
	LOSS [training: 0.1679432303988915 | validation: 0.14435027141581533]
	TIME [epoch: 36 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16797438686075322		[learning rate: 0.00013276]
	Learning Rate: 0.000132763
	LOSS [training: 0.16797438686075322 | validation: 0.13851332875644168]
	TIME [epoch: 36 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1657045077374444		[learning rate: 0.00013223]
	Learning Rate: 0.000132235
	LOSS [training: 0.1657045077374444 | validation: 0.14064767057817584]
	TIME [epoch: 36 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1693521182006301		[learning rate: 0.00013171]
	Learning Rate: 0.000131709
	LOSS [training: 0.1693521182006301 | validation: 0.13744928101849035]
	TIME [epoch: 36 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15800834808233438		[learning rate: 0.00013119]
	Learning Rate: 0.000131185
	LOSS [training: 0.15800834808233438 | validation: 0.1435010674683155]
	TIME [epoch: 36 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16527394593989325		[learning rate: 0.00013066]
	Learning Rate: 0.000130663
	LOSS [training: 0.16527394593989325 | validation: 0.135825687947403]
	TIME [epoch: 36 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1668508469637139		[learning rate: 0.00013014]
	Learning Rate: 0.000130144
	LOSS [training: 0.1668508469637139 | validation: 0.14430772924037583]
	TIME [epoch: 36 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17078964829754112		[learning rate: 0.00012963]
	Learning Rate: 0.000129626
	LOSS [training: 0.17078964829754112 | validation: 0.14031377034993944]
	TIME [epoch: 36 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15398606146729685		[learning rate: 0.00012911]
	Learning Rate: 0.000129111
	LOSS [training: 0.15398606146729685 | validation: 0.13198259085935374]
	TIME [epoch: 36 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.169721767209697		[learning rate: 0.0001286]
	Learning Rate: 0.000128597
	LOSS [training: 0.169721767209697 | validation: 0.14759572595945963]
	TIME [epoch: 36 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16107541637116668		[learning rate: 0.00012809]
	Learning Rate: 0.000128086
	LOSS [training: 0.16107541637116668 | validation: 0.1446391057016225]
	TIME [epoch: 36 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1635229533478079		[learning rate: 0.00012758]
	Learning Rate: 0.000127576
	LOSS [training: 0.1635229533478079 | validation: 0.13946213088989823]
	TIME [epoch: 36 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16399346758616293		[learning rate: 0.00012707]
	Learning Rate: 0.000127069
	LOSS [training: 0.16399346758616293 | validation: 0.14207900562952192]
	TIME [epoch: 36 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1560845920910639		[learning rate: 0.00012656]
	Learning Rate: 0.000126563
	LOSS [training: 0.1560845920910639 | validation: 0.14064323874054283]
	TIME [epoch: 36.1 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1636432565117435		[learning rate: 0.00012606]
	Learning Rate: 0.00012606
	LOSS [training: 0.1636432565117435 | validation: 0.13715450486341924]
	TIME [epoch: 36.1 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16439030622893586		[learning rate: 0.00012556]
	Learning Rate: 0.000125559
	LOSS [training: 0.16439030622893586 | validation: 0.13912608459195094]
	TIME [epoch: 36.1 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1585857226080216		[learning rate: 0.00012506]
	Learning Rate: 0.000125059
	LOSS [training: 0.1585857226080216 | validation: 0.1403600704641052]
	TIME [epoch: 36 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16088834032238958		[learning rate: 0.00012456]
	Learning Rate: 0.000124562
	LOSS [training: 0.16088834032238958 | validation: 0.13779652255842084]
	TIME [epoch: 36 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15948084958321074		[learning rate: 0.00012407]
	Learning Rate: 0.000124066
	LOSS [training: 0.15948084958321074 | validation: 0.1400590063275408]
	TIME [epoch: 36 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16019039912060096		[learning rate: 0.00012357]
	Learning Rate: 0.000123573
	LOSS [training: 0.16019039912060096 | validation: 0.14408857430256536]
	TIME [epoch: 36.1 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16207078837155928		[learning rate: 0.00012308]
	Learning Rate: 0.000123081
	LOSS [training: 0.16207078837155928 | validation: 0.14783296559571676]
	TIME [epoch: 36 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15767128878680872		[learning rate: 0.00012259]
	Learning Rate: 0.000122592
	LOSS [training: 0.15767128878680872 | validation: 0.13500805206710084]
	TIME [epoch: 36 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1576317301704152		[learning rate: 0.0001221]
	Learning Rate: 0.000122104
	LOSS [training: 0.1576317301704152 | validation: 0.14149884133668916]
	TIME [epoch: 36 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15762754972217285		[learning rate: 0.00012162]
	Learning Rate: 0.000121619
	LOSS [training: 0.15762754972217285 | validation: 0.14038473750738717]
	TIME [epoch: 36 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16159653965755025		[learning rate: 0.00012113]
	Learning Rate: 0.000121135
	LOSS [training: 0.16159653965755025 | validation: 0.13995404471786904]
	TIME [epoch: 36 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16190486190794215		[learning rate: 0.00012065]
	Learning Rate: 0.000120653
	LOSS [training: 0.16190486190794215 | validation: 0.13366881970799324]
	TIME [epoch: 36 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1537007227922982		[learning rate: 0.00012017]
	Learning Rate: 0.000120173
	LOSS [training: 0.1537007227922982 | validation: 0.14428599055253555]
	TIME [epoch: 36 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1648725411667942		[learning rate: 0.0001197]
	Learning Rate: 0.000119695
	LOSS [training: 0.1648725411667942 | validation: 0.13535222241354755]
	TIME [epoch: 36 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16364880233462703		[learning rate: 0.00011922]
	Learning Rate: 0.000119219
	LOSS [training: 0.16364880233462703 | validation: 0.14128476776667878]
	TIME [epoch: 36 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16190454221086942		[learning rate: 0.00011875]
	Learning Rate: 0.000118745
	LOSS [training: 0.16190454221086942 | validation: 0.13412348786176526]
	TIME [epoch: 36 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15705710672996268		[learning rate: 0.00011827]
	Learning Rate: 0.000118273
	LOSS [training: 0.15705710672996268 | validation: 0.13686457459764192]
	TIME [epoch: 36 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.170649926130041		[learning rate: 0.0001178]
	Learning Rate: 0.000117802
	LOSS [training: 0.170649926130041 | validation: 0.1431971779454995]
	TIME [epoch: 36 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1721201100782954		[learning rate: 0.00011733]
	Learning Rate: 0.000117334
	LOSS [training: 0.1721201100782954 | validation: 0.14009211888466233]
	TIME [epoch: 36 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17422797076622645		[learning rate: 0.00011687]
	Learning Rate: 0.000116867
	LOSS [training: 0.17422797076622645 | validation: 0.1427936809604566]
	TIME [epoch: 36 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15677644965770826		[learning rate: 0.0001164]
	Learning Rate: 0.000116402
	LOSS [training: 0.15677644965770826 | validation: 0.13875933408809005]
	TIME [epoch: 36 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1660502408903634		[learning rate: 0.00011594]
	Learning Rate: 0.000115939
	LOSS [training: 0.1660502408903634 | validation: 0.14253629809977533]
	TIME [epoch: 36 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16716804705229638		[learning rate: 0.00011548]
	Learning Rate: 0.000115478
	LOSS [training: 0.16716804705229638 | validation: 0.139130286398172]
	TIME [epoch: 36 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1540875681832492		[learning rate: 0.00011502]
	Learning Rate: 0.000115019
	LOSS [training: 0.1540875681832492 | validation: 0.14649287855101525]
	TIME [epoch: 36 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15155044358959704		[learning rate: 0.00011456]
	Learning Rate: 0.000114561
	LOSS [training: 0.15155044358959704 | validation: 0.14204330924880598]
	TIME [epoch: 36 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16199055064005294		[learning rate: 0.00011411]
	Learning Rate: 0.000114106
	LOSS [training: 0.16199055064005294 | validation: 0.14134898023287898]
	TIME [epoch: 36 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15419165223681233		[learning rate: 0.00011365]
	Learning Rate: 0.000113652
	LOSS [training: 0.15419165223681233 | validation: 0.1365511522284399]
	TIME [epoch: 36 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1703480671442412		[learning rate: 0.0001132]
	Learning Rate: 0.0001132
	LOSS [training: 0.1703480671442412 | validation: 0.13059109340874406]
	TIME [epoch: 36 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15741143705093263		[learning rate: 0.00011275]
	Learning Rate: 0.00011275
	LOSS [training: 0.15741143705093263 | validation: 0.14493686504550327]
	TIME [epoch: 36 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16321922463707458		[learning rate: 0.0001123]
	Learning Rate: 0.000112301
	LOSS [training: 0.16321922463707458 | validation: 0.14044651712106482]
	TIME [epoch: 36 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16382183405208856		[learning rate: 0.00011185]
	Learning Rate: 0.000111855
	LOSS [training: 0.16382183405208856 | validation: 0.1440706904188441]
	TIME [epoch: 36 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16710070913488165		[learning rate: 0.00011141]
	Learning Rate: 0.00011141
	LOSS [training: 0.16710070913488165 | validation: 0.1447705837681013]
	TIME [epoch: 36 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16834910856407342		[learning rate: 0.00011097]
	Learning Rate: 0.000110967
	LOSS [training: 0.16834910856407342 | validation: 0.1460576225522673]
	TIME [epoch: 36 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16739829366004388		[learning rate: 0.00011053]
	Learning Rate: 0.000110525
	LOSS [training: 0.16739829366004388 | validation: 0.14117948032373798]
	TIME [epoch: 36 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17630578978856945		[learning rate: 0.00011009]
	Learning Rate: 0.000110086
	LOSS [training: 0.17630578978856945 | validation: 0.1380964742350946]
	TIME [epoch: 36 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16746831922754327		[learning rate: 0.00010965]
	Learning Rate: 0.000109648
	LOSS [training: 0.16746831922754327 | validation: 0.14219250101206277]
	TIME [epoch: 36 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15850391059616648		[learning rate: 0.00010921]
	Learning Rate: 0.000109212
	LOSS [training: 0.15850391059616648 | validation: 0.14200401443420016]
	TIME [epoch: 36 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17590699614979832		[learning rate: 0.00010878]
	Learning Rate: 0.000108777
	LOSS [training: 0.17590699614979832 | validation: 0.13359762709612272]
	TIME [epoch: 36 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1632227366707223		[learning rate: 0.00010834]
	Learning Rate: 0.000108345
	LOSS [training: 0.1632227366707223 | validation: 0.14100827741623592]
	TIME [epoch: 36 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16575948608576235		[learning rate: 0.00010791]
	Learning Rate: 0.000107914
	LOSS [training: 0.16575948608576235 | validation: 0.13949128676291825]
	TIME [epoch: 36 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17322175072918714		[learning rate: 0.00010748]
	Learning Rate: 0.000107485
	LOSS [training: 0.17322175072918714 | validation: 0.14280489411635233]
	TIME [epoch: 36 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16169337108298726		[learning rate: 0.00010706]
	Learning Rate: 0.000107057
	LOSS [training: 0.16169337108298726 | validation: 0.13845176596475148]
	TIME [epoch: 36 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1626222978308972		[learning rate: 0.00010663]
	Learning Rate: 0.000106631
	LOSS [training: 0.1626222978308972 | validation: 0.1390088388942163]
	TIME [epoch: 36 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15728275567066838		[learning rate: 0.00010621]
	Learning Rate: 0.000106207
	LOSS [training: 0.15728275567066838 | validation: 0.13467355262420094]
	TIME [epoch: 36 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1666086425531821		[learning rate: 0.00010578]
	Learning Rate: 0.000105785
	LOSS [training: 0.1666086425531821 | validation: 0.13626086258855868]
	TIME [epoch: 36 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16859806805629654		[learning rate: 0.00010536]
