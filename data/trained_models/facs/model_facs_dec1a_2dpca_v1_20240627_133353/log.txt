Args:
Namespace(name='model_facs_dec1a_2dpca_v1', outdir='out/model_training/model_facs_dec1a_2dpca_v1', training_data='data/training_data/facs/pca/dec1/transition1_subset_epi_tr_ce_an_pc12/training', validation_data='data/training_data/facs/pca/dec1/transition1_subset_epi_tr_ce_an_pc12/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=5, patience=200, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, ncells_sample=500, model_do_sample=False, dt=0.001, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 984057021

Training model...

Saving initial model state to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_133353/states/model_facs_dec1a_2dpca_v1_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7408194189332117		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7408194189332117 | validation: 0.5632328384816903]
	TIME [epoch: 57.5 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_133353/states/model_facs_dec1a_2dpca_v1_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6142492748405317		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6142492748405317 | validation: 0.5593544762747218]
	TIME [epoch: 35.1 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_133353/states/model_facs_dec1a_2dpca_v1_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6891431093900392		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6891431093900392 | validation: 0.5422816890338442]
	TIME [epoch: 35 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_133353/states/model_facs_dec1a_2dpca_v1_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5719893481714393		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5719893481714393 | validation: 0.5064385409536771]
	TIME [epoch: 35 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_133353/states/model_facs_dec1a_2dpca_v1_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5550241150632326		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5550241150632326 | validation: 0.48985296058514854]
	TIME [epoch: 35 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_133353/states/model_facs_dec1a_2dpca_v1_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5319297167243805		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5319297167243805 | validation: 0.4877024002014777]
	TIME [epoch: 35 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_133353/states/model_facs_dec1a_2dpca_v1_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.543949757899633		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.543949757899633 | validation: 0.45783334668143727]
	TIME [epoch: 35.1 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_133353/states/model_facs_dec1a_2dpca_v1_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5224097400670956		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5224097400670956 | validation: 0.4473417559697498]
	TIME [epoch: 35 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_133353/states/model_facs_dec1a_2dpca_v1_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5126882239783115		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5126882239783115 | validation: 0.43100368164531544]
	TIME [epoch: 35.1 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_133353/states/model_facs_dec1a_2dpca_v1_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4466674427661017		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4466674427661017 | validation: 0.39661337997869023]
	TIME [epoch: 35 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_133353/states/model_facs_dec1a_2dpca_v1_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.41815105317230117		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.41815105317230117 | validation: 0.34949171229695947]
	TIME [epoch: 35 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_133353/states/model_facs_dec1a_2dpca_v1_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4424907668577093		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4424907668577093 | validation: 0.3136644300536683]
	TIME [epoch: 35 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_133353/states/model_facs_dec1a_2dpca_v1_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3590958036272017		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3590958036272017 | validation: 0.3157071865065723]
	TIME [epoch: 35 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32862645438119453		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.32862645438119453 | validation: 0.27594294187358054]
	TIME [epoch: 35 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_133353/states/model_facs_dec1a_2dpca_v1_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3252908814403051		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3252908814403051 | validation: 0.2468445949987788]
	TIME [epoch: 35 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_133353/states/model_facs_dec1a_2dpca_v1_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.29545186025622194		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.29545186025622194 | validation: 0.224314293406258]
	TIME [epoch: 35.1 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_133353/states/model_facs_dec1a_2dpca_v1_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26763757661744203		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.26763757661744203 | validation: 0.20895449064469904]
	TIME [epoch: 35 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_133353/states/model_facs_dec1a_2dpca_v1_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.26463276133128333		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.26463276133128333 | validation: 0.20469482269414913]
	TIME [epoch: 35 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_133353/states/model_facs_dec1a_2dpca_v1_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.24607376981846274		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24607376981846274 | validation: 0.21770117868419042]
	TIME [epoch: 35 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23680468924940362		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23680468924940362 | validation: 0.18441295828618198]
	TIME [epoch: 35 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_133353/states/model_facs_dec1a_2dpca_v1_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22010056128844832		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22010056128844832 | validation: 0.2230029100939826]
	TIME [epoch: 35 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23963677623928406		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23963677623928406 | validation: 0.18949637673750303]
	TIME [epoch: 35 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2541668224228151		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2541668224228151 | validation: 0.1641384966878589]
	TIME [epoch: 35 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_133353/states/model_facs_dec1a_2dpca_v1_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.23451547259816052		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23451547259816052 | validation: 0.16468528108070643]
	TIME [epoch: 35 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22828709029195215		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22828709029195215 | validation: 0.1667058686606559]
	TIME [epoch: 35 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.21002761011288307		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.21002761011288307 | validation: 0.1496557893818951]
	TIME [epoch: 35 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_133353/states/model_facs_dec1a_2dpca_v1_26.pth
	Model improved!!!
EPOCH 27/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.19726935730162698		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.19726935730162698 | validation: 0.1366351735980626]
	TIME [epoch: 35 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_133353/states/model_facs_dec1a_2dpca_v1_27.pth
	Model improved!!!
EPOCH 28/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2177422604145671		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2177422604145671 | validation: 0.1497206259678399]
	TIME [epoch: 35 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1913699376133834		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1913699376133834 | validation: 0.17863682732689085]
	TIME [epoch: 35 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17396100217548688		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17396100217548688 | validation: 0.14154361496137943]
	TIME [epoch: 35 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.18834139204405476		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18834139204405476 | validation: 0.14941988295219794]
	TIME [epoch: 35 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.18195349580804548		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18195349580804548 | validation: 0.16165598604529238]
	TIME [epoch: 35 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2061416959909453		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2061416959909453 | validation: 0.13406089164248938]
	TIME [epoch: 35 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_133353/states/model_facs_dec1a_2dpca_v1_33.pth
	Model improved!!!
EPOCH 34/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17063827227997405		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17063827227997405 | validation: 0.14564211398271598]
	TIME [epoch: 35.1 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16420797838540738		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16420797838540738 | validation: 0.13211590833356843]
	TIME [epoch: 35 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_133353/states/model_facs_dec1a_2dpca_v1_35.pth
	Model improved!!!
EPOCH 36/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1721285125006992		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1721285125006992 | validation: 0.19001186445259627]
	TIME [epoch: 35 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17360149548775194		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17360149548775194 | validation: 0.14381229752310018]
	TIME [epoch: 35 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.18757136754226686		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18757136754226686 | validation: 0.15532519955223256]
	TIME [epoch: 35 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.20242743148006836		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20242743148006836 | validation: 0.14306230536397554]
	TIME [epoch: 35 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1863959053924337		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1863959053924337 | validation: 0.13280872219342277]
	TIME [epoch: 35 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16156892880314724		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16156892880314724 | validation: 0.1651424373044404]
	TIME [epoch: 35 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17183433055428418		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17183433055428418 | validation: 0.13796641198913856]
	TIME [epoch: 35 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17924276798643832		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17924276798643832 | validation: 0.18724696489236387]
	TIME [epoch: 35 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.19940882013032324		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.19940882013032324 | validation: 0.14709312656603377]
	TIME [epoch: 35 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.18815187422863186		[learning rate: 0.0099823]
	Learning Rate: 0.0099823
	LOSS [training: 0.18815187422863186 | validation: 0.13300391424809027]
	TIME [epoch: 35 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15336783418393182		[learning rate: 0.0099426]
	Learning Rate: 0.0099426
	LOSS [training: 0.15336783418393182 | validation: 0.1313093887911981]
	TIME [epoch: 35 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_133353/states/model_facs_dec1a_2dpca_v1_46.pth
	Model improved!!!
EPOCH 47/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16851095160571508		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 0.16851095160571508 | validation: 0.15100434875655733]
	TIME [epoch: 35 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1823077901570516		[learning rate: 0.0098637]
	Learning Rate: 0.00986367
	LOSS [training: 0.1823077901570516 | validation: 0.15280377325331998]
	TIME [epoch: 35 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15516380590558077		[learning rate: 0.0098244]
	Learning Rate: 0.00982444
	LOSS [training: 0.15516380590558077 | validation: 0.1350308452602233]
	TIME [epoch: 35 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1768077940239829		[learning rate: 0.0097854]
	Learning Rate: 0.00978536
	LOSS [training: 0.1768077940239829 | validation: 0.14238382610110675]
	TIME [epoch: 35 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16724974857168493		[learning rate: 0.0097464]
	Learning Rate: 0.00974644
	LOSS [training: 0.16724974857168493 | validation: 0.12348654026698994]
	TIME [epoch: 35 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_133353/states/model_facs_dec1a_2dpca_v1_51.pth
	Model improved!!!
EPOCH 52/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15115892422865107		[learning rate: 0.0097077]
	Learning Rate: 0.00970768
	LOSS [training: 0.15115892422865107 | validation: 0.13285312195512428]
	TIME [epoch: 35 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15591019039997198		[learning rate: 0.0096691]
	Learning Rate: 0.00966907
	LOSS [training: 0.15591019039997198 | validation: 0.1399495403960322]
	TIME [epoch: 35 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15968615165354438		[learning rate: 0.0096306]
	Learning Rate: 0.00963061
	LOSS [training: 0.15968615165354438 | validation: 0.1343509089081089]
	TIME [epoch: 35 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15149112698738376		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 0.15149112698738376 | validation: 0.14584200120894641]
	TIME [epoch: 35 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17536763087520338		[learning rate: 0.0095542]
	Learning Rate: 0.00955415
	LOSS [training: 0.17536763087520338 | validation: 0.20064566574867793]
	TIME [epoch: 35 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.18341728465157037		[learning rate: 0.0095162]
	Learning Rate: 0.00951616
	LOSS [training: 0.18341728465157037 | validation: 0.15208874483013293]
	TIME [epoch: 35 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.169184337189008		[learning rate: 0.0094783]
	Learning Rate: 0.00947831
	LOSS [training: 0.169184337189008 | validation: 0.14725705011211002]
	TIME [epoch: 34.9 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17152264186970687		[learning rate: 0.0094406]
	Learning Rate: 0.00944061
	LOSS [training: 0.17152264186970687 | validation: 0.1416562929602139]
	TIME [epoch: 35 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14376229047432812		[learning rate: 0.0094031]
	Learning Rate: 0.00940306
	LOSS [training: 0.14376229047432812 | validation: 0.1341550916891598]
	TIME [epoch: 35 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16446857188678965		[learning rate: 0.0093657]
	Learning Rate: 0.00936566
	LOSS [training: 0.16446857188678965 | validation: 0.1316827366184175]
	TIME [epoch: 35 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17107419772643748		[learning rate: 0.0093284]
	Learning Rate: 0.00932841
	LOSS [training: 0.17107419772643748 | validation: 0.1885947137969432]
	TIME [epoch: 34.9 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17544840202072853		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 0.17544840202072853 | validation: 0.15462918473535678]
	TIME [epoch: 35 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1778975562714746		[learning rate: 0.0092544]
	Learning Rate: 0.00925435
	LOSS [training: 0.1778975562714746 | validation: 0.12310338253756328]
	TIME [epoch: 35 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_133353/states/model_facs_dec1a_2dpca_v1_64.pth
	Model improved!!!
EPOCH 65/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1492130096249487		[learning rate: 0.0092175]
	Learning Rate: 0.00921755
	LOSS [training: 0.1492130096249487 | validation: 0.12842852700815993]
	TIME [epoch: 35 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1505878092787991		[learning rate: 0.0091809]
	Learning Rate: 0.00918089
	LOSS [training: 0.1505878092787991 | validation: 0.14646134150136741]
	TIME [epoch: 35 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.169608680387431		[learning rate: 0.0091444]
	Learning Rate: 0.00914437
	LOSS [training: 0.169608680387431 | validation: 0.12304649033695252]
	TIME [epoch: 35 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_133353/states/model_facs_dec1a_2dpca_v1_67.pth
	Model improved!!!
EPOCH 68/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14991242275965067		[learning rate: 0.009108]
	Learning Rate: 0.009108
	LOSS [training: 0.14991242275965067 | validation: 0.14644946416397145]
	TIME [epoch: 35 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14893491287426008		[learning rate: 0.0090718]
	Learning Rate: 0.00907178
	LOSS [training: 0.14893491287426008 | validation: 0.15015210636234186]
	TIME [epoch: 35 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16747608369901903		[learning rate: 0.0090357]
	Learning Rate: 0.00903569
	LOSS [training: 0.16747608369901903 | validation: 0.11076751929020053]
	TIME [epoch: 35 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_133353/states/model_facs_dec1a_2dpca_v1_70.pth
	Model improved!!!
EPOCH 71/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15588546044532953		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 0.15588546044532953 | validation: 0.12624454701670246]
	TIME [epoch: 35 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14450676673669133		[learning rate: 0.008964]
	Learning Rate: 0.00896396
	LOSS [training: 0.14450676673669133 | validation: 0.11199618695980744]
	TIME [epoch: 35 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14665228537091424		[learning rate: 0.0089283]
	Learning Rate: 0.00892831
	LOSS [training: 0.14665228537091424 | validation: 0.19977141228473966]
	TIME [epoch: 35 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17492223083277614		[learning rate: 0.0088928]
	Learning Rate: 0.0088928
	LOSS [training: 0.17492223083277614 | validation: 0.11928359504778159]
	TIME [epoch: 34.9 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.17164596410270333		[learning rate: 0.0088574]
	Learning Rate: 0.00885743
	LOSS [training: 0.17164596410270333 | validation: 0.11794963848292639]
	TIME [epoch: 35 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15042427219860585		[learning rate: 0.0088222]
	Learning Rate: 0.0088222
	LOSS [training: 0.15042427219860585 | validation: 0.11733726174633305]
	TIME [epoch: 35 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15095684710744248		[learning rate: 0.0087871]
	Learning Rate: 0.00878711
	LOSS [training: 0.15095684710744248 | validation: 0.11029196069302619]
	TIME [epoch: 35 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_133353/states/model_facs_dec1a_2dpca_v1_77.pth
	Model improved!!!
EPOCH 78/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14138779728441453		[learning rate: 0.0087522]
	Learning Rate: 0.00875216
	LOSS [training: 0.14138779728441453 | validation: 0.11539350730117388]
	TIME [epoch: 34.9 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14084511066146302		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 0.14084511066146302 | validation: 0.10833194338650273]
	TIME [epoch: 35 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_133353/states/model_facs_dec1a_2dpca_v1_79.pth
	Model improved!!!
EPOCH 80/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14354196112495424		[learning rate: 0.0086827]
	Learning Rate: 0.00868268
	LOSS [training: 0.14354196112495424 | validation: 0.12516634229507975]
	TIME [epoch: 35 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14326080912014097		[learning rate: 0.0086481]
	Learning Rate: 0.00864815
	LOSS [training: 0.14326080912014097 | validation: 0.14116113248557866]
	TIME [epoch: 35 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15391825663827574		[learning rate: 0.0086138]
	Learning Rate: 0.00861375
	LOSS [training: 0.15391825663827574 | validation: 0.1121516776864964]
	TIME [epoch: 35 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15856894430095883		[learning rate: 0.0085795]
	Learning Rate: 0.00857949
	LOSS [training: 0.15856894430095883 | validation: 0.12076500651400579]
	TIME [epoch: 35 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14199452617838393		[learning rate: 0.0085454]
	Learning Rate: 0.00854537
	LOSS [training: 0.14199452617838393 | validation: 0.12025691530266167]
	TIME [epoch: 35 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1361189820222206		[learning rate: 0.0085114]
	Learning Rate: 0.00851138
	LOSS [training: 0.1361189820222206 | validation: 0.16131000915811394]
	TIME [epoch: 35.1 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15224556366474795		[learning rate: 0.0084775]
	Learning Rate: 0.00847753
	LOSS [training: 0.15224556366474795 | validation: 0.15398566094396643]
	TIME [epoch: 35.1 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16303827330230827		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 0.16303827330230827 | validation: 0.1433474516424289]
	TIME [epoch: 35 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14683329036194015		[learning rate: 0.0084102]
	Learning Rate: 0.00841023
	LOSS [training: 0.14683329036194015 | validation: 0.14177465259628624]
	TIME [epoch: 35 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14980253789339315		[learning rate: 0.0083768]
	Learning Rate: 0.00837678
	LOSS [training: 0.14980253789339315 | validation: 0.14377864466438306]
	TIME [epoch: 35 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1721184625653307		[learning rate: 0.0083435]
	Learning Rate: 0.00834346
	LOSS [training: 0.1721184625653307 | validation: 0.12819218770823743]
	TIME [epoch: 35 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12876683981408577		[learning rate: 0.0083103]
	Learning Rate: 0.00831027
	LOSS [training: 0.12876683981408577 | validation: 0.1264012212096471]
	TIME [epoch: 35 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15781683451488965		[learning rate: 0.0082772]
	Learning Rate: 0.00827722
	LOSS [training: 0.15781683451488965 | validation: 0.1195083849588153]
	TIME [epoch: 35 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15121887058690053		[learning rate: 0.0082443]
	Learning Rate: 0.0082443
	LOSS [training: 0.15121887058690053 | validation: 0.11235864762936934]
	TIME [epoch: 35 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14264298357032926		[learning rate: 0.0082115]
	Learning Rate: 0.00821151
	LOSS [training: 0.14264298357032926 | validation: 0.12500978108145172]
	TIME [epoch: 34.9 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1396769144947792		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 0.1396769144947792 | validation: 0.11720716017170836]
	TIME [epoch: 35 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13120422665980638		[learning rate: 0.0081463]
	Learning Rate: 0.00814632
	LOSS [training: 0.13120422665980638 | validation: 0.12089259741421428]
	TIME [epoch: 34.9 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14092664900646437		[learning rate: 0.0081139]
	Learning Rate: 0.00811392
	LOSS [training: 0.14092664900646437 | validation: 0.13189348828612965]
	TIME [epoch: 34.9 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15093302997474695		[learning rate: 0.0080816]
	Learning Rate: 0.00808165
	LOSS [training: 0.15093302997474695 | validation: 0.11467349795863235]
	TIME [epoch: 34.9 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13844020599385803		[learning rate: 0.0080495]
	Learning Rate: 0.00804951
	LOSS [training: 0.13844020599385803 | validation: 0.11410087580240691]
	TIME [epoch: 35 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14541520331225458		[learning rate: 0.0080175]
	Learning Rate: 0.00801749
	LOSS [training: 0.14541520331225458 | validation: 0.1162275151015014]
	TIME [epoch: 34.9 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14216183168748098		[learning rate: 0.0079856]
	Learning Rate: 0.0079856
	LOSS [training: 0.14216183168748098 | validation: 0.119102905260589]
	TIME [epoch: 34.9 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.16135984528187536		[learning rate: 0.0079538]
	Learning Rate: 0.00795384
	LOSS [training: 0.16135984528187536 | validation: 0.11834278771098031]
	TIME [epoch: 34.9 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1318285750966949		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 0.1318285750966949 | validation: 0.1174126518762502]
	TIME [epoch: 34.9 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1531496291948713		[learning rate: 0.0078907]
	Learning Rate: 0.0078907
	LOSS [training: 0.1531496291948713 | validation: 0.0982222683352156]
	TIME [epoch: 34.9 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_133353/states/model_facs_dec1a_2dpca_v1_104.pth
	Model improved!!!
EPOCH 105/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15308660791783388		[learning rate: 0.0078593]
	Learning Rate: 0.00785931
	LOSS [training: 0.15308660791783388 | validation: 0.14205181831707733]
	TIME [epoch: 34.9 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14878032730188917		[learning rate: 0.0078281]
	Learning Rate: 0.00782805
	LOSS [training: 0.14878032730188917 | validation: 0.11027564466359545]
	TIME [epoch: 34.9 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15530644832901552		[learning rate: 0.0077969]
	Learning Rate: 0.00779692
	LOSS [training: 0.15530644832901552 | validation: 0.10753740364711269]
	TIME [epoch: 34.9 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13451767795305278		[learning rate: 0.0077659]
	Learning Rate: 0.00776591
	LOSS [training: 0.13451767795305278 | validation: 0.10671739616169391]
	TIME [epoch: 34.9 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14965100182736674		[learning rate: 0.007735]
	Learning Rate: 0.00773502
	LOSS [training: 0.14965100182736674 | validation: 0.10986507285303496]
	TIME [epoch: 34.9 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14344916583237863		[learning rate: 0.0077043]
	Learning Rate: 0.00770426
	LOSS [training: 0.14344916583237863 | validation: 0.11831311878809417]
	TIME [epoch: 34.9 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14523203626592945		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 0.14523203626592945 | validation: 0.12081560809158258]
	TIME [epoch: 34.9 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12709294480571243		[learning rate: 0.0076431]
	Learning Rate: 0.00764309
	LOSS [training: 0.12709294480571243 | validation: 0.10723554553028847]
	TIME [epoch: 34.9 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12870962423996987		[learning rate: 0.0076127]
	Learning Rate: 0.00761269
	LOSS [training: 0.12870962423996987 | validation: 0.1081701235606208]
	TIME [epoch: 34.9 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1347147966678511		[learning rate: 0.0075824]
	Learning Rate: 0.00758242
	LOSS [training: 0.1347147966678511 | validation: 0.11118242216076712]
	TIME [epoch: 34.9 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14204213759989948		[learning rate: 0.0075523]
	Learning Rate: 0.00755226
	LOSS [training: 0.14204213759989948 | validation: 0.10981619190686931]
	TIME [epoch: 34.9 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13477786682326443		[learning rate: 0.0075222]
	Learning Rate: 0.00752222
	LOSS [training: 0.13477786682326443 | validation: 0.11081643871309628]
	TIME [epoch: 34.9 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1429408560484146		[learning rate: 0.0074923]
	Learning Rate: 0.0074923
	LOSS [training: 0.1429408560484146 | validation: 0.11022083925057716]
	TIME [epoch: 34.9 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13834733414606268		[learning rate: 0.0074625]
	Learning Rate: 0.0074625
	LOSS [training: 0.13834733414606268 | validation: 0.1159498526918021]
	TIME [epoch: 34.9 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13165118363251727		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 0.13165118363251727 | validation: 0.114328937653512]
	TIME [epoch: 34.9 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15111057118832202		[learning rate: 0.0074033]
	Learning Rate: 0.00740326
	LOSS [training: 0.15111057118832202 | validation: 0.131009609279425]
	TIME [epoch: 34.9 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13453293348340337		[learning rate: 0.0073738]
	Learning Rate: 0.00737382
	LOSS [training: 0.13453293348340337 | validation: 0.10130185717432016]
	TIME [epoch: 34.9 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12772514754325193		[learning rate: 0.0073445]
	Learning Rate: 0.00734449
	LOSS [training: 0.12772514754325193 | validation: 0.10320033860445296]
	TIME [epoch: 34.9 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1313512122852247		[learning rate: 0.0073153]
	Learning Rate: 0.00731528
	LOSS [training: 0.1313512122852247 | validation: 0.11312993496129586]
	TIME [epoch: 34.9 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13772216250587577		[learning rate: 0.0072862]
	Learning Rate: 0.00728618
	LOSS [training: 0.13772216250587577 | validation: 0.11464529288606436]
	TIME [epoch: 34.9 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14065784005408613		[learning rate: 0.0072572]
	Learning Rate: 0.0072572
	LOSS [training: 0.14065784005408613 | validation: 0.11627466611961326]
	TIME [epoch: 34.9 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13312768631488825		[learning rate: 0.0072283]
	Learning Rate: 0.00722834
	LOSS [training: 0.13312768631488825 | validation: 0.1048911636193105]
	TIME [epoch: 34.9 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13416026070802856		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 0.13416026070802856 | validation: 0.11622010204677813]
	TIME [epoch: 34.9 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14100794176007858		[learning rate: 0.007171]
	Learning Rate: 0.00717095
	LOSS [training: 0.14100794176007858 | validation: 0.12436048743853742]
	TIME [epoch: 34.9 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14124771562219804		[learning rate: 0.0071424]
	Learning Rate: 0.00714243
	LOSS [training: 0.14124771562219804 | validation: 0.1358457195385419]
	TIME [epoch: 34.9 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15493220142917924		[learning rate: 0.007114]
	Learning Rate: 0.00711403
	LOSS [training: 0.15493220142917924 | validation: 0.10669069220404503]
	TIME [epoch: 34.9 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13585440166523424		[learning rate: 0.0070857]
	Learning Rate: 0.00708573
	LOSS [training: 0.13585440166523424 | validation: 0.11197370332436676]
	TIME [epoch: 34.9 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1324934163046878		[learning rate: 0.0070575]
	Learning Rate: 0.00705755
	LOSS [training: 0.1324934163046878 | validation: 0.11215702562614352]
	TIME [epoch: 34.9 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13209062331612761		[learning rate: 0.0070295]
	Learning Rate: 0.00702948
	LOSS [training: 0.13209062331612761 | validation: 0.09887828989309248]
	TIME [epoch: 34.9 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12837092353759463		[learning rate: 0.0070015]
	Learning Rate: 0.00700152
	LOSS [training: 0.12837092353759463 | validation: 0.10787659767471565]
	TIME [epoch: 34.9 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13246647650656992		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 0.13246647650656992 | validation: 0.10812541052813618]
	TIME [epoch: 34.9 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13791180561454977		[learning rate: 0.0069459]
	Learning Rate: 0.00694594
	LOSS [training: 0.13791180561454977 | validation: 0.10052015965161151]
	TIME [epoch: 34.9 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12966231858805705		[learning rate: 0.0069183]
	Learning Rate: 0.00691831
	LOSS [training: 0.12966231858805705 | validation: 0.11021915880543183]
	TIME [epoch: 34.9 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13219849186226396		[learning rate: 0.0068908]
	Learning Rate: 0.00689079
	LOSS [training: 0.13219849186226396 | validation: 0.11777074300746908]
	TIME [epoch: 34.9 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13019072573483298		[learning rate: 0.0068634]
	Learning Rate: 0.00686339
	LOSS [training: 0.13019072573483298 | validation: 0.10103546169689218]
	TIME [epoch: 34.9 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1367718891256351		[learning rate: 0.0068361]
	Learning Rate: 0.00683609
	LOSS [training: 0.1367718891256351 | validation: 0.11400430344035022]
	TIME [epoch: 34.9 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.15326280276928375		[learning rate: 0.0068089]
	Learning Rate: 0.0068089
	LOSS [training: 0.15326280276928375 | validation: 0.11757299297746363]
	TIME [epoch: 34.9 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14827402374719725		[learning rate: 0.0067818]
	Learning Rate: 0.00678182
	LOSS [training: 0.14827402374719725 | validation: 0.11669289758040553]
	TIME [epoch: 34.9 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1331841333163447		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 0.1331841333163447 | validation: 0.1056256087225234]
	TIME [epoch: 34.9 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1291402828370751		[learning rate: 0.006728]
	Learning Rate: 0.00672798
	LOSS [training: 0.1291402828370751 | validation: 0.11774607634368647]
	TIME [epoch: 34.9 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12916162850792234		[learning rate: 0.0067012]
	Learning Rate: 0.00670122
	LOSS [training: 0.12916162850792234 | validation: 0.1151830166039439]
	TIME [epoch: 34.9 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14686380694127862		[learning rate: 0.0066746]
	Learning Rate: 0.00667457
	LOSS [training: 0.14686380694127862 | validation: 0.10980916295184313]
	TIME [epoch: 34.9 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14800985594868257		[learning rate: 0.006648]
	Learning Rate: 0.00664802
	LOSS [training: 0.14800985594868257 | validation: 0.10328481454262231]
	TIME [epoch: 34.9 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12092101133935954		[learning rate: 0.0066216]
	Learning Rate: 0.00662158
	LOSS [training: 0.12092101133935954 | validation: 0.10211779122113888]
	TIME [epoch: 34.9 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12356874471009698		[learning rate: 0.0065952]
	Learning Rate: 0.00659524
	LOSS [training: 0.12356874471009698 | validation: 0.10503773214159513]
	TIME [epoch: 34.9 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1352771419845165		[learning rate: 0.006569]
	Learning Rate: 0.00656901
	LOSS [training: 0.1352771419845165 | validation: 0.09717900701539481]
	TIME [epoch: 34.9 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_133353/states/model_facs_dec1a_2dpca_v1_150.pth
	Model improved!!!
EPOCH 151/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12230002049719443		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 0.12230002049719443 | validation: 0.10203963950857028]
	TIME [epoch: 34.9 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12238834807049649		[learning rate: 0.0065169]
	Learning Rate: 0.00651686
	LOSS [training: 0.12238834807049649 | validation: 0.09851054553044146]
	TIME [epoch: 34.9 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13388103006967114		[learning rate: 0.0064909]
	Learning Rate: 0.00649094
	LOSS [training: 0.13388103006967114 | validation: 0.0967528677961407]
	TIME [epoch: 34.9 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_133353/states/model_facs_dec1a_2dpca_v1_153.pth
	Model improved!!!
EPOCH 154/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12517438305599088		[learning rate: 0.0064651]
	Learning Rate: 0.00646512
	LOSS [training: 0.12517438305599088 | validation: 0.10242387462043072]
	TIME [epoch: 34.9 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13058485102216696		[learning rate: 0.0064394]
	Learning Rate: 0.00643941
	LOSS [training: 0.13058485102216696 | validation: 0.10797973819747733]
	TIME [epoch: 34.9 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1306625113015419		[learning rate: 0.0064138]
	Learning Rate: 0.0064138
	LOSS [training: 0.1306625113015419 | validation: 0.1096029065452511]
	TIME [epoch: 34.9 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13234707315492722		[learning rate: 0.0063883]
	Learning Rate: 0.00638829
	LOSS [training: 0.13234707315492722 | validation: 0.10002057404502016]
	TIME [epoch: 34.9 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11981897199975913		[learning rate: 0.0063629]
	Learning Rate: 0.00636288
	LOSS [training: 0.11981897199975913 | validation: 0.13258264510838297]
	TIME [epoch: 34.9 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13637727086863116		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 0.13637727086863116 | validation: 0.10423078622186913]
	TIME [epoch: 34.9 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12309385065830544		[learning rate: 0.0063124]
	Learning Rate: 0.00631237
	LOSS [training: 0.12309385065830544 | validation: 0.12026186236848506]
	TIME [epoch: 34.9 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14745206830476684		[learning rate: 0.0062873]
	Learning Rate: 0.00628726
	LOSS [training: 0.14745206830476684 | validation: 0.11719610028719733]
	TIME [epoch: 34.9 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14306011109142378		[learning rate: 0.0062623]
	Learning Rate: 0.00626226
	LOSS [training: 0.14306011109142378 | validation: 0.09969919466862795]
	TIME [epoch: 34.9 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1330094077717322		[learning rate: 0.0062373]
	Learning Rate: 0.00623735
	LOSS [training: 0.1330094077717322 | validation: 0.09849895213563253]
	TIME [epoch: 34.9 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12166614397991113		[learning rate: 0.0062125]
	Learning Rate: 0.00621254
	LOSS [training: 0.12166614397991113 | validation: 0.10436423616253147]
	TIME [epoch: 34.9 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1269449669126836		[learning rate: 0.0061878]
	Learning Rate: 0.00618783
	LOSS [training: 0.1269449669126836 | validation: 0.10626420345904745]
	TIME [epoch: 34.9 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1452756311808742		[learning rate: 0.0061632]
	Learning Rate: 0.00616322
	LOSS [training: 0.1452756311808742 | validation: 0.11176327682952045]
	TIME [epoch: 34.9 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12918790094814267		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 0.12918790094814267 | validation: 0.09861867971310703]
	TIME [epoch: 34.9 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13369060400816737		[learning rate: 0.0061143]
	Learning Rate: 0.00611429
	LOSS [training: 0.13369060400816737 | validation: 0.11704867072261416]
	TIME [epoch: 34.9 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13408300529381448		[learning rate: 0.00609]
	Learning Rate: 0.00608997
	LOSS [training: 0.13408300529381448 | validation: 0.10184417271518531]
	TIME [epoch: 34.9 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13735433760029425		[learning rate: 0.0060658]
	Learning Rate: 0.00606575
	LOSS [training: 0.13735433760029425 | validation: 0.10261654238361637]
	TIME [epoch: 34.9 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1357702593143086		[learning rate: 0.0060416]
	Learning Rate: 0.00604163
	LOSS [training: 0.1357702593143086 | validation: 0.10775520172641913]
	TIME [epoch: 34.9 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12195437613917005		[learning rate: 0.0060176]
	Learning Rate: 0.0060176
	LOSS [training: 0.12195437613917005 | validation: 0.11350259826949202]
	TIME [epoch: 34.9 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11839318090799934		[learning rate: 0.0059937]
	Learning Rate: 0.00599366
	LOSS [training: 0.11839318090799934 | validation: 0.10188230944110414]
	TIME [epoch: 34.9 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1281120133750964		[learning rate: 0.0059698]
	Learning Rate: 0.00596982
	LOSS [training: 0.1281120133750964 | validation: 0.10215400151673001]
	TIME [epoch: 34.9 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13446201295545268		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 0.13446201295545268 | validation: 0.09904224407903324]
	TIME [epoch: 34.9 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13516247116605223		[learning rate: 0.0059224]
	Learning Rate: 0.00592243
	LOSS [training: 0.13516247116605223 | validation: 0.09658817605236443]
	TIME [epoch: 34.9 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_133353/states/model_facs_dec1a_2dpca_v1_176.pth
	Model improved!!!
EPOCH 177/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14166899834940025		[learning rate: 0.0058989]
	Learning Rate: 0.00589888
	LOSS [training: 0.14166899834940025 | validation: 0.09376596122600397]
	TIME [epoch: 34.9 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_133353/states/model_facs_dec1a_2dpca_v1_177.pth
	Model improved!!!
EPOCH 178/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12920969212406172		[learning rate: 0.0058754]
	Learning Rate: 0.00587541
	LOSS [training: 0.12920969212406172 | validation: 0.11058437553392395]
	TIME [epoch: 34.9 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13161727617841082		[learning rate: 0.005852]
	Learning Rate: 0.00585205
	LOSS [training: 0.13161727617841082 | validation: 0.09743148063672225]
	TIME [epoch: 34.9 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1335701631695954		[learning rate: 0.0058288]
	Learning Rate: 0.00582877
	LOSS [training: 0.1335701631695954 | validation: 0.09575438520958938]
	TIME [epoch: 34.9 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12739512351427779		[learning rate: 0.0058056]
	Learning Rate: 0.00580559
	LOSS [training: 0.12739512351427779 | validation: 0.10251099486316735]
	TIME [epoch: 34.9 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12238259666518268		[learning rate: 0.0057825]
	Learning Rate: 0.0057825
	LOSS [training: 0.12238259666518268 | validation: 0.12762766075586174]
	TIME [epoch: 34.9 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14014549849442182		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 0.14014549849442182 | validation: 0.112192881303261]
	TIME [epoch: 34.9 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12308687416808113		[learning rate: 0.0057366]
	Learning Rate: 0.00573659
	LOSS [training: 0.12308687416808113 | validation: 0.10868299990665105]
	TIME [epoch: 34.9 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13078244794225935		[learning rate: 0.0057138]
	Learning Rate: 0.00571377
	LOSS [training: 0.13078244794225935 | validation: 0.09639654605544382]
	TIME [epoch: 34.9 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12407839367398522		[learning rate: 0.005691]
	Learning Rate: 0.00569105
	LOSS [training: 0.12407839367398522 | validation: 0.11354943861729735]
	TIME [epoch: 34.9 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14266755677839546		[learning rate: 0.0056684]
	Learning Rate: 0.00566841
	LOSS [training: 0.14266755677839546 | validation: 0.11087628635470534]
	TIME [epoch: 34.9 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12490751881678275		[learning rate: 0.0056459]
	Learning Rate: 0.00564587
	LOSS [training: 0.12490751881678275 | validation: 0.11025302517250149]
	TIME [epoch: 34.9 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13326844926274184		[learning rate: 0.0056234]
	Learning Rate: 0.00562341
	LOSS [training: 0.13326844926274184 | validation: 0.10830106421112487]
	TIME [epoch: 34.9 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12824554671933128		[learning rate: 0.005601]
	Learning Rate: 0.00560105
	LOSS [training: 0.12824554671933128 | validation: 0.10551788217469674]
	TIME [epoch: 34.9 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.130643129860679		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 0.130643129860679 | validation: 0.1083061915208634]
	TIME [epoch: 34.9 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14267100949368447		[learning rate: 0.0055566]
	Learning Rate: 0.00555658
	LOSS [training: 0.14267100949368447 | validation: 0.10089346902717895]
	TIME [epoch: 34.9 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13944780798905623		[learning rate: 0.0055345]
	Learning Rate: 0.00553448
	LOSS [training: 0.13944780798905623 | validation: 0.10419858131339996]
	TIME [epoch: 34.9 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12739123191077611		[learning rate: 0.0055125]
	Learning Rate: 0.00551247
	LOSS [training: 0.12739123191077611 | validation: 0.09659620507025671]
	TIME [epoch: 34.9 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.128959823225129		[learning rate: 0.0054905]
	Learning Rate: 0.00549054
	LOSS [training: 0.128959823225129 | validation: 0.11317320778797887]
	TIME [epoch: 34.9 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14520502823769257		[learning rate: 0.0054687]
	Learning Rate: 0.00546871
	LOSS [training: 0.14520502823769257 | validation: 0.10791549112084545]
	TIME [epoch: 34.9 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1298046366498612		[learning rate: 0.005447]
	Learning Rate: 0.00544696
	LOSS [training: 0.1298046366498612 | validation: 0.09671003162403258]
	TIME [epoch: 34.9 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12131877474003147		[learning rate: 0.0054253]
	Learning Rate: 0.00542529
	LOSS [training: 0.12131877474003147 | validation: 0.09683853360567549]
	TIME [epoch: 34.9 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12214588511450748		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 0.12214588511450748 | validation: 0.09766871443661088]
	TIME [epoch: 34.9 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1321872394856365		[learning rate: 0.0053822]
	Learning Rate: 0.00538222
	LOSS [training: 0.1321872394856365 | validation: 0.10152901905534062]
	TIME [epoch: 34.9 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14077724309898304		[learning rate: 0.0053608]
	Learning Rate: 0.00536081
	LOSS [training: 0.14077724309898304 | validation: 0.1025829781714311]
	TIME [epoch: 35 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1330216109400636		[learning rate: 0.0053395]
	Learning Rate: 0.00533949
	LOSS [training: 0.1330216109400636 | validation: 0.10743521682256234]
	TIME [epoch: 35 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1276275288379666		[learning rate: 0.0053183]
	Learning Rate: 0.00531826
	LOSS [training: 0.1276275288379666 | validation: 0.10125095795351532]
	TIME [epoch: 35 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12356703103436928		[learning rate: 0.0052971]
	Learning Rate: 0.0052971
	LOSS [training: 0.12356703103436928 | validation: 0.10090100113240356]
	TIME [epoch: 35 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12494071897557475		[learning rate: 0.005276]
	Learning Rate: 0.00527604
	LOSS [training: 0.12494071897557475 | validation: 0.10389890736337834]
	TIME [epoch: 35 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14256679238426562		[learning rate: 0.0052551]
	Learning Rate: 0.00525505
	LOSS [training: 0.14256679238426562 | validation: 0.10661931555455414]
	TIME [epoch: 35 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12465510214312148		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 0.12465510214312148 | validation: 0.10649964873939591]
	TIME [epoch: 35 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12430718078341485		[learning rate: 0.0052133]
	Learning Rate: 0.00521333
	LOSS [training: 0.12430718078341485 | validation: 0.09472640197195889]
	TIME [epoch: 35 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12606129622937362		[learning rate: 0.0051926]
	Learning Rate: 0.0051926
	LOSS [training: 0.12606129622937362 | validation: 0.1061854000780964]
	TIME [epoch: 35 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1207454771091952		[learning rate: 0.0051719]
	Learning Rate: 0.00517194
	LOSS [training: 0.1207454771091952 | validation: 0.10884530913874628]
	TIME [epoch: 35 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1235789012291514		[learning rate: 0.0051514]
	Learning Rate: 0.00515137
	LOSS [training: 0.1235789012291514 | validation: 0.1107376374697008]
	TIME [epoch: 35 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12249633665495521		[learning rate: 0.0051309]
	Learning Rate: 0.00513089
	LOSS [training: 0.12249633665495521 | validation: 0.09544568039327027]
	TIME [epoch: 35 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1223978527327975		[learning rate: 0.0051105]
	Learning Rate: 0.00511048
	LOSS [training: 0.1223978527327975 | validation: 0.11003872472106076]
	TIME [epoch: 35 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13573530251628677		[learning rate: 0.0050902]
	Learning Rate: 0.00509015
	LOSS [training: 0.13573530251628677 | validation: 0.10552289705916482]
	TIME [epoch: 35 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12097449915259403		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 0.12097449915259403 | validation: 0.0966762719508963]
	TIME [epoch: 35 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14096609206847918		[learning rate: 0.0050497]
	Learning Rate: 0.00504974
	LOSS [training: 0.14096609206847918 | validation: 0.09103184280425933]
	TIME [epoch: 35 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_133353/states/model_facs_dec1a_2dpca_v1_216.pth
	Model improved!!!
EPOCH 217/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12711795961056022		[learning rate: 0.0050297]
	Learning Rate: 0.00502966
	LOSS [training: 0.12711795961056022 | validation: 0.10461585211175153]
	TIME [epoch: 34.9 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13221930106480428		[learning rate: 0.0050097]
	Learning Rate: 0.00500965
	LOSS [training: 0.13221930106480428 | validation: 0.09451396203001275]
	TIME [epoch: 35 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12493687647439805		[learning rate: 0.0049897]
	Learning Rate: 0.00498973
	LOSS [training: 0.12493687647439805 | validation: 0.10325317546075133]
	TIME [epoch: 34.9 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1137305540743303		[learning rate: 0.0049699]
	Learning Rate: 0.00496988
	LOSS [training: 0.1137305540743303 | validation: 0.11895701140181443]
	TIME [epoch: 34.9 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12600194104773013		[learning rate: 0.0049501]
	Learning Rate: 0.00495012
	LOSS [training: 0.12600194104773013 | validation: 0.1034228040401824]
	TIME [epoch: 34.9 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12946313324873474		[learning rate: 0.0049304]
	Learning Rate: 0.00493043
	LOSS [training: 0.12946313324873474 | validation: 0.10606945221685289]
	TIME [epoch: 34.9 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12649716660081767		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 0.12649716660081767 | validation: 0.10048345666969083]
	TIME [epoch: 34.9 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13835489949990493		[learning rate: 0.0048913]
	Learning Rate: 0.00489129
	LOSS [training: 0.13835489949990493 | validation: 0.09558025114974997]
	TIME [epoch: 34.9 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14038111695375982		[learning rate: 0.0048718]
	Learning Rate: 0.00487183
	LOSS [training: 0.14038111695375982 | validation: 0.09658324867116846]
	TIME [epoch: 34.9 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12432096259920075		[learning rate: 0.0048525]
	Learning Rate: 0.00485245
	LOSS [training: 0.12432096259920075 | validation: 0.10094882431333181]
	TIME [epoch: 34.9 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14548279340294587		[learning rate: 0.0048332]
	Learning Rate: 0.00483316
	LOSS [training: 0.14548279340294587 | validation: 0.10619263011268913]
	TIME [epoch: 35 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.126251005154225		[learning rate: 0.0048139]
	Learning Rate: 0.00481393
	LOSS [training: 0.126251005154225 | validation: 0.0975506583591991]
	TIME [epoch: 34.9 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13831590400433416		[learning rate: 0.0047948]
	Learning Rate: 0.00479479
	LOSS [training: 0.13831590400433416 | validation: 0.1002181163785538]
	TIME [epoch: 35 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1179550122895489		[learning rate: 0.0047757]
	Learning Rate: 0.00477572
	LOSS [training: 0.1179550122895489 | validation: 0.09992784042047058]
	TIME [epoch: 34.9 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11826788722102426		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.11826788722102426 | validation: 0.10352336975584504]
	TIME [epoch: 34.9 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11529352846899693		[learning rate: 0.0047378]
	Learning Rate: 0.0047378
	LOSS [training: 0.11529352846899693 | validation: 0.09890389720622572]
	TIME [epoch: 34.9 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13291392959151		[learning rate: 0.004719]
	Learning Rate: 0.00471896
	LOSS [training: 0.13291392959151 | validation: 0.09909540536538045]
	TIME [epoch: 34.9 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12598347745339503		[learning rate: 0.0047002]
	Learning Rate: 0.00470019
	LOSS [training: 0.12598347745339503 | validation: 0.09868766921268399]
	TIME [epoch: 34.9 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12911862721654468		[learning rate: 0.0046815]
	Learning Rate: 0.0046815
	LOSS [training: 0.12911862721654468 | validation: 0.09533869920323465]
	TIME [epoch: 35 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14191940553521093		[learning rate: 0.0046629]
	Learning Rate: 0.00466288
	LOSS [training: 0.14191940553521093 | validation: 0.09835528915584897]
	TIME [epoch: 35 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.121471411883166		[learning rate: 0.0046443]
	Learning Rate: 0.00464433
	LOSS [training: 0.121471411883166 | validation: 0.09918078513279138]
	TIME [epoch: 35 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11958722874752548		[learning rate: 0.0046259]
	Learning Rate: 0.00462586
	LOSS [training: 0.11958722874752548 | validation: 0.09986890337859447]
	TIME [epoch: 35 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12548845305474807		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 0.12548845305474807 | validation: 0.10624068875331716]
	TIME [epoch: 35 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11920915034366122		[learning rate: 0.0045891]
	Learning Rate: 0.00458913
	LOSS [training: 0.11920915034366122 | validation: 0.10001917715985767]
	TIME [epoch: 35 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1294755527279031		[learning rate: 0.0045709]
	Learning Rate: 0.00457088
	LOSS [training: 0.1294755527279031 | validation: 0.09944421495844219]
	TIME [epoch: 35 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13714801351573616		[learning rate: 0.0045527]
	Learning Rate: 0.0045527
	LOSS [training: 0.13714801351573616 | validation: 0.0978637014603516]
	TIME [epoch: 35 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11831193029326131		[learning rate: 0.0045346]
	Learning Rate: 0.00453459
	LOSS [training: 0.11831193029326131 | validation: 0.09182461939255]
	TIME [epoch: 34.9 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13185666239056495		[learning rate: 0.0045166]
	Learning Rate: 0.00451656
	LOSS [training: 0.13185666239056495 | validation: 0.09753750984761704]
	TIME [epoch: 35 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13769684531223345		[learning rate: 0.0044986]
	Learning Rate: 0.0044986
	LOSS [training: 0.13769684531223345 | validation: 0.09429173270066708]
	TIME [epoch: 35 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1241459081047011		[learning rate: 0.0044807]
	Learning Rate: 0.0044807
	LOSS [training: 0.1241459081047011 | validation: 0.11092589927339655]
	TIME [epoch: 34.9 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12868985867867255		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 0.12868985867867255 | validation: 0.10155444080505269]
	TIME [epoch: 35 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11899882163900477		[learning rate: 0.0044451]
	Learning Rate: 0.00444513
	LOSS [training: 0.11899882163900477 | validation: 0.08731411611733778]
	TIME [epoch: 34.9 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_133353/states/model_facs_dec1a_2dpca_v1_248.pth
	Model improved!!!
EPOCH 249/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11612251631139597		[learning rate: 0.0044275]
	Learning Rate: 0.00442745
	LOSS [training: 0.11612251631139597 | validation: 0.09907300117998925]
	TIME [epoch: 34.9 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13186135191681747		[learning rate: 0.0044098]
	Learning Rate: 0.00440984
	LOSS [training: 0.13186135191681747 | validation: 0.096968783330502]
	TIME [epoch: 34.9 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11730739698820798		[learning rate: 0.0043923]
	Learning Rate: 0.0043923
	LOSS [training: 0.11730739698820798 | validation: 0.10290527961967388]
	TIME [epoch: 35 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13962664190869264		[learning rate: 0.0043748]
	Learning Rate: 0.00437483
	LOSS [training: 0.13962664190869264 | validation: 0.10104051586629532]
	TIME [epoch: 34.9 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12925444667005748		[learning rate: 0.0043574]
	Learning Rate: 0.00435743
	LOSS [training: 0.12925444667005748 | validation: 0.09447365265398608]
	TIME [epoch: 34.9 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11745742149391451		[learning rate: 0.0043401]
	Learning Rate: 0.0043401
	LOSS [training: 0.11745742149391451 | validation: 0.11509882553179289]
	TIME [epoch: 34.9 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1264282613610676		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 0.1264282613610676 | validation: 0.09722189292529525]
	TIME [epoch: 34.9 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1194967040818838		[learning rate: 0.0043056]
	Learning Rate: 0.00430565
	LOSS [training: 0.1194967040818838 | validation: 0.09309090237950186]
	TIME [epoch: 34.9 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13309435957868296		[learning rate: 0.0042885]
	Learning Rate: 0.00428852
	LOSS [training: 0.13309435957868296 | validation: 0.09805894860713116]
	TIME [epoch: 34.9 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12550456101074273		[learning rate: 0.0042715]
	Learning Rate: 0.00427147
	LOSS [training: 0.12550456101074273 | validation: 0.09892675579430302]
	TIME [epoch: 34.9 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12146893214271742		[learning rate: 0.0042545]
	Learning Rate: 0.00425448
	LOSS [training: 0.12146893214271742 | validation: 0.1060418081200877]
	TIME [epoch: 34.9 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11851654172178344		[learning rate: 0.0042376]
	Learning Rate: 0.00423756
	LOSS [training: 0.11851654172178344 | validation: 0.10197363138234661]
	TIME [epoch: 34.9 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11693608152032284		[learning rate: 0.0042207]
	Learning Rate: 0.0042207
	LOSS [training: 0.11693608152032284 | validation: 0.10007561427533691]
	TIME [epoch: 34.9 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11563321745348507		[learning rate: 0.0042039]
	Learning Rate: 0.00420391
	LOSS [training: 0.11563321745348507 | validation: 0.0947142116813866]
	TIME [epoch: 34.9 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12860164319482886		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 0.12860164319482886 | validation: 0.09491882648089607]
	TIME [epoch: 34.9 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12217356595731552		[learning rate: 0.0041705]
	Learning Rate: 0.00417054
	LOSS [training: 0.12217356595731552 | validation: 0.0955092298039278]
	TIME [epoch: 34.9 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1357639711189059		[learning rate: 0.004154]
	Learning Rate: 0.00415395
	LOSS [training: 0.1357639711189059 | validation: 0.0994727171365849]
	TIME [epoch: 34.9 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12148749782887881		[learning rate: 0.0041374]
	Learning Rate: 0.00413743
	LOSS [training: 0.12148749782887881 | validation: 0.09753934004871284]
	TIME [epoch: 34.9 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1303130053013641		[learning rate: 0.004121]
	Learning Rate: 0.00412098
	LOSS [training: 0.1303130053013641 | validation: 0.0920282323046632]
	TIME [epoch: 34.9 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11060718273880286		[learning rate: 0.0041046]
	Learning Rate: 0.00410458
	LOSS [training: 0.11060718273880286 | validation: 0.0944645750804365]
	TIME [epoch: 34.9 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11812208556612881		[learning rate: 0.0040883]
	Learning Rate: 0.00408826
	LOSS [training: 0.11812208556612881 | validation: 0.10013991136802239]
	TIME [epoch: 34.9 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13324448294661997		[learning rate: 0.004072]
	Learning Rate: 0.004072
	LOSS [training: 0.13324448294661997 | validation: 0.10268635576021552]
	TIME [epoch: 34.9 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12020107298081212		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.12020107298081212 | validation: 0.09670166271421363]
	TIME [epoch: 34.9 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12383838733926754		[learning rate: 0.0040397]
	Learning Rate: 0.00403967
	LOSS [training: 0.12383838733926754 | validation: 0.0952123237890463]
	TIME [epoch: 34.9 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10818105948299989		[learning rate: 0.0040236]
	Learning Rate: 0.00402361
	LOSS [training: 0.10818105948299989 | validation: 0.09646172804752269]
	TIME [epoch: 34.9 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13029787730081643		[learning rate: 0.0040076]
	Learning Rate: 0.0040076
	LOSS [training: 0.13029787730081643 | validation: 0.10015691727289715]
	TIME [epoch: 34.9 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11464604363838096		[learning rate: 0.0039917]
	Learning Rate: 0.00399166
	LOSS [training: 0.11464604363838096 | validation: 0.10167780994948084]
	TIME [epoch: 34.9 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12711726365532575		[learning rate: 0.0039758]
	Learning Rate: 0.00397579
	LOSS [training: 0.12711726365532575 | validation: 0.10230886952008329]
	TIME [epoch: 34.9 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11937892965747311		[learning rate: 0.00396]
	Learning Rate: 0.00395997
	LOSS [training: 0.11937892965747311 | validation: 0.09536239458669106]
	TIME [epoch: 34.9 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12369908723993442		[learning rate: 0.0039442]
	Learning Rate: 0.00394422
	LOSS [training: 0.12369908723993442 | validation: 0.09074904270774516]
	TIME [epoch: 34.9 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12304110957714304		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 0.12304110957714304 | validation: 0.10273085540295575]
	TIME [epoch: 34.9 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14124231284541422		[learning rate: 0.0039129]
	Learning Rate: 0.00391291
	LOSS [training: 0.14124231284541422 | validation: 0.09522122261585053]
	TIME [epoch: 34.9 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11318226351944381		[learning rate: 0.0038973]
	Learning Rate: 0.00389735
	LOSS [training: 0.11318226351944381 | validation: 0.10056250705663014]
	TIME [epoch: 34.9 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11785916427599467		[learning rate: 0.0038818]
	Learning Rate: 0.00388185
	LOSS [training: 0.11785916427599467 | validation: 0.09762140241466377]
	TIME [epoch: 34.9 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11648477208365837		[learning rate: 0.0038664]
	Learning Rate: 0.00386641
	LOSS [training: 0.11648477208365837 | validation: 0.09940769613379793]
	TIME [epoch: 34.9 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12586690624675073		[learning rate: 0.003851]
	Learning Rate: 0.00385103
	LOSS [training: 0.12586690624675073 | validation: 0.09501855030954591]
	TIME [epoch: 34.9 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14489380549924624		[learning rate: 0.0038357]
	Learning Rate: 0.00383571
	LOSS [training: 0.14489380549924624 | validation: 0.093581378864342]
	TIME [epoch: 35 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11807727713848783		[learning rate: 0.0038205]
	Learning Rate: 0.00382046
	LOSS [training: 0.11807727713848783 | validation: 0.09935495890954901]
	TIME [epoch: 34.9 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13069658643645227		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 0.13069658643645227 | validation: 0.09481548745806967]
	TIME [epoch: 34.9 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12483191050814295		[learning rate: 0.0037901]
	Learning Rate: 0.00379013
	LOSS [training: 0.12483191050814295 | validation: 0.09834833141496561]
	TIME [epoch: 34.9 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12408861531968274		[learning rate: 0.0037751]
	Learning Rate: 0.00377505
	LOSS [training: 0.12408861531968274 | validation: 0.0906388722468339]
	TIME [epoch: 34.9 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11920465754610084		[learning rate: 0.00376]
	Learning Rate: 0.00376004
	LOSS [training: 0.11920465754610084 | validation: 0.08962808048961865]
	TIME [epoch: 34.9 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12226044840061473		[learning rate: 0.0037451]
	Learning Rate: 0.00374508
	LOSS [training: 0.12226044840061473 | validation: 0.09461282127412589]
	TIME [epoch: 34.9 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11422014343206113		[learning rate: 0.0037302]
	Learning Rate: 0.00373019
	LOSS [training: 0.11422014343206113 | validation: 0.09568186927766073]
	TIME [epoch: 34.9 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11513562421876822		[learning rate: 0.0037154]
	Learning Rate: 0.00371535
	LOSS [training: 0.11513562421876822 | validation: 0.09886325542973398]
	TIME [epoch: 34.9 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11725178684804198		[learning rate: 0.0037006]
	Learning Rate: 0.00370058
	LOSS [training: 0.11725178684804198 | validation: 0.0909748012557123]
	TIME [epoch: 34.9 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12527710101335998		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 0.12527710101335998 | validation: 0.10177471410569576]
	TIME [epoch: 34.9 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1270061176091239		[learning rate: 0.0036712]
	Learning Rate: 0.0036712
	LOSS [training: 0.1270061176091239 | validation: 0.09407168167617855]
	TIME [epoch: 34.9 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13589029689018892		[learning rate: 0.0036566]
	Learning Rate: 0.0036566
	LOSS [training: 0.13589029689018892 | validation: 0.0929301227435623]
	TIME [epoch: 35 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11812752484656446		[learning rate: 0.0036421]
	Learning Rate: 0.00364205
	LOSS [training: 0.11812752484656446 | validation: 0.09348467683906396]
	TIME [epoch: 34.9 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1208704084935755		[learning rate: 0.0036276]
	Learning Rate: 0.00362757
	LOSS [training: 0.1208704084935755 | validation: 0.09348142435867021]
	TIME [epoch: 34.9 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11910299694229404		[learning rate: 0.0036131]
	Learning Rate: 0.00361314
	LOSS [training: 0.11910299694229404 | validation: 0.09796896397006064]
	TIME [epoch: 34.9 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10918359224736088		[learning rate: 0.0035988]
	Learning Rate: 0.00359877
	LOSS [training: 0.10918359224736088 | validation: 0.09600920353168216]
	TIME [epoch: 34.9 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11660461409090443		[learning rate: 0.0035845]
	Learning Rate: 0.00358445
	LOSS [training: 0.11660461409090443 | validation: 0.10418051670174637]
	TIME [epoch: 34.9 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11485358186071903		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 0.11485358186071903 | validation: 0.09489901468861275]
	TIME [epoch: 34.9 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12491234131434359		[learning rate: 0.003556]
	Learning Rate: 0.003556
	LOSS [training: 0.12491234131434359 | validation: 0.10179448236200166]
	TIME [epoch: 34.9 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1331185149874089		[learning rate: 0.0035419]
	Learning Rate: 0.00354185
	LOSS [training: 0.1331185149874089 | validation: 0.09619636360814456]
	TIME [epoch: 34.9 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12086220528013346		[learning rate: 0.0035278]
	Learning Rate: 0.00352777
	LOSS [training: 0.12086220528013346 | validation: 0.09777057459557592]
	TIME [epoch: 34.9 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12022944677855188		[learning rate: 0.0035137]
	Learning Rate: 0.00351374
	LOSS [training: 0.12022944677855188 | validation: 0.09462315540933679]
	TIME [epoch: 34.9 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11829912049731127		[learning rate: 0.0034998]
	Learning Rate: 0.00349976
	LOSS [training: 0.11829912049731127 | validation: 0.09100831560245168]
	TIME [epoch: 34.9 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11680705799650995		[learning rate: 0.0034858]
	Learning Rate: 0.00348584
	LOSS [training: 0.11680705799650995 | validation: 0.10177901687949457]
	TIME [epoch: 34.9 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11634426177756185		[learning rate: 0.003472]
	Learning Rate: 0.00347198
	LOSS [training: 0.11634426177756185 | validation: 0.09429959899561968]
	TIME [epoch: 34.9 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11425422352698623		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.11425422352698623 | validation: 0.09717879243203147]
	TIME [epoch: 34.9 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13456258023835005		[learning rate: 0.0034444]
	Learning Rate: 0.00344441
	LOSS [training: 0.13456258023835005 | validation: 0.09471789307223238]
	TIME [epoch: 34.9 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11919406316090941		[learning rate: 0.0034307]
	Learning Rate: 0.00343071
	LOSS [training: 0.11919406316090941 | validation: 0.10175452305169734]
	TIME [epoch: 34.9 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11778764032267526		[learning rate: 0.0034171]
	Learning Rate: 0.00341707
	LOSS [training: 0.11778764032267526 | validation: 0.10627947441795405]
	TIME [epoch: 34.9 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11410714581363227		[learning rate: 0.0034035]
	Learning Rate: 0.00340348
	LOSS [training: 0.11410714581363227 | validation: 0.1020918928017647]
	TIME [epoch: 35 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12510865717892175		[learning rate: 0.0033899]
	Learning Rate: 0.00338994
	LOSS [training: 0.12510865717892175 | validation: 0.10301717886310999]
	TIME [epoch: 34.9 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11692695938828379		[learning rate: 0.0033765]
	Learning Rate: 0.00337646
	LOSS [training: 0.11692695938828379 | validation: 0.09951089304760732]
	TIME [epoch: 34.9 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12041064063119657		[learning rate: 0.003363]
	Learning Rate: 0.00336303
	LOSS [training: 0.12041064063119657 | validation: 0.09325092086772134]
	TIME [epoch: 35 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12897057772340037		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 0.12897057772340037 | validation: 0.09957866109709593]
	TIME [epoch: 35 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1120729589850036		[learning rate: 0.0033363]
	Learning Rate: 0.00333633
	LOSS [training: 0.1120729589850036 | validation: 0.09886511258620434]
	TIME [epoch: 35 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11494270209871837		[learning rate: 0.0033231]
	Learning Rate: 0.00332306
	LOSS [training: 0.11494270209871837 | validation: 0.10870289728752931]
	TIME [epoch: 34.9 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12435303379952242		[learning rate: 0.0033098]
	Learning Rate: 0.00330985
	LOSS [training: 0.12435303379952242 | validation: 0.09072129328197762]
	TIME [epoch: 35 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11732015523248543		[learning rate: 0.0032967]
	Learning Rate: 0.00329668
	LOSS [training: 0.11732015523248543 | validation: 0.09174480859006327]
	TIME [epoch: 35 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11535758369815914		[learning rate: 0.0032836]
	Learning Rate: 0.00328357
	LOSS [training: 0.11535758369815914 | validation: 0.09743793489439753]
	TIME [epoch: 34.9 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11289814269249604		[learning rate: 0.0032705]
	Learning Rate: 0.00327051
	LOSS [training: 0.11289814269249604 | validation: 0.10416178579643105]
	TIME [epoch: 35 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12126293878902462		[learning rate: 0.0032575]
	Learning Rate: 0.0032575
	LOSS [training: 0.12126293878902462 | validation: 0.09369996561329273]
	TIME [epoch: 34.9 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11702670181268554		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 0.11702670181268554 | validation: 0.10104097270560564]
	TIME [epoch: 35 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11549098897259229		[learning rate: 0.0032316]
	Learning Rate: 0.00323164
	LOSS [training: 0.11549098897259229 | validation: 0.09971226492363741]
	TIME [epoch: 34.9 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11897633566879318		[learning rate: 0.0032188]
	Learning Rate: 0.00321879
	LOSS [training: 0.11897633566879318 | validation: 0.09671890339746499]
	TIME [epoch: 35 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11849124458080992		[learning rate: 0.003206]
	Learning Rate: 0.00320599
	LOSS [training: 0.11849124458080992 | validation: 0.09364163346726886]
	TIME [epoch: 34.9 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12086772724061717		[learning rate: 0.0031932]
	Learning Rate: 0.00319323
	LOSS [training: 0.12086772724061717 | validation: 0.09838186413689483]
	TIME [epoch: 34.9 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1314439035608769		[learning rate: 0.0031805]
	Learning Rate: 0.00318053
	LOSS [training: 0.1314439035608769 | validation: 0.09479776258962527]
	TIME [epoch: 34.9 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10919426049116183		[learning rate: 0.0031679]
	Learning Rate: 0.00316788
	LOSS [training: 0.10919426049116183 | validation: 0.10114437149014759]
	TIME [epoch: 34.9 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11941716046179457		[learning rate: 0.0031553]
	Learning Rate: 0.00315528
	LOSS [training: 0.11941716046179457 | validation: 0.10336330191700316]
	TIME [epoch: 34.9 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13277284542918869		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 0.13277284542918869 | validation: 0.09335280361247918]
	TIME [epoch: 34.9 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1175994832861776		[learning rate: 0.0031302]
	Learning Rate: 0.00313023
	LOSS [training: 0.1175994832861776 | validation: 0.09250872273368523]
	TIME [epoch: 35 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11966245120529734		[learning rate: 0.0031178]
	Learning Rate: 0.00311779
	LOSS [training: 0.11966245120529734 | validation: 0.10227564369735062]
	TIME [epoch: 34.9 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12169940741940183		[learning rate: 0.0031054]
	Learning Rate: 0.00310538
	LOSS [training: 0.12169940741940183 | validation: 0.09606704143726334]
	TIME [epoch: 35 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1303162508564533		[learning rate: 0.003093]
	Learning Rate: 0.00309303
	LOSS [training: 0.1303162508564533 | validation: 0.09625100758227885]
	TIME [epoch: 34.9 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11639897007332481		[learning rate: 0.0030807]
	Learning Rate: 0.00308073
	LOSS [training: 0.11639897007332481 | validation: 0.09932545859637078]
	TIME [epoch: 34.9 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12514714391953705		[learning rate: 0.0030685]
	Learning Rate: 0.00306848
	LOSS [training: 0.12514714391953705 | validation: 0.0954340768051509]
	TIME [epoch: 34.9 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11838164760805187		[learning rate: 0.0030563]
	Learning Rate: 0.00305627
	LOSS [training: 0.11838164760805187 | validation: 0.096639504082311]
	TIME [epoch: 34.9 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12082180285885685		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 0.12082180285885685 | validation: 0.08640600817736961]
	TIME [epoch: 34.9 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_133353/states/model_facs_dec1a_2dpca_v1_343.pth
	Model improved!!!
EPOCH 344/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11435431229566712		[learning rate: 0.003032]
	Learning Rate: 0.00303201
	LOSS [training: 0.11435431229566712 | validation: 0.09251506355986572]
	TIME [epoch: 34.9 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12057101706530565		[learning rate: 0.00302]
	Learning Rate: 0.00301995
	LOSS [training: 0.12057101706530565 | validation: 0.09313904974273483]
	TIME [epoch: 34.9 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12451949122536922		[learning rate: 0.0030079]
	Learning Rate: 0.00300794
	LOSS [training: 0.12451949122536922 | validation: 0.09947315983970781]
	TIME [epoch: 34.9 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12665563877791178		[learning rate: 0.002996]
	Learning Rate: 0.00299598
	LOSS [training: 0.12665563877791178 | validation: 0.09591246624750557]
	TIME [epoch: 34.9 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12189370335700946		[learning rate: 0.0029841]
	Learning Rate: 0.00298406
	LOSS [training: 0.12189370335700946 | validation: 0.09867972354575612]
	TIME [epoch: 34.9 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11568829942175934		[learning rate: 0.0029722]
	Learning Rate: 0.00297219
	LOSS [training: 0.11568829942175934 | validation: 0.0932210944323044]
	TIME [epoch: 34.9 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11532846421718886		[learning rate: 0.0029604]
	Learning Rate: 0.00296037
	LOSS [training: 0.11532846421718886 | validation: 0.09528769716000876]
	TIME [epoch: 34.9 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11890237771723772		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.11890237771723772 | validation: 0.10052994518393446]
	TIME [epoch: 34.9 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11662741982478103		[learning rate: 0.0029369]
	Learning Rate: 0.00293687
	LOSS [training: 0.11662741982478103 | validation: 0.08676945466323989]
	TIME [epoch: 34.9 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11460861709873564		[learning rate: 0.0029252]
	Learning Rate: 0.00292519
	LOSS [training: 0.11460861709873564 | validation: 0.10467539241655546]
	TIME [epoch: 34.9 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13478188772897906		[learning rate: 0.0029136]
	Learning Rate: 0.00291355
	LOSS [training: 0.13478188772897906 | validation: 0.09898723516189864]
	TIME [epoch: 34.9 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12674906967707308		[learning rate: 0.002902]
	Learning Rate: 0.00290197
	LOSS [training: 0.12674906967707308 | validation: 0.10083511789950231]
	TIME [epoch: 34.9 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11923362189959603		[learning rate: 0.0028904]
	Learning Rate: 0.00289042
	LOSS [training: 0.11923362189959603 | validation: 0.09476991900780947]
	TIME [epoch: 34.9 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11308613850643552		[learning rate: 0.0028789]
	Learning Rate: 0.00287893
	LOSS [training: 0.11308613850643552 | validation: 0.09576025037752087]
	TIME [epoch: 35 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11255108853907414		[learning rate: 0.0028675]
	Learning Rate: 0.00286748
	LOSS [training: 0.11255108853907414 | validation: 0.1032537149469351]
	TIME [epoch: 34.9 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11999438435744578		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 0.11999438435744578 | validation: 0.09661538364296283]
	TIME [epoch: 34.9 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11491184492485128		[learning rate: 0.0028447]
	Learning Rate: 0.00284471
	LOSS [training: 0.11491184492485128 | validation: 0.0910241904427804]
	TIME [epoch: 34.9 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12262152204309541		[learning rate: 0.0028334]
	Learning Rate: 0.0028334
	LOSS [training: 0.12262152204309541 | validation: 0.0941691953934963]
	TIME [epoch: 34.9 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11727522023530906		[learning rate: 0.0028221]
	Learning Rate: 0.00282213
	LOSS [training: 0.11727522023530906 | validation: 0.09122044992652205]
	TIME [epoch: 34.9 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12619763816347454		[learning rate: 0.0028109]
	Learning Rate: 0.00281091
	LOSS [training: 0.12619763816347454 | validation: 0.09614256909001424]
	TIME [epoch: 34.9 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12196443433159322		[learning rate: 0.0027997]
	Learning Rate: 0.00279973
	LOSS [training: 0.12196443433159322 | validation: 0.0982116739351205]
	TIME [epoch: 34.9 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11276071220490531		[learning rate: 0.0027886]
	Learning Rate: 0.00278859
	LOSS [training: 0.11276071220490531 | validation: 0.10000143347478688]
	TIME [epoch: 34.9 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11262598888571852		[learning rate: 0.0027775]
	Learning Rate: 0.0027775
	LOSS [training: 0.11262598888571852 | validation: 0.09145574145707125]
	TIME [epoch: 34.9 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11091565432776866		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 0.11091565432776866 | validation: 0.09722932993442016]
	TIME [epoch: 34.9 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11656248293532216		[learning rate: 0.0027554]
	Learning Rate: 0.00275545
	LOSS [training: 0.11656248293532216 | validation: 0.10009466289129802]
	TIME [epoch: 34.9 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11954669182000001		[learning rate: 0.0027445]
	Learning Rate: 0.00274449
	LOSS [training: 0.11954669182000001 | validation: 0.09468922375999891]
	TIME [epoch: 34.9 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11508949958152276		[learning rate: 0.0027336]
	Learning Rate: 0.00273357
	LOSS [training: 0.11508949958152276 | validation: 0.0887415727358909]
	TIME [epoch: 34.9 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11421788915689916		[learning rate: 0.0027227]
	Learning Rate: 0.0027227
	LOSS [training: 0.11421788915689916 | validation: 0.09902895300714706]
	TIME [epoch: 34.9 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11710862978060048		[learning rate: 0.0027119]
	Learning Rate: 0.00271187
	LOSS [training: 0.11710862978060048 | validation: 0.0914641345568972]
	TIME [epoch: 34.9 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12788010772525843		[learning rate: 0.0027011]
	Learning Rate: 0.00270109
	LOSS [training: 0.12788010772525843 | validation: 0.08847191253736304]
	TIME [epoch: 34.9 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11571805876237838		[learning rate: 0.0026903]
	Learning Rate: 0.00269034
	LOSS [training: 0.11571805876237838 | validation: 0.0857912840938339]
	TIME [epoch: 34.9 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_133353/states/model_facs_dec1a_2dpca_v1_374.pth
	Model improved!!!
EPOCH 375/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1145998398041951		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 0.1145998398041951 | validation: 0.09959872212195017]
	TIME [epoch: 35 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11777354839538168		[learning rate: 0.002669]
	Learning Rate: 0.00266899
	LOSS [training: 0.11777354839538168 | validation: 0.0895414174232622]
	TIME [epoch: 34.9 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11029461826426606		[learning rate: 0.0026584]
	Learning Rate: 0.00265837
	LOSS [training: 0.11029461826426606 | validation: 0.094605158159338]
	TIME [epoch: 34.9 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13112008963550567		[learning rate: 0.0026478]
	Learning Rate: 0.0026478
	LOSS [training: 0.13112008963550567 | validation: 0.09371343172276911]
	TIME [epoch: 34.9 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11843835354779642		[learning rate: 0.0026373]
	Learning Rate: 0.00263727
	LOSS [training: 0.11843835354779642 | validation: 0.09567607053186566]
	TIME [epoch: 34.9 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12227518562673748		[learning rate: 0.0026268]
	Learning Rate: 0.00262678
	LOSS [training: 0.12227518562673748 | validation: 0.08766037927619799]
	TIME [epoch: 34.9 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11324199737619578		[learning rate: 0.0026163]
	Learning Rate: 0.00261633
	LOSS [training: 0.11324199737619578 | validation: 0.09814232406685267]
	TIME [epoch: 34.9 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11733389709479426		[learning rate: 0.0026059]
	Learning Rate: 0.00260592
	LOSS [training: 0.11733389709479426 | validation: 0.09326814736493579]
	TIME [epoch: 34.9 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12278927524854523		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 0.12278927524854523 | validation: 0.09547744408117893]
	TIME [epoch: 34.9 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.127990147429414		[learning rate: 0.0025852]
	Learning Rate: 0.00258523
	LOSS [training: 0.127990147429414 | validation: 0.09094890547781713]
	TIME [epoch: 34.9 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11820082105723244		[learning rate: 0.002575]
	Learning Rate: 0.00257495
	LOSS [training: 0.11820082105723244 | validation: 0.09414816655235973]
	TIME [epoch: 34.9 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1219865944968257		[learning rate: 0.0025647]
	Learning Rate: 0.00256471
	LOSS [training: 0.1219865944968257 | validation: 0.09097823290249063]
	TIME [epoch: 34.9 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11993799603336891		[learning rate: 0.0025545]
	Learning Rate: 0.00255451
	LOSS [training: 0.11993799603336891 | validation: 0.09693861004999875]
	TIME [epoch: 34.9 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1292009078514414		[learning rate: 0.0025444]
	Learning Rate: 0.00254435
	LOSS [training: 0.1292009078514414 | validation: 0.0911428614614351]
	TIME [epoch: 34.9 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11396134160683848		[learning rate: 0.0025342]
	Learning Rate: 0.00253423
	LOSS [training: 0.11396134160683848 | validation: 0.09521646600289742]
	TIME [epoch: 34.9 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12054186647124972		[learning rate: 0.0025242]
	Learning Rate: 0.00252415
	LOSS [training: 0.12054186647124972 | validation: 0.09123438876110326]
	TIME [epoch: 34.9 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1105489506731		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.1105489506731 | validation: 0.0867348339458885]
	TIME [epoch: 34.9 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11418862089245632		[learning rate: 0.0025041]
	Learning Rate: 0.00250411
	LOSS [training: 0.11418862089245632 | validation: 0.09350427165352733]
	TIME [epoch: 34.9 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11645620491483484		[learning rate: 0.0024942]
	Learning Rate: 0.00249415
	LOSS [training: 0.11645620491483484 | validation: 0.10330279089069587]
	TIME [epoch: 34.9 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1283494199296148		[learning rate: 0.0024842]
	Learning Rate: 0.00248423
	LOSS [training: 0.1283494199296148 | validation: 0.08926156683079309]
	TIME [epoch: 34.9 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12467214773732883		[learning rate: 0.0024744]
	Learning Rate: 0.00247435
	LOSS [training: 0.12467214773732883 | validation: 0.09420282269962492]
	TIME [epoch: 34.9 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12219025853310608		[learning rate: 0.0024645]
	Learning Rate: 0.00246451
	LOSS [training: 0.12219025853310608 | validation: 0.10106684452043457]
	TIME [epoch: 34.9 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11389481924351107		[learning rate: 0.0024547]
	Learning Rate: 0.00245471
	LOSS [training: 0.11389481924351107 | validation: 0.09332239817638396]
	TIME [epoch: 34.9 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11875194733442435		[learning rate: 0.0024449]
	Learning Rate: 0.00244495
	LOSS [training: 0.11875194733442435 | validation: 0.09239446877255553]
	TIME [epoch: 35 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11589671297362328		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 0.11589671297362328 | validation: 0.09424505691548021]
	TIME [epoch: 35 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1188491910865516		[learning rate: 0.0024255]
	Learning Rate: 0.00242554
	LOSS [training: 0.1188491910865516 | validation: 0.0922552485579263]
	TIME [epoch: 35 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1127860328301983		[learning rate: 0.0024159]
	Learning Rate: 0.00241589
	LOSS [training: 0.1127860328301983 | validation: 0.09225919101629457]
	TIME [epoch: 35 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12139484304761708		[learning rate: 0.0024063]
	Learning Rate: 0.00240628
	LOSS [training: 0.12139484304761708 | validation: 0.09524307791696325]
	TIME [epoch: 34.9 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1226655790177565		[learning rate: 0.0023967]
	Learning Rate: 0.00239671
	LOSS [training: 0.1226655790177565 | validation: 0.09284504001441515]
	TIME [epoch: 34.9 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11511017276770923		[learning rate: 0.0023872]
	Learning Rate: 0.00238718
	LOSS [training: 0.11511017276770923 | validation: 0.09375469249146458]
	TIME [epoch: 35 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11447302620817555		[learning rate: 0.0023777]
	Learning Rate: 0.00237768
	LOSS [training: 0.11447302620817555 | validation: 0.08930283024607799]
	TIME [epoch: 34.9 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1205915336404025		[learning rate: 0.0023682]
	Learning Rate: 0.00236823
	LOSS [training: 0.1205915336404025 | validation: 0.09334497559074802]
	TIME [epoch: 35 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11998507011395068		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 0.11998507011395068 | validation: 0.0969275422615626]
	TIME [epoch: 35 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.13184954798016563		[learning rate: 0.0023494]
	Learning Rate: 0.00234942
	LOSS [training: 0.13184954798016563 | validation: 0.08616975586839988]
	TIME [epoch: 34.9 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11393522032738772		[learning rate: 0.0023401]
	Learning Rate: 0.00234008
	LOSS [training: 0.11393522032738772 | validation: 0.08902265805610624]
	TIME [epoch: 34.9 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11529338228523771		[learning rate: 0.0023308]
	Learning Rate: 0.00233077
	LOSS [training: 0.11529338228523771 | validation: 0.09498768479109561]
	TIME [epoch: 34.9 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11149094863477495		[learning rate: 0.0023215]
	Learning Rate: 0.0023215
	LOSS [training: 0.11149094863477495 | validation: 0.09356550999366257]
	TIME [epoch: 35 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11503218860783934		[learning rate: 0.0023123]
	Learning Rate: 0.00231227
	LOSS [training: 0.11503218860783934 | validation: 0.09504151690068992]
	TIME [epoch: 34.9 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11867253913674099		[learning rate: 0.0023031]
	Learning Rate: 0.00230307
	LOSS [training: 0.11867253913674099 | validation: 0.09492545578642786]
	TIME [epoch: 35 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12022103225473045		[learning rate: 0.0022939]
	Learning Rate: 0.00229391
	LOSS [training: 0.12022103225473045 | validation: 0.09945845002137736]
	TIME [epoch: 35 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12731421901678483		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 0.12731421901678483 | validation: 0.09290546797811734]
	TIME [epoch: 34.9 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12606027208234327		[learning rate: 0.0022757]
	Learning Rate: 0.0022757
	LOSS [training: 0.12606027208234327 | validation: 0.09086551647860788]
	TIME [epoch: 35 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11156423864339936		[learning rate: 0.0022667]
	Learning Rate: 0.00226665
	LOSS [training: 0.11156423864339936 | validation: 0.09185392642875981]
	TIME [epoch: 34.9 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1093747924964809		[learning rate: 0.0022576]
	Learning Rate: 0.00225764
	LOSS [training: 0.1093747924964809 | validation: 0.0960964034807881]
	TIME [epoch: 34.9 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12081326757454341		[learning rate: 0.0022487]
	Learning Rate: 0.00224866
	LOSS [training: 0.12081326757454341 | validation: 0.09667582693992798]
	TIME [epoch: 34.9 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11072355067307738		[learning rate: 0.0022397]
	Learning Rate: 0.00223971
	LOSS [training: 0.11072355067307738 | validation: 0.08983876744494165]
	TIME [epoch: 34.9 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11547257729522335		[learning rate: 0.0022308]
	Learning Rate: 0.0022308
	LOSS [training: 0.11547257729522335 | validation: 0.09143596408856006]
	TIME [epoch: 34.9 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11355589513594858		[learning rate: 0.0022219]
	Learning Rate: 0.00222193
	LOSS [training: 0.11355589513594858 | validation: 0.09797365537555872]
	TIME [epoch: 34.9 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11625106268108033		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.11625106268108033 | validation: 0.09472383256100338]
	TIME [epoch: 34.9 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12092665202457588		[learning rate: 0.0022043]
	Learning Rate: 0.00220429
	LOSS [training: 0.12092665202457588 | validation: 0.0949929594415981]
	TIME [epoch: 34.9 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11627681338652339		[learning rate: 0.0021955]
	Learning Rate: 0.00219553
	LOSS [training: 0.11627681338652339 | validation: 0.09147892939884676]
	TIME [epoch: 34.9 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1133951347166368		[learning rate: 0.0021868]
	Learning Rate: 0.00218679
	LOSS [training: 0.1133951347166368 | validation: 0.10253622313517279]
	TIME [epoch: 34.9 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11138370908166625		[learning rate: 0.0021781]
	Learning Rate: 0.0021781
	LOSS [training: 0.11138370908166625 | validation: 0.09293000787253998]
	TIME [epoch: 34.9 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11181987533986154		[learning rate: 0.0021694]
	Learning Rate: 0.00216943
	LOSS [training: 0.11181987533986154 | validation: 0.10020577047270822]
	TIME [epoch: 35 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12759048532454426		[learning rate: 0.0021608]
	Learning Rate: 0.0021608
	LOSS [training: 0.12759048532454426 | validation: 0.09337761420734761]
	TIME [epoch: 34.9 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11909635236976718		[learning rate: 0.0021522]
	Learning Rate: 0.00215221
	LOSS [training: 0.11909635236976718 | validation: 0.09328866249979426]
	TIME [epoch: 34.9 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11163713129759333		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.11163713129759333 | validation: 0.08951959936600917]
	TIME [epoch: 34.9 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11619432551366786		[learning rate: 0.0021351]
	Learning Rate: 0.00213512
	LOSS [training: 0.11619432551366786 | validation: 0.09775319557735573]
	TIME [epoch: 34.9 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1039195164701522		[learning rate: 0.0021266]
	Learning Rate: 0.00212663
	LOSS [training: 0.1039195164701522 | validation: 0.09102958289223484]
	TIME [epoch: 34.9 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11215339496491189		[learning rate: 0.0021182]
	Learning Rate: 0.00211817
	LOSS [training: 0.11215339496491189 | validation: 0.08947595103398547]
	TIME [epoch: 34.9 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1253257820733698		[learning rate: 0.0021097]
	Learning Rate: 0.00210975
	LOSS [training: 0.1253257820733698 | validation: 0.09037176541724842]
	TIME [epoch: 34.9 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11783338882729567		[learning rate: 0.0021014]
	Learning Rate: 0.00210136
	LOSS [training: 0.11783338882729567 | validation: 0.09258764591960193]
	TIME [epoch: 34.9 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1150490657670567		[learning rate: 0.002093]
	Learning Rate: 0.002093
	LOSS [training: 0.1150490657670567 | validation: 0.10057981666002]
	TIME [epoch: 34.9 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11625285879398306		[learning rate: 0.0020847]
	Learning Rate: 0.00208468
	LOSS [training: 0.11625285879398306 | validation: 0.09493066334080631]
	TIME [epoch: 34.9 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11337917238934286		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.11337917238934286 | validation: 0.09531113366400885]
	TIME [epoch: 34.9 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.111274063219229		[learning rate: 0.0020681]
	Learning Rate: 0.00206813
	LOSS [training: 0.111274063219229 | validation: 0.10190224410593685]
	TIME [epoch: 34.9 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11326181144214914		[learning rate: 0.0020599]
	Learning Rate: 0.0020599
	LOSS [training: 0.11326181144214914 | validation: 0.0944545171988163]
	TIME [epoch: 34.9 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11585136332527816		[learning rate: 0.0020517]
	Learning Rate: 0.00205171
	LOSS [training: 0.11585136332527816 | validation: 0.09136083526130837]
	TIME [epoch: 34.9 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10973998163363272		[learning rate: 0.0020435]
	Learning Rate: 0.00204355
	LOSS [training: 0.10973998163363272 | validation: 0.08995649184818535]
	TIME [epoch: 34.9 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11441099471130374		[learning rate: 0.0020354]
	Learning Rate: 0.00203542
	LOSS [training: 0.11441099471130374 | validation: 0.09042789053062208]
	TIME [epoch: 34.9 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11214243054204782		[learning rate: 0.0020273]
	Learning Rate: 0.00202732
	LOSS [training: 0.11214243054204782 | validation: 0.09341541426268456]
	TIME [epoch: 35 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12325721925925917		[learning rate: 0.0020193]
	Learning Rate: 0.00201926
	LOSS [training: 0.12325721925925917 | validation: 0.09047633003795817]
	TIME [epoch: 34.9 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12686629247687553		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 0.12686629247687553 | validation: 0.09022473411925]
	TIME [epoch: 34.9 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10348613382973967		[learning rate: 0.0020032]
	Learning Rate: 0.00200323
	LOSS [training: 0.10348613382973967 | validation: 0.09486003540326139]
	TIME [epoch: 35 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1123006909523278		[learning rate: 0.0019953]
	Learning Rate: 0.00199526
	LOSS [training: 0.1123006909523278 | validation: 0.0979203471322527]
	TIME [epoch: 34.9 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11080335164377342		[learning rate: 0.0019873]
	Learning Rate: 0.00198733
	LOSS [training: 0.11080335164377342 | validation: 0.08856971588215452]
	TIME [epoch: 34.9 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11569619022912916		[learning rate: 0.0019794]
	Learning Rate: 0.00197942
	LOSS [training: 0.11569619022912916 | validation: 0.08662330318054165]
	TIME [epoch: 34.9 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11172763998283136		[learning rate: 0.0019715]
	Learning Rate: 0.00197155
	LOSS [training: 0.11172763998283136 | validation: 0.09731569835797774]
	TIME [epoch: 34.9 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1100084031651863		[learning rate: 0.0019637]
	Learning Rate: 0.00196371
	LOSS [training: 0.1100084031651863 | validation: 0.09323744085887346]
	TIME [epoch: 34.9 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1273582179399052		[learning rate: 0.0019559]
	Learning Rate: 0.0019559
	LOSS [training: 0.1273582179399052 | validation: 0.09730883690746821]
	TIME [epoch: 34.9 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11945734638105991		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 0.11945734638105991 | validation: 0.0920360851252581]
	TIME [epoch: 34.9 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1094070237592441		[learning rate: 0.0019404]
	Learning Rate: 0.00194037
	LOSS [training: 0.1094070237592441 | validation: 0.09259276116110912]
	TIME [epoch: 34.9 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10996475316576276		[learning rate: 0.0019327]
	Learning Rate: 0.00193265
	LOSS [training: 0.10996475316576276 | validation: 0.09583398835663011]
	TIME [epoch: 34.9 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1096466698297457		[learning rate: 0.001925]
	Learning Rate: 0.00192497
	LOSS [training: 0.1096466698297457 | validation: 0.0989165956727284]
	TIME [epoch: 34.9 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11931192084784131		[learning rate: 0.0019173]
	Learning Rate: 0.00191731
	LOSS [training: 0.11931192084784131 | validation: 0.09339963094068032]
	TIME [epoch: 34.9 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11065019282930845		[learning rate: 0.0019097]
	Learning Rate: 0.00190968
	LOSS [training: 0.11065019282930845 | validation: 0.09227734969543999]
	TIME [epoch: 34.9 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11887610504836174		[learning rate: 0.0019021]
	Learning Rate: 0.00190209
	LOSS [training: 0.11887610504836174 | validation: 0.09093584371038696]
	TIME [epoch: 34.9 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12291877686021288		[learning rate: 0.0018945]
	Learning Rate: 0.00189452
	LOSS [training: 0.12291877686021288 | validation: 0.09809208702634906]
	TIME [epoch: 34.9 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11209415587806341		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.11209415587806341 | validation: 0.09746372126988181]
	TIME [epoch: 34.9 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1156507618714392		[learning rate: 0.0018795]
	Learning Rate: 0.00187948
	LOSS [training: 0.1156507618714392 | validation: 0.09523854464094308]
	TIME [epoch: 34.9 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11282451444631938		[learning rate: 0.001872]
	Learning Rate: 0.00187201
	LOSS [training: 0.11282451444631938 | validation: 0.09808411850327155]
	TIME [epoch: 34.9 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11746307192419995		[learning rate: 0.0018646]
	Learning Rate: 0.00186456
	LOSS [training: 0.11746307192419995 | validation: 0.08703259831439465]
	TIME [epoch: 34.9 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11605187365448717		[learning rate: 0.0018571]
	Learning Rate: 0.00185715
	LOSS [training: 0.11605187365448717 | validation: 0.09249527056283664]
	TIME [epoch: 34.9 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11788833633281512		[learning rate: 0.0018498]
	Learning Rate: 0.00184976
	LOSS [training: 0.11788833633281512 | validation: 0.08878717692984298]
	TIME [epoch: 34.9 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11075518742026035		[learning rate: 0.0018424]
	Learning Rate: 0.0018424
	LOSS [training: 0.11075518742026035 | validation: 0.09535708119500781]
	TIME [epoch: 34.9 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12069782598656983		[learning rate: 0.0018351]
	Learning Rate: 0.00183508
	LOSS [training: 0.12069782598656983 | validation: 0.09772777682601871]
	TIME [epoch: 34.9 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11406749257293204		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.11406749257293204 | validation: 0.09921505977355813]
	TIME [epoch: 34.9 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11598396181713332		[learning rate: 0.0018205]
	Learning Rate: 0.00182051
	LOSS [training: 0.11598396181713332 | validation: 0.09465383204240324]
	TIME [epoch: 34.9 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12232811416161843		[learning rate: 0.0018133]
	Learning Rate: 0.00181327
	LOSS [training: 0.12232811416161843 | validation: 0.09652610064449604]
	TIME [epoch: 34.9 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10934669234489075		[learning rate: 0.0018061]
	Learning Rate: 0.00180605
	LOSS [training: 0.10934669234489075 | validation: 0.09242931691961398]
	TIME [epoch: 34.9 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11423745627429824		[learning rate: 0.0017989]
	Learning Rate: 0.00179887
	LOSS [training: 0.11423745627429824 | validation: 0.08697884342920169]
	TIME [epoch: 34.9 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11476174608549096		[learning rate: 0.0017917]
	Learning Rate: 0.00179172
	LOSS [training: 0.11476174608549096 | validation: 0.09385916540516685]
	TIME [epoch: 34.9 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11741466915108598		[learning rate: 0.0017846]
	Learning Rate: 0.00178459
	LOSS [training: 0.11741466915108598 | validation: 0.10009698366071158]
	TIME [epoch: 34.9 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1037114961287172		[learning rate: 0.0017775]
	Learning Rate: 0.00177749
	LOSS [training: 0.1037114961287172 | validation: 0.0907316446017932]
	TIME [epoch: 34.9 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11398314643906558		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.11398314643906558 | validation: 0.091198975011708]
	TIME [epoch: 34.9 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11763830754954091		[learning rate: 0.0017634]
	Learning Rate: 0.00176338
	LOSS [training: 0.11763830754954091 | validation: 0.09331063472417503]
	TIME [epoch: 34.9 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11720211557405585		[learning rate: 0.0017564]
	Learning Rate: 0.00175637
	LOSS [training: 0.11720211557405585 | validation: 0.09030199276448334]
	TIME [epoch: 34.9 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11751541838180228		[learning rate: 0.0017494]
	Learning Rate: 0.00174938
	LOSS [training: 0.11751541838180228 | validation: 0.09899513920325524]
	TIME [epoch: 34.9 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1109710565778263		[learning rate: 0.0017424]
	Learning Rate: 0.00174242
	LOSS [training: 0.1109710565778263 | validation: 0.10146394035827541]
	TIME [epoch: 34.9 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10916401160115452		[learning rate: 0.0017355]
	Learning Rate: 0.00173549
	LOSS [training: 0.10916401160115452 | validation: 0.0942382277911511]
	TIME [epoch: 34.9 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11518150861981008		[learning rate: 0.0017286]
	Learning Rate: 0.00172859
	LOSS [training: 0.11518150861981008 | validation: 0.09480255868217766]
	TIME [epoch: 34.9 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11718497783839218		[learning rate: 0.0017217]
	Learning Rate: 0.00172172
	LOSS [training: 0.11718497783839218 | validation: 0.0955692468961862]
	TIME [epoch: 34.9 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11434135818901023		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 0.11434135818901023 | validation: 0.09347852257421337]
	TIME [epoch: 34.9 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10393780633043466		[learning rate: 0.001708]
	Learning Rate: 0.00170805
	LOSS [training: 0.10393780633043466 | validation: 0.09860320622088245]
	TIME [epoch: 34.9 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12415283497877382		[learning rate: 0.0017013]
	Learning Rate: 0.00170125
	LOSS [training: 0.12415283497877382 | validation: 0.09069733965732718]
	TIME [epoch: 34.9 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1144255056348395		[learning rate: 0.0016945]
	Learning Rate: 0.00169449
	LOSS [training: 0.1144255056348395 | validation: 0.1012394813293497]
	TIME [epoch: 34.9 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12250065093774751		[learning rate: 0.0016877]
	Learning Rate: 0.00168775
	LOSS [training: 0.12250065093774751 | validation: 0.09450419794302387]
	TIME [epoch: 34.9 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12572987625255136		[learning rate: 0.001681]
	Learning Rate: 0.00168104
	LOSS [training: 0.12572987625255136 | validation: 0.0952684278438168]
	TIME [epoch: 34.9 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11357594018284521		[learning rate: 0.0016743]
	Learning Rate: 0.00167435
	LOSS [training: 0.11357594018284521 | validation: 0.09353923992309573]
	TIME [epoch: 34.9 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11466926693611972		[learning rate: 0.0016677]
	Learning Rate: 0.00166769
	LOSS [training: 0.11466926693611972 | validation: 0.09773554769867734]
	TIME [epoch: 34.9 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11536924736481009		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.11536924736481009 | validation: 0.09445959075251412]
	TIME [epoch: 34.9 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12116121721568453		[learning rate: 0.0016545]
	Learning Rate: 0.00165445
	LOSS [training: 0.12116121721568453 | validation: 0.08895998324187944]
	TIME [epoch: 34.9 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11289556288370929		[learning rate: 0.0016479]
	Learning Rate: 0.00164787
	LOSS [training: 0.11289556288370929 | validation: 0.08710147886164564]
	TIME [epoch: 34.9 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10614452542497158		[learning rate: 0.0016413]
	Learning Rate: 0.00164132
	LOSS [training: 0.10614452542497158 | validation: 0.08821790062987415]
	TIME [epoch: 34.9 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12072503275372526		[learning rate: 0.0016348]
	Learning Rate: 0.00163479
	LOSS [training: 0.12072503275372526 | validation: 0.09992548230745321]
	TIME [epoch: 34.9 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1144190314560751		[learning rate: 0.0016283]
	Learning Rate: 0.00162829
	LOSS [training: 0.1144190314560751 | validation: 0.08957885307153897]
	TIME [epoch: 34.9 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12309444359304433		[learning rate: 0.0016218]
	Learning Rate: 0.00162181
	LOSS [training: 0.12309444359304433 | validation: 0.10020077528084817]
	TIME [epoch: 35 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12660115756373969		[learning rate: 0.0016154]
	Learning Rate: 0.00161536
	LOSS [training: 0.12660115756373969 | validation: 0.0935430713860222]
	TIME [epoch: 35 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10742712488841961		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 0.10742712488841961 | validation: 0.09501177850238647]
	TIME [epoch: 35 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11863911859048709		[learning rate: 0.0016025]
	Learning Rate: 0.00160254
	LOSS [training: 0.11863911859048709 | validation: 0.09084527813150864]
	TIME [epoch: 35 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12486481882350982		[learning rate: 0.0015962]
	Learning Rate: 0.00159616
	LOSS [training: 0.12486481882350982 | validation: 0.09378386613796075]
	TIME [epoch: 35 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11332655297860998		[learning rate: 0.0015898]
	Learning Rate: 0.00158981
	LOSS [training: 0.11332655297860998 | validation: 0.09190519786941671]
	TIME [epoch: 35 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10867523819641817		[learning rate: 0.0015835]
	Learning Rate: 0.00158349
	LOSS [training: 0.10867523819641817 | validation: 0.09661204322773499]
	TIME [epoch: 35 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11627776742337684		[learning rate: 0.0015772]
	Learning Rate: 0.00157719
	LOSS [training: 0.11627776742337684 | validation: 0.0960317898477317]
	TIME [epoch: 35 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11815199175048893		[learning rate: 0.0015709]
	Learning Rate: 0.00157092
	LOSS [training: 0.11815199175048893 | validation: 0.08807297285011342]
	TIME [epoch: 35 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12082702112135234		[learning rate: 0.0015647]
	Learning Rate: 0.00156467
	LOSS [training: 0.12082702112135234 | validation: 0.09442555366292019]
	TIME [epoch: 35 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1220587992760193		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.1220587992760193 | validation: 0.09284992222636301]
	TIME [epoch: 34.9 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11201649537000266		[learning rate: 0.0015522]
	Learning Rate: 0.00155225
	LOSS [training: 0.11201649537000266 | validation: 0.08960200317949692]
	TIME [epoch: 35 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12270605258657143		[learning rate: 0.0015461]
	Learning Rate: 0.00154608
	LOSS [training: 0.12270605258657143 | validation: 0.09496329981770735]
	TIME [epoch: 34.9 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11351533449518292		[learning rate: 0.0015399]
	Learning Rate: 0.00153993
	LOSS [training: 0.11351533449518292 | validation: 0.09865244921456]
	TIME [epoch: 35 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11517791843741312		[learning rate: 0.0015338]
	Learning Rate: 0.0015338
	LOSS [training: 0.11517791843741312 | validation: 0.09324194441460101]
	TIME [epoch: 34.9 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11205939915338894		[learning rate: 0.0015277]
	Learning Rate: 0.0015277
	LOSS [training: 0.11205939915338894 | validation: 0.09486743694429747]
	TIME [epoch: 34.9 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10813787143792039		[learning rate: 0.0015216]
	Learning Rate: 0.00152163
	LOSS [training: 0.10813787143792039 | validation: 0.08917818647942474]
	TIME [epoch: 35 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10944304775133389		[learning rate: 0.0015156]
	Learning Rate: 0.00151557
	LOSS [training: 0.10944304775133389 | validation: 0.09797847316802899]
	TIME [epoch: 34.9 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1074581756119821		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.1074581756119821 | validation: 0.09276970251372485]
	TIME [epoch: 34.9 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11381823520629032		[learning rate: 0.0015035]
	Learning Rate: 0.00150354
	LOSS [training: 0.11381823520629032 | validation: 0.09446450063104758]
	TIME [epoch: 34.9 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11079248235531709		[learning rate: 0.0014976]
	Learning Rate: 0.00149756
	LOSS [training: 0.11079248235531709 | validation: 0.09908191553096113]
	TIME [epoch: 34.9 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10748470702155846		[learning rate: 0.0014916]
	Learning Rate: 0.00149161
	LOSS [training: 0.10748470702155846 | validation: 0.10125444446855618]
	TIME [epoch: 34.9 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11614366244527588		[learning rate: 0.0014857]
	Learning Rate: 0.00148567
	LOSS [training: 0.11614366244527588 | validation: 0.09373569109214633]
	TIME [epoch: 34.9 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11746379197768496		[learning rate: 0.0014798]
	Learning Rate: 0.00147976
	LOSS [training: 0.11746379197768496 | validation: 0.09279116951979813]
	TIME [epoch: 34.9 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11416152264467942		[learning rate: 0.0014739]
	Learning Rate: 0.00147388
	LOSS [training: 0.11416152264467942 | validation: 0.09607336731822418]
	TIME [epoch: 35 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11955636376894975		[learning rate: 0.001468]
	Learning Rate: 0.00146802
	LOSS [training: 0.11955636376894975 | validation: 0.09113253621102874]
	TIME [epoch: 35 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12954218667484385		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.12954218667484385 | validation: 0.09019766495499748]
	TIME [epoch: 35 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12523207198849923		[learning rate: 0.0014564]
	Learning Rate: 0.00145636
	LOSS [training: 0.12523207198849923 | validation: 0.0957529666678473]
	TIME [epoch: 35 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11864449080197385		[learning rate: 0.0014506]
	Learning Rate: 0.00145057
	LOSS [training: 0.11864449080197385 | validation: 0.09116057604127596]
	TIME [epoch: 35 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10605928689641651		[learning rate: 0.0014448]
	Learning Rate: 0.0014448
	LOSS [training: 0.10605928689641651 | validation: 0.08972556484999177]
	TIME [epoch: 35 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11281942568639601		[learning rate: 0.0014391]
	Learning Rate: 0.00143905
	LOSS [training: 0.11281942568639601 | validation: 0.09075840935876922]
	TIME [epoch: 35 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11251808504956104		[learning rate: 0.0014333]
	Learning Rate: 0.00143333
	LOSS [training: 0.11251808504956104 | validation: 0.09090390275144322]
	TIME [epoch: 35 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10668217896394692		[learning rate: 0.0014276]
	Learning Rate: 0.00142763
	LOSS [training: 0.10668217896394692 | validation: 0.08067103170155596]
	TIME [epoch: 35 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_133353/states/model_facs_dec1a_2dpca_v1_533.pth
	Model improved!!!
EPOCH 534/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11717172263818461		[learning rate: 0.001422]
	Learning Rate: 0.00142195
	LOSS [training: 0.11717172263818461 | validation: 0.09552605409730741]
	TIME [epoch: 35 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1155660360849165		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.1155660360849165 | validation: 0.09094972276332139]
	TIME [epoch: 35 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11583585174155682		[learning rate: 0.0014107]
	Learning Rate: 0.00141066
	LOSS [training: 0.11583585174155682 | validation: 0.09337583861331543]
	TIME [epoch: 35 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10873082507571988		[learning rate: 0.0014051]
	Learning Rate: 0.00140505
	LOSS [training: 0.10873082507571988 | validation: 0.09411636619119615]
	TIME [epoch: 35 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11821254263964841		[learning rate: 0.0013995]
	Learning Rate: 0.00139946
	LOSS [training: 0.11821254263964841 | validation: 0.09760687290665118]
	TIME [epoch: 35 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11396241904857901		[learning rate: 0.0013939]
	Learning Rate: 0.0013939
	LOSS [training: 0.11396241904857901 | validation: 0.09489246292405448]
	TIME [epoch: 35 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11032717369837905		[learning rate: 0.0013884]
	Learning Rate: 0.00138835
	LOSS [training: 0.11032717369837905 | validation: 0.0884531017691854]
	TIME [epoch: 35 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11218419453983428		[learning rate: 0.0013828]
	Learning Rate: 0.00138283
	LOSS [training: 0.11218419453983428 | validation: 0.09010208352566913]
	TIME [epoch: 35 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10635453069201829		[learning rate: 0.0013773]
	Learning Rate: 0.00137733
	LOSS [training: 0.10635453069201829 | validation: 0.08910867987011702]
	TIME [epoch: 35 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11268849045636051		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 0.11268849045636051 | validation: 0.09816228367071107]
	TIME [epoch: 35 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11851473637247484		[learning rate: 0.0013664]
	Learning Rate: 0.0013664
	LOSS [training: 0.11851473637247484 | validation: 0.08748565851455473]
	TIME [epoch: 35 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11989640392747719		[learning rate: 0.001361]
	Learning Rate: 0.00136096
	LOSS [training: 0.11989640392747719 | validation: 0.09149469270576496]
	TIME [epoch: 35 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11674146262537184		[learning rate: 0.0013555]
	Learning Rate: 0.00135555
	LOSS [training: 0.11674146262537184 | validation: 0.09580702433772863]
	TIME [epoch: 35 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10744055771405989		[learning rate: 0.0013502]
	Learning Rate: 0.00135016
	LOSS [training: 0.10744055771405989 | validation: 0.09265381258217596]
	TIME [epoch: 35 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11072976853654967		[learning rate: 0.0013448]
	Learning Rate: 0.00134479
	LOSS [training: 0.11072976853654967 | validation: 0.09222743304213125]
	TIME [epoch: 35 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11784570876744474		[learning rate: 0.0013394]
	Learning Rate: 0.00133944
	LOSS [training: 0.11784570876744474 | validation: 0.09042730738027435]
	TIME [epoch: 35 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11006614811703191		[learning rate: 0.0013341]
	Learning Rate: 0.00133411
	LOSS [training: 0.11006614811703191 | validation: 0.08974672555631738]
	TIME [epoch: 35 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1126744767573314		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.1126744767573314 | validation: 0.09332740581041207]
	TIME [epoch: 35 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11092479244739667		[learning rate: 0.0013235]
	Learning Rate: 0.00132352
	LOSS [training: 0.11092479244739667 | validation: 0.09378379827868752]
	TIME [epoch: 35 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11063101101301702		[learning rate: 0.0013183]
	Learning Rate: 0.00131826
	LOSS [training: 0.11063101101301702 | validation: 0.09408477328828839]
	TIME [epoch: 35 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10827416010770127		[learning rate: 0.001313]
	Learning Rate: 0.00131301
	LOSS [training: 0.10827416010770127 | validation: 0.09423818426334898]
	TIME [epoch: 35 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10778106982025049		[learning rate: 0.0013078]
	Learning Rate: 0.00130779
	LOSS [training: 0.10778106982025049 | validation: 0.09251923915475838]
	TIME [epoch: 35 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11551225142999624		[learning rate: 0.0013026]
	Learning Rate: 0.00130259
	LOSS [training: 0.11551225142999624 | validation: 0.09380808607832658]
	TIME [epoch: 35 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11584199572714447		[learning rate: 0.0012974]
	Learning Rate: 0.00129741
	LOSS [training: 0.11584199572714447 | validation: 0.09954574061636919]
	TIME [epoch: 35 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11069295658240441		[learning rate: 0.0012922]
	Learning Rate: 0.00129225
	LOSS [training: 0.11069295658240441 | validation: 0.09305671927860948]
	TIME [epoch: 35 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11666802878387023		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 0.11666802878387023 | validation: 0.09082750287454158]
	TIME [epoch: 35 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11109778323613069		[learning rate: 0.001282]
	Learning Rate: 0.00128199
	LOSS [training: 0.11109778323613069 | validation: 0.09802490874323197]
	TIME [epoch: 35 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11630994557323288		[learning rate: 0.0012769]
	Learning Rate: 0.00127689
	LOSS [training: 0.11630994557323288 | validation: 0.09127241930333582]
	TIME [epoch: 35 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1103266832551904		[learning rate: 0.0012718]
	Learning Rate: 0.00127181
	LOSS [training: 0.1103266832551904 | validation: 0.09071921440695678]
	TIME [epoch: 35 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10629143330829842		[learning rate: 0.0012668]
	Learning Rate: 0.00126675
	LOSS [training: 0.10629143330829842 | validation: 0.09079871881358949]
	TIME [epoch: 35 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12425721520227076		[learning rate: 0.0012617]
	Learning Rate: 0.00126172
	LOSS [training: 0.12425721520227076 | validation: 0.0898310295286372]
	TIME [epoch: 35 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11188468736243834		[learning rate: 0.0012567]
	Learning Rate: 0.0012567
	LOSS [training: 0.11188468736243834 | validation: 0.08871787988269017]
	TIME [epoch: 35 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11431924217372787		[learning rate: 0.0012517]
	Learning Rate: 0.0012517
	LOSS [training: 0.11431924217372787 | validation: 0.09909770777164596]
	TIME [epoch: 35 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11875941515909252		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 0.11875941515909252 | validation: 0.09023426503668863]
	TIME [epoch: 35 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11439259508770289		[learning rate: 0.0012418]
	Learning Rate: 0.00124176
	LOSS [training: 0.11439259508770289 | validation: 0.08998837639769555]
	TIME [epoch: 35 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10489504622182239		[learning rate: 0.0012368]
	Learning Rate: 0.00123682
	LOSS [training: 0.10489504622182239 | validation: 0.09014259569370944]
	TIME [epoch: 35 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11294016495939828		[learning rate: 0.0012319]
	Learning Rate: 0.0012319
	LOSS [training: 0.11294016495939828 | validation: 0.09432887229976769]
	TIME [epoch: 35 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10327947315034881		[learning rate: 0.001227]
	Learning Rate: 0.001227
	LOSS [training: 0.10327947315034881 | validation: 0.08929685185648102]
	TIME [epoch: 35 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11749777268137046		[learning rate: 0.0012221]
	Learning Rate: 0.00122212
	LOSS [training: 0.11749777268137046 | validation: 0.09887252901888324]
	TIME [epoch: 35 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11507631525098579		[learning rate: 0.0012173]
	Learning Rate: 0.00121726
	LOSS [training: 0.11507631525098579 | validation: 0.09141191388679067]
	TIME [epoch: 35 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11115397468080906		[learning rate: 0.0012124]
	Learning Rate: 0.00121242
	LOSS [training: 0.11115397468080906 | validation: 0.09491478400053899]
	TIME [epoch: 35 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10831374717260224		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 0.10831374717260224 | validation: 0.08671818992992913]
	TIME [epoch: 35 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10103972487093922		[learning rate: 0.0012028]
	Learning Rate: 0.0012028
	LOSS [training: 0.10103972487093922 | validation: 0.09868051712224482]
	TIME [epoch: 35 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10561376447921067		[learning rate: 0.001198]
	Learning Rate: 0.00119801
	LOSS [training: 0.10561376447921067 | validation: 0.0922895167154837]
	TIME [epoch: 35 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12395720452383732		[learning rate: 0.0011932]
	Learning Rate: 0.00119325
	LOSS [training: 0.12395720452383732 | validation: 0.0946288270849076]
	TIME [epoch: 35 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10731246037048067		[learning rate: 0.0011885]
	Learning Rate: 0.0011885
	LOSS [training: 0.10731246037048067 | validation: 0.08573981539359145]
	TIME [epoch: 35 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11582273718812806		[learning rate: 0.0011838]
	Learning Rate: 0.00118378
	LOSS [training: 0.11582273718812806 | validation: 0.08881875053806061]
	TIME [epoch: 35 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11510895520304791		[learning rate: 0.0011791]
	Learning Rate: 0.00117907
	LOSS [training: 0.11510895520304791 | validation: 0.0910600408714835]
	TIME [epoch: 35 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1101512067813521		[learning rate: 0.0011744]
	Learning Rate: 0.00117438
	LOSS [training: 0.1101512067813521 | validation: 0.09834740586850166]
	TIME [epoch: 35 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10998397402424162		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 0.10998397402424162 | validation: 0.09014770154255944]
	TIME [epoch: 35 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1099202450484298		[learning rate: 0.0011651]
	Learning Rate: 0.00116505
	LOSS [training: 0.1099202450484298 | validation: 0.09718615737936132]
	TIME [epoch: 35 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11530955248341246		[learning rate: 0.0011604]
	Learning Rate: 0.00116042
	LOSS [training: 0.11530955248341246 | validation: 0.09671050452847792]
	TIME [epoch: 35 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11590068050012999		[learning rate: 0.0011558]
	Learning Rate: 0.00115581
	LOSS [training: 0.11590068050012999 | validation: 0.08784957684194264]
	TIME [epoch: 35 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1145411706339925		[learning rate: 0.0011512]
	Learning Rate: 0.00115121
	LOSS [training: 0.1145411706339925 | validation: 0.09350445164097185]
	TIME [epoch: 35 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12359465129132559		[learning rate: 0.0011466]
	Learning Rate: 0.00114663
	LOSS [training: 0.12359465129132559 | validation: 0.09438936324836478]
	TIME [epoch: 35 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11309441415810888		[learning rate: 0.0011421]
	Learning Rate: 0.00114207
	LOSS [training: 0.11309441415810888 | validation: 0.09018036108427642]
	TIME [epoch: 35 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11515048725129932		[learning rate: 0.0011375]
	Learning Rate: 0.00113753
	LOSS [training: 0.11515048725129932 | validation: 0.09266185102548212]
	TIME [epoch: 35 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1262039362425282		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.1262039362425282 | validation: 0.09088682587782]
	TIME [epoch: 35 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11562377264303403		[learning rate: 0.0011285]
	Learning Rate: 0.0011285
	LOSS [training: 0.11562377264303403 | validation: 0.08319643856881595]
	TIME [epoch: 35 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10968212168817153		[learning rate: 0.001124]
	Learning Rate: 0.00112401
	LOSS [training: 0.10968212168817153 | validation: 0.0993480096798749]
	TIME [epoch: 35 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11213837925895816		[learning rate: 0.0011195]
	Learning Rate: 0.00111954
	LOSS [training: 0.11213837925895816 | validation: 0.08666600079676774]
	TIME [epoch: 35 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11941217411886236		[learning rate: 0.0011151]
	Learning Rate: 0.00111508
	LOSS [training: 0.11941217411886236 | validation: 0.08806102766643864]
	TIME [epoch: 35 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11361911706232096		[learning rate: 0.0011106]
	Learning Rate: 0.00111065
	LOSS [training: 0.11361911706232096 | validation: 0.08647156000805614]
	TIME [epoch: 35 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11279754466559237		[learning rate: 0.0011062]
	Learning Rate: 0.00110623
	LOSS [training: 0.11279754466559237 | validation: 0.09212210975904456]
	TIME [epoch: 35 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11532676448208878		[learning rate: 0.0011018]
	Learning Rate: 0.00110183
	LOSS [training: 0.11532676448208878 | validation: 0.0893748722341059]
	TIME [epoch: 35 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11240219777573651		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 0.11240219777573651 | validation: 0.08934923593661055]
	TIME [epoch: 35 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12153004283039431		[learning rate: 0.0010931]
	Learning Rate: 0.00109309
	LOSS [training: 0.12153004283039431 | validation: 0.08958969697766729]
	TIME [epoch: 35 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10888617458908523		[learning rate: 0.0010887]
	Learning Rate: 0.00108874
	LOSS [training: 0.10888617458908523 | validation: 0.0881734620057075]
	TIME [epoch: 35 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10817003289990502		[learning rate: 0.0010844]
	Learning Rate: 0.00108441
	LOSS [training: 0.10817003289990502 | validation: 0.09021851461311907]
	TIME [epoch: 35 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1070018977790505		[learning rate: 0.0010801]
	Learning Rate: 0.00108009
	LOSS [training: 0.1070018977790505 | validation: 0.08816622469557556]
	TIME [epoch: 35 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10753905656713544		[learning rate: 0.0010758]
	Learning Rate: 0.0010758
	LOSS [training: 0.10753905656713544 | validation: 0.09317696398212373]
	TIME [epoch: 35 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10347233985368678		[learning rate: 0.0010715]
	Learning Rate: 0.00107152
	LOSS [training: 0.10347233985368678 | validation: 0.09802932148422536]
	TIME [epoch: 35 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11235342481464126		[learning rate: 0.0010673]
	Learning Rate: 0.00106726
	LOSS [training: 0.11235342481464126 | validation: 0.09356275955725196]
	TIME [epoch: 35 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11179798790733525		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 0.11179798790733525 | validation: 0.09012077959822473]
	TIME [epoch: 35 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10906608812164155		[learning rate: 0.0010588]
	Learning Rate: 0.00105878
	LOSS [training: 0.10906608812164155 | validation: 0.09535989505243754]
	TIME [epoch: 35 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11487309608653756		[learning rate: 0.0010546]
	Learning Rate: 0.00105457
	LOSS [training: 0.11487309608653756 | validation: 0.09455462695542394]
	TIME [epoch: 35 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10968578514112054		[learning rate: 0.0010504]
	Learning Rate: 0.00105038
	LOSS [training: 0.10968578514112054 | validation: 0.09215454619947235]
	TIME [epoch: 35 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11421678183968452		[learning rate: 0.0010462]
	Learning Rate: 0.0010462
	LOSS [training: 0.11421678183968452 | validation: 0.09760342358167765]
	TIME [epoch: 35 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11091171529909066		[learning rate: 0.001042]
	Learning Rate: 0.00104204
	LOSS [training: 0.11091171529909066 | validation: 0.08383195107878352]
	TIME [epoch: 35 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1189915154386601		[learning rate: 0.0010379]
	Learning Rate: 0.0010379
	LOSS [training: 0.1189915154386601 | validation: 0.08778060441343881]
	TIME [epoch: 35.2 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11174195340064003		[learning rate: 0.0010338]
	Learning Rate: 0.00103377
	LOSS [training: 0.11174195340064003 | validation: 0.09424621034713036]
	TIME [epoch: 35.1 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10973891986538262		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 0.10973891986538262 | validation: 0.09951995358767071]
	TIME [epoch: 35.1 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11104836228908167		[learning rate: 0.0010256]
	Learning Rate: 0.00102556
	LOSS [training: 0.11104836228908167 | validation: 0.09294291927809925]
	TIME [epoch: 35.1 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10409263465042895		[learning rate: 0.0010215]
	Learning Rate: 0.00102148
	LOSS [training: 0.10409263465042895 | validation: 0.08972601705645278]
	TIME [epoch: 35.1 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11608225324109345		[learning rate: 0.0010174]
	Learning Rate: 0.00101742
	LOSS [training: 0.11608225324109345 | validation: 0.09184686223156699]
	TIME [epoch: 35.1 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11124298674915714		[learning rate: 0.0010134]
	Learning Rate: 0.00101337
	LOSS [training: 0.11124298674915714 | validation: 0.09153000670680153]
	TIME [epoch: 35.1 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10768670480261158		[learning rate: 0.0010093]
	Learning Rate: 0.00100934
	LOSS [training: 0.10768670480261158 | validation: 0.09357050224257037]
	TIME [epoch: 35.1 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10253307780356478		[learning rate: 0.0010053]
	Learning Rate: 0.00100533
	LOSS [training: 0.10253307780356478 | validation: 0.09844452372509456]
	TIME [epoch: 35.1 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11254748298621389		[learning rate: 0.0010013]
	Learning Rate: 0.00100133
	LOSS [training: 0.11254748298621389 | validation: 0.08406000696767643]
	TIME [epoch: 35.1 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1153360999981919		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 0.1153360999981919 | validation: 0.08986967001820342]
	TIME [epoch: 35.1 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10680828430689271		[learning rate: 0.00099338]
	Learning Rate: 0.00099338
	LOSS [training: 0.10680828430689271 | validation: 0.08965102614633347]
	TIME [epoch: 35.1 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11054324908869313		[learning rate: 0.00098943]
	Learning Rate: 0.000989429
	LOSS [training: 0.11054324908869313 | validation: 0.09673155702647193]
	TIME [epoch: 35.1 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11611727739325614		[learning rate: 0.00098549]
	Learning Rate: 0.000985494
	LOSS [training: 0.11611727739325614 | validation: 0.0904648071945131]
	TIME [epoch: 35.1 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10332965284124858		[learning rate: 0.00098157]
	Learning Rate: 0.000981574
	LOSS [training: 0.10332965284124858 | validation: 0.08804783719320669]
	TIME [epoch: 35.1 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11303638035595236		[learning rate: 0.00097767]
	Learning Rate: 0.00097767
	LOSS [training: 0.11303638035595236 | validation: 0.09232604951219622]
	TIME [epoch: 35.1 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1021793993265168		[learning rate: 0.00097378]
	Learning Rate: 0.000973782
	LOSS [training: 0.1021793993265168 | validation: 0.09251759826525321]
	TIME [epoch: 35.1 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1141532489151744		[learning rate: 0.00096991]
	Learning Rate: 0.000969909
	LOSS [training: 0.1141532489151744 | validation: 0.0913791360254538]
	TIME [epoch: 35.1 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11007133872917232		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.11007133872917232 | validation: 0.0905020306238317]
	TIME [epoch: 35.1 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10109248676394059		[learning rate: 0.00096221]
	Learning Rate: 0.000962209
	LOSS [training: 0.10109248676394059 | validation: 0.09716211178207138]
	TIME [epoch: 35.1 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11124404028189185		[learning rate: 0.00095838]
	Learning Rate: 0.000958382
	LOSS [training: 0.11124404028189185 | validation: 0.09172142724852095]
	TIME [epoch: 35.1 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11093706813877385		[learning rate: 0.00095457]
	Learning Rate: 0.00095457
	LOSS [training: 0.11093706813877385 | validation: 0.09035008910308004]
	TIME [epoch: 35.1 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10768858331884591		[learning rate: 0.00095077]
	Learning Rate: 0.000950773
	LOSS [training: 0.10768858331884591 | validation: 0.09203621080843694]
	TIME [epoch: 35.1 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11014420905430204		[learning rate: 0.00094699]
	Learning Rate: 0.000946992
	LOSS [training: 0.11014420905430204 | validation: 0.09154933321251459]
	TIME [epoch: 35.1 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1048826745324805		[learning rate: 0.00094323]
	Learning Rate: 0.000943225
	LOSS [training: 0.1048826745324805 | validation: 0.09278320813654899]
	TIME [epoch: 35.1 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10559794688069418		[learning rate: 0.00093947]
	Learning Rate: 0.000939474
	LOSS [training: 0.10559794688069418 | validation: 0.08839666447406666]
	TIME [epoch: 35.1 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11932551758757409		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.11932551758757409 | validation: 0.10125725385524864]
	TIME [epoch: 35.1 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1099363811874536		[learning rate: 0.00093202]
	Learning Rate: 0.000932015
	LOSS [training: 0.1099363811874536 | validation: 0.09165423440394962]
	TIME [epoch: 35.1 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11223600334347089		[learning rate: 0.00092831]
	Learning Rate: 0.000928309
	LOSS [training: 0.11223600334347089 | validation: 0.09101478355138456]
	TIME [epoch: 35.1 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.128780057700775		[learning rate: 0.00092462]
	Learning Rate: 0.000924616
	LOSS [training: 0.128780057700775 | validation: 0.09149562712767745]
	TIME [epoch: 35 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11692802376472594		[learning rate: 0.00092094]
	Learning Rate: 0.000920939
	LOSS [training: 0.11692802376472594 | validation: 0.09104895322090711]
	TIME [epoch: 35.1 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10940344126533091		[learning rate: 0.00091728]
	Learning Rate: 0.000917276
	LOSS [training: 0.10940344126533091 | validation: 0.09331198527407325]
	TIME [epoch: 35 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12118248240943884		[learning rate: 0.00091363]
	Learning Rate: 0.000913628
	LOSS [training: 0.12118248240943884 | validation: 0.09063695793387108]
	TIME [epoch: 35.1 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10352581183950922		[learning rate: 0.00090999]
	Learning Rate: 0.000909994
	LOSS [training: 0.10352581183950922 | validation: 0.09276878570523794]
	TIME [epoch: 35.1 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11326582395435608		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.11326582395435608 | validation: 0.09319724315984576]
	TIME [epoch: 35.1 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10302782438883074		[learning rate: 0.00090277]
	Learning Rate: 0.00090277
	LOSS [training: 0.10302782438883074 | validation: 0.09021945787111844]
	TIME [epoch: 35.1 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1034679052745377		[learning rate: 0.00089918]
	Learning Rate: 0.000899179
	LOSS [training: 0.1034679052745377 | validation: 0.08963486601063173]
	TIME [epoch: 35.1 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10877264901680926		[learning rate: 0.0008956]
	Learning Rate: 0.000895603
	LOSS [training: 0.10877264901680926 | validation: 0.08764309912108348]
	TIME [epoch: 35.2 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10894644150851349		[learning rate: 0.00089204]
	Learning Rate: 0.000892041
	LOSS [training: 0.10894644150851349 | validation: 0.09649351951933538]
	TIME [epoch: 35 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10611954659535473		[learning rate: 0.00088849]
	Learning Rate: 0.000888493
	LOSS [training: 0.10611954659535473 | validation: 0.08886409849883495]
	TIME [epoch: 35.1 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10731550614244599		[learning rate: 0.00088496]
	Learning Rate: 0.000884959
	LOSS [training: 0.10731550614244599 | validation: 0.09221640830084812]
	TIME [epoch: 35 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10841897361147491		[learning rate: 0.00088144]
	Learning Rate: 0.000881439
	LOSS [training: 0.10841897361147491 | validation: 0.09719154688092488]
	TIME [epoch: 35 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10944332302331573		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 0.10944332302331573 | validation: 0.09789882422813226]
	TIME [epoch: 35 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1124084072264556		[learning rate: 0.00087444]
	Learning Rate: 0.000874441
	LOSS [training: 0.1124084072264556 | validation: 0.09293524559690029]
	TIME [epoch: 35.1 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11404163191138858		[learning rate: 0.00087096]
	Learning Rate: 0.000870964
	LOSS [training: 0.11404163191138858 | validation: 0.10094412054000153]
	TIME [epoch: 35 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10497928341348906		[learning rate: 0.0008675]
	Learning Rate: 0.0008675
	LOSS [training: 0.10497928341348906 | validation: 0.09503925970700669]
	TIME [epoch: 35 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1094627260116728		[learning rate: 0.00086405]
	Learning Rate: 0.000864049
	LOSS [training: 0.1094627260116728 | validation: 0.09400887112543596]
	TIME [epoch: 35 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10416474032208722		[learning rate: 0.00086061]
	Learning Rate: 0.000860613
	LOSS [training: 0.10416474032208722 | validation: 0.09312950079017636]
	TIME [epoch: 35.1 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11781123863613518		[learning rate: 0.00085719]
	Learning Rate: 0.00085719
	LOSS [training: 0.11781123863613518 | validation: 0.08893561182726258]
	TIME [epoch: 35 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11457604282076013		[learning rate: 0.00085378]
	Learning Rate: 0.00085378
	LOSS [training: 0.11457604282076013 | validation: 0.08468623846922244]
	TIME [epoch: 35 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10733930584320972		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 0.10733930584320972 | validation: 0.09912637912697111]
	TIME [epoch: 35 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11382464921747812		[learning rate: 0.000847]
	Learning Rate: 0.000847002
	LOSS [training: 0.11382464921747812 | validation: 0.08836445318844499]
	TIME [epoch: 35.1 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1127531715134452		[learning rate: 0.00084363]
	Learning Rate: 0.000843634
	LOSS [training: 0.1127531715134452 | validation: 0.09509196818283014]
	TIME [epoch: 35.1 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11330091901928203		[learning rate: 0.00084028]
	Learning Rate: 0.000840278
	LOSS [training: 0.11330091901928203 | validation: 0.09571969202296864]
	TIME [epoch: 35.1 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10852031666507406		[learning rate: 0.00083694]
	Learning Rate: 0.000836936
	LOSS [training: 0.10852031666507406 | validation: 0.10194112723224258]
	TIME [epoch: 35.1 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.106544293479144		[learning rate: 0.00083361]
	Learning Rate: 0.000833608
	LOSS [training: 0.106544293479144 | validation: 0.08597227536220983]
	TIME [epoch: 35 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11889010408363172		[learning rate: 0.00083029]
	Learning Rate: 0.000830292
	LOSS [training: 0.11889010408363172 | validation: 0.0908660507225924]
	TIME [epoch: 35 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1096699990004996		[learning rate: 0.00082699]
	Learning Rate: 0.00082699
	LOSS [training: 0.1096699990004996 | validation: 0.0903484131530914]
	TIME [epoch: 35.2 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11489285008484863		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.11489285008484863 | validation: 0.09059573244131872]
	TIME [epoch: 35 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10751427908717992		[learning rate: 0.00082042]
	Learning Rate: 0.000820424
	LOSS [training: 0.10751427908717992 | validation: 0.0895117314107253]
	TIME [epoch: 35.1 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10968825187987163		[learning rate: 0.00081716]
	Learning Rate: 0.000817161
	LOSS [training: 0.10968825187987163 | validation: 0.0888797057612944]
	TIME [epoch: 35.1 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11103330946158574		[learning rate: 0.00081391]
	Learning Rate: 0.000813911
	LOSS [training: 0.11103330946158574 | validation: 0.08741327936584235]
	TIME [epoch: 35.1 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10668260885756843		[learning rate: 0.00081067]
	Learning Rate: 0.000810674
	LOSS [training: 0.10668260885756843 | validation: 0.09261107336430538]
	TIME [epoch: 35.1 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11837581698371495		[learning rate: 0.00080745]
	Learning Rate: 0.00080745
	LOSS [training: 0.11837581698371495 | validation: 0.09761689123395259]
	TIME [epoch: 35.1 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1070236894614513		[learning rate: 0.00080424]
	Learning Rate: 0.000804238
	LOSS [training: 0.1070236894614513 | validation: 0.0895191691844637]
	TIME [epoch: 35 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1055464252527717		[learning rate: 0.00080104]
	Learning Rate: 0.000801039
	LOSS [training: 0.1055464252527717 | validation: 0.10124676163226472]
	TIME [epoch: 35.1 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11251032120554649		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 0.11251032120554649 | validation: 0.08975023784940891]
	TIME [epoch: 35.1 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10626316688400547		[learning rate: 0.00079468]
	Learning Rate: 0.00079468
	LOSS [training: 0.10626316688400547 | validation: 0.0933481536922988]
	TIME [epoch: 35.1 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11608686184758404		[learning rate: 0.00079152]
	Learning Rate: 0.000791519
	LOSS [training: 0.11608686184758404 | validation: 0.09315811966203977]
	TIME [epoch: 35 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11794640581416879		[learning rate: 0.00078837]
	Learning Rate: 0.000788371
	LOSS [training: 0.11794640581416879 | validation: 0.08797191953847308]
	TIME [epoch: 35.1 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11269152383108096		[learning rate: 0.00078524]
	Learning Rate: 0.000785236
	LOSS [training: 0.11269152383108096 | validation: 0.09459106414653738]
	TIME [epoch: 35.1 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10961556407522159		[learning rate: 0.00078211]
	Learning Rate: 0.000782113
	LOSS [training: 0.10961556407522159 | validation: 0.09145271961087106]
	TIME [epoch: 35.1 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12208500570928776		[learning rate: 0.000779]
	Learning Rate: 0.000779002
	LOSS [training: 0.12208500570928776 | validation: 0.08858467109858757]
	TIME [epoch: 35.1 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10974770152861167		[learning rate: 0.0007759]
	Learning Rate: 0.000775904
	LOSS [training: 0.10974770152861167 | validation: 0.09706147550879177]
	TIME [epoch: 35.1 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1118557792015156		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 0.1118557792015156 | validation: 0.0932416766538596]
	TIME [epoch: 35 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10592551126324494		[learning rate: 0.00076974]
	Learning Rate: 0.000769744
	LOSS [training: 0.10592551126324494 | validation: 0.08515039860270242]
	TIME [epoch: 35.1 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10942881017020573		[learning rate: 0.00076668]
	Learning Rate: 0.000766682
	LOSS [training: 0.10942881017020573 | validation: 0.09135633907974453]
	TIME [epoch: 35.1 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.12765908342624518		[learning rate: 0.00076363]
	Learning Rate: 0.000763633
	LOSS [training: 0.12765908342624518 | validation: 0.09190472490889895]
	TIME [epoch: 35 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10831026449878997		[learning rate: 0.0007606]
	Learning Rate: 0.000760596
	LOSS [training: 0.10831026449878997 | validation: 0.09192728205503227]
	TIME [epoch: 35 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10830160184613735		[learning rate: 0.00075757]
	Learning Rate: 0.000757571
	LOSS [training: 0.10830160184613735 | validation: 0.09558306265833275]
	TIME [epoch: 35 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11260228470974204		[learning rate: 0.00075456]
	Learning Rate: 0.000754557
	LOSS [training: 0.11260228470974204 | validation: 0.09702583717587152]
	TIME [epoch: 35 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10439900526968077		[learning rate: 0.00075156]
	Learning Rate: 0.000751556
	LOSS [training: 0.10439900526968077 | validation: 0.09404134470714057]
	TIME [epoch: 35.1 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11151584011709773		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 0.11151584011709773 | validation: 0.0918048443992863]
	TIME [epoch: 35.1 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11493296982025576		[learning rate: 0.00074559]
	Learning Rate: 0.00074559
	LOSS [training: 0.11493296982025576 | validation: 0.08889168840502193]
	TIME [epoch: 35 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10342276420945314		[learning rate: 0.00074262]
	Learning Rate: 0.000742624
	LOSS [training: 0.10342276420945314 | validation: 0.09293562254409518]
	TIME [epoch: 35 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10941050935801985		[learning rate: 0.00073967]
	Learning Rate: 0.000739671
	LOSS [training: 0.10941050935801985 | validation: 0.09190200415468953]
	TIME [epoch: 35 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11119873196208821		[learning rate: 0.00073673]
	Learning Rate: 0.000736729
	LOSS [training: 0.11119873196208821 | validation: 0.09502573043456852]
	TIME [epoch: 35.1 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11383928044762165		[learning rate: 0.0007338]
	Learning Rate: 0.000733799
	LOSS [training: 0.11383928044762165 | validation: 0.08980539038671125]
	TIME [epoch: 35.1 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10691460391549157		[learning rate: 0.00073088]
	Learning Rate: 0.00073088
	LOSS [training: 0.10691460391549157 | validation: 0.09523793744290028]
	TIME [epoch: 35 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11513588467345207		[learning rate: 0.00072797]
	Learning Rate: 0.000727973
	LOSS [training: 0.11513588467345207 | validation: 0.08654804700409739]
	TIME [epoch: 35 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11185189268127038		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 0.11185189268127038 | validation: 0.09946467649656847]
	TIME [epoch: 35 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11764366208577387		[learning rate: 0.00072219]
	Learning Rate: 0.000722194
	LOSS [training: 0.11764366208577387 | validation: 0.09573272910289927]
	TIME [epoch: 35 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10338400942658865		[learning rate: 0.00071932]
	Learning Rate: 0.000719322
	LOSS [training: 0.10338400942658865 | validation: 0.0891001452444207]
	TIME [epoch: 35.1 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11388077464615158		[learning rate: 0.00071646]
	Learning Rate: 0.000716461
	LOSS [training: 0.11388077464615158 | validation: 0.09119343156934712]
	TIME [epoch: 35.1 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11255881663913232		[learning rate: 0.00071361]
	Learning Rate: 0.000713611
	LOSS [training: 0.11255881663913232 | validation: 0.08667169723576726]
	TIME [epoch: 35 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11108979197500304		[learning rate: 0.00071077]
	Learning Rate: 0.000710773
	LOSS [training: 0.11108979197500304 | validation: 0.09732305195460048]
	TIME [epoch: 35.1 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11205367101177204		[learning rate: 0.00070795]
	Learning Rate: 0.000707946
	LOSS [training: 0.11205367101177204 | validation: 0.09215843335622952]
	TIME [epoch: 35.1 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11297359063951513		[learning rate: 0.00070513]
	Learning Rate: 0.00070513
	LOSS [training: 0.11297359063951513 | validation: 0.09312359381207422]
	TIME [epoch: 35 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11006759684576523		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.11006759684576523 | validation: 0.09727038795902605]
	TIME [epoch: 35 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10967583532633483		[learning rate: 0.00069953]
	Learning Rate: 0.000699532
	LOSS [training: 0.10967583532633483 | validation: 0.09267475562446191]
	TIME [epoch: 35 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11136601194647017		[learning rate: 0.00069675]
	Learning Rate: 0.00069675
	LOSS [training: 0.11136601194647017 | validation: 0.08979988749465702]
	TIME [epoch: 35 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1145867008654618		[learning rate: 0.00069398]
	Learning Rate: 0.000693979
	LOSS [training: 0.1145867008654618 | validation: 0.09313515538246771]
	TIME [epoch: 35 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10820995315307219		[learning rate: 0.00069122]
	Learning Rate: 0.000691219
	LOSS [training: 0.10820995315307219 | validation: 0.0938096831220693]
	TIME [epoch: 35 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10700416196289647		[learning rate: 0.00068847]
	Learning Rate: 0.000688469
	LOSS [training: 0.10700416196289647 | validation: 0.08640529865491174]
	TIME [epoch: 35 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11165279958722346		[learning rate: 0.00068573]
	Learning Rate: 0.000685731
	LOSS [training: 0.11165279958722346 | validation: 0.09247963583496108]
	TIME [epoch: 35.1 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11153291324050701		[learning rate: 0.000683]
	Learning Rate: 0.000683004
	LOSS [training: 0.11153291324050701 | validation: 0.09042794002294277]
	TIME [epoch: 35.1 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11625426167726258		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 0.11625426167726258 | validation: 0.09891328249666347]
	TIME [epoch: 35 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10617388988550552		[learning rate: 0.00067758]
	Learning Rate: 0.000677582
	LOSS [training: 0.10617388988550552 | validation: 0.08629355973040095]
	TIME [epoch: 35 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10895220019575447		[learning rate: 0.00067489]
	Learning Rate: 0.000674887
	LOSS [training: 0.10895220019575447 | validation: 0.08397783883323669]
	TIME [epoch: 35 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10874673870696694		[learning rate: 0.0006722]
	Learning Rate: 0.000672202
	LOSS [training: 0.10874673870696694 | validation: 0.09206451454493039]
	TIME [epoch: 35.1 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11010281212030198		[learning rate: 0.00066953]
	Learning Rate: 0.000669529
	LOSS [training: 0.11010281212030198 | validation: 0.08441797849237201]
	TIME [epoch: 35 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.11569773635028173		[learning rate: 0.00066687]
	Learning Rate: 0.000666866
	LOSS [training: 0.11569773635028173 | validation: 0.0879714694050103]
	TIME [epoch: 35.1 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10089627214342191		[learning rate: 0.00066421]
	Learning Rate: 0.000664213
	LOSS [training: 0.10089627214342191 | validation: 0.09110121114454775]
	TIME [epoch: 35 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10620170473130551		[learning rate: 0.00066157]
	Learning Rate: 0.000661572
	LOSS [training: 0.10620170473130551 | validation: 0.10117022802903297]
	TIME [epoch: 35 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10254923010947288		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 0.10254923010947288 | validation: 0.09014186080496903]
	TIME [epoch: 35 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10953595206019864		[learning rate: 0.00065632]
	Learning Rate: 0.00065632
	LOSS [training: 0.10953595206019864 | validation: 0.09437681503980298]
	TIME [epoch: 35 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10992715419232683		[learning rate: 0.00065371]
	Learning Rate: 0.000653709
	LOSS [training: 0.10992715419232683 | validation: 0.09986654086915066]
	TIME [epoch: 35 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10650903596472193		[learning rate: 0.00065111]
	Learning Rate: 0.000651109
	LOSS [training: 0.10650903596472193 | validation: 0.09301714191423988]
	TIME [epoch: 35.1 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10702847321922976		[learning rate: 0.00064852]
	Learning Rate: 0.00064852
	LOSS [training: 0.10702847321922976 | validation: 0.09064049697815438]
	TIME [epoch: 35 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.10654439814188518		[learning rate: 0.00064594]
	Learning Rate: 0.00064594
	LOSS [training: 0.10654439814188518 | validation: 0.09060296219609432]
	TIME [epoch: 35 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.115255632569594		[learning rate: 0.00064337]
	Learning Rate: 0.000643371
	LOSS [training: 0.115255632569594 | validation: 0.09537255391390542]
	TIME [epoch: 35 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1055331060478336		[learning rate: 0.00064081]
	Learning Rate: 0.000640812
	LOSS [training: 0.1055331060478336 | validation: 0.09855073704537794]
	TIME [epoch: 35 sec]
	Saving model to: out/model_training/model_facs_dec1a_2dpca_v1_20240627_133353/states/model_facs_dec1a_2dpca_v1_734.pth
Halted early. No improvement in validation loss for 200 epochs.
Finished training in 25741.606 seconds.
