Args:
Namespace(name='model_facs_v3_dec2b_2dpca_v15b', outdir='out/model_training/model_facs_v3_dec2b_2dpca_v15b', training_data='data/training_data/facs_v3/pca/dec2_fitonsubset/transition2_subset_ce_pn_m_pc12/training', validation_data='data/training_data/facs_v3/pca/dec2_fitonsubset/transition2_subset_ce_pn_m_pc12/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=10, batch_size=50, patience=200, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, quadratic_a=1.0, quadratic_b=1.0, ndims=2, nparams=2, nsigs=2, ncells=100, ncells_sample=100, model_do_sample=False, dt=0.005, dt_schedule='stepped', dt_schedule_bounds=[50, 100, 200, 300], dt_schedule_scales=[0.5, 0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', kernel='multiscale', bw_range=[0.2, 0.5, 0.9, 1.1, 1.3, 1.5, 2.0], optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 3565394

Training model...

Saving initial model state to: out/model_training/model_facs_v3_dec2b_2dpca_v15b_20240716_171520/states/model_facs_v3_dec2b_2dpca_v15b_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9160976089458311		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9160976089458311 | validation: 0.9389976218024656]
	TIME [epoch: 29.4 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v15b_20240716_171520/states/model_facs_v3_dec2b_2dpca_v15b_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7153275444209848		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7153275444209848 | validation: 0.9286962799180064]
	TIME [epoch: 3.65 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v15b_20240716_171520/states/model_facs_v3_dec2b_2dpca_v15b_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6993245394473211		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6993245394473211 | validation: 0.9563625984518513]
	TIME [epoch: 3.63 sec]
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.585139557674498		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.585139557674498 | validation: 0.8082242816654198]
	TIME [epoch: 3.61 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v15b_20240716_171520/states/model_facs_v3_dec2b_2dpca_v15b_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5677630154569081		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5677630154569081 | validation: 0.8633373273291677]
	TIME [epoch: 3.63 sec]
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5923020100126201		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5923020100126201 | validation: 0.7587427279812868]
	TIME [epoch: 3.64 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v15b_20240716_171520/states/model_facs_v3_dec2b_2dpca_v15b_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5371575716792999		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5371575716792999 | validation: 0.73099007105769]
	TIME [epoch: 3.63 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v15b_20240716_171520/states/model_facs_v3_dec2b_2dpca_v15b_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5217362434987615		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5217362434987615 | validation: 0.7096500748869887]
	TIME [epoch: 3.63 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v15b_20240716_171520/states/model_facs_v3_dec2b_2dpca_v15b_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5138262263241374		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5138262263241374 | validation: 0.846924918883312]
	TIME [epoch: 3.65 sec]
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5552925640636153		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5552925640636153 | validation: 0.6546780854426298]
	TIME [epoch: 3.63 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v15b_20240716_171520/states/model_facs_v3_dec2b_2dpca_v15b_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40959645465242783		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.40959645465242783 | validation: 0.6055668526854617]
	TIME [epoch: 3.63 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v15b_20240716_171520/states/model_facs_v3_dec2b_2dpca_v15b_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5058706851709328		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5058706851709328 | validation: 0.671249850200602]
	TIME [epoch: 3.63 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4146989897918937		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4146989897918937 | validation: 0.6416631883870715]
	TIME [epoch: 3.63 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41369569582269194		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.41369569582269194 | validation: 0.5794644151672609]
	TIME [epoch: 3.63 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v15b_20240716_171520/states/model_facs_v3_dec2b_2dpca_v15b_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44016473344422397		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.44016473344422397 | validation: 0.6279191056144574]
	TIME [epoch: 3.64 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4186930384913866		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4186930384913866 | validation: 0.5425147008137934]
	TIME [epoch: 3.63 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v15b_20240716_171520/states/model_facs_v3_dec2b_2dpca_v15b_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3691200673874172		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3691200673874172 | validation: 0.5510902317351319]
	TIME [epoch: 3.65 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3894416668610492		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3894416668610492 | validation: 0.6105466276588458]
	TIME [epoch: 3.64 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38371287212274563		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.38371287212274563 | validation: 0.48249250395817794]
	TIME [epoch: 3.63 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v15b_20240716_171520/states/model_facs_v3_dec2b_2dpca_v15b_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3386999771142409		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3386999771142409 | validation: 0.4675048668550034]
	TIME [epoch: 3.63 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v15b_20240716_171520/states/model_facs_v3_dec2b_2dpca_v15b_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2940417711338983		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2940417711338983 | validation: 0.4618242701201534]
	TIME [epoch: 3.63 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v15b_20240716_171520/states/model_facs_v3_dec2b_2dpca_v15b_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23517202271871313		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23517202271871313 | validation: 0.4584881999218027]
	TIME [epoch: 3.63 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v15b_20240716_171520/states/model_facs_v3_dec2b_2dpca_v15b_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41259845003644036		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.41259845003644036 | validation: 0.4404890379030983]
	TIME [epoch: 3.62 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v15b_20240716_171520/states/model_facs_v3_dec2b_2dpca_v15b_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25763431443035095		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.25763431443035095 | validation: 0.42128706590039683]
	TIME [epoch: 3.63 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v15b_20240716_171520/states/model_facs_v3_dec2b_2dpca_v15b_24.pth
	Model improved!!!
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.240843922015317		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.240843922015317 | validation: 0.4627747802932707]
	TIME [epoch: 3.64 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2768182072279996		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2768182072279996 | validation: 0.5188553907145124]
	TIME [epoch: 3.65 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2823546842392378		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2823546842392378 | validation: 0.4299316827580387]
	TIME [epoch: 3.64 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2803397531289009		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2803397531289009 | validation: 0.4698123995736221]
	TIME [epoch: 3.64 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23100370000561865		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23100370000561865 | validation: 0.40046686517013574]
	TIME [epoch: 3.64 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v15b_20240716_171520/states/model_facs_v3_dec2b_2dpca_v15b_29.pth
	Model improved!!!
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19955153563643296		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.19955153563643296 | validation: 0.5279376952168312]
	TIME [epoch: 3.64 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28846608461947265		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.28846608461947265 | validation: 0.4608381121780218]
	TIME [epoch: 3.64 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25185450514703056		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.25185450514703056 | validation: 0.39280756753928864]
	TIME [epoch: 3.64 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v15b_20240716_171520/states/model_facs_v3_dec2b_2dpca_v15b_32.pth
	Model improved!!!
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2930510772230406		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2930510772230406 | validation: 0.4883428976345804]
	TIME [epoch: 3.62 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3072770194994728		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3072770194994728 | validation: 0.3938260053191197]
	TIME [epoch: 3.64 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2105191766782875		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2105191766782875 | validation: 0.3938358132085522]
	TIME [epoch: 3.63 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19818103262333578		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.19818103262333578 | validation: 0.5659520300248153]
	TIME [epoch: 3.62 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34457147991217824		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.34457147991217824 | validation: 0.45023661127812503]
	TIME [epoch: 3.62 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2710816226760967		[learning rate: 0.0099882]
	Learning Rate: 0.0099882
	LOSS [training: 0.2710816226760967 | validation: 0.6741988574693614]
	TIME [epoch: 3.62 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3062704111608813		[learning rate: 0.0099411]
	Learning Rate: 0.00994113
	LOSS [training: 0.3062704111608813 | validation: 0.40639811480634314]
	TIME [epoch: 3.62 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2375490648418081		[learning rate: 0.0098943]
	Learning Rate: 0.00989429
	LOSS [training: 0.2375490648418081 | validation: 0.5603222650606404]
	TIME [epoch: 3.62 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2766426355305704		[learning rate: 0.0098477]
	Learning Rate: 0.00984767
	LOSS [training: 0.2766426355305704 | validation: 0.3936817716240286]
	TIME [epoch: 3.62 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22786665351057472		[learning rate: 0.0098013]
	Learning Rate: 0.00980126
	LOSS [training: 0.22786665351057472 | validation: 0.5494247747643661]
	TIME [epoch: 3.62 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3209656305719405		[learning rate: 0.0097551]
	Learning Rate: 0.00975508
	LOSS [training: 0.3209656305719405 | validation: 0.714722951357572]
	TIME [epoch: 3.63 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35944281953821616		[learning rate: 0.0097091]
	Learning Rate: 0.00970911
	LOSS [training: 0.35944281953821616 | validation: 0.40174489474598857]
	TIME [epoch: 3.62 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20953741696510775		[learning rate: 0.0096634]
	Learning Rate: 0.00966336
	LOSS [training: 0.20953741696510775 | validation: 0.45695728687652126]
	TIME [epoch: 3.62 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19648491091924597		[learning rate: 0.0096178]
	Learning Rate: 0.00961783
	LOSS [training: 0.19648491091924597 | validation: 0.3842264670572773]
	TIME [epoch: 3.62 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v15b_20240716_171520/states/model_facs_v3_dec2b_2dpca_v15b_46.pth
	Model improved!!!
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1996537001196009		[learning rate: 0.0095725]
	Learning Rate: 0.00957251
	LOSS [training: 0.1996537001196009 | validation: 0.40771563518373155]
	TIME [epoch: 3.64 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2441824091048077		[learning rate: 0.0095274]
	Learning Rate: 0.0095274
	LOSS [training: 0.2441824091048077 | validation: 0.533121328625925]
	TIME [epoch: 3.64 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2582123469246602		[learning rate: 0.0094825]
	Learning Rate: 0.0094825
	LOSS [training: 0.2582123469246602 | validation: 0.4210868108317125]
	TIME [epoch: 3.64 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22755955562333186		[learning rate: 0.0094378]
	Learning Rate: 0.00943782
	LOSS [training: 0.22755955562333186 | validation: 0.41790373733990716]
	TIME [epoch: 3.64 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23923345293369824		[learning rate: 0.0093933]
	Learning Rate: 0.00939335
	LOSS [training: 0.23923345293369824 | validation: 0.4538905691355835]
	TIME [epoch: 30.6 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20951641121742268		[learning rate: 0.0093491]
	Learning Rate: 0.00934909
	LOSS [training: 0.20951641121742268 | validation: 0.47950738743001176]
	TIME [epoch: 6.98 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23822913363532955		[learning rate: 0.009305]
	Learning Rate: 0.00930503
	LOSS [training: 0.23822913363532955 | validation: 0.42870649564900376]
	TIME [epoch: 6.97 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28877589125196584		[learning rate: 0.0092612]
	Learning Rate: 0.00926119
	LOSS [training: 0.28877589125196584 | validation: 0.42950017625538695]
	TIME [epoch: 6.99 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.260408811208627		[learning rate: 0.0092175]
	Learning Rate: 0.00921755
	LOSS [training: 0.260408811208627 | validation: 0.3842056390785412]
	TIME [epoch: 6.98 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v15b_20240716_171520/states/model_facs_v3_dec2b_2dpca_v15b_55.pth
	Model improved!!!
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19072840368478472		[learning rate: 0.0091741]
	Learning Rate: 0.00917411
	LOSS [training: 0.19072840368478472 | validation: 0.3278944875484145]
	TIME [epoch: 6.94 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v15b_20240716_171520/states/model_facs_v3_dec2b_2dpca_v15b_56.pth
	Model improved!!!
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2502994135318996		[learning rate: 0.0091309]
	Learning Rate: 0.00913088
	LOSS [training: 0.2502994135318996 | validation: 0.6159841198658887]
	TIME [epoch: 6.96 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2967610082163935		[learning rate: 0.0090879]
	Learning Rate: 0.00908786
	LOSS [training: 0.2967610082163935 | validation: 0.40478630635488655]
	TIME [epoch: 6.98 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2747501306236759		[learning rate: 0.009045]
	Learning Rate: 0.00904503
	LOSS [training: 0.2747501306236759 | validation: 0.43797301852748666]
	TIME [epoch: 6.99 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2289212915695304		[learning rate: 0.0090024]
	Learning Rate: 0.00900241
	LOSS [training: 0.2289212915695304 | validation: 0.6778902679515841]
	TIME [epoch: 6.98 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2721529847960146		[learning rate: 0.00896]
	Learning Rate: 0.00895999
	LOSS [training: 0.2721529847960146 | validation: 0.3649195267476863]
	TIME [epoch: 6.98 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1956963468186699		[learning rate: 0.0089178]
	Learning Rate: 0.00891777
	LOSS [training: 0.1956963468186699 | validation: 0.44739694971947674]
	TIME [epoch: 6.96 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21612306137054857		[learning rate: 0.0088758]
	Learning Rate: 0.00887575
	LOSS [training: 0.21612306137054857 | validation: 0.39953471684918473]
	TIME [epoch: 6.98 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2068291218034365		[learning rate: 0.0088339]
	Learning Rate: 0.00883393
	LOSS [training: 0.2068291218034365 | validation: 0.43999734659002193]
	TIME [epoch: 6.99 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2500561290311802		[learning rate: 0.0087923]
	Learning Rate: 0.0087923
	LOSS [training: 0.2500561290311802 | validation: 0.39067246575467685]
	TIME [epoch: 6.97 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24190351066844432		[learning rate: 0.0087509]
	Learning Rate: 0.00875087
	LOSS [training: 0.24190351066844432 | validation: 0.451005557395367]
	TIME [epoch: 6.97 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22937253068437652		[learning rate: 0.0087096]
	Learning Rate: 0.00870964
	LOSS [training: 0.22937253068437652 | validation: 0.3949363122034598]
	TIME [epoch: 6.97 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19686059286843663		[learning rate: 0.0086686]
	Learning Rate: 0.00866859
	LOSS [training: 0.19686059286843663 | validation: 0.34900039223341506]
	TIME [epoch: 6.98 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1946541523320791		[learning rate: 0.0086277]
	Learning Rate: 0.00862775
	LOSS [training: 0.1946541523320791 | validation: 0.6737931020159529]
	TIME [epoch: 6.99 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28226340430952496		[learning rate: 0.0085871]
	Learning Rate: 0.00858709
	LOSS [training: 0.28226340430952496 | validation: 0.31501097391916705]
	TIME [epoch: 6.97 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v15b_20240716_171520/states/model_facs_v3_dec2b_2dpca_v15b_70.pth
	Model improved!!!
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21559928265599002		[learning rate: 0.0085466]
	Learning Rate: 0.00854663
	LOSS [training: 0.21559928265599002 | validation: 0.5113128445875766]
	TIME [epoch: 6.93 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20701090709007178		[learning rate: 0.0085064]
	Learning Rate: 0.00850636
	LOSS [training: 0.20701090709007178 | validation: 0.40617876341625136]
	TIME [epoch: 6.94 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2112276713552741		[learning rate: 0.0084663]
	Learning Rate: 0.00846627
	LOSS [training: 0.2112276713552741 | validation: 0.3593488467180727]
	TIME [epoch: 6.95 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2205964203990033		[learning rate: 0.0084264]
	Learning Rate: 0.00842638
	LOSS [training: 0.2205964203990033 | validation: 0.38342303994867516]
	TIME [epoch: 6.95 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22319454209131687		[learning rate: 0.0083867]
	Learning Rate: 0.00838667
	LOSS [training: 0.22319454209131687 | validation: 0.32767587803662934]
	TIME [epoch: 6.93 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21522864848303233		[learning rate: 0.0083472]
	Learning Rate: 0.00834715
	LOSS [training: 0.21522864848303233 | validation: 0.3881725824470137]
	TIME [epoch: 6.93 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19480083870171594		[learning rate: 0.0083078]
	Learning Rate: 0.00830782
	LOSS [training: 0.19480083870171594 | validation: 0.4360806954299389]
	TIME [epoch: 6.96 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2355033456847496		[learning rate: 0.0082687]
	Learning Rate: 0.00826867
	LOSS [training: 0.2355033456847496 | validation: 0.3047445652683124]
	TIME [epoch: 6.95 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v15b_20240716_171520/states/model_facs_v3_dec2b_2dpca_v15b_78.pth
	Model improved!!!
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21065911018610686		[learning rate: 0.0082297]
	Learning Rate: 0.00822971
	LOSS [training: 0.21065911018610686 | validation: 0.35158464210539286]
	TIME [epoch: 6.99 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24391178696825286		[learning rate: 0.0081909]
	Learning Rate: 0.00819093
	LOSS [training: 0.24391178696825286 | validation: 0.3848576866000968]
	TIME [epoch: 6.98 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2220538795790955		[learning rate: 0.0081523]
	Learning Rate: 0.00815233
	LOSS [training: 0.2220538795790955 | validation: 0.4171804624757657]
	TIME [epoch: 6.98 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25660681187693135		[learning rate: 0.0081139]
	Learning Rate: 0.00811392
	LOSS [training: 0.25660681187693135 | validation: 0.4040253502184568]
	TIME [epoch: 6.99 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20634886377173578		[learning rate: 0.0080757]
	Learning Rate: 0.00807569
	LOSS [training: 0.20634886377173578 | validation: 0.3877911339411337]
	TIME [epoch: 6.99 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22698287159194597		[learning rate: 0.0080376]
	Learning Rate: 0.00803763
	LOSS [training: 0.22698287159194597 | validation: 0.3366095044474302]
	TIME [epoch: 6.98 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2011747625264928		[learning rate: 0.0079998]
	Learning Rate: 0.00799976
	LOSS [training: 0.2011747625264928 | validation: 0.41263399129741724]
	TIME [epoch: 6.98 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20216418969777805		[learning rate: 0.0079621]
	Learning Rate: 0.00796206
	LOSS [training: 0.20216418969777805 | validation: 0.3721520054326554]
	TIME [epoch: 6.98 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19326626060986776		[learning rate: 0.0079245]
	Learning Rate: 0.00792455
	LOSS [training: 0.19326626060986776 | validation: 0.3228759375504512]
	TIME [epoch: 6.99 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19766262455316852		[learning rate: 0.0078872]
	Learning Rate: 0.0078872
	LOSS [training: 0.19766262455316852 | validation: 0.40941241240532283]
	TIME [epoch: 7 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25921835118657827		[learning rate: 0.00785]
	Learning Rate: 0.00785004
	LOSS [training: 0.25921835118657827 | validation: 0.44092973904974136]
	TIME [epoch: 6.98 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2055917490809848		[learning rate: 0.007813]
	Learning Rate: 0.00781305
	LOSS [training: 0.2055917490809848 | validation: 0.32570610575079617]
	TIME [epoch: 6.98 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15395051303180357		[learning rate: 0.0077762]
	Learning Rate: 0.00777623
	LOSS [training: 0.15395051303180357 | validation: 0.3372845666106129]
	TIME [epoch: 6.99 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18485171620683144		[learning rate: 0.0077396]
	Learning Rate: 0.00773959
	LOSS [training: 0.18485171620683144 | validation: 0.6220744895493214]
	TIME [epoch: 6.99 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2468424605054714		[learning rate: 0.0077031]
	Learning Rate: 0.00770312
	LOSS [training: 0.2468424605054714 | validation: 0.38163309145795415]
	TIME [epoch: 6.99 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22012709980067563		[learning rate: 0.0076668]
	Learning Rate: 0.00766682
	LOSS [training: 0.22012709980067563 | validation: 0.3641250364645636]
	TIME [epoch: 6.99 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21090240940028554		[learning rate: 0.0076307]
	Learning Rate: 0.0076307
	LOSS [training: 0.21090240940028554 | validation: 0.3452172088417962]
	TIME [epoch: 6.98 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20011558497712928		[learning rate: 0.0075947]
	Learning Rate: 0.00759474
	LOSS [training: 0.20011558497712928 | validation: 0.37958829428326013]
	TIME [epoch: 6.98 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2078656599930362		[learning rate: 0.007559]
	Learning Rate: 0.00755895
	LOSS [training: 0.2078656599930362 | validation: 0.5235657144047176]
	TIME [epoch: 6.98 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24426086283240606		[learning rate: 0.0075233]
	Learning Rate: 0.00752333
	LOSS [training: 0.24426086283240606 | validation: 0.5045394664464632]
	TIME [epoch: 6.99 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18715047529988332		[learning rate: 0.0074879]
	Learning Rate: 0.00748788
	LOSS [training: 0.18715047529988332 | validation: 0.34818914890543534]
	TIME [epoch: 6.98 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19124140528033837		[learning rate: 0.0074526]
	Learning Rate: 0.0074526
	LOSS [training: 0.19124140528033837 | validation: 0.32039036831628986]
	TIME [epoch: 6.98 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20620596344467335		[learning rate: 0.0074175]
	Learning Rate: 0.00741748
	LOSS [training: 0.20620596344467335 | validation: 0.540002014613109]
	TIME [epoch: 38.8 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2210347235930664		[learning rate: 0.0073825]
	Learning Rate: 0.00738253
	LOSS [training: 0.2210347235930664 | validation: 0.38625291919804156]
	TIME [epoch: 15.2 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22202888495629974		[learning rate: 0.0073477]
	Learning Rate: 0.00734774
	LOSS [training: 0.22202888495629974 | validation: 0.3896807035394202]
	TIME [epoch: 15.2 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21940033167672235		[learning rate: 0.0073131]
	Learning Rate: 0.00731312
	LOSS [training: 0.21940033167672235 | validation: 0.357036141215941]
	TIME [epoch: 15.2 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21002846413665052		[learning rate: 0.0072787]
	Learning Rate: 0.00727866
	LOSS [training: 0.21002846413665052 | validation: 0.36896700793787474]
	TIME [epoch: 15.2 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26378001642263005		[learning rate: 0.0072444]
	Learning Rate: 0.00724436
	LOSS [training: 0.26378001642263005 | validation: 0.3757783542025959]
	TIME [epoch: 15.2 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2396270170018708		[learning rate: 0.0072102]
	Learning Rate: 0.00721022
	LOSS [training: 0.2396270170018708 | validation: 0.50465125744801]
	TIME [epoch: 15.2 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2229928760597246		[learning rate: 0.0071762]
	Learning Rate: 0.00717625
	LOSS [training: 0.2229928760597246 | validation: 0.447628876867725]
	TIME [epoch: 15.2 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19438202028338933		[learning rate: 0.0071424]
	Learning Rate: 0.00714243
	LOSS [training: 0.19438202028338933 | validation: 0.3730165545953258]
	TIME [epoch: 15.2 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19857454247354556		[learning rate: 0.0071088]
	Learning Rate: 0.00710878
	LOSS [training: 0.19857454247354556 | validation: 0.39052686318951524]
	TIME [epoch: 15.2 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18742007225837737		[learning rate: 0.0070753]
	Learning Rate: 0.00707528
	LOSS [training: 0.18742007225837737 | validation: 0.5152357409946237]
	TIME [epoch: 15.2 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25349241379894116		[learning rate: 0.0070419]
	Learning Rate: 0.00704194
	LOSS [training: 0.25349241379894116 | validation: 0.334480322064022]
	TIME [epoch: 15.2 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18238571963860947		[learning rate: 0.0070088]
	Learning Rate: 0.00700876
	LOSS [training: 0.18238571963860947 | validation: 0.40109411316304466]
	TIME [epoch: 15.2 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1874563801036387		[learning rate: 0.0069757]
	Learning Rate: 0.00697573
	LOSS [training: 0.1874563801036387 | validation: 0.3810591345090312]
	TIME [epoch: 15.2 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16749650390142987		[learning rate: 0.0069429]
	Learning Rate: 0.00694286
	LOSS [training: 0.16749650390142987 | validation: 0.3372172691162492]
	TIME [epoch: 15.2 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1936010489563021		[learning rate: 0.0069101]
	Learning Rate: 0.00691014
	LOSS [training: 0.1936010489563021 | validation: 0.3743822491155752]
	TIME [epoch: 15.2 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2001375194043009		[learning rate: 0.0068776]
	Learning Rate: 0.00687758
	LOSS [training: 0.2001375194043009 | validation: 0.38150524110735395]
	TIME [epoch: 15.2 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2041051528069599		[learning rate: 0.0068452]
	Learning Rate: 0.00684518
	LOSS [training: 0.2041051528069599 | validation: 0.328537151126137]
	TIME [epoch: 15.2 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21413914419714952		[learning rate: 0.0068129]
	Learning Rate: 0.00681292
	LOSS [training: 0.21413914419714952 | validation: 0.3271656529725564]
	TIME [epoch: 15.2 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19538922134047346		[learning rate: 0.0067808]
	Learning Rate: 0.00678082
	LOSS [training: 0.19538922134047346 | validation: 0.3494933898268257]
	TIME [epoch: 15.2 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1896831296331807		[learning rate: 0.0067489]
	Learning Rate: 0.00674887
	LOSS [training: 0.1896831296331807 | validation: 0.38195016036368656]
	TIME [epoch: 15.2 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20564560203816076		[learning rate: 0.0067171]
	Learning Rate: 0.00671706
	LOSS [training: 0.20564560203816076 | validation: 0.33812221373979695]
	TIME [epoch: 15.2 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16567024503412195		[learning rate: 0.0066854]
	Learning Rate: 0.00668541
	LOSS [training: 0.16567024503412195 | validation: 0.3659273687857922]
	TIME [epoch: 15.2 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21443933708069485		[learning rate: 0.0066539]
	Learning Rate: 0.00665391
	LOSS [training: 0.21443933708069485 | validation: 0.36139516473296823]
	TIME [epoch: 15.2 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16322138545577422		[learning rate: 0.0066226]
	Learning Rate: 0.00662256
	LOSS [training: 0.16322138545577422 | validation: 0.35591240226816057]
	TIME [epoch: 15.2 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19754238509215782		[learning rate: 0.0065913]
	Learning Rate: 0.00659135
	LOSS [training: 0.19754238509215782 | validation: 0.4598467050628883]
	TIME [epoch: 15.2 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22075922244621468		[learning rate: 0.0065603]
	Learning Rate: 0.00656029
	LOSS [training: 0.22075922244621468 | validation: 0.3633541224162922]
	TIME [epoch: 15.2 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1641073942150311		[learning rate: 0.0065294]
	Learning Rate: 0.00652938
	LOSS [training: 0.1641073942150311 | validation: 0.3751330684578839]
	TIME [epoch: 15.2 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19172611270863482		[learning rate: 0.0064986]
	Learning Rate: 0.00649861
	LOSS [training: 0.19172611270863482 | validation: 0.4333232876478005]
	TIME [epoch: 15.2 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2727612827439193		[learning rate: 0.006468]
	Learning Rate: 0.00646799
	LOSS [training: 0.2727612827439193 | validation: 0.37311454165465013]
	TIME [epoch: 15.2 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1908553121532927		[learning rate: 0.0064375]
	Learning Rate: 0.00643751
	LOSS [training: 0.1908553121532927 | validation: 0.3576840104293681]
	TIME [epoch: 15.2 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1742999542399685		[learning rate: 0.0064072]
	Learning Rate: 0.00640718
	LOSS [training: 0.1742999542399685 | validation: 0.33462155273156946]
	TIME [epoch: 15.2 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16118923614501293		[learning rate: 0.006377]
	Learning Rate: 0.00637698
	LOSS [training: 0.16118923614501293 | validation: 0.3831994200797862]
	TIME [epoch: 15.2 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16484607535137988		[learning rate: 0.0063469]
	Learning Rate: 0.00634694
	LOSS [training: 0.16484607535137988 | validation: 0.35804310871439]
	TIME [epoch: 15.2 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20486728215347447		[learning rate: 0.006317]
	Learning Rate: 0.00631703
	LOSS [training: 0.20486728215347447 | validation: 0.46360010859429535]
	TIME [epoch: 15.2 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20687635053827858		[learning rate: 0.0062873]
	Learning Rate: 0.00628726
	LOSS [training: 0.20687635053827858 | validation: 0.47438278239603754]
	TIME [epoch: 15.2 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3469142300901962		[learning rate: 0.0062576]
	Learning Rate: 0.00625764
	LOSS [training: 0.3469142300901962 | validation: 0.5196460143219992]
	TIME [epoch: 15.2 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31170561080951475		[learning rate: 0.0062281]
	Learning Rate: 0.00622815
	LOSS [training: 0.31170561080951475 | validation: 0.5292625469382028]
	TIME [epoch: 15.2 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3010963210758629		[learning rate: 0.0061988]
	Learning Rate: 0.0061988
	LOSS [training: 0.3010963210758629 | validation: 0.4444077112057133]
	TIME [epoch: 15.2 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25154031648397074		[learning rate: 0.0061696]
	Learning Rate: 0.00616959
	LOSS [training: 0.25154031648397074 | validation: 0.4124733798269338]
	TIME [epoch: 15.2 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24583847946588877		[learning rate: 0.0061405]
	Learning Rate: 0.00614052
	LOSS [training: 0.24583847946588877 | validation: 0.4479327799548544]
	TIME [epoch: 15.2 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21568203027130695		[learning rate: 0.0061116]
	Learning Rate: 0.00611158
	LOSS [training: 0.21568203027130695 | validation: 0.33681274559065844]
	TIME [epoch: 15.2 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18614033161108628		[learning rate: 0.0060828]
	Learning Rate: 0.00608279
	LOSS [training: 0.18614033161108628 | validation: 0.3404370380699166]
	TIME [epoch: 15.2 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18380991661336213		[learning rate: 0.0060541]
	Learning Rate: 0.00605412
	LOSS [training: 0.18380991661336213 | validation: 0.44317587143529596]
	TIME [epoch: 15.2 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2712587005008553		[learning rate: 0.0060256]
	Learning Rate: 0.0060256
	LOSS [training: 0.2712587005008553 | validation: 0.546986797330591]
	TIME [epoch: 15.2 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2362180740190037		[learning rate: 0.0059972]
	Learning Rate: 0.0059972
	LOSS [training: 0.2362180740190037 | validation: 0.2891596062170917]
	TIME [epoch: 15.1 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v15b_20240716_171520/states/model_facs_v3_dec2b_2dpca_v15b_146.pth
	Model improved!!!
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20235703616563777		[learning rate: 0.0059689]
	Learning Rate: 0.00596894
	LOSS [training: 0.20235703616563777 | validation: 0.386185667546777]
	TIME [epoch: 15.2 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18362117311598034		[learning rate: 0.0059408]
	Learning Rate: 0.00594082
	LOSS [training: 0.18362117311598034 | validation: 0.33297943388900386]
	TIME [epoch: 15.2 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16723621263167254		[learning rate: 0.0059128]
	Learning Rate: 0.00591282
	LOSS [training: 0.16723621263167254 | validation: 0.3022693030602806]
	TIME [epoch: 15.2 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18375086500254584		[learning rate: 0.005885]
	Learning Rate: 0.00588496
	LOSS [training: 0.18375086500254584 | validation: 0.380226305922641]
	TIME [epoch: 15.2 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18279368677256033		[learning rate: 0.0058572]
	Learning Rate: 0.00585723
	LOSS [training: 0.18279368677256033 | validation: 0.4439992847931766]
	TIME [epoch: 15.2 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3294631037769303		[learning rate: 0.0058296]
	Learning Rate: 0.00582963
	LOSS [training: 0.3294631037769303 | validation: 0.43269175602055165]
	TIME [epoch: 15.2 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2627403522986704		[learning rate: 0.0058022]
	Learning Rate: 0.00580216
	LOSS [training: 0.2627403522986704 | validation: 0.3925664710431117]
	TIME [epoch: 15.2 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26196215650767746		[learning rate: 0.0057748]
	Learning Rate: 0.00577482
	LOSS [training: 0.26196215650767746 | validation: 0.4170877568733388]
	TIME [epoch: 15.2 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25385876759301595		[learning rate: 0.0057476]
	Learning Rate: 0.00574761
	LOSS [training: 0.25385876759301595 | validation: 0.40958946347619124]
	TIME [epoch: 15.2 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2486091577826561		[learning rate: 0.0057205]
	Learning Rate: 0.00572052
	LOSS [training: 0.2486091577826561 | validation: 0.376139626424682]
	TIME [epoch: 15.2 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1855056073774637		[learning rate: 0.0056936]
	Learning Rate: 0.00569357
	LOSS [training: 0.1855056073774637 | validation: 0.42050959786458075]
	TIME [epoch: 15.2 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18622747574541804		[learning rate: 0.0056667]
	Learning Rate: 0.00566674
	LOSS [training: 0.18622747574541804 | validation: 0.46968861352816976]
	TIME [epoch: 15.2 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2167717024043253		[learning rate: 0.00564]
	Learning Rate: 0.00564004
	LOSS [training: 0.2167717024043253 | validation: 0.36045302512760846]
	TIME [epoch: 15.2 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17585730560255378		[learning rate: 0.0056135]
	Learning Rate: 0.00561346
	LOSS [training: 0.17585730560255378 | validation: 0.4588490014692112]
	TIME [epoch: 15.2 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2046400063319718		[learning rate: 0.005587]
	Learning Rate: 0.00558701
	LOSS [training: 0.2046400063319718 | validation: 0.3674722194568673]
	TIME [epoch: 15.2 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17451129182748273		[learning rate: 0.0055607]
	Learning Rate: 0.00556068
	LOSS [training: 0.17451129182748273 | validation: 0.38133238660766683]
	TIME [epoch: 15.2 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18218951279098333		[learning rate: 0.0055345]
	Learning Rate: 0.00553448
	LOSS [training: 0.18218951279098333 | validation: 0.3433191644743086]
	TIME [epoch: 15.2 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17282347006129645		[learning rate: 0.0055084]
	Learning Rate: 0.0055084
	LOSS [training: 0.17282347006129645 | validation: 0.3603848744693571]
	TIME [epoch: 15.2 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21566585033084498		[learning rate: 0.0054824]
	Learning Rate: 0.00548245
	LOSS [training: 0.21566585033084498 | validation: 0.36142442667469865]
	TIME [epoch: 15.2 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16691469656377023		[learning rate: 0.0054566]
	Learning Rate: 0.00545661
	LOSS [training: 0.16691469656377023 | validation: 0.3939952364210705]
	TIME [epoch: 15.2 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15975805156117104		[learning rate: 0.0054309]
	Learning Rate: 0.0054309
	LOSS [training: 0.15975805156117104 | validation: 0.34478258375373755]
	TIME [epoch: 15.2 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16765312566656557		[learning rate: 0.0054053]
	Learning Rate: 0.00540531
	LOSS [training: 0.16765312566656557 | validation: 0.3673848731886345]
	TIME [epoch: 15.2 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1981171833364126		[learning rate: 0.0053798]
	Learning Rate: 0.00537984
	LOSS [training: 0.1981171833364126 | validation: 0.3683125546798183]
	TIME [epoch: 15.2 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20710247065478804		[learning rate: 0.0053545]
	Learning Rate: 0.00535449
	LOSS [training: 0.20710247065478804 | validation: 0.35443628792239756]
	TIME [epoch: 15.2 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19227362226586203		[learning rate: 0.0053293]
	Learning Rate: 0.00532926
	LOSS [training: 0.19227362226586203 | validation: 0.3524582705421595]
	TIME [epoch: 15.2 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17722928102293029		[learning rate: 0.0053041]
	Learning Rate: 0.00530415
	LOSS [training: 0.17722928102293029 | validation: 0.3355037679961562]
	TIME [epoch: 15.2 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16465517973587016		[learning rate: 0.0052792]
	Learning Rate: 0.00527915
	LOSS [training: 0.16465517973587016 | validation: 0.37168076979606707]
	TIME [epoch: 15.2 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17625941697716843		[learning rate: 0.0052543]
	Learning Rate: 0.00525428
	LOSS [training: 0.17625941697716843 | validation: 0.36785356404260355]
	TIME [epoch: 15.2 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17799468803267168		[learning rate: 0.0052295]
	Learning Rate: 0.00522952
	LOSS [training: 0.17799468803267168 | validation: 0.2939796963370175]
	TIME [epoch: 15.2 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1690250554598699		[learning rate: 0.0052049]
	Learning Rate: 0.00520487
	LOSS [training: 0.1690250554598699 | validation: 0.35106141381455946]
	TIME [epoch: 15.2 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18469242108265677		[learning rate: 0.0051803]
	Learning Rate: 0.00518035
	LOSS [training: 0.18469242108265677 | validation: 0.4215237876028825]
	TIME [epoch: 15.2 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1919613321722413		[learning rate: 0.0051559]
	Learning Rate: 0.00515594
	LOSS [training: 0.1919613321722413 | validation: 0.37108590222689314]
	TIME [epoch: 15.1 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19604488988098456		[learning rate: 0.0051316]
	Learning Rate: 0.00513164
	LOSS [training: 0.19604488988098456 | validation: 0.33910391783152893]
	TIME [epoch: 15.2 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16591809278317904		[learning rate: 0.0051075]
	Learning Rate: 0.00510746
	LOSS [training: 0.16591809278317904 | validation: 0.3640153780315293]
	TIME [epoch: 15.2 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15118638593624284		[learning rate: 0.0050834]
	Learning Rate: 0.00508339
	LOSS [training: 0.15118638593624284 | validation: 0.3608325242037425]
	TIME [epoch: 15.2 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1640531220168483		[learning rate: 0.0050594]
	Learning Rate: 0.00505944
	LOSS [training: 0.1640531220168483 | validation: 0.30564604225334047]
	TIME [epoch: 15.2 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19786394837641544		[learning rate: 0.0050356]
	Learning Rate: 0.0050356
	LOSS [training: 0.19786394837641544 | validation: 0.33083133198368075]
	TIME [epoch: 15.2 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16512886726896076		[learning rate: 0.0050119]
	Learning Rate: 0.00501187
	LOSS [training: 0.16512886726896076 | validation: 0.38962069805503263]
	TIME [epoch: 15.2 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1655281049854937		[learning rate: 0.0049883]
	Learning Rate: 0.00498826
	LOSS [training: 0.1655281049854937 | validation: 0.3065877480144499]
	TIME [epoch: 15.2 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16937758359789065		[learning rate: 0.0049648]
	Learning Rate: 0.00496475
	LOSS [training: 0.16937758359789065 | validation: 0.3166934406386144]
	TIME [epoch: 15.2 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1659404457150952		[learning rate: 0.0049414]
	Learning Rate: 0.00494136
	LOSS [training: 0.1659404457150952 | validation: 0.3050241592481612]
	TIME [epoch: 15.2 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1872126959841447		[learning rate: 0.0049181]
	Learning Rate: 0.00491807
	LOSS [training: 0.1872126959841447 | validation: 0.3614769305941628]
	TIME [epoch: 15.2 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15446395204812732		[learning rate: 0.0048949]
	Learning Rate: 0.0048949
	LOSS [training: 0.15446395204812732 | validation: 0.3653219347477224]
	TIME [epoch: 15.2 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16937553828694463		[learning rate: 0.0048718]
	Learning Rate: 0.00487183
	LOSS [training: 0.16937553828694463 | validation: 0.34523221631376466]
	TIME [epoch: 15.2 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17758185536607196		[learning rate: 0.0048489]
	Learning Rate: 0.00484888
	LOSS [training: 0.17758185536607196 | validation: 0.3677781078612653]
	TIME [epoch: 15.2 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24258300296231922		[learning rate: 0.004826]
	Learning Rate: 0.00482603
	LOSS [training: 0.24258300296231922 | validation: 0.4108185300193928]
	TIME [epoch: 15.2 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20883777687367866		[learning rate: 0.0048033]
	Learning Rate: 0.00480329
	LOSS [training: 0.20883777687367866 | validation: 0.33387660316462464]
	TIME [epoch: 15.2 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1885785424378688		[learning rate: 0.0047807]
	Learning Rate: 0.00478065
	LOSS [training: 0.1885785424378688 | validation: 0.3040764668322067]
	TIME [epoch: 15.2 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14783255693512068		[learning rate: 0.0047581]
	Learning Rate: 0.00475813
	LOSS [training: 0.14783255693512068 | validation: 0.3715289936517578]
	TIME [epoch: 15.2 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16439369317049762		[learning rate: 0.0047357]
	Learning Rate: 0.0047357
	LOSS [training: 0.16439369317049762 | validation: 0.3943816577924063]
	TIME [epoch: 15.2 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15792579802318332		[learning rate: 0.0047134]
	Learning Rate: 0.00471339
	LOSS [training: 0.15792579802318332 | validation: 0.4906433086198086]
	TIME [epoch: 15.2 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.233035712101195		[learning rate: 0.0046912]
	Learning Rate: 0.00469118
	LOSS [training: 0.233035712101195 | validation: 0.3266336685150645]
	TIME [epoch: 15.2 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19852740959713763		[learning rate: 0.0046691]
	Learning Rate: 0.00466907
	LOSS [training: 0.19852740959713763 | validation: 0.32883953980492037]
	TIME [epoch: 15.2 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17168109593436393		[learning rate: 0.0046471]
	Learning Rate: 0.00464707
	LOSS [training: 0.17168109593436393 | validation: 0.33342712002614416]
	TIME [epoch: 15.2 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14011880344383698		[learning rate: 0.0046252]
	Learning Rate: 0.00462518
	LOSS [training: 0.14011880344383698 | validation: 0.31920627025473214]
	TIME [epoch: 56.4 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19248157819281442		[learning rate: 0.0046034]
	Learning Rate: 0.00460338
	LOSS [training: 0.19248157819281442 | validation: 0.35999793053031637]
	TIME [epoch: 32.7 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17879433249164442		[learning rate: 0.0045817]
	Learning Rate: 0.00458169
	LOSS [training: 0.17879433249164442 | validation: 0.2875108309613393]
	TIME [epoch: 32.7 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v15b_20240716_171520/states/model_facs_v3_dec2b_2dpca_v15b_203.pth
	Model improved!!!
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15621805655384502		[learning rate: 0.0045601]
	Learning Rate: 0.0045601
	LOSS [training: 0.15621805655384502 | validation: 0.30241118968780295]
	TIME [epoch: 32.5 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17251043459501006		[learning rate: 0.0045386]
	Learning Rate: 0.00453861
	LOSS [training: 0.17251043459501006 | validation: 0.33014732469782226]
	TIME [epoch: 32.5 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17614120417653917		[learning rate: 0.0045172]
	Learning Rate: 0.00451723
	LOSS [training: 0.17614120417653917 | validation: 0.34144324726522157]
	TIME [epoch: 32.5 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16451027024543458		[learning rate: 0.0044959]
	Learning Rate: 0.00449594
	LOSS [training: 0.16451027024543458 | validation: 0.3216014203271187]
	TIME [epoch: 32.6 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16478839167547962		[learning rate: 0.0044748]
	Learning Rate: 0.00447475
	LOSS [training: 0.16478839167547962 | validation: 0.33185992674681697]
	TIME [epoch: 32.5 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19553471471308118		[learning rate: 0.0044537]
	Learning Rate: 0.00445367
	LOSS [training: 0.19553471471308118 | validation: 0.3560779706336642]
	TIME [epoch: 32.6 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20471140223056453		[learning rate: 0.0044327]
	Learning Rate: 0.00443268
	LOSS [training: 0.20471140223056453 | validation: 0.3750449268927494]
	TIME [epoch: 32.5 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1680865046347956		[learning rate: 0.0044118]
	Learning Rate: 0.0044118
	LOSS [training: 0.1680865046347956 | validation: 0.30558721814875683]
	TIME [epoch: 32.5 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1712031918264459		[learning rate: 0.004391]
	Learning Rate: 0.00439101
	LOSS [training: 0.1712031918264459 | validation: 0.4223603503893098]
	TIME [epoch: 32.5 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21413998420293345		[learning rate: 0.0043703]
	Learning Rate: 0.00437032
	LOSS [training: 0.21413998420293345 | validation: 0.3197898373778576]
	TIME [epoch: 32.5 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17886042619082132		[learning rate: 0.0043497]
	Learning Rate: 0.00434972
	LOSS [training: 0.17886042619082132 | validation: 0.3311659819046155]
	TIME [epoch: 32.6 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18795810233320095		[learning rate: 0.0043292]
	Learning Rate: 0.00432923
	LOSS [training: 0.18795810233320095 | validation: 0.3366571005279975]
	TIME [epoch: 32.5 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15256599827367817		[learning rate: 0.0043088]
	Learning Rate: 0.00430883
	LOSS [training: 0.15256599827367817 | validation: 0.3495262529472841]
	TIME [epoch: 32.5 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1418934329360123		[learning rate: 0.0042885]
	Learning Rate: 0.00428852
	LOSS [training: 0.1418934329360123 | validation: 0.32626325705797726]
	TIME [epoch: 32.5 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16433811784826202		[learning rate: 0.0042683]
	Learning Rate: 0.00426831
	LOSS [training: 0.16433811784826202 | validation: 0.3221410977487615]
	TIME [epoch: 32.5 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15065153196183917		[learning rate: 0.0042482]
	Learning Rate: 0.0042482
	LOSS [training: 0.15065153196183917 | validation: 0.31905661796670814]
	TIME [epoch: 32.6 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18194440086650598		[learning rate: 0.0042282]
	Learning Rate: 0.00422818
	LOSS [training: 0.18194440086650598 | validation: 0.33715743582240354]
	TIME [epoch: 32.6 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19186998496870353		[learning rate: 0.0042083]
	Learning Rate: 0.00420826
	LOSS [training: 0.19186998496870353 | validation: 0.3858104939386242]
	TIME [epoch: 32.5 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15335501177352595		[learning rate: 0.0041884]
	Learning Rate: 0.00418843
	LOSS [training: 0.15335501177352595 | validation: 0.4156601701559624]
	TIME [epoch: 32.5 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18736082542553067		[learning rate: 0.0041687]
	Learning Rate: 0.00416869
	LOSS [training: 0.18736082542553067 | validation: 0.4527629480964139]
	TIME [epoch: 32.5 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15731420082581649		[learning rate: 0.0041491]
	Learning Rate: 0.00414905
	LOSS [training: 0.15731420082581649 | validation: 0.3257971640998985]
	TIME [epoch: 32.5 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16749735766419516		[learning rate: 0.0041295]
	Learning Rate: 0.0041295
	LOSS [training: 0.16749735766419516 | validation: 0.33257329280746684]
	TIME [epoch: 32.6 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20850013246753318		[learning rate: 0.00411]
	Learning Rate: 0.00411004
	LOSS [training: 0.20850013246753318 | validation: 0.3233432893786832]
	TIME [epoch: 32.5 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15767171273420325		[learning rate: 0.0040907]
	Learning Rate: 0.00409067
	LOSS [training: 0.15767171273420325 | validation: 0.3671669031522313]
	TIME [epoch: 32.6 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20710244260621927		[learning rate: 0.0040714]
	Learning Rate: 0.0040714
	LOSS [training: 0.20710244260621927 | validation: 0.3496890333045208]
	TIME [epoch: 32.5 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17637176526880288		[learning rate: 0.0040522]
	Learning Rate: 0.00405221
	LOSS [training: 0.17637176526880288 | validation: 0.3097156031263154]
	TIME [epoch: 32.5 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17989670375494		[learning rate: 0.0040331]
	Learning Rate: 0.00403312
	LOSS [training: 0.17989670375494 | validation: 0.3195267384012975]
	TIME [epoch: 32.6 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16052043343338895		[learning rate: 0.0040141]
	Learning Rate: 0.00401411
	LOSS [training: 0.16052043343338895 | validation: 0.363507562588767]
	TIME [epoch: 32.5 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15144662908563852		[learning rate: 0.0039952]
	Learning Rate: 0.0039952
	LOSS [training: 0.15144662908563852 | validation: 0.2833373161047777]
	TIME [epoch: 32.5 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v15b_20240716_171520/states/model_facs_v3_dec2b_2dpca_v15b_232.pth
	Model improved!!!
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17061510788847092		[learning rate: 0.0039764]
	Learning Rate: 0.00397637
	LOSS [training: 0.17061510788847092 | validation: 0.3744419033117427]
	TIME [epoch: 32.6 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15881852473914476		[learning rate: 0.0039576]
	Learning Rate: 0.00395764
	LOSS [training: 0.15881852473914476 | validation: 0.3442865367810707]
	TIME [epoch: 32.6 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1572446286194428		[learning rate: 0.003939]
	Learning Rate: 0.00393899
	LOSS [training: 0.1572446286194428 | validation: 0.34749352619144125]
	TIME [epoch: 32.6 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16053658790324382		[learning rate: 0.0039204]
	Learning Rate: 0.00392043
	LOSS [training: 0.16053658790324382 | validation: 0.40246647630843474]
	TIME [epoch: 32.6 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22010950482700425		[learning rate: 0.003902]
	Learning Rate: 0.00390195
	LOSS [training: 0.22010950482700425 | validation: 0.32550169770449916]
	TIME [epoch: 32.6 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1418345866267328		[learning rate: 0.0038836]
	Learning Rate: 0.00388357
	LOSS [training: 0.1418345866267328 | validation: 0.34845214777178884]
	TIME [epoch: 32.5 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1708932686602357		[learning rate: 0.0038653]
	Learning Rate: 0.00386527
	LOSS [training: 0.1708932686602357 | validation: 0.3170408939194494]
	TIME [epoch: 32.6 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14816757184896742		[learning rate: 0.0038471]
	Learning Rate: 0.00384705
	LOSS [training: 0.14816757184896742 | validation: 0.31839140847637654]
	TIME [epoch: 32.6 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17365988904964574		[learning rate: 0.0038289]
	Learning Rate: 0.00382893
	LOSS [training: 0.17365988904964574 | validation: 0.28841707538971395]
	TIME [epoch: 32.6 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14570770142348102		[learning rate: 0.0038109]
	Learning Rate: 0.00381088
	LOSS [training: 0.14570770142348102 | validation: 0.347397451954858]
	TIME [epoch: 32.6 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16219979624924893		[learning rate: 0.0037929]
	Learning Rate: 0.00379293
	LOSS [training: 0.16219979624924893 | validation: 0.3459686328355107]
	TIME [epoch: 32.6 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17237402368201593		[learning rate: 0.0037751]
	Learning Rate: 0.00377505
	LOSS [training: 0.17237402368201593 | validation: 0.3369018951115215]
	TIME [epoch: 32.5 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15748125935622898		[learning rate: 0.0037573]
	Learning Rate: 0.00375726
	LOSS [training: 0.15748125935622898 | validation: 0.33794096060774065]
	TIME [epoch: 32.6 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16658236631048076		[learning rate: 0.0037396]
	Learning Rate: 0.00373956
	LOSS [training: 0.16658236631048076 | validation: 0.31415070020347946]
	TIME [epoch: 32.5 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16103465085906674		[learning rate: 0.0037219]
	Learning Rate: 0.00372194
	LOSS [training: 0.16103465085906674 | validation: 0.3539324386990661]
	TIME [epoch: 32.6 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19521133841501467		[learning rate: 0.0037044]
	Learning Rate: 0.0037044
	LOSS [training: 0.19521133841501467 | validation: 0.33704833757211633]
	TIME [epoch: 32.6 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17632051462657067		[learning rate: 0.0036869]
	Learning Rate: 0.00368695
	LOSS [training: 0.17632051462657067 | validation: 0.34478575446178406]
	TIME [epoch: 32.5 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1913934470504193		[learning rate: 0.0036696]
	Learning Rate: 0.00366957
	LOSS [training: 0.1913934470504193 | validation: 0.33824187346021756]
	TIME [epoch: 32.5 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1859760238295952		[learning rate: 0.0036523]
	Learning Rate: 0.00365228
	LOSS [training: 0.1859760238295952 | validation: 0.31377845192954934]
	TIME [epoch: 32.6 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17924538947117166		[learning rate: 0.0036351]
	Learning Rate: 0.00363507
	LOSS [training: 0.17924538947117166 | validation: 0.34145728327784713]
	TIME [epoch: 32.6 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.157401007281696		[learning rate: 0.0036179]
	Learning Rate: 0.00361794
	LOSS [training: 0.157401007281696 | validation: 0.31129501658654646]
	TIME [epoch: 32.6 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14385907601777703		[learning rate: 0.0036009]
	Learning Rate: 0.00360089
	LOSS [training: 0.14385907601777703 | validation: 0.34942457820271106]
	TIME [epoch: 32.6 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1594189534571221		[learning rate: 0.0035839]
	Learning Rate: 0.00358393
	LOSS [training: 0.1594189534571221 | validation: 0.27678264327892965]
	TIME [epoch: 32.6 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v15b_20240716_171520/states/model_facs_v3_dec2b_2dpca_v15b_255.pth
	Model improved!!!
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15682347500508195		[learning rate: 0.003567]
	Learning Rate: 0.00356704
	LOSS [training: 0.15682347500508195 | validation: 0.3369223341230932]
	TIME [epoch: 32.5 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15143838789524325		[learning rate: 0.0035502]
	Learning Rate: 0.00355023
	LOSS [training: 0.15143838789524325 | validation: 0.36774540080990437]
	TIME [epoch: 32.6 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16403990288217032		[learning rate: 0.0035335]
	Learning Rate: 0.0035335
	LOSS [training: 0.16403990288217032 | validation: 0.2996221229229274]
	TIME [epoch: 32.6 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16799200974344747		[learning rate: 0.0035168]
	Learning Rate: 0.00351685
	LOSS [training: 0.16799200974344747 | validation: 0.3556881719297838]
	TIME [epoch: 32.7 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1806839199897901		[learning rate: 0.0035003]
	Learning Rate: 0.00350028
	LOSS [training: 0.1806839199897901 | validation: 0.32867600770487526]
	TIME [epoch: 32.6 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15011445200925222		[learning rate: 0.0034838]
	Learning Rate: 0.00348378
	LOSS [training: 0.15011445200925222 | validation: 0.2926952806595149]
	TIME [epoch: 32.6 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14212446642595836		[learning rate: 0.0034674]
	Learning Rate: 0.00346737
	LOSS [training: 0.14212446642595836 | validation: 0.3254640361512466]
	TIME [epoch: 32.6 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17200333693451222		[learning rate: 0.003451]
	Learning Rate: 0.00345103
	LOSS [training: 0.17200333693451222 | validation: 0.33842727111237186]
	TIME [epoch: 32.7 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15965071161657746		[learning rate: 0.0034348]
	Learning Rate: 0.00343477
	LOSS [training: 0.15965071161657746 | validation: 0.3044794557041398]
	TIME [epoch: 32.6 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17917273012294482		[learning rate: 0.0034186]
	Learning Rate: 0.00341858
	LOSS [training: 0.17917273012294482 | validation: 0.38974058245913695]
	TIME [epoch: 32.7 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16661783393161145		[learning rate: 0.0034025]
	Learning Rate: 0.00340247
	LOSS [training: 0.16661783393161145 | validation: 0.3342039289782508]
	TIME [epoch: 32.7 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14870234520729433		[learning rate: 0.0033864]
	Learning Rate: 0.00338644
	LOSS [training: 0.14870234520729433 | validation: 0.2797149033932645]
	TIME [epoch: 32.7 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1744802372411733		[learning rate: 0.0033705]
	Learning Rate: 0.00337048
	LOSS [training: 0.1744802372411733 | validation: 0.33133393265141164]
	TIME [epoch: 32.5 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1534755658272168		[learning rate: 0.0033546]
	Learning Rate: 0.0033546
	LOSS [training: 0.1534755658272168 | validation: 0.3069598063822488]
	TIME [epoch: 32.5 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1481912760910457		[learning rate: 0.0033388]
	Learning Rate: 0.00333879
	LOSS [training: 0.1481912760910457 | validation: 0.33467386372490227]
	TIME [epoch: 32.6 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1286348356769803		[learning rate: 0.0033231]
	Learning Rate: 0.00332306
	LOSS [training: 0.1286348356769803 | validation: 0.4422629912491522]
	TIME [epoch: 32.6 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18080140639322068		[learning rate: 0.0033074]
	Learning Rate: 0.0033074
	LOSS [training: 0.18080140639322068 | validation: 0.30130289068733945]
	TIME [epoch: 32.5 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13919519286548637		[learning rate: 0.0032918]
	Learning Rate: 0.00329182
	LOSS [training: 0.13919519286548637 | validation: 0.32705268635324314]
	TIME [epoch: 32.5 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17353517938141602		[learning rate: 0.0032763]
	Learning Rate: 0.00327631
	LOSS [training: 0.17353517938141602 | validation: 0.3680997554263541]
	TIME [epoch: 32.6 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1603077589719028		[learning rate: 0.0032609]
	Learning Rate: 0.00326087
	LOSS [training: 0.1603077589719028 | validation: 0.30183270362171527]
	TIME [epoch: 32.6 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16387504353706261		[learning rate: 0.0032455]
	Learning Rate: 0.0032455
	LOSS [training: 0.16387504353706261 | validation: 0.35018311611600383]
	TIME [epoch: 32.6 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16813156247970393		[learning rate: 0.0032302]
	Learning Rate: 0.00323021
	LOSS [training: 0.16813156247970393 | validation: 0.33086764102549504]
	TIME [epoch: 32.7 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14932815652221523		[learning rate: 0.003215]
	Learning Rate: 0.00321499
	LOSS [training: 0.14932815652221523 | validation: 0.3314522480969286]
	TIME [epoch: 32.7 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14225631736003383		[learning rate: 0.0031998]
	Learning Rate: 0.00319984
	LOSS [training: 0.14225631736003383 | validation: 0.31613937417578286]
	TIME [epoch: 32.6 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14586382220662547		[learning rate: 0.0031848]
	Learning Rate: 0.00318476
	LOSS [training: 0.14586382220662547 | validation: 0.32455032476713563]
	TIME [epoch: 32.7 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1543930647962607		[learning rate: 0.0031698]
	Learning Rate: 0.00316975
	LOSS [training: 0.1543930647962607 | validation: 0.29846065417312484]
	TIME [epoch: 32.6 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1427003857547537		[learning rate: 0.0031548]
	Learning Rate: 0.00315482
	LOSS [training: 0.1427003857547537 | validation: 0.3745719391462471]
	TIME [epoch: 32.7 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1647697750900257		[learning rate: 0.00314]
	Learning Rate: 0.00313995
	LOSS [training: 0.1647697750900257 | validation: 0.3295521451084132]
	TIME [epoch: 32.7 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1841790432505555		[learning rate: 0.0031252]
	Learning Rate: 0.00312516
	LOSS [training: 0.1841790432505555 | validation: 0.3044464634209136]
	TIME [epoch: 32.6 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14147445543779513		[learning rate: 0.0031104]
	Learning Rate: 0.00311043
	LOSS [training: 0.14147445543779513 | validation: 0.3070927221449347]
	TIME [epoch: 32.6 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17112293153676242		[learning rate: 0.0030958]
	Learning Rate: 0.00309577
	LOSS [training: 0.17112293153676242 | validation: 0.31062177444191763]
	TIME [epoch: 32.6 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15037247366073794		[learning rate: 0.0030812]
	Learning Rate: 0.00308119
	LOSS [training: 0.15037247366073794 | validation: 0.34260871522899444]
	TIME [epoch: 32.6 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1549430251959214		[learning rate: 0.0030667]
	Learning Rate: 0.00306667
	LOSS [training: 0.1549430251959214 | validation: 0.3021409877811639]
	TIME [epoch: 32.5 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16089612386485827		[learning rate: 0.0030522]
	Learning Rate: 0.00305222
	LOSS [training: 0.16089612386485827 | validation: 0.34219832977798753]
	TIME [epoch: 32.5 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15298961191730728		[learning rate: 0.0030378]
	Learning Rate: 0.00303783
	LOSS [training: 0.15298961191730728 | validation: 0.3226646887025331]
	TIME [epoch: 32.5 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19519012423947216		[learning rate: 0.0030235]
	Learning Rate: 0.00302352
	LOSS [training: 0.19519012423947216 | validation: 0.31380521332848754]
	TIME [epoch: 32.6 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14351335200213625		[learning rate: 0.0030093]
	Learning Rate: 0.00300927
	LOSS [training: 0.14351335200213625 | validation: 0.3051387705285184]
	TIME [epoch: 32.5 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14320207761444087		[learning rate: 0.0029951]
	Learning Rate: 0.00299509
	LOSS [training: 0.14320207761444087 | validation: 0.3356829221877271]
	TIME [epoch: 32.6 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1609889982970748		[learning rate: 0.002981]
	Learning Rate: 0.00298098
	LOSS [training: 0.1609889982970748 | validation: 0.317021897429239]
	TIME [epoch: 32.5 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16543540508840196		[learning rate: 0.0029669]
	Learning Rate: 0.00296693
	LOSS [training: 0.16543540508840196 | validation: 0.3126928265776016]
	TIME [epoch: 32.5 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14256700467300135		[learning rate: 0.002953]
	Learning Rate: 0.00295295
	LOSS [training: 0.14256700467300135 | validation: 0.2841021746980888]
	TIME [epoch: 32.5 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18572019692859845		[learning rate: 0.002939]
	Learning Rate: 0.00293904
	LOSS [training: 0.18572019692859845 | validation: 0.3441406871683158]
	TIME [epoch: 32.5 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15081416817426688		[learning rate: 0.0029252]
	Learning Rate: 0.00292519
	LOSS [training: 0.15081416817426688 | validation: 0.29414485007666036]
	TIME [epoch: 32.6 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1709153802103799		[learning rate: 0.0029114]
	Learning Rate: 0.0029114
	LOSS [training: 0.1709153802103799 | validation: 0.29745051879854023]
	TIME [epoch: 32.5 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17061993257766178		[learning rate: 0.0028977]
	Learning Rate: 0.00289769
	LOSS [training: 0.17061993257766178 | validation: 0.3421668427063907]
	TIME [epoch: 32.6 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15686070239748393		[learning rate: 0.002884]
	Learning Rate: 0.00288403
	LOSS [training: 0.15686070239748393 | validation: 0.294705061079546]
	TIME [epoch: 90.8 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14595590727057592		[learning rate: 0.0028704]
	Learning Rate: 0.00287044
	LOSS [training: 0.14595590727057592 | validation: 0.32475874732315413]
	TIME [epoch: 67.4 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17671971634918315		[learning rate: 0.0028569]
	Learning Rate: 0.00285692
	LOSS [training: 0.17671971634918315 | validation: 0.3026913033763829]
	TIME [epoch: 67.3 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14450883492885536		[learning rate: 0.0028435]
	Learning Rate: 0.00284345
	LOSS [training: 0.14450883492885536 | validation: 0.3203738216419452]
	TIME [epoch: 67.3 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18735679638129282		[learning rate: 0.0028301]
	Learning Rate: 0.00283005
	LOSS [training: 0.18735679638129282 | validation: 0.3292054586510138]
	TIME [epoch: 67.4 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1491110996208547		[learning rate: 0.0028167]
	Learning Rate: 0.00281672
	LOSS [training: 0.1491110996208547 | validation: 0.3425476658593824]
	TIME [epoch: 67.4 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1782080664594844		[learning rate: 0.0028034]
	Learning Rate: 0.00280345
	LOSS [training: 0.1782080664594844 | validation: 0.3216869308438642]
	TIME [epoch: 67.4 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14969841116874869		[learning rate: 0.0027902]
	Learning Rate: 0.00279024
	LOSS [training: 0.14969841116874869 | validation: 0.3341672923659015]
	TIME [epoch: 67.3 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16110831019207156		[learning rate: 0.0027771]
	Learning Rate: 0.00277709
	LOSS [training: 0.16110831019207156 | validation: 0.2856064610814037]
	TIME [epoch: 67.3 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15877429997590103		[learning rate: 0.002764]
	Learning Rate: 0.002764
	LOSS [training: 0.15877429997590103 | validation: 0.32995516420311743]
	TIME [epoch: 67.3 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15482671405161466		[learning rate: 0.002751]
	Learning Rate: 0.00275098
	LOSS [training: 0.15482671405161466 | validation: 0.32876476145413486]
	TIME [epoch: 67.3 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15535274431556817		[learning rate: 0.002738]
	Learning Rate: 0.00273802
	LOSS [training: 0.15535274431556817 | validation: 0.29118698508980145]
	TIME [epoch: 67.4 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1478862151455044		[learning rate: 0.0027251]
	Learning Rate: 0.00272511
	LOSS [training: 0.1478862151455044 | validation: 0.29063784694140554]
	TIME [epoch: 67.3 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16852732412335542		[learning rate: 0.0027123]
	Learning Rate: 0.00271227
	LOSS [training: 0.16852732412335542 | validation: 0.2944188362541542]
	TIME [epoch: 67.3 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15464999623404496		[learning rate: 0.0026995]
	Learning Rate: 0.00269949
	LOSS [training: 0.15464999623404496 | validation: 0.3008783359220845]
	TIME [epoch: 67.4 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14160103246272768		[learning rate: 0.0026868]
	Learning Rate: 0.00268677
	LOSS [training: 0.14160103246272768 | validation: 0.32448603565729406]
	TIME [epoch: 67.4 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16763118057965914		[learning rate: 0.0026741]
	Learning Rate: 0.00267411
	LOSS [training: 0.16763118057965914 | validation: 0.3153325235018053]
	TIME [epoch: 67.3 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13638804249315778		[learning rate: 0.0026615]
	Learning Rate: 0.00266151
	LOSS [training: 0.13638804249315778 | validation: 0.3329986819027453]
	TIME [epoch: 67.3 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1384210494823675		[learning rate: 0.002649]
	Learning Rate: 0.00264897
	LOSS [training: 0.1384210494823675 | validation: 0.2703014746738768]
	TIME [epoch: 67.4 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v15b_20240716_171520/states/model_facs_v3_dec2b_2dpca_v15b_319.pth
	Model improved!!!
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16578651702636477		[learning rate: 0.0026365]
	Learning Rate: 0.00263649
	LOSS [training: 0.16578651702636477 | validation: 0.34430056571074924]
	TIME [epoch: 67.5 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15720002515016163		[learning rate: 0.0026241]
	Learning Rate: 0.00262406
	LOSS [training: 0.15720002515016163 | validation: 0.29368351621057753]
	TIME [epoch: 67.5 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14765344345478068		[learning rate: 0.0026117]
	Learning Rate: 0.0026117
	LOSS [training: 0.14765344345478068 | validation: 0.30413626099764574]
	TIME [epoch: 67.5 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14918015929172188		[learning rate: 0.0025994]
	Learning Rate: 0.00259939
	LOSS [training: 0.14918015929172188 | validation: 0.2951828926269278]
	TIME [epoch: 67.3 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15873719178985474		[learning rate: 0.0025871]
	Learning Rate: 0.00258714
	LOSS [training: 0.15873719178985474 | validation: 0.3456806993879131]
	TIME [epoch: 67.2 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15885675779347413		[learning rate: 0.002575]
	Learning Rate: 0.00257495
	LOSS [training: 0.15885675779347413 | validation: 0.3152011017137925]
	TIME [epoch: 67.2 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14916413021423341		[learning rate: 0.0025628]
	Learning Rate: 0.00256282
	LOSS [training: 0.14916413021423341 | validation: 0.2874688492852257]
	TIME [epoch: 67.2 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13242185638352988		[learning rate: 0.0025507]
	Learning Rate: 0.00255074
	LOSS [training: 0.13242185638352988 | validation: 0.3094735590102904]
	TIME [epoch: 67.3 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14615368581882177		[learning rate: 0.0025387]
	Learning Rate: 0.00253872
	LOSS [training: 0.14615368581882177 | validation: 0.3100802311316123]
	TIME [epoch: 67.2 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15042900739278603		[learning rate: 0.0025268]
	Learning Rate: 0.00252676
	LOSS [training: 0.15042900739278603 | validation: 0.2985033008065929]
	TIME [epoch: 67.2 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14558986724632378		[learning rate: 0.0025149]
	Learning Rate: 0.00251485
	LOSS [training: 0.14558986724632378 | validation: 0.32607858280432367]
	TIME [epoch: 67.2 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16036638046463		[learning rate: 0.002503]
	Learning Rate: 0.002503
	LOSS [training: 0.16036638046463 | validation: 0.2952235468432011]
	TIME [epoch: 67.2 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1602556649727863		[learning rate: 0.0024912]
	Learning Rate: 0.00249121
	LOSS [training: 0.1602556649727863 | validation: 0.29991833921628613]
	TIME [epoch: 67.3 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1880482874781384		[learning rate: 0.0024795]
	Learning Rate: 0.00247947
	LOSS [training: 0.1880482874781384 | validation: 0.35511553876516533]
	TIME [epoch: 67.3 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15265993082461682		[learning rate: 0.0024678]
	Learning Rate: 0.00246779
	LOSS [training: 0.15265993082461682 | validation: 0.3472634572139024]
	TIME [epoch: 67.3 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1601437089075562		[learning rate: 0.0024562]
	Learning Rate: 0.00245616
	LOSS [training: 0.1601437089075562 | validation: 0.2927398867405781]
	TIME [epoch: 67.3 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14682710458299672		[learning rate: 0.0024446]
	Learning Rate: 0.00244458
	LOSS [training: 0.14682710458299672 | validation: 0.31743880935680646]
	TIME [epoch: 67.2 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16211683097155896		[learning rate: 0.0024331]
	Learning Rate: 0.00243307
	LOSS [training: 0.16211683097155896 | validation: 0.32100433206881424]
	TIME [epoch: 67.3 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1424010685594547		[learning rate: 0.0024216]
	Learning Rate: 0.0024216
	LOSS [training: 0.1424010685594547 | validation: 0.303561700308799]
	TIME [epoch: 67.2 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1402302077643291		[learning rate: 0.0024102]
	Learning Rate: 0.00241019
	LOSS [training: 0.1402302077643291 | validation: 0.28904422273523994]
	TIME [epoch: 67.3 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15437468553625305		[learning rate: 0.0023988]
	Learning Rate: 0.00239883
	LOSS [training: 0.15437468553625305 | validation: 0.3217689749976362]
	TIME [epoch: 67.2 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12474233964751122		[learning rate: 0.0023875]
	Learning Rate: 0.00238753
	LOSS [training: 0.12474233964751122 | validation: 0.31459404650829065]
	TIME [epoch: 67.4 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15174032513229677		[learning rate: 0.0023763]
	Learning Rate: 0.00237628
	LOSS [training: 0.15174032513229677 | validation: 0.2978524593699868]
	TIME [epoch: 67.3 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14109981474536765		[learning rate: 0.0023651]
	Learning Rate: 0.00236508
	LOSS [training: 0.14109981474536765 | validation: 0.2991876710092111]
	TIME [epoch: 67.3 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16766651845062192		[learning rate: 0.0023539]
	Learning Rate: 0.00235394
	LOSS [training: 0.16766651845062192 | validation: 0.3073420763493138]
	TIME [epoch: 67.3 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1756516675472788		[learning rate: 0.0023428]
	Learning Rate: 0.00234285
	LOSS [training: 0.1756516675472788 | validation: 0.3245807081431652]
	TIME [epoch: 67.3 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14740496027717132		[learning rate: 0.0023318]
	Learning Rate: 0.00233181
	LOSS [training: 0.14740496027717132 | validation: 0.31528585444884777]
	TIME [epoch: 67.3 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13567031416834135		[learning rate: 0.0023208]
	Learning Rate: 0.00232082
	LOSS [training: 0.13567031416834135 | validation: 0.2885363879349643]
	TIME [epoch: 67.3 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13568813034864227		[learning rate: 0.0023099]
	Learning Rate: 0.00230988
	LOSS [training: 0.13568813034864227 | validation: 0.29191918530954086]
	TIME [epoch: 67.3 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1651873742379541		[learning rate: 0.002299]
	Learning Rate: 0.002299
	LOSS [training: 0.1651873742379541 | validation: 0.31764468542563057]
	TIME [epoch: 67.2 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13704639336252628		[learning rate: 0.0022882]
	Learning Rate: 0.00228816
	LOSS [training: 0.13704639336252628 | validation: 0.3173746911965587]
	TIME [epoch: 67.3 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15395364932875005		[learning rate: 0.0022774]
	Learning Rate: 0.00227738
	LOSS [training: 0.15395364932875005 | validation: 0.30825623088693]
	TIME [epoch: 67.3 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16002337408381767		[learning rate: 0.0022667]
	Learning Rate: 0.00226665
	LOSS [training: 0.16002337408381767 | validation: 0.327786933318144]
	TIME [epoch: 67.2 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15760326230283478		[learning rate: 0.002256]
	Learning Rate: 0.00225597
	LOSS [training: 0.15760326230283478 | validation: 0.3045928519344]
	TIME [epoch: 67.3 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1283378339137388		[learning rate: 0.0022453]
	Learning Rate: 0.00224534
	LOSS [training: 0.1283378339137388 | validation: 0.31868626330434124]
	TIME [epoch: 67.2 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15570473793078515		[learning rate: 0.0022348]
	Learning Rate: 0.00223476
	LOSS [training: 0.15570473793078515 | validation: 0.2934813571991148]
	TIME [epoch: 67.3 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1386942696950383		[learning rate: 0.0022242]
	Learning Rate: 0.00222423
	LOSS [training: 0.1386942696950383 | validation: 0.30747140149472796]
	TIME [epoch: 67.3 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1521663171346771		[learning rate: 0.0022137]
	Learning Rate: 0.00221375
	LOSS [training: 0.1521663171346771 | validation: 0.29570570990707856]
	TIME [epoch: 67.3 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13428238251408797		[learning rate: 0.0022033]
	Learning Rate: 0.00220332
	LOSS [training: 0.13428238251408797 | validation: 0.3036180016386058]
	TIME [epoch: 67.2 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1325693210434166		[learning rate: 0.0021929]
	Learning Rate: 0.00219293
	LOSS [training: 0.1325693210434166 | validation: 0.28636393560303597]
	TIME [epoch: 67.3 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1418043115128918		[learning rate: 0.0021826]
	Learning Rate: 0.0021826
	LOSS [training: 0.1418043115128918 | validation: 0.3546084478173158]
	TIME [epoch: 67.3 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17104900438452564		[learning rate: 0.0021723]
	Learning Rate: 0.00217232
	LOSS [training: 0.17104900438452564 | validation: 0.3016808939806545]
	TIME [epoch: 67.3 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15791249613408948		[learning rate: 0.0021621]
	Learning Rate: 0.00216208
	LOSS [training: 0.15791249613408948 | validation: 0.31491944559704443]
	TIME [epoch: 67.3 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14074520615246625		[learning rate: 0.0021519]
	Learning Rate: 0.00215189
	LOSS [training: 0.14074520615246625 | validation: 0.32388855965291663]
	TIME [epoch: 67.3 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14414671479998822		[learning rate: 0.0021418]
	Learning Rate: 0.00214175
	LOSS [training: 0.14414671479998822 | validation: 0.29609890486444684]
	TIME [epoch: 67.2 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15403018207796423		[learning rate: 0.0021317]
	Learning Rate: 0.00213166
	LOSS [training: 0.15403018207796423 | validation: 0.3091479970514286]
	TIME [epoch: 67.3 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14581535778516191		[learning rate: 0.0021216]
	Learning Rate: 0.00212162
	LOSS [training: 0.14581535778516191 | validation: 0.2933573721978964]
	TIME [epoch: 67.3 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14367086404205776		[learning rate: 0.0021116]
	Learning Rate: 0.00211162
	LOSS [training: 0.14367086404205776 | validation: 0.3118750141443879]
	TIME [epoch: 67.2 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13309128489382616		[learning rate: 0.0021017]
	Learning Rate: 0.00210167
	LOSS [training: 0.13309128489382616 | validation: 0.3371323565038875]
	TIME [epoch: 67.2 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14979261630488558		[learning rate: 0.0020918]
	Learning Rate: 0.00209176
	LOSS [training: 0.14979261630488558 | validation: 0.32052148370644346]
	TIME [epoch: 67.2 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14647816375971975		[learning rate: 0.0020819]
	Learning Rate: 0.00208191
	LOSS [training: 0.14647816375971975 | validation: 0.3114455534606847]
	TIME [epoch: 67.2 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.151657881843834		[learning rate: 0.0020721]
	Learning Rate: 0.0020721
	LOSS [training: 0.151657881843834 | validation: 0.3751357507281151]
	TIME [epoch: 67.2 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15109684555071734		[learning rate: 0.0020623]
	Learning Rate: 0.00206233
	LOSS [training: 0.15109684555071734 | validation: 0.3159797298099893]
	TIME [epoch: 67.3 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17365537225712335		[learning rate: 0.0020526]
	Learning Rate: 0.00205262
	LOSS [training: 0.17365537225712335 | validation: 0.32167226760473644]
	TIME [epoch: 67.2 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16076137570000862		[learning rate: 0.0020429]
	Learning Rate: 0.00204294
	LOSS [training: 0.16076137570000862 | validation: 0.33347331786202256]
	TIME [epoch: 67.3 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13211090767879102		[learning rate: 0.0020333]
	Learning Rate: 0.00203332
	LOSS [training: 0.13211090767879102 | validation: 0.31386775662484356]
	TIME [epoch: 67.3 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14143993534475188		[learning rate: 0.0020237]
	Learning Rate: 0.00202374
	LOSS [training: 0.14143993534475188 | validation: 0.33109827409983644]
	TIME [epoch: 67.3 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1346824663871051		[learning rate: 0.0020142]
	Learning Rate: 0.0020142
	LOSS [training: 0.1346824663871051 | validation: 0.3157026794633454]
	TIME [epoch: 67.3 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15231969716602034		[learning rate: 0.0020047]
	Learning Rate: 0.00200471
	LOSS [training: 0.15231969716602034 | validation: 0.30121095876617987]
	TIME [epoch: 67.3 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14782703107444337		[learning rate: 0.0019953]
	Learning Rate: 0.00199526
	LOSS [training: 0.14782703107444337 | validation: 0.3044040280894739]
	TIME [epoch: 67.2 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1648483808489108		[learning rate: 0.0019859]
	Learning Rate: 0.00198586
	LOSS [training: 0.1648483808489108 | validation: 0.30166859362376697]
	TIME [epoch: 67.3 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17430345267011693		[learning rate: 0.0019765]
	Learning Rate: 0.0019765
	LOSS [training: 0.17430345267011693 | validation: 0.31355464465073746]
	TIME [epoch: 67.2 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15338655585699176		[learning rate: 0.0019672]
	Learning Rate: 0.00196719
	LOSS [training: 0.15338655585699176 | validation: 0.31450885915674115]
	TIME [epoch: 67.3 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.143325963876062		[learning rate: 0.0019579]
	Learning Rate: 0.00195792
	LOSS [training: 0.143325963876062 | validation: 0.33819706253688747]
	TIME [epoch: 67.3 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13644443178884666		[learning rate: 0.0019487]
	Learning Rate: 0.00194869
	LOSS [training: 0.13644443178884666 | validation: 0.29970589280349774]
	TIME [epoch: 67.3 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1372626557941021		[learning rate: 0.0019395]
	Learning Rate: 0.00193951
	LOSS [training: 0.1372626557941021 | validation: 0.29622360171807427]
	TIME [epoch: 67.2 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13134592318930932		[learning rate: 0.0019304]
	Learning Rate: 0.00193037
	LOSS [training: 0.13134592318930932 | validation: 0.28905087221740305]
	TIME [epoch: 67.2 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14186322068568724		[learning rate: 0.0019213]
	Learning Rate: 0.00192128
	LOSS [training: 0.14186322068568724 | validation: 0.3294425548601234]
	TIME [epoch: 67.3 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16135843253798415		[learning rate: 0.0019122]
	Learning Rate: 0.00191222
	LOSS [training: 0.16135843253798415 | validation: 0.3007542241244812]
	TIME [epoch: 67.3 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1400529174503046		[learning rate: 0.0019032]
	Learning Rate: 0.00190321
	LOSS [training: 0.1400529174503046 | validation: 0.3200721702454778]
	TIME [epoch: 67.3 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13140505670831387		[learning rate: 0.0018942]
	Learning Rate: 0.00189424
	LOSS [training: 0.13140505670831387 | validation: 0.3579803353752981]
	TIME [epoch: 67.2 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17866517220216205		[learning rate: 0.0018853]
	Learning Rate: 0.00188532
	LOSS [training: 0.17866517220216205 | validation: 0.30350379662214]
	TIME [epoch: 67.2 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12672939534068942		[learning rate: 0.0018764]
	Learning Rate: 0.00187643
	LOSS [training: 0.12672939534068942 | validation: 0.30107406619315014]
	TIME [epoch: 67.2 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13286745745968997		[learning rate: 0.0018676]
	Learning Rate: 0.00186759
	LOSS [training: 0.13286745745968997 | validation: 0.30733066396451036]
	TIME [epoch: 67.3 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16364249614843768		[learning rate: 0.0018588]
	Learning Rate: 0.00185879
	LOSS [training: 0.16364249614843768 | validation: 0.30229883932062374]
	TIME [epoch: 67.2 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16597540929873192		[learning rate: 0.00185]
	Learning Rate: 0.00185003
	LOSS [training: 0.16597540929873192 | validation: 0.3266054997913142]
	TIME [epoch: 67.3 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14539725168898962		[learning rate: 0.0018413]
	Learning Rate: 0.00184132
	LOSS [training: 0.14539725168898962 | validation: 0.2838470893032525]
	TIME [epoch: 67.3 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14517596260068946		[learning rate: 0.0018326]
	Learning Rate: 0.00183264
	LOSS [training: 0.14517596260068946 | validation: 0.30497322650116004]
	TIME [epoch: 67.2 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14411843873437036		[learning rate: 0.001824]
	Learning Rate: 0.001824
	LOSS [training: 0.14411843873437036 | validation: 0.31840106056244577]
	TIME [epoch: 67.5 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1524896829461268		[learning rate: 0.0018154]
	Learning Rate: 0.00181541
	LOSS [training: 0.1524896829461268 | validation: 0.3085028066958534]
	TIME [epoch: 67.5 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13707301966277424		[learning rate: 0.0018069]
	Learning Rate: 0.00180685
	LOSS [training: 0.13707301966277424 | validation: 0.3140723614851687]
	TIME [epoch: 67.5 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14128776671451604		[learning rate: 0.0017983]
	Learning Rate: 0.00179834
	LOSS [training: 0.14128776671451604 | validation: 0.2903664309049775]
	TIME [epoch: 67.4 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1455226259375584		[learning rate: 0.0017899]
	Learning Rate: 0.00178987
	LOSS [training: 0.1455226259375584 | validation: 0.3012222533598585]
	TIME [epoch: 67.4 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14974801644058539		[learning rate: 0.0017814]
	Learning Rate: 0.00178143
	LOSS [training: 0.14974801644058539 | validation: 0.32280892045549525]
	TIME [epoch: 67.6 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1396313576160042		[learning rate: 0.001773]
	Learning Rate: 0.00177304
	LOSS [training: 0.1396313576160042 | validation: 0.3043787290822233]
	TIME [epoch: 67.4 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16626082161634845		[learning rate: 0.0017647]
	Learning Rate: 0.00176468
	LOSS [training: 0.16626082161634845 | validation: 0.30854725305532155]
	TIME [epoch: 67.2 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.181217097813266		[learning rate: 0.0017564]
	Learning Rate: 0.00175637
	LOSS [training: 0.181217097813266 | validation: 0.3432809804167993]
	TIME [epoch: 67.4 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1605569777124767		[learning rate: 0.0017481]
	Learning Rate: 0.00174809
	LOSS [training: 0.1605569777124767 | validation: 0.2930159250323733]
	TIME [epoch: 67.1 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14890864472810372		[learning rate: 0.0017399]
	Learning Rate: 0.00173985
	LOSS [training: 0.14890864472810372 | validation: 0.29054281265511694]
	TIME [epoch: 67.3 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1474108990034615		[learning rate: 0.0017317]
	Learning Rate: 0.00173166
	LOSS [training: 0.1474108990034615 | validation: 0.29619235768250024]
	TIME [epoch: 67.3 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1539174992838776		[learning rate: 0.0017235]
	Learning Rate: 0.0017235
	LOSS [training: 0.1539174992838776 | validation: 0.31355467963368133]
	TIME [epoch: 67.5 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14504574007407317		[learning rate: 0.0017154]
	Learning Rate: 0.00171537
	LOSS [training: 0.14504574007407317 | validation: 0.29611046715258627]
	TIME [epoch: 67.4 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1416457550872245		[learning rate: 0.0017073]
	Learning Rate: 0.00170729
	LOSS [training: 0.1416457550872245 | validation: 0.271888552906612]
	TIME [epoch: 67.4 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1370647662397659		[learning rate: 0.0016992]
	Learning Rate: 0.00169925
	LOSS [training: 0.1370647662397659 | validation: 0.3127728622671368]
	TIME [epoch: 67.4 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.155324939580883		[learning rate: 0.0016912]
	Learning Rate: 0.00169124
	LOSS [training: 0.155324939580883 | validation: 0.3202115525434232]
	TIME [epoch: 67.3 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12348143074785993		[learning rate: 0.0016833]
	Learning Rate: 0.00168327
	LOSS [training: 0.12348143074785993 | validation: 0.3057587326130032]
	TIME [epoch: 67.3 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13753936568703792		[learning rate: 0.0016753]
	Learning Rate: 0.00167534
	LOSS [training: 0.13753936568703792 | validation: 0.3063529563438957]
	TIME [epoch: 67.3 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15123061133932042		[learning rate: 0.0016674]
	Learning Rate: 0.00166744
	LOSS [training: 0.15123061133932042 | validation: 0.3132853985854766]
	TIME [epoch: 67.4 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14959698580032074		[learning rate: 0.0016596]
	Learning Rate: 0.00165959
	LOSS [training: 0.14959698580032074 | validation: 0.2945386004841962]
	TIME [epoch: 67.3 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1551651122122932		[learning rate: 0.0016518]
	Learning Rate: 0.00165177
	LOSS [training: 0.1551651122122932 | validation: 0.303114289968755]
	TIME [epoch: 67.3 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12331957357520848		[learning rate: 0.001644]
	Learning Rate: 0.00164398
	LOSS [training: 0.12331957357520848 | validation: 0.3033055418804206]
	TIME [epoch: 67.3 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12856128040327036		[learning rate: 0.0016362]
	Learning Rate: 0.00163624
	LOSS [training: 0.12856128040327036 | validation: 0.313973417793869]
	TIME [epoch: 67.4 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1418908488226037		[learning rate: 0.0016285]
	Learning Rate: 0.00162853
	LOSS [training: 0.1418908488226037 | validation: 0.285573473784015]
	TIME [epoch: 67.4 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1322553889252103		[learning rate: 0.0016209]
	Learning Rate: 0.00162085
	LOSS [training: 0.1322553889252103 | validation: 0.3181675383437117]
	TIME [epoch: 67.3 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15400105973070383		[learning rate: 0.0016132]
	Learning Rate: 0.00161322
	LOSS [training: 0.15400105973070383 | validation: 0.28292432279337937]
	TIME [epoch: 67.4 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14711461700240436		[learning rate: 0.0016056]
	Learning Rate: 0.00160561
	LOSS [training: 0.14711461700240436 | validation: 0.2928120580735247]
	TIME [epoch: 67.4 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13314285878500853		[learning rate: 0.001598]
	Learning Rate: 0.00159805
	LOSS [training: 0.13314285878500853 | validation: 0.3326630350076009]
	TIME [epoch: 67.3 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17325763959286095		[learning rate: 0.0015905]
	Learning Rate: 0.00159052
	LOSS [training: 0.17325763959286095 | validation: 0.31662280238494633]
	TIME [epoch: 67.3 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13126470490250333		[learning rate: 0.001583]
	Learning Rate: 0.00158302
	LOSS [training: 0.13126470490250333 | validation: 0.299158539187497]
	TIME [epoch: 67.4 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14000844483335564		[learning rate: 0.0015756]
	Learning Rate: 0.00157556
	LOSS [training: 0.14000844483335564 | validation: 0.28129901257430734]
	TIME [epoch: 67.4 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17102865836870318		[learning rate: 0.0015681]
	Learning Rate: 0.00156814
	LOSS [training: 0.17102865836870318 | validation: 0.3231602938571503]
	TIME [epoch: 67.4 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15654941716755438		[learning rate: 0.0015607]
	Learning Rate: 0.00156075
	LOSS [training: 0.15654941716755438 | validation: 0.32291478635977444]
	TIME [epoch: 67.3 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11924425597155838		[learning rate: 0.0015534]
	Learning Rate: 0.0015534
	LOSS [training: 0.11924425597155838 | validation: 0.2951901787573528]
	TIME [epoch: 67.4 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15967804422717746		[learning rate: 0.0015461]
	Learning Rate: 0.00154608
	LOSS [training: 0.15967804422717746 | validation: 0.300576290558234]
	TIME [epoch: 67.4 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13868316401830927		[learning rate: 0.0015388]
	Learning Rate: 0.00153879
	LOSS [training: 0.13868316401830927 | validation: 0.3047322649079257]
	TIME [epoch: 67.4 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1430706489031669		[learning rate: 0.0015315]
	Learning Rate: 0.00153154
	LOSS [training: 0.1430706489031669 | validation: 0.307173638545237]
	TIME [epoch: 67.3 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14200799365835476		[learning rate: 0.0015243]
	Learning Rate: 0.00152432
	LOSS [training: 0.14200799365835476 | validation: 0.28623269645637983]
	TIME [epoch: 67.4 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1409672053168508		[learning rate: 0.0015171]
	Learning Rate: 0.00151714
	LOSS [training: 0.1409672053168508 | validation: 0.31306871036527206]
	TIME [epoch: 67.3 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15341895123451368		[learning rate: 0.00151]
	Learning Rate: 0.00150999
	LOSS [training: 0.15341895123451368 | validation: 0.27711498184257644]
	TIME [epoch: 67.3 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13591871430591568		[learning rate: 0.0015029]
	Learning Rate: 0.00150288
	LOSS [training: 0.13591871430591568 | validation: 0.31815209159961566]
	TIME [epoch: 67.3 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14145407701158105		[learning rate: 0.0014958]
	Learning Rate: 0.00149579
	LOSS [training: 0.14145407701158105 | validation: 0.3211717990964185]
	TIME [epoch: 67.3 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1353802477596497		[learning rate: 0.0014887]
	Learning Rate: 0.00148875
	LOSS [training: 0.1353802477596497 | validation: 0.3003575447560163]
	TIME [epoch: 67.3 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12987628316793673		[learning rate: 0.0014817]
	Learning Rate: 0.00148173
	LOSS [training: 0.12987628316793673 | validation: 0.3355766639201807]
	TIME [epoch: 67.3 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12432292341213225		[learning rate: 0.0014747]
	Learning Rate: 0.00147475
	LOSS [training: 0.12432292341213225 | validation: 0.32183102436356636]
	TIME [epoch: 67.4 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1418105919002358		[learning rate: 0.0014678]
	Learning Rate: 0.0014678
	LOSS [training: 0.1418105919002358 | validation: 0.30626740461188606]
	TIME [epoch: 67.3 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12942085607635687		[learning rate: 0.0014609]
	Learning Rate: 0.00146088
	LOSS [training: 0.12942085607635687 | validation: 0.3046905250144143]
	TIME [epoch: 67.4 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1425993175680616		[learning rate: 0.001454]
	Learning Rate: 0.001454
	LOSS [training: 0.1425993175680616 | validation: 0.30584178788201194]
	TIME [epoch: 67.4 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15424313093945505		[learning rate: 0.0014471]
	Learning Rate: 0.00144715
	LOSS [training: 0.15424313093945505 | validation: 0.2884662362187102]
	TIME [epoch: 67.4 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13247682722847964		[learning rate: 0.0014403]
	Learning Rate: 0.00144033
	LOSS [training: 0.13247682722847964 | validation: 0.32727867093723495]
	TIME [epoch: 67.4 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15265392272112183		[learning rate: 0.0014335]
	Learning Rate: 0.00143354
	LOSS [training: 0.15265392272112183 | validation: 0.29464663420983445]
	TIME [epoch: 67.4 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15942306273271614		[learning rate: 0.0014268]
	Learning Rate: 0.00142679
	LOSS [training: 0.15942306273271614 | validation: 0.28333003840369153]
	TIME [epoch: 67.4 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14763984706110267		[learning rate: 0.0014201]
	Learning Rate: 0.00142006
	LOSS [training: 0.14763984706110267 | validation: 0.3015691602547542]
	TIME [epoch: 67.3 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16624489479140256		[learning rate: 0.0014134]
	Learning Rate: 0.00141337
	LOSS [training: 0.16624489479140256 | validation: 0.3017557453191914]
	TIME [epoch: 67.3 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14664463435026603		[learning rate: 0.0014067]
	Learning Rate: 0.00140671
	LOSS [training: 0.14664463435026603 | validation: 0.3019852026463512]
	TIME [epoch: 67.3 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16112532162619517		[learning rate: 0.0014001]
	Learning Rate: 0.00140008
	LOSS [training: 0.16112532162619517 | validation: 0.2883657956845171]
	TIME [epoch: 67.3 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12513839255506778		[learning rate: 0.0013935]
	Learning Rate: 0.00139349
	LOSS [training: 0.12513839255506778 | validation: 0.3029874041443115]
	TIME [epoch: 67.3 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14097827497292612		[learning rate: 0.0013869]
	Learning Rate: 0.00138692
	LOSS [training: 0.14097827497292612 | validation: 0.2909823650448955]
	TIME [epoch: 67.3 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1654202817682357		[learning rate: 0.0013804]
	Learning Rate: 0.00138038
	LOSS [training: 0.1654202817682357 | validation: 0.31628300590006414]
	TIME [epoch: 67.3 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1652003038132026		[learning rate: 0.0013739]
	Learning Rate: 0.00137388
	LOSS [training: 0.1652003038132026 | validation: 0.28992977065681297]
	TIME [epoch: 67.3 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15873989690584817		[learning rate: 0.0013674]
	Learning Rate: 0.00136741
	LOSS [training: 0.15873989690584817 | validation: 0.3151148814551289]
	TIME [epoch: 67.2 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13608492903240857		[learning rate: 0.001361]
	Learning Rate: 0.00136096
	LOSS [training: 0.13608492903240857 | validation: 0.3002827835888375]
	TIME [epoch: 67.3 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13081930854559126		[learning rate: 0.0013545]
	Learning Rate: 0.00135455
	LOSS [training: 0.13081930854559126 | validation: 0.29115762179956334]
	TIME [epoch: 67.3 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1346866525530228		[learning rate: 0.0013482]
	Learning Rate: 0.00134817
	LOSS [training: 0.1346866525530228 | validation: 0.30255946270548684]
	TIME [epoch: 67.4 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16056157518519654		[learning rate: 0.0013418]
	Learning Rate: 0.00134181
	LOSS [training: 0.16056157518519654 | validation: 0.3151887255935827]
	TIME [epoch: 67.4 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1481526000681771		[learning rate: 0.0013355]
	Learning Rate: 0.00133549
	LOSS [training: 0.1481526000681771 | validation: 0.2894755377355474]
	TIME [epoch: 67.3 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18138956754755836		[learning rate: 0.0013292]
	Learning Rate: 0.0013292
	LOSS [training: 0.18138956754755836 | validation: 0.31982289550188603]
	TIME [epoch: 67.3 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15037112265438465		[learning rate: 0.0013229]
	Learning Rate: 0.00132293
	LOSS [training: 0.15037112265438465 | validation: 0.3006541715805159]
	TIME [epoch: 67.2 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14204448849982085		[learning rate: 0.0013167]
	Learning Rate: 0.0013167
	LOSS [training: 0.14204448849982085 | validation: 0.31217496916577037]
	TIME [epoch: 67.3 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.143528592301229		[learning rate: 0.0013105]
	Learning Rate: 0.0013105
	LOSS [training: 0.143528592301229 | validation: 0.29339496849205915]
	TIME [epoch: 67.3 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12234711582464475		[learning rate: 0.0013043]
	Learning Rate: 0.00130432
	LOSS [training: 0.12234711582464475 | validation: 0.2981012880242492]
	TIME [epoch: 67.3 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14844045875920753		[learning rate: 0.0012982]
	Learning Rate: 0.00129818
	LOSS [training: 0.14844045875920753 | validation: 0.3575447810170207]
	TIME [epoch: 67.4 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17143568275422738		[learning rate: 0.0012921]
	Learning Rate: 0.00129206
	LOSS [training: 0.17143568275422738 | validation: 0.3136128649544999]
	TIME [epoch: 67.3 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14944984014380924		[learning rate: 0.001286]
	Learning Rate: 0.00128597
	LOSS [training: 0.14944984014380924 | validation: 0.3360536553132185]
	TIME [epoch: 67.5 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1634481910675338		[learning rate: 0.0012799]
	Learning Rate: 0.00127991
	LOSS [training: 0.1634481910675338 | validation: 0.2981944046167003]
	TIME [epoch: 67.5 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14142220276217798		[learning rate: 0.0012739]
	Learning Rate: 0.00127388
	LOSS [training: 0.14142220276217798 | validation: 0.3033799142189748]
	TIME [epoch: 67.4 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13591863039356442		[learning rate: 0.0012679]
	Learning Rate: 0.00126788
	LOSS [training: 0.13591863039356442 | validation: 0.31786760437441247]
	TIME [epoch: 67.5 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14578654795838233		[learning rate: 0.0012619]
	Learning Rate: 0.0012619
	LOSS [training: 0.14578654795838233 | validation: 0.2944033507272903]
	TIME [epoch: 67.5 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13322670677952844		[learning rate: 0.001256]
	Learning Rate: 0.00125596
	LOSS [training: 0.13322670677952844 | validation: 0.2864866161756192]
	TIME [epoch: 67.5 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15195546849413025		[learning rate: 0.00125]
	Learning Rate: 0.00125004
	LOSS [training: 0.15195546849413025 | validation: 0.30476552975757226]
	TIME [epoch: 67.5 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14740798264681665		[learning rate: 0.0012441]
	Learning Rate: 0.00124415
	LOSS [training: 0.14740798264681665 | validation: 0.2965842072439565]
	TIME [epoch: 67.5 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1275057073646641		[learning rate: 0.0012383]
	Learning Rate: 0.00123828
	LOSS [training: 0.1275057073646641 | validation: 0.3064590886112474]
	TIME [epoch: 67.5 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1393105394060489		[learning rate: 0.0012324]
	Learning Rate: 0.00123245
	LOSS [training: 0.1393105394060489 | validation: 0.2992777508852124]
	TIME [epoch: 67.4 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14614264712827535		[learning rate: 0.0012266]
	Learning Rate: 0.00122664
	LOSS [training: 0.14614264712827535 | validation: 0.297236772908467]
	TIME [epoch: 67.4 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14783717175758784		[learning rate: 0.0012209]
	Learning Rate: 0.00122086
	LOSS [training: 0.14783717175758784 | validation: 0.30861478285358834]
	TIME [epoch: 67.5 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12785281660040945		[learning rate: 0.0012151]
	Learning Rate: 0.00121511
	LOSS [training: 0.12785281660040945 | validation: 0.28772631769529866]
	TIME [epoch: 67.5 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14019670770544904		[learning rate: 0.0012094]
	Learning Rate: 0.00120938
	LOSS [training: 0.14019670770544904 | validation: 0.30251988913858163]
	TIME [epoch: 67.3 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14239135435591896		[learning rate: 0.0012037]
	Learning Rate: 0.00120368
	LOSS [training: 0.14239135435591896 | validation: 0.308495196537707]
	TIME [epoch: 67.2 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13055463460049171		[learning rate: 0.001198]
	Learning Rate: 0.00119801
	LOSS [training: 0.13055463460049171 | validation: 0.29921219610606237]
	TIME [epoch: 67.2 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13931091953081118		[learning rate: 0.0011924]
	Learning Rate: 0.00119237
	LOSS [training: 0.13931091953081118 | validation: 0.3288729114885308]
	TIME [epoch: 67.2 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14139368951779008		[learning rate: 0.0011867]
	Learning Rate: 0.00118675
	LOSS [training: 0.14139368951779008 | validation: 0.3053951799450218]
	TIME [epoch: 67.3 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13608721880861513		[learning rate: 0.0011812]
	Learning Rate: 0.00118116
	LOSS [training: 0.13608721880861513 | validation: 0.3165836114307579]
	TIME [epoch: 67.2 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1450389858880452		[learning rate: 0.0011756]
	Learning Rate: 0.00117559
	LOSS [training: 0.1450389858880452 | validation: 0.30540042607284107]
	TIME [epoch: 67.3 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1438542355314621		[learning rate: 0.0011701]
	Learning Rate: 0.00117005
	LOSS [training: 0.1438542355314621 | validation: 0.3273674612490955]
	TIME [epoch: 67.4 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1586300677362741		[learning rate: 0.0011645]
	Learning Rate: 0.00116454
	LOSS [training: 0.1586300677362741 | validation: 0.31218652908386596]
	TIME [epoch: 67.3 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14809638393135308		[learning rate: 0.0011591]
	Learning Rate: 0.00115905
	LOSS [training: 0.14809638393135308 | validation: 0.2869337417542475]
	TIME [epoch: 67.4 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1380958654298657		[learning rate: 0.0011536]
	Learning Rate: 0.00115359
	LOSS [training: 0.1380958654298657 | validation: 0.30093298230169385]
	TIME [epoch: 67.4 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14890269575107057		[learning rate: 0.0011482]
	Learning Rate: 0.00114815
	LOSS [training: 0.14890269575107057 | validation: 0.3018137159310812]
	TIME [epoch: 67.5 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14687696480989715		[learning rate: 0.0011427]
	Learning Rate: 0.00114274
	LOSS [training: 0.14687696480989715 | validation: 0.2992494821112735]
	TIME [epoch: 67.5 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.140181972738998		[learning rate: 0.0011374]
	Learning Rate: 0.00113736
	LOSS [training: 0.140181972738998 | validation: 0.30719468681800094]
	TIME [epoch: 67.4 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13865771825705314		[learning rate: 0.001132]
	Learning Rate: 0.001132
	LOSS [training: 0.13865771825705314 | validation: 0.2791556809100767]
	TIME [epoch: 67.5 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14745534060991367		[learning rate: 0.0011267]
	Learning Rate: 0.00112667
	LOSS [training: 0.14745534060991367 | validation: 0.33639315402113296]
	TIME [epoch: 67.5 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14202226545326146		[learning rate: 0.0011214]
	Learning Rate: 0.00112136
	LOSS [training: 0.14202226545326146 | validation: 0.30192910203170253]
	TIME [epoch: 67.4 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15504500279823474		[learning rate: 0.0011161]
	Learning Rate: 0.00111607
	LOSS [training: 0.15504500279823474 | validation: 0.30894129123432695]
	TIME [epoch: 67.4 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13440800107032297		[learning rate: 0.0011108]
	Learning Rate: 0.00111081
	LOSS [training: 0.13440800107032297 | validation: 0.2891965074825534]
	TIME [epoch: 67.3 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1250104062083631		[learning rate: 0.0011056]
	Learning Rate: 0.00110558
	LOSS [training: 0.1250104062083631 | validation: 0.29710847145655833]
	TIME [epoch: 67.4 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13747272402667093		[learning rate: 0.0011004]
	Learning Rate: 0.00110037
	LOSS [training: 0.13747272402667093 | validation: 0.3039095913568946]
	TIME [epoch: 67.5 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.156775465051815		[learning rate: 0.0010952]
	Learning Rate: 0.00109518
	LOSS [training: 0.156775465051815 | validation: 0.3145445662397601]
	TIME [epoch: 67.5 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15376196131341116		[learning rate: 0.00109]
	Learning Rate: 0.00109002
	LOSS [training: 0.15376196131341116 | validation: 0.32825546029929126]
	TIME [epoch: 67.6 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12811364121689833		[learning rate: 0.0010849]
	Learning Rate: 0.00108489
	LOSS [training: 0.12811364121689833 | validation: 0.3008193978824454]
	TIME [epoch: 67.5 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13836544877848958		[learning rate: 0.0010798]
	Learning Rate: 0.00107978
	LOSS [training: 0.13836544877848958 | validation: 0.32087233917410657]
	TIME [epoch: 67.5 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14401650300053653		[learning rate: 0.0010747]
	Learning Rate: 0.00107469
	LOSS [training: 0.14401650300053653 | validation: 0.303864312821725]
	TIME [epoch: 67.6 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14714899578825752		[learning rate: 0.0010696]
	Learning Rate: 0.00106962
	LOSS [training: 0.14714899578825752 | validation: 0.28027907935861396]
	TIME [epoch: 67.6 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1432974925926106		[learning rate: 0.0010646]
	Learning Rate: 0.00106458
	LOSS [training: 0.1432974925926106 | validation: 0.31508553515345766]
	TIME [epoch: 67.6 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.133371588034121		[learning rate: 0.0010596]
	Learning Rate: 0.00105957
	LOSS [training: 0.133371588034121 | validation: 0.32181081644411463]
	TIME [epoch: 67.5 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1293530131069123		[learning rate: 0.0010546]
	Learning Rate: 0.00105457
	LOSS [training: 0.1293530131069123 | validation: 0.30432727182299624]
	TIME [epoch: 67.5 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1337914736075345		[learning rate: 0.0010496]
	Learning Rate: 0.0010496
	LOSS [training: 0.1337914736075345 | validation: 0.29617648451757633]
	TIME [epoch: 67.6 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1590625052406201		[learning rate: 0.0010447]
	Learning Rate: 0.00104466
	LOSS [training: 0.1590625052406201 | validation: 0.306762928826617]
	TIME [epoch: 67.6 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.144407903838688		[learning rate: 0.0010397]
	Learning Rate: 0.00103974
	LOSS [training: 0.144407903838688 | validation: 0.302739678602605]
	TIME [epoch: 67.5 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14814885803510042		[learning rate: 0.0010348]
	Learning Rate: 0.00103484
	LOSS [training: 0.14814885803510042 | validation: 0.2941754398005189]
	TIME [epoch: 67.6 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14541119323484272		[learning rate: 0.00103]
	Learning Rate: 0.00102996
	LOSS [training: 0.14541119323484272 | validation: 0.2949269608166867]
	TIME [epoch: 67.6 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1371004225576725		[learning rate: 0.0010251]
	Learning Rate: 0.00102511
	LOSS [training: 0.1371004225576725 | validation: 0.34247264214125306]
	TIME [epoch: 67.5 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v15b_20240716_171520/states/model_facs_v3_dec2b_2dpca_v15b_520.pth
Halted early. No improvement in validation loss for 200 epochs.
Finished training in 20285.793 seconds.
