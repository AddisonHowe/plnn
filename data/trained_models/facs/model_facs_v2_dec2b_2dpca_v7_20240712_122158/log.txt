Args:
Namespace(name='model_facs_v2_dec2b_2dpca_v7', outdir='out/model_training/model_facs_v2_dec2b_2dpca_v7', training_data='data/training_data/facs_v2/pca/dec2_fitonsubset/transition2_subset_ce_pn_m_pc12/training', validation_data='data/training_data/facs_v2/pca/dec2_fitonsubset/transition2_subset_ce_pn_m_pc12/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=10, batch_size=50, patience=200, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, quadratic_a=1.0, quadratic_b=1.0, ndims=2, nparams=2, nsigs=2, ncells=200, ncells_sample=200, model_do_sample=False, dt=0.005, dt_schedule='stepped', dt_schedule_bounds=[500, 1000, 1500], dt_schedule_scales=[0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=True, sigma=0.02, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', kernel='multiscale', bw_range=[0.2, 0.5, 0.9, 1.1, 1.3, 1.5, 2.0], optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 1089364454

Training model...

Saving initial model state to: out/model_training/model_facs_v2_dec2b_2dpca_v7_20240712_122158/states/model_facs_v2_dec2b_2dpca_v7_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1891636613413268		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1891636613413268 | validation: 1.0760047362667862]
	TIME [epoch: 34.2 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v7_20240712_122158/states/model_facs_v2_dec2b_2dpca_v7_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7301657897498761		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7301657897498761 | validation: 0.8144859434773916]
	TIME [epoch: 4.74 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v7_20240712_122158/states/model_facs_v2_dec2b_2dpca_v7_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6695250065212403		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6695250065212403 | validation: 0.7906244186523875]
	TIME [epoch: 4.7 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v7_20240712_122158/states/model_facs_v2_dec2b_2dpca_v7_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6018520609951619		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6018520609951619 | validation: 0.7605486383127806]
	TIME [epoch: 4.72 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v7_20240712_122158/states/model_facs_v2_dec2b_2dpca_v7_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5253333402792882		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5253333402792882 | validation: 0.714868514739856]
	TIME [epoch: 4.71 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v7_20240712_122158/states/model_facs_v2_dec2b_2dpca_v7_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5334944612743613		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5334944612743613 | validation: 0.6519508773402296]
	TIME [epoch: 4.71 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v7_20240712_122158/states/model_facs_v2_dec2b_2dpca_v7_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.49635621569518895		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.49635621569518895 | validation: 0.658212044650899]
	TIME [epoch: 4.71 sec]
EPOCH 8/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4582679314240986		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4582679314240986 | validation: 0.7235304719025788]
	TIME [epoch: 4.74 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4488199883850982		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4488199883850982 | validation: 0.5868666869972937]
	TIME [epoch: 4.71 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v7_20240712_122158/states/model_facs_v2_dec2b_2dpca_v7_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41306288056395346		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.41306288056395346 | validation: 0.5548447534129167]
	TIME [epoch: 4.71 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v7_20240712_122158/states/model_facs_v2_dec2b_2dpca_v7_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3791298608902491		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3791298608902491 | validation: 0.5738671559840823]
	TIME [epoch: 4.73 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4232005763311567		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4232005763311567 | validation: 0.5327254519286214]
	TIME [epoch: 4.71 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v7_20240712_122158/states/model_facs_v2_dec2b_2dpca_v7_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3013274951636676		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3013274951636676 | validation: 0.4925393658232269]
	TIME [epoch: 4.72 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v7_20240712_122158/states/model_facs_v2_dec2b_2dpca_v7_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3568383262907905		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3568383262907905 | validation: 0.6918555884368268]
	TIME [epoch: 4.72 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3330326631417737		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3330326631417737 | validation: 0.491171449632764]
	TIME [epoch: 4.72 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v7_20240712_122158/states/model_facs_v2_dec2b_2dpca_v7_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3056411935844613		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3056411935844613 | validation: 0.49237227399329203]
	TIME [epoch: 4.71 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28460745577467766		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.28460745577467766 | validation: 0.6196925218996518]
	TIME [epoch: 4.73 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3181256634014913		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3181256634014913 | validation: 0.5377313824447816]
	TIME [epoch: 4.73 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31903962538904895		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.31903962538904895 | validation: 0.4690275047570779]
	TIME [epoch: 4.71 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v7_20240712_122158/states/model_facs_v2_dec2b_2dpca_v7_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31008216427292445		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.31008216427292445 | validation: 0.47439855999002467]
	TIME [epoch: 4.71 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30120916808690923		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.30120916808690923 | validation: 0.4630225958394302]
	TIME [epoch: 4.71 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v7_20240712_122158/states/model_facs_v2_dec2b_2dpca_v7_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27049188127056656		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.27049188127056656 | validation: 0.49645465110774517]
	TIME [epoch: 4.7 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32229577351752603		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.32229577351752603 | validation: 0.4709814329403501]
	TIME [epoch: 4.7 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2668421351187281		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2668421351187281 | validation: 0.568571642304362]
	TIME [epoch: 4.72 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2968143006082372		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2968143006082372 | validation: 0.5191513181083371]
	TIME [epoch: 4.7 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2944750142078699		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2944750142078699 | validation: 0.43515978303184855]
	TIME [epoch: 4.71 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v7_20240712_122158/states/model_facs_v2_dec2b_2dpca_v7_26.pth
	Model improved!!!
EPOCH 27/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2290237032160371		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2290237032160371 | validation: 0.5766321390877056]
	TIME [epoch: 4.71 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34339831184365		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.34339831184365 | validation: 0.4606290591763792]
	TIME [epoch: 4.72 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2670309766088936		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2670309766088936 | validation: 0.39954208401840935]
	TIME [epoch: 4.71 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v7_20240712_122158/states/model_facs_v2_dec2b_2dpca_v7_29.pth
	Model improved!!!
EPOCH 30/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32768066807113955		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.32768066807113955 | validation: 0.6923396198546923]
	TIME [epoch: 4.73 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30488296830616524		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.30488296830616524 | validation: 0.45519893707089254]
	TIME [epoch: 4.71 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2389330209229529		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2389330209229529 | validation: 0.43575246623945596]
	TIME [epoch: 4.71 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2464735423693866		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2464735423693866 | validation: 0.4707366280720769]
	TIME [epoch: 4.71 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27777863165669175		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.27777863165669175 | validation: 0.413740870457353]
	TIME [epoch: 4.71 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28455031794937613		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.28455031794937613 | validation: 0.5414940863733758]
	TIME [epoch: 4.7 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31255851462760975		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.31255851462760975 | validation: 0.41996459974104694]
	TIME [epoch: 4.7 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.247511778674101		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.247511778674101 | validation: 0.41692496934787565]
	TIME [epoch: 4.71 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25068366594278113		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.25068366594278113 | validation: 0.41578837421715964]
	TIME [epoch: 4.71 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25136830958211853		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.25136830958211853 | validation: 0.390263101960019]
	TIME [epoch: 4.71 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v7_20240712_122158/states/model_facs_v2_dec2b_2dpca_v7_39.pth
	Model improved!!!
EPOCH 40/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2619181497946722		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2619181497946722 | validation: 0.7163556396517822]
	TIME [epoch: 4.72 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3277734355331714		[learning rate: 0.0099646]
	Learning Rate: 0.00996464
	LOSS [training: 0.3277734355331714 | validation: 0.6180381834372275]
	TIME [epoch: 4.7 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3088042796830533		[learning rate: 0.0099206]
	Learning Rate: 0.00992061
	LOSS [training: 0.3088042796830533 | validation: 0.4191396849197003]
	TIME [epoch: 4.7 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2351766337140655		[learning rate: 0.0098768]
	Learning Rate: 0.00987678
	LOSS [training: 0.2351766337140655 | validation: 0.36285152118074804]
	TIME [epoch: 4.7 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v7_20240712_122158/states/model_facs_v2_dec2b_2dpca_v7_43.pth
	Model improved!!!
EPOCH 44/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24414549005808978		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 0.24414549005808978 | validation: 0.46276269383681634]
	TIME [epoch: 4.71 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2755208743205405		[learning rate: 0.0097897]
	Learning Rate: 0.0097897
	LOSS [training: 0.2755208743205405 | validation: 0.6356320329200752]
	TIME [epoch: 4.71 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2411972926838481		[learning rate: 0.0097464]
	Learning Rate: 0.00974644
	LOSS [training: 0.2411972926838481 | validation: 0.39725851742060836]
	TIME [epoch: 4.71 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2291022999099767		[learning rate: 0.0097034]
	Learning Rate: 0.00970338
	LOSS [training: 0.2291022999099767 | validation: 0.42484972347661126]
	TIME [epoch: 4.71 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21914586703290073		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 0.21914586703290073 | validation: 0.4124852994201879]
	TIME [epoch: 4.7 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2954460382313576		[learning rate: 0.0096178]
	Learning Rate: 0.00961783
	LOSS [training: 0.2954460382313576 | validation: 0.41132911385982923]
	TIME [epoch: 4.7 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2224618525300388		[learning rate: 0.0095753]
	Learning Rate: 0.00957533
	LOSS [training: 0.2224618525300388 | validation: 0.36026113650699754]
	TIME [epoch: 4.7 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v7_20240712_122158/states/model_facs_v2_dec2b_2dpca_v7_50.pth
	Model improved!!!
EPOCH 51/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22394272413021285		[learning rate: 0.009533]
	Learning Rate: 0.00953303
	LOSS [training: 0.22394272413021285 | validation: 0.3907849658540552]
	TIME [epoch: 4.7 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20285098708381488		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 0.20285098708381488 | validation: 0.3818417155428683]
	TIME [epoch: 4.71 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23007052191686245		[learning rate: 0.009449]
	Learning Rate: 0.00944897
	LOSS [training: 0.23007052191686245 | validation: 0.3997386682088256]
	TIME [epoch: 4.71 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21840844020096917		[learning rate: 0.0094072]
	Learning Rate: 0.00940722
	LOSS [training: 0.21840844020096917 | validation: 0.36814830059842796]
	TIME [epoch: 4.7 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2195430936777032		[learning rate: 0.0093657]
	Learning Rate: 0.00936566
	LOSS [training: 0.2195430936777032 | validation: 0.5165075267542297]
	TIME [epoch: 4.7 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2160817058578451		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 0.2160817058578451 | validation: 0.4191049760303475]
	TIME [epoch: 4.71 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2547213100092796		[learning rate: 0.0092831]
	Learning Rate: 0.00928308
	LOSS [training: 0.2547213100092796 | validation: 0.37494095637756614]
	TIME [epoch: 4.71 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3087994718724871		[learning rate: 0.0092421]
	Learning Rate: 0.00924207
	LOSS [training: 0.3087994718724871 | validation: 0.4551762910838226]
	TIME [epoch: 4.7 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2869452474025559		[learning rate: 0.0092012]
	Learning Rate: 0.00920124
	LOSS [training: 0.2869452474025559 | validation: 0.4131714422227266]
	TIME [epoch: 4.71 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2623955885197391		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 0.2623955885197391 | validation: 0.4024151219646013]
	TIME [epoch: 4.7 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28354508107885057		[learning rate: 0.0091201]
	Learning Rate: 0.00912011
	LOSS [training: 0.28354508107885057 | validation: 0.37895585731683856]
	TIME [epoch: 4.7 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23335697385776366		[learning rate: 0.0090798]
	Learning Rate: 0.00907981
	LOSS [training: 0.23335697385776366 | validation: 0.3721274033879216]
	TIME [epoch: 4.7 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2123240338092245		[learning rate: 0.0090397]
	Learning Rate: 0.0090397
	LOSS [training: 0.2123240338092245 | validation: 0.32814995469166597]
	TIME [epoch: 4.7 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v7_20240712_122158/states/model_facs_v2_dec2b_2dpca_v7_63.pth
	Model improved!!!
EPOCH 64/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23373579128228822		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 0.23373579128228822 | validation: 0.3634887599044913]
	TIME [epoch: 4.7 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23707914143423175		[learning rate: 0.00896]
	Learning Rate: 0.00895999
	LOSS [training: 0.23707914143423175 | validation: 0.4309955787770878]
	TIME [epoch: 4.72 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24327767049659754		[learning rate: 0.0089204]
	Learning Rate: 0.00892041
	LOSS [training: 0.24327767049659754 | validation: 0.3736541610052116]
	TIME [epoch: 4.71 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26153242403751		[learning rate: 0.008881]
	Learning Rate: 0.00888099
	LOSS [training: 0.26153242403751 | validation: 0.4475369609619665]
	TIME [epoch: 4.7 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2124701885058023		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 0.2124701885058023 | validation: 0.3352380092279651]
	TIME [epoch: 4.69 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1953049291466392		[learning rate: 0.0088027]
	Learning Rate: 0.00880269
	LOSS [training: 0.1953049291466392 | validation: 0.35052864430330466]
	TIME [epoch: 4.7 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22222743060691882		[learning rate: 0.0087638]
	Learning Rate: 0.0087638
	LOSS [training: 0.22222743060691882 | validation: 0.39059084102208835]
	TIME [epoch: 4.7 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21625196947244194		[learning rate: 0.0087251]
	Learning Rate: 0.00872508
	LOSS [training: 0.21625196947244194 | validation: 0.3568034722144868]
	TIME [epoch: 4.7 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20773890001076384		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 0.20773890001076384 | validation: 0.34351009118194376]
	TIME [epoch: 4.7 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2693844627458696		[learning rate: 0.0086481]
	Learning Rate: 0.00864815
	LOSS [training: 0.2693844627458696 | validation: 0.4706072063619009]
	TIME [epoch: 4.7 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2604157995069871		[learning rate: 0.0086099]
	Learning Rate: 0.00860994
	LOSS [training: 0.2604157995069871 | validation: 0.37609240277519784]
	TIME [epoch: 4.7 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19159644519744334		[learning rate: 0.0085719]
	Learning Rate: 0.0085719
	LOSS [training: 0.19159644519744334 | validation: 0.38977187597219354]
	TIME [epoch: 4.7 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2040030954449877		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 0.2040030954449877 | validation: 0.3961974617997137]
	TIME [epoch: 4.7 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21160675924920486		[learning rate: 0.0084963]
	Learning Rate: 0.00849632
	LOSS [training: 0.21160675924920486 | validation: 0.33445809108809893]
	TIME [epoch: 4.7 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2023957071546736		[learning rate: 0.0084588]
	Learning Rate: 0.00845878
	LOSS [training: 0.2023957071546736 | validation: 0.469281851472586]
	TIME [epoch: 4.71 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2216220595601243		[learning rate: 0.0084214]
	Learning Rate: 0.00842141
	LOSS [training: 0.2216220595601243 | validation: 0.35243392120476164]
	TIME [epoch: 4.7 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2452124057160207		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 0.2452124057160207 | validation: 0.346200724080738]
	TIME [epoch: 4.69 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21803219734276996		[learning rate: 0.0083472]
	Learning Rate: 0.00834715
	LOSS [training: 0.21803219734276996 | validation: 0.3660428628471287]
	TIME [epoch: 4.7 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2080199107253342		[learning rate: 0.0083103]
	Learning Rate: 0.00831027
	LOSS [training: 0.2080199107253342 | validation: 0.38415346954591156]
	TIME [epoch: 4.7 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22253447520895783		[learning rate: 0.0082736]
	Learning Rate: 0.00827356
	LOSS [training: 0.22253447520895783 | validation: 0.3712251658261612]
	TIME [epoch: 4.7 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22064311373708495		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 0.22064311373708495 | validation: 0.38724329474147606]
	TIME [epoch: 4.71 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21897871676935482		[learning rate: 0.0082006]
	Learning Rate: 0.00820061
	LOSS [training: 0.21897871676935482 | validation: 0.37295041775171456]
	TIME [epoch: 4.71 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20185809775990152		[learning rate: 0.0081644]
	Learning Rate: 0.00816438
	LOSS [training: 0.20185809775990152 | validation: 0.41017403525018026]
	TIME [epoch: 4.7 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23439987121825548		[learning rate: 0.0081283]
	Learning Rate: 0.0081283
	LOSS [training: 0.23439987121825548 | validation: 0.5025901059429349]
	TIME [epoch: 4.69 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19372189407597443		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 0.19372189407597443 | validation: 0.35006135255908416]
	TIME [epoch: 4.7 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1818959664884445		[learning rate: 0.0080566]
	Learning Rate: 0.00805664
	LOSS [training: 0.1818959664884445 | validation: 0.39399922780629554]
	TIME [epoch: 4.71 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25468960268411983		[learning rate: 0.008021]
	Learning Rate: 0.00802104
	LOSS [training: 0.25468960268411983 | validation: 0.36742726924425695]
	TIME [epoch: 4.7 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20187364956522663		[learning rate: 0.0079856]
	Learning Rate: 0.0079856
	LOSS [training: 0.20187364956522663 | validation: 0.30254312777609366]
	TIME [epoch: 4.71 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v7_20240712_122158/states/model_facs_v2_dec2b_2dpca_v7_91.pth
	Model improved!!!
EPOCH 92/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20410317876686		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 0.20410317876686 | validation: 0.42299471110579634]
	TIME [epoch: 4.71 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2318122340777909		[learning rate: 0.0079152]
	Learning Rate: 0.00791519
	LOSS [training: 0.2318122340777909 | validation: 0.37704921643764705]
	TIME [epoch: 4.71 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19344186398619226		[learning rate: 0.0078802]
	Learning Rate: 0.00788022
	LOSS [training: 0.19344186398619226 | validation: 0.3306420850050143]
	TIME [epoch: 4.7 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19232158171503724		[learning rate: 0.0078454]
	Learning Rate: 0.00784541
	LOSS [training: 0.19232158171503724 | validation: 0.35037992625416375]
	TIME [epoch: 4.7 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2082288187201918		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 0.2082288187201918 | validation: 0.4460499546647302]
	TIME [epoch: 4.7 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19679952815017568		[learning rate: 0.0077762]
	Learning Rate: 0.00777623
	LOSS [training: 0.19679952815017568 | validation: 0.4073242036740677]
	TIME [epoch: 4.71 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20295930632645068		[learning rate: 0.0077419]
	Learning Rate: 0.00774188
	LOSS [training: 0.20295930632645068 | validation: 0.4272749616957249]
	TIME [epoch: 4.7 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.216587127782596		[learning rate: 0.0077077]
	Learning Rate: 0.00770767
	LOSS [training: 0.216587127782596 | validation: 0.3896982091556857]
	TIME [epoch: 4.7 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22476012534712334		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 0.22476012534712334 | validation: 0.3577188599572881]
	TIME [epoch: 4.7 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19803435981994683		[learning rate: 0.0076397]
	Learning Rate: 0.00763971
	LOSS [training: 0.19803435981994683 | validation: 0.35780261546465514]
	TIME [epoch: 4.71 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2528187996481727		[learning rate: 0.007606]
	Learning Rate: 0.00760596
	LOSS [training: 0.2528187996481727 | validation: 0.3622646826865211]
	TIME [epoch: 4.71 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22108932798039943		[learning rate: 0.0075724]
	Learning Rate: 0.00757235
	LOSS [training: 0.22108932798039943 | validation: 0.45350587505395457]
	TIME [epoch: 4.71 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21578465981667244		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 0.21578465981667244 | validation: 0.3713345722475188]
	TIME [epoch: 4.71 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21002493106788256		[learning rate: 0.0075056]
	Learning Rate: 0.00750559
	LOSS [training: 0.21002493106788256 | validation: 0.3199394893203431]
	TIME [epoch: 4.7 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20121606629601776		[learning rate: 0.0074724]
	Learning Rate: 0.00747242
	LOSS [training: 0.20121606629601776 | validation: 0.3737626951811709]
	TIME [epoch: 4.7 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18758456252134142		[learning rate: 0.0074394]
	Learning Rate: 0.00743941
	LOSS [training: 0.18758456252134142 | validation: 0.32126280384138783]
	TIME [epoch: 4.71 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20477576576615658		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 0.20477576576615658 | validation: 0.35875445652743276]
	TIME [epoch: 4.7 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2043370142795069		[learning rate: 0.0073738]
	Learning Rate: 0.00737382
	LOSS [training: 0.2043370142795069 | validation: 0.3284941266627889]
	TIME [epoch: 4.7 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17552212509495616		[learning rate: 0.0073412]
	Learning Rate: 0.00734124
	LOSS [training: 0.17552212509495616 | validation: 0.33271049328742774]
	TIME [epoch: 4.7 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20294668730915982		[learning rate: 0.0073088]
	Learning Rate: 0.0073088
	LOSS [training: 0.20294668730915982 | validation: 0.3352961235174795]
	TIME [epoch: 4.7 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2222418135365273		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 0.2222418135365273 | validation: 0.3344196677175293]
	TIME [epoch: 4.71 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18255600350857248		[learning rate: 0.0072444]
	Learning Rate: 0.00724436
	LOSS [training: 0.18255600350857248 | validation: 0.33092437925398005]
	TIME [epoch: 4.72 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18044155726434538		[learning rate: 0.0072124]
	Learning Rate: 0.00721235
	LOSS [training: 0.18044155726434538 | validation: 0.34042548528023253]
	TIME [epoch: 4.7 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22349592987802652		[learning rate: 0.0071805]
	Learning Rate: 0.00718049
	LOSS [training: 0.22349592987802652 | validation: 0.32983366691935817]
	TIME [epoch: 4.7 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1986702773629207		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 0.1986702773629207 | validation: 0.4656774699772508]
	TIME [epoch: 4.72 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21870232272943171		[learning rate: 0.0071172]
	Learning Rate: 0.00711718
	LOSS [training: 0.21870232272943171 | validation: 0.3986723820796671]
	TIME [epoch: 4.7 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19218403305888107		[learning rate: 0.0070857]
	Learning Rate: 0.00708573
	LOSS [training: 0.19218403305888107 | validation: 0.3194983477296107]
	TIME [epoch: 4.7 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19430465035632843		[learning rate: 0.0070544]
	Learning Rate: 0.00705442
	LOSS [training: 0.19430465035632843 | validation: 0.3383192294409191]
	TIME [epoch: 4.72 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18223480644004267		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 0.18223480644004267 | validation: 0.3813643264204686]
	TIME [epoch: 4.71 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1910533641081919		[learning rate: 0.0069922]
	Learning Rate: 0.00699222
	LOSS [training: 0.1910533641081919 | validation: 0.4481165124049847]
	TIME [epoch: 4.71 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19675820026059423		[learning rate: 0.0069613]
	Learning Rate: 0.00696133
	LOSS [training: 0.19675820026059423 | validation: 0.40308686168411834]
	TIME [epoch: 4.71 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19164855447604906		[learning rate: 0.0069306]
	Learning Rate: 0.00693057
	LOSS [training: 0.19164855447604906 | validation: 0.4052527670626799]
	TIME [epoch: 4.71 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18662754292561828		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 0.18662754292561828 | validation: 0.3914531150968814]
	TIME [epoch: 4.7 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24666755632195808		[learning rate: 0.0068695]
	Learning Rate: 0.00686947
	LOSS [training: 0.24666755632195808 | validation: 0.328789020030675]
	TIME [epoch: 4.7 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20987773468283746		[learning rate: 0.0068391]
	Learning Rate: 0.00683912
	LOSS [training: 0.20987773468283746 | validation: 0.3611361843374161]
	TIME [epoch: 4.7 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20444267305643327		[learning rate: 0.0068089]
	Learning Rate: 0.0068089
	LOSS [training: 0.20444267305643327 | validation: 0.36239425459659874]
	TIME [epoch: 4.7 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18326246118780937		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 0.18326246118780937 | validation: 0.3360403386083897]
	TIME [epoch: 4.7 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1833422831092676		[learning rate: 0.0067489]
	Learning Rate: 0.00674887
	LOSS [training: 0.1833422831092676 | validation: 0.35107844702804003]
	TIME [epoch: 4.72 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2119976608424711		[learning rate: 0.006719]
	Learning Rate: 0.00671905
	LOSS [training: 0.2119976608424711 | validation: 0.3619805884844327]
	TIME [epoch: 4.71 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1913441687850422		[learning rate: 0.0066894]
	Learning Rate: 0.00668936
	LOSS [training: 0.1913441687850422 | validation: 0.34140347330652654]
	TIME [epoch: 4.71 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20768314075975008		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 0.20768314075975008 | validation: 0.3555782220564056]
	TIME [epoch: 4.71 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1885547333988779		[learning rate: 0.0066304]
	Learning Rate: 0.00663038
	LOSS [training: 0.1885547333988779 | validation: 0.37854595725588963]
	TIME [epoch: 4.71 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19323106127217493		[learning rate: 0.0066011]
	Learning Rate: 0.00660109
	LOSS [training: 0.19323106127217493 | validation: 0.33305458097489926]
	TIME [epoch: 4.7 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1882483841479444		[learning rate: 0.0065719]
	Learning Rate: 0.00657192
	LOSS [training: 0.1882483841479444 | validation: 0.3626902179145885]
	TIME [epoch: 4.74 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18463596048198153		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 0.18463596048198153 | validation: 0.37729755092320155]
	TIME [epoch: 4.73 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19949787745106193		[learning rate: 0.006514]
	Learning Rate: 0.00651398
	LOSS [training: 0.19949787745106193 | validation: 0.3290027116094014]
	TIME [epoch: 4.71 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19868760326675233		[learning rate: 0.0064852]
	Learning Rate: 0.00648519
	LOSS [training: 0.19868760326675233 | validation: 0.32981007126610445]
	TIME [epoch: 4.71 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2485524143322783		[learning rate: 0.0064565]
	Learning Rate: 0.00645654
	LOSS [training: 0.2485524143322783 | validation: 0.364132904266368]
	TIME [epoch: 4.73 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1921462241225723		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 0.1921462241225723 | validation: 0.3510734422807185]
	TIME [epoch: 4.71 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1819733830330055		[learning rate: 0.0063996]
	Learning Rate: 0.00639961
	LOSS [training: 0.1819733830330055 | validation: 0.3344674145075953]
	TIME [epoch: 4.73 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17691726423250015		[learning rate: 0.0063713]
	Learning Rate: 0.00637134
	LOSS [training: 0.17691726423250015 | validation: 0.3609207884193407]
	TIME [epoch: 4.74 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19978731631235355		[learning rate: 0.0063432]
	Learning Rate: 0.00634319
	LOSS [training: 0.19978731631235355 | validation: 0.3341117931223267]
	TIME [epoch: 4.7 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19280434519964398		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 0.19280434519964398 | validation: 0.3322201549373221]
	TIME [epoch: 4.7 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18894407352193715		[learning rate: 0.0062873]
	Learning Rate: 0.00628726
	LOSS [training: 0.18894407352193715 | validation: 0.35046786625728715]
	TIME [epoch: 4.7 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2081146637732474		[learning rate: 0.0062595]
	Learning Rate: 0.00625948
	LOSS [training: 0.2081146637732474 | validation: 0.3377962558169097]
	TIME [epoch: 4.7 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20834592231404586		[learning rate: 0.0062318]
	Learning Rate: 0.00623183
	LOSS [training: 0.20834592231404586 | validation: 0.38185695657785124]
	TIME [epoch: 4.71 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18285488695916216		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 0.18285488695916216 | validation: 0.3396178822229194]
	TIME [epoch: 4.72 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18965042511443275		[learning rate: 0.0061769]
	Learning Rate: 0.00617688
	LOSS [training: 0.18965042511443275 | validation: 0.3497097291560581]
	TIME [epoch: 4.72 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18605569650251477		[learning rate: 0.0061496]
	Learning Rate: 0.00614959
	LOSS [training: 0.18605569650251477 | validation: 0.3448150942412197]
	TIME [epoch: 4.7 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18582704016937238		[learning rate: 0.0061224]
	Learning Rate: 0.00612242
	LOSS [training: 0.18582704016937238 | validation: 0.3605644395884866]
	TIME [epoch: 4.73 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1824381994829807		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 0.1824381994829807 | validation: 0.33502779474761746]
	TIME [epoch: 4.72 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19036868405603471		[learning rate: 0.0060684]
	Learning Rate: 0.00606844
	LOSS [training: 0.19036868405603471 | validation: 0.31834928943535423]
	TIME [epoch: 4.7 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18369756238841767		[learning rate: 0.0060416]
	Learning Rate: 0.00604163
	LOSS [training: 0.18369756238841767 | validation: 0.3797127347377959]
	TIME [epoch: 4.72 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19145362203089417		[learning rate: 0.0060149]
	Learning Rate: 0.00601493
	LOSS [training: 0.19145362203089417 | validation: 0.37461365362701615]
	TIME [epoch: 4.74 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17906450800713075		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 0.17906450800713075 | validation: 0.4110963988517747]
	TIME [epoch: 4.74 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22812988219203545		[learning rate: 0.0059619]
	Learning Rate: 0.0059619
	LOSS [training: 0.22812988219203545 | validation: 0.3178709062910808]
	TIME [epoch: 4.73 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18629154104989923		[learning rate: 0.0059356]
	Learning Rate: 0.00593556
	LOSS [training: 0.18629154104989923 | validation: 0.34044086783727096]
	TIME [epoch: 4.74 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1793545197647683		[learning rate: 0.0059093]
	Learning Rate: 0.00590933
	LOSS [training: 0.1793545197647683 | validation: 0.3593517735408005]
	TIME [epoch: 4.71 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2170556481869046		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 0.2170556481869046 | validation: 0.34809907612657154]
	TIME [epoch: 4.74 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21414911181932456		[learning rate: 0.0058572]
	Learning Rate: 0.00585723
	LOSS [training: 0.21414911181932456 | validation: 0.34151024121878726]
	TIME [epoch: 4.72 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19975669141570304		[learning rate: 0.0058314]
	Learning Rate: 0.00583135
	LOSS [training: 0.19975669141570304 | validation: 0.33576680023340055]
	TIME [epoch: 4.76 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1866478860964139		[learning rate: 0.0058056]
	Learning Rate: 0.00580559
	LOSS [training: 0.1866478860964139 | validation: 0.3220614885456879]
	TIME [epoch: 4.72 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2087673809295593		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 0.2087673809295593 | validation: 0.31872620431825904]
	TIME [epoch: 4.71 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1887032263339329		[learning rate: 0.0057544]
	Learning Rate: 0.0057544
	LOSS [training: 0.1887032263339329 | validation: 0.32440165418169814]
	TIME [epoch: 4.72 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19400728003180567		[learning rate: 0.005729]
	Learning Rate: 0.00572897
	LOSS [training: 0.19400728003180567 | validation: 0.33318568956866373]
	TIME [epoch: 4.75 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18261157574029743		[learning rate: 0.0057037]
	Learning Rate: 0.00570366
	LOSS [training: 0.18261157574029743 | validation: 0.332609446685591]
	TIME [epoch: 4.73 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17059056038577308		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 0.17059056038577308 | validation: 0.3940123440270162]
	TIME [epoch: 4.72 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1769692685421718		[learning rate: 0.0056534]
	Learning Rate: 0.00565337
	LOSS [training: 0.1769692685421718 | validation: 0.34015581091647745]
	TIME [epoch: 4.71 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20971743471801024		[learning rate: 0.0056284]
	Learning Rate: 0.0056284
	LOSS [training: 0.20971743471801024 | validation: 0.3385485149372157]
	TIME [epoch: 4.71 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19135458112156453		[learning rate: 0.0056035]
	Learning Rate: 0.00560353
	LOSS [training: 0.19135458112156453 | validation: 0.322019647152419]
	TIME [epoch: 4.73 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1770587692611123		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 0.1770587692611123 | validation: 0.3230467012502826]
	TIME [epoch: 4.76 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17663157943307617		[learning rate: 0.0055541]
	Learning Rate: 0.00555412
	LOSS [training: 0.17663157943307617 | validation: 0.3460593599190313]
	TIME [epoch: 4.72 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23829648121334515		[learning rate: 0.0055296]
	Learning Rate: 0.00552958
	LOSS [training: 0.23829648121334515 | validation: 0.33984743831979997]
	TIME [epoch: 4.73 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18760605841785313		[learning rate: 0.0055052]
	Learning Rate: 0.00550515
	LOSS [training: 0.18760605841785313 | validation: 0.30808324465609804]
	TIME [epoch: 4.72 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1807242557359015		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 0.1807242557359015 | validation: 0.3146387064219104]
	TIME [epoch: 4.74 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1784753194636857		[learning rate: 0.0054566]
	Learning Rate: 0.00545661
	LOSS [training: 0.1784753194636857 | validation: 0.3047307278136974]
	TIME [epoch: 4.72 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1838479734665876		[learning rate: 0.0054325]
	Learning Rate: 0.0054325
	LOSS [training: 0.1838479734665876 | validation: 0.33168643803532605]
	TIME [epoch: 4.73 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19429566983447788		[learning rate: 0.0054085]
	Learning Rate: 0.0054085
	LOSS [training: 0.19429566983447788 | validation: 0.32380504944252464]
	TIME [epoch: 4.76 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18767859656109714		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 0.18767859656109714 | validation: 0.33899363140473043]
	TIME [epoch: 4.72 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1797539039901584		[learning rate: 0.0053608]
	Learning Rate: 0.00536081
	LOSS [training: 0.1797539039901584 | validation: 0.32299491498127353]
	TIME [epoch: 4.7 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16949838505734818		[learning rate: 0.0053371]
	Learning Rate: 0.00533713
	LOSS [training: 0.16949838505734818 | validation: 0.348889319645062]
	TIME [epoch: 4.72 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18086037563985774		[learning rate: 0.0053135]
	Learning Rate: 0.00531355
	LOSS [training: 0.18086037563985774 | validation: 0.2998238999221301]
	TIME [epoch: 4.75 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v7_20240712_122158/states/model_facs_v2_dec2b_2dpca_v7_183.pth
	Model improved!!!
EPOCH 184/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18039787799266455		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 0.18039787799266455 | validation: 0.33500307817193825]
	TIME [epoch: 4.73 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18993452845455236		[learning rate: 0.0052667]
	Learning Rate: 0.0052667
	LOSS [training: 0.18993452845455236 | validation: 0.35839677081319304]
	TIME [epoch: 4.71 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18469702231000767		[learning rate: 0.0052434]
	Learning Rate: 0.00524343
	LOSS [training: 0.18469702231000767 | validation: 0.36579085628553554]
	TIME [epoch: 4.76 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21258631559419222		[learning rate: 0.0052203]
	Learning Rate: 0.00522026
	LOSS [training: 0.21258631559419222 | validation: 0.32478157185853485]
	TIME [epoch: 4.73 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17381245685654506		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 0.17381245685654506 | validation: 0.31290993402491474]
	TIME [epoch: 4.75 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16917686316253014		[learning rate: 0.0051742]
	Learning Rate: 0.00517423
	LOSS [training: 0.16917686316253014 | validation: 0.3118266248222987]
	TIME [epoch: 4.76 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17143157993519373		[learning rate: 0.0051514]
	Learning Rate: 0.00515137
	LOSS [training: 0.17143157993519373 | validation: 0.3361236511251358]
	TIME [epoch: 4.74 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1804106090769443		[learning rate: 0.0051286]
	Learning Rate: 0.00512861
	LOSS [training: 0.1804106090769443 | validation: 0.3788322248194311]
	TIME [epoch: 4.72 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1974405386484937		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 0.1974405386484937 | validation: 0.29748477480562074]
	TIME [epoch: 4.79 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v7_20240712_122158/states/model_facs_v2_dec2b_2dpca_v7_192.pth
	Model improved!!!
EPOCH 193/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17328440335587778		[learning rate: 0.0050834]
	Learning Rate: 0.00508339
	LOSS [training: 0.17328440335587778 | validation: 0.3200964443469302]
	TIME [epoch: 4.73 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17803915485206231		[learning rate: 0.0050609]
	Learning Rate: 0.00506093
	LOSS [training: 0.17803915485206231 | validation: 0.31105854474858846]
	TIME [epoch: 4.71 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1711925404853386		[learning rate: 0.0050386]
	Learning Rate: 0.00503857
	LOSS [training: 0.1711925404853386 | validation: 0.32071575508394323]
	TIME [epoch: 4.7 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1830790598041287		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 0.1830790598041287 | validation: 0.31746630001484827]
	TIME [epoch: 4.74 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18324605680234357		[learning rate: 0.0049941]
	Learning Rate: 0.00499415
	LOSS [training: 0.18324605680234357 | validation: 0.3125538967468989]
	TIME [epoch: 4.71 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17336352775325198		[learning rate: 0.0049721]
	Learning Rate: 0.00497208
	LOSS [training: 0.17336352775325198 | validation: 0.2894816087549202]
	TIME [epoch: 4.74 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v7_20240712_122158/states/model_facs_v2_dec2b_2dpca_v7_198.pth
	Model improved!!!
EPOCH 199/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1840164554013352		[learning rate: 0.0049501]
	Learning Rate: 0.00495012
	LOSS [training: 0.1840164554013352 | validation: 0.31268469899155454]
	TIME [epoch: 4.73 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1759822134017655		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 0.1759822134017655 | validation: 0.3122141606246622]
	TIME [epoch: 4.7 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17771282152779738		[learning rate: 0.0049065]
	Learning Rate: 0.00490647
	LOSS [training: 0.17771282152779738 | validation: 0.3461597622065498]
	TIME [epoch: 4.71 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1974198423585737		[learning rate: 0.0048848]
	Learning Rate: 0.00488479
	LOSS [training: 0.1974198423585737 | validation: 0.3539948214865969]
	TIME [epoch: 4.74 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.176679870472861		[learning rate: 0.0048632]
	Learning Rate: 0.00486321
	LOSS [training: 0.176679870472861 | validation: 0.3116533998944212]
	TIME [epoch: 4.71 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17326926093019104		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 0.17326926093019104 | validation: 0.35629114927217914]
	TIME [epoch: 4.73 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1802707742521902		[learning rate: 0.0048203]
	Learning Rate: 0.00482033
	LOSS [training: 0.1802707742521902 | validation: 0.34302799205040907]
	TIME [epoch: 4.72 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17480073522917772		[learning rate: 0.004799]
	Learning Rate: 0.00479903
	LOSS [training: 0.17480073522917772 | validation: 0.35174467192461895]
	TIME [epoch: 4.71 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18182865513275784		[learning rate: 0.0047778]
	Learning Rate: 0.00477783
	LOSS [training: 0.18182865513275784 | validation: 0.33118614124791346]
	TIME [epoch: 4.7 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17631834888763995		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.17631834888763995 | validation: 0.32947135052929677]
	TIME [epoch: 4.71 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17621343560318165		[learning rate: 0.0047357]
	Learning Rate: 0.0047357
	LOSS [training: 0.17621343560318165 | validation: 0.34940725557202473]
	TIME [epoch: 4.72 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17572495391490647		[learning rate: 0.0047148]
	Learning Rate: 0.00471478
	LOSS [training: 0.17572495391490647 | validation: 0.29360573730746525]
	TIME [epoch: 4.7 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19195391112549554		[learning rate: 0.0046939]
	Learning Rate: 0.00469395
	LOSS [training: 0.19195391112549554 | validation: 0.3381213366077305]
	TIME [epoch: 4.72 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1875485397154392		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 0.1875485397154392 | validation: 0.3201488609213024]
	TIME [epoch: 4.77 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17429469219584395		[learning rate: 0.0046526]
	Learning Rate: 0.00465256
	LOSS [training: 0.17429469219584395 | validation: 0.29514382269365685]
	TIME [epoch: 4.72 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1775409841531525		[learning rate: 0.004632]
	Learning Rate: 0.00463201
	LOSS [training: 0.1775409841531525 | validation: 0.3136314618244778]
	TIME [epoch: 4.7 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1609533221023151		[learning rate: 0.0046115]
	Learning Rate: 0.00461154
	LOSS [training: 0.1609533221023151 | validation: 0.3275835040963383]
	TIME [epoch: 4.72 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1767724045545808		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 0.1767724045545808 | validation: 0.35368477020527633]
	TIME [epoch: 4.71 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1898479008902867		[learning rate: 0.0045709]
	Learning Rate: 0.00457088
	LOSS [training: 0.1898479008902867 | validation: 0.32131660866613176]
	TIME [epoch: 4.73 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1873637582138138		[learning rate: 0.0045507]
	Learning Rate: 0.00455069
	LOSS [training: 0.1873637582138138 | validation: 0.3188179728515902]
	TIME [epoch: 4.71 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16896079971255024		[learning rate: 0.0045306]
	Learning Rate: 0.00453058
	LOSS [training: 0.16896079971255024 | validation: 0.34622947568825957]
	TIME [epoch: 4.71 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18159893517761025		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 0.18159893517761025 | validation: 0.30085626171990226]
	TIME [epoch: 4.71 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17549470983199972		[learning rate: 0.0044906]
	Learning Rate: 0.00449063
	LOSS [training: 0.17549470983199972 | validation: 0.34978038491521934]
	TIME [epoch: 4.73 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17123053217037765		[learning rate: 0.0044708]
	Learning Rate: 0.00447079
	LOSS [training: 0.17123053217037765 | validation: 0.31800409134067714]
	TIME [epoch: 4.71 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1832322721512714		[learning rate: 0.004451]
	Learning Rate: 0.00445104
	LOSS [training: 0.1832322721512714 | validation: 0.33208715008215034]
	TIME [epoch: 4.71 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1771352595140485		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 0.1771352595140485 | validation: 0.3098842053977593]
	TIME [epoch: 4.72 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1753731678859851		[learning rate: 0.0044118]
	Learning Rate: 0.0044118
	LOSS [training: 0.1753731678859851 | validation: 0.3362869084431209]
	TIME [epoch: 4.7 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17511496862771422		[learning rate: 0.0043923]
	Learning Rate: 0.0043923
	LOSS [training: 0.17511496862771422 | validation: 0.31482859478105857]
	TIME [epoch: 4.71 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17382210357367658		[learning rate: 0.0043729]
	Learning Rate: 0.0043729
	LOSS [training: 0.17382210357367658 | validation: 0.33079702202795375]
	TIME [epoch: 4.71 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17202791935599038		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 0.17202791935599038 | validation: 0.3349114773915033]
	TIME [epoch: 4.71 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1787657833700137		[learning rate: 0.0043343]
	Learning Rate: 0.00433434
	LOSS [training: 0.1787657833700137 | validation: 0.3028653898153564]
	TIME [epoch: 4.71 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1686742358350891		[learning rate: 0.0043152]
	Learning Rate: 0.00431519
	LOSS [training: 0.1686742358350891 | validation: 0.3105854065783539]
	TIME [epoch: 4.74 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1751883875125227		[learning rate: 0.0042961]
	Learning Rate: 0.00429612
	LOSS [training: 0.1751883875125227 | validation: 0.30648541377305083]
	TIME [epoch: 4.71 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18314296502287508		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 0.18314296502287508 | validation: 0.31904934695279563]
	TIME [epoch: 4.7 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16992965553907502		[learning rate: 0.0042582]
	Learning Rate: 0.00425825
	LOSS [training: 0.16992965553907502 | validation: 0.3059629319117199]
	TIME [epoch: 4.71 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17227928162127118		[learning rate: 0.0042394]
	Learning Rate: 0.00423943
	LOSS [training: 0.17227928162127118 | validation: 0.3236495626492511]
	TIME [epoch: 4.72 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17048128124139436		[learning rate: 0.0042207]
	Learning Rate: 0.0042207
	LOSS [training: 0.17048128124139436 | validation: 0.31040482327133556]
	TIME [epoch: 4.7 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16900947152103213		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 0.16900947152103213 | validation: 0.3259605601558387]
	TIME [epoch: 4.71 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17221588366262724		[learning rate: 0.0041835]
	Learning Rate: 0.00418349
	LOSS [training: 0.17221588366262724 | validation: 0.33861096738599045]
	TIME [epoch: 4.72 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16074158395121146		[learning rate: 0.004165]
	Learning Rate: 0.004165
	LOSS [training: 0.16074158395121146 | validation: 0.31736414124993984]
	TIME [epoch: 4.71 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1894664215370907		[learning rate: 0.0041466]
	Learning Rate: 0.0041466
	LOSS [training: 0.1894664215370907 | validation: 0.31281371368174715]
	TIME [epoch: 4.7 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16924825503044968		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 0.16924825503044968 | validation: 0.3212626716470585]
	TIME [epoch: 4.7 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18280428356485962		[learning rate: 0.00411]
	Learning Rate: 0.00411004
	LOSS [training: 0.18280428356485962 | validation: 0.3263837094641159]
	TIME [epoch: 4.7 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17703346460189004		[learning rate: 0.0040919]
	Learning Rate: 0.00409188
	LOSS [training: 0.17703346460189004 | validation: 0.3309261370965448]
	TIME [epoch: 4.72 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16356741549436143		[learning rate: 0.0040738]
	Learning Rate: 0.0040738
	LOSS [training: 0.16356741549436143 | validation: 0.2872766334225622]
	TIME [epoch: 4.73 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v7_20240712_122158/states/model_facs_v2_dec2b_2dpca_v7_243.pth
	Model improved!!!
EPOCH 244/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16957807950083037		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.16957807950083037 | validation: 0.3091130951803943]
	TIME [epoch: 4.71 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17081124233723208		[learning rate: 0.0040379]
	Learning Rate: 0.00403788
	LOSS [training: 0.17081124233723208 | validation: 0.34543975524588877]
	TIME [epoch: 4.7 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16347896927231537		[learning rate: 0.00402]
	Learning Rate: 0.00402004
	LOSS [training: 0.16347896927231537 | validation: 0.3324304331224842]
	TIME [epoch: 4.72 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1632705873342941		[learning rate: 0.0040023]
	Learning Rate: 0.00400228
	LOSS [training: 0.1632705873342941 | validation: 0.3267432038844795]
	TIME [epoch: 4.71 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18389499472208498		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 0.18389499472208498 | validation: 0.33444985757151274]
	TIME [epoch: 4.71 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16537162967290095		[learning rate: 0.003967]
	Learning Rate: 0.00396699
	LOSS [training: 0.16537162967290095 | validation: 0.32339933594632464]
	TIME [epoch: 4.7 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17355597113544624		[learning rate: 0.0039495]
	Learning Rate: 0.00394947
	LOSS [training: 0.17355597113544624 | validation: 0.3258828663714132]
	TIME [epoch: 4.7 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17518943145430738		[learning rate: 0.003932]
	Learning Rate: 0.00393202
	LOSS [training: 0.17518943145430738 | validation: 0.32128630464850866]
	TIME [epoch: 4.7 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18190634595041275		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 0.18190634595041275 | validation: 0.3170262634628064]
	TIME [epoch: 4.7 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1721654129095814		[learning rate: 0.0038973]
	Learning Rate: 0.00389735
	LOSS [training: 0.1721654129095814 | validation: 0.31413697345344055]
	TIME [epoch: 4.72 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1753222646532528		[learning rate: 0.0038801]
	Learning Rate: 0.00388013
	LOSS [training: 0.1753222646532528 | validation: 0.3088805155370095]
	TIME [epoch: 4.7 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15970958591337142		[learning rate: 0.003863]
	Learning Rate: 0.00386299
	LOSS [training: 0.15970958591337142 | validation: 0.3395866243100237]
	TIME [epoch: 4.74 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16951728033576827		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 0.16951728033576827 | validation: 0.3194417195808548]
	TIME [epoch: 4.72 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16314711543597568		[learning rate: 0.0038289]
	Learning Rate: 0.00382893
	LOSS [training: 0.16314711543597568 | validation: 0.3117034377949919]
	TIME [epoch: 4.7 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17183388738475708		[learning rate: 0.003812]
	Learning Rate: 0.00381201
	LOSS [training: 0.17183388738475708 | validation: 0.32404767820422326]
	TIME [epoch: 4.7 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16338024107991017		[learning rate: 0.0037952]
	Learning Rate: 0.00379517
	LOSS [training: 0.16338024107991017 | validation: 0.32575184378267247]
	TIME [epoch: 4.71 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16652114348439162		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 0.16652114348439162 | validation: 0.294809817795663]
	TIME [epoch: 4.7 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.163250619216677		[learning rate: 0.0037617]
	Learning Rate: 0.0037617
	LOSS [training: 0.163250619216677 | validation: 0.3162646049459398]
	TIME [epoch: 4.71 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17557107276342782		[learning rate: 0.0037451]
	Learning Rate: 0.00374508
	LOSS [training: 0.17557107276342782 | validation: 0.3209299730310955]
	TIME [epoch: 4.71 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17423656986945082		[learning rate: 0.0037285]
	Learning Rate: 0.00372854
	LOSS [training: 0.17423656986945082 | validation: 0.325471434176938]
	TIME [epoch: 4.7 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15606613260614413		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 0.15606613260614413 | validation: 0.2880510379292079]
	TIME [epoch: 4.7 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17250575544632535		[learning rate: 0.0036957]
	Learning Rate: 0.00369566
	LOSS [training: 0.17250575544632535 | validation: 0.30051410403675455]
	TIME [epoch: 4.71 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1666441190735188		[learning rate: 0.0036793]
	Learning Rate: 0.00367933
	LOSS [training: 0.1666441190735188 | validation: 0.3132219536887355]
	TIME [epoch: 4.71 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1762640989564018		[learning rate: 0.0036631]
	Learning Rate: 0.00366308
	LOSS [training: 0.1762640989564018 | validation: 0.31554229366536923]
	TIME [epoch: 4.7 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1725050301397213		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 0.1725050301397213 | validation: 0.2859791722844066]
	TIME [epoch: 4.73 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v7_20240712_122158/states/model_facs_v2_dec2b_2dpca_v7_268.pth
	Model improved!!!
EPOCH 269/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16387557354762006		[learning rate: 0.0036308]
	Learning Rate: 0.00363078
	LOSS [training: 0.16387557354762006 | validation: 0.33881184925765157]
	TIME [epoch: 4.7 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16353299630461457		[learning rate: 0.0036147]
	Learning Rate: 0.00361474
	LOSS [training: 0.16353299630461457 | validation: 0.3128083995404963]
	TIME [epoch: 4.7 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16182965459509308		[learning rate: 0.0035988]
	Learning Rate: 0.00359877
	LOSS [training: 0.16182965459509308 | validation: 0.31759719981902473]
	TIME [epoch: 4.71 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17851395970638007		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 0.17851395970638007 | validation: 0.3065033030126094]
	TIME [epoch: 4.7 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16225793396336624		[learning rate: 0.003567]
	Learning Rate: 0.00356704
	LOSS [training: 0.16225793396336624 | validation: 0.34224461506292764]
	TIME [epoch: 4.7 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16753323555669825		[learning rate: 0.0035513]
	Learning Rate: 0.00355128
	LOSS [training: 0.16753323555669825 | validation: 0.3306250927729366]
	TIME [epoch: 4.71 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16339426761703318		[learning rate: 0.0035356]
	Learning Rate: 0.00353559
	LOSS [training: 0.16339426761703318 | validation: 0.2884542039165312]
	TIME [epoch: 4.73 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16203431711798447		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 0.16203431711798447 | validation: 0.3075345075659802]
	TIME [epoch: 4.7 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1758950958923677		[learning rate: 0.0035044]
	Learning Rate: 0.00350441
	LOSS [training: 0.1758950958923677 | validation: 0.3196129799617785]
	TIME [epoch: 4.7 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16668935050458686		[learning rate: 0.0034889]
	Learning Rate: 0.00348893
	LOSS [training: 0.16668935050458686 | validation: 0.38418149396937723]
	TIME [epoch: 4.73 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16992125297064664		[learning rate: 0.0034735]
	Learning Rate: 0.00347352
	LOSS [training: 0.16992125297064664 | validation: 0.3120038334006612]
	TIME [epoch: 4.71 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16687922493443125		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.16687922493443125 | validation: 0.34304691605716725]
	TIME [epoch: 4.72 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1598896758453205		[learning rate: 0.0034429]
	Learning Rate: 0.00344289
	LOSS [training: 0.1598896758453205 | validation: 0.28776563760926477]
	TIME [epoch: 4.72 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16392471098100744		[learning rate: 0.0034277]
	Learning Rate: 0.00342768
	LOSS [training: 0.16392471098100744 | validation: 0.30259308163794235]
	TIME [epoch: 4.7 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1744064745046237		[learning rate: 0.0034125]
	Learning Rate: 0.00341253
	LOSS [training: 0.1744064745046237 | validation: 0.29677341130375406]
	TIME [epoch: 4.72 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16840297577748653		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 0.16840297577748653 | validation: 0.3023311388304894]
	TIME [epoch: 4.71 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18419736779929055		[learning rate: 0.0033824]
	Learning Rate: 0.00338245
	LOSS [training: 0.18419736779929055 | validation: 0.28670899101307346]
	TIME [epoch: 4.71 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16486591732296965		[learning rate: 0.0033675]
	Learning Rate: 0.0033675
	LOSS [training: 0.16486591732296965 | validation: 0.2919492057764915]
	TIME [epoch: 4.7 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16397520597497883		[learning rate: 0.0033526]
	Learning Rate: 0.00335262
	LOSS [training: 0.16397520597497883 | validation: 0.3152555645613461]
	TIME [epoch: 4.71 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1693652870753785		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 0.1693652870753785 | validation: 0.355554779976415]
	TIME [epoch: 4.72 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1672562304294037		[learning rate: 0.0033231]
	Learning Rate: 0.00332306
	LOSS [training: 0.1672562304294037 | validation: 0.30853055701427434]
	TIME [epoch: 4.7 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16985775879375942		[learning rate: 0.0033084]
	Learning Rate: 0.00330838
	LOSS [training: 0.16985775879375942 | validation: 0.3116336653965479]
	TIME [epoch: 4.7 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1681425639514752		[learning rate: 0.0032938]
	Learning Rate: 0.00329376
	LOSS [training: 0.1681425639514752 | validation: 0.32570165754643915]
	TIME [epoch: 4.71 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16754683960532005		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 0.16754683960532005 | validation: 0.2958342409361368]
	TIME [epoch: 4.71 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16746984958312847		[learning rate: 0.0032647]
	Learning Rate: 0.00326472
	LOSS [training: 0.16746984958312847 | validation: 0.2998916924102843]
	TIME [epoch: 4.73 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1601618403257832		[learning rate: 0.0032503]
	Learning Rate: 0.0032503
	LOSS [training: 0.1601618403257832 | validation: 0.3075643097249069]
	TIME [epoch: 4.7 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1743738470043102		[learning rate: 0.0032359]
	Learning Rate: 0.00323594
	LOSS [training: 0.1743738470043102 | validation: 0.30891776465338117]
	TIME [epoch: 4.7 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16369790285255031		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 0.16369790285255031 | validation: 0.2905706936520621]
	TIME [epoch: 4.7 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15623983741724218		[learning rate: 0.0032074]
	Learning Rate: 0.00320741
	LOSS [training: 0.15623983741724218 | validation: 0.30380774950820066]
	TIME [epoch: 4.71 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16721006439782365		[learning rate: 0.0031932]
	Learning Rate: 0.00319323
	LOSS [training: 0.16721006439782365 | validation: 0.3248607096611461]
	TIME [epoch: 4.7 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16297603153683665		[learning rate: 0.0031791]
	Learning Rate: 0.00317913
	LOSS [training: 0.16297603153683665 | validation: 0.3007411233821424]
	TIME [epoch: 4.71 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15810846110055282		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 0.15810846110055282 | validation: 0.323620756859362]
	TIME [epoch: 4.7 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17023953074900605		[learning rate: 0.0031511]
	Learning Rate: 0.0031511
	LOSS [training: 0.17023953074900605 | validation: 0.2870583545514549]
	TIME [epoch: 4.71 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1639773641995438		[learning rate: 0.0031372]
	Learning Rate: 0.00313717
	LOSS [training: 0.1639773641995438 | validation: 0.32199704231442866]
	TIME [epoch: 4.71 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15522584736019798		[learning rate: 0.0031233]
	Learning Rate: 0.00312331
	LOSS [training: 0.15522584736019798 | validation: 0.3286166736909892]
	TIME [epoch: 4.72 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18223688010370032		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 0.18223688010370032 | validation: 0.3351153530125716]
	TIME [epoch: 4.71 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17453010606839572		[learning rate: 0.0030958]
	Learning Rate: 0.00309577
	LOSS [training: 0.17453010606839572 | validation: 0.28561109328702317]
	TIME [epoch: 4.7 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v7_20240712_122158/states/model_facs_v2_dec2b_2dpca_v7_305.pth
	Model improved!!!
EPOCH 306/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16296052423951124		[learning rate: 0.0030821]
	Learning Rate: 0.0030821
	LOSS [training: 0.16296052423951124 | validation: 0.3182456320684283]
	TIME [epoch: 4.75 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16076341520370044		[learning rate: 0.0030685]
	Learning Rate: 0.00306848
	LOSS [training: 0.16076341520370044 | validation: 0.32031822015305583]
	TIME [epoch: 4.72 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1618253191793793		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 0.1618253191793793 | validation: 0.32108964309520305]
	TIME [epoch: 4.72 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16395648642219687		[learning rate: 0.0030414]
	Learning Rate: 0.00304142
	LOSS [training: 0.16395648642219687 | validation: 0.2892478451406002]
	TIME [epoch: 4.73 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16189833054651842		[learning rate: 0.003028]
	Learning Rate: 0.00302799
	LOSS [training: 0.16189833054651842 | validation: 0.31578300060692377]
	TIME [epoch: 4.73 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1613732466391336		[learning rate: 0.0030146]
	Learning Rate: 0.00301461
	LOSS [training: 0.1613732466391336 | validation: 0.31237863001749555]
	TIME [epoch: 4.73 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1676252628137413		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 0.1676252628137413 | validation: 0.3222852779767087]
	TIME [epoch: 4.73 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16552823909233533		[learning rate: 0.002988]
	Learning Rate: 0.00298803
	LOSS [training: 0.16552823909233533 | validation: 0.30989393430718915]
	TIME [epoch: 4.72 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16444231470200638		[learning rate: 0.0029748]
	Learning Rate: 0.00297483
	LOSS [training: 0.16444231470200638 | validation: 0.30513103011326764]
	TIME [epoch: 4.77 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17109320001250938		[learning rate: 0.0029617]
	Learning Rate: 0.00296168
	LOSS [training: 0.17109320001250938 | validation: 0.3027149032743337]
	TIME [epoch: 4.75 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17441989191963395		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.17441989191963395 | validation: 0.3481642266832101]
	TIME [epoch: 4.72 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16345180272208795		[learning rate: 0.0029356]
	Learning Rate: 0.00293557
	LOSS [training: 0.16345180272208795 | validation: 0.3263223677578205]
	TIME [epoch: 4.75 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17250421896990722		[learning rate: 0.0029226]
	Learning Rate: 0.0029226
	LOSS [training: 0.17250421896990722 | validation: 0.31467339865569705]
	TIME [epoch: 4.76 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1724836470676194		[learning rate: 0.0029097]
	Learning Rate: 0.00290969
	LOSS [training: 0.1724836470676194 | validation: 0.3524670275823209]
	TIME [epoch: 4.73 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17202592199295513		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 0.17202592199295513 | validation: 0.29664053645851485]
	TIME [epoch: 4.73 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1617741033046261		[learning rate: 0.002884]
	Learning Rate: 0.00288403
	LOSS [training: 0.1617741033046261 | validation: 0.2963408991911781]
	TIME [epoch: 4.75 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15713232509712294		[learning rate: 0.0028713]
	Learning Rate: 0.00287129
	LOSS [training: 0.15713232509712294 | validation: 0.32190430558186817]
	TIME [epoch: 4.73 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15485788830806632		[learning rate: 0.0028586]
	Learning Rate: 0.0028586
	LOSS [training: 0.15485788830806632 | validation: 0.32149788031350046]
	TIME [epoch: 4.72 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17053259295840262		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 0.17053259295840262 | validation: 0.3030592987729965]
	TIME [epoch: 4.75 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16964646456552868		[learning rate: 0.0028334]
	Learning Rate: 0.0028334
	LOSS [training: 0.16964646456552868 | validation: 0.30256633563142804]
	TIME [epoch: 4.73 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1649595568020767		[learning rate: 0.0028209]
	Learning Rate: 0.00282088
	LOSS [training: 0.1649595568020767 | validation: 0.30636100651475207]
	TIME [epoch: 4.72 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1575628750094544		[learning rate: 0.0028084]
	Learning Rate: 0.00280842
	LOSS [training: 0.1575628750094544 | validation: 0.30553485814915793]
	TIME [epoch: 4.73 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16768863702264505		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 0.16768863702264505 | validation: 0.2919238695994347]
	TIME [epoch: 4.73 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15682851525031194		[learning rate: 0.0027837]
	Learning Rate: 0.00278366
	LOSS [training: 0.15682851525031194 | validation: 0.32878061896167143]
	TIME [epoch: 4.74 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1581882676155395		[learning rate: 0.0027714]
	Learning Rate: 0.00277136
	LOSS [training: 0.1581882676155395 | validation: 0.27231979247669397]
	TIME [epoch: 4.73 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v7_20240712_122158/states/model_facs_v2_dec2b_2dpca_v7_330.pth
	Model improved!!!
EPOCH 331/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14684653875162795		[learning rate: 0.0027591]
	Learning Rate: 0.00275911
	LOSS [training: 0.14684653875162795 | validation: 0.30242382153570135]
	TIME [epoch: 4.74 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15846103485052176		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 0.15846103485052176 | validation: 0.28653116326414946]
	TIME [epoch: 4.71 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16197615713567745		[learning rate: 0.0027348]
	Learning Rate: 0.00273478
	LOSS [training: 0.16197615713567745 | validation: 0.30563439090685074]
	TIME [epoch: 4.71 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16889026925786593		[learning rate: 0.0027227]
	Learning Rate: 0.0027227
	LOSS [training: 0.16889026925786593 | validation: 0.34319058634722555]
	TIME [epoch: 4.74 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16708765678010437		[learning rate: 0.0027107]
	Learning Rate: 0.00271067
	LOSS [training: 0.16708765678010437 | validation: 0.3222048934729448]
	TIME [epoch: 4.71 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16894004117037753		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 0.16894004117037753 | validation: 0.31233783357032263]
	TIME [epoch: 4.71 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16838553601356218		[learning rate: 0.0026868]
	Learning Rate: 0.00268677
	LOSS [training: 0.16838553601356218 | validation: 0.3132182299275257]
	TIME [epoch: 4.74 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15925160546103		[learning rate: 0.0026749]
	Learning Rate: 0.0026749
	LOSS [training: 0.15925160546103 | validation: 0.30155221526737025]
	TIME [epoch: 4.75 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1618938871884264		[learning rate: 0.0026631]
	Learning Rate: 0.00266308
	LOSS [training: 0.1618938871884264 | validation: 0.29988089585497035]
	TIME [epoch: 4.72 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16654237464624955		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 0.16654237464624955 | validation: 0.3064982612566712]
	TIME [epoch: 4.71 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17473644914112038		[learning rate: 0.0026396]
	Learning Rate: 0.0026396
	LOSS [training: 0.17473644914112038 | validation: 0.28600327676218795]
	TIME [epoch: 4.73 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17022429527350125		[learning rate: 0.0026279]
	Learning Rate: 0.00262794
	LOSS [training: 0.17022429527350125 | validation: 0.2850379188034726]
	TIME [epoch: 4.71 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15813552225937705		[learning rate: 0.0026163]
	Learning Rate: 0.00261633
	LOSS [training: 0.15813552225937705 | validation: 0.3044746273146531]
	TIME [epoch: 4.73 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1506410340444339		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 0.1506410340444339 | validation: 0.29179081446276545]
	TIME [epoch: 4.72 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16460903031236254		[learning rate: 0.0025933]
	Learning Rate: 0.00259326
	LOSS [training: 0.16460903031236254 | validation: 0.29001067667093183]
	TIME [epoch: 4.71 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15633306850349185		[learning rate: 0.0025818]
	Learning Rate: 0.0025818
	LOSS [training: 0.15633306850349185 | validation: 0.3062523822529975]
	TIME [epoch: 4.71 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1601537574465372		[learning rate: 0.0025704]
	Learning Rate: 0.0025704
	LOSS [training: 0.1601537574465372 | validation: 0.3070530268694012]
	TIME [epoch: 4.73 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16253201598832295		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.16253201598832295 | validation: 0.32056705539146585]
	TIME [epoch: 4.72 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1577618551730877		[learning rate: 0.0025477]
	Learning Rate: 0.00254773
	LOSS [training: 0.1577618551730877 | validation: 0.3310842306354232]
	TIME [epoch: 4.71 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1638893196330224		[learning rate: 0.0025365]
	Learning Rate: 0.00253648
	LOSS [training: 0.1638893196330224 | validation: 0.36017614832762873]
	TIME [epoch: 4.71 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16743055699745985		[learning rate: 0.0025253]
	Learning Rate: 0.00252527
	LOSS [training: 0.16743055699745985 | validation: 0.2983202572452337]
	TIME [epoch: 4.73 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16126539623473674		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.16126539623473674 | validation: 0.3084263576904189]
	TIME [epoch: 4.71 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16684835924455296		[learning rate: 0.002503]
	Learning Rate: 0.002503
	LOSS [training: 0.16684835924455296 | validation: 0.305211233955855]
	TIME [epoch: 4.71 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16394582326478507		[learning rate: 0.0024919]
	Learning Rate: 0.00249194
	LOSS [training: 0.16394582326478507 | validation: 0.3156806611931235]
	TIME [epoch: 4.73 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1626671292413473		[learning rate: 0.0024809]
	Learning Rate: 0.00248093
	LOSS [training: 0.1626671292413473 | validation: 0.3189417556500347]
	TIME [epoch: 4.72 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15935129498248216		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 0.15935129498248216 | validation: 0.309330964868887]
	TIME [epoch: 4.72 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1618865567063861		[learning rate: 0.0024591]
	Learning Rate: 0.00245906
	LOSS [training: 0.1618865567063861 | validation: 0.3245047500317842]
	TIME [epoch: 4.72 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1542565213176535		[learning rate: 0.0024482]
	Learning Rate: 0.0024482
	LOSS [training: 0.1542565213176535 | validation: 0.29483957620305173]
	TIME [epoch: 4.74 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15736865760174773		[learning rate: 0.0024374]
	Learning Rate: 0.00243738
	LOSS [training: 0.15736865760174773 | validation: 0.3156221840833989]
	TIME [epoch: 4.71 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16789644968008127		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.16789644968008127 | validation: 0.33926069608739257]
	TIME [epoch: 4.71 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16116826150916488		[learning rate: 0.0024159]
	Learning Rate: 0.00241589
	LOSS [training: 0.16116826150916488 | validation: 0.31013156056859614]
	TIME [epoch: 4.72 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15972051305057514		[learning rate: 0.0024052]
	Learning Rate: 0.00240521
	LOSS [training: 0.15972051305057514 | validation: 0.3095140500623913]
	TIME [epoch: 4.71 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16945307979867166		[learning rate: 0.0023946]
	Learning Rate: 0.00239459
	LOSS [training: 0.16945307979867166 | validation: 0.30623900395252335]
	TIME [epoch: 4.71 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16858980639871363		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 0.16858980639871363 | validation: 0.2834297838335304]
	TIME [epoch: 4.72 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1645967949792769		[learning rate: 0.0023735]
	Learning Rate: 0.00237347
	LOSS [training: 0.1645967949792769 | validation: 0.2992354858458049]
	TIME [epoch: 4.71 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16675487734304323		[learning rate: 0.002363]
	Learning Rate: 0.00236299
	LOSS [training: 0.16675487734304323 | validation: 0.3280315338098211]
	TIME [epoch: 4.72 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16304366141112095		[learning rate: 0.0023525]
	Learning Rate: 0.00235255
	LOSS [training: 0.16304366141112095 | validation: 0.3020316449210565]
	TIME [epoch: 4.71 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15609908168568404		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.15609908168568404 | validation: 0.3134787412718776]
	TIME [epoch: 4.75 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1603607468657638		[learning rate: 0.0023318]
	Learning Rate: 0.00233181
	LOSS [training: 0.1603607468657638 | validation: 0.31971881687262094]
	TIME [epoch: 4.72 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16116348044426668		[learning rate: 0.0023215]
	Learning Rate: 0.0023215
	LOSS [training: 0.16116348044426668 | validation: 0.303069310268961]
	TIME [epoch: 4.71 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.165758913127958		[learning rate: 0.0023112]
	Learning Rate: 0.00231125
	LOSS [training: 0.165758913127958 | validation: 0.3155309489320869]
	TIME [epoch: 4.73 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16665572744074866		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.16665572744074866 | validation: 0.31532807879387925]
	TIME [epoch: 4.71 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16543221466404925		[learning rate: 0.0022909]
	Learning Rate: 0.00229087
	LOSS [training: 0.16543221466404925 | validation: 0.3045069181537038]
	TIME [epoch: 4.71 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1616526895046012		[learning rate: 0.0022807]
	Learning Rate: 0.00228075
	LOSS [training: 0.1616526895046012 | validation: 0.28766192464606544]
	TIME [epoch: 4.71 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1544629394789932		[learning rate: 0.0022707]
	Learning Rate: 0.00227067
	LOSS [training: 0.1544629394789932 | validation: 0.3029644701316328]
	TIME [epoch: 4.75 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1581179174713827		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.1581179174713827 | validation: 0.2910903423117079]
	TIME [epoch: 4.72 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16633826430343537		[learning rate: 0.0022506]
	Learning Rate: 0.00225065
	LOSS [training: 0.16633826430343537 | validation: 0.3073303866374196]
	TIME [epoch: 4.7 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15463452272422207		[learning rate: 0.0022407]
	Learning Rate: 0.0022407
	LOSS [training: 0.15463452272422207 | validation: 0.3071180321479683]
	TIME [epoch: 4.7 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1619973412856838		[learning rate: 0.0022308]
	Learning Rate: 0.0022308
	LOSS [training: 0.1619973412856838 | validation: 0.3031399513430581]
	TIME [epoch: 4.74 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1571525490264994		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.1571525490264994 | validation: 0.31476143294568176]
	TIME [epoch: 4.72 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15207006236695472		[learning rate: 0.0022111]
	Learning Rate: 0.00221114
	LOSS [training: 0.15207006236695472 | validation: 0.33252222170435985]
	TIME [epoch: 4.72 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16432040993109656		[learning rate: 0.0022014]
	Learning Rate: 0.00220137
	LOSS [training: 0.16432040993109656 | validation: 0.29968412520779103]
	TIME [epoch: 4.71 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15852919852867198		[learning rate: 0.0021916]
	Learning Rate: 0.00219164
	LOSS [training: 0.15852919852867198 | validation: 0.3157541326989033]
	TIME [epoch: 4.71 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16049115740247338		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.16049115740247338 | validation: 0.28839582946786696]
	TIME [epoch: 4.71 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16268102946014076		[learning rate: 0.0021723]
	Learning Rate: 0.00217232
	LOSS [training: 0.16268102946014076 | validation: 0.32262832150143533]
	TIME [epoch: 4.71 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15086148020161985		[learning rate: 0.0021627]
	Learning Rate: 0.00216272
	LOSS [training: 0.15086148020161985 | validation: 0.3193403681745415]
	TIME [epoch: 4.71 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15397073294990707		[learning rate: 0.0021532]
	Learning Rate: 0.00215316
	LOSS [training: 0.15397073294990707 | validation: 0.30342922147967827]
	TIME [epoch: 4.7 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15784447810434873		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.15784447810434873 | validation: 0.3266545239570701]
	TIME [epoch: 4.71 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15802137975536837		[learning rate: 0.0021342]
	Learning Rate: 0.00213418
	LOSS [training: 0.15802137975536837 | validation: 0.3051287834116609]
	TIME [epoch: 4.7 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16177716739099104		[learning rate: 0.0021247]
	Learning Rate: 0.00212475
	LOSS [training: 0.16177716739099104 | validation: 0.30690665723670063]
	TIME [epoch: 4.71 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1539969094441963		[learning rate: 0.0021154]
	Learning Rate: 0.00211536
	LOSS [training: 0.1539969094441963 | validation: 0.30038411582226854]
	TIME [epoch: 4.7 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1592969253187266		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.1592969253187266 | validation: 0.31758730687769127]
	TIME [epoch: 4.72 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15592531856728498		[learning rate: 0.0020967]
	Learning Rate: 0.00209671
	LOSS [training: 0.15592531856728498 | validation: 0.30525082437161666]
	TIME [epoch: 4.71 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16211109541746185		[learning rate: 0.0020874]
	Learning Rate: 0.00208745
	LOSS [training: 0.16211109541746185 | validation: 0.29065644494754944]
	TIME [epoch: 4.72 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15742777531093183		[learning rate: 0.0020782]
	Learning Rate: 0.00207822
	LOSS [training: 0.15742777531093183 | validation: 0.3134344245800107]
	TIME [epoch: 4.71 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1613005329985792		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.1613005329985792 | validation: 0.2933626345181012]
	TIME [epoch: 4.7 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16136841427144505		[learning rate: 0.0020599]
	Learning Rate: 0.0020599
	LOSS [training: 0.16136841427144505 | validation: 0.2949844305548606]
	TIME [epoch: 4.71 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15579526250774317		[learning rate: 0.0020508]
	Learning Rate: 0.0020508
	LOSS [training: 0.15579526250774317 | validation: 0.32179911267851125]
	TIME [epoch: 4.71 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15921682819639088		[learning rate: 0.0020417]
	Learning Rate: 0.00204174
	LOSS [training: 0.15921682819639088 | validation: 0.32004575295703236]
	TIME [epoch: 4.7 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1522120957613539		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.1522120957613539 | validation: 0.30477389173432395]
	TIME [epoch: 4.71 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16709222081113767		[learning rate: 0.0020237]
	Learning Rate: 0.00202374
	LOSS [training: 0.16709222081113767 | validation: 0.2965157088874806]
	TIME [epoch: 4.72 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1702344312468332		[learning rate: 0.0020148]
	Learning Rate: 0.00201479
	LOSS [training: 0.1702344312468332 | validation: 0.2868816512608898]
	TIME [epoch: 4.71 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1592412958747634		[learning rate: 0.0020059]
	Learning Rate: 0.00200589
	LOSS [training: 0.1592412958747634 | validation: 0.3002119964601106]
	TIME [epoch: 4.7 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16099733726701074		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.16099733726701074 | validation: 0.2904808731198727]
	TIME [epoch: 4.71 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16248979545288894		[learning rate: 0.0019882]
	Learning Rate: 0.00198821
	LOSS [training: 0.16248979545288894 | validation: 0.28714162853775677]
	TIME [epoch: 4.71 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1644579925856908		[learning rate: 0.0019794]
	Learning Rate: 0.00197942
	LOSS [training: 0.1644579925856908 | validation: 0.2843140514488823]
	TIME [epoch: 4.7 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14926890012965802		[learning rate: 0.0019707]
	Learning Rate: 0.00197068
	LOSS [training: 0.14926890012965802 | validation: 0.3095614694271942]
	TIME [epoch: 4.71 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16028384997523118		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.16028384997523118 | validation: 0.34546744960236997]
	TIME [epoch: 4.7 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16548518979454646		[learning rate: 0.0019533]
	Learning Rate: 0.0019533
	LOSS [training: 0.16548518979454646 | validation: 0.30278862605716567]
	TIME [epoch: 4.7 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15341315064608296		[learning rate: 0.0019447]
	Learning Rate: 0.00194467
	LOSS [training: 0.15341315064608296 | validation: 0.2949493359792445]
	TIME [epoch: 4.71 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15546593205090473		[learning rate: 0.0019361]
	Learning Rate: 0.00193608
	LOSS [training: 0.15546593205090473 | validation: 0.2849163774597354]
	TIME [epoch: 4.71 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1607316351640671		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.1607316351640671 | validation: 0.30205031159840695]
	TIME [epoch: 4.7 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15712164778792956		[learning rate: 0.001919]
	Learning Rate: 0.00191901
	LOSS [training: 0.15712164778792956 | validation: 0.31238434600454323]
	TIME [epoch: 4.71 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16080887162917862		[learning rate: 0.0019105]
	Learning Rate: 0.00191053
	LOSS [training: 0.16080887162917862 | validation: 0.31116524507481086]
	TIME [epoch: 4.71 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16549802338902678		[learning rate: 0.0019021]
	Learning Rate: 0.00190209
	LOSS [training: 0.16549802338902678 | validation: 0.31310975743548336]
	TIME [epoch: 4.7 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15750719071293548		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.15750719071293548 | validation: 0.30179973263332116]
	TIME [epoch: 4.71 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17069278381432512		[learning rate: 0.0018853]
	Learning Rate: 0.00188532
	LOSS [training: 0.17069278381432512 | validation: 0.3177660882200607]
	TIME [epoch: 4.7 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15929650300047254		[learning rate: 0.001877]
	Learning Rate: 0.00187699
	LOSS [training: 0.15929650300047254 | validation: 0.2943869039700617]
	TIME [epoch: 4.7 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16209784749277373		[learning rate: 0.0018687]
	Learning Rate: 0.0018687
	LOSS [training: 0.16209784749277373 | validation: 0.2987481619417452]
	TIME [epoch: 4.72 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15934926554528003		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.15934926554528003 | validation: 0.3118459588940905]
	TIME [epoch: 4.72 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16108095600663191		[learning rate: 0.0018522]
	Learning Rate: 0.00185222
	LOSS [training: 0.16108095600663191 | validation: 0.3062511232807553]
	TIME [epoch: 4.7 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16107667108655072		[learning rate: 0.001844]
	Learning Rate: 0.00184404
	LOSS [training: 0.16107667108655072 | validation: 0.28782436582054716]
	TIME [epoch: 4.71 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15497028050813752		[learning rate: 0.0018359]
	Learning Rate: 0.00183589
	LOSS [training: 0.15497028050813752 | validation: 0.30200772296927947]
	TIME [epoch: 4.7 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1614113470144612		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.1614113470144612 | validation: 0.2904636729217449]
	TIME [epoch: 4.7 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1496686971766787		[learning rate: 0.0018197]
	Learning Rate: 0.0018197
	LOSS [training: 0.1496686971766787 | validation: 0.310349952793947]
	TIME [epoch: 4.7 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1615241813948456		[learning rate: 0.0018117]
	Learning Rate: 0.00181166
	LOSS [training: 0.1615241813948456 | validation: 0.32885630435522173]
	TIME [epoch: 4.71 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16329159512746103		[learning rate: 0.0018037]
	Learning Rate: 0.00180366
	LOSS [training: 0.16329159512746103 | validation: 0.316227290109126]
	TIME [epoch: 4.7 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16230289512777302		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.16230289512777302 | validation: 0.2843539889751855]
	TIME [epoch: 4.71 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16261413604303643		[learning rate: 0.0017878]
	Learning Rate: 0.00178775
	LOSS [training: 0.16261413604303643 | validation: 0.2997591453491948]
	TIME [epoch: 4.71 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16057350776267132		[learning rate: 0.0017799]
	Learning Rate: 0.00177985
	LOSS [training: 0.16057350776267132 | validation: 0.3100013781171686]
	TIME [epoch: 4.71 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16218009050898205		[learning rate: 0.001772]
	Learning Rate: 0.00177199
	LOSS [training: 0.16218009050898205 | validation: 0.30499157149591943]
	TIME [epoch: 4.7 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15838037814729738		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.15838037814729738 | validation: 0.29133358098911405]
	TIME [epoch: 4.71 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1609183344817831		[learning rate: 0.0017564]
	Learning Rate: 0.00175637
	LOSS [training: 0.1609183344817831 | validation: 0.31818720772176823]
	TIME [epoch: 4.7 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1673595805302046		[learning rate: 0.0017486]
	Learning Rate: 0.00174861
	LOSS [training: 0.1673595805302046 | validation: 0.2911044999047422]
	TIME [epoch: 4.71 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1596000864084935		[learning rate: 0.0017409]
	Learning Rate: 0.00174088
	LOSS [training: 0.1596000864084935 | validation: 0.29545129037440804]
	TIME [epoch: 4.71 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16134114758670434		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.16134114758670434 | validation: 0.30571076574094636]
	TIME [epoch: 4.7 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1591124736837008		[learning rate: 0.0017255]
	Learning Rate: 0.00172553
	LOSS [training: 0.1591124736837008 | validation: 0.32160098580900176]
	TIME [epoch: 4.71 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15684714504045164		[learning rate: 0.0017179]
	Learning Rate: 0.00171791
	LOSS [training: 0.15684714504045164 | validation: 0.2929522301874879]
	TIME [epoch: 4.71 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.160425571264247		[learning rate: 0.0017103]
	Learning Rate: 0.00171032
	LOSS [training: 0.160425571264247 | validation: 0.2856224961528378]
	TIME [epoch: 4.71 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15457522928470513		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.15457522928470513 | validation: 0.29128951575395945]
	TIME [epoch: 4.7 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.163264234530662		[learning rate: 0.0016952]
	Learning Rate: 0.00169524
	LOSS [training: 0.163264234530662 | validation: 0.2978935401977122]
	TIME [epoch: 4.7 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15602013863463593		[learning rate: 0.0016877]
	Learning Rate: 0.00168775
	LOSS [training: 0.15602013863463593 | validation: 0.3138498455524889]
	TIME [epoch: 4.71 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16240218622167946		[learning rate: 0.0016803]
	Learning Rate: 0.00168029
	LOSS [training: 0.16240218622167946 | validation: 0.31932845279311906]
	TIME [epoch: 4.7 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1578768826765201		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.1578768826765201 | validation: 0.2829001558065177]
	TIME [epoch: 4.7 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1608409252391278		[learning rate: 0.0016655]
	Learning Rate: 0.00166548
	LOSS [training: 0.1608409252391278 | validation: 0.29909628942310895]
	TIME [epoch: 4.72 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16028761913974507		[learning rate: 0.0016581]
	Learning Rate: 0.00165812
	LOSS [training: 0.16028761913974507 | validation: 0.29495232529442106]
	TIME [epoch: 4.71 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16811214260168678		[learning rate: 0.0016508]
	Learning Rate: 0.00165079
	LOSS [training: 0.16811214260168678 | validation: 0.30048567509950314]
	TIME [epoch: 4.71 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16183940841436426		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.16183940841436426 | validation: 0.2901707280219324]
	TIME [epoch: 4.7 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.163215836607076		[learning rate: 0.0016362]
	Learning Rate: 0.00163624
	LOSS [training: 0.163215836607076 | validation: 0.28468561671029075]
	TIME [epoch: 4.71 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1575560335521113		[learning rate: 0.001629]
	Learning Rate: 0.00162901
	LOSS [training: 0.1575560335521113 | validation: 0.2893904592169098]
	TIME [epoch: 4.71 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1623346190695555		[learning rate: 0.0016218]
	Learning Rate: 0.00162181
	LOSS [training: 0.1623346190695555 | validation: 0.2988524825346824]
	TIME [epoch: 4.71 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15913591596599685		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.15913591596599685 | validation: 0.28979062483212664]
	TIME [epoch: 4.71 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16428195376704724		[learning rate: 0.0016075]
	Learning Rate: 0.00160751
	LOSS [training: 0.16428195376704724 | validation: 0.2977930869110089]
	TIME [epoch: 4.71 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1598368172032315		[learning rate: 0.0016004]
	Learning Rate: 0.00160041
	LOSS [training: 0.1598368172032315 | validation: 0.28928225748350617]
	TIME [epoch: 4.71 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15914125614719538		[learning rate: 0.0015933]
	Learning Rate: 0.00159334
	LOSS [training: 0.15914125614719538 | validation: 0.30724780964566845]
	TIME [epoch: 4.71 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15455130698818126		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.15455130698818126 | validation: 0.30703690162248415]
	TIME [epoch: 4.71 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15542775692038985		[learning rate: 0.0015793]
	Learning Rate: 0.00157929
	LOSS [training: 0.15542775692038985 | validation: 0.28470954826241285]
	TIME [epoch: 4.7 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15753888689382597		[learning rate: 0.0015723]
	Learning Rate: 0.00157231
	LOSS [training: 0.15753888689382597 | validation: 0.30588735986424853]
	TIME [epoch: 4.75 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15985036669992042		[learning rate: 0.0015654]
	Learning Rate: 0.00156536
	LOSS [training: 0.15985036669992042 | validation: 0.3067799562505464]
	TIME [epoch: 4.71 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15472348233368577		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.15472348233368577 | validation: 0.29718033925143195]
	TIME [epoch: 4.7 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16136091749352635		[learning rate: 0.0015516]
	Learning Rate: 0.00155156
	LOSS [training: 0.16136091749352635 | validation: 0.3113729953723404]
	TIME [epoch: 4.7 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1568214936104671		[learning rate: 0.0015447]
	Learning Rate: 0.00154471
	LOSS [training: 0.1568214936104671 | validation: 0.30833637053414037]
	TIME [epoch: 4.7 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.159817162651456		[learning rate: 0.0015379]
	Learning Rate: 0.00153788
	LOSS [training: 0.159817162651456 | validation: 0.310065385496905]
	TIME [epoch: 4.71 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16008333575633232		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.16008333575633232 | validation: 0.3095159767635397]
	TIME [epoch: 4.72 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16295024680123232		[learning rate: 0.0015243]
	Learning Rate: 0.00152432
	LOSS [training: 0.16295024680123232 | validation: 0.30296496449374133]
	TIME [epoch: 4.71 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16299379143894804		[learning rate: 0.0015176]
	Learning Rate: 0.00151759
	LOSS [training: 0.16299379143894804 | validation: 0.3163812016977952]
	TIME [epoch: 4.71 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15793738978200045		[learning rate: 0.0015109]
	Learning Rate: 0.00151088
	LOSS [training: 0.15793738978200045 | validation: 0.3068354686646552]
	TIME [epoch: 4.7 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1540103358242123		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.1540103358242123 | validation: 0.2913660007931556]
	TIME [epoch: 4.71 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15407257831459029		[learning rate: 0.0014976]
	Learning Rate: 0.00149756
	LOSS [training: 0.15407257831459029 | validation: 0.2896283552804821]
	TIME [epoch: 4.7 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16115975606271854		[learning rate: 0.0014909]
	Learning Rate: 0.00149094
	LOSS [training: 0.16115975606271854 | validation: 0.3275794694335935]
	TIME [epoch: 4.72 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1550662047513434		[learning rate: 0.0014844]
	Learning Rate: 0.00148436
	LOSS [training: 0.1550662047513434 | validation: 0.3041551309115312]
	TIME [epoch: 4.71 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16385932972530606		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.16385932972530606 | validation: 0.30418633280398566]
	TIME [epoch: 4.71 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15988226685271698		[learning rate: 0.0014713]
	Learning Rate: 0.00147127
	LOSS [training: 0.15988226685271698 | validation: 0.3096556787921089]
	TIME [epoch: 4.71 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15655657069691342		[learning rate: 0.0014648]
	Learning Rate: 0.00146477
	LOSS [training: 0.15655657069691342 | validation: 0.30441297818600643]
	TIME [epoch: 4.71 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15404219718018355		[learning rate: 0.0014583]
	Learning Rate: 0.0014583
	LOSS [training: 0.15404219718018355 | validation: 0.3017863034146438]
	TIME [epoch: 4.7 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15617747814704583		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.15617747814704583 | validation: 0.2888406714724426]
	TIME [epoch: 4.7 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1554827051979367		[learning rate: 0.0014454]
	Learning Rate: 0.00144544
	LOSS [training: 0.1554827051979367 | validation: 0.31739890908069857]
	TIME [epoch: 4.72 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1584528294868272		[learning rate: 0.0014391]
	Learning Rate: 0.00143905
	LOSS [training: 0.1584528294868272 | validation: 0.29618706182890875]
	TIME [epoch: 4.71 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16245850330017167		[learning rate: 0.0014327]
	Learning Rate: 0.0014327
	LOSS [training: 0.16245850330017167 | validation: 0.30101770171153475]
	TIME [epoch: 4.7 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15089307885526032		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.15089307885526032 | validation: 0.2824401636318577]
	TIME [epoch: 4.7 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.160946651836071		[learning rate: 0.0014201]
	Learning Rate: 0.00142006
	LOSS [training: 0.160946651836071 | validation: 0.2888235241038417]
	TIME [epoch: 4.71 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1549944360364767		[learning rate: 0.0014138]
	Learning Rate: 0.00141379
	LOSS [training: 0.1549944360364767 | validation: 0.29267161902078503]
	TIME [epoch: 4.71 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15960626321709234		[learning rate: 0.0014075]
	Learning Rate: 0.00140754
	LOSS [training: 0.15960626321709234 | validation: 0.30043064942732145]
	TIME [epoch: 4.76 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15674870894191997		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.15674870894191997 | validation: 0.2992386309739786]
	TIME [epoch: 4.72 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16303681929118602		[learning rate: 0.0013951]
	Learning Rate: 0.00139513
	LOSS [training: 0.16303681929118602 | validation: 0.29370232997312407]
	TIME [epoch: 4.7 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15460327001326238		[learning rate: 0.001389]
	Learning Rate: 0.00138897
	LOSS [training: 0.15460327001326238 | validation: 0.29849357672326887]
	TIME [epoch: 4.71 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1651743594691733		[learning rate: 0.0013828]
	Learning Rate: 0.00138283
	LOSS [training: 0.1651743594691733 | validation: 0.30578455163339907]
	TIME [epoch: 4.71 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15439886750765974		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.15439886750765974 | validation: 0.29481640479398835]
	TIME [epoch: 4.71 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16260929632276358		[learning rate: 0.0013706]
	Learning Rate: 0.00137064
	LOSS [training: 0.16260929632276358 | validation: 0.32884303199141257]
	TIME [epoch: 4.71 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1580683178877944		[learning rate: 0.0013646]
	Learning Rate: 0.00136458
	LOSS [training: 0.1580683178877944 | validation: 0.2929395984398997]
	TIME [epoch: 4.72 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15537269391265784		[learning rate: 0.0013586]
	Learning Rate: 0.00135855
	LOSS [training: 0.15537269391265784 | validation: 0.3066057157341116]
	TIME [epoch: 4.71 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15818219813533677		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.15818219813533677 | validation: 0.31202249864023945]
	TIME [epoch: 4.75 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.156017170884515		[learning rate: 0.0013466]
	Learning Rate: 0.00134658
	LOSS [training: 0.156017170884515 | validation: 0.3076300537607487]
	TIME [epoch: 4.71 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17006594065509875		[learning rate: 0.0013406]
	Learning Rate: 0.00134063
	LOSS [training: 0.17006594065509875 | validation: 0.2784968370902645]
	TIME [epoch: 4.71 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1576263036062032		[learning rate: 0.0013347]
	Learning Rate: 0.0013347
	LOSS [training: 0.1576263036062032 | validation: 0.30883396318368456]
	TIME [epoch: 4.71 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15266712721033604		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.15266712721033604 | validation: 0.31715323584006977]
	TIME [epoch: 4.72 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15808260456479148		[learning rate: 0.0013229]
	Learning Rate: 0.00132293
	LOSS [training: 0.15808260456479148 | validation: 0.3028024721289778]
	TIME [epoch: 4.75 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16482072025386332		[learning rate: 0.0013171]
	Learning Rate: 0.00131709
	LOSS [training: 0.16482072025386332 | validation: 0.30035983068272165]
	TIME [epoch: 4.71 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15078915706090718		[learning rate: 0.0013113]
	Learning Rate: 0.00131127
	LOSS [training: 0.15078915706090718 | validation: 0.3169366732246351]
	TIME [epoch: 4.74 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15879175986641042		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.15879175986641042 | validation: 0.2990862144977251]
	TIME [epoch: 4.74 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15206148974303074		[learning rate: 0.0012997]
	Learning Rate: 0.00129971
	LOSS [training: 0.15206148974303074 | validation: 0.30220707010519465]
	TIME [epoch: 30.1 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14798560273855738		[learning rate: 0.001294]
	Learning Rate: 0.00129397
	LOSS [training: 0.14798560273855738 | validation: 0.31187172555794046]
	TIME [epoch: 9.08 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16006389952892378		[learning rate: 0.0012882]
	Learning Rate: 0.00128825
	LOSS [training: 0.16006389952892378 | validation: 0.29414816693336515]
	TIME [epoch: 9.06 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15696788476094975		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.15696788476094975 | validation: 0.28137976924998803]
	TIME [epoch: 9.05 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15788045048537208		[learning rate: 0.0012769]
	Learning Rate: 0.00127689
	LOSS [training: 0.15788045048537208 | validation: 0.304137237293531]
	TIME [epoch: 9.06 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1592018362750645		[learning rate: 0.0012712]
	Learning Rate: 0.00127125
	LOSS [training: 0.1592018362750645 | validation: 0.31428722056894204]
	TIME [epoch: 9.07 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15670236047169117		[learning rate: 0.0012656]
	Learning Rate: 0.00126563
	LOSS [training: 0.15670236047169117 | validation: 0.3089848267228467]
	TIME [epoch: 9.05 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15772491807952363		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.15772491807952363 | validation: 0.30187175685701995]
	TIME [epoch: 9.06 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15370682482494952		[learning rate: 0.0012545]
	Learning Rate: 0.00125447
	LOSS [training: 0.15370682482494952 | validation: 0.2958989175586274]
	TIME [epoch: 9.07 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16310512129608618		[learning rate: 0.0012489]
	Learning Rate: 0.00124893
	LOSS [training: 0.16310512129608618 | validation: 0.31112886474306956]
	TIME [epoch: 9.05 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15363021470478314		[learning rate: 0.0012434]
	Learning Rate: 0.00124341
	LOSS [training: 0.15363021470478314 | validation: 0.31589423569917974]
	TIME [epoch: 9.05 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.161180948857161		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.161180948857161 | validation: 0.3013220535232563]
	TIME [epoch: 9.06 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15899368282115092		[learning rate: 0.0012324]
	Learning Rate: 0.00123245
	LOSS [training: 0.15899368282115092 | validation: 0.2921583437989199]
	TIME [epoch: 9.06 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1564759393541611		[learning rate: 0.001227]
	Learning Rate: 0.001227
	LOSS [training: 0.1564759393541611 | validation: 0.3123398555764179]
	TIME [epoch: 9.06 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15004725221642895		[learning rate: 0.0012216]
	Learning Rate: 0.00122158
	LOSS [training: 0.15004725221642895 | validation: 0.29779643389966737]
	TIME [epoch: 9.08 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15550626046740068		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.15550626046740068 | validation: 0.31357249925563296]
	TIME [epoch: 9.08 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15866148133951122		[learning rate: 0.0012108]
	Learning Rate: 0.00121081
	LOSS [training: 0.15866148133951122 | validation: 0.29892299726342253]
	TIME [epoch: 9.04 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15569807400859997		[learning rate: 0.0012055]
	Learning Rate: 0.00120546
	LOSS [training: 0.15569807400859997 | validation: 0.3237858759042137]
	TIME [epoch: 9.06 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16096627180228135		[learning rate: 0.0012001]
	Learning Rate: 0.00120014
	LOSS [training: 0.16096627180228135 | validation: 0.30816964150322707]
	TIME [epoch: 9.06 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15700867385506484		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.15700867385506484 | validation: 0.3030229779993426]
	TIME [epoch: 9.05 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1541544325149723		[learning rate: 0.0011896]
	Learning Rate: 0.00118956
	LOSS [training: 0.1541544325149723 | validation: 0.28630827587377283]
	TIME [epoch: 9.05 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16442191749641555		[learning rate: 0.0011843]
	Learning Rate: 0.0011843
	LOSS [training: 0.16442191749641555 | validation: 0.29864682495568673]
	TIME [epoch: 9.07 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15350135975896426		[learning rate: 0.0011791]
	Learning Rate: 0.00117907
	LOSS [training: 0.15350135975896426 | validation: 0.3152574333925865]
	TIME [epoch: 9.06 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15974135895778627		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.15974135895778627 | validation: 0.308042380999181]
	TIME [epoch: 9.05 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1654641372800115		[learning rate: 0.0011687]
	Learning Rate: 0.00116867
	LOSS [training: 0.1654641372800115 | validation: 0.3214458701272689]
	TIME [epoch: 9.06 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14923727917832402		[learning rate: 0.0011635]
	Learning Rate: 0.00116351
	LOSS [training: 0.14923727917832402 | validation: 0.29071887253262724]
	TIME [epoch: 9.06 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15865903889054242		[learning rate: 0.0011584]
	Learning Rate: 0.00115837
	LOSS [training: 0.15865903889054242 | validation: 0.290172549843084]
	TIME [epoch: 9.09 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1456906385879122		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.1456906385879122 | validation: 0.2924008010721694]
	TIME [epoch: 9.06 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15772205654062638		[learning rate: 0.0011482]
	Learning Rate: 0.00114815
	LOSS [training: 0.15772205654062638 | validation: 0.2902314970854375]
	TIME [epoch: 9.07 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16057769468153898		[learning rate: 0.0011431]
	Learning Rate: 0.00114308
	LOSS [training: 0.16057769468153898 | validation: 0.29473738373475517]
	TIME [epoch: 9.05 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15310795206794356		[learning rate: 0.001138]
	Learning Rate: 0.00113803
	LOSS [training: 0.15310795206794356 | validation: 0.3020469919479469]
	TIME [epoch: 9.05 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v7_20240712_122158/states/model_facs_v2_dec2b_2dpca_v7_531.pth
Halted early. No improvement in validation loss for 200 epochs.
Finished training in 2718.816 seconds.
