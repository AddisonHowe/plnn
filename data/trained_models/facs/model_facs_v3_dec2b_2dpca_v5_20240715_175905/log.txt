Args:
Namespace(name='model_facs_v3_dec2b_2dpca_v5', outdir='out/model_training/model_facs_v3_dec2b_2dpca_v5', training_data='data/training_data/facs_v3/pca/dec2_fitonsubset/transition2_subset_ce_pn_m_pc12/training', validation_data='data/training_data/facs_v3/pca/dec2_fitonsubset/transition2_subset_ce_pn_m_pc12/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=10, batch_size=50, patience=200, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, quadratic_a=1.0, quadratic_b=1.0, ndims=2, nparams=2, nsigs=2, ncells=50, ncells_sample=50, model_do_sample=False, dt=0.005, dt_schedule='stepped', dt_schedule_bounds=[500, 1000, 1500], dt_schedule_scales=[0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=True, sigma=0.02, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', kernel='multiscale', bw_range=[0.2, 0.5, 0.9, 1.1, 1.3, 1.5, 2.0], optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 1705918039

Training model...

Saving initial model state to: out/model_training/model_facs_v3_dec2b_2dpca_v5_20240715_175905/states/model_facs_v3_dec2b_2dpca_v5_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1604437520142692		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1604437520142692 | validation: 1.2381223479224213]
	TIME [epoch: 32.8 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v5_20240715_175905/states/model_facs_v3_dec2b_2dpca_v5_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9644066819989595		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9644066819989595 | validation: 0.8851383433537285]
	TIME [epoch: 3.37 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v5_20240715_175905/states/model_facs_v3_dec2b_2dpca_v5_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7846929876944543		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7846929876944543 | validation: 0.8529220764357689]
	TIME [epoch: 3.38 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v5_20240715_175905/states/model_facs_v3_dec2b_2dpca_v5_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7147036407718949		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7147036407718949 | validation: 0.8351791628501908]
	TIME [epoch: 3.35 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v5_20240715_175905/states/model_facs_v3_dec2b_2dpca_v5_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7260462219957146		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7260462219957146 | validation: 0.824344743993267]
	TIME [epoch: 3.39 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v5_20240715_175905/states/model_facs_v3_dec2b_2dpca_v5_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.620733538592015		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.620733538592015 | validation: 0.7958544367683313]
	TIME [epoch: 3.36 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v5_20240715_175905/states/model_facs_v3_dec2b_2dpca_v5_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5964121950630142		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5964121950630142 | validation: 0.7430997546403969]
	TIME [epoch: 3.36 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v5_20240715_175905/states/model_facs_v3_dec2b_2dpca_v5_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6320545589044291		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6320545589044291 | validation: 0.7743951127942711]
	TIME [epoch: 3.36 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5710734510601113		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5710734510601113 | validation: 0.7223523260287692]
	TIME [epoch: 3.36 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v5_20240715_175905/states/model_facs_v3_dec2b_2dpca_v5_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5724800257571647		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5724800257571647 | validation: 0.7682911124262872]
	TIME [epoch: 3.36 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5684526505161961		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5684526505161961 | validation: 0.6410694599944646]
	TIME [epoch: 3.36 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v5_20240715_175905/states/model_facs_v3_dec2b_2dpca_v5_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5617490352562323		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5617490352562323 | validation: 0.6933663214547665]
	TIME [epoch: 3.37 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5201893317191599		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5201893317191599 | validation: 0.5460495120947152]
	TIME [epoch: 3.37 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v5_20240715_175905/states/model_facs_v3_dec2b_2dpca_v5_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4116063204648391		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4116063204648391 | validation: 0.7524346969796843]
	TIME [epoch: 3.37 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6051005978448106		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6051005978448106 | validation: 0.5488171836747651]
	TIME [epoch: 3.41 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4144904034471456		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4144904034471456 | validation: 0.5713990222396317]
	TIME [epoch: 3.36 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4016638799538407		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4016638799538407 | validation: 0.47132663807161573]
	TIME [epoch: 3.37 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v5_20240715_175905/states/model_facs_v3_dec2b_2dpca_v5_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4084474094997451		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4084474094997451 | validation: 0.5405194867642684]
	TIME [epoch: 3.36 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32874928316882773		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.32874928316882773 | validation: 0.5216494282004588]
	TIME [epoch: 3.36 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4094680044313672		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4094680044313672 | validation: 0.5618328699178563]
	TIME [epoch: 3.35 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3793394446487299		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3793394446487299 | validation: 0.4607595672954018]
	TIME [epoch: 3.35 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v5_20240715_175905/states/model_facs_v3_dec2b_2dpca_v5_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32307028494194584		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.32307028494194584 | validation: 0.4550832368471617]
	TIME [epoch: 3.36 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v5_20240715_175905/states/model_facs_v3_dec2b_2dpca_v5_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2977983269830353		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2977983269830353 | validation: 0.4477135734022754]
	TIME [epoch: 3.37 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v5_20240715_175905/states/model_facs_v3_dec2b_2dpca_v5_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3008383092232201		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3008383092232201 | validation: 0.5194202908815483]
	TIME [epoch: 3.36 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30851521851787833		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.30851521851787833 | validation: 0.49076531640651305]
	TIME [epoch: 3.35 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30447028452922864		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.30447028452922864 | validation: 0.4250718250277462]
	TIME [epoch: 3.4 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v5_20240715_175905/states/model_facs_v3_dec2b_2dpca_v5_26.pth
	Model improved!!!
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2664679979008931		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2664679979008931 | validation: 0.4413262350983028]
	TIME [epoch: 3.36 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31529603964738695		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.31529603964738695 | validation: 0.46562035039546246]
	TIME [epoch: 3.35 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2837258232388237		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2837258232388237 | validation: 0.3828021192576427]
	TIME [epoch: 3.37 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v5_20240715_175905/states/model_facs_v3_dec2b_2dpca_v5_29.pth
	Model improved!!!
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25579401442733185		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.25579401442733185 | validation: 0.37732460416537633]
	TIME [epoch: 3.37 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v5_20240715_175905/states/model_facs_v3_dec2b_2dpca_v5_30.pth
	Model improved!!!
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24523742956372604		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24523742956372604 | validation: 0.42884586328997865]
	TIME [epoch: 3.36 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2856052171582481		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2856052171582481 | validation: 0.5296280676797164]
	TIME [epoch: 3.37 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2747900057404061		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2747900057404061 | validation: 0.5915179661712042]
	TIME [epoch: 3.38 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32085617794454935		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.32085617794454935 | validation: 0.5601823163894379]
	TIME [epoch: 3.38 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30117819260268897		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.30117819260268897 | validation: 0.32198615971950545]
	TIME [epoch: 3.4 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v5_20240715_175905/states/model_facs_v3_dec2b_2dpca_v5_35.pth
	Model improved!!!
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.253211090448511		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.253211090448511 | validation: 0.5033757016079278]
	TIME [epoch: 3.37 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3035555983094884		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3035555983094884 | validation: 0.36849565507047033]
	TIME [epoch: 3.37 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24587931083687178		[learning rate: 0.0099882]
	Learning Rate: 0.0099882
	LOSS [training: 0.24587931083687178 | validation: 0.4546324684026724]
	TIME [epoch: 3.36 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33529163653027333		[learning rate: 0.0099411]
	Learning Rate: 0.00994113
	LOSS [training: 0.33529163653027333 | validation: 0.4556301117832847]
	TIME [epoch: 3.36 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25231262113314323		[learning rate: 0.0098943]
	Learning Rate: 0.00989429
	LOSS [training: 0.25231262113314323 | validation: 0.4539945461249749]
	TIME [epoch: 3.35 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20601144362590396		[learning rate: 0.0098477]
	Learning Rate: 0.00984767
	LOSS [training: 0.20601144362590396 | validation: 0.4431509181917884]
	TIME [epoch: 3.36 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2559976458601575		[learning rate: 0.0098013]
	Learning Rate: 0.00980126
	LOSS [training: 0.2559976458601575 | validation: 0.3708329564692525]
	TIME [epoch: 3.36 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19133401147739929		[learning rate: 0.0097551]
	Learning Rate: 0.00975508
	LOSS [training: 0.19133401147739929 | validation: 0.5258708940187911]
	TIME [epoch: 3.37 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2668367563780452		[learning rate: 0.0097091]
	Learning Rate: 0.00970911
	LOSS [training: 0.2668367563780452 | validation: 0.436183543417568]
	TIME [epoch: 3.36 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2530421697137362		[learning rate: 0.0096634]
	Learning Rate: 0.00966336
	LOSS [training: 0.2530421697137362 | validation: 0.4327133020112577]
	TIME [epoch: 3.37 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39747574597296614		[learning rate: 0.0096178]
	Learning Rate: 0.00961783
	LOSS [training: 0.39747574597296614 | validation: 0.40871046501047303]
	TIME [epoch: 3.36 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3041916194432279		[learning rate: 0.0095725]
	Learning Rate: 0.00957251
	LOSS [training: 0.3041916194432279 | validation: 0.541352660646576]
	TIME [epoch: 3.36 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2980139391512911		[learning rate: 0.0095274]
	Learning Rate: 0.0095274
	LOSS [training: 0.2980139391512911 | validation: 0.3650784438830045]
	TIME [epoch: 3.35 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23416538741611603		[learning rate: 0.0094825]
	Learning Rate: 0.0094825
	LOSS [training: 0.23416538741611603 | validation: 0.5743800613193991]
	TIME [epoch: 3.36 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2785032266810792		[learning rate: 0.0094378]
	Learning Rate: 0.00943782
	LOSS [training: 0.2785032266810792 | validation: 0.37055391422516726]
	TIME [epoch: 3.38 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24874704103018372		[learning rate: 0.0093933]
	Learning Rate: 0.00939335
	LOSS [training: 0.24874704103018372 | validation: 0.40071527112751254]
	TIME [epoch: 3.38 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24165635929842336		[learning rate: 0.0093491]
	Learning Rate: 0.00934909
	LOSS [training: 0.24165635929842336 | validation: 0.4448980966073711]
	TIME [epoch: 3.37 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25334016320700653		[learning rate: 0.009305]
	Learning Rate: 0.00930503
	LOSS [training: 0.25334016320700653 | validation: 0.48231465962518266]
	TIME [epoch: 3.37 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34345555650037707		[learning rate: 0.0092612]
	Learning Rate: 0.00926119
	LOSS [training: 0.34345555650037707 | validation: 0.4282789936756335]
	TIME [epoch: 3.38 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26577121994976427		[learning rate: 0.0092175]
	Learning Rate: 0.00921755
	LOSS [training: 0.26577121994976427 | validation: 0.39564850664294626]
	TIME [epoch: 3.37 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2703104219078878		[learning rate: 0.0091741]
	Learning Rate: 0.00917411
	LOSS [training: 0.2703104219078878 | validation: 0.4653453983718503]
	TIME [epoch: 3.35 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21501390200012319		[learning rate: 0.0091309]
	Learning Rate: 0.00913088
	LOSS [training: 0.21501390200012319 | validation: 0.40359691616472726]
	TIME [epoch: 3.36 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24710038704873177		[learning rate: 0.0090879]
	Learning Rate: 0.00908786
	LOSS [training: 0.24710038704873177 | validation: 0.3482438575924643]
	TIME [epoch: 3.36 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20245050443370854		[learning rate: 0.009045]
	Learning Rate: 0.00904503
	LOSS [training: 0.20245050443370854 | validation: 0.46572142244877585]
	TIME [epoch: 3.37 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27783083385795293		[learning rate: 0.0090024]
	Learning Rate: 0.00900241
	LOSS [training: 0.27783083385795293 | validation: 0.34919471613158426]
	TIME [epoch: 3.36 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2508256907325521		[learning rate: 0.00896]
	Learning Rate: 0.00895999
	LOSS [training: 0.2508256907325521 | validation: 0.37982640653579375]
	TIME [epoch: 3.37 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2279178269488924		[learning rate: 0.0089178]
	Learning Rate: 0.00891777
	LOSS [training: 0.2279178269488924 | validation: 0.41407955311891026]
	TIME [epoch: 3.36 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29319154993434887		[learning rate: 0.0088758]
	Learning Rate: 0.00887575
	LOSS [training: 0.29319154993434887 | validation: 0.6409761423804061]
	TIME [epoch: 3.36 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3072972758804465		[learning rate: 0.0088339]
	Learning Rate: 0.00883393
	LOSS [training: 0.3072972758804465 | validation: 0.3709354437214631]
	TIME [epoch: 3.39 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21933513531062518		[learning rate: 0.0087923]
	Learning Rate: 0.0087923
	LOSS [training: 0.21933513531062518 | validation: 0.4152429691268321]
	TIME [epoch: 3.36 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17839041039523584		[learning rate: 0.0087509]
	Learning Rate: 0.00875087
	LOSS [training: 0.17839041039523584 | validation: 0.40415805301791397]
	TIME [epoch: 3.37 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26817115726144575		[learning rate: 0.0087096]
	Learning Rate: 0.00870964
	LOSS [training: 0.26817115726144575 | validation: 0.4418087286487478]
	TIME [epoch: 3.37 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26226320013612914		[learning rate: 0.0086686]
	Learning Rate: 0.00866859
	LOSS [training: 0.26226320013612914 | validation: 0.6184468400146159]
	TIME [epoch: 3.37 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28194432387539475		[learning rate: 0.0086277]
	Learning Rate: 0.00862775
	LOSS [training: 0.28194432387539475 | validation: 0.4822140941936391]
	TIME [epoch: 3.37 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24119775549557335		[learning rate: 0.0085871]
	Learning Rate: 0.00858709
	LOSS [training: 0.24119775549557335 | validation: 0.3721313328517628]
	TIME [epoch: 3.37 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23581138908705454		[learning rate: 0.0085466]
	Learning Rate: 0.00854663
	LOSS [training: 0.23581138908705454 | validation: 0.5378517684658666]
	TIME [epoch: 3.37 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23462280387343248		[learning rate: 0.0085064]
	Learning Rate: 0.00850636
	LOSS [training: 0.23462280387343248 | validation: 0.3910124669998696]
	TIME [epoch: 3.36 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20984784957502167		[learning rate: 0.0084663]
	Learning Rate: 0.00846627
	LOSS [training: 0.20984784957502167 | validation: 0.3858654606631167]
	TIME [epoch: 3.37 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23596657040921226		[learning rate: 0.0084264]
	Learning Rate: 0.00842638
	LOSS [training: 0.23596657040921226 | validation: 0.4033507715762256]
	TIME [epoch: 3.37 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2294738260117992		[learning rate: 0.0083867]
	Learning Rate: 0.00838667
	LOSS [training: 0.2294738260117992 | validation: 0.36353759557276505]
	TIME [epoch: 3.37 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19409085142847976		[learning rate: 0.0083472]
	Learning Rate: 0.00834715
	LOSS [training: 0.19409085142847976 | validation: 0.3491211538409463]
	TIME [epoch: 3.37 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2026660331744025		[learning rate: 0.0083078]
	Learning Rate: 0.00830782
	LOSS [training: 0.2026660331744025 | validation: 0.358254289916123]
	TIME [epoch: 3.37 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19327699357624697		[learning rate: 0.0082687]
	Learning Rate: 0.00826867
	LOSS [training: 0.19327699357624697 | validation: 0.5665591956023016]
	TIME [epoch: 3.36 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23950590251051548		[learning rate: 0.0082297]
	Learning Rate: 0.00822971
	LOSS [training: 0.23950590251051548 | validation: 0.5571033274047906]
	TIME [epoch: 3.36 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2537278612979797		[learning rate: 0.0081909]
	Learning Rate: 0.00819093
	LOSS [training: 0.2537278612979797 | validation: 0.44875885337115373]
	TIME [epoch: 3.37 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.252902677862006		[learning rate: 0.0081523]
	Learning Rate: 0.00815233
	LOSS [training: 0.252902677862006 | validation: 0.5151832104045054]
	TIME [epoch: 3.37 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4480086449776855		[learning rate: 0.0081139]
	Learning Rate: 0.00811392
	LOSS [training: 0.4480086449776855 | validation: 0.5908790984367785]
	TIME [epoch: 3.38 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43133364816999453		[learning rate: 0.0080757]
	Learning Rate: 0.00807569
	LOSS [training: 0.43133364816999453 | validation: 0.5851893369407861]
	TIME [epoch: 3.36 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42251594576740376		[learning rate: 0.0080376]
	Learning Rate: 0.00803763
	LOSS [training: 0.42251594576740376 | validation: 0.5254270572012478]
	TIME [epoch: 3.37 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35352855272739053		[learning rate: 0.0079998]
	Learning Rate: 0.00799976
	LOSS [training: 0.35352855272739053 | validation: 0.45553210668093147]
	TIME [epoch: 3.36 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28722527393327235		[learning rate: 0.0079621]
	Learning Rate: 0.00796206
	LOSS [training: 0.28722527393327235 | validation: 0.4015205522427948]
	TIME [epoch: 3.37 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17597000615708058		[learning rate: 0.0079245]
	Learning Rate: 0.00792455
	LOSS [training: 0.17597000615708058 | validation: 0.3577802379306213]
	TIME [epoch: 3.36 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19480759193486252		[learning rate: 0.0078872]
	Learning Rate: 0.0078872
	LOSS [training: 0.19480759193486252 | validation: 0.3541851887557731]
	TIME [epoch: 3.37 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2022488553250258		[learning rate: 0.00785]
	Learning Rate: 0.00785004
	LOSS [training: 0.2022488553250258 | validation: 0.3425245632571209]
	TIME [epoch: 3.36 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18813318522145644		[learning rate: 0.007813]
	Learning Rate: 0.00781305
	LOSS [training: 0.18813318522145644 | validation: 0.3482095602266149]
	TIME [epoch: 3.36 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19524246894609326		[learning rate: 0.0077762]
	Learning Rate: 0.00777623
	LOSS [training: 0.19524246894609326 | validation: 0.31541598991494735]
	TIME [epoch: 3.38 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v5_20240715_175905/states/model_facs_v3_dec2b_2dpca_v5_91.pth
	Model improved!!!
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24545349136150424		[learning rate: 0.0077396]
	Learning Rate: 0.00773959
	LOSS [training: 0.24545349136150424 | validation: 0.567855039580557]
	TIME [epoch: 3.36 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27331217769067756		[learning rate: 0.0077031]
	Learning Rate: 0.00770312
	LOSS [training: 0.27331217769067756 | validation: 0.3551507016788164]
	TIME [epoch: 3.37 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20975171841918425		[learning rate: 0.0076668]
	Learning Rate: 0.00766682
	LOSS [training: 0.20975171841918425 | validation: 0.35283923881793844]
	TIME [epoch: 3.36 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18092387633833332		[learning rate: 0.0076307]
	Learning Rate: 0.0076307
	LOSS [training: 0.18092387633833332 | validation: 0.6962803803996991]
	TIME [epoch: 3.36 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28022734360654855		[learning rate: 0.0075947]
	Learning Rate: 0.00759474
	LOSS [training: 0.28022734360654855 | validation: 0.46649055056343447]
	TIME [epoch: 3.37 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27328105464415897		[learning rate: 0.007559]
	Learning Rate: 0.00755895
	LOSS [training: 0.27328105464415897 | validation: 0.43179685757304687]
	TIME [epoch: 3.36 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1918571136387904		[learning rate: 0.0075233]
	Learning Rate: 0.00752333
	LOSS [training: 0.1918571136387904 | validation: 0.42649556272540606]
	TIME [epoch: 3.36 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1858298905742919		[learning rate: 0.0074879]
	Learning Rate: 0.00748788
	LOSS [training: 0.1858298905742919 | validation: 0.3279664963245516]
	TIME [epoch: 3.38 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24639206501457778		[learning rate: 0.0074526]
	Learning Rate: 0.0074526
	LOSS [training: 0.24639206501457778 | validation: 0.46424695567799595]
	TIME [epoch: 3.36 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27885498038785317		[learning rate: 0.0074175]
	Learning Rate: 0.00741748
	LOSS [training: 0.27885498038785317 | validation: 0.46525864422106705]
	TIME [epoch: 3.36 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.240332689701661		[learning rate: 0.0073825]
	Learning Rate: 0.00738253
	LOSS [training: 0.240332689701661 | validation: 0.3827989464092087]
	TIME [epoch: 3.37 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2030588236818962		[learning rate: 0.0073477]
	Learning Rate: 0.00734774
	LOSS [training: 0.2030588236818962 | validation: 0.4898236843899785]
	TIME [epoch: 3.45 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2756330247320736		[learning rate: 0.0073131]
	Learning Rate: 0.00731312
	LOSS [training: 0.2756330247320736 | validation: 0.3709747223603272]
	TIME [epoch: 3.37 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2226803083140647		[learning rate: 0.0072787]
	Learning Rate: 0.00727866
	LOSS [training: 0.2226803083140647 | validation: 0.3353256864768437]
	TIME [epoch: 3.36 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1889038190356939		[learning rate: 0.0072444]
	Learning Rate: 0.00724436
	LOSS [training: 0.1889038190356939 | validation: 0.446307297903544]
	TIME [epoch: 3.37 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23712037162631608		[learning rate: 0.0072102]
	Learning Rate: 0.00721022
	LOSS [training: 0.23712037162631608 | validation: 0.35465954526671883]
	TIME [epoch: 3.36 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2120285631320009		[learning rate: 0.0071762]
	Learning Rate: 0.00717625
	LOSS [training: 0.2120285631320009 | validation: 0.4701710172462652]
	TIME [epoch: 3.37 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.206862185044106		[learning rate: 0.0071424]
	Learning Rate: 0.00714243
	LOSS [training: 0.206862185044106 | validation: 0.4799631285797239]
	TIME [epoch: 3.36 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2304009124536535		[learning rate: 0.0071088]
	Learning Rate: 0.00710878
	LOSS [training: 0.2304009124536535 | validation: 0.42190536324393957]
	TIME [epoch: 3.36 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19889893863399805		[learning rate: 0.0070753]
	Learning Rate: 0.00707528
	LOSS [training: 0.19889893863399805 | validation: 0.40248653790493705]
	TIME [epoch: 3.35 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25644975208830173		[learning rate: 0.0070419]
	Learning Rate: 0.00704194
	LOSS [training: 0.25644975208830173 | validation: 0.4174679132745909]
	TIME [epoch: 3.36 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18877221295247376		[learning rate: 0.0070088]
	Learning Rate: 0.00700876
	LOSS [training: 0.18877221295247376 | validation: 0.41056572289447346]
	TIME [epoch: 3.37 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22911231545224237		[learning rate: 0.0069757]
	Learning Rate: 0.00697573
	LOSS [training: 0.22911231545224237 | validation: 0.408166216293853]
	TIME [epoch: 3.35 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2552503523359147		[learning rate: 0.0069429]
	Learning Rate: 0.00694286
	LOSS [training: 0.2552503523359147 | validation: 0.40945271144419587]
	TIME [epoch: 3.37 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20438749177021412		[learning rate: 0.0069101]
	Learning Rate: 0.00691014
	LOSS [training: 0.20438749177021412 | validation: 0.49515615060482254]
	TIME [epoch: 3.36 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.224984052660353		[learning rate: 0.0068776]
	Learning Rate: 0.00687758
	LOSS [training: 0.224984052660353 | validation: 0.3687042809165569]
	TIME [epoch: 3.37 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18684341308692837		[learning rate: 0.0068452]
	Learning Rate: 0.00684518
	LOSS [training: 0.18684341308692837 | validation: 0.36553649464129145]
	TIME [epoch: 3.37 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1815966076105452		[learning rate: 0.0068129]
	Learning Rate: 0.00681292
	LOSS [training: 0.1815966076105452 | validation: 0.37807001357957226]
	TIME [epoch: 3.37 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.204135746433378		[learning rate: 0.0067808]
	Learning Rate: 0.00678082
	LOSS [training: 0.204135746433378 | validation: 0.30091954054171843]
	TIME [epoch: 3.37 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v5_20240715_175905/states/model_facs_v3_dec2b_2dpca_v5_120.pth
	Model improved!!!
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2113779230447773		[learning rate: 0.0067489]
	Learning Rate: 0.00674887
	LOSS [training: 0.2113779230447773 | validation: 0.35442870875766264]
	TIME [epoch: 3.36 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21099488551852938		[learning rate: 0.0067171]
	Learning Rate: 0.00671706
	LOSS [training: 0.21099488551852938 | validation: 0.3883240537599955]
	TIME [epoch: 3.37 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2563061607299719		[learning rate: 0.0066854]
	Learning Rate: 0.00668541
	LOSS [training: 0.2563061607299719 | validation: 0.38380330620682446]
	TIME [epoch: 3.36 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21713857185228333		[learning rate: 0.0066539]
	Learning Rate: 0.00665391
	LOSS [training: 0.21713857185228333 | validation: 0.37684677205411254]
	TIME [epoch: 3.37 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1970913219524483		[learning rate: 0.0066226]
	Learning Rate: 0.00662256
	LOSS [training: 0.1970913219524483 | validation: 0.4075944897437541]
	TIME [epoch: 3.36 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3173120091668711		[learning rate: 0.0065913]
	Learning Rate: 0.00659135
	LOSS [training: 0.3173120091668711 | validation: 0.47458753980209184]
	TIME [epoch: 3.37 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27232848326334325		[learning rate: 0.0065603]
	Learning Rate: 0.00656029
	LOSS [training: 0.27232848326334325 | validation: 0.4747443182869324]
	TIME [epoch: 3.36 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21614202410093106		[learning rate: 0.0065294]
	Learning Rate: 0.00652938
	LOSS [training: 0.21614202410093106 | validation: 0.4040409650414606]
	TIME [epoch: 3.37 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20562616173288129		[learning rate: 0.0064986]
	Learning Rate: 0.00649861
	LOSS [training: 0.20562616173288129 | validation: 0.41598473276589676]
	TIME [epoch: 3.37 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22055450372760665		[learning rate: 0.006468]
	Learning Rate: 0.00646799
	LOSS [training: 0.22055450372760665 | validation: 0.3740850886581728]
	TIME [epoch: 3.36 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19070691851838223		[learning rate: 0.0064375]
	Learning Rate: 0.00643751
	LOSS [training: 0.19070691851838223 | validation: 0.3988853940610183]
	TIME [epoch: 3.37 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21411607132792232		[learning rate: 0.0064072]
	Learning Rate: 0.00640718
	LOSS [training: 0.21411607132792232 | validation: 0.39822266480489543]
	TIME [epoch: 3.36 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2238568182359719		[learning rate: 0.006377]
	Learning Rate: 0.00637698
	LOSS [training: 0.2238568182359719 | validation: 0.38933164314331337]
	TIME [epoch: 3.37 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20317708022911246		[learning rate: 0.0063469]
	Learning Rate: 0.00634694
	LOSS [training: 0.20317708022911246 | validation: 0.387796453569577]
	TIME [epoch: 3.37 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1688117131257347		[learning rate: 0.006317]
	Learning Rate: 0.00631703
	LOSS [training: 0.1688117131257347 | validation: 0.4060756624577846]
	TIME [epoch: 3.36 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2140122950071473		[learning rate: 0.0062873]
	Learning Rate: 0.00628726
	LOSS [training: 0.2140122950071473 | validation: 0.4932167471869366]
	TIME [epoch: 3.35 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2546840291742935		[learning rate: 0.0062576]
	Learning Rate: 0.00625764
	LOSS [training: 0.2546840291742935 | validation: 0.39600606056454435]
	TIME [epoch: 3.37 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22878042975358384		[learning rate: 0.0062281]
	Learning Rate: 0.00622815
	LOSS [training: 0.22878042975358384 | validation: 0.34270749485956514]
	TIME [epoch: 3.37 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3387746059388338		[learning rate: 0.0061988]
	Learning Rate: 0.0061988
	LOSS [training: 0.3387746059388338 | validation: 0.5383129975960467]
	TIME [epoch: 3.36 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41914162758828755		[learning rate: 0.0061696]
	Learning Rate: 0.00616959
	LOSS [training: 0.41914162758828755 | validation: 0.4943214661785388]
	TIME [epoch: 3.36 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32302550918340595		[learning rate: 0.0061405]
	Learning Rate: 0.00614052
	LOSS [training: 0.32302550918340595 | validation: 0.4671248367001256]
	TIME [epoch: 3.37 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25395307245405285		[learning rate: 0.0061116]
	Learning Rate: 0.00611158
	LOSS [training: 0.25395307245405285 | validation: 0.4589202565858954]
	TIME [epoch: 3.35 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22501897837306603		[learning rate: 0.0060828]
	Learning Rate: 0.00608279
	LOSS [training: 0.22501897837306603 | validation: 0.38292313667292277]
	TIME [epoch: 3.37 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19258970778667123		[learning rate: 0.0060541]
	Learning Rate: 0.00605412
	LOSS [training: 0.19258970778667123 | validation: 0.3829066780033629]
	TIME [epoch: 3.37 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1744464871612143		[learning rate: 0.0060256]
	Learning Rate: 0.0060256
	LOSS [training: 0.1744464871612143 | validation: 0.38536775935219275]
	TIME [epoch: 3.36 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19272477787035275		[learning rate: 0.0059972]
	Learning Rate: 0.0059972
	LOSS [training: 0.19272477787035275 | validation: 0.40700030231533424]
	TIME [epoch: 3.36 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19446357058865216		[learning rate: 0.0059689]
	Learning Rate: 0.00596894
	LOSS [training: 0.19446357058865216 | validation: 0.34784305034518]
	TIME [epoch: 3.36 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21449018541028592		[learning rate: 0.0059408]
	Learning Rate: 0.00594082
	LOSS [training: 0.21449018541028592 | validation: 0.34235777550239366]
	TIME [epoch: 3.36 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2095387187744363		[learning rate: 0.0059128]
	Learning Rate: 0.00591282
	LOSS [training: 0.2095387187744363 | validation: 0.38789476912346776]
	TIME [epoch: 3.36 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19713886821816046		[learning rate: 0.005885]
	Learning Rate: 0.00588496
	LOSS [training: 0.19713886821816046 | validation: 0.2942388488806402]
	TIME [epoch: 3.37 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v5_20240715_175905/states/model_facs_v3_dec2b_2dpca_v5_150.pth
	Model improved!!!
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15439319424482595		[learning rate: 0.0058572]
	Learning Rate: 0.00585723
	LOSS [training: 0.15439319424482595 | validation: 0.3767970672733585]
	TIME [epoch: 3.36 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20208651325856078		[learning rate: 0.0058296]
	Learning Rate: 0.00582963
	LOSS [training: 0.20208651325856078 | validation: 0.5386591974477929]
	TIME [epoch: 3.37 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2329007256016684		[learning rate: 0.0058022]
	Learning Rate: 0.00580216
	LOSS [training: 0.2329007256016684 | validation: 0.43959248811779794]
	TIME [epoch: 3.36 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20880662065934957		[learning rate: 0.0057748]
	Learning Rate: 0.00577482
	LOSS [training: 0.20880662065934957 | validation: 0.35087993490986613]
	TIME [epoch: 3.37 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21055849919070366		[learning rate: 0.0057476]
	Learning Rate: 0.00574761
	LOSS [training: 0.21055849919070366 | validation: 0.29683785737743684]
	TIME [epoch: 3.35 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2059664850721296		[learning rate: 0.0057205]
	Learning Rate: 0.00572052
	LOSS [training: 0.2059664850721296 | validation: 0.4185806400280353]
	TIME [epoch: 3.36 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23085950284068707		[learning rate: 0.0056936]
	Learning Rate: 0.00569357
	LOSS [training: 0.23085950284068707 | validation: 0.38518043675469615]
	TIME [epoch: 3.37 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2090874842748911		[learning rate: 0.0056667]
	Learning Rate: 0.00566674
	LOSS [training: 0.2090874842748911 | validation: 0.3450818311304965]
	TIME [epoch: 3.36 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21521333335343468		[learning rate: 0.00564]
	Learning Rate: 0.00564004
	LOSS [training: 0.21521333335343468 | validation: 0.49742629978972364]
	TIME [epoch: 3.36 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22378710538636098		[learning rate: 0.0056135]
	Learning Rate: 0.00561346
	LOSS [training: 0.22378710538636098 | validation: 0.29053092612217]
	TIME [epoch: 3.38 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v5_20240715_175905/states/model_facs_v3_dec2b_2dpca_v5_160.pth
	Model improved!!!
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1973812904669846		[learning rate: 0.005587]
	Learning Rate: 0.00558701
	LOSS [training: 0.1973812904669846 | validation: 0.42583925938874767]
	TIME [epoch: 3.36 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20771512374737489		[learning rate: 0.0055607]
	Learning Rate: 0.00556068
	LOSS [training: 0.20771512374737489 | validation: 0.36055327986242336]
	TIME [epoch: 3.36 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20006465007387664		[learning rate: 0.0055345]
	Learning Rate: 0.00553448
	LOSS [training: 0.20006465007387664 | validation: 0.3399625408782681]
	TIME [epoch: 3.37 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2771644230809482		[learning rate: 0.0055084]
	Learning Rate: 0.0055084
	LOSS [training: 0.2771644230809482 | validation: 0.42299729047813184]
	TIME [epoch: 3.36 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2635692616807193		[learning rate: 0.0054824]
	Learning Rate: 0.00548245
	LOSS [training: 0.2635692616807193 | validation: 0.478690604057893]
	TIME [epoch: 3.36 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23195463326368898		[learning rate: 0.0054566]
	Learning Rate: 0.00545661
	LOSS [training: 0.23195463326368898 | validation: 0.4500677504648754]
	TIME [epoch: 3.36 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18769642430033354		[learning rate: 0.0054309]
	Learning Rate: 0.0054309
	LOSS [training: 0.18769642430033354 | validation: 0.3303293575296063]
	TIME [epoch: 3.37 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18290118777653103		[learning rate: 0.0054053]
	Learning Rate: 0.00540531
	LOSS [training: 0.18290118777653103 | validation: 0.3574086702807402]
	TIME [epoch: 3.36 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18248009401226034		[learning rate: 0.0053798]
	Learning Rate: 0.00537984
	LOSS [training: 0.18248009401226034 | validation: 0.3290680889440122]
	TIME [epoch: 3.36 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1926114203536603		[learning rate: 0.0053545]
	Learning Rate: 0.00535449
	LOSS [training: 0.1926114203536603 | validation: 0.32427547044907]
	TIME [epoch: 3.36 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17546662892634332		[learning rate: 0.0053293]
	Learning Rate: 0.00532926
	LOSS [training: 0.17546662892634332 | validation: 0.30945942100688917]
	TIME [epoch: 3.37 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1880879612107429		[learning rate: 0.0053041]
	Learning Rate: 0.00530415
	LOSS [training: 0.1880879612107429 | validation: 0.40077048175735985]
	TIME [epoch: 3.36 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20327655480689683		[learning rate: 0.0052792]
	Learning Rate: 0.00527915
	LOSS [training: 0.20327655480689683 | validation: 0.34779138635942297]
	TIME [epoch: 3.43 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15918665916408137		[learning rate: 0.0052543]
	Learning Rate: 0.00525428
	LOSS [training: 0.15918665916408137 | validation: 0.31992811294135987]
	TIME [epoch: 3.36 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1734026970011757		[learning rate: 0.0052295]
	Learning Rate: 0.00522952
	LOSS [training: 0.1734026970011757 | validation: 0.38451310108192754]
	TIME [epoch: 3.35 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18137312587753515		[learning rate: 0.0052049]
	Learning Rate: 0.00520487
	LOSS [training: 0.18137312587753515 | validation: 0.3884456197625095]
	TIME [epoch: 3.36 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21929377026955277		[learning rate: 0.0051803]
	Learning Rate: 0.00518035
	LOSS [training: 0.21929377026955277 | validation: 0.404713949372365]
	TIME [epoch: 3.35 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18242420598867645		[learning rate: 0.0051559]
	Learning Rate: 0.00515594
	LOSS [training: 0.18242420598867645 | validation: 0.4213248305282006]
	TIME [epoch: 3.36 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19705016182020796		[learning rate: 0.0051316]
	Learning Rate: 0.00513164
	LOSS [training: 0.19705016182020796 | validation: 0.3317854331077953]
	TIME [epoch: 3.36 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2075971941040288		[learning rate: 0.0051075]
	Learning Rate: 0.00510746
	LOSS [training: 0.2075971941040288 | validation: 0.36247980978957]
	TIME [epoch: 3.36 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16743818982928108		[learning rate: 0.0050834]
	Learning Rate: 0.00508339
	LOSS [training: 0.16743818982928108 | validation: 0.3197801445146766]
	TIME [epoch: 3.36 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17667919431173787		[learning rate: 0.0050594]
	Learning Rate: 0.00505944
	LOSS [training: 0.17667919431173787 | validation: 0.3133019228670335]
	TIME [epoch: 3.35 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17563722621285235		[learning rate: 0.0050356]
	Learning Rate: 0.0050356
	LOSS [training: 0.17563722621285235 | validation: 0.39249159334531797]
	TIME [epoch: 3.36 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2033105328734232		[learning rate: 0.0050119]
	Learning Rate: 0.00501187
	LOSS [training: 0.2033105328734232 | validation: 0.3769413630327343]
	TIME [epoch: 3.37 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.193473142068712		[learning rate: 0.0049883]
	Learning Rate: 0.00498826
	LOSS [training: 0.193473142068712 | validation: 0.5290267841081353]
	TIME [epoch: 3.36 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19257796042305944		[learning rate: 0.0049648]
	Learning Rate: 0.00496475
	LOSS [training: 0.19257796042305944 | validation: 0.3342791824506104]
	TIME [epoch: 3.37 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1800033526952575		[learning rate: 0.0049414]
	Learning Rate: 0.00494136
	LOSS [training: 0.1800033526952575 | validation: 0.4227452437024816]
	TIME [epoch: 3.36 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22861676935705172		[learning rate: 0.0049181]
	Learning Rate: 0.00491807
	LOSS [training: 0.22861676935705172 | validation: 0.31602702633055807]
	TIME [epoch: 3.36 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19826382551333557		[learning rate: 0.0048949]
	Learning Rate: 0.0048949
	LOSS [training: 0.19826382551333557 | validation: 0.3391620054223079]
	TIME [epoch: 3.37 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19082552201678427		[learning rate: 0.0048718]
	Learning Rate: 0.00487183
	LOSS [training: 0.19082552201678427 | validation: 0.38145071769921696]
	TIME [epoch: 3.37 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23627186929362806		[learning rate: 0.0048489]
	Learning Rate: 0.00484888
	LOSS [training: 0.23627186929362806 | validation: 0.4574101915957655]
	TIME [epoch: 3.36 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24549023750964918		[learning rate: 0.004826]
	Learning Rate: 0.00482603
	LOSS [training: 0.24549023750964918 | validation: 0.39302897243982476]
	TIME [epoch: 3.36 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18350179239302078		[learning rate: 0.0048033]
	Learning Rate: 0.00480329
	LOSS [training: 0.18350179239302078 | validation: 0.38920444816838595]
	TIME [epoch: 3.37 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17543669047387964		[learning rate: 0.0047807]
	Learning Rate: 0.00478065
	LOSS [training: 0.17543669047387964 | validation: 0.42283203362143357]
	TIME [epoch: 3.36 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20217362509490885		[learning rate: 0.0047581]
	Learning Rate: 0.00475813
	LOSS [training: 0.20217362509490885 | validation: 0.32441791002622467]
	TIME [epoch: 3.36 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17544698033869688		[learning rate: 0.0047357]
	Learning Rate: 0.0047357
	LOSS [training: 0.17544698033869688 | validation: 0.5000247614978672]
	TIME [epoch: 3.36 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18759466138309017		[learning rate: 0.0047134]
	Learning Rate: 0.00471339
	LOSS [training: 0.18759466138309017 | validation: 0.3065901359865182]
	TIME [epoch: 3.37 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1542526280842779		[learning rate: 0.0046912]
	Learning Rate: 0.00469118
	LOSS [training: 0.1542526280842779 | validation: 0.3731153076706508]
	TIME [epoch: 3.37 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23131026396831567		[learning rate: 0.0046691]
	Learning Rate: 0.00466907
	LOSS [training: 0.23131026396831567 | validation: 0.37146776444627966]
	TIME [epoch: 3.36 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1770124043601659		[learning rate: 0.0046471]
	Learning Rate: 0.00464707
	LOSS [training: 0.1770124043601659 | validation: 0.3345867609932905]
	TIME [epoch: 3.36 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18635874049500756		[learning rate: 0.0046252]
	Learning Rate: 0.00462518
	LOSS [training: 0.18635874049500756 | validation: 0.32004196976194743]
	TIME [epoch: 3.36 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17087664287046772		[learning rate: 0.0046034]
	Learning Rate: 0.00460338
	LOSS [training: 0.17087664287046772 | validation: 0.37387324900813834]
	TIME [epoch: 3.36 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.319285291515387		[learning rate: 0.0045817]
	Learning Rate: 0.00458169
	LOSS [training: 0.319285291515387 | validation: 0.4332642349624596]
	TIME [epoch: 3.36 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2874155307511018		[learning rate: 0.0045601]
	Learning Rate: 0.0045601
	LOSS [training: 0.2874155307511018 | validation: 0.36500461951402063]
	TIME [epoch: 3.35 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18500929101409497		[learning rate: 0.0045386]
	Learning Rate: 0.00453861
	LOSS [training: 0.18500929101409497 | validation: 0.37287269477729157]
	TIME [epoch: 3.36 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2265725832850003		[learning rate: 0.0045172]
	Learning Rate: 0.00451723
	LOSS [training: 0.2265725832850003 | validation: 0.3492622157632226]
	TIME [epoch: 3.37 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1911446757571118		[learning rate: 0.0044959]
	Learning Rate: 0.00449594
	LOSS [training: 0.1911446757571118 | validation: 0.3546837945356929]
	TIME [epoch: 3.37 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1908658829969367		[learning rate: 0.0044748]
	Learning Rate: 0.00447475
	LOSS [training: 0.1908658829969367 | validation: 0.36302560990025345]
	TIME [epoch: 3.36 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1984045582644418		[learning rate: 0.0044537]
	Learning Rate: 0.00445367
	LOSS [training: 0.1984045582644418 | validation: 0.3361238293329517]
	TIME [epoch: 3.37 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24880060183784267		[learning rate: 0.0044327]
	Learning Rate: 0.00443268
	LOSS [training: 0.24880060183784267 | validation: 0.4466535656907357]
	TIME [epoch: 3.38 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2878128704840297		[learning rate: 0.0044118]
	Learning Rate: 0.0044118
	LOSS [training: 0.2878128704840297 | validation: 0.427932116327685]
	TIME [epoch: 3.37 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21703532552863872		[learning rate: 0.004391]
	Learning Rate: 0.00439101
	LOSS [training: 0.21703532552863872 | validation: 0.3486206111004123]
	TIME [epoch: 3.35 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20948145570784169		[learning rate: 0.0043703]
	Learning Rate: 0.00437032
	LOSS [training: 0.20948145570784169 | validation: 0.33336601080316375]
	TIME [epoch: 3.36 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20489074508300154		[learning rate: 0.0043497]
	Learning Rate: 0.00434972
	LOSS [training: 0.20489074508300154 | validation: 0.34992256785315906]
	TIME [epoch: 3.36 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17549839074791654		[learning rate: 0.0043292]
	Learning Rate: 0.00432923
	LOSS [training: 0.17549839074791654 | validation: 0.31510030812945367]
	TIME [epoch: 3.37 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18659305910127327		[learning rate: 0.0043088]
	Learning Rate: 0.00430883
	LOSS [training: 0.18659305910127327 | validation: 0.35361047940376583]
	TIME [epoch: 3.36 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18472448110353146		[learning rate: 0.0042885]
	Learning Rate: 0.00428852
	LOSS [training: 0.18472448110353146 | validation: 0.3395461724491452]
	TIME [epoch: 3.36 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15842382150513615		[learning rate: 0.0042683]
	Learning Rate: 0.00426831
	LOSS [training: 0.15842382150513615 | validation: 0.32788449307379575]
	TIME [epoch: 3.36 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15364596879658904		[learning rate: 0.0042482]
	Learning Rate: 0.0042482
	LOSS [training: 0.15364596879658904 | validation: 0.32550704869186814]
	TIME [epoch: 3.36 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21517354208259437		[learning rate: 0.0042282]
	Learning Rate: 0.00422818
	LOSS [training: 0.21517354208259437 | validation: 0.3715797891260875]
	TIME [epoch: 3.36 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18729781846898882		[learning rate: 0.0042083]
	Learning Rate: 0.00420826
	LOSS [training: 0.18729781846898882 | validation: 0.3300544757361316]
	TIME [epoch: 3.36 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16406813354789224		[learning rate: 0.0041884]
	Learning Rate: 0.00418843
	LOSS [training: 0.16406813354789224 | validation: 0.3285616964606302]
	TIME [epoch: 3.36 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.191452094121333		[learning rate: 0.0041687]
	Learning Rate: 0.00416869
	LOSS [training: 0.191452094121333 | validation: 0.4043175585122543]
	TIME [epoch: 3.36 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2270649832019343		[learning rate: 0.0041491]
	Learning Rate: 0.00414905
	LOSS [training: 0.2270649832019343 | validation: 0.34407722859096557]
	TIME [epoch: 3.37 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.167175107971161		[learning rate: 0.0041295]
	Learning Rate: 0.0041295
	LOSS [training: 0.167175107971161 | validation: 0.37011446517436475]
	TIME [epoch: 3.36 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17795214126847772		[learning rate: 0.00411]
	Learning Rate: 0.00411004
	LOSS [training: 0.17795214126847772 | validation: 0.48271558641102047]
	TIME [epoch: 3.36 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28830404017720124		[learning rate: 0.0040907]
	Learning Rate: 0.00409067
	LOSS [training: 0.28830404017720124 | validation: 0.37201187604652225]
	TIME [epoch: 3.36 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1977018787400512		[learning rate: 0.0040714]
	Learning Rate: 0.0040714
	LOSS [training: 0.1977018787400512 | validation: 0.37355146779435344]
	TIME [epoch: 3.38 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1736303158515267		[learning rate: 0.0040522]
	Learning Rate: 0.00405221
	LOSS [training: 0.1736303158515267 | validation: 0.3377005540119248]
	TIME [epoch: 3.36 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.164264658979076		[learning rate: 0.0040331]
	Learning Rate: 0.00403312
	LOSS [training: 0.164264658979076 | validation: 0.34367998007221495]
	TIME [epoch: 3.36 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22553701884733246		[learning rate: 0.0040141]
	Learning Rate: 0.00401411
	LOSS [training: 0.22553701884733246 | validation: 0.3652637443425983]
	TIME [epoch: 3.37 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16138059951481645		[learning rate: 0.0039952]
	Learning Rate: 0.0039952
	LOSS [training: 0.16138059951481645 | validation: 0.3421263883217995]
	TIME [epoch: 3.37 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17519344092954287		[learning rate: 0.0039764]
	Learning Rate: 0.00397637
	LOSS [training: 0.17519344092954287 | validation: 0.3778940766340209]
	TIME [epoch: 3.36 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19431561752023982		[learning rate: 0.0039576]
	Learning Rate: 0.00395764
	LOSS [training: 0.19431561752023982 | validation: 0.3451303961501601]
	TIME [epoch: 3.35 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16340778502275238		[learning rate: 0.003939]
	Learning Rate: 0.00393899
	LOSS [training: 0.16340778502275238 | validation: 0.34857220412611795]
	TIME [epoch: 3.36 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17199504075419014		[learning rate: 0.0039204]
	Learning Rate: 0.00392043
	LOSS [training: 0.17199504075419014 | validation: 0.30692183527040373]
	TIME [epoch: 3.36 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16173232331992393		[learning rate: 0.003902]
	Learning Rate: 0.00390195
	LOSS [training: 0.16173232331992393 | validation: 0.30813991805440344]
	TIME [epoch: 3.36 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17036100098939028		[learning rate: 0.0038836]
	Learning Rate: 0.00388357
	LOSS [training: 0.17036100098939028 | validation: 0.3771835110790641]
	TIME [epoch: 3.37 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17293152256600988		[learning rate: 0.0038653]
	Learning Rate: 0.00386527
	LOSS [training: 0.17293152256600988 | validation: 0.36275599664598557]
	TIME [epoch: 3.35 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18803752563011922		[learning rate: 0.0038471]
	Learning Rate: 0.00384705
	LOSS [training: 0.18803752563011922 | validation: 0.3921443654413272]
	TIME [epoch: 3.36 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1710589323790478		[learning rate: 0.0038289]
	Learning Rate: 0.00382893
	LOSS [training: 0.1710589323790478 | validation: 0.35115526377425843]
	TIME [epoch: 3.36 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18646906903320645		[learning rate: 0.0038109]
	Learning Rate: 0.00381088
	LOSS [training: 0.18646906903320645 | validation: 0.345404321815521]
	TIME [epoch: 3.36 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1748344144604655		[learning rate: 0.0037929]
	Learning Rate: 0.00379293
	LOSS [training: 0.1748344144604655 | validation: 0.29806884224695707]
	TIME [epoch: 3.35 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14816885674929084		[learning rate: 0.0037751]
	Learning Rate: 0.00377505
	LOSS [training: 0.14816885674929084 | validation: 0.40901113823333035]
	TIME [epoch: 3.36 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16815707836337684		[learning rate: 0.0037573]
	Learning Rate: 0.00375726
	LOSS [training: 0.16815707836337684 | validation: 0.37166564953034736]
	TIME [epoch: 3.36 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18969849499300762		[learning rate: 0.0037396]
	Learning Rate: 0.00373956
	LOSS [training: 0.18969849499300762 | validation: 0.347132966488725]
	TIME [epoch: 3.37 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19871704421835754		[learning rate: 0.0037219]
	Learning Rate: 0.00372194
	LOSS [training: 0.19871704421835754 | validation: 0.33690878126357626]
	TIME [epoch: 3.37 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16208046795419373		[learning rate: 0.0037044]
	Learning Rate: 0.0037044
	LOSS [training: 0.16208046795419373 | validation: 0.38080815061970597]
	TIME [epoch: 3.37 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17822052040385955		[learning rate: 0.0036869]
	Learning Rate: 0.00368695
	LOSS [training: 0.17822052040385955 | validation: 0.37344308750558325]
	TIME [epoch: 3.36 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17455553494188142		[learning rate: 0.0036696]
	Learning Rate: 0.00366957
	LOSS [training: 0.17455553494188142 | validation: 0.321907577716833]
	TIME [epoch: 3.36 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1660313594941794		[learning rate: 0.0036523]
	Learning Rate: 0.00365228
	LOSS [training: 0.1660313594941794 | validation: 0.29888115919637576]
	TIME [epoch: 3.36 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17782237653953184		[learning rate: 0.0036351]
	Learning Rate: 0.00363507
	LOSS [training: 0.17782237653953184 | validation: 0.3535725155747839]
	TIME [epoch: 3.37 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16154400669790023		[learning rate: 0.0036179]
	Learning Rate: 0.00361794
	LOSS [training: 0.16154400669790023 | validation: 0.34753498916246245]
	TIME [epoch: 3.35 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17909062769178205		[learning rate: 0.0036009]
	Learning Rate: 0.00360089
	LOSS [training: 0.17909062769178205 | validation: 0.3260336613452367]
	TIME [epoch: 3.36 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1756887742739325		[learning rate: 0.0035839]
	Learning Rate: 0.00358393
	LOSS [training: 0.1756887742739325 | validation: 0.32978706065063507]
	TIME [epoch: 3.38 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19725928582324215		[learning rate: 0.003567]
	Learning Rate: 0.00356704
	LOSS [training: 0.19725928582324215 | validation: 0.28936202786900855]
	TIME [epoch: 3.37 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v5_20240715_175905/states/model_facs_v3_dec2b_2dpca_v5_256.pth
	Model improved!!!
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.196381304028584		[learning rate: 0.0035502]
	Learning Rate: 0.00355023
	LOSS [training: 0.196381304028584 | validation: 0.312480955008206]
	TIME [epoch: 3.37 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1768913867677106		[learning rate: 0.0035335]
	Learning Rate: 0.0035335
	LOSS [training: 0.1768913867677106 | validation: 0.3336617891548686]
	TIME [epoch: 3.36 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1651160132089645		[learning rate: 0.0035168]
	Learning Rate: 0.00351685
	LOSS [training: 0.1651160132089645 | validation: 0.40706010222589245]
	TIME [epoch: 3.36 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23182317614366996		[learning rate: 0.0035003]
	Learning Rate: 0.00350028
	LOSS [training: 0.23182317614366996 | validation: 0.3579163237915468]
	TIME [epoch: 3.36 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17680297640089332		[learning rate: 0.0034838]
	Learning Rate: 0.00348378
	LOSS [training: 0.17680297640089332 | validation: 0.3435549035036439]
	TIME [epoch: 3.37 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15587113773011596		[learning rate: 0.0034674]
	Learning Rate: 0.00346737
	LOSS [training: 0.15587113773011596 | validation: 0.32966020249810346]
	TIME [epoch: 3.36 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1700909197790105		[learning rate: 0.003451]
	Learning Rate: 0.00345103
	LOSS [training: 0.1700909197790105 | validation: 0.4585111336337659]
	TIME [epoch: 3.35 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19599607736118238		[learning rate: 0.0034348]
	Learning Rate: 0.00343477
	LOSS [training: 0.19599607736118238 | validation: 0.3105802614401616]
	TIME [epoch: 3.36 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15406679342953475		[learning rate: 0.0034186]
	Learning Rate: 0.00341858
	LOSS [training: 0.15406679342953475 | validation: 0.3340302490565015]
	TIME [epoch: 3.37 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17406053809768146		[learning rate: 0.0034025]
	Learning Rate: 0.00340247
	LOSS [training: 0.17406053809768146 | validation: 0.33880554356772496]
	TIME [epoch: 3.35 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17109011371020835		[learning rate: 0.0033864]
	Learning Rate: 0.00338644
	LOSS [training: 0.17109011371020835 | validation: 0.31343591069938487]
	TIME [epoch: 3.36 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1599748295826871		[learning rate: 0.0033705]
	Learning Rate: 0.00337048
	LOSS [training: 0.1599748295826871 | validation: 0.29252244260559873]
	TIME [epoch: 3.36 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15765149049163488		[learning rate: 0.0033546]
	Learning Rate: 0.0033546
	LOSS [training: 0.15765149049163488 | validation: 0.3839490445014125]
	TIME [epoch: 3.36 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16192549321128386		[learning rate: 0.0033388]
	Learning Rate: 0.00333879
	LOSS [training: 0.16192549321128386 | validation: 0.31696365214795563]
	TIME [epoch: 3.36 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16514801983838567		[learning rate: 0.0033231]
	Learning Rate: 0.00332306
	LOSS [training: 0.16514801983838567 | validation: 0.33410987620452764]
	TIME [epoch: 3.35 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17749927949512873		[learning rate: 0.0033074]
	Learning Rate: 0.0033074
	LOSS [training: 0.17749927949512873 | validation: 0.3114366401249315]
	TIME [epoch: 3.36 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17359124050772484		[learning rate: 0.0032918]
	Learning Rate: 0.00329182
	LOSS [training: 0.17359124050772484 | validation: 0.40467249201924077]
	TIME [epoch: 3.35 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19406476014975194		[learning rate: 0.0032763]
	Learning Rate: 0.00327631
	LOSS [training: 0.19406476014975194 | validation: 0.3189557481395392]
	TIME [epoch: 3.36 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14626319210998798		[learning rate: 0.0032609]
	Learning Rate: 0.00326087
	LOSS [training: 0.14626319210998798 | validation: 0.3345460106022161]
	TIME [epoch: 3.36 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1620587237634777		[learning rate: 0.0032455]
	Learning Rate: 0.0032455
	LOSS [training: 0.1620587237634777 | validation: 0.3735905026306251]
	TIME [epoch: 3.36 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18699480018717032		[learning rate: 0.0032302]
	Learning Rate: 0.00323021
	LOSS [training: 0.18699480018717032 | validation: 0.37988878746594734]
	TIME [epoch: 3.37 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18699527165027346		[learning rate: 0.003215]
	Learning Rate: 0.00321499
	LOSS [training: 0.18699527165027346 | validation: 0.303337640602873]
	TIME [epoch: 3.37 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2017048729144686		[learning rate: 0.0031998]
	Learning Rate: 0.00319984
	LOSS [training: 0.2017048729144686 | validation: 0.32778762123133315]
	TIME [epoch: 3.36 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1449597180039842		[learning rate: 0.0031848]
	Learning Rate: 0.00318476
	LOSS [training: 0.1449597180039842 | validation: 0.34807372846706236]
	TIME [epoch: 3.36 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18955642059373928		[learning rate: 0.0031698]
	Learning Rate: 0.00316975
	LOSS [training: 0.18955642059373928 | validation: 0.3463229304513506]
	TIME [epoch: 3.35 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14174559403031184		[learning rate: 0.0031548]
	Learning Rate: 0.00315482
	LOSS [training: 0.14174559403031184 | validation: 0.3403199368755707]
	TIME [epoch: 3.35 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16839404899507157		[learning rate: 0.00314]
	Learning Rate: 0.00313995
	LOSS [training: 0.16839404899507157 | validation: 0.36658048516644426]
	TIME [epoch: 3.36 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16006091369864636		[learning rate: 0.0031252]
	Learning Rate: 0.00312516
	LOSS [training: 0.16006091369864636 | validation: 0.3431261970581091]
	TIME [epoch: 3.35 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17015990585692417		[learning rate: 0.0031104]
	Learning Rate: 0.00311043
	LOSS [training: 0.17015990585692417 | validation: 0.33986157755944224]
	TIME [epoch: 3.35 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14693653581945726		[learning rate: 0.0030958]
	Learning Rate: 0.00309577
	LOSS [training: 0.14693653581945726 | validation: 0.3527007973851835]
	TIME [epoch: 3.37 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18985889493298141		[learning rate: 0.0030812]
	Learning Rate: 0.00308119
	LOSS [training: 0.18985889493298141 | validation: 0.3381632531385226]
	TIME [epoch: 3.36 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18529822931295212		[learning rate: 0.0030667]
	Learning Rate: 0.00306667
	LOSS [training: 0.18529822931295212 | validation: 0.34082354153321887]
	TIME [epoch: 3.37 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1887014699080668		[learning rate: 0.0030522]
	Learning Rate: 0.00305222
	LOSS [training: 0.1887014699080668 | validation: 0.33834910818920216]
	TIME [epoch: 3.36 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1502661055215554		[learning rate: 0.0030378]
	Learning Rate: 0.00303783
	LOSS [training: 0.1502661055215554 | validation: 0.32939573260300103]
	TIME [epoch: 3.35 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1638409597001887		[learning rate: 0.0030235]
	Learning Rate: 0.00302352
	LOSS [training: 0.1638409597001887 | validation: 0.29400737598706056]
	TIME [epoch: 3.35 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16315221617851036		[learning rate: 0.0030093]
	Learning Rate: 0.00300927
	LOSS [training: 0.16315221617851036 | validation: 0.30795582353587314]
	TIME [epoch: 3.38 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1734913107241726		[learning rate: 0.0029951]
	Learning Rate: 0.00299509
	LOSS [training: 0.1734913107241726 | validation: 0.31029041288773024]
	TIME [epoch: 3.36 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16582843889052543		[learning rate: 0.002981]
	Learning Rate: 0.00298098
	LOSS [training: 0.16582843889052543 | validation: 0.3358954497984763]
	TIME [epoch: 3.36 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20055278325067616		[learning rate: 0.0029669]
	Learning Rate: 0.00296693
	LOSS [training: 0.20055278325067616 | validation: 0.34614966531167046]
	TIME [epoch: 3.36 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19204495953893597		[learning rate: 0.002953]
	Learning Rate: 0.00295295
	LOSS [training: 0.19204495953893597 | validation: 0.34913758036752957]
	TIME [epoch: 3.36 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16449607659864335		[learning rate: 0.002939]
	Learning Rate: 0.00293904
	LOSS [training: 0.16449607659864335 | validation: 0.3873162849213819]
	TIME [epoch: 3.36 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20805407359694966		[learning rate: 0.0029252]
	Learning Rate: 0.00292519
	LOSS [training: 0.20805407359694966 | validation: 0.2838562095117206]
	TIME [epoch: 3.35 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v5_20240715_175905/states/model_facs_v3_dec2b_2dpca_v5_298.pth
	Model improved!!!
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16523728048592556		[learning rate: 0.0029114]
	Learning Rate: 0.0029114
	LOSS [training: 0.16523728048592556 | validation: 0.3815625789171123]
	TIME [epoch: 3.36 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1774969146232231		[learning rate: 0.0028977]
	Learning Rate: 0.00289769
	LOSS [training: 0.1774969146232231 | validation: 0.35250260208727724]
	TIME [epoch: 3.36 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1612375467738999		[learning rate: 0.002884]
	Learning Rate: 0.00288403
	LOSS [training: 0.1612375467738999 | validation: 0.41243717081450076]
	TIME [epoch: 3.37 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1563819633124721		[learning rate: 0.0028704]
	Learning Rate: 0.00287044
	LOSS [training: 0.1563819633124721 | validation: 0.32092955845278004]
	TIME [epoch: 3.36 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1657058428215636		[learning rate: 0.0028569]
	Learning Rate: 0.00285692
	LOSS [training: 0.1657058428215636 | validation: 0.3528981407835294]
	TIME [epoch: 3.35 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1960001926302894		[learning rate: 0.0028435]
	Learning Rate: 0.00284345
	LOSS [training: 0.1960001926302894 | validation: 0.3770274845111098]
	TIME [epoch: 3.37 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20178180255721345		[learning rate: 0.0028301]
	Learning Rate: 0.00283005
	LOSS [training: 0.20178180255721345 | validation: 0.33879450208694595]
	TIME [epoch: 3.36 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25086232636466915		[learning rate: 0.0028167]
	Learning Rate: 0.00281672
	LOSS [training: 0.25086232636466915 | validation: 0.37449859197739355]
	TIME [epoch: 3.36 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21127032175745114		[learning rate: 0.0028034]
	Learning Rate: 0.00280345
	LOSS [training: 0.21127032175745114 | validation: 0.3419662279405248]
	TIME [epoch: 3.35 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14217054637368298		[learning rate: 0.0027902]
	Learning Rate: 0.00279024
	LOSS [training: 0.14217054637368298 | validation: 0.30401553136939485]
	TIME [epoch: 3.36 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15407943684122455		[learning rate: 0.0027771]
	Learning Rate: 0.00277709
	LOSS [training: 0.15407943684122455 | validation: 0.2984200604909127]
	TIME [epoch: 3.36 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11783492077606154		[learning rate: 0.002764]
	Learning Rate: 0.002764
	LOSS [training: 0.11783492077606154 | validation: 0.33833652063124203]
	TIME [epoch: 3.36 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1532412310552777		[learning rate: 0.002751]
	Learning Rate: 0.00275098
	LOSS [training: 0.1532412310552777 | validation: 0.30335708197109396]
	TIME [epoch: 3.35 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.174001405061889		[learning rate: 0.002738]
	Learning Rate: 0.00273802
	LOSS [training: 0.174001405061889 | validation: 0.29028473103758456]
	TIME [epoch: 3.36 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16924908286594612		[learning rate: 0.0027251]
	Learning Rate: 0.00272511
	LOSS [training: 0.16924908286594612 | validation: 0.3241314660439806]
	TIME [epoch: 3.35 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15232945502167825		[learning rate: 0.0027123]
	Learning Rate: 0.00271227
	LOSS [training: 0.15232945502167825 | validation: 0.3979789457159965]
	TIME [epoch: 3.36 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21267318807182808		[learning rate: 0.0026995]
	Learning Rate: 0.00269949
	LOSS [training: 0.21267318807182808 | validation: 0.28474601602337457]
	TIME [epoch: 3.36 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17707624588422077		[learning rate: 0.0026868]
	Learning Rate: 0.00268677
	LOSS [training: 0.17707624588422077 | validation: 0.34597072716782723]
	TIME [epoch: 3.36 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15778367762164416		[learning rate: 0.0026741]
	Learning Rate: 0.00267411
	LOSS [training: 0.15778367762164416 | validation: 0.3492911504405577]
	TIME [epoch: 3.36 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16806696124015114		[learning rate: 0.0026615]
	Learning Rate: 0.00266151
	LOSS [training: 0.16806696124015114 | validation: 0.33146576010478945]
	TIME [epoch: 3.36 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1497404856442192		[learning rate: 0.002649]
	Learning Rate: 0.00264897
	LOSS [training: 0.1497404856442192 | validation: 0.2917062315282672]
	TIME [epoch: 3.37 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14620697352880752		[learning rate: 0.0026365]
	Learning Rate: 0.00263649
	LOSS [training: 0.14620697352880752 | validation: 0.36579747509830496]
	TIME [epoch: 3.36 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15152476703675602		[learning rate: 0.0026241]
	Learning Rate: 0.00262406
	LOSS [training: 0.15152476703675602 | validation: 0.39173618601357973]
	TIME [epoch: 3.37 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19048957045364465		[learning rate: 0.0026117]
	Learning Rate: 0.0026117
	LOSS [training: 0.19048957045364465 | validation: 0.3426541707748973]
	TIME [epoch: 3.36 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15777306268143976		[learning rate: 0.0025994]
	Learning Rate: 0.00259939
	LOSS [training: 0.15777306268143976 | validation: 0.3043622976958814]
	TIME [epoch: 3.35 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1600485291825409		[learning rate: 0.0025871]
	Learning Rate: 0.00258714
	LOSS [training: 0.1600485291825409 | validation: 0.3325496715417301]
	TIME [epoch: 3.37 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20187574013664575		[learning rate: 0.002575]
	Learning Rate: 0.00257495
	LOSS [training: 0.20187574013664575 | validation: 0.3870448600327667]
	TIME [epoch: 3.35 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.143746675994641		[learning rate: 0.0025628]
	Learning Rate: 0.00256282
	LOSS [training: 0.143746675994641 | validation: 0.35682552166941733]
	TIME [epoch: 3.36 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1688056152732564		[learning rate: 0.0025507]
	Learning Rate: 0.00255074
	LOSS [training: 0.1688056152732564 | validation: 0.3479461433116282]
	TIME [epoch: 3.36 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1673535129648048		[learning rate: 0.0025387]
	Learning Rate: 0.00253872
	LOSS [training: 0.1673535129648048 | validation: 0.33087525416911084]
	TIME [epoch: 3.35 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13972758494394685		[learning rate: 0.0025268]
	Learning Rate: 0.00252676
	LOSS [training: 0.13972758494394685 | validation: 0.340420777739569]
	TIME [epoch: 3.35 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1502917461241987		[learning rate: 0.0025149]
	Learning Rate: 0.00251485
	LOSS [training: 0.1502917461241987 | validation: 0.3301425729596784]
	TIME [epoch: 3.35 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18201810849549382		[learning rate: 0.002503]
	Learning Rate: 0.002503
	LOSS [training: 0.18201810849549382 | validation: 0.31442927165087853]
	TIME [epoch: 3.36 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1465119172171263		[learning rate: 0.0024912]
	Learning Rate: 0.00249121
	LOSS [training: 0.1465119172171263 | validation: 0.32819074129724407]
	TIME [epoch: 3.38 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17223908429187235		[learning rate: 0.0024795]
	Learning Rate: 0.00247947
	LOSS [training: 0.17223908429187235 | validation: 0.3267704964689353]
	TIME [epoch: 3.36 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20183331409293892		[learning rate: 0.0024678]
	Learning Rate: 0.00246779
	LOSS [training: 0.20183331409293892 | validation: 0.3067515734932084]
	TIME [epoch: 3.36 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1660377001504487		[learning rate: 0.0024562]
	Learning Rate: 0.00245616
	LOSS [training: 0.1660377001504487 | validation: 0.3226219849760329]
	TIME [epoch: 3.36 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15626978673494046		[learning rate: 0.0024446]
	Learning Rate: 0.00244458
	LOSS [training: 0.15626978673494046 | validation: 0.332618435323938]
	TIME [epoch: 3.37 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1365074525537214		[learning rate: 0.0024331]
	Learning Rate: 0.00243307
	LOSS [training: 0.1365074525537214 | validation: 0.3032830241434755]
	TIME [epoch: 3.35 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15903214423300086		[learning rate: 0.0024216]
	Learning Rate: 0.0024216
	LOSS [training: 0.15903214423300086 | validation: 0.32204694463313144]
	TIME [epoch: 3.36 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14186604577583828		[learning rate: 0.0024102]
	Learning Rate: 0.00241019
	LOSS [training: 0.14186604577583828 | validation: 0.2870139341593579]
	TIME [epoch: 3.36 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1392355572934717		[learning rate: 0.0023988]
	Learning Rate: 0.00239883
	LOSS [training: 0.1392355572934717 | validation: 0.36188990860922327]
	TIME [epoch: 3.36 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1752351311501701		[learning rate: 0.0023875]
	Learning Rate: 0.00238753
	LOSS [training: 0.1752351311501701 | validation: 0.31337846323285856]
	TIME [epoch: 3.35 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1551924223257266		[learning rate: 0.0023763]
	Learning Rate: 0.00237628
	LOSS [training: 0.1551924223257266 | validation: 0.3524688225437954]
	TIME [epoch: 3.36 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1401627237296644		[learning rate: 0.0023651]
	Learning Rate: 0.00236508
	LOSS [training: 0.1401627237296644 | validation: 0.3085068631028183]
	TIME [epoch: 3.36 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19115886203320487		[learning rate: 0.0023539]
	Learning Rate: 0.00235394
	LOSS [training: 0.19115886203320487 | validation: 0.38501106390713846]
	TIME [epoch: 3.38 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15838160579472194		[learning rate: 0.0023428]
	Learning Rate: 0.00234285
	LOSS [training: 0.15838160579472194 | validation: 0.34685017615479186]
	TIME [epoch: 3.37 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1351139435582366		[learning rate: 0.0023318]
	Learning Rate: 0.00233181
	LOSS [training: 0.1351139435582366 | validation: 0.3112668415274688]
	TIME [epoch: 3.37 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15762680132405726		[learning rate: 0.0023208]
	Learning Rate: 0.00232082
	LOSS [training: 0.15762680132405726 | validation: 0.3252613680717672]
	TIME [epoch: 3.36 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16326576657951658		[learning rate: 0.0023099]
	Learning Rate: 0.00230988
	LOSS [training: 0.16326576657951658 | validation: 0.3650655774934759]
	TIME [epoch: 3.37 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16839898426686292		[learning rate: 0.002299]
	Learning Rate: 0.002299
	LOSS [training: 0.16839898426686292 | validation: 0.39000752914554826]
	TIME [epoch: 3.36 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17238610863174586		[learning rate: 0.0022882]
	Learning Rate: 0.00228816
	LOSS [training: 0.17238610863174586 | validation: 0.3189682206114529]
	TIME [epoch: 3.35 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17175810690791754		[learning rate: 0.0022774]
	Learning Rate: 0.00227738
	LOSS [training: 0.17175810690791754 | validation: 0.35454147252121543]
	TIME [epoch: 3.36 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18985533689473794		[learning rate: 0.0022667]
	Learning Rate: 0.00226665
	LOSS [training: 0.18985533689473794 | validation: 0.3414640029021533]
	TIME [epoch: 3.36 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16987371910667365		[learning rate: 0.002256]
	Learning Rate: 0.00225597
	LOSS [training: 0.16987371910667365 | validation: 0.3085646187041932]
	TIME [epoch: 3.37 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1691134036559375		[learning rate: 0.0022453]
	Learning Rate: 0.00224534
	LOSS [training: 0.1691134036559375 | validation: 0.3181739858057767]
	TIME [epoch: 3.36 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13349468686688842		[learning rate: 0.0022348]
	Learning Rate: 0.00223476
	LOSS [training: 0.13349468686688842 | validation: 0.3445169111943548]
	TIME [epoch: 3.36 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17347060597595956		[learning rate: 0.0022242]
	Learning Rate: 0.00222423
	LOSS [training: 0.17347060597595956 | validation: 0.31634481561731587]
	TIME [epoch: 3.34 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15050643954366136		[learning rate: 0.0022137]
	Learning Rate: 0.00221375
	LOSS [training: 0.15050643954366136 | validation: 0.3434601718011503]
	TIME [epoch: 3.36 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1496667090124118		[learning rate: 0.0022033]
	Learning Rate: 0.00220332
	LOSS [training: 0.1496667090124118 | validation: 0.31815412158935724]
	TIME [epoch: 3.35 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17046859149892302		[learning rate: 0.0021929]
	Learning Rate: 0.00219293
	LOSS [training: 0.17046859149892302 | validation: 0.3678839094003625]
	TIME [epoch: 3.37 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1663700682186202		[learning rate: 0.0021826]
	Learning Rate: 0.0021826
	LOSS [training: 0.1663700682186202 | validation: 0.3067624417332564]
	TIME [epoch: 3.35 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2179106526537714		[learning rate: 0.0021723]
	Learning Rate: 0.00217232
	LOSS [training: 0.2179106526537714 | validation: 0.30090702225537064]
	TIME [epoch: 3.35 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1741043958999719		[learning rate: 0.0021621]
	Learning Rate: 0.00216208
	LOSS [training: 0.1741043958999719 | validation: 0.33065117880976086]
	TIME [epoch: 3.36 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17412279291532654		[learning rate: 0.0021519]
	Learning Rate: 0.00215189
	LOSS [training: 0.17412279291532654 | validation: 0.30088582958098337]
	TIME [epoch: 3.35 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1387060576520242		[learning rate: 0.0021418]
	Learning Rate: 0.00214175
	LOSS [training: 0.1387060576520242 | validation: 0.31248087383271866]
	TIME [epoch: 3.36 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16335082363407466		[learning rate: 0.0021317]
	Learning Rate: 0.00213166
	LOSS [training: 0.16335082363407466 | validation: 0.38415136063595723]
	TIME [epoch: 3.36 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15175850566471225		[learning rate: 0.0021216]
	Learning Rate: 0.00212162
	LOSS [training: 0.15175850566471225 | validation: 0.3139157303409477]
	TIME [epoch: 3.36 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15727680490967916		[learning rate: 0.0021116]
	Learning Rate: 0.00211162
	LOSS [training: 0.15727680490967916 | validation: 0.3965017622769862]
	TIME [epoch: 3.36 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1951824957185493		[learning rate: 0.0021017]
	Learning Rate: 0.00210167
	LOSS [training: 0.1951824957185493 | validation: 0.3343604360477459]
	TIME [epoch: 3.37 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1783916949447709		[learning rate: 0.0020918]
	Learning Rate: 0.00209176
	LOSS [training: 0.1783916949447709 | validation: 0.32577532271088483]
	TIME [epoch: 3.36 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15206371987963907		[learning rate: 0.0020819]
	Learning Rate: 0.00208191
	LOSS [training: 0.15206371987963907 | validation: 0.3490993877851356]
	TIME [epoch: 3.36 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14676761620360992		[learning rate: 0.0020721]
	Learning Rate: 0.0020721
	LOSS [training: 0.14676761620360992 | validation: 0.2768568956226624]
	TIME [epoch: 3.37 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v5_20240715_175905/states/model_facs_v3_dec2b_2dpca_v5_371.pth
	Model improved!!!
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1585927637937347		[learning rate: 0.0020623]
	Learning Rate: 0.00206233
	LOSS [training: 0.1585927637937347 | validation: 0.33112352242886905]
	TIME [epoch: 3.37 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1529056043989358		[learning rate: 0.0020526]
	Learning Rate: 0.00205262
	LOSS [training: 0.1529056043989358 | validation: 0.33019640558467644]
	TIME [epoch: 3.36 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14751968823421943		[learning rate: 0.0020429]
	Learning Rate: 0.00204294
	LOSS [training: 0.14751968823421943 | validation: 0.33502786808377116]
	TIME [epoch: 3.35 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12651094823327685		[learning rate: 0.0020333]
	Learning Rate: 0.00203332
	LOSS [training: 0.12651094823327685 | validation: 0.3224888491586099]
	TIME [epoch: 3.37 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15740079897605894		[learning rate: 0.0020237]
	Learning Rate: 0.00202374
	LOSS [training: 0.15740079897605894 | validation: 0.2927595722409437]
	TIME [epoch: 3.36 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1514291044146742		[learning rate: 0.0020142]
	Learning Rate: 0.0020142
	LOSS [training: 0.1514291044146742 | validation: 0.2877983452490729]
	TIME [epoch: 3.36 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1532301648938637		[learning rate: 0.0020047]
	Learning Rate: 0.00200471
	LOSS [training: 0.1532301648938637 | validation: 0.29216717324304003]
	TIME [epoch: 3.36 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15031379417182192		[learning rate: 0.0019953]
	Learning Rate: 0.00199526
	LOSS [training: 0.15031379417182192 | validation: 0.3197176432348843]
	TIME [epoch: 3.38 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1751453552569352		[learning rate: 0.0019859]
	Learning Rate: 0.00198586
	LOSS [training: 0.1751453552569352 | validation: 0.310177329954888]
	TIME [epoch: 3.35 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1544023660110219		[learning rate: 0.0019765]
	Learning Rate: 0.0019765
	LOSS [training: 0.1544023660110219 | validation: 0.32193779286341695]
	TIME [epoch: 3.36 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12693197768289546		[learning rate: 0.0019672]
	Learning Rate: 0.00196719
	LOSS [training: 0.12693197768289546 | validation: 0.30555271183910343]
	TIME [epoch: 3.37 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14620326870659112		[learning rate: 0.0019579]
	Learning Rate: 0.00195792
	LOSS [training: 0.14620326870659112 | validation: 0.3192172293072168]
	TIME [epoch: 3.36 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15676673717769707		[learning rate: 0.0019487]
	Learning Rate: 0.00194869
	LOSS [training: 0.15676673717769707 | validation: 0.393004405013625]
	TIME [epoch: 3.39 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14367109111956167		[learning rate: 0.0019395]
	Learning Rate: 0.00193951
	LOSS [training: 0.14367109111956167 | validation: 0.31777322254675255]
	TIME [epoch: 3.36 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.187639605102531		[learning rate: 0.0019304]
	Learning Rate: 0.00193037
	LOSS [training: 0.187639605102531 | validation: 0.3206410302521453]
	TIME [epoch: 3.36 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16129753347008768		[learning rate: 0.0019213]
	Learning Rate: 0.00192128
	LOSS [training: 0.16129753347008768 | validation: 0.3820498514081214]
	TIME [epoch: 3.35 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16134000767241158		[learning rate: 0.0019122]
	Learning Rate: 0.00191222
	LOSS [training: 0.16134000767241158 | validation: 0.2903880744665241]
	TIME [epoch: 3.36 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15811360468414148		[learning rate: 0.0019032]
	Learning Rate: 0.00190321
	LOSS [training: 0.15811360468414148 | validation: 0.32838653600106904]
	TIME [epoch: 3.36 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15032130758865828		[learning rate: 0.0018942]
	Learning Rate: 0.00189424
	LOSS [training: 0.15032130758865828 | validation: 0.3525237410981898]
	TIME [epoch: 3.36 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1484177449837826		[learning rate: 0.0018853]
	Learning Rate: 0.00188532
	LOSS [training: 0.1484177449837826 | validation: 0.3157196294040577]
	TIME [epoch: 3.35 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15170857915468178		[learning rate: 0.0018764]
	Learning Rate: 0.00187643
	LOSS [training: 0.15170857915468178 | validation: 0.3562048301549556]
	TIME [epoch: 3.36 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13479220791909952		[learning rate: 0.0018676]
	Learning Rate: 0.00186759
	LOSS [training: 0.13479220791909952 | validation: 0.3262776626762283]
	TIME [epoch: 3.35 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1661192374409003		[learning rate: 0.0018588]
	Learning Rate: 0.00185879
	LOSS [training: 0.1661192374409003 | validation: 0.32445111259635306]
	TIME [epoch: 3.36 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14061498349456106		[learning rate: 0.00185]
	Learning Rate: 0.00185003
	LOSS [training: 0.14061498349456106 | validation: 0.28444568145554344]
	TIME [epoch: 3.35 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16058354878033265		[learning rate: 0.0018413]
	Learning Rate: 0.00184132
	LOSS [training: 0.16058354878033265 | validation: 0.3419745293445862]
	TIME [epoch: 3.35 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14153973809444056		[learning rate: 0.0018326]
	Learning Rate: 0.00183264
	LOSS [training: 0.14153973809444056 | validation: 0.31285916239054945]
	TIME [epoch: 3.35 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1863973178162426		[learning rate: 0.001824]
	Learning Rate: 0.001824
	LOSS [training: 0.1863973178162426 | validation: 0.3695962545393772]
	TIME [epoch: 3.36 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17087135934375453		[learning rate: 0.0018154]
	Learning Rate: 0.00181541
	LOSS [training: 0.17087135934375453 | validation: 0.3173292086148359]
	TIME [epoch: 3.37 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1820534665658153		[learning rate: 0.0018069]
	Learning Rate: 0.00180685
	LOSS [training: 0.1820534665658153 | validation: 0.33994905644577195]
	TIME [epoch: 3.36 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16206446331105442		[learning rate: 0.0017983]
	Learning Rate: 0.00179834
	LOSS [training: 0.16206446331105442 | validation: 0.32356611892563575]
	TIME [epoch: 3.38 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1692843230439349		[learning rate: 0.0017899]
	Learning Rate: 0.00178987
	LOSS [training: 0.1692843230439349 | validation: 0.33892268220721605]
	TIME [epoch: 3.36 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18241309075807863		[learning rate: 0.0017814]
	Learning Rate: 0.00178143
	LOSS [training: 0.18241309075807863 | validation: 0.316135159084383]
	TIME [epoch: 3.37 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17995227761067767		[learning rate: 0.001773]
	Learning Rate: 0.00177304
	LOSS [training: 0.17995227761067767 | validation: 0.31377971951004346]
	TIME [epoch: 3.37 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14978428078079828		[learning rate: 0.0017647]
	Learning Rate: 0.00176468
	LOSS [training: 0.14978428078079828 | validation: 0.28569114668708334]
	TIME [epoch: 3.37 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16097445229810153		[learning rate: 0.0017564]
	Learning Rate: 0.00175637
	LOSS [training: 0.16097445229810153 | validation: 0.2842493342247189]
	TIME [epoch: 3.36 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18109033008413045		[learning rate: 0.0017481]
	Learning Rate: 0.00174809
	LOSS [training: 0.18109033008413045 | validation: 0.3810815285539751]
	TIME [epoch: 3.37 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18682465515361701		[learning rate: 0.0017399]
	Learning Rate: 0.00173985
	LOSS [training: 0.18682465515361701 | validation: 0.32759932791413854]
	TIME [epoch: 3.39 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14368233092559546		[learning rate: 0.0017317]
	Learning Rate: 0.00173166
	LOSS [training: 0.14368233092559546 | validation: 0.3422124251685518]
	TIME [epoch: 3.37 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15897931334918028		[learning rate: 0.0017235]
	Learning Rate: 0.0017235
	LOSS [training: 0.15897931334918028 | validation: 0.31927456794937614]
	TIME [epoch: 3.37 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13868184497021727		[learning rate: 0.0017154]
	Learning Rate: 0.00171537
	LOSS [training: 0.13868184497021727 | validation: 0.3223788027854515]
	TIME [epoch: 3.36 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14407216077511306		[learning rate: 0.0017073]
	Learning Rate: 0.00170729
	LOSS [training: 0.14407216077511306 | validation: 0.3343800219993013]
	TIME [epoch: 3.36 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2253135541143524		[learning rate: 0.0016992]
	Learning Rate: 0.00169925
	LOSS [training: 0.2253135541143524 | validation: 0.33153089341621306]
	TIME [epoch: 3.37 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1622905746213945		[learning rate: 0.0016912]
	Learning Rate: 0.00169124
	LOSS [training: 0.1622905746213945 | validation: 0.3187629561755656]
	TIME [epoch: 3.36 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1424244367405749		[learning rate: 0.0016833]
	Learning Rate: 0.00168327
	LOSS [training: 0.1424244367405749 | validation: 0.32333182267098076]
	TIME [epoch: 3.37 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17394504578728215		[learning rate: 0.0016753]
	Learning Rate: 0.00167534
	LOSS [training: 0.17394504578728215 | validation: 0.29371288644709626]
	TIME [epoch: 3.35 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12785719241196175		[learning rate: 0.0016674]
	Learning Rate: 0.00166744
	LOSS [training: 0.12785719241196175 | validation: 0.3570313985631786]
	TIME [epoch: 3.38 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1281678058465892		[learning rate: 0.0016596]
	Learning Rate: 0.00165959
	LOSS [training: 0.1281678058465892 | validation: 0.3505276589409476]
	TIME [epoch: 3.36 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16725230830338694		[learning rate: 0.0016518]
	Learning Rate: 0.00165177
	LOSS [training: 0.16725230830338694 | validation: 0.2654582425003698]
	TIME [epoch: 3.36 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v5_20240715_175905/states/model_facs_v3_dec2b_2dpca_v5_419.pth
	Model improved!!!
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14768913512651186		[learning rate: 0.001644]
	Learning Rate: 0.00164398
	LOSS [training: 0.14768913512651186 | validation: 0.3159042947834882]
	TIME [epoch: 3.37 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1528192661399527		[learning rate: 0.0016362]
	Learning Rate: 0.00163624
	LOSS [training: 0.1528192661399527 | validation: 0.302289747030956]
	TIME [epoch: 3.36 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13742223717901644		[learning rate: 0.0016285]
	Learning Rate: 0.00162853
	LOSS [training: 0.13742223717901644 | validation: 0.36084295544297934]
	TIME [epoch: 3.37 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19913133540287592		[learning rate: 0.0016209]
	Learning Rate: 0.00162085
	LOSS [training: 0.19913133540287592 | validation: 0.3726479875073579]
	TIME [epoch: 3.36 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15815893040410184		[learning rate: 0.0016132]
	Learning Rate: 0.00161322
	LOSS [training: 0.15815893040410184 | validation: 0.30307487354384743]
	TIME [epoch: 3.37 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13828377547301485		[learning rate: 0.0016056]
	Learning Rate: 0.00160561
	LOSS [training: 0.13828377547301485 | validation: 0.34563132541089897]
	TIME [epoch: 3.38 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14885944052159186		[learning rate: 0.001598]
	Learning Rate: 0.00159805
	LOSS [training: 0.14885944052159186 | validation: 0.30650040419168806]
	TIME [epoch: 3.38 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1381032103350045		[learning rate: 0.0015905]
	Learning Rate: 0.00159052
	LOSS [training: 0.1381032103350045 | validation: 0.3267884560153684]
	TIME [epoch: 3.36 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1777671821796578		[learning rate: 0.001583]
	Learning Rate: 0.00158302
	LOSS [training: 0.1777671821796578 | validation: 0.3305849761624733]
	TIME [epoch: 3.38 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14793630807910188		[learning rate: 0.0015756]
	Learning Rate: 0.00157556
	LOSS [training: 0.14793630807910188 | validation: 0.28103200650552096]
	TIME [epoch: 3.38 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13913742660231437		[learning rate: 0.0015681]
	Learning Rate: 0.00156814
	LOSS [training: 0.13913742660231437 | validation: 0.3022694771563429]
	TIME [epoch: 3.36 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16096233485319847		[learning rate: 0.0015607]
	Learning Rate: 0.00156075
	LOSS [training: 0.16096233485319847 | validation: 0.3438875292377583]
	TIME [epoch: 3.38 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15366513441885882		[learning rate: 0.0015534]
	Learning Rate: 0.0015534
	LOSS [training: 0.15366513441885882 | validation: 0.31281939978734563]
	TIME [epoch: 3.36 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15083717103578442		[learning rate: 0.0015461]
	Learning Rate: 0.00154608
	LOSS [training: 0.15083717103578442 | validation: 0.354613826110383]
	TIME [epoch: 3.36 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14813840784187238		[learning rate: 0.0015388]
	Learning Rate: 0.00153879
	LOSS [training: 0.14813840784187238 | validation: 0.29232210577549045]
	TIME [epoch: 3.37 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17114950198630363		[learning rate: 0.0015315]
	Learning Rate: 0.00153154
	LOSS [training: 0.17114950198630363 | validation: 0.27673729264743047]
	TIME [epoch: 3.37 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15131241696195033		[learning rate: 0.0015243]
	Learning Rate: 0.00152432
	LOSS [training: 0.15131241696195033 | validation: 0.3475801366093725]
	TIME [epoch: 3.37 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15227805404031672		[learning rate: 0.0015171]
	Learning Rate: 0.00151714
	LOSS [training: 0.15227805404031672 | validation: 0.28739908120118435]
	TIME [epoch: 3.36 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1518570032321971		[learning rate: 0.00151]
	Learning Rate: 0.00150999
	LOSS [training: 0.1518570032321971 | validation: 0.3093435449414635]
	TIME [epoch: 3.37 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13901798018630687		[learning rate: 0.0015029]
	Learning Rate: 0.00150288
	LOSS [training: 0.13901798018630687 | validation: 0.3318457884802327]
	TIME [epoch: 3.38 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1525773777068272		[learning rate: 0.0014958]
	Learning Rate: 0.00149579
	LOSS [training: 0.1525773777068272 | validation: 0.3023682239472087]
	TIME [epoch: 3.37 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1250177363394281		[learning rate: 0.0014887]
	Learning Rate: 0.00148875
	LOSS [training: 0.1250177363394281 | validation: 0.3078570538529811]
	TIME [epoch: 3.36 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14865311645743534		[learning rate: 0.0014817]
	Learning Rate: 0.00148173
	LOSS [training: 0.14865311645743534 | validation: 0.32596553318789606]
	TIME [epoch: 3.37 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1575954738896292		[learning rate: 0.0014747]
	Learning Rate: 0.00147475
	LOSS [training: 0.1575954738896292 | validation: 0.31460255863809994]
	TIME [epoch: 3.35 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12244976196078211		[learning rate: 0.0014678]
	Learning Rate: 0.0014678
	LOSS [training: 0.12244976196078211 | validation: 0.30391383372381553]
	TIME [epoch: 3.36 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16233665906376793		[learning rate: 0.0014609]
	Learning Rate: 0.00146088
	LOSS [training: 0.16233665906376793 | validation: 0.31531035384448625]
	TIME [epoch: 3.36 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1515555968450661		[learning rate: 0.001454]
	Learning Rate: 0.001454
	LOSS [training: 0.1515555968450661 | validation: 0.3205142566033278]
	TIME [epoch: 3.37 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1417432964285438		[learning rate: 0.0014471]
	Learning Rate: 0.00144715
	LOSS [training: 0.1417432964285438 | validation: 0.29946429546293224]
	TIME [epoch: 3.36 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14278925941970144		[learning rate: 0.0014403]
	Learning Rate: 0.00144033
	LOSS [training: 0.14278925941970144 | validation: 0.33842989466214995]
	TIME [epoch: 3.36 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13952197186424814		[learning rate: 0.0014335]
	Learning Rate: 0.00143354
	LOSS [training: 0.13952197186424814 | validation: 0.28645830062648014]
	TIME [epoch: 3.37 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14365113005485586		[learning rate: 0.0014268]
	Learning Rate: 0.00142679
	LOSS [training: 0.14365113005485586 | validation: 0.28783785497260905]
	TIME [epoch: 3.38 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15451976956172697		[learning rate: 0.0014201]
	Learning Rate: 0.00142006
	LOSS [training: 0.15451976956172697 | validation: 0.33388992903965536]
	TIME [epoch: 3.37 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13694965261550146		[learning rate: 0.0014134]
	Learning Rate: 0.00141337
	LOSS [training: 0.13694965261550146 | validation: 0.30607658912142]
	TIME [epoch: 3.37 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1623182548611724		[learning rate: 0.0014067]
	Learning Rate: 0.00140671
	LOSS [training: 0.1623182548611724 | validation: 0.32881013918230984]
	TIME [epoch: 3.38 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17425587919245658		[learning rate: 0.0014001]
	Learning Rate: 0.00140008
	LOSS [training: 0.17425587919245658 | validation: 0.28589282543759503]
	TIME [epoch: 3.37 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14551195277113804		[learning rate: 0.0013935]
	Learning Rate: 0.00139349
	LOSS [training: 0.14551195277113804 | validation: 0.3806620961339369]
	TIME [epoch: 3.37 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19932465161727692		[learning rate: 0.0013869]
	Learning Rate: 0.00138692
	LOSS [training: 0.19932465161727692 | validation: 0.3267749375230397]
	TIME [epoch: 3.36 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17067976246202127		[learning rate: 0.0013804]
	Learning Rate: 0.00138038
	LOSS [training: 0.17067976246202127 | validation: 0.3091098338184981]
	TIME [epoch: 3.37 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17481010414796888		[learning rate: 0.0013739]
	Learning Rate: 0.00137388
	LOSS [training: 0.17481010414796888 | validation: 0.3188825534841601]
	TIME [epoch: 3.36 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1663571985770517		[learning rate: 0.0013674]
	Learning Rate: 0.00136741
	LOSS [training: 0.1663571985770517 | validation: 0.3653045196058075]
	TIME [epoch: 3.36 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16238892478075778		[learning rate: 0.001361]
	Learning Rate: 0.00136096
	LOSS [training: 0.16238892478075778 | validation: 0.3319275429361992]
	TIME [epoch: 3.37 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19057658348482487		[learning rate: 0.0013545]
	Learning Rate: 0.00135455
	LOSS [training: 0.19057658348482487 | validation: 0.3306566704052347]
	TIME [epoch: 3.37 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15165675014220198		[learning rate: 0.0013482]
	Learning Rate: 0.00134817
	LOSS [training: 0.15165675014220198 | validation: 0.28383374182441773]
	TIME [epoch: 3.36 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1748622907771743		[learning rate: 0.0013418]
	Learning Rate: 0.00134181
	LOSS [training: 0.1748622907771743 | validation: 0.28495988811248385]
	TIME [epoch: 3.37 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1659180219137372		[learning rate: 0.0013355]
	Learning Rate: 0.00133549
	LOSS [training: 0.1659180219137372 | validation: 0.30419378296258237]
	TIME [epoch: 3.37 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17780026131500523		[learning rate: 0.0013292]
	Learning Rate: 0.0013292
	LOSS [training: 0.17780026131500523 | validation: 0.27485496747419913]
	TIME [epoch: 3.37 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14969364379886446		[learning rate: 0.0013229]
	Learning Rate: 0.00132293
	LOSS [training: 0.14969364379886446 | validation: 0.3079702937258051]
	TIME [epoch: 3.38 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14900113613842195		[learning rate: 0.0013167]
	Learning Rate: 0.0013167
	LOSS [training: 0.14900113613842195 | validation: 0.3031883016114748]
	TIME [epoch: 3.42 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15743863120086876		[learning rate: 0.0013105]
	Learning Rate: 0.0013105
	LOSS [training: 0.15743863120086876 | validation: 0.29213197111059497]
	TIME [epoch: 3.37 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1394708916933463		[learning rate: 0.0013043]
	Learning Rate: 0.00130432
	LOSS [training: 0.1394708916933463 | validation: 0.29879172915824487]
	TIME [epoch: 3.36 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16284185723846245		[learning rate: 0.0012982]
	Learning Rate: 0.00129818
	LOSS [training: 0.16284185723846245 | validation: 0.2660869637763184]
	TIME [epoch: 3.36 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14842177025297298		[learning rate: 0.0012921]
	Learning Rate: 0.00129206
	LOSS [training: 0.14842177025297298 | validation: 0.30128471301023907]
	TIME [epoch: 3.36 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13798347832312832		[learning rate: 0.001286]
	Learning Rate: 0.00128597
	LOSS [training: 0.13798347832312832 | validation: 0.31882979470652484]
	TIME [epoch: 3.36 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.156872409458364		[learning rate: 0.0012799]
	Learning Rate: 0.00127991
	LOSS [training: 0.156872409458364 | validation: 0.29423626895844446]
	TIME [epoch: 3.37 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12419323778540343		[learning rate: 0.0012739]
	Learning Rate: 0.00127388
	LOSS [training: 0.12419323778540343 | validation: 0.3150984189608372]
	TIME [epoch: 3.37 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13859221023432988		[learning rate: 0.0012679]
	Learning Rate: 0.00126788
	LOSS [training: 0.13859221023432988 | validation: 0.28552775733830493]
	TIME [epoch: 3.36 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14923085593244023		[learning rate: 0.0012619]
	Learning Rate: 0.0012619
	LOSS [training: 0.14923085593244023 | validation: 0.3241992287349037]
	TIME [epoch: 3.36 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12368017945631794		[learning rate: 0.001256]
	Learning Rate: 0.00125596
	LOSS [training: 0.12368017945631794 | validation: 0.3436238154648874]
	TIME [epoch: 3.36 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15785840291657544		[learning rate: 0.00125]
	Learning Rate: 0.00125004
	LOSS [training: 0.15785840291657544 | validation: 0.2839448684807735]
	TIME [epoch: 3.37 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14918714436526764		[learning rate: 0.0012441]
	Learning Rate: 0.00124415
	LOSS [training: 0.14918714436526764 | validation: 0.3184821351309042]
	TIME [epoch: 3.36 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13843012185636128		[learning rate: 0.0012383]
	Learning Rate: 0.00123828
	LOSS [training: 0.13843012185636128 | validation: 0.29469653585660105]
	TIME [epoch: 3.37 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15782254519285419		[learning rate: 0.0012324]
	Learning Rate: 0.00123245
	LOSS [training: 0.15782254519285419 | validation: 0.3123442783912644]
	TIME [epoch: 3.37 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15322324506582632		[learning rate: 0.0012266]
	Learning Rate: 0.00122664
	LOSS [training: 0.15322324506582632 | validation: 0.29523779127683486]
	TIME [epoch: 3.37 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1378848705335528		[learning rate: 0.0012209]
	Learning Rate: 0.00122086
	LOSS [training: 0.1378848705335528 | validation: 0.30750748006701145]
	TIME [epoch: 3.38 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15396055950781679		[learning rate: 0.0012151]
	Learning Rate: 0.00121511
	LOSS [training: 0.15396055950781679 | validation: 0.3145788180846422]
	TIME [epoch: 3.37 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15637111302756518		[learning rate: 0.0012094]
	Learning Rate: 0.00120938
	LOSS [training: 0.15637111302756518 | validation: 0.3704446603497787]
	TIME [epoch: 3.36 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18626726309143524		[learning rate: 0.0012037]
	Learning Rate: 0.00120368
	LOSS [training: 0.18626726309143524 | validation: 0.3076635923741393]
	TIME [epoch: 3.35 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16458991969983772		[learning rate: 0.001198]
	Learning Rate: 0.00119801
	LOSS [training: 0.16458991969983772 | validation: 0.31237537454622977]
	TIME [epoch: 3.37 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12908537337005177		[learning rate: 0.0011924]
	Learning Rate: 0.00119237
	LOSS [training: 0.12908537337005177 | validation: 0.3206173506561397]
	TIME [epoch: 3.36 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16731105999422913		[learning rate: 0.0011867]
	Learning Rate: 0.00118675
	LOSS [training: 0.16731105999422913 | validation: 0.32808997711621407]
	TIME [epoch: 3.36 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1302909645785337		[learning rate: 0.0011812]
	Learning Rate: 0.00118116
	LOSS [training: 0.1302909645785337 | validation: 0.2714171055546128]
	TIME [epoch: 3.36 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13249562070322263		[learning rate: 0.0011756]
	Learning Rate: 0.00117559
	LOSS [training: 0.13249562070322263 | validation: 0.2850018677925594]
	TIME [epoch: 3.36 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13246738404489508		[learning rate: 0.0011701]
	Learning Rate: 0.00117005
	LOSS [training: 0.13246738404489508 | validation: 0.35559812871443447]
	TIME [epoch: 3.37 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20545132851919634		[learning rate: 0.0011645]
	Learning Rate: 0.00116454
	LOSS [training: 0.20545132851919634 | validation: 0.31804189400674626]
	TIME [epoch: 3.37 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12796742641890924		[learning rate: 0.0011591]
	Learning Rate: 0.00115905
	LOSS [training: 0.12796742641890924 | validation: 0.2958054857558797]
	TIME [epoch: 3.38 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13128535734696853		[learning rate: 0.0011536]
	Learning Rate: 0.00115359
	LOSS [training: 0.13128535734696853 | validation: 0.32051525649989665]
	TIME [epoch: 3.38 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1454473836297741		[learning rate: 0.0011482]
	Learning Rate: 0.00114815
	LOSS [training: 0.1454473836297741 | validation: 0.3400850919503672]
	TIME [epoch: 3.37 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14223648415702886		[learning rate: 0.0011427]
	Learning Rate: 0.00114274
	LOSS [training: 0.14223648415702886 | validation: 0.301669233662729]
	TIME [epoch: 3.38 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16621568367750142		[learning rate: 0.0011374]
	Learning Rate: 0.00113736
	LOSS [training: 0.16621568367750142 | validation: 0.30536346390223046]
	TIME [epoch: 3.36 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11102679675649879		[learning rate: 0.001132]
	Learning Rate: 0.001132
	LOSS [training: 0.11102679675649879 | validation: 0.32077403114632225]
	TIME [epoch: 3.36 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13033536783469651		[learning rate: 0.0011267]
	Learning Rate: 0.00112667
	LOSS [training: 0.13033536783469651 | validation: 0.32820560595192994]
	TIME [epoch: 3.36 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12842839749530877		[learning rate: 0.0011214]
	Learning Rate: 0.00112136
	LOSS [training: 0.12842839749530877 | validation: 0.31473968484921094]
	TIME [epoch: 27.2 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15870064923966093		[learning rate: 0.0011161]
	Learning Rate: 0.00111607
	LOSS [training: 0.15870064923966093 | validation: 0.3183918209968289]
	TIME [epoch: 6.44 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1272709495913728		[learning rate: 0.0011108]
	Learning Rate: 0.00111081
	LOSS [training: 0.1272709495913728 | validation: 0.32481199291181634]
	TIME [epoch: 6.42 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16635187625837183		[learning rate: 0.0011056]
	Learning Rate: 0.00110558
	LOSS [training: 0.16635187625837183 | validation: 0.31951720107318354]
	TIME [epoch: 6.4 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16827408043003805		[learning rate: 0.0011004]
	Learning Rate: 0.00110037
	LOSS [training: 0.16827408043003805 | validation: 0.3189910970169259]
	TIME [epoch: 6.4 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1614017540814351		[learning rate: 0.0010952]
	Learning Rate: 0.00109518
	LOSS [training: 0.1614017540814351 | validation: 0.3210086382909134]
	TIME [epoch: 6.45 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1713173180174711		[learning rate: 0.00109]
	Learning Rate: 0.00109002
	LOSS [training: 0.1713173180174711 | validation: 0.3228991265796303]
	TIME [epoch: 6.42 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1537319690871255		[learning rate: 0.0010849]
	Learning Rate: 0.00108489
	LOSS [training: 0.1537319690871255 | validation: 0.30602748028335536]
	TIME [epoch: 6.46 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11935875296213519		[learning rate: 0.0010798]
	Learning Rate: 0.00107978
	LOSS [training: 0.11935875296213519 | validation: 0.2888064670983223]
	TIME [epoch: 6.45 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15032853117595918		[learning rate: 0.0010747]
	Learning Rate: 0.00107469
	LOSS [training: 0.15032853117595918 | validation: 0.3101601883229725]
	TIME [epoch: 6.45 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1465859465154355		[learning rate: 0.0010696]
	Learning Rate: 0.00106962
	LOSS [training: 0.1465859465154355 | validation: 0.3518432122072894]
	TIME [epoch: 6.44 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1835917867143021		[learning rate: 0.0010646]
	Learning Rate: 0.00106458
	LOSS [training: 0.1835917867143021 | validation: 0.2798156080765842]
	TIME [epoch: 6.44 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16281538516156766		[learning rate: 0.0010596]
	Learning Rate: 0.00105957
	LOSS [training: 0.16281538516156766 | validation: 0.31013867214545393]
	TIME [epoch: 6.42 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13555126524685712		[learning rate: 0.0010546]
	Learning Rate: 0.00105457
	LOSS [training: 0.13555126524685712 | validation: 0.35917883072619466]
	TIME [epoch: 6.43 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14775740535279605		[learning rate: 0.0010496]
	Learning Rate: 0.0010496
	LOSS [training: 0.14775740535279605 | validation: 0.31512513631603084]
	TIME [epoch: 6.44 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1459160241086113		[learning rate: 0.0010447]
	Learning Rate: 0.00104466
	LOSS [training: 0.1459160241086113 | validation: 0.31595251276430875]
	TIME [epoch: 6.44 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15542724801199398		[learning rate: 0.0010397]
	Learning Rate: 0.00103974
	LOSS [training: 0.15542724801199398 | validation: 0.27715911148955574]
	TIME [epoch: 6.42 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16015095329681667		[learning rate: 0.0010348]
	Learning Rate: 0.00103484
	LOSS [training: 0.16015095329681667 | validation: 0.3050068747481305]
	TIME [epoch: 6.44 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1289364968683384		[learning rate: 0.00103]
	Learning Rate: 0.00102996
	LOSS [training: 0.1289364968683384 | validation: 0.3251230211152768]
	TIME [epoch: 6.42 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14557167030433688		[learning rate: 0.0010251]
	Learning Rate: 0.00102511
	LOSS [training: 0.14557167030433688 | validation: 0.2856957891445496]
	TIME [epoch: 6.42 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16538750912791822		[learning rate: 0.0010203]
	Learning Rate: 0.00102028
	LOSS [training: 0.16538750912791822 | validation: 0.30677816025629895]
	TIME [epoch: 6.43 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1493440500865736		[learning rate: 0.0010155]
	Learning Rate: 0.00101547
	LOSS [training: 0.1493440500865736 | validation: 0.3402660696146435]
	TIME [epoch: 6.41 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13227343744801906		[learning rate: 0.0010107]
	Learning Rate: 0.00101068
	LOSS [training: 0.13227343744801906 | validation: 0.3231337435942479]
	TIME [epoch: 6.42 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14676152702165057		[learning rate: 0.0010059]
	Learning Rate: 0.00100592
	LOSS [training: 0.14676152702165057 | validation: 0.29976075222561716]
	TIME [epoch: 6.42 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11368856516252066		[learning rate: 0.0010012]
	Learning Rate: 0.00100118
	LOSS [training: 0.11368856516252066 | validation: 0.29865705309027907]
	TIME [epoch: 6.42 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14377437982022018		[learning rate: 0.00099646]
	Learning Rate: 0.000996464
	LOSS [training: 0.14377437982022018 | validation: 0.2883299606218535]
	TIME [epoch: 6.41 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15311346315348978		[learning rate: 0.00099177]
	Learning Rate: 0.000991768
	LOSS [training: 0.15311346315348978 | validation: 0.30356244401058546]
	TIME [epoch: 6.42 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1321399476547525		[learning rate: 0.0009871]
	Learning Rate: 0.000987095
	LOSS [training: 0.1321399476547525 | validation: 0.29845184619797716]
	TIME [epoch: 6.42 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1528325266609425		[learning rate: 0.00098244]
	Learning Rate: 0.000982444
	LOSS [training: 0.1528325266609425 | validation: 0.31255920937139636]
	TIME [epoch: 6.42 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1723058921443505		[learning rate: 0.00097781]
	Learning Rate: 0.000977814
	LOSS [training: 0.1723058921443505 | validation: 0.3298385597728978]
	TIME [epoch: 6.41 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13143045826184702		[learning rate: 0.00097321]
	Learning Rate: 0.000973207
	LOSS [training: 0.13143045826184702 | validation: 0.320230050888629]
	TIME [epoch: 6.43 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12251593046594533		[learning rate: 0.00096862]
	Learning Rate: 0.000968621
	LOSS [training: 0.12251593046594533 | validation: 0.2890492269444497]
	TIME [epoch: 6.43 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14366219369161676		[learning rate: 0.00096406]
	Learning Rate: 0.000964057
	LOSS [training: 0.14366219369161676 | validation: 0.28762790465979615]
	TIME [epoch: 6.44 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13076134255708743		[learning rate: 0.00095951]
	Learning Rate: 0.000959514
	LOSS [training: 0.13076134255708743 | validation: 0.2860810058945477]
	TIME [epoch: 6.45 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14169432842198623		[learning rate: 0.00095499]
	Learning Rate: 0.000954993
	LOSS [training: 0.14169432842198623 | validation: 0.32562747948397514]
	TIME [epoch: 6.46 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16794581265682096		[learning rate: 0.00095049]
	Learning Rate: 0.000950493
	LOSS [training: 0.16794581265682096 | validation: 0.32060533398906477]
	TIME [epoch: 6.42 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1462823557687996		[learning rate: 0.00094601]
	Learning Rate: 0.000946014
	LOSS [training: 0.1462823557687996 | validation: 0.3190915936939206]
	TIME [epoch: 6.4 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14114153066147508		[learning rate: 0.00094156]
	Learning Rate: 0.000941556
	LOSS [training: 0.14114153066147508 | validation: 0.31385751614054325]
	TIME [epoch: 6.41 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1459459808911659		[learning rate: 0.00093712]
	Learning Rate: 0.000937119
	LOSS [training: 0.1459459808911659 | validation: 0.305964577560138]
	TIME [epoch: 6.4 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.167648601432387		[learning rate: 0.0009327]
	Learning Rate: 0.000932703
	LOSS [training: 0.167648601432387 | validation: 0.30527126471507016]
	TIME [epoch: 6.45 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15576606644172727		[learning rate: 0.00092831]
	Learning Rate: 0.000928309
	LOSS [training: 0.15576606644172727 | validation: 0.2865782046174426]
	TIME [epoch: 6.42 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12524715061164626		[learning rate: 0.00092393]
	Learning Rate: 0.000923934
	LOSS [training: 0.12524715061164626 | validation: 0.32832879095733586]
	TIME [epoch: 6.41 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13592805257287116		[learning rate: 0.00091958]
	Learning Rate: 0.000919581
	LOSS [training: 0.13592805257287116 | validation: 0.3262247461659628]
	TIME [epoch: 6.41 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1291068073806529		[learning rate: 0.00091525]
	Learning Rate: 0.000915247
	LOSS [training: 0.1291068073806529 | validation: 0.29414245156075125]
	TIME [epoch: 6.42 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14713556418434443		[learning rate: 0.00091093]
	Learning Rate: 0.000910934
	LOSS [training: 0.14713556418434443 | validation: 0.3192543663771838]
	TIME [epoch: 6.42 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14758402072630425		[learning rate: 0.00090664]
	Learning Rate: 0.000906642
	LOSS [training: 0.14758402072630425 | validation: 0.32403938357269824]
	TIME [epoch: 6.42 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1347184658706946		[learning rate: 0.00090237]
	Learning Rate: 0.00090237
	LOSS [training: 0.1347184658706946 | validation: 0.30182486591356134]
	TIME [epoch: 6.43 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14052929008999687		[learning rate: 0.00089812]
	Learning Rate: 0.000898118
	LOSS [training: 0.14052929008999687 | validation: 0.3218298971259995]
	TIME [epoch: 6.42 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1632474380847105		[learning rate: 0.00089389]
	Learning Rate: 0.000893886
	LOSS [training: 0.1632474380847105 | validation: 0.3099228641750096]
	TIME [epoch: 6.41 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1462026819743365		[learning rate: 0.00088967]
	Learning Rate: 0.000889674
	LOSS [training: 0.1462026819743365 | validation: 0.30448033826977056]
	TIME [epoch: 6.41 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16514006599096281		[learning rate: 0.00088548]
	Learning Rate: 0.000885481
	LOSS [training: 0.16514006599096281 | validation: 0.3092200294568927]
	TIME [epoch: 6.41 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1562775535088194		[learning rate: 0.00088131]
	Learning Rate: 0.000881309
	LOSS [training: 0.1562775535088194 | validation: 0.2706553637198678]
	TIME [epoch: 6.46 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13044246655128658		[learning rate: 0.00087716]
	Learning Rate: 0.000877156
	LOSS [training: 0.13044246655128658 | validation: 0.3137270143841203]
	TIME [epoch: 6.44 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12430243283090532		[learning rate: 0.00087302]
	Learning Rate: 0.000873023
	LOSS [training: 0.12430243283090532 | validation: 0.3207075063114407]
	TIME [epoch: 6.42 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13118786465418972		[learning rate: 0.00086891]
	Learning Rate: 0.000868909
	LOSS [training: 0.13118786465418972 | validation: 0.2909995462523528]
	TIME [epoch: 6.43 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11590119261201615		[learning rate: 0.00086481]
	Learning Rate: 0.000864815
	LOSS [training: 0.11590119261201615 | validation: 0.2926897859882022]
	TIME [epoch: 6.43 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12448965148481297		[learning rate: 0.00086074]
	Learning Rate: 0.00086074
	LOSS [training: 0.12448965148481297 | validation: 0.330773991410005]
	TIME [epoch: 6.42 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14523127157002413		[learning rate: 0.00085668]
	Learning Rate: 0.000856684
	LOSS [training: 0.14523127157002413 | validation: 0.3089196808109133]
	TIME [epoch: 6.43 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12510319798664796		[learning rate: 0.00085265]
	Learning Rate: 0.000852647
	LOSS [training: 0.12510319798664796 | validation: 0.2993921704778191]
	TIME [epoch: 6.43 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14406865758005946		[learning rate: 0.00084863]
	Learning Rate: 0.000848629
	LOSS [training: 0.14406865758005946 | validation: 0.3226502488263719]
	TIME [epoch: 6.44 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13981054820885316		[learning rate: 0.00084463]
	Learning Rate: 0.00084463
	LOSS [training: 0.13981054820885316 | validation: 0.2932383864399988]
	TIME [epoch: 6.41 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12425950641208698		[learning rate: 0.00084065]
	Learning Rate: 0.00084065
	LOSS [training: 0.12425950641208698 | validation: 0.2920646003865115]
	TIME [epoch: 6.41 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1431669166992075		[learning rate: 0.00083669]
	Learning Rate: 0.000836689
	LOSS [training: 0.1431669166992075 | validation: 0.3047431497714801]
	TIME [epoch: 6.42 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14190574880501855		[learning rate: 0.00083275]
	Learning Rate: 0.000832746
	LOSS [training: 0.14190574880501855 | validation: 0.3229919074890849]
	TIME [epoch: 6.42 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16041640060215845		[learning rate: 0.00082882]
	Learning Rate: 0.000828822
	LOSS [training: 0.16041640060215845 | validation: 0.3208571663372721]
	TIME [epoch: 6.41 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15856391912587228		[learning rate: 0.00082492]
	Learning Rate: 0.000824917
	LOSS [training: 0.15856391912587228 | validation: 0.32098353789991946]
	TIME [epoch: 6.41 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15346055388479612		[learning rate: 0.00082103]
	Learning Rate: 0.00082103
	LOSS [training: 0.15346055388479612 | validation: 0.2988258653050567]
	TIME [epoch: 6.41 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15362494100291574		[learning rate: 0.00081716]
	Learning Rate: 0.000817161
	LOSS [training: 0.15362494100291574 | validation: 0.32159724824536057]
	TIME [epoch: 6.41 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13634559516998138		[learning rate: 0.00081331]
	Learning Rate: 0.000813311
	LOSS [training: 0.13634559516998138 | validation: 0.3160443734403839]
	TIME [epoch: 6.43 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1446070168381388		[learning rate: 0.00080948]
	Learning Rate: 0.000809478
	LOSS [training: 0.1446070168381388 | validation: 0.33236554750331415]
	TIME [epoch: 6.41 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1240432720871961		[learning rate: 0.00080566]
	Learning Rate: 0.000805664
	LOSS [training: 0.1240432720871961 | validation: 0.29951236135578235]
	TIME [epoch: 6.41 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1388828770496641		[learning rate: 0.00080187]
	Learning Rate: 0.000801868
	LOSS [training: 0.1388828770496641 | validation: 0.3105670915781424]
	TIME [epoch: 6.41 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14747694124775088		[learning rate: 0.00079809]
	Learning Rate: 0.000798089
	LOSS [training: 0.14747694124775088 | validation: 0.293448741506548]
	TIME [epoch: 6.43 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1271919515253919		[learning rate: 0.00079433]
	Learning Rate: 0.000794328
	LOSS [training: 0.1271919515253919 | validation: 0.3072738910161539]
	TIME [epoch: 6.39 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1354653825982693		[learning rate: 0.00079059]
	Learning Rate: 0.000790585
	LOSS [training: 0.1354653825982693 | validation: 0.3031157899305642]
	TIME [epoch: 6.41 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.134471510512761		[learning rate: 0.00078686]
	Learning Rate: 0.00078686
	LOSS [training: 0.134471510512761 | validation: 0.3205502108207287]
	TIME [epoch: 6.44 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14595468723869875		[learning rate: 0.00078315]
	Learning Rate: 0.000783152
	LOSS [training: 0.14595468723869875 | validation: 0.2915804054280061]
	TIME [epoch: 6.41 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13168438018402445		[learning rate: 0.00077946]
	Learning Rate: 0.000779462
	LOSS [training: 0.13168438018402445 | validation: 0.3086464878982813]
	TIME [epoch: 6.4 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15483115786994492		[learning rate: 0.00077579]
	Learning Rate: 0.000775789
	LOSS [training: 0.15483115786994492 | validation: 0.3128619456769071]
	TIME [epoch: 6.43 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15700538915154558		[learning rate: 0.00077213]
	Learning Rate: 0.000772133
	LOSS [training: 0.15700538915154558 | validation: 0.27514046223851646]
	TIME [epoch: 6.39 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13103248575164336		[learning rate: 0.00076849]
	Learning Rate: 0.000768495
	LOSS [training: 0.13103248575164336 | validation: 0.3110910842369639]
	TIME [epoch: 6.44 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13083706429020403		[learning rate: 0.00076487]
	Learning Rate: 0.000764874
	LOSS [training: 0.13083706429020403 | validation: 0.3144390197023998]
	TIME [epoch: 6.41 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12319812689804807		[learning rate: 0.00076127]
	Learning Rate: 0.00076127
	LOSS [training: 0.12319812689804807 | validation: 0.32423971770023485]
	TIME [epoch: 6.41 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10291630204676137		[learning rate: 0.00075768]
	Learning Rate: 0.000757682
	LOSS [training: 0.10291630204676137 | validation: 0.31319400766076255]
	TIME [epoch: 6.41 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15643853299619617		[learning rate: 0.00075411]
	Learning Rate: 0.000754112
	LOSS [training: 0.15643853299619617 | validation: 0.2981038510314085]
	TIME [epoch: 6.43 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1379761738049459		[learning rate: 0.00075056]
	Learning Rate: 0.000750559
	LOSS [training: 0.1379761738049459 | validation: 0.2839398950516909]
	TIME [epoch: 6.41 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12697972860979304		[learning rate: 0.00074702]
	Learning Rate: 0.000747022
	LOSS [training: 0.12697972860979304 | validation: 0.30860619209107587]
	TIME [epoch: 6.52 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15358560108486538		[learning rate: 0.0007435]
	Learning Rate: 0.000743502
	LOSS [training: 0.15358560108486538 | validation: 0.28960445506725746]
	TIME [epoch: 6.41 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13104734424351358		[learning rate: 0.00074]
	Learning Rate: 0.000739998
	LOSS [training: 0.13104734424351358 | validation: 0.2561431283136372]
	TIME [epoch: 6.43 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v5_20240715_175905/states/model_facs_v3_dec2b_2dpca_v5_589.pth
	Model improved!!!
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.160208377958532		[learning rate: 0.00073651]
	Learning Rate: 0.000736511
	LOSS [training: 0.160208377958532 | validation: 0.2877243514166179]
	TIME [epoch: 6.39 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14801815186164588		[learning rate: 0.00073304]
	Learning Rate: 0.000733041
	LOSS [training: 0.14801815186164588 | validation: 0.2980573794538467]
	TIME [epoch: 6.43 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13495808967927375		[learning rate: 0.00072959]
	Learning Rate: 0.000729587
	LOSS [training: 0.13495808967927375 | validation: 0.2978782087707348]
	TIME [epoch: 6.42 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1673529130117199		[learning rate: 0.00072615]
	Learning Rate: 0.000726149
	LOSS [training: 0.1673529130117199 | validation: 0.30434053489801266]
	TIME [epoch: 6.43 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15241237863267743		[learning rate: 0.00072273]
	Learning Rate: 0.000722727
	LOSS [training: 0.15241237863267743 | validation: 0.34664358239095744]
	TIME [epoch: 6.4 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15251708923035853		[learning rate: 0.00071932]
	Learning Rate: 0.000719321
	LOSS [training: 0.15251708923035853 | validation: 0.31797010843665735]
	TIME [epoch: 6.46 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13862425231626416		[learning rate: 0.00071593]
	Learning Rate: 0.000715932
	LOSS [training: 0.13862425231626416 | validation: 0.2787598153493354]
	TIME [epoch: 6.4 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1441152444783531		[learning rate: 0.00071256]
	Learning Rate: 0.000712558
	LOSS [training: 0.1441152444783531 | validation: 0.3255943504656477]
	TIME [epoch: 6.39 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1449953258301417		[learning rate: 0.0007092]
	Learning Rate: 0.000709201
	LOSS [training: 0.1449953258301417 | validation: 0.3131049830756589]
	TIME [epoch: 6.39 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.140400592046718		[learning rate: 0.00070586]
	Learning Rate: 0.000705859
	LOSS [training: 0.140400592046718 | validation: 0.3088645014640765]
	TIME [epoch: 6.41 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1335916930267568		[learning rate: 0.00070253]
	Learning Rate: 0.000702533
	LOSS [training: 0.1335916930267568 | validation: 0.31475726896343464]
	TIME [epoch: 6.38 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12242109911508904		[learning rate: 0.00069922]
	Learning Rate: 0.000699222
	LOSS [training: 0.12242109911508904 | validation: 0.3170049922419908]
	TIME [epoch: 6.4 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14026664252381044		[learning rate: 0.00069593]
	Learning Rate: 0.000695928
	LOSS [training: 0.14026664252381044 | validation: 0.33533662641449147]
	TIME [epoch: 6.39 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13162751467665038		[learning rate: 0.00069265]
	Learning Rate: 0.000692648
	LOSS [training: 0.13162751467665038 | validation: 0.3042282935701206]
	TIME [epoch: 6.39 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13291868232913392		[learning rate: 0.00068938]
	Learning Rate: 0.000689385
	LOSS [training: 0.13291868232913392 | validation: 0.3023660308302835]
	TIME [epoch: 6.38 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11718969634562296		[learning rate: 0.00068614]
	Learning Rate: 0.000686136
	LOSS [training: 0.11718969634562296 | validation: 0.2923076261086803]
	TIME [epoch: 6.38 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1566815913878679		[learning rate: 0.0006829]
	Learning Rate: 0.000682903
	LOSS [training: 0.1566815913878679 | validation: 0.3101130519042976]
	TIME [epoch: 6.41 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13988136451173871		[learning rate: 0.00067969]
	Learning Rate: 0.000679685
	LOSS [training: 0.13988136451173871 | validation: 0.2992030512287021]
	TIME [epoch: 6.41 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14833725119227367		[learning rate: 0.00067648]
	Learning Rate: 0.000676482
	LOSS [training: 0.14833725119227367 | validation: 0.31564073819370375]
	TIME [epoch: 6.38 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10854732507653331		[learning rate: 0.00067329]
	Learning Rate: 0.000673295
	LOSS [training: 0.10854732507653331 | validation: 0.2774065882756194]
	TIME [epoch: 6.4 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14398782406784832		[learning rate: 0.00067012]
	Learning Rate: 0.000670122
	LOSS [training: 0.14398782406784832 | validation: 0.309198763157858]
	TIME [epoch: 6.38 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1363325293902743		[learning rate: 0.00066696]
	Learning Rate: 0.000666964
	LOSS [training: 0.1363325293902743 | validation: 0.315652105952902]
	TIME [epoch: 6.39 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17038135610038424		[learning rate: 0.00066382]
	Learning Rate: 0.000663821
	LOSS [training: 0.17038135610038424 | validation: 0.33909044063982563]
	TIME [epoch: 6.4 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15293925134749886		[learning rate: 0.00066069]
	Learning Rate: 0.000660694
	LOSS [training: 0.15293925134749886 | validation: 0.31750847712577146]
	TIME [epoch: 6.37 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.162969048431017		[learning rate: 0.00065758]
	Learning Rate: 0.00065758
	LOSS [training: 0.162969048431017 | validation: 0.3188006760964961]
	TIME [epoch: 6.4 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14010652367528514		[learning rate: 0.00065448]
	Learning Rate: 0.000654482
	LOSS [training: 0.14010652367528514 | validation: 0.3224603594528112]
	TIME [epoch: 6.4 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14786768710725273		[learning rate: 0.0006514]
	Learning Rate: 0.000651398
	LOSS [training: 0.14786768710725273 | validation: 0.2966597016424921]
	TIME [epoch: 6.4 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15930196676281677		[learning rate: 0.00064833]
	Learning Rate: 0.000648328
	LOSS [training: 0.15930196676281677 | validation: 0.2912085831145537]
	TIME [epoch: 6.39 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14767867883165942		[learning rate: 0.00064527]
	Learning Rate: 0.000645273
	LOSS [training: 0.14767867883165942 | validation: 0.33742639999243473]
	TIME [epoch: 6.42 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18393075224543165		[learning rate: 0.00064223]
	Learning Rate: 0.000642232
	LOSS [training: 0.18393075224543165 | validation: 0.2996805729298096]
	TIME [epoch: 6.4 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14925086256970907		[learning rate: 0.00063921]
	Learning Rate: 0.000639206
	LOSS [training: 0.14925086256970907 | validation: 0.29828401783382796]
	TIME [epoch: 6.4 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14460071311038997		[learning rate: 0.00063619]
	Learning Rate: 0.000636194
	LOSS [training: 0.14460071311038997 | validation: 0.3011795328336141]
	TIME [epoch: 6.39 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1201356683803364		[learning rate: 0.0006332]
	Learning Rate: 0.000633196
	LOSS [training: 0.1201356683803364 | validation: 0.2978889018809023]
	TIME [epoch: 6.39 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13648995833493824		[learning rate: 0.00063021]
	Learning Rate: 0.000630213
	LOSS [training: 0.13648995833493824 | validation: 0.33082693756363457]
	TIME [epoch: 6.4 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15140376749573992		[learning rate: 0.00062724]
	Learning Rate: 0.000627243
	LOSS [training: 0.15140376749573992 | validation: 0.3017702291898247]
	TIME [epoch: 6.41 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14418855158155652		[learning rate: 0.00062429]
	Learning Rate: 0.000624287
	LOSS [training: 0.14418855158155652 | validation: 0.3380247785305238]
	TIME [epoch: 6.41 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13738162905113893		[learning rate: 0.00062135]
	Learning Rate: 0.000621346
	LOSS [training: 0.13738162905113893 | validation: 0.28163350060149395]
	TIME [epoch: 6.41 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12279467785185005		[learning rate: 0.00061842]
	Learning Rate: 0.000618418
	LOSS [training: 0.12279467785185005 | validation: 0.322127277634943]
	TIME [epoch: 6.4 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18127290352726028		[learning rate: 0.0006155]
	Learning Rate: 0.000615504
	LOSS [training: 0.18127290352726028 | validation: 0.29490638282713383]
	TIME [epoch: 6.39 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17530276185552723		[learning rate: 0.0006126]
	Learning Rate: 0.000612604
	LOSS [training: 0.17530276185552723 | validation: 0.2687946129102718]
	TIME [epoch: 6.39 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1409579055110724		[learning rate: 0.00060972]
	Learning Rate: 0.000609717
	LOSS [training: 0.1409579055110724 | validation: 0.2837148399477895]
	TIME [epoch: 6.38 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12921604845371323		[learning rate: 0.00060684]
	Learning Rate: 0.000606844
	LOSS [training: 0.12921604845371323 | validation: 0.3297163074239073]
	TIME [epoch: 6.4 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12538958787487361		[learning rate: 0.00060398]
	Learning Rate: 0.000603984
	LOSS [training: 0.12538958787487361 | validation: 0.2645745239381415]
	TIME [epoch: 6.38 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12570289553590094		[learning rate: 0.00060114]
	Learning Rate: 0.000601138
	LOSS [training: 0.12570289553590094 | validation: 0.29356761200107745]
	TIME [epoch: 6.41 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17384037162052862		[learning rate: 0.00059831]
	Learning Rate: 0.000598306
	LOSS [training: 0.17384037162052862 | validation: 0.28848637770224167]
	TIME [epoch: 6.37 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13554378347523557		[learning rate: 0.00059549]
	Learning Rate: 0.000595486
	LOSS [training: 0.13554378347523557 | validation: 0.3119737637222301]
	TIME [epoch: 6.41 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16838376650673395		[learning rate: 0.00059268]
	Learning Rate: 0.00059268
	LOSS [training: 0.16838376650673395 | validation: 0.31304526826291806]
	TIME [epoch: 6.39 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13463606611113982		[learning rate: 0.00058989]
	Learning Rate: 0.000589888
	LOSS [training: 0.13463606611113982 | validation: 0.33337953915230734]
	TIME [epoch: 6.4 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12139313040173835		[learning rate: 0.00058711]
	Learning Rate: 0.000587108
	LOSS [training: 0.12139313040173835 | validation: 0.2730737657691879]
	TIME [epoch: 6.4 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16669146580080715		[learning rate: 0.00058434]
	Learning Rate: 0.000584341
	LOSS [training: 0.16669146580080715 | validation: 0.32060244671517313]
	TIME [epoch: 6.37 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14001445978653454		[learning rate: 0.00058159]
	Learning Rate: 0.000581588
	LOSS [training: 0.14001445978653454 | validation: 0.3237336301941753]
	TIME [epoch: 6.39 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14616764394778087		[learning rate: 0.00057885]
	Learning Rate: 0.000578847
	LOSS [training: 0.14616764394778087 | validation: 0.31949722374733125]
	TIME [epoch: 6.4 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1122287669616583		[learning rate: 0.00057612]
	Learning Rate: 0.00057612
	LOSS [training: 0.1122287669616583 | validation: 0.2997555222405694]
	TIME [epoch: 6.37 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1252219798920819		[learning rate: 0.00057341]
	Learning Rate: 0.000573405
	LOSS [training: 0.1252219798920819 | validation: 0.2800050379202354]
	TIME [epoch: 6.4 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1108279410932655		[learning rate: 0.0005707]
	Learning Rate: 0.000570703
	LOSS [training: 0.1108279410932655 | validation: 0.30939589505374604]
	TIME [epoch: 6.38 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1379228732322496		[learning rate: 0.00056801]
	Learning Rate: 0.000568014
	LOSS [training: 0.1379228732322496 | validation: 0.30697864675221953]
	TIME [epoch: 6.41 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1434826342586818		[learning rate: 0.00056534]
	Learning Rate: 0.000565337
	LOSS [training: 0.1434826342586818 | validation: 0.31347441186424163]
	TIME [epoch: 6.37 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13387508043873486		[learning rate: 0.00056267]
	Learning Rate: 0.000562673
	LOSS [training: 0.13387508043873486 | validation: 0.2910848733105312]
	TIME [epoch: 6.48 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13015051515703285		[learning rate: 0.00056002]
	Learning Rate: 0.000560022
	LOSS [training: 0.13015051515703285 | validation: 0.3326467435498843]
	TIME [epoch: 6.39 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14797035430466304		[learning rate: 0.00055738]
	Learning Rate: 0.000557383
	LOSS [training: 0.14797035430466304 | validation: 0.30083507103758184]
	TIME [epoch: 6.39 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1289917275903412		[learning rate: 0.00055476]
	Learning Rate: 0.000554757
	LOSS [training: 0.1289917275903412 | validation: 0.2920723127880757]
	TIME [epoch: 6.39 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1493527748673596		[learning rate: 0.00055214]
	Learning Rate: 0.000552143
	LOSS [training: 0.1493527748673596 | validation: 0.3036807298011671]
	TIME [epoch: 6.4 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17687319290727366		[learning rate: 0.00054954]
	Learning Rate: 0.000549541
	LOSS [training: 0.17687319290727366 | validation: 0.32822241655227347]
	TIME [epoch: 6.37 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16974177496585108		[learning rate: 0.00054695]
	Learning Rate: 0.000546951
	LOSS [training: 0.16974177496585108 | validation: 0.2839726319993718]
	TIME [epoch: 6.41 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18211091332658164		[learning rate: 0.00054437]
	Learning Rate: 0.000544374
	LOSS [training: 0.18211091332658164 | validation: 0.2936036981263948]
	TIME [epoch: 6.35 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13091401313881368		[learning rate: 0.00054181]
	Learning Rate: 0.000541809
	LOSS [training: 0.13091401313881368 | validation: 0.28291354942442226]
	TIME [epoch: 6.39 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15024629332975337		[learning rate: 0.00053926]
	Learning Rate: 0.000539256
	LOSS [training: 0.15024629332975337 | validation: 0.31021730309560525]
	TIME [epoch: 6.39 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13466291556421403		[learning rate: 0.00053671]
	Learning Rate: 0.000536715
	LOSS [training: 0.13466291556421403 | validation: 0.3152507914722389]
	TIME [epoch: 6.39 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12303449620675685		[learning rate: 0.00053419]
	Learning Rate: 0.000534186
	LOSS [training: 0.12303449620675685 | validation: 0.28220705814715386]
	TIME [epoch: 6.41 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13208916680908078		[learning rate: 0.00053167]
	Learning Rate: 0.000531669
	LOSS [training: 0.13208916680908078 | validation: 0.3081941864106032]
	TIME [epoch: 6.39 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13778449076436647		[learning rate: 0.00052916]
	Learning Rate: 0.000529163
	LOSS [training: 0.13778449076436647 | validation: 0.32476618319826656]
	TIME [epoch: 6.37 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1376696078900227		[learning rate: 0.00052667]
	Learning Rate: 0.00052667
	LOSS [training: 0.1376696078900227 | validation: 0.30851456352182505]
	TIME [epoch: 6.38 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12041068636357202		[learning rate: 0.00052419]
	Learning Rate: 0.000524188
	LOSS [training: 0.12041068636357202 | validation: 0.33576918457817795]
	TIME [epoch: 6.36 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15398881354624877		[learning rate: 0.00052172]
	Learning Rate: 0.000521718
	LOSS [training: 0.15398881354624877 | validation: 0.2826027598467055]
	TIME [epoch: 6.39 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1330069743051788		[learning rate: 0.00051926]
	Learning Rate: 0.00051926
	LOSS [training: 0.1330069743051788 | validation: 0.31462331979068475]
	TIME [epoch: 6.4 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12892803331069339		[learning rate: 0.00051681]
	Learning Rate: 0.000516813
	LOSS [training: 0.12892803331069339 | validation: 0.27199772966644625]
	TIME [epoch: 6.38 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13990948411663096		[learning rate: 0.00051438]
	Learning Rate: 0.000514378
	LOSS [training: 0.13990948411663096 | validation: 0.30386961760926057]
	TIME [epoch: 6.38 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13190151853712953		[learning rate: 0.00051195]
	Learning Rate: 0.000511954
	LOSS [training: 0.13190151853712953 | validation: 0.3322341638173347]
	TIME [epoch: 6.36 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12736824023613008		[learning rate: 0.00050954]
	Learning Rate: 0.000509541
	LOSS [training: 0.12736824023613008 | validation: 0.28777170684230174]
	TIME [epoch: 6.38 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14097875840079535		[learning rate: 0.00050714]
	Learning Rate: 0.00050714
	LOSS [training: 0.14097875840079535 | validation: 0.26131852989288346]
	TIME [epoch: 6.38 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15015769880032728		[learning rate: 0.00050475]
	Learning Rate: 0.000504751
	LOSS [training: 0.15015769880032728 | validation: 0.31590549999152956]
	TIME [epoch: 6.41 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1304452304777999		[learning rate: 0.00050237]
	Learning Rate: 0.000502372
	LOSS [training: 0.1304452304777999 | validation: 0.3025782464582335]
	TIME [epoch: 6.39 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14370172305810636		[learning rate: 0.00050001]
	Learning Rate: 0.000500005
	LOSS [training: 0.14370172305810636 | validation: 0.3077182835414441]
	TIME [epoch: 6.39 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16472386712441878		[learning rate: 0.00049765]
	Learning Rate: 0.000497649
	LOSS [training: 0.16472386712441878 | validation: 0.32161275207285506]
	TIME [epoch: 6.39 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1296426879260468		[learning rate: 0.0004953]
	Learning Rate: 0.000495304
	LOSS [training: 0.1296426879260468 | validation: 0.2911645818146369]
	TIME [epoch: 6.37 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12138866291980782		[learning rate: 0.00049297]
	Learning Rate: 0.00049297
	LOSS [training: 0.12138866291980782 | validation: 0.3072181612437249]
	TIME [epoch: 6.39 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13692322350061456		[learning rate: 0.00049065]
	Learning Rate: 0.000490647
	LOSS [training: 0.13692322350061456 | validation: 0.32418091563911033]
	TIME [epoch: 6.4 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13342744984873647		[learning rate: 0.00048834]
	Learning Rate: 0.000488335
	LOSS [training: 0.13342744984873647 | validation: 0.3323735142272059]
	TIME [epoch: 6.39 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14230020533840632		[learning rate: 0.00048603]
	Learning Rate: 0.000486034
	LOSS [training: 0.14230020533840632 | validation: 0.29357922578687407]
	TIME [epoch: 6.37 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13266875993685062		[learning rate: 0.00048374]
	Learning Rate: 0.000483744
	LOSS [training: 0.13266875993685062 | validation: 0.32307146469330905]
	TIME [epoch: 6.39 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13067119566054694		[learning rate: 0.00048146]
	Learning Rate: 0.000481464
	LOSS [training: 0.13067119566054694 | validation: 0.29314409377425354]
	TIME [epoch: 6.4 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12740909265930087		[learning rate: 0.0004792]
	Learning Rate: 0.000479196
	LOSS [training: 0.12740909265930087 | validation: 0.32637834114928177]
	TIME [epoch: 6.4 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15854147853456785		[learning rate: 0.00047694]
	Learning Rate: 0.000476938
	LOSS [training: 0.15854147853456785 | validation: 0.3333855855380306]
	TIME [epoch: 6.38 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14373716297974615		[learning rate: 0.00047469]
	Learning Rate: 0.00047469
	LOSS [training: 0.14373716297974615 | validation: 0.3154254830857829]
	TIME [epoch: 6.39 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1365638422974198		[learning rate: 0.00047245]
	Learning Rate: 0.000472453
	LOSS [training: 0.1365638422974198 | validation: 0.298768939618824]
	TIME [epoch: 6.4 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1190128133228719		[learning rate: 0.00047023]
	Learning Rate: 0.000470227
	LOSS [training: 0.1190128133228719 | validation: 0.31579686858601264]
	TIME [epoch: 6.37 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1108050912385445		[learning rate: 0.00046801]
	Learning Rate: 0.000468011
	LOSS [training: 0.1108050912385445 | validation: 0.3065380360907571]
	TIME [epoch: 6.4 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1547905102203622		[learning rate: 0.00046581]
	Learning Rate: 0.000465806
	LOSS [training: 0.1547905102203622 | validation: 0.29556029288124713]
	TIME [epoch: 6.38 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14223770692711565		[learning rate: 0.00046361]
	Learning Rate: 0.000463611
	LOSS [training: 0.14223770692711565 | validation: 0.29768925154681086]
	TIME [epoch: 6.4 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14081348741249763		[learning rate: 0.00046143]
	Learning Rate: 0.000461426
	LOSS [training: 0.14081348741249763 | validation: 0.28512025497573396]
	TIME [epoch: 6.39 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15996987988205724		[learning rate: 0.00045925]
	Learning Rate: 0.000459252
	LOSS [training: 0.15996987988205724 | validation: 0.30275682836324436]
	TIME [epoch: 6.41 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18038618077038582		[learning rate: 0.00045709]
	Learning Rate: 0.000457088
	LOSS [training: 0.18038618077038582 | validation: 0.2784655519874496]
	TIME [epoch: 6.39 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14549772433822789		[learning rate: 0.00045493]
	Learning Rate: 0.000454934
	LOSS [training: 0.14549772433822789 | validation: 0.36511981886739325]
	TIME [epoch: 6.39 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1601764836385263		[learning rate: 0.00045279]
	Learning Rate: 0.000452791
	LOSS [training: 0.1601764836385263 | validation: 0.3156746895066819]
	TIME [epoch: 6.38 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11567240262576106		[learning rate: 0.00045066]
	Learning Rate: 0.000450657
	LOSS [training: 0.11567240262576106 | validation: 0.30349124215442685]
	TIME [epoch: 6.44 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1379299536793941		[learning rate: 0.00044853]
	Learning Rate: 0.000448533
	LOSS [training: 0.1379299536793941 | validation: 0.32053492601144695]
	TIME [epoch: 6.39 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11862297070186643		[learning rate: 0.00044642]
	Learning Rate: 0.00044642
	LOSS [training: 0.11862297070186643 | validation: 0.28379290505144117]
	TIME [epoch: 6.41 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13997503830261526		[learning rate: 0.00044432]
	Learning Rate: 0.000444316
	LOSS [training: 0.13997503830261526 | validation: 0.32127266548739086]
	TIME [epoch: 6.41 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19416921526954165		[learning rate: 0.00044222]
	Learning Rate: 0.000442223
	LOSS [training: 0.19416921526954165 | validation: 0.31109171594200047]
	TIME [epoch: 6.41 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12546087924560997		[learning rate: 0.00044014]
	Learning Rate: 0.000440139
	LOSS [training: 0.12546087924560997 | validation: 0.29488108200276886]
	TIME [epoch: 6.42 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1261117669761257		[learning rate: 0.00043806]
	Learning Rate: 0.000438065
	LOSS [training: 0.1261117669761257 | validation: 0.29990820617832153]
	TIME [epoch: 6.41 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1410361571752688		[learning rate: 0.000436]
	Learning Rate: 0.000436001
	LOSS [training: 0.1410361571752688 | validation: 0.3262451963343579]
	TIME [epoch: 6.38 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17206381546008898		[learning rate: 0.00043395]
	Learning Rate: 0.000433946
	LOSS [training: 0.17206381546008898 | validation: 0.31492359416014454]
	TIME [epoch: 6.4 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13819684380258423		[learning rate: 0.0004319]
	Learning Rate: 0.000431901
	LOSS [training: 0.13819684380258423 | validation: 0.28589831653317277]
	TIME [epoch: 6.39 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1427419456628368		[learning rate: 0.00042987]
	Learning Rate: 0.000429866
	LOSS [training: 0.1427419456628368 | validation: 0.28101715616323875]
	TIME [epoch: 6.41 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14367680790703888		[learning rate: 0.00042784]
	Learning Rate: 0.000427841
	LOSS [training: 0.14367680790703888 | validation: 0.3005518041465973]
	TIME [epoch: 6.41 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14402568450513942		[learning rate: 0.00042582]
	Learning Rate: 0.000425825
	LOSS [training: 0.14402568450513942 | validation: 0.3471974788935223]
	TIME [epoch: 6.4 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13006661056138316		[learning rate: 0.00042382]
	Learning Rate: 0.000423818
	LOSS [training: 0.13006661056138316 | validation: 0.33623200158414923]
	TIME [epoch: 6.4 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1497886487466341		[learning rate: 0.00042182]
	Learning Rate: 0.000421821
	LOSS [training: 0.1497886487466341 | validation: 0.32098883013844215]
	TIME [epoch: 6.38 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14275446323739188		[learning rate: 0.00041983]
	Learning Rate: 0.000419833
	LOSS [training: 0.14275446323739188 | validation: 0.29762754489097315]
	TIME [epoch: 6.4 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13196973589671415		[learning rate: 0.00041786]
	Learning Rate: 0.000417855
	LOSS [training: 0.13196973589671415 | validation: 0.29462351375576445]
	TIME [epoch: 6.4 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14924421244955258		[learning rate: 0.00041589]
	Learning Rate: 0.000415886
	LOSS [training: 0.14924421244955258 | validation: 0.2662878296454073]
	TIME [epoch: 6.4 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12118747869598795		[learning rate: 0.00041393]
	Learning Rate: 0.000413926
	LOSS [training: 0.12118747869598795 | validation: 0.3224908331402346]
	TIME [epoch: 6.38 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12665571965954334		[learning rate: 0.00041198]
	Learning Rate: 0.000411976
	LOSS [training: 0.12665571965954334 | validation: 0.3195990626385483]
	TIME [epoch: 6.39 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11198439530546885		[learning rate: 0.00041003]
	Learning Rate: 0.000410035
	LOSS [training: 0.11198439530546885 | validation: 0.3173327533594536]
	TIME [epoch: 6.38 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12173641693241274		[learning rate: 0.0004081]
	Learning Rate: 0.000408102
	LOSS [training: 0.12173641693241274 | validation: 0.28250979177702235]
	TIME [epoch: 6.36 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16370918939261703		[learning rate: 0.00040618]
	Learning Rate: 0.000406179
	LOSS [training: 0.16370918939261703 | validation: 0.2889609364118751]
	TIME [epoch: 6.41 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1479154012255478		[learning rate: 0.00040427]
	Learning Rate: 0.000404266
	LOSS [training: 0.1479154012255478 | validation: 0.3096986213580275]
	TIME [epoch: 6.39 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15883630017269496		[learning rate: 0.00040236]
	Learning Rate: 0.000402361
	LOSS [training: 0.15883630017269496 | validation: 0.29770317733741514]
	TIME [epoch: 6.38 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14224703063266025		[learning rate: 0.00040046]
	Learning Rate: 0.000400465
	LOSS [training: 0.14224703063266025 | validation: 0.29188344663206]
	TIME [epoch: 6.39 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1307877009971103		[learning rate: 0.00039858]
	Learning Rate: 0.000398578
	LOSS [training: 0.1307877009971103 | validation: 0.32054443362849755]
	TIME [epoch: 6.4 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13198325475272915		[learning rate: 0.0003967]
	Learning Rate: 0.000396699
	LOSS [training: 0.13198325475272915 | validation: 0.33359830391225886]
	TIME [epoch: 6.37 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16066748998105485		[learning rate: 0.00039483]
	Learning Rate: 0.00039483
	LOSS [training: 0.16066748998105485 | validation: 0.2774604375387012]
	TIME [epoch: 6.37 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11825517771626304		[learning rate: 0.00039297]
	Learning Rate: 0.00039297
	LOSS [training: 0.11825517771626304 | validation: 0.3113232259279577]
	TIME [epoch: 6.39 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12796847777646853		[learning rate: 0.00039112]
	Learning Rate: 0.000391118
	LOSS [training: 0.12796847777646853 | validation: 0.29300061025017926]
	TIME [epoch: 6.4 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15568644707010332		[learning rate: 0.00038927]
	Learning Rate: 0.000389275
	LOSS [training: 0.15568644707010332 | validation: 0.2754240210537451]
	TIME [epoch: 6.39 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1035560438965195		[learning rate: 0.00038744]
	Learning Rate: 0.000387441
	LOSS [training: 0.1035560438965195 | validation: 0.292017690668494]
	TIME [epoch: 6.4 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13542904204360712		[learning rate: 0.00038561]
	Learning Rate: 0.000385615
	LOSS [training: 0.13542904204360712 | validation: 0.31481633145996935]
	TIME [epoch: 6.38 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14423192669016133		[learning rate: 0.0003838]
	Learning Rate: 0.000383798
	LOSS [training: 0.14423192669016133 | validation: 0.2955783818480606]
	TIME [epoch: 6.39 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12884653135353052		[learning rate: 0.00038199]
	Learning Rate: 0.000381989
	LOSS [training: 0.12884653135353052 | validation: 0.28923904810517426]
	TIME [epoch: 6.4 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15551004871396518		[learning rate: 0.00038019]
	Learning Rate: 0.000380189
	LOSS [training: 0.15551004871396518 | validation: 0.27756594732756196]
	TIME [epoch: 6.41 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13215043049090247		[learning rate: 0.0003784]
	Learning Rate: 0.000378398
	LOSS [training: 0.13215043049090247 | validation: 0.2920603727852206]
	TIME [epoch: 6.37 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1230211967163656		[learning rate: 0.00037661]
	Learning Rate: 0.000376615
	LOSS [training: 0.1230211967163656 | validation: 0.3112885255342463]
	TIME [epoch: 6.42 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1313731143997305		[learning rate: 0.00037484]
	Learning Rate: 0.00037484
	LOSS [training: 0.1313731143997305 | validation: 0.29470029840290435]
	TIME [epoch: 6.37 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13241857567766435		[learning rate: 0.00037307]
	Learning Rate: 0.000373074
	LOSS [training: 0.13241857567766435 | validation: 0.28267154498146396]
	TIME [epoch: 6.39 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15145467313962718		[learning rate: 0.00037132]
	Learning Rate: 0.000371316
	LOSS [training: 0.15145467313962718 | validation: 0.30656790958691305]
	TIME [epoch: 6.38 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15619426929811048		[learning rate: 0.00036957]
	Learning Rate: 0.000369566
	LOSS [training: 0.15619426929811048 | validation: 0.2913944646839225]
	TIME [epoch: 6.4 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1626388346272061		[learning rate: 0.00036782]
	Learning Rate: 0.000367825
	LOSS [training: 0.1626388346272061 | validation: 0.30795904434495536]
	TIME [epoch: 6.37 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15385934485331257		[learning rate: 0.00036609]
	Learning Rate: 0.000366092
	LOSS [training: 0.15385934485331257 | validation: 0.3010972877060125]
	TIME [epoch: 6.4 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16548707603798732		[learning rate: 0.00036437]
	Learning Rate: 0.000364367
	LOSS [training: 0.16548707603798732 | validation: 0.31366168551515633]
	TIME [epoch: 6.38 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14912941460286666		[learning rate: 0.00036265]
	Learning Rate: 0.00036265
	LOSS [training: 0.14912941460286666 | validation: 0.3096753770673179]
	TIME [epoch: 6.4 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13994613919502705		[learning rate: 0.00036094]
	Learning Rate: 0.000360941
	LOSS [training: 0.13994613919502705 | validation: 0.32315303042996335]
	TIME [epoch: 6.39 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13643024203517895		[learning rate: 0.00035924]
	Learning Rate: 0.00035924
	LOSS [training: 0.13643024203517895 | validation: 0.34330198348587365]
	TIME [epoch: 6.38 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10881575442315376		[learning rate: 0.00035755]
	Learning Rate: 0.000357547
	LOSS [training: 0.10881575442315376 | validation: 0.3162121259066783]
	TIME [epoch: 6.39 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16097028892458703		[learning rate: 0.00035586]
	Learning Rate: 0.000355862
	LOSS [training: 0.16097028892458703 | validation: 0.2952739708780985]
	TIME [epoch: 6.4 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10943266587515896		[learning rate: 0.00035419]
	Learning Rate: 0.000354185
	LOSS [training: 0.10943266587515896 | validation: 0.30085566188729024]
	TIME [epoch: 6.36 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12020355118853508		[learning rate: 0.00035252]
	Learning Rate: 0.000352517
	LOSS [training: 0.12020355118853508 | validation: 0.312631459449789]
	TIME [epoch: 6.38 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1307343167223634		[learning rate: 0.00035086]
	Learning Rate: 0.000350855
	LOSS [training: 0.1307343167223634 | validation: 0.3114253289504828]
	TIME [epoch: 6.38 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15363092301267517		[learning rate: 0.0003492]
	Learning Rate: 0.000349202
	LOSS [training: 0.15363092301267517 | validation: 0.32634481298469553]
	TIME [epoch: 6.36 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13332507103281363		[learning rate: 0.00034756]
	Learning Rate: 0.000347557
	LOSS [training: 0.13332507103281363 | validation: 0.3008245003977641]
	TIME [epoch: 6.39 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.155412941713434		[learning rate: 0.00034592]
	Learning Rate: 0.000345919
	LOSS [training: 0.155412941713434 | validation: 0.33032994854515296]
	TIME [epoch: 6.4 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10736074050883189		[learning rate: 0.00034429]
	Learning Rate: 0.000344289
	LOSS [training: 0.10736074050883189 | validation: 0.307200910383164]
	TIME [epoch: 6.38 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14447870884774788		[learning rate: 0.00034267]
	Learning Rate: 0.000342667
	LOSS [training: 0.14447870884774788 | validation: 0.32464077129162633]
	TIME [epoch: 6.38 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15600887070039451		[learning rate: 0.00034105]
	Learning Rate: 0.000341052
	LOSS [training: 0.15600887070039451 | validation: 0.29090010661772964]
	TIME [epoch: 6.37 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1267464493082829		[learning rate: 0.00033944]
	Learning Rate: 0.000339445
	LOSS [training: 0.1267464493082829 | validation: 0.32884193158705904]
	TIME [epoch: 6.37 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12347626551250433		[learning rate: 0.00033785]
	Learning Rate: 0.000337845
	LOSS [training: 0.12347626551250433 | validation: 0.3013354258495617]
	TIME [epoch: 6.38 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12432047384280775		[learning rate: 0.00033625]
	Learning Rate: 0.000336253
	LOSS [training: 0.12432047384280775 | validation: 0.28852121760980626]
	TIME [epoch: 6.39 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13882516286615615		[learning rate: 0.00033467]
	Learning Rate: 0.000334669
	LOSS [training: 0.13882516286615615 | validation: 0.28190538849979774]
	TIME [epoch: 6.38 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1412376487777637		[learning rate: 0.00033309]
	Learning Rate: 0.000333092
	LOSS [training: 0.1412376487777637 | validation: 0.2974798630029646]
	TIME [epoch: 6.37 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13415639731421605		[learning rate: 0.00033152]
	Learning Rate: 0.000331522
	LOSS [training: 0.13415639731421605 | validation: 0.34192952363626944]
	TIME [epoch: 6.36 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12962278674698946		[learning rate: 0.00032996]
	Learning Rate: 0.00032996
	LOSS [training: 0.12962278674698946 | validation: 0.3048176758484948]
	TIME [epoch: 6.37 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1527347710292875		[learning rate: 0.00032841]
	Learning Rate: 0.000328405
	LOSS [training: 0.1527347710292875 | validation: 0.28855453412542914]
	TIME [epoch: 6.36 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1561683281218446		[learning rate: 0.00032686]
	Learning Rate: 0.000326858
	LOSS [training: 0.1561683281218446 | validation: 0.28729539888343186]
	TIME [epoch: 6.39 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14668756960629534		[learning rate: 0.00032532]
	Learning Rate: 0.000325318
	LOSS [training: 0.14668756960629534 | validation: 0.31020197355742574]
	TIME [epoch: 6.35 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1444898457604335		[learning rate: 0.00032378]
	Learning Rate: 0.000323785
	LOSS [training: 0.1444898457604335 | validation: 0.32871296541289297]
	TIME [epoch: 6.37 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13357323552583808		[learning rate: 0.00032226]
	Learning Rate: 0.000322259
	LOSS [training: 0.13357323552583808 | validation: 0.3133773618922962]
	TIME [epoch: 6.4 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11756190691271481		[learning rate: 0.00032074]
	Learning Rate: 0.000320741
	LOSS [training: 0.11756190691271481 | validation: 0.29266131492972763]
	TIME [epoch: 6.44 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1385319003821471		[learning rate: 0.00031923]
	Learning Rate: 0.000319229
	LOSS [training: 0.1385319003821471 | validation: 0.30399181967357825]
	TIME [epoch: 6.38 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14556499881987797		[learning rate: 0.00031772]
	Learning Rate: 0.000317725
	LOSS [training: 0.14556499881987797 | validation: 0.3089803628143025]
	TIME [epoch: 6.41 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1515122664731011		[learning rate: 0.00031623]
	Learning Rate: 0.000316228
	LOSS [training: 0.1515122664731011 | validation: 0.3188746536219916]
	TIME [epoch: 6.39 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13949297101518612		[learning rate: 0.00031474]
	Learning Rate: 0.000314738
	LOSS [training: 0.13949297101518612 | validation: 0.3186384282062006]
	TIME [epoch: 6.37 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12890552324944837		[learning rate: 0.00031325]
	Learning Rate: 0.000313255
	LOSS [training: 0.12890552324944837 | validation: 0.29840353492207483]
	TIME [epoch: 6.37 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1325279361528793		[learning rate: 0.00031178]
	Learning Rate: 0.000311778
	LOSS [training: 0.1325279361528793 | validation: 0.3148480467860567]
	TIME [epoch: 6.38 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13822762815336087		[learning rate: 0.00031031]
	Learning Rate: 0.000310309
	LOSS [training: 0.13822762815336087 | validation: 0.2789383327753659]
	TIME [epoch: 6.39 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11396629316238321		[learning rate: 0.00030885]
	Learning Rate: 0.000308847
	LOSS [training: 0.11396629316238321 | validation: 0.29776424006497826]
	TIME [epoch: 6.38 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1461932911821814		[learning rate: 0.00030739]
	Learning Rate: 0.000307392
	LOSS [training: 0.1461932911821814 | validation: 0.28608801369210685]
	TIME [epoch: 6.41 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14557257464835405		[learning rate: 0.00030594]
	Learning Rate: 0.000305943
	LOSS [training: 0.14557257464835405 | validation: 0.2962496435992626]
	TIME [epoch: 6.39 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13243201562705623		[learning rate: 0.0003045]
	Learning Rate: 0.000304502
	LOSS [training: 0.13243201562705623 | validation: 0.300190161344675]
	TIME [epoch: 6.35 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12378113085173831		[learning rate: 0.00030307]
	Learning Rate: 0.000303067
	LOSS [training: 0.12378113085173831 | validation: 0.31948068742909613]
	TIME [epoch: 6.39 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15084270572719177		[learning rate: 0.00030164]
	Learning Rate: 0.000301639
	LOSS [training: 0.15084270572719177 | validation: 0.32214698264368846]
	TIME [epoch: 6.38 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1520360434321083		[learning rate: 0.00030022]
	Learning Rate: 0.000300217
	LOSS [training: 0.1520360434321083 | validation: 0.3079876143844428]
	TIME [epoch: 6.36 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15642235013437852		[learning rate: 0.0002988]
	Learning Rate: 0.000298803
	LOSS [training: 0.15642235013437852 | validation: 0.3321774987031658]
	TIME [epoch: 6.38 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1395940787050755		[learning rate: 0.00029739]
	Learning Rate: 0.000297395
	LOSS [training: 0.1395940787050755 | validation: 0.3180746879180305]
	TIME [epoch: 6.38 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1466098981761095		[learning rate: 0.00029599]
	Learning Rate: 0.000295993
	LOSS [training: 0.1466098981761095 | validation: 0.31233753255760227]
	TIME [epoch: 6.35 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13178337902219034		[learning rate: 0.0002946]
	Learning Rate: 0.000294599
	LOSS [training: 0.13178337902219034 | validation: 0.29691258939842574]
	TIME [epoch: 6.36 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13089364692389413		[learning rate: 0.00029321]
	Learning Rate: 0.00029321
	LOSS [training: 0.13089364692389413 | validation: 0.32154368576344117]
	TIME [epoch: 6.37 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11302650945224402		[learning rate: 0.00029183]
	Learning Rate: 0.000291829
	LOSS [training: 0.11302650945224402 | validation: 0.3201963266398606]
	TIME [epoch: 6.35 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15801053353816935		[learning rate: 0.00029045]
	Learning Rate: 0.000290454
	LOSS [training: 0.15801053353816935 | validation: 0.3030573617060158]
	TIME [epoch: 6.38 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14343670960619426		[learning rate: 0.00028909]
	Learning Rate: 0.000289085
	LOSS [training: 0.14343670960619426 | validation: 0.3293375948752673]
	TIME [epoch: 6.4 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1540219078831979		[learning rate: 0.00028772]
	Learning Rate: 0.000287723
	LOSS [training: 0.1540219078831979 | validation: 0.2767723376880637]
	TIME [epoch: 6.37 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1638934886217716		[learning rate: 0.00028637]
	Learning Rate: 0.000286367
	LOSS [training: 0.1638934886217716 | validation: 0.32154550664175996]
	TIME [epoch: 6.38 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v5_20240715_175905/states/model_facs_v3_dec2b_2dpca_v5_790.pth
Halted early. No improvement in validation loss for 200 epochs.
Finished training in 3725.896 seconds.
