Args:
Namespace(name='model_facs_v3_dec1b_2dpca_v15b', outdir='out/model_training/model_facs_v3_dec1b_2dpca_v15b', training_data='data/training_data/facs_v3/pca/dec1_fitonsubset/transition1_subset_epi_tr_ce_an_pc12/training', validation_data='data/training_data/facs_v3/pca/dec1_fitonsubset/transition1_subset_epi_tr_ce_an_pc12/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=10, batch_size=50, patience=200, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, quadratic_a=1.0, quadratic_b=1.0, ndims=2, nparams=2, nsigs=2, ncells=100, ncells_sample=100, model_do_sample=False, dt=0.005, dt_schedule='stepped', dt_schedule_bounds=[50, 100, 200, 300], dt_schedule_scales=[0.5, 0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', kernel='multiscale', bw_range=[0.2, 0.5, 0.9, 1.1, 1.3, 1.5, 2.0], optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 2069975858

Training model...

Saving initial model state to: out/model_training/model_facs_v3_dec1b_2dpca_v15b_20240719_005205/states/model_facs_v3_dec1b_2dpca_v15b_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.6566683215631166		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6566683215631166 | validation: 1.2638857459355275]
	TIME [epoch: 19.6 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15b_20240719_005205/states/model_facs_v3_dec1b_2dpca_v15b_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.3590622440889957		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3590622440889957 | validation: 1.1803458744738922]
	TIME [epoch: 5.19 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15b_20240719_005205/states/model_facs_v3_dec1b_2dpca_v15b_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.2985848169452987		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2985848169452987 | validation: 1.1770063287457881]
	TIME [epoch: 5.18 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15b_20240719_005205/states/model_facs_v3_dec1b_2dpca_v15b_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.2305639347235824		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2305639347235824 | validation: 1.100632217119837]
	TIME [epoch: 5.18 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15b_20240719_005205/states/model_facs_v3_dec1b_2dpca_v15b_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.2143606965439695		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2143606965439695 | validation: 1.0784647107376748]
	TIME [epoch: 5.18 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15b_20240719_005205/states/model_facs_v3_dec1b_2dpca_v15b_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.1376579733053154		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1376579733053154 | validation: 1.0974409181635292]
	TIME [epoch: 5.19 sec]
EPOCH 7/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.1342699367712437		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1342699367712437 | validation: 1.0624098389199985]
	TIME [epoch: 5.18 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15b_20240719_005205/states/model_facs_v3_dec1b_2dpca_v15b_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.0791382438596904		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0791382438596904 | validation: 1.0414224185317018]
	TIME [epoch: 5.18 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15b_20240719_005205/states/model_facs_v3_dec1b_2dpca_v15b_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.1443878176339257		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1443878176339257 | validation: 0.9592218428466797]
	TIME [epoch: 5.18 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15b_20240719_005205/states/model_facs_v3_dec1b_2dpca_v15b_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.005564732370199		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.005564732370199 | validation: 0.9576656922914168]
	TIME [epoch: 5.18 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15b_20240719_005205/states/model_facs_v3_dec1b_2dpca_v15b_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.9864593759724376		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9864593759724376 | validation: 0.9199509240262854]
	TIME [epoch: 5.21 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15b_20240719_005205/states/model_facs_v3_dec1b_2dpca_v15b_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.924263923503708		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.924263923503708 | validation: 1.0819362668710986]
	TIME [epoch: 5.18 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.9029763545835503		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9029763545835503 | validation: 0.8427677670861764]
	TIME [epoch: 5.17 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15b_20240719_005205/states/model_facs_v3_dec1b_2dpca_v15b_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.8004509496479019		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8004509496479019 | validation: 0.9138657101687906]
	TIME [epoch: 5.18 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.8742057165442835		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8742057165442835 | validation: 0.7108176806130564]
	TIME [epoch: 5.17 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15b_20240719_005205/states/model_facs_v3_dec1b_2dpca_v15b_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.7102446601078424		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7102446601078424 | validation: 0.7301046802492805]
	TIME [epoch: 5.18 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.6511627434241789		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6511627434241789 | validation: 0.7208455391021835]
	TIME [epoch: 5.18 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.6494142959580199		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6494142959580199 | validation: 0.5183690445354882]
	TIME [epoch: 5.17 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15b_20240719_005205/states/model_facs_v3_dec1b_2dpca_v15b_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5151717165925106		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5151717165925106 | validation: 0.4349875828039753]
	TIME [epoch: 5.18 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15b_20240719_005205/states/model_facs_v3_dec1b_2dpca_v15b_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.621890869080918		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.621890869080918 | validation: 0.3952853862432725]
	TIME [epoch: 5.19 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15b_20240719_005205/states/model_facs_v3_dec1b_2dpca_v15b_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4790036359409228		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4790036359409228 | validation: 0.40946125271041894]
	TIME [epoch: 5.17 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.488012469590746		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.488012469590746 | validation: 0.3999254926640386]
	TIME [epoch: 5.21 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.445627774631326		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.445627774631326 | validation: 0.37921867125796915]
	TIME [epoch: 5.17 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15b_20240719_005205/states/model_facs_v3_dec1b_2dpca_v15b_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4617835732927061		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4617835732927061 | validation: 0.36554408705505015]
	TIME [epoch: 5.19 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15b_20240719_005205/states/model_facs_v3_dec1b_2dpca_v15b_24.pth
	Model improved!!!
EPOCH 25/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.42630348580611277		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.42630348580611277 | validation: 0.3845070634443745]
	TIME [epoch: 5.18 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4514230997684532		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4514230997684532 | validation: 0.3562631592074229]
	TIME [epoch: 5.17 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15b_20240719_005205/states/model_facs_v3_dec1b_2dpca_v15b_26.pth
	Model improved!!!
EPOCH 27/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4314647293159135		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4314647293159135 | validation: 0.362354795889184]
	TIME [epoch: 5.2 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.410852924589761		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.410852924589761 | validation: 0.32741873224269546]
	TIME [epoch: 5.18 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15b_20240719_005205/states/model_facs_v3_dec1b_2dpca_v15b_28.pth
	Model improved!!!
EPOCH 29/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.42104271319862435		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.42104271319862435 | validation: 0.3113226217353694]
	TIME [epoch: 5.18 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15b_20240719_005205/states/model_facs_v3_dec1b_2dpca_v15b_29.pth
	Model improved!!!
EPOCH 30/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.39658290341470553		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.39658290341470553 | validation: 0.34333984612665136]
	TIME [epoch: 5.18 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3909700933530291		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3909700933530291 | validation: 0.3355766533085567]
	TIME [epoch: 5.17 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.39250845067589885		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.39250845067589885 | validation: 0.325027342706466]
	TIME [epoch: 5.18 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3878173721550045		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3878173721550045 | validation: 0.3376344172253275]
	TIME [epoch: 5.17 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3804902679588526		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3804902679588526 | validation: 0.32904573403204007]
	TIME [epoch: 5.17 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.39641214678898673		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.39641214678898673 | validation: 0.2849346254355535]
	TIME [epoch: 5.18 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15b_20240719_005205/states/model_facs_v3_dec1b_2dpca_v15b_35.pth
	Model improved!!!
EPOCH 36/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.38080676107595735		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.38080676107595735 | validation: 0.29339094398038895]
	TIME [epoch: 5.18 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.38273659551774414		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.38273659551774414 | validation: 0.30457460068695497]
	TIME [epoch: 5.18 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.38784454882041897		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.38784454882041897 | validation: 0.3106827957507249]
	TIME [epoch: 5.18 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3442639249553679		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3442639249553679 | validation: 0.3209015838351684]
	TIME [epoch: 5.18 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3432512775374081		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3432512775374081 | validation: 0.29842211688317655]
	TIME [epoch: 5.18 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3465820040231235		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3465820040231235 | validation: 0.3181193230466669]
	TIME [epoch: 5.18 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.36849971272331317		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.36849971272331317 | validation: 0.29799465367164885]
	TIME [epoch: 5.17 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3555800864589121		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3555800864589121 | validation: 0.27177615818222434]
	TIME [epoch: 5.18 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15b_20240719_005205/states/model_facs_v3_dec1b_2dpca_v15b_43.pth
	Model improved!!!
EPOCH 44/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.37571049132062		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.37571049132062 | validation: 0.2944655511601008]
	TIME [epoch: 5.18 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.37535990999500307		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.37535990999500307 | validation: 0.2876608072184873]
	TIME [epoch: 5.17 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.33191513581591403		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.33191513581591403 | validation: 0.2784835474090859]
	TIME [epoch: 5.17 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.35021440193205366		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.35021440193205366 | validation: 0.30349636705921385]
	TIME [epoch: 5.17 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.35038853504693		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.35038853504693 | validation: 0.3126355660250991]
	TIME [epoch: 5.17 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3489955802394113		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3489955802394113 | validation: 0.2752294000349831]
	TIME [epoch: 5.17 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3459254518510863		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3459254518510863 | validation: 0.2637554622316384]
	TIME [epoch: 5.17 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15b_20240719_005205/states/model_facs_v3_dec1b_2dpca_v15b_50.pth
	Model improved!!!
EPOCH 51/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3457148698184276		[learning rate: 0.0099705]
	Learning Rate: 0.00997052
	LOSS [training: 0.3457148698184276 | validation: 0.27014114073203566]
	TIME [epoch: 22.6 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3275008859353182		[learning rate: 0.0099353]
	Learning Rate: 0.00993527
	LOSS [training: 0.3275008859353182 | validation: 0.26081787320581373]
	TIME [epoch: 9.92 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15b_20240719_005205/states/model_facs_v3_dec1b_2dpca_v15b_52.pth
	Model improved!!!
EPOCH 53/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3732658241513847		[learning rate: 0.0099001]
	Learning Rate: 0.00990013
	LOSS [training: 0.3732658241513847 | validation: 0.2496518936923175]
	TIME [epoch: 9.89 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15b_20240719_005205/states/model_facs_v3_dec1b_2dpca_v15b_53.pth
	Model improved!!!
EPOCH 54/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.32365118285738065		[learning rate: 0.0098651]
	Learning Rate: 0.00986512
	LOSS [training: 0.32365118285738065 | validation: 0.3094481117848017]
	TIME [epoch: 9.9 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3211278527213879		[learning rate: 0.0098302]
	Learning Rate: 0.00983024
	LOSS [training: 0.3211278527213879 | validation: 0.28754123213342525]
	TIME [epoch: 9.89 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.33039688268838036		[learning rate: 0.0097955]
	Learning Rate: 0.00979548
	LOSS [training: 0.33039688268838036 | validation: 0.26015348586231424]
	TIME [epoch: 9.88 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.32360030354771424		[learning rate: 0.0097608]
	Learning Rate: 0.00976084
	LOSS [training: 0.32360030354771424 | validation: 0.24717583200063054]
	TIME [epoch: 9.89 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15b_20240719_005205/states/model_facs_v3_dec1b_2dpca_v15b_57.pth
	Model improved!!!
EPOCH 58/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.30335763293744217		[learning rate: 0.0097263]
	Learning Rate: 0.00972632
	LOSS [training: 0.30335763293744217 | validation: 0.2588345608342483]
	TIME [epoch: 9.9 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.32259904666311623		[learning rate: 0.0096919]
	Learning Rate: 0.00969193
	LOSS [training: 0.32259904666311623 | validation: 0.2461315397230995]
	TIME [epoch: 9.88 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15b_20240719_005205/states/model_facs_v3_dec1b_2dpca_v15b_59.pth
	Model improved!!!
EPOCH 60/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.330383605272732		[learning rate: 0.0096577]
	Learning Rate: 0.00965766
	LOSS [training: 0.330383605272732 | validation: 0.25471125914255566]
	TIME [epoch: 9.88 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3105642607622632		[learning rate: 0.0096235]
	Learning Rate: 0.00962351
	LOSS [training: 0.3105642607622632 | validation: 0.25233554012449433]
	TIME [epoch: 9.88 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3140852035849883		[learning rate: 0.0095895]
	Learning Rate: 0.00958948
	LOSS [training: 0.3140852035849883 | validation: 0.24692895902182058]
	TIME [epoch: 9.9 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.30217843308849174		[learning rate: 0.0095556]
	Learning Rate: 0.00955557
	LOSS [training: 0.30217843308849174 | validation: 0.29840434818153355]
	TIME [epoch: 9.88 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3610032900338038		[learning rate: 0.0095218]
	Learning Rate: 0.00952177
	LOSS [training: 0.3610032900338038 | validation: 0.25915682832578646]
	TIME [epoch: 9.88 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2985535739553673		[learning rate: 0.0094881]
	Learning Rate: 0.0094881
	LOSS [training: 0.2985535739553673 | validation: 0.33341375685792546]
	TIME [epoch: 9.88 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3198066357972046		[learning rate: 0.0094546]
	Learning Rate: 0.00945455
	LOSS [training: 0.3198066357972046 | validation: 0.23300629850949944]
	TIME [epoch: 9.89 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15b_20240719_005205/states/model_facs_v3_dec1b_2dpca_v15b_66.pth
	Model improved!!!
EPOCH 67/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2979295036255058		[learning rate: 0.0094211]
	Learning Rate: 0.00942112
	LOSS [training: 0.2979295036255058 | validation: 0.24712323287210286]
	TIME [epoch: 9.9 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.31913557724837965		[learning rate: 0.0093878]
	Learning Rate: 0.00938781
	LOSS [training: 0.31913557724837965 | validation: 0.24864370424904453]
	TIME [epoch: 9.9 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3106355435734898		[learning rate: 0.0093546]
	Learning Rate: 0.00935461
	LOSS [training: 0.3106355435734898 | validation: 0.259163528369923]
	TIME [epoch: 9.89 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3044643495574821		[learning rate: 0.0093215]
	Learning Rate: 0.00932153
	LOSS [training: 0.3044643495574821 | validation: 0.24830032990998677]
	TIME [epoch: 9.89 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.31862689725705		[learning rate: 0.0092886]
	Learning Rate: 0.00928857
	LOSS [training: 0.31862689725705 | validation: 0.23412960962531848]
	TIME [epoch: 9.9 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29405923168776116		[learning rate: 0.0092557]
	Learning Rate: 0.00925572
	LOSS [training: 0.29405923168776116 | validation: 0.2881435105978048]
	TIME [epoch: 9.89 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3617003134998104		[learning rate: 0.009223]
	Learning Rate: 0.00922299
	LOSS [training: 0.3617003134998104 | validation: 0.29113306804171046]
	TIME [epoch: 9.89 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3046065855312916		[learning rate: 0.0091904]
	Learning Rate: 0.00919038
	LOSS [training: 0.3046065855312916 | validation: 0.24131609757262779]
	TIME [epoch: 9.89 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2818348306163861		[learning rate: 0.0091579]
	Learning Rate: 0.00915788
	LOSS [training: 0.2818348306163861 | validation: 0.24507649261463832]
	TIME [epoch: 9.9 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3222222096609486		[learning rate: 0.0091255]
	Learning Rate: 0.00912549
	LOSS [training: 0.3222222096609486 | validation: 0.24928051274104743]
	TIME [epoch: 9.91 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3026682265136915		[learning rate: 0.0090932]
	Learning Rate: 0.00909323
	LOSS [training: 0.3026682265136915 | validation: 0.23676889356364525]
	TIME [epoch: 9.9 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29379773528469794		[learning rate: 0.0090611]
	Learning Rate: 0.00906107
	LOSS [training: 0.29379773528469794 | validation: 0.23348868819405885]
	TIME [epoch: 9.89 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2833684308471201		[learning rate: 0.009029]
	Learning Rate: 0.00902903
	LOSS [training: 0.2833684308471201 | validation: 0.2599286454772469]
	TIME [epoch: 9.9 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3016610182463479		[learning rate: 0.0089971]
	Learning Rate: 0.0089971
	LOSS [training: 0.3016610182463479 | validation: 0.2529781873213543]
	TIME [epoch: 9.91 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.289082881247995		[learning rate: 0.0089653]
	Learning Rate: 0.00896528
	LOSS [training: 0.289082881247995 | validation: 0.23917272255355587]
	TIME [epoch: 9.89 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28512390183269104		[learning rate: 0.0089336]
	Learning Rate: 0.00893358
	LOSS [training: 0.28512390183269104 | validation: 0.22386680147493535]
	TIME [epoch: 9.9 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15b_20240719_005205/states/model_facs_v3_dec1b_2dpca_v15b_82.pth
	Model improved!!!
EPOCH 83/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.30870218934541854		[learning rate: 0.008902]
	Learning Rate: 0.00890199
	LOSS [training: 0.30870218934541854 | validation: 0.24686435550718464]
	TIME [epoch: 9.9 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27815724280502746		[learning rate: 0.0088705]
	Learning Rate: 0.00887051
	LOSS [training: 0.27815724280502746 | validation: 0.2611855800316157]
	TIME [epoch: 9.9 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28134218396994415		[learning rate: 0.0088391]
	Learning Rate: 0.00883914
	LOSS [training: 0.28134218396994415 | validation: 0.24112034631073773]
	TIME [epoch: 9.9 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3073118505536006		[learning rate: 0.0088079]
	Learning Rate: 0.00880789
	LOSS [training: 0.3073118505536006 | validation: 0.24887408135105832]
	TIME [epoch: 9.9 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3071708072246471		[learning rate: 0.0087767]
	Learning Rate: 0.00877674
	LOSS [training: 0.3071708072246471 | validation: 0.26378582873216827]
	TIME [epoch: 9.89 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.31826381333000775		[learning rate: 0.0087457]
	Learning Rate: 0.00874571
	LOSS [training: 0.31826381333000775 | validation: 0.22211936790627168]
	TIME [epoch: 9.9 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15b_20240719_005205/states/model_facs_v3_dec1b_2dpca_v15b_88.pth
	Model improved!!!
EPOCH 89/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2842062656175994		[learning rate: 0.0087148]
	Learning Rate: 0.00871478
	LOSS [training: 0.2842062656175994 | validation: 0.2355393017024196]
	TIME [epoch: 9.91 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29294469404135415		[learning rate: 0.008684]
	Learning Rate: 0.00868396
	LOSS [training: 0.29294469404135415 | validation: 0.24236699360196665]
	TIME [epoch: 9.89 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2882957316670973		[learning rate: 0.0086533]
	Learning Rate: 0.00865326
	LOSS [training: 0.2882957316670973 | validation: 0.23106635213313798]
	TIME [epoch: 9.9 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2958963626437077		[learning rate: 0.0086227]
	Learning Rate: 0.00862265
	LOSS [training: 0.2958963626437077 | validation: 0.25781379077013]
	TIME [epoch: 9.9 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2894289991479495		[learning rate: 0.0085922]
	Learning Rate: 0.00859216
	LOSS [training: 0.2894289991479495 | validation: 0.2327447177257962]
	TIME [epoch: 9.9 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27854999846067213		[learning rate: 0.0085618]
	Learning Rate: 0.00856178
	LOSS [training: 0.27854999846067213 | validation: 0.22678609108754286]
	TIME [epoch: 9.9 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2950216671755342		[learning rate: 0.0085315]
	Learning Rate: 0.0085315
	LOSS [training: 0.2950216671755342 | validation: 0.21429152625471812]
	TIME [epoch: 9.89 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15b_20240719_005205/states/model_facs_v3_dec1b_2dpca_v15b_95.pth
	Model improved!!!
EPOCH 96/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.271971568893638		[learning rate: 0.0085013]
	Learning Rate: 0.00850134
	LOSS [training: 0.271971568893638 | validation: 0.23159374580299402]
	TIME [epoch: 9.92 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2919352633885259		[learning rate: 0.0084713]
	Learning Rate: 0.00847127
	LOSS [training: 0.2919352633885259 | validation: 0.22188820790549907]
	TIME [epoch: 9.92 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29054084992890983		[learning rate: 0.0084413]
	Learning Rate: 0.00844132
	LOSS [training: 0.29054084992890983 | validation: 0.2229291378438209]
	TIME [epoch: 9.93 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27141774343478225		[learning rate: 0.0084115]
	Learning Rate: 0.00841147
	LOSS [training: 0.27141774343478225 | validation: 0.22516459595388602]
	TIME [epoch: 9.9 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2759978058662211		[learning rate: 0.0083817]
	Learning Rate: 0.00838172
	LOSS [training: 0.2759978058662211 | validation: 0.23762279258043892]
	TIME [epoch: 9.91 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28641708662764004		[learning rate: 0.0083521]
	Learning Rate: 0.00835208
	LOSS [training: 0.28641708662764004 | validation: 0.25196518991935135]
	TIME [epoch: 33.9 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2784107761325619		[learning rate: 0.0083225]
	Learning Rate: 0.00832255
	LOSS [training: 0.2784107761325619 | validation: 0.2200198692506233]
	TIME [epoch: 21.5 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2911035638710869		[learning rate: 0.0082931]
	Learning Rate: 0.00829312
	LOSS [training: 0.2911035638710869 | validation: 0.22002376477960217]
	TIME [epoch: 21.5 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27281541198504816		[learning rate: 0.0082638]
	Learning Rate: 0.00826379
	LOSS [training: 0.27281541198504816 | validation: 0.21174689471077887]
	TIME [epoch: 21.5 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15b_20240719_005205/states/model_facs_v3_dec1b_2dpca_v15b_104.pth
	Model improved!!!
EPOCH 105/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28738532398674693		[learning rate: 0.0082346]
	Learning Rate: 0.00823457
	LOSS [training: 0.28738532398674693 | validation: 0.23378465705828239]
	TIME [epoch: 21.5 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2848004622697112		[learning rate: 0.0082055]
	Learning Rate: 0.00820545
	LOSS [training: 0.2848004622697112 | validation: 0.22759469820811243]
	TIME [epoch: 21.5 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27161924634382373		[learning rate: 0.0081764]
	Learning Rate: 0.00817644
	LOSS [training: 0.27161924634382373 | validation: 0.23316620276577088]
	TIME [epoch: 21.5 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2888872452316325		[learning rate: 0.0081475]
	Learning Rate: 0.00814752
	LOSS [training: 0.2888872452316325 | validation: 0.2083319933645623]
	TIME [epoch: 21.5 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15b_20240719_005205/states/model_facs_v3_dec1b_2dpca_v15b_108.pth
	Model improved!!!
EPOCH 109/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2810533448650116		[learning rate: 0.0081187]
	Learning Rate: 0.00811871
	LOSS [training: 0.2810533448650116 | validation: 0.2285394708726412]
	TIME [epoch: 21.5 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28205995827737596		[learning rate: 0.00809]
	Learning Rate: 0.00809
	LOSS [training: 0.28205995827737596 | validation: 0.22701302012289748]
	TIME [epoch: 21.5 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.30312330569417595		[learning rate: 0.0080614]
	Learning Rate: 0.0080614
	LOSS [training: 0.30312330569417595 | validation: 0.23460668319026898]
	TIME [epoch: 21.5 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2900356811850598		[learning rate: 0.0080329]
	Learning Rate: 0.00803289
	LOSS [training: 0.2900356811850598 | validation: 0.2231799689649519]
	TIME [epoch: 21.5 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2797285061127321		[learning rate: 0.0080045]
	Learning Rate: 0.00800448
	LOSS [training: 0.2797285061127321 | validation: 0.22212663660485057]
	TIME [epoch: 21.5 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26655744359843475		[learning rate: 0.0079762]
	Learning Rate: 0.00797618
	LOSS [training: 0.26655744359843475 | validation: 0.21204747845282385]
	TIME [epoch: 21.5 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29554395683621343		[learning rate: 0.007948]
	Learning Rate: 0.00794797
	LOSS [training: 0.29554395683621343 | validation: 0.22375942710853022]
	TIME [epoch: 21.5 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28382946352693833		[learning rate: 0.0079199]
	Learning Rate: 0.00791987
	LOSS [training: 0.28382946352693833 | validation: 0.21781375649192172]
	TIME [epoch: 21.5 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27128873730252046		[learning rate: 0.0078919]
	Learning Rate: 0.00789186
	LOSS [training: 0.27128873730252046 | validation: 0.22306000993728398]
	TIME [epoch: 21.5 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27689176544312516		[learning rate: 0.007864]
	Learning Rate: 0.00786395
	LOSS [training: 0.27689176544312516 | validation: 0.22003909156688062]
	TIME [epoch: 21.5 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26179447412352536		[learning rate: 0.0078361]
	Learning Rate: 0.00783615
	LOSS [training: 0.26179447412352536 | validation: 0.23538317673946324]
	TIME [epoch: 21.5 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27422520423208013		[learning rate: 0.0078084]
	Learning Rate: 0.00780844
	LOSS [training: 0.27422520423208013 | validation: 0.23109007348001304]
	TIME [epoch: 21.5 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2770145863484587		[learning rate: 0.0077808]
	Learning Rate: 0.00778083
	LOSS [training: 0.2770145863484587 | validation: 0.22003857612410313]
	TIME [epoch: 21.5 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2899750458555606		[learning rate: 0.0077533]
	Learning Rate: 0.00775331
	LOSS [training: 0.2899750458555606 | validation: 0.2312360808571178]
	TIME [epoch: 21.5 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2908377269391341		[learning rate: 0.0077259]
	Learning Rate: 0.00772589
	LOSS [training: 0.2908377269391341 | validation: 0.21722058885457196]
	TIME [epoch: 21.5 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27007694455646253		[learning rate: 0.0076986]
	Learning Rate: 0.00769857
	LOSS [training: 0.27007694455646253 | validation: 0.21515557154053472]
	TIME [epoch: 21.5 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2636955781678805		[learning rate: 0.0076714]
	Learning Rate: 0.00767135
	LOSS [training: 0.2636955781678805 | validation: 0.22023670956048463]
	TIME [epoch: 21.5 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28427550765555526		[learning rate: 0.0076442]
	Learning Rate: 0.00764422
	LOSS [training: 0.28427550765555526 | validation: 0.21989545624650533]
	TIME [epoch: 21.5 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28260271513339247		[learning rate: 0.0076172]
	Learning Rate: 0.00761719
	LOSS [training: 0.28260271513339247 | validation: 0.22510231648692436]
	TIME [epoch: 21.5 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27271453369380033		[learning rate: 0.0075903]
	Learning Rate: 0.00759025
	LOSS [training: 0.27271453369380033 | validation: 0.21366409266431025]
	TIME [epoch: 21.5 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2723093109152751		[learning rate: 0.0075634]
	Learning Rate: 0.00756341
	LOSS [training: 0.2723093109152751 | validation: 0.2214180309521784]
	TIME [epoch: 21.5 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28285380906743884		[learning rate: 0.0075367]
	Learning Rate: 0.00753667
	LOSS [training: 0.28285380906743884 | validation: 0.22377055704626353]
	TIME [epoch: 21.5 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26765471969398197		[learning rate: 0.00751]
	Learning Rate: 0.00751002
	LOSS [training: 0.26765471969398197 | validation: 0.2259235318327555]
	TIME [epoch: 21.5 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26611361093104985		[learning rate: 0.0074835]
	Learning Rate: 0.00748346
	LOSS [training: 0.26611361093104985 | validation: 0.21778586468365488]
	TIME [epoch: 21.5 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2783633639274117		[learning rate: 0.007457]
	Learning Rate: 0.007457
	LOSS [training: 0.2783633639274117 | validation: 0.21343790045283142]
	TIME [epoch: 21.5 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2869597160193978		[learning rate: 0.0074306]
	Learning Rate: 0.00743063
	LOSS [training: 0.2869597160193978 | validation: 0.21612344121316882]
	TIME [epoch: 21.5 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.30135074858398797		[learning rate: 0.0074044]
	Learning Rate: 0.00740435
	LOSS [training: 0.30135074858398797 | validation: 0.21032636843327487]
	TIME [epoch: 21.5 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26326218749552593		[learning rate: 0.0073782]
	Learning Rate: 0.00737817
	LOSS [training: 0.26326218749552593 | validation: 0.23175378602464577]
	TIME [epoch: 21.5 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2831794849020259		[learning rate: 0.0073521]
	Learning Rate: 0.00735208
	LOSS [training: 0.2831794849020259 | validation: 0.21398582530132285]
	TIME [epoch: 21.6 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2661269142401452		[learning rate: 0.0073261]
	Learning Rate: 0.00732608
	LOSS [training: 0.2661269142401452 | validation: 0.22258563920742444]
	TIME [epoch: 21.5 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2740325580424417		[learning rate: 0.0073002]
	Learning Rate: 0.00730018
	LOSS [training: 0.2740325580424417 | validation: 0.2394469529190773]
	TIME [epoch: 21.5 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26986459191792816		[learning rate: 0.0072744]
	Learning Rate: 0.00727436
	LOSS [training: 0.26986459191792816 | validation: 0.21164651772470244]
	TIME [epoch: 21.5 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2737398365615577		[learning rate: 0.0072486]
	Learning Rate: 0.00724864
	LOSS [training: 0.2737398365615577 | validation: 0.20527446378684822]
	TIME [epoch: 21.5 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15b_20240719_005205/states/model_facs_v3_dec1b_2dpca_v15b_141.pth
	Model improved!!!
EPOCH 142/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2695806441808723		[learning rate: 0.007223]
	Learning Rate: 0.007223
	LOSS [training: 0.2695806441808723 | validation: 0.22179173850169845]
	TIME [epoch: 21.5 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2624220953514933		[learning rate: 0.0071975]
	Learning Rate: 0.00719746
	LOSS [training: 0.2624220953514933 | validation: 0.21678975545889118]
	TIME [epoch: 21.5 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2699156759238971		[learning rate: 0.007172]
	Learning Rate: 0.00717201
	LOSS [training: 0.2699156759238971 | validation: 0.21732461256004787]
	TIME [epoch: 21.5 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2724924643126598		[learning rate: 0.0071467]
	Learning Rate: 0.00714665
	LOSS [training: 0.2724924643126598 | validation: 0.21893227355308661]
	TIME [epoch: 21.5 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26973700236640846		[learning rate: 0.0071214]
	Learning Rate: 0.00712138
	LOSS [training: 0.26973700236640846 | validation: 0.21340065138444553]
	TIME [epoch: 21.5 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2746337738610989		[learning rate: 0.0070962]
	Learning Rate: 0.0070962
	LOSS [training: 0.2746337738610989 | validation: 0.21696822586472503]
	TIME [epoch: 21.5 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2682613834372079		[learning rate: 0.0070711]
	Learning Rate: 0.0070711
	LOSS [training: 0.2682613834372079 | validation: 0.21596565010206498]
	TIME [epoch: 21.5 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27335104096160256		[learning rate: 0.0070461]
	Learning Rate: 0.0070461
	LOSS [training: 0.27335104096160256 | validation: 0.209125816111645]
	TIME [epoch: 21.5 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2653117053059638		[learning rate: 0.0070212]
	Learning Rate: 0.00702118
	LOSS [training: 0.2653117053059638 | validation: 0.21768553562981427]
	TIME [epoch: 21.5 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26607936269657523		[learning rate: 0.0069964]
	Learning Rate: 0.00699635
	LOSS [training: 0.26607936269657523 | validation: 0.22092435432884155]
	TIME [epoch: 21.5 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.280552186973468		[learning rate: 0.0069716]
	Learning Rate: 0.00697161
	LOSS [training: 0.280552186973468 | validation: 0.2199025874840413]
	TIME [epoch: 21.5 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2533773099134618		[learning rate: 0.006947]
	Learning Rate: 0.00694696
	LOSS [training: 0.2533773099134618 | validation: 0.2202859968378208]
	TIME [epoch: 21.5 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26333178409730124		[learning rate: 0.0069224]
	Learning Rate: 0.00692239
	LOSS [training: 0.26333178409730124 | validation: 0.2042296774962422]
	TIME [epoch: 21.5 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15b_20240719_005205/states/model_facs_v3_dec1b_2dpca_v15b_154.pth
	Model improved!!!
EPOCH 155/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2677778610170247		[learning rate: 0.0068979]
	Learning Rate: 0.00689792
	LOSS [training: 0.2677778610170247 | validation: 0.2344861695169888]
	TIME [epoch: 21.6 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28434171906851097		[learning rate: 0.0068735]
	Learning Rate: 0.00687352
	LOSS [training: 0.28434171906851097 | validation: 0.22019421739799577]
	TIME [epoch: 21.5 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2663820750680655		[learning rate: 0.0068492]
	Learning Rate: 0.00684922
	LOSS [training: 0.2663820750680655 | validation: 0.21770519698741286]
	TIME [epoch: 21.5 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27400745356710005		[learning rate: 0.006825]
	Learning Rate: 0.006825
	LOSS [training: 0.27400745356710005 | validation: 0.21730153631043966]
	TIME [epoch: 21.5 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2556016562856933		[learning rate: 0.0068009]
	Learning Rate: 0.00680086
	LOSS [training: 0.2556016562856933 | validation: 0.22177218492891632]
	TIME [epoch: 21.5 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2803610081491072		[learning rate: 0.0067768]
	Learning Rate: 0.00677681
	LOSS [training: 0.2803610081491072 | validation: 0.22580584121493225]
	TIME [epoch: 21.5 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2726128677228354		[learning rate: 0.0067529]
	Learning Rate: 0.00675285
	LOSS [training: 0.2726128677228354 | validation: 0.21125125560534092]
	TIME [epoch: 21.5 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26100075340740975		[learning rate: 0.006729]
	Learning Rate: 0.00672897
	LOSS [training: 0.26100075340740975 | validation: 0.22225662734767598]
	TIME [epoch: 21.5 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26868468201100754		[learning rate: 0.0067052]
	Learning Rate: 0.00670518
	LOSS [training: 0.26868468201100754 | validation: 0.21542708713244743]
	TIME [epoch: 21.5 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2634725666724008		[learning rate: 0.0066815]
	Learning Rate: 0.00668147
	LOSS [training: 0.2634725666724008 | validation: 0.21887919077775625]
	TIME [epoch: 21.5 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25586878502877364		[learning rate: 0.0066578]
	Learning Rate: 0.00665784
	LOSS [training: 0.25586878502877364 | validation: 0.22993737106339668]
	TIME [epoch: 21.5 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2745864642727323		[learning rate: 0.0066343]
	Learning Rate: 0.0066343
	LOSS [training: 0.2745864642727323 | validation: 0.22346253370920946]
	TIME [epoch: 21.5 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2704109649323473		[learning rate: 0.0066108]
	Learning Rate: 0.00661084
	LOSS [training: 0.2704109649323473 | validation: 0.23762535273337093]
	TIME [epoch: 21.5 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2825335160583045		[learning rate: 0.0065875]
	Learning Rate: 0.00658746
	LOSS [training: 0.2825335160583045 | validation: 0.22902151387894037]
	TIME [epoch: 21.5 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26548466165946893		[learning rate: 0.0065642]
	Learning Rate: 0.00656416
	LOSS [training: 0.26548466165946893 | validation: 0.20912323906541302]
	TIME [epoch: 21.5 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2570729359670176		[learning rate: 0.006541]
	Learning Rate: 0.00654095
	LOSS [training: 0.2570729359670176 | validation: 0.21803197283880307]
	TIME [epoch: 21.5 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2678889973404213		[learning rate: 0.0065178]
	Learning Rate: 0.00651782
	LOSS [training: 0.2678889973404213 | validation: 0.2199981526626194]
	TIME [epoch: 21.5 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25641709340281144		[learning rate: 0.0064948]
	Learning Rate: 0.00649477
	LOSS [training: 0.25641709340281144 | validation: 0.21246412178583746]
	TIME [epoch: 21.5 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2586645691021036		[learning rate: 0.0064718]
	Learning Rate: 0.00647181
	LOSS [training: 0.2586645691021036 | validation: 0.22381232345929072]
	TIME [epoch: 21.5 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26455089178844093		[learning rate: 0.0064489]
	Learning Rate: 0.00644892
	LOSS [training: 0.26455089178844093 | validation: 0.21061446153643715]
	TIME [epoch: 21.5 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2642303101000062		[learning rate: 0.0064261]
	Learning Rate: 0.00642612
	LOSS [training: 0.2642303101000062 | validation: 0.21558404167528994]
	TIME [epoch: 21.5 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25964823537797493		[learning rate: 0.0064034]
	Learning Rate: 0.00640339
	LOSS [training: 0.25964823537797493 | validation: 0.254305573469913]
	TIME [epoch: 21.5 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.277807369820624		[learning rate: 0.0063808]
	Learning Rate: 0.00638075
	LOSS [training: 0.277807369820624 | validation: 0.22061997267534167]
	TIME [epoch: 21.5 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2762234129273207		[learning rate: 0.0063582]
	Learning Rate: 0.00635819
	LOSS [training: 0.2762234129273207 | validation: 0.22317312133541395]
	TIME [epoch: 21.5 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26001253264805313		[learning rate: 0.0063357]
	Learning Rate: 0.0063357
	LOSS [training: 0.26001253264805313 | validation: 0.21188878035779388]
	TIME [epoch: 21.5 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26270391866090964		[learning rate: 0.0063133]
	Learning Rate: 0.0063133
	LOSS [training: 0.26270391866090964 | validation: 0.212838657337416]
	TIME [epoch: 21.5 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26303537342322736		[learning rate: 0.006291]
	Learning Rate: 0.00629097
	LOSS [training: 0.26303537342322736 | validation: 0.21345547862013242]
	TIME [epoch: 21.5 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2701290322616962		[learning rate: 0.0062687]
	Learning Rate: 0.00626873
	LOSS [training: 0.2701290322616962 | validation: 0.22129959370895422]
	TIME [epoch: 21.5 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2594678905426098		[learning rate: 0.0062466]
	Learning Rate: 0.00624656
	LOSS [training: 0.2594678905426098 | validation: 0.2300947453033002]
	TIME [epoch: 21.5 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25304177784627063		[learning rate: 0.0062245]
	Learning Rate: 0.00622447
	LOSS [training: 0.25304177784627063 | validation: 0.21852388776043452]
	TIME [epoch: 21.6 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27449638966543505		[learning rate: 0.0062025]
	Learning Rate: 0.00620246
	LOSS [training: 0.27449638966543505 | validation: 0.20226423441500946]
	TIME [epoch: 21.5 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15b_20240719_005205/states/model_facs_v3_dec1b_2dpca_v15b_185.pth
	Model improved!!!
EPOCH 186/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26344167813415825		[learning rate: 0.0061805]
	Learning Rate: 0.00618053
	LOSS [training: 0.26344167813415825 | validation: 0.22681531928863063]
	TIME [epoch: 21.6 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2526798834490569		[learning rate: 0.0061587]
	Learning Rate: 0.00615867
	LOSS [training: 0.2526798834490569 | validation: 0.2364914572947062]
	TIME [epoch: 21.5 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2747409703337936		[learning rate: 0.0061369]
	Learning Rate: 0.00613689
	LOSS [training: 0.2747409703337936 | validation: 0.21404708752574195]
	TIME [epoch: 21.5 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26119911803386636		[learning rate: 0.0061152]
	Learning Rate: 0.00611519
	LOSS [training: 0.26119911803386636 | validation: 0.22209246624728948]
	TIME [epoch: 21.5 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25674739951131154		[learning rate: 0.0060936]
	Learning Rate: 0.00609357
	LOSS [training: 0.25674739951131154 | validation: 0.2202062360231234]
	TIME [epoch: 21.5 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.260516938738051		[learning rate: 0.006072]
	Learning Rate: 0.00607202
	LOSS [training: 0.260516938738051 | validation: 0.21376883349161435]
	TIME [epoch: 21.5 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26453668219916854		[learning rate: 0.0060505]
	Learning Rate: 0.00605055
	LOSS [training: 0.26453668219916854 | validation: 0.21262914344606218]
	TIME [epoch: 21.5 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26765520513070884		[learning rate: 0.0060292]
	Learning Rate: 0.00602915
	LOSS [training: 0.26765520513070884 | validation: 0.21894344918990621]
	TIME [epoch: 21.5 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2566002212437741		[learning rate: 0.0060078]
	Learning Rate: 0.00600783
	LOSS [training: 0.2566002212437741 | validation: 0.24391223131306644]
	TIME [epoch: 21.5 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27145686391398827		[learning rate: 0.0059866]
	Learning Rate: 0.00598659
	LOSS [training: 0.27145686391398827 | validation: 0.2165836419979245]
	TIME [epoch: 21.5 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2537082804014044		[learning rate: 0.0059654]
	Learning Rate: 0.00596542
	LOSS [training: 0.2537082804014044 | validation: 0.21052448400678142]
	TIME [epoch: 21.5 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2608226470858902		[learning rate: 0.0059443]
	Learning Rate: 0.00594433
	LOSS [training: 0.2608226470858902 | validation: 0.20866659558598433]
	TIME [epoch: 21.5 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2854438254306614		[learning rate: 0.0059233]
	Learning Rate: 0.0059233
	LOSS [training: 0.2854438254306614 | validation: 0.23466967383902326]
	TIME [epoch: 21.5 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2657687086676271		[learning rate: 0.0059024]
	Learning Rate: 0.00590236
	LOSS [training: 0.2657687086676271 | validation: 0.2079664641636571]
	TIME [epoch: 21.5 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.251566558969122		[learning rate: 0.0058815]
	Learning Rate: 0.00588149
	LOSS [training: 0.251566558969122 | validation: 0.21406334211121533]
	TIME [epoch: 21.5 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2708123642320043		[learning rate: 0.0058607]
	Learning Rate: 0.00586069
	LOSS [training: 0.2708123642320043 | validation: 0.22044436611680918]
	TIME [epoch: 58.9 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26612588153623173		[learning rate: 0.00584]
	Learning Rate: 0.00583996
	LOSS [training: 0.26612588153623173 | validation: 0.21462132658487065]
	TIME [epoch: 46.4 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2535272278228609		[learning rate: 0.0058193]
	Learning Rate: 0.00581931
	LOSS [training: 0.2535272278228609 | validation: 0.2142789902138885]
	TIME [epoch: 46.4 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25940576575586943		[learning rate: 0.0057987]
	Learning Rate: 0.00579874
	LOSS [training: 0.25940576575586943 | validation: 0.21311944728973406]
	TIME [epoch: 46.3 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2636268731942515		[learning rate: 0.0057782]
	Learning Rate: 0.00577823
	LOSS [training: 0.2636268731942515 | validation: 0.21849114318286222]
	TIME [epoch: 46.4 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26961274421206777		[learning rate: 0.0057578]
	Learning Rate: 0.0057578
	LOSS [training: 0.26961274421206777 | validation: 0.21854324501165606]
	TIME [epoch: 46.3 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2646271815155814		[learning rate: 0.0057374]
	Learning Rate: 0.00573744
	LOSS [training: 0.2646271815155814 | validation: 0.20364904823947644]
	TIME [epoch: 46.4 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2625367379261368		[learning rate: 0.0057171]
	Learning Rate: 0.00571715
	LOSS [training: 0.2625367379261368 | validation: 0.2120091315637187]
	TIME [epoch: 46.4 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2596177839549476		[learning rate: 0.0056969]
	Learning Rate: 0.00569693
	LOSS [training: 0.2596177839549476 | validation: 0.2067168733054614]
	TIME [epoch: 46.3 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2656400856238031		[learning rate: 0.0056768]
	Learning Rate: 0.00567679
	LOSS [training: 0.2656400856238031 | validation: 0.22836239382530055]
	TIME [epoch: 46.4 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2443588556173917		[learning rate: 0.0056567]
	Learning Rate: 0.00565671
	LOSS [training: 0.2443588556173917 | validation: 0.21376160046900097]
	TIME [epoch: 46.4 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26412611381959045		[learning rate: 0.0056367]
	Learning Rate: 0.00563671
	LOSS [training: 0.26412611381959045 | validation: 0.21522980009380058]
	TIME [epoch: 46.3 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24478679769220502		[learning rate: 0.0056168]
	Learning Rate: 0.00561678
	LOSS [training: 0.24478679769220502 | validation: 0.21307525673132974]
	TIME [epoch: 46.4 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26406380475298435		[learning rate: 0.0055969]
	Learning Rate: 0.00559691
	LOSS [training: 0.26406380475298435 | validation: 0.21531861126785717]
	TIME [epoch: 46.3 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27583719536157103		[learning rate: 0.0055771]
	Learning Rate: 0.00557712
	LOSS [training: 0.27583719536157103 | validation: 0.21010503659406427]
	TIME [epoch: 46.3 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2664282313712362		[learning rate: 0.0055574]
	Learning Rate: 0.0055574
	LOSS [training: 0.2664282313712362 | validation: 0.2091170553932838]
	TIME [epoch: 46.3 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24406539493500748		[learning rate: 0.0055378]
	Learning Rate: 0.00553775
	LOSS [training: 0.24406539493500748 | validation: 0.21871510451809253]
	TIME [epoch: 46.3 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2580670225050226		[learning rate: 0.0055182]
	Learning Rate: 0.00551817
	LOSS [training: 0.2580670225050226 | validation: 0.21687408667259733]
	TIME [epoch: 46.3 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26527723323633073		[learning rate: 0.0054987]
	Learning Rate: 0.00549865
	LOSS [training: 0.26527723323633073 | validation: 0.2025782025736514]
	TIME [epoch: 46.3 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2650037749378831		[learning rate: 0.0054792]
	Learning Rate: 0.00547921
	LOSS [training: 0.2650037749378831 | validation: 0.23043244528789356]
	TIME [epoch: 46.3 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26344920816376133		[learning rate: 0.0054598]
	Learning Rate: 0.00545983
	LOSS [training: 0.26344920816376133 | validation: 0.21208296750920966]
	TIME [epoch: 46.3 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2491790187057312		[learning rate: 0.0054405]
	Learning Rate: 0.00544053
	LOSS [training: 0.2491790187057312 | validation: 0.2143582647582119]
	TIME [epoch: 46.4 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2556904053975783		[learning rate: 0.0054213]
	Learning Rate: 0.00542129
	LOSS [training: 0.2556904053975783 | validation: 0.2118475616674874]
	TIME [epoch: 46.3 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2516314886372498		[learning rate: 0.0054021]
	Learning Rate: 0.00540212
	LOSS [training: 0.2516314886372498 | validation: 0.19562607598616558]
	TIME [epoch: 46.4 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15b_20240719_005205/states/model_facs_v3_dec1b_2dpca_v15b_224.pth
	Model improved!!!
EPOCH 225/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25919800120064124		[learning rate: 0.005383]
	Learning Rate: 0.00538302
	LOSS [training: 0.25919800120064124 | validation: 0.22015258308388302]
	TIME [epoch: 46.3 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2795993053042661		[learning rate: 0.005364]
	Learning Rate: 0.00536398
	LOSS [training: 0.2795993053042661 | validation: 0.21284815132092588]
	TIME [epoch: 46.3 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2551415363809288		[learning rate: 0.005345]
	Learning Rate: 0.00534501
	LOSS [training: 0.2551415363809288 | validation: 0.21860898939187803]
	TIME [epoch: 46.3 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2520037629245911		[learning rate: 0.0053261]
	Learning Rate: 0.00532611
	LOSS [training: 0.2520037629245911 | validation: 0.2086906742491717]
	TIME [epoch: 46.3 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2601855278276903		[learning rate: 0.0053073]
	Learning Rate: 0.00530728
	LOSS [training: 0.2601855278276903 | validation: 0.22956862397167727]
	TIME [epoch: 46.2 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25687419495338676		[learning rate: 0.0052885]
	Learning Rate: 0.00528851
	LOSS [training: 0.25687419495338676 | validation: 0.2241000029574073]
	TIME [epoch: 46.3 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25720966301782844		[learning rate: 0.0052698]
	Learning Rate: 0.00526981
	LOSS [training: 0.25720966301782844 | validation: 0.22589876617137797]
	TIME [epoch: 46.2 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27667708679452596		[learning rate: 0.0052512]
	Learning Rate: 0.00525117
	LOSS [training: 0.27667708679452596 | validation: 0.23175494277492184]
	TIME [epoch: 46.3 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2684321072181987		[learning rate: 0.0052326]
	Learning Rate: 0.0052326
	LOSS [training: 0.2684321072181987 | validation: 0.20829297162113222]
	TIME [epoch: 46.3 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.253730426899178		[learning rate: 0.0052141]
	Learning Rate: 0.0052141
	LOSS [training: 0.253730426899178 | validation: 0.22456137055523281]
	TIME [epoch: 46.3 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2599256935111581		[learning rate: 0.0051957]
	Learning Rate: 0.00519566
	LOSS [training: 0.2599256935111581 | validation: 0.23134138453892103]
	TIME [epoch: 46.3 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2695920090416675		[learning rate: 0.0051773]
	Learning Rate: 0.00517729
	LOSS [training: 0.2695920090416675 | validation: 0.22516130633275316]
	TIME [epoch: 46.3 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2521002077336372		[learning rate: 0.005159]
	Learning Rate: 0.00515898
	LOSS [training: 0.2521002077336372 | validation: 0.2290119961782821]
	TIME [epoch: 46.3 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2657295608262555		[learning rate: 0.0051407]
	Learning Rate: 0.00514074
	LOSS [training: 0.2657295608262555 | validation: 0.20683919344791057]
	TIME [epoch: 46.3 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2528517615846688		[learning rate: 0.0051226]
	Learning Rate: 0.00512256
	LOSS [training: 0.2528517615846688 | validation: 0.20602289441629637]
	TIME [epoch: 46.3 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25667372476318673		[learning rate: 0.0051044]
	Learning Rate: 0.00510445
	LOSS [training: 0.25667372476318673 | validation: 0.20392912311593864]
	TIME [epoch: 46.3 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2471644832643187		[learning rate: 0.0050864]
	Learning Rate: 0.0050864
	LOSS [training: 0.2471644832643187 | validation: 0.2110264044096625]
	TIME [epoch: 46.3 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2599041892434683		[learning rate: 0.0050684]
	Learning Rate: 0.00506841
	LOSS [training: 0.2599041892434683 | validation: 0.20998561783910455]
	TIME [epoch: 46.2 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2556144318642983		[learning rate: 0.0050505]
	Learning Rate: 0.00505049
	LOSS [training: 0.2556144318642983 | validation: 0.22655959307227871]
	TIME [epoch: 46.3 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26628296194691276		[learning rate: 0.0050326]
	Learning Rate: 0.00503263
	LOSS [training: 0.26628296194691276 | validation: 0.2210692867151145]
	TIME [epoch: 46.3 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.267472286241555		[learning rate: 0.0050148]
	Learning Rate: 0.00501483
	LOSS [training: 0.267472286241555 | validation: 0.20958558274356776]
	TIME [epoch: 46.3 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2635695110541872		[learning rate: 0.0049971]
	Learning Rate: 0.0049971
	LOSS [training: 0.2635695110541872 | validation: 0.22504318848619284]
	TIME [epoch: 46.3 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25791401629049104		[learning rate: 0.0049794]
	Learning Rate: 0.00497943
	LOSS [training: 0.25791401629049104 | validation: 0.2168744770184717]
	TIME [epoch: 46.3 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2817476582007071		[learning rate: 0.0049618]
	Learning Rate: 0.00496182
	LOSS [training: 0.2817476582007071 | validation: 0.2238436585591753]
	TIME [epoch: 46.4 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25025479039387827		[learning rate: 0.0049443]
	Learning Rate: 0.00494427
	LOSS [training: 0.25025479039387827 | validation: 0.21779101899990067]
	TIME [epoch: 46.3 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25145072529212714		[learning rate: 0.0049268]
	Learning Rate: 0.00492679
	LOSS [training: 0.25145072529212714 | validation: 0.23474875106698007]
	TIME [epoch: 46.3 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2533327088848679		[learning rate: 0.0049094]
	Learning Rate: 0.00490937
	LOSS [training: 0.2533327088848679 | validation: 0.2035991698430264]
	TIME [epoch: 46.3 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25567146060547086		[learning rate: 0.004892]
	Learning Rate: 0.00489201
	LOSS [training: 0.25567146060547086 | validation: 0.2087379976144031]
	TIME [epoch: 46.4 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26310586977767464		[learning rate: 0.0048747]
	Learning Rate: 0.00487471
	LOSS [training: 0.26310586977767464 | validation: 0.21026478732043147]
	TIME [epoch: 46.4 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25627809675874297		[learning rate: 0.0048575]
	Learning Rate: 0.00485747
	LOSS [training: 0.25627809675874297 | validation: 0.21641650166047716]
	TIME [epoch: 46.3 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25909119386123053		[learning rate: 0.0048403]
	Learning Rate: 0.00484029
	LOSS [training: 0.25909119386123053 | validation: 0.22004330303520864]
	TIME [epoch: 46.3 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2653807290443878		[learning rate: 0.0048232]
	Learning Rate: 0.00482318
	LOSS [training: 0.2653807290443878 | validation: 0.2224425612410424]
	TIME [epoch: 46.3 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2544429209354721		[learning rate: 0.0048061]
	Learning Rate: 0.00480612
	LOSS [training: 0.2544429209354721 | validation: 0.2210579767930172]
	TIME [epoch: 46.3 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2642102409703745		[learning rate: 0.0047891]
	Learning Rate: 0.00478913
	LOSS [training: 0.2642102409703745 | validation: 0.22339505279867003]
	TIME [epoch: 46.3 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24984488450376105		[learning rate: 0.0047722]
	Learning Rate: 0.00477219
	LOSS [training: 0.24984488450376105 | validation: 0.20213554658008465]
	TIME [epoch: 46.3 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2713253922239893		[learning rate: 0.0047553]
	Learning Rate: 0.00475532
	LOSS [training: 0.2713253922239893 | validation: 0.22122641598456982]
	TIME [epoch: 46.3 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25420985926876477		[learning rate: 0.0047385]
	Learning Rate: 0.0047385
	LOSS [training: 0.25420985926876477 | validation: 0.21172217245040753]
	TIME [epoch: 46.3 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2611779629500349		[learning rate: 0.0047217]
	Learning Rate: 0.00472175
	LOSS [training: 0.2611779629500349 | validation: 0.2313032082910554]
	TIME [epoch: 46.3 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26208663670171056		[learning rate: 0.004705]
	Learning Rate: 0.00470505
	LOSS [training: 0.26208663670171056 | validation: 0.2267618308098668]
	TIME [epoch: 46.3 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.251031760497429		[learning rate: 0.0046884]
	Learning Rate: 0.00468841
	LOSS [training: 0.251031760497429 | validation: 0.2259594368880053]
	TIME [epoch: 46.3 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26832581513705206		[learning rate: 0.0046718]
	Learning Rate: 0.00467183
	LOSS [training: 0.26832581513705206 | validation: 0.22242112885858392]
	TIME [epoch: 46.3 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2680143745598351		[learning rate: 0.0046553]
	Learning Rate: 0.00465531
	LOSS [training: 0.2680143745598351 | validation: 0.20830471502547745]
	TIME [epoch: 46.3 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25008019719550545		[learning rate: 0.0046388]
	Learning Rate: 0.00463885
	LOSS [training: 0.25008019719550545 | validation: 0.20928047442672013]
	TIME [epoch: 46.4 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25409483823817547		[learning rate: 0.0046224]
	Learning Rate: 0.00462245
	LOSS [training: 0.25409483823817547 | validation: 0.21568179347663735]
	TIME [epoch: 46.3 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25513282916359725		[learning rate: 0.0046061]
	Learning Rate: 0.0046061
	LOSS [training: 0.25513282916359725 | validation: 0.2216662205769792]
	TIME [epoch: 46.3 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25642756184368287		[learning rate: 0.0045898]
	Learning Rate: 0.00458981
	LOSS [training: 0.25642756184368287 | validation: 0.21829787665994133]
	TIME [epoch: 46.3 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2572022554791062		[learning rate: 0.0045736]
	Learning Rate: 0.00457358
	LOSS [training: 0.2572022554791062 | validation: 0.20382507077204642]
	TIME [epoch: 46.3 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2735681522366829		[learning rate: 0.0045574]
	Learning Rate: 0.00455741
	LOSS [training: 0.2735681522366829 | validation: 0.21322790659768348]
	TIME [epoch: 46.3 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2599010277092156		[learning rate: 0.0045413]
	Learning Rate: 0.00454129
	LOSS [training: 0.2599010277092156 | validation: 0.20398356374395812]
	TIME [epoch: 46.3 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25539411936619166		[learning rate: 0.0045252]
	Learning Rate: 0.00452523
	LOSS [training: 0.25539411936619166 | validation: 0.20847018916013563]
	TIME [epoch: 46.3 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24590254310881576		[learning rate: 0.0045092]
	Learning Rate: 0.00450923
	LOSS [training: 0.24590254310881576 | validation: 0.2151614609249713]
	TIME [epoch: 46.2 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2606392082126116		[learning rate: 0.0044933]
	Learning Rate: 0.00449329
	LOSS [training: 0.2606392082126116 | validation: 0.23145784060062274]
	TIME [epoch: 46.3 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2549368995119817		[learning rate: 0.0044774]
	Learning Rate: 0.0044774
	LOSS [training: 0.2549368995119817 | validation: 0.21990937316865558]
	TIME [epoch: 46.2 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2522164049369206		[learning rate: 0.0044616]
	Learning Rate: 0.00446156
	LOSS [training: 0.2522164049369206 | validation: 0.22210189226661942]
	TIME [epoch: 46.3 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2563608872159849		[learning rate: 0.0044458]
	Learning Rate: 0.00444579
	LOSS [training: 0.2563608872159849 | validation: 0.2156675479016481]
	TIME [epoch: 46.3 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2484736848022271		[learning rate: 0.0044301]
	Learning Rate: 0.00443007
	LOSS [training: 0.2484736848022271 | validation: 0.22382543199200758]
	TIME [epoch: 46.3 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26338182356024076		[learning rate: 0.0044144]
	Learning Rate: 0.0044144
	LOSS [training: 0.26338182356024076 | validation: 0.2124503998715949]
	TIME [epoch: 46.3 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26032242415950463		[learning rate: 0.0043988]
	Learning Rate: 0.00439879
	LOSS [training: 0.26032242415950463 | validation: 0.22172823237430794]
	TIME [epoch: 46.3 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25055098866583253		[learning rate: 0.0043832]
	Learning Rate: 0.00438324
	LOSS [training: 0.25055098866583253 | validation: 0.21514955688577383]
	TIME [epoch: 46.2 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2474122856193098		[learning rate: 0.0043677]
	Learning Rate: 0.00436774
	LOSS [training: 0.2474122856193098 | validation: 0.21161424699315873]
	TIME [epoch: 46.2 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2500938574685661		[learning rate: 0.0043523]
	Learning Rate: 0.00435229
	LOSS [training: 0.2500938574685661 | validation: 0.21031000353858306]
	TIME [epoch: 46.3 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26634812827985094		[learning rate: 0.0043369]
	Learning Rate: 0.0043369
	LOSS [training: 0.26634812827985094 | validation: 0.20279207941295402]
	TIME [epoch: 46.3 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2556292301904982		[learning rate: 0.0043216]
	Learning Rate: 0.00432156
	LOSS [training: 0.2556292301904982 | validation: 0.20388871276312348]
	TIME [epoch: 46.3 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25504949696222545		[learning rate: 0.0043063]
	Learning Rate: 0.00430628
	LOSS [training: 0.25504949696222545 | validation: 0.21612712746865523]
	TIME [epoch: 46.2 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2635531499160931		[learning rate: 0.0042911]
	Learning Rate: 0.00429106
	LOSS [training: 0.2635531499160931 | validation: 0.21834203098328828]
	TIME [epoch: 46.3 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26054743788549706		[learning rate: 0.0042759]
	Learning Rate: 0.00427588
	LOSS [training: 0.26054743788549706 | validation: 0.22231879160404922]
	TIME [epoch: 46.2 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26558322024212655		[learning rate: 0.0042608]
	Learning Rate: 0.00426076
	LOSS [training: 0.26558322024212655 | validation: 0.2155736604004735]
	TIME [epoch: 46.2 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25872202837233854		[learning rate: 0.0042457]
	Learning Rate: 0.00424569
	LOSS [training: 0.25872202837233854 | validation: 0.21130049900643008]
	TIME [epoch: 46.3 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2561643491806959		[learning rate: 0.0042307]
	Learning Rate: 0.00423068
	LOSS [training: 0.2561643491806959 | validation: 0.20874369299084763]
	TIME [epoch: 46.3 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25683591824836616		[learning rate: 0.0042157]
	Learning Rate: 0.00421572
	LOSS [training: 0.25683591824836616 | validation: 0.22539895902588386]
	TIME [epoch: 46.3 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2585989880949778		[learning rate: 0.0042008]
	Learning Rate: 0.00420081
	LOSS [training: 0.2585989880949778 | validation: 0.2113563319833418]
	TIME [epoch: 46.3 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.254184865850464		[learning rate: 0.004186]
	Learning Rate: 0.00418596
	LOSS [training: 0.254184865850464 | validation: 0.2130240948085666]
	TIME [epoch: 46.3 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2682647038580473		[learning rate: 0.0041712]
	Learning Rate: 0.00417116
	LOSS [training: 0.2682647038580473 | validation: 0.2112853571812999]
	TIME [epoch: 46.2 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2630545810857003		[learning rate: 0.0041564]
	Learning Rate: 0.00415641
	LOSS [training: 0.2630545810857003 | validation: 0.20961476496860937]
	TIME [epoch: 46.2 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2666665513923838		[learning rate: 0.0041417]
	Learning Rate: 0.00414171
	LOSS [training: 0.2666665513923838 | validation: 0.22222589328166759]
	TIME [epoch: 46.2 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24168498152221493		[learning rate: 0.0041271]
	Learning Rate: 0.00412706
	LOSS [training: 0.24168498152221493 | validation: 0.20269839469225442]
	TIME [epoch: 46.3 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2572345537940269		[learning rate: 0.0041125]
	Learning Rate: 0.00411247
	LOSS [training: 0.2572345537940269 | validation: 0.224673000869214]
	TIME [epoch: 108 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2522232590800415		[learning rate: 0.0040979]
	Learning Rate: 0.00409793
	LOSS [training: 0.2522232590800415 | validation: 0.22098282396938057]
	TIME [epoch: 96 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26249770773809694		[learning rate: 0.0040834]
	Learning Rate: 0.00408344
	LOSS [training: 0.26249770773809694 | validation: 0.2154058516285473]
	TIME [epoch: 95.9 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24223049059368282		[learning rate: 0.004069]
	Learning Rate: 0.004069
	LOSS [training: 0.24223049059368282 | validation: 0.21345512341907935]
	TIME [epoch: 95.9 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2591613134449433		[learning rate: 0.0040546]
	Learning Rate: 0.00405461
	LOSS [training: 0.2591613134449433 | validation: 0.21416375752985523]
	TIME [epoch: 95.9 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.261380329934567		[learning rate: 0.0040403]
	Learning Rate: 0.00404027
	LOSS [training: 0.261380329934567 | validation: 0.21727449212748215]
	TIME [epoch: 95.9 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25908484732655324		[learning rate: 0.004026]
	Learning Rate: 0.00402598
	LOSS [training: 0.25908484732655324 | validation: 0.210663239764075]
	TIME [epoch: 95.9 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24904643189188666		[learning rate: 0.0040117]
	Learning Rate: 0.00401175
	LOSS [training: 0.24904643189188666 | validation: 0.21599807830887263]
	TIME [epoch: 95.8 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2350276107643474		[learning rate: 0.0039976]
	Learning Rate: 0.00399756
	LOSS [training: 0.2350276107643474 | validation: 0.21371992057960404]
	TIME [epoch: 95.8 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26652925975204506		[learning rate: 0.0039834]
	Learning Rate: 0.00398342
	LOSS [training: 0.26652925975204506 | validation: 0.21558459448624118]
	TIME [epoch: 96 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2509066548947553		[learning rate: 0.0039693]
	Learning Rate: 0.00396934
	LOSS [training: 0.2509066548947553 | validation: 0.22882654336426653]
	TIME [epoch: 96 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26562775134180777		[learning rate: 0.0039553]
	Learning Rate: 0.0039553
	LOSS [training: 0.26562775134180777 | validation: 0.2092043861101404]
	TIME [epoch: 95.9 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2508091190000261		[learning rate: 0.0039413]
	Learning Rate: 0.00394131
	LOSS [training: 0.2508091190000261 | validation: 0.2233608261966415]
	TIME [epoch: 96 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24772888365583656		[learning rate: 0.0039274]
	Learning Rate: 0.00392738
	LOSS [training: 0.24772888365583656 | validation: 0.22651740235333812]
	TIME [epoch: 95.9 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24840452317746853		[learning rate: 0.0039135]
	Learning Rate: 0.00391349
	LOSS [training: 0.24840452317746853 | validation: 0.21049755660814634]
	TIME [epoch: 95.8 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2547035881331596		[learning rate: 0.0038997]
	Learning Rate: 0.00389965
	LOSS [training: 0.2547035881331596 | validation: 0.21911332374550385]
	TIME [epoch: 95.9 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2675169282117466		[learning rate: 0.0038859]
	Learning Rate: 0.00388586
	LOSS [training: 0.2675169282117466 | validation: 0.20659245978277435]
	TIME [epoch: 95.9 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24697465951279848		[learning rate: 0.0038721]
	Learning Rate: 0.00387212
	LOSS [training: 0.24697465951279848 | validation: 0.20168776093485605]
	TIME [epoch: 95.7 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25941590705342665		[learning rate: 0.0038584]
	Learning Rate: 0.00385843
	LOSS [training: 0.25941590705342665 | validation: 0.190206634977545]
	TIME [epoch: 95.9 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15b_20240719_005205/states/model_facs_v3_dec1b_2dpca_v15b_319.pth
	Model improved!!!
EPOCH 320/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2459600989750362		[learning rate: 0.0038448]
	Learning Rate: 0.00384478
	LOSS [training: 0.2459600989750362 | validation: 0.20324457489919992]
	TIME [epoch: 95.8 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2474758105910053		[learning rate: 0.0038312]
	Learning Rate: 0.00383119
	LOSS [training: 0.2474758105910053 | validation: 0.20933673089699742]
	TIME [epoch: 96 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2546957536397631		[learning rate: 0.0038176]
	Learning Rate: 0.00381764
	LOSS [training: 0.2546957536397631 | validation: 0.21093194268619947]
	TIME [epoch: 95.9 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24638079562897344		[learning rate: 0.0038041]
	Learning Rate: 0.00380414
	LOSS [training: 0.24638079562897344 | validation: 0.21397882514384436]
	TIME [epoch: 96 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2603641843858038		[learning rate: 0.0037907]
	Learning Rate: 0.00379069
	LOSS [training: 0.2603641843858038 | validation: 0.2210665643578656]
	TIME [epoch: 95.9 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2500203457207229		[learning rate: 0.0037773]
	Learning Rate: 0.00377728
	LOSS [training: 0.2500203457207229 | validation: 0.19748522369577076]
	TIME [epoch: 95.9 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25924308393620316		[learning rate: 0.0037639]
	Learning Rate: 0.00376393
	LOSS [training: 0.25924308393620316 | validation: 0.23442964002583855]
	TIME [epoch: 95.7 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25830669183192356		[learning rate: 0.0037506]
	Learning Rate: 0.00375062
	LOSS [training: 0.25830669183192356 | validation: 0.2043505786114835]
	TIME [epoch: 95.9 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2537367696726011		[learning rate: 0.0037374]
	Learning Rate: 0.00373735
	LOSS [training: 0.2537367696726011 | validation: 0.21891282053625122]
	TIME [epoch: 95.9 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2576187603303712		[learning rate: 0.0037241]
	Learning Rate: 0.00372414
	LOSS [training: 0.2576187603303712 | validation: 0.20555753519890563]
	TIME [epoch: 95.9 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24668736243244138		[learning rate: 0.003711]
	Learning Rate: 0.00371097
	LOSS [training: 0.24668736243244138 | validation: 0.20833748110949216]
	TIME [epoch: 95.9 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25018686874652357		[learning rate: 0.0036978]
	Learning Rate: 0.00369785
	LOSS [training: 0.25018686874652357 | validation: 0.19975673453049908]
	TIME [epoch: 95.9 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24819434510979368		[learning rate: 0.0036848]
	Learning Rate: 0.00368477
	LOSS [training: 0.24819434510979368 | validation: 0.19229972873901982]
	TIME [epoch: 95.9 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25375662349198214		[learning rate: 0.0036717]
	Learning Rate: 0.00367174
	LOSS [training: 0.25375662349198214 | validation: 0.21869650503426724]
	TIME [epoch: 95.9 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27238829833851275		[learning rate: 0.0036588]
	Learning Rate: 0.00365875
	LOSS [training: 0.27238829833851275 | validation: 0.2088235273945819]
	TIME [epoch: 95.7 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2605309210732729		[learning rate: 0.0036458]
	Learning Rate: 0.00364582
	LOSS [training: 0.2605309210732729 | validation: 0.21676465392968422]
	TIME [epoch: 95.9 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.256392405325709		[learning rate: 0.0036329]
	Learning Rate: 0.00363292
	LOSS [training: 0.256392405325709 | validation: 0.21013575147652713]
	TIME [epoch: 95.9 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24981324693225335		[learning rate: 0.0036201]
	Learning Rate: 0.00362008
	LOSS [training: 0.24981324693225335 | validation: 0.21609157932700923]
	TIME [epoch: 95.9 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25108747166617945		[learning rate: 0.0036073]
	Learning Rate: 0.00360728
	LOSS [training: 0.25108747166617945 | validation: 0.21152175155944825]
	TIME [epoch: 95.9 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2514261767313786		[learning rate: 0.0035945]
	Learning Rate: 0.00359452
	LOSS [training: 0.2514261767313786 | validation: 0.21781174512271523]
	TIME [epoch: 95.9 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24858494811375284		[learning rate: 0.0035818]
	Learning Rate: 0.00358181
	LOSS [training: 0.24858494811375284 | validation: 0.21769981151507842]
	TIME [epoch: 95.9 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2499703124359717		[learning rate: 0.0035691]
	Learning Rate: 0.00356914
	LOSS [training: 0.2499703124359717 | validation: 0.2059875298703732]
	TIME [epoch: 95.9 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25202332529954014		[learning rate: 0.0035565]
	Learning Rate: 0.00355652
	LOSS [training: 0.25202332529954014 | validation: 0.21564330685668268]
	TIME [epoch: 95.9 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2503436597734865		[learning rate: 0.0035439]
	Learning Rate: 0.00354395
	LOSS [training: 0.2503436597734865 | validation: 0.21222167879045858]
	TIME [epoch: 95.9 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24324475343345578		[learning rate: 0.0035314]
	Learning Rate: 0.00353141
	LOSS [training: 0.24324475343345578 | validation: 0.20926506668194556]
	TIME [epoch: 95.8 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26520438403012736		[learning rate: 0.0035189]
	Learning Rate: 0.00351893
	LOSS [training: 0.26520438403012736 | validation: 0.2065823410232585]
	TIME [epoch: 95.9 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24248730340201283		[learning rate: 0.0035065]
	Learning Rate: 0.00350648
	LOSS [training: 0.24248730340201283 | validation: 0.21732842329642538]
	TIME [epoch: 95.9 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24882588163997063		[learning rate: 0.0034941]
	Learning Rate: 0.00349408
	LOSS [training: 0.24882588163997063 | validation: 0.21430402897457163]
	TIME [epoch: 96 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2743334551994532		[learning rate: 0.0034817]
	Learning Rate: 0.00348173
	LOSS [training: 0.2743334551994532 | validation: 0.20398134785872246]
	TIME [epoch: 95.9 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25289115979541377		[learning rate: 0.0034694]
	Learning Rate: 0.00346942
	LOSS [training: 0.25289115979541377 | validation: 0.2088574592055481]
	TIME [epoch: 95.9 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24741613550700114		[learning rate: 0.0034571]
	Learning Rate: 0.00345715
	LOSS [training: 0.24741613550700114 | validation: 0.20946110021522474]
	TIME [epoch: 95.9 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24613194165843452		[learning rate: 0.0034449]
	Learning Rate: 0.00344492
	LOSS [training: 0.24613194165843452 | validation: 0.2089708269287228]
	TIME [epoch: 96 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24978462511214086		[learning rate: 0.0034327]
	Learning Rate: 0.00343274
	LOSS [training: 0.24978462511214086 | validation: 0.2057595242622161]
	TIME [epoch: 95.9 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23801904864352982		[learning rate: 0.0034206]
	Learning Rate: 0.0034206
	LOSS [training: 0.23801904864352982 | validation: 0.2093475095940617]
	TIME [epoch: 95.9 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2632486539359106		[learning rate: 0.0034085]
	Learning Rate: 0.00340851
	LOSS [training: 0.2632486539359106 | validation: 0.20529391814252612]
	TIME [epoch: 95.9 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2648699927256634		[learning rate: 0.0033965]
	Learning Rate: 0.00339645
	LOSS [training: 0.2648699927256634 | validation: 0.20829239521087736]
	TIME [epoch: 95.9 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2604209049794692		[learning rate: 0.0033844]
	Learning Rate: 0.00338444
	LOSS [training: 0.2604209049794692 | validation: 0.21497975380517736]
	TIME [epoch: 95.9 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2504621542257029		[learning rate: 0.0033725]
	Learning Rate: 0.00337247
	LOSS [training: 0.2504621542257029 | validation: 0.20529004227801764]
	TIME [epoch: 95.9 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2587522977809387		[learning rate: 0.0033605]
	Learning Rate: 0.00336055
	LOSS [training: 0.2587522977809387 | validation: 0.2121629278675182]
	TIME [epoch: 95.9 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2689068112500198		[learning rate: 0.0033487]
	Learning Rate: 0.00334867
	LOSS [training: 0.2689068112500198 | validation: 0.21647960123307394]
	TIME [epoch: 96 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24934502052772353		[learning rate: 0.0033368]
	Learning Rate: 0.00333682
	LOSS [training: 0.24934502052772353 | validation: 0.21566584894110014]
	TIME [epoch: 95.9 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25008022640745803		[learning rate: 0.003325]
	Learning Rate: 0.00332502
	LOSS [training: 0.25008022640745803 | validation: 0.20877472412155457]
	TIME [epoch: 95.8 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24213111094958673		[learning rate: 0.0033133]
	Learning Rate: 0.00331327
	LOSS [training: 0.24213111094958673 | validation: 0.2171453118455501]
	TIME [epoch: 95.9 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.255828319316196		[learning rate: 0.0033016]
	Learning Rate: 0.00330155
	LOSS [training: 0.255828319316196 | validation: 0.21076120746416374]
	TIME [epoch: 95.9 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25055606150840676		[learning rate: 0.0032899]
	Learning Rate: 0.00328988
	LOSS [training: 0.25055606150840676 | validation: 0.2177444619319649]
	TIME [epoch: 96 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24866821303680373		[learning rate: 0.0032782]
	Learning Rate: 0.00327824
	LOSS [training: 0.24866821303680373 | validation: 0.21722723699449328]
	TIME [epoch: 95.9 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25278644163407277		[learning rate: 0.0032666]
	Learning Rate: 0.00326665
	LOSS [training: 0.25278644163407277 | validation: 0.21319874045121642]
	TIME [epoch: 95.9 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2493282596481945		[learning rate: 0.0032551]
	Learning Rate: 0.0032551
	LOSS [training: 0.2493282596481945 | validation: 0.2100488552951208]
	TIME [epoch: 95.9 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24469830734093498		[learning rate: 0.0032436]
	Learning Rate: 0.00324359
	LOSS [training: 0.24469830734093498 | validation: 0.2168291787539268]
	TIME [epoch: 95.9 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24475662658345831		[learning rate: 0.0032321]
	Learning Rate: 0.00323212
	LOSS [training: 0.24475662658345831 | validation: 0.22061288635964238]
	TIME [epoch: 96 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2528752608626197		[learning rate: 0.0032207]
	Learning Rate: 0.00322069
	LOSS [training: 0.2528752608626197 | validation: 0.21601018906822328]
	TIME [epoch: 95.9 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24372917912749936		[learning rate: 0.0032093]
	Learning Rate: 0.0032093
	LOSS [training: 0.24372917912749936 | validation: 0.21325536061367673]
	TIME [epoch: 96 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2434174995228253		[learning rate: 0.003198]
	Learning Rate: 0.00319795
	LOSS [training: 0.2434174995228253 | validation: 0.20312164278012865]
	TIME [epoch: 95.9 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26271856545610084		[learning rate: 0.0031866]
	Learning Rate: 0.00318664
	LOSS [training: 0.26271856545610084 | validation: 0.20852581832092873]
	TIME [epoch: 95.9 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2467254320069089		[learning rate: 0.0031754]
	Learning Rate: 0.00317537
	LOSS [training: 0.2467254320069089 | validation: 0.2167289910320484]
	TIME [epoch: 95.9 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2506311621018024		[learning rate: 0.0031641]
	Learning Rate: 0.00316415
	LOSS [training: 0.2506311621018024 | validation: 0.20842245008653992]
	TIME [epoch: 95.9 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.261068124025061		[learning rate: 0.003153]
	Learning Rate: 0.00315296
	LOSS [training: 0.261068124025061 | validation: 0.2109921294781419]
	TIME [epoch: 95.9 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2682987439081495		[learning rate: 0.0031418]
	Learning Rate: 0.00314181
	LOSS [training: 0.2682987439081495 | validation: 0.20547436649146805]
	TIME [epoch: 95.9 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24414957264392237		[learning rate: 0.0031307]
	Learning Rate: 0.0031307
	LOSS [training: 0.24414957264392237 | validation: 0.20758487903531947]
	TIME [epoch: 95.9 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2497262347593199		[learning rate: 0.0031196]
	Learning Rate: 0.00311963
	LOSS [training: 0.2497262347593199 | validation: 0.2166720808533204]
	TIME [epoch: 95.9 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2560328803985847		[learning rate: 0.0031086]
	Learning Rate: 0.00310859
	LOSS [training: 0.2560328803985847 | validation: 0.19860095305260203]
	TIME [epoch: 96 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2358776003214936		[learning rate: 0.0030976]
	Learning Rate: 0.0030976
	LOSS [training: 0.2358776003214936 | validation: 0.20262284497834954]
	TIME [epoch: 96 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2552958441343824		[learning rate: 0.0030866]
	Learning Rate: 0.00308665
	LOSS [training: 0.2552958441343824 | validation: 0.20414312884546745]
	TIME [epoch: 95.9 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2548038741805207		[learning rate: 0.0030757]
	Learning Rate: 0.00307573
	LOSS [training: 0.2548038741805207 | validation: 0.20663620578708963]
	TIME [epoch: 95.9 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24595773413084285		[learning rate: 0.0030649]
	Learning Rate: 0.00306486
	LOSS [training: 0.24595773413084285 | validation: 0.2049918251114431]
	TIME [epoch: 96 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25659513177586657		[learning rate: 0.003054]
	Learning Rate: 0.00305402
	LOSS [training: 0.25659513177586657 | validation: 0.21420502621152693]
	TIME [epoch: 95.9 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2539863650780378		[learning rate: 0.0030432]
	Learning Rate: 0.00304322
	LOSS [training: 0.2539863650780378 | validation: 0.2104826928025274]
	TIME [epoch: 95.9 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2512934516694696		[learning rate: 0.0030325]
	Learning Rate: 0.00303246
	LOSS [training: 0.2512934516694696 | validation: 0.20972578775920053]
	TIME [epoch: 95.9 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24560615451085424		[learning rate: 0.0030217]
	Learning Rate: 0.00302174
	LOSS [training: 0.24560615451085424 | validation: 0.21306416944355214]
	TIME [epoch: 95.9 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24593684044961314		[learning rate: 0.003011]
	Learning Rate: 0.00301105
	LOSS [training: 0.24593684044961314 | validation: 0.21508919954683278]
	TIME [epoch: 95.9 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25448096683801785		[learning rate: 0.0030004]
	Learning Rate: 0.0030004
	LOSS [training: 0.25448096683801785 | validation: 0.21905732320560048]
	TIME [epoch: 95.8 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26108413132220326		[learning rate: 0.0029898]
	Learning Rate: 0.00298979
	LOSS [training: 0.26108413132220326 | validation: 0.22204488117611315]
	TIME [epoch: 95.9 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24426217140536377		[learning rate: 0.0029792]
	Learning Rate: 0.00297922
	LOSS [training: 0.24426217140536377 | validation: 0.21303803787114464]
	TIME [epoch: 95.9 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24884229122589419		[learning rate: 0.0029687]
	Learning Rate: 0.00296869
	LOSS [training: 0.24884229122589419 | validation: 0.21388177474576783]
	TIME [epoch: 95.9 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26049311393349656		[learning rate: 0.0029582]
	Learning Rate: 0.00295819
	LOSS [training: 0.26049311393349656 | validation: 0.20800368991841287]
	TIME [epoch: 95.8 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25992457250648443		[learning rate: 0.0029477]
	Learning Rate: 0.00294773
	LOSS [training: 0.25992457250648443 | validation: 0.22106081366952735]
	TIME [epoch: 95.9 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2497184374863616		[learning rate: 0.0029373]
	Learning Rate: 0.0029373
	LOSS [training: 0.2497184374863616 | validation: 0.21391548552322265]
	TIME [epoch: 95.9 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24454466662449773		[learning rate: 0.0029269]
	Learning Rate: 0.00292692
	LOSS [training: 0.24454466662449773 | validation: 0.21699312899593987]
	TIME [epoch: 95.9 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24995850003746634		[learning rate: 0.0029166]
	Learning Rate: 0.00291657
	LOSS [training: 0.24995850003746634 | validation: 0.21492526336018228]
	TIME [epoch: 95.9 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2521365196758243		[learning rate: 0.0029063]
	Learning Rate: 0.00290625
	LOSS [training: 0.2521365196758243 | validation: 0.22165184170939362]
	TIME [epoch: 95.9 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24956145580213554		[learning rate: 0.002896]
	Learning Rate: 0.00289598
	LOSS [training: 0.24956145580213554 | validation: 0.21097126837913205]
	TIME [epoch: 95.9 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2520203489131377		[learning rate: 0.0028857]
	Learning Rate: 0.00288573
	LOSS [training: 0.2520203489131377 | validation: 0.19975999537930594]
	TIME [epoch: 96 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23699693757833387		[learning rate: 0.0028755]
	Learning Rate: 0.00287553
	LOSS [training: 0.23699693757833387 | validation: 0.2173598571740835]
	TIME [epoch: 95.9 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24893531688740286		[learning rate: 0.0028654]
	Learning Rate: 0.00286536
	LOSS [training: 0.24893531688740286 | validation: 0.20167150888400628]
	TIME [epoch: 96 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25313920273364604		[learning rate: 0.0028552]
	Learning Rate: 0.00285523
	LOSS [training: 0.25313920273364604 | validation: 0.2118048511700744]
	TIME [epoch: 96 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2545847275415131		[learning rate: 0.0028451]
	Learning Rate: 0.00284513
	LOSS [training: 0.2545847275415131 | validation: 0.21217583408710244]
	TIME [epoch: 95.9 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2405221329215066		[learning rate: 0.0028351]
	Learning Rate: 0.00283507
	LOSS [training: 0.2405221329215066 | validation: 0.20619041676013922]
	TIME [epoch: 95.9 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2445359325727686		[learning rate: 0.002825]
	Learning Rate: 0.00282505
	LOSS [training: 0.2445359325727686 | validation: 0.196213989316756]
	TIME [epoch: 95.8 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2567053676753532		[learning rate: 0.0028151]
	Learning Rate: 0.00281506
	LOSS [training: 0.2567053676753532 | validation: 0.21611242032357394]
	TIME [epoch: 95.8 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25654051876987344		[learning rate: 0.0028051]
	Learning Rate: 0.0028051
	LOSS [training: 0.25654051876987344 | validation: 0.21325267278849963]
	TIME [epoch: 95.8 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2592891865726425		[learning rate: 0.0027952]
	Learning Rate: 0.00279518
	LOSS [training: 0.2592891865726425 | validation: 0.20894367599153368]
	TIME [epoch: 95.8 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2530730636743462		[learning rate: 0.0027853]
	Learning Rate: 0.0027853
	LOSS [training: 0.2530730636743462 | validation: 0.2149942390948763]
	TIME [epoch: 95.9 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2520237355343239		[learning rate: 0.0027754]
	Learning Rate: 0.00277545
	LOSS [training: 0.2520237355343239 | validation: 0.20845434115689132]
	TIME [epoch: 95.8 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23968612300667588		[learning rate: 0.0027656]
	Learning Rate: 0.00276564
	LOSS [training: 0.23968612300667588 | validation: 0.21297209684516566]
	TIME [epoch: 95.9 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25245756984045664		[learning rate: 0.0027559]
	Learning Rate: 0.00275586
	LOSS [training: 0.25245756984045664 | validation: 0.20759662026381953]
	TIME [epoch: 95.9 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2559183976251251		[learning rate: 0.0027461]
	Learning Rate: 0.00274611
	LOSS [training: 0.2559183976251251 | validation: 0.2246152292776987]
	TIME [epoch: 95.9 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24639153722120574		[learning rate: 0.0027364]
	Learning Rate: 0.0027364
	LOSS [training: 0.24639153722120574 | validation: 0.21299676133249887]
	TIME [epoch: 95.9 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2562599305787547		[learning rate: 0.0027267]
	Learning Rate: 0.00272672
	LOSS [training: 0.2562599305787547 | validation: 0.20651405525063388]
	TIME [epoch: 95.9 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25281370364373706		[learning rate: 0.0027171]
	Learning Rate: 0.00271708
	LOSS [training: 0.25281370364373706 | validation: 0.22057547517182394]
	TIME [epoch: 95.9 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24740951275258782		[learning rate: 0.0027075]
	Learning Rate: 0.00270747
	LOSS [training: 0.24740951275258782 | validation: 0.2060986434000208]
	TIME [epoch: 95.8 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.263186240382438		[learning rate: 0.0026979]
	Learning Rate: 0.0026979
	LOSS [training: 0.263186240382438 | validation: 0.21900569190620364]
	TIME [epoch: 95.8 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2525248952532902		[learning rate: 0.0026884]
	Learning Rate: 0.00268836
	LOSS [training: 0.2525248952532902 | validation: 0.20714860935768717]
	TIME [epoch: 96 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.257726500586916		[learning rate: 0.0026789]
	Learning Rate: 0.00267885
	LOSS [training: 0.257726500586916 | validation: 0.21800861831727153]
	TIME [epoch: 95.7 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2559700647090379		[learning rate: 0.0026694]
	Learning Rate: 0.00266938
	LOSS [training: 0.2559700647090379 | validation: 0.19053346525004583]
	TIME [epoch: 95.9 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2530569881622491		[learning rate: 0.0026599]
	Learning Rate: 0.00265994
	LOSS [training: 0.2530569881622491 | validation: 0.21291304001739825]
	TIME [epoch: 95.9 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24018030603658946		[learning rate: 0.0026505]
	Learning Rate: 0.00265053
	LOSS [training: 0.24018030603658946 | validation: 0.20732852927121304]
	TIME [epoch: 95.9 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24097720597105776		[learning rate: 0.0026412]
	Learning Rate: 0.00264116
	LOSS [training: 0.24097720597105776 | validation: 0.2080835274932582]
	TIME [epoch: 95.8 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23860205954115243		[learning rate: 0.0026318]
	Learning Rate: 0.00263182
	LOSS [training: 0.23860205954115243 | validation: 0.20775558503956204]
	TIME [epoch: 95.8 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24598503173760275		[learning rate: 0.0026225]
	Learning Rate: 0.00262251
	LOSS [training: 0.24598503173760275 | validation: 0.203446909500291]
	TIME [epoch: 96 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2641792612467285		[learning rate: 0.0026132]
	Learning Rate: 0.00261324
	LOSS [training: 0.2641792612467285 | validation: 0.2136818273199715]
	TIME [epoch: 95.8 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24392700980933943		[learning rate: 0.002604]
	Learning Rate: 0.002604
	LOSS [training: 0.24392700980933943 | validation: 0.19944614411405923]
	TIME [epoch: 95.7 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25051170219892		[learning rate: 0.0025948]
	Learning Rate: 0.00259479
	LOSS [training: 0.25051170219892 | validation: 0.20609423430629853]
	TIME [epoch: 95.8 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24808322633717259		[learning rate: 0.0025856]
	Learning Rate: 0.00258562
	LOSS [training: 0.24808322633717259 | validation: 0.24040837830687084]
	TIME [epoch: 95.8 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2520799229656071		[learning rate: 0.0025765]
	Learning Rate: 0.00257647
	LOSS [training: 0.2520799229656071 | validation: 0.2047817724486601]
	TIME [epoch: 95.8 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2648168031654787		[learning rate: 0.0025674]
	Learning Rate: 0.00256736
	LOSS [training: 0.2648168031654787 | validation: 0.2056839114088838]
	TIME [epoch: 95.7 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24081960242327968		[learning rate: 0.0025583]
	Learning Rate: 0.00255828
	LOSS [training: 0.24081960242327968 | validation: 0.2013860290695894]
	TIME [epoch: 95.8 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24266603633560513		[learning rate: 0.0025492]
	Learning Rate: 0.00254924
	LOSS [training: 0.24266603633560513 | validation: 0.21427169483082179]
	TIME [epoch: 95.8 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2522201402951117		[learning rate: 0.0025402]
	Learning Rate: 0.00254022
	LOSS [training: 0.2522201402951117 | validation: 0.20695018987563368]
	TIME [epoch: 95.8 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2494324271028883		[learning rate: 0.0025312]
	Learning Rate: 0.00253124
	LOSS [training: 0.2494324271028883 | validation: 0.21285823826758254]
	TIME [epoch: 95.7 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24006251606190468		[learning rate: 0.0025223]
	Learning Rate: 0.00252229
	LOSS [training: 0.24006251606190468 | validation: 0.21036324730670186]
	TIME [epoch: 95.8 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24525359669553637		[learning rate: 0.0025134]
	Learning Rate: 0.00251337
	LOSS [training: 0.24525359669553637 | validation: 0.21317796830358682]
	TIME [epoch: 95.8 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2480999897379218		[learning rate: 0.0025045]
	Learning Rate: 0.00250448
	LOSS [training: 0.2480999897379218 | validation: 0.20648888903585094]
	TIME [epoch: 95.8 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26220072650963916		[learning rate: 0.0024956]
	Learning Rate: 0.00249563
	LOSS [training: 0.26220072650963916 | validation: 0.21391701199270963]
	TIME [epoch: 95.8 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2541026701054163		[learning rate: 0.0024868]
	Learning Rate: 0.0024868
	LOSS [training: 0.2541026701054163 | validation: 0.20220289837919517]
	TIME [epoch: 95.8 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2535951660439115		[learning rate: 0.002478]
	Learning Rate: 0.00247801
	LOSS [training: 0.2535951660439115 | validation: 0.22189607148147586]
	TIME [epoch: 95.8 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24321769724939876		[learning rate: 0.0024692]
	Learning Rate: 0.00246924
	LOSS [training: 0.24321769724939876 | validation: 0.2123205722038028]
	TIME [epoch: 95.8 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2444818518592696		[learning rate: 0.0024605]
	Learning Rate: 0.00246051
	LOSS [training: 0.2444818518592696 | validation: 0.2013244304995574]
	TIME [epoch: 95.8 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.256090494493284		[learning rate: 0.0024518]
	Learning Rate: 0.00245181
	LOSS [training: 0.256090494493284 | validation: 0.2057689687137742]
	TIME [epoch: 95.8 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2564393646441938		[learning rate: 0.0024431]
	Learning Rate: 0.00244314
	LOSS [training: 0.2564393646441938 | validation: 0.21896165645942026]
	TIME [epoch: 95.7 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.253126002276215		[learning rate: 0.0024345]
	Learning Rate: 0.0024345
	LOSS [training: 0.253126002276215 | validation: 0.2039106544069717]
	TIME [epoch: 95.8 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24478937019041702		[learning rate: 0.0024259]
	Learning Rate: 0.00242589
	LOSS [training: 0.24478937019041702 | validation: 0.21486630318784697]
	TIME [epoch: 95.8 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2461748514967498		[learning rate: 0.0024173]
	Learning Rate: 0.00241732
	LOSS [training: 0.2461748514967498 | validation: 0.21563215971253807]
	TIME [epoch: 95.8 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26069856151388743		[learning rate: 0.0024088]
	Learning Rate: 0.00240877
	LOSS [training: 0.26069856151388743 | validation: 0.2052263905531473]
	TIME [epoch: 95.8 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24620594083035743		[learning rate: 0.0024002]
	Learning Rate: 0.00240025
	LOSS [training: 0.24620594083035743 | validation: 0.21676099915546015]
	TIME [epoch: 95.8 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24314918034666208		[learning rate: 0.0023918]
	Learning Rate: 0.00239176
	LOSS [training: 0.24314918034666208 | validation: 0.2132543062566839]
	TIME [epoch: 95.8 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2509007397291728		[learning rate: 0.0023833]
	Learning Rate: 0.0023833
	LOSS [training: 0.2509007397291728 | validation: 0.21178701826168678]
	TIME [epoch: 95.8 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2494307893403912		[learning rate: 0.0023749]
	Learning Rate: 0.00237488
	LOSS [training: 0.2494307893403912 | validation: 0.2150988296237363]
	TIME [epoch: 95.8 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24286622380606968		[learning rate: 0.0023665]
	Learning Rate: 0.00236648
	LOSS [training: 0.24286622380606968 | validation: 0.21331327800406158]
	TIME [epoch: 95.8 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2481400699082282		[learning rate: 0.0023581]
	Learning Rate: 0.00235811
	LOSS [training: 0.2481400699082282 | validation: 0.2070472105847072]
	TIME [epoch: 95.7 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24749720520598062		[learning rate: 0.0023498]
	Learning Rate: 0.00234977
	LOSS [training: 0.24749720520598062 | validation: 0.23787296948596737]
	TIME [epoch: 95.8 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25059262714993025		[learning rate: 0.0023415]
	Learning Rate: 0.00234146
	LOSS [training: 0.25059262714993025 | validation: 0.21574885351469825]
	TIME [epoch: 95.8 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2536620838100772		[learning rate: 0.0023332]
	Learning Rate: 0.00233318
	LOSS [training: 0.2536620838100772 | validation: 0.22076142408643834]
	TIME [epoch: 95.8 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23797835314477392		[learning rate: 0.0023249]
	Learning Rate: 0.00232493
	LOSS [training: 0.23797835314477392 | validation: 0.21519277428032746]
	TIME [epoch: 95.7 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24369872594638706		[learning rate: 0.0023167]
	Learning Rate: 0.00231671
	LOSS [training: 0.24369872594638706 | validation: 0.19708888819716633]
	TIME [epoch: 95.8 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2602977022918203		[learning rate: 0.0023085]
	Learning Rate: 0.00230852
	LOSS [training: 0.2602977022918203 | validation: 0.2062175196484664]
	TIME [epoch: 95.8 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24542414345146715		[learning rate: 0.0023004]
	Learning Rate: 0.00230035
	LOSS [training: 0.24542414345146715 | validation: 0.22414840890219753]
	TIME [epoch: 95.8 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25071519409223436		[learning rate: 0.0022922]
	Learning Rate: 0.00229222
	LOSS [training: 0.25071519409223436 | validation: 0.21095308516285027]
	TIME [epoch: 95.8 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2535407476031773		[learning rate: 0.0022841]
	Learning Rate: 0.00228411
	LOSS [training: 0.2535407476031773 | validation: 0.21327199626643017]
	TIME [epoch: 95.8 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23580407193002537		[learning rate: 0.002276]
	Learning Rate: 0.00227604
	LOSS [training: 0.23580407193002537 | validation: 0.20043932784147556]
	TIME [epoch: 95.8 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23397354399285442		[learning rate: 0.002268]
	Learning Rate: 0.00226799
	LOSS [training: 0.23397354399285442 | validation: 0.20816732130251778]
	TIME [epoch: 95.8 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2464143960982711		[learning rate: 0.00226]
	Learning Rate: 0.00225997
	LOSS [training: 0.2464143960982711 | validation: 0.20733309664088648]
	TIME [epoch: 95.8 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25609771008166754		[learning rate: 0.002252]
	Learning Rate: 0.00225198
	LOSS [training: 0.25609771008166754 | validation: 0.20017350553600394]
	TIME [epoch: 95.8 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24383914890310002		[learning rate: 0.002244]
	Learning Rate: 0.00224401
	LOSS [training: 0.24383914890310002 | validation: 0.2209839368530476]
	TIME [epoch: 95.8 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2492233480366324		[learning rate: 0.0022361]
	Learning Rate: 0.00223608
	LOSS [training: 0.2492233480366324 | validation: 0.2054019585536178]
	TIME [epoch: 95.7 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2563975238316143		[learning rate: 0.0022282]
	Learning Rate: 0.00222817
	LOSS [training: 0.2563975238316143 | validation: 0.20947745741313578]
	TIME [epoch: 95.7 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23943304930104278		[learning rate: 0.0022203]
	Learning Rate: 0.00222029
	LOSS [training: 0.23943304930104278 | validation: 0.2004204367471531]
	TIME [epoch: 95.8 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24264028215911093		[learning rate: 0.0022124]
	Learning Rate: 0.00221244
	LOSS [training: 0.24264028215911093 | validation: 0.19540820762510766]
	TIME [epoch: 95.8 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25396922797827687		[learning rate: 0.0022046]
	Learning Rate: 0.00220462
	LOSS [training: 0.25396922797827687 | validation: 0.21552394954855028]
	TIME [epoch: 95.8 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2503285246379118		[learning rate: 0.0021968]
	Learning Rate: 0.00219682
	LOSS [training: 0.2503285246379118 | validation: 0.2363554637700931]
	TIME [epoch: 95.8 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24355988162168937		[learning rate: 0.0021891]
	Learning Rate: 0.00218905
	LOSS [training: 0.24355988162168937 | validation: 0.20298338688615392]
	TIME [epoch: 95.8 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24193950160137567		[learning rate: 0.0021813]
	Learning Rate: 0.00218131
	LOSS [training: 0.24193950160137567 | validation: 0.22037715609647957]
	TIME [epoch: 95.8 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2502436884382068		[learning rate: 0.0021736]
	Learning Rate: 0.0021736
	LOSS [training: 0.2502436884382068 | validation: 0.20549604743908517]
	TIME [epoch: 95.8 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24603652970676862		[learning rate: 0.0021659]
	Learning Rate: 0.00216591
	LOSS [training: 0.24603652970676862 | validation: 0.21479374801711767]
	TIME [epoch: 95.8 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2618378655898482		[learning rate: 0.0021583]
	Learning Rate: 0.00215825
	LOSS [training: 0.2618378655898482 | validation: 0.22320639224786287]
	TIME [epoch: 95.8 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2471218088426469		[learning rate: 0.0021506]
	Learning Rate: 0.00215062
	LOSS [training: 0.2471218088426469 | validation: 0.20451094204518278]
	TIME [epoch: 95.8 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24331103036277624		[learning rate: 0.002143]
	Learning Rate: 0.00214302
	LOSS [training: 0.24331103036277624 | validation: 0.19855120375963267]
	TIME [epoch: 95.8 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24429903938533562		[learning rate: 0.0021354]
	Learning Rate: 0.00213544
	LOSS [training: 0.24429903938533562 | validation: 0.22065672112232484]
	TIME [epoch: 95.8 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24035571041857942		[learning rate: 0.0021279]
	Learning Rate: 0.00212789
	LOSS [training: 0.24035571041857942 | validation: 0.22071926695819988]
	TIME [epoch: 95.8 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24529428743484424		[learning rate: 0.0021204]
	Learning Rate: 0.00212036
	LOSS [training: 0.24529428743484424 | validation: 0.2253639848522445]
	TIME [epoch: 95.8 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25041842852480006		[learning rate: 0.0021129]
	Learning Rate: 0.00211287
	LOSS [training: 0.25041842852480006 | validation: 0.22120686301379128]
	TIME [epoch: 95.8 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24468330874633573		[learning rate: 0.0021054]
	Learning Rate: 0.00210539
	LOSS [training: 0.24468330874633573 | validation: 0.20511995729553756]
	TIME [epoch: 95.8 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25397395200770934		[learning rate: 0.0020979]
	Learning Rate: 0.00209795
	LOSS [training: 0.25397395200770934 | validation: 0.21311110713784745]
	TIME [epoch: 95.8 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26021054320070575		[learning rate: 0.0020905]
	Learning Rate: 0.00209053
	LOSS [training: 0.26021054320070575 | validation: 0.22222501056252586]
	TIME [epoch: 95.8 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24151164501563696		[learning rate: 0.0020831]
	Learning Rate: 0.00208314
	LOSS [training: 0.24151164501563696 | validation: 0.20837251300116938]
	TIME [epoch: 96 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24913909832955405		[learning rate: 0.0020758]
	Learning Rate: 0.00207577
	LOSS [training: 0.24913909832955405 | validation: 0.21064434487757447]
	TIME [epoch: 95.8 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25378294894496894		[learning rate: 0.0020684]
	Learning Rate: 0.00206843
	LOSS [training: 0.25378294894496894 | validation: 0.21804115533479015]
	TIME [epoch: 95.7 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2500086546330866		[learning rate: 0.0020611]
	Learning Rate: 0.00206112
	LOSS [training: 0.2500086546330866 | validation: 0.2057157525769857]
	TIME [epoch: 95.8 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23856655393304307		[learning rate: 0.0020538]
	Learning Rate: 0.00205383
	LOSS [training: 0.23856655393304307 | validation: 0.2037990351675973]
	TIME [epoch: 95.7 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2607122223123225		[learning rate: 0.0020466]
	Learning Rate: 0.00204657
	LOSS [training: 0.2607122223123225 | validation: 0.20974729169803225]
	TIME [epoch: 95.7 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24841960367255578		[learning rate: 0.0020393]
	Learning Rate: 0.00203933
	LOSS [training: 0.24841960367255578 | validation: 0.21653892051414533]
	TIME [epoch: 95.8 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2500178450170812		[learning rate: 0.0020321]
	Learning Rate: 0.00203212
	LOSS [training: 0.2500178450170812 | validation: 0.21474931564024455]
	TIME [epoch: 95.8 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2482531911618451		[learning rate: 0.0020249]
	Learning Rate: 0.00202493
	LOSS [training: 0.2482531911618451 | validation: 0.20384018456350414]
	TIME [epoch: 95.8 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2387030167812398		[learning rate: 0.0020178]
	Learning Rate: 0.00201777
	LOSS [training: 0.2387030167812398 | validation: 0.21329294632108672]
	TIME [epoch: 95.8 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24820403471904715		[learning rate: 0.0020106]
	Learning Rate: 0.00201064
	LOSS [training: 0.24820403471904715 | validation: 0.2067686390234381]
	TIME [epoch: 95.8 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2490157620676262		[learning rate: 0.0020035]
	Learning Rate: 0.00200353
	LOSS [training: 0.2490157620676262 | validation: 0.21115942853339703]
	TIME [epoch: 95.7 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24030843574644115		[learning rate: 0.0019964]
	Learning Rate: 0.00199644
	LOSS [training: 0.24030843574644115 | validation: 0.2172599243147686]
	TIME [epoch: 95.8 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26047567138533		[learning rate: 0.0019894]
	Learning Rate: 0.00198938
	LOSS [training: 0.26047567138533 | validation: 0.21634406324935568]
	TIME [epoch: 95.8 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24039619119034775		[learning rate: 0.0019823]
	Learning Rate: 0.00198235
	LOSS [training: 0.24039619119034775 | validation: 0.20797632700995713]
	TIME [epoch: 95.8 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24146657085182688		[learning rate: 0.0019753]
	Learning Rate: 0.00197534
	LOSS [training: 0.24146657085182688 | validation: 0.20604593533746457]
	TIME [epoch: 95.8 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2454557021167919		[learning rate: 0.0019684]
	Learning Rate: 0.00196835
	LOSS [training: 0.2454557021167919 | validation: 0.2078285522529033]
	TIME [epoch: 95.8 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24246546678612405		[learning rate: 0.0019614]
	Learning Rate: 0.00196139
	LOSS [training: 0.24246546678612405 | validation: 0.21327670764944676]
	TIME [epoch: 95.8 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24995708993346052		[learning rate: 0.0019545]
	Learning Rate: 0.00195445
	LOSS [training: 0.24995708993346052 | validation: 0.2057475728230891]
	TIME [epoch: 95.8 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2530106151693447		[learning rate: 0.0019475]
	Learning Rate: 0.00194754
	LOSS [training: 0.2530106151693447 | validation: 0.21016552807653657]
	TIME [epoch: 95.8 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23191082506790095		[learning rate: 0.0019407]
	Learning Rate: 0.00194066
	LOSS [training: 0.23191082506790095 | validation: 0.2063043633172396]
	TIME [epoch: 95.8 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24343642582618333		[learning rate: 0.0019338]
	Learning Rate: 0.00193379
	LOSS [training: 0.24343642582618333 | validation: 0.20384469238965938]
	TIME [epoch: 95.8 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24232593656809773		[learning rate: 0.001927]
	Learning Rate: 0.00192696
	LOSS [training: 0.24232593656809773 | validation: 0.2033471998279341]
	TIME [epoch: 95.8 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24657364371239301		[learning rate: 0.0019201]
	Learning Rate: 0.00192014
	LOSS [training: 0.24657364371239301 | validation: 0.20966967715215662]
	TIME [epoch: 95.8 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25113456464321565		[learning rate: 0.0019134]
	Learning Rate: 0.00191335
	LOSS [training: 0.25113456464321565 | validation: 0.21519691021839193]
	TIME [epoch: 95.9 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24435099377390013		[learning rate: 0.0019066]
	Learning Rate: 0.00190659
	LOSS [training: 0.24435099377390013 | validation: 0.21651652563396184]
	TIME [epoch: 95.8 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2557201479172529		[learning rate: 0.0018998]
	Learning Rate: 0.00189984
	LOSS [training: 0.2557201479172529 | validation: 0.2036810892590339]
	TIME [epoch: 95.8 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2516960124021698		[learning rate: 0.0018931]
	Learning Rate: 0.00189313
	LOSS [training: 0.2516960124021698 | validation: 0.2133273286559235]
	TIME [epoch: 95.7 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v15b_20240719_005205/states/model_facs_v3_dec1b_2dpca_v15b_520.pth
Halted early. No improvement in validation loss for 200 epochs.
Finished training in 28734.772 seconds.
