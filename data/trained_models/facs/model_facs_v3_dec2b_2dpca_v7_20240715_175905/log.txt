Args:
Namespace(name='model_facs_v3_dec2b_2dpca_v7', outdir='out/model_training/model_facs_v3_dec2b_2dpca_v7', training_data='data/training_data/facs_v3/pca/dec2_fitonsubset/transition2_subset_ce_pn_m_pc12/training', validation_data='data/training_data/facs_v3/pca/dec2_fitonsubset/transition2_subset_ce_pn_m_pc12/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=10, batch_size=50, patience=200, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, quadratic_a=1.0, quadratic_b=1.0, ndims=2, nparams=2, nsigs=2, ncells=200, ncells_sample=200, model_do_sample=False, dt=0.005, dt_schedule='stepped', dt_schedule_bounds=[500, 1000, 1500], dt_schedule_scales=[0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=True, sigma=0.02, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', kernel='multiscale', bw_range=[0.2, 0.5, 0.9, 1.1, 1.3, 1.5, 2.0], optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 3357919132

Training model...

Saving initial model state to: out/model_training/model_facs_v3_dec2b_2dpca_v7_20240715_175905/states/model_facs_v3_dec2b_2dpca_v7_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2281918912093888		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2281918912093888 | validation: 0.8740632714178619]
	TIME [epoch: 33.8 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v7_20240715_175905/states/model_facs_v3_dec2b_2dpca_v7_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7162362445838123		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7162362445838123 | validation: 0.9053930304405039]
	TIME [epoch: 3.79 sec]
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.626562750990815		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.626562750990815 | validation: 0.7422084210515538]
	TIME [epoch: 3.79 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v7_20240715_175905/states/model_facs_v3_dec2b_2dpca_v7_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5187954079144697		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5187954079144697 | validation: 0.6970178136576024]
	TIME [epoch: 3.79 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v7_20240715_175905/states/model_facs_v3_dec2b_2dpca_v7_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5269082824388335		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5269082824388335 | validation: 0.741179151732013]
	TIME [epoch: 3.85 sec]
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5168252086163865		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5168252086163865 | validation: 0.6541497311010763]
	TIME [epoch: 3.78 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v7_20240715_175905/states/model_facs_v3_dec2b_2dpca_v7_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4550376326145458		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4550376326145458 | validation: 0.6580703206007283]
	TIME [epoch: 3.88 sec]
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43659437685700514		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.43659437685700514 | validation: 0.8138993402466094]
	TIME [epoch: 3.79 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5017852369043918		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5017852369043918 | validation: 0.6362274504944487]
	TIME [epoch: 3.79 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v7_20240715_175905/states/model_facs_v3_dec2b_2dpca_v7_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44325498257623436		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.44325498257623436 | validation: 0.6541857581553082]
	TIME [epoch: 3.79 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4467685117112902		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4467685117112902 | validation: 0.6329933985601521]
	TIME [epoch: 3.8 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v7_20240715_175905/states/model_facs_v3_dec2b_2dpca_v7_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46408508105429214		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.46408508105429214 | validation: 0.5633807599050671]
	TIME [epoch: 3.79 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v7_20240715_175905/states/model_facs_v3_dec2b_2dpca_v7_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38324332458566146		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.38324332458566146 | validation: 0.6044188877108255]
	TIME [epoch: 3.79 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4213049578256281		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4213049578256281 | validation: 0.598335066773201]
	TIME [epoch: 3.78 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39539568956427185		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.39539568956427185 | validation: 0.6565247662138869]
	TIME [epoch: 3.78 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3856701558476569		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3856701558476569 | validation: 0.5352375917251118]
	TIME [epoch: 3.78 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v7_20240715_175905/states/model_facs_v3_dec2b_2dpca_v7_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34641740105979035		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.34641740105979035 | validation: 0.5971925697678043]
	TIME [epoch: 3.81 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32852790005903393		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.32852790005903393 | validation: 0.601233814924742]
	TIME [epoch: 3.79 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33004182204433125		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.33004182204433125 | validation: 0.6377941606980525]
	TIME [epoch: 3.8 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40894787358831564		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.40894787358831564 | validation: 0.5629124421958952]
	TIME [epoch: 3.79 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3115303419356336		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3115303419356336 | validation: 0.6045921494803823]
	TIME [epoch: 3.78 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3492096059419943		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3492096059419943 | validation: 0.5149319630430946]
	TIME [epoch: 3.79 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v7_20240715_175905/states/model_facs_v3_dec2b_2dpca_v7_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3219446235178927		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3219446235178927 | validation: 0.5047500529350812]
	TIME [epoch: 3.8 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v7_20240715_175905/states/model_facs_v3_dec2b_2dpca_v7_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2950840637523964		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2950840637523964 | validation: 0.6759437855355078]
	TIME [epoch: 3.8 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38682827376065565		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.38682827376065565 | validation: 0.4827210208196028]
	TIME [epoch: 3.78 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v7_20240715_175905/states/model_facs_v3_dec2b_2dpca_v7_25.pth
	Model improved!!!
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2591962390516103		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2591962390516103 | validation: 0.48383743323779194]
	TIME [epoch: 3.78 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32779968831814277		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.32779968831814277 | validation: 0.5890922826185776]
	TIME [epoch: 3.78 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34311472424774825		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.34311472424774825 | validation: 0.57405256077606]
	TIME [epoch: 3.79 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25923795184258		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.25923795184258 | validation: 0.49562702012615206]
	TIME [epoch: 3.78 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30756095424941343		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.30756095424941343 | validation: 0.47542450838581407]
	TIME [epoch: 3.79 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v7_20240715_175905/states/model_facs_v3_dec2b_2dpca_v7_30.pth
	Model improved!!!
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3003518218046843		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3003518218046843 | validation: 0.4601437315078706]
	TIME [epoch: 3.78 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v7_20240715_175905/states/model_facs_v3_dec2b_2dpca_v7_31.pth
	Model improved!!!
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31631500033284643		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.31631500033284643 | validation: 0.5569844396481458]
	TIME [epoch: 3.79 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3555605750129479		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3555605750129479 | validation: 0.45847469309467975]
	TIME [epoch: 3.78 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v7_20240715_175905/states/model_facs_v3_dec2b_2dpca_v7_33.pth
	Model improved!!!
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29366721115335354		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.29366721115335354 | validation: 0.4561927412220634]
	TIME [epoch: 3.87 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v7_20240715_175905/states/model_facs_v3_dec2b_2dpca_v7_34.pth
	Model improved!!!
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2586421181554265		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2586421181554265 | validation: 0.507374114980676]
	TIME [epoch: 3.77 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3015036953127749		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3015036953127749 | validation: 0.46407010249612357]
	TIME [epoch: 3.78 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2817827217521849		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2817827217521849 | validation: 0.4913501214589414]
	TIME [epoch: 3.77 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.333687965365524		[learning rate: 0.0099882]
	Learning Rate: 0.0099882
	LOSS [training: 0.333687965365524 | validation: 0.5016791511062546]
	TIME [epoch: 3.77 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2324769172935701		[learning rate: 0.0099411]
	Learning Rate: 0.00994113
	LOSS [training: 0.2324769172935701 | validation: 0.4828601584778641]
	TIME [epoch: 3.77 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3058963084856702		[learning rate: 0.0098943]
	Learning Rate: 0.00989429
	LOSS [training: 0.3058963084856702 | validation: 0.51760436193817]
	TIME [epoch: 3.77 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3278923881572857		[learning rate: 0.0098477]
	Learning Rate: 0.00984767
	LOSS [training: 0.3278923881572857 | validation: 0.5608644558422655]
	TIME [epoch: 3.77 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27185198935503224		[learning rate: 0.0098013]
	Learning Rate: 0.00980126
	LOSS [training: 0.27185198935503224 | validation: 0.46128938506427847]
	TIME [epoch: 3.78 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3058625752062133		[learning rate: 0.0097551]
	Learning Rate: 0.00975508
	LOSS [training: 0.3058625752062133 | validation: 0.43314271977586005]
	TIME [epoch: 3.79 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v7_20240715_175905/states/model_facs_v3_dec2b_2dpca_v7_43.pth
	Model improved!!!
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25586055015474596		[learning rate: 0.0097091]
	Learning Rate: 0.00970911
	LOSS [training: 0.25586055015474596 | validation: 0.4763439663306699]
	TIME [epoch: 3.78 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31981976638002474		[learning rate: 0.0096634]
	Learning Rate: 0.00966336
	LOSS [training: 0.31981976638002474 | validation: 0.46707829684072333]
	TIME [epoch: 3.79 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2812045755921367		[learning rate: 0.0096178]
	Learning Rate: 0.00961783
	LOSS [training: 0.2812045755921367 | validation: 0.45966437498419854]
	TIME [epoch: 3.78 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2977533087880872		[learning rate: 0.0095725]
	Learning Rate: 0.00957251
	LOSS [training: 0.2977533087880872 | validation: 0.4466368623567589]
	TIME [epoch: 3.78 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2621929053907265		[learning rate: 0.0095274]
	Learning Rate: 0.0095274
	LOSS [training: 0.2621929053907265 | validation: 0.4661663865145183]
	TIME [epoch: 3.78 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2551968292772419		[learning rate: 0.0094825]
	Learning Rate: 0.0094825
	LOSS [training: 0.2551968292772419 | validation: 0.49723934811429954]
	TIME [epoch: 3.78 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28310261288014593		[learning rate: 0.0094378]
	Learning Rate: 0.00943782
	LOSS [training: 0.28310261288014593 | validation: 0.513978723821729]
	TIME [epoch: 3.78 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2685439700736457		[learning rate: 0.0093933]
	Learning Rate: 0.00939335
	LOSS [training: 0.2685439700736457 | validation: 0.4630036660125786]
	TIME [epoch: 3.77 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2558423494661116		[learning rate: 0.0093491]
	Learning Rate: 0.00934909
	LOSS [training: 0.2558423494661116 | validation: 0.509311331965549]
	TIME [epoch: 3.77 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25888060662793333		[learning rate: 0.009305]
	Learning Rate: 0.00930503
	LOSS [training: 0.25888060662793333 | validation: 0.5494533278094008]
	TIME [epoch: 3.77 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2756361645853121		[learning rate: 0.0092612]
	Learning Rate: 0.00926119
	LOSS [training: 0.2756361645853121 | validation: 0.39187793999452103]
	TIME [epoch: 3.77 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v7_20240715_175905/states/model_facs_v3_dec2b_2dpca_v7_54.pth
	Model improved!!!
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28720130313128583		[learning rate: 0.0092175]
	Learning Rate: 0.00921755
	LOSS [training: 0.28720130313128583 | validation: 0.4617054749546182]
	TIME [epoch: 3.79 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23811191613697058		[learning rate: 0.0091741]
	Learning Rate: 0.00917411
	LOSS [training: 0.23811191613697058 | validation: 0.510315765497568]
	TIME [epoch: 3.78 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30906309620976447		[learning rate: 0.0091309]
	Learning Rate: 0.00913088
	LOSS [training: 0.30906309620976447 | validation: 0.44457129107086446]
	TIME [epoch: 3.79 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3144515806404777		[learning rate: 0.0090879]
	Learning Rate: 0.00908786
	LOSS [training: 0.3144515806404777 | validation: 0.4370540626019001]
	TIME [epoch: 3.78 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28634293146500234		[learning rate: 0.009045]
	Learning Rate: 0.00904503
	LOSS [training: 0.28634293146500234 | validation: 0.471161517968953]
	TIME [epoch: 3.78 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29879539622366014		[learning rate: 0.0090024]
	Learning Rate: 0.00900241
	LOSS [training: 0.29879539622366014 | validation: 0.4390265706450246]
	TIME [epoch: 3.78 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2855772367003926		[learning rate: 0.00896]
	Learning Rate: 0.00895999
	LOSS [training: 0.2855772367003926 | validation: 0.5331860303782526]
	TIME [epoch: 3.79 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25795681237042206		[learning rate: 0.0089178]
	Learning Rate: 0.00891777
	LOSS [training: 0.25795681237042206 | validation: 0.7074178844442216]
	TIME [epoch: 3.78 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2877253631209361		[learning rate: 0.0088758]
	Learning Rate: 0.00887575
	LOSS [training: 0.2877253631209361 | validation: 0.4618148561308041]
	TIME [epoch: 3.78 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31317896580303356		[learning rate: 0.0088339]
	Learning Rate: 0.00883393
	LOSS [training: 0.31317896580303356 | validation: 0.5442993346368263]
	TIME [epoch: 3.77 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36622918643726043		[learning rate: 0.0087923]
	Learning Rate: 0.0087923
	LOSS [training: 0.36622918643726043 | validation: 0.5050388750143788]
	TIME [epoch: 3.78 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2755169082611377		[learning rate: 0.0087509]
	Learning Rate: 0.00875087
	LOSS [training: 0.2755169082611377 | validation: 0.5469651117888807]
	TIME [epoch: 3.77 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2778906884884956		[learning rate: 0.0087096]
	Learning Rate: 0.00870964
	LOSS [training: 0.2778906884884956 | validation: 0.49042838311860454]
	TIME [epoch: 3.77 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.275549833723939		[learning rate: 0.0086686]
	Learning Rate: 0.00866859
	LOSS [training: 0.275549833723939 | validation: 0.43247193825403907]
	TIME [epoch: 3.77 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23816222982844143		[learning rate: 0.0086277]
	Learning Rate: 0.00862775
	LOSS [training: 0.23816222982844143 | validation: 0.49034701671070197]
	TIME [epoch: 3.79 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24370235437868792		[learning rate: 0.0085871]
	Learning Rate: 0.00858709
	LOSS [training: 0.24370235437868792 | validation: 0.44387464031578805]
	TIME [epoch: 3.77 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26275474114832514		[learning rate: 0.0085466]
	Learning Rate: 0.00854663
	LOSS [training: 0.26275474114832514 | validation: 0.5315675205643895]
	TIME [epoch: 3.77 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28424005951804004		[learning rate: 0.0085064]
	Learning Rate: 0.00850636
	LOSS [training: 0.28424005951804004 | validation: 0.47561866246159734]
	TIME [epoch: 3.77 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24768310530100995		[learning rate: 0.0084663]
	Learning Rate: 0.00846627
	LOSS [training: 0.24768310530100995 | validation: 0.3818523392184364]
	TIME [epoch: 3.77 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v7_20240715_175905/states/model_facs_v3_dec2b_2dpca_v7_73.pth
	Model improved!!!
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22445729264991715		[learning rate: 0.0084264]
	Learning Rate: 0.00842638
	LOSS [training: 0.22445729264991715 | validation: 0.45863958268873467]
	TIME [epoch: 3.79 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22858332432668294		[learning rate: 0.0083867]
	Learning Rate: 0.00838667
	LOSS [training: 0.22858332432668294 | validation: 0.3438839200718746]
	TIME [epoch: 3.78 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v7_20240715_175905/states/model_facs_v3_dec2b_2dpca_v7_75.pth
	Model improved!!!
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22239279212844099		[learning rate: 0.0083472]
	Learning Rate: 0.00834715
	LOSS [training: 0.22239279212844099 | validation: 0.4937614234281018]
	TIME [epoch: 3.78 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19082182122681207		[learning rate: 0.0083078]
	Learning Rate: 0.00830782
	LOSS [training: 0.19082182122681207 | validation: 0.5293731862980356]
	TIME [epoch: 3.79 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.255424726371994		[learning rate: 0.0082687]
	Learning Rate: 0.00826867
	LOSS [training: 0.255424726371994 | validation: 0.6758759564439424]
	TIME [epoch: 3.79 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3123903796248457		[learning rate: 0.0082297]
	Learning Rate: 0.00822971
	LOSS [training: 0.3123903796248457 | validation: 0.4797707118383332]
	TIME [epoch: 3.78 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23155462358787215		[learning rate: 0.0081909]
	Learning Rate: 0.00819093
	LOSS [training: 0.23155462358787215 | validation: 0.39562966585847636]
	TIME [epoch: 3.78 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23560547942626797		[learning rate: 0.0081523]
	Learning Rate: 0.00815233
	LOSS [training: 0.23560547942626797 | validation: 0.5070803864387756]
	TIME [epoch: 3.8 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23682692567817626		[learning rate: 0.0081139]
	Learning Rate: 0.00811392
	LOSS [training: 0.23682692567817626 | validation: 0.3697698842528326]
	TIME [epoch: 3.78 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20319618735916742		[learning rate: 0.0080757]
	Learning Rate: 0.00807569
	LOSS [training: 0.20319618735916742 | validation: 0.38036712037625314]
	TIME [epoch: 3.78 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24925337121808405		[learning rate: 0.0080376]
	Learning Rate: 0.00803763
	LOSS [training: 0.24925337121808405 | validation: 0.3774339334935423]
	TIME [epoch: 3.77 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2279603027318871		[learning rate: 0.0079998]
	Learning Rate: 0.00799976
	LOSS [training: 0.2279603027318871 | validation: 0.43536727020028343]
	TIME [epoch: 3.77 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25557301743690053		[learning rate: 0.0079621]
	Learning Rate: 0.00796206
	LOSS [training: 0.25557301743690053 | validation: 0.3851188219388344]
	TIME [epoch: 3.78 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21761774649168938		[learning rate: 0.0079245]
	Learning Rate: 0.00792455
	LOSS [training: 0.21761774649168938 | validation: 0.5232195913643024]
	TIME [epoch: 3.78 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2629869327069894		[learning rate: 0.0078872]
	Learning Rate: 0.0078872
	LOSS [training: 0.2629869327069894 | validation: 0.5798110794006917]
	TIME [epoch: 3.78 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2365751880316743		[learning rate: 0.00785]
	Learning Rate: 0.00785004
	LOSS [training: 0.2365751880316743 | validation: 0.3596261198186189]
	TIME [epoch: 3.79 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19893630170651383		[learning rate: 0.007813]
	Learning Rate: 0.00781305
	LOSS [training: 0.19893630170651383 | validation: 0.3787593663347534]
	TIME [epoch: 3.78 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19556421446806244		[learning rate: 0.0077762]
	Learning Rate: 0.00777623
	LOSS [training: 0.19556421446806244 | validation: 0.3525462534828537]
	TIME [epoch: 3.79 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2930169781306562		[learning rate: 0.0077396]
	Learning Rate: 0.00773959
	LOSS [training: 0.2930169781306562 | validation: 0.4660944739250942]
	TIME [epoch: 3.79 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23670618795574233		[learning rate: 0.0077031]
	Learning Rate: 0.00770312
	LOSS [training: 0.23670618795574233 | validation: 0.37416488629937267]
	TIME [epoch: 3.78 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2129360883887558		[learning rate: 0.0076668]
	Learning Rate: 0.00766682
	LOSS [training: 0.2129360883887558 | validation: 0.5269154918222221]
	TIME [epoch: 3.78 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25013677115509186		[learning rate: 0.0076307]
	Learning Rate: 0.0076307
	LOSS [training: 0.25013677115509186 | validation: 0.41578542268285923]
	TIME [epoch: 3.78 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2307171063921165		[learning rate: 0.0075947]
	Learning Rate: 0.00759474
	LOSS [training: 0.2307171063921165 | validation: 0.43883224943886123]
	TIME [epoch: 3.78 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25336702522300625		[learning rate: 0.007559]
	Learning Rate: 0.00755895
	LOSS [training: 0.25336702522300625 | validation: 0.5401125364436875]
	TIME [epoch: 3.78 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28723239996719585		[learning rate: 0.0075233]
	Learning Rate: 0.00752333
	LOSS [training: 0.28723239996719585 | validation: 0.46633070854640013]
	TIME [epoch: 3.82 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30426003035591803		[learning rate: 0.0074879]
	Learning Rate: 0.00748788
	LOSS [training: 0.30426003035591803 | validation: 0.5003063804134741]
	TIME [epoch: 3.78 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2510176948311126		[learning rate: 0.0074526]
	Learning Rate: 0.0074526
	LOSS [training: 0.2510176948311126 | validation: 0.39470868451279445]
	TIME [epoch: 3.78 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20367805630899147		[learning rate: 0.0074175]
	Learning Rate: 0.00741748
	LOSS [training: 0.20367805630899147 | validation: 0.4104606013148028]
	TIME [epoch: 3.78 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21786773902404694		[learning rate: 0.0073825]
	Learning Rate: 0.00738253
	LOSS [training: 0.21786773902404694 | validation: 0.4963803140594593]
	TIME [epoch: 3.77 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21104887020999752		[learning rate: 0.0073477]
	Learning Rate: 0.00734774
	LOSS [training: 0.21104887020999752 | validation: 0.406847242028053]
	TIME [epoch: 3.78 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20302274847065527		[learning rate: 0.0073131]
	Learning Rate: 0.00731312
	LOSS [training: 0.20302274847065527 | validation: 0.37345021631260833]
	TIME [epoch: 3.79 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23660795051317557		[learning rate: 0.0072787]
	Learning Rate: 0.00727866
	LOSS [training: 0.23660795051317557 | validation: 0.43180487019408953]
	TIME [epoch: 3.77 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20797071569178593		[learning rate: 0.0072444]
	Learning Rate: 0.00724436
	LOSS [training: 0.20797071569178593 | validation: 0.4091712129174643]
	TIME [epoch: 3.79 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21061242393427246		[learning rate: 0.0072102]
	Learning Rate: 0.00721022
	LOSS [training: 0.21061242393427246 | validation: 0.4615824344454648]
	TIME [epoch: 3.77 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24462516149973879		[learning rate: 0.0071762]
	Learning Rate: 0.00717625
	LOSS [training: 0.24462516149973879 | validation: 0.5506865234302355]
	TIME [epoch: 3.78 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2537402648118234		[learning rate: 0.0071424]
	Learning Rate: 0.00714243
	LOSS [training: 0.2537402648118234 | validation: 0.44165486545889165]
	TIME [epoch: 3.77 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28942271704639155		[learning rate: 0.0071088]
	Learning Rate: 0.00710878
	LOSS [training: 0.28942271704639155 | validation: 0.46028487978867944]
	TIME [epoch: 3.78 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26879170323266405		[learning rate: 0.0070753]
	Learning Rate: 0.00707528
	LOSS [training: 0.26879170323266405 | validation: 0.3371214035120098]
	TIME [epoch: 3.77 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v7_20240715_175905/states/model_facs_v3_dec2b_2dpca_v7_111.pth
	Model improved!!!
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2117768856664944		[learning rate: 0.0070419]
	Learning Rate: 0.00704194
	LOSS [training: 0.2117768856664944 | validation: 0.33307172009035535]
	TIME [epoch: 3.78 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v7_20240715_175905/states/model_facs_v3_dec2b_2dpca_v7_112.pth
	Model improved!!!
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18928025080267097		[learning rate: 0.0070088]
	Learning Rate: 0.00700876
	LOSS [training: 0.18928025080267097 | validation: 0.3490456612155212]
	TIME [epoch: 3.79 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19641854363166608		[learning rate: 0.0069757]
	Learning Rate: 0.00697573
	LOSS [training: 0.19641854363166608 | validation: 0.4233470676878459]
	TIME [epoch: 3.8 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20338196155743216		[learning rate: 0.0069429]
	Learning Rate: 0.00694286
	LOSS [training: 0.20338196155743216 | validation: 0.36459351181594324]
	TIME [epoch: 3.79 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1949356851867599		[learning rate: 0.0069101]
	Learning Rate: 0.00691014
	LOSS [training: 0.1949356851867599 | validation: 0.35372399438198904]
	TIME [epoch: 3.79 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2018642564867537		[learning rate: 0.0068776]
	Learning Rate: 0.00687758
	LOSS [training: 0.2018642564867537 | validation: 0.36339468175779416]
	TIME [epoch: 3.79 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24624236435714594		[learning rate: 0.0068452]
	Learning Rate: 0.00684518
	LOSS [training: 0.24624236435714594 | validation: 0.36928654672256245]
	TIME [epoch: 3.79 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21523597605912886		[learning rate: 0.0068129]
	Learning Rate: 0.00681292
	LOSS [training: 0.21523597605912886 | validation: 0.347888859045113]
	TIME [epoch: 3.79 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22029204802987404		[learning rate: 0.0067808]
	Learning Rate: 0.00678082
	LOSS [training: 0.22029204802987404 | validation: 0.3996374618153243]
	TIME [epoch: 3.78 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19783201001419762		[learning rate: 0.0067489]
	Learning Rate: 0.00674887
	LOSS [training: 0.19783201001419762 | validation: 0.3632592257962742]
	TIME [epoch: 3.79 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20235697267129016		[learning rate: 0.0067171]
	Learning Rate: 0.00671706
	LOSS [training: 0.20235697267129016 | validation: 0.39865947172964017]
	TIME [epoch: 3.79 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22773758708966615		[learning rate: 0.0066854]
	Learning Rate: 0.00668541
	LOSS [training: 0.22773758708966615 | validation: 0.4290147153275593]
	TIME [epoch: 3.79 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19018245149868665		[learning rate: 0.0066539]
	Learning Rate: 0.00665391
	LOSS [training: 0.19018245149868665 | validation: 0.3870190225454248]
	TIME [epoch: 3.78 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21374778557452162		[learning rate: 0.0066226]
	Learning Rate: 0.00662256
	LOSS [training: 0.21374778557452162 | validation: 0.4986363755260874]
	TIME [epoch: 3.79 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31567920488722867		[learning rate: 0.0065913]
	Learning Rate: 0.00659135
	LOSS [training: 0.31567920488722867 | validation: 0.48584169502847274]
	TIME [epoch: 3.79 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2855578455519208		[learning rate: 0.0065603]
	Learning Rate: 0.00656029
	LOSS [training: 0.2855578455519208 | validation: 0.455815820447833]
	TIME [epoch: 3.79 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27936855285147927		[learning rate: 0.0065294]
	Learning Rate: 0.00652938
	LOSS [training: 0.27936855285147927 | validation: 0.4338852570342125]
	TIME [epoch: 3.78 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2408696421005337		[learning rate: 0.0064986]
	Learning Rate: 0.00649861
	LOSS [training: 0.2408696421005337 | validation: 0.5073222459273529]
	TIME [epoch: 3.79 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2291355383116268		[learning rate: 0.006468]
	Learning Rate: 0.00646799
	LOSS [training: 0.2291355383116268 | validation: 0.4881239935257597]
	TIME [epoch: 3.78 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24974395331552446		[learning rate: 0.0064375]
	Learning Rate: 0.00643751
	LOSS [training: 0.24974395331552446 | validation: 0.4350471529276512]
	TIME [epoch: 3.78 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20271021127789984		[learning rate: 0.0064072]
	Learning Rate: 0.00640718
	LOSS [training: 0.20271021127789984 | validation: 0.3560976049879191]
	TIME [epoch: 3.79 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20670162276387882		[learning rate: 0.006377]
	Learning Rate: 0.00637698
	LOSS [training: 0.20670162276387882 | validation: 0.34246355060174605]
	TIME [epoch: 3.79 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18851527966189835		[learning rate: 0.0063469]
	Learning Rate: 0.00634694
	LOSS [training: 0.18851527966189835 | validation: 0.48378404007884074]
	TIME [epoch: 3.78 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23377017357550864		[learning rate: 0.006317]
	Learning Rate: 0.00631703
	LOSS [training: 0.23377017357550864 | validation: 0.36531413377840627]
	TIME [epoch: 3.78 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18947792297139776		[learning rate: 0.0062873]
	Learning Rate: 0.00628726
	LOSS [training: 0.18947792297139776 | validation: 0.3489345509515966]
	TIME [epoch: 3.79 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1861546837436152		[learning rate: 0.0062576]
	Learning Rate: 0.00625764
	LOSS [training: 0.1861546837436152 | validation: 0.34981434691530355]
	TIME [epoch: 3.78 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25312405364461765		[learning rate: 0.0062281]
	Learning Rate: 0.00622815
	LOSS [training: 0.25312405364461765 | validation: 0.5022299119445]
	TIME [epoch: 3.79 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2704948578950671		[learning rate: 0.0061988]
	Learning Rate: 0.0061988
	LOSS [training: 0.2704948578950671 | validation: 0.537655329239585]
	TIME [epoch: 3.78 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21852079840465072		[learning rate: 0.0061696]
	Learning Rate: 0.00616959
	LOSS [training: 0.21852079840465072 | validation: 0.3751661176392911]
	TIME [epoch: 3.79 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19243190437996316		[learning rate: 0.0061405]
	Learning Rate: 0.00614052
	LOSS [training: 0.19243190437996316 | validation: 0.33507534275939377]
	TIME [epoch: 3.78 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19387396854218275		[learning rate: 0.0061116]
	Learning Rate: 0.00611158
	LOSS [training: 0.19387396854218275 | validation: 0.35321213607560026]
	TIME [epoch: 3.79 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2900422967663826		[learning rate: 0.0060828]
	Learning Rate: 0.00608279
	LOSS [training: 0.2900422967663826 | validation: 0.5330200625545258]
	TIME [epoch: 3.8 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2566878904423727		[learning rate: 0.0060541]
	Learning Rate: 0.00605412
	LOSS [training: 0.2566878904423727 | validation: 0.3484480894826175]
	TIME [epoch: 3.78 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17362297025195766		[learning rate: 0.0060256]
	Learning Rate: 0.0060256
	LOSS [training: 0.17362297025195766 | validation: 0.34010667540674877]
	TIME [epoch: 3.79 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16920583397797856		[learning rate: 0.0059972]
	Learning Rate: 0.0059972
	LOSS [training: 0.16920583397797856 | validation: 0.37200565824620124]
	TIME [epoch: 3.78 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19164926154500547		[learning rate: 0.0059689]
	Learning Rate: 0.00596894
	LOSS [training: 0.19164926154500547 | validation: 0.39728457534339456]
	TIME [epoch: 3.79 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18359390770115672		[learning rate: 0.0059408]
	Learning Rate: 0.00594082
	LOSS [training: 0.18359390770115672 | validation: 0.45484556680745186]
	TIME [epoch: 3.78 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17436036254487652		[learning rate: 0.0059128]
	Learning Rate: 0.00591282
	LOSS [training: 0.17436036254487652 | validation: 0.38005009299110976]
	TIME [epoch: 3.8 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19151094282851241		[learning rate: 0.005885]
	Learning Rate: 0.00588496
	LOSS [training: 0.19151094282851241 | validation: 0.3615380626662279]
	TIME [epoch: 3.79 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17578449220173825		[learning rate: 0.0058572]
	Learning Rate: 0.00585723
	LOSS [training: 0.17578449220173825 | validation: 0.46514964908404044]
	TIME [epoch: 3.78 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20130386430902775		[learning rate: 0.0058296]
	Learning Rate: 0.00582963
	LOSS [training: 0.20130386430902775 | validation: 0.48438869250857064]
	TIME [epoch: 3.77 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.294130291309004		[learning rate: 0.0058022]
	Learning Rate: 0.00580216
	LOSS [training: 0.294130291309004 | validation: 0.36995728111747195]
	TIME [epoch: 3.78 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23778237658840887		[learning rate: 0.0057748]
	Learning Rate: 0.00577482
	LOSS [training: 0.23778237658840887 | validation: 0.35857668787048824]
	TIME [epoch: 3.77 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2000028866099313		[learning rate: 0.0057476]
	Learning Rate: 0.00574761
	LOSS [training: 0.2000028866099313 | validation: 0.3689352196769433]
	TIME [epoch: 3.78 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18634103053357612		[learning rate: 0.0057205]
	Learning Rate: 0.00572052
	LOSS [training: 0.18634103053357612 | validation: 0.3485092815785911]
	TIME [epoch: 3.77 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17587199729458758		[learning rate: 0.0056936]
	Learning Rate: 0.00569357
	LOSS [training: 0.17587199729458758 | validation: 0.3715391330592293]
	TIME [epoch: 3.78 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1967755727050598		[learning rate: 0.0056667]
	Learning Rate: 0.00566674
	LOSS [training: 0.1967755727050598 | validation: 0.3136149148512933]
	TIME [epoch: 3.78 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v7_20240715_175905/states/model_facs_v3_dec2b_2dpca_v7_158.pth
	Model improved!!!
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17278341007977868		[learning rate: 0.00564]
	Learning Rate: 0.00564004
	LOSS [training: 0.17278341007977868 | validation: 0.335702664400005]
	TIME [epoch: 3.78 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17665329910954383		[learning rate: 0.0056135]
	Learning Rate: 0.00561346
	LOSS [training: 0.17665329910954383 | validation: 0.46618652229921365]
	TIME [epoch: 3.79 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1538865501343163		[learning rate: 0.005587]
	Learning Rate: 0.00558701
	LOSS [training: 0.1538865501343163 | validation: 0.3536893552736108]
	TIME [epoch: 3.78 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15646563392018076		[learning rate: 0.0055607]
	Learning Rate: 0.00556068
	LOSS [training: 0.15646563392018076 | validation: 0.3550663126522542]
	TIME [epoch: 3.78 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18322080212180028		[learning rate: 0.0055345]
	Learning Rate: 0.00553448
	LOSS [training: 0.18322080212180028 | validation: 0.39613716827856893]
	TIME [epoch: 3.77 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16532185440272373		[learning rate: 0.0055084]
	Learning Rate: 0.0055084
	LOSS [training: 0.16532185440272373 | validation: 0.389857937504728]
	TIME [epoch: 3.78 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18077838001137672		[learning rate: 0.0054824]
	Learning Rate: 0.00548245
	LOSS [training: 0.18077838001137672 | validation: 0.3909635904559121]
	TIME [epoch: 3.78 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1707563202651981		[learning rate: 0.0054566]
	Learning Rate: 0.00545661
	LOSS [training: 0.1707563202651981 | validation: 0.4229970698315331]
	TIME [epoch: 3.78 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2615795040647776		[learning rate: 0.0054309]
	Learning Rate: 0.0054309
	LOSS [training: 0.2615795040647776 | validation: 0.3363117807064053]
	TIME [epoch: 3.78 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18786304975935075		[learning rate: 0.0054053]
	Learning Rate: 0.00540531
	LOSS [training: 0.18786304975935075 | validation: 0.3415385226363742]
	TIME [epoch: 3.77 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18590310747763494		[learning rate: 0.0053798]
	Learning Rate: 0.00537984
	LOSS [training: 0.18590310747763494 | validation: 0.3609668745518512]
	TIME [epoch: 3.78 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19467428145526308		[learning rate: 0.0053545]
	Learning Rate: 0.00535449
	LOSS [training: 0.19467428145526308 | validation: 0.3571371596631214]
	TIME [epoch: 3.78 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21037399547091615		[learning rate: 0.0053293]
	Learning Rate: 0.00532926
	LOSS [training: 0.21037399547091615 | validation: 0.44119850312398506]
	TIME [epoch: 3.78 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20729753456795022		[learning rate: 0.0053041]
	Learning Rate: 0.00530415
	LOSS [training: 0.20729753456795022 | validation: 0.4064151206291203]
	TIME [epoch: 3.78 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1939101115192951		[learning rate: 0.0052792]
	Learning Rate: 0.00527915
	LOSS [training: 0.1939101115192951 | validation: 0.3302347254525294]
	TIME [epoch: 3.78 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17573011610180997		[learning rate: 0.0052543]
	Learning Rate: 0.00525428
	LOSS [training: 0.17573011610180997 | validation: 0.3992187990240774]
	TIME [epoch: 3.8 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1774537695055029		[learning rate: 0.0052295]
	Learning Rate: 0.00522952
	LOSS [training: 0.1774537695055029 | validation: 0.3624237008282154]
	TIME [epoch: 3.77 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1677497005268038		[learning rate: 0.0052049]
	Learning Rate: 0.00520487
	LOSS [training: 0.1677497005268038 | validation: 0.3312894772038381]
	TIME [epoch: 3.78 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18595688209878908		[learning rate: 0.0051803]
	Learning Rate: 0.00518035
	LOSS [training: 0.18595688209878908 | validation: 0.47708372728838716]
	TIME [epoch: 3.78 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18215326478186897		[learning rate: 0.0051559]
	Learning Rate: 0.00515594
	LOSS [training: 0.18215326478186897 | validation: 0.37365313688946333]
	TIME [epoch: 3.78 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16543190012466724		[learning rate: 0.0051316]
	Learning Rate: 0.00513164
	LOSS [training: 0.16543190012466724 | validation: 0.3421562217219914]
	TIME [epoch: 3.78 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16590572454520278		[learning rate: 0.0051075]
	Learning Rate: 0.00510746
	LOSS [training: 0.16590572454520278 | validation: 0.374965878450195]
	TIME [epoch: 3.78 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16651802276623232		[learning rate: 0.0050834]
	Learning Rate: 0.00508339
	LOSS [training: 0.16651802276623232 | validation: 0.42933332828605886]
	TIME [epoch: 3.78 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18823023194269667		[learning rate: 0.0050594]
	Learning Rate: 0.00505944
	LOSS [training: 0.18823023194269667 | validation: 0.36471376968798896]
	TIME [epoch: 3.79 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18997095316178242		[learning rate: 0.0050356]
	Learning Rate: 0.0050356
	LOSS [training: 0.18997095316178242 | validation: 0.4737824921056466]
	TIME [epoch: 3.79 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18312639458475388		[learning rate: 0.0050119]
	Learning Rate: 0.00501187
	LOSS [training: 0.18312639458475388 | validation: 0.40245838503386744]
	TIME [epoch: 3.79 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1906333636108948		[learning rate: 0.0049883]
	Learning Rate: 0.00498826
	LOSS [training: 0.1906333636108948 | validation: 0.32994650152673244]
	TIME [epoch: 3.78 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16270457224596818		[learning rate: 0.0049648]
	Learning Rate: 0.00496475
	LOSS [training: 0.16270457224596818 | validation: 0.46648459465142167]
	TIME [epoch: 3.78 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18679216742412405		[learning rate: 0.0049414]
	Learning Rate: 0.00494136
	LOSS [training: 0.18679216742412405 | validation: 0.3467793835252958]
	TIME [epoch: 3.77 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18516397435585025		[learning rate: 0.0049181]
	Learning Rate: 0.00491807
	LOSS [training: 0.18516397435585025 | validation: 0.3292131085829809]
	TIME [epoch: 3.78 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1630872463276523		[learning rate: 0.0048949]
	Learning Rate: 0.0048949
	LOSS [training: 0.1630872463276523 | validation: 0.3620836663330143]
	TIME [epoch: 3.78 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1697220804439672		[learning rate: 0.0048718]
	Learning Rate: 0.00487183
	LOSS [training: 0.1697220804439672 | validation: 0.3618673790953332]
	TIME [epoch: 3.78 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15831713465066372		[learning rate: 0.0048489]
	Learning Rate: 0.00484888
	LOSS [training: 0.15831713465066372 | validation: 0.3415244009780127]
	TIME [epoch: 3.78 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16926168267786865		[learning rate: 0.004826]
	Learning Rate: 0.00482603
	LOSS [training: 0.16926168267786865 | validation: 0.4062130941975816]
	TIME [epoch: 3.77 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2152538364662934		[learning rate: 0.0048033]
	Learning Rate: 0.00480329
	LOSS [training: 0.2152538364662934 | validation: 0.3731342012911202]
	TIME [epoch: 3.78 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1766494008499533		[learning rate: 0.0047807]
	Learning Rate: 0.00478065
	LOSS [training: 0.1766494008499533 | validation: 0.40951874090530305]
	TIME [epoch: 3.78 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1909993897743805		[learning rate: 0.0047581]
	Learning Rate: 0.00475813
	LOSS [training: 0.1909993897743805 | validation: 0.3647706082626452]
	TIME [epoch: 3.79 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18834615311376296		[learning rate: 0.0047357]
	Learning Rate: 0.0047357
	LOSS [training: 0.18834615311376296 | validation: 0.36749711803510016]
	TIME [epoch: 3.77 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16192183905656146		[learning rate: 0.0047134]
	Learning Rate: 0.00471339
	LOSS [training: 0.16192183905656146 | validation: 0.42960041358444523]
	TIME [epoch: 3.78 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24090445281350625		[learning rate: 0.0046912]
	Learning Rate: 0.00469118
	LOSS [training: 0.24090445281350625 | validation: 0.3724566829469715]
	TIME [epoch: 3.77 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1833883955019242		[learning rate: 0.0046691]
	Learning Rate: 0.00466907
	LOSS [training: 0.1833883955019242 | validation: 0.316986737467687]
	TIME [epoch: 3.78 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1635416146706482		[learning rate: 0.0046471]
	Learning Rate: 0.00464707
	LOSS [training: 0.1635416146706482 | validation: 0.35750328358819566]
	TIME [epoch: 3.78 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1714631056882879		[learning rate: 0.0046252]
	Learning Rate: 0.00462518
	LOSS [training: 0.1714631056882879 | validation: 0.4020362915251758]
	TIME [epoch: 3.78 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1677752427518786		[learning rate: 0.0046034]
	Learning Rate: 0.00460338
	LOSS [training: 0.1677752427518786 | validation: 0.3436419849625627]
	TIME [epoch: 3.78 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16495093265512095		[learning rate: 0.0045817]
	Learning Rate: 0.00458169
	LOSS [training: 0.16495093265512095 | validation: 0.4052781473329647]
	TIME [epoch: 3.77 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15577145661804623		[learning rate: 0.0045601]
	Learning Rate: 0.0045601
	LOSS [training: 0.15577145661804623 | validation: 0.3175377036056572]
	TIME [epoch: 3.77 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17436898479522428		[learning rate: 0.0045386]
	Learning Rate: 0.00453861
	LOSS [training: 0.17436898479522428 | validation: 0.3864684959285357]
	TIME [epoch: 3.79 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16849389601810694		[learning rate: 0.0045172]
	Learning Rate: 0.00451723
	LOSS [training: 0.16849389601810694 | validation: 0.3190438375706884]
	TIME [epoch: 3.78 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16227077985972263		[learning rate: 0.0044959]
	Learning Rate: 0.00449594
	LOSS [training: 0.16227077985972263 | validation: 0.33691485166826085]
	TIME [epoch: 3.77 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16794147353182273		[learning rate: 0.0044748]
	Learning Rate: 0.00447475
	LOSS [training: 0.16794147353182273 | validation: 0.3215713169479839]
	TIME [epoch: 3.8 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17515116452046273		[learning rate: 0.0044537]
	Learning Rate: 0.00445367
	LOSS [training: 0.17515116452046273 | validation: 0.3302730520736222]
	TIME [epoch: 3.78 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1808010129748305		[learning rate: 0.0044327]
	Learning Rate: 0.00443268
	LOSS [training: 0.1808010129748305 | validation: 0.3745500517156097]
	TIME [epoch: 3.77 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14573059707411762		[learning rate: 0.0044118]
	Learning Rate: 0.0044118
	LOSS [training: 0.14573059707411762 | validation: 0.349412467853848]
	TIME [epoch: 3.77 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1882562364086887		[learning rate: 0.004391]
	Learning Rate: 0.00439101
	LOSS [training: 0.1882562364086887 | validation: 0.4004444164350358]
	TIME [epoch: 3.78 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1953412274207412		[learning rate: 0.0043703]
	Learning Rate: 0.00437032
	LOSS [training: 0.1953412274207412 | validation: 0.40853559437405607]
	TIME [epoch: 3.77 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16256481147423635		[learning rate: 0.0043497]
	Learning Rate: 0.00434972
	LOSS [training: 0.16256481147423635 | validation: 0.3876739191344198]
	TIME [epoch: 3.78 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16923845312422273		[learning rate: 0.0043292]
	Learning Rate: 0.00432923
	LOSS [training: 0.16923845312422273 | validation: 0.3358874577039774]
	TIME [epoch: 3.77 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17454713193237062		[learning rate: 0.0043088]
	Learning Rate: 0.00430883
	LOSS [training: 0.17454713193237062 | validation: 0.3354502417003015]
	TIME [epoch: 3.79 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1504291034856809		[learning rate: 0.0042885]
	Learning Rate: 0.00428852
	LOSS [training: 0.1504291034856809 | validation: 0.31179418785031426]
	TIME [epoch: 3.78 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v7_20240715_175905/states/model_facs_v3_dec2b_2dpca_v7_217.pth
	Model improved!!!
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15741343964052282		[learning rate: 0.0042683]
	Learning Rate: 0.00426831
	LOSS [training: 0.15741343964052282 | validation: 0.3498358473998932]
	TIME [epoch: 3.78 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15188748178546502		[learning rate: 0.0042482]
	Learning Rate: 0.0042482
	LOSS [training: 0.15188748178546502 | validation: 0.31135333442540836]
	TIME [epoch: 3.79 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v7_20240715_175905/states/model_facs_v3_dec2b_2dpca_v7_219.pth
	Model improved!!!
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17570791427034974		[learning rate: 0.0042282]
	Learning Rate: 0.00422818
	LOSS [training: 0.17570791427034974 | validation: 0.3172197056000863]
	TIME [epoch: 3.78 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1863312853358151		[learning rate: 0.0042083]
	Learning Rate: 0.00420826
	LOSS [training: 0.1863312853358151 | validation: 0.3303228950562668]
	TIME [epoch: 3.78 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18097181423299233		[learning rate: 0.0041884]
	Learning Rate: 0.00418843
	LOSS [training: 0.18097181423299233 | validation: 0.3086839937349627]
	TIME [epoch: 3.78 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v7_20240715_175905/states/model_facs_v3_dec2b_2dpca_v7_222.pth
	Model improved!!!
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1590078474553226		[learning rate: 0.0041687]
	Learning Rate: 0.00416869
	LOSS [training: 0.1590078474553226 | validation: 0.3226443806387866]
	TIME [epoch: 3.78 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18699941027021344		[learning rate: 0.0041491]
	Learning Rate: 0.00414905
	LOSS [training: 0.18699941027021344 | validation: 0.3164402789957607]
	TIME [epoch: 3.78 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17978923518926054		[learning rate: 0.0041295]
	Learning Rate: 0.0041295
	LOSS [training: 0.17978923518926054 | validation: 0.35057354937156027]
	TIME [epoch: 3.77 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15361922063875005		[learning rate: 0.00411]
	Learning Rate: 0.00411004
	LOSS [training: 0.15361922063875005 | validation: 0.3296469687839643]
	TIME [epoch: 3.77 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16015856028866346		[learning rate: 0.0040907]
	Learning Rate: 0.00409067
	LOSS [training: 0.16015856028866346 | validation: 0.3270080608144218]
	TIME [epoch: 3.79 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1585710805909316		[learning rate: 0.0040714]
	Learning Rate: 0.0040714
	LOSS [training: 0.1585710805909316 | validation: 0.2964731322019053]
	TIME [epoch: 3.78 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v7_20240715_175905/states/model_facs_v3_dec2b_2dpca_v7_228.pth
	Model improved!!!
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16495675024845882		[learning rate: 0.0040522]
	Learning Rate: 0.00405221
	LOSS [training: 0.16495675024845882 | validation: 0.3523874942022486]
	TIME [epoch: 3.79 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1845461464067995		[learning rate: 0.0040331]
	Learning Rate: 0.00403312
	LOSS [training: 0.1845461464067995 | validation: 0.3224368665940017]
	TIME [epoch: 3.78 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16318248015200765		[learning rate: 0.0040141]
	Learning Rate: 0.00401411
	LOSS [training: 0.16318248015200765 | validation: 0.42840140173553737]
	TIME [epoch: 3.78 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1670190979184727		[learning rate: 0.0039952]
	Learning Rate: 0.0039952
	LOSS [training: 0.1670190979184727 | validation: 0.3243472616375718]
	TIME [epoch: 3.78 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15136967775969878		[learning rate: 0.0039764]
	Learning Rate: 0.00397637
	LOSS [training: 0.15136967775969878 | validation: 0.3418952742256767]
	TIME [epoch: 3.79 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.157129015203415		[learning rate: 0.0039576]
	Learning Rate: 0.00395764
	LOSS [training: 0.157129015203415 | validation: 0.3080955485554969]
	TIME [epoch: 3.78 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17421044056570126		[learning rate: 0.003939]
	Learning Rate: 0.00393899
	LOSS [training: 0.17421044056570126 | validation: 0.34192354511410783]
	TIME [epoch: 3.78 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1499839487969561		[learning rate: 0.0039204]
	Learning Rate: 0.00392043
	LOSS [training: 0.1499839487969561 | validation: 0.3820475195923252]
	TIME [epoch: 3.77 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19620727931728024		[learning rate: 0.003902]
	Learning Rate: 0.00390195
	LOSS [training: 0.19620727931728024 | validation: 0.31466564264224534]
	TIME [epoch: 3.78 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16606404429428462		[learning rate: 0.0038836]
	Learning Rate: 0.00388357
	LOSS [training: 0.16606404429428462 | validation: 0.3303636356362838]
	TIME [epoch: 3.78 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16797152712046548		[learning rate: 0.0038653]
	Learning Rate: 0.00386527
	LOSS [training: 0.16797152712046548 | validation: 0.3592270370463204]
	TIME [epoch: 3.84 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15145313894088397		[learning rate: 0.0038471]
	Learning Rate: 0.00384705
	LOSS [training: 0.15145313894088397 | validation: 0.3618925471259871]
	TIME [epoch: 3.8 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17221767224432583		[learning rate: 0.0038289]
	Learning Rate: 0.00382893
	LOSS [training: 0.17221767224432583 | validation: 0.3453814163773326]
	TIME [epoch: 3.78 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16657253499499616		[learning rate: 0.0038109]
	Learning Rate: 0.00381088
	LOSS [training: 0.16657253499499616 | validation: 0.3269795581699843]
	TIME [epoch: 3.78 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14891260894907676		[learning rate: 0.0037929]
	Learning Rate: 0.00379293
	LOSS [training: 0.14891260894907676 | validation: 0.30499441307747316]
	TIME [epoch: 3.77 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18199573760504362		[learning rate: 0.0037751]
	Learning Rate: 0.00377505
	LOSS [training: 0.18199573760504362 | validation: 0.3341326694364119]
	TIME [epoch: 3.78 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1808902807385444		[learning rate: 0.0037573]
	Learning Rate: 0.00375726
	LOSS [training: 0.1808902807385444 | validation: 0.29823543115929574]
	TIME [epoch: 3.78 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15814322492141847		[learning rate: 0.0037396]
	Learning Rate: 0.00373956
	LOSS [training: 0.15814322492141847 | validation: 0.3357888195938721]
	TIME [epoch: 3.78 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16746959079315588		[learning rate: 0.0037219]
	Learning Rate: 0.00372194
	LOSS [training: 0.16746959079315588 | validation: 0.3807763159794315]
	TIME [epoch: 3.77 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15491340967084494		[learning rate: 0.0037044]
	Learning Rate: 0.0037044
	LOSS [training: 0.15491340967084494 | validation: 0.42795184131743996]
	TIME [epoch: 3.78 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14886821614469858		[learning rate: 0.0036869]
	Learning Rate: 0.00368695
	LOSS [training: 0.14886821614469858 | validation: 0.33066738860163214]
	TIME [epoch: 3.77 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15559624066429475		[learning rate: 0.0036696]
	Learning Rate: 0.00366957
	LOSS [training: 0.15559624066429475 | validation: 0.3351544328418792]
	TIME [epoch: 3.78 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16566484938873893		[learning rate: 0.0036523]
	Learning Rate: 0.00365228
	LOSS [training: 0.16566484938873893 | validation: 0.33295808377773445]
	TIME [epoch: 3.78 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16317991326510745		[learning rate: 0.0036351]
	Learning Rate: 0.00363507
	LOSS [training: 0.16317991326510745 | validation: 0.39001260567440577]
	TIME [epoch: 3.78 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18308330505436643		[learning rate: 0.0036179]
	Learning Rate: 0.00361794
	LOSS [training: 0.18308330505436643 | validation: 0.41391215261754327]
	TIME [epoch: 3.78 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1600050344348038		[learning rate: 0.0036009]
	Learning Rate: 0.00360089
	LOSS [training: 0.1600050344348038 | validation: 0.32899913663825703]
	TIME [epoch: 3.78 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15338443227760132		[learning rate: 0.0035839]
	Learning Rate: 0.00358393
	LOSS [training: 0.15338443227760132 | validation: 0.3013427308839986]
	TIME [epoch: 3.77 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17278273659062182		[learning rate: 0.003567]
	Learning Rate: 0.00356704
	LOSS [training: 0.17278273659062182 | validation: 0.41185296132077]
	TIME [epoch: 3.78 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18147942031015019		[learning rate: 0.0035502]
	Learning Rate: 0.00355023
	LOSS [training: 0.18147942031015019 | validation: 0.3078416843983317]
	TIME [epoch: 3.78 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14456128189855152		[learning rate: 0.0035335]
	Learning Rate: 0.0035335
	LOSS [training: 0.14456128189855152 | validation: 0.3105459425656406]
	TIME [epoch: 3.78 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14184382492823255		[learning rate: 0.0035168]
	Learning Rate: 0.00351685
	LOSS [training: 0.14184382492823255 | validation: 0.5272334178393984]
	TIME [epoch: 3.77 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17689078117122214		[learning rate: 0.0035003]
	Learning Rate: 0.00350028
	LOSS [training: 0.17689078117122214 | validation: 0.33695477495855525]
	TIME [epoch: 3.78 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17014705673078018		[learning rate: 0.0034838]
	Learning Rate: 0.00348378
	LOSS [training: 0.17014705673078018 | validation: 0.31051263413033875]
	TIME [epoch: 3.78 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14799993352686258		[learning rate: 0.0034674]
	Learning Rate: 0.00346737
	LOSS [training: 0.14799993352686258 | validation: 0.3537684669992695]
	TIME [epoch: 3.79 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1619318812600148		[learning rate: 0.003451]
	Learning Rate: 0.00345103
	LOSS [training: 0.1619318812600148 | validation: 0.33558994535260733]
	TIME [epoch: 3.78 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1552266249724346		[learning rate: 0.0034348]
	Learning Rate: 0.00343477
	LOSS [training: 0.1552266249724346 | validation: 0.334507700502756]
	TIME [epoch: 3.79 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18253409381500435		[learning rate: 0.0034186]
	Learning Rate: 0.00341858
	LOSS [training: 0.18253409381500435 | validation: 0.3500637791762044]
	TIME [epoch: 3.78 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1708585887795426		[learning rate: 0.0034025]
	Learning Rate: 0.00340247
	LOSS [training: 0.1708585887795426 | validation: 0.372874846013356]
	TIME [epoch: 3.79 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18370889286292214		[learning rate: 0.0033864]
	Learning Rate: 0.00338644
	LOSS [training: 0.18370889286292214 | validation: 0.3925540197094205]
	TIME [epoch: 3.78 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15689717155760108		[learning rate: 0.0033705]
	Learning Rate: 0.00337048
	LOSS [training: 0.15689717155760108 | validation: 0.32030566022853085]
	TIME [epoch: 3.79 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15999945048315214		[learning rate: 0.0033546]
	Learning Rate: 0.0033546
	LOSS [training: 0.15999945048315214 | validation: 0.3170667817028106]
	TIME [epoch: 3.78 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1365275519612401		[learning rate: 0.0033388]
	Learning Rate: 0.00333879
	LOSS [training: 0.1365275519612401 | validation: 0.3020684784426524]
	TIME [epoch: 3.79 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14655524404850648		[learning rate: 0.0033231]
	Learning Rate: 0.00332306
	LOSS [training: 0.14655524404850648 | validation: 0.29219850458622076]
	TIME [epoch: 3.77 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v7_20240715_175905/states/model_facs_v3_dec2b_2dpca_v7_271.pth
	Model improved!!!
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14668525463829124		[learning rate: 0.0033074]
	Learning Rate: 0.0033074
	LOSS [training: 0.14668525463829124 | validation: 0.3131593628870613]
	TIME [epoch: 3.79 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14737991070810935		[learning rate: 0.0032918]
	Learning Rate: 0.00329182
	LOSS [training: 0.14737991070810935 | validation: 0.2955052392858436]
	TIME [epoch: 3.78 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14859091564393304		[learning rate: 0.0032763]
	Learning Rate: 0.00327631
	LOSS [training: 0.14859091564393304 | validation: 0.3577667742236548]
	TIME [epoch: 3.8 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1515397020970488		[learning rate: 0.0032609]
	Learning Rate: 0.00326087
	LOSS [training: 0.1515397020970488 | validation: 0.32409042740215566]
	TIME [epoch: 3.78 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15689050934638224		[learning rate: 0.0032455]
	Learning Rate: 0.0032455
	LOSS [training: 0.15689050934638224 | validation: 0.3130060872649865]
	TIME [epoch: 3.79 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13481524918411492		[learning rate: 0.0032302]
	Learning Rate: 0.00323021
	LOSS [training: 0.13481524918411492 | validation: 0.3104452071837935]
	TIME [epoch: 3.78 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17073304554880353		[learning rate: 0.003215]
	Learning Rate: 0.00321499
	LOSS [training: 0.17073304554880353 | validation: 0.30982222910497725]
	TIME [epoch: 3.77 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17661631435954855		[learning rate: 0.0031998]
	Learning Rate: 0.00319984
	LOSS [training: 0.17661631435954855 | validation: 0.35279343853166245]
	TIME [epoch: 3.78 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17210390233369133		[learning rate: 0.0031848]
	Learning Rate: 0.00318476
	LOSS [training: 0.17210390233369133 | validation: 0.37418602850114413]
	TIME [epoch: 3.78 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15387258854494465		[learning rate: 0.0031698]
	Learning Rate: 0.00316975
	LOSS [training: 0.15387258854494465 | validation: 0.3637502563429912]
	TIME [epoch: 3.78 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14898992361999291		[learning rate: 0.0031548]
	Learning Rate: 0.00315482
	LOSS [training: 0.14898992361999291 | validation: 0.3644077033156234]
	TIME [epoch: 3.79 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17011895302547436		[learning rate: 0.00314]
	Learning Rate: 0.00313995
	LOSS [training: 0.17011895302547436 | validation: 0.3049751833388634]
	TIME [epoch: 3.77 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15693576303242107		[learning rate: 0.0031252]
	Learning Rate: 0.00312516
	LOSS [training: 0.15693576303242107 | validation: 0.3067096134645356]
	TIME [epoch: 3.79 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14383402004637602		[learning rate: 0.0031104]
	Learning Rate: 0.00311043
	LOSS [training: 0.14383402004637602 | validation: 0.3598673039409517]
	TIME [epoch: 3.79 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16613906783570123		[learning rate: 0.0030958]
	Learning Rate: 0.00309577
	LOSS [training: 0.16613906783570123 | validation: 0.31374827764177154]
	TIME [epoch: 3.78 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15216596490007053		[learning rate: 0.0030812]
	Learning Rate: 0.00308119
	LOSS [training: 0.15216596490007053 | validation: 0.31352470514011177]
	TIME [epoch: 3.79 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18891014588554023		[learning rate: 0.0030667]
	Learning Rate: 0.00306667
	LOSS [training: 0.18891014588554023 | validation: 0.40003163866878705]
	TIME [epoch: 3.78 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1806854388302065		[learning rate: 0.0030522]
	Learning Rate: 0.00305222
	LOSS [training: 0.1806854388302065 | validation: 0.322029635716974]
	TIME [epoch: 3.79 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13437746743724927		[learning rate: 0.0030378]
	Learning Rate: 0.00303783
	LOSS [training: 0.13437746743724927 | validation: 0.3153052381343249]
	TIME [epoch: 3.78 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17115502854171935		[learning rate: 0.0030235]
	Learning Rate: 0.00302352
	LOSS [training: 0.17115502854171935 | validation: 0.31773551123717697]
	TIME [epoch: 3.78 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14609719943683047		[learning rate: 0.0030093]
	Learning Rate: 0.00300927
	LOSS [training: 0.14609719943683047 | validation: 0.28739625971656096]
	TIME [epoch: 3.78 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v7_20240715_175905/states/model_facs_v3_dec2b_2dpca_v7_292.pth
	Model improved!!!
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.156138158783252		[learning rate: 0.0029951]
	Learning Rate: 0.00299509
	LOSS [training: 0.156138158783252 | validation: 0.3326902143939726]
	TIME [epoch: 3.77 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16059026485168143		[learning rate: 0.002981]
	Learning Rate: 0.00298098
	LOSS [training: 0.16059026485168143 | validation: 0.2944679179699902]
	TIME [epoch: 3.77 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16122099113127908		[learning rate: 0.0029669]
	Learning Rate: 0.00296693
	LOSS [training: 0.16122099113127908 | validation: 0.361536262542021]
	TIME [epoch: 3.76 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14005627150350564		[learning rate: 0.002953]
	Learning Rate: 0.00295295
	LOSS [training: 0.14005627150350564 | validation: 0.3385287724178336]
	TIME [epoch: 3.78 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16495617551937863		[learning rate: 0.002939]
	Learning Rate: 0.00293904
	LOSS [training: 0.16495617551937863 | validation: 0.31373552107488545]
	TIME [epoch: 3.78 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14642045292845204		[learning rate: 0.0029252]
	Learning Rate: 0.00292519
	LOSS [training: 0.14642045292845204 | validation: 0.3138597410465495]
	TIME [epoch: 3.76 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13495995518586745		[learning rate: 0.0029114]
	Learning Rate: 0.0029114
	LOSS [training: 0.13495995518586745 | validation: 0.31424933541398203]
	TIME [epoch: 3.77 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17212129658138445		[learning rate: 0.0028977]
	Learning Rate: 0.00289769
	LOSS [training: 0.17212129658138445 | validation: 0.36228931639386586]
	TIME [epoch: 3.78 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1540775552767851		[learning rate: 0.002884]
	Learning Rate: 0.00288403
	LOSS [training: 0.1540775552767851 | validation: 0.4222059841749224]
	TIME [epoch: 3.79 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16873723945676616		[learning rate: 0.0028704]
	Learning Rate: 0.00287044
	LOSS [training: 0.16873723945676616 | validation: 0.3787193701354182]
	TIME [epoch: 3.78 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16000130248542302		[learning rate: 0.0028569]
	Learning Rate: 0.00285692
	LOSS [training: 0.16000130248542302 | validation: 0.320299073667647]
	TIME [epoch: 3.78 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14049768915387642		[learning rate: 0.0028435]
	Learning Rate: 0.00284345
	LOSS [training: 0.14049768915387642 | validation: 0.33741037074321417]
	TIME [epoch: 3.78 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1381603753687072		[learning rate: 0.0028301]
	Learning Rate: 0.00283005
	LOSS [training: 0.1381603753687072 | validation: 0.33330839388499023]
	TIME [epoch: 3.78 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14564263343511916		[learning rate: 0.0028167]
	Learning Rate: 0.00281672
	LOSS [training: 0.14564263343511916 | validation: 0.34002739985143493]
	TIME [epoch: 3.78 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1438716328006714		[learning rate: 0.0028034]
	Learning Rate: 0.00280345
	LOSS [training: 0.1438716328006714 | validation: 0.3374559518122964]
	TIME [epoch: 3.78 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1548243625404755		[learning rate: 0.0027902]
	Learning Rate: 0.00279024
	LOSS [training: 0.1548243625404755 | validation: 0.3152106252525579]
	TIME [epoch: 3.79 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17690476711043818		[learning rate: 0.0027771]
	Learning Rate: 0.00277709
	LOSS [training: 0.17690476711043818 | validation: 0.29834771882223865]
	TIME [epoch: 3.78 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16770673076810058		[learning rate: 0.002764]
	Learning Rate: 0.002764
	LOSS [training: 0.16770673076810058 | validation: 0.3049379637116495]
	TIME [epoch: 3.79 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13332678428614939		[learning rate: 0.002751]
	Learning Rate: 0.00275098
	LOSS [training: 0.13332678428614939 | validation: 0.32241263227847455]
	TIME [epoch: 3.78 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15462004866609122		[learning rate: 0.002738]
	Learning Rate: 0.00273802
	LOSS [training: 0.15462004866609122 | validation: 0.34875296091679425]
	TIME [epoch: 3.78 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1514805712966114		[learning rate: 0.0027251]
	Learning Rate: 0.00272511
	LOSS [training: 0.1514805712966114 | validation: 0.30869327875027686]
	TIME [epoch: 3.78 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1681044925583462		[learning rate: 0.0027123]
	Learning Rate: 0.00271227
	LOSS [training: 0.1681044925583462 | validation: 0.3272447319102022]
	TIME [epoch: 3.78 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15405711604189065		[learning rate: 0.0026995]
	Learning Rate: 0.00269949
	LOSS [training: 0.15405711604189065 | validation: 0.28965097993036093]
	TIME [epoch: 3.78 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16865512192372384		[learning rate: 0.0026868]
	Learning Rate: 0.00268677
	LOSS [training: 0.16865512192372384 | validation: 0.3157206129596744]
	TIME [epoch: 3.79 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1322308316891334		[learning rate: 0.0026741]
	Learning Rate: 0.00267411
	LOSS [training: 0.1322308316891334 | validation: 0.2980625632587578]
	TIME [epoch: 3.78 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14583886298127047		[learning rate: 0.0026615]
	Learning Rate: 0.00266151
	LOSS [training: 0.14583886298127047 | validation: 0.3098372912681667]
	TIME [epoch: 3.79 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15990686262013137		[learning rate: 0.002649]
	Learning Rate: 0.00264897
	LOSS [training: 0.15990686262013137 | validation: 0.3220278157210865]
	TIME [epoch: 3.78 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13957563276559662		[learning rate: 0.0026365]
	Learning Rate: 0.00263649
	LOSS [training: 0.13957563276559662 | validation: 0.2968392797981028]
	TIME [epoch: 3.8 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14167370682700187		[learning rate: 0.0026241]
	Learning Rate: 0.00262406
	LOSS [training: 0.14167370682700187 | validation: 0.30930014734650124]
	TIME [epoch: 3.78 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16982500830126698		[learning rate: 0.0026117]
	Learning Rate: 0.0026117
	LOSS [training: 0.16982500830126698 | validation: 0.39565944809151504]
	TIME [epoch: 3.79 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15248310511827637		[learning rate: 0.0025994]
	Learning Rate: 0.00259939
	LOSS [training: 0.15248310511827637 | validation: 0.3495731987563745]
	TIME [epoch: 3.78 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13229556490148794		[learning rate: 0.0025871]
	Learning Rate: 0.00258714
	LOSS [training: 0.13229556490148794 | validation: 0.34340915595649124]
	TIME [epoch: 3.79 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1600399340854414		[learning rate: 0.002575]
	Learning Rate: 0.00257495
	LOSS [training: 0.1600399340854414 | validation: 0.3137726811960854]
	TIME [epoch: 3.78 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14979448961533479		[learning rate: 0.0025628]
	Learning Rate: 0.00256282
	LOSS [training: 0.14979448961533479 | validation: 0.3120863720063553]
	TIME [epoch: 3.79 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16140620768951244		[learning rate: 0.0025507]
	Learning Rate: 0.00255074
	LOSS [training: 0.16140620768951244 | validation: 0.3373858664826713]
	TIME [epoch: 3.78 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12929246915904416		[learning rate: 0.0025387]
	Learning Rate: 0.00253872
	LOSS [training: 0.12929246915904416 | validation: 0.30522199222628477]
	TIME [epoch: 3.78 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1619619276284779		[learning rate: 0.0025268]
	Learning Rate: 0.00252676
	LOSS [training: 0.1619619276284779 | validation: 0.3146182149973147]
	TIME [epoch: 3.78 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16313020275828352		[learning rate: 0.0025149]
	Learning Rate: 0.00251485
	LOSS [training: 0.16313020275828352 | validation: 0.3637230888352823]
	TIME [epoch: 3.78 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1685052971081122		[learning rate: 0.002503]
	Learning Rate: 0.002503
	LOSS [training: 0.1685052971081122 | validation: 0.2973405312045086]
	TIME [epoch: 3.78 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12206554978746437		[learning rate: 0.0024912]
	Learning Rate: 0.00249121
	LOSS [training: 0.12206554978746437 | validation: 0.2936280918523622]
	TIME [epoch: 3.79 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12465137433572929		[learning rate: 0.0024795]
	Learning Rate: 0.00247947
	LOSS [training: 0.12465137433572929 | validation: 0.3262222463744279]
	TIME [epoch: 3.78 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14623803104666933		[learning rate: 0.0024678]
	Learning Rate: 0.00246779
	LOSS [training: 0.14623803104666933 | validation: 0.29932112871632544]
	TIME [epoch: 3.79 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13868771163294785		[learning rate: 0.0024562]
	Learning Rate: 0.00245616
	LOSS [training: 0.13868771163294785 | validation: 0.3144211124532736]
	TIME [epoch: 3.78 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1449031638430756		[learning rate: 0.0024446]
	Learning Rate: 0.00244458
	LOSS [training: 0.1449031638430756 | validation: 0.33094905976548955]
	TIME [epoch: 3.78 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1701896747494471		[learning rate: 0.0024331]
	Learning Rate: 0.00243307
	LOSS [training: 0.1701896747494471 | validation: 0.34985412332436905]
	TIME [epoch: 3.78 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16257947647784515		[learning rate: 0.0024216]
	Learning Rate: 0.0024216
	LOSS [training: 0.16257947647784515 | validation: 0.30504453768022666]
	TIME [epoch: 3.82 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13772213279251935		[learning rate: 0.0024102]
	Learning Rate: 0.00241019
	LOSS [training: 0.13772213279251935 | validation: 0.30753704826491773]
	TIME [epoch: 3.78 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16002384965145164		[learning rate: 0.0023988]
	Learning Rate: 0.00239883
	LOSS [training: 0.16002384965145164 | validation: 0.35592385794728437]
	TIME [epoch: 3.79 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15494449186805181		[learning rate: 0.0023875]
	Learning Rate: 0.00238753
	LOSS [training: 0.15494449186805181 | validation: 0.3227352167208026]
	TIME [epoch: 3.78 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1573946928899697		[learning rate: 0.0023763]
	Learning Rate: 0.00237628
	LOSS [training: 0.1573946928899697 | validation: 0.2805383484791931]
	TIME [epoch: 3.79 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v7_20240715_175905/states/model_facs_v3_dec2b_2dpca_v7_342.pth
	Model improved!!!
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14689238978949812		[learning rate: 0.0023651]
	Learning Rate: 0.00236508
	LOSS [training: 0.14689238978949812 | validation: 0.3147545221319272]
	TIME [epoch: 3.78 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13272011445433027		[learning rate: 0.0023539]
	Learning Rate: 0.00235394
	LOSS [training: 0.13272011445433027 | validation: 0.35896995399722]
	TIME [epoch: 3.8 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13926639579674718		[learning rate: 0.0023428]
	Learning Rate: 0.00234285
	LOSS [training: 0.13926639579674718 | validation: 0.29070610899293103]
	TIME [epoch: 3.78 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.132078564747288		[learning rate: 0.0023318]
	Learning Rate: 0.00233181
	LOSS [training: 0.132078564747288 | validation: 0.3207301874307666]
	TIME [epoch: 3.79 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16575703801339603		[learning rate: 0.0023208]
	Learning Rate: 0.00232082
	LOSS [training: 0.16575703801339603 | validation: 0.3329359182387514]
	TIME [epoch: 3.79 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16764983214245913		[learning rate: 0.0023099]
	Learning Rate: 0.00230988
	LOSS [training: 0.16764983214245913 | validation: 0.3157574870002047]
	TIME [epoch: 3.78 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1443662535993259		[learning rate: 0.002299]
	Learning Rate: 0.002299
	LOSS [training: 0.1443662535993259 | validation: 0.34780650352438225]
	TIME [epoch: 3.78 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1566687285119407		[learning rate: 0.0022882]
	Learning Rate: 0.00228816
	LOSS [training: 0.1566687285119407 | validation: 0.28453580566807757]
	TIME [epoch: 3.79 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.147113135525471		[learning rate: 0.0022774]
	Learning Rate: 0.00227738
	LOSS [training: 0.147113135525471 | validation: 0.2929280533816305]
	TIME [epoch: 3.79 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14219539313856755		[learning rate: 0.0022667]
	Learning Rate: 0.00226665
	LOSS [training: 0.14219539313856755 | validation: 0.3028290298694406]
	TIME [epoch: 3.79 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14069853826699125		[learning rate: 0.002256]
	Learning Rate: 0.00225597
	LOSS [training: 0.14069853826699125 | validation: 0.2929722748686394]
	TIME [epoch: 3.78 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1608927024954749		[learning rate: 0.0022453]
	Learning Rate: 0.00224534
	LOSS [training: 0.1608927024954749 | validation: 0.3058639293809516]
	TIME [epoch: 3.79 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16213071904231036		[learning rate: 0.0022348]
	Learning Rate: 0.00223476
	LOSS [training: 0.16213071904231036 | validation: 0.310654309328255]
	TIME [epoch: 3.78 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16936563483327288		[learning rate: 0.0022242]
	Learning Rate: 0.00222423
	LOSS [training: 0.16936563483327288 | validation: 0.31927892257941676]
	TIME [epoch: 3.8 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1530653315577048		[learning rate: 0.0022137]
	Learning Rate: 0.00221375
	LOSS [training: 0.1530653315577048 | validation: 0.3037583722527083]
	TIME [epoch: 3.77 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14902644759303788		[learning rate: 0.0022033]
	Learning Rate: 0.00220332
	LOSS [training: 0.14902644759303788 | validation: 0.3010529235766734]
	TIME [epoch: 3.79 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12099026974143423		[learning rate: 0.0021929]
	Learning Rate: 0.00219293
	LOSS [training: 0.12099026974143423 | validation: 0.310206703482148]
	TIME [epoch: 3.78 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15156773866158085		[learning rate: 0.0021826]
	Learning Rate: 0.0021826
	LOSS [training: 0.15156773866158085 | validation: 0.31538730952140903]
	TIME [epoch: 3.77 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14374431056514195		[learning rate: 0.0021723]
	Learning Rate: 0.00217232
	LOSS [training: 0.14374431056514195 | validation: 0.3313474291426181]
	TIME [epoch: 3.8 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1569054142693158		[learning rate: 0.0021621]
	Learning Rate: 0.00216208
	LOSS [training: 0.1569054142693158 | validation: 0.313111910043435]
	TIME [epoch: 3.79 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17479308604596988		[learning rate: 0.0021519]
	Learning Rate: 0.00215189
	LOSS [training: 0.17479308604596988 | validation: 0.29060749732033203]
	TIME [epoch: 3.79 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14252392116637042		[learning rate: 0.0021418]
	Learning Rate: 0.00214175
	LOSS [training: 0.14252392116637042 | validation: 0.3081774038960845]
	TIME [epoch: 3.79 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16173452974322242		[learning rate: 0.0021317]
	Learning Rate: 0.00213166
	LOSS [training: 0.16173452974322242 | validation: 0.3312651153635727]
	TIME [epoch: 3.78 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1340600245227631		[learning rate: 0.0021216]
	Learning Rate: 0.00212162
	LOSS [training: 0.1340600245227631 | validation: 0.30183198328692035]
	TIME [epoch: 3.78 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14365692609934247		[learning rate: 0.0021116]
	Learning Rate: 0.00211162
	LOSS [training: 0.14365692609934247 | validation: 0.34094219510614004]
	TIME [epoch: 3.78 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13654278532848105		[learning rate: 0.0021017]
	Learning Rate: 0.00210167
	LOSS [training: 0.13654278532848105 | validation: 0.3024724552909024]
	TIME [epoch: 3.8 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13753246652896578		[learning rate: 0.0020918]
	Learning Rate: 0.00209176
	LOSS [training: 0.13753246652896578 | validation: 0.30913461743846077]
	TIME [epoch: 3.79 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13042459742651857		[learning rate: 0.0020819]
	Learning Rate: 0.00208191
	LOSS [training: 0.13042459742651857 | validation: 0.31990595925763904]
	TIME [epoch: 3.78 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14287377147702568		[learning rate: 0.0020721]
	Learning Rate: 0.0020721
	LOSS [training: 0.14287377147702568 | validation: 0.35642168109693606]
	TIME [epoch: 3.79 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13987858613862159		[learning rate: 0.0020623]
	Learning Rate: 0.00206233
	LOSS [training: 0.13987858613862159 | validation: 0.3112068792449159]
	TIME [epoch: 3.79 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16812151323347924		[learning rate: 0.0020526]
	Learning Rate: 0.00205262
	LOSS [training: 0.16812151323347924 | validation: 0.31544920781375124]
	TIME [epoch: 3.78 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15392168139913462		[learning rate: 0.0020429]
	Learning Rate: 0.00204294
	LOSS [training: 0.15392168139913462 | validation: 0.3367709197929724]
	TIME [epoch: 3.78 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13964237354283413		[learning rate: 0.0020333]
	Learning Rate: 0.00203332
	LOSS [training: 0.13964237354283413 | validation: 0.31943145649040827]
	TIME [epoch: 3.79 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13697859121283837		[learning rate: 0.0020237]
	Learning Rate: 0.00202374
	LOSS [training: 0.13697859121283837 | validation: 0.2985979449697205]
	TIME [epoch: 3.78 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1514942554931166		[learning rate: 0.0020142]
	Learning Rate: 0.0020142
	LOSS [training: 0.1514942554931166 | validation: 0.3018143890207649]
	TIME [epoch: 3.79 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13443671710823493		[learning rate: 0.0020047]
	Learning Rate: 0.00200471
	LOSS [training: 0.13443671710823493 | validation: 0.31386264182761153]
	TIME [epoch: 3.78 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15938001059902565		[learning rate: 0.0019953]
	Learning Rate: 0.00199526
	LOSS [training: 0.15938001059902565 | validation: 0.2940463367578628]
	TIME [epoch: 3.79 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14415566468625302		[learning rate: 0.0019859]
	Learning Rate: 0.00198586
	LOSS [training: 0.14415566468625302 | validation: 0.3375846007577723]
	TIME [epoch: 3.79 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14817627918474907		[learning rate: 0.0019765]
	Learning Rate: 0.0019765
	LOSS [training: 0.14817627918474907 | validation: 0.3306130459998]
	TIME [epoch: 3.78 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1461136145367592		[learning rate: 0.0019672]
	Learning Rate: 0.00196719
	LOSS [training: 0.1461136145367592 | validation: 0.29985841403507]
	TIME [epoch: 3.78 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14083636701492486		[learning rate: 0.0019579]
	Learning Rate: 0.00195792
	LOSS [training: 0.14083636701492486 | validation: 0.31054860452636424]
	TIME [epoch: 3.78 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13693300631913932		[learning rate: 0.0019487]
	Learning Rate: 0.00194869
	LOSS [training: 0.13693300631913932 | validation: 0.3854403519846186]
	TIME [epoch: 3.78 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1611941480665075		[learning rate: 0.0019395]
	Learning Rate: 0.00193951
	LOSS [training: 0.1611941480665075 | validation: 0.3212463326030987]
	TIME [epoch: 3.77 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15404314224268623		[learning rate: 0.0019304]
	Learning Rate: 0.00193037
	LOSS [training: 0.15404314224268623 | validation: 0.3011213617045435]
	TIME [epoch: 3.78 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15479383703883026		[learning rate: 0.0019213]
	Learning Rate: 0.00192128
	LOSS [training: 0.15479383703883026 | validation: 0.3134268362579237]
	TIME [epoch: 3.79 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13439408984582735		[learning rate: 0.0019122]
	Learning Rate: 0.00191222
	LOSS [training: 0.13439408984582735 | validation: 0.37833495214691465]
	TIME [epoch: 3.8 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15070151741871973		[learning rate: 0.0019032]
	Learning Rate: 0.00190321
	LOSS [training: 0.15070151741871973 | validation: 0.3024387712205753]
	TIME [epoch: 3.79 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15068720596777957		[learning rate: 0.0018942]
	Learning Rate: 0.00189424
	LOSS [training: 0.15068720596777957 | validation: 0.3315149292592812]
	TIME [epoch: 3.78 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1627842668939915		[learning rate: 0.0018853]
	Learning Rate: 0.00188532
	LOSS [training: 0.1627842668939915 | validation: 0.2949314713254685]
	TIME [epoch: 3.79 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14814572713432533		[learning rate: 0.0018764]
	Learning Rate: 0.00187643
	LOSS [training: 0.14814572713432533 | validation: 0.32934092471819426]
	TIME [epoch: 3.79 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16260409596394493		[learning rate: 0.0018676]
	Learning Rate: 0.00186759
	LOSS [training: 0.16260409596394493 | validation: 0.3335967059925796]
	TIME [epoch: 3.78 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14132213079970082		[learning rate: 0.0018588]
	Learning Rate: 0.00185879
	LOSS [training: 0.14132213079970082 | validation: 0.34698354450107294]
	TIME [epoch: 3.78 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13994327022544328		[learning rate: 0.00185]
	Learning Rate: 0.00185003
	LOSS [training: 0.13994327022544328 | validation: 0.28268114839998576]
	TIME [epoch: 3.78 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12844518155872026		[learning rate: 0.0018413]
	Learning Rate: 0.00184132
	LOSS [training: 0.12844518155872026 | validation: 0.3029962863059432]
	TIME [epoch: 3.78 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16861236159609191		[learning rate: 0.0018326]
	Learning Rate: 0.00183264
	LOSS [training: 0.16861236159609191 | validation: 0.32413691798558775]
	TIME [epoch: 3.78 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1396724129977651		[learning rate: 0.001824]
	Learning Rate: 0.001824
	LOSS [training: 0.1396724129977651 | validation: 0.295053168941556]
	TIME [epoch: 3.79 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1536799752171716		[learning rate: 0.0018154]
	Learning Rate: 0.00181541
	LOSS [training: 0.1536799752171716 | validation: 0.31731762241393235]
	TIME [epoch: 3.78 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14610793241434672		[learning rate: 0.0018069]
	Learning Rate: 0.00180685
	LOSS [training: 0.14610793241434672 | validation: 0.31295661992123563]
	TIME [epoch: 3.77 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1347400452533461		[learning rate: 0.0017983]
	Learning Rate: 0.00179834
	LOSS [training: 0.1347400452533461 | validation: 0.28735577852020144]
	TIME [epoch: 3.77 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13394750575894326		[learning rate: 0.0017899]
	Learning Rate: 0.00178987
	LOSS [training: 0.13394750575894326 | validation: 0.29592944707697044]
	TIME [epoch: 3.78 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1263565242991283		[learning rate: 0.0017814]
	Learning Rate: 0.00178143
	LOSS [training: 0.1263565242991283 | validation: 0.29810548143397375]
	TIME [epoch: 3.77 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14661516878215883		[learning rate: 0.001773]
	Learning Rate: 0.00177304
	LOSS [training: 0.14661516878215883 | validation: 0.30525375938083055]
	TIME [epoch: 3.79 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1494496446372621		[learning rate: 0.0017647]
	Learning Rate: 0.00176468
	LOSS [training: 0.1494496446372621 | validation: 0.31954900309309775]
	TIME [epoch: 3.78 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15150861088391307		[learning rate: 0.0017564]
	Learning Rate: 0.00175637
	LOSS [training: 0.15150861088391307 | validation: 0.30905241057089106]
	TIME [epoch: 3.77 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12666857359643205		[learning rate: 0.0017481]
	Learning Rate: 0.00174809
	LOSS [training: 0.12666857359643205 | validation: 0.31295523661265573]
	TIME [epoch: 3.77 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1641017327529361		[learning rate: 0.0017399]
	Learning Rate: 0.00173985
	LOSS [training: 0.1641017327529361 | validation: 0.34310141362404656]
	TIME [epoch: 3.77 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13164213898026775		[learning rate: 0.0017317]
	Learning Rate: 0.00173166
	LOSS [training: 0.13164213898026775 | validation: 0.3152224592433146]
	TIME [epoch: 3.78 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13109979387454956		[learning rate: 0.0017235]
	Learning Rate: 0.0017235
	LOSS [training: 0.13109979387454956 | validation: 0.2834874221129371]
	TIME [epoch: 3.77 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14325187898648886		[learning rate: 0.0017154]
	Learning Rate: 0.00171537
	LOSS [training: 0.14325187898648886 | validation: 0.29378393513862605]
	TIME [epoch: 3.77 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1365120607949769		[learning rate: 0.0017073]
	Learning Rate: 0.00170729
	LOSS [training: 0.1365120607949769 | validation: 0.2904379676188]
	TIME [epoch: 3.77 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1449842063916198		[learning rate: 0.0016992]
	Learning Rate: 0.00169925
	LOSS [training: 0.1449842063916198 | validation: 0.3309703914604186]
	TIME [epoch: 3.78 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14732216771670456		[learning rate: 0.0016912]
	Learning Rate: 0.00169124
	LOSS [training: 0.14732216771670456 | validation: 0.3030160706841095]
	TIME [epoch: 3.77 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13862994309949142		[learning rate: 0.0016833]
	Learning Rate: 0.00168327
	LOSS [training: 0.13862994309949142 | validation: 0.30013633004400164]
	TIME [epoch: 3.78 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13137775078666863		[learning rate: 0.0016753]
	Learning Rate: 0.00167534
	LOSS [training: 0.13137775078666863 | validation: 0.2903621532301789]
	TIME [epoch: 3.79 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14311558517510636		[learning rate: 0.0016674]
	Learning Rate: 0.00166744
	LOSS [training: 0.14311558517510636 | validation: 0.2929213364453675]
	TIME [epoch: 3.8 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12652132379481423		[learning rate: 0.0016596]
	Learning Rate: 0.00165959
	LOSS [training: 0.12652132379481423 | validation: 0.29708347756763814]
	TIME [epoch: 3.78 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13782356619912847		[learning rate: 0.0016518]
	Learning Rate: 0.00165177
	LOSS [training: 0.13782356619912847 | validation: 0.2920065294899135]
	TIME [epoch: 3.77 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15334331211403857		[learning rate: 0.001644]
	Learning Rate: 0.00164398
	LOSS [training: 0.15334331211403857 | validation: 0.2924872545382907]
	TIME [epoch: 3.77 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14489202958310443		[learning rate: 0.0016362]
	Learning Rate: 0.00163624
	LOSS [training: 0.14489202958310443 | validation: 0.3201054093714067]
	TIME [epoch: 3.78 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15231595375630422		[learning rate: 0.0016285]
	Learning Rate: 0.00162853
	LOSS [training: 0.15231595375630422 | validation: 0.2845137598070081]
	TIME [epoch: 3.77 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.145690633643993		[learning rate: 0.0016209]
	Learning Rate: 0.00162085
	LOSS [training: 0.145690633643993 | validation: 0.3307156307649257]
	TIME [epoch: 3.78 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13592957322737576		[learning rate: 0.0016132]
	Learning Rate: 0.00161322
	LOSS [training: 0.13592957322737576 | validation: 0.2941684433542299]
	TIME [epoch: 3.77 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1411149956237823		[learning rate: 0.0016056]
	Learning Rate: 0.00160561
	LOSS [training: 0.1411149956237823 | validation: 0.2986626048244573]
	TIME [epoch: 3.78 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1480737529243137		[learning rate: 0.001598]
	Learning Rate: 0.00159805
	LOSS [training: 0.1480737529243137 | validation: 0.32404343731549184]
	TIME [epoch: 3.78 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14041465058851588		[learning rate: 0.0015905]
	Learning Rate: 0.00159052
	LOSS [training: 0.14041465058851588 | validation: 0.30012510066375486]
	TIME [epoch: 3.79 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14563419384747817		[learning rate: 0.001583]
	Learning Rate: 0.00158302
	LOSS [training: 0.14563419384747817 | validation: 0.33780150444104073]
	TIME [epoch: 3.78 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14683865750043731		[learning rate: 0.0015756]
	Learning Rate: 0.00157556
	LOSS [training: 0.14683865750043731 | validation: 0.29339394989029427]
	TIME [epoch: 3.77 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13932809623739623		[learning rate: 0.0015681]
	Learning Rate: 0.00156814
	LOSS [training: 0.13932809623739623 | validation: 0.29183164019273833]
	TIME [epoch: 3.79 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13739487142933016		[learning rate: 0.0015607]
	Learning Rate: 0.00156075
	LOSS [training: 0.13739487142933016 | validation: 0.3061895203359437]
	TIME [epoch: 3.78 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16298113177118528		[learning rate: 0.0015534]
	Learning Rate: 0.0015534
	LOSS [training: 0.16298113177118528 | validation: 0.2896533725817269]
	TIME [epoch: 3.78 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12208261363646182		[learning rate: 0.0015461]
	Learning Rate: 0.00154608
	LOSS [training: 0.12208261363646182 | validation: 0.33765486095316727]
	TIME [epoch: 3.77 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15122081573900953		[learning rate: 0.0015388]
	Learning Rate: 0.00153879
	LOSS [training: 0.15122081573900953 | validation: 0.29812518798245885]
	TIME [epoch: 3.78 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13058938607034642		[learning rate: 0.0015315]
	Learning Rate: 0.00153154
	LOSS [training: 0.13058938607034642 | validation: 0.2891305064478655]
	TIME [epoch: 3.78 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13426148532937063		[learning rate: 0.0015243]
	Learning Rate: 0.00152432
	LOSS [training: 0.13426148532937063 | validation: 0.298638748439332]
	TIME [epoch: 3.78 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15271324720437565		[learning rate: 0.0015171]
	Learning Rate: 0.00151714
	LOSS [training: 0.15271324720437565 | validation: 0.2980411845632038]
	TIME [epoch: 3.77 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13935916316771146		[learning rate: 0.00151]
	Learning Rate: 0.00150999
	LOSS [training: 0.13935916316771146 | validation: 0.32183530547045364]
	TIME [epoch: 3.8 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12771379866579718		[learning rate: 0.0015029]
	Learning Rate: 0.00150288
	LOSS [training: 0.12771379866579718 | validation: 0.3937160602607419]
	TIME [epoch: 3.77 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14702783146882892		[learning rate: 0.0014958]
	Learning Rate: 0.00149579
	LOSS [training: 0.14702783146882892 | validation: 0.3093976156213547]
	TIME [epoch: 3.79 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16225982358087138		[learning rate: 0.0014887]
	Learning Rate: 0.00148875
	LOSS [training: 0.16225982358087138 | validation: 0.3184494063719014]
	TIME [epoch: 3.77 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14060678526320988		[learning rate: 0.0014817]
	Learning Rate: 0.00148173
	LOSS [training: 0.14060678526320988 | validation: 0.3072599693719743]
	TIME [epoch: 3.79 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14112500780884055		[learning rate: 0.0014747]
	Learning Rate: 0.00147475
	LOSS [training: 0.14112500780884055 | validation: 0.2935452806125206]
	TIME [epoch: 3.77 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16050385921696103		[learning rate: 0.0014678]
	Learning Rate: 0.0014678
	LOSS [training: 0.16050385921696103 | validation: 0.371692410089107]
	TIME [epoch: 3.78 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14657448928390457		[learning rate: 0.0014609]
	Learning Rate: 0.00146088
	LOSS [training: 0.14657448928390457 | validation: 0.2810802764714332]
	TIME [epoch: 3.78 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1371937026348269		[learning rate: 0.001454]
	Learning Rate: 0.001454
	LOSS [training: 0.1371937026348269 | validation: 0.3221996334072794]
	TIME [epoch: 3.8 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12591433217176648		[learning rate: 0.0014471]
	Learning Rate: 0.00144715
	LOSS [training: 0.12591433217176648 | validation: 0.287106909048407]
	TIME [epoch: 3.78 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15269111454708115		[learning rate: 0.0014403]
	Learning Rate: 0.00144033
	LOSS [training: 0.15269111454708115 | validation: 0.3005008404875824]
	TIME [epoch: 3.79 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15273320156995404		[learning rate: 0.0014335]
	Learning Rate: 0.00143354
	LOSS [training: 0.15273320156995404 | validation: 0.31221906163478863]
	TIME [epoch: 3.79 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1329386859675804		[learning rate: 0.0014268]
	Learning Rate: 0.00142679
	LOSS [training: 0.1329386859675804 | validation: 0.3252161514320747]
	TIME [epoch: 3.79 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15292624052102827		[learning rate: 0.0014201]
	Learning Rate: 0.00142006
	LOSS [training: 0.15292624052102827 | validation: 0.29623970259886184]
	TIME [epoch: 3.79 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13732621680047177		[learning rate: 0.0014134]
	Learning Rate: 0.00141337
	LOSS [training: 0.13732621680047177 | validation: 0.3137946119778796]
	TIME [epoch: 3.79 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1355607385428159		[learning rate: 0.0014067]
	Learning Rate: 0.00140671
	LOSS [training: 0.1355607385428159 | validation: 0.31648574369208177]
	TIME [epoch: 3.78 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15119471749445462		[learning rate: 0.0014001]
	Learning Rate: 0.00140008
	LOSS [training: 0.15119471749445462 | validation: 0.2973207406293094]
	TIME [epoch: 3.79 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17197985840338198		[learning rate: 0.0013935]
	Learning Rate: 0.00139349
	LOSS [training: 0.17197985840338198 | validation: 0.32265785526653984]
	TIME [epoch: 3.78 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15014278489544725		[learning rate: 0.0013869]
	Learning Rate: 0.00138692
	LOSS [training: 0.15014278489544725 | validation: 0.2985126119413926]
	TIME [epoch: 3.78 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1407528089223516		[learning rate: 0.0013804]
	Learning Rate: 0.00138038
	LOSS [training: 0.1407528089223516 | validation: 0.28483990881241966]
	TIME [epoch: 3.78 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14023826726338945		[learning rate: 0.0013739]
	Learning Rate: 0.00137388
	LOSS [training: 0.14023826726338945 | validation: 0.3255861355808351]
	TIME [epoch: 3.8 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12234192795645488		[learning rate: 0.0013674]
	Learning Rate: 0.00136741
	LOSS [training: 0.12234192795645488 | validation: 0.2826906933377945]
	TIME [epoch: 3.78 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13186833957153277		[learning rate: 0.001361]
	Learning Rate: 0.00136096
	LOSS [training: 0.13186833957153277 | validation: 0.32302630388658987]
	TIME [epoch: 3.79 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14684377854391995		[learning rate: 0.0013545]
	Learning Rate: 0.00135455
	LOSS [training: 0.14684377854391995 | validation: 0.2990753935744937]
	TIME [epoch: 3.78 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12845945534941758		[learning rate: 0.0013482]
	Learning Rate: 0.00134817
	LOSS [training: 0.12845945534941758 | validation: 0.30467912942221814]
	TIME [epoch: 3.79 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15216017539702087		[learning rate: 0.0013418]
	Learning Rate: 0.00134181
	LOSS [training: 0.15216017539702087 | validation: 0.3560492663262038]
	TIME [epoch: 3.78 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12406319501679253		[learning rate: 0.0013355]
	Learning Rate: 0.00133549
	LOSS [training: 0.12406319501679253 | validation: 0.30454148030294853]
	TIME [epoch: 3.79 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1460544167189179		[learning rate: 0.0013292]
	Learning Rate: 0.0013292
	LOSS [training: 0.1460544167189179 | validation: 0.31313895015208487]
	TIME [epoch: 3.78 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12803415727766104		[learning rate: 0.0013229]
	Learning Rate: 0.00132293
	LOSS [training: 0.12803415727766104 | validation: 0.28465210545225583]
	TIME [epoch: 3.79 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13269771429758712		[learning rate: 0.0013167]
	Learning Rate: 0.0013167
	LOSS [training: 0.13269771429758712 | validation: 0.32278078671169275]
	TIME [epoch: 3.78 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13665341619284804		[learning rate: 0.0013105]
	Learning Rate: 0.0013105
	LOSS [training: 0.13665341619284804 | validation: 0.29674841047809647]
	TIME [epoch: 3.78 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1308379981146247		[learning rate: 0.0013043]
	Learning Rate: 0.00130432
	LOSS [training: 0.1308379981146247 | validation: 0.31493717246771047]
	TIME [epoch: 3.78 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13409615464668279		[learning rate: 0.0012982]
	Learning Rate: 0.00129818
	LOSS [training: 0.13409615464668279 | validation: 0.2941970516836618]
	TIME [epoch: 3.78 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13900210916681693		[learning rate: 0.0012921]
	Learning Rate: 0.00129206
	LOSS [training: 0.13900210916681693 | validation: 0.2804510637649221]
	TIME [epoch: 3.79 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v7_20240715_175905/states/model_facs_v3_dec2b_2dpca_v7_471.pth
	Model improved!!!
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12681257433750104		[learning rate: 0.001286]
	Learning Rate: 0.00128597
	LOSS [training: 0.12681257433750104 | validation: 0.3011625998361632]
	TIME [epoch: 3.78 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13510369688586643		[learning rate: 0.0012799]
	Learning Rate: 0.00127991
	LOSS [training: 0.13510369688586643 | validation: 0.29375584912733493]
	TIME [epoch: 3.78 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15208906306503966		[learning rate: 0.0012739]
	Learning Rate: 0.00127388
	LOSS [training: 0.15208906306503966 | validation: 0.29522361104247696]
	TIME [epoch: 3.79 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13960534460747653		[learning rate: 0.0012679]
	Learning Rate: 0.00126788
	LOSS [training: 0.13960534460747653 | validation: 0.30299579712137736]
	TIME [epoch: 3.79 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13313672437591564		[learning rate: 0.0012619]
	Learning Rate: 0.0012619
	LOSS [training: 0.13313672437591564 | validation: 0.31984607876771237]
	TIME [epoch: 3.79 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14066859690807149		[learning rate: 0.001256]
	Learning Rate: 0.00125596
	LOSS [training: 0.14066859690807149 | validation: 0.2892973971506562]
	TIME [epoch: 3.78 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.151612523744746		[learning rate: 0.00125]
	Learning Rate: 0.00125004
	LOSS [training: 0.151612523744746 | validation: 0.3176479619345291]
	TIME [epoch: 3.78 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15260896491172063		[learning rate: 0.0012441]
	Learning Rate: 0.00124415
	LOSS [training: 0.15260896491172063 | validation: 0.30198774770500775]
	TIME [epoch: 3.77 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14591311269614937		[learning rate: 0.0012383]
	Learning Rate: 0.00123828
	LOSS [training: 0.14591311269614937 | validation: 0.3069177815033733]
	TIME [epoch: 3.79 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13871216757981636		[learning rate: 0.0012324]
	Learning Rate: 0.00123245
	LOSS [training: 0.13871216757981636 | validation: 0.2989059557496822]
	TIME [epoch: 3.79 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13857318226564075		[learning rate: 0.0012266]
	Learning Rate: 0.00122664
	LOSS [training: 0.13857318226564075 | validation: 0.28390599405965783]
	TIME [epoch: 3.78 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1318962317264556		[learning rate: 0.0012209]
	Learning Rate: 0.00122086
	LOSS [training: 0.1318962317264556 | validation: 0.29788675051141]
	TIME [epoch: 3.79 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1528721879965484		[learning rate: 0.0012151]
	Learning Rate: 0.00121511
	LOSS [training: 0.1528721879965484 | validation: 0.33108838632214266]
	TIME [epoch: 3.79 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14036536532250704		[learning rate: 0.0012094]
	Learning Rate: 0.00120938
	LOSS [training: 0.14036536532250704 | validation: 0.2856005867049692]
	TIME [epoch: 3.78 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13113331468824682		[learning rate: 0.0012037]
	Learning Rate: 0.00120368
	LOSS [training: 0.13113331468824682 | validation: 0.3064879491430819]
	TIME [epoch: 3.78 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13682789707430487		[learning rate: 0.001198]
	Learning Rate: 0.00119801
	LOSS [training: 0.13682789707430487 | validation: 0.29612651288932473]
	TIME [epoch: 3.79 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13573800830144478		[learning rate: 0.0011924]
	Learning Rate: 0.00119237
	LOSS [training: 0.13573800830144478 | validation: 0.2986373686462223]
	TIME [epoch: 3.78 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12520702846108503		[learning rate: 0.0011867]
	Learning Rate: 0.00118675
	LOSS [training: 0.12520702846108503 | validation: 0.33719389230937147]
	TIME [epoch: 3.79 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13955702293048533		[learning rate: 0.0011812]
	Learning Rate: 0.00118116
	LOSS [training: 0.13955702293048533 | validation: 0.3134815652393999]
	TIME [epoch: 3.79 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14702309445954775		[learning rate: 0.0011756]
	Learning Rate: 0.00117559
	LOSS [training: 0.14702309445954775 | validation: 0.2960360882700474]
	TIME [epoch: 3.79 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14189171761088704		[learning rate: 0.0011701]
	Learning Rate: 0.00117005
	LOSS [training: 0.14189171761088704 | validation: 0.28799017267713495]
	TIME [epoch: 3.79 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13769114271476932		[learning rate: 0.0011645]
	Learning Rate: 0.00116454
	LOSS [training: 0.13769114271476932 | validation: 0.3162265809045724]
	TIME [epoch: 3.8 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14999443172254998		[learning rate: 0.0011591]
	Learning Rate: 0.00115905
	LOSS [training: 0.14999443172254998 | validation: 0.3107982633285952]
	TIME [epoch: 3.8 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15328079790917373		[learning rate: 0.0011536]
	Learning Rate: 0.00115359
	LOSS [training: 0.15328079790917373 | validation: 0.31083521656535107]
	TIME [epoch: 3.79 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15343522335287282		[learning rate: 0.0011482]
	Learning Rate: 0.00114815
	LOSS [training: 0.15343522335287282 | validation: 0.3037756828524692]
	TIME [epoch: 3.8 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1389798768287104		[learning rate: 0.0011427]
	Learning Rate: 0.00114274
	LOSS [training: 0.1389798768287104 | validation: 0.29472563092202336]
	TIME [epoch: 3.78 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16064452962169057		[learning rate: 0.0011374]
	Learning Rate: 0.00113736
	LOSS [training: 0.16064452962169057 | validation: 0.3497821446351449]
	TIME [epoch: 3.8 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13578127618447125		[learning rate: 0.001132]
	Learning Rate: 0.001132
	LOSS [training: 0.13578127618447125 | validation: 0.2933950731959232]
	TIME [epoch: 3.81 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13727190137958517		[learning rate: 0.0011267]
	Learning Rate: 0.00112667
	LOSS [training: 0.13727190137958517 | validation: 0.3026759454686983]
	TIME [epoch: 3.78 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1356627701841952		[learning rate: 0.0011214]
	Learning Rate: 0.00112136
	LOSS [training: 0.1356627701841952 | validation: 0.2950295335898419]
	TIME [epoch: 28.4 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1414031676589909		[learning rate: 0.0011161]
	Learning Rate: 0.00111607
	LOSS [training: 0.1414031676589909 | validation: 0.3414054163879853]
	TIME [epoch: 7.26 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12998615939789093		[learning rate: 0.0011108]
	Learning Rate: 0.00111081
	LOSS [training: 0.12998615939789093 | validation: 0.3076138953959035]
	TIME [epoch: 7.24 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14580505757745008		[learning rate: 0.0011056]
	Learning Rate: 0.00110558
	LOSS [training: 0.14580505757745008 | validation: 0.3005043497585916]
	TIME [epoch: 7.27 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12401421968619195		[learning rate: 0.0011004]
	Learning Rate: 0.00110037
	LOSS [training: 0.12401421968619195 | validation: 0.31398117389767044]
	TIME [epoch: 7.26 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16362216477332964		[learning rate: 0.0010952]
	Learning Rate: 0.00109518
	LOSS [training: 0.16362216477332964 | validation: 0.29336724573456796]
	TIME [epoch: 7.27 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13546553169642692		[learning rate: 0.00109]
	Learning Rate: 0.00109002
	LOSS [training: 0.13546553169642692 | validation: 0.30931255716457445]
	TIME [epoch: 7.24 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.149795141561961		[learning rate: 0.0010849]
	Learning Rate: 0.00108489
	LOSS [training: 0.149795141561961 | validation: 0.3123518404188868]
	TIME [epoch: 7.26 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13721801902262634		[learning rate: 0.0010798]
	Learning Rate: 0.00107978
	LOSS [training: 0.13721801902262634 | validation: 0.30808280655611053]
	TIME [epoch: 7.25 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13584737510774017		[learning rate: 0.0010747]
	Learning Rate: 0.00107469
	LOSS [training: 0.13584737510774017 | validation: 0.34792880227613376]
	TIME [epoch: 7.28 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15121048824978198		[learning rate: 0.0010696]
	Learning Rate: 0.00106962
	LOSS [training: 0.15121048824978198 | validation: 0.2783958427842005]
	TIME [epoch: 7.23 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v7_20240715_175905/states/model_facs_v3_dec2b_2dpca_v7_511.pth
	Model improved!!!
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15447278843467377		[learning rate: 0.0010646]
	Learning Rate: 0.00106458
	LOSS [training: 0.15447278843467377 | validation: 0.32129999802261183]
	TIME [epoch: 7.25 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1242878415611621		[learning rate: 0.0010596]
	Learning Rate: 0.00105957
	LOSS [training: 0.1242878415611621 | validation: 0.2811038085882393]
	TIME [epoch: 7.27 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1247760695351282		[learning rate: 0.0010546]
	Learning Rate: 0.00105457
	LOSS [training: 0.1247760695351282 | validation: 0.3026184064050076]
	TIME [epoch: 7.35 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13731712867522206		[learning rate: 0.0010496]
	Learning Rate: 0.0010496
	LOSS [training: 0.13731712867522206 | validation: 0.2954572007779867]
	TIME [epoch: 7.26 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13174893739951724		[learning rate: 0.0010447]
	Learning Rate: 0.00104466
	LOSS [training: 0.13174893739951724 | validation: 0.2956969911550272]
	TIME [epoch: 7.28 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14209918046586645		[learning rate: 0.0010397]
	Learning Rate: 0.00103974
	LOSS [training: 0.14209918046586645 | validation: 0.304584384827969]
	TIME [epoch: 7.25 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12080065260971846		[learning rate: 0.0010348]
	Learning Rate: 0.00103484
	LOSS [training: 0.12080065260971846 | validation: 0.30637681659778093]
	TIME [epoch: 7.26 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13127952335521692		[learning rate: 0.00103]
	Learning Rate: 0.00102996
	LOSS [training: 0.13127952335521692 | validation: 0.29046414763934003]
	TIME [epoch: 7.26 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12974407701175858		[learning rate: 0.0010251]
	Learning Rate: 0.00102511
	LOSS [training: 0.12974407701175858 | validation: 0.2980131532264588]
	TIME [epoch: 7.26 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.140397661355954		[learning rate: 0.0010203]
	Learning Rate: 0.00102028
	LOSS [training: 0.140397661355954 | validation: 0.2924264383740087]
	TIME [epoch: 7.25 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1416353822149367		[learning rate: 0.0010155]
	Learning Rate: 0.00101547
	LOSS [training: 0.1416353822149367 | validation: 0.2919919534901985]
	TIME [epoch: 7.27 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1460041827545656		[learning rate: 0.0010107]
	Learning Rate: 0.00101068
	LOSS [training: 0.1460041827545656 | validation: 0.2975433494629549]
	TIME [epoch: 7.26 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14921633163618298		[learning rate: 0.0010059]
	Learning Rate: 0.00100592
	LOSS [training: 0.14921633163618298 | validation: 0.30401554888264687]
	TIME [epoch: 7.25 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12299961832482896		[learning rate: 0.0010012]
	Learning Rate: 0.00100118
	LOSS [training: 0.12299961832482896 | validation: 0.29160662477770233]
	TIME [epoch: 7.26 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1301929875793422		[learning rate: 0.00099646]
	Learning Rate: 0.000996464
	LOSS [training: 0.1301929875793422 | validation: 0.31484955939883724]
	TIME [epoch: 7.24 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12231172462420538		[learning rate: 0.00099177]
	Learning Rate: 0.000991768
	LOSS [training: 0.12231172462420538 | validation: 0.2913885943392499]
	TIME [epoch: 7.25 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12436562917249629		[learning rate: 0.0009871]
	Learning Rate: 0.000987095
	LOSS [training: 0.12436562917249629 | validation: 0.293943166138047]
	TIME [epoch: 7.28 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14449831867045637		[learning rate: 0.00098244]
	Learning Rate: 0.000982444
	LOSS [training: 0.14449831867045637 | validation: 0.310611598552311]
	TIME [epoch: 7.25 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14320591064923194		[learning rate: 0.00097781]
	Learning Rate: 0.000977814
	LOSS [training: 0.14320591064923194 | validation: 0.29367492857766975]
	TIME [epoch: 7.25 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14449455625900465		[learning rate: 0.00097321]
	Learning Rate: 0.000973207
	LOSS [training: 0.14449455625900465 | validation: 0.297330827711122]
	TIME [epoch: 7.26 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.145764287656623		[learning rate: 0.00096862]
	Learning Rate: 0.000968621
	LOSS [training: 0.145764287656623 | validation: 0.32116654604423506]
	TIME [epoch: 7.25 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1537812423971362		[learning rate: 0.00096406]
	Learning Rate: 0.000964057
	LOSS [training: 0.1537812423971362 | validation: 0.32973177255474034]
	TIME [epoch: 7.27 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16663967094402948		[learning rate: 0.00095951]
	Learning Rate: 0.000959514
	LOSS [training: 0.16663967094402948 | validation: 0.28302343456956847]
	TIME [epoch: 7.26 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14803202219408118		[learning rate: 0.00095499]
	Learning Rate: 0.000954993
	LOSS [training: 0.14803202219408118 | validation: 0.2967645745620659]
	TIME [epoch: 7.25 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13434911342812847		[learning rate: 0.00095049]
	Learning Rate: 0.000950493
	LOSS [training: 0.13434911342812847 | validation: 0.29529622248374354]
	TIME [epoch: 7.25 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11865353920168666		[learning rate: 0.00094601]
	Learning Rate: 0.000946014
	LOSS [training: 0.11865353920168666 | validation: 0.3036204828761514]
	TIME [epoch: 7.25 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13125666857940851		[learning rate: 0.00094156]
	Learning Rate: 0.000941556
	LOSS [training: 0.13125666857940851 | validation: 0.3061698645108019]
	TIME [epoch: 7.25 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12246583062347823		[learning rate: 0.00093712]
	Learning Rate: 0.000937119
	LOSS [training: 0.12246583062347823 | validation: 0.29596851430707644]
	TIME [epoch: 7.28 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1376514901832076		[learning rate: 0.0009327]
	Learning Rate: 0.000932703
	LOSS [training: 0.1376514901832076 | validation: 0.29386529771963765]
	TIME [epoch: 7.26 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15640464071802562		[learning rate: 0.00092831]
	Learning Rate: 0.000928309
	LOSS [training: 0.15640464071802562 | validation: 0.29361499182782147]
	TIME [epoch: 7.27 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13563827398067638		[learning rate: 0.00092393]
	Learning Rate: 0.000923934
	LOSS [training: 0.13563827398067638 | validation: 0.3158459112626194]
	TIME [epoch: 7.27 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13885151817282682		[learning rate: 0.00091958]
	Learning Rate: 0.000919581
	LOSS [training: 0.13885151817282682 | validation: 0.33364185449699435]
	TIME [epoch: 7.26 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1476541984150828		[learning rate: 0.00091525]
	Learning Rate: 0.000915247
	LOSS [training: 0.1476541984150828 | validation: 0.28216030984388635]
	TIME [epoch: 7.28 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14492692640444652		[learning rate: 0.00091093]
	Learning Rate: 0.000910934
	LOSS [training: 0.14492692640444652 | validation: 0.3151533879278488]
	TIME [epoch: 7.27 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16031011873412745		[learning rate: 0.00090664]
	Learning Rate: 0.000906642
	LOSS [training: 0.16031011873412745 | validation: 0.33381927102853104]
	TIME [epoch: 7.27 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15222451176195678		[learning rate: 0.00090237]
	Learning Rate: 0.00090237
	LOSS [training: 0.15222451176195678 | validation: 0.2963940676992267]
	TIME [epoch: 7.26 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12872392171895428		[learning rate: 0.00089812]
	Learning Rate: 0.000898118
	LOSS [training: 0.12872392171895428 | validation: 0.28999386290420825]
	TIME [epoch: 7.26 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12917908460443542		[learning rate: 0.00089389]
	Learning Rate: 0.000893886
	LOSS [training: 0.12917908460443542 | validation: 0.2853595339970094]
	TIME [epoch: 7.25 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13143592179200708		[learning rate: 0.00088967]
	Learning Rate: 0.000889674
	LOSS [training: 0.13143592179200708 | validation: 0.30658214350645574]
	TIME [epoch: 7.26 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14520594622391414		[learning rate: 0.00088548]
	Learning Rate: 0.000885481
	LOSS [training: 0.14520594622391414 | validation: 0.29288440237983454]
	TIME [epoch: 7.28 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11979661588354272		[learning rate: 0.00088131]
	Learning Rate: 0.000881309
	LOSS [training: 0.11979661588354272 | validation: 0.30060605288656916]
	TIME [epoch: 7.25 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13213615815551316		[learning rate: 0.00087716]
	Learning Rate: 0.000877156
	LOSS [training: 0.13213615815551316 | validation: 0.29305632853233543]
	TIME [epoch: 7.26 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1270439284560752		[learning rate: 0.00087302]
	Learning Rate: 0.000873023
	LOSS [training: 0.1270439284560752 | validation: 0.3130648184530426]
	TIME [epoch: 7.27 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12559393538155653		[learning rate: 0.00086891]
	Learning Rate: 0.000868909
	LOSS [training: 0.12559393538155653 | validation: 0.2982460352093621]
	TIME [epoch: 7.26 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12111816158992023		[learning rate: 0.00086481]
	Learning Rate: 0.000864815
	LOSS [training: 0.12111816158992023 | validation: 0.29490020281405144]
	TIME [epoch: 7.35 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1263804288779944		[learning rate: 0.00086074]
	Learning Rate: 0.00086074
	LOSS [training: 0.1263804288779944 | validation: 0.2915349657944626]
	TIME [epoch: 7.34 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12703138417246862		[learning rate: 0.00085668]
	Learning Rate: 0.000856684
	LOSS [training: 0.12703138417246862 | validation: 0.28503753409120847]
	TIME [epoch: 7.34 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1523545765507011		[learning rate: 0.00085265]
	Learning Rate: 0.000852647
	LOSS [training: 0.1523545765507011 | validation: 0.3577479599935229]
	TIME [epoch: 7.35 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13459172271107162		[learning rate: 0.00084863]
	Learning Rate: 0.000848629
	LOSS [training: 0.13459172271107162 | validation: 0.3058268111368177]
	TIME [epoch: 7.35 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1508014578535202		[learning rate: 0.00084463]
	Learning Rate: 0.00084463
	LOSS [training: 0.1508014578535202 | validation: 0.31890422012250186]
	TIME [epoch: 7.35 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15605672302869747		[learning rate: 0.00084065]
	Learning Rate: 0.00084065
	LOSS [training: 0.15605672302869747 | validation: 0.3163218582998566]
	TIME [epoch: 7.35 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14681115056243682		[learning rate: 0.00083669]
	Learning Rate: 0.000836689
	LOSS [training: 0.14681115056243682 | validation: 0.2981072167374531]
	TIME [epoch: 7.35 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14588664495652404		[learning rate: 0.00083275]
	Learning Rate: 0.000832746
	LOSS [training: 0.14588664495652404 | validation: 0.2978241788453649]
	TIME [epoch: 7.33 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12795173082901662		[learning rate: 0.00082882]
	Learning Rate: 0.000828822
	LOSS [training: 0.12795173082901662 | validation: 0.301970575030192]
	TIME [epoch: 7.33 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13984101450602407		[learning rate: 0.00082492]
	Learning Rate: 0.000824917
	LOSS [training: 0.13984101450602407 | validation: 0.3079255563071002]
	TIME [epoch: 7.35 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13294166272815905		[learning rate: 0.00082103]
	Learning Rate: 0.00082103
	LOSS [training: 0.13294166272815905 | validation: 0.32992491686593617]
	TIME [epoch: 7.36 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1622355546625582		[learning rate: 0.00081716]
	Learning Rate: 0.000817161
	LOSS [training: 0.1622355546625582 | validation: 0.3040602826389975]
	TIME [epoch: 7.35 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14486073100404281		[learning rate: 0.00081331]
	Learning Rate: 0.000813311
	LOSS [training: 0.14486073100404281 | validation: 0.2971526713537003]
	TIME [epoch: 7.35 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12788807633556543		[learning rate: 0.00080948]
	Learning Rate: 0.000809478
	LOSS [training: 0.12788807633556543 | validation: 0.3214232587795591]
	TIME [epoch: 7.34 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16166389827448271		[learning rate: 0.00080566]
	Learning Rate: 0.000805664
	LOSS [training: 0.16166389827448271 | validation: 0.312237508545866]
	TIME [epoch: 7.35 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1392528116946607		[learning rate: 0.00080187]
	Learning Rate: 0.000801868
	LOSS [training: 0.1392528116946607 | validation: 0.29014370746522733]
	TIME [epoch: 7.39 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12788613207107974		[learning rate: 0.00079809]
	Learning Rate: 0.000798089
	LOSS [training: 0.12788613207107974 | validation: 0.2955821730407682]
	TIME [epoch: 7.35 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12468081014144271		[learning rate: 0.00079433]
	Learning Rate: 0.000794328
	LOSS [training: 0.12468081014144271 | validation: 0.2999541102639505]
	TIME [epoch: 7.36 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1341648160833681		[learning rate: 0.00079059]
	Learning Rate: 0.000790585
	LOSS [training: 0.1341648160833681 | validation: 0.2911209266834355]
	TIME [epoch: 7.36 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1398418084670855		[learning rate: 0.00078686]
	Learning Rate: 0.00078686
	LOSS [training: 0.1398418084670855 | validation: 0.2931699931379249]
	TIME [epoch: 7.33 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13080162109810717		[learning rate: 0.00078315]
	Learning Rate: 0.000783152
	LOSS [training: 0.13080162109810717 | validation: 0.30448884852332636]
	TIME [epoch: 7.36 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1483700443248322		[learning rate: 0.00077946]
	Learning Rate: 0.000779462
	LOSS [training: 0.1483700443248322 | validation: 0.3093670979943824]
	TIME [epoch: 7.35 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15464488112426966		[learning rate: 0.00077579]
	Learning Rate: 0.000775789
	LOSS [training: 0.15464488112426966 | validation: 0.2994597043552681]
	TIME [epoch: 7.36 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1321727056240633		[learning rate: 0.00077213]
	Learning Rate: 0.000772133
	LOSS [training: 0.1321727056240633 | validation: 0.3174546890073501]
	TIME [epoch: 7.33 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1372137050761233		[learning rate: 0.00076849]
	Learning Rate: 0.000768495
	LOSS [training: 0.1372137050761233 | validation: 0.28671044878751073]
	TIME [epoch: 7.35 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13071673782314547		[learning rate: 0.00076487]
	Learning Rate: 0.000764874
	LOSS [training: 0.13071673782314547 | validation: 0.31884525196507235]
	TIME [epoch: 7.35 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12737516701561497		[learning rate: 0.00076127]
	Learning Rate: 0.00076127
	LOSS [training: 0.12737516701561497 | validation: 0.3298772149778305]
	TIME [epoch: 7.32 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15223897637220007		[learning rate: 0.00075768]
	Learning Rate: 0.000757682
	LOSS [training: 0.15223897637220007 | validation: 0.2882229408587375]
	TIME [epoch: 7.36 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1479933949380772		[learning rate: 0.00075411]
	Learning Rate: 0.000754112
	LOSS [training: 0.1479933949380772 | validation: 0.30064210190141333]
	TIME [epoch: 7.37 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1363626067306148		[learning rate: 0.00075056]
	Learning Rate: 0.000750559
	LOSS [training: 0.1363626067306148 | validation: 0.29295760730919707]
	TIME [epoch: 7.33 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15271576467943865		[learning rate: 0.00074702]
	Learning Rate: 0.000747022
	LOSS [training: 0.15271576467943865 | validation: 0.30231628187749116]
	TIME [epoch: 7.36 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14066083105879765		[learning rate: 0.0007435]
	Learning Rate: 0.000743502
	LOSS [training: 0.14066083105879765 | validation: 0.2966942400102059]
	TIME [epoch: 7.34 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13543406112709136		[learning rate: 0.00074]
	Learning Rate: 0.000739998
	LOSS [training: 0.13543406112709136 | validation: 0.30938438047496963]
	TIME [epoch: 7.36 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14147167562424384		[learning rate: 0.00073651]
	Learning Rate: 0.000736511
	LOSS [training: 0.14147167562424384 | validation: 0.30095197154714154]
	TIME [epoch: 7.38 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14662772186526382		[learning rate: 0.00073304]
	Learning Rate: 0.000733041
	LOSS [training: 0.14662772186526382 | validation: 0.3007259570872968]
	TIME [epoch: 7.37 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12499069270216116		[learning rate: 0.00072959]
	Learning Rate: 0.000729587
	LOSS [training: 0.12499069270216116 | validation: 0.31654055890116256]
	TIME [epoch: 7.36 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14142549281844974		[learning rate: 0.00072615]
	Learning Rate: 0.000726149
	LOSS [training: 0.14142549281844974 | validation: 0.2944098679224476]
	TIME [epoch: 7.36 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16117769022240122		[learning rate: 0.00072273]
	Learning Rate: 0.000722727
	LOSS [training: 0.16117769022240122 | validation: 0.29594963600916274]
	TIME [epoch: 7.37 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13365363030228286		[learning rate: 0.00071932]
	Learning Rate: 0.000719321
	LOSS [training: 0.13365363030228286 | validation: 0.2972285005343914]
	TIME [epoch: 7.37 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13009159504575965		[learning rate: 0.00071593]
	Learning Rate: 0.000715932
	LOSS [training: 0.13009159504575965 | validation: 0.2843075897053718]
	TIME [epoch: 7.38 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14695584295532127		[learning rate: 0.00071256]
	Learning Rate: 0.000712558
	LOSS [training: 0.14695584295532127 | validation: 0.3385754869289687]
	TIME [epoch: 7.34 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15082658707525312		[learning rate: 0.0007092]
	Learning Rate: 0.000709201
	LOSS [training: 0.15082658707525312 | validation: 0.2906562944351936]
	TIME [epoch: 7.38 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13790573055018876		[learning rate: 0.00070586]
	Learning Rate: 0.000705859
	LOSS [training: 0.13790573055018876 | validation: 0.3233625770405619]
	TIME [epoch: 7.36 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13186780123065175		[learning rate: 0.00070253]
	Learning Rate: 0.000702533
	LOSS [training: 0.13186780123065175 | validation: 0.2909883541061586]
	TIME [epoch: 7.37 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12567881730146213		[learning rate: 0.00069922]
	Learning Rate: 0.000699222
	LOSS [training: 0.12567881730146213 | validation: 0.30192213960492265]
	TIME [epoch: 7.35 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13413644761179908		[learning rate: 0.00069593]
	Learning Rate: 0.000695928
	LOSS [training: 0.13413644761179908 | validation: 0.3068453928199366]
	TIME [epoch: 7.35 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13095593352627255		[learning rate: 0.00069265]
	Learning Rate: 0.000692648
	LOSS [training: 0.13095593352627255 | validation: 0.32205472345675035]
	TIME [epoch: 7.35 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13541559820538746		[learning rate: 0.00068938]
	Learning Rate: 0.000689385
	LOSS [training: 0.13541559820538746 | validation: 0.2993646696471599]
	TIME [epoch: 7.34 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1539571146699834		[learning rate: 0.00068614]
	Learning Rate: 0.000686136
	LOSS [training: 0.1539571146699834 | validation: 0.3098839172800633]
	TIME [epoch: 7.36 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1257859533874825		[learning rate: 0.0006829]
	Learning Rate: 0.000682903
	LOSS [training: 0.1257859533874825 | validation: 0.29626055460187256]
	TIME [epoch: 7.35 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13860521519673036		[learning rate: 0.00067969]
	Learning Rate: 0.000679685
	LOSS [training: 0.13860521519673036 | validation: 0.30249524261063043]
	TIME [epoch: 7.34 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1469033056753438		[learning rate: 0.00067648]
	Learning Rate: 0.000676482
	LOSS [training: 0.1469033056753438 | validation: 0.30043733539433515]
	TIME [epoch: 7.35 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13174443045548978		[learning rate: 0.00067329]
	Learning Rate: 0.000673295
	LOSS [training: 0.13174443045548978 | validation: 0.305594665034644]
	TIME [epoch: 7.34 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13189226851407962		[learning rate: 0.00067012]
	Learning Rate: 0.000670122
	LOSS [training: 0.13189226851407962 | validation: 0.30247060855508845]
	TIME [epoch: 7.36 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14080041699220072		[learning rate: 0.00066696]
	Learning Rate: 0.000666964
	LOSS [training: 0.14080041699220072 | validation: 0.3247958085578993]
	TIME [epoch: 7.34 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12280166016831229		[learning rate: 0.00066382]
	Learning Rate: 0.000663821
	LOSS [training: 0.12280166016831229 | validation: 0.3027859258266177]
	TIME [epoch: 7.35 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15147275228635923		[learning rate: 0.00066069]
	Learning Rate: 0.000660694
	LOSS [training: 0.15147275228635923 | validation: 0.2889596556317188]
	TIME [epoch: 7.36 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14405828407944704		[learning rate: 0.00065758]
	Learning Rate: 0.00065758
	LOSS [training: 0.14405828407944704 | validation: 0.3074830932322912]
	TIME [epoch: 7.34 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12811007967510352		[learning rate: 0.00065448]
	Learning Rate: 0.000654482
	LOSS [training: 0.12811007967510352 | validation: 0.3013842340916382]
	TIME [epoch: 7.36 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14137187976895524		[learning rate: 0.0006514]
	Learning Rate: 0.000651398
	LOSS [training: 0.14137187976895524 | validation: 0.3044459156895936]
	TIME [epoch: 7.36 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13620329793944072		[learning rate: 0.00064833]
	Learning Rate: 0.000648328
	LOSS [training: 0.13620329793944072 | validation: 0.3106296877046696]
	TIME [epoch: 7.35 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12777133131896076		[learning rate: 0.00064527]
	Learning Rate: 0.000645273
	LOSS [training: 0.12777133131896076 | validation: 0.29137294918775736]
	TIME [epoch: 7.36 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1297833222160469		[learning rate: 0.00064223]
	Learning Rate: 0.000642232
	LOSS [training: 0.1297833222160469 | validation: 0.2922123723107653]
	TIME [epoch: 7.35 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13382886883819756		[learning rate: 0.00063921]
	Learning Rate: 0.000639206
	LOSS [training: 0.13382886883819756 | validation: 0.29736794153901686]
	TIME [epoch: 7.31 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14475984215482388		[learning rate: 0.00063619]
	Learning Rate: 0.000636194
	LOSS [training: 0.14475984215482388 | validation: 0.3000998505898721]
	TIME [epoch: 7.37 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14725196697703108		[learning rate: 0.0006332]
	Learning Rate: 0.000633196
	LOSS [training: 0.14725196697703108 | validation: 0.3017287046013643]
	TIME [epoch: 7.36 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1360923042580211		[learning rate: 0.00063021]
	Learning Rate: 0.000630213
	LOSS [training: 0.1360923042580211 | validation: 0.30729914792488144]
	TIME [epoch: 7.38 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13536728271769172		[learning rate: 0.00062724]
	Learning Rate: 0.000627243
	LOSS [training: 0.13536728271769172 | validation: 0.28706515501365343]
	TIME [epoch: 7.38 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11917072881116679		[learning rate: 0.00062429]
	Learning Rate: 0.000624287
	LOSS [training: 0.11917072881116679 | validation: 0.2928776404835091]
	TIME [epoch: 7.37 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1296587615415296		[learning rate: 0.00062135]
	Learning Rate: 0.000621346
	LOSS [training: 0.1296587615415296 | validation: 0.3017528393460545]
	TIME [epoch: 7.37 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13287688649689489		[learning rate: 0.00061842]
	Learning Rate: 0.000618418
	LOSS [training: 0.13287688649689489 | validation: 0.2957628102275508]
	TIME [epoch: 7.36 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15212190278930424		[learning rate: 0.0006155]
	Learning Rate: 0.000615504
	LOSS [training: 0.15212190278930424 | validation: 0.32238013652153547]
	TIME [epoch: 7.36 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11752446085946341		[learning rate: 0.0006126]
	Learning Rate: 0.000612604
	LOSS [training: 0.11752446085946341 | validation: 0.29720658747716]
	TIME [epoch: 7.36 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13497321835099207		[learning rate: 0.00060972]
	Learning Rate: 0.000609717
	LOSS [training: 0.13497321835099207 | validation: 0.28744917247167207]
	TIME [epoch: 7.4 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12361555206716053		[learning rate: 0.00060684]
	Learning Rate: 0.000606844
	LOSS [training: 0.12361555206716053 | validation: 0.30902251202612885]
	TIME [epoch: 7.38 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15191825549248028		[learning rate: 0.00060398]
	Learning Rate: 0.000603984
	LOSS [training: 0.15191825549248028 | validation: 0.3007977684237979]
	TIME [epoch: 7.35 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12416817113259937		[learning rate: 0.00060114]
	Learning Rate: 0.000601138
	LOSS [training: 0.12416817113259937 | validation: 0.31305900483240073]
	TIME [epoch: 7.36 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1289775297119582		[learning rate: 0.00059831]
	Learning Rate: 0.000598306
	LOSS [training: 0.1289775297119582 | validation: 0.3085592516259598]
	TIME [epoch: 7.35 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13856727072287178		[learning rate: 0.00059549]
	Learning Rate: 0.000595486
	LOSS [training: 0.13856727072287178 | validation: 0.296283352741764]
	TIME [epoch: 7.37 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1421590944049747		[learning rate: 0.00059268]
	Learning Rate: 0.00059268
	LOSS [training: 0.1421590944049747 | validation: 0.30132259880329226]
	TIME [epoch: 7.4 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13924980754569116		[learning rate: 0.00058989]
	Learning Rate: 0.000589888
	LOSS [training: 0.13924980754569116 | validation: 0.28560293848144985]
	TIME [epoch: 7.37 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15533648674507516		[learning rate: 0.00058711]
	Learning Rate: 0.000587108
	LOSS [training: 0.15533648674507516 | validation: 0.30897653937412867]
	TIME [epoch: 7.38 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13335166396390805		[learning rate: 0.00058434]
	Learning Rate: 0.000584341
	LOSS [training: 0.13335166396390805 | validation: 0.3070149278302657]
	TIME [epoch: 7.33 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13079958747015466		[learning rate: 0.00058159]
	Learning Rate: 0.000581588
	LOSS [training: 0.13079958747015466 | validation: 0.311126620498194]
	TIME [epoch: 7.34 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12814996781911886		[learning rate: 0.00057885]
	Learning Rate: 0.000578847
	LOSS [training: 0.12814996781911886 | validation: 0.2948366388913878]
	TIME [epoch: 7.31 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14132680676037004		[learning rate: 0.00057612]
	Learning Rate: 0.00057612
	LOSS [training: 0.14132680676037004 | validation: 0.2943960291554378]
	TIME [epoch: 7.34 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14155753903208687		[learning rate: 0.00057341]
	Learning Rate: 0.000573405
	LOSS [training: 0.14155753903208687 | validation: 0.30782841882463946]
	TIME [epoch: 7.3 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13136079919064875		[learning rate: 0.0005707]
	Learning Rate: 0.000570703
	LOSS [training: 0.13136079919064875 | validation: 0.3018778830925428]
	TIME [epoch: 7.37 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1276659387393877		[learning rate: 0.00056801]
	Learning Rate: 0.000568014
	LOSS [training: 0.1276659387393877 | validation: 0.2804730116073699]
	TIME [epoch: 7.35 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14574075458151867		[learning rate: 0.00056534]
	Learning Rate: 0.000565337
	LOSS [training: 0.14574075458151867 | validation: 0.2962433461304125]
	TIME [epoch: 7.36 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13655376847466916		[learning rate: 0.00056267]
	Learning Rate: 0.000562673
	LOSS [training: 0.13655376847466916 | validation: 0.30375718686293496]
	TIME [epoch: 7.33 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12907785644010206		[learning rate: 0.00056002]
	Learning Rate: 0.000560022
	LOSS [training: 0.12907785644010206 | validation: 0.31518887785566907]
	TIME [epoch: 7.37 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16252755603416275		[learning rate: 0.00055738]
	Learning Rate: 0.000557383
	LOSS [training: 0.16252755603416275 | validation: 0.295905415389101]
	TIME [epoch: 7.34 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12657326609301975		[learning rate: 0.00055476]
	Learning Rate: 0.000554757
	LOSS [training: 0.12657326609301975 | validation: 0.3118076881839931]
	TIME [epoch: 7.35 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15480114203491033		[learning rate: 0.00055214]
	Learning Rate: 0.000552143
	LOSS [training: 0.15480114203491033 | validation: 0.2793268300000534]
	TIME [epoch: 7.39 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14788395699055557		[learning rate: 0.00054954]
	Learning Rate: 0.000549541
	LOSS [training: 0.14788395699055557 | validation: 0.2909073591047483]
	TIME [epoch: 7.47 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13617675515343813		[learning rate: 0.00054695]
	Learning Rate: 0.000546951
	LOSS [training: 0.13617675515343813 | validation: 0.30918197444976]
	TIME [epoch: 7.36 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14040241510220583		[learning rate: 0.00054437]
	Learning Rate: 0.000544374
	LOSS [training: 0.14040241510220583 | validation: 0.30473991352598784]
	TIME [epoch: 7.37 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14783009350895637		[learning rate: 0.00054181]
	Learning Rate: 0.000541809
	LOSS [training: 0.14783009350895637 | validation: 0.2864546614080671]
	TIME [epoch: 7.35 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13382334931480155		[learning rate: 0.00053926]
	Learning Rate: 0.000539256
	LOSS [training: 0.13382334931480155 | validation: 0.3069120633771285]
	TIME [epoch: 7.36 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.155169490064042		[learning rate: 0.00053671]
	Learning Rate: 0.000536715
	LOSS [training: 0.155169490064042 | validation: 0.31235142078271383]
	TIME [epoch: 7.36 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13717575069592985		[learning rate: 0.00053419]
	Learning Rate: 0.000534186
	LOSS [training: 0.13717575069592985 | validation: 0.30239538688936957]
	TIME [epoch: 7.39 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12546519679311113		[learning rate: 0.00053167]
	Learning Rate: 0.000531669
	LOSS [training: 0.12546519679311113 | validation: 0.28505236052192734]
	TIME [epoch: 7.35 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13136852639978924		[learning rate: 0.00052916]
	Learning Rate: 0.000529163
	LOSS [training: 0.13136852639978924 | validation: 0.2885372435128221]
	TIME [epoch: 7.38 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1362315121637693		[learning rate: 0.00052667]
	Learning Rate: 0.00052667
	LOSS [training: 0.1362315121637693 | validation: 0.29779323552576964]
	TIME [epoch: 7.35 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1301664656255785		[learning rate: 0.00052419]
	Learning Rate: 0.000524188
	LOSS [training: 0.1301664656255785 | validation: 0.30737686004628145]
	TIME [epoch: 7.36 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12415631669131315		[learning rate: 0.00052172]
	Learning Rate: 0.000521718
	LOSS [training: 0.12415631669131315 | validation: 0.2972666393870107]
	TIME [epoch: 7.34 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1323563798046345		[learning rate: 0.00051926]
	Learning Rate: 0.00051926
	LOSS [training: 0.1323563798046345 | validation: 0.2885885379154422]
	TIME [epoch: 7.38 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12433622920193338		[learning rate: 0.00051681]
	Learning Rate: 0.000516813
	LOSS [training: 0.12433622920193338 | validation: 0.29911698716937496]
	TIME [epoch: 7.33 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14262453388303706		[learning rate: 0.00051438]
	Learning Rate: 0.000514378
	LOSS [training: 0.14262453388303706 | validation: 0.31808862417710615]
	TIME [epoch: 7.37 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14190507592534385		[learning rate: 0.00051195]
	Learning Rate: 0.000511954
	LOSS [training: 0.14190507592534385 | validation: 0.29842084456884743]
	TIME [epoch: 7.35 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13628438372351975		[learning rate: 0.00050954]
	Learning Rate: 0.000509541
	LOSS [training: 0.13628438372351975 | validation: 0.29258014898904977]
	TIME [epoch: 7.38 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14713317238673343		[learning rate: 0.00050714]
	Learning Rate: 0.00050714
	LOSS [training: 0.14713317238673343 | validation: 0.2972774679466489]
	TIME [epoch: 7.4 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1384737269381952		[learning rate: 0.00050475]
	Learning Rate: 0.000504751
	LOSS [training: 0.1384737269381952 | validation: 0.2947048109391814]
	TIME [epoch: 7.39 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12303290180427184		[learning rate: 0.00050237]
	Learning Rate: 0.000502372
	LOSS [training: 0.12303290180427184 | validation: 0.28381491517030294]
	TIME [epoch: 7.38 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15885550734872253		[learning rate: 0.00050001]
	Learning Rate: 0.000500005
	LOSS [training: 0.15885550734872253 | validation: 0.3021590881627683]
	TIME [epoch: 7.36 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11935036641635843		[learning rate: 0.00049765]
	Learning Rate: 0.000497649
	LOSS [training: 0.11935036641635843 | validation: 0.30179715141598285]
	TIME [epoch: 7.34 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13963232949409257		[learning rate: 0.0004953]
	Learning Rate: 0.000495304
	LOSS [training: 0.13963232949409257 | validation: 0.29616208283350803]
	TIME [epoch: 7.35 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13543563657245822		[learning rate: 0.00049297]
	Learning Rate: 0.00049297
	LOSS [training: 0.13543563657245822 | validation: 0.28838707171395483]
	TIME [epoch: 7.35 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12750053018474838		[learning rate: 0.00049065]
	Learning Rate: 0.000490647
	LOSS [training: 0.12750053018474838 | validation: 0.29171933820213536]
	TIME [epoch: 7.37 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16317097872681996		[learning rate: 0.00048834]
	Learning Rate: 0.000488335
	LOSS [training: 0.16317097872681996 | validation: 0.2984808952101044]
	TIME [epoch: 7.32 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12042468350047633		[learning rate: 0.00048603]
	Learning Rate: 0.000486034
	LOSS [training: 0.12042468350047633 | validation: 0.2935428921223012]
	TIME [epoch: 7.35 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12843900571058492		[learning rate: 0.00048374]
	Learning Rate: 0.000483744
	LOSS [training: 0.12843900571058492 | validation: 0.2897781602389314]
	TIME [epoch: 7.36 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13809169066880764		[learning rate: 0.00048146]
	Learning Rate: 0.000481464
	LOSS [training: 0.13809169066880764 | validation: 0.2961659212987272]
	TIME [epoch: 7.38 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14502514876571138		[learning rate: 0.0004792]
	Learning Rate: 0.000479196
	LOSS [training: 0.14502514876571138 | validation: 0.3049625639812643]
	TIME [epoch: 7.36 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1305895213340309		[learning rate: 0.00047694]
	Learning Rate: 0.000476938
	LOSS [training: 0.1305895213340309 | validation: 0.2936738118975202]
	TIME [epoch: 7.37 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14674890814512337		[learning rate: 0.00047469]
	Learning Rate: 0.00047469
	LOSS [training: 0.14674890814512337 | validation: 0.3130472703705309]
	TIME [epoch: 7.33 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13666997357777327		[learning rate: 0.00047245]
	Learning Rate: 0.000472453
	LOSS [training: 0.13666997357777327 | validation: 0.3021943329607417]
	TIME [epoch: 7.46 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1172032150845185		[learning rate: 0.00047023]
	Learning Rate: 0.000470227
	LOSS [training: 0.1172032150845185 | validation: 0.28553381646905807]
	TIME [epoch: 7.36 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1242326678966211		[learning rate: 0.00046801]
	Learning Rate: 0.000468011
	LOSS [training: 0.1242326678966211 | validation: 0.3022556553800424]
	TIME [epoch: 7.41 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14413244240190903		[learning rate: 0.00046581]
	Learning Rate: 0.000465806
	LOSS [training: 0.14413244240190903 | validation: 0.2977254383246187]
	TIME [epoch: 7.38 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13713419325092657		[learning rate: 0.00046361]
	Learning Rate: 0.000463611
	LOSS [training: 0.13713419325092657 | validation: 0.3069238339894568]
	TIME [epoch: 7.38 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14261149493176412		[learning rate: 0.00046143]
	Learning Rate: 0.000461426
	LOSS [training: 0.14261149493176412 | validation: 0.29067211947386307]
	TIME [epoch: 7.35 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13442299131744717		[learning rate: 0.00045925]
	Learning Rate: 0.000459252
	LOSS [training: 0.13442299131744717 | validation: 0.3042543326732718]
	TIME [epoch: 7.38 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1509533896664593		[learning rate: 0.00045709]
	Learning Rate: 0.000457088
	LOSS [training: 0.1509533896664593 | validation: 0.29874595939650567]
	TIME [epoch: 7.36 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1238689785059949		[learning rate: 0.00045493]
	Learning Rate: 0.000454934
	LOSS [training: 0.1238689785059949 | validation: 0.29777351101187555]
	TIME [epoch: 7.38 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1577391310869125		[learning rate: 0.00045279]
	Learning Rate: 0.000452791
	LOSS [training: 0.1577391310869125 | validation: 0.28529681925659184]
	TIME [epoch: 7.37 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12715399174417655		[learning rate: 0.00045066]
	Learning Rate: 0.000450657
	LOSS [training: 0.12715399174417655 | validation: 0.3098855147330922]
	TIME [epoch: 7.35 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12814207823286888		[learning rate: 0.00044853]
	Learning Rate: 0.000448533
	LOSS [training: 0.12814207823286888 | validation: 0.3114313767570181]
	TIME [epoch: 7.34 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15000519018753328		[learning rate: 0.00044642]
	Learning Rate: 0.00044642
	LOSS [training: 0.15000519018753328 | validation: 0.2843799876069807]
	TIME [epoch: 7.35 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14073024811473092		[learning rate: 0.00044432]
	Learning Rate: 0.000444316
	LOSS [training: 0.14073024811473092 | validation: 0.2967647938334571]
	TIME [epoch: 7.34 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12579657756155468		[learning rate: 0.00044222]
	Learning Rate: 0.000442223
	LOSS [training: 0.12579657756155468 | validation: 0.28940996008052444]
	TIME [epoch: 7.34 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13170619565762576		[learning rate: 0.00044014]
	Learning Rate: 0.000440139
	LOSS [training: 0.13170619565762576 | validation: 0.3092088262307034]
	TIME [epoch: 7.34 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11692984335145856		[learning rate: 0.00043806]
	Learning Rate: 0.000438065
	LOSS [training: 0.11692984335145856 | validation: 0.29584409532857986]
	TIME [epoch: 7.39 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12248160355427422		[learning rate: 0.000436]
	Learning Rate: 0.000436001
	LOSS [training: 0.12248160355427422 | validation: 0.29940274296431324]
	TIME [epoch: 7.34 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12027369680220289		[learning rate: 0.00043395]
	Learning Rate: 0.000433946
	LOSS [training: 0.12027369680220289 | validation: 0.2919799099888266]
	TIME [epoch: 7.35 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1569189941730021		[learning rate: 0.0004319]
	Learning Rate: 0.000431901
	LOSS [training: 0.1569189941730021 | validation: 0.29824891087937183]
	TIME [epoch: 7.38 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12639623317215762		[learning rate: 0.00042987]
	Learning Rate: 0.000429866
	LOSS [training: 0.12639623317215762 | validation: 0.2883660110362723]
	TIME [epoch: 7.37 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17534668252265273		[learning rate: 0.00042784]
	Learning Rate: 0.000427841
	LOSS [training: 0.17534668252265273 | validation: 0.31258961195605284]
	TIME [epoch: 7.35 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1257425108999196		[learning rate: 0.00042582]
	Learning Rate: 0.000425825
	LOSS [training: 0.1257425108999196 | validation: 0.30531361695205655]
	TIME [epoch: 7.38 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15019961158397283		[learning rate: 0.00042382]
	Learning Rate: 0.000423818
	LOSS [training: 0.15019961158397283 | validation: 0.3058469156573512]
	TIME [epoch: 7.35 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1396942952105108		[learning rate: 0.00042182]
	Learning Rate: 0.000421821
	LOSS [training: 0.1396942952105108 | validation: 0.3068916428843922]
	TIME [epoch: 7.35 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12680646300322448		[learning rate: 0.00041983]
	Learning Rate: 0.000419833
	LOSS [training: 0.12680646300322448 | validation: 0.28523843089650097]
	TIME [epoch: 7.38 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15085695857346199		[learning rate: 0.00041786]
	Learning Rate: 0.000417855
	LOSS [training: 0.15085695857346199 | validation: 0.3061012908746953]
	TIME [epoch: 7.36 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13265439793991401		[learning rate: 0.00041589]
	Learning Rate: 0.000415886
	LOSS [training: 0.13265439793991401 | validation: 0.29132077905011466]
	TIME [epoch: 7.35 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11790446797486599		[learning rate: 0.00041393]
	Learning Rate: 0.000413926
	LOSS [training: 0.11790446797486599 | validation: 0.2956165692357588]
	TIME [epoch: 7.36 sec]
	Saving model to: out/model_training/model_facs_v3_dec2b_2dpca_v7_20240715_175905/states/model_facs_v3_dec2b_2dpca_v7_712.pth
Halted early. No improvement in validation loss for 200 epochs.
Finished training in 3620.224 seconds.
