Args:
Namespace(name='model_facs_dec1b_2d_v1', outdir='out/model_training/model_facs_dec1b_2d_v1', training_data='data/training_data/facs/dec1_fitonsubset/transition1_subset_epi_tr_ce_an_pc12/training', validation_data='data/training_data/facs/dec1_fitonsubset/transition1_subset_epi_tr_ce_an_pc12/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=5, patience=200, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, dt=0.001, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 2352861489

Training model...

Saving initial model state to: out/model_training/model_facs_dec1b_2d_v1_20240622_120511/states/model_facs_dec1b_2d_v1_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 9/9] avg loss: 3.8659372019160756		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8659372019160756 | validation: 2.3752435359672557]
	TIME [epoch: 64.8 sec]
	Saving model to: out/model_training/model_facs_dec1b_2d_v1_20240622_120511/states/model_facs_dec1b_2d_v1_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.9558598828719742		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9558598828719742 | validation: 1.4062713904837034]
	TIME [epoch: 35.9 sec]
	Saving model to: out/model_training/model_facs_dec1b_2d_v1_20240622_120511/states/model_facs_dec1b_2d_v1_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.510365736524901		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.510365736524901 | validation: 2.3057067111729994]
	TIME [epoch: 36 sec]
EPOCH 4/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.4033559862180562		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4033559862180562 | validation: 1.126038055009288]
	TIME [epoch: 35.9 sec]
	Saving model to: out/model_training/model_facs_dec1b_2d_v1_20240622_120511/states/model_facs_dec1b_2d_v1_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.9684603345863153		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9684603345863153 | validation: 0.9341901819959825]
	TIME [epoch: 36 sec]
	Saving model to: out/model_training/model_facs_dec1b_2d_v1_20240622_120511/states/model_facs_dec1b_2d_v1_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.8158418003479323		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8158418003479323 | validation: 1.2031538345279509]
	TIME [epoch: 36 sec]
EPOCH 7/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.8480278653115273		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8480278653115273 | validation: 0.5479879121433081]
	TIME [epoch: 36 sec]
	Saving model to: out/model_training/model_facs_dec1b_2d_v1_20240622_120511/states/model_facs_dec1b_2d_v1_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5463531396797874		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5463531396797874 | validation: 0.6507744914084788]
	TIME [epoch: 36 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4099596513440224		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4099596513440224 | validation: 0.479332141626709]
	TIME [epoch: 36 sec]
	Saving model to: out/model_training/model_facs_dec1b_2d_v1_20240622_120511/states/model_facs_dec1b_2d_v1_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.35851663991318067		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.35851663991318067 | validation: 0.2847680072160112]
	TIME [epoch: 36 sec]
	Saving model to: out/model_training/model_facs_dec1b_2d_v1_20240622_120511/states/model_facs_dec1b_2d_v1_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2417939783720846		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2417939783720846 | validation: 0.2660008121051508]
	TIME [epoch: 36 sec]
	Saving model to: out/model_training/model_facs_dec1b_2d_v1_20240622_120511/states/model_facs_dec1b_2d_v1_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.19319275174241254		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.19319275174241254 | validation: 0.31084966376011286]
	TIME [epoch: 36 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.14698065282282746		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14698065282282746 | validation: 0.09211944791775162]
	TIME [epoch: 36 sec]
	Saving model to: out/model_training/model_facs_dec1b_2d_v1_20240622_120511/states/model_facs_dec1b_2d_v1_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0717857647213213		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0717857647213213 | validation: 0.056282656572637854]
	TIME [epoch: 36 sec]
	Saving model to: out/model_training/model_facs_dec1b_2d_v1_20240622_120511/states/model_facs_dec1b_2d_v1_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.04841290881939708		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04841290881939708 | validation: 0.03519280952785571]
	TIME [epoch: 36 sec]
	Saving model to: out/model_training/model_facs_dec1b_2d_v1_20240622_120511/states/model_facs_dec1b_2d_v1_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.03726511887228366		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03726511887228366 | validation: 0.030635422915181204]
	TIME [epoch: 36 sec]
	Saving model to: out/model_training/model_facs_dec1b_2d_v1_20240622_120511/states/model_facs_dec1b_2d_v1_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.02675094888397566		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.02675094888397566 | validation: 0.02735415916165241]
	TIME [epoch: 36 sec]
	Saving model to: out/model_training/model_facs_dec1b_2d_v1_20240622_120511/states/model_facs_dec1b_2d_v1_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.025060411486754895		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.025060411486754895 | validation: 0.0186796774543772]
	TIME [epoch: 36 sec]
	Saving model to: out/model_training/model_facs_dec1b_2d_v1_20240622_120511/states/model_facs_dec1b_2d_v1_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01815004095635815		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.01815004095635815 | validation: 0.022629511268958354]
	TIME [epoch: 36 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.018517684833287335		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.018517684833287335 | validation: 0.014379085050526088]
	TIME [epoch: 36 sec]
	Saving model to: out/model_training/model_facs_dec1b_2d_v1_20240622_120511/states/model_facs_dec1b_2d_v1_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.015617190299032968		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.015617190299032968 | validation: 0.018286805334652927]
	TIME [epoch: 36 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0182362681420883		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0182362681420883 | validation: 0.021318955377339847]
	TIME [epoch: 36 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.017424506183899076		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.017424506183899076 | validation: 0.011750714542757841]
	TIME [epoch: 36 sec]
	Saving model to: out/model_training/model_facs_dec1b_2d_v1_20240622_120511/states/model_facs_dec1b_2d_v1_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01702940807183743		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.01702940807183743 | validation: 0.011170240374631364]
	TIME [epoch: 36 sec]
	Saving model to: out/model_training/model_facs_dec1b_2d_v1_20240622_120511/states/model_facs_dec1b_2d_v1_24.pth
	Model improved!!!
EPOCH 25/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.013590322042529267		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.013590322042529267 | validation: 0.020474167641538026]
	TIME [epoch: 36 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011306138156141766		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.011306138156141766 | validation: 0.016542706786432295]
	TIME [epoch: 36 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.014992664206980576		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.014992664206980576 | validation: 0.01672843765767735]
	TIME [epoch: 36 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.015171249480246575		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.015171249480246575 | validation: 0.01359761295655948]
	TIME [epoch: 36 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01141229128561468		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.01141229128561468 | validation: 0.01471780023799533]
	TIME [epoch: 36 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.014267259557297192		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.014267259557297192 | validation: 0.010780723035464948]
	TIME [epoch: 36 sec]
	Saving model to: out/model_training/model_facs_dec1b_2d_v1_20240622_120511/states/model_facs_dec1b_2d_v1_30.pth
	Model improved!!!
EPOCH 31/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010219366954513243		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.010219366954513243 | validation: 0.013749139421058137]
	TIME [epoch: 36 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01569243782053412		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.01569243782053412 | validation: 0.027124700819749836]
	TIME [epoch: 36 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.016489582619426738		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.016489582619426738 | validation: 0.01091378004933618]
	TIME [epoch: 36 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011482074179148318		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.011482074179148318 | validation: 0.016061966501666212]
	TIME [epoch: 36 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012452604708565608		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.012452604708565608 | validation: 0.01684358907808224]
	TIME [epoch: 36 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.015182467168734547		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.015182467168734547 | validation: 0.010119910284573092]
	TIME [epoch: 36 sec]
	Saving model to: out/model_training/model_facs_dec1b_2d_v1_20240622_120511/states/model_facs_dec1b_2d_v1_36.pth
	Model improved!!!
EPOCH 37/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.013896839230321652		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.013896839230321652 | validation: 0.010168709798867045]
	TIME [epoch: 36 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.013984398168128456		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.013984398168128456 | validation: 0.02739066698339126]
	TIME [epoch: 36 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.017255245267764716		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.017255245267764716 | validation: 0.013406109219415785]
	TIME [epoch: 36 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01230729537078738		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.01230729537078738 | validation: 0.009590125826361345]
	TIME [epoch: 36 sec]
	Saving model to: out/model_training/model_facs_dec1b_2d_v1_20240622_120511/states/model_facs_dec1b_2d_v1_40.pth
	Model improved!!!
EPOCH 41/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012012364854252703		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.012012364854252703 | validation: 0.011579003909943864]
	TIME [epoch: 36 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.014688322535428974		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.014688322535428974 | validation: 0.03094944252286594]
	TIME [epoch: 36 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.014964302969067552		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.014964302969067552 | validation: 0.016346333412487864]
	TIME [epoch: 36 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.014883812477032006		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.014883812477032006 | validation: 0.00982241851218774]
	TIME [epoch: 36 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.014325044973359784		[learning rate: 0.0099823]
	Learning Rate: 0.0099823
	LOSS [training: 0.014325044973359784 | validation: 0.025079536737497504]
	TIME [epoch: 36 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.013052492973976525		[learning rate: 0.0099426]
	Learning Rate: 0.0099426
	LOSS [training: 0.013052492973976525 | validation: 0.020977656096767158]
	TIME [epoch: 36 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.015011866841922406		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 0.015011866841922406 | validation: 0.014005920292923042]
	TIME [epoch: 36 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.014731375255153917		[learning rate: 0.0098637]
	Learning Rate: 0.00986367
	LOSS [training: 0.014731375255153917 | validation: 0.014434675663295416]
	TIME [epoch: 36 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.013906154975166094		[learning rate: 0.0098244]
	Learning Rate: 0.00982444
	LOSS [training: 0.013906154975166094 | validation: 0.010840538371522537]
	TIME [epoch: 36 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.016312594849956483		[learning rate: 0.0097854]
	Learning Rate: 0.00978536
	LOSS [training: 0.016312594849956483 | validation: 0.014648515300347748]
	TIME [epoch: 36 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012673174352399159		[learning rate: 0.0097464]
	Learning Rate: 0.00974644
	LOSS [training: 0.012673174352399159 | validation: 0.03575312685907318]
	TIME [epoch: 36 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01444010901124636		[learning rate: 0.0097077]
	Learning Rate: 0.00970768
	LOSS [training: 0.01444010901124636 | validation: 0.01224755832421259]
	TIME [epoch: 36 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011054465832002959		[learning rate: 0.0096691]
	Learning Rate: 0.00966907
	LOSS [training: 0.011054465832002959 | validation: 0.019862130742099374]
	TIME [epoch: 36 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.019229578601909783		[learning rate: 0.0096306]
	Learning Rate: 0.00963061
	LOSS [training: 0.019229578601909783 | validation: 0.010788441952394888]
	TIME [epoch: 36 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011060312770499688		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 0.011060312770499688 | validation: 0.012442620154095422]
	TIME [epoch: 36 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.017141521757874076		[learning rate: 0.0095542]
	Learning Rate: 0.00955415
	LOSS [training: 0.017141521757874076 | validation: 0.011547750341091088]
	TIME [epoch: 36 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011386074082691738		[learning rate: 0.0095162]
	Learning Rate: 0.00951616
	LOSS [training: 0.011386074082691738 | validation: 0.018217991694258938]
	TIME [epoch: 36 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012035842190138493		[learning rate: 0.0094783]
	Learning Rate: 0.00947831
	LOSS [training: 0.012035842190138493 | validation: 0.01155270856243119]
	TIME [epoch: 36 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.017021111245354895		[learning rate: 0.0094406]
	Learning Rate: 0.00944061
	LOSS [training: 0.017021111245354895 | validation: 0.019202819335902344]
	TIME [epoch: 36 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.015297883226764033		[learning rate: 0.0094031]
	Learning Rate: 0.00940306
	LOSS [training: 0.015297883226764033 | validation: 0.01422848122606164]
	TIME [epoch: 36 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01465606683878862		[learning rate: 0.0093657]
	Learning Rate: 0.00936566
	LOSS [training: 0.01465606683878862 | validation: 0.009690332263154914]
	TIME [epoch: 36 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011358629782752502		[learning rate: 0.0093284]
	Learning Rate: 0.00932841
	LOSS [training: 0.011358629782752502 | validation: 0.014507688226067706]
	TIME [epoch: 36 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011595582806728174		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 0.011595582806728174 | validation: 0.01170791342557465]
	TIME [epoch: 36 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012426201900755964		[learning rate: 0.0092544]
	Learning Rate: 0.00925435
	LOSS [training: 0.012426201900755964 | validation: 0.010229290778099953]
	TIME [epoch: 35.9 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.013465743642062532		[learning rate: 0.0092175]
	Learning Rate: 0.00921755
	LOSS [training: 0.013465743642062532 | validation: 0.010500722166552503]
	TIME [epoch: 36 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010086176215738431		[learning rate: 0.0091809]
	Learning Rate: 0.00918089
	LOSS [training: 0.010086176215738431 | validation: 0.019958075499842475]
	TIME [epoch: 36 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.017012523950657152		[learning rate: 0.0091444]
	Learning Rate: 0.00914437
	LOSS [training: 0.017012523950657152 | validation: 0.009897769444633622]
	TIME [epoch: 36 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.015682616514692556		[learning rate: 0.009108]
	Learning Rate: 0.009108
	LOSS [training: 0.015682616514692556 | validation: 0.01008112875874541]
	TIME [epoch: 36 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011533582528651465		[learning rate: 0.0090718]
	Learning Rate: 0.00907178
	LOSS [training: 0.011533582528651465 | validation: 0.01664396567332533]
	TIME [epoch: 36 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.014959150366019334		[learning rate: 0.0090357]
	Learning Rate: 0.00903569
	LOSS [training: 0.014959150366019334 | validation: 0.016745069221435097]
	TIME [epoch: 36 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.014736696233948502		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 0.014736696233948502 | validation: 0.012374212034288023]
	TIME [epoch: 36 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012359374125672243		[learning rate: 0.008964]
	Learning Rate: 0.00896396
	LOSS [training: 0.012359374125672243 | validation: 0.01482072853633296]
	TIME [epoch: 36 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.014282668430487125		[learning rate: 0.0089283]
	Learning Rate: 0.00892831
	LOSS [training: 0.014282668430487125 | validation: 0.014789914225293275]
	TIME [epoch: 36 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01456200333831325		[learning rate: 0.0088928]
	Learning Rate: 0.0088928
	LOSS [training: 0.01456200333831325 | validation: 0.0253411340644352]
	TIME [epoch: 36 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.016688232276022577		[learning rate: 0.0088574]
	Learning Rate: 0.00885743
	LOSS [training: 0.016688232276022577 | validation: 0.011607052302578951]
	TIME [epoch: 36 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011043490850246127		[learning rate: 0.0088222]
	Learning Rate: 0.0088222
	LOSS [training: 0.011043490850246127 | validation: 0.013970456179015512]
	TIME [epoch: 36 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012958989381077443		[learning rate: 0.0087871]
	Learning Rate: 0.00878711
	LOSS [training: 0.012958989381077443 | validation: 0.009598592753507013]
	TIME [epoch: 36 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012822145314571822		[learning rate: 0.0087522]
	Learning Rate: 0.00875216
	LOSS [training: 0.012822145314571822 | validation: 0.01346822729854372]
	TIME [epoch: 36 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01403491685314816		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 0.01403491685314816 | validation: 0.010135456441426178]
	TIME [epoch: 36 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012739012148891254		[learning rate: 0.0086827]
	Learning Rate: 0.00868268
	LOSS [training: 0.012739012148891254 | validation: 0.015233878151206578]
	TIME [epoch: 36 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01532055742656118		[learning rate: 0.0086481]
	Learning Rate: 0.00864815
	LOSS [training: 0.01532055742656118 | validation: 0.010771574666266059]
	TIME [epoch: 36 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.018037267912538027		[learning rate: 0.0086138]
	Learning Rate: 0.00861375
	LOSS [training: 0.018037267912538027 | validation: 0.01913172251655029]
	TIME [epoch: 36 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.013659092254241698		[learning rate: 0.0085795]
	Learning Rate: 0.00857949
	LOSS [training: 0.013659092254241698 | validation: 0.010275869407323729]
	TIME [epoch: 36 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010556696303611193		[learning rate: 0.0085454]
	Learning Rate: 0.00854537
	LOSS [training: 0.010556696303611193 | validation: 0.010869145092752143]
	TIME [epoch: 36 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012847883859001904		[learning rate: 0.0085114]
	Learning Rate: 0.00851138
	LOSS [training: 0.012847883859001904 | validation: 0.009848847092129537]
	TIME [epoch: 36 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01139916775859266		[learning rate: 0.0084775]
	Learning Rate: 0.00847753
	LOSS [training: 0.01139916775859266 | validation: 0.018301719241013734]
	TIME [epoch: 36 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.015896565161429104		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 0.015896565161429104 | validation: 0.009589037885177124]
	TIME [epoch: 36 sec]
	Saving model to: out/model_training/model_facs_dec1b_2d_v1_20240622_120511/states/model_facs_dec1b_2d_v1_87.pth
	Model improved!!!
EPOCH 88/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011810424128099026		[learning rate: 0.0084102]
	Learning Rate: 0.00841023
	LOSS [training: 0.011810424128099026 | validation: 0.014279066726027339]
	TIME [epoch: 36 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011191013659274412		[learning rate: 0.0083768]
	Learning Rate: 0.00837678
	LOSS [training: 0.011191013659274412 | validation: 0.011878438745914668]
	TIME [epoch: 36 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012120173480340684		[learning rate: 0.0083435]
	Learning Rate: 0.00834346
	LOSS [training: 0.012120173480340684 | validation: 0.017914678959792426]
	TIME [epoch: 36 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.016996008853306783		[learning rate: 0.0083103]
	Learning Rate: 0.00831027
	LOSS [training: 0.016996008853306783 | validation: 0.011825502989128111]
	TIME [epoch: 36 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01600035256244512		[learning rate: 0.0082772]
	Learning Rate: 0.00827722
	LOSS [training: 0.01600035256244512 | validation: 0.009706682907701776]
	TIME [epoch: 36 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010987077311769964		[learning rate: 0.0082443]
	Learning Rate: 0.0082443
	LOSS [training: 0.010987077311769964 | validation: 0.017092568479859366]
	TIME [epoch: 36 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012520789754275096		[learning rate: 0.0082115]
	Learning Rate: 0.00821151
	LOSS [training: 0.012520789754275096 | validation: 0.01742650786310034]
	TIME [epoch: 36 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.015440596259065362		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 0.015440596259065362 | validation: 0.011393277176629099]
	TIME [epoch: 36 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011881258716574227		[learning rate: 0.0081463]
	Learning Rate: 0.00814632
	LOSS [training: 0.011881258716574227 | validation: 0.00936087824542955]
	TIME [epoch: 36 sec]
	Saving model to: out/model_training/model_facs_dec1b_2d_v1_20240622_120511/states/model_facs_dec1b_2d_v1_96.pth
	Model improved!!!
EPOCH 97/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011583833349064746		[learning rate: 0.0081139]
	Learning Rate: 0.00811392
	LOSS [training: 0.011583833349064746 | validation: 0.007894641776176662]
	TIME [epoch: 36 sec]
	Saving model to: out/model_training/model_facs_dec1b_2d_v1_20240622_120511/states/model_facs_dec1b_2d_v1_97.pth
	Model improved!!!
EPOCH 98/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.014702831806905896		[learning rate: 0.0080816]
	Learning Rate: 0.00808165
	LOSS [training: 0.014702831806905896 | validation: 0.017976378148652335]
	TIME [epoch: 36 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012940444717605977		[learning rate: 0.0080495]
	Learning Rate: 0.00804951
	LOSS [training: 0.012940444717605977 | validation: 0.014136563609193548]
	TIME [epoch: 36 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012160270668444726		[learning rate: 0.0080175]
	Learning Rate: 0.00801749
	LOSS [training: 0.012160270668444726 | validation: 0.03309977122812091]
	TIME [epoch: 36 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.02047541840697634		[learning rate: 0.0079856]
	Learning Rate: 0.0079856
	LOSS [training: 0.02047541840697634 | validation: 0.014876037891075066]
	TIME [epoch: 36 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010690251814503608		[learning rate: 0.0079538]
	Learning Rate: 0.00795384
	LOSS [training: 0.010690251814503608 | validation: 0.010542552573835256]
	TIME [epoch: 36 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.013073011587389329		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 0.013073011587389329 | validation: 0.02180396231920598]
	TIME [epoch: 36 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.013606851997093848		[learning rate: 0.0078907]
	Learning Rate: 0.0078907
	LOSS [training: 0.013606851997093848 | validation: 0.00849434489119202]
	TIME [epoch: 36 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011980965806275142		[learning rate: 0.0078593]
	Learning Rate: 0.00785931
	LOSS [training: 0.011980965806275142 | validation: 0.014016073714151473]
	TIME [epoch: 36 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.013172801458242994		[learning rate: 0.0078281]
	Learning Rate: 0.00782805
	LOSS [training: 0.013172801458242994 | validation: 0.009177303513627236]
	TIME [epoch: 36 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.013108377424994124		[learning rate: 0.0077969]
	Learning Rate: 0.00779692
	LOSS [training: 0.013108377424994124 | validation: 0.012209681879745849]
	TIME [epoch: 36 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.014216166249580322		[learning rate: 0.0077659]
	Learning Rate: 0.00776591
	LOSS [training: 0.014216166249580322 | validation: 0.016273210132583038]
	TIME [epoch: 36 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012448015833088643		[learning rate: 0.007735]
	Learning Rate: 0.00773502
	LOSS [training: 0.012448015833088643 | validation: 0.01260735948515479]
	TIME [epoch: 36 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01130566135812863		[learning rate: 0.0077043]
	Learning Rate: 0.00770426
	LOSS [training: 0.01130566135812863 | validation: 0.009431644145688003]
	TIME [epoch: 36 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012171471223460904		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 0.012171471223460904 | validation: 0.015732978229655324]
	TIME [epoch: 36 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01344462430989486		[learning rate: 0.0076431]
	Learning Rate: 0.00764309
	LOSS [training: 0.01344462430989486 | validation: 0.011060445443033761]
	TIME [epoch: 36 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01185464425627411		[learning rate: 0.0076127]
	Learning Rate: 0.00761269
	LOSS [training: 0.01185464425627411 | validation: 0.010815290926395944]
	TIME [epoch: 36 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012308755168835428		[learning rate: 0.0075824]
	Learning Rate: 0.00758242
	LOSS [training: 0.012308755168835428 | validation: 0.010270149202814164]
	TIME [epoch: 36 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010993372003145017		[learning rate: 0.0075523]
	Learning Rate: 0.00755226
	LOSS [training: 0.010993372003145017 | validation: 0.013044774628609168]
	TIME [epoch: 36 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011648966192974916		[learning rate: 0.0075222]
	Learning Rate: 0.00752222
	LOSS [training: 0.011648966192974916 | validation: 0.025544651352040832]
	TIME [epoch: 36 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012816520931157073		[learning rate: 0.0074923]
	Learning Rate: 0.0074923
	LOSS [training: 0.012816520931157073 | validation: 0.012092244941161442]
	TIME [epoch: 36 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012444903620668068		[learning rate: 0.0074625]
	Learning Rate: 0.0074625
	LOSS [training: 0.012444903620668068 | validation: 0.016818519380096014]
	TIME [epoch: 36 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.013797612909709107		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 0.013797612909709107 | validation: 0.009452686466010338]
	TIME [epoch: 36 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011120215952343667		[learning rate: 0.0074033]
	Learning Rate: 0.00740326
	LOSS [training: 0.011120215952343667 | validation: 0.010111402507715975]
	TIME [epoch: 36 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012019478908501037		[learning rate: 0.0073738]
	Learning Rate: 0.00737382
	LOSS [training: 0.012019478908501037 | validation: 0.010438571217357865]
	TIME [epoch: 36 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011953933757637158		[learning rate: 0.0073445]
	Learning Rate: 0.00734449
	LOSS [training: 0.011953933757637158 | validation: 0.011178364312026044]
	TIME [epoch: 36 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.015354187122267679		[learning rate: 0.0073153]
	Learning Rate: 0.00731528
	LOSS [training: 0.015354187122267679 | validation: 0.014121381478837647]
	TIME [epoch: 36 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012215974710413708		[learning rate: 0.0072862]
	Learning Rate: 0.00728618
	LOSS [training: 0.012215974710413708 | validation: 0.010043642056360378]
	TIME [epoch: 36 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009718872569431004		[learning rate: 0.0072572]
	Learning Rate: 0.0072572
	LOSS [training: 0.009718872569431004 | validation: 0.015281063209428097]
	TIME [epoch: 36 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011530541895326138		[learning rate: 0.0072283]
	Learning Rate: 0.00722834
	LOSS [training: 0.011530541895326138 | validation: 0.011868879759419648]
	TIME [epoch: 36 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010896418885957078		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 0.010896418885957078 | validation: 0.009780052379480032]
	TIME [epoch: 36 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.013328023167097839		[learning rate: 0.007171]
	Learning Rate: 0.00717095
	LOSS [training: 0.013328023167097839 | validation: 0.01406320186787866]
	TIME [epoch: 36 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010634652206298285		[learning rate: 0.0071424]
	Learning Rate: 0.00714243
	LOSS [training: 0.010634652206298285 | validation: 0.016756080855323315]
	TIME [epoch: 36 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.015286233964073517		[learning rate: 0.007114]
	Learning Rate: 0.00711403
	LOSS [training: 0.015286233964073517 | validation: 0.03547615047016541]
	TIME [epoch: 36 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.013769611575680532		[learning rate: 0.0070857]
	Learning Rate: 0.00708573
	LOSS [training: 0.013769611575680532 | validation: 0.011010033333395968]
	TIME [epoch: 36 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010154581081879293		[learning rate: 0.0070575]
	Learning Rate: 0.00705755
	LOSS [training: 0.010154581081879293 | validation: 0.00982814051937293]
	TIME [epoch: 36 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011020157838707852		[learning rate: 0.0070295]
	Learning Rate: 0.00702948
	LOSS [training: 0.011020157838707852 | validation: 0.01192402125905943]
	TIME [epoch: 36 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012525508261508871		[learning rate: 0.0070015]
	Learning Rate: 0.00700152
	LOSS [training: 0.012525508261508871 | validation: 0.008261593388667646]
	TIME [epoch: 35.9 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012780942411196343		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 0.012780942411196343 | validation: 0.010768302987522729]
	TIME [epoch: 36 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.013662764853656957		[learning rate: 0.0069459]
	Learning Rate: 0.00694594
	LOSS [training: 0.013662764853656957 | validation: 0.01009242637532548]
	TIME [epoch: 36 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01219518808913408		[learning rate: 0.0069183]
	Learning Rate: 0.00691831
	LOSS [training: 0.01219518808913408 | validation: 0.01168609565653869]
	TIME [epoch: 35.9 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010760791467061949		[learning rate: 0.0068908]
	Learning Rate: 0.00689079
	LOSS [training: 0.010760791467061949 | validation: 0.011146099684075749]
	TIME [epoch: 36 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011906915215274615		[learning rate: 0.0068634]
	Learning Rate: 0.00686339
	LOSS [training: 0.011906915215274615 | validation: 0.01005077039974259]
	TIME [epoch: 36 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010281844400060802		[learning rate: 0.0068361]
	Learning Rate: 0.00683609
	LOSS [training: 0.010281844400060802 | validation: 0.009399590898059626]
	TIME [epoch: 36 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.014353385645412078		[learning rate: 0.0068089]
	Learning Rate: 0.0068089
	LOSS [training: 0.014353385645412078 | validation: 0.010751319977130702]
	TIME [epoch: 35.9 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01232547330313981		[learning rate: 0.0067818]
	Learning Rate: 0.00678182
	LOSS [training: 0.01232547330313981 | validation: 0.008954530185654255]
	TIME [epoch: 35.9 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010883091909557059		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 0.010883091909557059 | validation: 0.010707323119395054]
	TIME [epoch: 36 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012710649140717649		[learning rate: 0.006728]
	Learning Rate: 0.00672798
	LOSS [training: 0.012710649140717649 | validation: 0.01405785841588179]
	TIME [epoch: 36 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012918479733858578		[learning rate: 0.0067012]
	Learning Rate: 0.00670122
	LOSS [training: 0.012918479733858578 | validation: 0.010829605223797611]
	TIME [epoch: 36 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0133662811209812		[learning rate: 0.0066746]
	Learning Rate: 0.00667457
	LOSS [training: 0.0133662811209812 | validation: 0.008656679218445307]
	TIME [epoch: 36 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01094857150312123		[learning rate: 0.006648]
	Learning Rate: 0.00664802
	LOSS [training: 0.01094857150312123 | validation: 0.00782348117041912]
	TIME [epoch: 35.9 sec]
	Saving model to: out/model_training/model_facs_dec1b_2d_v1_20240622_120511/states/model_facs_dec1b_2d_v1_147.pth
	Model improved!!!
EPOCH 148/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011637000351098511		[learning rate: 0.0066216]
	Learning Rate: 0.00662158
	LOSS [training: 0.011637000351098511 | validation: 0.008401497667626422]
	TIME [epoch: 36 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010773259171268567		[learning rate: 0.0065952]
	Learning Rate: 0.00659524
	LOSS [training: 0.010773259171268567 | validation: 0.009499788912017993]
	TIME [epoch: 36 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010514138825963724		[learning rate: 0.006569]
	Learning Rate: 0.00656901
	LOSS [training: 0.010514138825963724 | validation: 0.012364589006566066]
	TIME [epoch: 36 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01461638800628536		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 0.01461638800628536 | validation: 0.00855516455435312]
	TIME [epoch: 36 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009974837890402101		[learning rate: 0.0065169]
	Learning Rate: 0.00651686
	LOSS [training: 0.009974837890402101 | validation: 0.012372122683927306]
	TIME [epoch: 36 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.014597668120050656		[learning rate: 0.0064909]
	Learning Rate: 0.00649094
	LOSS [training: 0.014597668120050656 | validation: 0.00890876993096856]
	TIME [epoch: 36 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011675748970093804		[learning rate: 0.0064651]
	Learning Rate: 0.00646512
	LOSS [training: 0.011675748970093804 | validation: 0.014624155952518791]
	TIME [epoch: 36 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01289426626874058		[learning rate: 0.0064394]
	Learning Rate: 0.00643941
	LOSS [training: 0.01289426626874058 | validation: 0.008297502967982156]
	TIME [epoch: 36 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011079304133909526		[learning rate: 0.0064138]
	Learning Rate: 0.0064138
	LOSS [training: 0.011079304133909526 | validation: 0.009671592885335988]
	TIME [epoch: 36 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011959977899823546		[learning rate: 0.0063883]
	Learning Rate: 0.00638829
	LOSS [training: 0.011959977899823546 | validation: 0.016221717498519535]
	TIME [epoch: 36 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0161905861530005		[learning rate: 0.0063629]
	Learning Rate: 0.00636288
	LOSS [training: 0.0161905861530005 | validation: 0.008966058876637262]
	TIME [epoch: 36 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00923446518452789		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 0.00923446518452789 | validation: 0.013263585258322932]
	TIME [epoch: 36 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01366446925112764		[learning rate: 0.0063124]
	Learning Rate: 0.00631237
	LOSS [training: 0.01366446925112764 | validation: 0.01006225806795844]
	TIME [epoch: 35.9 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.013610372527192365		[learning rate: 0.0062873]
	Learning Rate: 0.00628726
	LOSS [training: 0.013610372527192365 | validation: 0.01182537089076902]
	TIME [epoch: 36 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010701565018847002		[learning rate: 0.0062623]
	Learning Rate: 0.00626226
	LOSS [training: 0.010701565018847002 | validation: 0.00986269844221304]
	TIME [epoch: 36 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01042309296168717		[learning rate: 0.0062373]
	Learning Rate: 0.00623735
	LOSS [training: 0.01042309296168717 | validation: 0.01445400026114527]
	TIME [epoch: 35.9 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010125709988103805		[learning rate: 0.0062125]
	Learning Rate: 0.00621254
	LOSS [training: 0.010125709988103805 | validation: 0.02059578614943885]
	TIME [epoch: 36 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.013237577198283107		[learning rate: 0.0061878]
	Learning Rate: 0.00618783
	LOSS [training: 0.013237577198283107 | validation: 0.015738713474051282]
	TIME [epoch: 35.9 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.013954787844138335		[learning rate: 0.0061632]
	Learning Rate: 0.00616322
	LOSS [training: 0.013954787844138335 | validation: 0.01154800238134413]
	TIME [epoch: 36 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.013985636164357959		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 0.013985636164357959 | validation: 0.009525648685907155]
	TIME [epoch: 36 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010851415503020517		[learning rate: 0.0061143]
	Learning Rate: 0.00611429
	LOSS [training: 0.010851415503020517 | validation: 0.007783490965231813]
	TIME [epoch: 36 sec]
	Saving model to: out/model_training/model_facs_dec1b_2d_v1_20240622_120511/states/model_facs_dec1b_2d_v1_168.pth
	Model improved!!!
EPOCH 169/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011520178335779683		[learning rate: 0.00609]
	Learning Rate: 0.00608997
	LOSS [training: 0.011520178335779683 | validation: 0.008952460569732748]
	TIME [epoch: 36 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010407741054874546		[learning rate: 0.0060658]
	Learning Rate: 0.00606575
	LOSS [training: 0.010407741054874546 | validation: 0.009557170891617414]
	TIME [epoch: 36 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010522482055024792		[learning rate: 0.0060416]
	Learning Rate: 0.00604163
	LOSS [training: 0.010522482055024792 | validation: 0.012841791109277457]
	TIME [epoch: 36 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010221095157477076		[learning rate: 0.0060176]
	Learning Rate: 0.0060176
	LOSS [training: 0.010221095157477076 | validation: 0.008921194311696908]
	TIME [epoch: 36 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009306233270913669		[learning rate: 0.0059937]
	Learning Rate: 0.00599366
	LOSS [training: 0.009306233270913669 | validation: 0.01580281850957752]
	TIME [epoch: 36 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.016510636182677223		[learning rate: 0.0059698]
	Learning Rate: 0.00596982
	LOSS [training: 0.016510636182677223 | validation: 0.013663998215983849]
	TIME [epoch: 36 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010288775599022554		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 0.010288775599022554 | validation: 0.010275186902740829]
	TIME [epoch: 36 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011598896925923205		[learning rate: 0.0059224]
	Learning Rate: 0.00592243
	LOSS [training: 0.011598896925923205 | validation: 0.007116677159428949]
	TIME [epoch: 36 sec]
	Saving model to: out/model_training/model_facs_dec1b_2d_v1_20240622_120511/states/model_facs_dec1b_2d_v1_176.pth
	Model improved!!!
EPOCH 177/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008639278581669244		[learning rate: 0.0058989]
	Learning Rate: 0.00589888
	LOSS [training: 0.008639278581669244 | validation: 0.013927396869203875]
	TIME [epoch: 36 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010219226116299667		[learning rate: 0.0058754]
	Learning Rate: 0.00587541
	LOSS [training: 0.010219226116299667 | validation: 0.009967282919881568]
	TIME [epoch: 36 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010568932246760464		[learning rate: 0.005852]
	Learning Rate: 0.00585205
	LOSS [training: 0.010568932246760464 | validation: 0.011653416552829376]
	TIME [epoch: 36 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010753353763160221		[learning rate: 0.0058288]
	Learning Rate: 0.00582877
	LOSS [training: 0.010753353763160221 | validation: 0.011562329352254928]
	TIME [epoch: 36 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011399639135377266		[learning rate: 0.0058056]
	Learning Rate: 0.00580559
	LOSS [training: 0.011399639135377266 | validation: 0.008747251713513529]
	TIME [epoch: 36 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011944065154105078		[learning rate: 0.0057825]
	Learning Rate: 0.0057825
	LOSS [training: 0.011944065154105078 | validation: 0.011864729153996648]
	TIME [epoch: 36 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011867038967051298		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 0.011867038967051298 | validation: 0.010102949564145983]
	TIME [epoch: 36 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011645687879265587		[learning rate: 0.0057366]
	Learning Rate: 0.00573659
	LOSS [training: 0.011645687879265587 | validation: 0.008985155868339086]
	TIME [epoch: 36 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010635846216152938		[learning rate: 0.0057138]
	Learning Rate: 0.00571377
	LOSS [training: 0.010635846216152938 | validation: 0.010704317553095968]
	TIME [epoch: 36 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0115377889919939		[learning rate: 0.005691]
	Learning Rate: 0.00569105
	LOSS [training: 0.0115377889919939 | validation: 0.007660771126345778]
	TIME [epoch: 35.9 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009647175363970108		[learning rate: 0.0056684]
	Learning Rate: 0.00566841
	LOSS [training: 0.009647175363970108 | validation: 0.011101150587149436]
	TIME [epoch: 36 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01103910530416426		[learning rate: 0.0056459]
	Learning Rate: 0.00564587
	LOSS [training: 0.01103910530416426 | validation: 0.011100291190534324]
	TIME [epoch: 35.9 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01235635188431233		[learning rate: 0.0056234]
	Learning Rate: 0.00562341
	LOSS [training: 0.01235635188431233 | validation: 0.011759213674900515]
	TIME [epoch: 36 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009811641393225568		[learning rate: 0.005601]
	Learning Rate: 0.00560105
	LOSS [training: 0.009811641393225568 | validation: 0.00818559286869303]
	TIME [epoch: 35.9 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012603065155316628		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 0.012603065155316628 | validation: 0.007337417887629108]
	TIME [epoch: 36 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.013289338917285084		[learning rate: 0.0055566]
	Learning Rate: 0.00555658
	LOSS [training: 0.013289338917285084 | validation: 0.007922378779481308]
	TIME [epoch: 35.9 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009388604066101784		[learning rate: 0.0055345]
	Learning Rate: 0.00553448
	LOSS [training: 0.009388604066101784 | validation: 0.01218424268851423]
	TIME [epoch: 36 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010703428662155352		[learning rate: 0.0055125]
	Learning Rate: 0.00551247
	LOSS [training: 0.010703428662155352 | validation: 0.012213807034885555]
	TIME [epoch: 36 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01233789226158618		[learning rate: 0.0054905]
	Learning Rate: 0.00549054
	LOSS [training: 0.01233789226158618 | validation: 0.007551520382374469]
	TIME [epoch: 36 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012762459165643832		[learning rate: 0.0054687]
	Learning Rate: 0.00546871
	LOSS [training: 0.012762459165643832 | validation: 0.011260324100376745]
	TIME [epoch: 36 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008735837260879812		[learning rate: 0.005447]
	Learning Rate: 0.00544696
	LOSS [training: 0.008735837260879812 | validation: 0.012644366161912585]
	TIME [epoch: 36 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.014860964186892311		[learning rate: 0.0054253]
	Learning Rate: 0.00542529
	LOSS [training: 0.014860964186892311 | validation: 0.01365155344348123]
	TIME [epoch: 35.9 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009987948044377599		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 0.009987948044377599 | validation: 0.011338414166380005]
	TIME [epoch: 35.9 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.015642247217074346		[learning rate: 0.0053822]
	Learning Rate: 0.00538222
	LOSS [training: 0.015642247217074346 | validation: 0.007416226041248755]
	TIME [epoch: 35.9 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009147323973186995		[learning rate: 0.0053608]
	Learning Rate: 0.00536081
	LOSS [training: 0.009147323973186995 | validation: 0.013518096409523808]
	TIME [epoch: 36 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01104957588598248		[learning rate: 0.0053395]
	Learning Rate: 0.00533949
	LOSS [training: 0.01104957588598248 | validation: 0.008059070055881506]
	TIME [epoch: 35.9 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011650969535823653		[learning rate: 0.0053183]
	Learning Rate: 0.00531826
	LOSS [training: 0.011650969535823653 | validation: 0.015211378937056041]
	TIME [epoch: 36 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.013287807643628968		[learning rate: 0.0052971]
	Learning Rate: 0.0052971
	LOSS [training: 0.013287807643628968 | validation: 0.011266339357833758]
	TIME [epoch: 36 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011270047982857027		[learning rate: 0.005276]
	Learning Rate: 0.00527604
	LOSS [training: 0.011270047982857027 | validation: 0.012480629604862565]
	TIME [epoch: 36.2 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010667981405776544		[learning rate: 0.0052551]
	Learning Rate: 0.00525505
	LOSS [training: 0.010667981405776544 | validation: 0.01041937431397984]
	TIME [epoch: 36 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011177022972547614		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 0.011177022972547614 | validation: 0.013421024916153731]
	TIME [epoch: 36 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011381847743217734		[learning rate: 0.0052133]
	Learning Rate: 0.00521333
	LOSS [training: 0.011381847743217734 | validation: 0.01039853325510853]
	TIME [epoch: 36 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010019911555509253		[learning rate: 0.0051926]
	Learning Rate: 0.0051926
	LOSS [training: 0.010019911555509253 | validation: 0.009125280095042685]
	TIME [epoch: 36 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009715593257694454		[learning rate: 0.0051719]
	Learning Rate: 0.00517194
	LOSS [training: 0.009715593257694454 | validation: 0.013679323859274672]
	TIME [epoch: 36 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012211391208951572		[learning rate: 0.0051514]
	Learning Rate: 0.00515137
	LOSS [training: 0.012211391208951572 | validation: 0.009165398863183611]
	TIME [epoch: 36 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009073781622968536		[learning rate: 0.0051309]
	Learning Rate: 0.00513089
	LOSS [training: 0.009073781622968536 | validation: 0.009148870813605842]
	TIME [epoch: 36 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011391536244293343		[learning rate: 0.0051105]
	Learning Rate: 0.00511048
	LOSS [training: 0.011391536244293343 | validation: 0.01018119153131894]
	TIME [epoch: 36 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009986470784914126		[learning rate: 0.0050902]
	Learning Rate: 0.00509015
	LOSS [training: 0.009986470784914126 | validation: 0.010263302832853937]
	TIME [epoch: 36 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009944882612979114		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 0.009944882612979114 | validation: 0.011258328047016737]
	TIME [epoch: 36 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011556979641240729		[learning rate: 0.0050497]
	Learning Rate: 0.00504974
	LOSS [training: 0.011556979641240729 | validation: 0.0123936108462192]
	TIME [epoch: 35.9 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010711884319639835		[learning rate: 0.0050297]
	Learning Rate: 0.00502966
	LOSS [training: 0.010711884319639835 | validation: 0.008921531003342857]
	TIME [epoch: 36 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008981100776677835		[learning rate: 0.0050097]
	Learning Rate: 0.00500965
	LOSS [training: 0.008981100776677835 | validation: 0.009213576865789514]
	TIME [epoch: 36 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008821491691458506		[learning rate: 0.0049897]
	Learning Rate: 0.00498973
	LOSS [training: 0.008821491691458506 | validation: 0.009951907637455683]
	TIME [epoch: 36 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009740897391752483		[learning rate: 0.0049699]
	Learning Rate: 0.00496988
	LOSS [training: 0.009740897391752483 | validation: 0.016607064627079362]
	TIME [epoch: 36 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012244610980365401		[learning rate: 0.0049501]
	Learning Rate: 0.00495012
	LOSS [training: 0.012244610980365401 | validation: 0.0090283175153544]
	TIME [epoch: 36 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010150796588885833		[learning rate: 0.0049304]
	Learning Rate: 0.00493043
	LOSS [training: 0.010150796588885833 | validation: 0.009469017973502317]
	TIME [epoch: 36 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009856286135113539		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 0.009856286135113539 | validation: 0.008710035295787103]
	TIME [epoch: 36 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011219094613026037		[learning rate: 0.0048913]
	Learning Rate: 0.00489129
	LOSS [training: 0.011219094613026037 | validation: 0.008260531706393404]
	TIME [epoch: 36 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01022835576673782		[learning rate: 0.0048718]
	Learning Rate: 0.00487183
	LOSS [training: 0.01022835576673782 | validation: 0.008649240946968879]
	TIME [epoch: 36 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009474731657026617		[learning rate: 0.0048525]
	Learning Rate: 0.00485245
	LOSS [training: 0.009474731657026617 | validation: 0.008539110208481002]
	TIME [epoch: 36 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010748987361881797		[learning rate: 0.0048332]
	Learning Rate: 0.00483316
	LOSS [training: 0.010748987361881797 | validation: 0.007932003635434249]
	TIME [epoch: 36 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011148071601552826		[learning rate: 0.0048139]
	Learning Rate: 0.00481393
	LOSS [training: 0.011148071601552826 | validation: 0.010734106427571995]
	TIME [epoch: 36 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012912696758282384		[learning rate: 0.0047948]
	Learning Rate: 0.00479479
	LOSS [training: 0.012912696758282384 | validation: 0.011370366587172196]
	TIME [epoch: 36 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010851394009911164		[learning rate: 0.0047757]
	Learning Rate: 0.00477572
	LOSS [training: 0.010851394009911164 | validation: 0.007904849319946736]
	TIME [epoch: 35.9 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0101439714793116		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.0101439714793116 | validation: 0.011400746500528556]
	TIME [epoch: 36 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009719514324101529		[learning rate: 0.0047378]
	Learning Rate: 0.0047378
	LOSS [training: 0.009719514324101529 | validation: 0.008948060291951962]
	TIME [epoch: 36 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01113250828784082		[learning rate: 0.004719]
	Learning Rate: 0.00471896
	LOSS [training: 0.01113250828784082 | validation: 0.009319204436027531]
	TIME [epoch: 35.9 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010634015311268667		[learning rate: 0.0047002]
	Learning Rate: 0.00470019
	LOSS [training: 0.010634015311268667 | validation: 0.00704023321056575]
	TIME [epoch: 36 sec]
	Saving model to: out/model_training/model_facs_dec1b_2d_v1_20240622_120511/states/model_facs_dec1b_2d_v1_234.pth
	Model improved!!!
EPOCH 235/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008636301932584968		[learning rate: 0.0046815]
	Learning Rate: 0.0046815
	LOSS [training: 0.008636301932584968 | validation: 0.009842231002287863]
	TIME [epoch: 36 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009848415103945582		[learning rate: 0.0046629]
	Learning Rate: 0.00466288
	LOSS [training: 0.009848415103945582 | validation: 0.012112507994003718]
	TIME [epoch: 35.9 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011671449287997309		[learning rate: 0.0046443]
	Learning Rate: 0.00464433
	LOSS [training: 0.011671449287997309 | validation: 0.009847765506547854]
	TIME [epoch: 36 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012163057606763799		[learning rate: 0.0046259]
	Learning Rate: 0.00462586
	LOSS [training: 0.012163057606763799 | validation: 0.007966184307009096]
	TIME [epoch: 35.9 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009455252606077968		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 0.009455252606077968 | validation: 0.008509373824156428]
	TIME [epoch: 36 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010199282000174377		[learning rate: 0.0045891]
	Learning Rate: 0.00458913
	LOSS [training: 0.010199282000174377 | validation: 0.011761149383947293]
	TIME [epoch: 36 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010638361281058408		[learning rate: 0.0045709]
	Learning Rate: 0.00457088
	LOSS [training: 0.010638361281058408 | validation: 0.008548337812154926]
	TIME [epoch: 36 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01000607328131964		[learning rate: 0.0045527]
	Learning Rate: 0.0045527
	LOSS [training: 0.01000607328131964 | validation: 0.009608609300335923]
	TIME [epoch: 35.9 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008903624793863509		[learning rate: 0.0045346]
	Learning Rate: 0.00453459
	LOSS [training: 0.008903624793863509 | validation: 0.008472798545418181]
	TIME [epoch: 35.9 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009585215182351385		[learning rate: 0.0045166]
	Learning Rate: 0.00451656
	LOSS [training: 0.009585215182351385 | validation: 0.007524594399515516]
	TIME [epoch: 36 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008546074439860444		[learning rate: 0.0044986]
	Learning Rate: 0.0044986
	LOSS [training: 0.008546074439860444 | validation: 0.010635702015780058]
	TIME [epoch: 36 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009110132877378921		[learning rate: 0.0044807]
	Learning Rate: 0.0044807
	LOSS [training: 0.009110132877378921 | validation: 0.012069958209828324]
	TIME [epoch: 35.9 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011797907755604235		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 0.011797907755604235 | validation: 0.007714035859481508]
	TIME [epoch: 36 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010594013677747136		[learning rate: 0.0044451]
	Learning Rate: 0.00444513
	LOSS [training: 0.010594013677747136 | validation: 0.00980071416758483]
	TIME [epoch: 35.9 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012482765614066159		[learning rate: 0.0044275]
	Learning Rate: 0.00442745
	LOSS [training: 0.012482765614066159 | validation: 0.008870365816311367]
	TIME [epoch: 36 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009434264769019932		[learning rate: 0.0044098]
	Learning Rate: 0.00440984
	LOSS [training: 0.009434264769019932 | validation: 0.009540097599896494]
	TIME [epoch: 36 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010302962465418416		[learning rate: 0.0043923]
	Learning Rate: 0.0043923
	LOSS [training: 0.010302962465418416 | validation: 0.007931837628587918]
	TIME [epoch: 36 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011137556939216718		[learning rate: 0.0043748]
	Learning Rate: 0.00437483
	LOSS [training: 0.011137556939216718 | validation: 0.007739950313954039]
	TIME [epoch: 36 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010327666188487135		[learning rate: 0.0043574]
	Learning Rate: 0.00435743
	LOSS [training: 0.010327666188487135 | validation: 0.008250793048989463]
	TIME [epoch: 36 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011589109333033469		[learning rate: 0.0043401]
	Learning Rate: 0.0043401
	LOSS [training: 0.011589109333033469 | validation: 0.008086770788214586]
	TIME [epoch: 36 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009892326283108934		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 0.009892326283108934 | validation: 0.008255538140478231]
	TIME [epoch: 36 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010278198508866106		[learning rate: 0.0043056]
	Learning Rate: 0.00430565
	LOSS [training: 0.010278198508866106 | validation: 0.01265244665800772]
	TIME [epoch: 36 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010975480595483629		[learning rate: 0.0042885]
	Learning Rate: 0.00428852
	LOSS [training: 0.010975480595483629 | validation: 0.008340391628844368]
	TIME [epoch: 36 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011414616088696357		[learning rate: 0.0042715]
	Learning Rate: 0.00427147
	LOSS [training: 0.011414616088696357 | validation: 0.008460680395946834]
	TIME [epoch: 36 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010337285263322941		[learning rate: 0.0042545]
	Learning Rate: 0.00425448
	LOSS [training: 0.010337285263322941 | validation: 0.0068112421476833164]
	TIME [epoch: 36 sec]
	Saving model to: out/model_training/model_facs_dec1b_2d_v1_20240622_120511/states/model_facs_dec1b_2d_v1_259.pth
	Model improved!!!
EPOCH 260/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009510376169968677		[learning rate: 0.0042376]
	Learning Rate: 0.00423756
	LOSS [training: 0.009510376169968677 | validation: 0.007549292753675707]
	TIME [epoch: 36 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009862134823417076		[learning rate: 0.0042207]
	Learning Rate: 0.0042207
	LOSS [training: 0.009862134823417076 | validation: 0.00827195887007845]
	TIME [epoch: 36 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011587617358988		[learning rate: 0.0042039]
	Learning Rate: 0.00420391
	LOSS [training: 0.011587617358988 | validation: 0.008672325582616564]
	TIME [epoch: 36 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.013511159581601269		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 0.013511159581601269 | validation: 0.007969720080353966]
	TIME [epoch: 36 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010249371044005563		[learning rate: 0.0041705]
	Learning Rate: 0.00417054
	LOSS [training: 0.010249371044005563 | validation: 0.00867137420351737]
	TIME [epoch: 35.9 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011033083189109479		[learning rate: 0.004154]
	Learning Rate: 0.00415395
	LOSS [training: 0.011033083189109479 | validation: 0.007552497126784946]
	TIME [epoch: 35.9 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010832943649047936		[learning rate: 0.0041374]
	Learning Rate: 0.00413743
	LOSS [training: 0.010832943649047936 | validation: 0.00835279830497564]
	TIME [epoch: 36 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010600326931333441		[learning rate: 0.004121]
	Learning Rate: 0.00412098
	LOSS [training: 0.010600326931333441 | validation: 0.008633116553404072]
	TIME [epoch: 35.9 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011192038517787526		[learning rate: 0.0041046]
	Learning Rate: 0.00410458
	LOSS [training: 0.011192038517787526 | validation: 0.022120073777460038]
	TIME [epoch: 36 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012533189192911527		[learning rate: 0.0040883]
	Learning Rate: 0.00408826
	LOSS [training: 0.012533189192911527 | validation: 0.010309161755509893]
	TIME [epoch: 35.9 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011298595999949899		[learning rate: 0.004072]
	Learning Rate: 0.004072
	LOSS [training: 0.011298595999949899 | validation: 0.009061410692161539]
	TIME [epoch: 36 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010100553631180061		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.010100553631180061 | validation: 0.008461313542593957]
	TIME [epoch: 36 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012931343451427177		[learning rate: 0.0040397]
	Learning Rate: 0.00403967
	LOSS [training: 0.012931343451427177 | validation: 0.008637058669249438]
	TIME [epoch: 36 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012526324150548183		[learning rate: 0.0040236]
	Learning Rate: 0.00402361
	LOSS [training: 0.012526324150548183 | validation: 0.018086411510104282]
	TIME [epoch: 35.9 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.014200357138609473		[learning rate: 0.0040076]
	Learning Rate: 0.0040076
	LOSS [training: 0.014200357138609473 | validation: 0.007330089849686935]
	TIME [epoch: 36 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009984570051225609		[learning rate: 0.0039917]
	Learning Rate: 0.00399166
	LOSS [training: 0.009984570051225609 | validation: 0.007721718578780808]
	TIME [epoch: 36 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010036894619003513		[learning rate: 0.0039758]
	Learning Rate: 0.00397579
	LOSS [training: 0.010036894619003513 | validation: 0.007503824441762133]
	TIME [epoch: 36 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010703184131311987		[learning rate: 0.00396]
	Learning Rate: 0.00395997
	LOSS [training: 0.010703184131311987 | validation: 0.01043682798188077]
	TIME [epoch: 36 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010582302390296248		[learning rate: 0.0039442]
	Learning Rate: 0.00394422
	LOSS [training: 0.010582302390296248 | validation: 0.009093911685606412]
	TIME [epoch: 36 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.013573718011282666		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 0.013573718011282666 | validation: 0.00794860872113274]
	TIME [epoch: 36 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009395485210408817		[learning rate: 0.0039129]
	Learning Rate: 0.00391291
	LOSS [training: 0.009395485210408817 | validation: 0.008164853244520024]
	TIME [epoch: 36 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008796805250884696		[learning rate: 0.0038973]
	Learning Rate: 0.00389735
	LOSS [training: 0.008796805250884696 | validation: 0.012404949800402913]
	TIME [epoch: 36 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011207648890192233		[learning rate: 0.0038818]
	Learning Rate: 0.00388185
	LOSS [training: 0.011207648890192233 | validation: 0.008609501377766544]
	TIME [epoch: 35.9 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010341764268628907		[learning rate: 0.0038664]
	Learning Rate: 0.00386641
	LOSS [training: 0.010341764268628907 | validation: 0.011221254921208682]
	TIME [epoch: 35.9 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010969855822854743		[learning rate: 0.003851]
	Learning Rate: 0.00385103
	LOSS [training: 0.010969855822854743 | validation: 0.007385682497380674]
	TIME [epoch: 36 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009935335226300924		[learning rate: 0.0038357]
	Learning Rate: 0.00383571
	LOSS [training: 0.009935335226300924 | validation: 0.008096876800502192]
	TIME [epoch: 35.9 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009254606309525674		[learning rate: 0.0038205]
	Learning Rate: 0.00382046
	LOSS [training: 0.009254606309525674 | validation: 0.012209358149802294]
	TIME [epoch: 35.9 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011049670220560828		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 0.011049670220560828 | validation: 0.008368808135077139]
	TIME [epoch: 36 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009619389343802659		[learning rate: 0.0037901]
	Learning Rate: 0.00379013
	LOSS [training: 0.009619389343802659 | validation: 0.007570297349973077]
	TIME [epoch: 36 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010285456246825619		[learning rate: 0.0037751]
	Learning Rate: 0.00377505
	LOSS [training: 0.010285456246825619 | validation: 0.008881823527511204]
	TIME [epoch: 35.9 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011854500234485095		[learning rate: 0.00376]
	Learning Rate: 0.00376004
	LOSS [training: 0.011854500234485095 | validation: 0.008453823417463934]
	TIME [epoch: 36 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009501151603982025		[learning rate: 0.0037451]
	Learning Rate: 0.00374508
	LOSS [training: 0.009501151603982025 | validation: 0.007685503819171294]
	TIME [epoch: 36 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010569156803718359		[learning rate: 0.0037302]
	Learning Rate: 0.00373019
	LOSS [training: 0.010569156803718359 | validation: 0.0074636335734694055]
	TIME [epoch: 36 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009780642132923241		[learning rate: 0.0037154]
	Learning Rate: 0.00371535
	LOSS [training: 0.009780642132923241 | validation: 0.010079055587981264]
	TIME [epoch: 35.9 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009776110074735434		[learning rate: 0.0037006]
	Learning Rate: 0.00370058
	LOSS [training: 0.009776110074735434 | validation: 0.009875713133725856]
	TIME [epoch: 36 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009369076292611828		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 0.009369076292611828 | validation: 0.01564030589405615]
	TIME [epoch: 35.9 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012161646522009698		[learning rate: 0.0036712]
	Learning Rate: 0.0036712
	LOSS [training: 0.012161646522009698 | validation: 0.014494599045844343]
	TIME [epoch: 36 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01149690899749605		[learning rate: 0.0036566]
	Learning Rate: 0.0036566
	LOSS [training: 0.01149690899749605 | validation: 0.008692680261042886]
	TIME [epoch: 36 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00902939854165264		[learning rate: 0.0036421]
	Learning Rate: 0.00364205
	LOSS [training: 0.00902939854165264 | validation: 0.010464279966228038]
	TIME [epoch: 36 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010475472172021761		[learning rate: 0.0036276]
	Learning Rate: 0.00362757
	LOSS [training: 0.010475472172021761 | validation: 0.010121638045038215]
	TIME [epoch: 36 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009136539777721128		[learning rate: 0.0036131]
	Learning Rate: 0.00361314
	LOSS [training: 0.009136539777721128 | validation: 0.00791539998665911]
	TIME [epoch: 36 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009293898720048682		[learning rate: 0.0035988]
	Learning Rate: 0.00359877
	LOSS [training: 0.009293898720048682 | validation: 0.0077751782569631805]
	TIME [epoch: 36 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009354847391771524		[learning rate: 0.0035845]
	Learning Rate: 0.00358445
	LOSS [training: 0.009354847391771524 | validation: 0.011244471062682369]
	TIME [epoch: 36 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010379720028874141		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 0.010379720028874141 | validation: 0.011855472334710907]
	TIME [epoch: 36 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010220540521022893		[learning rate: 0.003556]
	Learning Rate: 0.003556
	LOSS [training: 0.010220540521022893 | validation: 0.008059385278663695]
	TIME [epoch: 36 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009228294386296826		[learning rate: 0.0035419]
	Learning Rate: 0.00354185
	LOSS [training: 0.009228294386296826 | validation: 0.008848259642334969]
	TIME [epoch: 36 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01080830341889862		[learning rate: 0.0035278]
	Learning Rate: 0.00352777
	LOSS [training: 0.01080830341889862 | validation: 0.007641401106515415]
	TIME [epoch: 36 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00967555739992828		[learning rate: 0.0035137]
	Learning Rate: 0.00351374
	LOSS [training: 0.00967555739992828 | validation: 0.00799486578845881]
	TIME [epoch: 36 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009073846849169426		[learning rate: 0.0034998]
	Learning Rate: 0.00349976
	LOSS [training: 0.009073846849169426 | validation: 0.00825083784799495]
	TIME [epoch: 36 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010362902042332155		[learning rate: 0.0034858]
	Learning Rate: 0.00348584
	LOSS [training: 0.010362902042332155 | validation: 0.008191030335830459]
	TIME [epoch: 36 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009595336910699888		[learning rate: 0.003472]
	Learning Rate: 0.00347198
	LOSS [training: 0.009595336910699888 | validation: 0.008383296048160408]
	TIME [epoch: 36 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010115718864805966		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.010115718864805966 | validation: 0.008797140082360455]
	TIME [epoch: 36 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010351843928576725		[learning rate: 0.0034444]
	Learning Rate: 0.00344441
	LOSS [training: 0.010351843928576725 | validation: 0.008390668817180732]
	TIME [epoch: 36 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009897681075945915		[learning rate: 0.0034307]
	Learning Rate: 0.00343071
	LOSS [training: 0.009897681075945915 | validation: 0.006974653135730575]
	TIME [epoch: 36 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011009476991603716		[learning rate: 0.0034171]
	Learning Rate: 0.00341707
	LOSS [training: 0.011009476991603716 | validation: 0.007684230610201212]
	TIME [epoch: 36 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009249030353646251		[learning rate: 0.0034035]
	Learning Rate: 0.00340348
	LOSS [training: 0.009249030353646251 | validation: 0.007433824209284512]
	TIME [epoch: 36 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009200101658034024		[learning rate: 0.0033899]
	Learning Rate: 0.00338994
	LOSS [training: 0.009200101658034024 | validation: 0.008626702440571675]
	TIME [epoch: 36 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01055795525716475		[learning rate: 0.0033765]
	Learning Rate: 0.00337646
	LOSS [training: 0.01055795525716475 | validation: 0.008093432149753466]
	TIME [epoch: 35.9 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011000426384623957		[learning rate: 0.003363]
	Learning Rate: 0.00336303
	LOSS [training: 0.011000426384623957 | validation: 0.008392508277855645]
	TIME [epoch: 36 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010188297652287036		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 0.010188297652287036 | validation: 0.007666057926465011]
	TIME [epoch: 35.9 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00979403154204773		[learning rate: 0.0033363]
	Learning Rate: 0.00333633
	LOSS [training: 0.00979403154204773 | validation: 0.010559571050188597]
	TIME [epoch: 35.9 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009198697333118401		[learning rate: 0.0033231]
	Learning Rate: 0.00332306
	LOSS [training: 0.009198697333118401 | validation: 0.008758597164082085]
	TIME [epoch: 36 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010071768734975818		[learning rate: 0.0033098]
	Learning Rate: 0.00330985
	LOSS [training: 0.010071768734975818 | validation: 0.008854690452159506]
	TIME [epoch: 35.9 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012285810901601494		[learning rate: 0.0032967]
	Learning Rate: 0.00329668
	LOSS [training: 0.012285810901601494 | validation: 0.008643066729052866]
	TIME [epoch: 35.9 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010481493828673154		[learning rate: 0.0032836]
	Learning Rate: 0.00328357
	LOSS [training: 0.010481493828673154 | validation: 0.008165053462958042]
	TIME [epoch: 35.9 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010387798539824043		[learning rate: 0.0032705]
	Learning Rate: 0.00327051
	LOSS [training: 0.010387798539824043 | validation: 0.008012184626650574]
	TIME [epoch: 35.9 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009790492301112499		[learning rate: 0.0032575]
	Learning Rate: 0.0032575
	LOSS [training: 0.009790492301112499 | validation: 0.007977857385444907]
	TIME [epoch: 35.9 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009576293266996098		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 0.009576293266996098 | validation: 0.009355139150758664]
	TIME [epoch: 35.9 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009879387809833147		[learning rate: 0.0032316]
	Learning Rate: 0.00323164
	LOSS [training: 0.009879387809833147 | validation: 0.009363625241759271]
	TIME [epoch: 36 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010032113672842267		[learning rate: 0.0032188]
	Learning Rate: 0.00321879
	LOSS [training: 0.010032113672842267 | validation: 0.00803481013720199]
	TIME [epoch: 35.9 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009354770730142934		[learning rate: 0.003206]
	Learning Rate: 0.00320599
	LOSS [training: 0.009354770730142934 | validation: 0.008102029890964726]
	TIME [epoch: 35.9 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008656091189938812		[learning rate: 0.0031932]
	Learning Rate: 0.00319323
	LOSS [training: 0.008656091189938812 | validation: 0.009644815467568027]
	TIME [epoch: 35.9 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009520408633795741		[learning rate: 0.0031805]
	Learning Rate: 0.00318053
	LOSS [training: 0.009520408633795741 | validation: 0.008799153406702965]
	TIME [epoch: 35.9 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008918476866397861		[learning rate: 0.0031679]
	Learning Rate: 0.00316788
	LOSS [training: 0.008918476866397861 | validation: 0.020015696252696107]
	TIME [epoch: 35.9 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.016078677218759625		[learning rate: 0.0031553]
	Learning Rate: 0.00315528
	LOSS [training: 0.016078677218759625 | validation: 0.007335706307300504]
	TIME [epoch: 36 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01244918439376157		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 0.01244918439376157 | validation: 0.009533447564220573]
	TIME [epoch: 35.9 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009092287188923631		[learning rate: 0.0031302]
	Learning Rate: 0.00313023
	LOSS [training: 0.009092287188923631 | validation: 0.009680621723258228]
	TIME [epoch: 35.9 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010139667258475765		[learning rate: 0.0031178]
	Learning Rate: 0.00311779
	LOSS [training: 0.010139667258475765 | validation: 0.009323166603214911]
	TIME [epoch: 36 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008742462834106906		[learning rate: 0.0031054]
	Learning Rate: 0.00310538
	LOSS [training: 0.008742462834106906 | validation: 0.00786276969230881]
	TIME [epoch: 36 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009440866410289989		[learning rate: 0.003093]
	Learning Rate: 0.00309303
	LOSS [training: 0.009440866410289989 | validation: 0.01115107361085331]
	TIME [epoch: 36 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010503592987677508		[learning rate: 0.0030807]
	Learning Rate: 0.00308073
	LOSS [training: 0.010503592987677508 | validation: 0.007794636447144158]
	TIME [epoch: 35.9 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009441012249732738		[learning rate: 0.0030685]
	Learning Rate: 0.00306848
	LOSS [training: 0.009441012249732738 | validation: 0.007731178408359884]
	TIME [epoch: 36 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009357160858119069		[learning rate: 0.0030563]
	Learning Rate: 0.00305627
	LOSS [training: 0.009357160858119069 | validation: 0.010084685835874217]
	TIME [epoch: 36 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010164463187281007		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 0.010164463187281007 | validation: 0.007381579825689851]
	TIME [epoch: 36 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009437666614345218		[learning rate: 0.003032]
	Learning Rate: 0.00303201
	LOSS [training: 0.009437666614345218 | validation: 0.008820847701300486]
	TIME [epoch: 35.9 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009630382491237646		[learning rate: 0.00302]
	Learning Rate: 0.00301995
	LOSS [training: 0.009630382491237646 | validation: 0.007818170120627538]
	TIME [epoch: 35.9 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010189831283728405		[learning rate: 0.0030079]
	Learning Rate: 0.00300794
	LOSS [training: 0.010189831283728405 | validation: 0.008142805999373092]
	TIME [epoch: 36 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010058446003021812		[learning rate: 0.002996]
	Learning Rate: 0.00299598
	LOSS [training: 0.010058446003021812 | validation: 0.008848357871667498]
	TIME [epoch: 36 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008594796771862914		[learning rate: 0.0029841]
	Learning Rate: 0.00298406
	LOSS [training: 0.008594796771862914 | validation: 0.01157841208568636]
	TIME [epoch: 35.9 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011155185935210437		[learning rate: 0.0029722]
	Learning Rate: 0.00297219
	LOSS [training: 0.011155185935210437 | validation: 0.007896443739055608]
	TIME [epoch: 36 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008369439782085477		[learning rate: 0.0029604]
	Learning Rate: 0.00296037
	LOSS [training: 0.008369439782085477 | validation: 0.007693200323568386]
	TIME [epoch: 35.9 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01053100484340837		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.01053100484340837 | validation: 0.009619368189319785]
	TIME [epoch: 35.9 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008333336642016992		[learning rate: 0.0029369]
	Learning Rate: 0.00293687
	LOSS [training: 0.008333336642016992 | validation: 0.008869921810403181]
	TIME [epoch: 35.9 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008944432780993359		[learning rate: 0.0029252]
	Learning Rate: 0.00292519
	LOSS [training: 0.008944432780993359 | validation: 0.009514888425647046]
	TIME [epoch: 36 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008915116500692905		[learning rate: 0.0029136]
	Learning Rate: 0.00291355
	LOSS [training: 0.008915116500692905 | validation: 0.00812099834082371]
	TIME [epoch: 35.9 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009953806207000253		[learning rate: 0.002902]
	Learning Rate: 0.00290197
	LOSS [training: 0.009953806207000253 | validation: 0.008643428491115475]
	TIME [epoch: 36 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010327619995846558		[learning rate: 0.0028904]
	Learning Rate: 0.00289042
	LOSS [training: 0.010327619995846558 | validation: 0.00915499504454377]
	TIME [epoch: 36 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011230309942835125		[learning rate: 0.0028789]
	Learning Rate: 0.00287893
	LOSS [training: 0.011230309942835125 | validation: 0.007496029862333264]
	TIME [epoch: 36 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010505640097899784		[learning rate: 0.0028675]
	Learning Rate: 0.00286748
	LOSS [training: 0.010505640097899784 | validation: 0.007897128204612542]
	TIME [epoch: 36 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009268796372881496		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 0.009268796372881496 | validation: 0.010917594624619586]
	TIME [epoch: 36 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009995863771776334		[learning rate: 0.0028447]
	Learning Rate: 0.00284471
	LOSS [training: 0.009995863771776334 | validation: 0.007566103343265326]
	TIME [epoch: 36 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008975101995294171		[learning rate: 0.0028334]
	Learning Rate: 0.0028334
	LOSS [training: 0.008975101995294171 | validation: 0.008161110598434102]
	TIME [epoch: 36 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009581998678347723		[learning rate: 0.0028221]
	Learning Rate: 0.00282213
	LOSS [training: 0.009581998678347723 | validation: 0.008535433119528788]
	TIME [epoch: 36 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010343211234753255		[learning rate: 0.0028109]
	Learning Rate: 0.00281091
	LOSS [training: 0.010343211234753255 | validation: 0.007457594611616965]
	TIME [epoch: 36 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00867802897568319		[learning rate: 0.0027997]
	Learning Rate: 0.00279973
	LOSS [training: 0.00867802897568319 | validation: 0.00752430316451429]
	TIME [epoch: 36 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008809035471206745		[learning rate: 0.0027886]
	Learning Rate: 0.00278859
	LOSS [training: 0.008809035471206745 | validation: 0.00787201696261147]
	TIME [epoch: 36 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009623300126433539		[learning rate: 0.0027775]
	Learning Rate: 0.0027775
	LOSS [training: 0.009623300126433539 | validation: 0.008231797474403845]
	TIME [epoch: 36 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010612382401871514		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 0.010612382401871514 | validation: 0.008006800316764356]
	TIME [epoch: 36 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01068005126258239		[learning rate: 0.0027554]
	Learning Rate: 0.00275545
	LOSS [training: 0.01068005126258239 | validation: 0.009327735555918404]
	TIME [epoch: 36 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011362668061667686		[learning rate: 0.0027445]
	Learning Rate: 0.00274449
	LOSS [training: 0.011362668061667686 | validation: 0.007975795169507496]
	TIME [epoch: 36 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008592978279027814		[learning rate: 0.0027336]
	Learning Rate: 0.00273357
	LOSS [training: 0.008592978279027814 | validation: 0.007725087735602859]
	TIME [epoch: 36 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00946719162364251		[learning rate: 0.0027227]
	Learning Rate: 0.0027227
	LOSS [training: 0.00946719162364251 | validation: 0.00793431679332338]
	TIME [epoch: 36 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008744641087525028		[learning rate: 0.0027119]
	Learning Rate: 0.00271187
	LOSS [training: 0.008744641087525028 | validation: 0.008317996711956339]
	TIME [epoch: 35.9 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008768586542439217		[learning rate: 0.0027011]
	Learning Rate: 0.00270109
	LOSS [training: 0.008768586542439217 | validation: 0.009173587910601948]
	TIME [epoch: 36 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007849039840382368		[learning rate: 0.0026903]
	Learning Rate: 0.00269034
	LOSS [training: 0.007849039840382368 | validation: 0.011987766243066479]
	TIME [epoch: 36 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010184267198718032		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 0.010184267198718032 | validation: 0.0121579231735933]
	TIME [epoch: 36 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009805075237261457		[learning rate: 0.002669]
	Learning Rate: 0.00266899
	LOSS [training: 0.009805075237261457 | validation: 0.009629411155631913]
	TIME [epoch: 36 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009824280987678869		[learning rate: 0.0026584]
	Learning Rate: 0.00265837
	LOSS [training: 0.009824280987678869 | validation: 0.007292607434234007]
	TIME [epoch: 36 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009399317845876498		[learning rate: 0.0026478]
	Learning Rate: 0.0026478
	LOSS [training: 0.009399317845876498 | validation: 0.010543393774847708]
	TIME [epoch: 36 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009571619527652944		[learning rate: 0.0026373]
	Learning Rate: 0.00263727
	LOSS [training: 0.009571619527652944 | validation: 0.007883466018598458]
	TIME [epoch: 36 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009193123599476225		[learning rate: 0.0026268]
	Learning Rate: 0.00262678
	LOSS [training: 0.009193123599476225 | validation: 0.007149182606936773]
	TIME [epoch: 36 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012107509377339613		[learning rate: 0.0026163]
	Learning Rate: 0.00261633
	LOSS [training: 0.012107509377339613 | validation: 0.009111474834145535]
	TIME [epoch: 36 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009593023905099156		[learning rate: 0.0026059]
	Learning Rate: 0.00260592
	LOSS [training: 0.009593023905099156 | validation: 0.009030778199043164]
	TIME [epoch: 36 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009781345303337251		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 0.009781345303337251 | validation: 0.01047806446847117]
	TIME [epoch: 36 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012203223889155066		[learning rate: 0.0025852]
	Learning Rate: 0.00258523
	LOSS [training: 0.012203223889155066 | validation: 0.007026278524883111]
	TIME [epoch: 36 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009519255748324238		[learning rate: 0.002575]
	Learning Rate: 0.00257495
	LOSS [training: 0.009519255748324238 | validation: 0.006720718068568813]
	TIME [epoch: 36 sec]
	Saving model to: out/model_training/model_facs_dec1b_2d_v1_20240622_120511/states/model_facs_dec1b_2d_v1_385.pth
	Model improved!!!
EPOCH 386/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011112918797081924		[learning rate: 0.0025647]
	Learning Rate: 0.00256471
	LOSS [training: 0.011112918797081924 | validation: 0.008976265927654966]
	TIME [epoch: 36 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010300386687762859		[learning rate: 0.0025545]
	Learning Rate: 0.00255451
	LOSS [training: 0.010300386687762859 | validation: 0.007406664153169973]
	TIME [epoch: 36 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008891939566066508		[learning rate: 0.0025444]
	Learning Rate: 0.00254435
	LOSS [training: 0.008891939566066508 | validation: 0.009316282423994574]
	TIME [epoch: 36 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009584071899608304		[learning rate: 0.0025342]
	Learning Rate: 0.00253423
	LOSS [training: 0.009584071899608304 | validation: 0.008343564463374356]
	TIME [epoch: 36 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009468252314670043		[learning rate: 0.0025242]
	Learning Rate: 0.00252415
	LOSS [training: 0.009468252314670043 | validation: 0.008251550786348111]
	TIME [epoch: 36 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00915922003858374		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.00915922003858374 | validation: 0.007214423273267929]
	TIME [epoch: 36 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007770032495623659		[learning rate: 0.0025041]
	Learning Rate: 0.00250411
	LOSS [training: 0.007770032495623659 | validation: 0.0092417593290109]
	TIME [epoch: 36 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008389931542649585		[learning rate: 0.0024942]
	Learning Rate: 0.00249415
	LOSS [training: 0.008389931542649585 | validation: 0.008584771634702157]
	TIME [epoch: 36 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008459036037348778		[learning rate: 0.0024842]
	Learning Rate: 0.00248423
	LOSS [training: 0.008459036037348778 | validation: 0.008693762762542644]
	TIME [epoch: 36 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.013445016132806818		[learning rate: 0.0024744]
	Learning Rate: 0.00247435
	LOSS [training: 0.013445016132806818 | validation: 0.00812102336695308]
	TIME [epoch: 36 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009388544480901193		[learning rate: 0.0024645]
	Learning Rate: 0.00246451
	LOSS [training: 0.009388544480901193 | validation: 0.008108906954335807]
	TIME [epoch: 36 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009538029879593488		[learning rate: 0.0024547]
	Learning Rate: 0.00245471
	LOSS [training: 0.009538029879593488 | validation: 0.008789318971619298]
	TIME [epoch: 36 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009696901050356345		[learning rate: 0.0024449]
	Learning Rate: 0.00244495
	LOSS [training: 0.009696901050356345 | validation: 0.007926532538168326]
	TIME [epoch: 36 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01075889448115674		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 0.01075889448115674 | validation: 0.00951608859988091]
	TIME [epoch: 36 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011819947214070536		[learning rate: 0.0024255]
	Learning Rate: 0.00242554
	LOSS [training: 0.011819947214070536 | validation: 0.009663401543479586]
	TIME [epoch: 35.9 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00890031093746004		[learning rate: 0.0024159]
	Learning Rate: 0.00241589
	LOSS [training: 0.00890031093746004 | validation: 0.0074652772694767]
	TIME [epoch: 35.9 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010915167930585515		[learning rate: 0.0024063]
	Learning Rate: 0.00240628
	LOSS [training: 0.010915167930585515 | validation: 0.006983089371234606]
	TIME [epoch: 36 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008622606395476927		[learning rate: 0.0023967]
	Learning Rate: 0.00239671
	LOSS [training: 0.008622606395476927 | validation: 0.007223277944849773]
	TIME [epoch: 36 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009648760326256495		[learning rate: 0.0023872]
	Learning Rate: 0.00238718
	LOSS [training: 0.009648760326256495 | validation: 0.008571861965258516]
	TIME [epoch: 35.9 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012142375779625458		[learning rate: 0.0023777]
	Learning Rate: 0.00237768
	LOSS [training: 0.012142375779625458 | validation: 0.007221478680351434]
	TIME [epoch: 36 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009885043372485629		[learning rate: 0.0023682]
	Learning Rate: 0.00236823
	LOSS [training: 0.009885043372485629 | validation: 0.00720141433807323]
	TIME [epoch: 36 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00935881349924116		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 0.00935881349924116 | validation: 0.009769960471897288]
	TIME [epoch: 35.9 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012424323912886717		[learning rate: 0.0023494]
	Learning Rate: 0.00234942
	LOSS [training: 0.012424323912886717 | validation: 0.009295566617818449]
	TIME [epoch: 36 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009337756542196077		[learning rate: 0.0023401]
	Learning Rate: 0.00234008
	LOSS [training: 0.009337756542196077 | validation: 0.008115274240555758]
	TIME [epoch: 36 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00989403312999007		[learning rate: 0.0023308]
	Learning Rate: 0.00233077
	LOSS [training: 0.00989403312999007 | validation: 0.006767354422730025]
	TIME [epoch: 35.9 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009469639646761044		[learning rate: 0.0023215]
	Learning Rate: 0.0023215
	LOSS [training: 0.009469639646761044 | validation: 0.007786657835827567]
	TIME [epoch: 36 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009204823098319473		[learning rate: 0.0023123]
	Learning Rate: 0.00231227
	LOSS [training: 0.009204823098319473 | validation: 0.007231050743966838]
	TIME [epoch: 35.9 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009090831601806883		[learning rate: 0.0023031]
	Learning Rate: 0.00230307
	LOSS [training: 0.009090831601806883 | validation: 0.007627366056412002]
	TIME [epoch: 35.9 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009172406869441782		[learning rate: 0.0022939]
	Learning Rate: 0.00229391
	LOSS [training: 0.009172406869441782 | validation: 0.007262483318106675]
	TIME [epoch: 36 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00941964438845853		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 0.00941964438845853 | validation: 0.008448322688912588]
	TIME [epoch: 36 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009728578356679169		[learning rate: 0.0022757]
	Learning Rate: 0.0022757
	LOSS [training: 0.009728578356679169 | validation: 0.008052419915392295]
	TIME [epoch: 35.9 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008613821442450743		[learning rate: 0.0022667]
	Learning Rate: 0.00226665
	LOSS [training: 0.008613821442450743 | validation: 0.0079965941558235]
	TIME [epoch: 35.9 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009431916083385226		[learning rate: 0.0022576]
	Learning Rate: 0.00225764
	LOSS [training: 0.009431916083385226 | validation: 0.010536079290572755]
	TIME [epoch: 36 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011763034598670855		[learning rate: 0.0022487]
	Learning Rate: 0.00224866
	LOSS [training: 0.011763034598670855 | validation: 0.006755676975061774]
	TIME [epoch: 35.9 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011839797274168382		[learning rate: 0.0022397]
	Learning Rate: 0.00223971
	LOSS [training: 0.011839797274168382 | validation: 0.007761308671289843]
	TIME [epoch: 35.9 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010713350776610528		[learning rate: 0.0022308]
	Learning Rate: 0.0022308
	LOSS [training: 0.010713350776610528 | validation: 0.011444404533324213]
	TIME [epoch: 36 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009604187436421559		[learning rate: 0.0022219]
	Learning Rate: 0.00222193
	LOSS [training: 0.009604187436421559 | validation: 0.008168979330316715]
	TIME [epoch: 36 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008462756840289713		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.008462756840289713 | validation: 0.008288114292505177]
	TIME [epoch: 36 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009501060444416511		[learning rate: 0.0022043]
	Learning Rate: 0.00220429
	LOSS [training: 0.009501060444416511 | validation: 0.007830363286008618]
	TIME [epoch: 36 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009508250863087823		[learning rate: 0.0021955]
	Learning Rate: 0.00219553
	LOSS [training: 0.009508250863087823 | validation: 0.008263843655800525]
	TIME [epoch: 36 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008955237661388695		[learning rate: 0.0021868]
	Learning Rate: 0.00218679
	LOSS [training: 0.008955237661388695 | validation: 0.007999092990513526]
	TIME [epoch: 36 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009087519970241237		[learning rate: 0.0021781]
	Learning Rate: 0.0021781
	LOSS [training: 0.009087519970241237 | validation: 0.007351929166420544]
	TIME [epoch: 36 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00957308101796109		[learning rate: 0.0021694]
	Learning Rate: 0.00216943
	LOSS [training: 0.00957308101796109 | validation: 0.008110770015891614]
	TIME [epoch: 36 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010187813067499916		[learning rate: 0.0021608]
	Learning Rate: 0.0021608
	LOSS [training: 0.010187813067499916 | validation: 0.007545063957397002]
	TIME [epoch: 36 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012239508423994547		[learning rate: 0.0021522]
	Learning Rate: 0.00215221
	LOSS [training: 0.012239508423994547 | validation: 0.007333343230066009]
	TIME [epoch: 36 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008709726424421492		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.008709726424421492 | validation: 0.007675408180538712]
	TIME [epoch: 36 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008835325792075917		[learning rate: 0.0021351]
	Learning Rate: 0.00213512
	LOSS [training: 0.008835325792075917 | validation: 0.007957089686270477]
	TIME [epoch: 36 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008570974664811775		[learning rate: 0.0021266]
	Learning Rate: 0.00212663
	LOSS [training: 0.008570974664811775 | validation: 0.009965873325490931]
	TIME [epoch: 36 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009461659957872506		[learning rate: 0.0021182]
	Learning Rate: 0.00211817
	LOSS [training: 0.009461659957872506 | validation: 0.00863203275953786]
	TIME [epoch: 36 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0096317467771602		[learning rate: 0.0021097]
	Learning Rate: 0.00210975
	LOSS [training: 0.0096317467771602 | validation: 0.006988633118511932]
	TIME [epoch: 35.9 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008767912109784455		[learning rate: 0.0021014]
	Learning Rate: 0.00210136
	LOSS [training: 0.008767912109784455 | validation: 0.010241500995589554]
	TIME [epoch: 36 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010186040821555394		[learning rate: 0.002093]
	Learning Rate: 0.002093
	LOSS [training: 0.010186040821555394 | validation: 0.007527392457111981]
	TIME [epoch: 36 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009839978443436466		[learning rate: 0.0020847]
	Learning Rate: 0.00208468
	LOSS [training: 0.009839978443436466 | validation: 0.008830800685454335]
	TIME [epoch: 36 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01048460003090303		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.01048460003090303 | validation: 0.007885077111405413]
	TIME [epoch: 36 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00957973353796768		[learning rate: 0.0020681]
	Learning Rate: 0.00206813
	LOSS [training: 0.00957973353796768 | validation: 0.00793281468678661]
	TIME [epoch: 36 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010361131083275405		[learning rate: 0.0020599]
	Learning Rate: 0.0020599
	LOSS [training: 0.010361131083275405 | validation: 0.0078226326638762]
	TIME [epoch: 35.9 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009181737526578812		[learning rate: 0.0020517]
	Learning Rate: 0.00205171
	LOSS [training: 0.009181737526578812 | validation: 0.009336056315742889]
	TIME [epoch: 35.9 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009011100825153785		[learning rate: 0.0020435]
	Learning Rate: 0.00204355
	LOSS [training: 0.009011100825153785 | validation: 0.0075188345513588885]
	TIME [epoch: 35.9 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009394909224912576		[learning rate: 0.0020354]
	Learning Rate: 0.00203542
	LOSS [training: 0.009394909224912576 | validation: 0.007058947773938345]
	TIME [epoch: 35.9 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008770471510537493		[learning rate: 0.0020273]
	Learning Rate: 0.00202732
	LOSS [training: 0.008770471510537493 | validation: 0.007996671429562677]
	TIME [epoch: 36 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009570229384129868		[learning rate: 0.0020193]
	Learning Rate: 0.00201926
	LOSS [training: 0.009570229384129868 | validation: 0.007599219929492795]
	TIME [epoch: 35.9 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008843403357715291		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 0.008843403357715291 | validation: 0.008520949214196279]
	TIME [epoch: 35.9 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009881650070678798		[learning rate: 0.0020032]
	Learning Rate: 0.00200323
	LOSS [training: 0.009881650070678798 | validation: 0.0083480802922365]
	TIME [epoch: 35.9 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008762667016452131		[learning rate: 0.0019953]
	Learning Rate: 0.00199526
	LOSS [training: 0.008762667016452131 | validation: 0.01080490444982447]
	TIME [epoch: 36 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009073999293562137		[learning rate: 0.0019873]
	Learning Rate: 0.00198733
	LOSS [training: 0.009073999293562137 | validation: 0.007103257151378775]
	TIME [epoch: 35.9 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010580975128643172		[learning rate: 0.0019794]
	Learning Rate: 0.00197942
	LOSS [training: 0.010580975128643172 | validation: 0.007099475091122104]
	TIME [epoch: 35.9 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011070297148602646		[learning rate: 0.0019715]
	Learning Rate: 0.00197155
	LOSS [training: 0.011070297148602646 | validation: 0.007641559447094997]
	TIME [epoch: 36 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008987334878657835		[learning rate: 0.0019637]
	Learning Rate: 0.00196371
	LOSS [training: 0.008987334878657835 | validation: 0.007270286560907941]
	TIME [epoch: 35.9 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009460744843630778		[learning rate: 0.0019559]
	Learning Rate: 0.0019559
	LOSS [training: 0.009460744843630778 | validation: 0.007512569401630839]
	TIME [epoch: 36 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008965213749172259		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 0.008965213749172259 | validation: 0.009558143184515436]
	TIME [epoch: 35.9 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009788587727337619		[learning rate: 0.0019404]
	Learning Rate: 0.00194037
	LOSS [training: 0.009788587727337619 | validation: 0.007679105805227566]
	TIME [epoch: 36 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01058638460456115		[learning rate: 0.0019327]
	Learning Rate: 0.00193265
	LOSS [training: 0.01058638460456115 | validation: 0.00832859054820934]
	TIME [epoch: 36 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0110829826209664		[learning rate: 0.001925]
	Learning Rate: 0.00192497
	LOSS [training: 0.0110829826209664 | validation: 0.008174027171047924]
	TIME [epoch: 36 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012975161698798		[learning rate: 0.0019173]
	Learning Rate: 0.00191731
	LOSS [training: 0.012975161698798 | validation: 0.00837555342379821]
	TIME [epoch: 35.9 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010583610940493184		[learning rate: 0.0019097]
	Learning Rate: 0.00190968
	LOSS [training: 0.010583610940493184 | validation: 0.0082277762884473]
	TIME [epoch: 35.9 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010504805704318838		[learning rate: 0.0019021]
	Learning Rate: 0.00190209
	LOSS [training: 0.010504805704318838 | validation: 0.007014155111296302]
	TIME [epoch: 36 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008589357531352787		[learning rate: 0.0018945]
	Learning Rate: 0.00189452
	LOSS [training: 0.008589357531352787 | validation: 0.007541294028403765]
	TIME [epoch: 35.9 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009454409368025626		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.009454409368025626 | validation: 0.007069483336233061]
	TIME [epoch: 36 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008880492645202943		[learning rate: 0.0018795]
	Learning Rate: 0.00187948
	LOSS [training: 0.008880492645202943 | validation: 0.007252681373136794]
	TIME [epoch: 36 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0091482006554569		[learning rate: 0.001872]
	Learning Rate: 0.00187201
	LOSS [training: 0.0091482006554569 | validation: 0.007496785878605312]
	TIME [epoch: 36 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00812355866428023		[learning rate: 0.0018646]
	Learning Rate: 0.00186456
	LOSS [training: 0.00812355866428023 | validation: 0.010443607468657006]
	TIME [epoch: 36 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008978774022567611		[learning rate: 0.0018571]
	Learning Rate: 0.00185715
	LOSS [training: 0.008978774022567611 | validation: 0.007677594484457821]
	TIME [epoch: 36 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00891993055266226		[learning rate: 0.0018498]
	Learning Rate: 0.00184976
	LOSS [training: 0.00891993055266226 | validation: 0.008502402184417505]
	TIME [epoch: 35.9 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009007161900289835		[learning rate: 0.0018424]
	Learning Rate: 0.0018424
	LOSS [training: 0.009007161900289835 | validation: 0.007625842806143664]
	TIME [epoch: 36 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008679601819168565		[learning rate: 0.0018351]
	Learning Rate: 0.00183508
	LOSS [training: 0.008679601819168565 | validation: 0.009022504654979361]
	TIME [epoch: 36 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00921850685377485		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.00921850685377485 | validation: 0.008346132133264326]
	TIME [epoch: 36 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009764528272712437		[learning rate: 0.0018205]
	Learning Rate: 0.00182051
	LOSS [training: 0.009764528272712437 | validation: 0.007735835684899027]
	TIME [epoch: 36 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010818221811178412		[learning rate: 0.0018133]
	Learning Rate: 0.00181327
	LOSS [training: 0.010818221811178412 | validation: 0.007351200805396273]
	TIME [epoch: 36 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008994646291401164		[learning rate: 0.0018061]
	Learning Rate: 0.00180605
	LOSS [training: 0.008994646291401164 | validation: 0.00885980592467699]
	TIME [epoch: 36 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009314996276803808		[learning rate: 0.0017989]
	Learning Rate: 0.00179887
	LOSS [training: 0.009314996276803808 | validation: 0.008417467473749456]
	TIME [epoch: 36 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00943862109025209		[learning rate: 0.0017917]
	Learning Rate: 0.00179172
	LOSS [training: 0.00943862109025209 | validation: 0.008004066311780234]
	TIME [epoch: 36 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010588857773429468		[learning rate: 0.0017846]
	Learning Rate: 0.00178459
	LOSS [training: 0.010588857773429468 | validation: 0.007643170327851526]
	TIME [epoch: 36 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008580192677697003		[learning rate: 0.0017775]
	Learning Rate: 0.00177749
	LOSS [training: 0.008580192677697003 | validation: 0.008801111678493002]
	TIME [epoch: 36 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008598667032589094		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.008598667032589094 | validation: 0.00888716232922036]
	TIME [epoch: 36 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009851570314156365		[learning rate: 0.0017634]
	Learning Rate: 0.00176338
	LOSS [training: 0.009851570314156365 | validation: 0.009559079405094808]
	TIME [epoch: 36 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009001913038563507		[learning rate: 0.0017564]
	Learning Rate: 0.00175637
	LOSS [training: 0.009001913038563507 | validation: 0.007553327588399559]
	TIME [epoch: 36 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009589026665040117		[learning rate: 0.0017494]
	Learning Rate: 0.00174938
	LOSS [training: 0.009589026665040117 | validation: 0.007528312658314951]
	TIME [epoch: 36 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01023636170190042		[learning rate: 0.0017424]
	Learning Rate: 0.00174242
	LOSS [training: 0.01023636170190042 | validation: 0.008612160569053492]
	TIME [epoch: 36 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00909754925803327		[learning rate: 0.0017355]
	Learning Rate: 0.00173549
	LOSS [training: 0.00909754925803327 | validation: 0.007986635511376284]
	TIME [epoch: 36 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012172760262679397		[learning rate: 0.0017286]
	Learning Rate: 0.00172859
	LOSS [training: 0.012172760262679397 | validation: 0.009207908369198643]
	TIME [epoch: 36 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009210868884292655		[learning rate: 0.0017217]
	Learning Rate: 0.00172172
	LOSS [training: 0.009210868884292655 | validation: 0.007360150170083601]
	TIME [epoch: 35.9 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00873272413583992		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 0.00873272413583992 | validation: 0.008180526124687107]
	TIME [epoch: 35.9 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010050480168332529		[learning rate: 0.001708]
	Learning Rate: 0.00170805
	LOSS [training: 0.010050480168332529 | validation: 0.007606580221468184]
	TIME [epoch: 36 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.013028487557281719		[learning rate: 0.0017013]
	Learning Rate: 0.00170125
	LOSS [training: 0.013028487557281719 | validation: 0.006978346000311793]
	TIME [epoch: 36 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009469019780386488		[learning rate: 0.0016945]
	Learning Rate: 0.00169449
	LOSS [training: 0.009469019780386488 | validation: 0.0074469945227280485]
	TIME [epoch: 36 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00988815773677502		[learning rate: 0.0016877]
	Learning Rate: 0.00168775
	LOSS [training: 0.00988815773677502 | validation: 0.007941063806436605]
	TIME [epoch: 36 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00860036488337933		[learning rate: 0.001681]
	Learning Rate: 0.00168104
	LOSS [training: 0.00860036488337933 | validation: 0.008166027638908262]
	TIME [epoch: 36 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008667034459815455		[learning rate: 0.0016743]
	Learning Rate: 0.00167435
	LOSS [training: 0.008667034459815455 | validation: 0.008790611058543509]
	TIME [epoch: 36 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009457614645883804		[learning rate: 0.0016677]
	Learning Rate: 0.00166769
	LOSS [training: 0.009457614645883804 | validation: 0.007241528691167903]
	TIME [epoch: 36 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010167612723742295		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.010167612723742295 | validation: 0.008240049998334524]
	TIME [epoch: 36 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008497501765499127		[learning rate: 0.0016545]
	Learning Rate: 0.00165445
	LOSS [training: 0.008497501765499127 | validation: 0.007313404447868472]
	TIME [epoch: 36 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00925127115981534		[learning rate: 0.0016479]
	Learning Rate: 0.00164787
	LOSS [training: 0.00925127115981534 | validation: 0.006831965124549607]
	TIME [epoch: 36 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008058882835185403		[learning rate: 0.0016413]
	Learning Rate: 0.00164132
	LOSS [training: 0.008058882835185403 | validation: 0.00761090446584464]
	TIME [epoch: 36 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008666874133226261		[learning rate: 0.0016348]
	Learning Rate: 0.00163479
	LOSS [training: 0.008666874133226261 | validation: 0.0071425405237549545]
	TIME [epoch: 36 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010700291406029667		[learning rate: 0.0016283]
	Learning Rate: 0.00162829
	LOSS [training: 0.010700291406029667 | validation: 0.0077458791081155675]
	TIME [epoch: 36 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01034653420282046		[learning rate: 0.0016218]
	Learning Rate: 0.00162181
	LOSS [training: 0.01034653420282046 | validation: 0.007711177761746063]
	TIME [epoch: 36 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008283452470671188		[learning rate: 0.0016154]
	Learning Rate: 0.00161536
	LOSS [training: 0.008283452470671188 | validation: 0.008554353672965457]
	TIME [epoch: 36 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009313124924658005		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 0.009313124924658005 | validation: 0.007627672889927224]
	TIME [epoch: 35.9 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008459233079201297		[learning rate: 0.0016025]
	Learning Rate: 0.00160254
	LOSS [training: 0.008459233079201297 | validation: 0.008159409871320697]
	TIME [epoch: 35.9 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008814002139360991		[learning rate: 0.0015962]
	Learning Rate: 0.00159616
	LOSS [training: 0.008814002139360991 | validation: 0.009203348107866802]
	TIME [epoch: 36 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008864704433822375		[learning rate: 0.0015898]
	Learning Rate: 0.00158981
	LOSS [training: 0.008864704433822375 | validation: 0.008321597369126264]
	TIME [epoch: 36 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010165433962413796		[learning rate: 0.0015835]
	Learning Rate: 0.00158349
	LOSS [training: 0.010165433962413796 | validation: 0.007950382044683275]
	TIME [epoch: 36 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008900216458894529		[learning rate: 0.0015772]
	Learning Rate: 0.00157719
	LOSS [training: 0.008900216458894529 | validation: 0.008357857807015274]
	TIME [epoch: 36 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008807549281207817		[learning rate: 0.0015709]
	Learning Rate: 0.00157092
	LOSS [training: 0.008807549281207817 | validation: 0.0074077275162316315]
	TIME [epoch: 36 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009628201108159033		[learning rate: 0.0015647]
	Learning Rate: 0.00156467
	LOSS [training: 0.009628201108159033 | validation: 0.00705851242105641]
	TIME [epoch: 36 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010706818615068375		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.010706818615068375 | validation: 0.007257726727171487]
	TIME [epoch: 36 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00855372455699712		[learning rate: 0.0015522]
	Learning Rate: 0.00155225
	LOSS [training: 0.00855372455699712 | validation: 0.007371405113772762]
	TIME [epoch: 36 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009154031043454365		[learning rate: 0.0015461]
	Learning Rate: 0.00154608
	LOSS [training: 0.009154031043454365 | validation: 0.007977979224648482]
	TIME [epoch: 36 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00883468502900631		[learning rate: 0.0015399]
	Learning Rate: 0.00153993
	LOSS [training: 0.00883468502900631 | validation: 0.007305298545097617]
	TIME [epoch: 36 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008996415498836152		[learning rate: 0.0015338]
	Learning Rate: 0.0015338
	LOSS [training: 0.008996415498836152 | validation: 0.008619792724587324]
	TIME [epoch: 36 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009533732010389814		[learning rate: 0.0015277]
	Learning Rate: 0.0015277
	LOSS [training: 0.009533732010389814 | validation: 0.008018423515936885]
	TIME [epoch: 36 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008578629122257273		[learning rate: 0.0015216]
	Learning Rate: 0.00152163
	LOSS [training: 0.008578629122257273 | validation: 0.007727122045283058]
	TIME [epoch: 36 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00943805864845681		[learning rate: 0.0015156]
	Learning Rate: 0.00151557
	LOSS [training: 0.00943805864845681 | validation: 0.0071479912686607874]
	TIME [epoch: 36 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008715226604457242		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.008715226604457242 | validation: 0.00745630632612751]
	TIME [epoch: 35.9 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009253935001467978		[learning rate: 0.0015035]
	Learning Rate: 0.00150354
	LOSS [training: 0.009253935001467978 | validation: 0.007177447459974192]
	TIME [epoch: 36 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008177626919070709		[learning rate: 0.0014976]
	Learning Rate: 0.00149756
	LOSS [training: 0.008177626919070709 | validation: 0.00847255154752109]
	TIME [epoch: 36 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009261058637397268		[learning rate: 0.0014916]
	Learning Rate: 0.00149161
	LOSS [training: 0.009261058637397268 | validation: 0.007204850373109246]
	TIME [epoch: 36 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009036503770888783		[learning rate: 0.0014857]
	Learning Rate: 0.00148567
	LOSS [training: 0.009036503770888783 | validation: 0.0074392867400564335]
	TIME [epoch: 36 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009213019823217863		[learning rate: 0.0014798]
	Learning Rate: 0.00147976
	LOSS [training: 0.009213019823217863 | validation: 0.00704531851417062]
	TIME [epoch: 36 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009625285346437036		[learning rate: 0.0014739]
	Learning Rate: 0.00147388
	LOSS [training: 0.009625285346437036 | validation: 0.006922551459567798]
	TIME [epoch: 36 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008169424808089925		[learning rate: 0.001468]
	Learning Rate: 0.00146802
	LOSS [training: 0.008169424808089925 | validation: 0.007233723430041446]
	TIME [epoch: 36 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012787009936218955		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.012787009936218955 | validation: 0.007127419264515359]
	TIME [epoch: 36 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009698862027475948		[learning rate: 0.0014564]
	Learning Rate: 0.00145636
	LOSS [training: 0.009698862027475948 | validation: 0.006948313459696404]
	TIME [epoch: 36 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008134598975280577		[learning rate: 0.0014506]
	Learning Rate: 0.00145057
	LOSS [training: 0.008134598975280577 | validation: 0.006985132643465347]
	TIME [epoch: 36 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011342328493900726		[learning rate: 0.0014448]
	Learning Rate: 0.0014448
	LOSS [training: 0.011342328493900726 | validation: 0.009822979429590468]
	TIME [epoch: 36 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011015981145488487		[learning rate: 0.0014391]
	Learning Rate: 0.00143905
	LOSS [training: 0.011015981145488487 | validation: 0.007228083028222453]
	TIME [epoch: 36 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0088948160724721		[learning rate: 0.0014333]
	Learning Rate: 0.00143333
	LOSS [training: 0.0088948160724721 | validation: 0.007754038027456489]
	TIME [epoch: 36 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008884575793591825		[learning rate: 0.0014276]
	Learning Rate: 0.00142763
	LOSS [training: 0.008884575793591825 | validation: 0.008069580087516447]
	TIME [epoch: 36 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008950965268515033		[learning rate: 0.001422]
	Learning Rate: 0.00142195
	LOSS [training: 0.008950965268515033 | validation: 0.00723704638549179]
	TIME [epoch: 36 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00959809072756106		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.00959809072756106 | validation: 0.0071947922006026805]
	TIME [epoch: 36 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008505126447217265		[learning rate: 0.0014107]
	Learning Rate: 0.00141066
	LOSS [training: 0.008505126447217265 | validation: 0.00814448929716451]
	TIME [epoch: 36 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008546321496552		[learning rate: 0.0014051]
	Learning Rate: 0.00140505
	LOSS [training: 0.008546321496552 | validation: 0.007661625207743753]
	TIME [epoch: 36 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00955791166884366		[learning rate: 0.0013995]
	Learning Rate: 0.00139946
	LOSS [training: 0.00955791166884366 | validation: 0.00738683088082231]
	TIME [epoch: 36 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009064209902994232		[learning rate: 0.0013939]
	Learning Rate: 0.0013939
	LOSS [training: 0.009064209902994232 | validation: 0.007190885108428163]
	TIME [epoch: 36 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009002441082761273		[learning rate: 0.0013884]
	Learning Rate: 0.00138835
	LOSS [training: 0.009002441082761273 | validation: 0.007613947229893903]
	TIME [epoch: 36 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008564573476596874		[learning rate: 0.0013828]
	Learning Rate: 0.00138283
	LOSS [training: 0.008564573476596874 | validation: 0.008448282070637516]
	TIME [epoch: 36 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009501176292902825		[learning rate: 0.0013773]
	Learning Rate: 0.00137733
	LOSS [training: 0.009501176292902825 | validation: 0.007482477166302033]
	TIME [epoch: 36 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008810264901646573		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 0.008810264901646573 | validation: 0.007396225709664468]
	TIME [epoch: 36 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009733207937262907		[learning rate: 0.0013664]
	Learning Rate: 0.0013664
	LOSS [training: 0.009733207937262907 | validation: 0.007127125524614977]
	TIME [epoch: 36 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009525089592697357		[learning rate: 0.001361]
	Learning Rate: 0.00136096
	LOSS [training: 0.009525089592697357 | validation: 0.007417970473121036]
	TIME [epoch: 36 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008738877270215585		[learning rate: 0.0013555]
	Learning Rate: 0.00135555
	LOSS [training: 0.008738877270215585 | validation: 0.0071731895592694606]
	TIME [epoch: 36 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009288668697068484		[learning rate: 0.0013502]
	Learning Rate: 0.00135016
	LOSS [training: 0.009288668697068484 | validation: 0.007692907944665756]
	TIME [epoch: 36 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009907273535207366		[learning rate: 0.0013448]
	Learning Rate: 0.00134479
	LOSS [training: 0.009907273535207366 | validation: 0.007777947782386744]
	TIME [epoch: 36 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009161706905133347		[learning rate: 0.0013394]
	Learning Rate: 0.00133944
	LOSS [training: 0.009161706905133347 | validation: 0.007329673649600302]
	TIME [epoch: 36 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01043472719587421		[learning rate: 0.0013341]
	Learning Rate: 0.00133411
	LOSS [training: 0.01043472719587421 | validation: 0.007143664099207509]
	TIME [epoch: 36 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009119521698336753		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.009119521698336753 | validation: 0.007099664684662726]
	TIME [epoch: 36 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008223215233896457		[learning rate: 0.0013235]
	Learning Rate: 0.00132352
	LOSS [training: 0.008223215233896457 | validation: 0.007597443514203271]
	TIME [epoch: 36 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00827577160698714		[learning rate: 0.0013183]
	Learning Rate: 0.00131826
	LOSS [training: 0.00827577160698714 | validation: 0.007966934758736364]
	TIME [epoch: 36 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008004104008153684		[learning rate: 0.001313]
	Learning Rate: 0.00131301
	LOSS [training: 0.008004104008153684 | validation: 0.007355737990670628]
	TIME [epoch: 36 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010527666039795675		[learning rate: 0.0013078]
	Learning Rate: 0.00130779
	LOSS [training: 0.010527666039795675 | validation: 0.007667311170116235]
	TIME [epoch: 36 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010230396156047277		[learning rate: 0.0013026]
	Learning Rate: 0.00130259
	LOSS [training: 0.010230396156047277 | validation: 0.007190086473958734]
	TIME [epoch: 36 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0088345748951705		[learning rate: 0.0012974]
	Learning Rate: 0.00129741
	LOSS [training: 0.0088345748951705 | validation: 0.007534363850209544]
	TIME [epoch: 36 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009187705917034078		[learning rate: 0.0012922]
	Learning Rate: 0.00129225
	LOSS [training: 0.009187705917034078 | validation: 0.007184143418352283]
	TIME [epoch: 36 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009612051183286976		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 0.009612051183286976 | validation: 0.006889315817553135]
	TIME [epoch: 36 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01106299175686698		[learning rate: 0.001282]
	Learning Rate: 0.00128199
	LOSS [training: 0.01106299175686698 | validation: 0.007644223111322108]
	TIME [epoch: 35.9 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01011899873183986		[learning rate: 0.0012769]
	Learning Rate: 0.00127689
	LOSS [training: 0.01011899873183986 | validation: 0.0071909680953014645]
	TIME [epoch: 36 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00895000072936334		[learning rate: 0.0012718]
	Learning Rate: 0.00127181
	LOSS [training: 0.00895000072936334 | validation: 0.007585691978562613]
	TIME [epoch: 36 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008756809268226824		[learning rate: 0.0012668]
	Learning Rate: 0.00126675
	LOSS [training: 0.008756809268226824 | validation: 0.00821646274545056]
	TIME [epoch: 36 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009567821789830531		[learning rate: 0.0012617]
	Learning Rate: 0.00126172
	LOSS [training: 0.009567821789830531 | validation: 0.007278382350756343]
	TIME [epoch: 36 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008731568198815026		[learning rate: 0.0012567]
	Learning Rate: 0.0012567
	LOSS [training: 0.008731568198815026 | validation: 0.00717119936063741]
	TIME [epoch: 36 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008450299857935627		[learning rate: 0.0012517]
	Learning Rate: 0.0012517
	LOSS [training: 0.008450299857935627 | validation: 0.00797332178197101]
	TIME [epoch: 36 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008437638707977878		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 0.008437638707977878 | validation: 0.007245158307893145]
	TIME [epoch: 36 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009075050527859929		[learning rate: 0.0012418]
	Learning Rate: 0.00124176
	LOSS [training: 0.009075050527859929 | validation: 0.007074897420318575]
	TIME [epoch: 36 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00954465737254613		[learning rate: 0.0012368]
	Learning Rate: 0.00123682
	LOSS [training: 0.00954465737254613 | validation: 0.007544088101297156]
	TIME [epoch: 36 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010627045600540067		[learning rate: 0.0012319]
	Learning Rate: 0.0012319
	LOSS [training: 0.010627045600540067 | validation: 0.0077072456557044965]
	TIME [epoch: 36 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007994272002763555		[learning rate: 0.001227]
	Learning Rate: 0.001227
	LOSS [training: 0.007994272002763555 | validation: 0.007492980049687544]
	TIME [epoch: 36 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008438237045514838		[learning rate: 0.0012221]
	Learning Rate: 0.00122212
	LOSS [training: 0.008438237045514838 | validation: 0.0074326671789975455]
	TIME [epoch: 36 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008798355685092466		[learning rate: 0.0012173]
	Learning Rate: 0.00121726
	LOSS [training: 0.008798355685092466 | validation: 0.007524971514669731]
	TIME [epoch: 36 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008950062339832573		[learning rate: 0.0012124]
	Learning Rate: 0.00121242
	LOSS [training: 0.008950062339832573 | validation: 0.007467773633260852]
	TIME [epoch: 36 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009097153371775947		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 0.009097153371775947 | validation: 0.006840800880241096]
	TIME [epoch: 36 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009518872920276443		[learning rate: 0.0012028]
	Learning Rate: 0.0012028
	LOSS [training: 0.009518872920276443 | validation: 0.006705102598357132]
	TIME [epoch: 36 sec]
	Saving model to: out/model_training/model_facs_dec1b_2d_v1_20240622_120511/states/model_facs_dec1b_2d_v1_576.pth
	Model improved!!!
EPOCH 577/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010619335210409631		[learning rate: 0.001198]
	Learning Rate: 0.00119801
	LOSS [training: 0.010619335210409631 | validation: 0.007624469771885747]
	TIME [epoch: 36 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008795976880392242		[learning rate: 0.0011932]
	Learning Rate: 0.00119325
	LOSS [training: 0.008795976880392242 | validation: 0.008047771045082105]
	TIME [epoch: 35.9 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008852441609113531		[learning rate: 0.0011885]
	Learning Rate: 0.0011885
	LOSS [training: 0.008852441609113531 | validation: 0.007351885490535092]
	TIME [epoch: 36 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008600761764074866		[learning rate: 0.0011838]
	Learning Rate: 0.00118378
	LOSS [training: 0.008600761764074866 | validation: 0.00713412671052025]
	TIME [epoch: 36 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009290365895421534		[learning rate: 0.0011791]
	Learning Rate: 0.00117907
	LOSS [training: 0.009290365895421534 | validation: 0.0070461667132018626]
	TIME [epoch: 36 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01069816636159365		[learning rate: 0.0011744]
	Learning Rate: 0.00117438
	LOSS [training: 0.01069816636159365 | validation: 0.008314972862714628]
	TIME [epoch: 36 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008284711813310914		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 0.008284711813310914 | validation: 0.007654667624756556]
	TIME [epoch: 36 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009789705965002822		[learning rate: 0.0011651]
	Learning Rate: 0.00116505
	LOSS [training: 0.009789705965002822 | validation: 0.007373497881896415]
	TIME [epoch: 36 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00821994916265497		[learning rate: 0.0011604]
	Learning Rate: 0.00116042
	LOSS [training: 0.00821994916265497 | validation: 0.007540270683545991]
	TIME [epoch: 36 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00832680609221109		[learning rate: 0.0011558]
	Learning Rate: 0.00115581
	LOSS [training: 0.00832680609221109 | validation: 0.00817066315889928]
	TIME [epoch: 36 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00829548363781559		[learning rate: 0.0011512]
	Learning Rate: 0.00115121
	LOSS [training: 0.00829548363781559 | validation: 0.007223977618926486]
	TIME [epoch: 36 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008641678913701593		[learning rate: 0.0011466]
	Learning Rate: 0.00114663
	LOSS [training: 0.008641678913701593 | validation: 0.0073844251488848715]
	TIME [epoch: 36 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008188966169493724		[learning rate: 0.0011421]
	Learning Rate: 0.00114207
	LOSS [training: 0.008188966169493724 | validation: 0.007729766819953711]
	TIME [epoch: 36 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008763555709087262		[learning rate: 0.0011375]
	Learning Rate: 0.00113753
	LOSS [training: 0.008763555709087262 | validation: 0.007578985692741469]
	TIME [epoch: 36 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009681017090232337		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.009681017090232337 | validation: 0.007402456635911081]
	TIME [epoch: 36 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00810726397458967		[learning rate: 0.0011285]
	Learning Rate: 0.0011285
	LOSS [training: 0.00810726397458967 | validation: 0.007908866774112892]
	TIME [epoch: 36 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008541410756218277		[learning rate: 0.001124]
	Learning Rate: 0.00112401
	LOSS [training: 0.008541410756218277 | validation: 0.007654070471844121]
	TIME [epoch: 36 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00869450976017348		[learning rate: 0.0011195]
	Learning Rate: 0.00111954
	LOSS [training: 0.00869450976017348 | validation: 0.0072362987783174985]
	TIME [epoch: 36 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009221099198543886		[learning rate: 0.0011151]
	Learning Rate: 0.00111508
	LOSS [training: 0.009221099198543886 | validation: 0.0072033598782315165]
	TIME [epoch: 36 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008753578604879514		[learning rate: 0.0011106]
	Learning Rate: 0.00111065
	LOSS [training: 0.008753578604879514 | validation: 0.006888878898714759]
	TIME [epoch: 36 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009367170238289157		[learning rate: 0.0011062]
	Learning Rate: 0.00110623
	LOSS [training: 0.009367170238289157 | validation: 0.006989682003897696]
	TIME [epoch: 36 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008537727063017843		[learning rate: 0.0011018]
	Learning Rate: 0.00110183
	LOSS [training: 0.008537727063017843 | validation: 0.007504538588545007]
	TIME [epoch: 36 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009227459940815369		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 0.009227459940815369 | validation: 0.007570566269508308]
	TIME [epoch: 36 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008134232922834187		[learning rate: 0.0010931]
	Learning Rate: 0.00109309
	LOSS [training: 0.008134232922834187 | validation: 0.008272315841117601]
	TIME [epoch: 36 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009059716271352223		[learning rate: 0.0010887]
	Learning Rate: 0.00108874
	LOSS [training: 0.009059716271352223 | validation: 0.007527976437711681]
	TIME [epoch: 36 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008827614463756496		[learning rate: 0.0010844]
	Learning Rate: 0.00108441
	LOSS [training: 0.008827614463756496 | validation: 0.007350298427955898]
	TIME [epoch: 36 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008650862364754517		[learning rate: 0.0010801]
	Learning Rate: 0.00108009
	LOSS [training: 0.008650862364754517 | validation: 0.007376619208211599]
	TIME [epoch: 36 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010149456128785334		[learning rate: 0.0010758]
	Learning Rate: 0.0010758
	LOSS [training: 0.010149456128785334 | validation: 0.007760397056824418]
	TIME [epoch: 36 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008342847900403329		[learning rate: 0.0010715]
	Learning Rate: 0.00107152
	LOSS [training: 0.008342847900403329 | validation: 0.006659388443164013]
	TIME [epoch: 36 sec]
	Saving model to: out/model_training/model_facs_dec1b_2d_v1_20240622_120511/states/model_facs_dec1b_2d_v1_605.pth
	Model improved!!!
EPOCH 606/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008966626140126714		[learning rate: 0.0010673]
	Learning Rate: 0.00106726
	LOSS [training: 0.008966626140126714 | validation: 0.007511015393605569]
	TIME [epoch: 36 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008649175565683415		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 0.008649175565683415 | validation: 0.007746823905839091]
	TIME [epoch: 36 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008270988202563952		[learning rate: 0.0010588]
	Learning Rate: 0.00105878
	LOSS [training: 0.008270988202563952 | validation: 0.007514680408744039]
	TIME [epoch: 36 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00980315142312345		[learning rate: 0.0010546]
	Learning Rate: 0.00105457
	LOSS [training: 0.00980315142312345 | validation: 0.00705546854736058]
	TIME [epoch: 36 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008308639375705758		[learning rate: 0.0010504]
	Learning Rate: 0.00105038
	LOSS [training: 0.008308639375705758 | validation: 0.007164702625847924]
	TIME [epoch: 36 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008682493423754038		[learning rate: 0.0010462]
	Learning Rate: 0.0010462
	LOSS [training: 0.008682493423754038 | validation: 0.007588417816385468]
	TIME [epoch: 35.9 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008666421330790397		[learning rate: 0.001042]
	Learning Rate: 0.00104204
	LOSS [training: 0.008666421330790397 | validation: 0.007367850406940932]
	TIME [epoch: 36 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009428233041388106		[learning rate: 0.0010379]
	Learning Rate: 0.0010379
	LOSS [training: 0.009428233041388106 | validation: 0.007522566509414458]
	TIME [epoch: 36 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009887187102630233		[learning rate: 0.0010338]
	Learning Rate: 0.00103377
	LOSS [training: 0.009887187102630233 | validation: 0.007588183327421963]
	TIME [epoch: 36 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009113172612486202		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 0.009113172612486202 | validation: 0.007186597147885316]
	TIME [epoch: 36 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009092664327589813		[learning rate: 0.0010256]
	Learning Rate: 0.00102556
	LOSS [training: 0.009092664327589813 | validation: 0.007374500137832243]
	TIME [epoch: 35.9 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00865208143307024		[learning rate: 0.0010215]
	Learning Rate: 0.00102148
	LOSS [training: 0.00865208143307024 | validation: 0.007300851427006561]
	TIME [epoch: 36 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008979422511184278		[learning rate: 0.0010174]
	Learning Rate: 0.00101742
	LOSS [training: 0.008979422511184278 | validation: 0.007522670995838351]
	TIME [epoch: 36 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010831251959433649		[learning rate: 0.0010134]
	Learning Rate: 0.00101337
	LOSS [training: 0.010831251959433649 | validation: 0.008095076039671143]
	TIME [epoch: 36 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009321450414087629		[learning rate: 0.0010093]
	Learning Rate: 0.00100934
	LOSS [training: 0.009321450414087629 | validation: 0.0076338971362156114]
	TIME [epoch: 35.9 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00860983265565151		[learning rate: 0.0010053]
	Learning Rate: 0.00100533
	LOSS [training: 0.00860983265565151 | validation: 0.007136569443827842]
	TIME [epoch: 36 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00878271018973918		[learning rate: 0.0010013]
	Learning Rate: 0.00100133
	LOSS [training: 0.00878271018973918 | validation: 0.008056094495521058]
	TIME [epoch: 36 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009374581248621		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 0.009374581248621 | validation: 0.007835686270593683]
	TIME [epoch: 36 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00937939463328273		[learning rate: 0.00099338]
	Learning Rate: 0.00099338
	LOSS [training: 0.00937939463328273 | validation: 0.007737427462709247]
	TIME [epoch: 35.9 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008707050761020277		[learning rate: 0.00098943]
	Learning Rate: 0.000989429
	LOSS [training: 0.008707050761020277 | validation: 0.007026279698527556]
	TIME [epoch: 36 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010101178220070046		[learning rate: 0.00098549]
	Learning Rate: 0.000985494
	LOSS [training: 0.010101178220070046 | validation: 0.007621046238028453]
	TIME [epoch: 36 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008867518007818178		[learning rate: 0.00098157]
	Learning Rate: 0.000981574
	LOSS [training: 0.008867518007818178 | validation: 0.007453522523341834]
	TIME [epoch: 36 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008207859395120018		[learning rate: 0.00097767]
	Learning Rate: 0.00097767
	LOSS [training: 0.008207859395120018 | validation: 0.007537649493916146]
	TIME [epoch: 36 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009876142744783453		[learning rate: 0.00097378]
	Learning Rate: 0.000973782
	LOSS [training: 0.009876142744783453 | validation: 0.007261251540410335]
	TIME [epoch: 36 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009013872890371151		[learning rate: 0.00096991]
	Learning Rate: 0.000969909
	LOSS [training: 0.009013872890371151 | validation: 0.007060265389988762]
	TIME [epoch: 36 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008772208645634811		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.008772208645634811 | validation: 0.00826288658567298]
	TIME [epoch: 36 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008947036911713729		[learning rate: 0.00096221]
	Learning Rate: 0.000962209
	LOSS [training: 0.008947036911713729 | validation: 0.007007815661189418]
	TIME [epoch: 36 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008637489833379515		[learning rate: 0.00095838]
	Learning Rate: 0.000958382
	LOSS [training: 0.008637489833379515 | validation: 0.007687536287704813]
	TIME [epoch: 36 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008479947890589317		[learning rate: 0.00095457]
	Learning Rate: 0.00095457
	LOSS [training: 0.008479947890589317 | validation: 0.00664946739713768]
	TIME [epoch: 35.9 sec]
	Saving model to: out/model_training/model_facs_dec1b_2d_v1_20240622_120511/states/model_facs_dec1b_2d_v1_634.pth
	Model improved!!!
EPOCH 635/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008395747781391169		[learning rate: 0.00095077]
	Learning Rate: 0.000950773
	LOSS [training: 0.008395747781391169 | validation: 0.0074354518842110594]
	TIME [epoch: 36 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008444057381780591		[learning rate: 0.00094699]
	Learning Rate: 0.000946992
	LOSS [training: 0.008444057381780591 | validation: 0.007431904294200109]
	TIME [epoch: 36 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00888486953512011		[learning rate: 0.00094323]
	Learning Rate: 0.000943225
	LOSS [training: 0.00888486953512011 | validation: 0.007467836890526575]
	TIME [epoch: 36 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009285699987133954		[learning rate: 0.00093947]
	Learning Rate: 0.000939474
	LOSS [training: 0.009285699987133954 | validation: 0.007064548686412486]
	TIME [epoch: 36 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009763751618095737		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.009763751618095737 | validation: 0.0073845538224484916]
	TIME [epoch: 36 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009005117324985419		[learning rate: 0.00093202]
	Learning Rate: 0.000932015
	LOSS [training: 0.009005117324985419 | validation: 0.0074219717182113605]
	TIME [epoch: 36 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00826512257504682		[learning rate: 0.00092831]
	Learning Rate: 0.000928309
	LOSS [training: 0.00826512257504682 | validation: 0.007278746410483486]
	TIME [epoch: 36 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008208820349946827		[learning rate: 0.00092462]
	Learning Rate: 0.000924616
	LOSS [training: 0.008208820349946827 | validation: 0.007747116309319639]
	TIME [epoch: 36 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008568023206792895		[learning rate: 0.00092094]
	Learning Rate: 0.000920939
	LOSS [training: 0.008568023206792895 | validation: 0.00790091408749845]
	TIME [epoch: 36 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0083267855263273		[learning rate: 0.00091728]
	Learning Rate: 0.000917276
	LOSS [training: 0.0083267855263273 | validation: 0.006607085869504088]
	TIME [epoch: 36 sec]
	Saving model to: out/model_training/model_facs_dec1b_2d_v1_20240622_120511/states/model_facs_dec1b_2d_v1_644.pth
	Model improved!!!
EPOCH 645/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007536194943275019		[learning rate: 0.00091363]
	Learning Rate: 0.000913628
	LOSS [training: 0.007536194943275019 | validation: 0.007256498769310516]
	TIME [epoch: 36 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00918045228225174		[learning rate: 0.00090999]
	Learning Rate: 0.000909994
	LOSS [training: 0.00918045228225174 | validation: 0.007102476816635589]
	TIME [epoch: 36 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010994218766098941		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.010994218766098941 | validation: 0.007005431192258826]
	TIME [epoch: 36 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009127873838150797		[learning rate: 0.00090277]
	Learning Rate: 0.00090277
	LOSS [training: 0.009127873838150797 | validation: 0.007423755961976039]
	TIME [epoch: 36 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008653325587286102		[learning rate: 0.00089918]
	Learning Rate: 0.000899179
	LOSS [training: 0.008653325587286102 | validation: 0.007692819060122887]
	TIME [epoch: 36 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008404580706097677		[learning rate: 0.0008956]
	Learning Rate: 0.000895603
	LOSS [training: 0.008404580706097677 | validation: 0.007388152825801418]
	TIME [epoch: 36 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010947811020830847		[learning rate: 0.00089204]
	Learning Rate: 0.000892041
	LOSS [training: 0.010947811020830847 | validation: 0.007584129804557689]
	TIME [epoch: 36 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008620591516427818		[learning rate: 0.00088849]
	Learning Rate: 0.000888493
	LOSS [training: 0.008620591516427818 | validation: 0.007282792719986069]
	TIME [epoch: 36 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008629098471743347		[learning rate: 0.00088496]
	Learning Rate: 0.000884959
	LOSS [training: 0.008629098471743347 | validation: 0.007846323897779088]
	TIME [epoch: 36 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008504640893550849		[learning rate: 0.00088144]
	Learning Rate: 0.000881439
	LOSS [training: 0.008504640893550849 | validation: 0.007422441499977013]
	TIME [epoch: 36 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009158385862338273		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 0.009158385862338273 | validation: 0.0069275551351836075]
	TIME [epoch: 36 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0085683879406802		[learning rate: 0.00087444]
	Learning Rate: 0.000874441
	LOSS [training: 0.0085683879406802 | validation: 0.00691554230726193]
	TIME [epoch: 36 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008662518298580703		[learning rate: 0.00087096]
	Learning Rate: 0.000870964
	LOSS [training: 0.008662518298580703 | validation: 0.007523254306637983]
	TIME [epoch: 36 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00928310566467511		[learning rate: 0.0008675]
	Learning Rate: 0.0008675
	LOSS [training: 0.00928310566467511 | validation: 0.006989801223710734]
	TIME [epoch: 36 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008854805522500512		[learning rate: 0.00086405]
	Learning Rate: 0.000864049
	LOSS [training: 0.008854805522500512 | validation: 0.0072021535090300405]
	TIME [epoch: 36 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009361061017294104		[learning rate: 0.00086061]
	Learning Rate: 0.000860613
	LOSS [training: 0.009361061017294104 | validation: 0.007472616271838604]
	TIME [epoch: 36 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01061869057361983		[learning rate: 0.00085719]
	Learning Rate: 0.00085719
	LOSS [training: 0.01061869057361983 | validation: 0.007566864017406925]
	TIME [epoch: 36 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009426490975278817		[learning rate: 0.00085378]
	Learning Rate: 0.00085378
	LOSS [training: 0.009426490975278817 | validation: 0.007272735516465727]
	TIME [epoch: 36 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009152550625075057		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 0.009152550625075057 | validation: 0.007563424601282726]
	TIME [epoch: 36 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008265921972064896		[learning rate: 0.000847]
	Learning Rate: 0.000847002
	LOSS [training: 0.008265921972064896 | validation: 0.007577844972330415]
	TIME [epoch: 35.9 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008715724646860386		[learning rate: 0.00084363]
	Learning Rate: 0.000843634
	LOSS [training: 0.008715724646860386 | validation: 0.007645738415908006]
	TIME [epoch: 36 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010987898407927668		[learning rate: 0.00084028]
	Learning Rate: 0.000840278
	LOSS [training: 0.010987898407927668 | validation: 0.007426335654889682]
	TIME [epoch: 35.9 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008890315667056057		[learning rate: 0.00083694]
	Learning Rate: 0.000836936
	LOSS [training: 0.008890315667056057 | validation: 0.007337427389316913]
	TIME [epoch: 36 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008462897191830385		[learning rate: 0.00083361]
	Learning Rate: 0.000833608
	LOSS [training: 0.008462897191830385 | validation: 0.007538636625206691]
	TIME [epoch: 36 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008738134227272773		[learning rate: 0.00083029]
	Learning Rate: 0.000830292
	LOSS [training: 0.008738134227272773 | validation: 0.007411935096335709]
	TIME [epoch: 36 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008915821495976979		[learning rate: 0.00082699]
	Learning Rate: 0.00082699
	LOSS [training: 0.008915821495976979 | validation: 0.007382085728419222]
	TIME [epoch: 36 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008851547405523283		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.008851547405523283 | validation: 0.007600339684839415]
	TIME [epoch: 36 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008367756958692447		[learning rate: 0.00082042]
	Learning Rate: 0.000820424
	LOSS [training: 0.008367756958692447 | validation: 0.006866049230836886]
	TIME [epoch: 35.9 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008187716979088672		[learning rate: 0.00081716]
	Learning Rate: 0.000817161
	LOSS [training: 0.008187716979088672 | validation: 0.007626850530483713]
	TIME [epoch: 36 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009066419777188589		[learning rate: 0.00081391]
	Learning Rate: 0.000813911
	LOSS [training: 0.009066419777188589 | validation: 0.00761185840928663]
	TIME [epoch: 36 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008422706018368883		[learning rate: 0.00081067]
	Learning Rate: 0.000810674
	LOSS [training: 0.008422706018368883 | validation: 0.00757156547775033]
	TIME [epoch: 36 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007959303141083575		[learning rate: 0.00080745]
	Learning Rate: 0.00080745
	LOSS [training: 0.007959303141083575 | validation: 0.007830224778283771]
	TIME [epoch: 36 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009092135943017176		[learning rate: 0.00080424]
	Learning Rate: 0.000804238
	LOSS [training: 0.009092135943017176 | validation: 0.007268817625794327]
	TIME [epoch: 36 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008451694394466708		[learning rate: 0.00080104]
	Learning Rate: 0.000801039
	LOSS [training: 0.008451694394466708 | validation: 0.0076771258874210714]
	TIME [epoch: 36 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00901340138847604		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 0.00901340138847604 | validation: 0.007178843195403149]
	TIME [epoch: 35.9 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009020166762254103		[learning rate: 0.00079468]
	Learning Rate: 0.00079468
	LOSS [training: 0.009020166762254103 | validation: 0.007298659297348742]
	TIME [epoch: 35.9 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01020115371399219		[learning rate: 0.00079152]
	Learning Rate: 0.000791519
	LOSS [training: 0.01020115371399219 | validation: 0.007242174208044369]
	TIME [epoch: 36 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009453767823555313		[learning rate: 0.00078837]
	Learning Rate: 0.000788371
	LOSS [training: 0.009453767823555313 | validation: 0.0071427005450595046]
	TIME [epoch: 36 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00972766997467503		[learning rate: 0.00078524]
	Learning Rate: 0.000785236
	LOSS [training: 0.00972766997467503 | validation: 0.007183227742992848]
	TIME [epoch: 36 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011478092689519754		[learning rate: 0.00078211]
	Learning Rate: 0.000782113
	LOSS [training: 0.011478092689519754 | validation: 0.007858958636920606]
	TIME [epoch: 36 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008326712826761604		[learning rate: 0.000779]
	Learning Rate: 0.000779002
	LOSS [training: 0.008326712826761604 | validation: 0.007163807300249042]
	TIME [epoch: 36 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008013490216034461		[learning rate: 0.0007759]
	Learning Rate: 0.000775904
	LOSS [training: 0.008013490216034461 | validation: 0.00693096209992278]
	TIME [epoch: 36 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011191131693494357		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 0.011191131693494357 | validation: 0.007473311158214729]
	TIME [epoch: 36 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0075223109706598346		[learning rate: 0.00076974]
	Learning Rate: 0.000769744
	LOSS [training: 0.0075223109706598346 | validation: 0.007786667239953205]
	TIME [epoch: 36 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00863117679333803		[learning rate: 0.00076668]
	Learning Rate: 0.000766682
	LOSS [training: 0.00863117679333803 | validation: 0.007070775759165966]
	TIME [epoch: 36 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008440443851983658		[learning rate: 0.00076363]
	Learning Rate: 0.000763633
	LOSS [training: 0.008440443851983658 | validation: 0.007312619975776831]
	TIME [epoch: 36 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00871975338034375		[learning rate: 0.0007606]
	Learning Rate: 0.000760596
	LOSS [training: 0.00871975338034375 | validation: 0.006878740798313224]
	TIME [epoch: 36 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008964613154789537		[learning rate: 0.00075757]
	Learning Rate: 0.000757571
	LOSS [training: 0.008964613154789537 | validation: 0.007168098545321225]
	TIME [epoch: 36 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008410862427203875		[learning rate: 0.00075456]
	Learning Rate: 0.000754557
	LOSS [training: 0.008410862427203875 | validation: 0.006833291602935963]
	TIME [epoch: 36 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009143639852383329		[learning rate: 0.00075156]
	Learning Rate: 0.000751556
	LOSS [training: 0.009143639852383329 | validation: 0.007717513416209655]
	TIME [epoch: 36 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008164625729680595		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 0.008164625729680595 | validation: 0.007028057095939087]
	TIME [epoch: 36 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008384580900942523		[learning rate: 0.00074559]
	Learning Rate: 0.00074559
	LOSS [training: 0.008384580900942523 | validation: 0.0074397767575820565]
	TIME [epoch: 36 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011333350045257765		[learning rate: 0.00074262]
	Learning Rate: 0.000742624
	LOSS [training: 0.011333350045257765 | validation: 0.007126700021852167]
	TIME [epoch: 36 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01079360028994544		[learning rate: 0.00073967]
	Learning Rate: 0.000739671
	LOSS [training: 0.01079360028994544 | validation: 0.007313798945301886]
	TIME [epoch: 36 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008093920096224706		[learning rate: 0.00073673]
	Learning Rate: 0.000736729
	LOSS [training: 0.008093920096224706 | validation: 0.006852534788501058]
	TIME [epoch: 36 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008881290069279249		[learning rate: 0.0007338]
	Learning Rate: 0.000733799
	LOSS [training: 0.008881290069279249 | validation: 0.00705902941344957]
	TIME [epoch: 36 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00836434471887086		[learning rate: 0.00073088]
	Learning Rate: 0.00073088
	LOSS [training: 0.00836434471887086 | validation: 0.0073742749282791255]
	TIME [epoch: 36 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008614378721609		[learning rate: 0.00072797]
	Learning Rate: 0.000727973
	LOSS [training: 0.008614378721609 | validation: 0.00816304490924145]
	TIME [epoch: 36 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008288830585198309		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 0.008288830585198309 | validation: 0.007468528473340177]
	TIME [epoch: 36 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008928582591861951		[learning rate: 0.00072219]
	Learning Rate: 0.000722194
	LOSS [training: 0.008928582591861951 | validation: 0.007684989036452326]
	TIME [epoch: 36 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008345348056068439		[learning rate: 0.00071932]
	Learning Rate: 0.000719322
	LOSS [training: 0.008345348056068439 | validation: 0.007198813151217483]
	TIME [epoch: 35.9 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009319369353072121		[learning rate: 0.00071646]
	Learning Rate: 0.000716461
	LOSS [training: 0.009319369353072121 | validation: 0.006962409989282654]
	TIME [epoch: 36 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008829572427147554		[learning rate: 0.00071361]
	Learning Rate: 0.000713611
	LOSS [training: 0.008829572427147554 | validation: 0.007243854914733646]
	TIME [epoch: 36 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008366909008308982		[learning rate: 0.00071077]
	Learning Rate: 0.000710773
	LOSS [training: 0.008366909008308982 | validation: 0.0074849823337240825]
	TIME [epoch: 35.9 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00907497199876715		[learning rate: 0.00070795]
	Learning Rate: 0.000707946
	LOSS [training: 0.00907497199876715 | validation: 0.007385822769996367]
	TIME [epoch: 36 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008204969579235711		[learning rate: 0.00070513]
	Learning Rate: 0.00070513
	LOSS [training: 0.008204969579235711 | validation: 0.006990514844835402]
	TIME [epoch: 36 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008466922550242053		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.008466922550242053 | validation: 0.007012799453789716]
	TIME [epoch: 36 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008664807929931106		[learning rate: 0.00069953]
	Learning Rate: 0.000699532
	LOSS [training: 0.008664807929931106 | validation: 0.007065580531298221]
	TIME [epoch: 36 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007773765627584191		[learning rate: 0.00069675]
	Learning Rate: 0.00069675
	LOSS [training: 0.007773765627584191 | validation: 0.006719252934627037]
	TIME [epoch: 36 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008622804346796143		[learning rate: 0.00069398]
	Learning Rate: 0.000693979
	LOSS [training: 0.008622804346796143 | validation: 0.007397427589473714]
	TIME [epoch: 36 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009276420332240305		[learning rate: 0.00069122]
	Learning Rate: 0.000691219
	LOSS [training: 0.009276420332240305 | validation: 0.006938904252344144]
	TIME [epoch: 36 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009060777912553889		[learning rate: 0.00068847]
	Learning Rate: 0.000688469
	LOSS [training: 0.009060777912553889 | validation: 0.007225282225229062]
	TIME [epoch: 35.9 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009294797020424092		[learning rate: 0.00068573]
	Learning Rate: 0.000685731
	LOSS [training: 0.009294797020424092 | validation: 0.007500643066386675]
	TIME [epoch: 36 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011409465842580591		[learning rate: 0.000683]
	Learning Rate: 0.000683004
	LOSS [training: 0.011409465842580591 | validation: 0.007498974257187636]
	TIME [epoch: 36 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00957982479769594		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 0.00957982479769594 | validation: 0.0071360284401706334]
	TIME [epoch: 36 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008688197229695263		[learning rate: 0.00067758]
	Learning Rate: 0.000677582
	LOSS [training: 0.008688197229695263 | validation: 0.007818592122528152]
	TIME [epoch: 36 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008352654559284071		[learning rate: 0.00067489]
	Learning Rate: 0.000674887
	LOSS [training: 0.008352654559284071 | validation: 0.006970130615845083]
	TIME [epoch: 36 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008147100812716263		[learning rate: 0.0006722]
	Learning Rate: 0.000672202
	LOSS [training: 0.008147100812716263 | validation: 0.0074502019357826745]
	TIME [epoch: 35.9 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009161518348047468		[learning rate: 0.00066953]
	Learning Rate: 0.000669529
	LOSS [training: 0.009161518348047468 | validation: 0.006704040334209513]
	TIME [epoch: 36 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008461701465630593		[learning rate: 0.00066687]
	Learning Rate: 0.000666866
	LOSS [training: 0.008461701465630593 | validation: 0.007217924267539125]
	TIME [epoch: 36 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008495429889729091		[learning rate: 0.00066421]
	Learning Rate: 0.000664213
	LOSS [training: 0.008495429889729091 | validation: 0.007799438139546174]
	TIME [epoch: 36 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009099334748552856		[learning rate: 0.00066157]
	Learning Rate: 0.000661572
	LOSS [training: 0.009099334748552856 | validation: 0.007630272949452205]
	TIME [epoch: 36 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009653833460141044		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 0.009653833460141044 | validation: 0.007154772835926085]
	TIME [epoch: 36 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009168855285800925		[learning rate: 0.00065632]
	Learning Rate: 0.00065632
	LOSS [training: 0.009168855285800925 | validation: 0.007331283390696171]
	TIME [epoch: 36 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009948358444776284		[learning rate: 0.00065371]
	Learning Rate: 0.000653709
	LOSS [training: 0.009948358444776284 | validation: 0.007895042418523564]
	TIME [epoch: 36 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008581265681226406		[learning rate: 0.00065111]
	Learning Rate: 0.000651109
	LOSS [training: 0.008581265681226406 | validation: 0.008515552011976308]
	TIME [epoch: 36 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009653933801152873		[learning rate: 0.00064852]
	Learning Rate: 0.00064852
	LOSS [training: 0.009653933801152873 | validation: 0.006885873034409321]
	TIME [epoch: 36 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009072099246459924		[learning rate: 0.00064594]
	Learning Rate: 0.00064594
	LOSS [training: 0.009072099246459924 | validation: 0.0070473474052974]
	TIME [epoch: 35.9 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008345632177315437		[learning rate: 0.00064337]
	Learning Rate: 0.000643371
	LOSS [training: 0.008345632177315437 | validation: 0.0071620269989808305]
	TIME [epoch: 36 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008893305592754273		[learning rate: 0.00064081]
	Learning Rate: 0.000640812
	LOSS [training: 0.008893305592754273 | validation: 0.007282197205407602]
	TIME [epoch: 36 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008345071308957		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 0.008345071308957 | validation: 0.0072157685809741915]
	TIME [epoch: 36 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008370923807506625		[learning rate: 0.00063572]
	Learning Rate: 0.000635725
	LOSS [training: 0.008370923807506625 | validation: 0.007148417209733041]
	TIME [epoch: 35.9 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008614546853717014		[learning rate: 0.0006332]
	Learning Rate: 0.000633196
	LOSS [training: 0.008614546853717014 | validation: 0.008068783083635966]
	TIME [epoch: 35.9 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009512590274499196		[learning rate: 0.00063068]
	Learning Rate: 0.000630678
	LOSS [training: 0.009512590274499196 | validation: 0.006962582786412379]
	TIME [epoch: 36 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008389111655075502		[learning rate: 0.00062817]
	Learning Rate: 0.00062817
	LOSS [training: 0.008389111655075502 | validation: 0.0074990264596863825]
	TIME [epoch: 36 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008369408280056239		[learning rate: 0.00062567]
	Learning Rate: 0.000625671
	LOSS [training: 0.008369408280056239 | validation: 0.007235343177041767]
	TIME [epoch: 36 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00823424038244364		[learning rate: 0.00062318]
	Learning Rate: 0.000623183
	LOSS [training: 0.00823424038244364 | validation: 0.007714978728142269]
	TIME [epoch: 35.9 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008146191969976986		[learning rate: 0.0006207]
	Learning Rate: 0.000620704
	LOSS [training: 0.008146191969976986 | validation: 0.0072343990613478945]
	TIME [epoch: 36 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00880574162379342		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 0.00880574162379342 | validation: 0.007347933238879831]
	TIME [epoch: 36 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011868318782773325		[learning rate: 0.00061578]
	Learning Rate: 0.000615777
	LOSS [training: 0.011868318782773325 | validation: 0.007147990846582819]
	TIME [epoch: 36 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008423679183276446		[learning rate: 0.00061333]
	Learning Rate: 0.000613327
	LOSS [training: 0.008423679183276446 | validation: 0.007059460172862445]
	TIME [epoch: 36 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00831106741903154		[learning rate: 0.00061089]
	Learning Rate: 0.000610888
	LOSS [training: 0.00831106741903154 | validation: 0.0070116622380343024]
	TIME [epoch: 36 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008853557768969289		[learning rate: 0.00060846]
	Learning Rate: 0.000608458
	LOSS [training: 0.008853557768969289 | validation: 0.007343959776329548]
	TIME [epoch: 35.9 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008881333594279563		[learning rate: 0.00060604]
	Learning Rate: 0.000606038
	LOSS [training: 0.008881333594279563 | validation: 0.007283740609811083]
	TIME [epoch: 35.9 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011011909771180195		[learning rate: 0.00060363]
	Learning Rate: 0.000603628
	LOSS [training: 0.011011909771180195 | validation: 0.007098717472263263]
	TIME [epoch: 35.9 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008419785401011333		[learning rate: 0.00060123]
	Learning Rate: 0.000601227
	LOSS [training: 0.008419785401011333 | validation: 0.00791295384008986]
	TIME [epoch: 36 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008305104195516312		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.008305104195516312 | validation: 0.007068901495797179]
	TIME [epoch: 35.9 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008364760623516905		[learning rate: 0.00059645]
	Learning Rate: 0.000596454
	LOSS [training: 0.008364760623516905 | validation: 0.007123520884318531]
	TIME [epoch: 36 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008801103364396035		[learning rate: 0.00059408]
	Learning Rate: 0.000594082
	LOSS [training: 0.008801103364396035 | validation: 0.0072318019682488365]
	TIME [epoch: 35.9 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008744983470354005		[learning rate: 0.00059172]
	Learning Rate: 0.000591719
	LOSS [training: 0.008744983470354005 | validation: 0.007342055495673026]
	TIME [epoch: 35.9 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00806173075718513		[learning rate: 0.00058937]
	Learning Rate: 0.000589365
	LOSS [training: 0.00806173075718513 | validation: 0.007445274572896174]
	TIME [epoch: 36 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00889791001271233		[learning rate: 0.00058702]
	Learning Rate: 0.000587021
	LOSS [training: 0.00889791001271233 | validation: 0.006963258625442795]
	TIME [epoch: 35.9 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010732759147315052		[learning rate: 0.00058469]
	Learning Rate: 0.000584687
	LOSS [training: 0.010732759147315052 | validation: 0.007673044605084956]
	TIME [epoch: 36 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007600954056320792		[learning rate: 0.00058236]
	Learning Rate: 0.000582361
	LOSS [training: 0.007600954056320792 | validation: 0.007180964543265658]
	TIME [epoch: 35.9 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009390838417189486		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 0.009390838417189486 | validation: 0.006760761967392792]
	TIME [epoch: 36 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008624454500809299		[learning rate: 0.00057774]
	Learning Rate: 0.000577738
	LOSS [training: 0.008624454500809299 | validation: 0.007186364810783006]
	TIME [epoch: 36 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009305641467226943		[learning rate: 0.00057544]
	Learning Rate: 0.00057544
	LOSS [training: 0.009305641467226943 | validation: 0.007267555300747133]
	TIME [epoch: 35.9 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009281960714278479		[learning rate: 0.00057315]
	Learning Rate: 0.000573151
	LOSS [training: 0.009281960714278479 | validation: 0.007161150344016605]
	TIME [epoch: 36 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008220546463567418		[learning rate: 0.00057087]
	Learning Rate: 0.000570872
	LOSS [training: 0.008220546463567418 | validation: 0.006916012433882726]
	TIME [epoch: 36 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008285634569918864		[learning rate: 0.0005686]
	Learning Rate: 0.000568601
	LOSS [training: 0.008285634569918864 | validation: 0.007377774411377672]
	TIME [epoch: 36 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008159073089947396		[learning rate: 0.00056634]
	Learning Rate: 0.00056634
	LOSS [training: 0.008159073089947396 | validation: 0.007342876719742606]
	TIME [epoch: 35.9 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008233085907426895		[learning rate: 0.00056409]
	Learning Rate: 0.000564087
	LOSS [training: 0.008233085907426895 | validation: 0.007392276206132263]
	TIME [epoch: 36 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00790414512943489		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 0.00790414512943489 | validation: 0.00731345482983325]
	TIME [epoch: 36 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009338240965219863		[learning rate: 0.00055961]
	Learning Rate: 0.000559609
	LOSS [training: 0.009338240965219863 | validation: 0.007332358479801675]
	TIME [epoch: 35.9 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008753451765452199		[learning rate: 0.00055738]
	Learning Rate: 0.000557383
	LOSS [training: 0.008753451765452199 | validation: 0.006753035846974682]
	TIME [epoch: 36 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008059810713326633		[learning rate: 0.00055517]
	Learning Rate: 0.000555166
	LOSS [training: 0.008059810713326633 | validation: 0.007255023958918071]
	TIME [epoch: 36 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009149323168923666		[learning rate: 0.00055296]
	Learning Rate: 0.000552958
	LOSS [training: 0.009149323168923666 | validation: 0.007246928888921494]
	TIME [epoch: 36 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009100464965021232		[learning rate: 0.00055076]
	Learning Rate: 0.000550759
	LOSS [training: 0.009100464965021232 | validation: 0.0075113410073664845]
	TIME [epoch: 36 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00883949961610856		[learning rate: 0.00054857]
	Learning Rate: 0.000548568
	LOSS [training: 0.00883949961610856 | validation: 0.007112984725373327]
	TIME [epoch: 36 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008710909274437616		[learning rate: 0.00054639]
	Learning Rate: 0.000546387
	LOSS [training: 0.008710909274437616 | validation: 0.007142690527195908]
	TIME [epoch: 36 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007874292503380268		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 0.007874292503380268 | validation: 0.007214955251893747]
	TIME [epoch: 36 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008772065473698708		[learning rate: 0.00054205]
	Learning Rate: 0.000542049
	LOSS [training: 0.008772065473698708 | validation: 0.007102804531599775]
	TIME [epoch: 35.9 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008610620240429497		[learning rate: 0.00053989]
	Learning Rate: 0.000539893
	LOSS [training: 0.008610620240429497 | validation: 0.007757509707801079]
	TIME [epoch: 36 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008313875774888157		[learning rate: 0.00053775]
	Learning Rate: 0.000537746
	LOSS [training: 0.008313875774888157 | validation: 0.00698899044047972]
	TIME [epoch: 35.9 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008034757986329478		[learning rate: 0.00053561]
	Learning Rate: 0.000535607
	LOSS [training: 0.008034757986329478 | validation: 0.006861356228708454]
	TIME [epoch: 35.9 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010191945958406029		[learning rate: 0.00053348]
	Learning Rate: 0.000533477
	LOSS [training: 0.010191945958406029 | validation: 0.006954944345042985]
	TIME [epoch: 35.9 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00811222363684911		[learning rate: 0.00053135]
	Learning Rate: 0.000531355
	LOSS [training: 0.00811222363684911 | validation: 0.007264653927785708]
	TIME [epoch: 35.9 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00825033804399167		[learning rate: 0.00052924]
	Learning Rate: 0.000529241
	LOSS [training: 0.00825033804399167 | validation: 0.007848166358110822]
	TIME [epoch: 35.9 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00831961123691487		[learning rate: 0.00052714]
	Learning Rate: 0.000527136
	LOSS [training: 0.00831961123691487 | validation: 0.007629397143280529]
	TIME [epoch: 36 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009110979131354781		[learning rate: 0.00052504]
	Learning Rate: 0.00052504
	LOSS [training: 0.009110979131354781 | validation: 0.007264381376865918]
	TIME [epoch: 35.9 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008004401648490894		[learning rate: 0.00052295]
	Learning Rate: 0.000522952
	LOSS [training: 0.008004401648490894 | validation: 0.007383227426002765]
	TIME [epoch: 36 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009022887269533274		[learning rate: 0.00052087]
	Learning Rate: 0.000520872
	LOSS [training: 0.009022887269533274 | validation: 0.007027629373918778]
	TIME [epoch: 36 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008714123209413475		[learning rate: 0.0005188]
	Learning Rate: 0.0005188
	LOSS [training: 0.008714123209413475 | validation: 0.006908600234670148]
	TIME [epoch: 36 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008087382785133004		[learning rate: 0.00051674]
	Learning Rate: 0.000516737
	LOSS [training: 0.008087382785133004 | validation: 0.0066923028072117365]
	TIME [epoch: 35.9 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008027706435106977		[learning rate: 0.00051468]
	Learning Rate: 0.000514681
	LOSS [training: 0.008027706435106977 | validation: 0.007006852162561162]
	TIME [epoch: 35.9 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00855714966724147		[learning rate: 0.00051263]
	Learning Rate: 0.000512634
	LOSS [training: 0.00855714966724147 | validation: 0.006748867247782853]
	TIME [epoch: 36 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009338754802605145		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 0.009338754802605145 | validation: 0.006711686827203055]
	TIME [epoch: 36 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0083642731788302		[learning rate: 0.00050856]
	Learning Rate: 0.000508565
	LOSS [training: 0.0083642731788302 | validation: 0.007319245856543662]
	TIME [epoch: 36 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008070557546402075		[learning rate: 0.00050654]
	Learning Rate: 0.000506542
	LOSS [training: 0.008070557546402075 | validation: 0.0070927110950197965]
	TIME [epoch: 36 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009136001171311211		[learning rate: 0.00050453]
	Learning Rate: 0.000504527
	LOSS [training: 0.009136001171311211 | validation: 0.007556131687078818]
	TIME [epoch: 36 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008370099981231421		[learning rate: 0.00050252]
	Learning Rate: 0.000502521
	LOSS [training: 0.008370099981231421 | validation: 0.007183922445727199]
	TIME [epoch: 36 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008533501995735219		[learning rate: 0.00050052]
	Learning Rate: 0.000500522
	LOSS [training: 0.008533501995735219 | validation: 0.0073976566403244305]
	TIME [epoch: 35.9 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008718826186972947		[learning rate: 0.00049853]
	Learning Rate: 0.000498531
	LOSS [training: 0.008718826186972947 | validation: 0.006845743044432124]
	TIME [epoch: 35.9 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008246780449916802		[learning rate: 0.00049655]
	Learning Rate: 0.000496548
	LOSS [training: 0.008246780449916802 | validation: 0.007326541099808672]
	TIME [epoch: 36 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008104612291447023		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 0.008104612291447023 | validation: 0.007181823858188561]
	TIME [epoch: 36 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008444281766740884		[learning rate: 0.00049261]
	Learning Rate: 0.000492606
	LOSS [training: 0.008444281766740884 | validation: 0.007077073098847736]
	TIME [epoch: 35.9 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008224021805860836		[learning rate: 0.00049065]
	Learning Rate: 0.000490647
	LOSS [training: 0.008224021805860836 | validation: 0.007056009519476794]
	TIME [epoch: 36 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011364022028385535		[learning rate: 0.0004887]
	Learning Rate: 0.000488696
	LOSS [training: 0.011364022028385535 | validation: 0.007456238255336004]
	TIME [epoch: 36 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008581847997271021		[learning rate: 0.00048675]
	Learning Rate: 0.000486752
	LOSS [training: 0.008581847997271021 | validation: 0.007783682145750072]
	TIME [epoch: 36 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008129706547398188		[learning rate: 0.00048482]
	Learning Rate: 0.000484816
	LOSS [training: 0.008129706547398188 | validation: 0.007496159538503476]
	TIME [epoch: 36 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008568266368623458		[learning rate: 0.00048289]
	Learning Rate: 0.000482888
	LOSS [training: 0.008568266368623458 | validation: 0.006773986508950008]
	TIME [epoch: 36 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00845183048162666		[learning rate: 0.00048097]
	Learning Rate: 0.000480967
	LOSS [training: 0.00845183048162666 | validation: 0.007621536202555963]
	TIME [epoch: 36 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008503029574571549		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 0.008503029574571549 | validation: 0.007286855623224647]
	TIME [epoch: 36 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00794579101285851		[learning rate: 0.00047715]
	Learning Rate: 0.000477149
	LOSS [training: 0.00794579101285851 | validation: 0.007116025746939795]
	TIME [epoch: 35.9 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008980569074747275		[learning rate: 0.00047525]
	Learning Rate: 0.000475251
	LOSS [training: 0.008980569074747275 | validation: 0.00722650777011877]
	TIME [epoch: 36 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009552158364235409		[learning rate: 0.00047336]
	Learning Rate: 0.000473361
	LOSS [training: 0.009552158364235409 | validation: 0.00765181007316241]
	TIME [epoch: 35.9 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010824099840490096		[learning rate: 0.00047148]
	Learning Rate: 0.000471478
	LOSS [training: 0.010824099840490096 | validation: 0.0069597049934945684]
	TIME [epoch: 35.9 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008341320239556667		[learning rate: 0.0004696]
	Learning Rate: 0.000469603
	LOSS [training: 0.008341320239556667 | validation: 0.00718299032693401]
	TIME [epoch: 35.9 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008519956926492107		[learning rate: 0.00046774]
	Learning Rate: 0.000467735
	LOSS [training: 0.008519956926492107 | validation: 0.007622876249733608]
	TIME [epoch: 36 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008385618050291714		[learning rate: 0.00046587]
	Learning Rate: 0.000465875
	LOSS [training: 0.008385618050291714 | validation: 0.007079774855879055]
	TIME [epoch: 36 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008453098094655272		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 0.008453098094655272 | validation: 0.006578718585318613]
	TIME [epoch: 36 sec]
	Saving model to: out/model_training/model_facs_dec1b_2d_v1_20240622_120511/states/model_facs_dec1b_2d_v1_815.pth
	Model improved!!!
EPOCH 816/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009610590634967695		[learning rate: 0.00046218]
	Learning Rate: 0.000462176
	LOSS [training: 0.009610590634967695 | validation: 0.007047952412457032]
	TIME [epoch: 36 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009116046783989213		[learning rate: 0.00046034]
	Learning Rate: 0.000460338
	LOSS [training: 0.009116046783989213 | validation: 0.0069388870403259304]
	TIME [epoch: 36 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008721743259216952		[learning rate: 0.00045851]
	Learning Rate: 0.000458507
	LOSS [training: 0.008721743259216952 | validation: 0.007842819791772638]
	TIME [epoch: 36 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008649569914093538		[learning rate: 0.00045668]
	Learning Rate: 0.000456684
	LOSS [training: 0.008649569914093538 | validation: 0.0067534021073411485]
	TIME [epoch: 36 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008043397994653305		[learning rate: 0.00045487]
	Learning Rate: 0.000454867
	LOSS [training: 0.008043397994653305 | validation: 0.007289044472929156]
	TIME [epoch: 36 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009465972872937526		[learning rate: 0.00045306]
	Learning Rate: 0.000453058
	LOSS [training: 0.009465972872937526 | validation: 0.0075658375513248995]
	TIME [epoch: 36 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009018215607000956		[learning rate: 0.00045126]
	Learning Rate: 0.000451256
	LOSS [training: 0.009018215607000956 | validation: 0.007024060770973994]
	TIME [epoch: 36 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008591095490303284		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 0.008591095490303284 | validation: 0.006473941568270361]
	TIME [epoch: 36 sec]
	Saving model to: out/model_training/model_facs_dec1b_2d_v1_20240622_120511/states/model_facs_dec1b_2d_v1_823.pth
	Model improved!!!
EPOCH 824/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008121355649529689		[learning rate: 0.00044767]
	Learning Rate: 0.000447674
	LOSS [training: 0.008121355649529689 | validation: 0.007867039659742274]
	TIME [epoch: 36 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008726415572177014		[learning rate: 0.00044589]
	Learning Rate: 0.000445893
	LOSS [training: 0.008726415572177014 | validation: 0.007246107644716044]
	TIME [epoch: 36 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00861105882810033		[learning rate: 0.00044412]
	Learning Rate: 0.00044412
	LOSS [training: 0.00861105882810033 | validation: 0.007356598975594647]
	TIME [epoch: 36 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008187853667540608		[learning rate: 0.00044235]
	Learning Rate: 0.000442353
	LOSS [training: 0.008187853667540608 | validation: 0.007420526029360662]
	TIME [epoch: 35.9 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0087687990912448		[learning rate: 0.00044059]
	Learning Rate: 0.000440594
	LOSS [training: 0.0087687990912448 | validation: 0.007415788095384013]
	TIME [epoch: 35.9 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008835837734771075		[learning rate: 0.00043884]
	Learning Rate: 0.000438842
	LOSS [training: 0.008835837734771075 | validation: 0.007788258336505832]
	TIME [epoch: 36 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011232911818950767		[learning rate: 0.0004371]
	Learning Rate: 0.000437096
	LOSS [training: 0.011232911818950767 | validation: 0.007441699061508285]
	TIME [epoch: 36 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009724354422196808		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 0.009724354422196808 | validation: 0.007283327663405221]
	TIME [epoch: 36 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008590788120305545		[learning rate: 0.00043363]
	Learning Rate: 0.000433626
	LOSS [training: 0.008590788120305545 | validation: 0.007138938049360113]
	TIME [epoch: 36 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0087072295681614		[learning rate: 0.0004319]
	Learning Rate: 0.000431901
	LOSS [training: 0.0087072295681614 | validation: 0.007042429975620067]
	TIME [epoch: 36 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009135386825812825		[learning rate: 0.00043018]
	Learning Rate: 0.000430184
	LOSS [training: 0.009135386825812825 | validation: 0.007854800730361898]
	TIME [epoch: 36 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008815891045432376		[learning rate: 0.00042847]
	Learning Rate: 0.000428473
	LOSS [training: 0.008815891045432376 | validation: 0.006791033063352887]
	TIME [epoch: 36 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008101974602422513		[learning rate: 0.00042677]
	Learning Rate: 0.000426768
	LOSS [training: 0.008101974602422513 | validation: 0.007501435555653293]
	TIME [epoch: 36 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008825247759130208		[learning rate: 0.00042507]
	Learning Rate: 0.000425071
	LOSS [training: 0.008825247759130208 | validation: 0.0074075819425331434]
	TIME [epoch: 36 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008830531655966142		[learning rate: 0.00042338]
	Learning Rate: 0.00042338
	LOSS [training: 0.008830531655966142 | validation: 0.007332471173783906]
	TIME [epoch: 36 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009141655813137053		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 0.009141655813137053 | validation: 0.006675718071326156]
	TIME [epoch: 36 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008079390101307166		[learning rate: 0.00042002]
	Learning Rate: 0.000420019
	LOSS [training: 0.008079390101307166 | validation: 0.007585056437326161]
	TIME [epoch: 36 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008247340918463995		[learning rate: 0.00041835]
	Learning Rate: 0.000418349
	LOSS [training: 0.008247340918463995 | validation: 0.007448685229278646]
	TIME [epoch: 36 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009071321149785759		[learning rate: 0.00041668]
	Learning Rate: 0.000416685
	LOSS [training: 0.009071321149785759 | validation: 0.0070852373910826934]
	TIME [epoch: 35.9 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007876266161944947		[learning rate: 0.00041503]
	Learning Rate: 0.000415028
	LOSS [training: 0.007876266161944947 | validation: 0.00734324793989122]
	TIME [epoch: 36 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008356889177660342		[learning rate: 0.00041338]
	Learning Rate: 0.000413377
	LOSS [training: 0.008356889177660342 | validation: 0.007440323138621019]
	TIME [epoch: 36 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008508719837140532		[learning rate: 0.00041173]
	Learning Rate: 0.000411733
	LOSS [training: 0.008508719837140532 | validation: 0.007211876521939909]
	TIME [epoch: 36 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008430455316445042		[learning rate: 0.0004101]
	Learning Rate: 0.000410095
	LOSS [training: 0.008430455316445042 | validation: 0.007528417240165304]
	TIME [epoch: 36 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008317247718942239		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 0.008317247718942239 | validation: 0.0074460837065060265]
	TIME [epoch: 36 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00983393474553542		[learning rate: 0.00040684]
	Learning Rate: 0.00040684
	LOSS [training: 0.00983393474553542 | validation: 0.006822847890341542]
	TIME [epoch: 36 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008161498084423353		[learning rate: 0.00040522]
	Learning Rate: 0.000405221
	LOSS [training: 0.008161498084423353 | validation: 0.0067699101265907835]
	TIME [epoch: 36 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009919880713843154		[learning rate: 0.00040361]
	Learning Rate: 0.00040361
	LOSS [training: 0.009919880713843154 | validation: 0.007429755425163274]
	TIME [epoch: 36 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010639092860950916		[learning rate: 0.000402]
	Learning Rate: 0.000402004
	LOSS [training: 0.010639092860950916 | validation: 0.007249265168101787]
	TIME [epoch: 36 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008889640109375306		[learning rate: 0.00040041]
	Learning Rate: 0.000400406
	LOSS [training: 0.008889640109375306 | validation: 0.0074628983015978135]
	TIME [epoch: 36 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008879041401889783		[learning rate: 0.00039881]
	Learning Rate: 0.000398813
	LOSS [training: 0.008879041401889783 | validation: 0.007515635503876671]
	TIME [epoch: 36 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00794285955522845		[learning rate: 0.00039723]
	Learning Rate: 0.000397227
	LOSS [training: 0.00794285955522845 | validation: 0.007272057409859718]
	TIME [epoch: 36 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012061982636280612		[learning rate: 0.00039565]
	Learning Rate: 0.000395647
	LOSS [training: 0.012061982636280612 | validation: 0.00761513779022307]
	TIME [epoch: 36 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00993128838125177		[learning rate: 0.00039407]
	Learning Rate: 0.000394073
	LOSS [training: 0.00993128838125177 | validation: 0.00717566800720065]
	TIME [epoch: 36 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008778896297522263		[learning rate: 0.00039251]
	Learning Rate: 0.000392506
	LOSS [training: 0.008778896297522263 | validation: 0.007361060997045765]
	TIME [epoch: 36 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008554004326766649		[learning rate: 0.00039094]
	Learning Rate: 0.000390945
	LOSS [training: 0.008554004326766649 | validation: 0.007059938181044232]
	TIME [epoch: 36 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011744738304538135		[learning rate: 0.00038939]
	Learning Rate: 0.00038939
	LOSS [training: 0.011744738304538135 | validation: 0.007481119957458288]
	TIME [epoch: 36 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008475361638722978		[learning rate: 0.00038784]
	Learning Rate: 0.000387841
	LOSS [training: 0.008475361638722978 | validation: 0.007758119485142351]
	TIME [epoch: 36 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008619857565601456		[learning rate: 0.0003863]
	Learning Rate: 0.000386299
	LOSS [training: 0.008619857565601456 | validation: 0.007024898357418536]
	TIME [epoch: 36 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008775963007974698		[learning rate: 0.00038476]
	Learning Rate: 0.000384762
	LOSS [training: 0.008775963007974698 | validation: 0.006994371250153253]
	TIME [epoch: 36 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010006326273220269		[learning rate: 0.00038323]
	Learning Rate: 0.000383232
	LOSS [training: 0.010006326273220269 | validation: 0.006933011867514693]
	TIME [epoch: 36 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008075823390781034		[learning rate: 0.00038171]
	Learning Rate: 0.000381708
	LOSS [training: 0.008075823390781034 | validation: 0.0072605673253355015]
	TIME [epoch: 36 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008413262678082943		[learning rate: 0.00038019]
	Learning Rate: 0.000380189
	LOSS [training: 0.008413262678082943 | validation: 0.007258410987468436]
	TIME [epoch: 36 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007855446023201977		[learning rate: 0.00037868]
	Learning Rate: 0.000378677
	LOSS [training: 0.007855446023201977 | validation: 0.006941400173444867]
	TIME [epoch: 36 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010892147507171431		[learning rate: 0.00037717]
	Learning Rate: 0.000377171
	LOSS [training: 0.010892147507171431 | validation: 0.007298663665187224]
	TIME [epoch: 36 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009355655274972598		[learning rate: 0.00037567]
	Learning Rate: 0.000375671
	LOSS [training: 0.009355655274972598 | validation: 0.007493519873763415]
	TIME [epoch: 36 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008917626016921193		[learning rate: 0.00037418]
	Learning Rate: 0.000374177
	LOSS [training: 0.008917626016921193 | validation: 0.00707589265901677]
	TIME [epoch: 36 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009631393903438958		[learning rate: 0.00037269]
	Learning Rate: 0.000372689
	LOSS [training: 0.009631393903438958 | validation: 0.006513833939029943]
	TIME [epoch: 36 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00839092307014976		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 0.00839092307014976 | validation: 0.006964218725327993]
	TIME [epoch: 36 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008678784335274472		[learning rate: 0.00036973]
	Learning Rate: 0.00036973
	LOSS [training: 0.008678784335274472 | validation: 0.007183236663990714]
	TIME [epoch: 36 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00937798352697935		[learning rate: 0.00036826]
	Learning Rate: 0.000368259
	LOSS [training: 0.00937798352697935 | validation: 0.006983935061355617]
	TIME [epoch: 36 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008863630669396742		[learning rate: 0.00036679]
	Learning Rate: 0.000366795
	LOSS [training: 0.008863630669396742 | validation: 0.006770241602920737]
	TIME [epoch: 35.9 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011243604403042786		[learning rate: 0.00036534]
	Learning Rate: 0.000365336
	LOSS [training: 0.011243604403042786 | validation: 0.007144415986661575]
	TIME [epoch: 36 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008769112602302754		[learning rate: 0.00036388]
	Learning Rate: 0.000363883
	LOSS [training: 0.008769112602302754 | validation: 0.007369806029655664]
	TIME [epoch: 35.9 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008281088377788128		[learning rate: 0.00036244]
	Learning Rate: 0.000362436
	LOSS [training: 0.008281088377788128 | validation: 0.0076555560527655385]
	TIME [epoch: 36 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008353810206575416		[learning rate: 0.00036099]
	Learning Rate: 0.000360994
	LOSS [training: 0.008353810206575416 | validation: 0.00698240396606598]
	TIME [epoch: 36 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007830554642930062		[learning rate: 0.00035956]
	Learning Rate: 0.000359558
	LOSS [training: 0.007830554642930062 | validation: 0.007228904128511955]
	TIME [epoch: 36 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00978428502217557		[learning rate: 0.00035813]
	Learning Rate: 0.000358128
	LOSS [training: 0.00978428502217557 | validation: 0.006684223339170963]
	TIME [epoch: 35.9 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008400656017911408		[learning rate: 0.0003567]
	Learning Rate: 0.000356704
	LOSS [training: 0.008400656017911408 | validation: 0.0073283103256795825]
	TIME [epoch: 36 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010459779825481928		[learning rate: 0.00035529]
	Learning Rate: 0.000355285
	LOSS [training: 0.010459779825481928 | validation: 0.007246362050513322]
	TIME [epoch: 36 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008349250021772637		[learning rate: 0.00035387]
	Learning Rate: 0.000353872
	LOSS [training: 0.008349250021772637 | validation: 0.006788182941095422]
	TIME [epoch: 36 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008546211460195623		[learning rate: 0.00035246]
	Learning Rate: 0.000352465
	LOSS [training: 0.008546211460195623 | validation: 0.007320409315687351]
	TIME [epoch: 36 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00839807637928155		[learning rate: 0.00035106]
	Learning Rate: 0.000351063
	LOSS [training: 0.00839807637928155 | validation: 0.007440995970202461]
	TIME [epoch: 36 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008302496790326522		[learning rate: 0.00034967]
	Learning Rate: 0.000349666
	LOSS [training: 0.008302496790326522 | validation: 0.00666849778648278]
	TIME [epoch: 36 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008762610620059915		[learning rate: 0.00034828]
	Learning Rate: 0.000348276
	LOSS [training: 0.008762610620059915 | validation: 0.007005784603184501]
	TIME [epoch: 36 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011307783371958181		[learning rate: 0.00034689]
	Learning Rate: 0.000346891
	LOSS [training: 0.011307783371958181 | validation: 0.007518240627756226]
	TIME [epoch: 36 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008306981185886568		[learning rate: 0.00034551]
	Learning Rate: 0.000345511
	LOSS [training: 0.008306981185886568 | validation: 0.006925901432384696]
	TIME [epoch: 36 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008644008268161502		[learning rate: 0.00034414]
	Learning Rate: 0.000344137
	LOSS [training: 0.008644008268161502 | validation: 0.006441645236089219]
	TIME [epoch: 36 sec]
	Saving model to: out/model_training/model_facs_dec1b_2d_v1_20240622_120511/states/model_facs_dec1b_2d_v1_890.pth
	Model improved!!!
EPOCH 891/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00814035647250575		[learning rate: 0.00034277]
	Learning Rate: 0.000342768
	LOSS [training: 0.00814035647250575 | validation: 0.007189442664026361]
	TIME [epoch: 36 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008316058053869486		[learning rate: 0.0003414]
	Learning Rate: 0.000341405
	LOSS [training: 0.008316058053869486 | validation: 0.007455160000646446]
	TIME [epoch: 36 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00839270110001366		[learning rate: 0.00034005]
	Learning Rate: 0.000340047
	LOSS [training: 0.00839270110001366 | validation: 0.006840206059134153]
	TIME [epoch: 36 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010883412604164323		[learning rate: 0.00033869]
	Learning Rate: 0.000338694
	LOSS [training: 0.010883412604164323 | validation: 0.007370217522249249]
	TIME [epoch: 36 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008263408658123028		[learning rate: 0.00033735]
	Learning Rate: 0.000337347
	LOSS [training: 0.008263408658123028 | validation: 0.00730229536500604]
	TIME [epoch: 36 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008181918696381758		[learning rate: 0.00033601]
	Learning Rate: 0.000336005
	LOSS [training: 0.008181918696381758 | validation: 0.006397177718591421]
	TIME [epoch: 36 sec]
	Saving model to: out/model_training/model_facs_dec1b_2d_v1_20240622_120511/states/model_facs_dec1b_2d_v1_896.pth
	Model improved!!!
EPOCH 897/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00790363069276983		[learning rate: 0.00033467]
	Learning Rate: 0.000334669
	LOSS [training: 0.00790363069276983 | validation: 0.007737388738761744]
	TIME [epoch: 36 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008086915844772315		[learning rate: 0.00033334]
	Learning Rate: 0.000333338
	LOSS [training: 0.008086915844772315 | validation: 0.00751466871126664]
	TIME [epoch: 36 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008947261150598745		[learning rate: 0.00033201]
	Learning Rate: 0.000332012
	LOSS [training: 0.008947261150598745 | validation: 0.006681808727176152]
	TIME [epoch: 36 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008681081923712454		[learning rate: 0.00033069]
	Learning Rate: 0.000330692
	LOSS [training: 0.008681081923712454 | validation: 0.0077048099482088265]
	TIME [epoch: 36 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008229418777491684		[learning rate: 0.00032938]
	Learning Rate: 0.000329376
	LOSS [training: 0.008229418777491684 | validation: 0.007325157768306387]
	TIME [epoch: 36 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008428078183277924		[learning rate: 0.00032807]
	Learning Rate: 0.000328066
	LOSS [training: 0.008428078183277924 | validation: 0.00795659226126363]
	TIME [epoch: 36 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008245967053171325		[learning rate: 0.00032676]
	Learning Rate: 0.000326761
	LOSS [training: 0.008245967053171325 | validation: 0.006868011845738047]
	TIME [epoch: 36 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00803472292996431		[learning rate: 0.00032546]
	Learning Rate: 0.000325462
	LOSS [training: 0.00803472292996431 | validation: 0.00731239211328861]
	TIME [epoch: 35.9 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008221245016517269		[learning rate: 0.00032417]
	Learning Rate: 0.000324167
	LOSS [training: 0.008221245016517269 | validation: 0.007239135166892656]
	TIME [epoch: 36 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008491355290687959		[learning rate: 0.00032288]
	Learning Rate: 0.000322878
	LOSS [training: 0.008491355290687959 | validation: 0.007587130287987595]
	TIME [epoch: 36 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00858281940929079		[learning rate: 0.00032159]
	Learning Rate: 0.000321594
	LOSS [training: 0.00858281940929079 | validation: 0.006853996622736483]
	TIME [epoch: 36 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00814343925159735		[learning rate: 0.00032031]
	Learning Rate: 0.000320315
	LOSS [training: 0.00814343925159735 | validation: 0.007734564430185342]
	TIME [epoch: 35.9 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009111871014193845		[learning rate: 0.00031904]
	Learning Rate: 0.000319041
	LOSS [training: 0.009111871014193845 | validation: 0.007151081578594417]
	TIME [epoch: 36 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009016384198168274		[learning rate: 0.00031777]
	Learning Rate: 0.000317772
	LOSS [training: 0.009016384198168274 | validation: 0.007040019724044928]
	TIME [epoch: 36 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008288634182227122		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 0.008288634182227122 | validation: 0.007100250993236741]
	TIME [epoch: 36 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010664336683406356		[learning rate: 0.00031525]
	Learning Rate: 0.000315249
	LOSS [training: 0.010664336683406356 | validation: 0.007194832476707972]
	TIME [epoch: 36 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007873638626490447		[learning rate: 0.000314]
	Learning Rate: 0.000313995
	LOSS [training: 0.007873638626490447 | validation: 0.007011819133975328]
	TIME [epoch: 36 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008335981479055664		[learning rate: 0.00031275]
	Learning Rate: 0.000312746
	LOSS [training: 0.008335981479055664 | validation: 0.007205557184128693]
	TIME [epoch: 36 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008908396363008874		[learning rate: 0.0003115]
	Learning Rate: 0.000311503
	LOSS [training: 0.008908396363008874 | validation: 0.006899028989360442]
	TIME [epoch: 35.9 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008064262936192569		[learning rate: 0.00031026]
	Learning Rate: 0.000310264
	LOSS [training: 0.008064262936192569 | validation: 0.006997443605737441]
	TIME [epoch: 36 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009079982838383469		[learning rate: 0.00030903]
	Learning Rate: 0.00030903
	LOSS [training: 0.009079982838383469 | validation: 0.007506834029034934]
	TIME [epoch: 35.9 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008360896565205243		[learning rate: 0.0003078]
	Learning Rate: 0.0003078
	LOSS [training: 0.008360896565205243 | validation: 0.007387274945237129]
	TIME [epoch: 36 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008534234887340607		[learning rate: 0.00030658]
	Learning Rate: 0.000306576
	LOSS [training: 0.008534234887340607 | validation: 0.006731340616884652]
	TIME [epoch: 36 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008476366487366898		[learning rate: 0.00030536]
	Learning Rate: 0.000305357
	LOSS [training: 0.008476366487366898 | validation: 0.007312965744050942]
	TIME [epoch: 35.9 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00856441936128862		[learning rate: 0.00030414]
	Learning Rate: 0.000304142
	LOSS [training: 0.00856441936128862 | validation: 0.006975597424050242]
	TIME [epoch: 36 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008763194089784657		[learning rate: 0.00030293]
	Learning Rate: 0.000302933
	LOSS [training: 0.008763194089784657 | validation: 0.007124808234017369]
	TIME [epoch: 36 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011483426747089857		[learning rate: 0.00030173]
	Learning Rate: 0.000301728
	LOSS [training: 0.011483426747089857 | validation: 0.007660303274733655]
	TIME [epoch: 36 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008202155225066217		[learning rate: 0.00030053]
	Learning Rate: 0.000300528
	LOSS [training: 0.008202155225066217 | validation: 0.00708649614235291]
	TIME [epoch: 36 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008999526958271414		[learning rate: 0.00029933]
	Learning Rate: 0.000299333
	LOSS [training: 0.008999526958271414 | validation: 0.006691099466174216]
	TIME [epoch: 36 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008347949693390849		[learning rate: 0.00029814]
	Learning Rate: 0.000298142
	LOSS [training: 0.008347949693390849 | validation: 0.007053706762248568]
	TIME [epoch: 36 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008326483772260633		[learning rate: 0.00029696]
	Learning Rate: 0.000296956
	LOSS [training: 0.008326483772260633 | validation: 0.006898921357751618]
	TIME [epoch: 35.9 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00770431625865874		[learning rate: 0.00029578]
	Learning Rate: 0.000295775
	LOSS [training: 0.00770431625865874 | validation: 0.007358275537067402]
	TIME [epoch: 36 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008169347677020452		[learning rate: 0.0002946]
	Learning Rate: 0.000294599
	LOSS [training: 0.008169347677020452 | validation: 0.007314694642108784]
	TIME [epoch: 35.9 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008514518205761462		[learning rate: 0.00029343]
	Learning Rate: 0.000293427
	LOSS [training: 0.008514518205761462 | validation: 0.007271346220469065]
	TIME [epoch: 35.9 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00886433690892686		[learning rate: 0.00029226]
	Learning Rate: 0.00029226
	LOSS [training: 0.00886433690892686 | validation: 0.007113216151635812]
	TIME [epoch: 36 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007884154964886507		[learning rate: 0.0002911]
	Learning Rate: 0.000291098
	LOSS [training: 0.007884154964886507 | validation: 0.007158798898855534]
	TIME [epoch: 36 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008195574255084472		[learning rate: 0.00028994]
	Learning Rate: 0.00028994
	LOSS [training: 0.008195574255084472 | validation: 0.007609127445856352]
	TIME [epoch: 36 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008248721060425877		[learning rate: 0.00028879]
	Learning Rate: 0.000288786
	LOSS [training: 0.008248721060425877 | validation: 0.007268156111724764]
	TIME [epoch: 36 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008291580876959762		[learning rate: 0.00028764]
	Learning Rate: 0.000287638
	LOSS [training: 0.008291580876959762 | validation: 0.007042836712456531]
	TIME [epoch: 36 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008894664910667753		[learning rate: 0.00028649]
	Learning Rate: 0.000286494
	LOSS [training: 0.008894664910667753 | validation: 0.007708195085420333]
	TIME [epoch: 35.9 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008460440069966104		[learning rate: 0.00028535]
	Learning Rate: 0.000285354
	LOSS [training: 0.008460440069966104 | validation: 0.006941119275920707]
	TIME [epoch: 36 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008648993155597716		[learning rate: 0.00028422]
	Learning Rate: 0.00028422
	LOSS [training: 0.008648993155597716 | validation: 0.006646449729732967]
	TIME [epoch: 35.9 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007494877700262902		[learning rate: 0.00028309]
	Learning Rate: 0.000283089
	LOSS [training: 0.007494877700262902 | validation: 0.007467646575559694]
	TIME [epoch: 36 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01118166886469744		[learning rate: 0.00028196]
	Learning Rate: 0.000281963
	LOSS [training: 0.01118166886469744 | validation: 0.007385352857127857]
	TIME [epoch: 36 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008164900361670164		[learning rate: 0.00028084]
	Learning Rate: 0.000280842
	LOSS [training: 0.008164900361670164 | validation: 0.007021763741552381]
	TIME [epoch: 36 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00841314456227039		[learning rate: 0.00027972]
	Learning Rate: 0.000279725
	LOSS [training: 0.00841314456227039 | validation: 0.007721239003467048]
	TIME [epoch: 36 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00790090981006794		[learning rate: 0.00027861]
	Learning Rate: 0.000278612
	LOSS [training: 0.00790090981006794 | validation: 0.007377367983988123]
	TIME [epoch: 36 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009439634188263081		[learning rate: 0.0002775]
	Learning Rate: 0.000277504
	LOSS [training: 0.009439634188263081 | validation: 0.007362364273474227]
	TIME [epoch: 36 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008792808172825205		[learning rate: 0.0002764]
	Learning Rate: 0.0002764
	LOSS [training: 0.008792808172825205 | validation: 0.00722226481534447]
	TIME [epoch: 36 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009007076730717569		[learning rate: 0.0002753]
	Learning Rate: 0.000275301
	LOSS [training: 0.009007076730717569 | validation: 0.006762065752864746]
	TIME [epoch: 36 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008285702546836981		[learning rate: 0.00027421]
	Learning Rate: 0.000274206
	LOSS [training: 0.008285702546836981 | validation: 0.006576984287203352]
	TIME [epoch: 35.9 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008110471759041865		[learning rate: 0.00027312]
	Learning Rate: 0.000273115
	LOSS [training: 0.008110471759041865 | validation: 0.007130662151129591]
	TIME [epoch: 35.9 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007998510951322542		[learning rate: 0.00027203]
	Learning Rate: 0.000272029
	LOSS [training: 0.007998510951322542 | validation: 0.007185046958733033]
	TIME [epoch: 36 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008556673202919703		[learning rate: 0.00027095]
	Learning Rate: 0.000270947
	LOSS [training: 0.008556673202919703 | validation: 0.007640652363414763]
	TIME [epoch: 35.9 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007708152196635571		[learning rate: 0.00026987]
	Learning Rate: 0.00026987
	LOSS [training: 0.007708152196635571 | validation: 0.00711778303518309]
	TIME [epoch: 36 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008557171886443908		[learning rate: 0.0002688]
	Learning Rate: 0.000268796
	LOSS [training: 0.008557171886443908 | validation: 0.0075714774367155405]
	TIME [epoch: 36 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008082023587649244		[learning rate: 0.00026773]
	Learning Rate: 0.000267727
	LOSS [training: 0.008082023587649244 | validation: 0.007407231640885539]
	TIME [epoch: 35.9 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008542805464901652		[learning rate: 0.00026666]
	Learning Rate: 0.000266662
	LOSS [training: 0.008542805464901652 | validation: 0.006982530583581231]
	TIME [epoch: 36 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00853830908970993		[learning rate: 0.0002656]
	Learning Rate: 0.000265602
	LOSS [training: 0.00853830908970993 | validation: 0.007200728007177424]
	TIME [epoch: 36 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008972335914169603		[learning rate: 0.00026455]
	Learning Rate: 0.000264545
	LOSS [training: 0.008972335914169603 | validation: 0.006846796101646882]
	TIME [epoch: 36 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00824248138410958		[learning rate: 0.00026349]
	Learning Rate: 0.000263493
	LOSS [training: 0.00824248138410958 | validation: 0.00742472131696407]
	TIME [epoch: 36 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008120108569320765		[learning rate: 0.00026245]
	Learning Rate: 0.000262445
	LOSS [training: 0.008120108569320765 | validation: 0.007724380812924312]
	TIME [epoch: 36 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00838473630594657		[learning rate: 0.0002614]
	Learning Rate: 0.000261401
	LOSS [training: 0.00838473630594657 | validation: 0.006836854991936855]
	TIME [epoch: 36 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00831799831335587		[learning rate: 0.00026036]
	Learning Rate: 0.000260362
	LOSS [training: 0.00831799831335587 | validation: 0.0070090419351709924]
	TIME [epoch: 36 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009556003525705467		[learning rate: 0.00025933]
	Learning Rate: 0.000259326
	LOSS [training: 0.009556003525705467 | validation: 0.007048498528727398]
	TIME [epoch: 36 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008569569247127653		[learning rate: 0.00025829]
	Learning Rate: 0.000258295
	LOSS [training: 0.008569569247127653 | validation: 0.007034996642662966]
	TIME [epoch: 36 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008040730068176636		[learning rate: 0.00025727]
	Learning Rate: 0.000257267
	LOSS [training: 0.008040730068176636 | validation: 0.0074868192002250835]
	TIME [epoch: 36 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00818026988667814		[learning rate: 0.00025624]
	Learning Rate: 0.000256244
	LOSS [training: 0.00818026988667814 | validation: 0.007476007200836787]
	TIME [epoch: 35.9 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008235593378674862		[learning rate: 0.00025522]
	Learning Rate: 0.000255225
	LOSS [training: 0.008235593378674862 | validation: 0.007384340709512634]
	TIME [epoch: 36 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00781173889923349		[learning rate: 0.00025421]
	Learning Rate: 0.00025421
	LOSS [training: 0.00781173889923349 | validation: 0.0075944897199199755]
	TIME [epoch: 36 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008806984607924765		[learning rate: 0.0002532]
	Learning Rate: 0.000253199
	LOSS [training: 0.008806984607924765 | validation: 0.007327530662348184]
	TIME [epoch: 36 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008339999401067196		[learning rate: 0.00025219]
	Learning Rate: 0.000252192
	LOSS [training: 0.008339999401067196 | validation: 0.006849114767234332]
	TIME [epoch: 35.9 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008446504962671882		[learning rate: 0.00025119]
	Learning Rate: 0.000251189
	LOSS [training: 0.008446504962671882 | validation: 0.007021615772071473]
	TIME [epoch: 35.9 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00806403201716237		[learning rate: 0.00025019]
	Learning Rate: 0.00025019
	LOSS [training: 0.00806403201716237 | validation: 0.007466651397069715]
	TIME [epoch: 35.9 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008157654517279712		[learning rate: 0.00024919]
	Learning Rate: 0.000249195
	LOSS [training: 0.008157654517279712 | validation: 0.007335193274899092]
	TIME [epoch: 36 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008241421313836744		[learning rate: 0.0002482]
	Learning Rate: 0.000248203
	LOSS [training: 0.008241421313836744 | validation: 0.006881945732848343]
	TIME [epoch: 36 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008414172899757452		[learning rate: 0.00024722]
	Learning Rate: 0.000247216
	LOSS [training: 0.008414172899757452 | validation: 0.007295864777190038]
	TIME [epoch: 36 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007697942455595148		[learning rate: 0.00024623]
	Learning Rate: 0.000246233
	LOSS [training: 0.007697942455595148 | validation: 0.00760820918971136]
	TIME [epoch: 36 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007834473089225562		[learning rate: 0.00024525]
	Learning Rate: 0.000245254
	LOSS [training: 0.007834473089225562 | validation: 0.0069619489207097904]
	TIME [epoch: 36 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0088880932487671		[learning rate: 0.00024428]
	Learning Rate: 0.000244278
	LOSS [training: 0.0088880932487671 | validation: 0.0074556845038352025]
	TIME [epoch: 35.9 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008162874811211064		[learning rate: 0.00024331]
	Learning Rate: 0.000243307
	LOSS [training: 0.008162874811211064 | validation: 0.00672448130213828]
	TIME [epoch: 36 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009288250282250114		[learning rate: 0.00024234]
	Learning Rate: 0.000242339
	LOSS [training: 0.009288250282250114 | validation: 0.006991058890191039]
	TIME [epoch: 35.9 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008067591415006145		[learning rate: 0.00024138]
	Learning Rate: 0.000241375
	LOSS [training: 0.008067591415006145 | validation: 0.0072762160219170145]
	TIME [epoch: 36 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008978173258783285		[learning rate: 0.00024042]
	Learning Rate: 0.000240415
	LOSS [training: 0.008978173258783285 | validation: 0.006943759560017662]
	TIME [epoch: 35.9 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008574188881334205		[learning rate: 0.00023946]
	Learning Rate: 0.000239459
	LOSS [training: 0.008574188881334205 | validation: 0.0071210774566672795]
	TIME [epoch: 36 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008314405423051154		[learning rate: 0.00023851]
	Learning Rate: 0.000238506
	LOSS [training: 0.008314405423051154 | validation: 0.007413137161456489]
	TIME [epoch: 36 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007934698839936551		[learning rate: 0.00023756]
	Learning Rate: 0.000237558
	LOSS [training: 0.007934698839936551 | validation: 0.006848517572007183]
	TIME [epoch: 36 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008439161737178921		[learning rate: 0.00023661]
	Learning Rate: 0.000236613
	LOSS [training: 0.008439161737178921 | validation: 0.0071260468453750656]
	TIME [epoch: 36 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008643293438626756		[learning rate: 0.00023567]
	Learning Rate: 0.000235672
	LOSS [training: 0.008643293438626756 | validation: 0.007213130725332256]
	TIME [epoch: 36 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00830979355678037		[learning rate: 0.00023473]
	Learning Rate: 0.000234735
	LOSS [training: 0.00830979355678037 | validation: 0.007298322152434032]
	TIME [epoch: 35.9 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00792285996085962		[learning rate: 0.0002338]
	Learning Rate: 0.000233801
	LOSS [training: 0.00792285996085962 | validation: 0.006681572981039196]
	TIME [epoch: 36 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008088099858332191		[learning rate: 0.00023287]
	Learning Rate: 0.000232871
	LOSS [training: 0.008088099858332191 | validation: 0.007681239392336878]
	TIME [epoch: 36 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009181032384473358		[learning rate: 0.00023194]
	Learning Rate: 0.000231945
	LOSS [training: 0.009181032384473358 | validation: 0.007215924719605147]
	TIME [epoch: 36 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008786544165281301		[learning rate: 0.00023102]
	Learning Rate: 0.000231022
	LOSS [training: 0.008786544165281301 | validation: 0.007770102265597663]
	TIME [epoch: 36 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007918850157841382		[learning rate: 0.0002301]
	Learning Rate: 0.000230103
	LOSS [training: 0.007918850157841382 | validation: 0.00701169789464319]
	TIME [epoch: 36 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008918705756892503		[learning rate: 0.00022919]
	Learning Rate: 0.000229188
	LOSS [training: 0.008918705756892503 | validation: 0.007011694841003249]
	TIME [epoch: 36 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008688087481040467		[learning rate: 0.00022828]
	Learning Rate: 0.000228277
	LOSS [training: 0.008688087481040467 | validation: 0.0067596866142911076]
	TIME [epoch: 36 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00842640688649292		[learning rate: 0.00022737]
	Learning Rate: 0.000227369
	LOSS [training: 0.00842640688649292 | validation: 0.007343459296687756]
	TIME [epoch: 35.9 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00860249802168364		[learning rate: 0.00022646]
	Learning Rate: 0.000226464
	LOSS [training: 0.00860249802168364 | validation: 0.00704696126138285]
	TIME [epoch: 36 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01216254964073962		[learning rate: 0.00022556]
	Learning Rate: 0.000225564
	LOSS [training: 0.01216254964073962 | validation: 0.006883139178832707]
	TIME [epoch: 36 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007554204303005526		[learning rate: 0.00022467]
	Learning Rate: 0.000224667
	LOSS [training: 0.007554204303005526 | validation: 0.007515860183142951]
	TIME [epoch: 36 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008167615654397714		[learning rate: 0.00022377]
	Learning Rate: 0.000223773
	LOSS [training: 0.008167615654397714 | validation: 0.007079763013039866]
	TIME [epoch: 36 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00871664267451416		[learning rate: 0.00022288]
	Learning Rate: 0.000222883
	LOSS [training: 0.00871664267451416 | validation: 0.007176874239018397]
	TIME [epoch: 36 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008028164310253284		[learning rate: 0.000222]
	Learning Rate: 0.000221997
	LOSS [training: 0.008028164310253284 | validation: 0.007436530556664237]
	TIME [epoch: 36 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008048217043615167		[learning rate: 0.00022111]
	Learning Rate: 0.000221114
	LOSS [training: 0.008048217043615167 | validation: 0.007256175369915514]
	TIME [epoch: 36 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008071465149281467		[learning rate: 0.00022023]
	Learning Rate: 0.000220234
	LOSS [training: 0.008071465149281467 | validation: 0.0065793001052941325]
	TIME [epoch: 36 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008974043606427696		[learning rate: 0.00021936]
	Learning Rate: 0.000219358
	LOSS [training: 0.008974043606427696 | validation: 0.007138997183972151]
	TIME [epoch: 36 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007933087433049563		[learning rate: 0.00021849]
	Learning Rate: 0.000218486
	LOSS [training: 0.007933087433049563 | validation: 0.007367906605599583]
	TIME [epoch: 36 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008008318835131385		[learning rate: 0.00021762]
	Learning Rate: 0.000217617
	LOSS [training: 0.008008318835131385 | validation: 0.007085595895740246]
	TIME [epoch: 36 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00887748924949767		[learning rate: 0.00021675]
	Learning Rate: 0.000216751
	LOSS [training: 0.00887748924949767 | validation: 0.007388997674223061]
	TIME [epoch: 35.9 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008338076910194699		[learning rate: 0.00021589]
	Learning Rate: 0.000215889
	LOSS [training: 0.008338076910194699 | validation: 0.006877875570811284]
	TIME [epoch: 36 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00891695609662784		[learning rate: 0.00021503]
	Learning Rate: 0.00021503
	LOSS [training: 0.00891695609662784 | validation: 0.007617037853074856]
	TIME [epoch: 36 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010929313527810007		[learning rate: 0.00021418]
	Learning Rate: 0.000214175
	LOSS [training: 0.010929313527810007 | validation: 0.007234472737246223]
	TIME [epoch: 36 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010815112929251806		[learning rate: 0.00021332]
	Learning Rate: 0.000213323
	LOSS [training: 0.010815112929251806 | validation: 0.007144143619496744]
	TIME [epoch: 36 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00885190827384439		[learning rate: 0.00021247]
	Learning Rate: 0.000212475
	LOSS [training: 0.00885190827384439 | validation: 0.006965305391108606]
	TIME [epoch: 36 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007744692521043545		[learning rate: 0.00021163]
	Learning Rate: 0.00021163
	LOSS [training: 0.007744692521043545 | validation: 0.007549508266759984]
	TIME [epoch: 36 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00851895378975236		[learning rate: 0.00021079]
	Learning Rate: 0.000210788
	LOSS [training: 0.00851895378975236 | validation: 0.0072207804187359725]
	TIME [epoch: 36 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008329876409401903		[learning rate: 0.00020995]
	Learning Rate: 0.00020995
	LOSS [training: 0.008329876409401903 | validation: 0.007373377251033793]
	TIME [epoch: 36 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009493303581343732		[learning rate: 0.00020911]
	Learning Rate: 0.000209115
	LOSS [training: 0.009493303581343732 | validation: 0.007603048312319749]
	TIME [epoch: 36 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008948311348136478		[learning rate: 0.00020828]
	Learning Rate: 0.000208283
	LOSS [training: 0.008948311348136478 | validation: 0.00733657790082317]
	TIME [epoch: 36 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008238522499856911		[learning rate: 0.00020745]
	Learning Rate: 0.000207455
	LOSS [training: 0.008238522499856911 | validation: 0.007135988403757879]
	TIME [epoch: 36 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00848667852199483		[learning rate: 0.00020663]
	Learning Rate: 0.00020663
	LOSS [training: 0.00848667852199483 | validation: 0.007246391454743009]
	TIME [epoch: 36 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008235557387930028		[learning rate: 0.00020581]
	Learning Rate: 0.000205808
	LOSS [training: 0.008235557387930028 | validation: 0.006686080379642095]
	TIME [epoch: 36 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007978280707761807		[learning rate: 0.00020499]
	Learning Rate: 0.000204989
	LOSS [training: 0.007978280707761807 | validation: 0.007249042725860494]
	TIME [epoch: 35.9 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007989508379900395		[learning rate: 0.00020417]
	Learning Rate: 0.000204174
	LOSS [training: 0.007989508379900395 | validation: 0.007545440612607398]
	TIME [epoch: 36 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008040505501802603		[learning rate: 0.00020336]
	Learning Rate: 0.000203362
	LOSS [training: 0.008040505501802603 | validation: 0.007259807428504824]
	TIME [epoch: 36 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008551212722338723		[learning rate: 0.00020255]
	Learning Rate: 0.000202553
	LOSS [training: 0.008551212722338723 | validation: 0.0070374427412071856]
	TIME [epoch: 36 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009016894016136954		[learning rate: 0.00020175]
	Learning Rate: 0.000201747
	LOSS [training: 0.009016894016136954 | validation: 0.006880499262695601]
	TIME [epoch: 36 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008083113138539504		[learning rate: 0.00020094]
	Learning Rate: 0.000200945
	LOSS [training: 0.008083113138539504 | validation: 0.0068740047880395325]
	TIME [epoch: 36 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00808268648183435		[learning rate: 0.00020015]
	Learning Rate: 0.000200146
	LOSS [training: 0.00808268648183435 | validation: 0.0073565459083800595]
	TIME [epoch: 36 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008495716568558756		[learning rate: 0.00019935]
	Learning Rate: 0.00019935
	LOSS [training: 0.008495716568558756 | validation: 0.006808133331562454]
	TIME [epoch: 36 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007950221709451553		[learning rate: 0.00019856]
	Learning Rate: 0.000198557
	LOSS [training: 0.007950221709451553 | validation: 0.007347073871500626]
	TIME [epoch: 36 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008156898777867938		[learning rate: 0.00019777]
	Learning Rate: 0.000197767
	LOSS [training: 0.008156898777867938 | validation: 0.00705150018920749]
	TIME [epoch: 36 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008045220461928225		[learning rate: 0.00019698]
	Learning Rate: 0.00019698
	LOSS [training: 0.008045220461928225 | validation: 0.007327607310474646]
	TIME [epoch: 36 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008547509742915037		[learning rate: 0.0001962]
	Learning Rate: 0.000196197
	LOSS [training: 0.008547509742915037 | validation: 0.0074143795453904425]
	TIME [epoch: 36 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00813115516077545		[learning rate: 0.00019542]
	Learning Rate: 0.000195417
	LOSS [training: 0.00813115516077545 | validation: 0.007359396342107601]
	TIME [epoch: 35.9 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00880952780290202		[learning rate: 0.00019464]
	Learning Rate: 0.000194639
	LOSS [training: 0.00880952780290202 | validation: 0.00694883590262386]
	TIME [epoch: 36 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007964874246767562		[learning rate: 0.00019387]
	Learning Rate: 0.000193865
	LOSS [training: 0.007964874246767562 | validation: 0.007113252179066181]
	TIME [epoch: 36 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008616082814133395		[learning rate: 0.00019309]
	Learning Rate: 0.000193094
	LOSS [training: 0.008616082814133395 | validation: 0.007043283946845396]
	TIME [epoch: 36 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008355942340324683		[learning rate: 0.00019233]
	Learning Rate: 0.000192326
	LOSS [training: 0.008355942340324683 | validation: 0.00760544192276401]
	TIME [epoch: 36 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008004216266990362		[learning rate: 0.00019156]
	Learning Rate: 0.000191561
	LOSS [training: 0.008004216266990362 | validation: 0.007354771828028723]
	TIME [epoch: 36 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00834152383865783		[learning rate: 0.0001908]
	Learning Rate: 0.000190799
	LOSS [training: 0.00834152383865783 | validation: 0.007125192237794153]
	TIME [epoch: 36 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007827012700874405		[learning rate: 0.00019004]
	Learning Rate: 0.00019004
	LOSS [training: 0.007827012700874405 | validation: 0.006976062508483874]
	TIME [epoch: 36 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008128617200117018		[learning rate: 0.00018928]
	Learning Rate: 0.000189285
	LOSS [training: 0.008128617200117018 | validation: 0.007479835627448868]
	TIME [epoch: 36 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007966735632140017		[learning rate: 0.00018853]
	Learning Rate: 0.000188532
	LOSS [training: 0.007966735632140017 | validation: 0.007229702150164212]
	TIME [epoch: 36 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009112089828502576		[learning rate: 0.00018778]
	Learning Rate: 0.000187782
	LOSS [training: 0.009112089828502576 | validation: 0.006870289113301534]
	TIME [epoch: 36 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00846922919843066		[learning rate: 0.00018704]
	Learning Rate: 0.000187035
	LOSS [training: 0.00846922919843066 | validation: 0.00684278253306498]
	TIME [epoch: 36 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008792401059065109		[learning rate: 0.00018629]
	Learning Rate: 0.000186291
	LOSS [training: 0.008792401059065109 | validation: 0.006999635665144992]
	TIME [epoch: 36 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008004511735541932		[learning rate: 0.00018555]
	Learning Rate: 0.00018555
	LOSS [training: 0.008004511735541932 | validation: 0.007498121594592599]
	TIME [epoch: 36 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008225168862234409		[learning rate: 0.00018481]
	Learning Rate: 0.000184812
	LOSS [training: 0.008225168862234409 | validation: 0.00692516736889206]
	TIME [epoch: 36 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00827351530247055		[learning rate: 0.00018408]
	Learning Rate: 0.000184077
	LOSS [training: 0.00827351530247055 | validation: 0.007340897300130692]
	TIME [epoch: 36 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00822446629381287		[learning rate: 0.00018335]
	Learning Rate: 0.000183345
	LOSS [training: 0.00822446629381287 | validation: 0.007167683926138642]
	TIME [epoch: 36 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01038365313731495		[learning rate: 0.00018262]
	Learning Rate: 0.000182616
	LOSS [training: 0.01038365313731495 | validation: 0.0074180816706204715]
	TIME [epoch: 36 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008291308480531293		[learning rate: 0.00018189]
	Learning Rate: 0.00018189
	LOSS [training: 0.008291308480531293 | validation: 0.007358608732290546]
	TIME [epoch: 36 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008980163465518859		[learning rate: 0.00018117]
	Learning Rate: 0.000181166
	LOSS [training: 0.008980163465518859 | validation: 0.007644902071593772]
	TIME [epoch: 36 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0087216671576766		[learning rate: 0.00018045]
	Learning Rate: 0.000180446
	LOSS [training: 0.0087216671576766 | validation: 0.007815160196739192]
	TIME [epoch: 36 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008175888216065854		[learning rate: 0.00017973]
	Learning Rate: 0.000179728
	LOSS [training: 0.008175888216065854 | validation: 0.0068200863561303]
	TIME [epoch: 36 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011653108315499372		[learning rate: 0.00017901]
	Learning Rate: 0.000179013
	LOSS [training: 0.011653108315499372 | validation: 0.0076039966076976]
	TIME [epoch: 36 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007935860578370774		[learning rate: 0.0001783]
	Learning Rate: 0.000178301
	LOSS [training: 0.007935860578370774 | validation: 0.007696512533004407]
	TIME [epoch: 36 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008777167797815677		[learning rate: 0.00017759]
	Learning Rate: 0.000177592
	LOSS [training: 0.008777167797815677 | validation: 0.006906625590611673]
	TIME [epoch: 36 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008096696682828189		[learning rate: 0.00017689]
	Learning Rate: 0.000176886
	LOSS [training: 0.008096696682828189 | validation: 0.007573353650534136]
	TIME [epoch: 36 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008038697619701185		[learning rate: 0.00017618]
	Learning Rate: 0.000176182
	LOSS [training: 0.008038697619701185 | validation: 0.007204745773574035]
	TIME [epoch: 36 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008219849958418691		[learning rate: 0.00017548]
	Learning Rate: 0.000175481
	LOSS [training: 0.008219849958418691 | validation: 0.007259583286475349]
	TIME [epoch: 36 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007923898364098661		[learning rate: 0.00017478]
	Learning Rate: 0.000174783
	LOSS [training: 0.007923898364098661 | validation: 0.007463535933998377]
	TIME [epoch: 36 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008879204808500967		[learning rate: 0.00017409]
	Learning Rate: 0.000174088
	LOSS [training: 0.008879204808500967 | validation: 0.007699835480004254]
	TIME [epoch: 36 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00850735925919626		[learning rate: 0.0001734]
	Learning Rate: 0.000173396
	LOSS [training: 0.00850735925919626 | validation: 0.007838377884462445]
	TIME [epoch: 36 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008309195527869163		[learning rate: 0.00017271]
	Learning Rate: 0.000172706
	LOSS [training: 0.008309195527869163 | validation: 0.007044773057971461]
	TIME [epoch: 36 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008024068630267984		[learning rate: 0.00017202]
	Learning Rate: 0.000172019
	LOSS [training: 0.008024068630267984 | validation: 0.007248615940023165]
	TIME [epoch: 36 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007765017163997672		[learning rate: 0.00017134]
	Learning Rate: 0.000171335
	LOSS [training: 0.007765017163997672 | validation: 0.007653470476681053]
	TIME [epoch: 36 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007915332704235742		[learning rate: 0.00017065]
	Learning Rate: 0.000170654
	LOSS [training: 0.007915332704235742 | validation: 0.00709810888101548]
	TIME [epoch: 35.9 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008132021182005367		[learning rate: 0.00016997]
	Learning Rate: 0.000169975
	LOSS [training: 0.008132021182005367 | validation: 0.007343550368518194]
	TIME [epoch: 36 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008166059720953737		[learning rate: 0.0001693]
	Learning Rate: 0.000169299
	LOSS [training: 0.008166059720953737 | validation: 0.007236284922204739]
	TIME [epoch: 36 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007866247391702623		[learning rate: 0.00016863]
	Learning Rate: 0.000168625
	LOSS [training: 0.007866247391702623 | validation: 0.006669704807611176]
	TIME [epoch: 36 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00776701433928521		[learning rate: 0.00016795]
	Learning Rate: 0.000167955
	LOSS [training: 0.00776701433928521 | validation: 0.00731335594833753]
	TIME [epoch: 36 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008040575850451277		[learning rate: 0.00016729]
	Learning Rate: 0.000167287
	LOSS [training: 0.008040575850451277 | validation: 0.007399641773756955]
	TIME [epoch: 36 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008077484341870975		[learning rate: 0.00016662]
	Learning Rate: 0.000166621
	LOSS [training: 0.008077484341870975 | validation: 0.00688344948149278]
	TIME [epoch: 36 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008683786078851249		[learning rate: 0.00016596]
	Learning Rate: 0.000165959
	LOSS [training: 0.008683786078851249 | validation: 0.007552546053573167]
	TIME [epoch: 36 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010583954555762779		[learning rate: 0.0001653]
	Learning Rate: 0.000165299
	LOSS [training: 0.010583954555762779 | validation: 0.0075037937415636646]
	TIME [epoch: 36 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009064668251064568		[learning rate: 0.00016464]
	Learning Rate: 0.000164641
	LOSS [training: 0.009064668251064568 | validation: 0.007223943122052562]
	TIME [epoch: 35.9 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00937561255535597		[learning rate: 0.00016399]
	Learning Rate: 0.000163986
	LOSS [training: 0.00937561255535597 | validation: 0.00695411642727109]
	TIME [epoch: 36 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007770819322436909		[learning rate: 0.00016333]
	Learning Rate: 0.000163334
	LOSS [training: 0.007770819322436909 | validation: 0.0070915208639205805]
	TIME [epoch: 36 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011635650677478558		[learning rate: 0.00016268]
	Learning Rate: 0.000162685
	LOSS [training: 0.011635650677478558 | validation: 0.007139248816362064]
	TIME [epoch: 36 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00856540160518227		[learning rate: 0.00016204]
	Learning Rate: 0.000162037
	LOSS [training: 0.00856540160518227 | validation: 0.00696309833361088]
	TIME [epoch: 36 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008449367755359058		[learning rate: 0.00016139]
	Learning Rate: 0.000161393
	LOSS [training: 0.008449367755359058 | validation: 0.0068057240200450324]
	TIME [epoch: 36 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008166530879917937		[learning rate: 0.00016075]
	Learning Rate: 0.000160751
	LOSS [training: 0.008166530879917937 | validation: 0.007086085367763234]
	TIME [epoch: 36 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008224347256550545		[learning rate: 0.00016011]
	Learning Rate: 0.000160112
	LOSS [training: 0.008224347256550545 | validation: 0.007203423210218928]
	TIME [epoch: 36 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009129855664595087		[learning rate: 0.00015947]
	Learning Rate: 0.000159475
	LOSS [training: 0.009129855664595087 | validation: 0.007697705158946691]
	TIME [epoch: 36 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008583100401059474		[learning rate: 0.00015884]
	Learning Rate: 0.000158841
	LOSS [training: 0.008583100401059474 | validation: 0.007342453934310225]
	TIME [epoch: 36 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007964539791724434		[learning rate: 0.00015821]
	Learning Rate: 0.000158209
	LOSS [training: 0.007964539791724434 | validation: 0.006955530345978929]
	TIME [epoch: 36 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0079083423487009		[learning rate: 0.00015758]
	Learning Rate: 0.00015758
	LOSS [training: 0.0079083423487009 | validation: 0.007193510243496015]
	TIME [epoch: 36 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008192621041385706		[learning rate: 0.00015695]
	Learning Rate: 0.000156953
	LOSS [training: 0.008192621041385706 | validation: 0.007291729381196298]
	TIME [epoch: 36 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008045871768716802		[learning rate: 0.00015633]
	Learning Rate: 0.000156329
	LOSS [training: 0.008045871768716802 | validation: 0.0069121931153528675]
	TIME [epoch: 36 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008910318482823495		[learning rate: 0.00015571]
	Learning Rate: 0.000155707
	LOSS [training: 0.008910318482823495 | validation: 0.007261139075905096]
	TIME [epoch: 36 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008423065280251892		[learning rate: 0.00015509]
	Learning Rate: 0.000155088
	LOSS [training: 0.008423065280251892 | validation: 0.006966683951955641]
	TIME [epoch: 36 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008697556566397275		[learning rate: 0.00015447]
	Learning Rate: 0.000154471
	LOSS [training: 0.008697556566397275 | validation: 0.007289847745448182]
	TIME [epoch: 35.9 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008796189452887779		[learning rate: 0.00015386]
	Learning Rate: 0.000153856
	LOSS [training: 0.008796189452887779 | validation: 0.0069149911776388035]
	TIME [epoch: 35.9 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008853868357800125		[learning rate: 0.00015324]
	Learning Rate: 0.000153244
	LOSS [training: 0.008853868357800125 | validation: 0.006545993502682329]
	TIME [epoch: 36 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011968544288029194		[learning rate: 0.00015263]
	Learning Rate: 0.000152635
	LOSS [training: 0.011968544288029194 | validation: 0.007085071693194433]
	TIME [epoch: 36 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008059683889213201		[learning rate: 0.00015203]
	Learning Rate: 0.000152028
	LOSS [training: 0.008059683889213201 | validation: 0.0077423995486330804]
	TIME [epoch: 36 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00798869924305668		[learning rate: 0.00015142]
	Learning Rate: 0.000151423
	LOSS [training: 0.00798869924305668 | validation: 0.007627864994990849]
	TIME [epoch: 36 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00842982856659569		[learning rate: 0.00015082]
	Learning Rate: 0.000150821
	LOSS [training: 0.00842982856659569 | validation: 0.007442347620402812]
	TIME [epoch: 36 sec]
	Saving model to: out/model_training/model_facs_dec1b_2d_v1_20240622_120511/states/model_facs_dec1b_2d_v1_1097.pth
Halted early. No improvement in validation loss for 200 epochs.
Finished training in 40032.879 seconds.
