Args:
Namespace(name='model_facs_v3_dec1b_2dpca_v8', outdir='out/model_training/model_facs_v3_dec1b_2dpca_v8', training_data='data/training_data/facs_v3/pca/dec1_fitonsubset/transition1_subset_epi_tr_ce_an_pc12/training', validation_data='data/training_data/facs_v3/pca/dec1_fitonsubset/transition1_subset_epi_tr_ce_an_pc12/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=10, batch_size=50, patience=200, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, quadratic_a=1.0, quadratic_b=1.0, ndims=2, nparams=2, nsigs=2, ncells=400, ncells_sample=400, model_do_sample=False, dt=0.005, dt_schedule='stepped', dt_schedule_bounds=[500, 1000, 1500], dt_schedule_scales=[0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=True, sigma=0.02, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', kernel='multiscale', bw_range=[0.2, 0.5, 0.9, 1.1, 1.3, 1.5, 2.0], optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 4020913320

Training model...

Saving initial model state to: out/model_training/model_facs_v3_dec1b_2dpca_v8_20240715_180006/states/model_facs_v3_dec1b_2dpca_v8_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.6398770433582028		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6398770433582028 | validation: 1.4084427472708145]
	TIME [epoch: 33 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v8_20240715_180006/states/model_facs_v3_dec1b_2dpca_v8_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.4715939028386555		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4715939028386555 | validation: 1.3102400709751856]
	TIME [epoch: 6.97 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v8_20240715_180006/states/model_facs_v3_dec1b_2dpca_v8_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.3901792777535267		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3901792777535267 | validation: 1.3530625286941655]
	TIME [epoch: 6.96 sec]
EPOCH 4/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.3356608163423598		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3356608163423598 | validation: 1.154998197448952]
	TIME [epoch: 6.96 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v8_20240715_180006/states/model_facs_v3_dec1b_2dpca_v8_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.3234920861835662		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3234920861835662 | validation: 1.120784878143536]
	TIME [epoch: 6.96 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v8_20240715_180006/states/model_facs_v3_dec1b_2dpca_v8_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.1729546826382846		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1729546826382846 | validation: 1.0495487698731982]
	TIME [epoch: 6.97 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v8_20240715_180006/states/model_facs_v3_dec1b_2dpca_v8_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.1474584132456196		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1474584132456196 | validation: 1.070423473463316]
	TIME [epoch: 6.95 sec]
EPOCH 8/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.1077502286038519		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1077502286038519 | validation: 1.0518780190982582]
	TIME [epoch: 6.95 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.0060931383691039		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0060931383691039 | validation: 1.3381105465859184]
	TIME [epoch: 6.95 sec]
EPOCH 10/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.0696626781344756		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0696626781344756 | validation: 0.965160721678249]
	TIME [epoch: 6.95 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v8_20240715_180006/states/model_facs_v3_dec1b_2dpca_v8_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.0220381442205424		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0220381442205424 | validation: 0.8959132176964502]
	TIME [epoch: 6.96 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v8_20240715_180006/states/model_facs_v3_dec1b_2dpca_v8_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.8614735927689713		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8614735927689713 | validation: 0.8863607358880475]
	TIME [epoch: 6.96 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v8_20240715_180006/states/model_facs_v3_dec1b_2dpca_v8_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.9609075071140066		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9609075071140066 | validation: 1.0594256631669083]
	TIME [epoch: 6.96 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.96133660213161		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.96133660213161 | validation: 0.8636888657580757]
	TIME [epoch: 6.95 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v8_20240715_180006/states/model_facs_v3_dec1b_2dpca_v8_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.8232885657569932		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8232885657569932 | validation: 0.9530207246902431]
	TIME [epoch: 6.97 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.0755251959054097		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0755251959054097 | validation: 0.9128000704547141]
	TIME [epoch: 6.96 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.0550323255542893		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0550323255542893 | validation: 0.9854929108529751]
	TIME [epoch: 6.96 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.9705058135788955		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9705058135788955 | validation: 0.8786046712536095]
	TIME [epoch: 6.96 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.9780403282900316		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9780403282900316 | validation: 0.8385245025771024]
	TIME [epoch: 6.97 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v8_20240715_180006/states/model_facs_v3_dec1b_2dpca_v8_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.8370554509499922		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8370554509499922 | validation: 0.8763687300653101]
	TIME [epoch: 6.96 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.8366932330404181		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8366932330404181 | validation: 0.7402455750842852]
	TIME [epoch: 6.95 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v8_20240715_180006/states/model_facs_v3_dec1b_2dpca_v8_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.8667049741457525		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8667049741457525 | validation: 0.7518048667847822]
	TIME [epoch: 6.96 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.8035656578407218		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8035656578407218 | validation: 0.6677531982183418]
	TIME [epoch: 6.95 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v8_20240715_180006/states/model_facs_v3_dec1b_2dpca_v8_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.8349711652255017		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8349711652255017 | validation: 0.9131301170630965]
	TIME [epoch: 6.96 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.7925824233379296		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7925824233379296 | validation: 0.6866383966390395]
	TIME [epoch: 6.95 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.6490741279887157		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6490741279887157 | validation: 0.6546995115612722]
	TIME [epoch: 6.95 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v8_20240715_180006/states/model_facs_v3_dec1b_2dpca_v8_26.pth
	Model improved!!!
EPOCH 27/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.669437601237067		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.669437601237067 | validation: 0.5943225168915776]
	TIME [epoch: 6.96 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v8_20240715_180006/states/model_facs_v3_dec1b_2dpca_v8_27.pth
	Model improved!!!
EPOCH 28/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.7324898181488946		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7324898181488946 | validation: 0.6504255337539634]
	TIME [epoch: 6.97 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.9117008017054253		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9117008017054253 | validation: 0.9418924602982337]
	TIME [epoch: 6.97 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.8273472661817401		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8273472661817401 | validation: 0.5842015357609656]
	TIME [epoch: 6.96 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v8_20240715_180006/states/model_facs_v3_dec1b_2dpca_v8_30.pth
	Model improved!!!
EPOCH 31/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.6382174077014232		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6382174077014232 | validation: 0.6501857152067417]
	TIME [epoch: 6.96 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.6140667958160905		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6140667958160905 | validation: 0.6815205621432183]
	TIME [epoch: 6.96 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.737603237475188		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.737603237475188 | validation: 0.8688770577328413]
	TIME [epoch: 6.96 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.7593304131138582		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7593304131138582 | validation: 0.570780294943762]
	TIME [epoch: 6.97 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v8_20240715_180006/states/model_facs_v3_dec1b_2dpca_v8_34.pth
	Model improved!!!
EPOCH 35/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.6127524438820551		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6127524438820551 | validation: 0.5410807492868285]
	TIME [epoch: 6.96 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v8_20240715_180006/states/model_facs_v3_dec1b_2dpca_v8_35.pth
	Model improved!!!
EPOCH 36/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.6428271898305188		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6428271898305188 | validation: 0.6881039687881321]
	TIME [epoch: 6.96 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.6254435852548962		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6254435852548962 | validation: 0.497431733099971]
	TIME [epoch: 6.96 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v8_20240715_180006/states/model_facs_v3_dec1b_2dpca_v8_37.pth
	Model improved!!!
EPOCH 38/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.6411962958030691		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6411962958030691 | validation: 0.7249247266924499]
	TIME [epoch: 6.96 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.6869223837970401		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6869223837970401 | validation: 0.6966472040467225]
	TIME [epoch: 6.97 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.9488551169536769		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9488551169536769 | validation: 0.7608050341878829]
	TIME [epoch: 6.96 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.8729737293883062		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8729737293883062 | validation: 0.8285276524645038]
	TIME [epoch: 6.96 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.889078547626783		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.889078547626783 | validation: 0.687154766760239]
	TIME [epoch: 6.96 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.9069156391803596		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9069156391803596 | validation: 0.7737019778062905]
	TIME [epoch: 6.96 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.7995461173867559		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7995461173867559 | validation: 0.6057573789487413]
	TIME [epoch: 6.99 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.6320781007828967		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6320781007828967 | validation: 0.575069031637864]
	TIME [epoch: 6.96 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.7096739649306055		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7096739649306055 | validation: 0.5446079032117447]
	TIME [epoch: 6.96 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.655918707083045		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.655918707083045 | validation: 0.7838258495585503]
	TIME [epoch: 6.96 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.669711507435789		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.669711507435789 | validation: 0.5913288917743246]
	TIME [epoch: 6.96 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.6068394011413459		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6068394011413459 | validation: 0.6181079071984624]
	TIME [epoch: 6.97 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.7118884407385648		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7118884407385648 | validation: 0.7293599535115213]
	TIME [epoch: 6.96 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.6930982534031761		[learning rate: 0.0099705]
	Learning Rate: 0.00997052
	LOSS [training: 0.6930982534031761 | validation: 0.5878259270350368]
	TIME [epoch: 6.96 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5920021550468938		[learning rate: 0.0099353]
	Learning Rate: 0.00993527
	LOSS [training: 0.5920021550468938 | validation: 0.5344962818762149]
	TIME [epoch: 6.98 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5733563035970156		[learning rate: 0.0099001]
	Learning Rate: 0.00990013
	LOSS [training: 0.5733563035970156 | validation: 0.5448990562119548]
	TIME [epoch: 6.97 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5394785166578707		[learning rate: 0.0098651]
	Learning Rate: 0.00986512
	LOSS [training: 0.5394785166578707 | validation: 0.49665739742671294]
	TIME [epoch: 6.97 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v8_20240715_180006/states/model_facs_v3_dec1b_2dpca_v8_54.pth
	Model improved!!!
EPOCH 55/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5495619883546575		[learning rate: 0.0098302]
	Learning Rate: 0.00983024
	LOSS [training: 0.5495619883546575 | validation: 0.5834879019726791]
	TIME [epoch: 6.96 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.794731447068853		[learning rate: 0.0097955]
	Learning Rate: 0.00979548
	LOSS [training: 0.794731447068853 | validation: 0.6272871088128424]
	TIME [epoch: 6.96 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5775812560689771		[learning rate: 0.0097608]
	Learning Rate: 0.00976084
	LOSS [training: 0.5775812560689771 | validation: 0.520279616744886]
	TIME [epoch: 6.96 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5077299757401819		[learning rate: 0.0097263]
	Learning Rate: 0.00972632
	LOSS [training: 0.5077299757401819 | validation: 0.5452738868441155]
	TIME [epoch: 6.97 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5420187511973803		[learning rate: 0.0096919]
	Learning Rate: 0.00969193
	LOSS [training: 0.5420187511973803 | validation: 0.5842515192256809]
	TIME [epoch: 6.96 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.7969095641208516		[learning rate: 0.0096577]
	Learning Rate: 0.00965766
	LOSS [training: 0.7969095641208516 | validation: 0.6684297118387919]
	TIME [epoch: 6.96 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.6055309604373991		[learning rate: 0.0096235]
	Learning Rate: 0.00962351
	LOSS [training: 0.6055309604373991 | validation: 0.4568401194494903]
	TIME [epoch: 6.95 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v8_20240715_180006/states/model_facs_v3_dec1b_2dpca_v8_61.pth
	Model improved!!!
EPOCH 62/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.6678441229336395		[learning rate: 0.0095895]
	Learning Rate: 0.00958948
	LOSS [training: 0.6678441229336395 | validation: 0.6092235659599309]
	TIME [epoch: 6.96 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.794921189367693		[learning rate: 0.0095556]
	Learning Rate: 0.00955557
	LOSS [training: 0.794921189367693 | validation: 0.5635739384457235]
	TIME [epoch: 6.97 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.6251039585250886		[learning rate: 0.0095218]
	Learning Rate: 0.00952177
	LOSS [training: 0.6251039585250886 | validation: 0.5089678018579201]
	TIME [epoch: 6.96 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.7610193969663138		[learning rate: 0.0094881]
	Learning Rate: 0.0094881
	LOSS [training: 0.7610193969663138 | validation: 0.5007487322892963]
	TIME [epoch: 6.96 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.6103000636525687		[learning rate: 0.0094546]
	Learning Rate: 0.00945455
	LOSS [training: 0.6103000636525687 | validation: 0.5462478150863987]
	TIME [epoch: 6.96 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.523972572697282		[learning rate: 0.0094211]
	Learning Rate: 0.00942112
	LOSS [training: 0.523972572697282 | validation: 0.4790871288669131]
	TIME [epoch: 6.96 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.566432990659511		[learning rate: 0.0093878]
	Learning Rate: 0.00938781
	LOSS [training: 0.566432990659511 | validation: 0.503127612982199]
	TIME [epoch: 6.97 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.6102752960470462		[learning rate: 0.0093546]
	Learning Rate: 0.00935461
	LOSS [training: 0.6102752960470462 | validation: 0.5717302523973747]
	TIME [epoch: 6.97 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.6238799645028753		[learning rate: 0.0093215]
	Learning Rate: 0.00932153
	LOSS [training: 0.6238799645028753 | validation: 0.45852993759523086]
	TIME [epoch: 6.96 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.550046186270181		[learning rate: 0.0092886]
	Learning Rate: 0.00928857
	LOSS [training: 0.550046186270181 | validation: 0.5156203283998507]
	TIME [epoch: 6.96 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5184782241706486		[learning rate: 0.0092557]
	Learning Rate: 0.00925572
	LOSS [training: 0.5184782241706486 | validation: 0.521812792855519]
	TIME [epoch: 6.96 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4982808949442145		[learning rate: 0.009223]
	Learning Rate: 0.00922299
	LOSS [training: 0.4982808949442145 | validation: 0.5278955023937798]
	TIME [epoch: 6.97 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.7105209701209642		[learning rate: 0.0091904]
	Learning Rate: 0.00919038
	LOSS [training: 0.7105209701209642 | validation: 0.5707294008357179]
	TIME [epoch: 6.96 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.7515498689498524		[learning rate: 0.0091579]
	Learning Rate: 0.00915788
	LOSS [training: 0.7515498689498524 | validation: 0.6008722231687219]
	TIME [epoch: 6.96 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.7188919804186251		[learning rate: 0.0091255]
	Learning Rate: 0.00912549
	LOSS [training: 0.7188919804186251 | validation: 0.6925619739630867]
	TIME [epoch: 6.96 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.7835794581032306		[learning rate: 0.0090932]
	Learning Rate: 0.00909323
	LOSS [training: 0.7835794581032306 | validation: 0.5376626230180691]
	TIME [epoch: 6.96 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.6639470368997763		[learning rate: 0.0090611]
	Learning Rate: 0.00906107
	LOSS [training: 0.6639470368997763 | validation: 0.6904285500021488]
	TIME [epoch: 6.97 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.7330218683949914		[learning rate: 0.009029]
	Learning Rate: 0.00902903
	LOSS [training: 0.7330218683949914 | validation: 0.4560644004370561]
	TIME [epoch: 6.96 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v8_20240715_180006/states/model_facs_v3_dec1b_2dpca_v8_79.pth
	Model improved!!!
EPOCH 80/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.6703735147824137		[learning rate: 0.0089971]
	Learning Rate: 0.0089971
	LOSS [training: 0.6703735147824137 | validation: 0.577374926383031]
	TIME [epoch: 6.97 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5824005195908682		[learning rate: 0.0089653]
	Learning Rate: 0.00896528
	LOSS [training: 0.5824005195908682 | validation: 0.42989825789673547]
	TIME [epoch: 6.96 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v8_20240715_180006/states/model_facs_v3_dec1b_2dpca_v8_81.pth
	Model improved!!!
EPOCH 82/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.722677423701994		[learning rate: 0.0089336]
	Learning Rate: 0.00893358
	LOSS [training: 0.722677423701994 | validation: 0.5090096920823727]
	TIME [epoch: 6.97 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.6032892717672224		[learning rate: 0.008902]
	Learning Rate: 0.00890199
	LOSS [training: 0.6032892717672224 | validation: 0.5796554783690651]
	TIME [epoch: 6.96 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.6848121096203554		[learning rate: 0.0088705]
	Learning Rate: 0.00887051
	LOSS [training: 0.6848121096203554 | validation: 0.5762384137811155]
	TIME [epoch: 6.97 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.8038312595904357		[learning rate: 0.0088391]
	Learning Rate: 0.00883914
	LOSS [training: 0.8038312595904357 | validation: 0.569879811432844]
	TIME [epoch: 6.96 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.6731970206861325		[learning rate: 0.0088079]
	Learning Rate: 0.00880789
	LOSS [training: 0.6731970206861325 | validation: 0.5199806023629212]
	TIME [epoch: 6.99 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.6011334149757847		[learning rate: 0.0087767]
	Learning Rate: 0.00877674
	LOSS [training: 0.6011334149757847 | validation: 0.5250579207016683]
	TIME [epoch: 6.97 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.6171373279505813		[learning rate: 0.0087457]
	Learning Rate: 0.00874571
	LOSS [training: 0.6171373279505813 | validation: 0.4661095576951107]
	TIME [epoch: 6.97 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.6110063287583976		[learning rate: 0.0087148]
	Learning Rate: 0.00871478
	LOSS [training: 0.6110063287583976 | validation: 0.46082270615049453]
	TIME [epoch: 6.96 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.6312255853177593		[learning rate: 0.008684]
	Learning Rate: 0.00868396
	LOSS [training: 0.6312255853177593 | validation: 0.5428633832825212]
	TIME [epoch: 6.96 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5679049223689577		[learning rate: 0.0086533]
	Learning Rate: 0.00865326
	LOSS [training: 0.5679049223689577 | validation: 0.45044702177867724]
	TIME [epoch: 6.96 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5425650225552973		[learning rate: 0.0086227]
	Learning Rate: 0.00862265
	LOSS [training: 0.5425650225552973 | validation: 0.42099913751241325]
	TIME [epoch: 6.97 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v8_20240715_180006/states/model_facs_v3_dec1b_2dpca_v8_92.pth
	Model improved!!!
EPOCH 93/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.574267856076608		[learning rate: 0.0085922]
	Learning Rate: 0.00859216
	LOSS [training: 0.574267856076608 | validation: 0.42710688833567517]
	TIME [epoch: 6.96 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.507062967092152		[learning rate: 0.0085618]
	Learning Rate: 0.00856178
	LOSS [training: 0.507062967092152 | validation: 0.40502931347069565]
	TIME [epoch: 6.95 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v8_20240715_180006/states/model_facs_v3_dec1b_2dpca_v8_94.pth
	Model improved!!!
EPOCH 95/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5187856639745972		[learning rate: 0.0085315]
	Learning Rate: 0.0085315
	LOSS [training: 0.5187856639745972 | validation: 0.5195721111562889]
	TIME [epoch: 6.96 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5054675615250536		[learning rate: 0.0085013]
	Learning Rate: 0.00850134
	LOSS [training: 0.5054675615250536 | validation: 0.4861710363082083]
	TIME [epoch: 6.95 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.6593946057158789		[learning rate: 0.0084713]
	Learning Rate: 0.00847127
	LOSS [training: 0.6593946057158789 | validation: 0.5656182602278371]
	TIME [epoch: 6.96 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5424927360639908		[learning rate: 0.0084413]
	Learning Rate: 0.00844132
	LOSS [training: 0.5424927360639908 | validation: 0.42906785210253695]
	TIME [epoch: 6.96 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.48537604475292023		[learning rate: 0.0084115]
	Learning Rate: 0.00841147
	LOSS [training: 0.48537604475292023 | validation: 0.5388932125468555]
	TIME [epoch: 6.95 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5302271532145787		[learning rate: 0.0083817]
	Learning Rate: 0.00838172
	LOSS [training: 0.5302271532145787 | validation: 0.4997010672126262]
	TIME [epoch: 6.96 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5079086719401603		[learning rate: 0.0083521]
	Learning Rate: 0.00835208
	LOSS [training: 0.5079086719401603 | validation: 0.6678677460350645]
	TIME [epoch: 6.96 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5430001864920453		[learning rate: 0.0083225]
	Learning Rate: 0.00832255
	LOSS [training: 0.5430001864920453 | validation: 0.500113483912351]
	TIME [epoch: 6.97 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5193669267850757		[learning rate: 0.0082931]
	Learning Rate: 0.00829312
	LOSS [training: 0.5193669267850757 | validation: 0.4485290428507909]
	TIME [epoch: 6.96 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5694029282573324		[learning rate: 0.0082638]
	Learning Rate: 0.00826379
	LOSS [training: 0.5694029282573324 | validation: 0.39807623976007767]
	TIME [epoch: 6.96 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v8_20240715_180006/states/model_facs_v3_dec1b_2dpca_v8_104.pth
	Model improved!!!
EPOCH 105/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.445842958984722		[learning rate: 0.0082346]
	Learning Rate: 0.00823457
	LOSS [training: 0.445842958984722 | validation: 0.40234436796536316]
	TIME [epoch: 6.96 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.49009307213243286		[learning rate: 0.0082055]
	Learning Rate: 0.00820545
	LOSS [training: 0.49009307213243286 | validation: 0.3925689054368598]
	TIME [epoch: 6.95 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v8_20240715_180006/states/model_facs_v3_dec1b_2dpca_v8_106.pth
	Model improved!!!
EPOCH 107/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4594733432553708		[learning rate: 0.0081764]
	Learning Rate: 0.00817644
	LOSS [training: 0.4594733432553708 | validation: 0.5427214645774469]
	TIME [epoch: 6.97 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5344036730796181		[learning rate: 0.0081475]
	Learning Rate: 0.00814752
	LOSS [training: 0.5344036730796181 | validation: 0.4063659785311934]
	TIME [epoch: 6.96 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.46088201453066285		[learning rate: 0.0081187]
	Learning Rate: 0.00811871
	LOSS [training: 0.46088201453066285 | validation: 0.4243227272929902]
	TIME [epoch: 6.96 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.48678594705762085		[learning rate: 0.00809]
	Learning Rate: 0.00809
	LOSS [training: 0.48678594705762085 | validation: 0.40298148363864633]
	TIME [epoch: 6.96 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5259745554262869		[learning rate: 0.0080614]
	Learning Rate: 0.0080614
	LOSS [training: 0.5259745554262869 | validation: 0.45167874769449395]
	TIME [epoch: 6.96 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.45991147345111044		[learning rate: 0.0080329]
	Learning Rate: 0.00803289
	LOSS [training: 0.45991147345111044 | validation: 0.39448529163665713]
	TIME [epoch: 6.97 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.42988985890545184		[learning rate: 0.0080045]
	Learning Rate: 0.00800448
	LOSS [training: 0.42988985890545184 | validation: 0.42161435413481796]
	TIME [epoch: 6.96 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4436402721901875		[learning rate: 0.0079762]
	Learning Rate: 0.00797618
	LOSS [training: 0.4436402721901875 | validation: 0.4712879065955843]
	TIME [epoch: 6.96 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.49793274401146403		[learning rate: 0.007948]
	Learning Rate: 0.00794797
	LOSS [training: 0.49793274401146403 | validation: 0.4731184133094811]
	TIME [epoch: 6.96 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4574755787455635		[learning rate: 0.0079199]
	Learning Rate: 0.00791987
	LOSS [training: 0.4574755787455635 | validation: 0.39335958093669465]
	TIME [epoch: 6.96 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4844456660189227		[learning rate: 0.0078919]
	Learning Rate: 0.00789186
	LOSS [training: 0.4844456660189227 | validation: 0.412971899304889]
	TIME [epoch: 6.96 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.44219013048735567		[learning rate: 0.007864]
	Learning Rate: 0.00786395
	LOSS [training: 0.44219013048735567 | validation: 0.4121960078976075]
	TIME [epoch: 6.96 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.42345045121277664		[learning rate: 0.0078361]
	Learning Rate: 0.00783615
	LOSS [training: 0.42345045121277664 | validation: 0.40354969996894824]
	TIME [epoch: 6.95 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.48054584826127317		[learning rate: 0.0078084]
	Learning Rate: 0.00780844
	LOSS [training: 0.48054584826127317 | validation: 0.4090228283915168]
	TIME [epoch: 6.95 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4296959500122221		[learning rate: 0.0077808]
	Learning Rate: 0.00778083
	LOSS [training: 0.4296959500122221 | validation: 0.4328890229229917]
	TIME [epoch: 6.96 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.44676860438101257		[learning rate: 0.0077533]
	Learning Rate: 0.00775331
	LOSS [training: 0.44676860438101257 | validation: 0.39351877362743987]
	TIME [epoch: 6.97 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4480839249219894		[learning rate: 0.0077259]
	Learning Rate: 0.00772589
	LOSS [training: 0.4480839249219894 | validation: 0.3917947937822645]
	TIME [epoch: 6.96 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v8_20240715_180006/states/model_facs_v3_dec1b_2dpca_v8_123.pth
	Model improved!!!
EPOCH 124/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.41678448404451496		[learning rate: 0.0076986]
	Learning Rate: 0.00769857
	LOSS [training: 0.41678448404451496 | validation: 0.4269755572924576]
	TIME [epoch: 6.96 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.42670543262996463		[learning rate: 0.0076714]
	Learning Rate: 0.00767135
	LOSS [training: 0.42670543262996463 | validation: 0.44755398955825276]
	TIME [epoch: 6.95 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.45338620822050973		[learning rate: 0.0076442]
	Learning Rate: 0.00764422
	LOSS [training: 0.45338620822050973 | validation: 0.43557113527486757]
	TIME [epoch: 6.97 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.43284815840765906		[learning rate: 0.0076172]
	Learning Rate: 0.00761719
	LOSS [training: 0.43284815840765906 | validation: 0.3890766857254593]
	TIME [epoch: 6.96 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v8_20240715_180006/states/model_facs_v3_dec1b_2dpca_v8_127.pth
	Model improved!!!
EPOCH 128/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4185928947430413		[learning rate: 0.0075903]
	Learning Rate: 0.00759025
	LOSS [training: 0.4185928947430413 | validation: 0.5269523387211636]
	TIME [epoch: 6.95 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.7430538315517435		[learning rate: 0.0075634]
	Learning Rate: 0.00756341
	LOSS [training: 0.7430538315517435 | validation: 0.4498485093979149]
	TIME [epoch: 6.95 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5776697817066968		[learning rate: 0.0075367]
	Learning Rate: 0.00753667
	LOSS [training: 0.5776697817066968 | validation: 0.4580450199588075]
	TIME [epoch: 6.95 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5443250300130683		[learning rate: 0.00751]
	Learning Rate: 0.00751002
	LOSS [training: 0.5443250300130683 | validation: 0.47712163489626835]
	TIME [epoch: 6.95 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5406310216241687		[learning rate: 0.0074835]
	Learning Rate: 0.00748346
	LOSS [training: 0.5406310216241687 | validation: 0.39291800107730585]
	TIME [epoch: 6.95 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.48303308968987885		[learning rate: 0.007457]
	Learning Rate: 0.007457
	LOSS [training: 0.48303308968987885 | validation: 0.4475635261544597]
	TIME [epoch: 6.95 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4723965068115728		[learning rate: 0.0074306]
	Learning Rate: 0.00743063
	LOSS [training: 0.4723965068115728 | validation: 0.4373354502374407]
	TIME [epoch: 6.95 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4666096372520799		[learning rate: 0.0074044]
	Learning Rate: 0.00740435
	LOSS [training: 0.4666096372520799 | validation: 0.4264886074904384]
	TIME [epoch: 6.95 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4885682883095659		[learning rate: 0.0073782]
	Learning Rate: 0.00737817
	LOSS [training: 0.4885682883095659 | validation: 0.44031061558349693]
	TIME [epoch: 6.95 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4532487336590847		[learning rate: 0.0073521]
	Learning Rate: 0.00735208
	LOSS [training: 0.4532487336590847 | validation: 0.3773015856157965]
	TIME [epoch: 6.95 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v8_20240715_180006/states/model_facs_v3_dec1b_2dpca_v8_137.pth
	Model improved!!!
EPOCH 138/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.439248486273047		[learning rate: 0.0073261]
	Learning Rate: 0.00732608
	LOSS [training: 0.439248486273047 | validation: 0.49049319091675503]
	TIME [epoch: 6.95 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4804763425280447		[learning rate: 0.0073002]
	Learning Rate: 0.00730018
	LOSS [training: 0.4804763425280447 | validation: 0.3771421197329205]
	TIME [epoch: 6.95 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v8_20240715_180006/states/model_facs_v3_dec1b_2dpca_v8_139.pth
	Model improved!!!
EPOCH 140/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.46129793884112313		[learning rate: 0.0072744]
	Learning Rate: 0.00727436
	LOSS [training: 0.46129793884112313 | validation: 0.38448639514030836]
	TIME [epoch: 6.97 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.43136855070349167		[learning rate: 0.0072486]
	Learning Rate: 0.00724864
	LOSS [training: 0.43136855070349167 | validation: 0.3669549961263064]
	TIME [epoch: 6.97 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v8_20240715_180006/states/model_facs_v3_dec1b_2dpca_v8_141.pth
	Model improved!!!
EPOCH 142/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.45654775192211305		[learning rate: 0.007223]
	Learning Rate: 0.007223
	LOSS [training: 0.45654775192211305 | validation: 0.3623226947048471]
	TIME [epoch: 6.96 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v8_20240715_180006/states/model_facs_v3_dec1b_2dpca_v8_142.pth
	Model improved!!!
EPOCH 143/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4380539813115314		[learning rate: 0.0071975]
	Learning Rate: 0.00719746
	LOSS [training: 0.4380539813115314 | validation: 0.38832736705736004]
	TIME [epoch: 6.97 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.42809411013601917		[learning rate: 0.007172]
	Learning Rate: 0.00717201
	LOSS [training: 0.42809411013601917 | validation: 0.4895173766177404]
	TIME [epoch: 6.96 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4448121332980512		[learning rate: 0.0071467]
	Learning Rate: 0.00714665
	LOSS [training: 0.4448121332980512 | validation: 0.3746568910225494]
	TIME [epoch: 6.98 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.414573480352661		[learning rate: 0.0071214]
	Learning Rate: 0.00712138
	LOSS [training: 0.414573480352661 | validation: 0.3743742835180981]
	TIME [epoch: 6.96 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4369044118516657		[learning rate: 0.0070962]
	Learning Rate: 0.0070962
	LOSS [training: 0.4369044118516657 | validation: 0.3906258625062728]
	TIME [epoch: 6.95 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4247743508269369		[learning rate: 0.0070711]
	Learning Rate: 0.0070711
	LOSS [training: 0.4247743508269369 | validation: 0.432987434573608]
	TIME [epoch: 6.95 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.43831264258531233		[learning rate: 0.0070461]
	Learning Rate: 0.0070461
	LOSS [training: 0.43831264258531233 | validation: 0.3818845920705666]
	TIME [epoch: 6.96 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.405612915947371		[learning rate: 0.0070212]
	Learning Rate: 0.00702118
	LOSS [training: 0.405612915947371 | validation: 0.35913513223720994]
	TIME [epoch: 6.95 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v8_20240715_180006/states/model_facs_v3_dec1b_2dpca_v8_150.pth
	Model improved!!!
EPOCH 151/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.43003841175049073		[learning rate: 0.0069964]
	Learning Rate: 0.00699635
	LOSS [training: 0.43003841175049073 | validation: 0.4018182938797228]
	TIME [epoch: 6.98 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4288467645964462		[learning rate: 0.0069716]
	Learning Rate: 0.00697161
	LOSS [training: 0.4288467645964462 | validation: 0.39088710413688815]
	TIME [epoch: 6.95 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4076720994155165		[learning rate: 0.006947]
	Learning Rate: 0.00694696
	LOSS [training: 0.4076720994155165 | validation: 0.37945393727961135]
	TIME [epoch: 6.95 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5091912334044337		[learning rate: 0.0069224]
	Learning Rate: 0.00692239
	LOSS [training: 0.5091912334044337 | validation: 0.42625228450825414]
	TIME [epoch: 6.95 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4724946865055601		[learning rate: 0.0068979]
	Learning Rate: 0.00689792
	LOSS [training: 0.4724946865055601 | validation: 0.3617573772462032]
	TIME [epoch: 6.96 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4063188114080021		[learning rate: 0.0068735]
	Learning Rate: 0.00687352
	LOSS [training: 0.4063188114080021 | validation: 0.3570031108226418]
	TIME [epoch: 6.96 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v8_20240715_180006/states/model_facs_v3_dec1b_2dpca_v8_156.pth
	Model improved!!!
EPOCH 157/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3967762928919277		[learning rate: 0.0068492]
	Learning Rate: 0.00684922
	LOSS [training: 0.3967762928919277 | validation: 0.35794837583092426]
	TIME [epoch: 6.96 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.382227842728023		[learning rate: 0.006825]
	Learning Rate: 0.006825
	LOSS [training: 0.382227842728023 | validation: 0.34912823244019725]
	TIME [epoch: 6.96 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v8_20240715_180006/states/model_facs_v3_dec1b_2dpca_v8_158.pth
	Model improved!!!
EPOCH 159/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3739914216426985		[learning rate: 0.0068009]
	Learning Rate: 0.00680086
	LOSS [training: 0.3739914216426985 | validation: 0.3814912324967004]
	TIME [epoch: 6.96 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3943262017725448		[learning rate: 0.0067768]
	Learning Rate: 0.00677681
	LOSS [training: 0.3943262017725448 | validation: 0.3739111638980515]
	TIME [epoch: 6.97 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.39621312563312666		[learning rate: 0.0067529]
	Learning Rate: 0.00675285
	LOSS [training: 0.39621312563312666 | validation: 0.4613000097123889]
	TIME [epoch: 6.96 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.44576880035355826		[learning rate: 0.006729]
	Learning Rate: 0.00672897
	LOSS [training: 0.44576880035355826 | validation: 0.3647308583144232]
	TIME [epoch: 6.96 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.36632093268420446		[learning rate: 0.0067052]
	Learning Rate: 0.00670518
	LOSS [training: 0.36632093268420446 | validation: 0.3541649456493753]
	TIME [epoch: 6.95 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3646944683164887		[learning rate: 0.0066815]
	Learning Rate: 0.00668147
	LOSS [training: 0.3646944683164887 | validation: 0.37732381690587136]
	TIME [epoch: 6.96 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3757567554594738		[learning rate: 0.0066578]
	Learning Rate: 0.00665784
	LOSS [training: 0.3757567554594738 | validation: 0.35586646761377805]
	TIME [epoch: 6.97 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.358519927175051		[learning rate: 0.0066343]
	Learning Rate: 0.0066343
	LOSS [training: 0.358519927175051 | validation: 0.3421611491305208]
	TIME [epoch: 6.96 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v8_20240715_180006/states/model_facs_v3_dec1b_2dpca_v8_166.pth
	Model improved!!!
EPOCH 167/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.37694688744921145		[learning rate: 0.0066108]
	Learning Rate: 0.00661084
	LOSS [training: 0.37694688744921145 | validation: 0.40801806418067416]
	TIME [epoch: 6.97 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3891133706703796		[learning rate: 0.0065875]
	Learning Rate: 0.00658746
	LOSS [training: 0.3891133706703796 | validation: 0.3501980897404435]
	TIME [epoch: 6.97 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3679193138213961		[learning rate: 0.0065642]
	Learning Rate: 0.00656416
	LOSS [training: 0.3679193138213961 | validation: 0.34898303693538946]
	TIME [epoch: 6.97 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.40093922838496016		[learning rate: 0.006541]
	Learning Rate: 0.00654095
	LOSS [training: 0.40093922838496016 | validation: 0.3694667251753312]
	TIME [epoch: 6.97 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3738745254147575		[learning rate: 0.0065178]
	Learning Rate: 0.00651782
	LOSS [training: 0.3738745254147575 | validation: 0.33852789861248256]
	TIME [epoch: 6.96 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v8_20240715_180006/states/model_facs_v3_dec1b_2dpca_v8_171.pth
	Model improved!!!
EPOCH 172/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3772504355465573		[learning rate: 0.0064948]
	Learning Rate: 0.00649477
	LOSS [training: 0.3772504355465573 | validation: 0.3726527460650268]
	TIME [epoch: 6.96 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3763910318852206		[learning rate: 0.0064718]
	Learning Rate: 0.00647181
	LOSS [training: 0.3763910318852206 | validation: 0.3888936746572562]
	TIME [epoch: 6.96 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3668287717725598		[learning rate: 0.0064489]
	Learning Rate: 0.00644892
	LOSS [training: 0.3668287717725598 | validation: 0.3653921029780587]
	TIME [epoch: 6.96 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3647619847719923		[learning rate: 0.0064261]
	Learning Rate: 0.00642612
	LOSS [training: 0.3647619847719923 | validation: 0.3558719381378306]
	TIME [epoch: 6.97 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.359219201235955		[learning rate: 0.0064034]
	Learning Rate: 0.00640339
	LOSS [training: 0.359219201235955 | validation: 0.36617426326591607]
	TIME [epoch: 6.96 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.37758622395142716		[learning rate: 0.0063808]
	Learning Rate: 0.00638075
	LOSS [training: 0.37758622395142716 | validation: 0.3701277909234921]
	TIME [epoch: 6.97 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.381712261306151		[learning rate: 0.0063582]
	Learning Rate: 0.00635819
	LOSS [training: 0.381712261306151 | validation: 0.385035464999628]
	TIME [epoch: 6.96 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3793768583743748		[learning rate: 0.0063357]
	Learning Rate: 0.0063357
	LOSS [training: 0.3793768583743748 | validation: 0.3527969936088118]
	TIME [epoch: 6.96 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3698382040442614		[learning rate: 0.0063133]
	Learning Rate: 0.0063133
	LOSS [training: 0.3698382040442614 | validation: 0.3590498346065999]
	TIME [epoch: 6.97 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.35092561045846665		[learning rate: 0.006291]
	Learning Rate: 0.00629097
	LOSS [training: 0.35092561045846665 | validation: 0.37147306119252577]
	TIME [epoch: 6.97 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3791449210528848		[learning rate: 0.0062687]
	Learning Rate: 0.00626873
	LOSS [training: 0.3791449210528848 | validation: 0.37308924238423924]
	TIME [epoch: 6.96 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3606946767375085		[learning rate: 0.0062466]
	Learning Rate: 0.00624656
	LOSS [training: 0.3606946767375085 | validation: 0.3473566216205123]
	TIME [epoch: 6.96 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3697763260304953		[learning rate: 0.0062245]
	Learning Rate: 0.00622447
	LOSS [training: 0.3697763260304953 | validation: 0.3765316087796942]
	TIME [epoch: 6.96 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.36295622119023757		[learning rate: 0.0062025]
	Learning Rate: 0.00620246
	LOSS [training: 0.36295622119023757 | validation: 0.339483354140847]
	TIME [epoch: 6.97 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3586974187620637		[learning rate: 0.0061805]
	Learning Rate: 0.00618053
	LOSS [training: 0.3586974187620637 | validation: 0.3598249004601587]
	TIME [epoch: 6.97 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.38235511014632556		[learning rate: 0.0061587]
	Learning Rate: 0.00615867
	LOSS [training: 0.38235511014632556 | validation: 0.3754032197254482]
	TIME [epoch: 6.96 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3556523898354516		[learning rate: 0.0061369]
	Learning Rate: 0.00613689
	LOSS [training: 0.3556523898354516 | validation: 0.3402151498814673]
	TIME [epoch: 6.96 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.35811444790885294		[learning rate: 0.0061152]
	Learning Rate: 0.00611519
	LOSS [training: 0.35811444790885294 | validation: 0.35918813134382743]
	TIME [epoch: 6.97 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.362398301007036		[learning rate: 0.0060936]
	Learning Rate: 0.00609357
	LOSS [training: 0.362398301007036 | validation: 0.3571737566387583]
	TIME [epoch: 6.97 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3488199572126222		[learning rate: 0.006072]
	Learning Rate: 0.00607202
	LOSS [training: 0.3488199572126222 | validation: 0.3425730800505412]
	TIME [epoch: 6.96 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.34587685498125254		[learning rate: 0.0060505]
	Learning Rate: 0.00605055
	LOSS [training: 0.34587685498125254 | validation: 0.3353058713016193]
	TIME [epoch: 6.96 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v8_20240715_180006/states/model_facs_v3_dec1b_2dpca_v8_192.pth
	Model improved!!!
EPOCH 193/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.372632485106192		[learning rate: 0.0060292]
	Learning Rate: 0.00602915
	LOSS [training: 0.372632485106192 | validation: 0.33766744899296053]
	TIME [epoch: 6.96 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.356422218668865		[learning rate: 0.0060078]
	Learning Rate: 0.00600783
	LOSS [training: 0.356422218668865 | validation: 0.3513504033430324]
	TIME [epoch: 6.97 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.34323359651069213		[learning rate: 0.0059866]
	Learning Rate: 0.00598659
	LOSS [training: 0.34323359651069213 | validation: 0.3312736289259756]
	TIME [epoch: 6.96 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v8_20240715_180006/states/model_facs_v3_dec1b_2dpca_v8_195.pth
	Model improved!!!
EPOCH 196/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.35638657526194045		[learning rate: 0.0059654]
	Learning Rate: 0.00596542
	LOSS [training: 0.35638657526194045 | validation: 0.34971783512910337]
	TIME [epoch: 6.96 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3462697419655829		[learning rate: 0.0059443]
	Learning Rate: 0.00594433
	LOSS [training: 0.3462697419655829 | validation: 0.371256748354202]
	TIME [epoch: 6.96 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.37845218747535353		[learning rate: 0.0059233]
	Learning Rate: 0.0059233
	LOSS [training: 0.37845218747535353 | validation: 0.34087166136889907]
	TIME [epoch: 6.96 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.34404759014057557		[learning rate: 0.0059024]
	Learning Rate: 0.00590236
	LOSS [training: 0.34404759014057557 | validation: 0.3860940251525763]
	TIME [epoch: 6.97 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3563922816108456		[learning rate: 0.0058815]
	Learning Rate: 0.00588149
	LOSS [training: 0.3563922816108456 | validation: 0.34121383016638174]
	TIME [epoch: 6.96 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3544347648036125		[learning rate: 0.0058607]
	Learning Rate: 0.00586069
	LOSS [training: 0.3544347648036125 | validation: 0.34802884138845214]
	TIME [epoch: 6.98 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3475702454009999		[learning rate: 0.00584]
	Learning Rate: 0.00583996
	LOSS [training: 0.3475702454009999 | validation: 0.3529252708153593]
	TIME [epoch: 6.97 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.33868902942048923		[learning rate: 0.0058193]
	Learning Rate: 0.00581931
	LOSS [training: 0.33868902942048923 | validation: 0.3597508864367213]
	TIME [epoch: 6.95 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3736403471943857		[learning rate: 0.0057987]
	Learning Rate: 0.00579874
	LOSS [training: 0.3736403471943857 | validation: 0.352209429145746]
	TIME [epoch: 6.96 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.33705553299676483		[learning rate: 0.0057782]
	Learning Rate: 0.00577823
	LOSS [training: 0.33705553299676483 | validation: 0.34890904077165696]
	TIME [epoch: 6.96 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3459218720994733		[learning rate: 0.0057578]
	Learning Rate: 0.0057578
	LOSS [training: 0.3459218720994733 | validation: 0.37832143707096166]
	TIME [epoch: 6.96 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3798639277904267		[learning rate: 0.0057374]
	Learning Rate: 0.00573744
	LOSS [training: 0.3798639277904267 | validation: 0.3396851909176305]
	TIME [epoch: 6.96 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.354654426805026		[learning rate: 0.0057171]
	Learning Rate: 0.00571715
	LOSS [training: 0.354654426805026 | validation: 0.3361098268028611]
	TIME [epoch: 6.96 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.40196049460386646		[learning rate: 0.0056969]
	Learning Rate: 0.00569693
	LOSS [training: 0.40196049460386646 | validation: 0.38500139290839863]
	TIME [epoch: 6.96 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.35666934789441446		[learning rate: 0.0056768]
	Learning Rate: 0.00567679
	LOSS [training: 0.35666934789441446 | validation: 0.33372848461173843]
	TIME [epoch: 6.96 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3396755013665614		[learning rate: 0.0056567]
	Learning Rate: 0.00565671
	LOSS [training: 0.3396755013665614 | validation: 0.3374967077168053]
	TIME [epoch: 6.96 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3558973785011604		[learning rate: 0.0056367]
	Learning Rate: 0.00563671
	LOSS [training: 0.3558973785011604 | validation: 0.35498279722789494]
	TIME [epoch: 6.96 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.33912622526672775		[learning rate: 0.0056168]
	Learning Rate: 0.00561678
	LOSS [training: 0.33912622526672775 | validation: 0.398685930628611]
	TIME [epoch: 6.96 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3756330736995645		[learning rate: 0.0055969]
	Learning Rate: 0.00559691
	LOSS [training: 0.3756330736995645 | validation: 0.3460035922612924]
	TIME [epoch: 6.97 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.34519622969291514		[learning rate: 0.0055771]
	Learning Rate: 0.00557712
	LOSS [training: 0.34519622969291514 | validation: 0.3433215247994186]
	TIME [epoch: 6.96 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3435333484516549		[learning rate: 0.0055574]
	Learning Rate: 0.0055574
	LOSS [training: 0.3435333484516549 | validation: 0.3488785841204075]
	TIME [epoch: 6.96 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3379802310219606		[learning rate: 0.0055378]
	Learning Rate: 0.00553775
	LOSS [training: 0.3379802310219606 | validation: 0.33499980700157544]
	TIME [epoch: 6.95 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.37908733368731123		[learning rate: 0.0055182]
	Learning Rate: 0.00551817
	LOSS [training: 0.37908733368731123 | validation: 0.40565224669136546]
	TIME [epoch: 6.96 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.37953572462353935		[learning rate: 0.0054987]
	Learning Rate: 0.00549865
	LOSS [training: 0.37953572462353935 | validation: 0.35038000488492854]
	TIME [epoch: 6.96 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3472169788739919		[learning rate: 0.0054792]
	Learning Rate: 0.00547921
	LOSS [training: 0.3472169788739919 | validation: 0.36151067177263047]
	TIME [epoch: 6.96 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3348464672174802		[learning rate: 0.0054598]
	Learning Rate: 0.00545983
	LOSS [training: 0.3348464672174802 | validation: 0.33604159076574813]
	TIME [epoch: 6.96 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.348338728959098		[learning rate: 0.0054405]
	Learning Rate: 0.00544053
	LOSS [training: 0.348338728959098 | validation: 0.3258039694555676]
	TIME [epoch: 6.96 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v8_20240715_180006/states/model_facs_v3_dec1b_2dpca_v8_222.pth
	Model improved!!!
EPOCH 223/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.34441029673077056		[learning rate: 0.0054213]
	Learning Rate: 0.00542129
	LOSS [training: 0.34441029673077056 | validation: 0.3371246697135849]
	TIME [epoch: 6.96 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.38922391666623907		[learning rate: 0.0054021]
	Learning Rate: 0.00540212
	LOSS [training: 0.38922391666623907 | validation: 0.3582073857208586]
	TIME [epoch: 6.96 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.38697501055128836		[learning rate: 0.005383]
	Learning Rate: 0.00538302
	LOSS [training: 0.38697501055128836 | validation: 0.3424447062155547]
	TIME [epoch: 6.95 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.32780167459284293		[learning rate: 0.005364]
	Learning Rate: 0.00536398
	LOSS [training: 0.32780167459284293 | validation: 0.3151585342355673]
	TIME [epoch: 6.95 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v8_20240715_180006/states/model_facs_v3_dec1b_2dpca_v8_226.pth
	Model improved!!!
EPOCH 227/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.34948702737262444		[learning rate: 0.005345]
	Learning Rate: 0.00534501
	LOSS [training: 0.34948702737262444 | validation: 0.3358139370337951]
	TIME [epoch: 6.96 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3448819195036086		[learning rate: 0.0053261]
	Learning Rate: 0.00532611
	LOSS [training: 0.3448819195036086 | validation: 0.3198716990724983]
	TIME [epoch: 6.96 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3667562303228986		[learning rate: 0.0053073]
	Learning Rate: 0.00530728
	LOSS [training: 0.3667562303228986 | validation: 0.32717287233007303]
	TIME [epoch: 7.04 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3455250301277513		[learning rate: 0.0052885]
	Learning Rate: 0.00528851
	LOSS [training: 0.3455250301277513 | validation: 0.3406895059406225]
	TIME [epoch: 6.95 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3473876668513998		[learning rate: 0.0052698]
	Learning Rate: 0.00526981
	LOSS [training: 0.3473876668513998 | validation: 0.35931281403413307]
	TIME [epoch: 6.95 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3515061375708996		[learning rate: 0.0052512]
	Learning Rate: 0.00525117
	LOSS [training: 0.3515061375708996 | validation: 0.35045341423752163]
	TIME [epoch: 6.95 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3523251980079274		[learning rate: 0.0052326]
	Learning Rate: 0.0052326
	LOSS [training: 0.3523251980079274 | validation: 0.35101287437065615]
	TIME [epoch: 6.96 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3442440602795805		[learning rate: 0.0052141]
	Learning Rate: 0.0052141
	LOSS [training: 0.3442440602795805 | validation: 0.3302620582540321]
	TIME [epoch: 6.96 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.33969579140009487		[learning rate: 0.0051957]
	Learning Rate: 0.00519566
	LOSS [training: 0.33969579140009487 | validation: 0.36031607447257796]
	TIME [epoch: 6.96 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3399700374054693		[learning rate: 0.0051773]
	Learning Rate: 0.00517729
	LOSS [training: 0.3399700374054693 | validation: 0.3250259950746545]
	TIME [epoch: 6.95 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.35299722425400293		[learning rate: 0.005159]
	Learning Rate: 0.00515898
	LOSS [training: 0.35299722425400293 | validation: 0.33093051108565075]
	TIME [epoch: 6.96 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.347861268242565		[learning rate: 0.0051407]
	Learning Rate: 0.00514074
	LOSS [training: 0.347861268242565 | validation: 0.3271052350172019]
	TIME [epoch: 6.97 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3335311870025209		[learning rate: 0.0051226]
	Learning Rate: 0.00512256
	LOSS [training: 0.3335311870025209 | validation: 0.34259064719616517]
	TIME [epoch: 6.96 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3331367986175883		[learning rate: 0.0051044]
	Learning Rate: 0.00510445
	LOSS [training: 0.3331367986175883 | validation: 0.3267922490902115]
	TIME [epoch: 6.95 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.40303744146214865		[learning rate: 0.0050864]
	Learning Rate: 0.0050864
	LOSS [training: 0.40303744146214865 | validation: 0.3691429231061002]
	TIME [epoch: 6.96 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3610701167365466		[learning rate: 0.0050684]
	Learning Rate: 0.00506841
	LOSS [training: 0.3610701167365466 | validation: 0.3283207838666856]
	TIME [epoch: 6.96 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.32396088453168465		[learning rate: 0.0050505]
	Learning Rate: 0.00505049
	LOSS [training: 0.32396088453168465 | validation: 0.32504718027091706]
	TIME [epoch: 6.96 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3362064441334331		[learning rate: 0.0050326]
	Learning Rate: 0.00503263
	LOSS [training: 0.3362064441334331 | validation: 0.33526392005186667]
	TIME [epoch: 6.96 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3287447532115642		[learning rate: 0.0050148]
	Learning Rate: 0.00501483
	LOSS [training: 0.3287447532115642 | validation: 0.3575934754085731]
	TIME [epoch: 6.96 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3466808239313189		[learning rate: 0.0049971]
	Learning Rate: 0.0049971
	LOSS [training: 0.3466808239313189 | validation: 0.353631865445098]
	TIME [epoch: 6.96 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.33448524274957414		[learning rate: 0.0049794]
	Learning Rate: 0.00497943
	LOSS [training: 0.33448524274957414 | validation: 0.3368694659871084]
	TIME [epoch: 6.97 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3328293241150827		[learning rate: 0.0049618]
	Learning Rate: 0.00496182
	LOSS [training: 0.3328293241150827 | validation: 0.33543638798877445]
	TIME [epoch: 6.96 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.32467896530331913		[learning rate: 0.0049443]
	Learning Rate: 0.00494427
	LOSS [training: 0.32467896530331913 | validation: 0.3062431250669541]
	TIME [epoch: 6.96 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v8_20240715_180006/states/model_facs_v3_dec1b_2dpca_v8_249.pth
	Model improved!!!
EPOCH 250/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.33378492520629366		[learning rate: 0.0049268]
	Learning Rate: 0.00492679
	LOSS [training: 0.33378492520629366 | validation: 0.34268573523180135]
	TIME [epoch: 6.96 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.32276842840350556		[learning rate: 0.0049094]
	Learning Rate: 0.00490937
	LOSS [training: 0.32276842840350556 | validation: 0.33281500176854995]
	TIME [epoch: 6.96 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.33983062829234867		[learning rate: 0.004892]
	Learning Rate: 0.00489201
	LOSS [training: 0.33983062829234867 | validation: 0.3242168451203911]
	TIME [epoch: 6.96 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.32590833948681913		[learning rate: 0.0048747]
	Learning Rate: 0.00487471
	LOSS [training: 0.32590833948681913 | validation: 0.3308772498219481]
	TIME [epoch: 6.96 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.33062816111610466		[learning rate: 0.0048575]
	Learning Rate: 0.00485747
	LOSS [training: 0.33062816111610466 | validation: 0.3206219638130573]
	TIME [epoch: 6.96 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3241636720123759		[learning rate: 0.0048403]
	Learning Rate: 0.00484029
	LOSS [training: 0.3241636720123759 | validation: 0.3388774922234783]
	TIME [epoch: 6.96 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.34963638942501		[learning rate: 0.0048232]
	Learning Rate: 0.00482318
	LOSS [training: 0.34963638942501 | validation: 0.32295409301611927]
	TIME [epoch: 6.95 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.32104192089885353		[learning rate: 0.0048061]
	Learning Rate: 0.00480612
	LOSS [training: 0.32104192089885353 | validation: 0.325454080311229]
	TIME [epoch: 6.96 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3183800905018826		[learning rate: 0.0047891]
	Learning Rate: 0.00478913
	LOSS [training: 0.3183800905018826 | validation: 0.3210767040533188]
	TIME [epoch: 6.96 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.33033837813744277		[learning rate: 0.0047722]
	Learning Rate: 0.00477219
	LOSS [training: 0.33033837813744277 | validation: 0.34049772436063397]
	TIME [epoch: 6.95 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3806515965564055		[learning rate: 0.0047553]
	Learning Rate: 0.00475532
	LOSS [training: 0.3806515965564055 | validation: 0.33203519361066564]
	TIME [epoch: 6.95 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3223742517041268		[learning rate: 0.0047385]
	Learning Rate: 0.0047385
	LOSS [training: 0.3223742517041268 | validation: 0.3434485681091409]
	TIME [epoch: 6.96 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3233599703620165		[learning rate: 0.0047217]
	Learning Rate: 0.00472175
	LOSS [training: 0.3233599703620165 | validation: 0.31004264821445676]
	TIME [epoch: 6.96 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.33065057525026836		[learning rate: 0.004705]
	Learning Rate: 0.00470505
	LOSS [training: 0.33065057525026836 | validation: 0.31286057599824296]
	TIME [epoch: 6.96 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.32022973877795274		[learning rate: 0.0046884]
	Learning Rate: 0.00468841
	LOSS [training: 0.32022973877795274 | validation: 0.31182449872833923]
	TIME [epoch: 6.96 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.32734615352833174		[learning rate: 0.0046718]
	Learning Rate: 0.00467183
	LOSS [training: 0.32734615352833174 | validation: 0.32162056569608993]
	TIME [epoch: 6.95 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.32415343415309156		[learning rate: 0.0046553]
	Learning Rate: 0.00465531
	LOSS [training: 0.32415343415309156 | validation: 0.33710513777931506]
	TIME [epoch: 6.96 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3308280690835814		[learning rate: 0.0046388]
	Learning Rate: 0.00463885
	LOSS [training: 0.3308280690835814 | validation: 0.3182011419042549]
	TIME [epoch: 6.96 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3289153386167321		[learning rate: 0.0046224]
	Learning Rate: 0.00462245
	LOSS [training: 0.3289153386167321 | validation: 0.335729257981871]
	TIME [epoch: 6.96 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3331935912178477		[learning rate: 0.0046061]
	Learning Rate: 0.0046061
	LOSS [training: 0.3331935912178477 | validation: 0.31694072515821153]
	TIME [epoch: 6.96 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3217428937373464		[learning rate: 0.0045898]
	Learning Rate: 0.00458981
	LOSS [training: 0.3217428937373464 | validation: 0.3589196907153096]
	TIME [epoch: 6.95 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.32851272096733475		[learning rate: 0.0045736]
	Learning Rate: 0.00457358
	LOSS [training: 0.32851272096733475 | validation: 0.31098099589621075]
	TIME [epoch: 6.97 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.331306193425492		[learning rate: 0.0045574]
	Learning Rate: 0.00455741
	LOSS [training: 0.331306193425492 | validation: 0.3120127827702244]
	TIME [epoch: 6.96 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3236786051067782		[learning rate: 0.0045413]
	Learning Rate: 0.00454129
	LOSS [training: 0.3236786051067782 | validation: 0.31902817178539555]
	TIME [epoch: 6.96 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3246404434321108		[learning rate: 0.0045252]
	Learning Rate: 0.00452523
	LOSS [training: 0.3246404434321108 | validation: 0.3143637693414624]
	TIME [epoch: 6.96 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3239957139725705		[learning rate: 0.0045092]
	Learning Rate: 0.00450923
	LOSS [training: 0.3239957139725705 | validation: 0.3159383408152752]
	TIME [epoch: 6.96 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.31873158906704374		[learning rate: 0.0044933]
	Learning Rate: 0.00449329
	LOSS [training: 0.31873158906704374 | validation: 0.32795271694412076]
	TIME [epoch: 6.97 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.32361707040266696		[learning rate: 0.0044774]
	Learning Rate: 0.0044774
	LOSS [training: 0.32361707040266696 | validation: 0.31540756925256674]
	TIME [epoch: 6.96 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3376351619594516		[learning rate: 0.0044616]
	Learning Rate: 0.00446156
	LOSS [training: 0.3376351619594516 | validation: 0.306618955517229]
	TIME [epoch: 6.96 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3336271640903575		[learning rate: 0.0044458]
	Learning Rate: 0.00444579
	LOSS [training: 0.3336271640903575 | validation: 0.3227047520516769]
	TIME [epoch: 6.96 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.31724042653764634		[learning rate: 0.0044301]
	Learning Rate: 0.00443007
	LOSS [training: 0.31724042653764634 | validation: 0.3027082723076062]
	TIME [epoch: 6.97 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v8_20240715_180006/states/model_facs_v3_dec1b_2dpca_v8_280.pth
	Model improved!!!
EPOCH 281/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3070073881585547		[learning rate: 0.0044144]
	Learning Rate: 0.0044144
	LOSS [training: 0.3070073881585547 | validation: 0.33765870548794624]
	TIME [epoch: 6.97 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.34019562055692015		[learning rate: 0.0043988]
	Learning Rate: 0.00439879
	LOSS [training: 0.34019562055692015 | validation: 0.3154302531458072]
	TIME [epoch: 6.96 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3177485665365919		[learning rate: 0.0043832]
	Learning Rate: 0.00438324
	LOSS [training: 0.3177485665365919 | validation: 0.31704011218793293]
	TIME [epoch: 6.96 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3111375517919462		[learning rate: 0.0043677]
	Learning Rate: 0.00436774
	LOSS [training: 0.3111375517919462 | validation: 0.3076065371239297]
	TIME [epoch: 6.96 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3066147534768899		[learning rate: 0.0043523]
	Learning Rate: 0.00435229
	LOSS [training: 0.3066147534768899 | validation: 0.31276487190133073]
	TIME [epoch: 6.96 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.32228418609516335		[learning rate: 0.0043369]
	Learning Rate: 0.0043369
	LOSS [training: 0.32228418609516335 | validation: 0.3080155039074164]
	TIME [epoch: 7.05 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.32061823268773587		[learning rate: 0.0043216]
	Learning Rate: 0.00432156
	LOSS [training: 0.32061823268773587 | validation: 0.31725833553365224]
	TIME [epoch: 6.96 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.31902660093902147		[learning rate: 0.0043063]
	Learning Rate: 0.00430628
	LOSS [training: 0.31902660093902147 | validation: 0.3170276130789354]
	TIME [epoch: 6.96 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3497550645086573		[learning rate: 0.0042911]
	Learning Rate: 0.00429106
	LOSS [training: 0.3497550645086573 | validation: 0.349625192921103]
	TIME [epoch: 6.96 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3211217914146534		[learning rate: 0.0042759]
	Learning Rate: 0.00427588
	LOSS [training: 0.3211217914146534 | validation: 0.31311549937096844]
	TIME [epoch: 6.97 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.31060214751982		[learning rate: 0.0042608]
	Learning Rate: 0.00426076
	LOSS [training: 0.31060214751982 | validation: 0.311933448730185]
	TIME [epoch: 6.96 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3199580591554733		[learning rate: 0.0042457]
	Learning Rate: 0.00424569
	LOSS [training: 0.3199580591554733 | validation: 0.31030566049502784]
	TIME [epoch: 6.96 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.32222368684925		[learning rate: 0.0042307]
	Learning Rate: 0.00423068
	LOSS [training: 0.32222368684925 | validation: 0.3166159531870256]
	TIME [epoch: 6.96 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.312935058579666		[learning rate: 0.0042157]
	Learning Rate: 0.00421572
	LOSS [training: 0.312935058579666 | validation: 0.32343846310587193]
	TIME [epoch: 6.95 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.318612118140223		[learning rate: 0.0042008]
	Learning Rate: 0.00420081
	LOSS [training: 0.318612118140223 | validation: 0.33315064632703834]
	TIME [epoch: 6.97 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3152863089779202		[learning rate: 0.004186]
	Learning Rate: 0.00418596
	LOSS [training: 0.3152863089779202 | validation: 0.3108958698083693]
	TIME [epoch: 6.96 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.30924767328294855		[learning rate: 0.0041712]
	Learning Rate: 0.00417116
	LOSS [training: 0.30924767328294855 | validation: 0.3142111509506616]
	TIME [epoch: 6.96 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3224789670184815		[learning rate: 0.0041564]
	Learning Rate: 0.00415641
	LOSS [training: 0.3224789670184815 | validation: 0.315445247152491]
	TIME [epoch: 6.96 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.325344415332957		[learning rate: 0.0041417]
	Learning Rate: 0.00414171
	LOSS [training: 0.325344415332957 | validation: 0.31497684718207325]
	TIME [epoch: 6.96 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3267854654271122		[learning rate: 0.0041271]
	Learning Rate: 0.00412706
	LOSS [training: 0.3267854654271122 | validation: 0.3332172377911988]
	TIME [epoch: 6.97 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.31058974442347304		[learning rate: 0.0041125]
	Learning Rate: 0.00411247
	LOSS [training: 0.31058974442347304 | validation: 0.32426173823247717]
	TIME [epoch: 6.97 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3116456568837282		[learning rate: 0.0040979]
	Learning Rate: 0.00409793
	LOSS [training: 0.3116456568837282 | validation: 0.30627584195070884]
	TIME [epoch: 6.97 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3232866298842044		[learning rate: 0.0040834]
	Learning Rate: 0.00408344
	LOSS [training: 0.3232866298842044 | validation: 0.31114821039268314]
	TIME [epoch: 6.96 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.31101993853081455		[learning rate: 0.004069]
	Learning Rate: 0.004069
	LOSS [training: 0.31101993853081455 | validation: 0.3605018830564235]
	TIME [epoch: 6.97 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.325056502543514		[learning rate: 0.0040546]
	Learning Rate: 0.00405461
	LOSS [training: 0.325056502543514 | validation: 0.3158344151085257]
	TIME [epoch: 6.97 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.32231142648365085		[learning rate: 0.0040403]
	Learning Rate: 0.00404027
	LOSS [training: 0.32231142648365085 | validation: 0.32766101725712293]
	TIME [epoch: 6.97 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3255298201081795		[learning rate: 0.004026]
	Learning Rate: 0.00402598
	LOSS [training: 0.3255298201081795 | validation: 0.30367357431594616]
	TIME [epoch: 6.96 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.31259750803899744		[learning rate: 0.0040117]
	Learning Rate: 0.00401175
	LOSS [training: 0.31259750803899744 | validation: 0.3243931083432414]
	TIME [epoch: 6.97 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3324479634285726		[learning rate: 0.0039976]
	Learning Rate: 0.00399756
	LOSS [training: 0.3324479634285726 | validation: 0.34638855115225564]
	TIME [epoch: 6.97 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3205945996456822		[learning rate: 0.0039834]
	Learning Rate: 0.00398342
	LOSS [training: 0.3205945996456822 | validation: 0.3115559563574504]
	TIME [epoch: 6.97 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3152842649405906		[learning rate: 0.0039693]
	Learning Rate: 0.00396934
	LOSS [training: 0.3152842649405906 | validation: 0.30084621743578094]
	TIME [epoch: 6.96 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v8_20240715_180006/states/model_facs_v3_dec1b_2dpca_v8_311.pth
	Model improved!!!
EPOCH 312/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.31364497537890834		[learning rate: 0.0039553]
	Learning Rate: 0.0039553
	LOSS [training: 0.31364497537890834 | validation: 0.3052725231299667]
	TIME [epoch: 6.96 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3234451650226326		[learning rate: 0.0039413]
	Learning Rate: 0.00394131
	LOSS [training: 0.3234451650226326 | validation: 0.31467965120549235]
	TIME [epoch: 6.96 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.31688628798103763		[learning rate: 0.0039274]
	Learning Rate: 0.00392738
	LOSS [training: 0.31688628798103763 | validation: 0.32731177206957923]
	TIME [epoch: 6.97 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.32764634413607857		[learning rate: 0.0039135]
	Learning Rate: 0.00391349
	LOSS [training: 0.32764634413607857 | validation: 0.3176027686360783]
	TIME [epoch: 6.96 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.34142377349599745		[learning rate: 0.0038997]
	Learning Rate: 0.00389965
	LOSS [training: 0.34142377349599745 | validation: 0.34526582557939733]
	TIME [epoch: 6.96 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.33198833137239736		[learning rate: 0.0038859]
	Learning Rate: 0.00388586
	LOSS [training: 0.33198833137239736 | validation: 0.31115186087456853]
	TIME [epoch: 6.95 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3189341142240539		[learning rate: 0.0038721]
	Learning Rate: 0.00387212
	LOSS [training: 0.3189341142240539 | validation: 0.30811572828489575]
	TIME [epoch: 6.96 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3046051355970568		[learning rate: 0.0038584]
	Learning Rate: 0.00385843
	LOSS [training: 0.3046051355970568 | validation: 0.3255967916264373]
	TIME [epoch: 6.96 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.32850805967882946		[learning rate: 0.0038448]
	Learning Rate: 0.00384478
	LOSS [training: 0.32850805967882946 | validation: 0.30469929858107647]
	TIME [epoch: 6.96 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3070376754256397		[learning rate: 0.0038312]
	Learning Rate: 0.00383119
	LOSS [training: 0.3070376754256397 | validation: 0.3087782407366126]
	TIME [epoch: 6.96 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.31158001636787347		[learning rate: 0.0038176]
	Learning Rate: 0.00381764
	LOSS [training: 0.31158001636787347 | validation: 0.31653726791972936]
	TIME [epoch: 6.96 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3009300871282972		[learning rate: 0.0038041]
	Learning Rate: 0.00380414
	LOSS [training: 0.3009300871282972 | validation: 0.3084020501294014]
	TIME [epoch: 6.96 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3332059187322663		[learning rate: 0.0037907]
	Learning Rate: 0.00379069
	LOSS [training: 0.3332059187322663 | validation: 0.30481201933218965]
	TIME [epoch: 6.97 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.30716125637382513		[learning rate: 0.0037773]
	Learning Rate: 0.00377728
	LOSS [training: 0.30716125637382513 | validation: 0.3035422985018452]
	TIME [epoch: 6.99 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3097449630708526		[learning rate: 0.0037639]
	Learning Rate: 0.00376393
	LOSS [training: 0.3097449630708526 | validation: 0.3149430818643035]
	TIME [epoch: 6.96 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3042750933265337		[learning rate: 0.0037506]
	Learning Rate: 0.00375062
	LOSS [training: 0.3042750933265337 | validation: 0.30921302477960105]
	TIME [epoch: 6.96 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4871291692324707		[learning rate: 0.0037374]
	Learning Rate: 0.00373735
	LOSS [training: 0.4871291692324707 | validation: 0.31614534854537885]
	TIME [epoch: 6.96 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3318594445356087		[learning rate: 0.0037241]
	Learning Rate: 0.00372414
	LOSS [training: 0.3318594445356087 | validation: 0.3091128204512832]
	TIME [epoch: 6.96 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3255477647303869		[learning rate: 0.003711]
	Learning Rate: 0.00371097
	LOSS [training: 0.3255477647303869 | validation: 0.3040103812848608]
	TIME [epoch: 6.97 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.31510416905101946		[learning rate: 0.0036978]
	Learning Rate: 0.00369785
	LOSS [training: 0.31510416905101946 | validation: 0.3224190340768332]
	TIME [epoch: 6.96 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3121574374539573		[learning rate: 0.0036848]
	Learning Rate: 0.00368477
	LOSS [training: 0.3121574374539573 | validation: 0.2979941315311231]
	TIME [epoch: 6.96 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v8_20240715_180006/states/model_facs_v3_dec1b_2dpca_v8_332.pth
	Model improved!!!
EPOCH 333/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3114234664314896		[learning rate: 0.0036717]
	Learning Rate: 0.00367174
	LOSS [training: 0.3114234664314896 | validation: 0.3041995670522032]
	TIME [epoch: 6.96 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3066765713144795		[learning rate: 0.0036588]
	Learning Rate: 0.00365875
	LOSS [training: 0.3066765713144795 | validation: 0.2968221522632855]
	TIME [epoch: 6.96 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v8_20240715_180006/states/model_facs_v3_dec1b_2dpca_v8_334.pth
	Model improved!!!
EPOCH 335/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2992007602556671		[learning rate: 0.0036458]
	Learning Rate: 0.00364582
	LOSS [training: 0.2992007602556671 | validation: 0.29600610709167746]
	TIME [epoch: 6.97 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v8_20240715_180006/states/model_facs_v3_dec1b_2dpca_v8_335.pth
	Model improved!!!
EPOCH 336/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3101616987752785		[learning rate: 0.0036329]
	Learning Rate: 0.00363292
	LOSS [training: 0.3101616987752785 | validation: 0.3111415193259767]
	TIME [epoch: 6.96 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.30612085486933377		[learning rate: 0.0036201]
	Learning Rate: 0.00362008
	LOSS [training: 0.30612085486933377 | validation: 0.31221568384306786]
	TIME [epoch: 6.96 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3924306759166276		[learning rate: 0.0036073]
	Learning Rate: 0.00360728
	LOSS [training: 0.3924306759166276 | validation: 0.39181127670926935]
	TIME [epoch: 6.96 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.32771419676572994		[learning rate: 0.0035945]
	Learning Rate: 0.00359452
	LOSS [training: 0.32771419676572994 | validation: 0.31414823997041086]
	TIME [epoch: 6.96 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2995929864060545		[learning rate: 0.0035818]
	Learning Rate: 0.00358181
	LOSS [training: 0.2995929864060545 | validation: 0.3028509096714682]
	TIME [epoch: 6.97 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3077444256035222		[learning rate: 0.0035691]
	Learning Rate: 0.00356914
	LOSS [training: 0.3077444256035222 | validation: 0.29846507570443215]
	TIME [epoch: 6.96 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29754722730477995		[learning rate: 0.0035565]
	Learning Rate: 0.00355652
	LOSS [training: 0.29754722730477995 | validation: 0.2996126629195632]
	TIME [epoch: 6.96 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3084549152982437		[learning rate: 0.0035439]
	Learning Rate: 0.00354395
	LOSS [training: 0.3084549152982437 | validation: 0.318399723833472]
	TIME [epoch: 6.96 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.31590032548898583		[learning rate: 0.0035314]
	Learning Rate: 0.00353141
	LOSS [training: 0.31590032548898583 | validation: 0.2988763295220293]
	TIME [epoch: 6.96 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3130564282028174		[learning rate: 0.0035189]
	Learning Rate: 0.00351893
	LOSS [training: 0.3130564282028174 | validation: 0.3103570692141455]
	TIME [epoch: 6.96 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.30580427983029534		[learning rate: 0.0035065]
	Learning Rate: 0.00350648
	LOSS [training: 0.30580427983029534 | validation: 0.3002086228559703]
	TIME [epoch: 6.96 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3074033017544238		[learning rate: 0.0034941]
	Learning Rate: 0.00349408
	LOSS [training: 0.3074033017544238 | validation: 0.33470204321013686]
	TIME [epoch: 6.96 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2997999382323187		[learning rate: 0.0034817]
	Learning Rate: 0.00348173
	LOSS [training: 0.2997999382323187 | validation: 0.3017632416964246]
	TIME [epoch: 6.96 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3010792401878271		[learning rate: 0.0034694]
	Learning Rate: 0.00346942
	LOSS [training: 0.3010792401878271 | validation: 0.30048009872577675]
	TIME [epoch: 6.96 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3072084709584386		[learning rate: 0.0034571]
	Learning Rate: 0.00345715
	LOSS [training: 0.3072084709584386 | validation: 0.3214019374125835]
	TIME [epoch: 6.97 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.36298233787504636		[learning rate: 0.0034449]
	Learning Rate: 0.00344492
	LOSS [training: 0.36298233787504636 | validation: 0.35875558643718364]
	TIME [epoch: 6.96 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.35885345399877805		[learning rate: 0.0034327]
	Learning Rate: 0.00343274
	LOSS [training: 0.35885345399877805 | validation: 0.3401845302137279]
	TIME [epoch: 6.98 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.35949715361035683		[learning rate: 0.0034206]
	Learning Rate: 0.0034206
	LOSS [training: 0.35949715361035683 | validation: 0.4720784488260337]
	TIME [epoch: 6.96 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.42607129577440617		[learning rate: 0.0034085]
	Learning Rate: 0.00340851
	LOSS [training: 0.42607129577440617 | validation: 0.3874276045557134]
	TIME [epoch: 6.95 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3478004605358838		[learning rate: 0.0033965]
	Learning Rate: 0.00339645
	LOSS [training: 0.3478004605358838 | validation: 0.35574192722278164]
	TIME [epoch: 6.96 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3392409935951442		[learning rate: 0.0033844]
	Learning Rate: 0.00338444
	LOSS [training: 0.3392409935951442 | validation: 0.3566130775800869]
	TIME [epoch: 6.96 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3360616949369668		[learning rate: 0.0033725]
	Learning Rate: 0.00337247
	LOSS [training: 0.3360616949369668 | validation: 0.34589579807197424]
	TIME [epoch: 6.96 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.33983259618186107		[learning rate: 0.0033605]
	Learning Rate: 0.00336055
	LOSS [training: 0.33983259618186107 | validation: 0.3497463593875435]
	TIME [epoch: 6.96 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.33104871411588815		[learning rate: 0.0033487]
	Learning Rate: 0.00334867
	LOSS [training: 0.33104871411588815 | validation: 0.3446078588312266]
	TIME [epoch: 6.95 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.331683433470177		[learning rate: 0.0033368]
	Learning Rate: 0.00333682
	LOSS [training: 0.331683433470177 | validation: 0.33404020237656734]
	TIME [epoch: 6.96 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3344954724862914		[learning rate: 0.003325]
	Learning Rate: 0.00332502
	LOSS [training: 0.3344954724862914 | validation: 0.33540496768895]
	TIME [epoch: 6.96 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3346497803305472		[learning rate: 0.0033133]
	Learning Rate: 0.00331327
	LOSS [training: 0.3346497803305472 | validation: 0.3320633619579791]
	TIME [epoch: 6.96 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3346317177289724		[learning rate: 0.0033016]
	Learning Rate: 0.00330155
	LOSS [training: 0.3346317177289724 | validation: 0.3313104534025014]
	TIME [epoch: 6.95 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3294313959185113		[learning rate: 0.0032899]
	Learning Rate: 0.00328988
	LOSS [training: 0.3294313959185113 | validation: 0.3313442527136458]
	TIME [epoch: 6.96 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3394018161944477		[learning rate: 0.0032782]
	Learning Rate: 0.00327824
	LOSS [training: 0.3394018161944477 | validation: 0.3269441613604338]
	TIME [epoch: 6.97 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3415715439864015		[learning rate: 0.0032666]
	Learning Rate: 0.00326665
	LOSS [training: 0.3415715439864015 | validation: 0.3638875041946298]
	TIME [epoch: 6.96 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3389377189195568		[learning rate: 0.0032551]
	Learning Rate: 0.0032551
	LOSS [training: 0.3389377189195568 | validation: 0.3260945279962747]
	TIME [epoch: 6.96 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.33066376404118086		[learning rate: 0.0032436]
	Learning Rate: 0.00324359
	LOSS [training: 0.33066376404118086 | validation: 0.3387210220848173]
	TIME [epoch: 6.96 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3308468753822022		[learning rate: 0.0032321]
	Learning Rate: 0.00323212
	LOSS [training: 0.3308468753822022 | validation: 0.337044854419076]
	TIME [epoch: 6.96 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.32103499596375323		[learning rate: 0.0032207]
	Learning Rate: 0.00322069
	LOSS [training: 0.32103499596375323 | validation: 0.33574039608931466]
	TIME [epoch: 6.97 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3268770958900298		[learning rate: 0.0032093]
	Learning Rate: 0.0032093
	LOSS [training: 0.3268770958900298 | validation: 0.32931164487568165]
	TIME [epoch: 6.96 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.33280567377708264		[learning rate: 0.003198]
	Learning Rate: 0.00319795
	LOSS [training: 0.33280567377708264 | validation: 0.33775619283062325]
	TIME [epoch: 6.96 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.32189286045573445		[learning rate: 0.0031866]
	Learning Rate: 0.00318664
	LOSS [training: 0.32189286045573445 | validation: 0.32092150595765456]
	TIME [epoch: 6.96 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3227526801447715		[learning rate: 0.0031754]
	Learning Rate: 0.00317537
	LOSS [training: 0.3227526801447715 | validation: 0.3382008726100457]
	TIME [epoch: 6.96 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.31881555426232194		[learning rate: 0.0031641]
	Learning Rate: 0.00316415
	LOSS [training: 0.31881555426232194 | validation: 0.3282888715705599]
	TIME [epoch: 6.97 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.32761326360351756		[learning rate: 0.003153]
	Learning Rate: 0.00315296
	LOSS [training: 0.32761326360351756 | validation: 0.3396747710798593]
	TIME [epoch: 6.97 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3240116131433231		[learning rate: 0.0031418]
	Learning Rate: 0.00314181
	LOSS [training: 0.3240116131433231 | validation: 0.3218836545783845]
	TIME [epoch: 6.96 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3096683960890296		[learning rate: 0.0031307]
	Learning Rate: 0.0031307
	LOSS [training: 0.3096683960890296 | validation: 0.32825636129072994]
	TIME [epoch: 6.96 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3398125364410833		[learning rate: 0.0031196]
	Learning Rate: 0.00311963
	LOSS [training: 0.3398125364410833 | validation: 0.3226752158264236]
	TIME [epoch: 6.95 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3160349929303088		[learning rate: 0.0031086]
	Learning Rate: 0.00310859
	LOSS [training: 0.3160349929303088 | validation: 0.33148126451712256]
	TIME [epoch: 6.96 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3178685615052501		[learning rate: 0.0030976]
	Learning Rate: 0.0030976
	LOSS [training: 0.3178685615052501 | validation: 0.32308883644753306]
	TIME [epoch: 6.96 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.31772592345109973		[learning rate: 0.0030866]
	Learning Rate: 0.00308665
	LOSS [training: 0.31772592345109973 | validation: 0.33494410930412416]
	TIME [epoch: 6.96 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.34201426657659567		[learning rate: 0.0030757]
	Learning Rate: 0.00307573
	LOSS [training: 0.34201426657659567 | validation: 0.4676125843656367]
	TIME [epoch: 6.96 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.42230691934599446		[learning rate: 0.0030649]
	Learning Rate: 0.00306486
	LOSS [training: 0.42230691934599446 | validation: 0.3574976732858908]
	TIME [epoch: 6.96 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.33643068058326925		[learning rate: 0.003054]
	Learning Rate: 0.00305402
	LOSS [training: 0.33643068058326925 | validation: 0.3423594785217032]
	TIME [epoch: 6.96 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.32551344733961235		[learning rate: 0.0030432]
	Learning Rate: 0.00304322
	LOSS [training: 0.32551344733961235 | validation: 0.33286432033439295]
	TIME [epoch: 6.96 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.33810337356347175		[learning rate: 0.0030325]
	Learning Rate: 0.00303246
	LOSS [training: 0.33810337356347175 | validation: 0.32484883087517635]
	TIME [epoch: 6.96 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.32229133490949263		[learning rate: 0.0030217]
	Learning Rate: 0.00302174
	LOSS [training: 0.32229133490949263 | validation: 0.33438662777865485]
	TIME [epoch: 6.95 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.322037634765739		[learning rate: 0.003011]
	Learning Rate: 0.00301105
	LOSS [training: 0.322037634765739 | validation: 0.33533278743516604]
	TIME [epoch: 6.96 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3193140910574295		[learning rate: 0.0030004]
	Learning Rate: 0.0030004
	LOSS [training: 0.3193140910574295 | validation: 0.32266476123667964]
	TIME [epoch: 6.96 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.32340559465577173		[learning rate: 0.0029898]
	Learning Rate: 0.00298979
	LOSS [training: 0.32340559465577173 | validation: 0.3287818085126911]
	TIME [epoch: 6.97 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3147084352395639		[learning rate: 0.0029792]
	Learning Rate: 0.00297922
	LOSS [training: 0.3147084352395639 | validation: 0.3155222062820033]
	TIME [epoch: 6.96 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.329038818557083		[learning rate: 0.0029687]
	Learning Rate: 0.00296869
	LOSS [training: 0.329038818557083 | validation: 0.33078170474875257]
	TIME [epoch: 6.96 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3040177511831582		[learning rate: 0.0029582]
	Learning Rate: 0.00295819
	LOSS [training: 0.3040177511831582 | validation: 0.3039060272126404]
	TIME [epoch: 6.96 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.30179225713098723		[learning rate: 0.0029477]
	Learning Rate: 0.00294773
	LOSS [training: 0.30179225713098723 | validation: 0.30821107382494867]
	TIME [epoch: 6.96 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.35900201768918394		[learning rate: 0.0029373]
	Learning Rate: 0.0029373
	LOSS [training: 0.35900201768918394 | validation: 0.3858800444775814]
	TIME [epoch: 6.96 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3315004085891016		[learning rate: 0.0029269]
	Learning Rate: 0.00292692
	LOSS [training: 0.3315004085891016 | validation: 0.3316797406130849]
	TIME [epoch: 6.96 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.32056457852592496		[learning rate: 0.0029166]
	Learning Rate: 0.00291657
	LOSS [training: 0.32056457852592496 | validation: 0.32705535311050155]
	TIME [epoch: 6.95 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.31367434242800146		[learning rate: 0.0029063]
	Learning Rate: 0.00290625
	LOSS [training: 0.31367434242800146 | validation: 0.33826733786493285]
	TIME [epoch: 6.95 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.32985405930818834		[learning rate: 0.002896]
	Learning Rate: 0.00289598
	LOSS [training: 0.32985405930818834 | validation: 0.3190343957885604]
	TIME [epoch: 6.96 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3174116369581522		[learning rate: 0.0028857]
	Learning Rate: 0.00288573
	LOSS [training: 0.3174116369581522 | validation: 0.3240010071594657]
	TIME [epoch: 6.97 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3175264482468828		[learning rate: 0.0028755]
	Learning Rate: 0.00287553
	LOSS [training: 0.3175264482468828 | validation: 0.3183553086699992]
	TIME [epoch: 6.96 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3231563495463633		[learning rate: 0.0028654]
	Learning Rate: 0.00286536
	LOSS [training: 0.3231563495463633 | validation: 0.32002204641306353]
	TIME [epoch: 6.96 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3216819978014355		[learning rate: 0.0028552]
	Learning Rate: 0.00285523
	LOSS [training: 0.3216819978014355 | validation: 0.32342715551638473]
	TIME [epoch: 6.96 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3300689908501628		[learning rate: 0.0028451]
	Learning Rate: 0.00284513
	LOSS [training: 0.3300689908501628 | validation: 0.31786071813952965]
	TIME [epoch: 6.96 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.313196706105689		[learning rate: 0.0028351]
	Learning Rate: 0.00283507
	LOSS [training: 0.313196706105689 | validation: 0.3132150463937526]
	TIME [epoch: 6.96 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3055214256368454		[learning rate: 0.002825]
	Learning Rate: 0.00282505
	LOSS [training: 0.3055214256368454 | validation: 0.3140608791292883]
	TIME [epoch: 6.96 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3074942835806495		[learning rate: 0.0028151]
	Learning Rate: 0.00281506
	LOSS [training: 0.3074942835806495 | validation: 0.30804631017376344]
	TIME [epoch: 6.96 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.31847771996125646		[learning rate: 0.0028051]
	Learning Rate: 0.0028051
	LOSS [training: 0.31847771996125646 | validation: 0.3487327261750214]
	TIME [epoch: 6.96 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3239701359817793		[learning rate: 0.0027952]
	Learning Rate: 0.00279518
	LOSS [training: 0.3239701359817793 | validation: 0.32962689373969156]
	TIME [epoch: 6.96 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.33118630517058356		[learning rate: 0.0027853]
	Learning Rate: 0.0027853
	LOSS [training: 0.33118630517058356 | validation: 0.3072966635311201]
	TIME [epoch: 6.96 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3010406225028035		[learning rate: 0.0027754]
	Learning Rate: 0.00277545
	LOSS [training: 0.3010406225028035 | validation: 0.313751995881289]
	TIME [epoch: 6.96 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29744267812874575		[learning rate: 0.0027656]
	Learning Rate: 0.00276564
	LOSS [training: 0.29744267812874575 | validation: 0.31983735219967185]
	TIME [epoch: 6.96 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.30609190279125414		[learning rate: 0.0027559]
	Learning Rate: 0.00275586
	LOSS [training: 0.30609190279125414 | validation: 0.2971638794855206]
	TIME [epoch: 6.96 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.31182043015244876		[learning rate: 0.0027461]
	Learning Rate: 0.00274611
	LOSS [training: 0.31182043015244876 | validation: 0.30903646833227505]
	TIME [epoch: 6.96 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29912555974830296		[learning rate: 0.0027364]
	Learning Rate: 0.0027364
	LOSS [training: 0.29912555974830296 | validation: 0.3135716781698196]
	TIME [epoch: 6.96 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.307622877931487		[learning rate: 0.0027267]
	Learning Rate: 0.00272672
	LOSS [training: 0.307622877931487 | validation: 0.3078979008503303]
	TIME [epoch: 6.96 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3039318212928948		[learning rate: 0.0027171]
	Learning Rate: 0.00271708
	LOSS [training: 0.3039318212928948 | validation: 0.29940033021184975]
	TIME [epoch: 6.96 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.30381406478309264		[learning rate: 0.0027075]
	Learning Rate: 0.00270747
	LOSS [training: 0.30381406478309264 | validation: 0.3457254245033243]
	TIME [epoch: 6.96 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.32812426322176846		[learning rate: 0.0026979]
	Learning Rate: 0.0026979
	LOSS [training: 0.32812426322176846 | validation: 0.3043505632039946]
	TIME [epoch: 6.96 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3003256511116414		[learning rate: 0.0026884]
	Learning Rate: 0.00268836
	LOSS [training: 0.3003256511116414 | validation: 0.2942340270839211]
	TIME [epoch: 6.96 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v8_20240715_180006/states/model_facs_v3_dec1b_2dpca_v8_421.pth
	Model improved!!!
EPOCH 422/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29710741935279483		[learning rate: 0.0026789]
	Learning Rate: 0.00267885
	LOSS [training: 0.29710741935279483 | validation: 0.3103190212137007]
	TIME [epoch: 6.97 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3021790184754811		[learning rate: 0.0026694]
	Learning Rate: 0.00266938
	LOSS [training: 0.3021790184754811 | validation: 0.29603734529526304]
	TIME [epoch: 6.96 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2927204854802999		[learning rate: 0.0026599]
	Learning Rate: 0.00265994
	LOSS [training: 0.2927204854802999 | validation: 0.3028798052759788]
	TIME [epoch: 6.96 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29187515925262775		[learning rate: 0.0026505]
	Learning Rate: 0.00265053
	LOSS [training: 0.29187515925262775 | validation: 0.2939702903717355]
	TIME [epoch: 6.96 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v8_20240715_180006/states/model_facs_v3_dec1b_2dpca_v8_425.pth
	Model improved!!!
EPOCH 426/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3559084597349786		[learning rate: 0.0026412]
	Learning Rate: 0.00264116
	LOSS [training: 0.3559084597349786 | validation: 0.3363716690517594]
	TIME [epoch: 6.97 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.35119238417149545		[learning rate: 0.0026318]
	Learning Rate: 0.00263182
	LOSS [training: 0.35119238417149545 | validation: 0.31645910542962286]
	TIME [epoch: 6.97 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3090509819452555		[learning rate: 0.0026225]
	Learning Rate: 0.00262251
	LOSS [training: 0.3090509819452555 | validation: 0.30793213997751356]
	TIME [epoch: 6.96 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.30189123900735254		[learning rate: 0.0026132]
	Learning Rate: 0.00261324
	LOSS [training: 0.30189123900735254 | validation: 0.30420966908257946]
	TIME [epoch: 6.96 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.301813655038126		[learning rate: 0.002604]
	Learning Rate: 0.002604
	LOSS [training: 0.301813655038126 | validation: 0.30176029321068454]
	TIME [epoch: 6.96 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.30145536400047385		[learning rate: 0.0025948]
	Learning Rate: 0.00259479
	LOSS [training: 0.30145536400047385 | validation: 0.30584207721636403]
	TIME [epoch: 6.96 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2924526935657672		[learning rate: 0.0025856]
	Learning Rate: 0.00258562
	LOSS [training: 0.2924526935657672 | validation: 0.2984378183257085]
	TIME [epoch: 6.97 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.30169614162276764		[learning rate: 0.0025765]
	Learning Rate: 0.00257647
	LOSS [training: 0.30169614162276764 | validation: 0.30250427482993103]
	TIME [epoch: 6.96 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2949222580314207		[learning rate: 0.0025674]
	Learning Rate: 0.00256736
	LOSS [training: 0.2949222580314207 | validation: 0.2989635718884574]
	TIME [epoch: 6.97 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3052005798623782		[learning rate: 0.0025583]
	Learning Rate: 0.00255828
	LOSS [training: 0.3052005798623782 | validation: 0.3073217532740352]
	TIME [epoch: 6.96 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.31348145576810554		[learning rate: 0.0025492]
	Learning Rate: 0.00254924
	LOSS [training: 0.31348145576810554 | validation: 0.2954941823104291]
	TIME [epoch: 6.96 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.31007561212073903		[learning rate: 0.0025402]
	Learning Rate: 0.00254022
	LOSS [training: 0.31007561212073903 | validation: 0.2955838150465972]
	TIME [epoch: 6.97 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.30413069995937214		[learning rate: 0.0025312]
	Learning Rate: 0.00253124
	LOSS [training: 0.30413069995937214 | validation: 0.39657530154780646]
	TIME [epoch: 6.96 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3908725260019768		[learning rate: 0.0025223]
	Learning Rate: 0.00252229
	LOSS [training: 0.3908725260019768 | validation: 0.35181987144066634]
	TIME [epoch: 6.96 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3211271806347442		[learning rate: 0.0025134]
	Learning Rate: 0.00251337
	LOSS [training: 0.3211271806347442 | validation: 0.34060608842740053]
	TIME [epoch: 6.96 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3159950435555593		[learning rate: 0.0025045]
	Learning Rate: 0.00250448
	LOSS [training: 0.3159950435555593 | validation: 0.3259374061606823]
	TIME [epoch: 6.96 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3128897439743164		[learning rate: 0.0024956]
	Learning Rate: 0.00249563
	LOSS [training: 0.3128897439743164 | validation: 0.32633272606913355]
	TIME [epoch: 6.97 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.34304480459795744		[learning rate: 0.0024868]
	Learning Rate: 0.0024868
	LOSS [training: 0.34304480459795744 | validation: 0.3311821962456294]
	TIME [epoch: 6.97 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.324747542245872		[learning rate: 0.002478]
	Learning Rate: 0.00247801
	LOSS [training: 0.324747542245872 | validation: 0.3148195043612237]
	TIME [epoch: 6.96 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.32332959723589616		[learning rate: 0.0024692]
	Learning Rate: 0.00246924
	LOSS [training: 0.32332959723589616 | validation: 0.31772633466417416]
	TIME [epoch: 6.96 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.32417960484043645		[learning rate: 0.0024605]
	Learning Rate: 0.00246051
	LOSS [training: 0.32417960484043645 | validation: 0.3164173364861801]
	TIME [epoch: 6.96 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.32501992869405555		[learning rate: 0.0024518]
	Learning Rate: 0.00245181
	LOSS [training: 0.32501992869405555 | validation: 0.31064338570485883]
	TIME [epoch: 6.97 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3345363837869739		[learning rate: 0.0024431]
	Learning Rate: 0.00244314
	LOSS [training: 0.3345363837869739 | validation: 0.3143994449496095]
	TIME [epoch: 6.96 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.31455981899581925		[learning rate: 0.0024345]
	Learning Rate: 0.0024345
	LOSS [training: 0.31455981899581925 | validation: 0.30888303871211653]
	TIME [epoch: 6.96 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3090861597547163		[learning rate: 0.0024259]
	Learning Rate: 0.00242589
	LOSS [training: 0.3090861597547163 | validation: 0.3125065207194316]
	TIME [epoch: 6.96 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3115101010459816		[learning rate: 0.0024173]
	Learning Rate: 0.00241732
	LOSS [training: 0.3115101010459816 | validation: 0.3170091539078223]
	TIME [epoch: 6.96 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.30571999705392		[learning rate: 0.0024088]
	Learning Rate: 0.00240877
	LOSS [training: 0.30571999705392 | validation: 0.3185535122436082]
	TIME [epoch: 6.97 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.31172166312124205		[learning rate: 0.0024002]
	Learning Rate: 0.00240025
	LOSS [training: 0.31172166312124205 | validation: 0.3167355443634424]
	TIME [epoch: 6.96 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.31254953251920875		[learning rate: 0.0023918]
	Learning Rate: 0.00239176
	LOSS [training: 0.31254953251920875 | validation: 0.3322604961272039]
	TIME [epoch: 6.96 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.312756238412286		[learning rate: 0.0023833]
	Learning Rate: 0.0023833
	LOSS [training: 0.312756238412286 | validation: 0.32104384922372686]
	TIME [epoch: 6.96 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3030826160451719		[learning rate: 0.0023749]
	Learning Rate: 0.00237488
	LOSS [training: 0.3030826160451719 | validation: 0.3127636310369645]
	TIME [epoch: 6.96 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.30091907967861875		[learning rate: 0.0023665]
	Learning Rate: 0.00236648
	LOSS [training: 0.30091907967861875 | validation: 0.29866992360227906]
	TIME [epoch: 6.97 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29902424617291673		[learning rate: 0.0023581]
	Learning Rate: 0.00235811
	LOSS [training: 0.29902424617291673 | validation: 0.2977106290601351]
	TIME [epoch: 6.97 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.31388807420392356		[learning rate: 0.0023498]
	Learning Rate: 0.00234977
	LOSS [training: 0.31388807420392356 | validation: 0.353091439046456]
	TIME [epoch: 6.96 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.361852786287647		[learning rate: 0.0023415]
	Learning Rate: 0.00234146
	LOSS [training: 0.361852786287647 | validation: 0.3023370076604256]
	TIME [epoch: 6.96 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.30298313805326815		[learning rate: 0.0023332]
	Learning Rate: 0.00233318
	LOSS [training: 0.30298313805326815 | validation: 0.3014333735996712]
	TIME [epoch: 6.96 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29756441575267445		[learning rate: 0.0023249]
	Learning Rate: 0.00232493
	LOSS [training: 0.29756441575267445 | validation: 0.30587574643660875]
	TIME [epoch: 6.97 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.30106657215229243		[learning rate: 0.0023167]
	Learning Rate: 0.00231671
	LOSS [training: 0.30106657215229243 | validation: 0.3086758971838307]
	TIME [epoch: 6.96 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3055502525549247		[learning rate: 0.0023085]
	Learning Rate: 0.00230852
	LOSS [training: 0.3055502525549247 | validation: 0.28842825019002094]
	TIME [epoch: 6.96 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v8_20240715_180006/states/model_facs_v3_dec1b_2dpca_v8_464.pth
	Model improved!!!
EPOCH 465/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.30550063583544357		[learning rate: 0.0023004]
	Learning Rate: 0.00230035
	LOSS [training: 0.30550063583544357 | validation: 0.2983537090551437]
	TIME [epoch: 6.97 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.297069912065333		[learning rate: 0.0022922]
	Learning Rate: 0.00229222
	LOSS [training: 0.297069912065333 | validation: 0.33441821237796227]
	TIME [epoch: 6.96 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.34049241465404606		[learning rate: 0.0022841]
	Learning Rate: 0.00228411
	LOSS [training: 0.34049241465404606 | validation: 0.30224295636788717]
	TIME [epoch: 6.96 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29324798960899673		[learning rate: 0.002276]
	Learning Rate: 0.00227604
	LOSS [training: 0.29324798960899673 | validation: 0.29320233887532243]
	TIME [epoch: 6.97 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2882620993442793		[learning rate: 0.002268]
	Learning Rate: 0.00226799
	LOSS [training: 0.2882620993442793 | validation: 0.3008617752806523]
	TIME [epoch: 6.96 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.30970480795476857		[learning rate: 0.00226]
	Learning Rate: 0.00225997
	LOSS [training: 0.30970480795476857 | validation: 0.30979706045733435]
	TIME [epoch: 6.96 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2988877455819651		[learning rate: 0.002252]
	Learning Rate: 0.00225198
	LOSS [training: 0.2988877455819651 | validation: 0.2892659520973543]
	TIME [epoch: 6.96 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29077298314290184		[learning rate: 0.002244]
	Learning Rate: 0.00224401
	LOSS [training: 0.29077298314290184 | validation: 0.30881635572616345]
	TIME [epoch: 6.97 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2898671978477506		[learning rate: 0.0022361]
	Learning Rate: 0.00223608
	LOSS [training: 0.2898671978477506 | validation: 0.29437238000552035]
	TIME [epoch: 6.97 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2922228141489755		[learning rate: 0.0022282]
	Learning Rate: 0.00222817
	LOSS [training: 0.2922228141489755 | validation: 0.29034798914823545]
	TIME [epoch: 6.96 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2938958383324312		[learning rate: 0.0022203]
	Learning Rate: 0.00222029
	LOSS [training: 0.2938958383324312 | validation: 0.29533332202247725]
	TIME [epoch: 6.96 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2979005774901093		[learning rate: 0.0022124]
	Learning Rate: 0.00221244
	LOSS [training: 0.2979005774901093 | validation: 0.2989872486286644]
	TIME [epoch: 6.96 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.291780954022587		[learning rate: 0.0022046]
	Learning Rate: 0.00220462
	LOSS [training: 0.291780954022587 | validation: 0.2903416790267978]
	TIME [epoch: 6.96 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2843977125167654		[learning rate: 0.0021968]
	Learning Rate: 0.00219682
	LOSS [training: 0.2843977125167654 | validation: 0.3046527748682381]
	TIME [epoch: 6.97 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.299483974286162		[learning rate: 0.0021891]
	Learning Rate: 0.00218905
	LOSS [training: 0.299483974286162 | validation: 0.30111032998672804]
	TIME [epoch: 7.01 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2972038098524809		[learning rate: 0.0021813]
	Learning Rate: 0.00218131
	LOSS [training: 0.2972038098524809 | validation: 0.3034923884125938]
	TIME [epoch: 6.96 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2932604270153732		[learning rate: 0.0021736]
	Learning Rate: 0.0021736
	LOSS [training: 0.2932604270153732 | validation: 0.3107815221063282]
	TIME [epoch: 6.96 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29580760966139125		[learning rate: 0.0021659]
	Learning Rate: 0.00216591
	LOSS [training: 0.29580760966139125 | validation: 0.2977596416606946]
	TIME [epoch: 6.96 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29372295352485694		[learning rate: 0.0021583]
	Learning Rate: 0.00215825
	LOSS [training: 0.29372295352485694 | validation: 0.3027462518378169]
	TIME [epoch: 6.97 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29934290634806054		[learning rate: 0.0021506]
	Learning Rate: 0.00215062
	LOSS [training: 0.29934290634806054 | validation: 0.3025716883120896]
	TIME [epoch: 6.96 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3129303575519125		[learning rate: 0.002143]
	Learning Rate: 0.00214302
	LOSS [training: 0.3129303575519125 | validation: 0.2967665193129172]
	TIME [epoch: 6.96 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2909814938484015		[learning rate: 0.0021354]
	Learning Rate: 0.00213544
	LOSS [training: 0.2909814938484015 | validation: 0.29815121866716543]
	TIME [epoch: 6.96 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2848556893338548		[learning rate: 0.0021279]
	Learning Rate: 0.00212789
	LOSS [training: 0.2848556893338548 | validation: 0.3019490229884706]
	TIME [epoch: 6.96 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29109556398444736		[learning rate: 0.0021204]
	Learning Rate: 0.00212036
	LOSS [training: 0.29109556398444736 | validation: 0.2929361585896276]
	TIME [epoch: 6.97 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2986095714167429		[learning rate: 0.0021129]
	Learning Rate: 0.00211287
	LOSS [training: 0.2986095714167429 | validation: 0.2873093250330129]
	TIME [epoch: 6.96 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v8_20240715_180006/states/model_facs_v3_dec1b_2dpca_v8_489.pth
	Model improved!!!
EPOCH 490/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29248854809771085		[learning rate: 0.0021054]
	Learning Rate: 0.00210539
	LOSS [training: 0.29248854809771085 | validation: 0.2938207364369358]
	TIME [epoch: 6.97 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28916764465270234		[learning rate: 0.0020979]
	Learning Rate: 0.00209795
	LOSS [training: 0.28916764465270234 | validation: 0.29564688590390775]
	TIME [epoch: 6.97 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29846492399852054		[learning rate: 0.0020905]
	Learning Rate: 0.00209053
	LOSS [training: 0.29846492399852054 | validation: 0.3222889969411406]
	TIME [epoch: 6.96 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.30605691464843304		[learning rate: 0.0020831]
	Learning Rate: 0.00208314
	LOSS [training: 0.30605691464843304 | validation: 0.29810821432326484]
	TIME [epoch: 6.97 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28313323788517397		[learning rate: 0.0020758]
	Learning Rate: 0.00207577
	LOSS [training: 0.28313323788517397 | validation: 0.3052824122542665]
	TIME [epoch: 6.96 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29039982678478		[learning rate: 0.0020684]
	Learning Rate: 0.00206843
	LOSS [training: 0.29039982678478 | validation: 0.2996417561902258]
	TIME [epoch: 6.97 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3058728158698618		[learning rate: 0.0020611]
	Learning Rate: 0.00206112
	LOSS [training: 0.3058728158698618 | validation: 0.2957025837360353]
	TIME [epoch: 6.96 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29024141200567294		[learning rate: 0.0020538]
	Learning Rate: 0.00205383
	LOSS [training: 0.29024141200567294 | validation: 0.2948418093383943]
	TIME [epoch: 6.96 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29435857936224885		[learning rate: 0.0020466]
	Learning Rate: 0.00204657
	LOSS [training: 0.29435857936224885 | validation: 0.29665466735447543]
	TIME [epoch: 6.97 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2869375908721491		[learning rate: 0.0020393]
	Learning Rate: 0.00203933
	LOSS [training: 0.2869375908721491 | validation: 0.29203896654920014]
	TIME [epoch: 6.96 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28621989439919004		[learning rate: 0.0020321]
	Learning Rate: 0.00203212
	LOSS [training: 0.28621989439919004 | validation: 0.30417673596732553]
	TIME [epoch: 6.96 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29701213260657866		[learning rate: 0.0020249]
	Learning Rate: 0.00202493
	LOSS [training: 0.29701213260657866 | validation: 0.2917663742243441]
	TIME [epoch: 29.7 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3034944770591142		[learning rate: 0.0020178]
	Learning Rate: 0.00201777
	LOSS [training: 0.3034944770591142 | validation: 0.3049840658491676]
	TIME [epoch: 13.4 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28896801389275323		[learning rate: 0.0020106]
	Learning Rate: 0.00201064
	LOSS [training: 0.28896801389275323 | validation: 0.28126486648199245]
	TIME [epoch: 13.4 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v8_20240715_180006/states/model_facs_v3_dec1b_2dpca_v8_503.pth
	Model improved!!!
EPOCH 504/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29051899932506614		[learning rate: 0.0020035]
	Learning Rate: 0.00200353
	LOSS [training: 0.29051899932506614 | validation: 0.28615548719690265]
	TIME [epoch: 13.4 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2864300997879801		[learning rate: 0.0019964]
	Learning Rate: 0.00199644
	LOSS [training: 0.2864300997879801 | validation: 0.29293784592566474]
	TIME [epoch: 13.4 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2892298673501958		[learning rate: 0.0019894]
	Learning Rate: 0.00198938
	LOSS [training: 0.2892298673501958 | validation: 0.28939742149947256]
	TIME [epoch: 13.4 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2953702555411008		[learning rate: 0.0019823]
	Learning Rate: 0.00198235
	LOSS [training: 0.2953702555411008 | validation: 0.3071820067492971]
	TIME [epoch: 13.4 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3142188438553533		[learning rate: 0.0019753]
	Learning Rate: 0.00197534
	LOSS [training: 0.3142188438553533 | validation: 0.29714821788280144]
	TIME [epoch: 13.4 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.30507328728235117		[learning rate: 0.0019684]
	Learning Rate: 0.00196835
	LOSS [training: 0.30507328728235117 | validation: 0.2956592987091325]
	TIME [epoch: 13.4 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28152522545641057		[learning rate: 0.0019614]
	Learning Rate: 0.00196139
	LOSS [training: 0.28152522545641057 | validation: 0.28404495130472657]
	TIME [epoch: 13.4 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28977987143469414		[learning rate: 0.0019545]
	Learning Rate: 0.00195445
	LOSS [training: 0.28977987143469414 | validation: 0.2894580198453153]
	TIME [epoch: 13.4 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.287767603747263		[learning rate: 0.0019475]
	Learning Rate: 0.00194754
	LOSS [training: 0.287767603747263 | validation: 0.3049578117089233]
	TIME [epoch: 13.4 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2890561638032476		[learning rate: 0.0019407]
	Learning Rate: 0.00194066
	LOSS [training: 0.2890561638032476 | validation: 0.29977067558634285]
	TIME [epoch: 13.4 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2918912804121087		[learning rate: 0.0019338]
	Learning Rate: 0.00193379
	LOSS [training: 0.2918912804121087 | validation: 0.29950720398415076]
	TIME [epoch: 13.4 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.292185197325075		[learning rate: 0.001927]
	Learning Rate: 0.00192696
	LOSS [training: 0.292185197325075 | validation: 0.2949784566832645]
	TIME [epoch: 13.4 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2908257698293429		[learning rate: 0.0019201]
	Learning Rate: 0.00192014
	LOSS [training: 0.2908257698293429 | validation: 0.29347554941206655]
	TIME [epoch: 13.4 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28304178990837403		[learning rate: 0.0019134]
	Learning Rate: 0.00191335
	LOSS [training: 0.28304178990837403 | validation: 0.3053197677292748]
	TIME [epoch: 13.4 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28827301149031087		[learning rate: 0.0019066]
	Learning Rate: 0.00190659
	LOSS [training: 0.28827301149031087 | validation: 0.2948447138532244]
	TIME [epoch: 13.4 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28589591298964684		[learning rate: 0.0018998]
	Learning Rate: 0.00189984
	LOSS [training: 0.28589591298964684 | validation: 0.2953871599217428]
	TIME [epoch: 13.4 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2882115646971452		[learning rate: 0.0018931]
	Learning Rate: 0.00189313
	LOSS [training: 0.2882115646971452 | validation: 0.29542466709709025]
	TIME [epoch: 13.4 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2855294281670417		[learning rate: 0.0018864]
	Learning Rate: 0.00188643
	LOSS [training: 0.2855294281670417 | validation: 0.28679278298392286]
	TIME [epoch: 13.4 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2826537506276588		[learning rate: 0.0018798]
	Learning Rate: 0.00187976
	LOSS [training: 0.2826537506276588 | validation: 0.2858780992695037]
	TIME [epoch: 13.4 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28274753049134344		[learning rate: 0.0018731]
	Learning Rate: 0.00187311
	LOSS [training: 0.28274753049134344 | validation: 0.28828686479287907]
	TIME [epoch: 13.4 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28383060637924723		[learning rate: 0.0018665]
	Learning Rate: 0.00186649
	LOSS [training: 0.28383060637924723 | validation: 0.2991519010090217]
	TIME [epoch: 13.4 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28940780793137716		[learning rate: 0.0018599]
	Learning Rate: 0.00185989
	LOSS [training: 0.28940780793137716 | validation: 0.2957880768219502]
	TIME [epoch: 13.4 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2829832349339979		[learning rate: 0.0018533]
	Learning Rate: 0.00185331
	LOSS [training: 0.2829832349339979 | validation: 0.2920953278658393]
	TIME [epoch: 13.4 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.286666064986842		[learning rate: 0.0018468]
	Learning Rate: 0.00184676
	LOSS [training: 0.286666064986842 | validation: 0.27739793355408465]
	TIME [epoch: 13.4 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v8_20240715_180006/states/model_facs_v3_dec1b_2dpca_v8_527.pth
	Model improved!!!
EPOCH 528/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29109746273038645		[learning rate: 0.0018402]
	Learning Rate: 0.00184023
	LOSS [training: 0.29109746273038645 | validation: 0.2852721706797402]
	TIME [epoch: 13.4 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2857877384507069		[learning rate: 0.0018337]
	Learning Rate: 0.00183372
	LOSS [training: 0.2857877384507069 | validation: 0.2859269023085614]
	TIME [epoch: 13.4 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2816515812229153		[learning rate: 0.0018272]
	Learning Rate: 0.00182724
	LOSS [training: 0.2816515812229153 | validation: 0.3015496278612895]
	TIME [epoch: 13.4 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2994130377585571		[learning rate: 0.0018208]
	Learning Rate: 0.00182078
	LOSS [training: 0.2994130377585571 | validation: 0.28869618167499567]
	TIME [epoch: 13.4 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2845456076656468		[learning rate: 0.0018143]
	Learning Rate: 0.00181434
	LOSS [training: 0.2845456076656468 | validation: 0.2891595548677629]
	TIME [epoch: 13.4 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28050346199670445		[learning rate: 0.0018079]
	Learning Rate: 0.00180792
	LOSS [training: 0.28050346199670445 | validation: 0.298423602516718]
	TIME [epoch: 13.4 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28669322890633114		[learning rate: 0.0018015]
	Learning Rate: 0.00180153
	LOSS [training: 0.28669322890633114 | validation: 0.2913811297925092]
	TIME [epoch: 13.4 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29328101808495605		[learning rate: 0.0017952]
	Learning Rate: 0.00179516
	LOSS [training: 0.29328101808495605 | validation: 0.2991252974276073]
	TIME [epoch: 13.4 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28452519319900377		[learning rate: 0.0017888]
	Learning Rate: 0.00178881
	LOSS [training: 0.28452519319900377 | validation: 0.28866401316486046]
	TIME [epoch: 13.4 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2933333585546764		[learning rate: 0.0017825]
	Learning Rate: 0.00178248
	LOSS [training: 0.2933333585546764 | validation: 0.3013376742498512]
	TIME [epoch: 13.4 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3065912640866009		[learning rate: 0.0017762]
	Learning Rate: 0.00177618
	LOSS [training: 0.3065912640866009 | validation: 0.30374234720498694]
	TIME [epoch: 13.4 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3010532437489774		[learning rate: 0.0017699]
	Learning Rate: 0.0017699
	LOSS [training: 0.3010532437489774 | validation: 0.3044308020892269]
	TIME [epoch: 13.4 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3051382449084706		[learning rate: 0.0017636]
	Learning Rate: 0.00176364
	LOSS [training: 0.3051382449084706 | validation: 0.2900102630370395]
	TIME [epoch: 13.4 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3035254537224284		[learning rate: 0.0017574]
	Learning Rate: 0.0017574
	LOSS [training: 0.3035254537224284 | validation: 0.29551301655735357]
	TIME [epoch: 13.4 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2891616429132238		[learning rate: 0.0017512]
	Learning Rate: 0.00175119
	LOSS [training: 0.2891616429132238 | validation: 0.28807387481530966]
	TIME [epoch: 13.4 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29120930354099755		[learning rate: 0.001745]
	Learning Rate: 0.001745
	LOSS [training: 0.29120930354099755 | validation: 0.2919056600070254]
	TIME [epoch: 13.4 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2959906344502488		[learning rate: 0.0017388]
	Learning Rate: 0.00173883
	LOSS [training: 0.2959906344502488 | validation: 0.2978489284351736]
	TIME [epoch: 13.4 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28565736994785423		[learning rate: 0.0017327]
	Learning Rate: 0.00173268
	LOSS [training: 0.28565736994785423 | validation: 0.2983023666750108]
	TIME [epoch: 13.4 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27769790717840054		[learning rate: 0.0017266]
	Learning Rate: 0.00172655
	LOSS [training: 0.27769790717840054 | validation: 0.2899115122739377]
	TIME [epoch: 13.4 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29215370613450015		[learning rate: 0.0017204]
	Learning Rate: 0.00172045
	LOSS [training: 0.29215370613450015 | validation: 0.2933380084076134]
	TIME [epoch: 13.4 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2840098003104929		[learning rate: 0.0017144]
	Learning Rate: 0.00171436
	LOSS [training: 0.2840098003104929 | validation: 0.3009550171529981]
	TIME [epoch: 13.6 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2818251719610877		[learning rate: 0.0017083]
	Learning Rate: 0.0017083
	LOSS [training: 0.2818251719610877 | validation: 0.29060613231085397]
	TIME [epoch: 13.4 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2857145218058199		[learning rate: 0.0017023]
	Learning Rate: 0.00170226
	LOSS [training: 0.2857145218058199 | validation: 0.29864716273089714]
	TIME [epoch: 13.4 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28832862377783164		[learning rate: 0.0016962]
	Learning Rate: 0.00169624
	LOSS [training: 0.28832862377783164 | validation: 0.2840453222084308]
	TIME [epoch: 13.4 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2790493065039541		[learning rate: 0.0016902]
	Learning Rate: 0.00169024
	LOSS [training: 0.2790493065039541 | validation: 0.2844156762465063]
	TIME [epoch: 13.4 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2909136590656099		[learning rate: 0.0016843]
	Learning Rate: 0.00168426
	LOSS [training: 0.2909136590656099 | validation: 0.2943002611622388]
	TIME [epoch: 13.4 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2961983714608129		[learning rate: 0.0016783]
	Learning Rate: 0.00167831
	LOSS [training: 0.2961983714608129 | validation: 0.33568221004269316]
	TIME [epoch: 13.4 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.31491131546406814		[learning rate: 0.0016724]
	Learning Rate: 0.00167237
	LOSS [training: 0.31491131546406814 | validation: 0.31098093006069294]
	TIME [epoch: 13.4 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.30355154328829126		[learning rate: 0.0016665]
	Learning Rate: 0.00166646
	LOSS [training: 0.30355154328829126 | validation: 0.31805120456519004]
	TIME [epoch: 13.4 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.30127059219938945		[learning rate: 0.0016606]
	Learning Rate: 0.00166057
	LOSS [training: 0.30127059219938945 | validation: 0.31863677008307467]
	TIME [epoch: 13.4 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3012567242789598		[learning rate: 0.0016547]
	Learning Rate: 0.00165469
	LOSS [training: 0.3012567242789598 | validation: 0.3013069888917115]
	TIME [epoch: 13.4 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.297348675250954		[learning rate: 0.0016488]
	Learning Rate: 0.00164884
	LOSS [training: 0.297348675250954 | validation: 0.3151174537181929]
	TIME [epoch: 13.4 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.297577276074717		[learning rate: 0.001643]
	Learning Rate: 0.00164301
	LOSS [training: 0.297577276074717 | validation: 0.30669449010212924]
	TIME [epoch: 13.4 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.30858067406925205		[learning rate: 0.0016372]
	Learning Rate: 0.0016372
	LOSS [training: 0.30858067406925205 | validation: 0.30953415661656963]
	TIME [epoch: 13.4 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3098873778101539		[learning rate: 0.0016314]
	Learning Rate: 0.00163141
	LOSS [training: 0.3098873778101539 | validation: 0.30237185947908995]
	TIME [epoch: 13.4 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.30141077207086536		[learning rate: 0.0016256]
	Learning Rate: 0.00162564
	LOSS [training: 0.30141077207086536 | validation: 0.31637945783433474]
	TIME [epoch: 13.4 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3019286381390065		[learning rate: 0.0016199]
	Learning Rate: 0.0016199
	LOSS [training: 0.3019286381390065 | validation: 0.3109461375520381]
	TIME [epoch: 13.4 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29623720092739814		[learning rate: 0.0016142]
	Learning Rate: 0.00161417
	LOSS [training: 0.29623720092739814 | validation: 0.3156877702214324]
	TIME [epoch: 13.4 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3073917928974094		[learning rate: 0.0016085]
	Learning Rate: 0.00160846
	LOSS [training: 0.3073917928974094 | validation: 0.3106398113769126]
	TIME [epoch: 13.4 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2960824658280068		[learning rate: 0.0016028]
	Learning Rate: 0.00160277
	LOSS [training: 0.2960824658280068 | validation: 0.2995304175883954]
	TIME [epoch: 13.4 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29366429289533275		[learning rate: 0.0015971]
	Learning Rate: 0.0015971
	LOSS [training: 0.29366429289533275 | validation: 0.3148076158786003]
	TIME [epoch: 13.4 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29793452975834683		[learning rate: 0.0015915]
	Learning Rate: 0.00159146
	LOSS [training: 0.29793452975834683 | validation: 0.30016433176602075]
	TIME [epoch: 13.4 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.31205258302384914		[learning rate: 0.0015858]
	Learning Rate: 0.00158583
	LOSS [training: 0.31205258302384914 | validation: 0.29310001363988136]
	TIME [epoch: 13.4 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28611493657436		[learning rate: 0.0015802]
	Learning Rate: 0.00158022
	LOSS [training: 0.28611493657436 | validation: 0.29336727826653136]
	TIME [epoch: 13.4 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2823758625935755		[learning rate: 0.0015746]
	Learning Rate: 0.00157463
	LOSS [training: 0.2823758625935755 | validation: 0.28400293091099116]
	TIME [epoch: 13.4 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2803318712091189		[learning rate: 0.0015691]
	Learning Rate: 0.00156907
	LOSS [training: 0.2803318712091189 | validation: 0.28877814203801827]
	TIME [epoch: 13.4 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2875136300155016		[learning rate: 0.0015635]
	Learning Rate: 0.00156352
	LOSS [training: 0.2875136300155016 | validation: 0.2845212290826248]
	TIME [epoch: 13.4 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2791503775398597		[learning rate: 0.001558]
	Learning Rate: 0.00155799
	LOSS [training: 0.2791503775398597 | validation: 0.2852143093167337]
	TIME [epoch: 13.4 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27419339858223907		[learning rate: 0.0015525]
	Learning Rate: 0.00155248
	LOSS [training: 0.27419339858223907 | validation: 0.2948117886155297]
	TIME [epoch: 13.4 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2759891040078574		[learning rate: 0.001547]
	Learning Rate: 0.00154699
	LOSS [training: 0.2759891040078574 | validation: 0.2895869126391144]
	TIME [epoch: 13.4 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2844684271990599		[learning rate: 0.0015415]
	Learning Rate: 0.00154152
	LOSS [training: 0.2844684271990599 | validation: 0.28258327258812266]
	TIME [epoch: 13.4 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28303446748477384		[learning rate: 0.0015361]
	Learning Rate: 0.00153607
	LOSS [training: 0.28303446748477384 | validation: 0.2954608484474328]
	TIME [epoch: 13.4 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2939134194472289		[learning rate: 0.0015306]
	Learning Rate: 0.00153064
	LOSS [training: 0.2939134194472289 | validation: 0.2914111308020483]
	TIME [epoch: 13.4 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2791272204797753		[learning rate: 0.0015252]
	Learning Rate: 0.00152522
	LOSS [training: 0.2791272204797753 | validation: 0.2804228963483245]
	TIME [epoch: 13.4 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2758466705843086		[learning rate: 0.0015198]
	Learning Rate: 0.00151983
	LOSS [training: 0.2758466705843086 | validation: 0.2820892724615457]
	TIME [epoch: 13.4 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27710637550597245		[learning rate: 0.0015145]
	Learning Rate: 0.00151446
	LOSS [training: 0.27710637550597245 | validation: 0.2830732027576447]
	TIME [epoch: 13.4 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.298874004566285		[learning rate: 0.0015091]
	Learning Rate: 0.0015091
	LOSS [training: 0.298874004566285 | validation: 0.2868999090194837]
	TIME [epoch: 13.4 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28882393097493836		[learning rate: 0.0015038]
	Learning Rate: 0.00150376
	LOSS [training: 0.28882393097493836 | validation: 0.2868328125517662]
	TIME [epoch: 13.4 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27721394785675796		[learning rate: 0.0014984]
	Learning Rate: 0.00149845
	LOSS [training: 0.27721394785675796 | validation: 0.28614994098086083]
	TIME [epoch: 13.4 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2837001547420161		[learning rate: 0.0014931]
	Learning Rate: 0.00149315
	LOSS [training: 0.2837001547420161 | validation: 0.2880683414295738]
	TIME [epoch: 13.4 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2795620127301985		[learning rate: 0.0014879]
	Learning Rate: 0.00148787
	LOSS [training: 0.2795620127301985 | validation: 0.28314503773719435]
	TIME [epoch: 13.4 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28216242546418474		[learning rate: 0.0014826]
	Learning Rate: 0.00148261
	LOSS [training: 0.28216242546418474 | validation: 0.28615373132616295]
	TIME [epoch: 13.4 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2904171264601291		[learning rate: 0.0014774]
	Learning Rate: 0.00147736
	LOSS [training: 0.2904171264601291 | validation: 0.28818516085596524]
	TIME [epoch: 13.4 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2773554125587761		[learning rate: 0.0014721]
	Learning Rate: 0.00147214
	LOSS [training: 0.2773554125587761 | validation: 0.2875634681452776]
	TIME [epoch: 13.4 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27877144310098184		[learning rate: 0.0014669]
	Learning Rate: 0.00146693
	LOSS [training: 0.27877144310098184 | validation: 0.28368140034805756]
	TIME [epoch: 13.4 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27697650325852313		[learning rate: 0.0014617]
	Learning Rate: 0.00146175
	LOSS [training: 0.27697650325852313 | validation: 0.28676044790259847]
	TIME [epoch: 13.4 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27826040151198256		[learning rate: 0.0014566]
	Learning Rate: 0.00145658
	LOSS [training: 0.27826040151198256 | validation: 0.29020727986429573]
	TIME [epoch: 13.4 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2848980847714069		[learning rate: 0.0014514]
	Learning Rate: 0.00145143
	LOSS [training: 0.2848980847714069 | validation: 0.30002843956989084]
	TIME [epoch: 13.4 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28076142707519053		[learning rate: 0.0014463]
	Learning Rate: 0.00144629
	LOSS [training: 0.28076142707519053 | validation: 0.2805050119570197]
	TIME [epoch: 13.4 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2750380550552139		[learning rate: 0.0014412]
	Learning Rate: 0.00144118
	LOSS [training: 0.2750380550552139 | validation: 0.28081360533307637]
	TIME [epoch: 13.4 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28085756587153415		[learning rate: 0.0014361]
	Learning Rate: 0.00143608
	LOSS [training: 0.28085756587153415 | validation: 0.288133239765388]
	TIME [epoch: 13.4 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.31727232720345594		[learning rate: 0.001431]
	Learning Rate: 0.001431
	LOSS [training: 0.31727232720345594 | validation: 0.3037538419463139]
	TIME [epoch: 13.4 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2833742161086619		[learning rate: 0.0014259]
	Learning Rate: 0.00142594
	LOSS [training: 0.2833742161086619 | validation: 0.28350368915170876]
	TIME [epoch: 13.4 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28823719009000626		[learning rate: 0.0014209]
	Learning Rate: 0.0014209
	LOSS [training: 0.28823719009000626 | validation: 0.2811601232246508]
	TIME [epoch: 13.4 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2802290141786191		[learning rate: 0.0014159]
	Learning Rate: 0.00141588
	LOSS [training: 0.2802290141786191 | validation: 0.2799088839072888]
	TIME [epoch: 13.4 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2753078858273951		[learning rate: 0.0014109]
	Learning Rate: 0.00141087
	LOSS [training: 0.2753078858273951 | validation: 0.2774167063338582]
	TIME [epoch: 13.4 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27861518827933746		[learning rate: 0.0014059]
	Learning Rate: 0.00140588
	LOSS [training: 0.27861518827933746 | validation: 0.28998691860755627]
	TIME [epoch: 13.4 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27915134996392155		[learning rate: 0.0014009]
	Learning Rate: 0.00140091
	LOSS [training: 0.27915134996392155 | validation: 0.28137312406327925]
	TIME [epoch: 13.4 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27960419956254107		[learning rate: 0.001396]
	Learning Rate: 0.00139596
	LOSS [training: 0.27960419956254107 | validation: 0.2896059736285087]
	TIME [epoch: 13.4 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27917132077336365		[learning rate: 0.001391]
	Learning Rate: 0.00139102
	LOSS [training: 0.27917132077336365 | validation: 0.28623413817669163]
	TIME [epoch: 13.4 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2726231050782782		[learning rate: 0.0013861]
	Learning Rate: 0.0013861
	LOSS [training: 0.2726231050782782 | validation: 0.2766892771001602]
	TIME [epoch: 13.4 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v8_20240715_180006/states/model_facs_v3_dec1b_2dpca_v8_608.pth
	Model improved!!!
EPOCH 609/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28902459440022726		[learning rate: 0.0013812]
	Learning Rate: 0.0013812
	LOSS [training: 0.28902459440022726 | validation: 0.2871624091314571]
	TIME [epoch: 13.4 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2741434801701783		[learning rate: 0.0013763]
	Learning Rate: 0.00137632
	LOSS [training: 0.2741434801701783 | validation: 0.28511292461484683]
	TIME [epoch: 13.4 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2751369475293396		[learning rate: 0.0013714]
	Learning Rate: 0.00137145
	LOSS [training: 0.2751369475293396 | validation: 0.29107910792803504]
	TIME [epoch: 13.4 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2759829926935496		[learning rate: 0.0013666]
	Learning Rate: 0.0013666
	LOSS [training: 0.2759829926935496 | validation: 0.28224057213007175]
	TIME [epoch: 13.4 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28092962680270944		[learning rate: 0.0013618]
	Learning Rate: 0.00136177
	LOSS [training: 0.28092962680270944 | validation: 0.28565222221071174]
	TIME [epoch: 13.4 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2762114465544116		[learning rate: 0.001357]
	Learning Rate: 0.00135695
	LOSS [training: 0.2762114465544116 | validation: 0.2872781304414741]
	TIME [epoch: 13.4 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2833443621730698		[learning rate: 0.0013522]
	Learning Rate: 0.00135215
	LOSS [training: 0.2833443621730698 | validation: 0.28367197632793584]
	TIME [epoch: 13.4 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27232668250535363		[learning rate: 0.0013474]
	Learning Rate: 0.00134737
	LOSS [training: 0.27232668250535363 | validation: 0.28301866513729057]
	TIME [epoch: 13.4 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2886095440823066		[learning rate: 0.0013426]
	Learning Rate: 0.00134261
	LOSS [training: 0.2886095440823066 | validation: 0.2884367055461092]
	TIME [epoch: 13.4 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27915714446212264		[learning rate: 0.0013379]
	Learning Rate: 0.00133786
	LOSS [training: 0.27915714446212264 | validation: 0.2829438987811571]
	TIME [epoch: 13.4 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28011139065256757		[learning rate: 0.0013331]
	Learning Rate: 0.00133313
	LOSS [training: 0.28011139065256757 | validation: 0.2880624119980752]
	TIME [epoch: 13.4 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2917664144196535		[learning rate: 0.0013284]
	Learning Rate: 0.00132841
	LOSS [training: 0.2917664144196535 | validation: 0.27923478735816576]
	TIME [epoch: 13.4 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2816049774729773		[learning rate: 0.0013237]
	Learning Rate: 0.00132372
	LOSS [training: 0.2816049774729773 | validation: 0.2778746440171286]
	TIME [epoch: 13.4 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2802436292982297		[learning rate: 0.001319]
	Learning Rate: 0.00131904
	LOSS [training: 0.2802436292982297 | validation: 0.2851994791617525]
	TIME [epoch: 13.4 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2894297977550601		[learning rate: 0.0013144]
	Learning Rate: 0.00131437
	LOSS [training: 0.2894297977550601 | validation: 0.2868177112535892]
	TIME [epoch: 13.4 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2953829347813726		[learning rate: 0.0013097]
	Learning Rate: 0.00130972
	LOSS [training: 0.2953829347813726 | validation: 0.288698365899136]
	TIME [epoch: 13.4 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2857515614486541		[learning rate: 0.0013051]
	Learning Rate: 0.00130509
	LOSS [training: 0.2857515614486541 | validation: 0.2828553613468709]
	TIME [epoch: 13.4 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2925813231101581		[learning rate: 0.0013005]
	Learning Rate: 0.00130048
	LOSS [training: 0.2925813231101581 | validation: 0.2781698907827702]
	TIME [epoch: 13.4 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28782106946967906		[learning rate: 0.0012959]
	Learning Rate: 0.00129588
	LOSS [training: 0.28782106946967906 | validation: 0.28235636680406867]
	TIME [epoch: 13.4 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28850612309509216		[learning rate: 0.0012913]
	Learning Rate: 0.0012913
	LOSS [training: 0.28850612309509216 | validation: 0.2798857419311696]
	TIME [epoch: 13.4 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28469091110230155		[learning rate: 0.0012867]
	Learning Rate: 0.00128673
	LOSS [training: 0.28469091110230155 | validation: 0.28417581549817383]
	TIME [epoch: 13.4 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28659882683839183		[learning rate: 0.0012822]
	Learning Rate: 0.00128218
	LOSS [training: 0.28659882683839183 | validation: 0.2786464026377941]
	TIME [epoch: 13.4 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3083014082829619		[learning rate: 0.0012776]
	Learning Rate: 0.00127765
	LOSS [training: 0.3083014082829619 | validation: 0.28418240693916064]
	TIME [epoch: 13.4 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2929524281256675		[learning rate: 0.0012731]
	Learning Rate: 0.00127313
	LOSS [training: 0.2929524281256675 | validation: 0.27557744619657804]
	TIME [epoch: 13.4 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v8_20240715_180006/states/model_facs_v3_dec1b_2dpca_v8_632.pth
	Model improved!!!
EPOCH 633/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.283232088269683		[learning rate: 0.0012686]
	Learning Rate: 0.00126863
	LOSS [training: 0.283232088269683 | validation: 0.28457231705930414]
	TIME [epoch: 13.4 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28074156298139163		[learning rate: 0.0012641]
	Learning Rate: 0.00126414
	LOSS [training: 0.28074156298139163 | validation: 0.2870087070179803]
	TIME [epoch: 13.4 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28660569539226893		[learning rate: 0.0012597]
	Learning Rate: 0.00125967
	LOSS [training: 0.28660569539226893 | validation: 0.28695588527934673]
	TIME [epoch: 13.4 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2816150004342259		[learning rate: 0.0012552]
	Learning Rate: 0.00125521
	LOSS [training: 0.2816150004342259 | validation: 0.28356895103602775]
	TIME [epoch: 13.4 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2830970429252642		[learning rate: 0.0012508]
	Learning Rate: 0.00125078
	LOSS [training: 0.2830970429252642 | validation: 0.2844630803809182]
	TIME [epoch: 13.4 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29485964681811927		[learning rate: 0.0012464]
	Learning Rate: 0.00124635
	LOSS [training: 0.29485964681811927 | validation: 0.28786006334517894]
	TIME [epoch: 13.4 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.289604279348598		[learning rate: 0.0012419]
	Learning Rate: 0.00124195
	LOSS [training: 0.289604279348598 | validation: 0.2837329371271691]
	TIME [epoch: 13.4 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2847325894270956		[learning rate: 0.0012376]
	Learning Rate: 0.00123755
	LOSS [training: 0.2847325894270956 | validation: 0.2851087032022051]
	TIME [epoch: 13.4 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2933887752952495		[learning rate: 0.0012332]
	Learning Rate: 0.00123318
	LOSS [training: 0.2933887752952495 | validation: 0.28727575209406886]
	TIME [epoch: 13.4 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29192666821594127		[learning rate: 0.0012288]
	Learning Rate: 0.00122882
	LOSS [training: 0.29192666821594127 | validation: 0.29095518844977375]
	TIME [epoch: 13.4 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2846195549500173		[learning rate: 0.0012245]
	Learning Rate: 0.00122447
	LOSS [training: 0.2846195549500173 | validation: 0.28176300334412013]
	TIME [epoch: 13.4 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2871273202524515		[learning rate: 0.0012201]
	Learning Rate: 0.00122014
	LOSS [training: 0.2871273202524515 | validation: 0.27349466828982505]
	TIME [epoch: 13.4 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v8_20240715_180006/states/model_facs_v3_dec1b_2dpca_v8_644.pth
	Model improved!!!
EPOCH 645/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.283854054774552		[learning rate: 0.0012158]
	Learning Rate: 0.00121583
	LOSS [training: 0.283854054774552 | validation: 0.27950419608100613]
	TIME [epoch: 13.4 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28095379121474673		[learning rate: 0.0012115]
	Learning Rate: 0.00121153
	LOSS [training: 0.28095379121474673 | validation: 0.2864565250938478]
	TIME [epoch: 13.4 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27802977897134085		[learning rate: 0.0012072]
	Learning Rate: 0.00120724
	LOSS [training: 0.27802977897134085 | validation: 0.28143919157004993]
	TIME [epoch: 13.4 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28218220596510996		[learning rate: 0.001203]
	Learning Rate: 0.00120297
	LOSS [training: 0.28218220596510996 | validation: 0.2762586932858447]
	TIME [epoch: 13.4 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2868775899401137		[learning rate: 0.0011987]
	Learning Rate: 0.00119872
	LOSS [training: 0.2868775899401137 | validation: 0.2806449833652242]
	TIME [epoch: 13.4 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28482836720280486		[learning rate: 0.0011945]
	Learning Rate: 0.00119448
	LOSS [training: 0.28482836720280486 | validation: 0.27536444609180344]
	TIME [epoch: 13.4 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2815086297153488		[learning rate: 0.0011903]
	Learning Rate: 0.00119026
	LOSS [training: 0.2815086297153488 | validation: 0.2835729687752365]
	TIME [epoch: 13.4 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2867156277685777		[learning rate: 0.001186]
	Learning Rate: 0.00118605
	LOSS [training: 0.2867156277685777 | validation: 0.281540760538764]
	TIME [epoch: 13.4 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27781054565521973		[learning rate: 0.0011819]
	Learning Rate: 0.00118185
	LOSS [training: 0.27781054565521973 | validation: 0.284038772611962]
	TIME [epoch: 13.4 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27798717403066925		[learning rate: 0.0011777]
	Learning Rate: 0.00117768
	LOSS [training: 0.27798717403066925 | validation: 0.2791831616620295]
	TIME [epoch: 13.4 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27975268344988335		[learning rate: 0.0011735]
	Learning Rate: 0.00117351
	LOSS [training: 0.27975268344988335 | validation: 0.28433793009251296]
	TIME [epoch: 13.4 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2923036516841307		[learning rate: 0.0011694]
	Learning Rate: 0.00116936
	LOSS [training: 0.2923036516841307 | validation: 0.28288214677345214]
	TIME [epoch: 13.4 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28417044420519816		[learning rate: 0.0011652]
	Learning Rate: 0.00116523
	LOSS [training: 0.28417044420519816 | validation: 0.28222789294265926]
	TIME [epoch: 13.4 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2844617638492916		[learning rate: 0.0011611]
	Learning Rate: 0.00116111
	LOSS [training: 0.2844617638492916 | validation: 0.28817734478383283]
	TIME [epoch: 13.4 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2824490190659963		[learning rate: 0.001157]
	Learning Rate: 0.001157
	LOSS [training: 0.2824490190659963 | validation: 0.2761872630217338]
	TIME [epoch: 13.4 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2810754707586996		[learning rate: 0.0011529]
	Learning Rate: 0.00115291
	LOSS [training: 0.2810754707586996 | validation: 0.2776712891505198]
	TIME [epoch: 13.4 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28417640379308523		[learning rate: 0.0011488]
	Learning Rate: 0.00114883
	LOSS [training: 0.28417640379308523 | validation: 0.27963503551776586]
	TIME [epoch: 13.4 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2862845944792715		[learning rate: 0.0011448]
	Learning Rate: 0.00114477
	LOSS [training: 0.2862845944792715 | validation: 0.28398610266739227]
	TIME [epoch: 13.4 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2908931658383785		[learning rate: 0.0011407]
	Learning Rate: 0.00114072
	LOSS [training: 0.2908931658383785 | validation: 0.2800310415674508]
	TIME [epoch: 13.4 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2773612765923073		[learning rate: 0.0011367]
	Learning Rate: 0.00113669
	LOSS [training: 0.2773612765923073 | validation: 0.28214447944420706]
	TIME [epoch: 13.4 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2873457191357603		[learning rate: 0.0011327]
	Learning Rate: 0.00113267
	LOSS [training: 0.2873457191357603 | validation: 0.2719096434498034]
	TIME [epoch: 13.4 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v8_20240715_180006/states/model_facs_v3_dec1b_2dpca_v8_665.pth
	Model improved!!!
EPOCH 666/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2904060766396009		[learning rate: 0.0011287]
	Learning Rate: 0.00112866
	LOSS [training: 0.2904060766396009 | validation: 0.27858923150216963]
	TIME [epoch: 13.4 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2793004604360411		[learning rate: 0.0011247]
	Learning Rate: 0.00112467
	LOSS [training: 0.2793004604360411 | validation: 0.28834791712868446]
	TIME [epoch: 13.4 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2878591001558468		[learning rate: 0.0011207]
	Learning Rate: 0.00112069
	LOSS [training: 0.2878591001558468 | validation: 0.27979940025549654]
	TIME [epoch: 13.4 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2857064949587078		[learning rate: 0.0011167]
	Learning Rate: 0.00111673
	LOSS [training: 0.2857064949587078 | validation: 0.28153642734175177]
	TIME [epoch: 13.4 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2875884833499496		[learning rate: 0.0011128]
	Learning Rate: 0.00111278
	LOSS [training: 0.2875884833499496 | validation: 0.2815009042710474]
	TIME [epoch: 13.4 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28029580968589485		[learning rate: 0.0011088]
	Learning Rate: 0.00110885
	LOSS [training: 0.28029580968589485 | validation: 0.2764429552228468]
	TIME [epoch: 13.4 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28173865965537975		[learning rate: 0.0011049]
	Learning Rate: 0.00110493
	LOSS [training: 0.28173865965537975 | validation: 0.2759089072897335]
	TIME [epoch: 13.4 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2837537527838434		[learning rate: 0.001101]
	Learning Rate: 0.00110102
	LOSS [training: 0.2837537527838434 | validation: 0.27546029778489123]
	TIME [epoch: 13.5 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28827164819563167		[learning rate: 0.0010971]
	Learning Rate: 0.00109713
	LOSS [training: 0.28827164819563167 | validation: 0.2749585407684454]
	TIME [epoch: 13.4 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27768753975424737		[learning rate: 0.0010932]
	Learning Rate: 0.00109325
	LOSS [training: 0.27768753975424737 | validation: 0.27014151750217064]
	TIME [epoch: 13.4 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v8_20240715_180006/states/model_facs_v3_dec1b_2dpca_v8_675.pth
	Model improved!!!
EPOCH 676/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27526076828773394		[learning rate: 0.0010894]
	Learning Rate: 0.00108938
	LOSS [training: 0.27526076828773394 | validation: 0.2723801171003867]
	TIME [epoch: 13.4 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28273386862808464		[learning rate: 0.0010855]
	Learning Rate: 0.00108553
	LOSS [training: 0.28273386862808464 | validation: 0.2831948490564044]
	TIME [epoch: 13.4 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2819966647379409		[learning rate: 0.0010817]
	Learning Rate: 0.00108169
	LOSS [training: 0.2819966647379409 | validation: 0.28088205930760973]
	TIME [epoch: 13.4 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2779302526118709		[learning rate: 0.0010779]
	Learning Rate: 0.00107786
	LOSS [training: 0.2779302526118709 | validation: 0.2775790065096781]
	TIME [epoch: 13.4 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27980240347251134		[learning rate: 0.0010741]
	Learning Rate: 0.00107405
	LOSS [training: 0.27980240347251134 | validation: 0.2804935561846401]
	TIME [epoch: 13.4 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28009163354119837		[learning rate: 0.0010703]
	Learning Rate: 0.00107025
	LOSS [training: 0.28009163354119837 | validation: 0.27407110598123596]
	TIME [epoch: 13.4 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27697854171796354		[learning rate: 0.0010665]
	Learning Rate: 0.00106647
	LOSS [training: 0.27697854171796354 | validation: 0.2854931973955129]
	TIME [epoch: 13.4 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2876244785487964		[learning rate: 0.0010627]
	Learning Rate: 0.0010627
	LOSS [training: 0.2876244785487964 | validation: 0.2763136438216596]
	TIME [epoch: 13.4 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28107520129081615		[learning rate: 0.0010589]
	Learning Rate: 0.00105894
	LOSS [training: 0.28107520129081615 | validation: 0.2810695491658657]
	TIME [epoch: 13.4 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2716543324747522		[learning rate: 0.0010552]
	Learning Rate: 0.0010552
	LOSS [training: 0.2716543324747522 | validation: 0.27723548593155345]
	TIME [epoch: 13.4 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28701288723794044		[learning rate: 0.0010515]
	Learning Rate: 0.00105147
	LOSS [training: 0.28701288723794044 | validation: 0.28289445568906674]
	TIME [epoch: 13.4 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28369120885992966		[learning rate: 0.0010477]
	Learning Rate: 0.00104775
	LOSS [training: 0.28369120885992966 | validation: 0.2781608577870865]
	TIME [epoch: 13.4 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28112445506939027		[learning rate: 0.001044]
	Learning Rate: 0.00104404
	LOSS [training: 0.28112445506939027 | validation: 0.27563337136561733]
	TIME [epoch: 13.4 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2772654901292825		[learning rate: 0.0010404]
	Learning Rate: 0.00104035
	LOSS [training: 0.2772654901292825 | validation: 0.2781750443345782]
	TIME [epoch: 13.4 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28564243288702545		[learning rate: 0.0010367]
	Learning Rate: 0.00103667
	LOSS [training: 0.28564243288702545 | validation: 0.2828276197124571]
	TIME [epoch: 13.4 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2819668787310053		[learning rate: 0.001033]
	Learning Rate: 0.00103301
	LOSS [training: 0.2819668787310053 | validation: 0.28022259373781855]
	TIME [epoch: 13.4 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28723815875538233		[learning rate: 0.0010294]
	Learning Rate: 0.00102935
	LOSS [training: 0.28723815875538233 | validation: 0.27970532218955246]
	TIME [epoch: 13.4 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2844595990441621		[learning rate: 0.0010257]
	Learning Rate: 0.00102571
	LOSS [training: 0.2844595990441621 | validation: 0.27563243528348325]
	TIME [epoch: 13.4 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27919795589945756		[learning rate: 0.0010221]
	Learning Rate: 0.00102209
	LOSS [training: 0.27919795589945756 | validation: 0.2793925937166437]
	TIME [epoch: 13.4 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27426071492150944		[learning rate: 0.0010185]
	Learning Rate: 0.00101847
	LOSS [training: 0.27426071492150944 | validation: 0.2851810283545809]
	TIME [epoch: 13.4 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27694150982710525		[learning rate: 0.0010149]
	Learning Rate: 0.00101487
	LOSS [training: 0.27694150982710525 | validation: 0.2864766838650093]
	TIME [epoch: 13.4 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28307344422181646		[learning rate: 0.0010113]
	Learning Rate: 0.00101128
	LOSS [training: 0.28307344422181646 | validation: 0.2795906975074328]
	TIME [epoch: 13.4 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2834463749496279		[learning rate: 0.0010077]
	Learning Rate: 0.0010077
	LOSS [training: 0.2834463749496279 | validation: 0.2793840778271226]
	TIME [epoch: 13.4 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28155089587931076		[learning rate: 0.0010041]
	Learning Rate: 0.00100414
	LOSS [training: 0.28155089587931076 | validation: 0.27632815998342203]
	TIME [epoch: 13.4 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2817006887883366		[learning rate: 0.0010006]
	Learning Rate: 0.00100059
	LOSS [training: 0.2817006887883366 | validation: 0.2762968170162986]
	TIME [epoch: 13.4 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28522632148884414		[learning rate: 0.00099705]
	Learning Rate: 0.000997052
	LOSS [training: 0.28522632148884414 | validation: 0.2743835901428041]
	TIME [epoch: 13.4 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2766806984669976		[learning rate: 0.00099353]
	Learning Rate: 0.000993527
	LOSS [training: 0.2766806984669976 | validation: 0.2780603106323798]
	TIME [epoch: 13.4 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2810281648826162		[learning rate: 0.00099001]
	Learning Rate: 0.000990013
	LOSS [training: 0.2810281648826162 | validation: 0.280594150492962]
	TIME [epoch: 13.4 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28262691932970774		[learning rate: 0.00098651]
	Learning Rate: 0.000986513
	LOSS [training: 0.28262691932970774 | validation: 0.2772405084307001]
	TIME [epoch: 13.4 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2820004367331383		[learning rate: 0.00098302]
	Learning Rate: 0.000983024
	LOSS [training: 0.2820004367331383 | validation: 0.2793908566600039]
	TIME [epoch: 13.4 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2842192050215618		[learning rate: 0.00097955]
	Learning Rate: 0.000979548
	LOSS [training: 0.2842192050215618 | validation: 0.27531590713412607]
	TIME [epoch: 13.4 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2794184891235274		[learning rate: 0.00097608]
	Learning Rate: 0.000976084
	LOSS [training: 0.2794184891235274 | validation: 0.2795860067561208]
	TIME [epoch: 13.4 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2784882601627754		[learning rate: 0.00097263]
	Learning Rate: 0.000972632
	LOSS [training: 0.2784882601627754 | validation: 0.27873832323841313]
	TIME [epoch: 13.4 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2838786728712356		[learning rate: 0.00096919]
	Learning Rate: 0.000969193
	LOSS [training: 0.2838786728712356 | validation: 0.2776993795958984]
	TIME [epoch: 13.4 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28560298915325216		[learning rate: 0.00096577]
	Learning Rate: 0.000965766
	LOSS [training: 0.28560298915325216 | validation: 0.2750092639728341]
	TIME [epoch: 13.4 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2851965650030615		[learning rate: 0.00096235]
	Learning Rate: 0.000962351
	LOSS [training: 0.2851965650030615 | validation: 0.28326402698440034]
	TIME [epoch: 13.4 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2815216237420153		[learning rate: 0.00095895]
	Learning Rate: 0.000958948
	LOSS [training: 0.2815216237420153 | validation: 0.275456788025722]
	TIME [epoch: 13.4 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2806738068764684		[learning rate: 0.00095556]
	Learning Rate: 0.000955557
	LOSS [training: 0.2806738068764684 | validation: 0.28135309344817994]
	TIME [epoch: 13.4 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2836803568542436		[learning rate: 0.00095218]
	Learning Rate: 0.000952178
	LOSS [training: 0.2836803568542436 | validation: 0.27202160588398294]
	TIME [epoch: 13.4 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27391413325156766		[learning rate: 0.00094881]
	Learning Rate: 0.00094881
	LOSS [training: 0.27391413325156766 | validation: 0.28238343344618777]
	TIME [epoch: 13.4 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27233282452116186		[learning rate: 0.00094546]
	Learning Rate: 0.000945455
	LOSS [training: 0.27233282452116186 | validation: 0.28052354295273896]
	TIME [epoch: 13.4 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2772981871938469		[learning rate: 0.00094211]
	Learning Rate: 0.000942112
	LOSS [training: 0.2772981871938469 | validation: 0.2758550542502559]
	TIME [epoch: 13.4 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2751244724823842		[learning rate: 0.00093878]
	Learning Rate: 0.000938781
	LOSS [training: 0.2751244724823842 | validation: 0.2779494150994215]
	TIME [epoch: 13.4 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2750724053328005		[learning rate: 0.00093546]
	Learning Rate: 0.000935461
	LOSS [training: 0.2750724053328005 | validation: 0.27989555030958263]
	TIME [epoch: 13.4 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2761651369518652		[learning rate: 0.00093215]
	Learning Rate: 0.000932153
	LOSS [training: 0.2761651369518652 | validation: 0.27527807115785513]
	TIME [epoch: 13.4 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28215689141731376		[learning rate: 0.00092886]
	Learning Rate: 0.000928857
	LOSS [training: 0.28215689141731376 | validation: 0.2785842534733179]
	TIME [epoch: 13.4 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2710767116467372		[learning rate: 0.00092557]
	Learning Rate: 0.000925572
	LOSS [training: 0.2710767116467372 | validation: 0.27465514442706723]
	TIME [epoch: 13.4 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2751651944402043		[learning rate: 0.0009223]
	Learning Rate: 0.000922299
	LOSS [training: 0.2751651944402043 | validation: 0.2734723340589368]
	TIME [epoch: 13.4 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27860308361947345		[learning rate: 0.00091904]
	Learning Rate: 0.000919038
	LOSS [training: 0.27860308361947345 | validation: 0.2817494752301725]
	TIME [epoch: 13.4 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2788281048865054		[learning rate: 0.00091579]
	Learning Rate: 0.000915788
	LOSS [training: 0.2788281048865054 | validation: 0.26956771458613726]
	TIME [epoch: 13.4 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v8_20240715_180006/states/model_facs_v3_dec1b_2dpca_v8_725.pth
	Model improved!!!
EPOCH 726/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2783803466123618		[learning rate: 0.00091255]
	Learning Rate: 0.000912549
	LOSS [training: 0.2783803466123618 | validation: 0.27692661543634955]
	TIME [epoch: 13.4 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2767815713212753		[learning rate: 0.00090932]
	Learning Rate: 0.000909323
	LOSS [training: 0.2767815713212753 | validation: 0.27778195935036165]
	TIME [epoch: 13.4 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2767560362962048		[learning rate: 0.00090611]
	Learning Rate: 0.000906107
	LOSS [training: 0.2767560362962048 | validation: 0.2779675709518631]
	TIME [epoch: 13.4 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2759648838315012		[learning rate: 0.0009029]
	Learning Rate: 0.000902903
	LOSS [training: 0.2759648838315012 | validation: 0.2765537725276988]
	TIME [epoch: 13.4 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2772088591199135		[learning rate: 0.00089971]
	Learning Rate: 0.00089971
	LOSS [training: 0.2772088591199135 | validation: 0.2775326603044856]
	TIME [epoch: 13.4 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2804605381993256		[learning rate: 0.00089653]
	Learning Rate: 0.000896529
	LOSS [training: 0.2804605381993256 | validation: 0.2806850968121345]
	TIME [epoch: 13.4 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27825837377282675		[learning rate: 0.00089336]
	Learning Rate: 0.000893358
	LOSS [training: 0.27825837377282675 | validation: 0.28289680341319945]
	TIME [epoch: 13.4 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2827421528865079		[learning rate: 0.0008902]
	Learning Rate: 0.000890199
	LOSS [training: 0.2827421528865079 | validation: 0.27661117213631525]
	TIME [epoch: 13.4 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27928463526586284		[learning rate: 0.00088705]
	Learning Rate: 0.000887051
	LOSS [training: 0.27928463526586284 | validation: 0.27706711272000184]
	TIME [epoch: 13.4 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27805451250406815		[learning rate: 0.00088391]
	Learning Rate: 0.000883914
	LOSS [training: 0.27805451250406815 | validation: 0.28789995030832405]
	TIME [epoch: 13.4 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28138373975125247		[learning rate: 0.00088079]
	Learning Rate: 0.000880789
	LOSS [training: 0.28138373975125247 | validation: 0.27623754875001316]
	TIME [epoch: 13.4 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27816637459368615		[learning rate: 0.00087767]
	Learning Rate: 0.000877674
	LOSS [training: 0.27816637459368615 | validation: 0.2745119013784315]
	TIME [epoch: 13.4 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27840200919648167		[learning rate: 0.00087457]
	Learning Rate: 0.000874571
	LOSS [training: 0.27840200919648167 | validation: 0.2739674647966432]
	TIME [epoch: 13.4 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2837966470418801		[learning rate: 0.00087148]
	Learning Rate: 0.000871478
	LOSS [training: 0.2837966470418801 | validation: 0.2773284420770733]
	TIME [epoch: 13.4 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27532919453113647		[learning rate: 0.0008684]
	Learning Rate: 0.000868396
	LOSS [training: 0.27532919453113647 | validation: 0.2731302434536074]
	TIME [epoch: 13.4 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27745548831474104		[learning rate: 0.00086533]
	Learning Rate: 0.000865326
	LOSS [training: 0.27745548831474104 | validation: 0.27764083551038643]
	TIME [epoch: 13.4 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2840236969725169		[learning rate: 0.00086227]
	Learning Rate: 0.000862266
	LOSS [training: 0.2840236969725169 | validation: 0.27049574611120014]
	TIME [epoch: 13.4 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27703714543037034		[learning rate: 0.00085922]
	Learning Rate: 0.000859216
	LOSS [training: 0.27703714543037034 | validation: 0.2758292502485852]
	TIME [epoch: 13.4 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2756572626035282		[learning rate: 0.00085618]
	Learning Rate: 0.000856178
	LOSS [training: 0.2756572626035282 | validation: 0.2729741436111418]
	TIME [epoch: 13.4 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2801456887293965		[learning rate: 0.00085315]
	Learning Rate: 0.00085315
	LOSS [training: 0.2801456887293965 | validation: 0.2705419053736236]
	TIME [epoch: 13.4 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27954282011378834		[learning rate: 0.00085013]
	Learning Rate: 0.000850134
	LOSS [training: 0.27954282011378834 | validation: 0.27768174781562605]
	TIME [epoch: 13.4 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2775597339642579		[learning rate: 0.00084713]
	Learning Rate: 0.000847127
	LOSS [training: 0.2775597339642579 | validation: 0.2791476637582819]
	TIME [epoch: 13.4 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2737192647541073		[learning rate: 0.00084413]
	Learning Rate: 0.000844132
	LOSS [training: 0.2737192647541073 | validation: 0.27027214069110017]
	TIME [epoch: 13.4 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27555360873319623		[learning rate: 0.00084115]
	Learning Rate: 0.000841147
	LOSS [training: 0.27555360873319623 | validation: 0.28003796764511507]
	TIME [epoch: 13.4 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27776539870762473		[learning rate: 0.00083817]
	Learning Rate: 0.000838172
	LOSS [training: 0.27776539870762473 | validation: 0.2729008140047194]
	TIME [epoch: 13.4 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2741644140581002		[learning rate: 0.00083521]
	Learning Rate: 0.000835209
	LOSS [training: 0.2741644140581002 | validation: 0.2746957971385774]
	TIME [epoch: 13.4 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27435740422519556		[learning rate: 0.00083225]
	Learning Rate: 0.000832255
	LOSS [training: 0.27435740422519556 | validation: 0.2675610440679905]
	TIME [epoch: 13.4 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v8_20240715_180006/states/model_facs_v3_dec1b_2dpca_v8_752.pth
	Model improved!!!
EPOCH 753/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27530293449668286		[learning rate: 0.00082931]
	Learning Rate: 0.000829312
	LOSS [training: 0.27530293449668286 | validation: 0.2818904556685098]
	TIME [epoch: 13.4 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27775041552703533		[learning rate: 0.00082638]
	Learning Rate: 0.000826379
	LOSS [training: 0.27775041552703533 | validation: 0.2750695414969052]
	TIME [epoch: 13.4 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27977276103463417		[learning rate: 0.00082346]
	Learning Rate: 0.000823457
	LOSS [training: 0.27977276103463417 | validation: 0.27730956799090367]
	TIME [epoch: 13.4 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2797420843297841		[learning rate: 0.00082055]
	Learning Rate: 0.000820545
	LOSS [training: 0.2797420843297841 | validation: 0.27762777403166317]
	TIME [epoch: 13.4 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27975124169048		[learning rate: 0.00081764]
	Learning Rate: 0.000817644
	LOSS [training: 0.27975124169048 | validation: 0.2805983304596138]
	TIME [epoch: 13.4 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27851992545645793		[learning rate: 0.00081475]
	Learning Rate: 0.000814752
	LOSS [training: 0.27851992545645793 | validation: 0.2688087764721681]
	TIME [epoch: 13.4 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27230640245198606		[learning rate: 0.00081187]
	Learning Rate: 0.000811871
	LOSS [training: 0.27230640245198606 | validation: 0.2728926942110121]
	TIME [epoch: 13.4 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27495569272316983		[learning rate: 0.000809]
	Learning Rate: 0.000809
	LOSS [training: 0.27495569272316983 | validation: 0.27632059629222605]
	TIME [epoch: 13.4 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2708697646363279		[learning rate: 0.00080614]
	Learning Rate: 0.00080614
	LOSS [training: 0.2708697646363279 | validation: 0.2781995669437796]
	TIME [epoch: 13.4 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28039697853992646		[learning rate: 0.00080329]
	Learning Rate: 0.000803289
	LOSS [training: 0.28039697853992646 | validation: 0.2728917277179733]
	TIME [epoch: 13.5 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2768051537968467		[learning rate: 0.00080045]
	Learning Rate: 0.000800448
	LOSS [training: 0.2768051537968467 | validation: 0.28030170891343786]
	TIME [epoch: 13.4 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28202758921474025		[learning rate: 0.00079762]
	Learning Rate: 0.000797618
	LOSS [training: 0.28202758921474025 | validation: 0.280124435373325]
	TIME [epoch: 13.4 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2775018002645047		[learning rate: 0.0007948]
	Learning Rate: 0.000794797
	LOSS [training: 0.2775018002645047 | validation: 0.28305090527664156]
	TIME [epoch: 13.4 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2721064540483466		[learning rate: 0.00079199]
	Learning Rate: 0.000791987
	LOSS [training: 0.2721064540483466 | validation: 0.28029119574731587]
	TIME [epoch: 13.4 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28083625868656376		[learning rate: 0.00078919]
	Learning Rate: 0.000789186
	LOSS [training: 0.28083625868656376 | validation: 0.2755058575105087]
	TIME [epoch: 13.4 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2711659402699091		[learning rate: 0.0007864]
	Learning Rate: 0.000786396
	LOSS [training: 0.2711659402699091 | validation: 0.2728766960500771]
	TIME [epoch: 13.4 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27564586390636164		[learning rate: 0.00078361]
	Learning Rate: 0.000783615
	LOSS [training: 0.27564586390636164 | validation: 0.28477118692775394]
	TIME [epoch: 13.4 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2868445741994931		[learning rate: 0.00078084]
	Learning Rate: 0.000780844
	LOSS [training: 0.2868445741994931 | validation: 0.27535698058423164]
	TIME [epoch: 13.4 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28089390517730983		[learning rate: 0.00077808]
	Learning Rate: 0.000778082
	LOSS [training: 0.28089390517730983 | validation: 0.2762910388838048]
	TIME [epoch: 13.4 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27694661892473577		[learning rate: 0.00077533]
	Learning Rate: 0.000775331
	LOSS [training: 0.27694661892473577 | validation: 0.27799913242364493]
	TIME [epoch: 13.4 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2757002097847246		[learning rate: 0.00077259]
	Learning Rate: 0.000772589
	LOSS [training: 0.2757002097847246 | validation: 0.27824989669442274]
	TIME [epoch: 13.4 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2758776510629553		[learning rate: 0.00076986]
	Learning Rate: 0.000769857
	LOSS [training: 0.2758776510629553 | validation: 0.27482619872421543]
	TIME [epoch: 13.4 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28376850723284835		[learning rate: 0.00076714]
	Learning Rate: 0.000767135
	LOSS [training: 0.28376850723284835 | validation: 0.27612901573514953]
	TIME [epoch: 13.4 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27952607701214927		[learning rate: 0.00076442]
	Learning Rate: 0.000764422
	LOSS [training: 0.27952607701214927 | validation: 0.2740811695280434]
	TIME [epoch: 13.4 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2705671003532224		[learning rate: 0.00076172]
	Learning Rate: 0.000761719
	LOSS [training: 0.2705671003532224 | validation: 0.27621113331275904]
	TIME [epoch: 13.4 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27405124295910926		[learning rate: 0.00075903]
	Learning Rate: 0.000759026
	LOSS [training: 0.27405124295910926 | validation: 0.28090384724556927]
	TIME [epoch: 13.4 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2742144067457832		[learning rate: 0.00075634]
	Learning Rate: 0.000756342
	LOSS [training: 0.2742144067457832 | validation: 0.27800211436445355]
	TIME [epoch: 13.4 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2769296434883652		[learning rate: 0.00075367]
	Learning Rate: 0.000753667
	LOSS [training: 0.2769296434883652 | validation: 0.2830309372633436]
	TIME [epoch: 13.4 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2765682726866296		[learning rate: 0.000751]
	Learning Rate: 0.000751002
	LOSS [training: 0.2765682726866296 | validation: 0.2776558670407499]
	TIME [epoch: 13.4 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27567859614706974		[learning rate: 0.00074835]
	Learning Rate: 0.000748346
	LOSS [training: 0.27567859614706974 | validation: 0.27318606780658006]
	TIME [epoch: 13.4 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27940509281113557		[learning rate: 0.0007457]
	Learning Rate: 0.0007457
	LOSS [training: 0.27940509281113557 | validation: 0.27922806092924823]
	TIME [epoch: 13.4 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27949322816958005		[learning rate: 0.00074306]
	Learning Rate: 0.000743063
	LOSS [training: 0.27949322816958005 | validation: 0.2780362928388814]
	TIME [epoch: 13.4 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27505691273051885		[learning rate: 0.00074044]
	Learning Rate: 0.000740435
	LOSS [training: 0.27505691273051885 | validation: 0.2749594698546634]
	TIME [epoch: 13.4 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2768864703220006		[learning rate: 0.00073782]
	Learning Rate: 0.000737817
	LOSS [training: 0.2768864703220006 | validation: 0.27832401893854397]
	TIME [epoch: 13.4 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2807082440574131		[learning rate: 0.00073521]
	Learning Rate: 0.000735208
	LOSS [training: 0.2807082440574131 | validation: 0.27558687078309]
	TIME [epoch: 13.4 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2711945089371827		[learning rate: 0.00073261]
	Learning Rate: 0.000732608
	LOSS [training: 0.2711945089371827 | validation: 0.27519016128056234]
	TIME [epoch: 13.4 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2811680159507952		[learning rate: 0.00073002]
	Learning Rate: 0.000730018
	LOSS [training: 0.2811680159507952 | validation: 0.2685405328683587]
	TIME [epoch: 13.4 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27488944487207234		[learning rate: 0.00072744]
	Learning Rate: 0.000727436
	LOSS [training: 0.27488944487207234 | validation: 0.27180301948396224]
	TIME [epoch: 13.4 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27394864181900364		[learning rate: 0.00072486]
	Learning Rate: 0.000724864
	LOSS [training: 0.27394864181900364 | validation: 0.2730679988269488]
	TIME [epoch: 13.4 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27418032259297376		[learning rate: 0.0007223]
	Learning Rate: 0.000722301
	LOSS [training: 0.27418032259297376 | validation: 0.2890159011950614]
	TIME [epoch: 13.4 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2799797756289593		[learning rate: 0.00071975]
	Learning Rate: 0.000719746
	LOSS [training: 0.2799797756289593 | validation: 0.27654701842485685]
	TIME [epoch: 13.4 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27343833431539644		[learning rate: 0.0007172]
	Learning Rate: 0.000717201
	LOSS [training: 0.27343833431539644 | validation: 0.2749634065786025]
	TIME [epoch: 13.4 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2726752936131347		[learning rate: 0.00071467]
	Learning Rate: 0.000714665
	LOSS [training: 0.2726752936131347 | validation: 0.27722568569915323]
	TIME [epoch: 13.4 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27691938110343683		[learning rate: 0.00071214]
	Learning Rate: 0.000712138
	LOSS [training: 0.27691938110343683 | validation: 0.2659541785443236]
	TIME [epoch: 13.4 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v8_20240715_180006/states/model_facs_v3_dec1b_2dpca_v8_796.pth
	Model improved!!!
EPOCH 797/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2759169271850402		[learning rate: 0.00070962]
	Learning Rate: 0.00070962
	LOSS [training: 0.2759169271850402 | validation: 0.28397866842503566]
	TIME [epoch: 13.4 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2764661439955065		[learning rate: 0.00070711]
	Learning Rate: 0.00070711
	LOSS [training: 0.2764661439955065 | validation: 0.27537307797368576]
	TIME [epoch: 13.4 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27751064463918745		[learning rate: 0.00070461]
	Learning Rate: 0.00070461
	LOSS [training: 0.27751064463918745 | validation: 0.28022020757658783]
	TIME [epoch: 13.4 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2772759392293667		[learning rate: 0.00070212]
	Learning Rate: 0.000702118
	LOSS [training: 0.2772759392293667 | validation: 0.2759688920127199]
	TIME [epoch: 13.4 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2750054892426692		[learning rate: 0.00069964]
	Learning Rate: 0.000699635
	LOSS [training: 0.2750054892426692 | validation: 0.2788285760488364]
	TIME [epoch: 13.4 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27220273803040457		[learning rate: 0.00069716]
	Learning Rate: 0.000697161
	LOSS [training: 0.27220273803040457 | validation: 0.27696964247384803]
	TIME [epoch: 13.4 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27764120874740933		[learning rate: 0.0006947]
	Learning Rate: 0.000694696
	LOSS [training: 0.27764120874740933 | validation: 0.27444107040230453]
	TIME [epoch: 13.4 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2719888860101953		[learning rate: 0.00069224]
	Learning Rate: 0.00069224
	LOSS [training: 0.2719888860101953 | validation: 0.2682888956282795]
	TIME [epoch: 13.4 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.275548657512544		[learning rate: 0.00068979]
	Learning Rate: 0.000689792
	LOSS [training: 0.275548657512544 | validation: 0.28391771467614246]
	TIME [epoch: 13.4 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2746167598578704		[learning rate: 0.00068735]
	Learning Rate: 0.000687352
	LOSS [training: 0.2746167598578704 | validation: 0.27730572084218647]
	TIME [epoch: 13.4 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2754539298398232		[learning rate: 0.00068492]
	Learning Rate: 0.000684922
	LOSS [training: 0.2754539298398232 | validation: 0.2764606466780913]
	TIME [epoch: 13.4 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2702277218909142		[learning rate: 0.0006825]
	Learning Rate: 0.0006825
	LOSS [training: 0.2702277218909142 | validation: 0.2702222806293299]
	TIME [epoch: 13.4 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27530888113838986		[learning rate: 0.00068009]
	Learning Rate: 0.000680086
	LOSS [training: 0.27530888113838986 | validation: 0.2852207965399932]
	TIME [epoch: 13.4 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26962481104845154		[learning rate: 0.00067768]
	Learning Rate: 0.000677682
	LOSS [training: 0.26962481104845154 | validation: 0.2718408552682523]
	TIME [epoch: 13.4 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27362614300620525		[learning rate: 0.00067529]
	Learning Rate: 0.000675285
	LOSS [training: 0.27362614300620525 | validation: 0.2761083652673213]
	TIME [epoch: 13.5 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2756123950380782		[learning rate: 0.0006729]
	Learning Rate: 0.000672897
	LOSS [training: 0.2756123950380782 | validation: 0.27287476208857225]
	TIME [epoch: 13.4 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.274682608577237		[learning rate: 0.00067052]
	Learning Rate: 0.000670518
	LOSS [training: 0.274682608577237 | validation: 0.26769214927177115]
	TIME [epoch: 13.4 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27198956968970867		[learning rate: 0.00066815]
	Learning Rate: 0.000668147
	LOSS [training: 0.27198956968970867 | validation: 0.2699557321482036]
	TIME [epoch: 13.4 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2764057756350105		[learning rate: 0.00066578]
	Learning Rate: 0.000665784
	LOSS [training: 0.2764057756350105 | validation: 0.2755277485347877]
	TIME [epoch: 13.4 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2781407550071063		[learning rate: 0.00066343]
	Learning Rate: 0.00066343
	LOSS [training: 0.2781407550071063 | validation: 0.27794926053576613]
	TIME [epoch: 13.4 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2786670970157468		[learning rate: 0.00066108]
	Learning Rate: 0.000661084
	LOSS [training: 0.2786670970157468 | validation: 0.27489402878292835]
	TIME [epoch: 13.4 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27857258023955084		[learning rate: 0.00065875]
	Learning Rate: 0.000658746
	LOSS [training: 0.27857258023955084 | validation: 0.27605506512583056]
	TIME [epoch: 13.4 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2826325844943649		[learning rate: 0.00065642]
	Learning Rate: 0.000656417
	LOSS [training: 0.2826325844943649 | validation: 0.27285119938417113]
	TIME [epoch: 13.4 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27415721613100497		[learning rate: 0.0006541]
	Learning Rate: 0.000654095
	LOSS [training: 0.27415721613100497 | validation: 0.27339958730157227]
	TIME [epoch: 13.4 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2765784333447316		[learning rate: 0.00065178]
	Learning Rate: 0.000651782
	LOSS [training: 0.2765784333447316 | validation: 0.270058141872275]
	TIME [epoch: 13.4 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27291546647168		[learning rate: 0.00064948]
	Learning Rate: 0.000649477
	LOSS [training: 0.27291546647168 | validation: 0.28834772714566176]
	TIME [epoch: 13.4 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27711003473074663		[learning rate: 0.00064718]
	Learning Rate: 0.000647181
	LOSS [training: 0.27711003473074663 | validation: 0.2723617095618747]
	TIME [epoch: 13.4 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2775361171199135		[learning rate: 0.00064489]
	Learning Rate: 0.000644892
	LOSS [training: 0.2775361171199135 | validation: 0.2709369475391417]
	TIME [epoch: 13.4 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2707329792118647		[learning rate: 0.00064261]
	Learning Rate: 0.000642612
	LOSS [training: 0.2707329792118647 | validation: 0.2755319822007153]
	TIME [epoch: 13.4 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2765144815281482		[learning rate: 0.00064034]
	Learning Rate: 0.000640339
	LOSS [training: 0.2765144815281482 | validation: 0.28126170082425617]
	TIME [epoch: 13.4 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27964481132945734		[learning rate: 0.00063808]
	Learning Rate: 0.000638075
	LOSS [training: 0.27964481132945734 | validation: 0.27194556668894226]
	TIME [epoch: 13.4 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27471596956537564		[learning rate: 0.00063582]
	Learning Rate: 0.000635819
	LOSS [training: 0.27471596956537564 | validation: 0.2779312250391932]
	TIME [epoch: 13.4 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2784713319990295		[learning rate: 0.00063357]
	Learning Rate: 0.00063357
	LOSS [training: 0.2784713319990295 | validation: 0.2731868308093442]
	TIME [epoch: 13.4 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2721034491987815		[learning rate: 0.00063133]
	Learning Rate: 0.00063133
	LOSS [training: 0.2721034491987815 | validation: 0.27066919697052183]
	TIME [epoch: 13.4 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2696229746408301		[learning rate: 0.0006291]
	Learning Rate: 0.000629098
	LOSS [training: 0.2696229746408301 | validation: 0.2740419161108609]
	TIME [epoch: 13.4 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27212927543596954		[learning rate: 0.00062687]
	Learning Rate: 0.000626873
	LOSS [training: 0.27212927543596954 | validation: 0.2723161205444618]
	TIME [epoch: 13.4 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27321379305144816		[learning rate: 0.00062466]
	Learning Rate: 0.000624656
	LOSS [training: 0.27321379305144816 | validation: 0.27579411501099915]
	TIME [epoch: 13.4 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2721290290770952		[learning rate: 0.00062245]
	Learning Rate: 0.000622447
	LOSS [training: 0.2721290290770952 | validation: 0.27493077060706395]
	TIME [epoch: 13.4 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2728717418156226		[learning rate: 0.00062025]
	Learning Rate: 0.000620246
	LOSS [training: 0.2728717418156226 | validation: 0.2683606723772011]
	TIME [epoch: 13.4 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2762263215725968		[learning rate: 0.00061805]
	Learning Rate: 0.000618053
	LOSS [training: 0.2762263215725968 | validation: 0.2762759748491393]
	TIME [epoch: 13.4 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27377664370667926		[learning rate: 0.00061587]
	Learning Rate: 0.000615867
	LOSS [training: 0.27377664370667926 | validation: 0.2749246174408018]
	TIME [epoch: 13.4 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2676766086449859		[learning rate: 0.00061369]
	Learning Rate: 0.00061369
	LOSS [training: 0.2676766086449859 | validation: 0.2721205522615152]
	TIME [epoch: 13.4 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27114944661098983		[learning rate: 0.00061152]
	Learning Rate: 0.000611519
	LOSS [training: 0.27114944661098983 | validation: 0.2681273097271708]
	TIME [epoch: 13.4 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27567973813030755		[learning rate: 0.00060936]
	Learning Rate: 0.000609357
	LOSS [training: 0.27567973813030755 | validation: 0.2848692125640616]
	TIME [epoch: 13.4 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.271666361039227		[learning rate: 0.0006072]
	Learning Rate: 0.000607202
	LOSS [training: 0.271666361039227 | validation: 0.27275353916682954]
	TIME [epoch: 13.4 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.273559131300987		[learning rate: 0.00060506]
	Learning Rate: 0.000605055
	LOSS [training: 0.273559131300987 | validation: 0.2710418611417235]
	TIME [epoch: 13.4 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2760169255652944		[learning rate: 0.00060292]
	Learning Rate: 0.000602915
	LOSS [training: 0.2760169255652944 | validation: 0.26861063949977265]
	TIME [epoch: 13.4 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27466045358558927		[learning rate: 0.00060078]
	Learning Rate: 0.000600784
	LOSS [training: 0.27466045358558927 | validation: 0.2715816174463977]
	TIME [epoch: 13.4 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2715573788835078		[learning rate: 0.00059866]
	Learning Rate: 0.000598659
	LOSS [training: 0.2715573788835078 | validation: 0.28062770305302676]
	TIME [epoch: 13.4 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2771210947264707		[learning rate: 0.00059654]
	Learning Rate: 0.000596542
	LOSS [training: 0.2771210947264707 | validation: 0.27103222981403763]
	TIME [epoch: 13.4 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2667929158365067		[learning rate: 0.00059443]
	Learning Rate: 0.000594432
	LOSS [training: 0.2667929158365067 | validation: 0.27649406644830676]
	TIME [epoch: 13.4 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2702622768501631		[learning rate: 0.00059233]
	Learning Rate: 0.00059233
	LOSS [training: 0.2702622768501631 | validation: 0.27296837157005266]
	TIME [epoch: 13.4 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2794491425155906		[learning rate: 0.00059024]
	Learning Rate: 0.000590236
	LOSS [training: 0.2794491425155906 | validation: 0.26445964382718823]
	TIME [epoch: 13.4 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v8_20240715_180006/states/model_facs_v3_dec1b_2dpca_v8_849.pth
	Model improved!!!
EPOCH 850/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2762515110332297		[learning rate: 0.00058815]
	Learning Rate: 0.000588149
	LOSS [training: 0.2762515110332297 | validation: 0.2716345547913327]
	TIME [epoch: 13.4 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27292254276453004		[learning rate: 0.00058607]
	Learning Rate: 0.000586069
	LOSS [training: 0.27292254276453004 | validation: 0.27819071706861426]
	TIME [epoch: 13.4 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2756565898004724		[learning rate: 0.000584]
	Learning Rate: 0.000583996
	LOSS [training: 0.2756565898004724 | validation: 0.2719258168662682]
	TIME [epoch: 13.4 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27406246315442256		[learning rate: 0.00058193]
	Learning Rate: 0.000581931
	LOSS [training: 0.27406246315442256 | validation: 0.2673967472220469]
	TIME [epoch: 13.4 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2722734027507414		[learning rate: 0.00057987]
	Learning Rate: 0.000579874
	LOSS [training: 0.2722734027507414 | validation: 0.2773697278653485]
	TIME [epoch: 13.4 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2742909059378768		[learning rate: 0.00057782]
	Learning Rate: 0.000577823
	LOSS [training: 0.2742909059378768 | validation: 0.2740056175182726]
	TIME [epoch: 13.4 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2774063873654428		[learning rate: 0.00057578]
	Learning Rate: 0.00057578
	LOSS [training: 0.2774063873654428 | validation: 0.2703039650816072]
	TIME [epoch: 13.4 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2758976455223538		[learning rate: 0.00057374]
	Learning Rate: 0.000573744
	LOSS [training: 0.2758976455223538 | validation: 0.27762464971962025]
	TIME [epoch: 13.4 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2725585103453619		[learning rate: 0.00057171]
	Learning Rate: 0.000571715
	LOSS [training: 0.2725585103453619 | validation: 0.27317295651787493]
	TIME [epoch: 13.4 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.272484610523071		[learning rate: 0.00056969]
	Learning Rate: 0.000569693
	LOSS [training: 0.272484610523071 | validation: 0.27771358028778403]
	TIME [epoch: 13.4 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27831086561912494		[learning rate: 0.00056768]
	Learning Rate: 0.000567679
	LOSS [training: 0.27831086561912494 | validation: 0.2812296293441682]
	TIME [epoch: 13.4 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27614778738133045		[learning rate: 0.00056567]
	Learning Rate: 0.000565671
	LOSS [training: 0.27614778738133045 | validation: 0.2702714206123241]
	TIME [epoch: 13.4 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27343942065566196		[learning rate: 0.00056367]
	Learning Rate: 0.000563671
	LOSS [training: 0.27343942065566196 | validation: 0.27759330188940023]
	TIME [epoch: 13.4 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27494928823444725		[learning rate: 0.00056168]
	Learning Rate: 0.000561678
	LOSS [training: 0.27494928823444725 | validation: 0.2760197825066728]
	TIME [epoch: 13.4 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.267898116814628		[learning rate: 0.00055969]
	Learning Rate: 0.000559692
	LOSS [training: 0.267898116814628 | validation: 0.2707037145554488]
	TIME [epoch: 13.4 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2725258656110735		[learning rate: 0.00055771]
	Learning Rate: 0.000557712
	LOSS [training: 0.2725258656110735 | validation: 0.2786619264483063]
	TIME [epoch: 13.4 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26786250637272774		[learning rate: 0.00055574]
	Learning Rate: 0.00055574
	LOSS [training: 0.26786250637272774 | validation: 0.27528222350717796]
	TIME [epoch: 13.4 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27323078660403377		[learning rate: 0.00055377]
	Learning Rate: 0.000553775
	LOSS [training: 0.27323078660403377 | validation: 0.28187811142110686]
	TIME [epoch: 13.4 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2762249914412075		[learning rate: 0.00055182]
	Learning Rate: 0.000551817
	LOSS [training: 0.2762249914412075 | validation: 0.27727579695626975]
	TIME [epoch: 13.4 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27527761111940535		[learning rate: 0.00054987]
	Learning Rate: 0.000549865
	LOSS [training: 0.27527761111940535 | validation: 0.2787465035586358]
	TIME [epoch: 13.4 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2761428665701318		[learning rate: 0.00054792]
	Learning Rate: 0.000547921
	LOSS [training: 0.2761428665701318 | validation: 0.27251664134563514]
	TIME [epoch: 13.4 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26780483276764727		[learning rate: 0.00054598]
	Learning Rate: 0.000545983
	LOSS [training: 0.26780483276764727 | validation: 0.2784568231397277]
	TIME [epoch: 13.4 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27465401677344187		[learning rate: 0.00054405]
	Learning Rate: 0.000544053
	LOSS [training: 0.27465401677344187 | validation: 0.2751685226295727]
	TIME [epoch: 13.4 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2726108450761173		[learning rate: 0.00054213]
	Learning Rate: 0.000542129
	LOSS [training: 0.2726108450761173 | validation: 0.27087206042439227]
	TIME [epoch: 13.4 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27168971136339		[learning rate: 0.00054021]
	Learning Rate: 0.000540212
	LOSS [training: 0.27168971136339 | validation: 0.2797799766819794]
	TIME [epoch: 13.4 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26830672235322384		[learning rate: 0.0005383]
	Learning Rate: 0.000538302
	LOSS [training: 0.26830672235322384 | validation: 0.2729124787977568]
	TIME [epoch: 13.4 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27086387646921667		[learning rate: 0.0005364]
	Learning Rate: 0.000536398
	LOSS [training: 0.27086387646921667 | validation: 0.2901851291859146]
	TIME [epoch: 13.4 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2751447699378362		[learning rate: 0.0005345]
	Learning Rate: 0.000534501
	LOSS [training: 0.2751447699378362 | validation: 0.2809053227849525]
	TIME [epoch: 13.4 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27369467215381066		[learning rate: 0.00053261]
	Learning Rate: 0.000532611
	LOSS [training: 0.27369467215381066 | validation: 0.2763096664292891]
	TIME [epoch: 13.4 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26761100456440434		[learning rate: 0.00053073]
	Learning Rate: 0.000530728
	LOSS [training: 0.26761100456440434 | validation: 0.27329095146051136]
	TIME [epoch: 13.4 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2747478181299949		[learning rate: 0.00052885]
	Learning Rate: 0.000528851
	LOSS [training: 0.2747478181299949 | validation: 0.27804631849521366]
	TIME [epoch: 13.4 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27169498686660926		[learning rate: 0.00052698]
	Learning Rate: 0.000526981
	LOSS [training: 0.27169498686660926 | validation: 0.28097538854993037]
	TIME [epoch: 13.4 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.273322988749941		[learning rate: 0.00052512]
	Learning Rate: 0.000525117
	LOSS [training: 0.273322988749941 | validation: 0.2722350865591141]
	TIME [epoch: 13.4 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2717285351194219		[learning rate: 0.00052326]
	Learning Rate: 0.000523261
	LOSS [training: 0.2717285351194219 | validation: 0.28267662496442764]
	TIME [epoch: 13.4 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2754031930436777		[learning rate: 0.00052141]
	Learning Rate: 0.00052141
	LOSS [training: 0.2754031930436777 | validation: 0.27622879733742156]
	TIME [epoch: 13.4 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2779673046752674		[learning rate: 0.00051957]
	Learning Rate: 0.000519566
	LOSS [training: 0.2779673046752674 | validation: 0.2746194408379779]
	TIME [epoch: 13.4 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2748088903981376		[learning rate: 0.00051773]
	Learning Rate: 0.000517729
	LOSS [training: 0.2748088903981376 | validation: 0.26781958247663173]
	TIME [epoch: 13.4 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27545577014675493		[learning rate: 0.0005159]
	Learning Rate: 0.000515898
	LOSS [training: 0.27545577014675493 | validation: 0.2697503900434316]
	TIME [epoch: 13.4 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2688930300771926		[learning rate: 0.00051407]
	Learning Rate: 0.000514074
	LOSS [training: 0.2688930300771926 | validation: 0.26896369306146994]
	TIME [epoch: 13.4 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26526750949637146		[learning rate: 0.00051226]
	Learning Rate: 0.000512256
	LOSS [training: 0.26526750949637146 | validation: 0.27811084824510357]
	TIME [epoch: 13.4 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2711739288304202		[learning rate: 0.00051044]
	Learning Rate: 0.000510445
	LOSS [training: 0.2711739288304202 | validation: 0.2728289370292444]
	TIME [epoch: 13.4 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27090048880063133		[learning rate: 0.00050864]
	Learning Rate: 0.00050864
	LOSS [training: 0.27090048880063133 | validation: 0.2691042540663525]
	TIME [epoch: 13.4 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.274384019701117		[learning rate: 0.00050684]
	Learning Rate: 0.000506841
	LOSS [training: 0.274384019701117 | validation: 0.2720039831074147]
	TIME [epoch: 13.4 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.269876852126308		[learning rate: 0.00050505]
	Learning Rate: 0.000505049
	LOSS [training: 0.269876852126308 | validation: 0.273174692393996]
	TIME [epoch: 13.4 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2652714124230581		[learning rate: 0.00050326]
	Learning Rate: 0.000503263
	LOSS [training: 0.2652714124230581 | validation: 0.27047336304416997]
	TIME [epoch: 13.4 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2768643026742354		[learning rate: 0.00050148]
	Learning Rate: 0.000501483
	LOSS [training: 0.2768643026742354 | validation: 0.2789054228537767]
	TIME [epoch: 13.4 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2699037645399177		[learning rate: 0.00049971]
	Learning Rate: 0.00049971
	LOSS [training: 0.2699037645399177 | validation: 0.27269156648328524]
	TIME [epoch: 13.4 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2728007015097064		[learning rate: 0.00049794]
	Learning Rate: 0.000497943
	LOSS [training: 0.2728007015097064 | validation: 0.268877908771072]
	TIME [epoch: 13.4 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.271298098401273		[learning rate: 0.00049618]
	Learning Rate: 0.000496182
	LOSS [training: 0.271298098401273 | validation: 0.2702678822212946]
	TIME [epoch: 13.4 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26916716656410783		[learning rate: 0.00049443]
	Learning Rate: 0.000494427
	LOSS [training: 0.26916716656410783 | validation: 0.2753351019365758]
	TIME [epoch: 13.4 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.276310790831169		[learning rate: 0.00049268]
	Learning Rate: 0.000492679
	LOSS [training: 0.276310790831169 | validation: 0.26667952851664917]
	TIME [epoch: 13.4 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27773528236802286		[learning rate: 0.00049094]
	Learning Rate: 0.000490937
	LOSS [training: 0.27773528236802286 | validation: 0.28300756990359466]
	TIME [epoch: 13.4 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2756302873262567		[learning rate: 0.0004892]
	Learning Rate: 0.000489201
	LOSS [training: 0.2756302873262567 | validation: 0.27204796300585016]
	TIME [epoch: 13.4 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27323807133465866		[learning rate: 0.00048747]
	Learning Rate: 0.000487471
	LOSS [training: 0.27323807133465866 | validation: 0.2720924921616899]
	TIME [epoch: 13.4 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2726204117456216		[learning rate: 0.00048575]
	Learning Rate: 0.000485747
	LOSS [training: 0.2726204117456216 | validation: 0.27141577102871783]
	TIME [epoch: 13.4 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2706100699167437		[learning rate: 0.00048403]
	Learning Rate: 0.000484029
	LOSS [training: 0.2706100699167437 | validation: 0.26433367613746467]
	TIME [epoch: 13.4 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v8_20240715_180006/states/model_facs_v3_dec1b_2dpca_v8_905.pth
	Model improved!!!
EPOCH 906/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2724817343388964		[learning rate: 0.00048232]
	Learning Rate: 0.000482318
	LOSS [training: 0.2724817343388964 | validation: 0.2767155501690433]
	TIME [epoch: 13.4 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27181665618004974		[learning rate: 0.00048061]
	Learning Rate: 0.000480612
	LOSS [training: 0.27181665618004974 | validation: 0.280605106672862]
	TIME [epoch: 13.4 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27595335307448265		[learning rate: 0.00047891]
	Learning Rate: 0.000478913
	LOSS [training: 0.27595335307448265 | validation: 0.27181991588729437]
	TIME [epoch: 13.4 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2778217707767729		[learning rate: 0.00047722]
	Learning Rate: 0.000477219
	LOSS [training: 0.2778217707767729 | validation: 0.26988724494843963]
	TIME [epoch: 13.4 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27190564728558203		[learning rate: 0.00047553]
	Learning Rate: 0.000475532
	LOSS [training: 0.27190564728558203 | validation: 0.2753493790233499]
	TIME [epoch: 13.4 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27141251156843665		[learning rate: 0.00047385]
	Learning Rate: 0.00047385
	LOSS [training: 0.27141251156843665 | validation: 0.2752086031754633]
	TIME [epoch: 13.4 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27658659435928173		[learning rate: 0.00047217]
	Learning Rate: 0.000472175
	LOSS [training: 0.27658659435928173 | validation: 0.2760510155111713]
	TIME [epoch: 13.4 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26845137408462877		[learning rate: 0.0004705]
	Learning Rate: 0.000470505
	LOSS [training: 0.26845137408462877 | validation: 0.2718485314929463]
	TIME [epoch: 13.4 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2707856278461273		[learning rate: 0.00046884]
	Learning Rate: 0.000468841
	LOSS [training: 0.2707856278461273 | validation: 0.2656027950650672]
	TIME [epoch: 13.4 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2681705430362087		[learning rate: 0.00046718]
	Learning Rate: 0.000467183
	LOSS [training: 0.2681705430362087 | validation: 0.273752248903357]
	TIME [epoch: 13.4 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26870056092896727		[learning rate: 0.00046553]
	Learning Rate: 0.000465531
	LOSS [training: 0.26870056092896727 | validation: 0.27215153758234073]
	TIME [epoch: 13.4 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2715182929024418		[learning rate: 0.00046388]
	Learning Rate: 0.000463885
	LOSS [training: 0.2715182929024418 | validation: 0.2780015367836131]
	TIME [epoch: 13.4 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2708844857783192		[learning rate: 0.00046224]
	Learning Rate: 0.000462245
	LOSS [training: 0.2708844857783192 | validation: 0.27528744655325765]
	TIME [epoch: 13.4 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2677891269618758		[learning rate: 0.00046061]
	Learning Rate: 0.00046061
	LOSS [training: 0.2677891269618758 | validation: 0.28305089181486165]
	TIME [epoch: 13.4 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27708604931221864		[learning rate: 0.00045898]
	Learning Rate: 0.000458981
	LOSS [training: 0.27708604931221864 | validation: 0.2820943762626496]
	TIME [epoch: 13.4 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2737666546693582		[learning rate: 0.00045736]
	Learning Rate: 0.000457358
	LOSS [training: 0.2737666546693582 | validation: 0.27780424489479627]
	TIME [epoch: 13.4 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2717915390205518		[learning rate: 0.00045574]
	Learning Rate: 0.000455741
	LOSS [training: 0.2717915390205518 | validation: 0.27557823247365765]
	TIME [epoch: 13.4 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2754667580724388		[learning rate: 0.00045413]
	Learning Rate: 0.000454129
	LOSS [training: 0.2754667580724388 | validation: 0.2722151416387698]
	TIME [epoch: 13.4 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2702355164781433		[learning rate: 0.00045252]
	Learning Rate: 0.000452523
	LOSS [training: 0.2702355164781433 | validation: 0.26783298288171087]
	TIME [epoch: 13.4 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27249063084437436		[learning rate: 0.00045092]
	Learning Rate: 0.000450923
	LOSS [training: 0.27249063084437436 | validation: 0.27553660192342233]
	TIME [epoch: 13.4 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26717201138208624		[learning rate: 0.00044933]
	Learning Rate: 0.000449329
	LOSS [training: 0.26717201138208624 | validation: 0.28097543259448937]
	TIME [epoch: 13.4 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27210326681164976		[learning rate: 0.00044774]
	Learning Rate: 0.00044774
	LOSS [training: 0.27210326681164976 | validation: 0.27573815426529713]
	TIME [epoch: 13.4 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26989741182173277		[learning rate: 0.00044616]
	Learning Rate: 0.000446156
	LOSS [training: 0.26989741182173277 | validation: 0.27221230460372825]
	TIME [epoch: 13.4 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2710600653753959		[learning rate: 0.00044458]
	Learning Rate: 0.000444579
	LOSS [training: 0.2710600653753959 | validation: 0.26978307232450505]
	TIME [epoch: 13.4 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2709275750240113		[learning rate: 0.00044301]
	Learning Rate: 0.000443007
	LOSS [training: 0.2709275750240113 | validation: 0.27425599124635874]
	TIME [epoch: 13.4 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27317696376758		[learning rate: 0.00044144]
	Learning Rate: 0.00044144
	LOSS [training: 0.27317696376758 | validation: 0.27510864943245605]
	TIME [epoch: 13.4 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27263666737117215		[learning rate: 0.00043988]
	Learning Rate: 0.000439879
	LOSS [training: 0.27263666737117215 | validation: 0.26822934683650923]
	TIME [epoch: 13.4 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2701365579527377		[learning rate: 0.00043832]
	Learning Rate: 0.000438324
	LOSS [training: 0.2701365579527377 | validation: 0.2673836896951892]
	TIME [epoch: 13.4 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2821005785454931		[learning rate: 0.00043677]
	Learning Rate: 0.000436774
	LOSS [training: 0.2821005785454931 | validation: 0.26620526021776997]
	TIME [epoch: 13.4 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27254000073747836		[learning rate: 0.00043523]
	Learning Rate: 0.000435229
	LOSS [training: 0.27254000073747836 | validation: 0.26772143701641266]
	TIME [epoch: 13.4 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2675141636517438		[learning rate: 0.00043369]
	Learning Rate: 0.00043369
	LOSS [training: 0.2675141636517438 | validation: 0.2620636859746316]
	TIME [epoch: 13.4 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v8_20240715_180006/states/model_facs_v3_dec1b_2dpca_v8_936.pth
	Model improved!!!
EPOCH 937/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26601239884334266		[learning rate: 0.00043216]
	Learning Rate: 0.000432156
	LOSS [training: 0.26601239884334266 | validation: 0.27782899639027087]
	TIME [epoch: 13.4 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27208814171167556		[learning rate: 0.00043063]
	Learning Rate: 0.000430628
	LOSS [training: 0.27208814171167556 | validation: 0.28262314809349914]
	TIME [epoch: 13.4 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.275062505670354		[learning rate: 0.00042911]
	Learning Rate: 0.000429106
	LOSS [training: 0.275062505670354 | validation: 0.28130807597044494]
	TIME [epoch: 13.4 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27147754295760534		[learning rate: 0.00042759]
	Learning Rate: 0.000427588
	LOSS [training: 0.27147754295760534 | validation: 0.2794392714269528]
	TIME [epoch: 13.4 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2739550757193346		[learning rate: 0.00042608]
	Learning Rate: 0.000426076
	LOSS [training: 0.2739550757193346 | validation: 0.2659957327447676]
	TIME [epoch: 13.4 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2716050429307208		[learning rate: 0.00042457]
	Learning Rate: 0.000424569
	LOSS [training: 0.2716050429307208 | validation: 0.28378688406044417]
	TIME [epoch: 13.4 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.269755421160125		[learning rate: 0.00042307]
	Learning Rate: 0.000423068
	LOSS [training: 0.269755421160125 | validation: 0.27273053112099077]
	TIME [epoch: 13.4 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2687655992342573		[learning rate: 0.00042157]
	Learning Rate: 0.000421572
	LOSS [training: 0.2687655992342573 | validation: 0.26843884695272935]
	TIME [epoch: 13.4 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27384929237625527		[learning rate: 0.00042008]
	Learning Rate: 0.000420081
	LOSS [training: 0.27384929237625527 | validation: 0.2709257050197146]
	TIME [epoch: 13.4 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27250223509235866		[learning rate: 0.0004186]
	Learning Rate: 0.000418596
	LOSS [training: 0.27250223509235866 | validation: 0.2763608206306599]
	TIME [epoch: 13.4 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27116752261214483		[learning rate: 0.00041712]
	Learning Rate: 0.000417116
	LOSS [training: 0.27116752261214483 | validation: 0.27122147097897775]
	TIME [epoch: 13.4 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27020979333477774		[learning rate: 0.00041564]
	Learning Rate: 0.000415641
	LOSS [training: 0.27020979333477774 | validation: 0.27584288144114655]
	TIME [epoch: 13.4 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26937068608467757		[learning rate: 0.00041417]
	Learning Rate: 0.000414171
	LOSS [training: 0.26937068608467757 | validation: 0.2756100384485987]
	TIME [epoch: 13.4 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2685508894399768		[learning rate: 0.00041271]
	Learning Rate: 0.000412706
	LOSS [training: 0.2685508894399768 | validation: 0.2683360403794138]
	TIME [epoch: 13.4 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2690270599815921		[learning rate: 0.00041125]
	Learning Rate: 0.000411247
	LOSS [training: 0.2690270599815921 | validation: 0.26682672713731165]
	TIME [epoch: 13.4 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2670719513520663		[learning rate: 0.00040979]
	Learning Rate: 0.000409793
	LOSS [training: 0.2670719513520663 | validation: 0.26843330302366]
	TIME [epoch: 13.4 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26889990262316316		[learning rate: 0.00040834]
	Learning Rate: 0.000408344
	LOSS [training: 0.26889990262316316 | validation: 0.2759814721880515]
	TIME [epoch: 13.4 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2672097412580563		[learning rate: 0.0004069]
	Learning Rate: 0.0004069
	LOSS [training: 0.2672097412580563 | validation: 0.2797837409922989]
	TIME [epoch: 13.4 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2691482036851459		[learning rate: 0.00040546]
	Learning Rate: 0.000405461
	LOSS [training: 0.2691482036851459 | validation: 0.28727582808909563]
	TIME [epoch: 13.4 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27256821955100663		[learning rate: 0.00040403]
	Learning Rate: 0.000404027
	LOSS [training: 0.27256821955100663 | validation: 0.28308288118831443]
	TIME [epoch: 13.4 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2678543207445477		[learning rate: 0.0004026]
	Learning Rate: 0.000402598
	LOSS [training: 0.2678543207445477 | validation: 0.27284022549066506]
	TIME [epoch: 13.4 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27246088736225454		[learning rate: 0.00040117]
	Learning Rate: 0.000401175
	LOSS [training: 0.27246088736225454 | validation: 0.2727474125534528]
	TIME [epoch: 13.4 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2763990900718671		[learning rate: 0.00039976]
	Learning Rate: 0.000399756
	LOSS [training: 0.2763990900718671 | validation: 0.2690875968221231]
	TIME [epoch: 13.4 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2717933584338509		[learning rate: 0.00039834]
	Learning Rate: 0.000398342
	LOSS [training: 0.2717933584338509 | validation: 0.2683600587262049]
	TIME [epoch: 13.4 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.270320123302428		[learning rate: 0.00039693]
	Learning Rate: 0.000396934
	LOSS [training: 0.270320123302428 | validation: 0.26684467180286997]
	TIME [epoch: 13.4 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2751784104164011		[learning rate: 0.00039553]
	Learning Rate: 0.00039553
	LOSS [training: 0.2751784104164011 | validation: 0.27304854867113415]
	TIME [epoch: 13.4 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2735769702649955		[learning rate: 0.00039413]
	Learning Rate: 0.000394131
	LOSS [training: 0.2735769702649955 | validation: 0.28110326241710704]
	TIME [epoch: 13.4 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27038319898048696		[learning rate: 0.00039274]
	Learning Rate: 0.000392738
	LOSS [training: 0.27038319898048696 | validation: 0.2768842025528703]
	TIME [epoch: 13.4 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2691778734527685		[learning rate: 0.00039135]
	Learning Rate: 0.000391349
	LOSS [training: 0.2691778734527685 | validation: 0.27065574608867193]
	TIME [epoch: 13.4 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2699532151777757		[learning rate: 0.00038997]
	Learning Rate: 0.000389965
	LOSS [training: 0.2699532151777757 | validation: 0.2727155211902135]
	TIME [epoch: 13.4 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2784216846028608		[learning rate: 0.00038859]
	Learning Rate: 0.000388586
	LOSS [training: 0.2784216846028608 | validation: 0.2714252622864858]
	TIME [epoch: 13.4 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27785079472662916		[learning rate: 0.00038721]
	Learning Rate: 0.000387212
	LOSS [training: 0.27785079472662916 | validation: 0.2702409526553141]
	TIME [epoch: 13.4 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2708143840845016		[learning rate: 0.00038584]
	Learning Rate: 0.000385843
	LOSS [training: 0.2708143840845016 | validation: 0.26820904673528484]
	TIME [epoch: 13.4 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2699139222651059		[learning rate: 0.00038448]
	Learning Rate: 0.000384478
	LOSS [training: 0.2699139222651059 | validation: 0.2614569507117529]
	TIME [epoch: 13.4 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v8_20240715_180006/states/model_facs_v3_dec1b_2dpca_v8_970.pth
	Model improved!!!
EPOCH 971/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2713417375144923		[learning rate: 0.00038312]
	Learning Rate: 0.000383119
	LOSS [training: 0.2713417375144923 | validation: 0.2710604235588089]
	TIME [epoch: 13.4 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27273552877751484		[learning rate: 0.00038176]
	Learning Rate: 0.000381764
	LOSS [training: 0.27273552877751484 | validation: 0.2744634162261209]
	TIME [epoch: 13.4 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2716871083142974		[learning rate: 0.00038041]
	Learning Rate: 0.000380414
	LOSS [training: 0.2716871083142974 | validation: 0.2696543690212464]
	TIME [epoch: 13.4 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2685897150560789		[learning rate: 0.00037907]
	Learning Rate: 0.000379069
	LOSS [training: 0.2685897150560789 | validation: 0.2688398685127665]
	TIME [epoch: 13.4 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2675817935310127		[learning rate: 0.00037773]
	Learning Rate: 0.000377728
	LOSS [training: 0.2675817935310127 | validation: 0.27750609783280605]
	TIME [epoch: 13.4 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27520038785756945		[learning rate: 0.00037639]
	Learning Rate: 0.000376393
	LOSS [training: 0.27520038785756945 | validation: 0.28353469671607656]
	TIME [epoch: 13.4 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27372510274812645		[learning rate: 0.00037506]
	Learning Rate: 0.000375062
	LOSS [training: 0.27372510274812645 | validation: 0.29140796627650584]
	TIME [epoch: 13.4 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27283931471787426		[learning rate: 0.00037374]
	Learning Rate: 0.000373735
	LOSS [training: 0.27283931471787426 | validation: 0.28036205048362756]
	TIME [epoch: 13.4 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26935632871920473		[learning rate: 0.00037241]
	Learning Rate: 0.000372414
	LOSS [training: 0.26935632871920473 | validation: 0.2822642065084353]
	TIME [epoch: 13.4 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27006462156746713		[learning rate: 0.0003711]
	Learning Rate: 0.000371097
	LOSS [training: 0.27006462156746713 | validation: 0.273836574388877]
	TIME [epoch: 13.4 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2644202143504597		[learning rate: 0.00036978]
	Learning Rate: 0.000369785
	LOSS [training: 0.2644202143504597 | validation: 0.2774404875102858]
	TIME [epoch: 13.4 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27016166254158475		[learning rate: 0.00036848]
	Learning Rate: 0.000368477
	LOSS [training: 0.27016166254158475 | validation: 0.26538685046582755]
	TIME [epoch: 13.4 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2636875522561997		[learning rate: 0.00036717]
	Learning Rate: 0.000367174
	LOSS [training: 0.2636875522561997 | validation: 0.26548401066655586]
	TIME [epoch: 13.4 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27264713841399607		[learning rate: 0.00036588]
	Learning Rate: 0.000365875
	LOSS [training: 0.27264713841399607 | validation: 0.27679080017352653]
	TIME [epoch: 13.4 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27358715530434796		[learning rate: 0.00036458]
	Learning Rate: 0.000364582
	LOSS [training: 0.27358715530434796 | validation: 0.27782298496561114]
	TIME [epoch: 13.4 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2730664370028834		[learning rate: 0.00036329]
	Learning Rate: 0.000363293
	LOSS [training: 0.2730664370028834 | validation: 0.27911271899502654]
	TIME [epoch: 13.4 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2678485147325988		[learning rate: 0.00036201]
	Learning Rate: 0.000362008
	LOSS [training: 0.2678485147325988 | validation: 0.2852040007896725]
	TIME [epoch: 13.4 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27343209779875716		[learning rate: 0.00036073]
	Learning Rate: 0.000360728
	LOSS [training: 0.27343209779875716 | validation: 0.2774166589283317]
	TIME [epoch: 13.4 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2694308804238761		[learning rate: 0.00035945]
	Learning Rate: 0.000359452
	LOSS [training: 0.2694308804238761 | validation: 0.26878525909363155]
	TIME [epoch: 13.4 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.275475114299084		[learning rate: 0.00035818]
	Learning Rate: 0.000358181
	LOSS [training: 0.275475114299084 | validation: 0.263990594488535]
	TIME [epoch: 13.4 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28250308685649633		[learning rate: 0.00035691]
	Learning Rate: 0.000356914
	LOSS [training: 0.28250308685649633 | validation: 0.2739639970396569]
	TIME [epoch: 13.4 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27503318771286445		[learning rate: 0.00035565]
	Learning Rate: 0.000355652
	LOSS [training: 0.27503318771286445 | validation: 0.2670808810911868]
	TIME [epoch: 13.4 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26928691480030953		[learning rate: 0.00035439]
	Learning Rate: 0.000354395
	LOSS [training: 0.26928691480030953 | validation: 0.2743574369653676]
	TIME [epoch: 13.4 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26835425539461927		[learning rate: 0.00035314]
	Learning Rate: 0.000353141
	LOSS [training: 0.26835425539461927 | validation: 0.2676635348241578]
	TIME [epoch: 13.4 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2685432109503822		[learning rate: 0.00035189]
	Learning Rate: 0.000351893
	LOSS [training: 0.2685432109503822 | validation: 0.2675062279977075]
	TIME [epoch: 13.4 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2703514360290989		[learning rate: 0.00035065]
	Learning Rate: 0.000350648
	LOSS [training: 0.2703514360290989 | validation: 0.271083109192097]
	TIME [epoch: 13.4 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2752370739167011		[learning rate: 0.00034941]
	Learning Rate: 0.000349408
	LOSS [training: 0.2752370739167011 | validation: 0.26752940434728884]
	TIME [epoch: 13.4 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26946296517507834		[learning rate: 0.00034817]
	Learning Rate: 0.000348173
	LOSS [training: 0.26946296517507834 | validation: 0.2632718572758438]
	TIME [epoch: 13.4 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27126797479419934		[learning rate: 0.00034694]
	Learning Rate: 0.000346942
	LOSS [training: 0.27126797479419934 | validation: 0.26914052413212824]
	TIME [epoch: 13.4 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2741412131203687		[learning rate: 0.00034571]
	Learning Rate: 0.000345715
	LOSS [training: 0.2741412131203687 | validation: 0.28162577173806014]
	TIME [epoch: 13.4 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27042065504953866		[learning rate: 0.00034449]
	Learning Rate: 0.000344492
	LOSS [training: 0.27042065504953866 | validation: 0.27728431452652114]
	TIME [epoch: 45 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26557784495192055		[learning rate: 0.00034327]
	Learning Rate: 0.000343274
	LOSS [training: 0.26557784495192055 | validation: 0.27462515586936853]
	TIME [epoch: 28.8 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27802424105100715		[learning rate: 0.00034206]
	Learning Rate: 0.00034206
	LOSS [training: 0.27802424105100715 | validation: 0.2779802026533312]
	TIME [epoch: 28.8 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27033707846222915		[learning rate: 0.00034085]
	Learning Rate: 0.000340851
	LOSS [training: 0.27033707846222915 | validation: 0.27274666609071063]
	TIME [epoch: 28.8 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2690030125752186		[learning rate: 0.00033965]
	Learning Rate: 0.000339645
	LOSS [training: 0.2690030125752186 | validation: 0.27552562401604397]
	TIME [epoch: 28.8 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2736769920149868		[learning rate: 0.00033844]
	Learning Rate: 0.000338444
	LOSS [training: 0.2736769920149868 | validation: 0.27017304525966884]
	TIME [epoch: 28.8 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.268906578563387		[learning rate: 0.00033725]
	Learning Rate: 0.000337247
	LOSS [training: 0.268906578563387 | validation: 0.2765659209126966]
	TIME [epoch: 28.8 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2719106291114243		[learning rate: 0.00033605]
	Learning Rate: 0.000336055
	LOSS [training: 0.2719106291114243 | validation: 0.2752366509291442]
	TIME [epoch: 28.8 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2664431527049484		[learning rate: 0.00033487]
	Learning Rate: 0.000334867
	LOSS [training: 0.2664431527049484 | validation: 0.27110630662113555]
	TIME [epoch: 28.8 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2697009633008523		[learning rate: 0.00033368]
	Learning Rate: 0.000333682
	LOSS [training: 0.2697009633008523 | validation: 0.26552255249980494]
	TIME [epoch: 28.8 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27348340444596964		[learning rate: 0.0003325]
	Learning Rate: 0.000332503
	LOSS [training: 0.27348340444596964 | validation: 0.26794838925393416]
	TIME [epoch: 28.8 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2737264362204901		[learning rate: 0.00033133]
	Learning Rate: 0.000331327
	LOSS [training: 0.2737264362204901 | validation: 0.2702518069363553]
	TIME [epoch: 28.8 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26987676767995633		[learning rate: 0.00033016]
	Learning Rate: 0.000330155
	LOSS [training: 0.26987676767995633 | validation: 0.2762490083349939]
	TIME [epoch: 28.8 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26489564186724746		[learning rate: 0.00032899]
	Learning Rate: 0.000328988
	LOSS [training: 0.26489564186724746 | validation: 0.2720650687041998]
	TIME [epoch: 28.8 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2705271293147857		[learning rate: 0.00032782]
	Learning Rate: 0.000327824
	LOSS [training: 0.2705271293147857 | validation: 0.27291714718365884]
	TIME [epoch: 28.8 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2682826906723139		[learning rate: 0.00032667]
	Learning Rate: 0.000326665
	LOSS [training: 0.2682826906723139 | validation: 0.2694399051494665]
	TIME [epoch: 28.8 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27866634098550175		[learning rate: 0.00032551]
	Learning Rate: 0.00032551
	LOSS [training: 0.27866634098550175 | validation: 0.2703901685812503]
	TIME [epoch: 28.8 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2651293095297176		[learning rate: 0.00032436]
	Learning Rate: 0.000324359
	LOSS [training: 0.2651293095297176 | validation: 0.27270527488097474]
	TIME [epoch: 28.8 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26921867279894135		[learning rate: 0.00032321]
	Learning Rate: 0.000323212
	LOSS [training: 0.26921867279894135 | validation: 0.270443403411109]
	TIME [epoch: 28.8 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27079930479240294		[learning rate: 0.00032207]
	Learning Rate: 0.000322069
	LOSS [training: 0.27079930479240294 | validation: 0.26807282271459165]
	TIME [epoch: 28.8 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2687449630583035		[learning rate: 0.00032093]
	Learning Rate: 0.00032093
	LOSS [training: 0.2687449630583035 | validation: 0.2729690572348519]
	TIME [epoch: 28.8 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2740783053822193		[learning rate: 0.0003198]
	Learning Rate: 0.000319795
	LOSS [training: 0.2740783053822193 | validation: 0.2757054668576612]
	TIME [epoch: 28.8 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2621260953110212		[learning rate: 0.00031866]
	Learning Rate: 0.000318664
	LOSS [training: 0.2621260953110212 | validation: 0.2727561530618896]
	TIME [epoch: 28.8 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27156146305937084		[learning rate: 0.00031754]
	Learning Rate: 0.000317537
	LOSS [training: 0.27156146305937084 | validation: 0.27571351839423847]
	TIME [epoch: 28.8 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26773721738899336		[learning rate: 0.00031641]
	Learning Rate: 0.000316414
	LOSS [training: 0.26773721738899336 | validation: 0.2720899302979514]
	TIME [epoch: 28.8 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27042105884805234		[learning rate: 0.0003153]
	Learning Rate: 0.000315296
	LOSS [training: 0.27042105884805234 | validation: 0.2731002113794043]
	TIME [epoch: 28.8 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26825498759907257		[learning rate: 0.00031418]
	Learning Rate: 0.000314181
	LOSS [training: 0.26825498759907257 | validation: 0.27058737343870337]
	TIME [epoch: 28.8 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26528810856157264		[learning rate: 0.00031307]
	Learning Rate: 0.00031307
	LOSS [training: 0.26528810856157264 | validation: 0.27285192054202934]
	TIME [epoch: 28.8 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2646984509023247		[learning rate: 0.00031196]
	Learning Rate: 0.000311963
	LOSS [training: 0.2646984509023247 | validation: 0.2760269800683139]
	TIME [epoch: 28.8 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26978389758999816		[learning rate: 0.00031086]
	Learning Rate: 0.00031086
	LOSS [training: 0.26978389758999816 | validation: 0.27606649599222893]
	TIME [epoch: 28.8 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.269601573986811		[learning rate: 0.00030976]
	Learning Rate: 0.00030976
	LOSS [training: 0.269601573986811 | validation: 0.2678535444129525]
	TIME [epoch: 28.8 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2629909116619204		[learning rate: 0.00030866]
	Learning Rate: 0.000308665
	LOSS [training: 0.2629909116619204 | validation: 0.27351829971217995]
	TIME [epoch: 28.8 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2665140971805762		[learning rate: 0.00030757]
	Learning Rate: 0.000307573
	LOSS [training: 0.2665140971805762 | validation: 0.2701036676756835]
	TIME [epoch: 28.8 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27019745204150425		[learning rate: 0.00030649]
	Learning Rate: 0.000306486
	LOSS [training: 0.27019745204150425 | validation: 0.26692397445130595]
	TIME [epoch: 28.8 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.267185895211347		[learning rate: 0.0003054]
	Learning Rate: 0.000305402
	LOSS [training: 0.267185895211347 | validation: 0.278322182412049]
	TIME [epoch: 28.8 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27190473417039474		[learning rate: 0.00030432]
	Learning Rate: 0.000304322
	LOSS [training: 0.27190473417039474 | validation: 0.2660484836344913]
	TIME [epoch: 28.8 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2739230371553169		[learning rate: 0.00030325]
	Learning Rate: 0.000303246
	LOSS [training: 0.2739230371553169 | validation: 0.26796865764754224]
	TIME [epoch: 28.8 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2675469562371153		[learning rate: 0.00030217]
	Learning Rate: 0.000302174
	LOSS [training: 0.2675469562371153 | validation: 0.2698638795671103]
	TIME [epoch: 28.9 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.266560906038872		[learning rate: 0.0003011]
	Learning Rate: 0.000301105
	LOSS [training: 0.266560906038872 | validation: 0.2714996603986059]
	TIME [epoch: 28.8 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26820237222247223		[learning rate: 0.00030004]
	Learning Rate: 0.00030004
	LOSS [training: 0.26820237222247223 | validation: 0.27339968952205074]
	TIME [epoch: 28.8 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2646744130024707		[learning rate: 0.00029898]
	Learning Rate: 0.000298979
	LOSS [training: 0.2646744130024707 | validation: 0.2730127728384659]
	TIME [epoch: 28.8 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27269235282790244		[learning rate: 0.00029792]
	Learning Rate: 0.000297922
	LOSS [training: 0.27269235282790244 | validation: 0.27733609660102154]
	TIME [epoch: 28.8 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26454959163127784		[learning rate: 0.00029687]
	Learning Rate: 0.000296868
	LOSS [training: 0.26454959163127784 | validation: 0.2741562543340891]
	TIME [epoch: 28.8 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2663379587102794		[learning rate: 0.00029582]
	Learning Rate: 0.000295819
	LOSS [training: 0.2663379587102794 | validation: 0.27293121314098334]
	TIME [epoch: 28.8 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26706281615369626		[learning rate: 0.00029477]
	Learning Rate: 0.000294773
	LOSS [training: 0.26706281615369626 | validation: 0.27550789547327054]
	TIME [epoch: 28.8 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2716708470508587		[learning rate: 0.00029373]
	Learning Rate: 0.00029373
	LOSS [training: 0.2716708470508587 | validation: 0.27500907131240976]
	TIME [epoch: 28.8 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26632706409987994		[learning rate: 0.00029269]
	Learning Rate: 0.000292692
	LOSS [training: 0.26632706409987994 | validation: 0.2762035564045204]
	TIME [epoch: 28.8 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2702843962573604		[learning rate: 0.00029166]
	Learning Rate: 0.000291657
	LOSS [training: 0.2702843962573604 | validation: 0.2739113299130499]
	TIME [epoch: 28.8 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2621280958523768		[learning rate: 0.00029063]
	Learning Rate: 0.000290625
	LOSS [training: 0.2621280958523768 | validation: 0.27232407461205005]
	TIME [epoch: 28.8 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26994648873686783		[learning rate: 0.0002896]
	Learning Rate: 0.000289598
	LOSS [training: 0.26994648873686783 | validation: 0.2702216412635945]
	TIME [epoch: 28.8 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2651291550421009		[learning rate: 0.00028857]
	Learning Rate: 0.000288574
	LOSS [training: 0.2651291550421009 | validation: 0.2726312764835801]
	TIME [epoch: 28.8 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2661630564208621		[learning rate: 0.00028755]
	Learning Rate: 0.000287553
	LOSS [training: 0.2661630564208621 | validation: 0.26965542055345126]
	TIME [epoch: 28.8 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2655719025092531		[learning rate: 0.00028654]
	Learning Rate: 0.000286536
	LOSS [training: 0.2655719025092531 | validation: 0.2734159445008117]
	TIME [epoch: 28.8 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2725858717417929		[learning rate: 0.00028552]
	Learning Rate: 0.000285523
	LOSS [training: 0.2725858717417929 | validation: 0.27248880325876584]
	TIME [epoch: 28.8 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2691020288455143		[learning rate: 0.00028451]
	Learning Rate: 0.000284513
	LOSS [training: 0.2691020288455143 | validation: 0.27477564705687463]
	TIME [epoch: 28.8 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26732072352276776		[learning rate: 0.00028351]
	Learning Rate: 0.000283507
	LOSS [training: 0.26732072352276776 | validation: 0.27027104509820943]
	TIME [epoch: 28.8 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26900286444051397		[learning rate: 0.0002825]
	Learning Rate: 0.000282505
	LOSS [training: 0.26900286444051397 | validation: 0.26957395013183316]
	TIME [epoch: 28.8 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2675012367509462		[learning rate: 0.00028151]
	Learning Rate: 0.000281506
	LOSS [training: 0.2675012367509462 | validation: 0.26842697755614336]
	TIME [epoch: 28.8 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27067196690959694		[learning rate: 0.00028051]
	Learning Rate: 0.00028051
	LOSS [training: 0.27067196690959694 | validation: 0.26546666804849306]
	TIME [epoch: 28.8 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26788174798891284		[learning rate: 0.00027952]
	Learning Rate: 0.000279518
	LOSS [training: 0.26788174798891284 | validation: 0.27093087001300564]
	TIME [epoch: 28.8 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26765395463168606		[learning rate: 0.00027853]
	Learning Rate: 0.00027853
	LOSS [training: 0.26765395463168606 | validation: 0.26885100787624383]
	TIME [epoch: 28.8 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26602487383525375		[learning rate: 0.00027754]
	Learning Rate: 0.000277545
	LOSS [training: 0.26602487383525375 | validation: 0.26814947455158344]
	TIME [epoch: 28.8 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2739416769354654		[learning rate: 0.00027656]
	Learning Rate: 0.000276563
	LOSS [training: 0.2739416769354654 | validation: 0.27109497060798404]
	TIME [epoch: 28.8 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2675910798598707		[learning rate: 0.00027559]
	Learning Rate: 0.000275586
	LOSS [training: 0.2675910798598707 | validation: 0.27129758329563874]
	TIME [epoch: 28.8 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26951945572980357		[learning rate: 0.00027461]
	Learning Rate: 0.000274611
	LOSS [training: 0.26951945572980357 | validation: 0.2719309948302798]
	TIME [epoch: 28.8 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26500424335270734		[learning rate: 0.00027364]
	Learning Rate: 0.00027364
	LOSS [training: 0.26500424335270734 | validation: 0.2736882611811041]
	TIME [epoch: 28.8 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26292959289411694		[learning rate: 0.00027267]
	Learning Rate: 0.000272672
	LOSS [training: 0.26292959289411694 | validation: 0.27098243514891257]
	TIME [epoch: 28.8 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2671447256345298		[learning rate: 0.00027171]
	Learning Rate: 0.000271708
	LOSS [training: 0.2671447256345298 | validation: 0.2712731922455289]
	TIME [epoch: 28.8 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2712892884254894		[learning rate: 0.00027075]
	Learning Rate: 0.000270747
	LOSS [training: 0.2712892884254894 | validation: 0.2662616983003637]
	TIME [epoch: 28.8 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26002792562444416		[learning rate: 0.00026979]
	Learning Rate: 0.00026979
	LOSS [training: 0.26002792562444416 | validation: 0.26859304402364514]
	TIME [epoch: 28.8 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2652917794062076		[learning rate: 0.00026884]
	Learning Rate: 0.000268836
	LOSS [training: 0.2652917794062076 | validation: 0.26749354919192897]
	TIME [epoch: 28.8 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26444629380099927		[learning rate: 0.00026789]
	Learning Rate: 0.000267885
	LOSS [training: 0.26444629380099927 | validation: 0.27423298721490363]
	TIME [epoch: 28.8 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26988376720761525		[learning rate: 0.00026694]
	Learning Rate: 0.000266938
	LOSS [training: 0.26988376720761525 | validation: 0.27197123870656437]
	TIME [epoch: 28.8 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2682136626258465		[learning rate: 0.00026599]
	Learning Rate: 0.000265994
	LOSS [training: 0.2682136626258465 | validation: 0.2684462764738582]
	TIME [epoch: 28.8 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26932031303110965		[learning rate: 0.00026505]
	Learning Rate: 0.000265053
	LOSS [training: 0.26932031303110965 | validation: 0.27472862947522503]
	TIME [epoch: 28.8 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27242180847798453		[learning rate: 0.00026412]
	Learning Rate: 0.000264116
	LOSS [training: 0.27242180847798453 | validation: 0.272576630050528]
	TIME [epoch: 28.8 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2730990291638274		[learning rate: 0.00026318]
	Learning Rate: 0.000263182
	LOSS [training: 0.2730990291638274 | validation: 0.2740953552519866]
	TIME [epoch: 28.8 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2680370171309736		[learning rate: 0.00026225]
	Learning Rate: 0.000262252
	LOSS [training: 0.2680370171309736 | validation: 0.26862732521996213]
	TIME [epoch: 28.8 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2693610567641192		[learning rate: 0.00026132]
	Learning Rate: 0.000261324
	LOSS [training: 0.2693610567641192 | validation: 0.27081378433604336]
	TIME [epoch: 28.8 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2644230651147814		[learning rate: 0.0002604]
	Learning Rate: 0.0002604
	LOSS [training: 0.2644230651147814 | validation: 0.2643823563608137]
	TIME [epoch: 28.8 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26900204983641324		[learning rate: 0.00025948]
	Learning Rate: 0.000259479
	LOSS [training: 0.26900204983641324 | validation: 0.26883570313273164]
	TIME [epoch: 28.8 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27247231298964053		[learning rate: 0.00025856]
	Learning Rate: 0.000258562
	LOSS [training: 0.27247231298964053 | validation: 0.27215343612314247]
	TIME [epoch: 28.8 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2698208345993414		[learning rate: 0.00025765]
	Learning Rate: 0.000257647
	LOSS [training: 0.2698208345993414 | validation: 0.26587629332028323]
	TIME [epoch: 28.8 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2713831537147627		[learning rate: 0.00025674]
	Learning Rate: 0.000256736
	LOSS [training: 0.2713831537147627 | validation: 0.26926974667805087]
	TIME [epoch: 28.8 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2717136672845536		[learning rate: 0.00025583]
	Learning Rate: 0.000255828
	LOSS [training: 0.2717136672845536 | validation: 0.2696402903140551]
	TIME [epoch: 28.8 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2697934265368695		[learning rate: 0.00025492]
	Learning Rate: 0.000254924
	LOSS [training: 0.2697934265368695 | validation: 0.26787952969485607]
	TIME [epoch: 28.8 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26855235237184943		[learning rate: 0.00025402]
	Learning Rate: 0.000254022
	LOSS [training: 0.26855235237184943 | validation: 0.2713427740931186]
	TIME [epoch: 28.8 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2670422125671698		[learning rate: 0.00025312]
	Learning Rate: 0.000253124
	LOSS [training: 0.2670422125671698 | validation: 0.2695708158920372]
	TIME [epoch: 28.8 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2693937950155661		[learning rate: 0.00025223]
	Learning Rate: 0.000252229
	LOSS [training: 0.2693937950155661 | validation: 0.27331147360730584]
	TIME [epoch: 28.8 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2635283249033502		[learning rate: 0.00025134]
	Learning Rate: 0.000251337
	LOSS [training: 0.2635283249033502 | validation: 0.27282637704402923]
	TIME [epoch: 28.8 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2689559782373054		[learning rate: 0.00025045]
	Learning Rate: 0.000250448
	LOSS [training: 0.2689559782373054 | validation: 0.26337852950996987]
	TIME [epoch: 28.8 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2668489743995575		[learning rate: 0.00024956]
	Learning Rate: 0.000249563
	LOSS [training: 0.2668489743995575 | validation: 0.26535058184231786]
	TIME [epoch: 28.8 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2704915166144444		[learning rate: 0.00024868]
	Learning Rate: 0.00024868
	LOSS [training: 0.2704915166144444 | validation: 0.2690620026962118]
	TIME [epoch: 28.8 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2642566862816929		[learning rate: 0.0002478]
	Learning Rate: 0.000247801
	LOSS [training: 0.2642566862816929 | validation: 0.27072355950652877]
	TIME [epoch: 28.8 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2740726581379849		[learning rate: 0.00024692]
	Learning Rate: 0.000246924
	LOSS [training: 0.2740726581379849 | validation: 0.271879095586966]
	TIME [epoch: 28.8 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26509357081361323		[learning rate: 0.00024605]
	Learning Rate: 0.000246051
	LOSS [training: 0.26509357081361323 | validation: 0.26216975965812866]
	TIME [epoch: 28.8 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2671511548804612		[learning rate: 0.00024518]
	Learning Rate: 0.000245181
	LOSS [training: 0.2671511548804612 | validation: 0.2750750547141558]
	TIME [epoch: 28.8 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2666475105029644		[learning rate: 0.00024431]
	Learning Rate: 0.000244314
	LOSS [training: 0.2666475105029644 | validation: 0.2688786499225117]
	TIME [epoch: 28.8 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2685830577998182		[learning rate: 0.00024345]
	Learning Rate: 0.00024345
	LOSS [training: 0.2685830577998182 | validation: 0.2697988733808793]
	TIME [epoch: 28.8 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26490685127018054		[learning rate: 0.00024259]
	Learning Rate: 0.000242589
	LOSS [training: 0.26490685127018054 | validation: 0.2713756234840325]
	TIME [epoch: 28.8 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2664788804549213		[learning rate: 0.00024173]
	Learning Rate: 0.000241732
	LOSS [training: 0.2664788804549213 | validation: 0.2701265126021696]
	TIME [epoch: 28.8 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2685288578540764		[learning rate: 0.00024088]
	Learning Rate: 0.000240877
	LOSS [training: 0.2685288578540764 | validation: 0.2763363171152463]
	TIME [epoch: 28.8 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26274670769600833		[learning rate: 0.00024002]
	Learning Rate: 0.000240025
	LOSS [training: 0.26274670769600833 | validation: 0.27030347937477595]
	TIME [epoch: 28.8 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26677227152479904		[learning rate: 0.00023918]
	Learning Rate: 0.000239176
	LOSS [training: 0.26677227152479904 | validation: 0.2699266436609795]
	TIME [epoch: 28.8 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26468011164929367		[learning rate: 0.00023833]
	Learning Rate: 0.00023833
	LOSS [training: 0.26468011164929367 | validation: 0.2721563447054061]
	TIME [epoch: 28.8 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26977806060524573		[learning rate: 0.00023749]
	Learning Rate: 0.000237488
	LOSS [training: 0.26977806060524573 | validation: 0.26879929809581593]
	TIME [epoch: 28.8 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2691236617237367		[learning rate: 0.00023665]
	Learning Rate: 0.000236648
	LOSS [training: 0.2691236617237367 | validation: 0.2681814645406707]
	TIME [epoch: 28.8 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2685084201383732		[learning rate: 0.00023581]
	Learning Rate: 0.000235811
	LOSS [training: 0.2685084201383732 | validation: 0.267973497348031]
	TIME [epoch: 28.8 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2646471585833642		[learning rate: 0.00023498]
	Learning Rate: 0.000234977
	LOSS [training: 0.2646471585833642 | validation: 0.26802376779906967]
	TIME [epoch: 28.8 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2663348791352247		[learning rate: 0.00023415]
	Learning Rate: 0.000234146
	LOSS [training: 0.2663348791352247 | validation: 0.27467407127465127]
	TIME [epoch: 28.8 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2688263198180606		[learning rate: 0.00023332]
	Learning Rate: 0.000233318
	LOSS [training: 0.2688263198180606 | validation: 0.26725356147700163]
	TIME [epoch: 28.8 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2682488146828102		[learning rate: 0.00023249]
	Learning Rate: 0.000232493
	LOSS [training: 0.2682488146828102 | validation: 0.27108368746681977]
	TIME [epoch: 28.8 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2665450207032985		[learning rate: 0.00023167]
	Learning Rate: 0.000231671
	LOSS [training: 0.2665450207032985 | validation: 0.267875257834468]
	TIME [epoch: 28.8 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26659667007601856		[learning rate: 0.00023085]
	Learning Rate: 0.000230852
	LOSS [training: 0.26659667007601856 | validation: 0.2704606566702766]
	TIME [epoch: 28.8 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2684284391475636		[learning rate: 0.00023004]
	Learning Rate: 0.000230036
	LOSS [training: 0.2684284391475636 | validation: 0.2681183087918134]
	TIME [epoch: 28.8 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.264210134951181		[learning rate: 0.00022922]
	Learning Rate: 0.000229222
	LOSS [training: 0.264210134951181 | validation: 0.2646435388996465]
	TIME [epoch: 28.8 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2692074481803493		[learning rate: 0.00022841]
	Learning Rate: 0.000228412
	LOSS [training: 0.2692074481803493 | validation: 0.2673792666361952]
	TIME [epoch: 28.8 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2680163378947891		[learning rate: 0.0002276]
	Learning Rate: 0.000227604
	LOSS [training: 0.2680163378947891 | validation: 0.26913234581248957]
	TIME [epoch: 28.8 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2661032394015386		[learning rate: 0.0002268]
	Learning Rate: 0.000226799
	LOSS [training: 0.2661032394015386 | validation: 0.2679176134924177]
	TIME [epoch: 28.8 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2637915483951241		[learning rate: 0.000226]
	Learning Rate: 0.000225997
	LOSS [training: 0.2637915483951241 | validation: 0.26607799617522404]
	TIME [epoch: 28.8 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26292440245613563		[learning rate: 0.0002252]
	Learning Rate: 0.000225198
	LOSS [training: 0.26292440245613563 | validation: 0.2661370617988481]
	TIME [epoch: 28.8 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2673814393721931		[learning rate: 0.0002244]
	Learning Rate: 0.000224401
	LOSS [training: 0.2673814393721931 | validation: 0.27274533090277236]
	TIME [epoch: 28.8 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26964788019471736		[learning rate: 0.00022361]
	Learning Rate: 0.000223608
	LOSS [training: 0.26964788019471736 | validation: 0.26813870818486524]
	TIME [epoch: 28.8 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2638160543962683		[learning rate: 0.00022282]
	Learning Rate: 0.000222817
	LOSS [training: 0.2638160543962683 | validation: 0.27217514753560695]
	TIME [epoch: 28.8 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2657025145920589		[learning rate: 0.00022203]
	Learning Rate: 0.000222029
	LOSS [training: 0.2657025145920589 | validation: 0.26922070016721167]
	TIME [epoch: 28.8 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26619462667440374		[learning rate: 0.00022124]
	Learning Rate: 0.000221244
	LOSS [training: 0.26619462667440374 | validation: 0.26878583671197187]
	TIME [epoch: 28.8 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26823625983253213		[learning rate: 0.00022046]
	Learning Rate: 0.000220462
	LOSS [training: 0.26823625983253213 | validation: 0.2721210934497623]
	TIME [epoch: 28.8 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2606879531121648		[learning rate: 0.00021968]
	Learning Rate: 0.000219682
	LOSS [training: 0.2606879531121648 | validation: 0.26963553514970223]
	TIME [epoch: 28.8 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2639148149666172		[learning rate: 0.00021891]
	Learning Rate: 0.000218905
	LOSS [training: 0.2639148149666172 | validation: 0.2627388516748522]
	TIME [epoch: 28.8 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26872701988198366		[learning rate: 0.00021813]
	Learning Rate: 0.000218131
	LOSS [training: 0.26872701988198366 | validation: 0.270040872444859]
	TIME [epoch: 28.8 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2657251909863956		[learning rate: 0.00021736]
	Learning Rate: 0.00021736
	LOSS [training: 0.2657251909863956 | validation: 0.2705393979857033]
	TIME [epoch: 28.8 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26359084392965443		[learning rate: 0.00021659]
	Learning Rate: 0.000216591
	LOSS [training: 0.26359084392965443 | validation: 0.2656560082207723]
	TIME [epoch: 28.8 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26925896711001784		[learning rate: 0.00021583]
	Learning Rate: 0.000215825
	LOSS [training: 0.26925896711001784 | validation: 0.27104101714054263]
	TIME [epoch: 28.8 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26603512575465693		[learning rate: 0.00021506]
	Learning Rate: 0.000215062
	LOSS [training: 0.26603512575465693 | validation: 0.2752743837418496]
	TIME [epoch: 28.8 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26971343741082404		[learning rate: 0.0002143]
	Learning Rate: 0.000214302
	LOSS [training: 0.26971343741082404 | validation: 0.2698718622846723]
	TIME [epoch: 28.8 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26801450567219437		[learning rate: 0.00021354]
	Learning Rate: 0.000213544
	LOSS [training: 0.26801450567219437 | validation: 0.27118099770055837]
	TIME [epoch: 28.8 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26627057589215136		[learning rate: 0.00021279]
	Learning Rate: 0.000212789
	LOSS [training: 0.26627057589215136 | validation: 0.27331176678372954]
	TIME [epoch: 28.8 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26484069904955054		[learning rate: 0.00021204]
	Learning Rate: 0.000212036
	LOSS [training: 0.26484069904955054 | validation: 0.2717692080789692]
	TIME [epoch: 28.8 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2711650650439929		[learning rate: 0.00021129]
	Learning Rate: 0.000211287
	LOSS [training: 0.2711650650439929 | validation: 0.27110962086852214]
	TIME [epoch: 28.8 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26683437689382006		[learning rate: 0.00021054]
	Learning Rate: 0.000210539
	LOSS [training: 0.26683437689382006 | validation: 0.2702763169020071]
	TIME [epoch: 28.8 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27331699694474265		[learning rate: 0.00020979]
	Learning Rate: 0.000209795
	LOSS [training: 0.27331699694474265 | validation: 0.2738447960592605]
	TIME [epoch: 28.8 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2671720944691627		[learning rate: 0.00020905]
	Learning Rate: 0.000209053
	LOSS [training: 0.2671720944691627 | validation: 0.2676787534846524]
	TIME [epoch: 28.8 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.271001783386942		[learning rate: 0.00020831]
	Learning Rate: 0.000208314
	LOSS [training: 0.271001783386942 | validation: 0.2687296289755472]
	TIME [epoch: 28.8 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26740654904929173		[learning rate: 0.00020758]
	Learning Rate: 0.000207577
	LOSS [training: 0.26740654904929173 | validation: 0.2654307930189436]
	TIME [epoch: 28.8 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26749479592536		[learning rate: 0.00020684]
	Learning Rate: 0.000206843
	LOSS [training: 0.26749479592536 | validation: 0.2689623490265557]
	TIME [epoch: 28.8 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2627681932854901		[learning rate: 0.00020611]
	Learning Rate: 0.000206112
	LOSS [training: 0.2627681932854901 | validation: 0.2715945982606106]
	TIME [epoch: 28.8 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2672194679639988		[learning rate: 0.00020538]
	Learning Rate: 0.000205383
	LOSS [training: 0.2672194679639988 | validation: 0.26783309370889385]
	TIME [epoch: 28.8 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2643044779524149		[learning rate: 0.00020466]
	Learning Rate: 0.000204657
	LOSS [training: 0.2643044779524149 | validation: 0.26754504342873286]
	TIME [epoch: 28.8 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2657687327425992		[learning rate: 0.00020393]
	Learning Rate: 0.000203933
	LOSS [training: 0.2657687327425992 | validation: 0.2694935042316626]
	TIME [epoch: 28.8 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2704668390232232		[learning rate: 0.00020321]
	Learning Rate: 0.000203212
	LOSS [training: 0.2704668390232232 | validation: 0.27239515292156813]
	TIME [epoch: 28.8 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26649094983864097		[learning rate: 0.00020249]
	Learning Rate: 0.000202493
	LOSS [training: 0.26649094983864097 | validation: 0.27218088624299774]
	TIME [epoch: 28.8 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2693346692525204		[learning rate: 0.00020178]
	Learning Rate: 0.000201777
	LOSS [training: 0.2693346692525204 | validation: 0.2717408098504402]
	TIME [epoch: 28.8 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26877070261845176		[learning rate: 0.00020106]
	Learning Rate: 0.000201064
	LOSS [training: 0.26877070261845176 | validation: 0.26960504398077717]
	TIME [epoch: 28.8 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27427040531072516		[learning rate: 0.00020035]
	Learning Rate: 0.000200353
	LOSS [training: 0.27427040531072516 | validation: 0.2672143515822373]
	TIME [epoch: 28.8 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2698149602829703		[learning rate: 0.00019964]
	Learning Rate: 0.000199644
	LOSS [training: 0.2698149602829703 | validation: 0.2680383002971098]
	TIME [epoch: 28.8 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27124119640285516		[learning rate: 0.00019894]
	Learning Rate: 0.000198938
	LOSS [training: 0.27124119640285516 | validation: 0.2665558747341264]
	TIME [epoch: 28.8 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2662895560815964		[learning rate: 0.00019823]
	Learning Rate: 0.000198235
	LOSS [training: 0.2662895560815964 | validation: 0.26506902363759394]
	TIME [epoch: 28.8 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27012786982551135		[learning rate: 0.00019753]
	Learning Rate: 0.000197534
	LOSS [training: 0.27012786982551135 | validation: 0.2676195170066023]
	TIME [epoch: 28.8 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2645786617628035		[learning rate: 0.00019684]
	Learning Rate: 0.000196835
	LOSS [training: 0.2645786617628035 | validation: 0.26199572847390706]
	TIME [epoch: 28.8 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2631535872106838		[learning rate: 0.00019614]
	Learning Rate: 0.000196139
	LOSS [training: 0.2631535872106838 | validation: 0.26962662442499996]
	TIME [epoch: 28.8 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26452788913482267		[learning rate: 0.00019545]
	Learning Rate: 0.000195446
	LOSS [training: 0.26452788913482267 | validation: 0.271407214315574]
	TIME [epoch: 28.8 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2673403934389877		[learning rate: 0.00019475]
	Learning Rate: 0.000194754
	LOSS [training: 0.2673403934389877 | validation: 0.2728097352421681]
	TIME [epoch: 28.8 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2646957857347893		[learning rate: 0.00019407]
	Learning Rate: 0.000194066
	LOSS [training: 0.2646957857347893 | validation: 0.26448037868177077]
	TIME [epoch: 28.8 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.264662312106813		[learning rate: 0.00019338]
	Learning Rate: 0.000193379
	LOSS [training: 0.264662312106813 | validation: 0.2712005088915762]
	TIME [epoch: 28.8 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26854128339935596		[learning rate: 0.0001927]
	Learning Rate: 0.000192696
	LOSS [training: 0.26854128339935596 | validation: 0.27111128745556373]
	TIME [epoch: 28.8 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2663965206776047		[learning rate: 0.00019201]
	Learning Rate: 0.000192014
	LOSS [training: 0.2663965206776047 | validation: 0.2749976454741455]
	TIME [epoch: 28.8 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2633777416412586		[learning rate: 0.00019134]
	Learning Rate: 0.000191335
	LOSS [training: 0.2633777416412586 | validation: 0.27016565821619204]
	TIME [epoch: 28.8 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2680257763561909		[learning rate: 0.00019066]
	Learning Rate: 0.000190659
	LOSS [training: 0.2680257763561909 | validation: 0.27253140602125014]
	TIME [epoch: 28.8 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2640301510001316		[learning rate: 0.00018998]
	Learning Rate: 0.000189984
	LOSS [training: 0.2640301510001316 | validation: 0.27437871311690165]
	TIME [epoch: 28.8 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2770854698223519		[learning rate: 0.00018931]
	Learning Rate: 0.000189313
	LOSS [training: 0.2770854698223519 | validation: 0.27214428484803366]
	TIME [epoch: 28.8 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2669564160705907		[learning rate: 0.00018864]
	Learning Rate: 0.000188643
	LOSS [training: 0.2669564160705907 | validation: 0.2691467279022569]
	TIME [epoch: 28.8 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v8_20240715_180006/states/model_facs_v3_dec1b_2dpca_v8_1171.pth
Halted early. No improvement in validation loss for 200 epochs.
Finished training in 15288.256 seconds.
