Args:
Namespace(name='model_facs_dec1b_2d_v1', outdir='out/model_training/model_facs_dec1b_2d_v1', training_data='data/training_data/facs/dec1_fitonsubset/transition1_subset_epi_tr_ce_an_pc12/training', validation_data='data/training_data/facs/dec1_fitonsubset/transition1_subset_epi_tr_ce_an_pc12/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=5, patience=200, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, dt=0.001, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 3742862518

Training model...

Saving initial model state to: out/model_training/model_facs_dec1b_2d_v1_20240622_154550/states/model_facs_dec1b_2d_v1_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 9/9] avg loss: 3.290065668590923		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.290065668590923 | validation: 1.791363819128453]
	TIME [epoch: 65.6 sec]
	Saving model to: out/model_training/model_facs_dec1b_2d_v1_20240622_154550/states/model_facs_dec1b_2d_v1_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.357243928451412		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.357243928451412 | validation: 1.2159627312685846]
	TIME [epoch: 35.6 sec]
	Saving model to: out/model_training/model_facs_dec1b_2d_v1_20240622_154550/states/model_facs_dec1b_2d_v1_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.1506991193949185		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1506991193949185 | validation: 1.0408684097351695]
	TIME [epoch: 35.6 sec]
	Saving model to: out/model_training/model_facs_dec1b_2d_v1_20240622_154550/states/model_facs_dec1b_2d_v1_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.8815512410890027		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8815512410890027 | validation: 0.9073210038904296]
	TIME [epoch: 35.6 sec]
	Saving model to: out/model_training/model_facs_dec1b_2d_v1_20240622_154550/states/model_facs_dec1b_2d_v1_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.8986512757675619		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8986512757675619 | validation: 0.6088276054563362]
	TIME [epoch: 35.6 sec]
	Saving model to: out/model_training/model_facs_dec1b_2d_v1_20240622_154550/states/model_facs_dec1b_2d_v1_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5218880540181196		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5218880540181196 | validation: 0.552639989017486]
	TIME [epoch: 35.6 sec]
	Saving model to: out/model_training/model_facs_dec1b_2d_v1_20240622_154550/states/model_facs_dec1b_2d_v1_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3713603639035094		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3713603639035094 | validation: 0.31435636017667806]
	TIME [epoch: 35.6 sec]
	Saving model to: out/model_training/model_facs_dec1b_2d_v1_20240622_154550/states/model_facs_dec1b_2d_v1_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.22309122067561202		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22309122067561202 | validation: 0.16443326451697612]
	TIME [epoch: 35.6 sec]
	Saving model to: out/model_training/model_facs_dec1b_2d_v1_20240622_154550/states/model_facs_dec1b_2d_v1_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.1037925934874915		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1037925934874915 | validation: 0.08751965183452304]
	TIME [epoch: 35.5 sec]
	Saving model to: out/model_training/model_facs_dec1b_2d_v1_20240622_154550/states/model_facs_dec1b_2d_v1_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.06729938798140124		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06729938798140124 | validation: 0.041461410178840155]
	TIME [epoch: 35.6 sec]
	Saving model to: out/model_training/model_facs_dec1b_2d_v1_20240622_154550/states/model_facs_dec1b_2d_v1_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.03643601918659069		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03643601918659069 | validation: 0.0359444792459835]
	TIME [epoch: 35.5 sec]
	Saving model to: out/model_training/model_facs_dec1b_2d_v1_20240622_154550/states/model_facs_dec1b_2d_v1_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.031170550689591854		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.031170550689591854 | validation: 0.02136197389026436]
	TIME [epoch: 35.6 sec]
	Saving model to: out/model_training/model_facs_dec1b_2d_v1_20240622_154550/states/model_facs_dec1b_2d_v1_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.024593803310241812		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.024593803310241812 | validation: 0.03604077334519431]
	TIME [epoch: 35.5 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.02239606364608838		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.02239606364608838 | validation: 0.014934393959991127]
	TIME [epoch: 35.6 sec]
	Saving model to: out/model_training/model_facs_dec1b_2d_v1_20240622_154550/states/model_facs_dec1b_2d_v1_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.021530238674851907		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.021530238674851907 | validation: 0.012165553605949678]
	TIME [epoch: 35.6 sec]
	Saving model to: out/model_training/model_facs_dec1b_2d_v1_20240622_154550/states/model_facs_dec1b_2d_v1_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.015471578349252744		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.015471578349252744 | validation: 0.05272293404138571]
	TIME [epoch: 35.5 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.022425591853886616		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.022425591853886616 | validation: 0.011939575222721448]
	TIME [epoch: 35.5 sec]
	Saving model to: out/model_training/model_facs_dec1b_2d_v1_20240622_154550/states/model_facs_dec1b_2d_v1_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.015163155893489436		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.015163155893489436 | validation: 0.030986166697568505]
	TIME [epoch: 35.5 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.015702344125735297		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.015702344125735297 | validation: 0.015618584149210534]
	TIME [epoch: 35.5 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01175119900989626		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.01175119900989626 | validation: 0.011963388751352317]
	TIME [epoch: 35.5 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01676284697011893		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.01676284697011893 | validation: 0.010972916019638294]
	TIME [epoch: 35.6 sec]
	Saving model to: out/model_training/model_facs_dec1b_2d_v1_20240622_154550/states/model_facs_dec1b_2d_v1_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.015049144741493813		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.015049144741493813 | validation: 0.016130826759474103]
	TIME [epoch: 35.5 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012627224014680626		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.012627224014680626 | validation: 0.011239999405071793]
	TIME [epoch: 35.6 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01241928524494567		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.01241928524494567 | validation: 0.012403083584723555]
	TIME [epoch: 35.5 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011717455766976949		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.011717455766976949 | validation: 0.012577652436384323]
	TIME [epoch: 35.6 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012839785742455955		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.012839785742455955 | validation: 0.021665264868865594]
	TIME [epoch: 35.6 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.016253353553349996		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.016253353553349996 | validation: 0.011958078187130492]
	TIME [epoch: 35.5 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.013866548270201775		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.013866548270201775 | validation: 0.01721639513668245]
	TIME [epoch: 35.5 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.019209274235518315		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.019209274235518315 | validation: 0.009191949536918424]
	TIME [epoch: 35.5 sec]
	Saving model to: out/model_training/model_facs_dec1b_2d_v1_20240622_154550/states/model_facs_dec1b_2d_v1_29.pth
	Model improved!!!
EPOCH 30/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011205700273895447		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.011205700273895447 | validation: 0.011927052013938363]
	TIME [epoch: 35.6 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011143311882038829		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.011143311882038829 | validation: 0.015780478469705227]
	TIME [epoch: 35.6 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01167637382284656		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.01167637382284656 | validation: 0.030429585051546672]
	TIME [epoch: 35.6 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01668220052146434		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.01668220052146434 | validation: 0.015271563849485687]
	TIME [epoch: 35.6 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.015149306361022843		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.015149306361022843 | validation: 0.018100470520873727]
	TIME [epoch: 35.6 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012976096162988079		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.012976096162988079 | validation: 0.009188372666549408]
	TIME [epoch: 35.6 sec]
	Saving model to: out/model_training/model_facs_dec1b_2d_v1_20240622_154550/states/model_facs_dec1b_2d_v1_35.pth
	Model improved!!!
EPOCH 36/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.014299401520498757		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.014299401520498757 | validation: 0.021201696029376594]
	TIME [epoch: 35.6 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.014157635425038296		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.014157635425038296 | validation: 0.0206861525416802]
	TIME [epoch: 35.5 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.014546478519232135		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.014546478519232135 | validation: 0.01182354241292168]
	TIME [epoch: 35.6 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.014336182904597126		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.014336182904597126 | validation: 0.011533429966659115]
	TIME [epoch: 35.6 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012696147397617609		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.012696147397617609 | validation: 0.013990757207550886]
	TIME [epoch: 35.5 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.015187956814857831		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.015187956814857831 | validation: 0.028268415714388206]
	TIME [epoch: 35.6 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.014885907464276753		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.014885907464276753 | validation: 0.011817706009486475]
	TIME [epoch: 35.6 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012179570704707493		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.012179570704707493 | validation: 0.01517423935859501]
	TIME [epoch: 35.6 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01516634911463948		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.01516634911463948 | validation: 0.008787424669724656]
	TIME [epoch: 35.6 sec]
	Saving model to: out/model_training/model_facs_dec1b_2d_v1_20240622_154550/states/model_facs_dec1b_2d_v1_44.pth
	Model improved!!!
EPOCH 45/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011153242377732554		[learning rate: 0.0099823]
	Learning Rate: 0.0099823
	LOSS [training: 0.011153242377732554 | validation: 0.016685721829870916]
	TIME [epoch: 35.7 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.020709882433359205		[learning rate: 0.0099426]
	Learning Rate: 0.0099426
	LOSS [training: 0.020709882433359205 | validation: 0.010764076968301213]
	TIME [epoch: 35.6 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012353625310541051		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 0.012353625310541051 | validation: 0.012389659021286845]
	TIME [epoch: 35.5 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009498921120981413		[learning rate: 0.0098637]
	Learning Rate: 0.00986367
	LOSS [training: 0.009498921120981413 | validation: 0.011835125577812198]
	TIME [epoch: 35.6 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.014621160309587877		[learning rate: 0.0098244]
	Learning Rate: 0.00982444
	LOSS [training: 0.014621160309587877 | validation: 0.01895329699408484]
	TIME [epoch: 35.6 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.015637461310944283		[learning rate: 0.0097854]
	Learning Rate: 0.00978536
	LOSS [training: 0.015637461310944283 | validation: 0.010406747671073783]
	TIME [epoch: 35.5 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.015245395658221726		[learning rate: 0.0097464]
	Learning Rate: 0.00974644
	LOSS [training: 0.015245395658221726 | validation: 0.009226455796338793]
	TIME [epoch: 35.5 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.013518315715628608		[learning rate: 0.0097077]
	Learning Rate: 0.00970768
	LOSS [training: 0.013518315715628608 | validation: 0.015330862074901053]
	TIME [epoch: 35.6 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.017316929834745937		[learning rate: 0.0096691]
	Learning Rate: 0.00966907
	LOSS [training: 0.017316929834745937 | validation: 0.008799792536193127]
	TIME [epoch: 35.6 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011665691230227928		[learning rate: 0.0096306]
	Learning Rate: 0.00963061
	LOSS [training: 0.011665691230227928 | validation: 0.012067541452248861]
	TIME [epoch: 35.6 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012568804578281724		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 0.012568804578281724 | validation: 0.0119470807873098]
	TIME [epoch: 35.6 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011574550206196256		[learning rate: 0.0095542]
	Learning Rate: 0.00955415
	LOSS [training: 0.011574550206196256 | validation: 0.013744782467910782]
	TIME [epoch: 35.6 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0185995175631743		[learning rate: 0.0095162]
	Learning Rate: 0.00951616
	LOSS [training: 0.0185995175631743 | validation: 0.010751817154216418]
	TIME [epoch: 35.6 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011429090790982482		[learning rate: 0.0094783]
	Learning Rate: 0.00947831
	LOSS [training: 0.011429090790982482 | validation: 0.008567733616202791]
	TIME [epoch: 35.6 sec]
	Saving model to: out/model_training/model_facs_dec1b_2d_v1_20240622_154550/states/model_facs_dec1b_2d_v1_58.pth
	Model improved!!!
EPOCH 59/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012138082524983452		[learning rate: 0.0094406]
	Learning Rate: 0.00944061
	LOSS [training: 0.012138082524983452 | validation: 0.02161106664991201]
	TIME [epoch: 35.6 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.015522427191259618		[learning rate: 0.0094031]
	Learning Rate: 0.00940306
	LOSS [training: 0.015522427191259618 | validation: 0.011729771444998316]
	TIME [epoch: 35.5 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012703312143824839		[learning rate: 0.0093657]
	Learning Rate: 0.00936566
	LOSS [training: 0.012703312143824839 | validation: 0.009156361575456297]
	TIME [epoch: 35.6 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011364037958011029		[learning rate: 0.0093284]
	Learning Rate: 0.00932841
	LOSS [training: 0.011364037958011029 | validation: 0.010529487744990754]
	TIME [epoch: 35.6 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.013957106285851903		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 0.013957106285851903 | validation: 0.01698886823830158]
	TIME [epoch: 35.6 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.020047254622143938		[learning rate: 0.0092544]
	Learning Rate: 0.00925435
	LOSS [training: 0.020047254622143938 | validation: 0.010723328002440264]
	TIME [epoch: 35.5 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010065481588916186		[learning rate: 0.0092175]
	Learning Rate: 0.00921755
	LOSS [training: 0.010065481588916186 | validation: 0.00895268563572799]
	TIME [epoch: 35.7 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010656430230645119		[learning rate: 0.0091809]
	Learning Rate: 0.00918089
	LOSS [training: 0.010656430230645119 | validation: 0.009633111335623968]
	TIME [epoch: 35.6 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011561539780336402		[learning rate: 0.0091444]
	Learning Rate: 0.00914437
	LOSS [training: 0.011561539780336402 | validation: 0.011089504819410418]
	TIME [epoch: 35.6 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.013126103629247786		[learning rate: 0.009108]
	Learning Rate: 0.009108
	LOSS [training: 0.013126103629247786 | validation: 0.010521259831671164]
	TIME [epoch: 35.6 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011095574085625774		[learning rate: 0.0090718]
	Learning Rate: 0.00907178
	LOSS [training: 0.011095574085625774 | validation: 0.01537022393141034]
	TIME [epoch: 35.6 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010636407985044628		[learning rate: 0.0090357]
	Learning Rate: 0.00903569
	LOSS [training: 0.010636407985044628 | validation: 0.00863041928669633]
	TIME [epoch: 35.6 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012731855508439983		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 0.012731855508439983 | validation: 0.009011731544156385]
	TIME [epoch: 35.6 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.014364024587964652		[learning rate: 0.008964]
	Learning Rate: 0.00896396
	LOSS [training: 0.014364024587964652 | validation: 0.020436724483275152]
	TIME [epoch: 35.6 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.013350156101293783		[learning rate: 0.0089283]
	Learning Rate: 0.00892831
	LOSS [training: 0.013350156101293783 | validation: 0.013411535625644034]
	TIME [epoch: 35.6 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011973406024958397		[learning rate: 0.0088928]
	Learning Rate: 0.0088928
	LOSS [training: 0.011973406024958397 | validation: 0.009573073532485191]
	TIME [epoch: 35.6 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010430667397893344		[learning rate: 0.0088574]
	Learning Rate: 0.00885743
	LOSS [training: 0.010430667397893344 | validation: 0.015962613803193405]
	TIME [epoch: 35.6 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.013746945859426946		[learning rate: 0.0088222]
	Learning Rate: 0.0088222
	LOSS [training: 0.013746945859426946 | validation: 0.010749667937223607]
	TIME [epoch: 35.6 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012379062754894631		[learning rate: 0.0087871]
	Learning Rate: 0.00878711
	LOSS [training: 0.012379062754894631 | validation: 0.0158917438190199]
	TIME [epoch: 35.6 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01265969299707833		[learning rate: 0.0087522]
	Learning Rate: 0.00875216
	LOSS [training: 0.01265969299707833 | validation: 0.010997118613976956]
	TIME [epoch: 35.6 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011284421307969764		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 0.011284421307969764 | validation: 0.01244240048963503]
	TIME [epoch: 35.6 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012305823375142843		[learning rate: 0.0086827]
	Learning Rate: 0.00868268
	LOSS [training: 0.012305823375142843 | validation: 0.008253655267380177]
	TIME [epoch: 35.7 sec]
	Saving model to: out/model_training/model_facs_dec1b_2d_v1_20240622_154550/states/model_facs_dec1b_2d_v1_80.pth
	Model improved!!!
EPOCH 81/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010029346505227727		[learning rate: 0.0086481]
	Learning Rate: 0.00864815
	LOSS [training: 0.010029346505227727 | validation: 0.011623226846929353]
	TIME [epoch: 35.6 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011230368834066147		[learning rate: 0.0086138]
	Learning Rate: 0.00861375
	LOSS [training: 0.011230368834066147 | validation: 0.02618062604741307]
	TIME [epoch: 35.6 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.016315461842081883		[learning rate: 0.0085795]
	Learning Rate: 0.00857949
	LOSS [training: 0.016315461842081883 | validation: 0.014404021538052226]
	TIME [epoch: 35.6 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012476138112395136		[learning rate: 0.0085454]
	Learning Rate: 0.00854537
	LOSS [training: 0.012476138112395136 | validation: 0.00769717329126122]
	TIME [epoch: 35.7 sec]
	Saving model to: out/model_training/model_facs_dec1b_2d_v1_20240622_154550/states/model_facs_dec1b_2d_v1_84.pth
	Model improved!!!
EPOCH 85/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010518406172218471		[learning rate: 0.0085114]
	Learning Rate: 0.00851138
	LOSS [training: 0.010518406172218471 | validation: 0.01840856679872503]
	TIME [epoch: 35.6 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011710064701384196		[learning rate: 0.0084775]
	Learning Rate: 0.00847753
	LOSS [training: 0.011710064701384196 | validation: 0.012832961627785267]
	TIME [epoch: 35.7 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011996641331360932		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 0.011996641331360932 | validation: 0.016063992392385283]
	TIME [epoch: 35.6 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.014440439163676037		[learning rate: 0.0084102]
	Learning Rate: 0.00841023
	LOSS [training: 0.014440439163676037 | validation: 0.010723043097718347]
	TIME [epoch: 35.6 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.013583671555059282		[learning rate: 0.0083768]
	Learning Rate: 0.00837678
	LOSS [training: 0.013583671555059282 | validation: 0.019743764815985988]
	TIME [epoch: 35.5 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011695238546006768		[learning rate: 0.0083435]
	Learning Rate: 0.00834346
	LOSS [training: 0.011695238546006768 | validation: 0.011762167904887044]
	TIME [epoch: 35.6 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01415331369803769		[learning rate: 0.0083103]
	Learning Rate: 0.00831027
	LOSS [training: 0.01415331369803769 | validation: 0.00987939283997365]
	TIME [epoch: 35.5 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010854655114495813		[learning rate: 0.0082772]
	Learning Rate: 0.00827722
	LOSS [training: 0.010854655114495813 | validation: 0.01213784601287667]
	TIME [epoch: 35.5 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011788752970947693		[learning rate: 0.0082443]
	Learning Rate: 0.0082443
	LOSS [training: 0.011788752970947693 | validation: 0.029461726598614724]
	TIME [epoch: 35.6 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.017009903500517537		[learning rate: 0.0082115]
	Learning Rate: 0.00821151
	LOSS [training: 0.017009903500517537 | validation: 0.011149082935185253]
	TIME [epoch: 35.6 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.014361693447588832		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 0.014361693447588832 | validation: 0.00866795332168683]
	TIME [epoch: 35.6 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01043071245777095		[learning rate: 0.0081463]
	Learning Rate: 0.00814632
	LOSS [training: 0.01043071245777095 | validation: 0.013941504090056529]
	TIME [epoch: 35.6 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.013497214717174357		[learning rate: 0.0081139]
	Learning Rate: 0.00811392
	LOSS [training: 0.013497214717174357 | validation: 0.014851957873633692]
	TIME [epoch: 35.5 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011771243552162657		[learning rate: 0.0080816]
	Learning Rate: 0.00808165
	LOSS [training: 0.011771243552162657 | validation: 0.01909703944379762]
	TIME [epoch: 35.6 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011779166557304457		[learning rate: 0.0080495]
	Learning Rate: 0.00804951
	LOSS [training: 0.011779166557304457 | validation: 0.00833286636498897]
	TIME [epoch: 35.6 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01267058810558802		[learning rate: 0.0080175]
	Learning Rate: 0.00801749
	LOSS [training: 0.01267058810558802 | validation: 0.018770089962533675]
	TIME [epoch: 35.6 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.013033994038478531		[learning rate: 0.0079856]
	Learning Rate: 0.0079856
	LOSS [training: 0.013033994038478531 | validation: 0.015710553375568672]
	TIME [epoch: 35.6 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012010238716787091		[learning rate: 0.0079538]
	Learning Rate: 0.00795384
	LOSS [training: 0.012010238716787091 | validation: 0.009669506083595803]
	TIME [epoch: 35.6 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011498766653722913		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 0.011498766653722913 | validation: 0.017207061216615176]
	TIME [epoch: 35.6 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01287163936702928		[learning rate: 0.0078907]
	Learning Rate: 0.0078907
	LOSS [training: 0.01287163936702928 | validation: 0.018396628265799]
	TIME [epoch: 35.5 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012749380426092659		[learning rate: 0.0078593]
	Learning Rate: 0.00785931
	LOSS [training: 0.012749380426092659 | validation: 0.008052584456646455]
	TIME [epoch: 35.6 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011448711689688147		[learning rate: 0.0078281]
	Learning Rate: 0.00782805
	LOSS [training: 0.011448711689688147 | validation: 0.014080353398455325]
	TIME [epoch: 35.5 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011405420078646752		[learning rate: 0.0077969]
	Learning Rate: 0.00779692
	LOSS [training: 0.011405420078646752 | validation: 0.009953580055294271]
	TIME [epoch: 35.5 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01084399570459556		[learning rate: 0.0077659]
	Learning Rate: 0.00776591
	LOSS [training: 0.01084399570459556 | validation: 0.007868588383122996]
	TIME [epoch: 35.5 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.013461619471024826		[learning rate: 0.007735]
	Learning Rate: 0.00773502
	LOSS [training: 0.013461619471024826 | validation: 0.012113692646354524]
	TIME [epoch: 35.6 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009745972752403197		[learning rate: 0.0077043]
	Learning Rate: 0.00770426
	LOSS [training: 0.009745972752403197 | validation: 0.009451584914629624]
	TIME [epoch: 35.6 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.014070686597911811		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 0.014070686597911811 | validation: 0.008570387380923727]
	TIME [epoch: 35.5 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009639205150186448		[learning rate: 0.0076431]
	Learning Rate: 0.00764309
	LOSS [training: 0.009639205150186448 | validation: 0.025314303965637504]
	TIME [epoch: 35.5 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.016702888396883657		[learning rate: 0.0076127]
	Learning Rate: 0.00761269
	LOSS [training: 0.016702888396883657 | validation: 0.008500816240131642]
	TIME [epoch: 35.5 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00977647688418219		[learning rate: 0.0075824]
	Learning Rate: 0.00758242
	LOSS [training: 0.00977647688418219 | validation: 0.015142350022160045]
	TIME [epoch: 35.5 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012099920989872876		[learning rate: 0.0075523]
	Learning Rate: 0.00755226
	LOSS [training: 0.012099920989872876 | validation: 0.011871713958558225]
	TIME [epoch: 35.5 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010256929253214291		[learning rate: 0.0075222]
	Learning Rate: 0.00752222
	LOSS [training: 0.010256929253214291 | validation: 0.009676128911544474]
	TIME [epoch: 35.6 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01629160576133418		[learning rate: 0.0074923]
	Learning Rate: 0.0074923
	LOSS [training: 0.01629160576133418 | validation: 0.018614985744178837]
	TIME [epoch: 35.6 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010990813250002451		[learning rate: 0.0074625]
	Learning Rate: 0.0074625
	LOSS [training: 0.010990813250002451 | validation: 0.010016249375439986]
	TIME [epoch: 35.5 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010141142491331358		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 0.010141142491331358 | validation: 0.008007407028808705]
	TIME [epoch: 35.5 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008979446243801197		[learning rate: 0.0074033]
	Learning Rate: 0.00740326
	LOSS [training: 0.008979446243801197 | validation: 0.009908774585177516]
	TIME [epoch: 35.6 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011470066470247427		[learning rate: 0.0073738]
	Learning Rate: 0.00737382
	LOSS [training: 0.011470066470247427 | validation: 0.011354950478022166]
	TIME [epoch: 35.6 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011836913698821352		[learning rate: 0.0073445]
	Learning Rate: 0.00734449
	LOSS [training: 0.011836913698821352 | validation: 0.01333429748778377]
	TIME [epoch: 35.5 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009791604670911749		[learning rate: 0.0073153]
	Learning Rate: 0.00731528
	LOSS [training: 0.009791604670911749 | validation: 0.007861727100933394]
	TIME [epoch: 35.6 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01196478581944159		[learning rate: 0.0072862]
	Learning Rate: 0.00728618
	LOSS [training: 0.01196478581944159 | validation: 0.009125688279781404]
	TIME [epoch: 35.5 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011253484166471282		[learning rate: 0.0072572]
	Learning Rate: 0.0072572
	LOSS [training: 0.011253484166471282 | validation: 0.007821051088377908]
	TIME [epoch: 35.6 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010996874709110073		[learning rate: 0.0072283]
	Learning Rate: 0.00722834
	LOSS [training: 0.010996874709110073 | validation: 0.01432682106935718]
	TIME [epoch: 35.5 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01312493116497952		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 0.01312493116497952 | validation: 0.032914487455966]
	TIME [epoch: 35.6 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.018510703320836985		[learning rate: 0.007171]
	Learning Rate: 0.00717095
	LOSS [training: 0.018510703320836985 | validation: 0.010495067812164489]
	TIME [epoch: 35.5 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009395955328112236		[learning rate: 0.0071424]
	Learning Rate: 0.00714243
	LOSS [training: 0.009395955328112236 | validation: 0.011905012756686633]
	TIME [epoch: 35.5 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01086958735672536		[learning rate: 0.007114]
	Learning Rate: 0.00711403
	LOSS [training: 0.01086958735672536 | validation: 0.009108373800222594]
	TIME [epoch: 35.5 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008641018300980784		[learning rate: 0.0070857]
	Learning Rate: 0.00708573
	LOSS [training: 0.008641018300980784 | validation: 0.03199659746245467]
	TIME [epoch: 35.6 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.013478607210590065		[learning rate: 0.0070575]
	Learning Rate: 0.00705755
	LOSS [training: 0.013478607210590065 | validation: 0.013896644797308238]
	TIME [epoch: 35.6 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011688984473216833		[learning rate: 0.0070295]
	Learning Rate: 0.00702948
	LOSS [training: 0.011688984473216833 | validation: 0.009033881227156561]
	TIME [epoch: 35.6 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01001306674850236		[learning rate: 0.0070015]
	Learning Rate: 0.00700152
	LOSS [training: 0.01001306674850236 | validation: 0.007781052500914272]
	TIME [epoch: 35.5 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011301959175126166		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 0.011301959175126166 | validation: 0.007601261086962556]
	TIME [epoch: 35.5 sec]
	Saving model to: out/model_training/model_facs_dec1b_2d_v1_20240622_154550/states/model_facs_dec1b_2d_v1_135.pth
	Model improved!!!
EPOCH 136/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01502348760484034		[learning rate: 0.0069459]
	Learning Rate: 0.00694594
	LOSS [training: 0.01502348760484034 | validation: 0.01264657115905469]
	TIME [epoch: 35.6 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011484220545343149		[learning rate: 0.0069183]
	Learning Rate: 0.00691831
	LOSS [training: 0.011484220545343149 | validation: 0.011242258607085472]
	TIME [epoch: 35.6 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00995487180674367		[learning rate: 0.0068908]
	Learning Rate: 0.00689079
	LOSS [training: 0.00995487180674367 | validation: 0.010395015451521276]
	TIME [epoch: 35.6 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009550001350796044		[learning rate: 0.0068634]
	Learning Rate: 0.00686339
	LOSS [training: 0.009550001350796044 | validation: 0.013570264979097135]
	TIME [epoch: 35.6 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011476288490808027		[learning rate: 0.0068361]
	Learning Rate: 0.00683609
	LOSS [training: 0.011476288490808027 | validation: 0.009822329651885852]
	TIME [epoch: 35.5 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.013286397915426372		[learning rate: 0.0068089]
	Learning Rate: 0.0068089
	LOSS [training: 0.013286397915426372 | validation: 0.010377932449133175]
	TIME [epoch: 35.6 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010164034058793911		[learning rate: 0.0067818]
	Learning Rate: 0.00678182
	LOSS [training: 0.010164034058793911 | validation: 0.009530544261647922]
	TIME [epoch: 35.5 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01052593692512527		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 0.01052593692512527 | validation: 0.009215247873958905]
	TIME [epoch: 35.5 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010942505656725866		[learning rate: 0.006728]
	Learning Rate: 0.00672798
	LOSS [training: 0.010942505656725866 | validation: 0.009156342871301435]
	TIME [epoch: 35.5 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01285835744711083		[learning rate: 0.0067012]
	Learning Rate: 0.00670122
	LOSS [training: 0.01285835744711083 | validation: 0.00827603019577344]
	TIME [epoch: 35.6 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011361862928773519		[learning rate: 0.0066746]
	Learning Rate: 0.00667457
	LOSS [training: 0.011361862928773519 | validation: 0.020306791020049144]
	TIME [epoch: 35.5 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.013854376977515827		[learning rate: 0.006648]
	Learning Rate: 0.00664802
	LOSS [training: 0.013854376977515827 | validation: 0.009614838624261046]
	TIME [epoch: 35.5 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010816398678622566		[learning rate: 0.0066216]
	Learning Rate: 0.00662158
	LOSS [training: 0.010816398678622566 | validation: 0.009466991510636309]
	TIME [epoch: 35.5 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008235506758286089		[learning rate: 0.0065952]
	Learning Rate: 0.00659524
	LOSS [training: 0.008235506758286089 | validation: 0.009648143187658565]
	TIME [epoch: 35.6 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011819668619055874		[learning rate: 0.006569]
	Learning Rate: 0.00656901
	LOSS [training: 0.011819668619055874 | validation: 0.009323368411934974]
	TIME [epoch: 35.6 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01175541884753374		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 0.01175541884753374 | validation: 0.010071813478445338]
	TIME [epoch: 35.6 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01305769873128709		[learning rate: 0.0065169]
	Learning Rate: 0.00651686
	LOSS [training: 0.01305769873128709 | validation: 0.010701857973676008]
	TIME [epoch: 35.6 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009957791364571592		[learning rate: 0.0064909]
	Learning Rate: 0.00649094
	LOSS [training: 0.009957791364571592 | validation: 0.007802378971729791]
	TIME [epoch: 35.6 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011435236149250818		[learning rate: 0.0064651]
	Learning Rate: 0.00646512
	LOSS [training: 0.011435236149250818 | validation: 0.011311169368523114]
	TIME [epoch: 35.6 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011013144423074437		[learning rate: 0.0064394]
	Learning Rate: 0.00643941
	LOSS [training: 0.011013144423074437 | validation: 0.00997699271963332]
	TIME [epoch: 35.6 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011943523520953049		[learning rate: 0.0064138]
	Learning Rate: 0.0064138
	LOSS [training: 0.011943523520953049 | validation: 0.011328440667237785]
	TIME [epoch: 35.6 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010393887269524636		[learning rate: 0.0063883]
	Learning Rate: 0.00638829
	LOSS [training: 0.010393887269524636 | validation: 0.015453942372068413]
	TIME [epoch: 35.6 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.013414539476655983		[learning rate: 0.0063629]
	Learning Rate: 0.00636288
	LOSS [training: 0.013414539476655983 | validation: 0.009521572670852903]
	TIME [epoch: 35.6 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012811531855509916		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 0.012811531855509916 | validation: 0.010458299660872986]
	TIME [epoch: 35.6 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011542603342014464		[learning rate: 0.0063124]
	Learning Rate: 0.00631237
	LOSS [training: 0.011542603342014464 | validation: 0.008612114610434088]
	TIME [epoch: 35.5 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00987537856474368		[learning rate: 0.0062873]
	Learning Rate: 0.00628726
	LOSS [training: 0.00987537856474368 | validation: 0.010894159225610368]
	TIME [epoch: 35.6 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010019684462859106		[learning rate: 0.0062623]
	Learning Rate: 0.00626226
	LOSS [training: 0.010019684462859106 | validation: 0.012052168473407928]
	TIME [epoch: 35.6 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011389622864277528		[learning rate: 0.0062373]
	Learning Rate: 0.00623735
	LOSS [training: 0.011389622864277528 | validation: 0.009523660758310215]
	TIME [epoch: 35.6 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01093155001304351		[learning rate: 0.0062125]
	Learning Rate: 0.00621254
	LOSS [training: 0.01093155001304351 | validation: 0.011402624657557554]
	TIME [epoch: 35.6 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012239933566364986		[learning rate: 0.0061878]
	Learning Rate: 0.00618783
	LOSS [training: 0.012239933566364986 | validation: 0.010825404062424476]
	TIME [epoch: 35.6 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012351484027038971		[learning rate: 0.0061632]
	Learning Rate: 0.00616322
	LOSS [training: 0.012351484027038971 | validation: 0.012382756359851213]
	TIME [epoch: 35.6 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011370900332765827		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 0.011370900332765827 | validation: 0.009152448583656972]
	TIME [epoch: 35.6 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.013380915776367113		[learning rate: 0.0061143]
	Learning Rate: 0.00611429
	LOSS [training: 0.013380915776367113 | validation: 0.010115525264798357]
	TIME [epoch: 35.6 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.015199828140640173		[learning rate: 0.00609]
	Learning Rate: 0.00608997
	LOSS [training: 0.015199828140640173 | validation: 0.011912025671126907]
	TIME [epoch: 35.6 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009942050133102617		[learning rate: 0.0060658]
	Learning Rate: 0.00606575
	LOSS [training: 0.009942050133102617 | validation: 0.008259338254724144]
	TIME [epoch: 35.6 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011432987475161227		[learning rate: 0.0060416]
	Learning Rate: 0.00604163
	LOSS [training: 0.011432987475161227 | validation: 0.00872699823604663]
	TIME [epoch: 35.5 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010768684069515958		[learning rate: 0.0060176]
	Learning Rate: 0.0060176
	LOSS [training: 0.010768684069515958 | validation: 0.007516422669426768]
	TIME [epoch: 35.6 sec]
	Saving model to: out/model_training/model_facs_dec1b_2d_v1_20240622_154550/states/model_facs_dec1b_2d_v1_172.pth
	Model improved!!!
EPOCH 173/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009474069988204558		[learning rate: 0.0059937]
	Learning Rate: 0.00599366
	LOSS [training: 0.009474069988204558 | validation: 0.013487643194002525]
	TIME [epoch: 35.6 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011316703254818376		[learning rate: 0.0059698]
	Learning Rate: 0.00596982
	LOSS [training: 0.011316703254818376 | validation: 0.009155301517221059]
	TIME [epoch: 35.5 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010590755801037334		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 0.010590755801037334 | validation: 0.010343215041752823]
	TIME [epoch: 35.6 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010425098538269314		[learning rate: 0.0059224]
	Learning Rate: 0.00592243
	LOSS [training: 0.010425098538269314 | validation: 0.01321311806127864]
	TIME [epoch: 35.6 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009342401077621921		[learning rate: 0.0058989]
	Learning Rate: 0.00589888
	LOSS [training: 0.009342401077621921 | validation: 0.008677789454165669]
	TIME [epoch: 35.6 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011191750830753838		[learning rate: 0.0058754]
	Learning Rate: 0.00587541
	LOSS [training: 0.011191750830753838 | validation: 0.008963552505296573]
	TIME [epoch: 35.6 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010279630748529405		[learning rate: 0.005852]
	Learning Rate: 0.00585205
	LOSS [training: 0.010279630748529405 | validation: 0.007763602868930448]
	TIME [epoch: 35.6 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009860011862793809		[learning rate: 0.0058288]
	Learning Rate: 0.00582877
	LOSS [training: 0.009860011862793809 | validation: 0.009946356365018779]
	TIME [epoch: 35.7 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009667304098749604		[learning rate: 0.0058056]
	Learning Rate: 0.00580559
	LOSS [training: 0.009667304098749604 | validation: 0.01198038180570343]
	TIME [epoch: 35.6 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009672063219463973		[learning rate: 0.0057825]
	Learning Rate: 0.0057825
	LOSS [training: 0.009672063219463973 | validation: 0.014164561758762333]
	TIME [epoch: 35.6 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010599798424648234		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 0.010599798424648234 | validation: 0.012726609534066808]
	TIME [epoch: 35.6 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011988182508637459		[learning rate: 0.0057366]
	Learning Rate: 0.00573659
	LOSS [training: 0.011988182508637459 | validation: 0.00755189680329262]
	TIME [epoch: 35.6 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008044313806918463		[learning rate: 0.0057138]
	Learning Rate: 0.00571377
	LOSS [training: 0.008044313806918463 | validation: 0.010871054850873429]
	TIME [epoch: 35.5 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00990098553705104		[learning rate: 0.005691]
	Learning Rate: 0.00569105
	LOSS [training: 0.00990098553705104 | validation: 0.010406499052288668]
	TIME [epoch: 35.6 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012178508408716168		[learning rate: 0.0056684]
	Learning Rate: 0.00566841
	LOSS [training: 0.012178508408716168 | validation: 0.007378598817842241]
	TIME [epoch: 35.6 sec]
	Saving model to: out/model_training/model_facs_dec1b_2d_v1_20240622_154550/states/model_facs_dec1b_2d_v1_187.pth
	Model improved!!!
EPOCH 188/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009404186018001361		[learning rate: 0.0056459]
	Learning Rate: 0.00564587
	LOSS [training: 0.009404186018001361 | validation: 0.007742885400782784]
	TIME [epoch: 35.6 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010700222940505953		[learning rate: 0.0056234]
	Learning Rate: 0.00562341
	LOSS [training: 0.010700222940505953 | validation: 0.01739810386274184]
	TIME [epoch: 35.6 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012879927623104843		[learning rate: 0.005601]
	Learning Rate: 0.00560105
	LOSS [training: 0.012879927623104843 | validation: 0.013631832263837304]
	TIME [epoch: 35.5 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012118972432272439		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 0.012118972432272439 | validation: 0.007016961848552508]
	TIME [epoch: 35.6 sec]
	Saving model to: out/model_training/model_facs_dec1b_2d_v1_20240622_154550/states/model_facs_dec1b_2d_v1_191.pth
	Model improved!!!
EPOCH 192/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01144071722855759		[learning rate: 0.0055566]
	Learning Rate: 0.00555658
	LOSS [training: 0.01144071722855759 | validation: 0.007875267345039077]
	TIME [epoch: 35.6 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008898784131161745		[learning rate: 0.0055345]
	Learning Rate: 0.00553448
	LOSS [training: 0.008898784131161745 | validation: 0.006887549510329341]
	TIME [epoch: 35.6 sec]
	Saving model to: out/model_training/model_facs_dec1b_2d_v1_20240622_154550/states/model_facs_dec1b_2d_v1_193.pth
	Model improved!!!
EPOCH 194/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010195922321747866		[learning rate: 0.0055125]
	Learning Rate: 0.00551247
	LOSS [training: 0.010195922321747866 | validation: 0.013609666541859005]
	TIME [epoch: 35.7 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011882208203985596		[learning rate: 0.0054905]
	Learning Rate: 0.00549054
	LOSS [training: 0.011882208203985596 | validation: 0.014495328541548776]
	TIME [epoch: 35.7 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010632217002284028		[learning rate: 0.0054687]
	Learning Rate: 0.00546871
	LOSS [training: 0.010632217002284028 | validation: 0.012166803131894768]
	TIME [epoch: 35.6 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011055756246659337		[learning rate: 0.005447]
	Learning Rate: 0.00544696
	LOSS [training: 0.011055756246659337 | validation: 0.009849076925108552]
	TIME [epoch: 35.6 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012622642385229924		[learning rate: 0.0054253]
	Learning Rate: 0.00542529
	LOSS [training: 0.012622642385229924 | validation: 0.009247818728659181]
	TIME [epoch: 35.6 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010063662195241222		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 0.010063662195241222 | validation: 0.01006222276350123]
	TIME [epoch: 35.6 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011420011861125455		[learning rate: 0.0053822]
	Learning Rate: 0.00538222
	LOSS [training: 0.011420011861125455 | validation: 0.007727227612277431]
	TIME [epoch: 35.6 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010310940323802415		[learning rate: 0.0053608]
	Learning Rate: 0.00536081
	LOSS [training: 0.010310940323802415 | validation: 0.007436162116533557]
	TIME [epoch: 35.6 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010061755469300389		[learning rate: 0.0053395]
	Learning Rate: 0.00533949
	LOSS [training: 0.010061755469300389 | validation: 0.015423736006542038]
	TIME [epoch: 35.5 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012469162115824843		[learning rate: 0.0053183]
	Learning Rate: 0.00531826
	LOSS [training: 0.012469162115824843 | validation: 0.009615621817281237]
	TIME [epoch: 35.5 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012456939312667881		[learning rate: 0.0052971]
	Learning Rate: 0.0052971
	LOSS [training: 0.012456939312667881 | validation: 0.009766494741052578]
	TIME [epoch: 35.5 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012147417280620089		[learning rate: 0.005276]
	Learning Rate: 0.00527604
	LOSS [training: 0.012147417280620089 | validation: 0.00888792867616282]
	TIME [epoch: 35.6 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009096215590855057		[learning rate: 0.0052551]
	Learning Rate: 0.00525505
	LOSS [training: 0.009096215590855057 | validation: 0.009562285236370932]
	TIME [epoch: 35.6 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011131499322334109		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 0.011131499322334109 | validation: 0.01556026638906401]
	TIME [epoch: 35.6 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011168943779719465		[learning rate: 0.0052133]
	Learning Rate: 0.00521333
	LOSS [training: 0.011168943779719465 | validation: 0.013920675092324353]
	TIME [epoch: 35.6 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01158839188024635		[learning rate: 0.0051926]
	Learning Rate: 0.0051926
	LOSS [training: 0.01158839188024635 | validation: 0.00804515986391071]
	TIME [epoch: 35.6 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00896518336220636		[learning rate: 0.0051719]
	Learning Rate: 0.00517194
	LOSS [training: 0.00896518336220636 | validation: 0.0077872791322545045]
	TIME [epoch: 35.6 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009363432872831768		[learning rate: 0.0051514]
	Learning Rate: 0.00515137
	LOSS [training: 0.009363432872831768 | validation: 0.010358371965958022]
	TIME [epoch: 35.6 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.015564119726774338		[learning rate: 0.0051309]
	Learning Rate: 0.00513089
	LOSS [training: 0.015564119726774338 | validation: 0.007694352166546192]
	TIME [epoch: 35.5 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01136647417036686		[learning rate: 0.0051105]
	Learning Rate: 0.00511048
	LOSS [training: 0.01136647417036686 | validation: 0.010017375428515352]
	TIME [epoch: 35.6 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00918821200005276		[learning rate: 0.0050902]
	Learning Rate: 0.00509015
	LOSS [training: 0.00918821200005276 | validation: 0.007058007521258243]
	TIME [epoch: 35.6 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0095381000112554		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 0.0095381000112554 | validation: 0.011729127649974386]
	TIME [epoch: 35.6 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011179386307797284		[learning rate: 0.0050497]
	Learning Rate: 0.00504974
	LOSS [training: 0.011179386307797284 | validation: 0.011594130251499832]
	TIME [epoch: 35.6 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011407141536334405		[learning rate: 0.0050297]
	Learning Rate: 0.00502966
	LOSS [training: 0.011407141536334405 | validation: 0.009650774670342983]
	TIME [epoch: 35.6 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009346490430324489		[learning rate: 0.0050097]
	Learning Rate: 0.00500965
	LOSS [training: 0.009346490430324489 | validation: 0.007478978726244567]
	TIME [epoch: 35.6 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009991729882729604		[learning rate: 0.0049897]
	Learning Rate: 0.00498973
	LOSS [training: 0.009991729882729604 | validation: 0.009547944703812847]
	TIME [epoch: 35.6 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010151799459749894		[learning rate: 0.0049699]
	Learning Rate: 0.00496988
	LOSS [training: 0.010151799459749894 | validation: 0.00975169670247431]
	TIME [epoch: 35.6 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011107477470102343		[learning rate: 0.0049501]
	Learning Rate: 0.00495012
	LOSS [training: 0.011107477470102343 | validation: 0.007212881328273052]
	TIME [epoch: 35.6 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010522065201650133		[learning rate: 0.0049304]
	Learning Rate: 0.00493043
	LOSS [training: 0.010522065201650133 | validation: 0.008024753869526408]
	TIME [epoch: 35.7 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.014732979554410589		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 0.014732979554410589 | validation: 0.007692174420589346]
	TIME [epoch: 35.6 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00890118637202583		[learning rate: 0.0048913]
	Learning Rate: 0.00489129
	LOSS [training: 0.00890118637202583 | validation: 0.008888790994141384]
	TIME [epoch: 35.6 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012683345901168295		[learning rate: 0.0048718]
	Learning Rate: 0.00487183
	LOSS [training: 0.012683345901168295 | validation: 0.012348355940679246]
	TIME [epoch: 35.5 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012976020457726896		[learning rate: 0.0048525]
	Learning Rate: 0.00485245
	LOSS [training: 0.012976020457726896 | validation: 0.009479989600073187]
	TIME [epoch: 35.6 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011328801750562952		[learning rate: 0.0048332]
	Learning Rate: 0.00483316
	LOSS [training: 0.011328801750562952 | validation: 0.016947695497741267]
	TIME [epoch: 35.6 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012615947798814626		[learning rate: 0.0048139]
	Learning Rate: 0.00481393
	LOSS [training: 0.012615947798814626 | validation: 0.010337778542422172]
	TIME [epoch: 35.5 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00840078818634536		[learning rate: 0.0047948]
	Learning Rate: 0.00479479
	LOSS [training: 0.00840078818634536 | validation: 0.0146002151849448]
	TIME [epoch: 35.6 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010345813114636605		[learning rate: 0.0047757]
	Learning Rate: 0.00477572
	LOSS [training: 0.010345813114636605 | validation: 0.009781229814255294]
	TIME [epoch: 35.7 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011247193502467565		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.011247193502467565 | validation: 0.007708386862188566]
	TIME [epoch: 35.6 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011070416390219152		[learning rate: 0.0047378]
	Learning Rate: 0.0047378
	LOSS [training: 0.011070416390219152 | validation: 0.010084188436806573]
	TIME [epoch: 35.6 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009741409106844403		[learning rate: 0.004719]
	Learning Rate: 0.00471896
	LOSS [training: 0.009741409106844403 | validation: 0.007472392143223377]
	TIME [epoch: 35.6 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00916102122490802		[learning rate: 0.0047002]
	Learning Rate: 0.00470019
	LOSS [training: 0.00916102122490802 | validation: 0.012450042451323053]
	TIME [epoch: 35.6 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011466295089995044		[learning rate: 0.0046815]
	Learning Rate: 0.0046815
	LOSS [training: 0.011466295089995044 | validation: 0.008029009903329092]
	TIME [epoch: 35.5 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009680333129361661		[learning rate: 0.0046629]
	Learning Rate: 0.00466288
	LOSS [training: 0.009680333129361661 | validation: 0.008746731674920044]
	TIME [epoch: 35.6 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008820216147734842		[learning rate: 0.0046443]
	Learning Rate: 0.00464433
	LOSS [training: 0.008820216147734842 | validation: 0.007043583955305062]
	TIME [epoch: 35.6 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011947270661005883		[learning rate: 0.0046259]
	Learning Rate: 0.00462586
	LOSS [training: 0.011947270661005883 | validation: 0.008424598570939237]
	TIME [epoch: 35.6 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010718834729677489		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 0.010718834729677489 | validation: 0.008105573754783175]
	TIME [epoch: 35.6 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010639048482165868		[learning rate: 0.0045891]
	Learning Rate: 0.00458913
	LOSS [training: 0.010639048482165868 | validation: 0.009747692253571217]
	TIME [epoch: 35.6 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009505041565793891		[learning rate: 0.0045709]
	Learning Rate: 0.00457088
	LOSS [training: 0.009505041565793891 | validation: 0.0073752085502799825]
	TIME [epoch: 35.6 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009414096884533821		[learning rate: 0.0045527]
	Learning Rate: 0.0045527
	LOSS [training: 0.009414096884533821 | validation: 0.009583725416724222]
	TIME [epoch: 35.6 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011461879451897696		[learning rate: 0.0045346]
	Learning Rate: 0.00453459
	LOSS [training: 0.011461879451897696 | validation: 0.007608847175774201]
	TIME [epoch: 35.6 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01029890334353342		[learning rate: 0.0045166]
	Learning Rate: 0.00451656
	LOSS [training: 0.01029890334353342 | validation: 0.008555892738446742]
	TIME [epoch: 35.6 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00886488721698941		[learning rate: 0.0044986]
	Learning Rate: 0.0044986
	LOSS [training: 0.00886488721698941 | validation: 0.0073071299975380685]
	TIME [epoch: 35.6 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010287055271038853		[learning rate: 0.0044807]
	Learning Rate: 0.0044807
	LOSS [training: 0.010287055271038853 | validation: 0.00988456587452918]
	TIME [epoch: 35.7 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010292903554846848		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 0.010292903554846848 | validation: 0.009277611184774789]
	TIME [epoch: 35.6 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008600116104264461		[learning rate: 0.0044451]
	Learning Rate: 0.00444513
	LOSS [training: 0.008600116104264461 | validation: 0.008910976249682645]
	TIME [epoch: 35.6 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009982122769293333		[learning rate: 0.0044275]
	Learning Rate: 0.00442745
	LOSS [training: 0.009982122769293333 | validation: 0.008389536601195697]
	TIME [epoch: 35.6 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009811371200238348		[learning rate: 0.0044098]
	Learning Rate: 0.00440984
	LOSS [training: 0.009811371200238348 | validation: 0.00994734405345847]
	TIME [epoch: 35.6 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011438886419031501		[learning rate: 0.0043923]
	Learning Rate: 0.0043923
	LOSS [training: 0.011438886419031501 | validation: 0.0076276241420813445]
	TIME [epoch: 35.5 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01100504023322609		[learning rate: 0.0043748]
	Learning Rate: 0.00437483
	LOSS [training: 0.01100504023322609 | validation: 0.008824791154266317]
	TIME [epoch: 35.5 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008959824236327811		[learning rate: 0.0043574]
	Learning Rate: 0.00435743
	LOSS [training: 0.008959824236327811 | validation: 0.008735238157440853]
	TIME [epoch: 35.7 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01022767856747288		[learning rate: 0.0043401]
	Learning Rate: 0.0043401
	LOSS [training: 0.01022767856747288 | validation: 0.009210277282810184]
	TIME [epoch: 35.6 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009453726796525702		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 0.009453726796525702 | validation: 0.009024767576010015]
	TIME [epoch: 35.6 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010404301599045793		[learning rate: 0.0043056]
	Learning Rate: 0.00430565
	LOSS [training: 0.010404301599045793 | validation: 0.008267857942066716]
	TIME [epoch: 35.6 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009993642735870603		[learning rate: 0.0042885]
	Learning Rate: 0.00428852
	LOSS [training: 0.009993642735870603 | validation: 0.008310783565647736]
	TIME [epoch: 35.6 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009145819926002602		[learning rate: 0.0042715]
	Learning Rate: 0.00427147
	LOSS [training: 0.009145819926002602 | validation: 0.010968195175352014]
	TIME [epoch: 35.6 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010848158909039323		[learning rate: 0.0042545]
	Learning Rate: 0.00425448
	LOSS [training: 0.010848158909039323 | validation: 0.007901048318180939]
	TIME [epoch: 35.5 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011344917528501523		[learning rate: 0.0042376]
	Learning Rate: 0.00423756
	LOSS [training: 0.011344917528501523 | validation: 0.008593991869000317]
	TIME [epoch: 35.7 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009091322416302733		[learning rate: 0.0042207]
	Learning Rate: 0.0042207
	LOSS [training: 0.009091322416302733 | validation: 0.00935320587609231]
	TIME [epoch: 35.6 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009208634022112389		[learning rate: 0.0042039]
	Learning Rate: 0.00420391
	LOSS [training: 0.009208634022112389 | validation: 0.012584439229392185]
	TIME [epoch: 35.6 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010598989843531298		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 0.010598989843531298 | validation: 0.008951003095746857]
	TIME [epoch: 35.6 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009545694179141037		[learning rate: 0.0041705]
	Learning Rate: 0.00417054
	LOSS [training: 0.009545694179141037 | validation: 0.0071757640258169495]
	TIME [epoch: 35.6 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009686622548599734		[learning rate: 0.004154]
	Learning Rate: 0.00415395
	LOSS [training: 0.009686622548599734 | validation: 0.008400070630466763]
	TIME [epoch: 35.6 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010440464106791931		[learning rate: 0.0041374]
	Learning Rate: 0.00413743
	LOSS [training: 0.010440464106791931 | validation: 0.008663860536721853]
	TIME [epoch: 35.6 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012883363784796058		[learning rate: 0.004121]
	Learning Rate: 0.00412098
	LOSS [training: 0.012883363784796058 | validation: 0.006808399927710802]
	TIME [epoch: 35.6 sec]
	Saving model to: out/model_training/model_facs_dec1b_2d_v1_20240622_154550/states/model_facs_dec1b_2d_v1_267.pth
	Model improved!!!
EPOCH 268/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008621454487082488		[learning rate: 0.0041046]
	Learning Rate: 0.00410458
	LOSS [training: 0.008621454487082488 | validation: 0.009415750076458982]
	TIME [epoch: 35.6 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009847304527118603		[learning rate: 0.0040883]
	Learning Rate: 0.00408826
	LOSS [training: 0.009847304527118603 | validation: 0.00967415785918629]
	TIME [epoch: 35.6 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009853195549312929		[learning rate: 0.004072]
	Learning Rate: 0.004072
	LOSS [training: 0.009853195549312929 | validation: 0.007895803058706324]
	TIME [epoch: 35.6 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011174676180911237		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.011174676180911237 | validation: 0.012468258412548155]
	TIME [epoch: 35.6 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01121109190603168		[learning rate: 0.0040397]
	Learning Rate: 0.00403967
	LOSS [training: 0.01121109190603168 | validation: 0.016318385281468718]
	TIME [epoch: 35.6 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011657145472680347		[learning rate: 0.0040236]
	Learning Rate: 0.00402361
	LOSS [training: 0.011657145472680347 | validation: 0.008438698131153704]
	TIME [epoch: 35.6 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009901992631724922		[learning rate: 0.0040076]
	Learning Rate: 0.0040076
	LOSS [training: 0.009901992631724922 | validation: 0.007191146332283802]
	TIME [epoch: 35.5 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01038012273797172		[learning rate: 0.0039917]
	Learning Rate: 0.00399166
	LOSS [training: 0.01038012273797172 | validation: 0.007952341432919115]
	TIME [epoch: 35.6 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009700712158323096		[learning rate: 0.0039758]
	Learning Rate: 0.00397579
	LOSS [training: 0.009700712158323096 | validation: 0.0095282330236484]
	TIME [epoch: 35.6 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010478550283337253		[learning rate: 0.00396]
	Learning Rate: 0.00395997
	LOSS [training: 0.010478550283337253 | validation: 0.00811646966598752]
	TIME [epoch: 35.6 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012650721123603572		[learning rate: 0.0039442]
	Learning Rate: 0.00394422
	LOSS [training: 0.012650721123603572 | validation: 0.00836301985628321]
	TIME [epoch: 35.6 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009218184738236969		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 0.009218184738236969 | validation: 0.008741077587106613]
	TIME [epoch: 35.6 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009156392991445023		[learning rate: 0.0039129]
	Learning Rate: 0.00391291
	LOSS [training: 0.009156392991445023 | validation: 0.012877385049587908]
	TIME [epoch: 35.6 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01093397826694734		[learning rate: 0.0038973]
	Learning Rate: 0.00389735
	LOSS [training: 0.01093397826694734 | validation: 0.011325402240514433]
	TIME [epoch: 35.6 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011841178324362581		[learning rate: 0.0038818]
	Learning Rate: 0.00388185
	LOSS [training: 0.011841178324362581 | validation: 0.007694302141002583]
	TIME [epoch: 35.6 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008535178890026215		[learning rate: 0.0038664]
	Learning Rate: 0.00386641
	LOSS [training: 0.008535178890026215 | validation: 0.011344369677809569]
	TIME [epoch: 35.6 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010050959341711697		[learning rate: 0.003851]
	Learning Rate: 0.00385103
	LOSS [training: 0.010050959341711697 | validation: 0.007131292994119689]
	TIME [epoch: 35.6 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011100848239855967		[learning rate: 0.0038357]
	Learning Rate: 0.00383571
	LOSS [training: 0.011100848239855967 | validation: 0.00743422439115525]
	TIME [epoch: 35.6 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009627202166781552		[learning rate: 0.0038205]
	Learning Rate: 0.00382046
	LOSS [training: 0.009627202166781552 | validation: 0.00902543156329763]
	TIME [epoch: 35.6 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008437581816766383		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 0.008437581816766383 | validation: 0.008931461220604864]
	TIME [epoch: 35.7 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010604798681712428		[learning rate: 0.0037901]
	Learning Rate: 0.00379013
	LOSS [training: 0.010604798681712428 | validation: 0.009365880250652278]
	TIME [epoch: 35.6 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009754056806066162		[learning rate: 0.0037751]
	Learning Rate: 0.00377505
	LOSS [training: 0.009754056806066162 | validation: 0.009862017140412998]
	TIME [epoch: 35.6 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01130067035348188		[learning rate: 0.00376]
	Learning Rate: 0.00376004
	LOSS [training: 0.01130067035348188 | validation: 0.007573324984418287]
	TIME [epoch: 35.6 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010316579493729126		[learning rate: 0.0037451]
	Learning Rate: 0.00374508
	LOSS [training: 0.010316579493729126 | validation: 0.009261525960824853]
	TIME [epoch: 35.6 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00946753492426069		[learning rate: 0.0037302]
	Learning Rate: 0.00373019
	LOSS [training: 0.00946753492426069 | validation: 0.01038380911654851]
	TIME [epoch: 35.5 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009799164931590878		[learning rate: 0.0037154]
	Learning Rate: 0.00371535
	LOSS [training: 0.009799164931590878 | validation: 0.010655395315917377]
	TIME [epoch: 35.6 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011878302349327538		[learning rate: 0.0037006]
	Learning Rate: 0.00370058
	LOSS [training: 0.011878302349327538 | validation: 0.009692620008427598]
	TIME [epoch: 35.6 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010470288312465728		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 0.010470288312465728 | validation: 0.007543971989115997]
	TIME [epoch: 35.6 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008774742025708573		[learning rate: 0.0036712]
	Learning Rate: 0.0036712
	LOSS [training: 0.008774742025708573 | validation: 0.007763915845810524]
	TIME [epoch: 35.6 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009161659724199448		[learning rate: 0.0036566]
	Learning Rate: 0.0036566
	LOSS [training: 0.009161659724199448 | validation: 0.011982903464189537]
	TIME [epoch: 35.6 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009547771778249024		[learning rate: 0.0036421]
	Learning Rate: 0.00364205
	LOSS [training: 0.009547771778249024 | validation: 0.00828882528260988]
	TIME [epoch: 35.5 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008911973129868273		[learning rate: 0.0036276]
	Learning Rate: 0.00362757
	LOSS [training: 0.008911973129868273 | validation: 0.007808710648293929]
	TIME [epoch: 35.6 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008366588523510169		[learning rate: 0.0036131]
	Learning Rate: 0.00361314
	LOSS [training: 0.008366588523510169 | validation: 0.008262909195718376]
	TIME [epoch: 35.6 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009788371204734114		[learning rate: 0.0035988]
	Learning Rate: 0.00359877
	LOSS [training: 0.009788371204734114 | validation: 0.007927942570017919]
	TIME [epoch: 35.7 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010024033746711743		[learning rate: 0.0035845]
	Learning Rate: 0.00358445
	LOSS [training: 0.010024033746711743 | validation: 0.007480922838805562]
	TIME [epoch: 35.6 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012332284223255434		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 0.012332284223255434 | validation: 0.007404200177747752]
	TIME [epoch: 35.6 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007878158966194374		[learning rate: 0.003556]
	Learning Rate: 0.003556
	LOSS [training: 0.007878158966194374 | validation: 0.011121177741953538]
	TIME [epoch: 35.6 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009558131711608932		[learning rate: 0.0035419]
	Learning Rate: 0.00354185
	LOSS [training: 0.009558131711608932 | validation: 0.008665798377231488]
	TIME [epoch: 35.6 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009175154002538384		[learning rate: 0.0035278]
	Learning Rate: 0.00352777
	LOSS [training: 0.009175154002538384 | validation: 0.008299091568961777]
	TIME [epoch: 35.6 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01040313760215596		[learning rate: 0.0035137]
	Learning Rate: 0.00351374
	LOSS [training: 0.01040313760215596 | validation: 0.007202336705017248]
	TIME [epoch: 35.6 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012268331462385436		[learning rate: 0.0034998]
	Learning Rate: 0.00349976
	LOSS [training: 0.012268331462385436 | validation: 0.00810214825437167]
	TIME [epoch: 35.6 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01122983280814725		[learning rate: 0.0034858]
	Learning Rate: 0.00348584
	LOSS [training: 0.01122983280814725 | validation: 0.007827463771979608]
	TIME [epoch: 35.6 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009929107718899753		[learning rate: 0.003472]
	Learning Rate: 0.00347198
	LOSS [training: 0.009929107718899753 | validation: 0.007429818494489498]
	TIME [epoch: 35.5 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008172365614041851		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.008172365614041851 | validation: 0.008696591274098699]
	TIME [epoch: 35.6 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010231053020018083		[learning rate: 0.0034444]
	Learning Rate: 0.00344441
	LOSS [training: 0.010231053020018083 | validation: 0.007270137180230729]
	TIME [epoch: 35.6 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010726079374388162		[learning rate: 0.0034307]
	Learning Rate: 0.00343071
	LOSS [training: 0.010726079374388162 | validation: 0.006886336555521369]
	TIME [epoch: 35.6 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009039749509968643		[learning rate: 0.0034171]
	Learning Rate: 0.00341707
	LOSS [training: 0.009039749509968643 | validation: 0.01093309481624194]
	TIME [epoch: 35.6 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009678228067435558		[learning rate: 0.0034035]
	Learning Rate: 0.00340348
	LOSS [training: 0.009678228067435558 | validation: 0.010207982588397294]
	TIME [epoch: 35.6 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009505775670087428		[learning rate: 0.0033899]
	Learning Rate: 0.00338994
	LOSS [training: 0.009505775670087428 | validation: 0.007548200334120821]
	TIME [epoch: 35.5 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008641824264737386		[learning rate: 0.0033765]
	Learning Rate: 0.00337646
	LOSS [training: 0.008641824264737386 | validation: 0.008475219885410633]
	TIME [epoch: 35.6 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0089242249549961		[learning rate: 0.003363]
	Learning Rate: 0.00336303
	LOSS [training: 0.0089242249549961 | validation: 0.008037767529621051]
	TIME [epoch: 35.5 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009285294189560365		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 0.009285294189560365 | validation: 0.00801627134978272]
	TIME [epoch: 35.6 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008652621653583208		[learning rate: 0.0033363]
	Learning Rate: 0.00333633
	LOSS [training: 0.008652621653583208 | validation: 0.008096445643113591]
	TIME [epoch: 35.5 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009669824991735299		[learning rate: 0.0033231]
	Learning Rate: 0.00332306
	LOSS [training: 0.009669824991735299 | validation: 0.008301838217025433]
	TIME [epoch: 35.6 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009782561947538756		[learning rate: 0.0033098]
	Learning Rate: 0.00330985
	LOSS [training: 0.009782561947538756 | validation: 0.008321996493288634]
	TIME [epoch: 35.5 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010903311073977287		[learning rate: 0.0032967]
	Learning Rate: 0.00329668
	LOSS [training: 0.010903311073977287 | validation: 0.007988267616993347]
	TIME [epoch: 35.6 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00984390382472778		[learning rate: 0.0032836]
	Learning Rate: 0.00328357
	LOSS [training: 0.00984390382472778 | validation: 0.007389435858530105]
	TIME [epoch: 35.5 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00871550530831253		[learning rate: 0.0032705]
	Learning Rate: 0.00327051
	LOSS [training: 0.00871550530831253 | validation: 0.009821708435467185]
	TIME [epoch: 35.5 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011688016685141184		[learning rate: 0.0032575]
	Learning Rate: 0.0032575
	LOSS [training: 0.011688016685141184 | validation: 0.00805534013324257]
	TIME [epoch: 35.5 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010614840783081633		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 0.010614840783081633 | validation: 0.007780657504249726]
	TIME [epoch: 35.5 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008957991146179426		[learning rate: 0.0032316]
	Learning Rate: 0.00323164
	LOSS [training: 0.008957991146179426 | validation: 0.007488234547585048]
	TIME [epoch: 35.6 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009643147360016336		[learning rate: 0.0032188]
	Learning Rate: 0.00321879
	LOSS [training: 0.009643147360016336 | validation: 0.009203471151868259]
	TIME [epoch: 35.5 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009392334028470214		[learning rate: 0.003206]
	Learning Rate: 0.00320599
	LOSS [training: 0.009392334028470214 | validation: 0.008432131008958788]
	TIME [epoch: 35.5 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009033717308446246		[learning rate: 0.0031932]
	Learning Rate: 0.00319323
	LOSS [training: 0.009033717308446246 | validation: 0.007110869044298846]
	TIME [epoch: 35.6 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010496231993065252		[learning rate: 0.0031805]
	Learning Rate: 0.00318053
	LOSS [training: 0.010496231993065252 | validation: 0.008752685451778538]
	TIME [epoch: 35.5 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008808649718733245		[learning rate: 0.0031679]
	Learning Rate: 0.00316788
	LOSS [training: 0.008808649718733245 | validation: 0.009459629417635989]
	TIME [epoch: 35.6 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012763752514072631		[learning rate: 0.0031553]
	Learning Rate: 0.00315528
	LOSS [training: 0.012763752514072631 | validation: 0.007954187354703138]
	TIME [epoch: 35.5 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009195750636869334		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 0.009195750636869334 | validation: 0.007582136212545487]
	TIME [epoch: 35.5 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008975808042921281		[learning rate: 0.0031302]
	Learning Rate: 0.00313023
	LOSS [training: 0.008975808042921281 | validation: 0.008004685501941746]
	TIME [epoch: 35.5 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009945788920021771		[learning rate: 0.0031178]
	Learning Rate: 0.00311779
	LOSS [training: 0.009945788920021771 | validation: 0.00830989152826982]
	TIME [epoch: 35.6 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008802763986238088		[learning rate: 0.0031054]
	Learning Rate: 0.00310538
	LOSS [training: 0.008802763986238088 | validation: 0.00902859344728281]
	TIME [epoch: 35.5 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009812862976252232		[learning rate: 0.003093]
	Learning Rate: 0.00309303
	LOSS [training: 0.009812862976252232 | validation: 0.009232362138937519]
	TIME [epoch: 35.6 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011721232765109389		[learning rate: 0.0030807]
	Learning Rate: 0.00308073
	LOSS [training: 0.011721232765109389 | validation: 0.010622064434559575]
	TIME [epoch: 35.5 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00876673056250027		[learning rate: 0.0030685]
	Learning Rate: 0.00306848
	LOSS [training: 0.00876673056250027 | validation: 0.007188071278222972]
	TIME [epoch: 35.6 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00954087045071565		[learning rate: 0.0030563]
	Learning Rate: 0.00305627
	LOSS [training: 0.00954087045071565 | validation: 0.007202203506040136]
	TIME [epoch: 35.5 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008900547112477458		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 0.008900547112477458 | validation: 0.007645662284726416]
	TIME [epoch: 35.6 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00930810386520539		[learning rate: 0.003032]
	Learning Rate: 0.00303201
	LOSS [training: 0.00930810386520539 | validation: 0.009698382543082978]
	TIME [epoch: 35.6 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008542998602346771		[learning rate: 0.00302]
	Learning Rate: 0.00301995
	LOSS [training: 0.008542998602346771 | validation: 0.00937153263066386]
	TIME [epoch: 35.6 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010456538747334803		[learning rate: 0.0030079]
	Learning Rate: 0.00300794
	LOSS [training: 0.010456538747334803 | validation: 0.008963675098749607]
	TIME [epoch: 35.5 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010148537199253753		[learning rate: 0.002996]
	Learning Rate: 0.00299598
	LOSS [training: 0.010148537199253753 | validation: 0.00788315342660348]
	TIME [epoch: 35.6 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007840019413067707		[learning rate: 0.0029841]
	Learning Rate: 0.00298406
	LOSS [training: 0.007840019413067707 | validation: 0.0082674813139302]
	TIME [epoch: 35.5 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009552062283403537		[learning rate: 0.0029722]
	Learning Rate: 0.00297219
	LOSS [training: 0.009552062283403537 | validation: 0.008970141701720006]
	TIME [epoch: 35.6 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010135152132886566		[learning rate: 0.0029604]
	Learning Rate: 0.00296037
	LOSS [training: 0.010135152132886566 | validation: 0.007394970237551629]
	TIME [epoch: 35.5 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009404198972145356		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.009404198972145356 | validation: 0.00774330388817909]
	TIME [epoch: 35.6 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007971535232973309		[learning rate: 0.0029369]
	Learning Rate: 0.00293687
	LOSS [training: 0.007971535232973309 | validation: 0.00841163793091408]
	TIME [epoch: 35.6 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009835270410655121		[learning rate: 0.0029252]
	Learning Rate: 0.00292519
	LOSS [training: 0.009835270410655121 | validation: 0.007846813455676513]
	TIME [epoch: 35.6 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008553274063303059		[learning rate: 0.0029136]
	Learning Rate: 0.00291355
	LOSS [training: 0.008553274063303059 | validation: 0.008536429351112887]
	TIME [epoch: 35.6 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009985992086340944		[learning rate: 0.002902]
	Learning Rate: 0.00290197
	LOSS [training: 0.009985992086340944 | validation: 0.008774020016074698]
	TIME [epoch: 35.6 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011026107099130052		[learning rate: 0.0028904]
	Learning Rate: 0.00289042
	LOSS [training: 0.011026107099130052 | validation: 0.008075673138285385]
	TIME [epoch: 35.6 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008847604154263748		[learning rate: 0.0028789]
	Learning Rate: 0.00287893
	LOSS [training: 0.008847604154263748 | validation: 0.00948137482885034]
	TIME [epoch: 35.6 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009592913563550475		[learning rate: 0.0028675]
	Learning Rate: 0.00286748
	LOSS [training: 0.009592913563550475 | validation: 0.007359522390121259]
	TIME [epoch: 35.7 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0118319461861979		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 0.0118319461861979 | validation: 0.007058348070890492]
	TIME [epoch: 35.6 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009245385023176258		[learning rate: 0.0028447]
	Learning Rate: 0.00284471
	LOSS [training: 0.009245385023176258 | validation: 0.00852499458384406]
	TIME [epoch: 35.6 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012388059111086383		[learning rate: 0.0028334]
	Learning Rate: 0.0028334
	LOSS [training: 0.012388059111086383 | validation: 0.007418923561846175]
	TIME [epoch: 35.6 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009288059848725673		[learning rate: 0.0028221]
	Learning Rate: 0.00282213
	LOSS [training: 0.009288059848725673 | validation: 0.007474302731369722]
	TIME [epoch: 35.6 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00912862805214524		[learning rate: 0.0028109]
	Learning Rate: 0.00281091
	LOSS [training: 0.00912862805214524 | validation: 0.007384767188639946]
	TIME [epoch: 35.5 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009391489130749768		[learning rate: 0.0027997]
	Learning Rate: 0.00279973
	LOSS [training: 0.009391489130749768 | validation: 0.007289394386823895]
	TIME [epoch: 35.6 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010152445727930465		[learning rate: 0.0027886]
	Learning Rate: 0.00278859
	LOSS [training: 0.010152445727930465 | validation: 0.009808759077113111]
	TIME [epoch: 35.5 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00951370762258755		[learning rate: 0.0027775]
	Learning Rate: 0.0027775
	LOSS [training: 0.00951370762258755 | validation: 0.007482142808408249]
	TIME [epoch: 35.6 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010017393508637342		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 0.010017393508637342 | validation: 0.007614117269480284]
	TIME [epoch: 35.5 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010026402987111703		[learning rate: 0.0027554]
	Learning Rate: 0.00275545
	LOSS [training: 0.010026402987111703 | validation: 0.007303467409309455]
	TIME [epoch: 35.6 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008358965597919592		[learning rate: 0.0027445]
	Learning Rate: 0.00274449
	LOSS [training: 0.008358965597919592 | validation: 0.007353144530579803]
	TIME [epoch: 35.5 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009248329362980737		[learning rate: 0.0027336]
	Learning Rate: 0.00273357
	LOSS [training: 0.009248329362980737 | validation: 0.012041982551738347]
	TIME [epoch: 35.6 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010055567952863161		[learning rate: 0.0027227]
	Learning Rate: 0.0027227
	LOSS [training: 0.010055567952863161 | validation: 0.007754198841959084]
	TIME [epoch: 35.5 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008936134551111977		[learning rate: 0.0027119]
	Learning Rate: 0.00271187
	LOSS [training: 0.008936134551111977 | validation: 0.00781921938591355]
	TIME [epoch: 35.5 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.013473642063512786		[learning rate: 0.0027011]
	Learning Rate: 0.00270109
	LOSS [training: 0.013473642063512786 | validation: 0.0067679316228408835]
	TIME [epoch: 35.5 sec]
	Saving model to: out/model_training/model_facs_dec1b_2d_v1_20240622_154550/states/model_facs_dec1b_2d_v1_373.pth
	Model improved!!!
EPOCH 374/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010297987802718421		[learning rate: 0.0026903]
	Learning Rate: 0.00269034
	LOSS [training: 0.010297987802718421 | validation: 0.006744501365833466]
	TIME [epoch: 35.6 sec]
	Saving model to: out/model_training/model_facs_dec1b_2d_v1_20240622_154550/states/model_facs_dec1b_2d_v1_374.pth
	Model improved!!!
EPOCH 375/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00828225966309642		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 0.00828225966309642 | validation: 0.010016509422873798]
	TIME [epoch: 35.6 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00965894399026594		[learning rate: 0.002669]
	Learning Rate: 0.00266899
	LOSS [training: 0.00965894399026594 | validation: 0.007251598970053066]
	TIME [epoch: 35.6 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00999196667813129		[learning rate: 0.0026584]
	Learning Rate: 0.00265837
	LOSS [training: 0.00999196667813129 | validation: 0.007269447358538375]
	TIME [epoch: 35.6 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009197929481165022		[learning rate: 0.0026478]
	Learning Rate: 0.0026478
	LOSS [training: 0.009197929481165022 | validation: 0.009462920597570866]
	TIME [epoch: 35.6 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009491438068513474		[learning rate: 0.0026373]
	Learning Rate: 0.00263727
	LOSS [training: 0.009491438068513474 | validation: 0.008534990456158971]
	TIME [epoch: 35.5 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011454871509812524		[learning rate: 0.0026268]
	Learning Rate: 0.00262678
	LOSS [training: 0.011454871509812524 | validation: 0.008765594393311513]
	TIME [epoch: 35.6 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00914469517775518		[learning rate: 0.0026163]
	Learning Rate: 0.00261633
	LOSS [training: 0.00914469517775518 | validation: 0.00895381375910064]
	TIME [epoch: 35.6 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009905003615180395		[learning rate: 0.0026059]
	Learning Rate: 0.00260592
	LOSS [training: 0.009905003615180395 | validation: 0.007562362159866662]
	TIME [epoch: 35.6 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008662825456799562		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 0.008662825456799562 | validation: 0.009386872998644047]
	TIME [epoch: 35.5 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012008951798794347		[learning rate: 0.0025852]
	Learning Rate: 0.00258523
	LOSS [training: 0.012008951798794347 | validation: 0.007367745452174131]
	TIME [epoch: 35.6 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00910745376152928		[learning rate: 0.002575]
	Learning Rate: 0.00257495
	LOSS [training: 0.00910745376152928 | validation: 0.00819256829988508]
	TIME [epoch: 35.5 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01075011952161075		[learning rate: 0.0025647]
	Learning Rate: 0.00256471
	LOSS [training: 0.01075011952161075 | validation: 0.00791202485785039]
	TIME [epoch: 35.6 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008884218594054336		[learning rate: 0.0025545]
	Learning Rate: 0.00255451
	LOSS [training: 0.008884218594054336 | validation: 0.008621714440688035]
	TIME [epoch: 35.5 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00850404163020156		[learning rate: 0.0025444]
	Learning Rate: 0.00254435
	LOSS [training: 0.00850404163020156 | validation: 0.008194467655189237]
	TIME [epoch: 35.6 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008750435061975103		[learning rate: 0.0025342]
	Learning Rate: 0.00253423
	LOSS [training: 0.008750435061975103 | validation: 0.007595876901966886]
	TIME [epoch: 35.6 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008306602367661444		[learning rate: 0.0025242]
	Learning Rate: 0.00252415
	LOSS [training: 0.008306602367661444 | validation: 0.010775414290386679]
	TIME [epoch: 35.6 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01127637203205081		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.01127637203205081 | validation: 0.007255960213889331]
	TIME [epoch: 35.6 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00932375265839777		[learning rate: 0.0025041]
	Learning Rate: 0.00250411
	LOSS [training: 0.00932375265839777 | validation: 0.007551698057035291]
	TIME [epoch: 35.6 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008867478825286802		[learning rate: 0.0024942]
	Learning Rate: 0.00249415
	LOSS [training: 0.008867478825286802 | validation: 0.006918845790025427]
	TIME [epoch: 35.6 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009776532240240731		[learning rate: 0.0024842]
	Learning Rate: 0.00248423
	LOSS [training: 0.009776532240240731 | validation: 0.007748233485382024]
	TIME [epoch: 35.6 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009692923809697836		[learning rate: 0.0024744]
	Learning Rate: 0.00247435
	LOSS [training: 0.009692923809697836 | validation: 0.006937433549776087]
	TIME [epoch: 35.5 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008696529727374907		[learning rate: 0.0024645]
	Learning Rate: 0.00246451
	LOSS [training: 0.008696529727374907 | validation: 0.010337435731397289]
	TIME [epoch: 35.6 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00944549269490484		[learning rate: 0.0024547]
	Learning Rate: 0.00245471
	LOSS [training: 0.00944549269490484 | validation: 0.007642946076804012]
	TIME [epoch: 35.6 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008027132226460502		[learning rate: 0.0024449]
	Learning Rate: 0.00244495
	LOSS [training: 0.008027132226460502 | validation: 0.009022842167093365]
	TIME [epoch: 35.6 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009390242812618969		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 0.009390242812618969 | validation: 0.008825872411103802]
	TIME [epoch: 35.6 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009683217973636808		[learning rate: 0.0024255]
	Learning Rate: 0.00242554
	LOSS [training: 0.009683217973636808 | validation: 0.006709976835982463]
	TIME [epoch: 35.6 sec]
	Saving model to: out/model_training/model_facs_dec1b_2d_v1_20240622_154550/states/model_facs_dec1b_2d_v1_400.pth
	Model improved!!!
EPOCH 401/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009401694794647995		[learning rate: 0.0024159]
	Learning Rate: 0.00241589
	LOSS [training: 0.009401694794647995 | validation: 0.00910100529661098]
	TIME [epoch: 35.6 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011132116116276155		[learning rate: 0.0024063]
	Learning Rate: 0.00240628
	LOSS [training: 0.011132116116276155 | validation: 0.008194756751732452]
	TIME [epoch: 35.5 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009100056963070749		[learning rate: 0.0023967]
	Learning Rate: 0.00239671
	LOSS [training: 0.009100056963070749 | validation: 0.007466123991059193]
	TIME [epoch: 35.5 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009215584513537973		[learning rate: 0.0023872]
	Learning Rate: 0.00238718
	LOSS [training: 0.009215584513537973 | validation: 0.008893602028347904]
	TIME [epoch: 35.5 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00990309987495287		[learning rate: 0.0023777]
	Learning Rate: 0.00237768
	LOSS [training: 0.00990309987495287 | validation: 0.007436659760068172]
	TIME [epoch: 35.5 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008952733667983721		[learning rate: 0.0023682]
	Learning Rate: 0.00236823
	LOSS [training: 0.008952733667983721 | validation: 0.008279465633264703]
	TIME [epoch: 35.5 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01075995053987291		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 0.01075995053987291 | validation: 0.008477139872583339]
	TIME [epoch: 35.5 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009519297869155846		[learning rate: 0.0023494]
	Learning Rate: 0.00234942
	LOSS [training: 0.009519297869155846 | validation: 0.007285661599520892]
	TIME [epoch: 35.5 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009527686304859609		[learning rate: 0.0023401]
	Learning Rate: 0.00234008
	LOSS [training: 0.009527686304859609 | validation: 0.008097085908251787]
	TIME [epoch: 35.5 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009407031635181667		[learning rate: 0.0023308]
	Learning Rate: 0.00233077
	LOSS [training: 0.009407031635181667 | validation: 0.006978838473820912]
	TIME [epoch: 35.5 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01260310519460935		[learning rate: 0.0023215]
	Learning Rate: 0.0023215
	LOSS [training: 0.01260310519460935 | validation: 0.007528370991793695]
	TIME [epoch: 35.5 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008487773978088144		[learning rate: 0.0023123]
	Learning Rate: 0.00231227
	LOSS [training: 0.008487773978088144 | validation: 0.008122958725842264]
	TIME [epoch: 35.6 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009904506406858962		[learning rate: 0.0023031]
	Learning Rate: 0.00230307
	LOSS [training: 0.009904506406858962 | validation: 0.008159916551781898]
	TIME [epoch: 35.6 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0088511443876308		[learning rate: 0.0022939]
	Learning Rate: 0.00229391
	LOSS [training: 0.0088511443876308 | validation: 0.00877455649051398]
	TIME [epoch: 35.6 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009957519773573809		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 0.009957519773573809 | validation: 0.007482378153175598]
	TIME [epoch: 35.6 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009284307098583904		[learning rate: 0.0022757]
	Learning Rate: 0.0022757
	LOSS [training: 0.009284307098583904 | validation: 0.007198707429003503]
	TIME [epoch: 35.6 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010069132757007278		[learning rate: 0.0022667]
	Learning Rate: 0.00226665
	LOSS [training: 0.010069132757007278 | validation: 0.007363013031114543]
	TIME [epoch: 35.5 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008371932325095921		[learning rate: 0.0022576]
	Learning Rate: 0.00225764
	LOSS [training: 0.008371932325095921 | validation: 0.00736687327234758]
	TIME [epoch: 35.6 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00899810340220908		[learning rate: 0.0022487]
	Learning Rate: 0.00224866
	LOSS [training: 0.00899810340220908 | validation: 0.008041600294178487]
	TIME [epoch: 35.6 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007960289751009894		[learning rate: 0.0022397]
	Learning Rate: 0.00223971
	LOSS [training: 0.007960289751009894 | validation: 0.008373565187285173]
	TIME [epoch: 35.6 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00880607125058426		[learning rate: 0.0022308]
	Learning Rate: 0.0022308
	LOSS [training: 0.00880607125058426 | validation: 0.007679975683403001]
	TIME [epoch: 35.5 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008689798838380992		[learning rate: 0.0022219]
	Learning Rate: 0.00222193
	LOSS [training: 0.008689798838380992 | validation: 0.008308605470108001]
	TIME [epoch: 35.5 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008963473832188436		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.008963473832188436 | validation: 0.007266728887159864]
	TIME [epoch: 35.6 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008429621095863234		[learning rate: 0.0022043]
	Learning Rate: 0.00220429
	LOSS [training: 0.008429621095863234 | validation: 0.00977459071753749]
	TIME [epoch: 35.6 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010597606800827292		[learning rate: 0.0021955]
	Learning Rate: 0.00219553
	LOSS [training: 0.010597606800827292 | validation: 0.00788863873337416]
	TIME [epoch: 35.5 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009678103596450693		[learning rate: 0.0021868]
	Learning Rate: 0.00218679
	LOSS [training: 0.009678103596450693 | validation: 0.007055133491692911]
	TIME [epoch: 35.6 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008921571886629315		[learning rate: 0.0021781]
	Learning Rate: 0.0021781
	LOSS [training: 0.008921571886629315 | validation: 0.007253629009653923]
	TIME [epoch: 35.5 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008782986512357902		[learning rate: 0.0021694]
	Learning Rate: 0.00216943
	LOSS [training: 0.008782986512357902 | validation: 0.0076520382602574075]
	TIME [epoch: 35.6 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010132638669797913		[learning rate: 0.0021608]
	Learning Rate: 0.0021608
	LOSS [training: 0.010132638669797913 | validation: 0.007478397915142746]
	TIME [epoch: 35.5 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009798846226138958		[learning rate: 0.0021522]
	Learning Rate: 0.00215221
	LOSS [training: 0.009798846226138958 | validation: 0.008191617672022967]
	TIME [epoch: 35.6 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009916204962278007		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.009916204962278007 | validation: 0.0071191722374007605]
	TIME [epoch: 35.6 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010835856966423673		[learning rate: 0.0021351]
	Learning Rate: 0.00213512
	LOSS [training: 0.010835856966423673 | validation: 0.007407616713423692]
	TIME [epoch: 35.6 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010137347066191559		[learning rate: 0.0021266]
	Learning Rate: 0.00212663
	LOSS [training: 0.010137347066191559 | validation: 0.00793265162771446]
	TIME [epoch: 35.5 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008858736351991523		[learning rate: 0.0021182]
	Learning Rate: 0.00211817
	LOSS [training: 0.008858736351991523 | validation: 0.00800479631401177]
	TIME [epoch: 35.6 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009645348300706319		[learning rate: 0.0021097]
	Learning Rate: 0.00210975
	LOSS [training: 0.009645348300706319 | validation: 0.0074524079904420715]
	TIME [epoch: 35.6 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008676724620554603		[learning rate: 0.0021014]
	Learning Rate: 0.00210136
	LOSS [training: 0.008676724620554603 | validation: 0.006952794544804042]
	TIME [epoch: 35.6 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008448368419578432		[learning rate: 0.002093]
	Learning Rate: 0.002093
	LOSS [training: 0.008448368419578432 | validation: 0.008604149626994993]
	TIME [epoch: 35.5 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008703727879206992		[learning rate: 0.0020847]
	Learning Rate: 0.00208468
	LOSS [training: 0.008703727879206992 | validation: 0.007782826541085171]
	TIME [epoch: 35.6 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008112120081678255		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.008112120081678255 | validation: 0.007438271314565742]
	TIME [epoch: 35.5 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010289195098726188		[learning rate: 0.0020681]
	Learning Rate: 0.00206813
	LOSS [training: 0.010289195098726188 | validation: 0.006695796496526768]
	TIME [epoch: 35.6 sec]
	Saving model to: out/model_training/model_facs_dec1b_2d_v1_20240622_154550/states/model_facs_dec1b_2d_v1_440.pth
	Model improved!!!
EPOCH 441/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009497451087850788		[learning rate: 0.0020599]
	Learning Rate: 0.0020599
	LOSS [training: 0.009497451087850788 | validation: 0.007242629018243743]
	TIME [epoch: 35.6 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010255942597674154		[learning rate: 0.0020517]
	Learning Rate: 0.00205171
	LOSS [training: 0.010255942597674154 | validation: 0.008311370678382612]
	TIME [epoch: 35.5 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010010301546708967		[learning rate: 0.0020435]
	Learning Rate: 0.00204355
	LOSS [training: 0.010010301546708967 | validation: 0.007637073383183456]
	TIME [epoch: 35.6 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00901719403929396		[learning rate: 0.0020354]
	Learning Rate: 0.00203542
	LOSS [training: 0.00901719403929396 | validation: 0.007437903813604811]
	TIME [epoch: 35.6 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009492654826322394		[learning rate: 0.0020273]
	Learning Rate: 0.00202732
	LOSS [training: 0.009492654826322394 | validation: 0.007231716047750543]
	TIME [epoch: 35.6 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00838900504388115		[learning rate: 0.0020193]
	Learning Rate: 0.00201926
	LOSS [training: 0.00838900504388115 | validation: 0.007663945441637514]
	TIME [epoch: 35.6 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009054927387604779		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 0.009054927387604779 | validation: 0.007265894915785493]
	TIME [epoch: 35.6 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008898745418369903		[learning rate: 0.0020032]
	Learning Rate: 0.00200323
	LOSS [training: 0.008898745418369903 | validation: 0.00755447025096403]
	TIME [epoch: 35.6 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009389005566157106		[learning rate: 0.0019953]
	Learning Rate: 0.00199526
	LOSS [training: 0.009389005566157106 | validation: 0.008558883765988613]
	TIME [epoch: 35.6 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009260380407850254		[learning rate: 0.0019873]
	Learning Rate: 0.00198733
	LOSS [training: 0.009260380407850254 | validation: 0.007551926425146909]
	TIME [epoch: 35.6 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009332641079770667		[learning rate: 0.0019794]
	Learning Rate: 0.00197942
	LOSS [training: 0.009332641079770667 | validation: 0.00717630445081181]
	TIME [epoch: 35.6 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01039752218950722		[learning rate: 0.0019715]
	Learning Rate: 0.00197155
	LOSS [training: 0.01039752218950722 | validation: 0.007931268110932085]
	TIME [epoch: 35.6 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009116574497708552		[learning rate: 0.0019637]
	Learning Rate: 0.00196371
	LOSS [training: 0.009116574497708552 | validation: 0.009580946243860496]
	TIME [epoch: 35.6 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009395726534975177		[learning rate: 0.0019559]
	Learning Rate: 0.0019559
	LOSS [training: 0.009395726534975177 | validation: 0.007440450595997428]
	TIME [epoch: 35.5 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008487744888779696		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 0.008487744888779696 | validation: 0.008194138718471177]
	TIME [epoch: 35.6 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007953700315877128		[learning rate: 0.0019404]
	Learning Rate: 0.00194037
	LOSS [training: 0.007953700315877128 | validation: 0.009785692567978713]
	TIME [epoch: 35.6 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010022461945217567		[learning rate: 0.0019327]
	Learning Rate: 0.00193265
	LOSS [training: 0.010022461945217567 | validation: 0.00791399313404514]
	TIME [epoch: 35.5 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009127910278991526		[learning rate: 0.001925]
	Learning Rate: 0.00192497
	LOSS [training: 0.009127910278991526 | validation: 0.009427828483716968]
	TIME [epoch: 35.5 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010038020455485065		[learning rate: 0.0019173]
	Learning Rate: 0.00191731
	LOSS [training: 0.010038020455485065 | validation: 0.008075368853832495]
	TIME [epoch: 35.5 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011213709525357033		[learning rate: 0.0019097]
	Learning Rate: 0.00190968
	LOSS [training: 0.011213709525357033 | validation: 0.008042612245908904]
	TIME [epoch: 35.6 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00849282932881825		[learning rate: 0.0019021]
	Learning Rate: 0.00190209
	LOSS [training: 0.00849282932881825 | validation: 0.0073365586738148286]
	TIME [epoch: 35.6 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008942914264969208		[learning rate: 0.0018945]
	Learning Rate: 0.00189452
	LOSS [training: 0.008942914264969208 | validation: 0.0074053711680445]
	TIME [epoch: 35.6 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00925403477650665		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.00925403477650665 | validation: 0.008319919890796178]
	TIME [epoch: 35.6 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007750387593237518		[learning rate: 0.0018795]
	Learning Rate: 0.00187948
	LOSS [training: 0.007750387593237518 | validation: 0.0076836765561034085]
	TIME [epoch: 35.6 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009434255991767004		[learning rate: 0.001872]
	Learning Rate: 0.00187201
	LOSS [training: 0.009434255991767004 | validation: 0.007043334436428089]
	TIME [epoch: 35.6 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008145375990362814		[learning rate: 0.0018646]
	Learning Rate: 0.00186456
	LOSS [training: 0.008145375990362814 | validation: 0.009244911433382557]
	TIME [epoch: 35.5 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009282686553261484		[learning rate: 0.0018571]
	Learning Rate: 0.00185715
	LOSS [training: 0.009282686553261484 | validation: 0.0076219141618316276]
	TIME [epoch: 35.5 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011963331598770856		[learning rate: 0.0018498]
	Learning Rate: 0.00184976
	LOSS [training: 0.011963331598770856 | validation: 0.006843268878771136]
	TIME [epoch: 35.5 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008175844679331974		[learning rate: 0.0018424]
	Learning Rate: 0.0018424
	LOSS [training: 0.008175844679331974 | validation: 0.00742071400109307]
	TIME [epoch: 35.5 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011272370960049398		[learning rate: 0.0018351]
	Learning Rate: 0.00183508
	LOSS [training: 0.011272370960049398 | validation: 0.0068962246725987]
	TIME [epoch: 35.5 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009024317593842385		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.009024317593842385 | validation: 0.007830701541247863]
	TIME [epoch: 35.5 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010362907389220456		[learning rate: 0.0018205]
	Learning Rate: 0.00182051
	LOSS [training: 0.010362907389220456 | validation: 0.006756763397464197]
	TIME [epoch: 35.5 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00939825678102387		[learning rate: 0.0018133]
	Learning Rate: 0.00181327
	LOSS [training: 0.00939825678102387 | validation: 0.007096922575802576]
	TIME [epoch: 35.6 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008505064491750569		[learning rate: 0.0018061]
	Learning Rate: 0.00180605
	LOSS [training: 0.008505064491750569 | validation: 0.008390206123736754]
	TIME [epoch: 35.6 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007794314418132858		[learning rate: 0.0017989]
	Learning Rate: 0.00179887
	LOSS [training: 0.007794314418132858 | validation: 0.007528183408897796]
	TIME [epoch: 35.6 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010108725413463924		[learning rate: 0.0017917]
	Learning Rate: 0.00179172
	LOSS [training: 0.010108725413463924 | validation: 0.0069418869361261406]
	TIME [epoch: 35.5 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009151093911942527		[learning rate: 0.0017846]
	Learning Rate: 0.00178459
	LOSS [training: 0.009151093911942527 | validation: 0.006517346282895567]
	TIME [epoch: 35.6 sec]
	Saving model to: out/model_training/model_facs_dec1b_2d_v1_20240622_154550/states/model_facs_dec1b_2d_v1_477.pth
	Model improved!!!
EPOCH 478/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009023872538299832		[learning rate: 0.0017775]
	Learning Rate: 0.00177749
	LOSS [training: 0.009023872538299832 | validation: 0.0077885260554849236]
	TIME [epoch: 35.6 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008761281840066791		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.008761281840066791 | validation: 0.007909027422731123]
	TIME [epoch: 35.5 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009625276187514823		[learning rate: 0.0017634]
	Learning Rate: 0.00176338
	LOSS [training: 0.009625276187514823 | validation: 0.00897406600714033]
	TIME [epoch: 35.6 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008452753221217382		[learning rate: 0.0017564]
	Learning Rate: 0.00175637
	LOSS [training: 0.008452753221217382 | validation: 0.0072828801021483525]
	TIME [epoch: 35.6 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008590644465537834		[learning rate: 0.0017494]
	Learning Rate: 0.00174938
	LOSS [training: 0.008590644465537834 | validation: 0.008176845412136532]
	TIME [epoch: 35.5 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009138155072529255		[learning rate: 0.0017424]
	Learning Rate: 0.00174242
	LOSS [training: 0.009138155072529255 | validation: 0.008075833407111616]
	TIME [epoch: 35.6 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009271386540709525		[learning rate: 0.0017355]
	Learning Rate: 0.00173549
	LOSS [training: 0.009271386540709525 | validation: 0.00730033314991319]
	TIME [epoch: 35.5 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009425008980299928		[learning rate: 0.0017286]
	Learning Rate: 0.00172859
	LOSS [training: 0.009425008980299928 | validation: 0.006918723095521472]
	TIME [epoch: 35.6 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009109476306588189		[learning rate: 0.0017217]
	Learning Rate: 0.00172172
	LOSS [training: 0.009109476306588189 | validation: 0.008076976993965954]
	TIME [epoch: 35.5 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010957709630902852		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 0.010957709630902852 | validation: 0.007754120118565894]
	TIME [epoch: 35.5 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011831255612075549		[learning rate: 0.001708]
	Learning Rate: 0.00170805
	LOSS [training: 0.011831255612075549 | validation: 0.007601582614769518]
	TIME [epoch: 35.5 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00800081086485633		[learning rate: 0.0017013]
	Learning Rate: 0.00170125
	LOSS [training: 0.00800081086485633 | validation: 0.007567762302395684]
	TIME [epoch: 35.5 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008524371575738047		[learning rate: 0.0016945]
	Learning Rate: 0.00169449
	LOSS [training: 0.008524371575738047 | validation: 0.007038770223205822]
	TIME [epoch: 35.5 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00866302041894405		[learning rate: 0.0016877]
	Learning Rate: 0.00168775
	LOSS [training: 0.00866302041894405 | validation: 0.008147549405284806]
	TIME [epoch: 35.6 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008922360428967595		[learning rate: 0.001681]
	Learning Rate: 0.00168104
	LOSS [training: 0.008922360428967595 | validation: 0.007025048213013184]
	TIME [epoch: 35.5 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009884627802100967		[learning rate: 0.0016743]
	Learning Rate: 0.00167435
	LOSS [training: 0.009884627802100967 | validation: 0.007235468211923397]
	TIME [epoch: 35.6 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009148444411145916		[learning rate: 0.0016677]
	Learning Rate: 0.00166769
	LOSS [training: 0.009148444411145916 | validation: 0.008004216600649493]
	TIME [epoch: 35.5 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008632194229718677		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.008632194229718677 | validation: 0.007393852707559918]
	TIME [epoch: 35.5 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008382488600279825		[learning rate: 0.0016545]
	Learning Rate: 0.00165445
	LOSS [training: 0.008382488600279825 | validation: 0.006836067445238886]
	TIME [epoch: 35.5 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009065185015340172		[learning rate: 0.0016479]
	Learning Rate: 0.00164787
	LOSS [training: 0.009065185015340172 | validation: 0.006795221135298108]
	TIME [epoch: 35.5 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00975354847496985		[learning rate: 0.0016413]
	Learning Rate: 0.00164132
	LOSS [training: 0.00975354847496985 | validation: 0.007583898775152763]
	TIME [epoch: 35.5 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009131356319429157		[learning rate: 0.0016348]
	Learning Rate: 0.00163479
	LOSS [training: 0.009131356319429157 | validation: 0.008188696977290646]
	TIME [epoch: 35.5 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009587661791913005		[learning rate: 0.0016283]
	Learning Rate: 0.00162829
	LOSS [training: 0.009587661791913005 | validation: 0.007287086987526221]
	TIME [epoch: 35.5 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00937875154052972		[learning rate: 0.0016218]
	Learning Rate: 0.00162181
	LOSS [training: 0.00937875154052972 | validation: 0.007605304573481813]
	TIME [epoch: 35.6 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00945476543276304		[learning rate: 0.0016154]
	Learning Rate: 0.00161536
	LOSS [training: 0.00945476543276304 | validation: 0.007752627311506913]
	TIME [epoch: 35.5 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009103425221474016		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 0.009103425221474016 | validation: 0.008438517271132175]
	TIME [epoch: 35.5 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009532370066569337		[learning rate: 0.0016025]
	Learning Rate: 0.00160254
	LOSS [training: 0.009532370066569337 | validation: 0.0075178598051632625]
	TIME [epoch: 35.5 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008130148750158404		[learning rate: 0.0015962]
	Learning Rate: 0.00159616
	LOSS [training: 0.008130148750158404 | validation: 0.0075533472243641655]
	TIME [epoch: 35.5 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010864298759261374		[learning rate: 0.0015898]
	Learning Rate: 0.00158981
	LOSS [training: 0.010864298759261374 | validation: 0.006813341833514311]
	TIME [epoch: 35.5 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008769801966978533		[learning rate: 0.0015835]
	Learning Rate: 0.00158349
	LOSS [training: 0.008769801966978533 | validation: 0.008245954060117425]
	TIME [epoch: 35.5 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008178528187101948		[learning rate: 0.0015772]
	Learning Rate: 0.00157719
	LOSS [training: 0.008178528187101948 | validation: 0.007015921003436283]
	TIME [epoch: 35.5 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009369883295345985		[learning rate: 0.0015709]
	Learning Rate: 0.00157092
	LOSS [training: 0.009369883295345985 | validation: 0.007432821813730772]
	TIME [epoch: 35.5 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008459329717853943		[learning rate: 0.0015647]
	Learning Rate: 0.00156467
	LOSS [training: 0.008459329717853943 | validation: 0.0083355658579636]
	TIME [epoch: 35.5 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008563780559099149		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.008563780559099149 | validation: 0.0068895937972420825]
	TIME [epoch: 35.5 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008836289437260326		[learning rate: 0.0015522]
	Learning Rate: 0.00155225
	LOSS [training: 0.008836289437260326 | validation: 0.007825282188918032]
	TIME [epoch: 35.5 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008416756187709063		[learning rate: 0.0015461]
	Learning Rate: 0.00154608
	LOSS [training: 0.008416756187709063 | validation: 0.007881987177969316]
	TIME [epoch: 35.5 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009702977337818528		[learning rate: 0.0015399]
	Learning Rate: 0.00153993
	LOSS [training: 0.009702977337818528 | validation: 0.007328326060649255]
	TIME [epoch: 35.5 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009347496724258133		[learning rate: 0.0015338]
	Learning Rate: 0.0015338
	LOSS [training: 0.009347496724258133 | validation: 0.006983926713324112]
	TIME [epoch: 35.5 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008880475279625783		[learning rate: 0.0015277]
	Learning Rate: 0.0015277
	LOSS [training: 0.008880475279625783 | validation: 0.007115316861102894]
	TIME [epoch: 35.5 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008698111247331629		[learning rate: 0.0015216]
	Learning Rate: 0.00152163
	LOSS [training: 0.008698111247331629 | validation: 0.007222966058356542]
	TIME [epoch: 35.5 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009116659463492703		[learning rate: 0.0015156]
	Learning Rate: 0.00151557
	LOSS [training: 0.009116659463492703 | validation: 0.0069636169905593764]
	TIME [epoch: 35.5 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008412853167662037		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.008412853167662037 | validation: 0.007471161450266281]
	TIME [epoch: 35.5 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008687899370692066		[learning rate: 0.0015035]
	Learning Rate: 0.00150354
	LOSS [training: 0.008687899370692066 | validation: 0.007570197312805208]
	TIME [epoch: 35.5 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009089835315049685		[learning rate: 0.0014976]
	Learning Rate: 0.00149756
	LOSS [training: 0.009089835315049685 | validation: 0.007883625388661924]
	TIME [epoch: 35.5 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008719131341546504		[learning rate: 0.0014916]
	Learning Rate: 0.00149161
	LOSS [training: 0.008719131341546504 | validation: 0.007876646954376936]
	TIME [epoch: 35.5 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010861536167499115		[learning rate: 0.0014857]
	Learning Rate: 0.00148567
	LOSS [training: 0.010861536167499115 | validation: 0.008120418186779816]
	TIME [epoch: 35.5 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008614538423899167		[learning rate: 0.0014798]
	Learning Rate: 0.00147976
	LOSS [training: 0.008614538423899167 | validation: 0.007439175870785594]
	TIME [epoch: 35.5 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008604360507872277		[learning rate: 0.0014739]
	Learning Rate: 0.00147388
	LOSS [training: 0.008604360507872277 | validation: 0.007101887313660874]
	TIME [epoch: 35.5 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0084717266676889		[learning rate: 0.001468]
	Learning Rate: 0.00146802
	LOSS [training: 0.0084717266676889 | validation: 0.008090605102064555]
	TIME [epoch: 35.5 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008987476922876972		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.008987476922876972 | validation: 0.007367834748705273]
	TIME [epoch: 35.5 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009914337037811135		[learning rate: 0.0014564]
	Learning Rate: 0.00145636
	LOSS [training: 0.009914337037811135 | validation: 0.006769642114495893]
	TIME [epoch: 35.5 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00824493567644573		[learning rate: 0.0014506]
	Learning Rate: 0.00145057
	LOSS [training: 0.00824493567644573 | validation: 0.007105473942626879]
	TIME [epoch: 35.6 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00934902548402656		[learning rate: 0.0014448]
	Learning Rate: 0.0014448
	LOSS [training: 0.00934902548402656 | validation: 0.007067082238426786]
	TIME [epoch: 35.5 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008819982935276255		[learning rate: 0.0014391]
	Learning Rate: 0.00143905
	LOSS [training: 0.008819982935276255 | validation: 0.00856900386015674]
	TIME [epoch: 35.5 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008474736308958173		[learning rate: 0.0014333]
	Learning Rate: 0.00143333
	LOSS [training: 0.008474736308958173 | validation: 0.007426644288352807]
	TIME [epoch: 35.5 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008814599675975022		[learning rate: 0.0014276]
	Learning Rate: 0.00142763
	LOSS [training: 0.008814599675975022 | validation: 0.007380595579923437]
	TIME [epoch: 35.5 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009886184507215214		[learning rate: 0.001422]
	Learning Rate: 0.00142195
	LOSS [training: 0.009886184507215214 | validation: 0.0075932325495789415]
	TIME [epoch: 35.5 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00902374972858675		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.00902374972858675 | validation: 0.007298400540765751]
	TIME [epoch: 35.6 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008812423855751468		[learning rate: 0.0014107]
	Learning Rate: 0.00141066
	LOSS [training: 0.008812423855751468 | validation: 0.00740820160459923]
	TIME [epoch: 35.5 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.01134785374103194		[learning rate: 0.0014051]
	Learning Rate: 0.00140505
	LOSS [training: 0.01134785374103194 | validation: 0.007733330670391196]
	TIME [epoch: 35.5 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009026439448866485		[learning rate: 0.0013995]
	Learning Rate: 0.00139946
	LOSS [training: 0.009026439448866485 | validation: 0.007324460856349054]
	TIME [epoch: 35.5 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008966868818976577		[learning rate: 0.0013939]
	Learning Rate: 0.0013939
	LOSS [training: 0.008966868818976577 | validation: 0.007000977129150994]
	TIME [epoch: 35.5 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008875174227714276		[learning rate: 0.0013884]
	Learning Rate: 0.00138835
	LOSS [training: 0.008875174227714276 | validation: 0.007299371794939077]
	TIME [epoch: 35.5 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011722096179974504		[learning rate: 0.0013828]
	Learning Rate: 0.00138283
	LOSS [training: 0.011722096179974504 | validation: 0.007840115255281912]
	TIME [epoch: 35.6 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009600124044322676		[learning rate: 0.0013773]
	Learning Rate: 0.00137733
	LOSS [training: 0.009600124044322676 | validation: 0.006780040632827481]
	TIME [epoch: 35.5 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008464052931296836		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 0.008464052931296836 | validation: 0.0073435554822878]
	TIME [epoch: 35.5 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008360891497149558		[learning rate: 0.0013664]
	Learning Rate: 0.0013664
	LOSS [training: 0.008360891497149558 | validation: 0.0072923255700444445]
	TIME [epoch: 35.5 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007915282372267013		[learning rate: 0.001361]
	Learning Rate: 0.00136096
	LOSS [training: 0.007915282372267013 | validation: 0.007577164175747182]
	TIME [epoch: 35.5 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008995080631413032		[learning rate: 0.0013555]
	Learning Rate: 0.00135555
	LOSS [training: 0.008995080631413032 | validation: 0.008191126914604947]
	TIME [epoch: 35.5 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008885376880580026		[learning rate: 0.0013502]
	Learning Rate: 0.00135016
	LOSS [training: 0.008885376880580026 | validation: 0.007685309915862355]
	TIME [epoch: 35.5 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008473135043259066		[learning rate: 0.0013448]
	Learning Rate: 0.00134479
	LOSS [training: 0.008473135043259066 | validation: 0.006617460475134696]
	TIME [epoch: 35.5 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008326477012688842		[learning rate: 0.0013394]
	Learning Rate: 0.00133944
	LOSS [training: 0.008326477012688842 | validation: 0.0077384908935049625]
	TIME [epoch: 35.5 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008482010860020227		[learning rate: 0.0013341]
	Learning Rate: 0.00133411
	LOSS [training: 0.008482010860020227 | validation: 0.007335854694850483]
	TIME [epoch: 35.5 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008221505019049339		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.008221505019049339 | validation: 0.006879465124928661]
	TIME [epoch: 35.5 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008769623399463758		[learning rate: 0.0013235]
	Learning Rate: 0.00132352
	LOSS [training: 0.008769623399463758 | validation: 0.009326849007784781]
	TIME [epoch: 35.5 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008895874415067992		[learning rate: 0.0013183]
	Learning Rate: 0.00131826
	LOSS [training: 0.008895874415067992 | validation: 0.006981966852880076]
	TIME [epoch: 35.5 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008181020007004285		[learning rate: 0.001313]
	Learning Rate: 0.00131301
	LOSS [training: 0.008181020007004285 | validation: 0.006935221945477407]
	TIME [epoch: 35.4 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007417720524942166		[learning rate: 0.0013078]
	Learning Rate: 0.00130779
	LOSS [training: 0.007417720524942166 | validation: 0.007340133095564809]
	TIME [epoch: 35.5 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00981729683162672		[learning rate: 0.0013026]
	Learning Rate: 0.00130259
	LOSS [training: 0.00981729683162672 | validation: 0.007016912632255817]
	TIME [epoch: 35.5 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009624624764622341		[learning rate: 0.0012974]
	Learning Rate: 0.00129741
	LOSS [training: 0.009624624764622341 | validation: 0.007346578967625109]
	TIME [epoch: 35.6 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009161717303666977		[learning rate: 0.0012922]
	Learning Rate: 0.00129225
	LOSS [training: 0.009161717303666977 | validation: 0.00879032063963919]
	TIME [epoch: 35.5 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009055178391540453		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 0.009055178391540453 | validation: 0.007272802745178844]
	TIME [epoch: 35.5 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009481607887663078		[learning rate: 0.001282]
	Learning Rate: 0.00128199
	LOSS [training: 0.009481607887663078 | validation: 0.006611292911583085]
	TIME [epoch: 35.5 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008193923618399006		[learning rate: 0.0012769]
	Learning Rate: 0.00127689
	LOSS [training: 0.008193923618399006 | validation: 0.007358084420753951]
	TIME [epoch: 35.6 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009535119443500759		[learning rate: 0.0012718]
	Learning Rate: 0.00127181
	LOSS [training: 0.009535119443500759 | validation: 0.007094460480186311]
	TIME [epoch: 35.5 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008232199262144373		[learning rate: 0.0012668]
	Learning Rate: 0.00126675
	LOSS [training: 0.008232199262144373 | validation: 0.007864203380204748]
	TIME [epoch: 35.5 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008863809520158089		[learning rate: 0.0012617]
	Learning Rate: 0.00126172
	LOSS [training: 0.008863809520158089 | validation: 0.008031168502819024]
	TIME [epoch: 35.5 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008908397432103445		[learning rate: 0.0012567]
	Learning Rate: 0.0012567
	LOSS [training: 0.008908397432103445 | validation: 0.007051448930056031]
	TIME [epoch: 35.6 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008911891878904054		[learning rate: 0.0012517]
	Learning Rate: 0.0012517
	LOSS [training: 0.008911891878904054 | validation: 0.006778225001598082]
	TIME [epoch: 35.5 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008189347306597835		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 0.008189347306597835 | validation: 0.007260146507917851]
	TIME [epoch: 35.5 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011034922837139369		[learning rate: 0.0012418]
	Learning Rate: 0.00124176
	LOSS [training: 0.011034922837139369 | validation: 0.00818526633753875]
	TIME [epoch: 35.5 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008575880450003934		[learning rate: 0.0012368]
	Learning Rate: 0.00123682
	LOSS [training: 0.008575880450003934 | validation: 0.00755384347934109]
	TIME [epoch: 35.5 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00849445366139658		[learning rate: 0.0012319]
	Learning Rate: 0.0012319
	LOSS [training: 0.00849445366139658 | validation: 0.007157731486617408]
	TIME [epoch: 35.5 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009093445556560149		[learning rate: 0.001227]
	Learning Rate: 0.001227
	LOSS [training: 0.009093445556560149 | validation: 0.006558732190733158]
	TIME [epoch: 35.6 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008346679801430905		[learning rate: 0.0012221]
	Learning Rate: 0.00122212
	LOSS [training: 0.008346679801430905 | validation: 0.0073837139201720844]
	TIME [epoch: 35.5 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008958542390013334		[learning rate: 0.0012173]
	Learning Rate: 0.00121726
	LOSS [training: 0.008958542390013334 | validation: 0.007189255097045888]
	TIME [epoch: 35.6 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009082790416423434		[learning rate: 0.0012124]
	Learning Rate: 0.00121242
	LOSS [training: 0.009082790416423434 | validation: 0.007244517972884598]
	TIME [epoch: 35.6 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008827024096179567		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 0.008827024096179567 | validation: 0.0073808507062225635]
	TIME [epoch: 35.6 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009388380192143282		[learning rate: 0.0012028]
	Learning Rate: 0.0012028
	LOSS [training: 0.009388380192143282 | validation: 0.006987247703987199]
	TIME [epoch: 35.5 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008540659351644454		[learning rate: 0.001198]
	Learning Rate: 0.00119801
	LOSS [training: 0.008540659351644454 | validation: 0.007117337395713066]
	TIME [epoch: 35.5 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0085913069300515		[learning rate: 0.0011932]
	Learning Rate: 0.00119325
	LOSS [training: 0.0085913069300515 | validation: 0.00691032691998966]
	TIME [epoch: 35.5 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007859832410606584		[learning rate: 0.0011885]
	Learning Rate: 0.0011885
	LOSS [training: 0.007859832410606584 | validation: 0.007039893025761965]
	TIME [epoch: 35.5 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008725757197521035		[learning rate: 0.0011838]
	Learning Rate: 0.00118378
	LOSS [training: 0.008725757197521035 | validation: 0.008627409765986452]
	TIME [epoch: 35.5 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008965517404490031		[learning rate: 0.0011791]
	Learning Rate: 0.00117907
	LOSS [training: 0.008965517404490031 | validation: 0.007254154568328897]
	TIME [epoch: 35.5 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008485486022476394		[learning rate: 0.0011744]
	Learning Rate: 0.00117438
	LOSS [training: 0.008485486022476394 | validation: 0.00722807722802898]
	TIME [epoch: 35.5 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008335029614056069		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 0.008335029614056069 | validation: 0.007821014430121025]
	TIME [epoch: 35.5 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008581584259762748		[learning rate: 0.0011651]
	Learning Rate: 0.00116505
	LOSS [training: 0.008581584259762748 | validation: 0.007984485267323494]
	TIME [epoch: 35.4 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00893711439078285		[learning rate: 0.0011604]
	Learning Rate: 0.00116042
	LOSS [training: 0.00893711439078285 | validation: 0.007119018920084069]
	TIME [epoch: 35.5 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009005725788360376		[learning rate: 0.0011558]
	Learning Rate: 0.00115581
	LOSS [training: 0.009005725788360376 | validation: 0.007349782110768857]
	TIME [epoch: 35.5 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008885406466986026		[learning rate: 0.0011512]
	Learning Rate: 0.00115121
	LOSS [training: 0.008885406466986026 | validation: 0.0076255419541001014]
	TIME [epoch: 35.4 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009651205828189284		[learning rate: 0.0011466]
	Learning Rate: 0.00114663
	LOSS [training: 0.009651205828189284 | validation: 0.007325638652266049]
	TIME [epoch: 35.5 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009618884651289378		[learning rate: 0.0011421]
	Learning Rate: 0.00114207
	LOSS [training: 0.009618884651289378 | validation: 0.007522268312456082]
	TIME [epoch: 35.6 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008912641195364104		[learning rate: 0.0011375]
	Learning Rate: 0.00113753
	LOSS [training: 0.008912641195364104 | validation: 0.006907936668927231]
	TIME [epoch: 35.5 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008493603536256595		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.008493603536256595 | validation: 0.007829433078580693]
	TIME [epoch: 35.6 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009179008967281209		[learning rate: 0.0011285]
	Learning Rate: 0.0011285
	LOSS [training: 0.009179008967281209 | validation: 0.007421350666094004]
	TIME [epoch: 35.5 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008683042326476351		[learning rate: 0.001124]
	Learning Rate: 0.00112401
	LOSS [training: 0.008683042326476351 | validation: 0.007448128261265086]
	TIME [epoch: 35.5 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008531347942387142		[learning rate: 0.0011195]
	Learning Rate: 0.00111954
	LOSS [training: 0.008531347942387142 | validation: 0.007618749876229597]
	TIME [epoch: 35.5 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011316351281249434		[learning rate: 0.0011151]
	Learning Rate: 0.00111508
	LOSS [training: 0.011316351281249434 | validation: 0.007269592363078861]
	TIME [epoch: 35.6 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008116519352876526		[learning rate: 0.0011106]
	Learning Rate: 0.00111065
	LOSS [training: 0.008116519352876526 | validation: 0.0074398765289589]
	TIME [epoch: 35.6 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008456250129245864		[learning rate: 0.0011062]
	Learning Rate: 0.00110623
	LOSS [training: 0.008456250129245864 | validation: 0.006828599697967404]
	TIME [epoch: 35.6 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00812560021536036		[learning rate: 0.0011018]
	Learning Rate: 0.00110183
	LOSS [training: 0.00812560021536036 | validation: 0.007098419667171422]
	TIME [epoch: 35.6 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009925509034455902		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 0.009925509034455902 | validation: 0.00688339851319023]
	TIME [epoch: 35.5 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009046164560921676		[learning rate: 0.0010931]
	Learning Rate: 0.00109309
	LOSS [training: 0.009046164560921676 | validation: 0.006950478831339746]
	TIME [epoch: 35.6 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008599187241566136		[learning rate: 0.0010887]
	Learning Rate: 0.00108874
	LOSS [training: 0.008599187241566136 | validation: 0.007487924948400973]
	TIME [epoch: 35.6 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012775385351471725		[learning rate: 0.0010844]
	Learning Rate: 0.00108441
	LOSS [training: 0.012775385351471725 | validation: 0.007379957035399426]
	TIME [epoch: 35.5 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008388966876558802		[learning rate: 0.0010801]
	Learning Rate: 0.00108009
	LOSS [training: 0.008388966876558802 | validation: 0.006854634692054794]
	TIME [epoch: 35.5 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00881666194592103		[learning rate: 0.0010758]
	Learning Rate: 0.0010758
	LOSS [training: 0.00881666194592103 | validation: 0.008079711123507286]
	TIME [epoch: 35.5 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008636001749643482		[learning rate: 0.0010715]
	Learning Rate: 0.00107152
	LOSS [training: 0.008636001749643482 | validation: 0.00717802635984509]
	TIME [epoch: 35.6 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008740529842839767		[learning rate: 0.0010673]
	Learning Rate: 0.00106726
	LOSS [training: 0.008740529842839767 | validation: 0.006934489909724823]
	TIME [epoch: 35.5 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008278614176407786		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 0.008278614176407786 | validation: 0.0073197489686209595]
	TIME [epoch: 35.6 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008776617482331042		[learning rate: 0.0010588]
	Learning Rate: 0.00105878
	LOSS [training: 0.008776617482331042 | validation: 0.007435209696749152]
	TIME [epoch: 35.6 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009621139624042414		[learning rate: 0.0010546]
	Learning Rate: 0.00105457
	LOSS [training: 0.009621139624042414 | validation: 0.006855618020830079]
	TIME [epoch: 35.6 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008354650336109258		[learning rate: 0.0010504]
	Learning Rate: 0.00105038
	LOSS [training: 0.008354650336109258 | validation: 0.007268336957680197]
	TIME [epoch: 35.6 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009323961732459172		[learning rate: 0.0010462]
	Learning Rate: 0.0010462
	LOSS [training: 0.009323961732459172 | validation: 0.006730598648414054]
	TIME [epoch: 35.5 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008519348606171819		[learning rate: 0.001042]
	Learning Rate: 0.00104204
	LOSS [training: 0.008519348606171819 | validation: 0.007230084666149815]
	TIME [epoch: 35.5 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010848181451346965		[learning rate: 0.0010379]
	Learning Rate: 0.0010379
	LOSS [training: 0.010848181451346965 | validation: 0.007596113325826078]
	TIME [epoch: 35.6 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008390847169667705		[learning rate: 0.0010338]
	Learning Rate: 0.00103377
	LOSS [training: 0.008390847169667705 | validation: 0.0072207750465210245]
	TIME [epoch: 35.5 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008099294990752896		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 0.008099294990752896 | validation: 0.007586919500811704]
	TIME [epoch: 35.5 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008362861614270455		[learning rate: 0.0010256]
	Learning Rate: 0.00102556
	LOSS [training: 0.008362861614270455 | validation: 0.007567090258235801]
	TIME [epoch: 35.6 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00825013785120209		[learning rate: 0.0010215]
	Learning Rate: 0.00102148
	LOSS [training: 0.00825013785120209 | validation: 0.007000407728337046]
	TIME [epoch: 35.5 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008409054170607		[learning rate: 0.0010174]
	Learning Rate: 0.00101742
	LOSS [training: 0.008409054170607 | validation: 0.007402413169709657]
	TIME [epoch: 35.6 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009520607719644296		[learning rate: 0.0010134]
	Learning Rate: 0.00101337
	LOSS [training: 0.009520607719644296 | validation: 0.006465694594994287]
	TIME [epoch: 35.5 sec]
	Saving model to: out/model_training/model_facs_dec1b_2d_v1_20240622_154550/states/model_facs_dec1b_2d_v1_619.pth
	Model improved!!!
EPOCH 620/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008799170862998792		[learning rate: 0.0010093]
	Learning Rate: 0.00100934
	LOSS [training: 0.008799170862998792 | validation: 0.007272392044732086]
	TIME [epoch: 35.6 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008785296817758933		[learning rate: 0.0010053]
	Learning Rate: 0.00100533
	LOSS [training: 0.008785296817758933 | validation: 0.007512525003761908]
	TIME [epoch: 35.7 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007912803455927769		[learning rate: 0.0010013]
	Learning Rate: 0.00100133
	LOSS [training: 0.007912803455927769 | validation: 0.007152174609632059]
	TIME [epoch: 35.5 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00923616943905353		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 0.00923616943905353 | validation: 0.007135106132981602]
	TIME [epoch: 35.6 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008029481263746504		[learning rate: 0.00099338]
	Learning Rate: 0.00099338
	LOSS [training: 0.008029481263746504 | validation: 0.007670115362976676]
	TIME [epoch: 35.6 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008261486516543822		[learning rate: 0.00098943]
	Learning Rate: 0.000989429
	LOSS [training: 0.008261486516543822 | validation: 0.007189284392112136]
	TIME [epoch: 35.6 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008351306988890297		[learning rate: 0.00098549]
	Learning Rate: 0.000985494
	LOSS [training: 0.008351306988890297 | validation: 0.0073457417807846785]
	TIME [epoch: 35.5 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009511293037432545		[learning rate: 0.00098157]
	Learning Rate: 0.000981574
	LOSS [training: 0.009511293037432545 | validation: 0.006748634185220662]
	TIME [epoch: 35.5 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009160091871185293		[learning rate: 0.00097767]
	Learning Rate: 0.00097767
	LOSS [training: 0.009160091871185293 | validation: 0.008045962615848272]
	TIME [epoch: 35.6 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009201940398526058		[learning rate: 0.00097378]
	Learning Rate: 0.000973782
	LOSS [training: 0.009201940398526058 | validation: 0.006980127173281825]
	TIME [epoch: 35.6 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008403331602751779		[learning rate: 0.00096991]
	Learning Rate: 0.000969909
	LOSS [training: 0.008403331602751779 | validation: 0.007772397746684763]
	TIME [epoch: 35.5 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009673075276527332		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.009673075276527332 | validation: 0.006844874106976237]
	TIME [epoch: 35.5 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009305854822415693		[learning rate: 0.00096221]
	Learning Rate: 0.000962209
	LOSS [training: 0.009305854822415693 | validation: 0.007468662587069477]
	TIME [epoch: 35.5 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008319793506128848		[learning rate: 0.00095838]
	Learning Rate: 0.000958382
	LOSS [training: 0.008319793506128848 | validation: 0.007282465705093513]
	TIME [epoch: 35.6 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00843316650659108		[learning rate: 0.00095457]
	Learning Rate: 0.00095457
	LOSS [training: 0.00843316650659108 | validation: 0.008085518637502814]
	TIME [epoch: 35.5 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009971363897063146		[learning rate: 0.00095077]
	Learning Rate: 0.000950773
	LOSS [training: 0.009971363897063146 | validation: 0.007037972534222808]
	TIME [epoch: 35.6 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009612491045325782		[learning rate: 0.00094699]
	Learning Rate: 0.000946992
	LOSS [training: 0.009612491045325782 | validation: 0.0072825409411708675]
	TIME [epoch: 35.5 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008115425101767167		[learning rate: 0.00094323]
	Learning Rate: 0.000943225
	LOSS [training: 0.008115425101767167 | validation: 0.007252043141700151]
	TIME [epoch: 35.6 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008838842124472338		[learning rate: 0.00093947]
	Learning Rate: 0.000939474
	LOSS [training: 0.008838842124472338 | validation: 0.0070203983956275764]
	TIME [epoch: 35.6 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009219834862965313		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.009219834862965313 | validation: 0.007393453873280875]
	TIME [epoch: 35.6 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008525071080693279		[learning rate: 0.00093202]
	Learning Rate: 0.000932015
	LOSS [training: 0.008525071080693279 | validation: 0.008546215287549477]
	TIME [epoch: 35.5 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00838349764833047		[learning rate: 0.00092831]
	Learning Rate: 0.000928309
	LOSS [training: 0.00838349764833047 | validation: 0.007288928264402314]
	TIME [epoch: 35.6 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009187258544018143		[learning rate: 0.00092462]
	Learning Rate: 0.000924616
	LOSS [training: 0.009187258544018143 | validation: 0.007219016304719511]
	TIME [epoch: 35.6 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008037709652213164		[learning rate: 0.00092094]
	Learning Rate: 0.000920939
	LOSS [training: 0.008037709652213164 | validation: 0.007433683484763304]
	TIME [epoch: 35.5 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007506040186947723		[learning rate: 0.00091728]
	Learning Rate: 0.000917276
	LOSS [training: 0.007506040186947723 | validation: 0.007760450439572528]
	TIME [epoch: 35.6 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009656399078813974		[learning rate: 0.00091363]
	Learning Rate: 0.000913628
	LOSS [training: 0.009656399078813974 | validation: 0.00671544951630057]
	TIME [epoch: 35.6 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00956782582568649		[learning rate: 0.00090999]
	Learning Rate: 0.000909994
	LOSS [training: 0.00956782582568649 | validation: 0.007620710616865747]
	TIME [epoch: 35.6 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008960396457069322		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.008960396457069322 | validation: 0.006981453288645021]
	TIME [epoch: 35.6 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008572840423607932		[learning rate: 0.00090277]
	Learning Rate: 0.00090277
	LOSS [training: 0.008572840423607932 | validation: 0.007225250320893109]
	TIME [epoch: 35.6 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0077595335968791935		[learning rate: 0.00089918]
	Learning Rate: 0.000899179
	LOSS [training: 0.0077595335968791935 | validation: 0.007188506349905488]
	TIME [epoch: 35.6 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008167832953594073		[learning rate: 0.0008956]
	Learning Rate: 0.000895603
	LOSS [training: 0.008167832953594073 | validation: 0.006712324529871046]
	TIME [epoch: 35.5 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009639827490972315		[learning rate: 0.00089204]
	Learning Rate: 0.000892041
	LOSS [training: 0.009639827490972315 | validation: 0.007516431205337165]
	TIME [epoch: 35.6 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007893531513616752		[learning rate: 0.00088849]
	Learning Rate: 0.000888493
	LOSS [training: 0.007893531513616752 | validation: 0.00767628537710976]
	TIME [epoch: 35.5 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008600604635033217		[learning rate: 0.00088496]
	Learning Rate: 0.000884959
	LOSS [training: 0.008600604635033217 | validation: 0.007006489152460991]
	TIME [epoch: 35.6 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00850800383565635		[learning rate: 0.00088144]
	Learning Rate: 0.000881439
	LOSS [training: 0.00850800383565635 | validation: 0.007224596379991018]
	TIME [epoch: 35.5 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008675958650946095		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 0.008675958650946095 | validation: 0.007323538661062475]
	TIME [epoch: 35.6 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00821354532831155		[learning rate: 0.00087444]
	Learning Rate: 0.000874441
	LOSS [training: 0.00821354532831155 | validation: 0.00695367892934966]
	TIME [epoch: 35.5 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009139002755377722		[learning rate: 0.00087096]
	Learning Rate: 0.000870964
	LOSS [training: 0.009139002755377722 | validation: 0.006957819853377939]
	TIME [epoch: 35.5 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008002749457689397		[learning rate: 0.0008675]
	Learning Rate: 0.0008675
	LOSS [training: 0.008002749457689397 | validation: 0.006957059244906824]
	TIME [epoch: 35.6 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008941626896951726		[learning rate: 0.00086405]
	Learning Rate: 0.000864049
	LOSS [training: 0.008941626896951726 | validation: 0.007388041015365418]
	TIME [epoch: 35.5 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008258092081257398		[learning rate: 0.00086061]
	Learning Rate: 0.000860613
	LOSS [training: 0.008258092081257398 | validation: 0.007011835534107727]
	TIME [epoch: 35.5 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008547010393557385		[learning rate: 0.00085719]
	Learning Rate: 0.00085719
	LOSS [training: 0.008547010393557385 | validation: 0.007405882250369933]
	TIME [epoch: 35.6 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009219908220289863		[learning rate: 0.00085378]
	Learning Rate: 0.00085378
	LOSS [training: 0.009219908220289863 | validation: 0.006705655281609988]
	TIME [epoch: 35.5 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007718235255002067		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 0.007718235255002067 | validation: 0.0070885399713325374]
	TIME [epoch: 35.5 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008874824730144079		[learning rate: 0.000847]
	Learning Rate: 0.000847002
	LOSS [training: 0.008874824730144079 | validation: 0.007599023206874059]
	TIME [epoch: 35.5 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008132518676503667		[learning rate: 0.00084363]
	Learning Rate: 0.000843634
	LOSS [training: 0.008132518676503667 | validation: 0.0070560430920326225]
	TIME [epoch: 35.5 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011741572974333274		[learning rate: 0.00084028]
	Learning Rate: 0.000840278
	LOSS [training: 0.011741572974333274 | validation: 0.007267598181072393]
	TIME [epoch: 35.5 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008660439840594527		[learning rate: 0.00083694]
	Learning Rate: 0.000836936
	LOSS [training: 0.008660439840594527 | validation: 0.006777204245481924]
	TIME [epoch: 35.6 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.012322852874192202		[learning rate: 0.00083361]
	Learning Rate: 0.000833608
	LOSS [training: 0.012322852874192202 | validation: 0.0070559885133853004]
	TIME [epoch: 35.5 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008558778351569575		[learning rate: 0.00083029]
	Learning Rate: 0.000830292
	LOSS [training: 0.008558778351569575 | validation: 0.006818441502040816]
	TIME [epoch: 35.6 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008279638483290379		[learning rate: 0.00082699]
	Learning Rate: 0.00082699
	LOSS [training: 0.008279638483290379 | validation: 0.006794120385489237]
	TIME [epoch: 35.5 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009144374366537106		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.009144374366537106 | validation: 0.006958346647797198]
	TIME [epoch: 35.5 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008861938026491822		[learning rate: 0.00082042]
	Learning Rate: 0.000820424
	LOSS [training: 0.008861938026491822 | validation: 0.00690550336843129]
	TIME [epoch: 35.6 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011217478985325944		[learning rate: 0.00081716]
	Learning Rate: 0.000817161
	LOSS [training: 0.011217478985325944 | validation: 0.007248520209281116]
	TIME [epoch: 35.6 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008615233814062718		[learning rate: 0.00081391]
	Learning Rate: 0.000813911
	LOSS [training: 0.008615233814062718 | validation: 0.007197678987284145]
	TIME [epoch: 35.5 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009013562381472209		[learning rate: 0.00081067]
	Learning Rate: 0.000810674
	LOSS [training: 0.009013562381472209 | validation: 0.006714583204148497]
	TIME [epoch: 35.6 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008698911955486978		[learning rate: 0.00080745]
	Learning Rate: 0.00080745
	LOSS [training: 0.008698911955486978 | validation: 0.0074907096974876995]
	TIME [epoch: 35.6 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00857732541040996		[learning rate: 0.00080424]
	Learning Rate: 0.000804238
	LOSS [training: 0.00857732541040996 | validation: 0.0071870460148719005]
	TIME [epoch: 35.6 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008336092279207957		[learning rate: 0.00080104]
	Learning Rate: 0.000801039
	LOSS [training: 0.008336092279207957 | validation: 0.007458011417259006]
	TIME [epoch: 35.6 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008683226747985615		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 0.008683226747985615 | validation: 0.007192420549481282]
	TIME [epoch: 35.5 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00796803434739028		[learning rate: 0.00079468]
	Learning Rate: 0.00079468
	LOSS [training: 0.00796803434739028 | validation: 0.00697190597719236]
	TIME [epoch: 35.5 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008650240720351629		[learning rate: 0.00079152]
	Learning Rate: 0.000791519
	LOSS [training: 0.008650240720351629 | validation: 0.0071294123426447215]
	TIME [epoch: 35.6 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008654997899364695		[learning rate: 0.00078837]
	Learning Rate: 0.000788371
	LOSS [training: 0.008654997899364695 | validation: 0.007493716208304063]
	TIME [epoch: 35.6 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007992154125536046		[learning rate: 0.00078524]
	Learning Rate: 0.000785236
	LOSS [training: 0.007992154125536046 | validation: 0.007117870133112008]
	TIME [epoch: 35.6 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008503696760332812		[learning rate: 0.00078211]
	Learning Rate: 0.000782113
	LOSS [training: 0.008503696760332812 | validation: 0.007262576449999577]
	TIME [epoch: 35.6 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008256249365316852		[learning rate: 0.000779]
	Learning Rate: 0.000779002
	LOSS [training: 0.008256249365316852 | validation: 0.0077976397901951475]
	TIME [epoch: 35.7 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008193706763165082		[learning rate: 0.0007759]
	Learning Rate: 0.000775904
	LOSS [training: 0.008193706763165082 | validation: 0.007189768004935995]
	TIME [epoch: 35.6 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00818193571894412		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 0.00818193571894412 | validation: 0.007534247220108155]
	TIME [epoch: 35.6 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009431883979383793		[learning rate: 0.00076974]
	Learning Rate: 0.000769744
	LOSS [training: 0.009431883979383793 | validation: 0.0067207430773330275]
	TIME [epoch: 35.5 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009351012737289426		[learning rate: 0.00076668]
	Learning Rate: 0.000766682
	LOSS [training: 0.009351012737289426 | validation: 0.0071361381849542275]
	TIME [epoch: 35.6 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008459954569625446		[learning rate: 0.00076363]
	Learning Rate: 0.000763633
	LOSS [training: 0.008459954569625446 | validation: 0.006986601737820825]
	TIME [epoch: 35.6 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008497772808651362		[learning rate: 0.0007606]
	Learning Rate: 0.000760596
	LOSS [training: 0.008497772808651362 | validation: 0.007634697742100545]
	TIME [epoch: 35.5 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009404262647756411		[learning rate: 0.00075757]
	Learning Rate: 0.000757571
	LOSS [training: 0.009404262647756411 | validation: 0.007042318406674371]
	TIME [epoch: 35.6 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008069958376690601		[learning rate: 0.00075456]
	Learning Rate: 0.000754557
	LOSS [training: 0.008069958376690601 | validation: 0.007906303117883326]
	TIME [epoch: 35.6 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00883148267638182		[learning rate: 0.00075156]
	Learning Rate: 0.000751556
	LOSS [training: 0.00883148267638182 | validation: 0.006942380146511065]
	TIME [epoch: 35.6 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008574787267101069		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 0.008574787267101069 | validation: 0.0075963263266755916]
	TIME [epoch: 35.6 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008941797805330323		[learning rate: 0.00074559]
	Learning Rate: 0.00074559
	LOSS [training: 0.008941797805330323 | validation: 0.006939938770991741]
	TIME [epoch: 35.6 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00764017676668767		[learning rate: 0.00074262]
	Learning Rate: 0.000742624
	LOSS [training: 0.00764017676668767 | validation: 0.007316691086945576]
	TIME [epoch: 35.6 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008355888729629774		[learning rate: 0.00073967]
	Learning Rate: 0.000739671
	LOSS [training: 0.008355888729629774 | validation: 0.0072087029669919925]
	TIME [epoch: 35.6 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009254673503211885		[learning rate: 0.00073673]
	Learning Rate: 0.000736729
	LOSS [training: 0.009254673503211885 | validation: 0.007061163303333076]
	TIME [epoch: 35.6 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008672774620325986		[learning rate: 0.0007338]
	Learning Rate: 0.000733799
	LOSS [training: 0.008672774620325986 | validation: 0.006987855885768663]
	TIME [epoch: 35.6 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008334596028553194		[learning rate: 0.00073088]
	Learning Rate: 0.00073088
	LOSS [training: 0.008334596028553194 | validation: 0.00735924307900807]
	TIME [epoch: 35.6 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00875365851207408		[learning rate: 0.00072797]
	Learning Rate: 0.000727973
	LOSS [training: 0.00875365851207408 | validation: 0.0071822007034214016]
	TIME [epoch: 35.6 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0088778228430089		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 0.0088778228430089 | validation: 0.006598039373122058]
	TIME [epoch: 35.6 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009120759441708811		[learning rate: 0.00072219]
	Learning Rate: 0.000722194
	LOSS [training: 0.009120759441708811 | validation: 0.006853098272338025]
	TIME [epoch: 35.6 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00860916078225524		[learning rate: 0.00071932]
	Learning Rate: 0.000719322
	LOSS [training: 0.00860916078225524 | validation: 0.0077661922516910845]
	TIME [epoch: 35.6 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008734781092576659		[learning rate: 0.00071646]
	Learning Rate: 0.000716461
	LOSS [training: 0.008734781092576659 | validation: 0.007542002435178051]
	TIME [epoch: 35.6 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008043572521709935		[learning rate: 0.00071361]
	Learning Rate: 0.000713611
	LOSS [training: 0.008043572521709935 | validation: 0.007308586135967747]
	TIME [epoch: 35.6 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008475569653340623		[learning rate: 0.00071077]
	Learning Rate: 0.000710773
	LOSS [training: 0.008475569653340623 | validation: 0.006856165203048303]
	TIME [epoch: 35.6 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009361165417423262		[learning rate: 0.00070795]
	Learning Rate: 0.000707946
	LOSS [training: 0.009361165417423262 | validation: 0.0070034133660458325]
	TIME [epoch: 35.6 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00813030748485136		[learning rate: 0.00070513]
	Learning Rate: 0.00070513
	LOSS [training: 0.00813030748485136 | validation: 0.007102225103115392]
	TIME [epoch: 35.6 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00814439575045139		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.00814439575045139 | validation: 0.007268601246800924]
	TIME [epoch: 35.6 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008848000862975314		[learning rate: 0.00069953]
	Learning Rate: 0.000699532
	LOSS [training: 0.008848000862975314 | validation: 0.006749572387612339]
	TIME [epoch: 35.6 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009344193030885302		[learning rate: 0.00069675]
	Learning Rate: 0.00069675
	LOSS [training: 0.009344193030885302 | validation: 0.006992713016119256]
	TIME [epoch: 35.6 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009378772768023118		[learning rate: 0.00069398]
	Learning Rate: 0.000693979
	LOSS [training: 0.009378772768023118 | validation: 0.006937746715113357]
	TIME [epoch: 35.5 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008244258933090033		[learning rate: 0.00069122]
	Learning Rate: 0.000691219
	LOSS [training: 0.008244258933090033 | validation: 0.007143222379619489]
	TIME [epoch: 35.6 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010852535665063043		[learning rate: 0.00068847]
	Learning Rate: 0.000688469
	LOSS [training: 0.010852535665063043 | validation: 0.00715389739020614]
	TIME [epoch: 35.6 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010313644661073052		[learning rate: 0.00068573]
	Learning Rate: 0.000685731
	LOSS [training: 0.010313644661073052 | validation: 0.0074188455308127664]
	TIME [epoch: 35.6 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008605539684398093		[learning rate: 0.000683]
	Learning Rate: 0.000683004
	LOSS [training: 0.008605539684398093 | validation: 0.007503562176310981]
	TIME [epoch: 35.6 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009975771069935588		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 0.009975771069935588 | validation: 0.007481216718615952]
	TIME [epoch: 35.6 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007950279801963304		[learning rate: 0.00067758]
	Learning Rate: 0.000677582
	LOSS [training: 0.007950279801963304 | validation: 0.007072594078840727]
	TIME [epoch: 35.6 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007933879726139967		[learning rate: 0.00067489]
	Learning Rate: 0.000674887
	LOSS [training: 0.007933879726139967 | validation: 0.006538585632747102]
	TIME [epoch: 35.6 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009087317307999339		[learning rate: 0.0006722]
	Learning Rate: 0.000672202
	LOSS [training: 0.009087317307999339 | validation: 0.006807871862393991]
	TIME [epoch: 35.6 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008321854858400016		[learning rate: 0.00066953]
	Learning Rate: 0.000669529
	LOSS [training: 0.008321854858400016 | validation: 0.00795817371082402]
	TIME [epoch: 35.6 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009428324199228635		[learning rate: 0.00066687]
	Learning Rate: 0.000666866
	LOSS [training: 0.009428324199228635 | validation: 0.007144731345072259]
	TIME [epoch: 35.6 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00837906511958477		[learning rate: 0.00066421]
	Learning Rate: 0.000664213
	LOSS [training: 0.00837906511958477 | validation: 0.0072375458118211135]
	TIME [epoch: 35.6 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008509647322844016		[learning rate: 0.00066157]
	Learning Rate: 0.000661572
	LOSS [training: 0.008509647322844016 | validation: 0.00728927714733747]
	TIME [epoch: 35.6 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009286061292437732		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 0.009286061292437732 | validation: 0.006937311616254838]
	TIME [epoch: 35.6 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00818362586393097		[learning rate: 0.00065632]
	Learning Rate: 0.00065632
	LOSS [training: 0.00818362586393097 | validation: 0.0068683096557918735]
	TIME [epoch: 35.6 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008319572114395267		[learning rate: 0.00065371]
	Learning Rate: 0.000653709
	LOSS [training: 0.008319572114395267 | validation: 0.007600838432648011]
	TIME [epoch: 35.6 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008224167970016375		[learning rate: 0.00065111]
	Learning Rate: 0.000651109
	LOSS [training: 0.008224167970016375 | validation: 0.006752301257237229]
	TIME [epoch: 35.6 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00840637360018521		[learning rate: 0.00064852]
	Learning Rate: 0.00064852
	LOSS [training: 0.00840637360018521 | validation: 0.006909746415391149]
	TIME [epoch: 35.6 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008238172878788187		[learning rate: 0.00064594]
	Learning Rate: 0.00064594
	LOSS [training: 0.008238172878788187 | validation: 0.007549468711891594]
	TIME [epoch: 35.5 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007749894386797829		[learning rate: 0.00064337]
	Learning Rate: 0.000643371
	LOSS [training: 0.007749894386797829 | validation: 0.007017763131113419]
	TIME [epoch: 35.6 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008065827505540663		[learning rate: 0.00064081]
	Learning Rate: 0.000640812
	LOSS [training: 0.008065827505540663 | validation: 0.0067264314664602105]
	TIME [epoch: 35.6 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007974557538007816		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 0.007974557538007816 | validation: 0.007493975640661099]
	TIME [epoch: 35.6 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00795322522579063		[learning rate: 0.00063572]
	Learning Rate: 0.000635725
	LOSS [training: 0.00795322522579063 | validation: 0.006975900757018444]
	TIME [epoch: 35.6 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008454545682947585		[learning rate: 0.0006332]
	Learning Rate: 0.000633196
	LOSS [training: 0.008454545682947585 | validation: 0.007299179159860706]
	TIME [epoch: 35.6 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008579309392636993		[learning rate: 0.00063068]
	Learning Rate: 0.000630678
	LOSS [training: 0.008579309392636993 | validation: 0.007225371371420129]
	TIME [epoch: 35.6 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007710199835415412		[learning rate: 0.00062817]
	Learning Rate: 0.00062817
	LOSS [training: 0.007710199835415412 | validation: 0.007005671541726573]
	TIME [epoch: 35.6 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008934148884479246		[learning rate: 0.00062567]
	Learning Rate: 0.000625671
	LOSS [training: 0.008934148884479246 | validation: 0.007309378569407374]
	TIME [epoch: 35.6 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008215550661343128		[learning rate: 0.00062318]
	Learning Rate: 0.000623183
	LOSS [training: 0.008215550661343128 | validation: 0.007412131593917387]
	TIME [epoch: 35.5 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00888577070640728		[learning rate: 0.0006207]
	Learning Rate: 0.000620704
	LOSS [training: 0.00888577070640728 | validation: 0.0071917068488569404]
	TIME [epoch: 35.6 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008078757132550862		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 0.008078757132550862 | validation: 0.007230590239575468]
	TIME [epoch: 35.6 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008143529707121165		[learning rate: 0.00061578]
	Learning Rate: 0.000615777
	LOSS [training: 0.008143529707121165 | validation: 0.006872289026163725]
	TIME [epoch: 35.6 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008467089038129157		[learning rate: 0.00061333]
	Learning Rate: 0.000613327
	LOSS [training: 0.008467089038129157 | validation: 0.007453087808323847]
	TIME [epoch: 35.6 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007759106318967436		[learning rate: 0.00061089]
	Learning Rate: 0.000610888
	LOSS [training: 0.007759106318967436 | validation: 0.006947915126516224]
	TIME [epoch: 35.6 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008410441340561656		[learning rate: 0.00060846]
	Learning Rate: 0.000608458
	LOSS [training: 0.008410441340561656 | validation: 0.0068165573762124345]
	TIME [epoch: 35.6 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008276335269867888		[learning rate: 0.00060604]
	Learning Rate: 0.000606038
	LOSS [training: 0.008276335269867888 | validation: 0.007375891866841533]
	TIME [epoch: 35.6 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008588440790758468		[learning rate: 0.00060363]
	Learning Rate: 0.000603628
	LOSS [training: 0.008588440790758468 | validation: 0.007117787262311453]
	TIME [epoch: 35.6 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008201210691091311		[learning rate: 0.00060123]
	Learning Rate: 0.000601227
	LOSS [training: 0.008201210691091311 | validation: 0.0074034569005551765]
	TIME [epoch: 35.6 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007856795051315847		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.007856795051315847 | validation: 0.007099321533683862]
	TIME [epoch: 35.6 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009123697992757373		[learning rate: 0.00059645]
	Learning Rate: 0.000596454
	LOSS [training: 0.009123697992757373 | validation: 0.0067823264077499]
	TIME [epoch: 35.6 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008658153726167999		[learning rate: 0.00059408]
	Learning Rate: 0.000594082
	LOSS [training: 0.008658153726167999 | validation: 0.006748331471569795]
	TIME [epoch: 35.6 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008638991032705493		[learning rate: 0.00059172]
	Learning Rate: 0.000591719
	LOSS [training: 0.008638991032705493 | validation: 0.007120888221326047]
	TIME [epoch: 35.6 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007823703550169134		[learning rate: 0.00058937]
	Learning Rate: 0.000589365
	LOSS [training: 0.007823703550169134 | validation: 0.006954071571284981]
	TIME [epoch: 35.6 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008254213358167641		[learning rate: 0.00058702]
	Learning Rate: 0.000587021
	LOSS [training: 0.008254213358167641 | validation: 0.006967997116772354]
	TIME [epoch: 35.6 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009103090382667468		[learning rate: 0.00058469]
	Learning Rate: 0.000584687
	LOSS [training: 0.009103090382667468 | validation: 0.006875530278337686]
	TIME [epoch: 35.6 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008464975489336259		[learning rate: 0.00058236]
	Learning Rate: 0.000582361
	LOSS [training: 0.008464975489336259 | validation: 0.0072111492573564695]
	TIME [epoch: 35.5 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00831442791913436		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 0.00831442791913436 | validation: 0.007171493058166422]
	TIME [epoch: 35.5 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008713299840313595		[learning rate: 0.00057774]
	Learning Rate: 0.000577738
	LOSS [training: 0.008713299840313595 | validation: 0.007406947762137484]
	TIME [epoch: 35.6 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007934798597180404		[learning rate: 0.00057544]
	Learning Rate: 0.00057544
	LOSS [training: 0.007934798597180404 | validation: 0.0071918613881793905]
	TIME [epoch: 35.6 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009478630380043068		[learning rate: 0.00057315]
	Learning Rate: 0.000573151
	LOSS [training: 0.009478630380043068 | validation: 0.006933362198058948]
	TIME [epoch: 35.6 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011165939554723083		[learning rate: 0.00057087]
	Learning Rate: 0.000570872
	LOSS [training: 0.011165939554723083 | validation: 0.007021383721553498]
	TIME [epoch: 35.6 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008073434164960135		[learning rate: 0.0005686]
	Learning Rate: 0.000568601
	LOSS [training: 0.008073434164960135 | validation: 0.007236328016782162]
	TIME [epoch: 35.6 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009116201321735235		[learning rate: 0.00056634]
	Learning Rate: 0.00056634
	LOSS [training: 0.009116201321735235 | validation: 0.007260750507468767]
	TIME [epoch: 35.6 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008356783046687516		[learning rate: 0.00056409]
	Learning Rate: 0.000564087
	LOSS [training: 0.008356783046687516 | validation: 0.006941335265403081]
	TIME [epoch: 35.6 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00851417884734403		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 0.00851417884734403 | validation: 0.0074044275643342814]
	TIME [epoch: 35.6 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008265244027368493		[learning rate: 0.00055961]
	Learning Rate: 0.000559609
	LOSS [training: 0.008265244027368493 | validation: 0.006831898593525021]
	TIME [epoch: 35.6 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00821176452678539		[learning rate: 0.00055738]
	Learning Rate: 0.000557383
	LOSS [training: 0.00821176452678539 | validation: 0.0074764787010072374]
	TIME [epoch: 35.6 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.011958843516875648		[learning rate: 0.00055517]
	Learning Rate: 0.000555166
	LOSS [training: 0.011958843516875648 | validation: 0.006741357581034696]
	TIME [epoch: 35.6 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010615567981570172		[learning rate: 0.00055296]
	Learning Rate: 0.000552958
	LOSS [training: 0.010615567981570172 | validation: 0.007704771227102029]
	TIME [epoch: 35.5 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008271784420509458		[learning rate: 0.00055076]
	Learning Rate: 0.000550759
	LOSS [training: 0.008271784420509458 | validation: 0.007312107604641294]
	TIME [epoch: 35.6 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008087330820410922		[learning rate: 0.00054857]
	Learning Rate: 0.000548568
	LOSS [training: 0.008087330820410922 | validation: 0.007803413428999409]
	TIME [epoch: 35.6 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008018538481060315		[learning rate: 0.00054639]
	Learning Rate: 0.000546387
	LOSS [training: 0.008018538481060315 | validation: 0.007270405185714632]
	TIME [epoch: 35.6 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008980404942226523		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 0.008980404942226523 | validation: 0.006654378286594717]
	TIME [epoch: 35.6 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008633187090720133		[learning rate: 0.00054205]
	Learning Rate: 0.000542049
	LOSS [training: 0.008633187090720133 | validation: 0.007493423511530146]
	TIME [epoch: 35.6 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009075100525258195		[learning rate: 0.00053989]
	Learning Rate: 0.000539893
	LOSS [training: 0.009075100525258195 | validation: 0.006751087720835077]
	TIME [epoch: 35.7 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00841412819607653		[learning rate: 0.00053775]
	Learning Rate: 0.000537746
	LOSS [training: 0.00841412819607653 | validation: 0.006653141955133997]
	TIME [epoch: 35.5 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008011365998912277		[learning rate: 0.00053561]
	Learning Rate: 0.000535607
	LOSS [training: 0.008011365998912277 | validation: 0.007270396375999711]
	TIME [epoch: 35.6 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008878807637385485		[learning rate: 0.00053348]
	Learning Rate: 0.000533477
	LOSS [training: 0.008878807637385485 | validation: 0.006801615878586685]
	TIME [epoch: 35.6 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008401784838852977		[learning rate: 0.00053135]
	Learning Rate: 0.000531355
	LOSS [training: 0.008401784838852977 | validation: 0.006972870894375349]
	TIME [epoch: 35.7 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008479713430477922		[learning rate: 0.00052924]
	Learning Rate: 0.000529241
	LOSS [training: 0.008479713430477922 | validation: 0.007351406391261977]
	TIME [epoch: 35.6 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008699825722545967		[learning rate: 0.00052714]
	Learning Rate: 0.000527136
	LOSS [training: 0.008699825722545967 | validation: 0.0067440302985920615]
	TIME [epoch: 35.6 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009384936638846438		[learning rate: 0.00052504]
	Learning Rate: 0.00052504
	LOSS [training: 0.009384936638846438 | validation: 0.007260001069325388]
	TIME [epoch: 35.6 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008534683900290723		[learning rate: 0.00052295]
	Learning Rate: 0.000522952
	LOSS [training: 0.008534683900290723 | validation: 0.007347241287264756]
	TIME [epoch: 35.6 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008909228070757594		[learning rate: 0.00052087]
	Learning Rate: 0.000520872
	LOSS [training: 0.008909228070757594 | validation: 0.007150164077218482]
	TIME [epoch: 35.6 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009052069812098227		[learning rate: 0.0005188]
	Learning Rate: 0.0005188
	LOSS [training: 0.009052069812098227 | validation: 0.007297981991548119]
	TIME [epoch: 35.6 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008609974393730128		[learning rate: 0.00051674]
	Learning Rate: 0.000516737
	LOSS [training: 0.008609974393730128 | validation: 0.007175399020538526]
	TIME [epoch: 35.6 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00845213152930497		[learning rate: 0.00051468]
	Learning Rate: 0.000514681
	LOSS [training: 0.00845213152930497 | validation: 0.007209608367632764]
	TIME [epoch: 35.6 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008055696637691255		[learning rate: 0.00051263]
	Learning Rate: 0.000512634
	LOSS [training: 0.008055696637691255 | validation: 0.007428251702322433]
	TIME [epoch: 35.6 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009069163647262492		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 0.009069163647262492 | validation: 0.007117365850629126]
	TIME [epoch: 35.6 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009329899579205004		[learning rate: 0.00050856]
	Learning Rate: 0.000508565
	LOSS [training: 0.009329899579205004 | validation: 0.0068178546170816826]
	TIME [epoch: 35.6 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.009032795651155601		[learning rate: 0.00050654]
	Learning Rate: 0.000506542
	LOSS [training: 0.009032795651155601 | validation: 0.006836201598934171]
	TIME [epoch: 35.6 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008626964471869232		[learning rate: 0.00050453]
	Learning Rate: 0.000504527
	LOSS [training: 0.008626964471869232 | validation: 0.007171249036467949]
	TIME [epoch: 35.6 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008039901960640592		[learning rate: 0.00050252]
	Learning Rate: 0.000502521
	LOSS [training: 0.008039901960640592 | validation: 0.007750653184665763]
	TIME [epoch: 35.6 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0085258204556886		[learning rate: 0.00050052]
	Learning Rate: 0.000500522
	LOSS [training: 0.0085258204556886 | validation: 0.007211611919789612]
	TIME [epoch: 35.6 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008941338641056019		[learning rate: 0.00049853]
	Learning Rate: 0.000498531
	LOSS [training: 0.008941338641056019 | validation: 0.007143157857927114]
	TIME [epoch: 35.6 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008275735902994606		[learning rate: 0.00049655]
	Learning Rate: 0.000496548
	LOSS [training: 0.008275735902994606 | validation: 0.006556990271212237]
	TIME [epoch: 35.5 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008231193597450552		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 0.008231193597450552 | validation: 0.006686949703095926]
	TIME [epoch: 35.6 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007437755168647813		[learning rate: 0.00049261]
	Learning Rate: 0.000492606
	LOSS [training: 0.007437755168647813 | validation: 0.007113684790553637]
	TIME [epoch: 35.5 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.010735025449773354		[learning rate: 0.00049065]
	Learning Rate: 0.000490647
	LOSS [training: 0.010735025449773354 | validation: 0.0072981204164441985]
	TIME [epoch: 35.6 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008672997410343436		[learning rate: 0.0004887]
	Learning Rate: 0.000488696
	LOSS [training: 0.008672997410343436 | validation: 0.007083194268590916]
	TIME [epoch: 35.7 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008458868173130494		[learning rate: 0.00048675]
	Learning Rate: 0.000486752
	LOSS [training: 0.008458868173130494 | validation: 0.007743489720707655]
	TIME [epoch: 35.6 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008354586664526714		[learning rate: 0.00048482]
	Learning Rate: 0.000484816
	LOSS [training: 0.008354586664526714 | validation: 0.007425740001945416]
	TIME [epoch: 35.6 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008012790722819692		[learning rate: 0.00048289]
	Learning Rate: 0.000482888
	LOSS [training: 0.008012790722819692 | validation: 0.007524415721951311]
	TIME [epoch: 35.7 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008861558530640749		[learning rate: 0.00048097]
	Learning Rate: 0.000480967
	LOSS [training: 0.008861558530640749 | validation: 0.007278790763043906]
	TIME [epoch: 35.6 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008108946277787374		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 0.008108946277787374 | validation: 0.006901651705636028]
	TIME [epoch: 35.6 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008255472910874966		[learning rate: 0.00047715]
	Learning Rate: 0.000477149
	LOSS [training: 0.008255472910874966 | validation: 0.007050460787679361]
	TIME [epoch: 35.6 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00954225466826692		[learning rate: 0.00047525]
	Learning Rate: 0.000475251
	LOSS [training: 0.00954225466826692 | validation: 0.0069462572957275535]
	TIME [epoch: 35.6 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008006320472204204		[learning rate: 0.00047336]
	Learning Rate: 0.000473361
	LOSS [training: 0.008006320472204204 | validation: 0.007119789468606448]
	TIME [epoch: 35.6 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.0077770350992786945		[learning rate: 0.00047148]
	Learning Rate: 0.000471478
	LOSS [training: 0.0077770350992786945 | validation: 0.0068248280252602945]
	TIME [epoch: 35.7 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008564056399094484		[learning rate: 0.0004696]
	Learning Rate: 0.000469603
	LOSS [training: 0.008564056399094484 | validation: 0.006987600712633419]
	TIME [epoch: 35.6 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008431808029486006		[learning rate: 0.00046774]
	Learning Rate: 0.000467735
	LOSS [training: 0.008431808029486006 | validation: 0.006718877427765198]
	TIME [epoch: 35.6 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00813122452281017		[learning rate: 0.00046587]
	Learning Rate: 0.000465875
	LOSS [training: 0.00813122452281017 | validation: 0.006810136983345272]
	TIME [epoch: 35.6 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00826166633875803		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 0.00826166633875803 | validation: 0.007182479071000239]
	TIME [epoch: 35.7 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008537119761565867		[learning rate: 0.00046218]
	Learning Rate: 0.000462176
	LOSS [training: 0.008537119761565867 | validation: 0.006977490111781978]
	TIME [epoch: 35.6 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.007234668317972614		[learning rate: 0.00046034]
	Learning Rate: 0.000460338
	LOSS [training: 0.007234668317972614 | validation: 0.0071151803766746815]
	TIME [epoch: 35.6 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008016855103107033		[learning rate: 0.00045851]
	Learning Rate: 0.000458507
	LOSS [training: 0.008016855103107033 | validation: 0.00779303115153977]
	TIME [epoch: 35.6 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.00853836415666542		[learning rate: 0.00045668]
	Learning Rate: 0.000456684
	LOSS [training: 0.00853836415666542 | validation: 0.0075432938003005936]
	TIME [epoch: 35.6 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.008168335071513537		[learning rate: 0.00045487]
	Learning Rate: 0.000454867
	LOSS [training: 0.008168335071513537 | validation: 0.006882495486405418]
	TIME [epoch: 35.6 sec]
	Saving model to: out/model_training/model_facs_dec1b_2d_v1_20240622_154550/states/model_facs_dec1b_2d_v1_820.pth
Halted early. No improvement in validation loss for 200 epochs.
Finished training in 29257.947 seconds.
