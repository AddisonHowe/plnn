Args:
Namespace(name='model_facs_v3_dec1b_2dpca_v13b', outdir='out/model_training/model_facs_v3_dec1b_2dpca_v13b', training_data='data/training_data/facs_v3/pca/dec1_fitonsubset/transition1_subset_epi_tr_ce_an_pc12/training', validation_data='data/training_data/facs_v3/pca/dec1_fitonsubset/transition1_subset_epi_tr_ce_an_pc12/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=10, batch_size=50, patience=200, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, quadratic_a=1.0, quadratic_b=1.0, ndims=2, nparams=2, nsigs=2, ncells=400, ncells_sample=400, model_do_sample=False, dt=0.005, dt_schedule='stepped', dt_schedule_bounds=[50, 100, 200, 300], dt_schedule_scales=[0.5, 0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', kernel='multiscale', bw_range=[0.2, 0.5, 0.9, 1.1, 1.3, 1.5, 2.0], optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 1071158772

Training model...

Saving initial model state to: out/model_training/model_facs_v3_dec1b_2dpca_v13b_20240716_161438/states/model_facs_v3_dec1b_2dpca_v13b_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.518740239251134		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.518740239251134 | validation: 1.1768903894143747]
	TIME [epoch: 25.1 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13b_20240716_161438/states/model_facs_v3_dec1b_2dpca_v13b_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.3061063345364643		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3061063345364643 | validation: 1.1104675943275812]
	TIME [epoch: 6.95 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13b_20240716_161438/states/model_facs_v3_dec1b_2dpca_v13b_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.2261821300794138		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2261821300794138 | validation: 1.0677240918364173]
	TIME [epoch: 6.96 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13b_20240716_161438/states/model_facs_v3_dec1b_2dpca_v13b_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.2111446555673548		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2111446555673548 | validation: 1.046874202571332]
	TIME [epoch: 6.93 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13b_20240716_161438/states/model_facs_v3_dec1b_2dpca_v13b_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.154831412429004		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.154831412429004 | validation: 1.0543957488504168]
	TIME [epoch: 6.95 sec]
EPOCH 6/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.1640213767109169		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1640213767109169 | validation: 1.0378634960159339]
	TIME [epoch: 6.93 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13b_20240716_161438/states/model_facs_v3_dec1b_2dpca_v13b_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.1059762830101525		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1059762830101525 | validation: 0.9445129312848903]
	TIME [epoch: 6.93 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13b_20240716_161438/states/model_facs_v3_dec1b_2dpca_v13b_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.0086627915227049		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0086627915227049 | validation: 0.9711336874497908]
	TIME [epoch: 6.93 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.9117890000569098		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9117890000569098 | validation: 0.7835512832845657]
	TIME [epoch: 6.94 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13b_20240716_161438/states/model_facs_v3_dec1b_2dpca_v13b_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.8999247848079942		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8999247848079942 | validation: 0.8506225907059093]
	TIME [epoch: 6.94 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.8293168858583072		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8293168858583072 | validation: 0.6880735553940152]
	TIME [epoch: 6.94 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13b_20240716_161438/states/model_facs_v3_dec1b_2dpca_v13b_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.7464647741423605		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7464647741423605 | validation: 0.6591731886362722]
	TIME [epoch: 6.94 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13b_20240716_161438/states/model_facs_v3_dec1b_2dpca_v13b_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.7145810583512585		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7145810583512585 | validation: 0.6351854143500015]
	TIME [epoch: 6.94 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13b_20240716_161438/states/model_facs_v3_dec1b_2dpca_v13b_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.6737647493927907		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6737647493927907 | validation: 0.5919597899824429]
	TIME [epoch: 6.93 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13b_20240716_161438/states/model_facs_v3_dec1b_2dpca_v13b_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.7409221241527306		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7409221241527306 | validation: 0.5188802375803414]
	TIME [epoch: 6.94 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13b_20240716_161438/states/model_facs_v3_dec1b_2dpca_v13b_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5985030254033923		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5985030254033923 | validation: 0.50465194410794]
	TIME [epoch: 6.93 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13b_20240716_161438/states/model_facs_v3_dec1b_2dpca_v13b_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5421147287734343		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5421147287734343 | validation: 0.4615709788565273]
	TIME [epoch: 6.94 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13b_20240716_161438/states/model_facs_v3_dec1b_2dpca_v13b_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5355714469774204		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5355714469774204 | validation: 0.5077005419343272]
	TIME [epoch: 6.95 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5292858521363889		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5292858521363889 | validation: 0.41270023125419203]
	TIME [epoch: 6.95 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13b_20240716_161438/states/model_facs_v3_dec1b_2dpca_v13b_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5010938868976773		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5010938868976773 | validation: 0.3923920670765008]
	TIME [epoch: 6.92 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13b_20240716_161438/states/model_facs_v3_dec1b_2dpca_v13b_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.46371877823449664		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.46371877823449664 | validation: 0.4484941021310059]
	TIME [epoch: 6.94 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4753852483079625		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4753852483079625 | validation: 0.39392038227920756]
	TIME [epoch: 6.94 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.49107889851328784		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.49107889851328784 | validation: 0.3463971784406317]
	TIME [epoch: 6.94 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13b_20240716_161438/states/model_facs_v3_dec1b_2dpca_v13b_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.43311146172553433		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.43311146172553433 | validation: 0.34922639198338773]
	TIME [epoch: 6.97 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.41419549430704		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.41419549430704 | validation: 0.32633605059654347]
	TIME [epoch: 6.94 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13b_20240716_161438/states/model_facs_v3_dec1b_2dpca_v13b_25.pth
	Model improved!!!
EPOCH 26/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4285207099563826		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4285207099563826 | validation: 0.31802552652740557]
	TIME [epoch: 6.95 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13b_20240716_161438/states/model_facs_v3_dec1b_2dpca_v13b_26.pth
	Model improved!!!
EPOCH 27/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.38984756503362333		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.38984756503362333 | validation: 0.3327108545547214]
	TIME [epoch: 6.96 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3790803960043248		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3790803960043248 | validation: 0.32640832748866666]
	TIME [epoch: 6.95 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3840757713496897		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3840757713496897 | validation: 0.31928431236946075]
	TIME [epoch: 6.95 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3990925338733317		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3990925338733317 | validation: 0.2882332434899424]
	TIME [epoch: 6.95 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13b_20240716_161438/states/model_facs_v3_dec1b_2dpca_v13b_30.pth
	Model improved!!!
EPOCH 31/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.36497482309992496		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.36497482309992496 | validation: 0.2890881444821428]
	TIME [epoch: 6.94 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3670232390841903		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3670232390841903 | validation: 0.30446455179992105]
	TIME [epoch: 6.95 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3691194348272518		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3691194348272518 | validation: 0.30073778055707134]
	TIME [epoch: 6.94 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.37425084348133053		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.37425084348133053 | validation: 0.28439042516224144]
	TIME [epoch: 6.95 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13b_20240716_161438/states/model_facs_v3_dec1b_2dpca_v13b_34.pth
	Model improved!!!
EPOCH 35/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.35092586926302705		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.35092586926302705 | validation: 0.3593715246975147]
	TIME [epoch: 6.94 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.38930950816251214		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.38930950816251214 | validation: 0.2796302389855635]
	TIME [epoch: 6.94 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13b_20240716_161438/states/model_facs_v3_dec1b_2dpca_v13b_36.pth
	Model improved!!!
EPOCH 37/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3527467377988643		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3527467377988643 | validation: 0.28904339776275323]
	TIME [epoch: 6.94 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3484940267775754		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3484940267775754 | validation: 0.27767329584410094]
	TIME [epoch: 6.94 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13b_20240716_161438/states/model_facs_v3_dec1b_2dpca_v13b_38.pth
	Model improved!!!
EPOCH 39/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.365156485593495		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.365156485593495 | validation: 0.29990962007528177]
	TIME [epoch: 7 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3385828970781528		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3385828970781528 | validation: 0.2766147490259595]
	TIME [epoch: 6.94 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13b_20240716_161438/states/model_facs_v3_dec1b_2dpca_v13b_40.pth
	Model improved!!!
EPOCH 41/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3277921423896602		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3277921423896602 | validation: 0.32884541479799034]
	TIME [epoch: 7.05 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3562835513334519		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3562835513334519 | validation: 0.31072983105245705]
	TIME [epoch: 6.94 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3347052041733383		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3347052041733383 | validation: 0.2696724910183057]
	TIME [epoch: 6.94 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13b_20240716_161438/states/model_facs_v3_dec1b_2dpca_v13b_43.pth
	Model improved!!!
EPOCH 44/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.33739727693068966		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.33739727693068966 | validation: 0.2799706368440388]
	TIME [epoch: 6.94 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3180702712808359		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3180702712808359 | validation: 0.28105223466374274]
	TIME [epoch: 6.95 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3241323900836225		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3241323900836225 | validation: 0.2628126342010972]
	TIME [epoch: 6.95 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13b_20240716_161438/states/model_facs_v3_dec1b_2dpca_v13b_46.pth
	Model improved!!!
EPOCH 47/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3506777565582855		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3506777565582855 | validation: 0.26358719329106306]
	TIME [epoch: 6.94 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3158154562622397		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3158154562622397 | validation: 0.2858186009791088]
	TIME [epoch: 6.94 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3283891737442637		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3283891737442637 | validation: 0.2535677500868584]
	TIME [epoch: 6.94 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13b_20240716_161438/states/model_facs_v3_dec1b_2dpca_v13b_49.pth
	Model improved!!!
EPOCH 50/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.30979789385924006		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.30979789385924006 | validation: 0.2515050259078356]
	TIME [epoch: 6.95 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13b_20240716_161438/states/model_facs_v3_dec1b_2dpca_v13b_50.pth
	Model improved!!!
EPOCH 51/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3312973895521614		[learning rate: 0.0099705]
	Learning Rate: 0.00997052
	LOSS [training: 0.3312973895521614 | validation: 0.25629446317264526]
	TIME [epoch: 29.7 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3356899792303329		[learning rate: 0.0099353]
	Learning Rate: 0.00993527
	LOSS [training: 0.3356899792303329 | validation: 0.25675766441153547]
	TIME [epoch: 13.4 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3138461158873551		[learning rate: 0.0099001]
	Learning Rate: 0.00990013
	LOSS [training: 0.3138461158873551 | validation: 0.27685598904244174]
	TIME [epoch: 13.4 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.32443517035921343		[learning rate: 0.0098651]
	Learning Rate: 0.00986512
	LOSS [training: 0.32443517035921343 | validation: 0.24659597052528398]
	TIME [epoch: 13.4 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13b_20240716_161438/states/model_facs_v3_dec1b_2dpca_v13b_54.pth
	Model improved!!!
EPOCH 55/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.32603663436280816		[learning rate: 0.0098302]
	Learning Rate: 0.00983024
	LOSS [training: 0.32603663436280816 | validation: 0.2677450859401395]
	TIME [epoch: 13.4 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3121170134465762		[learning rate: 0.0097955]
	Learning Rate: 0.00979548
	LOSS [training: 0.3121170134465762 | validation: 0.2468497214808396]
	TIME [epoch: 13.4 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.31590042856818207		[learning rate: 0.0097608]
	Learning Rate: 0.00976084
	LOSS [training: 0.31590042856818207 | validation: 0.25465805769114214]
	TIME [epoch: 13.4 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.33467801363175226		[learning rate: 0.0097263]
	Learning Rate: 0.00972632
	LOSS [training: 0.33467801363175226 | validation: 0.2524054458900614]
	TIME [epoch: 13.4 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29927206657105176		[learning rate: 0.0096919]
	Learning Rate: 0.00969193
	LOSS [training: 0.29927206657105176 | validation: 0.23439111654917685]
	TIME [epoch: 13.4 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13b_20240716_161438/states/model_facs_v3_dec1b_2dpca_v13b_59.pth
	Model improved!!!
EPOCH 60/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3030427363876964		[learning rate: 0.0096577]
	Learning Rate: 0.00965766
	LOSS [training: 0.3030427363876964 | validation: 0.2409059703021538]
	TIME [epoch: 13.4 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3032411905698123		[learning rate: 0.0096235]
	Learning Rate: 0.00962351
	LOSS [training: 0.3032411905698123 | validation: 0.24339204623270275]
	TIME [epoch: 13.4 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.322292259900764		[learning rate: 0.0095895]
	Learning Rate: 0.00958948
	LOSS [training: 0.322292259900764 | validation: 0.24623571486174822]
	TIME [epoch: 13.4 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3051977601405251		[learning rate: 0.0095556]
	Learning Rate: 0.00955557
	LOSS [training: 0.3051977601405251 | validation: 0.3114507835393075]
	TIME [epoch: 13.4 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3132211305439706		[learning rate: 0.0095218]
	Learning Rate: 0.00952177
	LOSS [training: 0.3132211305439706 | validation: 0.2279811401701492]
	TIME [epoch: 13.4 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13b_20240716_161438/states/model_facs_v3_dec1b_2dpca_v13b_64.pth
	Model improved!!!
EPOCH 65/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28805595327538225		[learning rate: 0.0094881]
	Learning Rate: 0.0094881
	LOSS [training: 0.28805595327538225 | validation: 0.30158032348425245]
	TIME [epoch: 13.4 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.32147554792725874		[learning rate: 0.0094546]
	Learning Rate: 0.00945455
	LOSS [training: 0.32147554792725874 | validation: 0.23899595619241615]
	TIME [epoch: 13.3 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2969157402441111		[learning rate: 0.0094211]
	Learning Rate: 0.00942112
	LOSS [training: 0.2969157402441111 | validation: 0.24710619033118206]
	TIME [epoch: 13.4 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2809799549530696		[learning rate: 0.0093878]
	Learning Rate: 0.00938781
	LOSS [training: 0.2809799549530696 | validation: 0.2465568922797056]
	TIME [epoch: 13.3 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.30564368748857645		[learning rate: 0.0093546]
	Learning Rate: 0.00935461
	LOSS [training: 0.30564368748857645 | validation: 0.22963827820096974]
	TIME [epoch: 13.4 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2872096450108516		[learning rate: 0.0093215]
	Learning Rate: 0.00932153
	LOSS [training: 0.2872096450108516 | validation: 0.2334529537566447]
	TIME [epoch: 13.4 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.31114468286712776		[learning rate: 0.0092886]
	Learning Rate: 0.00928857
	LOSS [training: 0.31114468286712776 | validation: 0.26916769736999846]
	TIME [epoch: 13.4 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2889622854239288		[learning rate: 0.0092557]
	Learning Rate: 0.00925572
	LOSS [training: 0.2889622854239288 | validation: 0.24656381788550313]
	TIME [epoch: 13.4 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29906823753463646		[learning rate: 0.009223]
	Learning Rate: 0.00922299
	LOSS [training: 0.29906823753463646 | validation: 0.24522489811600262]
	TIME [epoch: 13.4 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.31402429147752015		[learning rate: 0.0091904]
	Learning Rate: 0.00919038
	LOSS [training: 0.31402429147752015 | validation: 0.2535941877238481]
	TIME [epoch: 13.4 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29830399721789574		[learning rate: 0.0091579]
	Learning Rate: 0.00915788
	LOSS [training: 0.29830399721789574 | validation: 0.2535515109084724]
	TIME [epoch: 13.4 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28463892842400307		[learning rate: 0.0091255]
	Learning Rate: 0.00912549
	LOSS [training: 0.28463892842400307 | validation: 0.23202433606839096]
	TIME [epoch: 13.4 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2930819219246457		[learning rate: 0.0090932]
	Learning Rate: 0.00909323
	LOSS [training: 0.2930819219246457 | validation: 0.2347167840965733]
	TIME [epoch: 13.4 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2809361433965604		[learning rate: 0.0090611]
	Learning Rate: 0.00906107
	LOSS [training: 0.2809361433965604 | validation: 0.23570311161501561]
	TIME [epoch: 13.4 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.30774329577498943		[learning rate: 0.009029]
	Learning Rate: 0.00902903
	LOSS [training: 0.30774329577498943 | validation: 0.2297061757306008]
	TIME [epoch: 13.4 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2870849058251513		[learning rate: 0.0089971]
	Learning Rate: 0.0089971
	LOSS [training: 0.2870849058251513 | validation: 0.23502388940192667]
	TIME [epoch: 13.4 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2977926217165873		[learning rate: 0.0089653]
	Learning Rate: 0.00896528
	LOSS [training: 0.2977926217165873 | validation: 0.22802187396743584]
	TIME [epoch: 13.4 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2779706159993148		[learning rate: 0.0089336]
	Learning Rate: 0.00893358
	LOSS [training: 0.2779706159993148 | validation: 0.22629476508758276]
	TIME [epoch: 13.4 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13b_20240716_161438/states/model_facs_v3_dec1b_2dpca_v13b_82.pth
	Model improved!!!
EPOCH 83/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2721645635918714		[learning rate: 0.008902]
	Learning Rate: 0.00890199
	LOSS [training: 0.2721645635918714 | validation: 0.2279210989337294]
	TIME [epoch: 13.4 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2929560003977354		[learning rate: 0.0088705]
	Learning Rate: 0.00887051
	LOSS [training: 0.2929560003977354 | validation: 0.2282048486995297]
	TIME [epoch: 13.3 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.30102379056269585		[learning rate: 0.0088391]
	Learning Rate: 0.00883914
	LOSS [training: 0.30102379056269585 | validation: 0.22606881822151612]
	TIME [epoch: 13.4 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13b_20240716_161438/states/model_facs_v3_dec1b_2dpca_v13b_85.pth
	Model improved!!!
EPOCH 86/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2755992286616075		[learning rate: 0.0088079]
	Learning Rate: 0.00880789
	LOSS [training: 0.2755992286616075 | validation: 0.23675913119872244]
	TIME [epoch: 13.4 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29101559607616784		[learning rate: 0.0087767]
	Learning Rate: 0.00877674
	LOSS [training: 0.29101559607616784 | validation: 0.22714011313207189]
	TIME [epoch: 13.4 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.295219654550354		[learning rate: 0.0087457]
	Learning Rate: 0.00874571
	LOSS [training: 0.295219654550354 | validation: 0.23571674674017]
	TIME [epoch: 13.4 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.270574134709809		[learning rate: 0.0087148]
	Learning Rate: 0.00871478
	LOSS [training: 0.270574134709809 | validation: 0.22178981930721187]
	TIME [epoch: 13.4 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13b_20240716_161438/states/model_facs_v3_dec1b_2dpca_v13b_89.pth
	Model improved!!!
EPOCH 90/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2717731398155255		[learning rate: 0.008684]
	Learning Rate: 0.00868396
	LOSS [training: 0.2717731398155255 | validation: 0.22581247879938596]
	TIME [epoch: 13.3 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.30784788228479004		[learning rate: 0.0086533]
	Learning Rate: 0.00865326
	LOSS [training: 0.30784788228479004 | validation: 0.23401745762555715]
	TIME [epoch: 13.4 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2768965847416916		[learning rate: 0.0086227]
	Learning Rate: 0.00862265
	LOSS [training: 0.2768965847416916 | validation: 0.22386066271707367]
	TIME [epoch: 13.4 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.292359547027224		[learning rate: 0.0085922]
	Learning Rate: 0.00859216
	LOSS [training: 0.292359547027224 | validation: 0.2421884389737785]
	TIME [epoch: 13.4 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2849233009391546		[learning rate: 0.0085618]
	Learning Rate: 0.00856178
	LOSS [training: 0.2849233009391546 | validation: 0.23159450214395458]
	TIME [epoch: 13.4 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2859693779424054		[learning rate: 0.0085315]
	Learning Rate: 0.0085315
	LOSS [training: 0.2859693779424054 | validation: 0.22081185268304876]
	TIME [epoch: 13.4 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13b_20240716_161438/states/model_facs_v3_dec1b_2dpca_v13b_95.pth
	Model improved!!!
EPOCH 96/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2870447187411358		[learning rate: 0.0085013]
	Learning Rate: 0.00850134
	LOSS [training: 0.2870447187411358 | validation: 0.22994508698350477]
	TIME [epoch: 13.3 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2788654065321889		[learning rate: 0.0084713]
	Learning Rate: 0.00847127
	LOSS [training: 0.2788654065321889 | validation: 0.2160195371016314]
	TIME [epoch: 13.3 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13b_20240716_161438/states/model_facs_v3_dec1b_2dpca_v13b_97.pth
	Model improved!!!
EPOCH 98/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2861500840647528		[learning rate: 0.0084413]
	Learning Rate: 0.00844132
	LOSS [training: 0.2861500840647528 | validation: 0.23887556991797232]
	TIME [epoch: 13.3 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29250359124853326		[learning rate: 0.0084115]
	Learning Rate: 0.00841147
	LOSS [training: 0.29250359124853326 | validation: 0.22177143465180876]
	TIME [epoch: 13.4 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2796278459947141		[learning rate: 0.0083817]
	Learning Rate: 0.00838172
	LOSS [training: 0.2796278459947141 | validation: 0.22277795336302414]
	TIME [epoch: 13.4 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26579757865640713		[learning rate: 0.0083521]
	Learning Rate: 0.00835208
	LOSS [training: 0.26579757865640713 | validation: 0.21490056301476756]
	TIME [epoch: 44.8 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13b_20240716_161438/states/model_facs_v3_dec1b_2dpca_v13b_101.pth
	Model improved!!!
EPOCH 102/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27686974716651735		[learning rate: 0.0083225]
	Learning Rate: 0.00832255
	LOSS [training: 0.27686974716651735 | validation: 0.23658092495588798]
	TIME [epoch: 28.7 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2698025171757163		[learning rate: 0.0082931]
	Learning Rate: 0.00829312
	LOSS [training: 0.2698025171757163 | validation: 0.21414853455691935]
	TIME [epoch: 28.7 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13b_20240716_161438/states/model_facs_v3_dec1b_2dpca_v13b_103.pth
	Model improved!!!
EPOCH 104/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29495799448722354		[learning rate: 0.0082638]
	Learning Rate: 0.00826379
	LOSS [training: 0.29495799448722354 | validation: 0.2229244380442917]
	TIME [epoch: 28.7 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2786533263129009		[learning rate: 0.0082346]
	Learning Rate: 0.00823457
	LOSS [training: 0.2786533263129009 | validation: 0.22298006519918445]
	TIME [epoch: 28.7 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2735068189042232		[learning rate: 0.0082055]
	Learning Rate: 0.00820545
	LOSS [training: 0.2735068189042232 | validation: 0.2346000462029234]
	TIME [epoch: 28.8 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2851481244633116		[learning rate: 0.0081764]
	Learning Rate: 0.00817644
	LOSS [training: 0.2851481244633116 | validation: 0.2216342743620192]
	TIME [epoch: 28.8 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2749042898420199		[learning rate: 0.0081475]
	Learning Rate: 0.00814752
	LOSS [training: 0.2749042898420199 | validation: 0.21161899858948724]
	TIME [epoch: 28.8 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13b_20240716_161438/states/model_facs_v3_dec1b_2dpca_v13b_108.pth
	Model improved!!!
EPOCH 109/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27430768077459683		[learning rate: 0.0081187]
	Learning Rate: 0.00811871
	LOSS [training: 0.27430768077459683 | validation: 0.22353142231350742]
	TIME [epoch: 28.7 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2697374820071294		[learning rate: 0.00809]
	Learning Rate: 0.00809
	LOSS [training: 0.2697374820071294 | validation: 0.22428076349781928]
	TIME [epoch: 28.7 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2796519089347667		[learning rate: 0.0080614]
	Learning Rate: 0.0080614
	LOSS [training: 0.2796519089347667 | validation: 0.22494172204138718]
	TIME [epoch: 28.7 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27560221244790895		[learning rate: 0.0080329]
	Learning Rate: 0.00803289
	LOSS [training: 0.27560221244790895 | validation: 0.2178853017259205]
	TIME [epoch: 28.7 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2786264016994326		[learning rate: 0.0080045]
	Learning Rate: 0.00800448
	LOSS [training: 0.2786264016994326 | validation: 0.2228850863502047]
	TIME [epoch: 28.7 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2677133376923038		[learning rate: 0.0079762]
	Learning Rate: 0.00797618
	LOSS [training: 0.2677133376923038 | validation: 0.21790112438599946]
	TIME [epoch: 28.7 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26692576647015936		[learning rate: 0.007948]
	Learning Rate: 0.00794797
	LOSS [training: 0.26692576647015936 | validation: 0.23225446883852235]
	TIME [epoch: 28.7 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2846606615938202		[learning rate: 0.0079199]
	Learning Rate: 0.00791987
	LOSS [training: 0.2846606615938202 | validation: 0.22586370470974465]
	TIME [epoch: 28.7 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27060059608113335		[learning rate: 0.0078919]
	Learning Rate: 0.00789186
	LOSS [training: 0.27060059608113335 | validation: 0.21831344706451178]
	TIME [epoch: 28.7 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27513712943602836		[learning rate: 0.007864]
	Learning Rate: 0.00786395
	LOSS [training: 0.27513712943602836 | validation: 0.2132710687657858]
	TIME [epoch: 28.7 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2685591076251684		[learning rate: 0.0078361]
	Learning Rate: 0.00783615
	LOSS [training: 0.2685591076251684 | validation: 0.2243226319999037]
	TIME [epoch: 28.7 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27723251370215957		[learning rate: 0.0078084]
	Learning Rate: 0.00780844
	LOSS [training: 0.27723251370215957 | validation: 0.21763914593860906]
	TIME [epoch: 28.7 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2791075042388155		[learning rate: 0.0077808]
	Learning Rate: 0.00778083
	LOSS [training: 0.2791075042388155 | validation: 0.2194156203666502]
	TIME [epoch: 28.7 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2656717256570991		[learning rate: 0.0077533]
	Learning Rate: 0.00775331
	LOSS [training: 0.2656717256570991 | validation: 0.2212317486301211]
	TIME [epoch: 28.7 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26570640179272326		[learning rate: 0.0077259]
	Learning Rate: 0.00772589
	LOSS [training: 0.26570640179272326 | validation: 0.22543986413314016]
	TIME [epoch: 28.7 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2758325353279889		[learning rate: 0.0076986]
	Learning Rate: 0.00769857
	LOSS [training: 0.2758325353279889 | validation: 0.21590192091850366]
	TIME [epoch: 28.7 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27170010177698883		[learning rate: 0.0076714]
	Learning Rate: 0.00767135
	LOSS [training: 0.27170010177698883 | validation: 0.21485355726983366]
	TIME [epoch: 28.7 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26462171349462		[learning rate: 0.0076442]
	Learning Rate: 0.00764422
	LOSS [training: 0.26462171349462 | validation: 0.21864134772894683]
	TIME [epoch: 28.7 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26069217894519725		[learning rate: 0.0076172]
	Learning Rate: 0.00761719
	LOSS [training: 0.26069217894519725 | validation: 0.22234837619785588]
	TIME [epoch: 28.7 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2841356064434458		[learning rate: 0.0075903]
	Learning Rate: 0.00759025
	LOSS [training: 0.2841356064434458 | validation: 0.2146214778852885]
	TIME [epoch: 28.7 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25722531178441393		[learning rate: 0.0075634]
	Learning Rate: 0.00756341
	LOSS [training: 0.25722531178441393 | validation: 0.2165625445658302]
	TIME [epoch: 28.7 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27028843855844925		[learning rate: 0.0075367]
	Learning Rate: 0.00753667
	LOSS [training: 0.27028843855844925 | validation: 0.22078130058942586]
	TIME [epoch: 28.7 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.272185573309844		[learning rate: 0.00751]
	Learning Rate: 0.00751002
	LOSS [training: 0.272185573309844 | validation: 0.234825550726418]
	TIME [epoch: 28.7 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2672633257754301		[learning rate: 0.0074835]
	Learning Rate: 0.00748346
	LOSS [training: 0.2672633257754301 | validation: 0.21621534341223497]
	TIME [epoch: 28.7 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2712533634765992		[learning rate: 0.007457]
	Learning Rate: 0.007457
	LOSS [training: 0.2712533634765992 | validation: 0.21326527557999686]
	TIME [epoch: 28.7 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2661027690685848		[learning rate: 0.0074306]
	Learning Rate: 0.00743063
	LOSS [training: 0.2661027690685848 | validation: 0.22204959083309678]
	TIME [epoch: 28.7 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26431314264223366		[learning rate: 0.0074044]
	Learning Rate: 0.00740435
	LOSS [training: 0.26431314264223366 | validation: 0.2175982165623706]
	TIME [epoch: 28.7 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26540279327517424		[learning rate: 0.0073782]
	Learning Rate: 0.00737817
	LOSS [training: 0.26540279327517424 | validation: 0.208496880350224]
	TIME [epoch: 28.7 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13b_20240716_161438/states/model_facs_v3_dec1b_2dpca_v13b_136.pth
	Model improved!!!
EPOCH 137/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2605723272344124		[learning rate: 0.0073521]
	Learning Rate: 0.00735208
	LOSS [training: 0.2605723272344124 | validation: 0.22200392246472508]
	TIME [epoch: 28.7 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2668198539155549		[learning rate: 0.0073261]
	Learning Rate: 0.00732608
	LOSS [training: 0.2668198539155549 | validation: 0.22451865820424985]
	TIME [epoch: 28.7 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2566688077884638		[learning rate: 0.0073002]
	Learning Rate: 0.00730018
	LOSS [training: 0.2566688077884638 | validation: 0.21295646476664146]
	TIME [epoch: 28.7 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27648124127311297		[learning rate: 0.0072744]
	Learning Rate: 0.00727436
	LOSS [training: 0.27648124127311297 | validation: 0.21626776564956618]
	TIME [epoch: 28.7 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26572560208959506		[learning rate: 0.0072486]
	Learning Rate: 0.00724864
	LOSS [training: 0.26572560208959506 | validation: 0.21303047199271133]
	TIME [epoch: 28.7 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26524532724139355		[learning rate: 0.007223]
	Learning Rate: 0.007223
	LOSS [training: 0.26524532724139355 | validation: 0.21016385420492414]
	TIME [epoch: 28.7 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.263627587529206		[learning rate: 0.0071975]
	Learning Rate: 0.00719746
	LOSS [training: 0.263627587529206 | validation: 0.21519621571201908]
	TIME [epoch: 28.7 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26375373909142724		[learning rate: 0.007172]
	Learning Rate: 0.00717201
	LOSS [training: 0.26375373909142724 | validation: 0.2138395394260848]
	TIME [epoch: 28.7 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2654691499931257		[learning rate: 0.0071467]
	Learning Rate: 0.00714665
	LOSS [training: 0.2654691499931257 | validation: 0.21440113259658894]
	TIME [epoch: 28.7 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2669145154432592		[learning rate: 0.0071214]
	Learning Rate: 0.00712138
	LOSS [training: 0.2669145154432592 | validation: 0.21439469174570744]
	TIME [epoch: 28.7 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26447666001382625		[learning rate: 0.0070962]
	Learning Rate: 0.0070962
	LOSS [training: 0.26447666001382625 | validation: 0.23824583023528206]
	TIME [epoch: 28.7 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27643067119488474		[learning rate: 0.0070711]
	Learning Rate: 0.0070711
	LOSS [training: 0.27643067119488474 | validation: 0.21754402640691145]
	TIME [epoch: 28.7 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2695586936918166		[learning rate: 0.0070461]
	Learning Rate: 0.0070461
	LOSS [training: 0.2695586936918166 | validation: 0.2172931365683791]
	TIME [epoch: 28.7 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2681960991722521		[learning rate: 0.0070212]
	Learning Rate: 0.00702118
	LOSS [training: 0.2681960991722521 | validation: 0.2149045876605588]
	TIME [epoch: 28.7 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2598219124694286		[learning rate: 0.0069964]
	Learning Rate: 0.00699635
	LOSS [training: 0.2598219124694286 | validation: 0.22420858186701081]
	TIME [epoch: 28.7 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26316694118527534		[learning rate: 0.0069716]
	Learning Rate: 0.00697161
	LOSS [training: 0.26316694118527534 | validation: 0.22031650717044665]
	TIME [epoch: 28.7 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27147382116628394		[learning rate: 0.006947]
	Learning Rate: 0.00694696
	LOSS [training: 0.27147382116628394 | validation: 0.21232564547238558]
	TIME [epoch: 28.7 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2554358997189272		[learning rate: 0.0069224]
	Learning Rate: 0.00692239
	LOSS [training: 0.2554358997189272 | validation: 0.21810732778645509]
	TIME [epoch: 28.7 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2737997830294392		[learning rate: 0.0068979]
	Learning Rate: 0.00689792
	LOSS [training: 0.2737997830294392 | validation: 0.21115066014273567]
	TIME [epoch: 28.7 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2640556501284454		[learning rate: 0.0068735]
	Learning Rate: 0.00687352
	LOSS [training: 0.2640556501284454 | validation: 0.21171741375584227]
	TIME [epoch: 28.7 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2589280638151647		[learning rate: 0.0068492]
	Learning Rate: 0.00684922
	LOSS [training: 0.2589280638151647 | validation: 0.2127629834656158]
	TIME [epoch: 28.7 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26053115922540554		[learning rate: 0.006825]
	Learning Rate: 0.006825
	LOSS [training: 0.26053115922540554 | validation: 0.23023000724161066]
	TIME [epoch: 28.7 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27337885170381676		[learning rate: 0.0068009]
	Learning Rate: 0.00680086
	LOSS [training: 0.27337885170381676 | validation: 0.22378155153506926]
	TIME [epoch: 28.7 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25835969346501875		[learning rate: 0.0067768]
	Learning Rate: 0.00677681
	LOSS [training: 0.25835969346501875 | validation: 0.2127097885019909]
	TIME [epoch: 28.7 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2653853692219956		[learning rate: 0.0067529]
	Learning Rate: 0.00675285
	LOSS [training: 0.2653853692219956 | validation: 0.21190935966442837]
	TIME [epoch: 28.7 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2602003359261241		[learning rate: 0.006729]
	Learning Rate: 0.00672897
	LOSS [training: 0.2602003359261241 | validation: 0.21127406947948307]
	TIME [epoch: 28.7 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25651981590181844		[learning rate: 0.0067052]
	Learning Rate: 0.00670518
	LOSS [training: 0.25651981590181844 | validation: 0.21210679882166877]
	TIME [epoch: 28.7 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27222389748110715		[learning rate: 0.0066815]
	Learning Rate: 0.00668147
	LOSS [training: 0.27222389748110715 | validation: 0.21430422150672737]
	TIME [epoch: 28.7 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2577510887524575		[learning rate: 0.0066578]
	Learning Rate: 0.00665784
	LOSS [training: 0.2577510887524575 | validation: 0.21648103787348125]
	TIME [epoch: 28.7 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.261208254662502		[learning rate: 0.0066343]
	Learning Rate: 0.0066343
	LOSS [training: 0.261208254662502 | validation: 0.21498334726170404]
	TIME [epoch: 28.7 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2676721487777531		[learning rate: 0.0066108]
	Learning Rate: 0.00661084
	LOSS [training: 0.2676721487777531 | validation: 0.2116926843668388]
	TIME [epoch: 28.7 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25893557417781704		[learning rate: 0.0065875]
	Learning Rate: 0.00658746
	LOSS [training: 0.25893557417781704 | validation: 0.21682460254140704]
	TIME [epoch: 28.7 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26684885463597796		[learning rate: 0.0065642]
	Learning Rate: 0.00656416
	LOSS [training: 0.26684885463597796 | validation: 0.2236873579883254]
	TIME [epoch: 28.7 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26206571411953566		[learning rate: 0.006541]
	Learning Rate: 0.00654095
	LOSS [training: 0.26206571411953566 | validation: 0.21399822655631415]
	TIME [epoch: 28.7 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2574861271889994		[learning rate: 0.0065178]
	Learning Rate: 0.00651782
	LOSS [training: 0.2574861271889994 | validation: 0.21760036389287687]
	TIME [epoch: 28.7 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26435735703778557		[learning rate: 0.0064948]
	Learning Rate: 0.00649477
	LOSS [training: 0.26435735703778557 | validation: 0.21437857025274715]
	TIME [epoch: 28.7 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25790177437222866		[learning rate: 0.0064718]
	Learning Rate: 0.00647181
	LOSS [training: 0.25790177437222866 | validation: 0.21022366505157836]
	TIME [epoch: 28.7 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25685004545518414		[learning rate: 0.0064489]
	Learning Rate: 0.00644892
	LOSS [training: 0.25685004545518414 | validation: 0.2433519017328299]
	TIME [epoch: 28.7 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2732111761160288		[learning rate: 0.0064261]
	Learning Rate: 0.00642612
	LOSS [training: 0.2732111761160288 | validation: 0.21020522189633767]
	TIME [epoch: 28.7 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26799719130117133		[learning rate: 0.0064034]
	Learning Rate: 0.00640339
	LOSS [training: 0.26799719130117133 | validation: 0.21521709694214525]
	TIME [epoch: 28.7 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24831894294136211		[learning rate: 0.0063808]
	Learning Rate: 0.00638075
	LOSS [training: 0.24831894294136211 | validation: 0.21945671054393362]
	TIME [epoch: 28.7 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25674508995311557		[learning rate: 0.0063582]
	Learning Rate: 0.00635819
	LOSS [training: 0.25674508995311557 | validation: 0.21425550025587264]
	TIME [epoch: 28.7 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2565890579409907		[learning rate: 0.0063357]
	Learning Rate: 0.0063357
	LOSS [training: 0.2565890579409907 | validation: 0.2095063925908159]
	TIME [epoch: 28.7 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2510449625422414		[learning rate: 0.0063133]
	Learning Rate: 0.0063133
	LOSS [training: 0.2510449625422414 | validation: 0.21241014965891541]
	TIME [epoch: 28.7 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26417634319904043		[learning rate: 0.006291]
	Learning Rate: 0.00629097
	LOSS [training: 0.26417634319904043 | validation: 0.2170225275229257]
	TIME [epoch: 28.7 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2585758705391616		[learning rate: 0.0062687]
	Learning Rate: 0.00626873
	LOSS [training: 0.2585758705391616 | validation: 0.21694899257530315]
	TIME [epoch: 28.7 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2623941745893413		[learning rate: 0.0062466]
	Learning Rate: 0.00624656
	LOSS [training: 0.2623941745893413 | validation: 0.21263277730686]
	TIME [epoch: 28.7 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25467181738379846		[learning rate: 0.0062245]
	Learning Rate: 0.00622447
	LOSS [training: 0.25467181738379846 | validation: 0.21657926173586262]
	TIME [epoch: 28.7 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.265345429426526		[learning rate: 0.0062025]
	Learning Rate: 0.00620246
	LOSS [training: 0.265345429426526 | validation: 0.21507170065747708]
	TIME [epoch: 28.7 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24951817546363977		[learning rate: 0.0061805]
	Learning Rate: 0.00618053
	LOSS [training: 0.24951817546363977 | validation: 0.21901985057021953]
	TIME [epoch: 28.7 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26333226830731654		[learning rate: 0.0061587]
	Learning Rate: 0.00615867
	LOSS [training: 0.26333226830731654 | validation: 0.22001951845731393]
	TIME [epoch: 28.7 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24975358374409792		[learning rate: 0.0061369]
	Learning Rate: 0.00613689
	LOSS [training: 0.24975358374409792 | validation: 0.21124704889774454]
	TIME [epoch: 28.7 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2568576512792661		[learning rate: 0.0061152]
	Learning Rate: 0.00611519
	LOSS [training: 0.2568576512792661 | validation: 0.2149438813741003]
	TIME [epoch: 28.7 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2641775508734801		[learning rate: 0.0060936]
	Learning Rate: 0.00609357
	LOSS [training: 0.2641775508734801 | validation: 0.21523381769413247]
	TIME [epoch: 28.7 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26536575049924443		[learning rate: 0.006072]
	Learning Rate: 0.00607202
	LOSS [training: 0.26536575049924443 | validation: 0.21393932239377483]
	TIME [epoch: 28.7 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27389942953239266		[learning rate: 0.0060505]
	Learning Rate: 0.00605055
	LOSS [training: 0.27389942953239266 | validation: 0.2064512647978976]
	TIME [epoch: 28.7 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13b_20240716_161438/states/model_facs_v3_dec1b_2dpca_v13b_192.pth
	Model improved!!!
EPOCH 193/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26239023192811656		[learning rate: 0.0060292]
	Learning Rate: 0.00602915
	LOSS [training: 0.26239023192811656 | validation: 0.22235510260596786]
	TIME [epoch: 28.7 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.265645711168522		[learning rate: 0.0060078]
	Learning Rate: 0.00600783
	LOSS [training: 0.265645711168522 | validation: 0.22124822758734236]
	TIME [epoch: 28.7 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.256052672653387		[learning rate: 0.0059866]
	Learning Rate: 0.00598659
	LOSS [training: 0.256052672653387 | validation: 0.2070198537096998]
	TIME [epoch: 28.7 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2529850302127215		[learning rate: 0.0059654]
	Learning Rate: 0.00596542
	LOSS [training: 0.2529850302127215 | validation: 0.21341404502333883]
	TIME [epoch: 28.7 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25816380414884516		[learning rate: 0.0059443]
	Learning Rate: 0.00594433
	LOSS [training: 0.25816380414884516 | validation: 0.21520373639375606]
	TIME [epoch: 28.7 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25484463394440704		[learning rate: 0.0059233]
	Learning Rate: 0.0059233
	LOSS [training: 0.25484463394440704 | validation: 0.21858525779187027]
	TIME [epoch: 28.7 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26773677604815804		[learning rate: 0.0059024]
	Learning Rate: 0.00590236
	LOSS [training: 0.26773677604815804 | validation: 0.2115900500076701]
	TIME [epoch: 28.7 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2589083945820734		[learning rate: 0.0058815]
	Learning Rate: 0.00588149
	LOSS [training: 0.2589083945820734 | validation: 0.2158287376147637]
	TIME [epoch: 28.7 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25525615065629464		[learning rate: 0.0058607]
	Learning Rate: 0.00586069
	LOSS [training: 0.25525615065629464 | validation: 0.21533770572323457]
	TIME [epoch: 77.6 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25980236806435636		[learning rate: 0.00584]
	Learning Rate: 0.00583996
	LOSS [training: 0.25980236806435636 | validation: 0.2098424191601978]
	TIME [epoch: 61.4 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2602877276694124		[learning rate: 0.0058193]
	Learning Rate: 0.00581931
	LOSS [training: 0.2602877276694124 | validation: 0.20990978760853385]
	TIME [epoch: 61.4 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2569427044987216		[learning rate: 0.0057987]
	Learning Rate: 0.00579874
	LOSS [training: 0.2569427044987216 | validation: 0.2133137401373535]
	TIME [epoch: 61.4 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.253178958994063		[learning rate: 0.0057782]
	Learning Rate: 0.00577823
	LOSS [training: 0.253178958994063 | validation: 0.21492137753991428]
	TIME [epoch: 61.4 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27092689803196185		[learning rate: 0.0057578]
	Learning Rate: 0.0057578
	LOSS [training: 0.27092689803196185 | validation: 0.21573466800802468]
	TIME [epoch: 61.4 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.261313285427135		[learning rate: 0.0057374]
	Learning Rate: 0.00573744
	LOSS [training: 0.261313285427135 | validation: 0.2144906576089646]
	TIME [epoch: 61.4 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2550937486429216		[learning rate: 0.0057171]
	Learning Rate: 0.00571715
	LOSS [training: 0.2550937486429216 | validation: 0.21736348542964962]
	TIME [epoch: 61.5 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25385254264696394		[learning rate: 0.0056969]
	Learning Rate: 0.00569693
	LOSS [training: 0.25385254264696394 | validation: 0.20876032175523468]
	TIME [epoch: 61.4 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2521983933603666		[learning rate: 0.0056768]
	Learning Rate: 0.00567679
	LOSS [training: 0.2521983933603666 | validation: 0.2126175301940055]
	TIME [epoch: 61.4 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24418868659357948		[learning rate: 0.0056567]
	Learning Rate: 0.00565671
	LOSS [training: 0.24418868659357948 | validation: 0.21333510647926027]
	TIME [epoch: 61.4 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2699616360963371		[learning rate: 0.0056367]
	Learning Rate: 0.00563671
	LOSS [training: 0.2699616360963371 | validation: 0.21044034136027948]
	TIME [epoch: 61.4 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25372096758473717		[learning rate: 0.0056168]
	Learning Rate: 0.00561678
	LOSS [training: 0.25372096758473717 | validation: 0.2169135154186148]
	TIME [epoch: 61.4 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25601318357997943		[learning rate: 0.0055969]
	Learning Rate: 0.00559691
	LOSS [training: 0.25601318357997943 | validation: 0.2031959893603684]
	TIME [epoch: 61.4 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13b_20240716_161438/states/model_facs_v3_dec1b_2dpca_v13b_214.pth
	Model improved!!!
EPOCH 215/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25312764272764615		[learning rate: 0.0055771]
	Learning Rate: 0.00557712
	LOSS [training: 0.25312764272764615 | validation: 0.21581747913186425]
	TIME [epoch: 61.3 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24563805603478941		[learning rate: 0.0055574]
	Learning Rate: 0.0055574
	LOSS [training: 0.24563805603478941 | validation: 0.21461943430064984]
	TIME [epoch: 61.3 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25542417224330305		[learning rate: 0.0055378]
	Learning Rate: 0.00553775
	LOSS [training: 0.25542417224330305 | validation: 0.21193232942884724]
	TIME [epoch: 61.3 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2596296425742664		[learning rate: 0.0055182]
	Learning Rate: 0.00551817
	LOSS [training: 0.2596296425742664 | validation: 0.20856740808152702]
	TIME [epoch: 61.3 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25671565288189163		[learning rate: 0.0054987]
	Learning Rate: 0.00549865
	LOSS [training: 0.25671565288189163 | validation: 0.2089915172919124]
	TIME [epoch: 61.3 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.249030672594907		[learning rate: 0.0054792]
	Learning Rate: 0.00547921
	LOSS [training: 0.249030672594907 | validation: 0.21100645883675187]
	TIME [epoch: 61.3 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25068039243085866		[learning rate: 0.0054598]
	Learning Rate: 0.00545983
	LOSS [training: 0.25068039243085866 | validation: 0.21251104603122412]
	TIME [epoch: 61.3 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2492243468542232		[learning rate: 0.0054405]
	Learning Rate: 0.00544053
	LOSS [training: 0.2492243468542232 | validation: 0.22654004748787648]
	TIME [epoch: 61.3 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25065510753295034		[learning rate: 0.0054213]
	Learning Rate: 0.00542129
	LOSS [training: 0.25065510753295034 | validation: 0.21714417741591654]
	TIME [epoch: 61.3 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2542569562711848		[learning rate: 0.0054021]
	Learning Rate: 0.00540212
	LOSS [training: 0.2542569562711848 | validation: 0.2197441048300016]
	TIME [epoch: 61.3 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2628472359355459		[learning rate: 0.005383]
	Learning Rate: 0.00538302
	LOSS [training: 0.2628472359355459 | validation: 0.21326710790280484]
	TIME [epoch: 61.3 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25523770727789463		[learning rate: 0.005364]
	Learning Rate: 0.00536398
	LOSS [training: 0.25523770727789463 | validation: 0.21769686056767895]
	TIME [epoch: 61.3 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25644796942495585		[learning rate: 0.005345]
	Learning Rate: 0.00534501
	LOSS [training: 0.25644796942495585 | validation: 0.21111332029970495]
	TIME [epoch: 61.3 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24614199164025777		[learning rate: 0.0053261]
	Learning Rate: 0.00532611
	LOSS [training: 0.24614199164025777 | validation: 0.21670925651115516]
	TIME [epoch: 61.3 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25152661809778204		[learning rate: 0.0053073]
	Learning Rate: 0.00530728
	LOSS [training: 0.25152661809778204 | validation: 0.2116123513819815]
	TIME [epoch: 61.3 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25212999403939396		[learning rate: 0.0052885]
	Learning Rate: 0.00528851
	LOSS [training: 0.25212999403939396 | validation: 0.21264400315581752]
	TIME [epoch: 61.3 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24832134878497103		[learning rate: 0.0052698]
	Learning Rate: 0.00526981
	LOSS [training: 0.24832134878497103 | validation: 0.21592668499211234]
	TIME [epoch: 61.3 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2579839025046456		[learning rate: 0.0052512]
	Learning Rate: 0.00525117
	LOSS [training: 0.2579839025046456 | validation: 0.21608721308521933]
	TIME [epoch: 61.3 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24725330375394097		[learning rate: 0.0052326]
	Learning Rate: 0.0052326
	LOSS [training: 0.24725330375394097 | validation: 0.21800523585577164]
	TIME [epoch: 61.3 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25682426667978375		[learning rate: 0.0052141]
	Learning Rate: 0.0052141
	LOSS [training: 0.25682426667978375 | validation: 0.2056850652573708]
	TIME [epoch: 61.3 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2579577125731507		[learning rate: 0.0051957]
	Learning Rate: 0.00519566
	LOSS [training: 0.2579577125731507 | validation: 0.21490535046313006]
	TIME [epoch: 61.3 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25263264340388797		[learning rate: 0.0051773]
	Learning Rate: 0.00517729
	LOSS [training: 0.25263264340388797 | validation: 0.21357720462479604]
	TIME [epoch: 61.3 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25860890498495254		[learning rate: 0.005159]
	Learning Rate: 0.00515898
	LOSS [training: 0.25860890498495254 | validation: 0.210987171427267]
	TIME [epoch: 61.3 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24808528402792573		[learning rate: 0.0051407]
	Learning Rate: 0.00514074
	LOSS [training: 0.24808528402792573 | validation: 0.22098045943330868]
	TIME [epoch: 61.3 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25551504248064		[learning rate: 0.0051226]
	Learning Rate: 0.00512256
	LOSS [training: 0.25551504248064 | validation: 0.20247642200408253]
	TIME [epoch: 61.3 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13b_20240716_161438/states/model_facs_v3_dec1b_2dpca_v13b_239.pth
	Model improved!!!
EPOCH 240/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26219827456249073		[learning rate: 0.0051044]
	Learning Rate: 0.00510445
	LOSS [training: 0.26219827456249073 | validation: 0.20824783598461294]
	TIME [epoch: 61.3 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2547942233493217		[learning rate: 0.0050864]
	Learning Rate: 0.0050864
	LOSS [training: 0.2547942233493217 | validation: 0.22039428165416833]
	TIME [epoch: 61.3 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24760547740596758		[learning rate: 0.0050684]
	Learning Rate: 0.00506841
	LOSS [training: 0.24760547740596758 | validation: 0.2142979605224642]
	TIME [epoch: 61.3 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25310601796748977		[learning rate: 0.0050505]
	Learning Rate: 0.00505049
	LOSS [training: 0.25310601796748977 | validation: 0.2124694807217685]
	TIME [epoch: 61.3 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2578763940699611		[learning rate: 0.0050326]
	Learning Rate: 0.00503263
	LOSS [training: 0.2578763940699611 | validation: 0.22173577251594315]
	TIME [epoch: 61.3 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25249551106960133		[learning rate: 0.0050148]
	Learning Rate: 0.00501483
	LOSS [training: 0.25249551106960133 | validation: 0.21356710653639532]
	TIME [epoch: 61.3 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2541264519177796		[learning rate: 0.0049971]
	Learning Rate: 0.0049971
	LOSS [training: 0.2541264519177796 | validation: 0.21598563963654477]
	TIME [epoch: 61.3 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2545018613806907		[learning rate: 0.0049794]
	Learning Rate: 0.00497943
	LOSS [training: 0.2545018613806907 | validation: 0.20967075677033686]
	TIME [epoch: 61.3 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25025764959097724		[learning rate: 0.0049618]
	Learning Rate: 0.00496182
	LOSS [training: 0.25025764959097724 | validation: 0.21558882595268117]
	TIME [epoch: 61.3 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25158593582687533		[learning rate: 0.0049443]
	Learning Rate: 0.00494427
	LOSS [training: 0.25158593582687533 | validation: 0.21364838834379712]
	TIME [epoch: 61.3 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.256130286969217		[learning rate: 0.0049268]
	Learning Rate: 0.00492679
	LOSS [training: 0.256130286969217 | validation: 0.20793887105599013]
	TIME [epoch: 61.3 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24568454799614756		[learning rate: 0.0049094]
	Learning Rate: 0.00490937
	LOSS [training: 0.24568454799614756 | validation: 0.21237125258247253]
	TIME [epoch: 61.3 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2549775033162535		[learning rate: 0.004892]
	Learning Rate: 0.00489201
	LOSS [training: 0.2549775033162535 | validation: 0.20919827145621545]
	TIME [epoch: 61.3 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24548761838380526		[learning rate: 0.0048747]
	Learning Rate: 0.00487471
	LOSS [training: 0.24548761838380526 | validation: 0.21442404954580835]
	TIME [epoch: 61.3 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25686008532934734		[learning rate: 0.0048575]
	Learning Rate: 0.00485747
	LOSS [training: 0.25686008532934734 | validation: 0.21198629720284198]
	TIME [epoch: 61.3 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2542018811787647		[learning rate: 0.0048403]
	Learning Rate: 0.00484029
	LOSS [training: 0.2542018811787647 | validation: 0.20884605386092706]
	TIME [epoch: 61.3 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2542318892440368		[learning rate: 0.0048232]
	Learning Rate: 0.00482318
	LOSS [training: 0.2542318892440368 | validation: 0.2072384719202584]
	TIME [epoch: 61.3 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2601490866845115		[learning rate: 0.0048061]
	Learning Rate: 0.00480612
	LOSS [training: 0.2601490866845115 | validation: 0.20926580255865784]
	TIME [epoch: 61.3 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24645408878815225		[learning rate: 0.0047891]
	Learning Rate: 0.00478913
	LOSS [training: 0.24645408878815225 | validation: 0.2165998484951602]
	TIME [epoch: 61.3 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.255382928496056		[learning rate: 0.0047722]
	Learning Rate: 0.00477219
	LOSS [training: 0.255382928496056 | validation: 0.2095353627677748]
	TIME [epoch: 61.3 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2594064969788087		[learning rate: 0.0047553]
	Learning Rate: 0.00475532
	LOSS [training: 0.2594064969788087 | validation: 0.22270512461932848]
	TIME [epoch: 61.3 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25053920805700813		[learning rate: 0.0047385]
	Learning Rate: 0.0047385
	LOSS [training: 0.25053920805700813 | validation: 0.21497989199228199]
	TIME [epoch: 61.3 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2581646143236847		[learning rate: 0.0047217]
	Learning Rate: 0.00472175
	LOSS [training: 0.2581646143236847 | validation: 0.20970433360963942]
	TIME [epoch: 61.3 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24347088215669568		[learning rate: 0.004705]
	Learning Rate: 0.00470505
	LOSS [training: 0.24347088215669568 | validation: 0.215324407920245]
	TIME [epoch: 61.3 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25430091587864645		[learning rate: 0.0046884]
	Learning Rate: 0.00468841
	LOSS [training: 0.25430091587864645 | validation: 0.21280684975899905]
	TIME [epoch: 61.3 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25711459925199104		[learning rate: 0.0046718]
	Learning Rate: 0.00467183
	LOSS [training: 0.25711459925199104 | validation: 0.21048593392053885]
	TIME [epoch: 61.3 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.251554461517204		[learning rate: 0.0046553]
	Learning Rate: 0.00465531
	LOSS [training: 0.251554461517204 | validation: 0.21467334119632014]
	TIME [epoch: 61.3 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25026511538259205		[learning rate: 0.0046388]
	Learning Rate: 0.00463885
	LOSS [training: 0.25026511538259205 | validation: 0.209880716238073]
	TIME [epoch: 61.3 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2447610977935021		[learning rate: 0.0046224]
	Learning Rate: 0.00462245
	LOSS [training: 0.2447610977935021 | validation: 0.20852601255214825]
	TIME [epoch: 61.3 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25451632575886457		[learning rate: 0.0046061]
	Learning Rate: 0.0046061
	LOSS [training: 0.25451632575886457 | validation: 0.2114558771157832]
	TIME [epoch: 61.3 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25606932793819664		[learning rate: 0.0045898]
	Learning Rate: 0.00458981
	LOSS [training: 0.25606932793819664 | validation: 0.21954260986845858]
	TIME [epoch: 61.3 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25974530684867336		[learning rate: 0.0045736]
	Learning Rate: 0.00457358
	LOSS [training: 0.25974530684867336 | validation: 0.21249253089117634]
	TIME [epoch: 61.3 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2501855283043776		[learning rate: 0.0045574]
	Learning Rate: 0.00455741
	LOSS [training: 0.2501855283043776 | validation: 0.20744201789403965]
	TIME [epoch: 61.3 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2500812456570101		[learning rate: 0.0045413]
	Learning Rate: 0.00454129
	LOSS [training: 0.2500812456570101 | validation: 0.2145707878124436]
	TIME [epoch: 61.3 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25177599925438426		[learning rate: 0.0045252]
	Learning Rate: 0.00452523
	LOSS [training: 0.25177599925438426 | validation: 0.2095721729390716]
	TIME [epoch: 61.3 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2532921694113667		[learning rate: 0.0045092]
	Learning Rate: 0.00450923
	LOSS [training: 0.2532921694113667 | validation: 0.2114450683220425]
	TIME [epoch: 61.4 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25078758215987484		[learning rate: 0.0044933]
	Learning Rate: 0.00449329
	LOSS [training: 0.25078758215987484 | validation: 0.2111262918455044]
	TIME [epoch: 61.3 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2506334806226767		[learning rate: 0.0044774]
	Learning Rate: 0.0044774
	LOSS [training: 0.2506334806226767 | validation: 0.21300779888583032]
	TIME [epoch: 61.3 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2507409203697989		[learning rate: 0.0044616]
	Learning Rate: 0.00446156
	LOSS [training: 0.2507409203697989 | validation: 0.212669121944033]
	TIME [epoch: 61.3 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25150203242958336		[learning rate: 0.0044458]
	Learning Rate: 0.00444579
	LOSS [training: 0.25150203242958336 | validation: 0.23104055429201026]
	TIME [epoch: 61.3 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2610537782087188		[learning rate: 0.0044301]
	Learning Rate: 0.00443007
	LOSS [training: 0.2610537782087188 | validation: 0.21786652656929606]
	TIME [epoch: 61.3 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2515917777334095		[learning rate: 0.0044144]
	Learning Rate: 0.0044144
	LOSS [training: 0.2515917777334095 | validation: 0.2126837938084746]
	TIME [epoch: 61.3 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25949690983860263		[learning rate: 0.0043988]
	Learning Rate: 0.00439879
	LOSS [training: 0.25949690983860263 | validation: 0.2227956118404005]
	TIME [epoch: 61.3 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2604223667453552		[learning rate: 0.0043832]
	Learning Rate: 0.00438324
	LOSS [training: 0.2604223667453552 | validation: 0.20779069172077955]
	TIME [epoch: 61.3 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2481448226516421		[learning rate: 0.0043677]
	Learning Rate: 0.00436774
	LOSS [training: 0.2481448226516421 | validation: 0.2115847897915409]
	TIME [epoch: 61.3 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24617270361759033		[learning rate: 0.0043523]
	Learning Rate: 0.00435229
	LOSS [training: 0.24617270361759033 | validation: 0.2197420803487961]
	TIME [epoch: 61.3 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25410569521744586		[learning rate: 0.0043369]
	Learning Rate: 0.0043369
	LOSS [training: 0.25410569521744586 | validation: 0.21636999976727794]
	TIME [epoch: 61.3 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25546830581865587		[learning rate: 0.0043216]
	Learning Rate: 0.00432156
	LOSS [training: 0.25546830581865587 | validation: 0.20458962907897313]
	TIME [epoch: 61.3 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24546473948732406		[learning rate: 0.0043063]
	Learning Rate: 0.00430628
	LOSS [training: 0.24546473948732406 | validation: 0.21756351171513155]
	TIME [epoch: 61.3 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2487113959590623		[learning rate: 0.0042911]
	Learning Rate: 0.00429106
	LOSS [training: 0.2487113959590623 | validation: 0.2120481505581547]
	TIME [epoch: 61.3 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25513225163192993		[learning rate: 0.0042759]
	Learning Rate: 0.00427588
	LOSS [training: 0.25513225163192993 | validation: 0.20893035538352134]
	TIME [epoch: 61.3 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2565573427009737		[learning rate: 0.0042608]
	Learning Rate: 0.00426076
	LOSS [training: 0.2565573427009737 | validation: 0.21493817400559073]
	TIME [epoch: 61.3 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2520965771391296		[learning rate: 0.0042457]
	Learning Rate: 0.00424569
	LOSS [training: 0.2520965771391296 | validation: 0.21079452901536033]
	TIME [epoch: 61.4 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24584071055354106		[learning rate: 0.0042307]
	Learning Rate: 0.00423068
	LOSS [training: 0.24584071055354106 | validation: 0.21849508285369845]
	TIME [epoch: 61.4 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26177856304387553		[learning rate: 0.0042157]
	Learning Rate: 0.00421572
	LOSS [training: 0.26177856304387553 | validation: 0.21073736904342139]
	TIME [epoch: 61.3 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25674802201488894		[learning rate: 0.0042008]
	Learning Rate: 0.00420081
	LOSS [training: 0.25674802201488894 | validation: 0.21569878327136216]
	TIME [epoch: 61.3 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2502223895813807		[learning rate: 0.004186]
	Learning Rate: 0.00418596
	LOSS [training: 0.2502223895813807 | validation: 0.20511016634118837]
	TIME [epoch: 61.3 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25014928697689537		[learning rate: 0.0041712]
	Learning Rate: 0.00417116
	LOSS [training: 0.25014928697689537 | validation: 0.2104685930014516]
	TIME [epoch: 61.3 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25191420059382963		[learning rate: 0.0041564]
	Learning Rate: 0.00415641
	LOSS [training: 0.25191420059382963 | validation: 0.21188742963965607]
	TIME [epoch: 61.3 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2464563866544166		[learning rate: 0.0041417]
	Learning Rate: 0.00414171
	LOSS [training: 0.2464563866544166 | validation: 0.2127705315289631]
	TIME [epoch: 61.3 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2521321185227933		[learning rate: 0.0041271]
	Learning Rate: 0.00412706
	LOSS [training: 0.2521321185227933 | validation: 0.2111421496514056]
	TIME [epoch: 61.3 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2559915927464052		[learning rate: 0.0041125]
	Learning Rate: 0.00411247
	LOSS [training: 0.2559915927464052 | validation: 0.2156400642085501]
	TIME [epoch: 143 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2512547452699489		[learning rate: 0.0040979]
	Learning Rate: 0.00409793
	LOSS [training: 0.2512547452699489 | validation: 0.21170868783181646]
	TIME [epoch: 127 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25014080105554676		[learning rate: 0.0040834]
	Learning Rate: 0.00408344
	LOSS [training: 0.25014080105554676 | validation: 0.2120761488432053]
	TIME [epoch: 127 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2480645239483049		[learning rate: 0.004069]
	Learning Rate: 0.004069
	LOSS [training: 0.2480645239483049 | validation: 0.21067181377014182]
	TIME [epoch: 127 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24747871547258407		[learning rate: 0.0040546]
	Learning Rate: 0.00405461
	LOSS [training: 0.24747871547258407 | validation: 0.21454110040986157]
	TIME [epoch: 127 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24578330818984817		[learning rate: 0.0040403]
	Learning Rate: 0.00404027
	LOSS [training: 0.24578330818984817 | validation: 0.21162840900114607]
	TIME [epoch: 127 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24708505689753194		[learning rate: 0.004026]
	Learning Rate: 0.00402598
	LOSS [training: 0.24708505689753194 | validation: 0.21486976597204785]
	TIME [epoch: 127 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24798330095438836		[learning rate: 0.0040117]
	Learning Rate: 0.00401175
	LOSS [training: 0.24798330095438836 | validation: 0.20385466168284969]
	TIME [epoch: 127 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2512814723661964		[learning rate: 0.0039976]
	Learning Rate: 0.00399756
	LOSS [training: 0.2512814723661964 | validation: 0.20977849627586215]
	TIME [epoch: 127 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24393407334810288		[learning rate: 0.0039834]
	Learning Rate: 0.00398342
	LOSS [training: 0.24393407334810288 | validation: 0.21313290630866497]
	TIME [epoch: 127 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25095251893150566		[learning rate: 0.0039693]
	Learning Rate: 0.00396934
	LOSS [training: 0.25095251893150566 | validation: 0.20680024417973014]
	TIME [epoch: 127 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2535532295283039		[learning rate: 0.0039553]
	Learning Rate: 0.0039553
	LOSS [training: 0.2535532295283039 | validation: 0.22208312096751542]
	TIME [epoch: 127 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24510261339563563		[learning rate: 0.0039413]
	Learning Rate: 0.00394131
	LOSS [training: 0.24510261339563563 | validation: 0.208123162680771]
	TIME [epoch: 127 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24599763991627607		[learning rate: 0.0039274]
	Learning Rate: 0.00392738
	LOSS [training: 0.24599763991627607 | validation: 0.2147881010957043]
	TIME [epoch: 127 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2571189785485464		[learning rate: 0.0039135]
	Learning Rate: 0.00391349
	LOSS [training: 0.2571189785485464 | validation: 0.20338619272651387]
	TIME [epoch: 127 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2548886577264415		[learning rate: 0.0038997]
	Learning Rate: 0.00389965
	LOSS [training: 0.2548886577264415 | validation: 0.21144887840964727]
	TIME [epoch: 127 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24859738028688327		[learning rate: 0.0038859]
	Learning Rate: 0.00388586
	LOSS [training: 0.24859738028688327 | validation: 0.21044886067050111]
	TIME [epoch: 127 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2464267330500277		[learning rate: 0.0038721]
	Learning Rate: 0.00387212
	LOSS [training: 0.2464267330500277 | validation: 0.20485453105286208]
	TIME [epoch: 127 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2515244374133645		[learning rate: 0.0038584]
	Learning Rate: 0.00385843
	LOSS [training: 0.2515244374133645 | validation: 0.2069068975228665]
	TIME [epoch: 127 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2497405924830638		[learning rate: 0.0038448]
	Learning Rate: 0.00384478
	LOSS [training: 0.2497405924830638 | validation: 0.20813661345393716]
	TIME [epoch: 127 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24282470687549587		[learning rate: 0.0038312]
	Learning Rate: 0.00383119
	LOSS [training: 0.24282470687549587 | validation: 0.21501626468509732]
	TIME [epoch: 127 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24664055765246998		[learning rate: 0.0038176]
	Learning Rate: 0.00381764
	LOSS [training: 0.24664055765246998 | validation: 0.20755073501535723]
	TIME [epoch: 127 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24668365092017874		[learning rate: 0.0038041]
	Learning Rate: 0.00380414
	LOSS [training: 0.24668365092017874 | validation: 0.2088941179227605]
	TIME [epoch: 127 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2443305089989134		[learning rate: 0.0037907]
	Learning Rate: 0.00379069
	LOSS [training: 0.2443305089989134 | validation: 0.21474650002112838]
	TIME [epoch: 127 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25151105426827736		[learning rate: 0.0037773]
	Learning Rate: 0.00377728
	LOSS [training: 0.25151105426827736 | validation: 0.2056216932046581]
	TIME [epoch: 127 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24375085235088612		[learning rate: 0.0037639]
	Learning Rate: 0.00376393
	LOSS [training: 0.24375085235088612 | validation: 0.21163785089553996]
	TIME [epoch: 127 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2521875793230593		[learning rate: 0.0037506]
	Learning Rate: 0.00375062
	LOSS [training: 0.2521875793230593 | validation: 0.2107237819872298]
	TIME [epoch: 127 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24237049745874154		[learning rate: 0.0037374]
	Learning Rate: 0.00373735
	LOSS [training: 0.24237049745874154 | validation: 0.21074165151512694]
	TIME [epoch: 127 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25015561383135443		[learning rate: 0.0037241]
	Learning Rate: 0.00372414
	LOSS [training: 0.25015561383135443 | validation: 0.21135454284416247]
	TIME [epoch: 126 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.253330533300958		[learning rate: 0.003711]
	Learning Rate: 0.00371097
	LOSS [training: 0.253330533300958 | validation: 0.21057521143887709]
	TIME [epoch: 126 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24660121044414562		[learning rate: 0.0036978]
	Learning Rate: 0.00369785
	LOSS [training: 0.24660121044414562 | validation: 0.21571607070283103]
	TIME [epoch: 126 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2504892520639324		[learning rate: 0.0036848]
	Learning Rate: 0.00368477
	LOSS [training: 0.2504892520639324 | validation: 0.21077287911100204]
	TIME [epoch: 126 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2509940266682651		[learning rate: 0.0036717]
	Learning Rate: 0.00367174
	LOSS [training: 0.2509940266682651 | validation: 0.21586029733818038]
	TIME [epoch: 126 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2574549221424389		[learning rate: 0.0036588]
	Learning Rate: 0.00365875
	LOSS [training: 0.2574549221424389 | validation: 0.2103915767356904]
	TIME [epoch: 126 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24911011340829414		[learning rate: 0.0036458]
	Learning Rate: 0.00364582
	LOSS [training: 0.24911011340829414 | validation: 0.21018356929198984]
	TIME [epoch: 127 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25021491804641977		[learning rate: 0.0036329]
	Learning Rate: 0.00363292
	LOSS [training: 0.25021491804641977 | validation: 0.2137223083801593]
	TIME [epoch: 127 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2470060590966755		[learning rate: 0.0036201]
	Learning Rate: 0.00362008
	LOSS [training: 0.2470060590966755 | validation: 0.20642045074575172]
	TIME [epoch: 127 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2532213487923854		[learning rate: 0.0036073]
	Learning Rate: 0.00360728
	LOSS [training: 0.2532213487923854 | validation: 0.21587024274163272]
	TIME [epoch: 127 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2500300432196826		[learning rate: 0.0035945]
	Learning Rate: 0.00359452
	LOSS [training: 0.2500300432196826 | validation: 0.20685459259271471]
	TIME [epoch: 127 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2542159475605554		[learning rate: 0.0035818]
	Learning Rate: 0.00358181
	LOSS [training: 0.2542159475605554 | validation: 0.2123355905538183]
	TIME [epoch: 127 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24539170356138032		[learning rate: 0.0035691]
	Learning Rate: 0.00356914
	LOSS [training: 0.24539170356138032 | validation: 0.2128599543982342]
	TIME [epoch: 126 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2541176433237092		[learning rate: 0.0035565]
	Learning Rate: 0.00355652
	LOSS [training: 0.2541176433237092 | validation: 0.21159603032234092]
	TIME [epoch: 127 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24528153025469876		[learning rate: 0.0035439]
	Learning Rate: 0.00354395
	LOSS [training: 0.24528153025469876 | validation: 0.2073488162890181]
	TIME [epoch: 127 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2522542075913621		[learning rate: 0.0035314]
	Learning Rate: 0.00353141
	LOSS [training: 0.2522542075913621 | validation: 0.2106526774551997]
	TIME [epoch: 127 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24838240435770542		[learning rate: 0.0035189]
	Learning Rate: 0.00351893
	LOSS [training: 0.24838240435770542 | validation: 0.20444562961895518]
	TIME [epoch: 127 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2479997303316445		[learning rate: 0.0035065]
	Learning Rate: 0.00350648
	LOSS [training: 0.2479997303316445 | validation: 0.2078986027460558]
	TIME [epoch: 127 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2421710985179449		[learning rate: 0.0034941]
	Learning Rate: 0.00349408
	LOSS [training: 0.2421710985179449 | validation: 0.2104109942861455]
	TIME [epoch: 127 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2562637229259677		[learning rate: 0.0034817]
	Learning Rate: 0.00348173
	LOSS [training: 0.2562637229259677 | validation: 0.21832087780159237]
	TIME [epoch: 126 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24891322327456658		[learning rate: 0.0034694]
	Learning Rate: 0.00346942
	LOSS [training: 0.24891322327456658 | validation: 0.2068111707536612]
	TIME [epoch: 127 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24469100232726415		[learning rate: 0.0034571]
	Learning Rate: 0.00345715
	LOSS [training: 0.24469100232726415 | validation: 0.20897878119529428]
	TIME [epoch: 127 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2504985983475031		[learning rate: 0.0034449]
	Learning Rate: 0.00344492
	LOSS [training: 0.2504985983475031 | validation: 0.21116934407678617]
	TIME [epoch: 127 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24985875023156934		[learning rate: 0.0034327]
	Learning Rate: 0.00343274
	LOSS [training: 0.24985875023156934 | validation: 0.21344890106564351]
	TIME [epoch: 127 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2506544005225828		[learning rate: 0.0034206]
	Learning Rate: 0.0034206
	LOSS [training: 0.2506544005225828 | validation: 0.21127181255947294]
	TIME [epoch: 127 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24079095514516322		[learning rate: 0.0034085]
	Learning Rate: 0.00340851
	LOSS [training: 0.24079095514516322 | validation: 0.20808232678611255]
	TIME [epoch: 127 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2489853584904823		[learning rate: 0.0033965]
	Learning Rate: 0.00339645
	LOSS [training: 0.2489853584904823 | validation: 0.21286126270694336]
	TIME [epoch: 127 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2428120796532455		[learning rate: 0.0033844]
	Learning Rate: 0.00338444
	LOSS [training: 0.2428120796532455 | validation: 0.20727917875180038]
	TIME [epoch: 127 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24683353953085288		[learning rate: 0.0033725]
	Learning Rate: 0.00337247
	LOSS [training: 0.24683353953085288 | validation: 0.21338530103284245]
	TIME [epoch: 127 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25005930568727053		[learning rate: 0.0033605]
	Learning Rate: 0.00336055
	LOSS [training: 0.25005930568727053 | validation: 0.21829352043898456]
	TIME [epoch: 126 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24561030750698773		[learning rate: 0.0033487]
	Learning Rate: 0.00334867
	LOSS [training: 0.24561030750698773 | validation: 0.20795104215247812]
	TIME [epoch: 127 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24905855089337345		[learning rate: 0.0033368]
	Learning Rate: 0.00333682
	LOSS [training: 0.24905855089337345 | validation: 0.2103814899611598]
	TIME [epoch: 127 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2442231366747405		[learning rate: 0.003325]
	Learning Rate: 0.00332502
	LOSS [training: 0.2442231366747405 | validation: 0.20953089253416896]
	TIME [epoch: 127 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24363018575008022		[learning rate: 0.0033133]
	Learning Rate: 0.00331327
	LOSS [training: 0.24363018575008022 | validation: 0.21184508587712134]
	TIME [epoch: 127 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2607562055874894		[learning rate: 0.0033016]
	Learning Rate: 0.00330155
	LOSS [training: 0.2607562055874894 | validation: 0.2210527237676117]
	TIME [epoch: 127 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25548559496318307		[learning rate: 0.0032899]
	Learning Rate: 0.00328988
	LOSS [training: 0.25548559496318307 | validation: 0.21567008125938916]
	TIME [epoch: 127 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24904580865997383		[learning rate: 0.0032782]
	Learning Rate: 0.00327824
	LOSS [training: 0.24904580865997383 | validation: 0.2120674353379009]
	TIME [epoch: 127 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24968404753015463		[learning rate: 0.0032666]
	Learning Rate: 0.00326665
	LOSS [training: 0.24968404753015463 | validation: 0.21527418362255157]
	TIME [epoch: 127 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23883442201788643		[learning rate: 0.0032551]
	Learning Rate: 0.0032551
	LOSS [training: 0.23883442201788643 | validation: 0.2116742544371088]
	TIME [epoch: 127 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2493838025249587		[learning rate: 0.0032436]
	Learning Rate: 0.00324359
	LOSS [training: 0.2493838025249587 | validation: 0.21817999757129108]
	TIME [epoch: 127 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24796054961255506		[learning rate: 0.0032321]
	Learning Rate: 0.00323212
	LOSS [training: 0.24796054961255506 | validation: 0.2146458740917249]
	TIME [epoch: 127 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2510745126193416		[learning rate: 0.0032207]
	Learning Rate: 0.00322069
	LOSS [training: 0.2510745126193416 | validation: 0.20726683505373728]
	TIME [epoch: 127 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2474062397582196		[learning rate: 0.0032093]
	Learning Rate: 0.0032093
	LOSS [training: 0.2474062397582196 | validation: 0.20551979548734378]
	TIME [epoch: 127 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2491638211559154		[learning rate: 0.003198]
	Learning Rate: 0.00319795
	LOSS [training: 0.2491638211559154 | validation: 0.20896021896573322]
	TIME [epoch: 127 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2437982610624985		[learning rate: 0.0031866]
	Learning Rate: 0.00318664
	LOSS [training: 0.2437982610624985 | validation: 0.20658475281619224]
	TIME [epoch: 127 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25014746214689565		[learning rate: 0.0031754]
	Learning Rate: 0.00317537
	LOSS [training: 0.25014746214689565 | validation: 0.20856593557909373]
	TIME [epoch: 127 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2513035157510597		[learning rate: 0.0031641]
	Learning Rate: 0.00316415
	LOSS [training: 0.2513035157510597 | validation: 0.2079169023094416]
	TIME [epoch: 127 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24661174386440068		[learning rate: 0.003153]
	Learning Rate: 0.00315296
	LOSS [training: 0.24661174386440068 | validation: 0.21166233388436018]
	TIME [epoch: 127 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2500475650898594		[learning rate: 0.0031418]
	Learning Rate: 0.00314181
	LOSS [training: 0.2500475650898594 | validation: 0.21130618895468595]
	TIME [epoch: 127 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2523158097624952		[learning rate: 0.0031307]
	Learning Rate: 0.0031307
	LOSS [training: 0.2523158097624952 | validation: 0.2150305973714421]
	TIME [epoch: 127 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24845726007205657		[learning rate: 0.0031196]
	Learning Rate: 0.00311963
	LOSS [training: 0.24845726007205657 | validation: 0.2045469496622751]
	TIME [epoch: 127 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2433517199233239		[learning rate: 0.0031086]
	Learning Rate: 0.00310859
	LOSS [training: 0.2433517199233239 | validation: 0.20753858951683818]
	TIME [epoch: 127 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24529039411403017		[learning rate: 0.0030976]
	Learning Rate: 0.0030976
	LOSS [training: 0.24529039411403017 | validation: 0.20682826192017623]
	TIME [epoch: 127 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24895921486501646		[learning rate: 0.0030866]
	Learning Rate: 0.00308665
	LOSS [training: 0.24895921486501646 | validation: 0.20407080998218677]
	TIME [epoch: 127 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24611185072618894		[learning rate: 0.0030757]
	Learning Rate: 0.00307573
	LOSS [training: 0.24611185072618894 | validation: 0.20823087052189398]
	TIME [epoch: 127 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24636070716836364		[learning rate: 0.0030649]
	Learning Rate: 0.00306486
	LOSS [training: 0.24636070716836364 | validation: 0.2086533009845854]
	TIME [epoch: 127 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25077991415920553		[learning rate: 0.003054]
	Learning Rate: 0.00305402
	LOSS [training: 0.25077991415920553 | validation: 0.21516158531258528]
	TIME [epoch: 127 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24942112400813377		[learning rate: 0.0030432]
	Learning Rate: 0.00304322
	LOSS [training: 0.24942112400813377 | validation: 0.207970907104608]
	TIME [epoch: 126 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24347194199849861		[learning rate: 0.0030325]
	Learning Rate: 0.00303246
	LOSS [training: 0.24347194199849861 | validation: 0.20665552699140877]
	TIME [epoch: 126 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24685292529358038		[learning rate: 0.0030217]
	Learning Rate: 0.00302174
	LOSS [training: 0.24685292529358038 | validation: 0.20632550939110533]
	TIME [epoch: 126 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24510485169568855		[learning rate: 0.003011]
	Learning Rate: 0.00301105
	LOSS [training: 0.24510485169568855 | validation: 0.20583334948754833]
	TIME [epoch: 126 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24636466709039975		[learning rate: 0.0030004]
	Learning Rate: 0.0030004
	LOSS [training: 0.24636466709039975 | validation: 0.21251647640467225]
	TIME [epoch: 127 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2497533727699189		[learning rate: 0.0029898]
	Learning Rate: 0.00298979
	LOSS [training: 0.2497533727699189 | validation: 0.21009256061005313]
	TIME [epoch: 127 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24811647323529465		[learning rate: 0.0029792]
	Learning Rate: 0.00297922
	LOSS [training: 0.24811647323529465 | validation: 0.21321860388598807]
	TIME [epoch: 127 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24213738823921857		[learning rate: 0.0029687]
	Learning Rate: 0.00296869
	LOSS [training: 0.24213738823921857 | validation: 0.2151382231755091]
	TIME [epoch: 126 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24997578740510837		[learning rate: 0.0029582]
	Learning Rate: 0.00295819
	LOSS [training: 0.24997578740510837 | validation: 0.20946363376792637]
	TIME [epoch: 127 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24156924749934303		[learning rate: 0.0029477]
	Learning Rate: 0.00294773
	LOSS [training: 0.24156924749934303 | validation: 0.20928487354279518]
	TIME [epoch: 127 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24848437344448882		[learning rate: 0.0029373]
	Learning Rate: 0.0029373
	LOSS [training: 0.24848437344448882 | validation: 0.20966546834128094]
	TIME [epoch: 127 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24394478315838472		[learning rate: 0.0029269]
	Learning Rate: 0.00292692
	LOSS [training: 0.24394478315838472 | validation: 0.20966778010522988]
	TIME [epoch: 127 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2475087096729792		[learning rate: 0.0029166]
	Learning Rate: 0.00291657
	LOSS [training: 0.2475087096729792 | validation: 0.20725792593389766]
	TIME [epoch: 127 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2469842491051247		[learning rate: 0.0029063]
	Learning Rate: 0.00290625
	LOSS [training: 0.2469842491051247 | validation: 0.20548122413473582]
	TIME [epoch: 126 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2366059138500709		[learning rate: 0.002896]
	Learning Rate: 0.00289598
	LOSS [training: 0.2366059138500709 | validation: 0.2091499390020551]
	TIME [epoch: 127 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24899072434649686		[learning rate: 0.0028857]
	Learning Rate: 0.00288573
	LOSS [training: 0.24899072434649686 | validation: 0.20988298189713958]
	TIME [epoch: 126 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24212398051368048		[learning rate: 0.0028755]
	Learning Rate: 0.00287553
	LOSS [training: 0.24212398051368048 | validation: 0.20472236325328036]
	TIME [epoch: 126 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2391939562281948		[learning rate: 0.0028654]
	Learning Rate: 0.00286536
	LOSS [training: 0.2391939562281948 | validation: 0.22354494876980144]
	TIME [epoch: 126 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25214848224050995		[learning rate: 0.0028552]
	Learning Rate: 0.00285523
	LOSS [training: 0.25214848224050995 | validation: 0.21392486461203952]
	TIME [epoch: 126 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2478194260112788		[learning rate: 0.0028451]
	Learning Rate: 0.00284513
	LOSS [training: 0.2478194260112788 | validation: 0.21465589771444363]
	TIME [epoch: 126 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2410225017649069		[learning rate: 0.0028351]
	Learning Rate: 0.00283507
	LOSS [training: 0.2410225017649069 | validation: 0.21095746318259687]
	TIME [epoch: 126 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.251622953077709		[learning rate: 0.002825]
	Learning Rate: 0.00282505
	LOSS [training: 0.251622953077709 | validation: 0.20820672992793554]
	TIME [epoch: 126 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24537546746128866		[learning rate: 0.0028151]
	Learning Rate: 0.00281506
	LOSS [training: 0.24537546746128866 | validation: 0.21623182828170978]
	TIME [epoch: 126 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24744272799543243		[learning rate: 0.0028051]
	Learning Rate: 0.0028051
	LOSS [training: 0.24744272799543243 | validation: 0.21246646025849217]
	TIME [epoch: 126 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24834207602465086		[learning rate: 0.0027952]
	Learning Rate: 0.00279518
	LOSS [training: 0.24834207602465086 | validation: 0.21093163220358063]
	TIME [epoch: 126 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24642925732178722		[learning rate: 0.0027853]
	Learning Rate: 0.0027853
	LOSS [training: 0.24642925732178722 | validation: 0.21290610643031274]
	TIME [epoch: 126 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24458101819842973		[learning rate: 0.0027754]
	Learning Rate: 0.00277545
	LOSS [training: 0.24458101819842973 | validation: 0.2093518987900766]
	TIME [epoch: 126 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24531386802435193		[learning rate: 0.0027656]
	Learning Rate: 0.00276564
	LOSS [training: 0.24531386802435193 | validation: 0.20918563467197276]
	TIME [epoch: 126 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24876358516581995		[learning rate: 0.0027559]
	Learning Rate: 0.00275586
	LOSS [training: 0.24876358516581995 | validation: 0.20898045509213384]
	TIME [epoch: 126 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24417638636997838		[learning rate: 0.0027461]
	Learning Rate: 0.00274611
	LOSS [training: 0.24417638636997838 | validation: 0.20412873801815032]
	TIME [epoch: 126 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24638205728360904		[learning rate: 0.0027364]
	Learning Rate: 0.0027364
	LOSS [training: 0.24638205728360904 | validation: 0.20445993849843896]
	TIME [epoch: 126 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24388908550234178		[learning rate: 0.0027267]
	Learning Rate: 0.00272672
	LOSS [training: 0.24388908550234178 | validation: 0.209420639346486]
	TIME [epoch: 127 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2441266979873915		[learning rate: 0.0027171]
	Learning Rate: 0.00271708
	LOSS [training: 0.2441266979873915 | validation: 0.20924290074034207]
	TIME [epoch: 127 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25240858346449985		[learning rate: 0.0027075]
	Learning Rate: 0.00270747
	LOSS [training: 0.25240858346449985 | validation: 0.21549735359550354]
	TIME [epoch: 127 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24626374442782553		[learning rate: 0.0026979]
	Learning Rate: 0.0026979
	LOSS [training: 0.24626374442782553 | validation: 0.21067571231990864]
	TIME [epoch: 127 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24207518694876198		[learning rate: 0.0026884]
	Learning Rate: 0.00268836
	LOSS [training: 0.24207518694876198 | validation: 0.21073771447864537]
	TIME [epoch: 127 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24789106831619137		[learning rate: 0.0026789]
	Learning Rate: 0.00267885
	LOSS [training: 0.24789106831619137 | validation: 0.2046883862520359]
	TIME [epoch: 127 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2433230621989203		[learning rate: 0.0026694]
	Learning Rate: 0.00266938
	LOSS [training: 0.2433230621989203 | validation: 0.20602014998381332]
	TIME [epoch: 127 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2495511633863461		[learning rate: 0.0026599]
	Learning Rate: 0.00265994
	LOSS [training: 0.2495511633863461 | validation: 0.21399891893129622]
	TIME [epoch: 127 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2422565552682974		[learning rate: 0.0026505]
	Learning Rate: 0.00265053
	LOSS [training: 0.2422565552682974 | validation: 0.2134801798331889]
	TIME [epoch: 127 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24820433878931691		[learning rate: 0.0026412]
	Learning Rate: 0.00264116
	LOSS [training: 0.24820433878931691 | validation: 0.2034925028866077]
	TIME [epoch: 127 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24687062101906831		[learning rate: 0.0026318]
	Learning Rate: 0.00263182
	LOSS [training: 0.24687062101906831 | validation: 0.21187471018846615]
	TIME [epoch: 127 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24802385514559575		[learning rate: 0.0026225]
	Learning Rate: 0.00262251
	LOSS [training: 0.24802385514559575 | validation: 0.20476277544804938]
	TIME [epoch: 127 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2476450177355799		[learning rate: 0.0026132]
	Learning Rate: 0.00261324
	LOSS [training: 0.2476450177355799 | validation: 0.21466348513451128]
	TIME [epoch: 127 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24986541503670523		[learning rate: 0.002604]
	Learning Rate: 0.002604
	LOSS [training: 0.24986541503670523 | validation: 0.205022722183954]
	TIME [epoch: 127 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24376889303793803		[learning rate: 0.0025948]
	Learning Rate: 0.00259479
	LOSS [training: 0.24376889303793803 | validation: 0.20758916240790887]
	TIME [epoch: 126 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24999601251150175		[learning rate: 0.0025856]
	Learning Rate: 0.00258562
	LOSS [training: 0.24999601251150175 | validation: 0.2082509259645783]
	TIME [epoch: 127 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24149749270507306		[learning rate: 0.0025765]
	Learning Rate: 0.00257647
	LOSS [training: 0.24149749270507306 | validation: 0.20661540344444126]
	TIME [epoch: 126 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2394278802257289		[learning rate: 0.0025674]
	Learning Rate: 0.00256736
	LOSS [training: 0.2394278802257289 | validation: 0.20935839706812578]
	TIME [epoch: 127 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24228234116985292		[learning rate: 0.0025583]
	Learning Rate: 0.00255828
	LOSS [training: 0.24228234116985292 | validation: 0.20757306860040114]
	TIME [epoch: 127 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24803987413073772		[learning rate: 0.0025492]
	Learning Rate: 0.00254924
	LOSS [training: 0.24803987413073772 | validation: 0.2111670795478317]
	TIME [epoch: 127 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2469690686740232		[learning rate: 0.0025402]
	Learning Rate: 0.00254022
	LOSS [training: 0.2469690686740232 | validation: 0.21342656711826655]
	TIME [epoch: 127 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24312642853446917		[learning rate: 0.0025312]
	Learning Rate: 0.00253124
	LOSS [training: 0.24312642853446917 | validation: 0.20851404446920382]
	TIME [epoch: 127 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24089963891262242		[learning rate: 0.0025223]
	Learning Rate: 0.00252229
	LOSS [training: 0.24089963891262242 | validation: 0.2045775063893364]
	TIME [epoch: 126 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2435593794206287		[learning rate: 0.0025134]
	Learning Rate: 0.00251337
	LOSS [training: 0.2435593794206287 | validation: 0.20391797903488493]
	TIME [epoch: 127 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v13b_20240716_161438/states/model_facs_v3_dec1b_2dpca_v13b_440.pth
Halted early. No improvement in validation loss for 200 epochs.
Finished training in 27876.646 seconds.
