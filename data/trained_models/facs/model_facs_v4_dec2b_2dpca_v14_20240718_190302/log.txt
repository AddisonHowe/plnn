Args:
Namespace(name='model_facs_v4_dec2b_2dpca_v14', outdir='out/model_training/model_facs_v4_dec2b_2dpca_v14', training_data='data/training_data/facs_v4/pca/dec2_fitonsubset/transition2_subset_ce_pn_m_pc12/training', validation_data='data/training_data/facs_v4/pca/dec2_fitonsubset/transition2_subset_ce_pn_m_pc12/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=10, batch_size=50, patience=200, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, quadratic_a=1.0, quadratic_b=1.0, ndims=2, nparams=2, nsigs=2, ncells=200, ncells_sample=200, model_do_sample=False, dt=0.005, dt_schedule='stepped', dt_schedule_bounds=[50, 500, 1000], dt_schedule_scales=[0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', kernel='multiscale', bw_range=[0.2, 0.5, 0.9, 1.1, 1.3, 1.5, 2.0], optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 3830383430

Training model...

Saving initial model state to: out/model_training/model_facs_v4_dec2b_2dpca_v14_20240718_190302/states/model_facs_v4_dec2b_2dpca_v14_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8463213313339479		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8463213313339479 | validation: 0.8964553733110212]
	TIME [epoch: 26.4 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v14_20240718_190302/states/model_facs_v4_dec2b_2dpca_v14_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7156871942949655		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7156871942949655 | validation: 0.7935800542836329]
	TIME [epoch: 3.87 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v14_20240718_190302/states/model_facs_v4_dec2b_2dpca_v14_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5505761894678964		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5505761894678964 | validation: 0.7969534208752502]
	TIME [epoch: 3.86 sec]
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5298314447596504		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5298314447596504 | validation: 0.733603422318702]
	TIME [epoch: 3.85 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v14_20240718_190302/states/model_facs_v4_dec2b_2dpca_v14_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6265216555943356		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6265216555943356 | validation: 0.6992788982759108]
	TIME [epoch: 3.87 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v14_20240718_190302/states/model_facs_v4_dec2b_2dpca_v14_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4695330481899118		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4695330481899118 | validation: 0.6789139381769403]
	TIME [epoch: 3.86 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v14_20240718_190302/states/model_facs_v4_dec2b_2dpca_v14_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49031362798814826		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.49031362798814826 | validation: 0.6431228272537823]
	TIME [epoch: 3.85 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v14_20240718_190302/states/model_facs_v4_dec2b_2dpca_v14_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4496616471434066		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4496616471434066 | validation: 0.6636837081612563]
	TIME [epoch: 3.85 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4997633319949988		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4997633319949988 | validation: 0.6276610612710714]
	TIME [epoch: 3.85 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v14_20240718_190302/states/model_facs_v4_dec2b_2dpca_v14_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4108115683472857		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4108115683472857 | validation: 0.6588946580694434]
	TIME [epoch: 3.86 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4573699189764976		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4573699189764976 | validation: 0.6384753159451811]
	TIME [epoch: 3.85 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39363425909503047		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.39363425909503047 | validation: 0.6716841244150716]
	TIME [epoch: 3.85 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44935244351910425		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.44935244351910425 | validation: 0.6781869255173045]
	TIME [epoch: 3.85 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4689108645030118		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4689108645030118 | validation: 0.6588323742400602]
	TIME [epoch: 3.85 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48460309764947795		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.48460309764947795 | validation: 0.6611102294481468]
	TIME [epoch: 3.85 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4194707272632839		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4194707272632839 | validation: 0.6169401663528439]
	TIME [epoch: 3.86 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v14_20240718_190302/states/model_facs_v4_dec2b_2dpca_v14_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4291524148979237		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4291524148979237 | validation: 0.5839343334740635]
	TIME [epoch: 3.86 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v14_20240718_190302/states/model_facs_v4_dec2b_2dpca_v14_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39763348777169294		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.39763348777169294 | validation: 0.5479962427007422]
	TIME [epoch: 3.85 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v14_20240718_190302/states/model_facs_v4_dec2b_2dpca_v14_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40424440351881796		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.40424440351881796 | validation: 0.5767153802497]
	TIME [epoch: 3.86 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.410030003090153		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.410030003090153 | validation: 0.5754227813056976]
	TIME [epoch: 3.86 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3924214757793034		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3924214757793034 | validation: 0.5472894088391024]
	TIME [epoch: 3.86 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v14_20240718_190302/states/model_facs_v4_dec2b_2dpca_v14_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3331547390997787		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3331547390997787 | validation: 0.5265663568024213]
	TIME [epoch: 3.86 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v14_20240718_190302/states/model_facs_v4_dec2b_2dpca_v14_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34834521031920646		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.34834521031920646 | validation: 0.6368676018092362]
	TIME [epoch: 3.86 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40730771203356564		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.40730771203356564 | validation: 0.47171964011645096]
	TIME [epoch: 3.86 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v14_20240718_190302/states/model_facs_v4_dec2b_2dpca_v14_24.pth
	Model improved!!!
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33945824455780915		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.33945824455780915 | validation: 0.5377542775428923]
	TIME [epoch: 3.86 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3108343199931672		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3108343199931672 | validation: 0.6534265398920239]
	TIME [epoch: 3.85 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3908370162098552		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3908370162098552 | validation: 0.45904042349906493]
	TIME [epoch: 3.86 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v14_20240718_190302/states/model_facs_v4_dec2b_2dpca_v14_27.pth
	Model improved!!!
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2869965276603353		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2869965276603353 | validation: 0.3966636591478693]
	TIME [epoch: 3.85 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v14_20240718_190302/states/model_facs_v4_dec2b_2dpca_v14_28.pth
	Model improved!!!
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2590595233874774		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2590595233874774 | validation: 0.45756160265751983]
	TIME [epoch: 3.86 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2512937784310542		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2512937784310542 | validation: 0.4021247157245717]
	TIME [epoch: 3.85 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24084029401814888		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24084029401814888 | validation: 0.44329238305192237]
	TIME [epoch: 3.85 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30354544197336025		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.30354544197336025 | validation: 0.4400453185606715]
	TIME [epoch: 3.85 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25777122537578084		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.25777122537578084 | validation: 0.3884936631847329]
	TIME [epoch: 3.85 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v14_20240718_190302/states/model_facs_v4_dec2b_2dpca_v14_33.pth
	Model improved!!!
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26822584975047853		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.26822584975047853 | validation: 0.38598935412700414]
	TIME [epoch: 3.85 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v14_20240718_190302/states/model_facs_v4_dec2b_2dpca_v14_34.pth
	Model improved!!!
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23136957603605612		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23136957603605612 | validation: 0.38368948431769945]
	TIME [epoch: 3.86 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v14_20240718_190302/states/model_facs_v4_dec2b_2dpca_v14_35.pth
	Model improved!!!
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27840007514224874		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.27840007514224874 | validation: 0.38361464158586217]
	TIME [epoch: 3.86 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v14_20240718_190302/states/model_facs_v4_dec2b_2dpca_v14_36.pth
	Model improved!!!
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21589491926968182		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.21589491926968182 | validation: 0.3713968586682648]
	TIME [epoch: 3.86 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v14_20240718_190302/states/model_facs_v4_dec2b_2dpca_v14_37.pth
	Model improved!!!
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2503532112973216		[learning rate: 0.0099882]
	Learning Rate: 0.0099882
	LOSS [training: 0.2503532112973216 | validation: 0.4149357556149515]
	TIME [epoch: 3.86 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20448270402284263		[learning rate: 0.0099411]
	Learning Rate: 0.00994113
	LOSS [training: 0.20448270402284263 | validation: 0.35983757902863206]
	TIME [epoch: 3.86 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v14_20240718_190302/states/model_facs_v4_dec2b_2dpca_v14_39.pth
	Model improved!!!
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3138813498690961		[learning rate: 0.0098943]
	Learning Rate: 0.00989429
	LOSS [training: 0.3138813498690961 | validation: 0.3966074757663422]
	TIME [epoch: 3.86 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.274991276820285		[learning rate: 0.0098477]
	Learning Rate: 0.00984767
	LOSS [training: 0.274991276820285 | validation: 0.4750291295829598]
	TIME [epoch: 3.85 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22209994305952785		[learning rate: 0.0098013]
	Learning Rate: 0.00980126
	LOSS [training: 0.22209994305952785 | validation: 0.40276555506884126]
	TIME [epoch: 3.85 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26505566489279736		[learning rate: 0.0097551]
	Learning Rate: 0.00975508
	LOSS [training: 0.26505566489279736 | validation: 0.5833462881451555]
	TIME [epoch: 3.85 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29239877761421695		[learning rate: 0.0097091]
	Learning Rate: 0.00970911
	LOSS [training: 0.29239877761421695 | validation: 0.4480481992134041]
	TIME [epoch: 3.86 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25457191290734416		[learning rate: 0.0096634]
	Learning Rate: 0.00966336
	LOSS [training: 0.25457191290734416 | validation: 0.47172324892558604]
	TIME [epoch: 3.85 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.250018227982028		[learning rate: 0.0096178]
	Learning Rate: 0.00961783
	LOSS [training: 0.250018227982028 | validation: 0.3861565154916257]
	TIME [epoch: 3.85 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22427880137820594		[learning rate: 0.0095725]
	Learning Rate: 0.00957251
	LOSS [training: 0.22427880137820594 | validation: 0.36278802693250584]
	TIME [epoch: 3.85 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18664050264874515		[learning rate: 0.0095274]
	Learning Rate: 0.0095274
	LOSS [training: 0.18664050264874515 | validation: 0.4215633094770993]
	TIME [epoch: 3.85 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21554646831400365		[learning rate: 0.0094825]
	Learning Rate: 0.0094825
	LOSS [training: 0.21554646831400365 | validation: 0.37045326387189487]
	TIME [epoch: 3.86 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27219029468899536		[learning rate: 0.0094378]
	Learning Rate: 0.00943782
	LOSS [training: 0.27219029468899536 | validation: 0.4042978249530348]
	TIME [epoch: 3.85 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2680861911084659		[learning rate: 0.0093933]
	Learning Rate: 0.00939335
	LOSS [training: 0.2680861911084659 | validation: 0.42122931198277014]
	TIME [epoch: 28.2 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24658899189542355		[learning rate: 0.0093491]
	Learning Rate: 0.00934909
	LOSS [training: 0.24658899189542355 | validation: 0.444704890570686]
	TIME [epoch: 7.43 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.220179115061872		[learning rate: 0.009305]
	Learning Rate: 0.00930503
	LOSS [training: 0.220179115061872 | validation: 0.3955827304506561]
	TIME [epoch: 7.42 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24172578552777213		[learning rate: 0.0092612]
	Learning Rate: 0.00926119
	LOSS [training: 0.24172578552777213 | validation: 0.43767440933579904]
	TIME [epoch: 7.42 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2820062395282993		[learning rate: 0.0092175]
	Learning Rate: 0.00921755
	LOSS [training: 0.2820062395282993 | validation: 0.5873381127843877]
	TIME [epoch: 7.42 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27904691592182235		[learning rate: 0.0091741]
	Learning Rate: 0.00917411
	LOSS [training: 0.27904691592182235 | validation: 0.3859788578400937]
	TIME [epoch: 7.43 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18033886588663786		[learning rate: 0.0091309]
	Learning Rate: 0.00913088
	LOSS [training: 0.18033886588663786 | validation: 0.4466601685524027]
	TIME [epoch: 7.41 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2599251204647961		[learning rate: 0.0090879]
	Learning Rate: 0.00908786
	LOSS [training: 0.2599251204647961 | validation: 0.3392669470107995]
	TIME [epoch: 7.41 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v14_20240718_190302/states/model_facs_v4_dec2b_2dpca_v14_58.pth
	Model improved!!!
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1968837313817452		[learning rate: 0.009045]
	Learning Rate: 0.00904503
	LOSS [training: 0.1968837313817452 | validation: 0.47342144905001404]
	TIME [epoch: 7.41 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27541672091559016		[learning rate: 0.0090024]
	Learning Rate: 0.00900241
	LOSS [training: 0.27541672091559016 | validation: 0.3416347899245043]
	TIME [epoch: 7.42 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2015782206825712		[learning rate: 0.00896]
	Learning Rate: 0.00895999
	LOSS [training: 0.2015782206825712 | validation: 0.4191383927211076]
	TIME [epoch: 7.41 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1740863621705117		[learning rate: 0.0089178]
	Learning Rate: 0.00891777
	LOSS [training: 0.1740863621705117 | validation: 0.3475748120674488]
	TIME [epoch: 7.42 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2006334579420011		[learning rate: 0.0088758]
	Learning Rate: 0.00887575
	LOSS [training: 0.2006334579420011 | validation: 0.3753244958480075]
	TIME [epoch: 7.41 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16963191046107		[learning rate: 0.0088339]
	Learning Rate: 0.00883393
	LOSS [training: 0.16963191046107 | validation: 0.48157128016780804]
	TIME [epoch: 7.41 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24357334550736537		[learning rate: 0.0087923]
	Learning Rate: 0.0087923
	LOSS [training: 0.24357334550736537 | validation: 0.45787588157149706]
	TIME [epoch: 7.41 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19318036277132541		[learning rate: 0.0087509]
	Learning Rate: 0.00875087
	LOSS [training: 0.19318036277132541 | validation: 0.41740304243617776]
	TIME [epoch: 7.41 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2074454331579899		[learning rate: 0.0087096]
	Learning Rate: 0.00870964
	LOSS [training: 0.2074454331579899 | validation: 0.3430427960098045]
	TIME [epoch: 7.41 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15130348817066108		[learning rate: 0.0086686]
	Learning Rate: 0.00866859
	LOSS [training: 0.15130348817066108 | validation: 0.4494228835107822]
	TIME [epoch: 7.41 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21296416497460616		[learning rate: 0.0086277]
	Learning Rate: 0.00862775
	LOSS [training: 0.21296416497460616 | validation: 0.4180370214063597]
	TIME [epoch: 7.42 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1850398794591714		[learning rate: 0.0085871]
	Learning Rate: 0.00858709
	LOSS [training: 0.1850398794591714 | validation: 0.42029961950934824]
	TIME [epoch: 7.42 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20337576276834723		[learning rate: 0.0085466]
	Learning Rate: 0.00854663
	LOSS [training: 0.20337576276834723 | validation: 0.34872576576033887]
	TIME [epoch: 7.42 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21370899696498163		[learning rate: 0.0085064]
	Learning Rate: 0.00850636
	LOSS [training: 0.21370899696498163 | validation: 0.5148171146215731]
	TIME [epoch: 7.42 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24319561043595284		[learning rate: 0.0084663]
	Learning Rate: 0.00846627
	LOSS [training: 0.24319561043595284 | validation: 0.3280607259809891]
	TIME [epoch: 7.42 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v14_20240718_190302/states/model_facs_v4_dec2b_2dpca_v14_73.pth
	Model improved!!!
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17278704733923272		[learning rate: 0.0084264]
	Learning Rate: 0.00842638
	LOSS [training: 0.17278704733923272 | validation: 0.30458726802777303]
	TIME [epoch: 7.47 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v14_20240718_190302/states/model_facs_v4_dec2b_2dpca_v14_74.pth
	Model improved!!!
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15741080554430578		[learning rate: 0.0083867]
	Learning Rate: 0.00838667
	LOSS [training: 0.15741080554430578 | validation: 0.354621548913179]
	TIME [epoch: 7.43 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16271206786671824		[learning rate: 0.0083472]
	Learning Rate: 0.00834715
	LOSS [training: 0.16271206786671824 | validation: 0.49533862259036693]
	TIME [epoch: 7.42 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2727692664232748		[learning rate: 0.0083078]
	Learning Rate: 0.00830782
	LOSS [training: 0.2727692664232748 | validation: 0.3623068385252607]
	TIME [epoch: 7.41 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2148731093602166		[learning rate: 0.0082687]
	Learning Rate: 0.00826867
	LOSS [training: 0.2148731093602166 | validation: 0.3913495518093178]
	TIME [epoch: 7.42 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19032653597081098		[learning rate: 0.0082297]
	Learning Rate: 0.00822971
	LOSS [training: 0.19032653597081098 | validation: 0.4125912311349303]
	TIME [epoch: 7.41 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2164819972185196		[learning rate: 0.0081909]
	Learning Rate: 0.00819093
	LOSS [training: 0.2164819972185196 | validation: 0.41617216950870456]
	TIME [epoch: 7.41 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21947903325451915		[learning rate: 0.0081523]
	Learning Rate: 0.00815233
	LOSS [training: 0.21947903325451915 | validation: 0.3925028809071703]
	TIME [epoch: 7.42 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19264703116980625		[learning rate: 0.0081139]
	Learning Rate: 0.00811392
	LOSS [training: 0.19264703116980625 | validation: 0.35324395492739835]
	TIME [epoch: 7.42 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22038393787698118		[learning rate: 0.0080757]
	Learning Rate: 0.00807569
	LOSS [training: 0.22038393787698118 | validation: 0.3204008586959079]
	TIME [epoch: 7.42 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15945409021699067		[learning rate: 0.0080376]
	Learning Rate: 0.00803763
	LOSS [training: 0.15945409021699067 | validation: 0.3744148524533847]
	TIME [epoch: 7.42 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20911147233976013		[learning rate: 0.0079998]
	Learning Rate: 0.00799976
	LOSS [training: 0.20911147233976013 | validation: 0.5074032496811254]
	TIME [epoch: 7.42 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2266573774144296		[learning rate: 0.0079621]
	Learning Rate: 0.00796206
	LOSS [training: 0.2266573774144296 | validation: 0.35270890189255405]
	TIME [epoch: 7.41 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23235232238361675		[learning rate: 0.0079245]
	Learning Rate: 0.00792455
	LOSS [training: 0.23235232238361675 | validation: 0.3502075289854971]
	TIME [epoch: 7.41 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15212865647885374		[learning rate: 0.0078872]
	Learning Rate: 0.0078872
	LOSS [training: 0.15212865647885374 | validation: 0.3431116919244878]
	TIME [epoch: 7.42 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17090036951069648		[learning rate: 0.00785]
	Learning Rate: 0.00785004
	LOSS [training: 0.17090036951069648 | validation: 0.4869400216741232]
	TIME [epoch: 7.41 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19496571413588634		[learning rate: 0.007813]
	Learning Rate: 0.00781305
	LOSS [training: 0.19496571413588634 | validation: 0.3386906444685583]
	TIME [epoch: 7.41 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15328142785258414		[learning rate: 0.0077762]
	Learning Rate: 0.00777623
	LOSS [training: 0.15328142785258414 | validation: 0.4305770639892909]
	TIME [epoch: 7.41 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17431260272062896		[learning rate: 0.0077396]
	Learning Rate: 0.00773959
	LOSS [training: 0.17431260272062896 | validation: 0.39208307219623784]
	TIME [epoch: 7.42 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.204980208808471		[learning rate: 0.0077031]
	Learning Rate: 0.00770312
	LOSS [training: 0.204980208808471 | validation: 0.316907117156716]
	TIME [epoch: 7.42 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15865910444839068		[learning rate: 0.0076668]
	Learning Rate: 0.00766682
	LOSS [training: 0.15865910444839068 | validation: 0.34180854690911955]
	TIME [epoch: 7.42 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17941633318833428		[learning rate: 0.0076307]
	Learning Rate: 0.0076307
	LOSS [training: 0.17941633318833428 | validation: 0.3062340923003291]
	TIME [epoch: 7.42 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14168464546887488		[learning rate: 0.0075947]
	Learning Rate: 0.00759474
	LOSS [training: 0.14168464546887488 | validation: 0.30810195201059054]
	TIME [epoch: 7.42 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16227965976345646		[learning rate: 0.007559]
	Learning Rate: 0.00755895
	LOSS [training: 0.16227965976345646 | validation: 0.3594579296041577]
	TIME [epoch: 7.41 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1612431139783346		[learning rate: 0.0075233]
	Learning Rate: 0.00752333
	LOSS [training: 0.1612431139783346 | validation: 0.37194217230565985]
	TIME [epoch: 7.41 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15720683960487913		[learning rate: 0.0074879]
	Learning Rate: 0.00748788
	LOSS [training: 0.15720683960487913 | validation: 0.36239737943663775]
	TIME [epoch: 7.42 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17932551958649035		[learning rate: 0.0074526]
	Learning Rate: 0.0074526
	LOSS [training: 0.17932551958649035 | validation: 0.43765024009224357]
	TIME [epoch: 7.41 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16182783780572213		[learning rate: 0.0074175]
	Learning Rate: 0.00741748
	LOSS [training: 0.16182783780572213 | validation: 0.29690484823638397]
	TIME [epoch: 7.4 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v14_20240718_190302/states/model_facs_v4_dec2b_2dpca_v14_101.pth
	Model improved!!!
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15095591803299135		[learning rate: 0.0073825]
	Learning Rate: 0.00738253
	LOSS [training: 0.15095591803299135 | validation: 0.32827550919347115]
	TIME [epoch: 7.41 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16815943961861762		[learning rate: 0.0073477]
	Learning Rate: 0.00734774
	LOSS [training: 0.16815943961861762 | validation: 0.36928214919730035]
	TIME [epoch: 7.41 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1696817058571189		[learning rate: 0.0073131]
	Learning Rate: 0.00731312
	LOSS [training: 0.1696817058571189 | validation: 0.41488354436783154]
	TIME [epoch: 7.42 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13162525586800097		[learning rate: 0.0072787]
	Learning Rate: 0.00727866
	LOSS [training: 0.13162525586800097 | validation: 0.3703147298749071]
	TIME [epoch: 7.42 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18516643465666416		[learning rate: 0.0072444]
	Learning Rate: 0.00724436
	LOSS [training: 0.18516643465666416 | validation: 0.4521296430858244]
	TIME [epoch: 7.41 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1700520709242864		[learning rate: 0.0072102]
	Learning Rate: 0.00721022
	LOSS [training: 0.1700520709242864 | validation: 0.3111334622567042]
	TIME [epoch: 7.41 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17624008294853277		[learning rate: 0.0071762]
	Learning Rate: 0.00717625
	LOSS [training: 0.17624008294853277 | validation: 0.3311123903218269]
	TIME [epoch: 7.41 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17190296219955004		[learning rate: 0.0071424]
	Learning Rate: 0.00714243
	LOSS [training: 0.17190296219955004 | validation: 0.31224016831567497]
	TIME [epoch: 7.41 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16228159566919537		[learning rate: 0.0071088]
	Learning Rate: 0.00710878
	LOSS [training: 0.16228159566919537 | validation: 0.31201040220113846]
	TIME [epoch: 7.42 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1553095434693633		[learning rate: 0.0070753]
	Learning Rate: 0.00707528
	LOSS [training: 0.1553095434693633 | validation: 0.3425078803201516]
	TIME [epoch: 7.43 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1568905553800162		[learning rate: 0.0070419]
	Learning Rate: 0.00704194
	LOSS [training: 0.1568905553800162 | validation: 0.3067703036003367]
	TIME [epoch: 7.41 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17962592565085916		[learning rate: 0.0070088]
	Learning Rate: 0.00700876
	LOSS [training: 0.17962592565085916 | validation: 0.4217850651992836]
	TIME [epoch: 7.41 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15272263636302252		[learning rate: 0.0069757]
	Learning Rate: 0.00697573
	LOSS [training: 0.15272263636302252 | validation: 0.3814562893039448]
	TIME [epoch: 7.41 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1565682194023199		[learning rate: 0.0069429]
	Learning Rate: 0.00694286
	LOSS [training: 0.1565682194023199 | validation: 0.4499348539893075]
	TIME [epoch: 7.41 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19706994305754402		[learning rate: 0.0069101]
	Learning Rate: 0.00691014
	LOSS [training: 0.19706994305754402 | validation: 0.31865045339050857]
	TIME [epoch: 7.44 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1509179814377589		[learning rate: 0.0068776]
	Learning Rate: 0.00687758
	LOSS [training: 0.1509179814377589 | validation: 0.3134386163109115]
	TIME [epoch: 7.42 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14331267543918122		[learning rate: 0.0068452]
	Learning Rate: 0.00684518
	LOSS [training: 0.14331267543918122 | validation: 0.32620091756617026]
	TIME [epoch: 7.41 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1318239466676413		[learning rate: 0.0068129]
	Learning Rate: 0.00681292
	LOSS [training: 0.1318239466676413 | validation: 0.3218618266466089]
	TIME [epoch: 7.41 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1605055307378465		[learning rate: 0.0067808]
	Learning Rate: 0.00678082
	LOSS [training: 0.1605055307378465 | validation: 0.3700053929346511]
	TIME [epoch: 7.41 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20430871238712026		[learning rate: 0.0067489]
	Learning Rate: 0.00674887
	LOSS [training: 0.20430871238712026 | validation: 0.3898037260173519]
	TIME [epoch: 7.41 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15387499886051118		[learning rate: 0.0067171]
	Learning Rate: 0.00671706
	LOSS [training: 0.15387499886051118 | validation: 0.32700238953195715]
	TIME [epoch: 7.43 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16501590346619532		[learning rate: 0.0066854]
	Learning Rate: 0.00668541
	LOSS [training: 0.16501590346619532 | validation: 0.32238267907754126]
	TIME [epoch: 7.41 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1538411052348131		[learning rate: 0.0066539]
	Learning Rate: 0.00665391
	LOSS [training: 0.1538411052348131 | validation: 0.32542056852725165]
	TIME [epoch: 7.41 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15690472383853077		[learning rate: 0.0066226]
	Learning Rate: 0.00662256
	LOSS [training: 0.15690472383853077 | validation: 0.38362572576655607]
	TIME [epoch: 7.41 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1993494411772469		[learning rate: 0.0065913]
	Learning Rate: 0.00659135
	LOSS [training: 0.1993494411772469 | validation: 0.32151067194656]
	TIME [epoch: 7.42 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1653537915433117		[learning rate: 0.0065603]
	Learning Rate: 0.00656029
	LOSS [training: 0.1653537915433117 | validation: 0.416219035968755]
	TIME [epoch: 7.42 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16902147919647956		[learning rate: 0.0065294]
	Learning Rate: 0.00652938
	LOSS [training: 0.16902147919647956 | validation: 0.2955916923954548]
	TIME [epoch: 7.42 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v14_20240718_190302/states/model_facs_v4_dec2b_2dpca_v14_128.pth
	Model improved!!!
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14564256941186934		[learning rate: 0.0064986]
	Learning Rate: 0.00649861
	LOSS [training: 0.14564256941186934 | validation: 0.42374302703415917]
	TIME [epoch: 7.42 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20810218819240053		[learning rate: 0.006468]
	Learning Rate: 0.00646799
	LOSS [training: 0.20810218819240053 | validation: 0.29765663489044114]
	TIME [epoch: 7.41 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14482667873276786		[learning rate: 0.0064375]
	Learning Rate: 0.00643751
	LOSS [training: 0.14482667873276786 | validation: 0.35492762617702966]
	TIME [epoch: 7.41 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1676240078042289		[learning rate: 0.0064072]
	Learning Rate: 0.00640718
	LOSS [training: 0.1676240078042289 | validation: 0.35163105309881004]
	TIME [epoch: 7.41 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15360386719764846		[learning rate: 0.006377]
	Learning Rate: 0.00637698
	LOSS [training: 0.15360386719764846 | validation: 0.3094067317835816]
	TIME [epoch: 7.4 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1400126838634061		[learning rate: 0.0063469]
	Learning Rate: 0.00634694
	LOSS [training: 0.1400126838634061 | validation: 0.3179509756438772]
	TIME [epoch: 7.42 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1558029194539603		[learning rate: 0.006317]
	Learning Rate: 0.00631703
	LOSS [training: 0.1558029194539603 | validation: 0.33689578236708456]
	TIME [epoch: 7.42 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15373604568273277		[learning rate: 0.0062873]
	Learning Rate: 0.00628726
	LOSS [training: 0.15373604568273277 | validation: 0.3218229188761823]
	TIME [epoch: 7.41 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13653960988127864		[learning rate: 0.0062576]
	Learning Rate: 0.00625764
	LOSS [training: 0.13653960988127864 | validation: 0.3444023446075656]
	TIME [epoch: 7.41 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16021502641354507		[learning rate: 0.0062281]
	Learning Rate: 0.00622815
	LOSS [training: 0.16021502641354507 | validation: 0.30272625376745177]
	TIME [epoch: 7.41 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14715344364812152		[learning rate: 0.0061988]
	Learning Rate: 0.0061988
	LOSS [training: 0.14715344364812152 | validation: 0.28764725171297656]
	TIME [epoch: 7.4 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v14_20240718_190302/states/model_facs_v4_dec2b_2dpca_v14_139.pth
	Model improved!!!
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1476507677858528		[learning rate: 0.0061696]
	Learning Rate: 0.00616959
	LOSS [training: 0.1476507677858528 | validation: 0.39231149317388847]
	TIME [epoch: 7.42 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18613501616128425		[learning rate: 0.0061405]
	Learning Rate: 0.00614052
	LOSS [training: 0.18613501616128425 | validation: 0.3821169170377505]
	TIME [epoch: 7.42 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15643088355730891		[learning rate: 0.0061116]
	Learning Rate: 0.00611158
	LOSS [training: 0.15643088355730891 | validation: 0.32702193060910334]
	TIME [epoch: 7.41 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15299421628729407		[learning rate: 0.0060828]
	Learning Rate: 0.00608279
	LOSS [training: 0.15299421628729407 | validation: 0.31326264834313405]
	TIME [epoch: 7.41 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1760809564041076		[learning rate: 0.0060541]
	Learning Rate: 0.00605412
	LOSS [training: 0.1760809564041076 | validation: 0.3482920943948968]
	TIME [epoch: 7.41 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15478965811402695		[learning rate: 0.0060256]
	Learning Rate: 0.0060256
	LOSS [training: 0.15478965811402695 | validation: 0.3116946436985199]
	TIME [epoch: 7.41 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14597763468345035		[learning rate: 0.0059972]
	Learning Rate: 0.0059972
	LOSS [training: 0.14597763468345035 | validation: 0.30390353345753224]
	TIME [epoch: 7.41 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14923614400846177		[learning rate: 0.0059689]
	Learning Rate: 0.00596894
	LOSS [training: 0.14923614400846177 | validation: 0.3548310539645442]
	TIME [epoch: 7.42 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1485626003495568		[learning rate: 0.0059408]
	Learning Rate: 0.00594082
	LOSS [training: 0.1485626003495568 | validation: 0.4216202880656542]
	TIME [epoch: 7.41 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1406610349880391		[learning rate: 0.0059128]
	Learning Rate: 0.00591282
	LOSS [training: 0.1406610349880391 | validation: 0.3011729850907181]
	TIME [epoch: 7.41 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15079398057316773		[learning rate: 0.005885]
	Learning Rate: 0.00588496
	LOSS [training: 0.15079398057316773 | validation: 0.33568448444814414]
	TIME [epoch: 7.4 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16484712471201216		[learning rate: 0.0058572]
	Learning Rate: 0.00585723
	LOSS [training: 0.16484712471201216 | validation: 0.2825859932602268]
	TIME [epoch: 7.41 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v14_20240718_190302/states/model_facs_v4_dec2b_2dpca_v14_151.pth
	Model improved!!!
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1633926719401128		[learning rate: 0.0058296]
	Learning Rate: 0.00582963
	LOSS [training: 0.1633926719401128 | validation: 0.33544308790702915]
	TIME [epoch: 7.42 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1648324439191728		[learning rate: 0.0058022]
	Learning Rate: 0.00580216
	LOSS [training: 0.1648324439191728 | validation: 0.37128796422710497]
	TIME [epoch: 7.41 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18857583087553922		[learning rate: 0.0057748]
	Learning Rate: 0.00577482
	LOSS [training: 0.18857583087553922 | validation: 0.3337419899561729]
	TIME [epoch: 7.41 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15407414162558666		[learning rate: 0.0057476]
	Learning Rate: 0.00574761
	LOSS [training: 0.15407414162558666 | validation: 0.3567837459742148]
	TIME [epoch: 7.41 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18411035234875184		[learning rate: 0.0057205]
	Learning Rate: 0.00572052
	LOSS [training: 0.18411035234875184 | validation: 0.3341470051820271]
	TIME [epoch: 7.41 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13796740101245586		[learning rate: 0.0056936]
	Learning Rate: 0.00569357
	LOSS [training: 0.13796740101245586 | validation: 0.31936254680589066]
	TIME [epoch: 7.41 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15054358715507177		[learning rate: 0.0056667]
	Learning Rate: 0.00566674
	LOSS [training: 0.15054358715507177 | validation: 0.4158516172847741]
	TIME [epoch: 7.41 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14650394553867155		[learning rate: 0.00564]
	Learning Rate: 0.00564004
	LOSS [training: 0.14650394553867155 | validation: 0.35663672171317257]
	TIME [epoch: 7.42 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16785943712015058		[learning rate: 0.0056135]
	Learning Rate: 0.00561346
	LOSS [training: 0.16785943712015058 | validation: 0.3076788348014262]
	TIME [epoch: 7.41 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15271966997531677		[learning rate: 0.005587]
	Learning Rate: 0.00558701
	LOSS [training: 0.15271966997531677 | validation: 0.35922103555320495]
	TIME [epoch: 7.41 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14556750769502677		[learning rate: 0.0055607]
	Learning Rate: 0.00556068
	LOSS [training: 0.14556750769502677 | validation: 0.3377742260330424]
	TIME [epoch: 7.41 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.128045622293822		[learning rate: 0.0055345]
	Learning Rate: 0.00553448
	LOSS [training: 0.128045622293822 | validation: 0.35332501977950803]
	TIME [epoch: 7.41 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13117698922911464		[learning rate: 0.0055084]
	Learning Rate: 0.0055084
	LOSS [training: 0.13117698922911464 | validation: 0.29088175500140373]
	TIME [epoch: 7.41 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1943921514938269		[learning rate: 0.0054824]
	Learning Rate: 0.00548245
	LOSS [training: 0.1943921514938269 | validation: 0.350870057363856]
	TIME [epoch: 7.42 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1384681347362453		[learning rate: 0.0054566]
	Learning Rate: 0.00545661
	LOSS [training: 0.1384681347362453 | validation: 0.3296089935418122]
	TIME [epoch: 7.41 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15696057594379847		[learning rate: 0.0054309]
	Learning Rate: 0.0054309
	LOSS [training: 0.15696057594379847 | validation: 0.3187612790523502]
	TIME [epoch: 7.41 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15471850164009493		[learning rate: 0.0054053]
	Learning Rate: 0.00540531
	LOSS [training: 0.15471850164009493 | validation: 0.3396283562176913]
	TIME [epoch: 7.41 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15120761948823666		[learning rate: 0.0053798]
	Learning Rate: 0.00537984
	LOSS [training: 0.15120761948823666 | validation: 0.31727779526022126]
	TIME [epoch: 7.41 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15654971276509075		[learning rate: 0.0053545]
	Learning Rate: 0.00535449
	LOSS [training: 0.15654971276509075 | validation: 0.32043291719534533]
	TIME [epoch: 7.42 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15680371807153515		[learning rate: 0.0053293]
	Learning Rate: 0.00532926
	LOSS [training: 0.15680371807153515 | validation: 0.36517031094450636]
	TIME [epoch: 7.41 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15220549080028523		[learning rate: 0.0053041]
	Learning Rate: 0.00530415
	LOSS [training: 0.15220549080028523 | validation: 0.39631551748440813]
	TIME [epoch: 7.41 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14751241680848404		[learning rate: 0.0052792]
	Learning Rate: 0.00527915
	LOSS [training: 0.14751241680848404 | validation: 0.3130713094949936]
	TIME [epoch: 7.41 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1363016465965514		[learning rate: 0.0052543]
	Learning Rate: 0.00525428
	LOSS [training: 0.1363016465965514 | validation: 0.32736472358888324]
	TIME [epoch: 7.4 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16677723374452585		[learning rate: 0.0052295]
	Learning Rate: 0.00522952
	LOSS [training: 0.16677723374452585 | validation: 0.3002949244608839]
	TIME [epoch: 7.41 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1351379938116748		[learning rate: 0.0052049]
	Learning Rate: 0.00520487
	LOSS [training: 0.1351379938116748 | validation: 0.2865641028664523]
	TIME [epoch: 7.42 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14542322552338974		[learning rate: 0.0051803]
	Learning Rate: 0.00518035
	LOSS [training: 0.14542322552338974 | validation: 0.4093655450327484]
	TIME [epoch: 7.41 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15549820042573664		[learning rate: 0.0051559]
	Learning Rate: 0.00515594
	LOSS [training: 0.15549820042573664 | validation: 0.36376203495668286]
	TIME [epoch: 7.41 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14291467029940422		[learning rate: 0.0051316]
	Learning Rate: 0.00513164
	LOSS [training: 0.14291467029940422 | validation: 0.3216460749177418]
	TIME [epoch: 7.41 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15858308526704998		[learning rate: 0.0051075]
	Learning Rate: 0.00510746
	LOSS [training: 0.15858308526704998 | validation: 0.32085381532715085]
	TIME [epoch: 7.4 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13994754653877298		[learning rate: 0.0050834]
	Learning Rate: 0.00508339
	LOSS [training: 0.13994754653877298 | validation: 0.3066673644207002]
	TIME [epoch: 7.41 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13878312511291818		[learning rate: 0.0050594]
	Learning Rate: 0.00505944
	LOSS [training: 0.13878312511291818 | validation: 0.4064614588635661]
	TIME [epoch: 7.42 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11913222615496266		[learning rate: 0.0050356]
	Learning Rate: 0.0050356
	LOSS [training: 0.11913222615496266 | validation: 0.29291528543068857]
	TIME [epoch: 7.41 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15302210416989062		[learning rate: 0.0050119]
	Learning Rate: 0.00501187
	LOSS [training: 0.15302210416989062 | validation: 0.4393178148044817]
	TIME [epoch: 7.41 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18350829210044473		[learning rate: 0.0049883]
	Learning Rate: 0.00498826
	LOSS [training: 0.18350829210044473 | validation: 0.43933802312231396]
	TIME [epoch: 7.41 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16610910500792436		[learning rate: 0.0049648]
	Learning Rate: 0.00496475
	LOSS [training: 0.16610910500792436 | validation: 0.36035353096790845]
	TIME [epoch: 7.41 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13990289285702123		[learning rate: 0.0049414]
	Learning Rate: 0.00494136
	LOSS [training: 0.13990289285702123 | validation: 0.33213220753824557]
	TIME [epoch: 7.42 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.130122707526877		[learning rate: 0.0049181]
	Learning Rate: 0.00491807
	LOSS [training: 0.130122707526877 | validation: 0.33776175683815224]
	TIME [epoch: 7.42 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17996587762670269		[learning rate: 0.0048949]
	Learning Rate: 0.0048949
	LOSS [training: 0.17996587762670269 | validation: 0.34654310444429215]
	TIME [epoch: 7.41 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.156923505694301		[learning rate: 0.0048718]
	Learning Rate: 0.00487183
	LOSS [training: 0.156923505694301 | validation: 0.4401493953268195]
	TIME [epoch: 7.41 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15038382046164794		[learning rate: 0.0048489]
	Learning Rate: 0.00484888
	LOSS [training: 0.15038382046164794 | validation: 0.32737694042018295]
	TIME [epoch: 7.41 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15356764723837452		[learning rate: 0.004826]
	Learning Rate: 0.00482603
	LOSS [training: 0.15356764723837452 | validation: 0.33306822920034884]
	TIME [epoch: 7.41 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12558831546672586		[learning rate: 0.0048033]
	Learning Rate: 0.00480329
	LOSS [training: 0.12558831546672586 | validation: 0.3478777281377153]
	TIME [epoch: 7.42 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12458636765926781		[learning rate: 0.0047807]
	Learning Rate: 0.00478065
	LOSS [training: 0.12458636765926781 | validation: 0.30664876015761044]
	TIME [epoch: 7.42 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13182455011760946		[learning rate: 0.0047581]
	Learning Rate: 0.00475813
	LOSS [training: 0.13182455011760946 | validation: 0.34070483091853127]
	TIME [epoch: 7.4 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13253796686238667		[learning rate: 0.0047357]
	Learning Rate: 0.0047357
	LOSS [training: 0.13253796686238667 | validation: 0.3604282109143112]
	TIME [epoch: 7.41 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15980096677110503		[learning rate: 0.0047134]
	Learning Rate: 0.00471339
	LOSS [training: 0.15980096677110503 | validation: 0.36861049521764194]
	TIME [epoch: 7.41 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15204264744670654		[learning rate: 0.0046912]
	Learning Rate: 0.00469118
	LOSS [training: 0.15204264744670654 | validation: 0.3520620197739752]
	TIME [epoch: 7.45 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13301463137096972		[learning rate: 0.0046691]
	Learning Rate: 0.00466907
	LOSS [training: 0.13301463137096972 | validation: 0.306664248725418]
	TIME [epoch: 7.42 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1207943617915315		[learning rate: 0.0046471]
	Learning Rate: 0.00464707
	LOSS [training: 0.1207943617915315 | validation: 0.30772560245704905]
	TIME [epoch: 7.41 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12736606858346455		[learning rate: 0.0046252]
	Learning Rate: 0.00462518
	LOSS [training: 0.12736606858346455 | validation: 0.38739792432222053]
	TIME [epoch: 7.41 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13255358394747233		[learning rate: 0.0046034]
	Learning Rate: 0.00460338
	LOSS [training: 0.13255358394747233 | validation: 0.38177486487350437]
	TIME [epoch: 7.41 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1372442510881671		[learning rate: 0.0045817]
	Learning Rate: 0.00458169
	LOSS [training: 0.1372442510881671 | validation: 0.30768560039937104]
	TIME [epoch: 7.41 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14627855556669467		[learning rate: 0.0045601]
	Learning Rate: 0.0045601
	LOSS [training: 0.14627855556669467 | validation: 0.3283213854672801]
	TIME [epoch: 7.41 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14049196935285874		[learning rate: 0.0045386]
	Learning Rate: 0.00453861
	LOSS [training: 0.14049196935285874 | validation: 0.32942293884071094]
	TIME [epoch: 7.42 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14716870798416842		[learning rate: 0.0045172]
	Learning Rate: 0.00451723
	LOSS [training: 0.14716870798416842 | validation: 0.4027295180205218]
	TIME [epoch: 7.41 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13539263171296323		[learning rate: 0.0044959]
	Learning Rate: 0.00449594
	LOSS [training: 0.13539263171296323 | validation: 0.34363033056076847]
	TIME [epoch: 7.41 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11546234179624146		[learning rate: 0.0044748]
	Learning Rate: 0.00447475
	LOSS [training: 0.11546234179624146 | validation: 0.29434813476463983]
	TIME [epoch: 7.41 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12363137523043598		[learning rate: 0.0044537]
	Learning Rate: 0.00445367
	LOSS [training: 0.12363137523043598 | validation: 0.317641672820278]
	TIME [epoch: 7.42 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1378237140664715		[learning rate: 0.0044327]
	Learning Rate: 0.00443268
	LOSS [training: 0.1378237140664715 | validation: 0.3053103353538596]
	TIME [epoch: 7.41 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13781834826789202		[learning rate: 0.0044118]
	Learning Rate: 0.0044118
	LOSS [training: 0.13781834826789202 | validation: 0.3798472393935539]
	TIME [epoch: 7.41 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12792564500969358		[learning rate: 0.004391]
	Learning Rate: 0.00439101
	LOSS [training: 0.12792564500969358 | validation: 0.3644983966858273]
	TIME [epoch: 7.41 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13641617243177656		[learning rate: 0.0043703]
	Learning Rate: 0.00437032
	LOSS [training: 0.13641617243177656 | validation: 0.3358714264259903]
	TIME [epoch: 7.41 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14790798377397973		[learning rate: 0.0043497]
	Learning Rate: 0.00434972
	LOSS [training: 0.14790798377397973 | validation: 0.32536394121455636]
	TIME [epoch: 7.41 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1365866867634449		[learning rate: 0.0043292]
	Learning Rate: 0.00432923
	LOSS [training: 0.1365866867634449 | validation: 0.33853628474054026]
	TIME [epoch: 7.41 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13317254830659653		[learning rate: 0.0043088]
	Learning Rate: 0.00430883
	LOSS [training: 0.13317254830659653 | validation: 0.292732815295997]
	TIME [epoch: 7.41 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14617622129063557		[learning rate: 0.0042885]
	Learning Rate: 0.00428852
	LOSS [training: 0.14617622129063557 | validation: 0.34231258629784295]
	TIME [epoch: 7.41 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1424968445779718		[learning rate: 0.0042683]
	Learning Rate: 0.00426831
	LOSS [training: 0.1424968445779718 | validation: 0.33155113586206153]
	TIME [epoch: 7.41 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13130030706739748		[learning rate: 0.0042482]
	Learning Rate: 0.0042482
	LOSS [training: 0.13130030706739748 | validation: 0.36955497937509263]
	TIME [epoch: 7.4 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13007332834261856		[learning rate: 0.0042282]
	Learning Rate: 0.00422818
	LOSS [training: 0.13007332834261856 | validation: 0.4221982364951279]
	TIME [epoch: 7.41 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14203982671925497		[learning rate: 0.0042083]
	Learning Rate: 0.00420826
	LOSS [training: 0.14203982671925497 | validation: 0.33331667909612206]
	TIME [epoch: 7.42 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.124266766078729		[learning rate: 0.0041884]
	Learning Rate: 0.00418843
	LOSS [training: 0.124266766078729 | validation: 0.40139514213705124]
	TIME [epoch: 7.42 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1354940875165255		[learning rate: 0.0041687]
	Learning Rate: 0.00416869
	LOSS [training: 0.1354940875165255 | validation: 0.3349570818228259]
	TIME [epoch: 7.41 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14329827901192266		[learning rate: 0.0041491]
	Learning Rate: 0.00414905
	LOSS [training: 0.14329827901192266 | validation: 0.32528016069827664]
	TIME [epoch: 7.41 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1464364529348009		[learning rate: 0.0041295]
	Learning Rate: 0.0041295
	LOSS [training: 0.1464364529348009 | validation: 0.3303058085535994]
	TIME [epoch: 7.4 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14336467067003067		[learning rate: 0.00411]
	Learning Rate: 0.00411004
	LOSS [training: 0.14336467067003067 | validation: 0.32373339806323054]
	TIME [epoch: 7.41 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13604857948070842		[learning rate: 0.0040907]
	Learning Rate: 0.00409067
	LOSS [training: 0.13604857948070842 | validation: 0.30739996112330165]
	TIME [epoch: 7.41 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12108644192536874		[learning rate: 0.0040714]
	Learning Rate: 0.0040714
	LOSS [training: 0.12108644192536874 | validation: 0.306030262618134]
	TIME [epoch: 7.42 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14105730042030348		[learning rate: 0.0040522]
	Learning Rate: 0.00405221
	LOSS [training: 0.14105730042030348 | validation: 0.29834655293908724]
	TIME [epoch: 7.41 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15014001679387057		[learning rate: 0.0040331]
	Learning Rate: 0.00403312
	LOSS [training: 0.15014001679387057 | validation: 0.3885577060887849]
	TIME [epoch: 7.42 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13792352366498517		[learning rate: 0.0040141]
	Learning Rate: 0.00401411
	LOSS [training: 0.13792352366498517 | validation: 0.30368366431722604]
	TIME [epoch: 7.46 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1499959666582414		[learning rate: 0.0039952]
	Learning Rate: 0.0039952
	LOSS [training: 0.1499959666582414 | validation: 0.3328482318066516]
	TIME [epoch: 7.41 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13050270369941996		[learning rate: 0.0039764]
	Learning Rate: 0.00397637
	LOSS [training: 0.13050270369941996 | validation: 0.35674031028026787]
	TIME [epoch: 7.42 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11606826641296834		[learning rate: 0.0039576]
	Learning Rate: 0.00395764
	LOSS [training: 0.11606826641296834 | validation: 0.3954186323975671]
	TIME [epoch: 7.41 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11679123721271537		[learning rate: 0.003939]
	Learning Rate: 0.00393899
	LOSS [training: 0.11679123721271537 | validation: 0.35639665606726834]
	TIME [epoch: 7.41 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14573608809337987		[learning rate: 0.0039204]
	Learning Rate: 0.00392043
	LOSS [training: 0.14573608809337987 | validation: 0.3169676004638419]
	TIME [epoch: 7.41 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1278106814532055		[learning rate: 0.003902]
	Learning Rate: 0.00390195
	LOSS [training: 0.1278106814532055 | validation: 0.29007669989181084]
	TIME [epoch: 7.42 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12947066578808855		[learning rate: 0.0038836]
	Learning Rate: 0.00388357
	LOSS [training: 0.12947066578808855 | validation: 0.3448893892343616]
	TIME [epoch: 7.44 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16130581843630576		[learning rate: 0.0038653]
	Learning Rate: 0.00386527
	LOSS [training: 0.16130581843630576 | validation: 0.3436528874949467]
	TIME [epoch: 7.42 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1482956751868708		[learning rate: 0.0038471]
	Learning Rate: 0.00384705
	LOSS [training: 0.1482956751868708 | validation: 0.41178533798004363]
	TIME [epoch: 7.41 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1638426842442805		[learning rate: 0.0038289]
	Learning Rate: 0.00382893
	LOSS [training: 0.1638426842442805 | validation: 0.32257825933107975]
	TIME [epoch: 7.41 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13516630155034942		[learning rate: 0.0038109]
	Learning Rate: 0.00381088
	LOSS [training: 0.13516630155034942 | validation: 0.3218361661506872]
	TIME [epoch: 7.41 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1345186651459472		[learning rate: 0.0037929]
	Learning Rate: 0.00379293
	LOSS [training: 0.1345186651459472 | validation: 0.35839057099577465]
	TIME [epoch: 7.41 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13448065441531062		[learning rate: 0.0037751]
	Learning Rate: 0.00377505
	LOSS [training: 0.13448065441531062 | validation: 0.3946315646625031]
	TIME [epoch: 7.42 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1447551774987001		[learning rate: 0.0037573]
	Learning Rate: 0.00375726
	LOSS [training: 0.1447551774987001 | validation: 0.37869828576527004]
	TIME [epoch: 7.41 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1586969884313413		[learning rate: 0.0037396]
	Learning Rate: 0.00373956
	LOSS [training: 0.1586969884313413 | validation: 0.37246192874478234]
	TIME [epoch: 7.41 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12799672539047707		[learning rate: 0.0037219]
	Learning Rate: 0.00372194
	LOSS [training: 0.12799672539047707 | validation: 0.318449952934128]
	TIME [epoch: 7.42 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13024010979906853		[learning rate: 0.0037044]
	Learning Rate: 0.0037044
	LOSS [training: 0.13024010979906853 | validation: 0.32511390529882134]
	TIME [epoch: 7.4 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12777401891781215		[learning rate: 0.0036869]
	Learning Rate: 0.00368695
	LOSS [training: 0.12777401891781215 | validation: 0.30717790795645217]
	TIME [epoch: 7.41 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12797868624220038		[learning rate: 0.0036696]
	Learning Rate: 0.00366957
	LOSS [training: 0.12797868624220038 | validation: 0.3425710611817148]
	TIME [epoch: 7.42 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15131450613621192		[learning rate: 0.0036523]
	Learning Rate: 0.00365228
	LOSS [training: 0.15131450613621192 | validation: 0.29138747523852887]
	TIME [epoch: 7.42 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1351580535498907		[learning rate: 0.0036351]
	Learning Rate: 0.00363507
	LOSS [training: 0.1351580535498907 | validation: 0.3634857910241867]
	TIME [epoch: 7.41 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12533235729492767		[learning rate: 0.0036179]
	Learning Rate: 0.00361794
	LOSS [training: 0.12533235729492767 | validation: 0.3700648301006166]
	TIME [epoch: 7.41 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14049391273289946		[learning rate: 0.0036009]
	Learning Rate: 0.00360089
	LOSS [training: 0.14049391273289946 | validation: 0.32019461963013823]
	TIME [epoch: 7.41 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1290329011905318		[learning rate: 0.0035839]
	Learning Rate: 0.00358393
	LOSS [training: 0.1290329011905318 | validation: 0.35082336805362224]
	TIME [epoch: 7.42 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13599367449982977		[learning rate: 0.003567]
	Learning Rate: 0.00356704
	LOSS [training: 0.13599367449982977 | validation: 0.34731384351876315]
	TIME [epoch: 7.42 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13469091816004192		[learning rate: 0.0035502]
	Learning Rate: 0.00355023
	LOSS [training: 0.13469091816004192 | validation: 0.3291681349536453]
	TIME [epoch: 7.41 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12201116409789987		[learning rate: 0.0035335]
	Learning Rate: 0.0035335
	LOSS [training: 0.12201116409789987 | validation: 0.3161639025701442]
	TIME [epoch: 7.41 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13202819613245703		[learning rate: 0.0035168]
	Learning Rate: 0.00351685
	LOSS [training: 0.13202819613245703 | validation: 0.3251094889017069]
	TIME [epoch: 7.41 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1357200862773492		[learning rate: 0.0035003]
	Learning Rate: 0.00350028
	LOSS [training: 0.1357200862773492 | validation: 0.3225147725951265]
	TIME [epoch: 7.42 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12686679860782243		[learning rate: 0.0034838]
	Learning Rate: 0.00348378
	LOSS [training: 0.12686679860782243 | validation: 0.30313457079968875]
	TIME [epoch: 7.4 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1344619887912937		[learning rate: 0.0034674]
	Learning Rate: 0.00346737
	LOSS [training: 0.1344619887912937 | validation: 0.2986092452339725]
	TIME [epoch: 7.42 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1285785300307723		[learning rate: 0.003451]
	Learning Rate: 0.00345103
	LOSS [training: 0.1285785300307723 | validation: 0.3392803795827814]
	TIME [epoch: 7.41 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13073290719089095		[learning rate: 0.0034348]
	Learning Rate: 0.00343477
	LOSS [training: 0.13073290719089095 | validation: 0.3472666994508659]
	TIME [epoch: 7.41 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11528702954550207		[learning rate: 0.0034186]
	Learning Rate: 0.00341858
	LOSS [training: 0.11528702954550207 | validation: 0.39299707576014975]
	TIME [epoch: 7.41 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12427291709409764		[learning rate: 0.0034025]
	Learning Rate: 0.00340247
	LOSS [training: 0.12427291709409764 | validation: 0.30792452701793466]
	TIME [epoch: 7.43 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11962466957559344		[learning rate: 0.0033864]
	Learning Rate: 0.00338644
	LOSS [training: 0.11962466957559344 | validation: 0.3214228975224405]
	TIME [epoch: 7.41 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12288606771995272		[learning rate: 0.0033705]
	Learning Rate: 0.00337048
	LOSS [training: 0.12288606771995272 | validation: 0.3190105306866944]
	TIME [epoch: 7.41 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12646404223247026		[learning rate: 0.0033546]
	Learning Rate: 0.0033546
	LOSS [training: 0.12646404223247026 | validation: 0.28260113582930513]
	TIME [epoch: 7.41 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14798627169167994		[learning rate: 0.0033388]
	Learning Rate: 0.00333879
	LOSS [training: 0.14798627169167994 | validation: 0.3269745575517693]
	TIME [epoch: 7.41 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11687655071082419		[learning rate: 0.0033231]
	Learning Rate: 0.00332306
	LOSS [training: 0.11687655071082419 | validation: 0.31948026697813703]
	TIME [epoch: 7.44 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11954587523563182		[learning rate: 0.0033074]
	Learning Rate: 0.0033074
	LOSS [training: 0.11954587523563182 | validation: 0.29371171649579936]
	TIME [epoch: 7.42 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11167953595829316		[learning rate: 0.0032918]
	Learning Rate: 0.00329182
	LOSS [training: 0.11167953595829316 | validation: 0.3435873219616643]
	TIME [epoch: 7.42 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1260596837940263		[learning rate: 0.0032763]
	Learning Rate: 0.00327631
	LOSS [training: 0.1260596837940263 | validation: 0.32798046456535324]
	TIME [epoch: 7.42 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11962447835738582		[learning rate: 0.0032609]
	Learning Rate: 0.00326087
	LOSS [training: 0.11962447835738582 | validation: 0.31932787756385567]
	TIME [epoch: 7.41 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14269632476154714		[learning rate: 0.0032455]
	Learning Rate: 0.0032455
	LOSS [training: 0.14269632476154714 | validation: 0.3182597556484188]
	TIME [epoch: 7.41 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13009639156903333		[learning rate: 0.0032302]
	Learning Rate: 0.00323021
	LOSS [training: 0.13009639156903333 | validation: 0.359082868117449]
	TIME [epoch: 7.41 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12169653973439201		[learning rate: 0.003215]
	Learning Rate: 0.00321499
	LOSS [training: 0.12169653973439201 | validation: 0.32812845477617725]
	TIME [epoch: 7.42 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14442784039266077		[learning rate: 0.0031998]
	Learning Rate: 0.00319984
	LOSS [training: 0.14442784039266077 | validation: 0.35426086881037055]
	TIME [epoch: 7.42 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1429118396790535		[learning rate: 0.0031848]
	Learning Rate: 0.00318476
	LOSS [training: 0.1429118396790535 | validation: 0.3457236820538044]
	TIME [epoch: 7.42 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12452148783804798		[learning rate: 0.0031698]
	Learning Rate: 0.00316975
	LOSS [training: 0.12452148783804798 | validation: 0.3253848426675269]
	TIME [epoch: 7.41 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12647354759698612		[learning rate: 0.0031548]
	Learning Rate: 0.00315482
	LOSS [training: 0.12647354759698612 | validation: 0.3358565985017405]
	TIME [epoch: 7.42 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12733799226177436		[learning rate: 0.00314]
	Learning Rate: 0.00313995
	LOSS [training: 0.12733799226177436 | validation: 0.3141174739990975]
	TIME [epoch: 7.41 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1336207993272937		[learning rate: 0.0031252]
	Learning Rate: 0.00312516
	LOSS [training: 0.1336207993272937 | validation: 0.30696839024967804]
	TIME [epoch: 7.42 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12450058426024278		[learning rate: 0.0031104]
	Learning Rate: 0.00311043
	LOSS [training: 0.12450058426024278 | validation: 0.33221519311640524]
	TIME [epoch: 7.42 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11615712108669848		[learning rate: 0.0030958]
	Learning Rate: 0.00309577
	LOSS [training: 0.11615712108669848 | validation: 0.3777314424099405]
	TIME [epoch: 7.42 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12261211311037858		[learning rate: 0.0030812]
	Learning Rate: 0.00308119
	LOSS [training: 0.12261211311037858 | validation: 0.3105909028436916]
	TIME [epoch: 7.41 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1357172298121459		[learning rate: 0.0030667]
	Learning Rate: 0.00306667
	LOSS [training: 0.1357172298121459 | validation: 0.3083308877580353]
	TIME [epoch: 7.41 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12763224155105068		[learning rate: 0.0030522]
	Learning Rate: 0.00305222
	LOSS [training: 0.12763224155105068 | validation: 0.3048417276194902]
	TIME [epoch: 7.41 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11896108160789709		[learning rate: 0.0030378]
	Learning Rate: 0.00303783
	LOSS [training: 0.11896108160789709 | validation: 0.30642926804737275]
	TIME [epoch: 7.42 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1372659430186294		[learning rate: 0.0030235]
	Learning Rate: 0.00302352
	LOSS [training: 0.1372659430186294 | validation: 0.2886539012255535]
	TIME [epoch: 7.41 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12271187356334275		[learning rate: 0.0030093]
	Learning Rate: 0.00300927
	LOSS [training: 0.12271187356334275 | validation: 0.315583259524722]
	TIME [epoch: 7.42 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12358053855954938		[learning rate: 0.0029951]
	Learning Rate: 0.00299509
	LOSS [training: 0.12358053855954938 | validation: 0.3303222768773668]
	TIME [epoch: 7.41 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14094322979189847		[learning rate: 0.002981]
	Learning Rate: 0.00298098
	LOSS [training: 0.14094322979189847 | validation: 0.29377180685963017]
	TIME [epoch: 7.42 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12354144583994754		[learning rate: 0.0029669]
	Learning Rate: 0.00296693
	LOSS [training: 0.12354144583994754 | validation: 0.2755276382984262]
	TIME [epoch: 7.41 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v14_20240718_190302/states/model_facs_v4_dec2b_2dpca_v14_295.pth
	Model improved!!!
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1272191774583156		[learning rate: 0.002953]
	Learning Rate: 0.00295295
	LOSS [training: 0.1272191774583156 | validation: 0.3767522440640183]
	TIME [epoch: 7.5 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12453940331587726		[learning rate: 0.002939]
	Learning Rate: 0.00293904
	LOSS [training: 0.12453940331587726 | validation: 0.30683970219663737]
	TIME [epoch: 7.42 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12490699310079952		[learning rate: 0.0029252]
	Learning Rate: 0.00292519
	LOSS [training: 0.12490699310079952 | validation: 0.3256691710833889]
	TIME [epoch: 7.44 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12831695094369483		[learning rate: 0.0029114]
	Learning Rate: 0.0029114
	LOSS [training: 0.12831695094369483 | validation: 0.3038094218890789]
	TIME [epoch: 7.43 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12186846869976788		[learning rate: 0.0028977]
	Learning Rate: 0.00289769
	LOSS [training: 0.12186846869976788 | validation: 0.329329513749104]
	TIME [epoch: 7.42 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15121355094071637		[learning rate: 0.002884]
	Learning Rate: 0.00288403
	LOSS [training: 0.15121355094071637 | validation: 0.38135300381122483]
	TIME [epoch: 7.42 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14616923457991757		[learning rate: 0.0028704]
	Learning Rate: 0.00287044
	LOSS [training: 0.14616923457991757 | validation: 0.3299996496247868]
	TIME [epoch: 7.43 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11142217539557465		[learning rate: 0.0028569]
	Learning Rate: 0.00285692
	LOSS [training: 0.11142217539557465 | validation: 0.3477907046624756]
	TIME [epoch: 7.42 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13450501757249417		[learning rate: 0.0028435]
	Learning Rate: 0.00284345
	LOSS [training: 0.13450501757249417 | validation: 0.3374240345360473]
	TIME [epoch: 7.42 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13943812606808675		[learning rate: 0.0028301]
	Learning Rate: 0.00283005
	LOSS [training: 0.13943812606808675 | validation: 0.3282839467763292]
	TIME [epoch: 7.41 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13753224955833906		[learning rate: 0.0028167]
	Learning Rate: 0.00281672
	LOSS [training: 0.13753224955833906 | validation: 0.35115004515962817]
	TIME [epoch: 7.42 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11423725149912627		[learning rate: 0.0028034]
	Learning Rate: 0.00280345
	LOSS [training: 0.11423725149912627 | validation: 0.29173416932791435]
	TIME [epoch: 7.42 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12300579927723569		[learning rate: 0.0027902]
	Learning Rate: 0.00279024
	LOSS [training: 0.12300579927723569 | validation: 0.30520373578933657]
	TIME [epoch: 7.42 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13604730417173128		[learning rate: 0.0027771]
	Learning Rate: 0.00277709
	LOSS [training: 0.13604730417173128 | validation: 0.3173866972924658]
	TIME [epoch: 7.42 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11125330197643486		[learning rate: 0.002764]
	Learning Rate: 0.002764
	LOSS [training: 0.11125330197643486 | validation: 0.3178237187136632]
	TIME [epoch: 7.42 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13425475773533802		[learning rate: 0.002751]
	Learning Rate: 0.00275098
	LOSS [training: 0.13425475773533802 | validation: 0.2953115423493178]
	TIME [epoch: 7.42 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12737552105585567		[learning rate: 0.002738]
	Learning Rate: 0.00273802
	LOSS [training: 0.12737552105585567 | validation: 0.31106639876564257]
	TIME [epoch: 7.42 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1333415646490914		[learning rate: 0.0027251]
	Learning Rate: 0.00272511
	LOSS [training: 0.1333415646490914 | validation: 0.2860265024760822]
	TIME [epoch: 7.41 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1322864935021833		[learning rate: 0.0027123]
	Learning Rate: 0.00271227
	LOSS [training: 0.1322864935021833 | validation: 0.32963474438805607]
	TIME [epoch: 7.42 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13828555846511978		[learning rate: 0.0026995]
	Learning Rate: 0.00269949
	LOSS [training: 0.13828555846511978 | validation: 0.27853823677773687]
	TIME [epoch: 7.42 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1167384543313878		[learning rate: 0.0026868]
	Learning Rate: 0.00268677
	LOSS [training: 0.1167384543313878 | validation: 0.32147721992321787]
	TIME [epoch: 7.41 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13312822134663999		[learning rate: 0.0026741]
	Learning Rate: 0.00267411
	LOSS [training: 0.13312822134663999 | validation: 0.3063521692752629]
	TIME [epoch: 7.42 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1343291727185914		[learning rate: 0.0026615]
	Learning Rate: 0.00266151
	LOSS [training: 0.1343291727185914 | validation: 0.28231292348055453]
	TIME [epoch: 7.42 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1267601736879626		[learning rate: 0.002649]
	Learning Rate: 0.00264897
	LOSS [training: 0.1267601736879626 | validation: 0.31736859551219987]
	TIME [epoch: 7.42 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1438521279082152		[learning rate: 0.0026365]
	Learning Rate: 0.00263649
	LOSS [training: 0.1438521279082152 | validation: 0.3196103312821107]
	TIME [epoch: 7.43 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11845033992262526		[learning rate: 0.0026241]
	Learning Rate: 0.00262406
	LOSS [training: 0.11845033992262526 | validation: 0.3477437902509871]
	TIME [epoch: 7.42 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.140474771722015		[learning rate: 0.0026117]
	Learning Rate: 0.0026117
	LOSS [training: 0.140474771722015 | validation: 0.3161423259742893]
	TIME [epoch: 7.42 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12960491111335748		[learning rate: 0.0025994]
	Learning Rate: 0.00259939
	LOSS [training: 0.12960491111335748 | validation: 0.29820488308372634]
	TIME [epoch: 7.46 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11336265719853132		[learning rate: 0.0025871]
	Learning Rate: 0.00258714
	LOSS [training: 0.11336265719853132 | validation: 0.2834074838484817]
	TIME [epoch: 7.42 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12776726827563867		[learning rate: 0.002575]
	Learning Rate: 0.00257495
	LOSS [training: 0.12776726827563867 | validation: 0.33287377543423535]
	TIME [epoch: 7.42 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11920020586859131		[learning rate: 0.0025628]
	Learning Rate: 0.00256282
	LOSS [training: 0.11920020586859131 | validation: 0.3050700389520503]
	TIME [epoch: 7.43 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10575987031801097		[learning rate: 0.0025507]
	Learning Rate: 0.00255074
	LOSS [training: 0.10575987031801097 | validation: 0.3139701848264578]
	TIME [epoch: 7.42 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12218205188191973		[learning rate: 0.0025387]
	Learning Rate: 0.00253872
	LOSS [training: 0.12218205188191973 | validation: 0.2827463632281332]
	TIME [epoch: 7.41 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12088798576235904		[learning rate: 0.0025268]
	Learning Rate: 0.00252676
	LOSS [training: 0.12088798576235904 | validation: 0.319375072922328]
	TIME [epoch: 7.42 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11661913999148094		[learning rate: 0.0025149]
	Learning Rate: 0.00251485
	LOSS [training: 0.11661913999148094 | validation: 0.31535981575914196]
	TIME [epoch: 7.42 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12222550750251576		[learning rate: 0.002503]
	Learning Rate: 0.002503
	LOSS [training: 0.12222550750251576 | validation: 0.31963709188938183]
	TIME [epoch: 7.42 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12116778088574934		[learning rate: 0.0024912]
	Learning Rate: 0.00249121
	LOSS [training: 0.12116778088574934 | validation: 0.3055570863473548]
	TIME [epoch: 7.43 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1283154996640672		[learning rate: 0.0024795]
	Learning Rate: 0.00247947
	LOSS [training: 0.1283154996640672 | validation: 0.3320810545621833]
	TIME [epoch: 7.42 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12714304532719933		[learning rate: 0.0024678]
	Learning Rate: 0.00246779
	LOSS [training: 0.12714304532719933 | validation: 0.33798129835999335]
	TIME [epoch: 7.42 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12859861133106507		[learning rate: 0.0024562]
	Learning Rate: 0.00245616
	LOSS [training: 0.12859861133106507 | validation: 0.30350597747018576]
	TIME [epoch: 7.42 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13517972801487543		[learning rate: 0.0024446]
	Learning Rate: 0.00244458
	LOSS [training: 0.13517972801487543 | validation: 0.2884289288325142]
	TIME [epoch: 7.42 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14252369083911065		[learning rate: 0.0024331]
	Learning Rate: 0.00243307
	LOSS [training: 0.14252369083911065 | validation: 0.34250686122670737]
	TIME [epoch: 7.43 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11996094160098128		[learning rate: 0.0024216]
	Learning Rate: 0.0024216
	LOSS [training: 0.11996094160098128 | validation: 0.3299945086728685]
	TIME [epoch: 7.42 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13740027376625455		[learning rate: 0.0024102]
	Learning Rate: 0.00241019
	LOSS [training: 0.13740027376625455 | validation: 0.30498320784711086]
	TIME [epoch: 7.46 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1281354513354139		[learning rate: 0.0023988]
	Learning Rate: 0.00239883
	LOSS [training: 0.1281354513354139 | validation: 0.3759976377348167]
	TIME [epoch: 7.42 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13783019240579678		[learning rate: 0.0023875]
	Learning Rate: 0.00238753
	LOSS [training: 0.13783019240579678 | validation: 0.31523459728126196]
	TIME [epoch: 7.42 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.133253856067094		[learning rate: 0.0023763]
	Learning Rate: 0.00237628
	LOSS [training: 0.133253856067094 | validation: 0.2869291401597576]
	TIME [epoch: 7.41 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12241934518637344		[learning rate: 0.0023651]
	Learning Rate: 0.00236508
	LOSS [training: 0.12241934518637344 | validation: 0.3226023424228859]
	TIME [epoch: 7.43 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13070995646419017		[learning rate: 0.0023539]
	Learning Rate: 0.00235394
	LOSS [training: 0.13070995646419017 | validation: 0.32587071904181936]
	TIME [epoch: 7.42 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10789526773953255		[learning rate: 0.0023428]
	Learning Rate: 0.00234285
	LOSS [training: 0.10789526773953255 | validation: 0.2787650237802401]
	TIME [epoch: 7.41 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1117208199702455		[learning rate: 0.0023318]
	Learning Rate: 0.00233181
	LOSS [training: 0.1117208199702455 | validation: 0.29986026120453807]
	TIME [epoch: 7.42 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11681128635694518		[learning rate: 0.0023208]
	Learning Rate: 0.00232082
	LOSS [training: 0.11681128635694518 | validation: 0.32776751596308873]
	TIME [epoch: 7.41 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12746043904391519		[learning rate: 0.0023099]
	Learning Rate: 0.00230988
	LOSS [training: 0.12746043904391519 | validation: 0.29870809003756343]
	TIME [epoch: 7.43 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11394908201046486		[learning rate: 0.002299]
	Learning Rate: 0.002299
	LOSS [training: 0.11394908201046486 | validation: 0.3591490774378872]
	TIME [epoch: 7.42 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1134285572284794		[learning rate: 0.0022882]
	Learning Rate: 0.00228816
	LOSS [training: 0.1134285572284794 | validation: 0.33809388350777425]
	TIME [epoch: 7.42 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13249068685593304		[learning rate: 0.0022774]
	Learning Rate: 0.00227738
	LOSS [training: 0.13249068685593304 | validation: 0.2843239481787726]
	TIME [epoch: 7.42 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12035225947857982		[learning rate: 0.0022667]
	Learning Rate: 0.00226665
	LOSS [training: 0.12035225947857982 | validation: 0.2904219874589327]
	TIME [epoch: 7.41 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12793537496633042		[learning rate: 0.002256]
	Learning Rate: 0.00225597
	LOSS [training: 0.12793537496633042 | validation: 0.3192039461704127]
	TIME [epoch: 7.41 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12816890275203147		[learning rate: 0.0022453]
	Learning Rate: 0.00224534
	LOSS [training: 0.12816890275203147 | validation: 0.3205082621219229]
	TIME [epoch: 7.43 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11688825906963063		[learning rate: 0.0022348]
	Learning Rate: 0.00223476
	LOSS [training: 0.11688825906963063 | validation: 0.33937946087950943]
	TIME [epoch: 7.42 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10915900276234071		[learning rate: 0.0022242]
	Learning Rate: 0.00222423
	LOSS [training: 0.10915900276234071 | validation: 0.31139446584790154]
	TIME [epoch: 7.42 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.113195185672719		[learning rate: 0.0022137]
	Learning Rate: 0.00221375
	LOSS [training: 0.113195185672719 | validation: 0.33504811744576984]
	TIME [epoch: 7.41 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13005144336089125		[learning rate: 0.0022033]
	Learning Rate: 0.00220332
	LOSS [training: 0.13005144336089125 | validation: 0.3201798939704845]
	TIME [epoch: 7.43 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1252827317503825		[learning rate: 0.0021929]
	Learning Rate: 0.00219293
	LOSS [training: 0.1252827317503825 | validation: 0.31475246687776276]
	TIME [epoch: 7.42 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11412067923950743		[learning rate: 0.0021826]
	Learning Rate: 0.0021826
	LOSS [training: 0.11412067923950743 | validation: 0.301474745530746]
	TIME [epoch: 7.43 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11348081374300426		[learning rate: 0.0021723]
	Learning Rate: 0.00217232
	LOSS [training: 0.11348081374300426 | validation: 0.2910603212748099]
	TIME [epoch: 7.41 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11457556852235765		[learning rate: 0.0021621]
	Learning Rate: 0.00216208
	LOSS [training: 0.11457556852235765 | validation: 0.2934378539243377]
	TIME [epoch: 7.42 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1077687700462964		[learning rate: 0.0021519]
	Learning Rate: 0.00215189
	LOSS [training: 0.1077687700462964 | validation: 0.3177412040742956]
	TIME [epoch: 7.41 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11830755942336711		[learning rate: 0.0021418]
	Learning Rate: 0.00214175
	LOSS [training: 0.11830755942336711 | validation: 0.33887675173373166]
	TIME [epoch: 7.42 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11563435777422151		[learning rate: 0.0021317]
	Learning Rate: 0.00213166
	LOSS [training: 0.11563435777422151 | validation: 0.2845168802003889]
	TIME [epoch: 7.42 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13850491093399347		[learning rate: 0.0021216]
	Learning Rate: 0.00212162
	LOSS [training: 0.13850491093399347 | validation: 0.303242749059398]
	TIME [epoch: 7.42 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12274605904570157		[learning rate: 0.0021116]
	Learning Rate: 0.00211162
	LOSS [training: 0.12274605904570157 | validation: 0.32757029559697115]
	TIME [epoch: 7.41 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11876863323569598		[learning rate: 0.0021017]
	Learning Rate: 0.00210167
	LOSS [training: 0.11876863323569598 | validation: 0.31792157655164355]
	TIME [epoch: 7.41 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13043780692900458		[learning rate: 0.0020918]
	Learning Rate: 0.00209176
	LOSS [training: 0.13043780692900458 | validation: 0.28132182505006015]
	TIME [epoch: 7.41 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11873923339627396		[learning rate: 0.0020819]
	Learning Rate: 0.00208191
	LOSS [training: 0.11873923339627396 | validation: 0.33653663269477974]
	TIME [epoch: 7.42 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14039848871385358		[learning rate: 0.0020721]
	Learning Rate: 0.0020721
	LOSS [training: 0.14039848871385358 | validation: 0.3591667962951369]
	TIME [epoch: 7.43 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12289876797149744		[learning rate: 0.0020623]
	Learning Rate: 0.00206233
	LOSS [training: 0.12289876797149744 | validation: 0.3394128000551676]
	TIME [epoch: 7.42 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12002694797931386		[learning rate: 0.0020526]
	Learning Rate: 0.00205262
	LOSS [training: 0.12002694797931386 | validation: 0.31515023663360203]
	TIME [epoch: 7.41 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12757200840548993		[learning rate: 0.0020429]
	Learning Rate: 0.00204294
	LOSS [training: 0.12757200840548993 | validation: 0.342563731451222]
	TIME [epoch: 7.41 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1292974081308749		[learning rate: 0.0020333]
	Learning Rate: 0.00203332
	LOSS [training: 0.1292974081308749 | validation: 0.3007182961713886]
	TIME [epoch: 7.41 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13769567112007364		[learning rate: 0.0020237]
	Learning Rate: 0.00202374
	LOSS [training: 0.13769567112007364 | validation: 0.31345278552264594]
	TIME [epoch: 7.5 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11535921169015564		[learning rate: 0.0020142]
	Learning Rate: 0.0020142
	LOSS [training: 0.11535921169015564 | validation: 0.2796102834887476]
	TIME [epoch: 7.42 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1242469540494218		[learning rate: 0.0020047]
	Learning Rate: 0.00200471
	LOSS [training: 0.1242469540494218 | validation: 0.30175747947744574]
	TIME [epoch: 7.42 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12099964428329027		[learning rate: 0.0019953]
	Learning Rate: 0.00199526
	LOSS [training: 0.12099964428329027 | validation: 0.3272805057330748]
	TIME [epoch: 7.42 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1134605066983809		[learning rate: 0.0019859]
	Learning Rate: 0.00198586
	LOSS [training: 0.1134605066983809 | validation: 0.2975267777487165]
	TIME [epoch: 7.41 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10591438686109624		[learning rate: 0.0019765]
	Learning Rate: 0.0019765
	LOSS [training: 0.10591438686109624 | validation: 0.3093401217740525]
	TIME [epoch: 7.42 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12040462585523085		[learning rate: 0.0019672]
	Learning Rate: 0.00196719
	LOSS [training: 0.12040462585523085 | validation: 0.3076061883897207]
	TIME [epoch: 7.43 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13751324357984168		[learning rate: 0.0019579]
	Learning Rate: 0.00195792
	LOSS [training: 0.13751324357984168 | validation: 0.317167154666832]
	TIME [epoch: 7.42 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1393571327925235		[learning rate: 0.0019487]
	Learning Rate: 0.00194869
	LOSS [training: 0.1393571327925235 | validation: 0.32235074574170774]
	TIME [epoch: 7.41 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13512451034561385		[learning rate: 0.0019395]
	Learning Rate: 0.00193951
	LOSS [training: 0.13512451034561385 | validation: 0.3566531435319573]
	TIME [epoch: 7.41 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1154090531753073		[learning rate: 0.0019304]
	Learning Rate: 0.00193037
	LOSS [training: 0.1154090531753073 | validation: 0.31426425998726315]
	TIME [epoch: 7.41 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12656410556120987		[learning rate: 0.0019213]
	Learning Rate: 0.00192128
	LOSS [training: 0.12656410556120987 | validation: 0.3222029730349206]
	TIME [epoch: 7.41 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12027144194753005		[learning rate: 0.0019122]
	Learning Rate: 0.00191222
	LOSS [training: 0.12027144194753005 | validation: 0.2925321299434691]
	TIME [epoch: 7.43 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11209291741182198		[learning rate: 0.0019032]
	Learning Rate: 0.00190321
	LOSS [training: 0.11209291741182198 | validation: 0.29914723889463646]
	TIME [epoch: 7.41 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12963101098401036		[learning rate: 0.0018942]
	Learning Rate: 0.00189424
	LOSS [training: 0.12963101098401036 | validation: 0.31018881297981454]
	TIME [epoch: 7.42 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10375194440300493		[learning rate: 0.0018853]
	Learning Rate: 0.00188532
	LOSS [training: 0.10375194440300493 | validation: 0.29738348509856527]
	TIME [epoch: 7.42 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11918868848237732		[learning rate: 0.0018764]
	Learning Rate: 0.00187643
	LOSS [training: 0.11918868848237732 | validation: 0.3025821966749908]
	TIME [epoch: 7.41 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13125126164377063		[learning rate: 0.0018676]
	Learning Rate: 0.00186759
	LOSS [training: 0.13125126164377063 | validation: 0.3215015535499258]
	TIME [epoch: 7.42 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11811741504264493		[learning rate: 0.0018588]
	Learning Rate: 0.00185879
	LOSS [training: 0.11811741504264493 | validation: 0.3231116437008006]
	TIME [epoch: 7.43 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11630227824183212		[learning rate: 0.00185]
	Learning Rate: 0.00185003
	LOSS [training: 0.11630227824183212 | validation: 0.31817689523155046]
	TIME [epoch: 7.42 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1686488978413573		[learning rate: 0.0018413]
	Learning Rate: 0.00184132
	LOSS [training: 0.1686488978413573 | validation: 0.3012475895201418]
	TIME [epoch: 7.41 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1182002894185676		[learning rate: 0.0018326]
	Learning Rate: 0.00183264
	LOSS [training: 0.1182002894185676 | validation: 0.3408113424178242]
	TIME [epoch: 7.42 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12780979024921116		[learning rate: 0.001824]
	Learning Rate: 0.001824
	LOSS [training: 0.12780979024921116 | validation: 0.30345388284129515]
	TIME [epoch: 7.41 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12071774388004791		[learning rate: 0.0018154]
	Learning Rate: 0.00181541
	LOSS [training: 0.12071774388004791 | validation: 0.3130552408698298]
	TIME [epoch: 7.42 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13923875823099588		[learning rate: 0.0018069]
	Learning Rate: 0.00180685
	LOSS [training: 0.13923875823099588 | validation: 0.2999929072585732]
	TIME [epoch: 7.42 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13114022048283822		[learning rate: 0.0017983]
	Learning Rate: 0.00179834
	LOSS [training: 0.13114022048283822 | validation: 0.29616985177164235]
	TIME [epoch: 7.42 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11552178041997607		[learning rate: 0.0017899]
	Learning Rate: 0.00178987
	LOSS [training: 0.11552178041997607 | validation: 0.2903809407829609]
	TIME [epoch: 7.41 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10683665174486273		[learning rate: 0.0017814]
	Learning Rate: 0.00178143
	LOSS [training: 0.10683665174486273 | validation: 0.31127099541318565]
	TIME [epoch: 7.42 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13113353201398678		[learning rate: 0.001773]
	Learning Rate: 0.00177304
	LOSS [training: 0.13113353201398678 | validation: 0.30339497149487016]
	TIME [epoch: 7.41 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12033371328036817		[learning rate: 0.0017647]
	Learning Rate: 0.00176468
	LOSS [training: 0.12033371328036817 | validation: 0.3172026493618911]
	TIME [epoch: 7.43 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12281750718393669		[learning rate: 0.0017564]
	Learning Rate: 0.00175637
	LOSS [training: 0.12281750718393669 | validation: 0.33658923564324283]
	TIME [epoch: 7.41 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11013718875125085		[learning rate: 0.0017481]
	Learning Rate: 0.00174809
	LOSS [training: 0.11013718875125085 | validation: 0.3175469859532348]
	TIME [epoch: 7.42 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12549429246768146		[learning rate: 0.0017399]
	Learning Rate: 0.00173985
	LOSS [training: 0.12549429246768146 | validation: 0.3016039025202021]
	TIME [epoch: 7.41 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12764071093887358		[learning rate: 0.0017317]
	Learning Rate: 0.00173166
	LOSS [training: 0.12764071093887358 | validation: 0.2811231396697313]
	TIME [epoch: 7.42 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11292719472032305		[learning rate: 0.0017235]
	Learning Rate: 0.0017235
	LOSS [training: 0.11292719472032305 | validation: 0.3078109421551785]
	TIME [epoch: 7.42 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.127284304743863		[learning rate: 0.0017154]
	Learning Rate: 0.00171537
	LOSS [training: 0.127284304743863 | validation: 0.3141819808644044]
	TIME [epoch: 7.44 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10529201820578954		[learning rate: 0.0017073]
	Learning Rate: 0.00170729
	LOSS [training: 0.10529201820578954 | validation: 0.30397402005651863]
	TIME [epoch: 7.41 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11629587604075359		[learning rate: 0.0016992]
	Learning Rate: 0.00169925
	LOSS [training: 0.11629587604075359 | validation: 0.31133802671075694]
	TIME [epoch: 7.42 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13579814627004452		[learning rate: 0.0016912]
	Learning Rate: 0.00169124
	LOSS [training: 0.13579814627004452 | validation: 0.293354560636133]
	TIME [epoch: 7.42 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12465305423842019		[learning rate: 0.0016833]
	Learning Rate: 0.00168327
	LOSS [training: 0.12465305423842019 | validation: 0.29468748547530915]
	TIME [epoch: 7.41 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12769404256823935		[learning rate: 0.0016753]
	Learning Rate: 0.00167534
	LOSS [training: 0.12769404256823935 | validation: 0.3259915175852116]
	TIME [epoch: 7.44 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12177109742636047		[learning rate: 0.0016674]
	Learning Rate: 0.00166744
	LOSS [training: 0.12177109742636047 | validation: 0.3054536924014425]
	TIME [epoch: 7.43 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11738589405994149		[learning rate: 0.0016596]
	Learning Rate: 0.00165959
	LOSS [training: 0.11738589405994149 | validation: 0.3093395497580061]
	TIME [epoch: 7.41 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12009471843609092		[learning rate: 0.0016518]
	Learning Rate: 0.00165177
	LOSS [training: 0.12009471843609092 | validation: 0.2807197556592748]
	TIME [epoch: 7.42 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1337617766672624		[learning rate: 0.001644]
	Learning Rate: 0.00164398
	LOSS [training: 0.1337617766672624 | validation: 0.3080463452785453]
	TIME [epoch: 7.41 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11469792501615522		[learning rate: 0.0016362]
	Learning Rate: 0.00163624
	LOSS [training: 0.11469792501615522 | validation: 0.30052958326282403]
	TIME [epoch: 7.41 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11083449598622737		[learning rate: 0.0016285]
	Learning Rate: 0.00162853
	LOSS [training: 0.11083449598622737 | validation: 0.31001055233061037]
	TIME [epoch: 7.42 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10637251524025151		[learning rate: 0.0016209]
	Learning Rate: 0.00162085
	LOSS [training: 0.10637251524025151 | validation: 0.30366519355833677]
	TIME [epoch: 7.42 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1423164191424454		[learning rate: 0.0016132]
	Learning Rate: 0.00161322
	LOSS [training: 0.1423164191424454 | validation: 0.2921696491999567]
	TIME [epoch: 7.41 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10770946262527512		[learning rate: 0.0016056]
	Learning Rate: 0.00160561
	LOSS [training: 0.10770946262527512 | validation: 0.2885905837209096]
	TIME [epoch: 7.42 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10586637400885354		[learning rate: 0.001598]
	Learning Rate: 0.00159805
	LOSS [training: 0.10586637400885354 | validation: 0.3026184309741932]
	TIME [epoch: 7.41 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11158063291513058		[learning rate: 0.0015905]
	Learning Rate: 0.00159052
	LOSS [training: 0.11158063291513058 | validation: 0.31734279811264066]
	TIME [epoch: 7.42 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11594604962966651		[learning rate: 0.001583]
	Learning Rate: 0.00158302
	LOSS [training: 0.11594604962966651 | validation: 0.3063380277508184]
	TIME [epoch: 7.44 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11161416889460225		[learning rate: 0.0015756]
	Learning Rate: 0.00157556
	LOSS [training: 0.11161416889460225 | validation: 0.3297020934940933]
	TIME [epoch: 7.41 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1390927204544472		[learning rate: 0.0015681]
	Learning Rate: 0.00156814
	LOSS [training: 0.1390927204544472 | validation: 0.3432604785263276]
	TIME [epoch: 7.45 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.125806862721361		[learning rate: 0.0015607]
	Learning Rate: 0.00156075
	LOSS [training: 0.125806862721361 | validation: 0.32644015066464444]
	TIME [epoch: 7.44 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13386401249991706		[learning rate: 0.0015534]
	Learning Rate: 0.0015534
	LOSS [training: 0.13386401249991706 | validation: 0.3076341056287297]
	TIME [epoch: 7.43 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1089764473496611		[learning rate: 0.0015461]
	Learning Rate: 0.00154608
	LOSS [training: 0.1089764473496611 | validation: 0.2909490757828425]
	TIME [epoch: 7.42 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12031373461749945		[learning rate: 0.0015388]
	Learning Rate: 0.00153879
	LOSS [training: 0.12031373461749945 | validation: 0.30778712589592966]
	TIME [epoch: 7.42 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1245310007527951		[learning rate: 0.0015315]
	Learning Rate: 0.00153154
	LOSS [training: 0.1245310007527951 | validation: 0.31034104034337645]
	TIME [epoch: 7.42 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.142754971199953		[learning rate: 0.0015243]
	Learning Rate: 0.00152432
	LOSS [training: 0.142754971199953 | validation: 0.30649050242662873]
	TIME [epoch: 7.41 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11233921219985807		[learning rate: 0.0015171]
	Learning Rate: 0.00151714
	LOSS [training: 0.11233921219985807 | validation: 0.3142599160029326]
	TIME [epoch: 7.45 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10943450877956505		[learning rate: 0.00151]
	Learning Rate: 0.00150999
	LOSS [training: 0.10943450877956505 | validation: 0.28465996804671795]
	TIME [epoch: 7.44 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11423458943808447		[learning rate: 0.0015029]
	Learning Rate: 0.00150288
	LOSS [training: 0.11423458943808447 | validation: 0.3232450423073503]
	TIME [epoch: 7.42 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14938737031111365		[learning rate: 0.0014958]
	Learning Rate: 0.00149579
	LOSS [training: 0.14938737031111365 | validation: 0.3155565209097665]
	TIME [epoch: 7.42 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11779849436825424		[learning rate: 0.0014887]
	Learning Rate: 0.00148875
	LOSS [training: 0.11779849436825424 | validation: 0.29539840911961696]
	TIME [epoch: 7.41 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10729186866608426		[learning rate: 0.0014817]
	Learning Rate: 0.00148173
	LOSS [training: 0.10729186866608426 | validation: 0.29583427796590483]
	TIME [epoch: 7.42 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10819050295264915		[learning rate: 0.0014747]
	Learning Rate: 0.00147475
	LOSS [training: 0.10819050295264915 | validation: 0.3349375546266675]
	TIME [epoch: 7.42 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11007391110448264		[learning rate: 0.0014678]
	Learning Rate: 0.0014678
	LOSS [training: 0.11007391110448264 | validation: 0.3307210501401734]
	TIME [epoch: 7.41 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11637448536092503		[learning rate: 0.0014609]
	Learning Rate: 0.00146088
	LOSS [training: 0.11637448536092503 | validation: 0.29126193158672653]
	TIME [epoch: 7.44 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1125922732724083		[learning rate: 0.001454]
	Learning Rate: 0.001454
	LOSS [training: 0.1125922732724083 | validation: 0.30601825736123556]
	TIME [epoch: 7.41 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11061671835491309		[learning rate: 0.0014471]
	Learning Rate: 0.00144715
	LOSS [training: 0.11061671835491309 | validation: 0.3110451358731966]
	TIME [epoch: 7.41 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10377958437051953		[learning rate: 0.0014403]
	Learning Rate: 0.00144033
	LOSS [training: 0.10377958437051953 | validation: 0.3075297923841721]
	TIME [epoch: 7.41 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11068467689058446		[learning rate: 0.0014335]
	Learning Rate: 0.00143354
	LOSS [training: 0.11068467689058446 | validation: 0.29204359244125466]
	TIME [epoch: 7.41 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0995687247561693		[learning rate: 0.0014268]
	Learning Rate: 0.00142679
	LOSS [training: 0.0995687247561693 | validation: 0.28906707371719137]
	TIME [epoch: 7.42 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11855325642966907		[learning rate: 0.0014201]
	Learning Rate: 0.00142006
	LOSS [training: 0.11855325642966907 | validation: 0.2922507593736502]
	TIME [epoch: 7.43 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11733429151426267		[learning rate: 0.0014134]
	Learning Rate: 0.00141337
	LOSS [training: 0.11733429151426267 | validation: 0.30772626931305713]
	TIME [epoch: 7.42 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10937482311119784		[learning rate: 0.0014067]
	Learning Rate: 0.00140671
	LOSS [training: 0.10937482311119784 | validation: 0.2982704125917282]
	TIME [epoch: 7.41 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11586038571335676		[learning rate: 0.0014001]
	Learning Rate: 0.00140008
	LOSS [training: 0.11586038571335676 | validation: 0.31913895543376414]
	TIME [epoch: 7.41 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11580900310812409		[learning rate: 0.0013935]
	Learning Rate: 0.00139349
	LOSS [training: 0.11580900310812409 | validation: 0.29578373852840734]
	TIME [epoch: 7.42 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11385704750059018		[learning rate: 0.0013869]
	Learning Rate: 0.00138692
	LOSS [training: 0.11385704750059018 | validation: 0.29763162833881557]
	TIME [epoch: 7.44 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.122305301683984		[learning rate: 0.0013804]
	Learning Rate: 0.00138038
	LOSS [training: 0.122305301683984 | validation: 0.32557808303947244]
	TIME [epoch: 7.48 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12346684563781908		[learning rate: 0.0013739]
	Learning Rate: 0.00137388
	LOSS [training: 0.12346684563781908 | validation: 0.3099019298012782]
	TIME [epoch: 7.41 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10876306252351328		[learning rate: 0.0013674]
	Learning Rate: 0.00136741
	LOSS [training: 0.10876306252351328 | validation: 0.2956880624052161]
	TIME [epoch: 7.42 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1235561435763962		[learning rate: 0.001361]
	Learning Rate: 0.00136096
	LOSS [training: 0.1235561435763962 | validation: 0.2816979365725664]
	TIME [epoch: 7.42 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10739869525016003		[learning rate: 0.0013545]
	Learning Rate: 0.00135455
	LOSS [training: 0.10739869525016003 | validation: 0.32676536265699846]
	TIME [epoch: 7.41 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14386950991994668		[learning rate: 0.0013482]
	Learning Rate: 0.00134817
	LOSS [training: 0.14386950991994668 | validation: 0.2854150207464836]
	TIME [epoch: 7.43 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11038162185769326		[learning rate: 0.0013418]
	Learning Rate: 0.00134181
	LOSS [training: 0.11038162185769326 | validation: 0.30572027109194166]
	TIME [epoch: 7.42 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11414436369448742		[learning rate: 0.0013355]
	Learning Rate: 0.00133549
	LOSS [training: 0.11414436369448742 | validation: 0.33611092172778445]
	TIME [epoch: 7.41 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11582772637976371		[learning rate: 0.0013292]
	Learning Rate: 0.0013292
	LOSS [training: 0.11582772637976371 | validation: 0.2951703296968329]
	TIME [epoch: 7.41 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12284193860299475		[learning rate: 0.0013229]
	Learning Rate: 0.00132293
	LOSS [training: 0.12284193860299475 | validation: 0.29702097532363875]
	TIME [epoch: 7.41 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11596717121613406		[learning rate: 0.0013167]
	Learning Rate: 0.0013167
	LOSS [training: 0.11596717121613406 | validation: 0.311398275638466]
	TIME [epoch: 7.42 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12050979743846368		[learning rate: 0.0013105]
	Learning Rate: 0.0013105
	LOSS [training: 0.12050979743846368 | validation: 0.2828024722351553]
	TIME [epoch: 7.43 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10608285147987694		[learning rate: 0.0013043]
	Learning Rate: 0.00130432
	LOSS [training: 0.10608285147987694 | validation: 0.31982153458207063]
	TIME [epoch: 7.42 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10683887516361412		[learning rate: 0.0012982]
	Learning Rate: 0.00129818
	LOSS [training: 0.10683887516361412 | validation: 0.29966485647172375]
	TIME [epoch: 7.41 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11061235165865377		[learning rate: 0.0012921]
	Learning Rate: 0.00129206
	LOSS [training: 0.11061235165865377 | validation: 0.31598152189203804]
	TIME [epoch: 7.42 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11170463148990678		[learning rate: 0.001286]
	Learning Rate: 0.00128597
	LOSS [training: 0.11170463148990678 | validation: 0.33925731653222824]
	TIME [epoch: 7.42 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11749086957841715		[learning rate: 0.0012799]
	Learning Rate: 0.00127991
	LOSS [training: 0.11749086957841715 | validation: 0.29253697568587167]
	TIME [epoch: 7.42 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10933619866140028		[learning rate: 0.0012739]
	Learning Rate: 0.00127388
	LOSS [training: 0.10933619866140028 | validation: 0.32282718805620375]
	TIME [epoch: 7.43 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10784511433118649		[learning rate: 0.0012679]
	Learning Rate: 0.00126788
	LOSS [training: 0.10784511433118649 | validation: 0.3015300470359566]
	TIME [epoch: 7.42 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10796409154586994		[learning rate: 0.0012619]
	Learning Rate: 0.0012619
	LOSS [training: 0.10796409154586994 | validation: 0.2826841612609241]
	TIME [epoch: 7.41 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12699726836082914		[learning rate: 0.001256]
	Learning Rate: 0.00125596
	LOSS [training: 0.12699726836082914 | validation: 0.2856370303157958]
	TIME [epoch: 7.41 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14213547538622223		[learning rate: 0.00125]
	Learning Rate: 0.00125004
	LOSS [training: 0.14213547538622223 | validation: 0.29259832587027357]
	TIME [epoch: 7.42 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10553360775849294		[learning rate: 0.0012441]
	Learning Rate: 0.00124415
	LOSS [training: 0.10553360775849294 | validation: 0.3059043138580034]
	TIME [epoch: 7.45 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10702221490873247		[learning rate: 0.0012383]
	Learning Rate: 0.00123828
	LOSS [training: 0.10702221490873247 | validation: 0.3216345058464454]
	TIME [epoch: 7.41 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11223273236203546		[learning rate: 0.0012324]
	Learning Rate: 0.00123245
	LOSS [training: 0.11223273236203546 | validation: 0.293012285709679]
	TIME [epoch: 7.41 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11769197701895306		[learning rate: 0.0012266]
	Learning Rate: 0.00122664
	LOSS [training: 0.11769197701895306 | validation: 0.30477647134604036]
	TIME [epoch: 7.44 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1198631403365718		[learning rate: 0.0012209]
	Learning Rate: 0.00122086
	LOSS [training: 0.1198631403365718 | validation: 0.3001626705084072]
	TIME [epoch: 7.46 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12438315561719199		[learning rate: 0.0012151]
	Learning Rate: 0.00121511
	LOSS [training: 0.12438315561719199 | validation: 0.308157699195161]
	TIME [epoch: 7.43 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09500769972988739		[learning rate: 0.0012094]
	Learning Rate: 0.00120938
	LOSS [training: 0.09500769972988739 | validation: 0.32225609997487964]
	TIME [epoch: 7.42 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11098789626250832		[learning rate: 0.0012037]
	Learning Rate: 0.00120368
	LOSS [training: 0.11098789626250832 | validation: 0.3076209427560925]
	TIME [epoch: 7.44 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13021150884046728		[learning rate: 0.001198]
	Learning Rate: 0.00119801
	LOSS [training: 0.13021150884046728 | validation: 0.2893127085807371]
	TIME [epoch: 7.42 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10699970714416707		[learning rate: 0.0011924]
	Learning Rate: 0.00119237
	LOSS [training: 0.10699970714416707 | validation: 0.3060274334944157]
	TIME [epoch: 7.45 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12078967142344449		[learning rate: 0.0011867]
	Learning Rate: 0.00118675
	LOSS [training: 0.12078967142344449 | validation: 0.29878084634654867]
	TIME [epoch: 7.41 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10609922372731852		[learning rate: 0.0011812]
	Learning Rate: 0.00118116
	LOSS [training: 0.10609922372731852 | validation: 0.30753228751474937]
	TIME [epoch: 7.44 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10890878563576081		[learning rate: 0.0011756]
	Learning Rate: 0.00117559
	LOSS [training: 0.10890878563576081 | validation: 0.291608121453357]
	TIME [epoch: 7.44 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10531139074037332		[learning rate: 0.0011701]
	Learning Rate: 0.00117005
	LOSS [training: 0.10531139074037332 | validation: 0.30790849243337415]
	TIME [epoch: 7.43 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11232030873638792		[learning rate: 0.0011645]
	Learning Rate: 0.00116454
	LOSS [training: 0.11232030873638792 | validation: 0.31054979646025255]
	TIME [epoch: 7.43 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12461631149505575		[learning rate: 0.0011591]
	Learning Rate: 0.00115905
	LOSS [training: 0.12461631149505575 | validation: 0.2964683593290269]
	TIME [epoch: 7.44 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11106218284758285		[learning rate: 0.0011536]
	Learning Rate: 0.00115359
	LOSS [training: 0.11106218284758285 | validation: 0.3012450305164605]
	TIME [epoch: 7.43 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11913436842265743		[learning rate: 0.0011482]
	Learning Rate: 0.00114815
	LOSS [training: 0.11913436842265743 | validation: 0.3101594234714502]
	TIME [epoch: 7.45 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v14_20240718_190302/states/model_facs_v4_dec2b_2dpca_v14_496.pth
Halted early. No improvement in validation loss for 200 epochs.
Finished training in 3577.839 seconds.
