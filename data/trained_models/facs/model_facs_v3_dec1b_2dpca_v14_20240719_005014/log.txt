Args:
Namespace(name='model_facs_v3_dec1b_2dpca_v14', outdir='out/model_training/model_facs_v3_dec1b_2dpca_v14', training_data='data/training_data/facs_v3/pca/dec1_fitonsubset/transition1_subset_epi_tr_ce_an_pc12/training', validation_data='data/training_data/facs_v3/pca/dec1_fitonsubset/transition1_subset_epi_tr_ce_an_pc12/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=10, batch_size=50, patience=200, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, quadratic_a=1.0, quadratic_b=1.0, ndims=2, nparams=2, nsigs=2, ncells=200, ncells_sample=200, model_do_sample=False, dt=0.005, dt_schedule='stepped', dt_schedule_bounds=[50, 500, 1000], dt_schedule_scales=[0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', kernel='multiscale', bw_range=[0.2, 0.5, 0.9, 1.1, 1.3, 1.5, 2.0], optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 265168150

Training model...

Saving initial model state to: out/model_training/model_facs_v3_dec1b_2dpca_v14_20240719_005014/states/model_facs_v3_dec1b_2dpca_v14_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.4227302686881973		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4227302686881973 | validation: 1.2487562792931026]
	TIME [epoch: 21.3 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14_20240719_005014/states/model_facs_v3_dec1b_2dpca_v14_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.281000446883504		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.281000446883504 | validation: 1.0843665690011086]
	TIME [epoch: 5.86 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14_20240719_005014/states/model_facs_v3_dec1b_2dpca_v14_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.2164283109785137		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2164283109785137 | validation: 1.0191242153136468]
	TIME [epoch: 5.85 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14_20240719_005014/states/model_facs_v3_dec1b_2dpca_v14_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.1085386670595858		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1085386670595858 | validation: 0.9973682027870471]
	TIME [epoch: 5.86 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14_20240719_005014/states/model_facs_v3_dec1b_2dpca_v14_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.058910112508061		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.058910112508061 | validation: 0.9005551191260415]
	TIME [epoch: 5.87 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14_20240719_005014/states/model_facs_v3_dec1b_2dpca_v14_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.9957424435713226		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9957424435713226 | validation: 0.8868638728069851]
	TIME [epoch: 5.83 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14_20240719_005014/states/model_facs_v3_dec1b_2dpca_v14_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.9563091415338606		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9563091415338606 | validation: 0.8458228723828378]
	TIME [epoch: 5.86 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14_20240719_005014/states/model_facs_v3_dec1b_2dpca_v14_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.874580813544669		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.874580813544669 | validation: 0.7948831244610001]
	TIME [epoch: 5.86 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14_20240719_005014/states/model_facs_v3_dec1b_2dpca_v14_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.8842195063767656		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8842195063767656 | validation: 0.8512920026185078]
	TIME [epoch: 5.86 sec]
EPOCH 10/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.8031178183554936		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8031178183554936 | validation: 0.7361447343713937]
	TIME [epoch: 5.86 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14_20240719_005014/states/model_facs_v3_dec1b_2dpca_v14_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.7198947885274514		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7198947885274514 | validation: 0.7645792627511385]
	TIME [epoch: 5.86 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.6555035923196096		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6555035923196096 | validation: 0.6238778763284842]
	TIME [epoch: 5.87 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14_20240719_005014/states/model_facs_v3_dec1b_2dpca_v14_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.6158315899911174		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6158315899911174 | validation: 0.6220817209322898]
	TIME [epoch: 5.85 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14_20240719_005014/states/model_facs_v3_dec1b_2dpca_v14_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.6344577351962641		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6344577351962641 | validation: 0.5548338084064324]
	TIME [epoch: 5.86 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14_20240719_005014/states/model_facs_v3_dec1b_2dpca_v14_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5615785026261353		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5615785026261353 | validation: 0.48957159838012865]
	TIME [epoch: 5.86 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14_20240719_005014/states/model_facs_v3_dec1b_2dpca_v14_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.6541687309733084		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6541687309733084 | validation: 0.4664149621256904]
	TIME [epoch: 5.87 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14_20240719_005014/states/model_facs_v3_dec1b_2dpca_v14_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5205281958645579		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5205281958645579 | validation: 0.5111050349941842]
	TIME [epoch: 5.85 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4832812272108196		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4832812272108196 | validation: 0.4431761501293635]
	TIME [epoch: 5.86 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14_20240719_005014/states/model_facs_v3_dec1b_2dpca_v14_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.45403862518019616		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.45403862518019616 | validation: 0.4211280408899782]
	TIME [epoch: 5.84 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14_20240719_005014/states/model_facs_v3_dec1b_2dpca_v14_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.47398252752904385		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.47398252752904385 | validation: 0.4567824402520876]
	TIME [epoch: 5.86 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4735464108627241		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4735464108627241 | validation: 0.38348037486718833]
	TIME [epoch: 5.88 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14_20240719_005014/states/model_facs_v3_dec1b_2dpca_v14_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4486631768291991		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4486631768291991 | validation: 0.3889126169752542]
	TIME [epoch: 5.84 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4587834239483088		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4587834239483088 | validation: 0.3692099873449658]
	TIME [epoch: 5.84 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14_20240719_005014/states/model_facs_v3_dec1b_2dpca_v14_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3965446117505546		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3965446117505546 | validation: 0.346261691253534]
	TIME [epoch: 5.86 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14_20240719_005014/states/model_facs_v3_dec1b_2dpca_v14_24.pth
	Model improved!!!
EPOCH 25/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.40068168487930494		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.40068168487930494 | validation: 0.3292095736244307]
	TIME [epoch: 5.85 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14_20240719_005014/states/model_facs_v3_dec1b_2dpca_v14_25.pth
	Model improved!!!
EPOCH 26/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.375143898641957		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.375143898641957 | validation: 0.35501279751744036]
	TIME [epoch: 5.84 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4037573039109537		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4037573039109537 | validation: 0.33342910158576783]
	TIME [epoch: 5.83 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3806756627313203		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3806756627313203 | validation: 0.3083169219727182]
	TIME [epoch: 5.84 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14_20240719_005014/states/model_facs_v3_dec1b_2dpca_v14_28.pth
	Model improved!!!
EPOCH 29/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3625733514870619		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3625733514870619 | validation: 0.3071910556075969]
	TIME [epoch: 5.87 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14_20240719_005014/states/model_facs_v3_dec1b_2dpca_v14_29.pth
	Model improved!!!
EPOCH 30/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.38733039844022293		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.38733039844022293 | validation: 0.3620922509196808]
	TIME [epoch: 5.85 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.35302374967760963		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.35302374967760963 | validation: 0.3098521165704443]
	TIME [epoch: 5.85 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3663174112666881		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3663174112666881 | validation: 0.3456224411143637]
	TIME [epoch: 5.85 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.37402158708141586		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.37402158708141586 | validation: 0.2885159857268953]
	TIME [epoch: 5.85 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14_20240719_005014/states/model_facs_v3_dec1b_2dpca_v14_33.pth
	Model improved!!!
EPOCH 34/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3354463998946762		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3354463998946762 | validation: 0.33172393693617125]
	TIME [epoch: 5.87 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.35510606955021595		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.35510606955021595 | validation: 0.36696789653260425]
	TIME [epoch: 5.87 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.36460870376331916		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.36460870376331916 | validation: 0.2801022269387692]
	TIME [epoch: 5.85 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14_20240719_005014/states/model_facs_v3_dec1b_2dpca_v14_36.pth
	Model improved!!!
EPOCH 37/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3268361926972973		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3268361926972973 | validation: 0.28459359547186475]
	TIME [epoch: 5.85 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3099970872604758		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3099970872604758 | validation: 0.305405648779754]
	TIME [epoch: 5.83 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3338421402792297		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3338421402792297 | validation: 0.294919586482003]
	TIME [epoch: 5.84 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3262235291646381		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3262235291646381 | validation: 0.3138295636268722]
	TIME [epoch: 5.83 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3462608716507882		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3462608716507882 | validation: 0.27363829735409706]
	TIME [epoch: 5.85 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14_20240719_005014/states/model_facs_v3_dec1b_2dpca_v14_41.pth
	Model improved!!!
EPOCH 42/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3477919248215921		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3477919248215921 | validation: 0.2700267263883374]
	TIME [epoch: 5.87 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14_20240719_005014/states/model_facs_v3_dec1b_2dpca_v14_42.pth
	Model improved!!!
EPOCH 43/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.32169742761763415		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.32169742761763415 | validation: 0.27277760578519017]
	TIME [epoch: 5.85 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3335268238510786		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3335268238510786 | validation: 0.26776779750746116]
	TIME [epoch: 5.84 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14_20240719_005014/states/model_facs_v3_dec1b_2dpca_v14_44.pth
	Model improved!!!
EPOCH 45/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3184444617107263		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3184444617107263 | validation: 0.2565811916735369]
	TIME [epoch: 5.85 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14_20240719_005014/states/model_facs_v3_dec1b_2dpca_v14_45.pth
	Model improved!!!
EPOCH 46/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3175927966536729		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3175927966536729 | validation: 0.27656995159271097]
	TIME [epoch: 5.84 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.32683819586290214		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.32683819586290214 | validation: 0.2668257565762772]
	TIME [epoch: 5.82 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3146172087403015		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3146172087403015 | validation: 0.26910066636955027]
	TIME [epoch: 5.86 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.31597313719855774		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.31597313719855774 | validation: 0.26775952416803017]
	TIME [epoch: 5.84 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.32722671850375135		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.32722671850375135 | validation: 0.27255892602554993]
	TIME [epoch: 5.85 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.32085177000384396		[learning rate: 0.0099705]
	Learning Rate: 0.00997052
	LOSS [training: 0.32085177000384396 | validation: 0.24837167598812546]
	TIME [epoch: 24.7 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14_20240719_005014/states/model_facs_v3_dec1b_2dpca_v14_51.pth
	Model improved!!!
EPOCH 52/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3089651690903141		[learning rate: 0.0099353]
	Learning Rate: 0.00993527
	LOSS [training: 0.3089651690903141 | validation: 0.25947791797966835]
	TIME [epoch: 11.2 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.30581529491716286		[learning rate: 0.0099001]
	Learning Rate: 0.00990013
	LOSS [training: 0.30581529491716286 | validation: 0.2552946432251074]
	TIME [epoch: 11.2 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3203479788458796		[learning rate: 0.0098651]
	Learning Rate: 0.00986512
	LOSS [training: 0.3203479788458796 | validation: 0.2640790926361076]
	TIME [epoch: 11.2 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2964440826466838		[learning rate: 0.0098302]
	Learning Rate: 0.00983024
	LOSS [training: 0.2964440826466838 | validation: 0.27615944054273284]
	TIME [epoch: 11.2 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3177904432904746		[learning rate: 0.0097955]
	Learning Rate: 0.00979548
	LOSS [training: 0.3177904432904746 | validation: 0.25354134641165904]
	TIME [epoch: 11.2 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3003383272513162		[learning rate: 0.0097608]
	Learning Rate: 0.00976084
	LOSS [training: 0.3003383272513162 | validation: 0.26795843726392815]
	TIME [epoch: 11.2 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2962093058079976		[learning rate: 0.0097263]
	Learning Rate: 0.00972632
	LOSS [training: 0.2962093058079976 | validation: 0.24276510737845564]
	TIME [epoch: 11.1 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14_20240719_005014/states/model_facs_v3_dec1b_2dpca_v14_58.pth
	Model improved!!!
EPOCH 59/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3182657780798744		[learning rate: 0.0096919]
	Learning Rate: 0.00969193
	LOSS [training: 0.3182657780798744 | validation: 0.29590109278013765]
	TIME [epoch: 11.2 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.31364132060329225		[learning rate: 0.0096577]
	Learning Rate: 0.00965766
	LOSS [training: 0.31364132060329225 | validation: 0.24980883501579423]
	TIME [epoch: 11.2 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2888869248686878		[learning rate: 0.0096235]
	Learning Rate: 0.00962351
	LOSS [training: 0.2888869248686878 | validation: 0.24308698497567863]
	TIME [epoch: 11.2 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29121440832426715		[learning rate: 0.0095895]
	Learning Rate: 0.00958948
	LOSS [training: 0.29121440832426715 | validation: 0.24039403094768078]
	TIME [epoch: 11.2 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14_20240719_005014/states/model_facs_v3_dec1b_2dpca_v14_62.pth
	Model improved!!!
EPOCH 63/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2936241530671703		[learning rate: 0.0095556]
	Learning Rate: 0.00955557
	LOSS [training: 0.2936241530671703 | validation: 0.24163529430414005]
	TIME [epoch: 11.2 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2968225636389777		[learning rate: 0.0095218]
	Learning Rate: 0.00952177
	LOSS [training: 0.2968225636389777 | validation: 0.23411613095770703]
	TIME [epoch: 11.2 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14_20240719_005014/states/model_facs_v3_dec1b_2dpca_v14_64.pth
	Model improved!!!
EPOCH 65/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2969502073592847		[learning rate: 0.0094881]
	Learning Rate: 0.0094881
	LOSS [training: 0.2969502073592847 | validation: 0.24628832862792813]
	TIME [epoch: 11.2 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.30093493950144595		[learning rate: 0.0094546]
	Learning Rate: 0.00945455
	LOSS [training: 0.30093493950144595 | validation: 0.25324023171684396]
	TIME [epoch: 11.2 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29880208245648265		[learning rate: 0.0094211]
	Learning Rate: 0.00942112
	LOSS [training: 0.29880208245648265 | validation: 0.2756979633026325]
	TIME [epoch: 11.2 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28290478872002955		[learning rate: 0.0093878]
	Learning Rate: 0.00938781
	LOSS [training: 0.28290478872002955 | validation: 0.23987835855090683]
	TIME [epoch: 11.2 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2974210364140302		[learning rate: 0.0093546]
	Learning Rate: 0.00935461
	LOSS [training: 0.2974210364140302 | validation: 0.25631541081557907]
	TIME [epoch: 11.2 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2904434693316807		[learning rate: 0.0093215]
	Learning Rate: 0.00932153
	LOSS [training: 0.2904434693316807 | validation: 0.23945057384640728]
	TIME [epoch: 11.2 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3000388053232708		[learning rate: 0.0092886]
	Learning Rate: 0.00928857
	LOSS [training: 0.3000388053232708 | validation: 0.26051477782676313]
	TIME [epoch: 11.2 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3027806998052403		[learning rate: 0.0092557]
	Learning Rate: 0.00925572
	LOSS [training: 0.3027806998052403 | validation: 0.25821847400022424]
	TIME [epoch: 11.2 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2893665657331948		[learning rate: 0.009223]
	Learning Rate: 0.00922299
	LOSS [training: 0.2893665657331948 | validation: 0.2522096273001838]
	TIME [epoch: 11.2 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2936096064399559		[learning rate: 0.0091904]
	Learning Rate: 0.00919038
	LOSS [training: 0.2936096064399559 | validation: 0.24217537717215185]
	TIME [epoch: 11.2 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2911664313671109		[learning rate: 0.0091579]
	Learning Rate: 0.00915788
	LOSS [training: 0.2911664313671109 | validation: 0.24183284643533823]
	TIME [epoch: 11.2 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28190496188625624		[learning rate: 0.0091255]
	Learning Rate: 0.00912549
	LOSS [training: 0.28190496188625624 | validation: 0.26678134261107356]
	TIME [epoch: 11.2 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.31113713513367336		[learning rate: 0.0090932]
	Learning Rate: 0.00909323
	LOSS [training: 0.31113713513367336 | validation: 0.22994350648460005]
	TIME [epoch: 11.1 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14_20240719_005014/states/model_facs_v3_dec1b_2dpca_v14_77.pth
	Model improved!!!
EPOCH 78/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29070150278254014		[learning rate: 0.0090611]
	Learning Rate: 0.00906107
	LOSS [training: 0.29070150278254014 | validation: 0.2457028711270106]
	TIME [epoch: 11.2 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2991373547071981		[learning rate: 0.009029]
	Learning Rate: 0.00902903
	LOSS [training: 0.2991373547071981 | validation: 0.2229093483428426]
	TIME [epoch: 11.1 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14_20240719_005014/states/model_facs_v3_dec1b_2dpca_v14_79.pth
	Model improved!!!
EPOCH 80/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2844978137353549		[learning rate: 0.0089971]
	Learning Rate: 0.0089971
	LOSS [training: 0.2844978137353549 | validation: 0.22996714265106338]
	TIME [epoch: 11.2 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29901834980145275		[learning rate: 0.0089653]
	Learning Rate: 0.00896528
	LOSS [training: 0.29901834980145275 | validation: 0.22951035036601755]
	TIME [epoch: 11.2 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28521349269715884		[learning rate: 0.0089336]
	Learning Rate: 0.00893358
	LOSS [training: 0.28521349269715884 | validation: 0.23437394249498836]
	TIME [epoch: 11.1 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27860270408088345		[learning rate: 0.008902]
	Learning Rate: 0.00890199
	LOSS [training: 0.27860270408088345 | validation: 0.23889246980849171]
	TIME [epoch: 11.1 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2922513367086186		[learning rate: 0.0088705]
	Learning Rate: 0.00887051
	LOSS [training: 0.2922513367086186 | validation: 0.2203107733382852]
	TIME [epoch: 11.2 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14_20240719_005014/states/model_facs_v3_dec1b_2dpca_v14_84.pth
	Model improved!!!
EPOCH 85/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28952894167825133		[learning rate: 0.0088391]
	Learning Rate: 0.00883914
	LOSS [training: 0.28952894167825133 | validation: 0.2313594654194208]
	TIME [epoch: 11.2 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2830781604112448		[learning rate: 0.0088079]
	Learning Rate: 0.00880789
	LOSS [training: 0.2830781604112448 | validation: 0.23083518207166262]
	TIME [epoch: 11.2 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2803219062262395		[learning rate: 0.0087767]
	Learning Rate: 0.00877674
	LOSS [training: 0.2803219062262395 | validation: 0.23896523695752422]
	TIME [epoch: 11.2 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2893934590435202		[learning rate: 0.0087457]
	Learning Rate: 0.00874571
	LOSS [training: 0.2893934590435202 | validation: 0.22814941225113344]
	TIME [epoch: 11.1 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2870353654656302		[learning rate: 0.0087148]
	Learning Rate: 0.00871478
	LOSS [training: 0.2870353654656302 | validation: 0.2127667350531679]
	TIME [epoch: 11.1 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14_20240719_005014/states/model_facs_v3_dec1b_2dpca_v14_89.pth
	Model improved!!!
EPOCH 90/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27379126755047595		[learning rate: 0.008684]
	Learning Rate: 0.00868396
	LOSS [training: 0.27379126755047595 | validation: 0.23970384714630216]
	TIME [epoch: 11.2 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27760098258026017		[learning rate: 0.0086533]
	Learning Rate: 0.00865326
	LOSS [training: 0.27760098258026017 | validation: 0.222487471288951]
	TIME [epoch: 11.2 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2980121968636245		[learning rate: 0.0086227]
	Learning Rate: 0.00862265
	LOSS [training: 0.2980121968636245 | validation: 0.2514645425310874]
	TIME [epoch: 11.2 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27822821043770524		[learning rate: 0.0085922]
	Learning Rate: 0.00859216
	LOSS [training: 0.27822821043770524 | validation: 0.22559132178253916]
	TIME [epoch: 11.2 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28995229961022595		[learning rate: 0.0085618]
	Learning Rate: 0.00856178
	LOSS [training: 0.28995229961022595 | validation: 0.2277598684683107]
	TIME [epoch: 11.2 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28008094630190805		[learning rate: 0.0085315]
	Learning Rate: 0.0085315
	LOSS [training: 0.28008094630190805 | validation: 0.22285369051001394]
	TIME [epoch: 11.2 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27925006842206845		[learning rate: 0.0085013]
	Learning Rate: 0.00850134
	LOSS [training: 0.27925006842206845 | validation: 0.22204597714654736]
	TIME [epoch: 11.2 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27688332596980486		[learning rate: 0.0084713]
	Learning Rate: 0.00847127
	LOSS [training: 0.27688332596980486 | validation: 0.22464719898291902]
	TIME [epoch: 11.2 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2805688357683127		[learning rate: 0.0084413]
	Learning Rate: 0.00844132
	LOSS [training: 0.2805688357683127 | validation: 0.2248514394079919]
	TIME [epoch: 11.2 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27811210183687946		[learning rate: 0.0084115]
	Learning Rate: 0.00841147
	LOSS [training: 0.27811210183687946 | validation: 0.229543709462415]
	TIME [epoch: 11.2 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27459990809158324		[learning rate: 0.0083817]
	Learning Rate: 0.00838172
	LOSS [training: 0.27459990809158324 | validation: 0.2296863931667676]
	TIME [epoch: 11.2 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29189350361742006		[learning rate: 0.0083521]
	Learning Rate: 0.00835208
	LOSS [training: 0.29189350361742006 | validation: 0.21924430676130352]
	TIME [epoch: 11.2 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28481335651014134		[learning rate: 0.0083225]
	Learning Rate: 0.00832255
	LOSS [training: 0.28481335651014134 | validation: 0.2174046524700223]
	TIME [epoch: 11.2 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29370472120283514		[learning rate: 0.0082931]
	Learning Rate: 0.00829312
	LOSS [training: 0.29370472120283514 | validation: 0.21431806552094068]
	TIME [epoch: 11.2 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2675696835028467		[learning rate: 0.0082638]
	Learning Rate: 0.00826379
	LOSS [training: 0.2675696835028467 | validation: 0.21455815148733565]
	TIME [epoch: 11.2 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27270140877553345		[learning rate: 0.0082346]
	Learning Rate: 0.00823457
	LOSS [training: 0.27270140877553345 | validation: 0.23385561353486678]
	TIME [epoch: 11.2 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29387571483509317		[learning rate: 0.0082055]
	Learning Rate: 0.00820545
	LOSS [training: 0.29387571483509317 | validation: 0.22071362575745557]
	TIME [epoch: 11.2 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28507321356269594		[learning rate: 0.0081764]
	Learning Rate: 0.00817644
	LOSS [training: 0.28507321356269594 | validation: 0.20738936287364668]
	TIME [epoch: 11.2 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14_20240719_005014/states/model_facs_v3_dec1b_2dpca_v14_107.pth
	Model improved!!!
EPOCH 108/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2780685308223129		[learning rate: 0.0081475]
	Learning Rate: 0.00814752
	LOSS [training: 0.2780685308223129 | validation: 0.209497165486695]
	TIME [epoch: 11.2 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2814302499882873		[learning rate: 0.0081187]
	Learning Rate: 0.00811871
	LOSS [training: 0.2814302499882873 | validation: 0.25183190883060474]
	TIME [epoch: 11.2 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2928399356866193		[learning rate: 0.00809]
	Learning Rate: 0.00809
	LOSS [training: 0.2928399356866193 | validation: 0.22537328899616887]
	TIME [epoch: 11.2 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27516495273507596		[learning rate: 0.0080614]
	Learning Rate: 0.0080614
	LOSS [training: 0.27516495273507596 | validation: 0.2241630383712901]
	TIME [epoch: 11.2 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.271436923799426		[learning rate: 0.0080329]
	Learning Rate: 0.00803289
	LOSS [training: 0.271436923799426 | validation: 0.2304584616046696]
	TIME [epoch: 11.1 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2792822833844206		[learning rate: 0.0080045]
	Learning Rate: 0.00800448
	LOSS [training: 0.2792822833844206 | validation: 0.22267478815226335]
	TIME [epoch: 11.1 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2702372660656676		[learning rate: 0.0079762]
	Learning Rate: 0.00797618
	LOSS [training: 0.2702372660656676 | validation: 0.23276221992258223]
	TIME [epoch: 11.1 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28219210123559674		[learning rate: 0.007948]
	Learning Rate: 0.00794797
	LOSS [training: 0.28219210123559674 | validation: 0.2205554352216049]
	TIME [epoch: 11.1 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28111860050953935		[learning rate: 0.0079199]
	Learning Rate: 0.00791987
	LOSS [training: 0.28111860050953935 | validation: 0.2187788773124233]
	TIME [epoch: 11.2 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27538283894553767		[learning rate: 0.0078919]
	Learning Rate: 0.00789186
	LOSS [training: 0.27538283894553767 | validation: 0.21526138505034606]
	TIME [epoch: 11.2 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27994786512240893		[learning rate: 0.007864]
	Learning Rate: 0.00786395
	LOSS [training: 0.27994786512240893 | validation: 0.22193278387721965]
	TIME [epoch: 11.2 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26361679936033905		[learning rate: 0.0078361]
	Learning Rate: 0.00783615
	LOSS [training: 0.26361679936033905 | validation: 0.22440607413849034]
	TIME [epoch: 11.2 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2853613009238176		[learning rate: 0.0078084]
	Learning Rate: 0.00780844
	LOSS [training: 0.2853613009238176 | validation: 0.22053985239405544]
	TIME [epoch: 11.1 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2723965673073747		[learning rate: 0.0077808]
	Learning Rate: 0.00778083
	LOSS [training: 0.2723965673073747 | validation: 0.23077636898358883]
	TIME [epoch: 11.1 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2688337588588403		[learning rate: 0.0077533]
	Learning Rate: 0.00775331
	LOSS [training: 0.2688337588588403 | validation: 0.2247592578847574]
	TIME [epoch: 11.2 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27726927360010195		[learning rate: 0.0077259]
	Learning Rate: 0.00772589
	LOSS [training: 0.27726927360010195 | validation: 0.22152161090382894]
	TIME [epoch: 11.2 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2762225766930276		[learning rate: 0.0076986]
	Learning Rate: 0.00769857
	LOSS [training: 0.2762225766930276 | validation: 0.221536913093469]
	TIME [epoch: 11.2 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27827835366344106		[learning rate: 0.0076714]
	Learning Rate: 0.00767135
	LOSS [training: 0.27827835366344106 | validation: 0.21860068600779176]
	TIME [epoch: 11.2 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26479621402231457		[learning rate: 0.0076442]
	Learning Rate: 0.00764422
	LOSS [training: 0.26479621402231457 | validation: 0.21563283585474907]
	TIME [epoch: 11.2 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2775696859989978		[learning rate: 0.0076172]
	Learning Rate: 0.00761719
	LOSS [training: 0.2775696859989978 | validation: 0.22910396858832835]
	TIME [epoch: 11.2 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2722210217329902		[learning rate: 0.0075903]
	Learning Rate: 0.00759025
	LOSS [training: 0.2722210217329902 | validation: 0.2206997880397413]
	TIME [epoch: 11.2 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26869544622135866		[learning rate: 0.0075634]
	Learning Rate: 0.00756341
	LOSS [training: 0.26869544622135866 | validation: 0.22102087237179568]
	TIME [epoch: 11.2 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25927863236942894		[learning rate: 0.0075367]
	Learning Rate: 0.00753667
	LOSS [training: 0.25927863236942894 | validation: 0.2280955309569094]
	TIME [epoch: 11.1 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28102184233398303		[learning rate: 0.00751]
	Learning Rate: 0.00751002
	LOSS [training: 0.28102184233398303 | validation: 0.24090593029889235]
	TIME [epoch: 11.2 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28391109315035773		[learning rate: 0.0074835]
	Learning Rate: 0.00748346
	LOSS [training: 0.28391109315035773 | validation: 0.20886381192520606]
	TIME [epoch: 11.1 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27463535797063643		[learning rate: 0.007457]
	Learning Rate: 0.007457
	LOSS [training: 0.27463535797063643 | validation: 0.22915769490231455]
	TIME [epoch: 11.2 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27167477376931537		[learning rate: 0.0074306]
	Learning Rate: 0.00743063
	LOSS [training: 0.27167477376931537 | validation: 0.22410213514004845]
	TIME [epoch: 11.1 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2930161123794974		[learning rate: 0.0074044]
	Learning Rate: 0.00740435
	LOSS [training: 0.2930161123794974 | validation: 0.22444682507697927]
	TIME [epoch: 11.2 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2621953066644515		[learning rate: 0.0073782]
	Learning Rate: 0.00737817
	LOSS [training: 0.2621953066644515 | validation: 0.21588409964347943]
	TIME [epoch: 11.2 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28449816934062755		[learning rate: 0.0073521]
	Learning Rate: 0.00735208
	LOSS [training: 0.28449816934062755 | validation: 0.20322409168431546]
	TIME [epoch: 11.2 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14_20240719_005014/states/model_facs_v3_dec1b_2dpca_v14_137.pth
	Model improved!!!
EPOCH 138/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25534022759646086		[learning rate: 0.0073261]
	Learning Rate: 0.00732608
	LOSS [training: 0.25534022759646086 | validation: 0.21133229676713833]
	TIME [epoch: 11.2 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25673311319543807		[learning rate: 0.0073002]
	Learning Rate: 0.00730018
	LOSS [training: 0.25673311319543807 | validation: 0.22034815019837403]
	TIME [epoch: 11.1 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.279083118133225		[learning rate: 0.0072744]
	Learning Rate: 0.00727436
	LOSS [training: 0.279083118133225 | validation: 0.21808718477004674]
	TIME [epoch: 11.2 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2729093788429863		[learning rate: 0.0072486]
	Learning Rate: 0.00724864
	LOSS [training: 0.2729093788429863 | validation: 0.21411024268652895]
	TIME [epoch: 11.2 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2700717324599325		[learning rate: 0.007223]
	Learning Rate: 0.007223
	LOSS [training: 0.2700717324599325 | validation: 0.22797347036661014]
	TIME [epoch: 11.2 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26463087359793713		[learning rate: 0.0071975]
	Learning Rate: 0.00719746
	LOSS [training: 0.26463087359793713 | validation: 0.2115394360869499]
	TIME [epoch: 11.2 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2613880154126929		[learning rate: 0.007172]
	Learning Rate: 0.00717201
	LOSS [training: 0.2613880154126929 | validation: 0.2147615459437311]
	TIME [epoch: 11.2 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25886917505830004		[learning rate: 0.0071467]
	Learning Rate: 0.00714665
	LOSS [training: 0.25886917505830004 | validation: 0.22632276006244761]
	TIME [epoch: 11.2 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2726911199763991		[learning rate: 0.0071214]
	Learning Rate: 0.00712138
	LOSS [training: 0.2726911199763991 | validation: 0.21836306257150578]
	TIME [epoch: 11.2 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2604510038888375		[learning rate: 0.0070962]
	Learning Rate: 0.0070962
	LOSS [training: 0.2604510038888375 | validation: 0.21203871345322706]
	TIME [epoch: 11.2 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2683835932816348		[learning rate: 0.0070711]
	Learning Rate: 0.0070711
	LOSS [training: 0.2683835932816348 | validation: 0.22915682895862693]
	TIME [epoch: 11.2 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2666864817035202		[learning rate: 0.0070461]
	Learning Rate: 0.0070461
	LOSS [training: 0.2666864817035202 | validation: 0.21905090557374676]
	TIME [epoch: 11.2 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26179671580190345		[learning rate: 0.0070212]
	Learning Rate: 0.00702118
	LOSS [training: 0.26179671580190345 | validation: 0.2187787722330164]
	TIME [epoch: 11.2 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2651878385455026		[learning rate: 0.0069964]
	Learning Rate: 0.00699635
	LOSS [training: 0.2651878385455026 | validation: 0.22611885119407232]
	TIME [epoch: 11.2 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2883456344743615		[learning rate: 0.0069716]
	Learning Rate: 0.00697161
	LOSS [training: 0.2883456344743615 | validation: 0.2122211945397617]
	TIME [epoch: 11.2 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2735421193347342		[learning rate: 0.006947]
	Learning Rate: 0.00694696
	LOSS [training: 0.2735421193347342 | validation: 0.21217837831179046]
	TIME [epoch: 11.2 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.258942293158697		[learning rate: 0.0069224]
	Learning Rate: 0.00692239
	LOSS [training: 0.258942293158697 | validation: 0.21915880075766694]
	TIME [epoch: 11.2 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27338448651757097		[learning rate: 0.0068979]
	Learning Rate: 0.00689792
	LOSS [training: 0.27338448651757097 | validation: 0.22705757560433648]
	TIME [epoch: 11.2 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26948572046516167		[learning rate: 0.0068735]
	Learning Rate: 0.00687352
	LOSS [training: 0.26948572046516167 | validation: 0.21851293531087798]
	TIME [epoch: 11.2 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.261937143813006		[learning rate: 0.0068492]
	Learning Rate: 0.00684922
	LOSS [training: 0.261937143813006 | validation: 0.21104539831461722]
	TIME [epoch: 11.2 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26489923614201494		[learning rate: 0.006825]
	Learning Rate: 0.006825
	LOSS [training: 0.26489923614201494 | validation: 0.20999962343818374]
	TIME [epoch: 11.2 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26358850078907675		[learning rate: 0.0068009]
	Learning Rate: 0.00680086
	LOSS [training: 0.26358850078907675 | validation: 0.20892430198704579]
	TIME [epoch: 11.2 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2605434767940488		[learning rate: 0.0067768]
	Learning Rate: 0.00677681
	LOSS [training: 0.2605434767940488 | validation: 0.21816737828388613]
	TIME [epoch: 11.2 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26092674099251856		[learning rate: 0.0067529]
	Learning Rate: 0.00675285
	LOSS [training: 0.26092674099251856 | validation: 0.2305351240554181]
	TIME [epoch: 11.2 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2650414019399801		[learning rate: 0.006729]
	Learning Rate: 0.00672897
	LOSS [training: 0.2650414019399801 | validation: 0.24250074977238345]
	TIME [epoch: 11.2 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28258403182772024		[learning rate: 0.0067052]
	Learning Rate: 0.00670518
	LOSS [training: 0.28258403182772024 | validation: 0.21064947879655677]
	TIME [epoch: 11.2 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2559709688447999		[learning rate: 0.0066815]
	Learning Rate: 0.00668147
	LOSS [training: 0.2559709688447999 | validation: 0.220461121810292]
	TIME [epoch: 11.2 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27933463047157353		[learning rate: 0.0066578]
	Learning Rate: 0.00665784
	LOSS [training: 0.27933463047157353 | validation: 0.21546005316818428]
	TIME [epoch: 11.2 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2643376705168598		[learning rate: 0.0066343]
	Learning Rate: 0.0066343
	LOSS [training: 0.2643376705168598 | validation: 0.20334206823833698]
	TIME [epoch: 11.2 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26909589524859745		[learning rate: 0.0066108]
	Learning Rate: 0.00661084
	LOSS [training: 0.26909589524859745 | validation: 0.21461173561282884]
	TIME [epoch: 11.2 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.261361577004626		[learning rate: 0.0065875]
	Learning Rate: 0.00658746
	LOSS [training: 0.261361577004626 | validation: 0.22618149344890806]
	TIME [epoch: 11.2 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2640149920256949		[learning rate: 0.0065642]
	Learning Rate: 0.00656416
	LOSS [training: 0.2640149920256949 | validation: 0.23693439059785834]
	TIME [epoch: 11.2 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2646692499432027		[learning rate: 0.006541]
	Learning Rate: 0.00654095
	LOSS [training: 0.2646692499432027 | validation: 0.21976611849955532]
	TIME [epoch: 11.2 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2586060064707551		[learning rate: 0.0065178]
	Learning Rate: 0.00651782
	LOSS [training: 0.2586060064707551 | validation: 0.22040587720269977]
	TIME [epoch: 11.2 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2565619927929307		[learning rate: 0.0064948]
	Learning Rate: 0.00649477
	LOSS [training: 0.2565619927929307 | validation: 0.2188844766470528]
	TIME [epoch: 11.2 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.266811742134983		[learning rate: 0.0064718]
	Learning Rate: 0.00647181
	LOSS [training: 0.266811742134983 | validation: 0.2024083931818125]
	TIME [epoch: 11.2 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14_20240719_005014/states/model_facs_v3_dec1b_2dpca_v14_173.pth
	Model improved!!!
EPOCH 174/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.260012130406092		[learning rate: 0.0064489]
	Learning Rate: 0.00644892
	LOSS [training: 0.260012130406092 | validation: 0.23000286500139744]
	TIME [epoch: 11.2 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2645435440284265		[learning rate: 0.0064261]
	Learning Rate: 0.00642612
	LOSS [training: 0.2645435440284265 | validation: 0.22706063550628425]
	TIME [epoch: 11.2 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2580035852930927		[learning rate: 0.0064034]
	Learning Rate: 0.00640339
	LOSS [training: 0.2580035852930927 | validation: 0.22306789797769927]
	TIME [epoch: 11.2 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26044144848376		[learning rate: 0.0063808]
	Learning Rate: 0.00638075
	LOSS [training: 0.26044144848376 | validation: 0.21411822472779818]
	TIME [epoch: 11.2 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2617255608548894		[learning rate: 0.0063582]
	Learning Rate: 0.00635819
	LOSS [training: 0.2617255608548894 | validation: 0.21226619419969966]
	TIME [epoch: 11.2 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2617789798375194		[learning rate: 0.0063357]
	Learning Rate: 0.0063357
	LOSS [training: 0.2617789798375194 | validation: 0.2127458489876636]
	TIME [epoch: 11.2 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2759631928466972		[learning rate: 0.0063133]
	Learning Rate: 0.0063133
	LOSS [training: 0.2759631928466972 | validation: 0.21315499104866445]
	TIME [epoch: 11.2 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25722005727185915		[learning rate: 0.006291]
	Learning Rate: 0.00629097
	LOSS [training: 0.25722005727185915 | validation: 0.21046017707350767]
	TIME [epoch: 11.2 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26161747390857576		[learning rate: 0.0062687]
	Learning Rate: 0.00626873
	LOSS [training: 0.26161747390857576 | validation: 0.23141178847502078]
	TIME [epoch: 11.2 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2617090938345884		[learning rate: 0.0062466]
	Learning Rate: 0.00624656
	LOSS [training: 0.2617090938345884 | validation: 0.21989751047955944]
	TIME [epoch: 11.2 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2586995194874758		[learning rate: 0.0062245]
	Learning Rate: 0.00622447
	LOSS [training: 0.2586995194874758 | validation: 0.21970091143455067]
	TIME [epoch: 11.2 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2689065139979622		[learning rate: 0.0062025]
	Learning Rate: 0.00620246
	LOSS [training: 0.2689065139979622 | validation: 0.22301287632011943]
	TIME [epoch: 11.2 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26538752467954646		[learning rate: 0.0061805]
	Learning Rate: 0.00618053
	LOSS [training: 0.26538752467954646 | validation: 0.2211632474685914]
	TIME [epoch: 11.2 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2634343007717348		[learning rate: 0.0061587]
	Learning Rate: 0.00615867
	LOSS [training: 0.2634343007717348 | validation: 0.21259565888839452]
	TIME [epoch: 11.2 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2616888642265411		[learning rate: 0.0061369]
	Learning Rate: 0.00613689
	LOSS [training: 0.2616888642265411 | validation: 0.21375411000431832]
	TIME [epoch: 11.2 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26242058245848154		[learning rate: 0.0061152]
	Learning Rate: 0.00611519
	LOSS [training: 0.26242058245848154 | validation: 0.22817423064352432]
	TIME [epoch: 11.2 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26691003446674016		[learning rate: 0.0060936]
	Learning Rate: 0.00609357
	LOSS [training: 0.26691003446674016 | validation: 0.22155565623204235]
	TIME [epoch: 11.2 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26529816240152665		[learning rate: 0.006072]
	Learning Rate: 0.00607202
	LOSS [training: 0.26529816240152665 | validation: 0.20349846640317257]
	TIME [epoch: 11.2 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26391302822505247		[learning rate: 0.0060505]
	Learning Rate: 0.00605055
	LOSS [training: 0.26391302822505247 | validation: 0.2132056382405926]
	TIME [epoch: 11.2 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2586562407899811		[learning rate: 0.0060292]
	Learning Rate: 0.00602915
	LOSS [training: 0.2586562407899811 | validation: 0.22087624952391666]
	TIME [epoch: 11.2 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25689620363593985		[learning rate: 0.0060078]
	Learning Rate: 0.00600783
	LOSS [training: 0.25689620363593985 | validation: 0.21920157512207877]
	TIME [epoch: 11.2 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.274950754581041		[learning rate: 0.0059866]
	Learning Rate: 0.00598659
	LOSS [training: 0.274950754581041 | validation: 0.2152599751235318]
	TIME [epoch: 11.2 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26762448576721326		[learning rate: 0.0059654]
	Learning Rate: 0.00596542
	LOSS [training: 0.26762448576721326 | validation: 0.20736083441800587]
	TIME [epoch: 11.2 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.268321139839374		[learning rate: 0.0059443]
	Learning Rate: 0.00594433
	LOSS [training: 0.268321139839374 | validation: 0.21548159802930567]
	TIME [epoch: 11.2 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2678138816377767		[learning rate: 0.0059233]
	Learning Rate: 0.0059233
	LOSS [training: 0.2678138816377767 | validation: 0.22084599798648882]
	TIME [epoch: 11.2 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.251363512977713		[learning rate: 0.0059024]
	Learning Rate: 0.00590236
	LOSS [training: 0.251363512977713 | validation: 0.22400874190657755]
	TIME [epoch: 11.2 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25678565201620085		[learning rate: 0.0058815]
	Learning Rate: 0.00588149
	LOSS [training: 0.25678565201620085 | validation: 0.2256650961337127]
	TIME [epoch: 11.2 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25967205743283905		[learning rate: 0.0058607]
	Learning Rate: 0.00586069
	LOSS [training: 0.25967205743283905 | validation: 0.21967619610164682]
	TIME [epoch: 11.2 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26364251542175327		[learning rate: 0.00584]
	Learning Rate: 0.00583996
	LOSS [training: 0.26364251542175327 | validation: 0.21068788081416687]
	TIME [epoch: 11.2 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2547238109893598		[learning rate: 0.0058193]
	Learning Rate: 0.00581931
	LOSS [training: 0.2547238109893598 | validation: 0.22071969461896454]
	TIME [epoch: 11.2 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2505985703199209		[learning rate: 0.0057987]
	Learning Rate: 0.00579874
	LOSS [training: 0.2505985703199209 | validation: 0.21669960524497286]
	TIME [epoch: 11.2 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25203427037230025		[learning rate: 0.0057782]
	Learning Rate: 0.00577823
	LOSS [training: 0.25203427037230025 | validation: 0.2209814981613425]
	TIME [epoch: 11.2 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2618535976156913		[learning rate: 0.0057578]
	Learning Rate: 0.0057578
	LOSS [training: 0.2618535976156913 | validation: 0.21205997427924078]
	TIME [epoch: 11.2 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25540021644805605		[learning rate: 0.0057374]
	Learning Rate: 0.00573744
	LOSS [training: 0.25540021644805605 | validation: 0.22347957646170605]
	TIME [epoch: 11.2 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2689357720880365		[learning rate: 0.0057171]
	Learning Rate: 0.00571715
	LOSS [training: 0.2689357720880365 | validation: 0.21482954464673026]
	TIME [epoch: 11.2 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2517865524734857		[learning rate: 0.0056969]
	Learning Rate: 0.00569693
	LOSS [training: 0.2517865524734857 | validation: 0.223039767801247]
	TIME [epoch: 11.2 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.257832505989364		[learning rate: 0.0056768]
	Learning Rate: 0.00567679
	LOSS [training: 0.257832505989364 | validation: 0.2179577481675447]
	TIME [epoch: 11.2 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2668218595914517		[learning rate: 0.0056567]
	Learning Rate: 0.00565671
	LOSS [training: 0.2668218595914517 | validation: 0.21825904297585358]
	TIME [epoch: 11.2 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2609412441474326		[learning rate: 0.0056367]
	Learning Rate: 0.00563671
	LOSS [training: 0.2609412441474326 | validation: 0.21104783167986235]
	TIME [epoch: 11.2 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2570791975103586		[learning rate: 0.0056168]
	Learning Rate: 0.00561678
	LOSS [training: 0.2570791975103586 | validation: 0.21659652725145725]
	TIME [epoch: 11.2 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2674808297043884		[learning rate: 0.0055969]
	Learning Rate: 0.00559691
	LOSS [training: 0.2674808297043884 | validation: 0.21325968095004474]
	TIME [epoch: 11.2 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2622352684761861		[learning rate: 0.0055771]
	Learning Rate: 0.00557712
	LOSS [training: 0.2622352684761861 | validation: 0.2186420833445196]
	TIME [epoch: 11.2 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2588604753643526		[learning rate: 0.0055574]
	Learning Rate: 0.0055574
	LOSS [training: 0.2588604753643526 | validation: 0.22746345197825643]
	TIME [epoch: 11.2 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26738927236237614		[learning rate: 0.0055378]
	Learning Rate: 0.00553775
	LOSS [training: 0.26738927236237614 | validation: 0.20964116950398415]
	TIME [epoch: 11.2 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2560675168084145		[learning rate: 0.0055182]
	Learning Rate: 0.00551817
	LOSS [training: 0.2560675168084145 | validation: 0.22948766397843384]
	TIME [epoch: 11.2 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26682698177889		[learning rate: 0.0054987]
	Learning Rate: 0.00549865
	LOSS [training: 0.26682698177889 | validation: 0.2194995671306456]
	TIME [epoch: 11.2 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2557632182602751		[learning rate: 0.0054792]
	Learning Rate: 0.00547921
	LOSS [training: 0.2557632182602751 | validation: 0.21496583600715402]
	TIME [epoch: 11.2 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27668464412873783		[learning rate: 0.0054598]
	Learning Rate: 0.00545983
	LOSS [training: 0.27668464412873783 | validation: 0.2180285577949066]
	TIME [epoch: 11.2 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.250926617344699		[learning rate: 0.0054405]
	Learning Rate: 0.00544053
	LOSS [training: 0.250926617344699 | validation: 0.21397496427234558]
	TIME [epoch: 11.2 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2619666003833651		[learning rate: 0.0054213]
	Learning Rate: 0.00542129
	LOSS [training: 0.2619666003833651 | validation: 0.21364343273021652]
	TIME [epoch: 11.2 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.257654728526283		[learning rate: 0.0054021]
	Learning Rate: 0.00540212
	LOSS [training: 0.257654728526283 | validation: 0.22032132235611393]
	TIME [epoch: 11.2 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26638584053045017		[learning rate: 0.005383]
	Learning Rate: 0.00538302
	LOSS [training: 0.26638584053045017 | validation: 0.21753452739679613]
	TIME [epoch: 11.2 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25727146337038714		[learning rate: 0.005364]
	Learning Rate: 0.00536398
	LOSS [training: 0.25727146337038714 | validation: 0.20892949120379947]
	TIME [epoch: 11.2 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2552750894486079		[learning rate: 0.005345]
	Learning Rate: 0.00534501
	LOSS [training: 0.2552750894486079 | validation: 0.22524282197718795]
	TIME [epoch: 11.2 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2557650722207336		[learning rate: 0.0053261]
	Learning Rate: 0.00532611
	LOSS [training: 0.2557650722207336 | validation: 0.2249519079054095]
	TIME [epoch: 11.2 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2597592826664687		[learning rate: 0.0053073]
	Learning Rate: 0.00530728
	LOSS [training: 0.2597592826664687 | validation: 0.21846031794915763]
	TIME [epoch: 11.2 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25378295394280653		[learning rate: 0.0052885]
	Learning Rate: 0.00528851
	LOSS [training: 0.25378295394280653 | validation: 0.21153278315072344]
	TIME [epoch: 11.2 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2659855254798571		[learning rate: 0.0052698]
	Learning Rate: 0.00526981
	LOSS [training: 0.2659855254798571 | validation: 0.20965721689240352]
	TIME [epoch: 11.2 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26610393440397845		[learning rate: 0.0052512]
	Learning Rate: 0.00525117
	LOSS [training: 0.26610393440397845 | validation: 0.21844551578431184]
	TIME [epoch: 11.2 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26641398938900546		[learning rate: 0.0052326]
	Learning Rate: 0.0052326
	LOSS [training: 0.26641398938900546 | validation: 0.2194664875196019]
	TIME [epoch: 11.2 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2666097248059507		[learning rate: 0.0052141]
	Learning Rate: 0.0052141
	LOSS [training: 0.2666097248059507 | validation: 0.2184268463804237]
	TIME [epoch: 11.2 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2551097702150226		[learning rate: 0.0051957]
	Learning Rate: 0.00519566
	LOSS [training: 0.2551097702150226 | validation: 0.2085994031432134]
	TIME [epoch: 11.2 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2676735560921119		[learning rate: 0.0051773]
	Learning Rate: 0.00517729
	LOSS [training: 0.2676735560921119 | validation: 0.22365562885863755]
	TIME [epoch: 11.2 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2555552363908626		[learning rate: 0.005159]
	Learning Rate: 0.00515898
	LOSS [training: 0.2555552363908626 | validation: 0.21295013374456553]
	TIME [epoch: 11.2 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2485458210275976		[learning rate: 0.0051407]
	Learning Rate: 0.00514074
	LOSS [training: 0.2485458210275976 | validation: 0.21233670673499933]
	TIME [epoch: 11.2 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2656908250700036		[learning rate: 0.0051226]
	Learning Rate: 0.00512256
	LOSS [training: 0.2656908250700036 | validation: 0.20645385521273094]
	TIME [epoch: 11.2 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2572944203877238		[learning rate: 0.0051044]
	Learning Rate: 0.00510445
	LOSS [training: 0.2572944203877238 | validation: 0.212654455011907]
	TIME [epoch: 11.2 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2566485458435312		[learning rate: 0.0050864]
	Learning Rate: 0.0050864
	LOSS [training: 0.2566485458435312 | validation: 0.21332018053077428]
	TIME [epoch: 11.2 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25327125738486306		[learning rate: 0.0050684]
	Learning Rate: 0.00506841
	LOSS [training: 0.25327125738486306 | validation: 0.2085403495166545]
	TIME [epoch: 11.2 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25129689668261807		[learning rate: 0.0050505]
	Learning Rate: 0.00505049
	LOSS [training: 0.25129689668261807 | validation: 0.22165074287653633]
	TIME [epoch: 11.2 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26392008527169236		[learning rate: 0.0050326]
	Learning Rate: 0.00503263
	LOSS [training: 0.26392008527169236 | validation: 0.2190445354329018]
	TIME [epoch: 11.2 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26255978628522864		[learning rate: 0.0050148]
	Learning Rate: 0.00501483
	LOSS [training: 0.26255978628522864 | validation: 0.21190766106311507]
	TIME [epoch: 11.2 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26148536461451405		[learning rate: 0.0049971]
	Learning Rate: 0.0049971
	LOSS [training: 0.26148536461451405 | validation: 0.20791708970812778]
	TIME [epoch: 11.2 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2493778674773912		[learning rate: 0.0049794]
	Learning Rate: 0.00497943
	LOSS [training: 0.2493778674773912 | validation: 0.20826324858607226]
	TIME [epoch: 11.2 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24958290025014573		[learning rate: 0.0049618]
	Learning Rate: 0.00496182
	LOSS [training: 0.24958290025014573 | validation: 0.21117349435069038]
	TIME [epoch: 11.2 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24856896397370534		[learning rate: 0.0049443]
	Learning Rate: 0.00494427
	LOSS [training: 0.24856896397370534 | validation: 0.22129080834745488]
	TIME [epoch: 11.2 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2595739370114549		[learning rate: 0.0049268]
	Learning Rate: 0.00492679
	LOSS [training: 0.2595739370114549 | validation: 0.21143189426564452]
	TIME [epoch: 11.2 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2614572636806753		[learning rate: 0.0049094]
	Learning Rate: 0.00490937
	LOSS [training: 0.2614572636806753 | validation: 0.22363022843750718]
	TIME [epoch: 11.2 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2527719584911737		[learning rate: 0.004892]
	Learning Rate: 0.00489201
	LOSS [training: 0.2527719584911737 | validation: 0.2184680328390492]
	TIME [epoch: 11.2 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2557232761015617		[learning rate: 0.0048747]
	Learning Rate: 0.00487471
	LOSS [training: 0.2557232761015617 | validation: 0.2089255263036201]
	TIME [epoch: 11.2 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2566592931017328		[learning rate: 0.0048575]
	Learning Rate: 0.00485747
	LOSS [training: 0.2566592931017328 | validation: 0.20527228010040388]
	TIME [epoch: 11.2 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2563970156493532		[learning rate: 0.0048403]
	Learning Rate: 0.00484029
	LOSS [training: 0.2563970156493532 | validation: 0.23120646980953374]
	TIME [epoch: 11.2 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2602672131358997		[learning rate: 0.0048232]
	Learning Rate: 0.00482318
	LOSS [training: 0.2602672131358997 | validation: 0.20770926082069682]
	TIME [epoch: 11.2 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2643730568214599		[learning rate: 0.0048061]
	Learning Rate: 0.00480612
	LOSS [training: 0.2643730568214599 | validation: 0.21347389006335232]
	TIME [epoch: 11.2 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2587856920767761		[learning rate: 0.0047891]
	Learning Rate: 0.00478913
	LOSS [training: 0.2587856920767761 | validation: 0.2052267806633629]
	TIME [epoch: 11.2 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25866434188094933		[learning rate: 0.0047722]
	Learning Rate: 0.00477219
	LOSS [training: 0.25866434188094933 | validation: 0.21088851114706492]
	TIME [epoch: 11.2 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26101856228852244		[learning rate: 0.0047553]
	Learning Rate: 0.00475532
	LOSS [training: 0.26101856228852244 | validation: 0.21919331151888838]
	TIME [epoch: 11.2 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25824135029823764		[learning rate: 0.0047385]
	Learning Rate: 0.0047385
	LOSS [training: 0.25824135029823764 | validation: 0.21058030786619913]
	TIME [epoch: 11.2 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2526282997658483		[learning rate: 0.0047217]
	Learning Rate: 0.00472175
	LOSS [training: 0.2526282997658483 | validation: 0.21722944503115665]
	TIME [epoch: 11.2 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2665187511050518		[learning rate: 0.004705]
	Learning Rate: 0.00470505
	LOSS [training: 0.2665187511050518 | validation: 0.21847203682337724]
	TIME [epoch: 11.2 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2634447157988668		[learning rate: 0.0046884]
	Learning Rate: 0.00468841
	LOSS [training: 0.2634447157988668 | validation: 0.21107674491432388]
	TIME [epoch: 11.2 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25440862981680806		[learning rate: 0.0046718]
	Learning Rate: 0.00467183
	LOSS [training: 0.25440862981680806 | validation: 0.20943330194088436]
	TIME [epoch: 11.2 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2574503755421915		[learning rate: 0.0046553]
	Learning Rate: 0.00465531
	LOSS [training: 0.2574503755421915 | validation: 0.20937181198487717]
	TIME [epoch: 11.2 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2528977808143928		[learning rate: 0.0046388]
	Learning Rate: 0.00463885
	LOSS [training: 0.2528977808143928 | validation: 0.22066990720882673]
	TIME [epoch: 11.2 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25040192713712817		[learning rate: 0.0046224]
	Learning Rate: 0.00462245
	LOSS [training: 0.25040192713712817 | validation: 0.21785359858802375]
	TIME [epoch: 11.2 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2521995277105012		[learning rate: 0.0046061]
	Learning Rate: 0.0046061
	LOSS [training: 0.2521995277105012 | validation: 0.21633769548918735]
	TIME [epoch: 11.2 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25870032757935246		[learning rate: 0.0045898]
	Learning Rate: 0.00458981
	LOSS [training: 0.25870032757935246 | validation: 0.21463908372661883]
	TIME [epoch: 11.2 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26142829488860014		[learning rate: 0.0045736]
	Learning Rate: 0.00457358
	LOSS [training: 0.26142829488860014 | validation: 0.21037189782071133]
	TIME [epoch: 11.2 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2557985489919327		[learning rate: 0.0045574]
	Learning Rate: 0.00455741
	LOSS [training: 0.2557985489919327 | validation: 0.21789850467278055]
	TIME [epoch: 11.2 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25352528911829514		[learning rate: 0.0045413]
	Learning Rate: 0.00454129
	LOSS [training: 0.25352528911829514 | validation: 0.2144782284459546]
	TIME [epoch: 11.2 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2547571297366328		[learning rate: 0.0045252]
	Learning Rate: 0.00452523
	LOSS [training: 0.2547571297366328 | validation: 0.21177416850369318]
	TIME [epoch: 11.2 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24561802899404828		[learning rate: 0.0045092]
	Learning Rate: 0.00450923
	LOSS [training: 0.24561802899404828 | validation: 0.21960401155530174]
	TIME [epoch: 11.2 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2520733279523944		[learning rate: 0.0044933]
	Learning Rate: 0.00449329
	LOSS [training: 0.2520733279523944 | validation: 0.23574303253251472]
	TIME [epoch: 11.2 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26115637115839097		[learning rate: 0.0044774]
	Learning Rate: 0.0044774
	LOSS [training: 0.26115637115839097 | validation: 0.2207344864021072]
	TIME [epoch: 11.2 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26531051186191823		[learning rate: 0.0044616]
	Learning Rate: 0.00446156
	LOSS [training: 0.26531051186191823 | validation: 0.21256305154135338]
	TIME [epoch: 11.2 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2666674625562136		[learning rate: 0.0044458]
	Learning Rate: 0.00444579
	LOSS [training: 0.2666674625562136 | validation: 0.2197080700650164]
	TIME [epoch: 11.2 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25733010129637174		[learning rate: 0.0044301]
	Learning Rate: 0.00443007
	LOSS [training: 0.25733010129637174 | validation: 0.2013342585155798]
	TIME [epoch: 11.2 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14_20240719_005014/states/model_facs_v3_dec1b_2dpca_v14_280.pth
	Model improved!!!
EPOCH 281/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25172046297174466		[learning rate: 0.0044144]
	Learning Rate: 0.0044144
	LOSS [training: 0.25172046297174466 | validation: 0.21868446010470297]
	TIME [epoch: 11.2 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25939902755847394		[learning rate: 0.0043988]
	Learning Rate: 0.00439879
	LOSS [training: 0.25939902755847394 | validation: 0.21379659825801603]
	TIME [epoch: 11.2 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26160167478822866		[learning rate: 0.0043832]
	Learning Rate: 0.00438324
	LOSS [training: 0.26160167478822866 | validation: 0.20878573624618652]
	TIME [epoch: 11.2 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2611585976186202		[learning rate: 0.0043677]
	Learning Rate: 0.00436774
	LOSS [training: 0.2611585976186202 | validation: 0.20562362525997516]
	TIME [epoch: 11.2 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25426590671463906		[learning rate: 0.0043523]
	Learning Rate: 0.00435229
	LOSS [training: 0.25426590671463906 | validation: 0.21771052841480895]
	TIME [epoch: 11.2 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2480151471529903		[learning rate: 0.0043369]
	Learning Rate: 0.0043369
	LOSS [training: 0.2480151471529903 | validation: 0.21854276811986426]
	TIME [epoch: 11.2 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25223465484744456		[learning rate: 0.0043216]
	Learning Rate: 0.00432156
	LOSS [training: 0.25223465484744456 | validation: 0.2124694415166878]
	TIME [epoch: 11.2 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25035500764668034		[learning rate: 0.0043063]
	Learning Rate: 0.00430628
	LOSS [training: 0.25035500764668034 | validation: 0.21420922929921155]
	TIME [epoch: 11.2 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25049499360577726		[learning rate: 0.0042911]
	Learning Rate: 0.00429106
	LOSS [training: 0.25049499360577726 | validation: 0.20876516587883423]
	TIME [epoch: 11.2 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2586636363955951		[learning rate: 0.0042759]
	Learning Rate: 0.00427588
	LOSS [training: 0.2586636363955951 | validation: 0.20815702704690048]
	TIME [epoch: 11.2 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25278367726373635		[learning rate: 0.0042608]
	Learning Rate: 0.00426076
	LOSS [training: 0.25278367726373635 | validation: 0.2076666493548185]
	TIME [epoch: 11.2 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25389250645884137		[learning rate: 0.0042457]
	Learning Rate: 0.00424569
	LOSS [training: 0.25389250645884137 | validation: 0.2155544615357937]
	TIME [epoch: 11.2 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25176015833201154		[learning rate: 0.0042307]
	Learning Rate: 0.00423068
	LOSS [training: 0.25176015833201154 | validation: 0.22444403796067341]
	TIME [epoch: 11.2 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2668742015183822		[learning rate: 0.0042157]
	Learning Rate: 0.00421572
	LOSS [training: 0.2668742015183822 | validation: 0.213971684506787]
	TIME [epoch: 11.2 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25019414928178346		[learning rate: 0.0042008]
	Learning Rate: 0.00420081
	LOSS [training: 0.25019414928178346 | validation: 0.21937986193694542]
	TIME [epoch: 11.2 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2567718746239463		[learning rate: 0.004186]
	Learning Rate: 0.00418596
	LOSS [training: 0.2567718746239463 | validation: 0.21410652422378634]
	TIME [epoch: 11.2 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24884749753445168		[learning rate: 0.0041712]
	Learning Rate: 0.00417116
	LOSS [training: 0.24884749753445168 | validation: 0.21301477731809443]
	TIME [epoch: 11.2 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24428536242750218		[learning rate: 0.0041564]
	Learning Rate: 0.00415641
	LOSS [training: 0.24428536242750218 | validation: 0.205354816035151]
	TIME [epoch: 11.2 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25070853378725805		[learning rate: 0.0041417]
	Learning Rate: 0.00414171
	LOSS [training: 0.25070853378725805 | validation: 0.21335659894278963]
	TIME [epoch: 11.2 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25179317415084584		[learning rate: 0.0041271]
	Learning Rate: 0.00412706
	LOSS [training: 0.25179317415084584 | validation: 0.23334192340137064]
	TIME [epoch: 11.2 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24845465877285192		[learning rate: 0.0041125]
	Learning Rate: 0.00411247
	LOSS [training: 0.24845465877285192 | validation: 0.21527425827669866]
	TIME [epoch: 11.2 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25818142152276885		[learning rate: 0.0040979]
	Learning Rate: 0.00409793
	LOSS [training: 0.25818142152276885 | validation: 0.22766237608075585]
	TIME [epoch: 11.2 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25650253390329925		[learning rate: 0.0040834]
	Learning Rate: 0.00408344
	LOSS [training: 0.25650253390329925 | validation: 0.2244309348933188]
	TIME [epoch: 11.2 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24974880459006		[learning rate: 0.004069]
	Learning Rate: 0.004069
	LOSS [training: 0.24974880459006 | validation: 0.21271642242393943]
	TIME [epoch: 11.2 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24644395036266242		[learning rate: 0.0040546]
	Learning Rate: 0.00405461
	LOSS [training: 0.24644395036266242 | validation: 0.21590834563579242]
	TIME [epoch: 11.2 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25372163511217344		[learning rate: 0.0040403]
	Learning Rate: 0.00404027
	LOSS [training: 0.25372163511217344 | validation: 0.21176264962135166]
	TIME [epoch: 11.2 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2561357204029225		[learning rate: 0.004026]
	Learning Rate: 0.00402598
	LOSS [training: 0.2561357204029225 | validation: 0.21511779437391168]
	TIME [epoch: 11.2 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2554556011811412		[learning rate: 0.0040117]
	Learning Rate: 0.00401175
	LOSS [training: 0.2554556011811412 | validation: 0.20402911314666267]
	TIME [epoch: 11.2 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24821763970783994		[learning rate: 0.0039976]
	Learning Rate: 0.00399756
	LOSS [training: 0.24821763970783994 | validation: 0.21317912782568596]
	TIME [epoch: 11.2 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2636524431678837		[learning rate: 0.0039834]
	Learning Rate: 0.00398342
	LOSS [training: 0.2636524431678837 | validation: 0.21283885617500284]
	TIME [epoch: 11.2 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25681040123229665		[learning rate: 0.0039693]
	Learning Rate: 0.00396934
	LOSS [training: 0.25681040123229665 | validation: 0.21694161342023172]
	TIME [epoch: 11.2 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25456965156899436		[learning rate: 0.0039553]
	Learning Rate: 0.0039553
	LOSS [training: 0.25456965156899436 | validation: 0.19904427451892018]
	TIME [epoch: 11.2 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14_20240719_005014/states/model_facs_v3_dec1b_2dpca_v14_312.pth
	Model improved!!!
EPOCH 313/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25105322890654214		[learning rate: 0.0039413]
	Learning Rate: 0.00394131
	LOSS [training: 0.25105322890654214 | validation: 0.20580633465167306]
	TIME [epoch: 11.2 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25686122293763775		[learning rate: 0.0039274]
	Learning Rate: 0.00392738
	LOSS [training: 0.25686122293763775 | validation: 0.21376665621676136]
	TIME [epoch: 11.2 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24630196247351258		[learning rate: 0.0039135]
	Learning Rate: 0.00391349
	LOSS [training: 0.24630196247351258 | validation: 0.21310636258587748]
	TIME [epoch: 11.2 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2588682232377544		[learning rate: 0.0038997]
	Learning Rate: 0.00389965
	LOSS [training: 0.2588682232377544 | validation: 0.2115391832237318]
	TIME [epoch: 11.2 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2535940083780707		[learning rate: 0.0038859]
	Learning Rate: 0.00388586
	LOSS [training: 0.2535940083780707 | validation: 0.22042252701371096]
	TIME [epoch: 11.2 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2481243893885793		[learning rate: 0.0038721]
	Learning Rate: 0.00387212
	LOSS [training: 0.2481243893885793 | validation: 0.2078410055016427]
	TIME [epoch: 11.2 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2501641109195954		[learning rate: 0.0038584]
	Learning Rate: 0.00385843
	LOSS [training: 0.2501641109195954 | validation: 0.227757610370459]
	TIME [epoch: 11.2 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25439790835799553		[learning rate: 0.0038448]
	Learning Rate: 0.00384478
	LOSS [training: 0.25439790835799553 | validation: 0.20959394991958144]
	TIME [epoch: 11.2 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2474075153683223		[learning rate: 0.0038312]
	Learning Rate: 0.00383119
	LOSS [training: 0.2474075153683223 | validation: 0.21217891884683251]
	TIME [epoch: 11.2 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25335869938367295		[learning rate: 0.0038176]
	Learning Rate: 0.00381764
	LOSS [training: 0.25335869938367295 | validation: 0.21152973150297058]
	TIME [epoch: 11.2 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25067102808361175		[learning rate: 0.0038041]
	Learning Rate: 0.00380414
	LOSS [training: 0.25067102808361175 | validation: 0.2039082884239083]
	TIME [epoch: 11.2 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24536088587603533		[learning rate: 0.0037907]
	Learning Rate: 0.00379069
	LOSS [training: 0.24536088587603533 | validation: 0.21769596229295915]
	TIME [epoch: 11.2 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24292113495736842		[learning rate: 0.0037773]
	Learning Rate: 0.00377728
	LOSS [training: 0.24292113495736842 | validation: 0.20783419648140872]
	TIME [epoch: 11.2 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2528800875082856		[learning rate: 0.0037639]
	Learning Rate: 0.00376393
	LOSS [training: 0.2528800875082856 | validation: 0.2072563219372395]
	TIME [epoch: 11.2 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25165220655620296		[learning rate: 0.0037506]
	Learning Rate: 0.00375062
	LOSS [training: 0.25165220655620296 | validation: 0.2167831906675337]
	TIME [epoch: 11.2 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2512019092798775		[learning rate: 0.0037374]
	Learning Rate: 0.00373735
	LOSS [training: 0.2512019092798775 | validation: 0.20837370128166563]
	TIME [epoch: 11.2 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2581263207028104		[learning rate: 0.0037241]
	Learning Rate: 0.00372414
	LOSS [training: 0.2581263207028104 | validation: 0.21695837813841617]
	TIME [epoch: 11.2 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2493040423344539		[learning rate: 0.003711]
	Learning Rate: 0.00371097
	LOSS [training: 0.2493040423344539 | validation: 0.20532389189250563]
	TIME [epoch: 11.2 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2568001889481071		[learning rate: 0.0036978]
	Learning Rate: 0.00369785
	LOSS [training: 0.2568001889481071 | validation: 0.22000526272335347]
	TIME [epoch: 11.2 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2627030626277294		[learning rate: 0.0036848]
	Learning Rate: 0.00368477
	LOSS [training: 0.2627030626277294 | validation: 0.20951877913832034]
	TIME [epoch: 11.2 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24893627889365588		[learning rate: 0.0036717]
	Learning Rate: 0.00367174
	LOSS [training: 0.24893627889365588 | validation: 0.2166251498635104]
	TIME [epoch: 11.2 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2567854885060551		[learning rate: 0.0036588]
	Learning Rate: 0.00365875
	LOSS [training: 0.2567854885060551 | validation: 0.21587660333420847]
	TIME [epoch: 11.2 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2433086368930011		[learning rate: 0.0036458]
	Learning Rate: 0.00364582
	LOSS [training: 0.2433086368930011 | validation: 0.21948248381617824]
	TIME [epoch: 11.2 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2575843843848961		[learning rate: 0.0036329]
	Learning Rate: 0.00363292
	LOSS [training: 0.2575843843848961 | validation: 0.21468421692380907]
	TIME [epoch: 11.2 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24869798949869615		[learning rate: 0.0036201]
	Learning Rate: 0.00362008
	LOSS [training: 0.24869798949869615 | validation: 0.21787706975128546]
	TIME [epoch: 11.2 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25162573365410074		[learning rate: 0.0036073]
	Learning Rate: 0.00360728
	LOSS [training: 0.25162573365410074 | validation: 0.21613240640952974]
	TIME [epoch: 11.2 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24774837076197362		[learning rate: 0.0035945]
	Learning Rate: 0.00359452
	LOSS [training: 0.24774837076197362 | validation: 0.21507468454737727]
	TIME [epoch: 11.2 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25913943982573023		[learning rate: 0.0035818]
	Learning Rate: 0.00358181
	LOSS [training: 0.25913943982573023 | validation: 0.20558745088560607]
	TIME [epoch: 11.2 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2639969815725009		[learning rate: 0.0035691]
	Learning Rate: 0.00356914
	LOSS [training: 0.2639969815725009 | validation: 0.20584073848834591]
	TIME [epoch: 11.2 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.255017187910606		[learning rate: 0.0035565]
	Learning Rate: 0.00355652
	LOSS [training: 0.255017187910606 | validation: 0.20879471681353473]
	TIME [epoch: 11.2 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.245104292134359		[learning rate: 0.0035439]
	Learning Rate: 0.00354395
	LOSS [training: 0.245104292134359 | validation: 0.21849108949009177]
	TIME [epoch: 11.2 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2529037564144337		[learning rate: 0.0035314]
	Learning Rate: 0.00353141
	LOSS [training: 0.2529037564144337 | validation: 0.20950992253421025]
	TIME [epoch: 11.2 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24911275674736544		[learning rate: 0.0035189]
	Learning Rate: 0.00351893
	LOSS [training: 0.24911275674736544 | validation: 0.2099904738292894]
	TIME [epoch: 11.2 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24849724836083		[learning rate: 0.0035065]
	Learning Rate: 0.00350648
	LOSS [training: 0.24849724836083 | validation: 0.20900223267984436]
	TIME [epoch: 11.2 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26124531202463364		[learning rate: 0.0034941]
	Learning Rate: 0.00349408
	LOSS [training: 0.26124531202463364 | validation: 0.21532910894533625]
	TIME [epoch: 11.2 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24968873440070508		[learning rate: 0.0034817]
	Learning Rate: 0.00348173
	LOSS [training: 0.24968873440070508 | validation: 0.21716908065670718]
	TIME [epoch: 11.2 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2609959650165391		[learning rate: 0.0034694]
	Learning Rate: 0.00346942
	LOSS [training: 0.2609959650165391 | validation: 0.21265023805104058]
	TIME [epoch: 11.2 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2611425515810695		[learning rate: 0.0034571]
	Learning Rate: 0.00345715
	LOSS [training: 0.2611425515810695 | validation: 0.2130630363266187]
	TIME [epoch: 11.2 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2612794495403563		[learning rate: 0.0034449]
	Learning Rate: 0.00344492
	LOSS [training: 0.2612794495403563 | validation: 0.20960858353502637]
	TIME [epoch: 11.2 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2472490906516629		[learning rate: 0.0034327]
	Learning Rate: 0.00343274
	LOSS [training: 0.2472490906516629 | validation: 0.20280805499675272]
	TIME [epoch: 11.2 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25180764210959533		[learning rate: 0.0034206]
	Learning Rate: 0.0034206
	LOSS [training: 0.25180764210959533 | validation: 0.20586057696900775]
	TIME [epoch: 11.2 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25243828244321254		[learning rate: 0.0034085]
	Learning Rate: 0.00340851
	LOSS [training: 0.25243828244321254 | validation: 0.2250200914509355]
	TIME [epoch: 11.2 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25203464750214205		[learning rate: 0.0033965]
	Learning Rate: 0.00339645
	LOSS [training: 0.25203464750214205 | validation: 0.2163344300281897]
	TIME [epoch: 11.2 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2553699874020704		[learning rate: 0.0033844]
	Learning Rate: 0.00338444
	LOSS [training: 0.2553699874020704 | validation: 0.21523326173546234]
	TIME [epoch: 11.2 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25280860051338944		[learning rate: 0.0033725]
	Learning Rate: 0.00337247
	LOSS [training: 0.25280860051338944 | validation: 0.2118218027390794]
	TIME [epoch: 11.2 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2515217386935878		[learning rate: 0.0033605]
	Learning Rate: 0.00336055
	LOSS [training: 0.2515217386935878 | validation: 0.21510959269799185]
	TIME [epoch: 11.2 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26668926984562563		[learning rate: 0.0033487]
	Learning Rate: 0.00334867
	LOSS [training: 0.26668926984562563 | validation: 0.22115209483358395]
	TIME [epoch: 11.2 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2520915012377915		[learning rate: 0.0033368]
	Learning Rate: 0.00333682
	LOSS [training: 0.2520915012377915 | validation: 0.20998010933242478]
	TIME [epoch: 11.2 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2466726119756063		[learning rate: 0.003325]
	Learning Rate: 0.00332502
	LOSS [training: 0.2466726119756063 | validation: 0.21038415730568766]
	TIME [epoch: 11.2 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25509299749463393		[learning rate: 0.0033133]
	Learning Rate: 0.00331327
	LOSS [training: 0.25509299749463393 | validation: 0.21334103167572901]
	TIME [epoch: 11.2 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24912890552511058		[learning rate: 0.0033016]
	Learning Rate: 0.00330155
	LOSS [training: 0.24912890552511058 | validation: 0.2055693187849666]
	TIME [epoch: 11.2 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24900550464233495		[learning rate: 0.0032899]
	Learning Rate: 0.00328988
	LOSS [training: 0.24900550464233495 | validation: 0.2149904317730244]
	TIME [epoch: 11.2 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24191796253137568		[learning rate: 0.0032782]
	Learning Rate: 0.00327824
	LOSS [training: 0.24191796253137568 | validation: 0.21756894602988625]
	TIME [epoch: 11.2 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2599670350426449		[learning rate: 0.0032666]
	Learning Rate: 0.00326665
	LOSS [training: 0.2599670350426449 | validation: 0.2202546874707668]
	TIME [epoch: 11.2 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2508811730197886		[learning rate: 0.0032551]
	Learning Rate: 0.0032551
	LOSS [training: 0.2508811730197886 | validation: 0.21235986348979985]
	TIME [epoch: 11.2 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2573065766379173		[learning rate: 0.0032436]
	Learning Rate: 0.00324359
	LOSS [training: 0.2573065766379173 | validation: 0.21152025201597144]
	TIME [epoch: 11.2 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2537580535332395		[learning rate: 0.0032321]
	Learning Rate: 0.00323212
	LOSS [training: 0.2537580535332395 | validation: 0.21019161458504115]
	TIME [epoch: 11.2 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25136548126376107		[learning rate: 0.0032207]
	Learning Rate: 0.00322069
	LOSS [training: 0.25136548126376107 | validation: 0.21310998337288414]
	TIME [epoch: 11.2 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2446846376655802		[learning rate: 0.0032093]
	Learning Rate: 0.0032093
	LOSS [training: 0.2446846376655802 | validation: 0.21442912957186774]
	TIME [epoch: 11.2 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2522081082794167		[learning rate: 0.003198]
	Learning Rate: 0.00319795
	LOSS [training: 0.2522081082794167 | validation: 0.20920419226820663]
	TIME [epoch: 11.2 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25150131365145034		[learning rate: 0.0031866]
	Learning Rate: 0.00318664
	LOSS [training: 0.25150131365145034 | validation: 0.2060148305114054]
	TIME [epoch: 11.2 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24415653548275482		[learning rate: 0.0031754]
	Learning Rate: 0.00317537
	LOSS [training: 0.24415653548275482 | validation: 0.21662710211861178]
	TIME [epoch: 11.2 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2489111259728505		[learning rate: 0.0031641]
	Learning Rate: 0.00316415
	LOSS [training: 0.2489111259728505 | validation: 0.2118265161755101]
	TIME [epoch: 11.2 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24809357890082287		[learning rate: 0.003153]
	Learning Rate: 0.00315296
	LOSS [training: 0.24809357890082287 | validation: 0.21543508108132783]
	TIME [epoch: 11.2 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2445291655681849		[learning rate: 0.0031418]
	Learning Rate: 0.00314181
	LOSS [training: 0.2445291655681849 | validation: 0.2169460693892467]
	TIME [epoch: 11.2 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2560391993497257		[learning rate: 0.0031307]
	Learning Rate: 0.0031307
	LOSS [training: 0.2560391993497257 | validation: 0.2282502248794372]
	TIME [epoch: 11.2 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.251911530107721		[learning rate: 0.0031196]
	Learning Rate: 0.00311963
	LOSS [training: 0.251911530107721 | validation: 0.21112262746921356]
	TIME [epoch: 11.2 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2583181936108168		[learning rate: 0.0031086]
	Learning Rate: 0.00310859
	LOSS [training: 0.2583181936108168 | validation: 0.20762056445279745]
	TIME [epoch: 11.2 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.259073614760531		[learning rate: 0.0030976]
	Learning Rate: 0.0030976
	LOSS [training: 0.259073614760531 | validation: 0.22255291595814536]
	TIME [epoch: 11.2 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2475029901306198		[learning rate: 0.0030866]
	Learning Rate: 0.00308665
	LOSS [training: 0.2475029901306198 | validation: 0.21323732712660987]
	TIME [epoch: 11.2 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2531148213275754		[learning rate: 0.0030757]
	Learning Rate: 0.00307573
	LOSS [training: 0.2531148213275754 | validation: 0.20806424168194876]
	TIME [epoch: 11.2 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24421097872639227		[learning rate: 0.0030649]
	Learning Rate: 0.00306486
	LOSS [training: 0.24421097872639227 | validation: 0.2215127656056355]
	TIME [epoch: 11.2 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24261045741150014		[learning rate: 0.003054]
	Learning Rate: 0.00305402
	LOSS [training: 0.24261045741150014 | validation: 0.20666647111821498]
	TIME [epoch: 11.2 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25643427395211504		[learning rate: 0.0030432]
	Learning Rate: 0.00304322
	LOSS [training: 0.25643427395211504 | validation: 0.20796301658498173]
	TIME [epoch: 11.2 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2412314110377749		[learning rate: 0.0030325]
	Learning Rate: 0.00303246
	LOSS [training: 0.2412314110377749 | validation: 0.2018426423284207]
	TIME [epoch: 11.2 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25363909165732434		[learning rate: 0.0030217]
	Learning Rate: 0.00302174
	LOSS [training: 0.25363909165732434 | validation: 0.2098952808822571]
	TIME [epoch: 11.2 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24761164435466654		[learning rate: 0.003011]
	Learning Rate: 0.00301105
	LOSS [training: 0.24761164435466654 | validation: 0.2099670714766837]
	TIME [epoch: 11.2 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24257754868313317		[learning rate: 0.0030004]
	Learning Rate: 0.0030004
	LOSS [training: 0.24257754868313317 | validation: 0.21766612036551253]
	TIME [epoch: 11.2 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24867073616039959		[learning rate: 0.0029898]
	Learning Rate: 0.00298979
	LOSS [training: 0.24867073616039959 | validation: 0.2171048305127184]
	TIME [epoch: 11.2 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24329476922168106		[learning rate: 0.0029792]
	Learning Rate: 0.00297922
	LOSS [training: 0.24329476922168106 | validation: 0.2168610003998072]
	TIME [epoch: 11.2 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2531395853626441		[learning rate: 0.0029687]
	Learning Rate: 0.00296869
	LOSS [training: 0.2531395853626441 | validation: 0.22119886622609197]
	TIME [epoch: 11.2 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2579172195255299		[learning rate: 0.0029582]
	Learning Rate: 0.00295819
	LOSS [training: 0.2579172195255299 | validation: 0.22163218654787525]
	TIME [epoch: 11.2 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24967352835122214		[learning rate: 0.0029477]
	Learning Rate: 0.00294773
	LOSS [training: 0.24967352835122214 | validation: 0.22033440492716266]
	TIME [epoch: 11.2 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25175745962211266		[learning rate: 0.0029373]
	Learning Rate: 0.0029373
	LOSS [training: 0.25175745962211266 | validation: 0.20984147039318363]
	TIME [epoch: 11.1 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25155900664470404		[learning rate: 0.0029269]
	Learning Rate: 0.00292692
	LOSS [training: 0.25155900664470404 | validation: 0.20957428446916854]
	TIME [epoch: 11.2 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2465431478918021		[learning rate: 0.0029166]
	Learning Rate: 0.00291657
	LOSS [training: 0.2465431478918021 | validation: 0.20610606237292634]
	TIME [epoch: 11.1 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24440068324609343		[learning rate: 0.0029063]
	Learning Rate: 0.00290625
	LOSS [training: 0.24440068324609343 | validation: 0.20826285431045055]
	TIME [epoch: 11.2 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25751402735052825		[learning rate: 0.002896]
	Learning Rate: 0.00289598
	LOSS [training: 0.25751402735052825 | validation: 0.2051410548046524]
	TIME [epoch: 11.2 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.249954258387124		[learning rate: 0.0028857]
	Learning Rate: 0.00288573
	LOSS [training: 0.249954258387124 | validation: 0.2034132737868529]
	TIME [epoch: 11.2 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24329248394083125		[learning rate: 0.0028755]
	Learning Rate: 0.00287553
	LOSS [training: 0.24329248394083125 | validation: 0.2147401168066545]
	TIME [epoch: 11.2 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25227010077466877		[learning rate: 0.0028654]
	Learning Rate: 0.00286536
	LOSS [training: 0.25227010077466877 | validation: 0.21492306423498628]
	TIME [epoch: 11.2 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2374447313521136		[learning rate: 0.0028552]
	Learning Rate: 0.00285523
	LOSS [training: 0.2374447313521136 | validation: 0.20938202261684977]
	TIME [epoch: 11.2 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24931507494758895		[learning rate: 0.0028451]
	Learning Rate: 0.00284513
	LOSS [training: 0.24931507494758895 | validation: 0.20288078529685377]
	TIME [epoch: 11.2 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.253264660843341		[learning rate: 0.0028351]
	Learning Rate: 0.00283507
	LOSS [training: 0.253264660843341 | validation: 0.2147311142823003]
	TIME [epoch: 11.2 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24789723082401136		[learning rate: 0.002825]
	Learning Rate: 0.00282505
	LOSS [training: 0.24789723082401136 | validation: 0.21824267192867594]
	TIME [epoch: 11.2 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2519854575904981		[learning rate: 0.0028151]
	Learning Rate: 0.00281506
	LOSS [training: 0.2519854575904981 | validation: 0.2092190643303317]
	TIME [epoch: 11.2 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24909528836610276		[learning rate: 0.0028051]
	Learning Rate: 0.0028051
	LOSS [training: 0.24909528836610276 | validation: 0.21794823412786749]
	TIME [epoch: 11.2 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2524133566411217		[learning rate: 0.0027952]
	Learning Rate: 0.00279518
	LOSS [training: 0.2524133566411217 | validation: 0.2042950833419633]
	TIME [epoch: 11.2 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24895988781033876		[learning rate: 0.0027853]
	Learning Rate: 0.0027853
	LOSS [training: 0.24895988781033876 | validation: 0.20262096905639865]
	TIME [epoch: 11.2 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25463991440989103		[learning rate: 0.0027754]
	Learning Rate: 0.00277545
	LOSS [training: 0.25463991440989103 | validation: 0.21336144616194033]
	TIME [epoch: 11.2 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2516730575492759		[learning rate: 0.0027656]
	Learning Rate: 0.00276564
	LOSS [training: 0.2516730575492759 | validation: 0.21272084135791078]
	TIME [epoch: 11.2 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24561772288681857		[learning rate: 0.0027559]
	Learning Rate: 0.00275586
	LOSS [training: 0.24561772288681857 | validation: 0.21233377084205518]
	TIME [epoch: 11.2 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24812492907726091		[learning rate: 0.0027461]
	Learning Rate: 0.00274611
	LOSS [training: 0.24812492907726091 | validation: 0.20636934626598363]
	TIME [epoch: 11.2 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25627248574942885		[learning rate: 0.0027364]
	Learning Rate: 0.0027364
	LOSS [training: 0.25627248574942885 | validation: 0.2116179070479109]
	TIME [epoch: 11.2 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24803208138749253		[learning rate: 0.0027267]
	Learning Rate: 0.00272672
	LOSS [training: 0.24803208138749253 | validation: 0.21157763617303402]
	TIME [epoch: 11.2 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2560951512026291		[learning rate: 0.0027171]
	Learning Rate: 0.00271708
	LOSS [training: 0.2560951512026291 | validation: 0.21730688714849983]
	TIME [epoch: 11.2 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24932230165564953		[learning rate: 0.0027075]
	Learning Rate: 0.00270747
	LOSS [training: 0.24932230165564953 | validation: 0.21550747530343423]
	TIME [epoch: 11.2 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25194836125930326		[learning rate: 0.0026979]
	Learning Rate: 0.0026979
	LOSS [training: 0.25194836125930326 | validation: 0.20814766266213472]
	TIME [epoch: 11.2 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2530341271648133		[learning rate: 0.0026884]
	Learning Rate: 0.00268836
	LOSS [training: 0.2530341271648133 | validation: 0.2114084217753156]
	TIME [epoch: 11.2 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2570601826364545		[learning rate: 0.0026789]
	Learning Rate: 0.00267885
	LOSS [training: 0.2570601826364545 | validation: 0.2047858333298218]
	TIME [epoch: 11.2 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2502487955048799		[learning rate: 0.0026694]
	Learning Rate: 0.00266938
	LOSS [training: 0.2502487955048799 | validation: 0.21160431690696607]
	TIME [epoch: 11.2 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2452479014064354		[learning rate: 0.0026599]
	Learning Rate: 0.00265994
	LOSS [training: 0.2452479014064354 | validation: 0.2117217060500071]
	TIME [epoch: 11.2 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24383231368779987		[learning rate: 0.0026505]
	Learning Rate: 0.00265053
	LOSS [training: 0.24383231368779987 | validation: 0.213926639765742]
	TIME [epoch: 11.2 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24602039579917356		[learning rate: 0.0026412]
	Learning Rate: 0.00264116
	LOSS [training: 0.24602039579917356 | validation: 0.20844372239661105]
	TIME [epoch: 11.2 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24225443301898372		[learning rate: 0.0026318]
	Learning Rate: 0.00263182
	LOSS [training: 0.24225443301898372 | validation: 0.23181018883684074]
	TIME [epoch: 11.2 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24970233970673603		[learning rate: 0.0026225]
	Learning Rate: 0.00262251
	LOSS [training: 0.24970233970673603 | validation: 0.21670894723718245]
	TIME [epoch: 11.2 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2468348379642528		[learning rate: 0.0026132]
	Learning Rate: 0.00261324
	LOSS [training: 0.2468348379642528 | validation: 0.20489391858769362]
	TIME [epoch: 11.2 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25269076689104036		[learning rate: 0.002604]
	Learning Rate: 0.002604
	LOSS [training: 0.25269076689104036 | validation: 0.21086786469342952]
	TIME [epoch: 11.2 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24588199911177847		[learning rate: 0.0025948]
	Learning Rate: 0.00259479
	LOSS [training: 0.24588199911177847 | validation: 0.20823153482703055]
	TIME [epoch: 11.2 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.240188267591241		[learning rate: 0.0025856]
	Learning Rate: 0.00258562
	LOSS [training: 0.240188267591241 | validation: 0.2056356838858972]
	TIME [epoch: 11.2 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2596380912829102		[learning rate: 0.0025765]
	Learning Rate: 0.00257647
	LOSS [training: 0.2596380912829102 | validation: 0.22166408444948163]
	TIME [epoch: 11.2 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24573146171170293		[learning rate: 0.0025674]
	Learning Rate: 0.00256736
	LOSS [training: 0.24573146171170293 | validation: 0.204592843634619]
	TIME [epoch: 11.2 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2482278840343509		[learning rate: 0.0025583]
	Learning Rate: 0.00255828
	LOSS [training: 0.2482278840343509 | validation: 0.2089779275356222]
	TIME [epoch: 11.2 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.254619085460526		[learning rate: 0.0025492]
	Learning Rate: 0.00254924
	LOSS [training: 0.254619085460526 | validation: 0.21813822332810365]
	TIME [epoch: 11.2 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24520242001918494		[learning rate: 0.0025402]
	Learning Rate: 0.00254022
	LOSS [training: 0.24520242001918494 | validation: 0.20835158014008667]
	TIME [epoch: 11.2 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2569025792450178		[learning rate: 0.0025312]
	Learning Rate: 0.00253124
	LOSS [training: 0.2569025792450178 | validation: 0.20392516114420625]
	TIME [epoch: 11.2 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2476135766767199		[learning rate: 0.0025223]
	Learning Rate: 0.00252229
	LOSS [training: 0.2476135766767199 | validation: 0.2131302047701953]
	TIME [epoch: 11.2 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2532440564254182		[learning rate: 0.0025134]
	Learning Rate: 0.00251337
	LOSS [training: 0.2532440564254182 | validation: 0.2107579334377389]
	TIME [epoch: 11.2 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2426450933011615		[learning rate: 0.0025045]
	Learning Rate: 0.00250448
	LOSS [training: 0.2426450933011615 | validation: 0.2192155651107912]
	TIME [epoch: 11.2 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24920229613858966		[learning rate: 0.0024956]
	Learning Rate: 0.00249563
	LOSS [training: 0.24920229613858966 | validation: 0.2115632002902846]
	TIME [epoch: 11.2 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24772594457764083		[learning rate: 0.0024868]
	Learning Rate: 0.0024868
	LOSS [training: 0.24772594457764083 | validation: 0.2074137329948707]
	TIME [epoch: 11.2 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24586845796146017		[learning rate: 0.002478]
	Learning Rate: 0.00247801
	LOSS [training: 0.24586845796146017 | validation: 0.20977184348014996]
	TIME [epoch: 11.2 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2538275640506873		[learning rate: 0.0024692]
	Learning Rate: 0.00246924
	LOSS [training: 0.2538275640506873 | validation: 0.208948122909342]
	TIME [epoch: 11.2 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26140324032047796		[learning rate: 0.0024605]
	Learning Rate: 0.00246051
	LOSS [training: 0.26140324032047796 | validation: 0.20773763259706976]
	TIME [epoch: 11.2 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24202447870232602		[learning rate: 0.0024518]
	Learning Rate: 0.00245181
	LOSS [training: 0.24202447870232602 | validation: 0.2063649991138062]
	TIME [epoch: 11.2 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24727250765779482		[learning rate: 0.0024431]
	Learning Rate: 0.00244314
	LOSS [training: 0.24727250765779482 | validation: 0.20910726752613482]
	TIME [epoch: 11.2 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24583590448669126		[learning rate: 0.0024345]
	Learning Rate: 0.0024345
	LOSS [training: 0.24583590448669126 | validation: 0.21571570932070597]
	TIME [epoch: 11.2 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2452725520246808		[learning rate: 0.0024259]
	Learning Rate: 0.00242589
	LOSS [training: 0.2452725520246808 | validation: 0.21342670010549175]
	TIME [epoch: 11.2 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2482077367304447		[learning rate: 0.0024173]
	Learning Rate: 0.00241732
	LOSS [training: 0.2482077367304447 | validation: 0.2030599175869551]
	TIME [epoch: 11.2 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24777012962866232		[learning rate: 0.0024088]
	Learning Rate: 0.00240877
	LOSS [training: 0.24777012962866232 | validation: 0.21456979182140712]
	TIME [epoch: 11.2 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24656166716169756		[learning rate: 0.0024002]
	Learning Rate: 0.00240025
	LOSS [training: 0.24656166716169756 | validation: 0.2112133385888205]
	TIME [epoch: 11.2 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24776360200108485		[learning rate: 0.0023918]
	Learning Rate: 0.00239176
	LOSS [training: 0.24776360200108485 | validation: 0.21501663941386084]
	TIME [epoch: 11.2 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2354961072643926		[learning rate: 0.0023833]
	Learning Rate: 0.0023833
	LOSS [training: 0.2354961072643926 | validation: 0.20703729831307688]
	TIME [epoch: 11.2 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2511325921556814		[learning rate: 0.0023749]
	Learning Rate: 0.00237488
	LOSS [training: 0.2511325921556814 | validation: 0.21051935110236975]
	TIME [epoch: 11.2 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24598990378914676		[learning rate: 0.0023665]
	Learning Rate: 0.00236648
	LOSS [training: 0.24598990378914676 | validation: 0.20479929832730653]
	TIME [epoch: 11.2 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2512477751834093		[learning rate: 0.0023581]
	Learning Rate: 0.00235811
	LOSS [training: 0.2512477751834093 | validation: 0.2112182593783766]
	TIME [epoch: 11.2 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24863763136787054		[learning rate: 0.0023498]
	Learning Rate: 0.00234977
	LOSS [training: 0.24863763136787054 | validation: 0.2049041848174638]
	TIME [epoch: 11.2 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24595856249584483		[learning rate: 0.0023415]
	Learning Rate: 0.00234146
	LOSS [training: 0.24595856249584483 | validation: 0.21184524695770288]
	TIME [epoch: 11.2 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24968225540838485		[learning rate: 0.0023332]
	Learning Rate: 0.00233318
	LOSS [training: 0.24968225540838485 | validation: 0.20620993207381205]
	TIME [epoch: 11.2 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25039432528230715		[learning rate: 0.0023249]
	Learning Rate: 0.00232493
	LOSS [training: 0.25039432528230715 | validation: 0.21229992853372961]
	TIME [epoch: 11.2 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24682833000818707		[learning rate: 0.0023167]
	Learning Rate: 0.00231671
	LOSS [training: 0.24682833000818707 | validation: 0.21088092761685914]
	TIME [epoch: 11.2 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24555699862121952		[learning rate: 0.0023085]
	Learning Rate: 0.00230852
	LOSS [training: 0.24555699862121952 | validation: 0.21503681585446716]
	TIME [epoch: 11.2 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2462915587698585		[learning rate: 0.0023004]
	Learning Rate: 0.00230035
	LOSS [training: 0.2462915587698585 | validation: 0.20941871648523408]
	TIME [epoch: 11.2 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24801836943897748		[learning rate: 0.0022922]
	Learning Rate: 0.00229222
	LOSS [training: 0.24801836943897748 | validation: 0.2074237133344239]
	TIME [epoch: 11.2 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24876603662099087		[learning rate: 0.0022841]
	Learning Rate: 0.00228411
	LOSS [training: 0.24876603662099087 | validation: 0.2087115167112384]
	TIME [epoch: 11.2 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24638589251392143		[learning rate: 0.002276]
	Learning Rate: 0.00227604
	LOSS [training: 0.24638589251392143 | validation: 0.2124259603948996]
	TIME [epoch: 11.2 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2537621461118681		[learning rate: 0.002268]
	Learning Rate: 0.00226799
	LOSS [training: 0.2537621461118681 | validation: 0.2074024716401217]
	TIME [epoch: 11.2 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24468851262064206		[learning rate: 0.00226]
	Learning Rate: 0.00225997
	LOSS [training: 0.24468851262064206 | validation: 0.21465676311391588]
	TIME [epoch: 11.2 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2572365545604398		[learning rate: 0.002252]
	Learning Rate: 0.00225198
	LOSS [training: 0.2572365545604398 | validation: 0.2109337721227901]
	TIME [epoch: 11.2 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2528171728406769		[learning rate: 0.002244]
	Learning Rate: 0.00224401
	LOSS [training: 0.2528171728406769 | validation: 0.2128541329570393]
	TIME [epoch: 11.2 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2471624012011018		[learning rate: 0.0022361]
	Learning Rate: 0.00223608
	LOSS [training: 0.2471624012011018 | validation: 0.2164618542936088]
	TIME [epoch: 11.2 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24297545624763953		[learning rate: 0.0022282]
	Learning Rate: 0.00222817
	LOSS [training: 0.24297545624763953 | validation: 0.21270189466553027]
	TIME [epoch: 11.2 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2579599112691065		[learning rate: 0.0022203]
	Learning Rate: 0.00222029
	LOSS [training: 0.2579599112691065 | validation: 0.20678082010930718]
	TIME [epoch: 11.2 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2468469448300533		[learning rate: 0.0022124]
	Learning Rate: 0.00221244
	LOSS [training: 0.2468469448300533 | validation: 0.206511252251841]
	TIME [epoch: 11.2 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24862683564642782		[learning rate: 0.0022046]
	Learning Rate: 0.00220462
	LOSS [training: 0.24862683564642782 | validation: 0.2105152954909765]
	TIME [epoch: 11.2 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25026691305246107		[learning rate: 0.0021968]
	Learning Rate: 0.00219682
	LOSS [training: 0.25026691305246107 | validation: 0.2056552617574711]
	TIME [epoch: 11.2 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24433385130412258		[learning rate: 0.0021891]
	Learning Rate: 0.00218905
	LOSS [training: 0.24433385130412258 | validation: 0.20153847933764704]
	TIME [epoch: 11.2 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25189161475285354		[learning rate: 0.0021813]
	Learning Rate: 0.00218131
	LOSS [training: 0.25189161475285354 | validation: 0.20899243400067685]
	TIME [epoch: 11.2 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2567541867030209		[learning rate: 0.0021736]
	Learning Rate: 0.0021736
	LOSS [training: 0.2567541867030209 | validation: 0.21195949115628915]
	TIME [epoch: 11.2 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2405103850597052		[learning rate: 0.0021659]
	Learning Rate: 0.00216591
	LOSS [training: 0.2405103850597052 | validation: 0.21198011824604146]
	TIME [epoch: 11.2 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24425228898822857		[learning rate: 0.0021583]
	Learning Rate: 0.00215825
	LOSS [training: 0.24425228898822857 | validation: 0.20249844214578702]
	TIME [epoch: 11.2 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.237292360304774		[learning rate: 0.0021506]
	Learning Rate: 0.00215062
	LOSS [training: 0.237292360304774 | validation: 0.20626710917020352]
	TIME [epoch: 11.2 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25006565285010623		[learning rate: 0.002143]
	Learning Rate: 0.00214302
	LOSS [training: 0.25006565285010623 | validation: 0.20747742842258302]
	TIME [epoch: 11.2 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24635837262831087		[learning rate: 0.0021354]
	Learning Rate: 0.00213544
	LOSS [training: 0.24635837262831087 | validation: 0.2218932276170424]
	TIME [epoch: 11.2 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24395798338728017		[learning rate: 0.0021279]
	Learning Rate: 0.00212789
	LOSS [training: 0.24395798338728017 | validation: 0.2096807646658872]
	TIME [epoch: 11.2 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2498684415299234		[learning rate: 0.0021204]
	Learning Rate: 0.00212036
	LOSS [training: 0.2498684415299234 | validation: 0.20305078579909192]
	TIME [epoch: 11.2 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25921333658518436		[learning rate: 0.0021129]
	Learning Rate: 0.00211287
	LOSS [training: 0.25921333658518436 | validation: 0.20711255051124064]
	TIME [epoch: 11.2 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2446055169080953		[learning rate: 0.0021054]
	Learning Rate: 0.00210539
	LOSS [training: 0.2446055169080953 | validation: 0.20140569231636257]
	TIME [epoch: 11.2 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2429616893581957		[learning rate: 0.0020979]
	Learning Rate: 0.00209795
	LOSS [training: 0.2429616893581957 | validation: 0.20963858568439062]
	TIME [epoch: 11.2 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25025037404504374		[learning rate: 0.0020905]
	Learning Rate: 0.00209053
	LOSS [training: 0.25025037404504374 | validation: 0.21550940057359252]
	TIME [epoch: 11.2 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2551293612600163		[learning rate: 0.0020831]
	Learning Rate: 0.00208314
	LOSS [training: 0.2551293612600163 | validation: 0.21744468215218943]
	TIME [epoch: 11.2 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24231370635521302		[learning rate: 0.0020758]
	Learning Rate: 0.00207577
	LOSS [training: 0.24231370635521302 | validation: 0.21174044768346229]
	TIME [epoch: 11.2 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2412291165972514		[learning rate: 0.0020684]
	Learning Rate: 0.00206843
	LOSS [training: 0.2412291165972514 | validation: 0.21816856334490464]
	TIME [epoch: 11.2 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24229174085857777		[learning rate: 0.0020611]
	Learning Rate: 0.00206112
	LOSS [training: 0.24229174085857777 | validation: 0.2142599724721951]
	TIME [epoch: 11.2 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24127705126620957		[learning rate: 0.0020538]
	Learning Rate: 0.00205383
	LOSS [training: 0.24127705126620957 | validation: 0.20502844233578593]
	TIME [epoch: 11.2 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24570163006169074		[learning rate: 0.0020466]
	Learning Rate: 0.00204657
	LOSS [training: 0.24570163006169074 | validation: 0.20966089314286346]
	TIME [epoch: 11.2 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.250702995703983		[learning rate: 0.0020393]
	Learning Rate: 0.00203933
	LOSS [training: 0.250702995703983 | validation: 0.213128300211373]
	TIME [epoch: 11.2 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2585769005974931		[learning rate: 0.0020321]
	Learning Rate: 0.00203212
	LOSS [training: 0.2585769005974931 | validation: 0.2099522658644984]
	TIME [epoch: 11.2 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2534925536740571		[learning rate: 0.0020249]
	Learning Rate: 0.00202493
	LOSS [training: 0.2534925536740571 | validation: 0.22617215472812546]
	TIME [epoch: 37.5 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24675313384535102		[learning rate: 0.0020178]
	Learning Rate: 0.00201777
	LOSS [training: 0.24675313384535102 | validation: 0.20245775295856766]
	TIME [epoch: 24.1 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24930908669878504		[learning rate: 0.0020106]
	Learning Rate: 0.00201064
	LOSS [training: 0.24930908669878504 | validation: 0.21261770169206842]
	TIME [epoch: 24.1 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24583807595337745		[learning rate: 0.0020035]
	Learning Rate: 0.00200353
	LOSS [training: 0.24583807595337745 | validation: 0.21295457643982765]
	TIME [epoch: 24.1 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24685040971039784		[learning rate: 0.0019964]
	Learning Rate: 0.00199644
	LOSS [training: 0.24685040971039784 | validation: 0.21780537089107255]
	TIME [epoch: 24.1 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24688200033116695		[learning rate: 0.0019894]
	Learning Rate: 0.00198938
	LOSS [training: 0.24688200033116695 | validation: 0.20698599331589068]
	TIME [epoch: 24.1 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.250499948299293		[learning rate: 0.0019823]
	Learning Rate: 0.00198235
	LOSS [training: 0.250499948299293 | validation: 0.21167381784347356]
	TIME [epoch: 24.1 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24219285779358068		[learning rate: 0.0019753]
	Learning Rate: 0.00197534
	LOSS [training: 0.24219285779358068 | validation: 0.20607160922783904]
	TIME [epoch: 24.1 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2381031397122383		[learning rate: 0.0019684]
	Learning Rate: 0.00196835
	LOSS [training: 0.2381031397122383 | validation: 0.20406333682798555]
	TIME [epoch: 24.1 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24808696784460127		[learning rate: 0.0019614]
	Learning Rate: 0.00196139
	LOSS [training: 0.24808696784460127 | validation: 0.2075411472304857]
	TIME [epoch: 24.1 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2592110280390832		[learning rate: 0.0019545]
	Learning Rate: 0.00195445
	LOSS [training: 0.2592110280390832 | validation: 0.21381476984887074]
	TIME [epoch: 24.1 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24588745417946337		[learning rate: 0.0019475]
	Learning Rate: 0.00194754
	LOSS [training: 0.24588745417946337 | validation: 0.2071226833268022]
	TIME [epoch: 24.1 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2396786528388458		[learning rate: 0.0019407]
	Learning Rate: 0.00194066
	LOSS [training: 0.2396786528388458 | validation: 0.20977091950970098]
	TIME [epoch: 24.1 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14_20240719_005014/states/model_facs_v3_dec1b_2dpca_v14_513.pth
Halted early. No improvement in validation loss for 200 epochs.
Finished training in 5719.529 seconds.
