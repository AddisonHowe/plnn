Args:
Namespace(name='model_facs_v4_dec2b_2dpca_v14b', outdir='out/model_training/model_facs_v4_dec2b_2dpca_v14b', training_data='data/training_data/facs_v4/pca/dec2_fitonsubset/transition2_subset_ce_pn_m_pc12/training', validation_data='data/training_data/facs_v4/pca/dec2_fitonsubset/transition2_subset_ce_pn_m_pc12/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=10, batch_size=50, patience=200, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, quadratic_a=1.0, quadratic_b=1.0, ndims=2, nparams=2, nsigs=2, ncells=200, ncells_sample=200, model_do_sample=False, dt=0.005, dt_schedule='stepped', dt_schedule_bounds=[50, 100, 200, 300], dt_schedule_scales=[0.5, 0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', kernel='multiscale', bw_range=[0.2, 0.5, 0.9, 1.1, 1.3, 1.5, 2.0], optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 4180438162

Training model...

Saving initial model state to: out/model_training/model_facs_v4_dec2b_2dpca_v14b_20240719_004750/states/model_facs_v4_dec2b_2dpca_v14b_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4700707517703187		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4700707517703187 | validation: 0.9879592648536759]
	TIME [epoch: 30.6 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v14b_20240719_004750/states/model_facs_v4_dec2b_2dpca_v14b_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7593056252635149		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7593056252635149 | validation: 0.8494578262497983]
	TIME [epoch: 3.96 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v14b_20240719_004750/states/model_facs_v4_dec2b_2dpca_v14b_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6751489925182954		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6751489925182954 | validation: 0.9159202036762387]
	TIME [epoch: 3.94 sec]
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6451429861105396		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6451429861105396 | validation: 0.7651324269236859]
	TIME [epoch: 3.95 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v14b_20240719_004750/states/model_facs_v4_dec2b_2dpca_v14b_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6234382522208376		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6234382522208376 | validation: 0.7531258601350466]
	TIME [epoch: 3.95 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v14b_20240719_004750/states/model_facs_v4_dec2b_2dpca_v14b_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5595704039977468		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5595704039977468 | validation: 0.7412040735110842]
	TIME [epoch: 3.94 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v14b_20240719_004750/states/model_facs_v4_dec2b_2dpca_v14b_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5141988496461846		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5141988496461846 | validation: 0.6315071918218531]
	TIME [epoch: 3.95 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v14b_20240719_004750/states/model_facs_v4_dec2b_2dpca_v14b_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5051250281176453		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5051250281176453 | validation: 0.6511504693796588]
	TIME [epoch: 3.95 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47848593699262587		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.47848593699262587 | validation: 0.5860509265792907]
	TIME [epoch: 3.95 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v14b_20240719_004750/states/model_facs_v4_dec2b_2dpca_v14b_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47829808649264804		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.47829808649264804 | validation: 0.559896317779884]
	TIME [epoch: 3.95 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v14b_20240719_004750/states/model_facs_v4_dec2b_2dpca_v14b_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49326695131802717		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.49326695131802717 | validation: 0.5396930721283867]
	TIME [epoch: 3.95 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v14b_20240719_004750/states/model_facs_v4_dec2b_2dpca_v14b_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4520717704526521		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4520717704526521 | validation: 0.6561752727845656]
	TIME [epoch: 3.95 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.427286755048034		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.427286755048034 | validation: 0.5515987890977928]
	TIME [epoch: 3.94 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4819383871674585		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4819383871674585 | validation: 0.5277657604032927]
	TIME [epoch: 3.95 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v14b_20240719_004750/states/model_facs_v4_dec2b_2dpca_v14b_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4263763387826296		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4263763387826296 | validation: 0.5251843134338727]
	TIME [epoch: 3.95 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v14b_20240719_004750/states/model_facs_v4_dec2b_2dpca_v14b_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3986966136496176		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3986966136496176 | validation: 0.5350708622109634]
	TIME [epoch: 3.95 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3802239965508383		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3802239965508383 | validation: 0.47854423034492377]
	TIME [epoch: 3.94 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v14b_20240719_004750/states/model_facs_v4_dec2b_2dpca_v14b_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3831485822463837		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3831485822463837 | validation: 0.44669903476381134]
	TIME [epoch: 3.95 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v14b_20240719_004750/states/model_facs_v4_dec2b_2dpca_v14b_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38544906747574		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.38544906747574 | validation: 0.47810075347647685]
	TIME [epoch: 3.95 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3565994493852144		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3565994493852144 | validation: 0.4536566277724753]
	TIME [epoch: 3.94 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3301299025634129		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3301299025634129 | validation: 0.43415013921615997]
	TIME [epoch: 3.94 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v14b_20240719_004750/states/model_facs_v4_dec2b_2dpca_v14b_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3121666863468069		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3121666863468069 | validation: 0.45396544263202543]
	TIME [epoch: 3.95 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30100856680871135		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.30100856680871135 | validation: 0.4566431431113741]
	TIME [epoch: 3.95 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3424035756290998		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3424035756290998 | validation: 0.5208868283455208]
	TIME [epoch: 3.95 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3273509706167939		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3273509706167939 | validation: 0.4005608152969421]
	TIME [epoch: 3.94 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v14b_20240719_004750/states/model_facs_v4_dec2b_2dpca_v14b_25.pth
	Model improved!!!
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2927807425469148		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2927807425469148 | validation: 0.43209767058022136]
	TIME [epoch: 3.95 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28884215026132287		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.28884215026132287 | validation: 0.4725753687706754]
	TIME [epoch: 3.94 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32519849459844485		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.32519849459844485 | validation: 0.36293890193511136]
	TIME [epoch: 3.94 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v14b_20240719_004750/states/model_facs_v4_dec2b_2dpca_v14b_28.pth
	Model improved!!!
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32116471852977213		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.32116471852977213 | validation: 0.39195732426151625]
	TIME [epoch: 3.94 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31641947040058205		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.31641947040058205 | validation: 0.420352497455796]
	TIME [epoch: 3.94 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2662773811765234		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2662773811765234 | validation: 0.41592523256668623]
	TIME [epoch: 3.96 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2833817149846699		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2833817149846699 | validation: 0.3740931059300274]
	TIME [epoch: 3.94 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29537933987455767		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.29537933987455767 | validation: 0.40692047976025186]
	TIME [epoch: 3.94 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28168119020613347		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.28168119020613347 | validation: 0.3813925192052571]
	TIME [epoch: 3.94 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2513134699781101		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2513134699781101 | validation: 0.37643394025814825]
	TIME [epoch: 3.94 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2823025705010021		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2823025705010021 | validation: 0.47474579667387684]
	TIME [epoch: 3.94 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30377114477243267		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.30377114477243267 | validation: 0.4429652310909818]
	TIME [epoch: 3.94 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24715485311851837		[learning rate: 0.0099882]
	Learning Rate: 0.0099882
	LOSS [training: 0.24715485311851837 | validation: 0.400923036958565]
	TIME [epoch: 3.94 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2527581379709456		[learning rate: 0.0099411]
	Learning Rate: 0.00994113
	LOSS [training: 0.2527581379709456 | validation: 0.36595683804395834]
	TIME [epoch: 3.95 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25069497055530243		[learning rate: 0.0098943]
	Learning Rate: 0.00989429
	LOSS [training: 0.25069497055530243 | validation: 0.43138680393275064]
	TIME [epoch: 3.94 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23682569049241348		[learning rate: 0.0098477]
	Learning Rate: 0.00984767
	LOSS [training: 0.23682569049241348 | validation: 0.4083340871334399]
	TIME [epoch: 3.94 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26654960539180433		[learning rate: 0.0098013]
	Learning Rate: 0.00980126
	LOSS [training: 0.26654960539180433 | validation: 0.33083759401409363]
	TIME [epoch: 3.94 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v14b_20240719_004750/states/model_facs_v4_dec2b_2dpca_v14b_42.pth
	Model improved!!!
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2282632458835683		[learning rate: 0.0097551]
	Learning Rate: 0.00975508
	LOSS [training: 0.2282632458835683 | validation: 0.42185761378773745]
	TIME [epoch: 4.2 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2769878130162747		[learning rate: 0.0097091]
	Learning Rate: 0.00970911
	LOSS [training: 0.2769878130162747 | validation: 0.3530003057031559]
	TIME [epoch: 3.95 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.228119247568759		[learning rate: 0.0096634]
	Learning Rate: 0.00966336
	LOSS [training: 0.228119247568759 | validation: 0.4173521826167415]
	TIME [epoch: 3.95 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23385162947074353		[learning rate: 0.0096178]
	Learning Rate: 0.00961783
	LOSS [training: 0.23385162947074353 | validation: 0.40767271377279524]
	TIME [epoch: 3.96 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2419200425879688		[learning rate: 0.0095725]
	Learning Rate: 0.00957251
	LOSS [training: 0.2419200425879688 | validation: 0.40882684097790295]
	TIME [epoch: 3.95 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24759698740958228		[learning rate: 0.0095274]
	Learning Rate: 0.0095274
	LOSS [training: 0.24759698740958228 | validation: 0.3581446402738646]
	TIME [epoch: 3.94 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22495415472920444		[learning rate: 0.0094825]
	Learning Rate: 0.0094825
	LOSS [training: 0.22495415472920444 | validation: 0.39442841751523405]
	TIME [epoch: 3.95 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24202280512037166		[learning rate: 0.0094378]
	Learning Rate: 0.00943782
	LOSS [training: 0.24202280512037166 | validation: 0.3836433976543976]
	TIME [epoch: 3.94 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22154928773574498		[learning rate: 0.0093933]
	Learning Rate: 0.00939335
	LOSS [training: 0.22154928773574498 | validation: 0.4715006324602002]
	TIME [epoch: 32 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22994235568752514		[learning rate: 0.0093491]
	Learning Rate: 0.00934909
	LOSS [training: 0.22994235568752514 | validation: 0.42310100047287763]
	TIME [epoch: 7.61 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27080878412748216		[learning rate: 0.009305]
	Learning Rate: 0.00930503
	LOSS [training: 0.27080878412748216 | validation: 0.36870300951975543]
	TIME [epoch: 7.59 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2133820525519934		[learning rate: 0.0092612]
	Learning Rate: 0.00926119
	LOSS [training: 0.2133820525519934 | validation: 0.3491622811162919]
	TIME [epoch: 7.59 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22533002827596957		[learning rate: 0.0092175]
	Learning Rate: 0.00921755
	LOSS [training: 0.22533002827596957 | validation: 0.3447643150299232]
	TIME [epoch: 7.6 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2667098446014438		[learning rate: 0.0091741]
	Learning Rate: 0.00917411
	LOSS [training: 0.2667098446014438 | validation: 0.36545319615162036]
	TIME [epoch: 7.59 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18405095540512223		[learning rate: 0.0091309]
	Learning Rate: 0.00913088
	LOSS [training: 0.18405095540512223 | validation: 0.49505109252818424]
	TIME [epoch: 7.59 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22967168895404888		[learning rate: 0.0090879]
	Learning Rate: 0.00908786
	LOSS [training: 0.22967168895404888 | validation: 0.32028522572686724]
	TIME [epoch: 7.59 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v14b_20240719_004750/states/model_facs_v4_dec2b_2dpca_v14b_58.pth
	Model improved!!!
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22972128886688892		[learning rate: 0.009045]
	Learning Rate: 0.00904503
	LOSS [training: 0.22972128886688892 | validation: 0.311667225323184]
	TIME [epoch: 7.59 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v14b_20240719_004750/states/model_facs_v4_dec2b_2dpca_v14b_59.pth
	Model improved!!!
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18522511375549738		[learning rate: 0.0090024]
	Learning Rate: 0.00900241
	LOSS [training: 0.18522511375549738 | validation: 0.3784966255948807]
	TIME [epoch: 7.59 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18886544166410418		[learning rate: 0.00896]
	Learning Rate: 0.00895999
	LOSS [training: 0.18886544166410418 | validation: 0.39892968056434547]
	TIME [epoch: 7.57 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1888039075568264		[learning rate: 0.0089178]
	Learning Rate: 0.00891777
	LOSS [training: 0.1888039075568264 | validation: 0.3959080496734515]
	TIME [epoch: 7.57 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23369912316136865		[learning rate: 0.0088758]
	Learning Rate: 0.00887575
	LOSS [training: 0.23369912316136865 | validation: 0.3505098335514133]
	TIME [epoch: 7.59 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18567165466593966		[learning rate: 0.0088339]
	Learning Rate: 0.00883393
	LOSS [training: 0.18567165466593966 | validation: 0.3734248681159787]
	TIME [epoch: 7.58 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17397621761103305		[learning rate: 0.0087923]
	Learning Rate: 0.0087923
	LOSS [training: 0.17397621761103305 | validation: 0.331862756612378]
	TIME [epoch: 7.6 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2043982048896526		[learning rate: 0.0087509]
	Learning Rate: 0.00875087
	LOSS [training: 0.2043982048896526 | validation: 0.37345796326621306]
	TIME [epoch: 7.59 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21869688151884809		[learning rate: 0.0087096]
	Learning Rate: 0.00870964
	LOSS [training: 0.21869688151884809 | validation: 0.4571970768091199]
	TIME [epoch: 7.59 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20659318769536614		[learning rate: 0.0086686]
	Learning Rate: 0.00866859
	LOSS [training: 0.20659318769536614 | validation: 0.3439476496276553]
	TIME [epoch: 7.59 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18387724213784565		[learning rate: 0.0086277]
	Learning Rate: 0.00862775
	LOSS [training: 0.18387724213784565 | validation: 0.35280026955455174]
	TIME [epoch: 7.6 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2243569901138338		[learning rate: 0.0085871]
	Learning Rate: 0.00858709
	LOSS [training: 0.2243569901138338 | validation: 0.3042578317401504]
	TIME [epoch: 7.59 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v14b_20240719_004750/states/model_facs_v4_dec2b_2dpca_v14b_70.pth
	Model improved!!!
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18788762865329844		[learning rate: 0.0085466]
	Learning Rate: 0.00854663
	LOSS [training: 0.18788762865329844 | validation: 0.3938628569771163]
	TIME [epoch: 7.58 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22826319468287865		[learning rate: 0.0085064]
	Learning Rate: 0.00850636
	LOSS [training: 0.22826319468287865 | validation: 0.35681493730985675]
	TIME [epoch: 7.57 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17770549793514379		[learning rate: 0.0084663]
	Learning Rate: 0.00846627
	LOSS [training: 0.17770549793514379 | validation: 0.346556785482362]
	TIME [epoch: 7.58 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1807177892654233		[learning rate: 0.0084264]
	Learning Rate: 0.00842638
	LOSS [training: 0.1807177892654233 | validation: 0.30696727070938834]
	TIME [epoch: 7.58 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1955813921865949		[learning rate: 0.0083867]
	Learning Rate: 0.00838667
	LOSS [training: 0.1955813921865949 | validation: 0.34910622096465277]
	TIME [epoch: 7.58 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1894783251861106		[learning rate: 0.0083472]
	Learning Rate: 0.00834715
	LOSS [training: 0.1894783251861106 | validation: 0.38671657765003226]
	TIME [epoch: 7.57 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23431298220596636		[learning rate: 0.0083078]
	Learning Rate: 0.00830782
	LOSS [training: 0.23431298220596636 | validation: 0.3145326011497005]
	TIME [epoch: 7.57 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1802086155261902		[learning rate: 0.0082687]
	Learning Rate: 0.00826867
	LOSS [training: 0.1802086155261902 | validation: 0.34153700810880994]
	TIME [epoch: 7.57 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18486804562454573		[learning rate: 0.0082297]
	Learning Rate: 0.00822971
	LOSS [training: 0.18486804562454573 | validation: 0.3447351700082722]
	TIME [epoch: 7.58 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19182090344932212		[learning rate: 0.0081909]
	Learning Rate: 0.00819093
	LOSS [training: 0.19182090344932212 | validation: 0.41019265911255287]
	TIME [epoch: 7.57 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22531679207175667		[learning rate: 0.0081523]
	Learning Rate: 0.00815233
	LOSS [training: 0.22531679207175667 | validation: 0.3663664291065802]
	TIME [epoch: 7.56 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20176783784429697		[learning rate: 0.0081139]
	Learning Rate: 0.00811392
	LOSS [training: 0.20176783784429697 | validation: 0.3246230507157537]
	TIME [epoch: 7.57 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1443588931767144		[learning rate: 0.0080757]
	Learning Rate: 0.00807569
	LOSS [training: 0.1443588931767144 | validation: 0.3303734956092628]
	TIME [epoch: 7.58 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20364977685137897		[learning rate: 0.0080376]
	Learning Rate: 0.00803763
	LOSS [training: 0.20364977685137897 | validation: 0.3353541106592571]
	TIME [epoch: 7.57 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1678253967017705		[learning rate: 0.0079998]
	Learning Rate: 0.00799976
	LOSS [training: 0.1678253967017705 | validation: 0.43268115441458466]
	TIME [epoch: 7.57 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2306821672779729		[learning rate: 0.0079621]
	Learning Rate: 0.00796206
	LOSS [training: 0.2306821672779729 | validation: 0.36940542803581267]
	TIME [epoch: 7.56 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17180338252569965		[learning rate: 0.0079245]
	Learning Rate: 0.00792455
	LOSS [training: 0.17180338252569965 | validation: 0.3240288829440339]
	TIME [epoch: 7.58 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1915678782348321		[learning rate: 0.0078872]
	Learning Rate: 0.0078872
	LOSS [training: 0.1915678782348321 | validation: 0.4249724373536113]
	TIME [epoch: 7.57 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1862673475685275		[learning rate: 0.00785]
	Learning Rate: 0.00785004
	LOSS [training: 0.1862673475685275 | validation: 0.3361086949504043]
	TIME [epoch: 7.57 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15755939913009387		[learning rate: 0.007813]
	Learning Rate: 0.00781305
	LOSS [training: 0.15755939913009387 | validation: 0.3320865319233301]
	TIME [epoch: 7.57 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16738862424582215		[learning rate: 0.0077762]
	Learning Rate: 0.00777623
	LOSS [training: 0.16738862424582215 | validation: 0.3163118502218795]
	TIME [epoch: 7.58 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1402438502272122		[learning rate: 0.0077396]
	Learning Rate: 0.00773959
	LOSS [training: 0.1402438502272122 | validation: 0.3567597692730716]
	TIME [epoch: 7.58 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16520310335960775		[learning rate: 0.0077031]
	Learning Rate: 0.00770312
	LOSS [training: 0.16520310335960775 | validation: 0.4328987726949568]
	TIME [epoch: 7.57 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15431074046070808		[learning rate: 0.0076668]
	Learning Rate: 0.00766682
	LOSS [training: 0.15431074046070808 | validation: 0.4129624185761951]
	TIME [epoch: 7.57 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14513247197916437		[learning rate: 0.0076307]
	Learning Rate: 0.0076307
	LOSS [training: 0.14513247197916437 | validation: 0.3403474935110641]
	TIME [epoch: 7.57 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15861166680858263		[learning rate: 0.0075947]
	Learning Rate: 0.00759474
	LOSS [training: 0.15861166680858263 | validation: 0.4180606291686618]
	TIME [epoch: 7.58 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.212666628336096		[learning rate: 0.007559]
	Learning Rate: 0.00755895
	LOSS [training: 0.212666628336096 | validation: 0.3487533351114894]
	TIME [epoch: 7.57 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1714333091870667		[learning rate: 0.0075233]
	Learning Rate: 0.00752333
	LOSS [training: 0.1714333091870667 | validation: 0.33533881320655323]
	TIME [epoch: 7.57 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1803345745701398		[learning rate: 0.0074879]
	Learning Rate: 0.00748788
	LOSS [training: 0.1803345745701398 | validation: 0.3831272913777712]
	TIME [epoch: 7.58 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.222976421750344		[learning rate: 0.0074526]
	Learning Rate: 0.0074526
	LOSS [training: 0.222976421750344 | validation: 0.33395304368306994]
	TIME [epoch: 7.58 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1711781153713025		[learning rate: 0.0074175]
	Learning Rate: 0.00741748
	LOSS [training: 0.1711781153713025 | validation: 0.3286009559618924]
	TIME [epoch: 41.1 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16376161390416522		[learning rate: 0.0073825]
	Learning Rate: 0.00738253
	LOSS [training: 0.16376161390416522 | validation: 0.3869201839934493]
	TIME [epoch: 16.4 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18935191616110159		[learning rate: 0.0073477]
	Learning Rate: 0.00734774
	LOSS [training: 0.18935191616110159 | validation: 0.32880263010995525]
	TIME [epoch: 16.4 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14428491093991747		[learning rate: 0.0073131]
	Learning Rate: 0.00731312
	LOSS [training: 0.14428491093991747 | validation: 0.3318021595502402]
	TIME [epoch: 16.4 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16859203329801317		[learning rate: 0.0072787]
	Learning Rate: 0.00727866
	LOSS [training: 0.16859203329801317 | validation: 0.4050260477520975]
	TIME [epoch: 16.4 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16268356999079406		[learning rate: 0.0072444]
	Learning Rate: 0.00724436
	LOSS [training: 0.16268356999079406 | validation: 0.43903449891265306]
	TIME [epoch: 16.4 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16836219399356037		[learning rate: 0.0072102]
	Learning Rate: 0.00721022
	LOSS [training: 0.16836219399356037 | validation: 0.3439673881708274]
	TIME [epoch: 16.4 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15652884716882237		[learning rate: 0.0071762]
	Learning Rate: 0.00717625
	LOSS [training: 0.15652884716882237 | validation: 0.32727246622846506]
	TIME [epoch: 16.4 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1799205525977094		[learning rate: 0.0071424]
	Learning Rate: 0.00714243
	LOSS [training: 0.1799205525977094 | validation: 0.42138843085605343]
	TIME [epoch: 16.4 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15019351095507835		[learning rate: 0.0071088]
	Learning Rate: 0.00710878
	LOSS [training: 0.15019351095507835 | validation: 0.3242328869295055]
	TIME [epoch: 16.4 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14727115476142238		[learning rate: 0.0070753]
	Learning Rate: 0.00707528
	LOSS [training: 0.14727115476142238 | validation: 0.35021610593120195]
	TIME [epoch: 16.4 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17186916977987637		[learning rate: 0.0070419]
	Learning Rate: 0.00704194
	LOSS [training: 0.17186916977987637 | validation: 0.3474704386555697]
	TIME [epoch: 16.4 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15967108342667902		[learning rate: 0.0070088]
	Learning Rate: 0.00700876
	LOSS [training: 0.15967108342667902 | validation: 0.376963157760567]
	TIME [epoch: 16.4 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15270269073877296		[learning rate: 0.0069757]
	Learning Rate: 0.00697573
	LOSS [training: 0.15270269073877296 | validation: 0.3737469411896826]
	TIME [epoch: 16.4 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16692061729914268		[learning rate: 0.0069429]
	Learning Rate: 0.00694286
	LOSS [training: 0.16692061729914268 | validation: 0.40111140960331915]
	TIME [epoch: 16.4 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14251362450382807		[learning rate: 0.0069101]
	Learning Rate: 0.00691014
	LOSS [training: 0.14251362450382807 | validation: 0.29686565082301664]
	TIME [epoch: 16.4 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v14b_20240719_004750/states/model_facs_v4_dec2b_2dpca_v14b_116.pth
	Model improved!!!
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15622500269553788		[learning rate: 0.0068776]
	Learning Rate: 0.00687758
	LOSS [training: 0.15622500269553788 | validation: 0.4351654839566929]
	TIME [epoch: 16.4 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1427413199543444		[learning rate: 0.0068452]
	Learning Rate: 0.00684518
	LOSS [training: 0.1427413199543444 | validation: 0.3819511513238955]
	TIME [epoch: 16.4 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16627004918405158		[learning rate: 0.0068129]
	Learning Rate: 0.00681292
	LOSS [training: 0.16627004918405158 | validation: 0.34589363119406924]
	TIME [epoch: 16.4 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1668325210983331		[learning rate: 0.0067808]
	Learning Rate: 0.00678082
	LOSS [training: 0.1668325210983331 | validation: 0.31651966143963006]
	TIME [epoch: 16.4 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17170222525702428		[learning rate: 0.0067489]
	Learning Rate: 0.00674887
	LOSS [training: 0.17170222525702428 | validation: 0.3534483987458976]
	TIME [epoch: 16.4 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18170718794082447		[learning rate: 0.0067171]
	Learning Rate: 0.00671706
	LOSS [training: 0.18170718794082447 | validation: 0.3290855392716016]
	TIME [epoch: 16.4 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1329472474070127		[learning rate: 0.0066854]
	Learning Rate: 0.00668541
	LOSS [training: 0.1329472474070127 | validation: 0.3277011818078748]
	TIME [epoch: 16.4 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16388562735074352		[learning rate: 0.0066539]
	Learning Rate: 0.00665391
	LOSS [training: 0.16388562735074352 | validation: 0.3770310870698488]
	TIME [epoch: 16.4 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.177383386889104		[learning rate: 0.0066226]
	Learning Rate: 0.00662256
	LOSS [training: 0.177383386889104 | validation: 0.36569233106763904]
	TIME [epoch: 16.4 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19596103445489954		[learning rate: 0.0065913]
	Learning Rate: 0.00659135
	LOSS [training: 0.19596103445489954 | validation: 0.3285206790348267]
	TIME [epoch: 16.4 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16916759805144482		[learning rate: 0.0065603]
	Learning Rate: 0.00656029
	LOSS [training: 0.16916759805144482 | validation: 0.3713485575125797]
	TIME [epoch: 16.4 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17374074563284733		[learning rate: 0.0065294]
	Learning Rate: 0.00652938
	LOSS [training: 0.17374074563284733 | validation: 0.3016430759688613]
	TIME [epoch: 16.4 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14328546043504806		[learning rate: 0.0064986]
	Learning Rate: 0.00649861
	LOSS [training: 0.14328546043504806 | validation: 0.3951980300346573]
	TIME [epoch: 16.4 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14517521806725683		[learning rate: 0.006468]
	Learning Rate: 0.00646799
	LOSS [training: 0.14517521806725683 | validation: 0.40793048158547807]
	TIME [epoch: 16.4 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15946725467230433		[learning rate: 0.0064375]
	Learning Rate: 0.00643751
	LOSS [training: 0.15946725467230433 | validation: 0.32439429075413223]
	TIME [epoch: 16.4 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14906862735089488		[learning rate: 0.0064072]
	Learning Rate: 0.00640718
	LOSS [training: 0.14906862735089488 | validation: 0.3661127387420549]
	TIME [epoch: 16.4 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13815356173777016		[learning rate: 0.006377]
	Learning Rate: 0.00637698
	LOSS [training: 0.13815356173777016 | validation: 0.34471513705265794]
	TIME [epoch: 16.4 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15390492447632087		[learning rate: 0.0063469]
	Learning Rate: 0.00634694
	LOSS [training: 0.15390492447632087 | validation: 0.3076654220889161]
	TIME [epoch: 16.4 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1647675529524613		[learning rate: 0.006317]
	Learning Rate: 0.00631703
	LOSS [training: 0.1647675529524613 | validation: 0.3171509416509347]
	TIME [epoch: 16.4 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1432044048171912		[learning rate: 0.0062873]
	Learning Rate: 0.00628726
	LOSS [training: 0.1432044048171912 | validation: 0.3160284817576556]
	TIME [epoch: 16.4 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16485280401127395		[learning rate: 0.0062576]
	Learning Rate: 0.00625764
	LOSS [training: 0.16485280401127395 | validation: 0.42740814988623566]
	TIME [epoch: 16.4 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18380237472384098		[learning rate: 0.0062281]
	Learning Rate: 0.00622815
	LOSS [training: 0.18380237472384098 | validation: 0.3601635258679434]
	TIME [epoch: 16.4 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15294620549424068		[learning rate: 0.0061988]
	Learning Rate: 0.0061988
	LOSS [training: 0.15294620549424068 | validation: 0.32971576649633205]
	TIME [epoch: 16.4 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14164895291324145		[learning rate: 0.0061696]
	Learning Rate: 0.00616959
	LOSS [training: 0.14164895291324145 | validation: 0.3362072686018898]
	TIME [epoch: 16.4 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13739534408997842		[learning rate: 0.0061405]
	Learning Rate: 0.00614052
	LOSS [training: 0.13739534408997842 | validation: 0.34730852974183135]
	TIME [epoch: 16.4 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16412449835979454		[learning rate: 0.0061116]
	Learning Rate: 0.00611158
	LOSS [training: 0.16412449835979454 | validation: 0.35569264044078874]
	TIME [epoch: 16.4 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15857898436451826		[learning rate: 0.0060828]
	Learning Rate: 0.00608279
	LOSS [training: 0.15857898436451826 | validation: 0.33449197389505503]
	TIME [epoch: 16.4 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15276334901892688		[learning rate: 0.0060541]
	Learning Rate: 0.00605412
	LOSS [training: 0.15276334901892688 | validation: 0.2947575710426883]
	TIME [epoch: 16.4 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v14b_20240719_004750/states/model_facs_v4_dec2b_2dpca_v14b_144.pth
	Model improved!!!
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15559669783767732		[learning rate: 0.0060256]
	Learning Rate: 0.0060256
	LOSS [training: 0.15559669783767732 | validation: 0.4529598562461489]
	TIME [epoch: 16.4 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15520100748642246		[learning rate: 0.0059972]
	Learning Rate: 0.0059972
	LOSS [training: 0.15520100748642246 | validation: 0.29616784396608153]
	TIME [epoch: 16.4 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13588717788580196		[learning rate: 0.0059689]
	Learning Rate: 0.00596894
	LOSS [training: 0.13588717788580196 | validation: 0.4049558567963502]
	TIME [epoch: 16.4 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14347552547446873		[learning rate: 0.0059408]
	Learning Rate: 0.00594082
	LOSS [training: 0.14347552547446873 | validation: 0.3186830311595941]
	TIME [epoch: 16.4 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1476782734147159		[learning rate: 0.0059128]
	Learning Rate: 0.00591282
	LOSS [training: 0.1476782734147159 | validation: 0.3072214770185917]
	TIME [epoch: 16.4 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1527981723804273		[learning rate: 0.005885]
	Learning Rate: 0.00588496
	LOSS [training: 0.1527981723804273 | validation: 0.29302252103318593]
	TIME [epoch: 16.4 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v14b_20240719_004750/states/model_facs_v4_dec2b_2dpca_v14b_150.pth
	Model improved!!!
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14249452213493172		[learning rate: 0.0058572]
	Learning Rate: 0.00585723
	LOSS [training: 0.14249452213493172 | validation: 0.4130465345208365]
	TIME [epoch: 16.5 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19856509083918567		[learning rate: 0.0058296]
	Learning Rate: 0.00582963
	LOSS [training: 0.19856509083918567 | validation: 0.37107280241507645]
	TIME [epoch: 16.4 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16255614202151455		[learning rate: 0.0058022]
	Learning Rate: 0.00580216
	LOSS [training: 0.16255614202151455 | validation: 0.38011841619873366]
	TIME [epoch: 16.4 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15141057792881935		[learning rate: 0.0057748]
	Learning Rate: 0.00577482
	LOSS [training: 0.15141057792881935 | validation: 0.3180900139341808]
	TIME [epoch: 16.4 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15595428210188317		[learning rate: 0.0057476]
	Learning Rate: 0.00574761
	LOSS [training: 0.15595428210188317 | validation: 0.45609747224912467]
	TIME [epoch: 16.4 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1495285251217587		[learning rate: 0.0057205]
	Learning Rate: 0.00572052
	LOSS [training: 0.1495285251217587 | validation: 0.45338087794023985]
	TIME [epoch: 16.4 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17569053009318933		[learning rate: 0.0056936]
	Learning Rate: 0.00569357
	LOSS [training: 0.17569053009318933 | validation: 0.41754167342746856]
	TIME [epoch: 16.4 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1638782786320908		[learning rate: 0.0056667]
	Learning Rate: 0.00566674
	LOSS [training: 0.1638782786320908 | validation: 0.34004301053667985]
	TIME [epoch: 16.4 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12392038553335682		[learning rate: 0.00564]
	Learning Rate: 0.00564004
	LOSS [training: 0.12392038553335682 | validation: 0.32461582801481226]
	TIME [epoch: 16.4 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13790880955660634		[learning rate: 0.0056135]
	Learning Rate: 0.00561346
	LOSS [training: 0.13790880955660634 | validation: 0.43513455309606874]
	TIME [epoch: 16.4 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13374333083024867		[learning rate: 0.005587]
	Learning Rate: 0.00558701
	LOSS [training: 0.13374333083024867 | validation: 0.36182763750061697]
	TIME [epoch: 16.4 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13583715104182914		[learning rate: 0.0055607]
	Learning Rate: 0.00556068
	LOSS [training: 0.13583715104182914 | validation: 0.3969592711629917]
	TIME [epoch: 16.4 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1415255208913		[learning rate: 0.0055345]
	Learning Rate: 0.00553448
	LOSS [training: 0.1415255208913 | validation: 0.3619372113688095]
	TIME [epoch: 16.4 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19783232235836873		[learning rate: 0.0055084]
	Learning Rate: 0.0055084
	LOSS [training: 0.19783232235836873 | validation: 0.29520619198493936]
	TIME [epoch: 16.4 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1582467510265271		[learning rate: 0.0054824]
	Learning Rate: 0.00548245
	LOSS [training: 0.1582467510265271 | validation: 0.4841114794282788]
	TIME [epoch: 16.4 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1447553969354364		[learning rate: 0.0054566]
	Learning Rate: 0.00545661
	LOSS [training: 0.1447553969354364 | validation: 0.376095229488843]
	TIME [epoch: 16.4 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14737945159479074		[learning rate: 0.0054309]
	Learning Rate: 0.0054309
	LOSS [training: 0.14737945159479074 | validation: 0.3483150636170641]
	TIME [epoch: 16.4 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12323748011528367		[learning rate: 0.0054053]
	Learning Rate: 0.00540531
	LOSS [training: 0.12323748011528367 | validation: 0.3479081636025389]
	TIME [epoch: 16.4 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1501018787267007		[learning rate: 0.0053798]
	Learning Rate: 0.00537984
	LOSS [training: 0.1501018787267007 | validation: 0.4652285152715108]
	TIME [epoch: 16.4 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16109649802260237		[learning rate: 0.0053545]
	Learning Rate: 0.00535449
	LOSS [training: 0.16109649802260237 | validation: 0.35422127880490817]
	TIME [epoch: 16.4 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17321746686234482		[learning rate: 0.0053293]
	Learning Rate: 0.00532926
	LOSS [training: 0.17321746686234482 | validation: 0.3253303608468199]
	TIME [epoch: 16.4 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1321935413436487		[learning rate: 0.0053041]
	Learning Rate: 0.00530415
	LOSS [training: 0.1321935413436487 | validation: 0.3468919847959476]
	TIME [epoch: 16.4 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14696443770814183		[learning rate: 0.0052792]
	Learning Rate: 0.00527915
	LOSS [training: 0.14696443770814183 | validation: 0.30478234541807525]
	TIME [epoch: 16.4 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1452262784920071		[learning rate: 0.0052543]
	Learning Rate: 0.00525428
	LOSS [training: 0.1452262784920071 | validation: 0.3209041023779515]
	TIME [epoch: 16.4 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13536768749762337		[learning rate: 0.0052295]
	Learning Rate: 0.00522952
	LOSS [training: 0.13536768749762337 | validation: 0.3824213072665192]
	TIME [epoch: 16.4 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.140172113180966		[learning rate: 0.0052049]
	Learning Rate: 0.00520487
	LOSS [training: 0.140172113180966 | validation: 0.3388183047949212]
	TIME [epoch: 16.4 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15368663080554795		[learning rate: 0.0051803]
	Learning Rate: 0.00518035
	LOSS [training: 0.15368663080554795 | validation: 0.3235250232096549]
	TIME [epoch: 16.4 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16101789370695105		[learning rate: 0.0051559]
	Learning Rate: 0.00515594
	LOSS [training: 0.16101789370695105 | validation: 0.32952606562101944]
	TIME [epoch: 16.4 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13599499249324926		[learning rate: 0.0051316]
	Learning Rate: 0.00513164
	LOSS [training: 0.13599499249324926 | validation: 0.3009170773848078]
	TIME [epoch: 16.4 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.138147741949541		[learning rate: 0.0051075]
	Learning Rate: 0.00510746
	LOSS [training: 0.138147741949541 | validation: 0.35116218565502133]
	TIME [epoch: 16.4 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15593772950202855		[learning rate: 0.0050834]
	Learning Rate: 0.00508339
	LOSS [training: 0.15593772950202855 | validation: 0.30857426988878334]
	TIME [epoch: 16.4 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14609423698096477		[learning rate: 0.0050594]
	Learning Rate: 0.00505944
	LOSS [training: 0.14609423698096477 | validation: 0.30468793157094654]
	TIME [epoch: 16.4 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12877016610023423		[learning rate: 0.0050356]
	Learning Rate: 0.0050356
	LOSS [training: 0.12877016610023423 | validation: 0.4254845926623469]
	TIME [epoch: 16.4 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14494417427527337		[learning rate: 0.0050119]
	Learning Rate: 0.00501187
	LOSS [training: 0.14494417427527337 | validation: 0.3385783293203334]
	TIME [epoch: 16.4 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14190388183222014		[learning rate: 0.0049883]
	Learning Rate: 0.00498826
	LOSS [training: 0.14190388183222014 | validation: 0.32911313816235666]
	TIME [epoch: 16.4 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14940029672221408		[learning rate: 0.0049648]
	Learning Rate: 0.00496475
	LOSS [training: 0.14940029672221408 | validation: 0.3044309183332394]
	TIME [epoch: 16.4 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1329658647822651		[learning rate: 0.0049414]
	Learning Rate: 0.00494136
	LOSS [training: 0.1329658647822651 | validation: 0.32848529995184417]
	TIME [epoch: 16.4 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1623420095086641		[learning rate: 0.0049181]
	Learning Rate: 0.00491807
	LOSS [training: 0.1623420095086641 | validation: 0.3480111059288403]
	TIME [epoch: 16.4 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13481355662070404		[learning rate: 0.0048949]
	Learning Rate: 0.0048949
	LOSS [training: 0.13481355662070404 | validation: 0.3598314536438831]
	TIME [epoch: 16.4 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1240269351330576		[learning rate: 0.0048718]
	Learning Rate: 0.00487183
	LOSS [training: 0.1240269351330576 | validation: 0.3268021763746675]
	TIME [epoch: 16.4 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12443204210030645		[learning rate: 0.0048489]
	Learning Rate: 0.00484888
	LOSS [training: 0.12443204210030645 | validation: 0.35193057869542865]
	TIME [epoch: 16.4 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14217853095312138		[learning rate: 0.004826]
	Learning Rate: 0.00482603
	LOSS [training: 0.14217853095312138 | validation: 0.3084184177024332]
	TIME [epoch: 16.4 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13178312179273022		[learning rate: 0.0048033]
	Learning Rate: 0.00480329
	LOSS [training: 0.13178312179273022 | validation: 0.3267667527778464]
	TIME [epoch: 16.4 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.126477173559023		[learning rate: 0.0047807]
	Learning Rate: 0.00478065
	LOSS [training: 0.126477173559023 | validation: 0.3131496424978988]
	TIME [epoch: 16.4 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1389948182270179		[learning rate: 0.0047581]
	Learning Rate: 0.00475813
	LOSS [training: 0.1389948182270179 | validation: 0.34063126487395795]
	TIME [epoch: 16.4 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14836987442647476		[learning rate: 0.0047357]
	Learning Rate: 0.0047357
	LOSS [training: 0.14836987442647476 | validation: 0.4305572207059345]
	TIME [epoch: 16.4 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15496347314678885		[learning rate: 0.0047134]
	Learning Rate: 0.00471339
	LOSS [training: 0.15496347314678885 | validation: 0.3670597611532319]
	TIME [epoch: 16.4 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15984049411984538		[learning rate: 0.0046912]
	Learning Rate: 0.00469118
	LOSS [training: 0.15984049411984538 | validation: 0.3176763196531286]
	TIME [epoch: 16.4 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12681202184816526		[learning rate: 0.0046691]
	Learning Rate: 0.00466907
	LOSS [training: 0.12681202184816526 | validation: 0.3408324739921914]
	TIME [epoch: 16.4 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1437245721992308		[learning rate: 0.0046471]
	Learning Rate: 0.00464707
	LOSS [training: 0.1437245721992308 | validation: 0.2990608305104606]
	TIME [epoch: 16.4 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1487833584480757		[learning rate: 0.0046252]
	Learning Rate: 0.00462518
	LOSS [training: 0.1487833584480757 | validation: 0.3257460192883612]
	TIME [epoch: 59.7 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15320692856111945		[learning rate: 0.0046034]
	Learning Rate: 0.00460338
	LOSS [training: 0.15320692856111945 | validation: 0.2735405866277057]
	TIME [epoch: 35.3 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v14b_20240719_004750/states/model_facs_v4_dec2b_2dpca_v14b_202.pth
	Model improved!!!
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14272847839970806		[learning rate: 0.0045817]
	Learning Rate: 0.00458169
	LOSS [training: 0.14272847839970806 | validation: 0.3120209894400726]
	TIME [epoch: 35.3 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1464209630086452		[learning rate: 0.0045601]
	Learning Rate: 0.0045601
	LOSS [training: 0.1464209630086452 | validation: 0.31646222059291246]
	TIME [epoch: 35.3 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12366191053407762		[learning rate: 0.0045386]
	Learning Rate: 0.00453861
	LOSS [training: 0.12366191053407762 | validation: 0.36441669410588534]
	TIME [epoch: 35.3 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13469363297735998		[learning rate: 0.0045172]
	Learning Rate: 0.00451723
	LOSS [training: 0.13469363297735998 | validation: 0.32845214099272857]
	TIME [epoch: 35.3 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11345712652834698		[learning rate: 0.0044959]
	Learning Rate: 0.00449594
	LOSS [training: 0.11345712652834698 | validation: 0.3408914502701961]
	TIME [epoch: 35.3 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14812888003619729		[learning rate: 0.0044748]
	Learning Rate: 0.00447475
	LOSS [training: 0.14812888003619729 | validation: 0.31712206779152213]
	TIME [epoch: 35.3 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14431921389293897		[learning rate: 0.0044537]
	Learning Rate: 0.00445367
	LOSS [training: 0.14431921389293897 | validation: 0.3275096066538767]
	TIME [epoch: 35.3 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15543682002217468		[learning rate: 0.0044327]
	Learning Rate: 0.00443268
	LOSS [training: 0.15543682002217468 | validation: 0.3899656339401058]
	TIME [epoch: 35.3 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1282175905553407		[learning rate: 0.0044118]
	Learning Rate: 0.0044118
	LOSS [training: 0.1282175905553407 | validation: 0.37179514928274293]
	TIME [epoch: 35.3 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1357603579758299		[learning rate: 0.004391]
	Learning Rate: 0.00439101
	LOSS [training: 0.1357603579758299 | validation: 0.3240336305713199]
	TIME [epoch: 35.3 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12879351184108298		[learning rate: 0.0043703]
	Learning Rate: 0.00437032
	LOSS [training: 0.12879351184108298 | validation: 0.34316217887785505]
	TIME [epoch: 35.3 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13164481475681478		[learning rate: 0.0043497]
	Learning Rate: 0.00434972
	LOSS [training: 0.13164481475681478 | validation: 0.30945280501277417]
	TIME [epoch: 35.3 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1461540557236126		[learning rate: 0.0043292]
	Learning Rate: 0.00432923
	LOSS [training: 0.1461540557236126 | validation: 0.4787330450759861]
	TIME [epoch: 35.3 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12724996500291127		[learning rate: 0.0043088]
	Learning Rate: 0.00430883
	LOSS [training: 0.12724996500291127 | validation: 0.3161682625838003]
	TIME [epoch: 35.3 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12119286312785943		[learning rate: 0.0042885]
	Learning Rate: 0.00428852
	LOSS [training: 0.12119286312785943 | validation: 0.3377133335848109]
	TIME [epoch: 35.3 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1349472994308986		[learning rate: 0.0042683]
	Learning Rate: 0.00426831
	LOSS [training: 0.1349472994308986 | validation: 0.29578793727781355]
	TIME [epoch: 35.2 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12425300876910655		[learning rate: 0.0042482]
	Learning Rate: 0.0042482
	LOSS [training: 0.12425300876910655 | validation: 0.35313130425731865]
	TIME [epoch: 35.2 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13723359584360734		[learning rate: 0.0042282]
	Learning Rate: 0.00422818
	LOSS [training: 0.13723359584360734 | validation: 0.3623524613698557]
	TIME [epoch: 35.3 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14719643000564092		[learning rate: 0.0042083]
	Learning Rate: 0.00420826
	LOSS [training: 0.14719643000564092 | validation: 0.4005605569705923]
	TIME [epoch: 35.3 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12497346688131518		[learning rate: 0.0041884]
	Learning Rate: 0.00418843
	LOSS [training: 0.12497346688131518 | validation: 0.32310432160319263]
	TIME [epoch: 35.3 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14954913406724893		[learning rate: 0.0041687]
	Learning Rate: 0.00416869
	LOSS [training: 0.14954913406724893 | validation: 0.39601917730080116]
	TIME [epoch: 35.3 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13638752961402717		[learning rate: 0.0041491]
	Learning Rate: 0.00414905
	LOSS [training: 0.13638752961402717 | validation: 0.4030765584382354]
	TIME [epoch: 35.3 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13164778926254259		[learning rate: 0.0041295]
	Learning Rate: 0.0041295
	LOSS [training: 0.13164778926254259 | validation: 0.3199091092850072]
	TIME [epoch: 35.3 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12819628475737985		[learning rate: 0.00411]
	Learning Rate: 0.00411004
	LOSS [training: 0.12819628475737985 | validation: 0.3313857441834049]
	TIME [epoch: 35.3 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1695755072515107		[learning rate: 0.0040907]
	Learning Rate: 0.00409067
	LOSS [training: 0.1695755072515107 | validation: 0.31988817888504645]
	TIME [epoch: 35.3 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12296623896314013		[learning rate: 0.0040714]
	Learning Rate: 0.0040714
	LOSS [training: 0.12296623896314013 | validation: 0.3470536000801681]
	TIME [epoch: 35.3 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13292728869110643		[learning rate: 0.0040522]
	Learning Rate: 0.00405221
	LOSS [training: 0.13292728869110643 | validation: 0.3729827990053827]
	TIME [epoch: 35.3 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12916870331025032		[learning rate: 0.0040331]
	Learning Rate: 0.00403312
	LOSS [training: 0.12916870331025032 | validation: 0.2911835518408873]
	TIME [epoch: 35.3 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11551692428476941		[learning rate: 0.0040141]
	Learning Rate: 0.00401411
	LOSS [training: 0.11551692428476941 | validation: 0.3182507095731052]
	TIME [epoch: 35.3 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12130789079317054		[learning rate: 0.0039952]
	Learning Rate: 0.0039952
	LOSS [training: 0.12130789079317054 | validation: 0.31359865295220274]
	TIME [epoch: 35.3 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15176980376818888		[learning rate: 0.0039764]
	Learning Rate: 0.00397637
	LOSS [training: 0.15176980376818888 | validation: 0.3453759685170623]
	TIME [epoch: 35.3 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13144725084342818		[learning rate: 0.0039576]
	Learning Rate: 0.00395764
	LOSS [training: 0.13144725084342818 | validation: 0.3474230883821992]
	TIME [epoch: 35.3 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1298922729714435		[learning rate: 0.003939]
	Learning Rate: 0.00393899
	LOSS [training: 0.1298922729714435 | validation: 0.32557040135084514]
	TIME [epoch: 35.3 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1322989146899124		[learning rate: 0.0039204]
	Learning Rate: 0.00392043
	LOSS [training: 0.1322989146899124 | validation: 0.32875897828935874]
	TIME [epoch: 35.3 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15002776300701956		[learning rate: 0.003902]
	Learning Rate: 0.00390195
	LOSS [training: 0.15002776300701956 | validation: 0.3735375482497589]
	TIME [epoch: 35.3 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12724721881272968		[learning rate: 0.0038836]
	Learning Rate: 0.00388357
	LOSS [training: 0.12724721881272968 | validation: 0.3649767591264394]
	TIME [epoch: 35.3 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14660368672079288		[learning rate: 0.0038653]
	Learning Rate: 0.00386527
	LOSS [training: 0.14660368672079288 | validation: 0.30223349216970924]
	TIME [epoch: 35.3 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12413810500181315		[learning rate: 0.0038471]
	Learning Rate: 0.00384705
	LOSS [training: 0.12413810500181315 | validation: 0.3212180003761128]
	TIME [epoch: 35.3 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13387809139925025		[learning rate: 0.0038289]
	Learning Rate: 0.00382893
	LOSS [training: 0.13387809139925025 | validation: 0.29601648687982807]
	TIME [epoch: 35.3 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10325330967530441		[learning rate: 0.0038109]
	Learning Rate: 0.00381088
	LOSS [training: 0.10325330967530441 | validation: 0.2997533144896031]
	TIME [epoch: 35.3 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12515525120823126		[learning rate: 0.0037929]
	Learning Rate: 0.00379293
	LOSS [training: 0.12515525120823126 | validation: 0.32607837729258016]
	TIME [epoch: 35.3 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14380944789380382		[learning rate: 0.0037751]
	Learning Rate: 0.00377505
	LOSS [training: 0.14380944789380382 | validation: 0.3140067501394895]
	TIME [epoch: 35.3 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14430925477520345		[learning rate: 0.0037573]
	Learning Rate: 0.00375726
	LOSS [training: 0.14430925477520345 | validation: 0.2892087598215691]
	TIME [epoch: 35.3 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13466282079323594		[learning rate: 0.0037396]
	Learning Rate: 0.00373956
	LOSS [training: 0.13466282079323594 | validation: 0.2851797613985485]
	TIME [epoch: 35.3 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1261790818724028		[learning rate: 0.0037219]
	Learning Rate: 0.00372194
	LOSS [training: 0.1261790818724028 | validation: 0.3337950913260611]
	TIME [epoch: 35.3 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14543626204870924		[learning rate: 0.0037044]
	Learning Rate: 0.0037044
	LOSS [training: 0.14543626204870924 | validation: 0.30599247490324]
	TIME [epoch: 35.3 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1589405788910678		[learning rate: 0.0036869]
	Learning Rate: 0.00368695
	LOSS [training: 0.1589405788910678 | validation: 0.305837789967088]
	TIME [epoch: 35.3 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13880623463074643		[learning rate: 0.0036696]
	Learning Rate: 0.00366957
	LOSS [training: 0.13880623463074643 | validation: 0.33321682003080655]
	TIME [epoch: 35.3 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12292775646508439		[learning rate: 0.0036523]
	Learning Rate: 0.00365228
	LOSS [training: 0.12292775646508439 | validation: 0.3090723020792936]
	TIME [epoch: 35.3 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11959920598955687		[learning rate: 0.0036351]
	Learning Rate: 0.00363507
	LOSS [training: 0.11959920598955687 | validation: 0.3246325147286914]
	TIME [epoch: 35.3 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12087034884031382		[learning rate: 0.0036179]
	Learning Rate: 0.00361794
	LOSS [training: 0.12087034884031382 | validation: 0.3202042408916316]
	TIME [epoch: 35.2 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1207096146200098		[learning rate: 0.0036009]
	Learning Rate: 0.00360089
	LOSS [training: 0.1207096146200098 | validation: 0.3090490305622898]
	TIME [epoch: 35.3 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13316886018813492		[learning rate: 0.0035839]
	Learning Rate: 0.00358393
	LOSS [training: 0.13316886018813492 | validation: 0.2866153530882185]
	TIME [epoch: 35.3 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13076588722486848		[learning rate: 0.003567]
	Learning Rate: 0.00356704
	LOSS [training: 0.13076588722486848 | validation: 0.2802863473628616]
	TIME [epoch: 35.2 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12361261503113377		[learning rate: 0.0035502]
	Learning Rate: 0.00355023
	LOSS [training: 0.12361261503113377 | validation: 0.27113483243665437]
	TIME [epoch: 35.3 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v14b_20240719_004750/states/model_facs_v4_dec2b_2dpca_v14b_257.pth
	Model improved!!!
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.138140102462557		[learning rate: 0.0035335]
	Learning Rate: 0.0035335
	LOSS [training: 0.138140102462557 | validation: 0.3512740232695125]
	TIME [epoch: 35.3 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1586646631359953		[learning rate: 0.0035168]
	Learning Rate: 0.00351685
	LOSS [training: 0.1586646631359953 | validation: 0.4985795019904021]
	TIME [epoch: 35.3 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14516354548540195		[learning rate: 0.0035003]
	Learning Rate: 0.00350028
	LOSS [training: 0.14516354548540195 | validation: 0.4568629794556094]
	TIME [epoch: 35.3 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14321786827249622		[learning rate: 0.0034838]
	Learning Rate: 0.00348378
	LOSS [training: 0.14321786827249622 | validation: 0.35342004546244266]
	TIME [epoch: 35.2 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12604288868910885		[learning rate: 0.0034674]
	Learning Rate: 0.00346737
	LOSS [training: 0.12604288868910885 | validation: 0.35357588088022274]
	TIME [epoch: 35.3 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13137494316525195		[learning rate: 0.003451]
	Learning Rate: 0.00345103
	LOSS [training: 0.13137494316525195 | validation: 0.35740187976040566]
	TIME [epoch: 35.3 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12094168590946003		[learning rate: 0.0034348]
	Learning Rate: 0.00343477
	LOSS [training: 0.12094168590946003 | validation: 0.28508222881660256]
	TIME [epoch: 35.2 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12079729191208036		[learning rate: 0.0034186]
	Learning Rate: 0.00341858
	LOSS [training: 0.12079729191208036 | validation: 0.2902665546762536]
	TIME [epoch: 35.3 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1317081093114973		[learning rate: 0.0034025]
	Learning Rate: 0.00340247
	LOSS [training: 0.1317081093114973 | validation: 0.2692781415637623]
	TIME [epoch: 35.2 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v14b_20240719_004750/states/model_facs_v4_dec2b_2dpca_v14b_266.pth
	Model improved!!!
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1265578050553821		[learning rate: 0.0033864]
	Learning Rate: 0.00338644
	LOSS [training: 0.1265578050553821 | validation: 0.2760836329405591]
	TIME [epoch: 35.3 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11842779708092814		[learning rate: 0.0033705]
	Learning Rate: 0.00337048
	LOSS [training: 0.11842779708092814 | validation: 0.3100116923415039]
	TIME [epoch: 35.3 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12813575490481738		[learning rate: 0.0033546]
	Learning Rate: 0.0033546
	LOSS [training: 0.12813575490481738 | validation: 0.31193785408052344]
	TIME [epoch: 35.3 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11592215937507383		[learning rate: 0.0033388]
	Learning Rate: 0.00333879
	LOSS [training: 0.11592215937507383 | validation: 0.30559400050371166]
	TIME [epoch: 35.2 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1398771769102073		[learning rate: 0.0033231]
	Learning Rate: 0.00332306
	LOSS [training: 0.1398771769102073 | validation: 0.40850423049781526]
	TIME [epoch: 35.2 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12696451502011072		[learning rate: 0.0033074]
	Learning Rate: 0.0033074
	LOSS [training: 0.12696451502011072 | validation: 0.313016428676201]
	TIME [epoch: 35.3 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13946051896129258		[learning rate: 0.0032918]
	Learning Rate: 0.00329182
	LOSS [training: 0.13946051896129258 | validation: 0.30955025056117397]
	TIME [epoch: 35.3 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11645240254704453		[learning rate: 0.0032763]
	Learning Rate: 0.00327631
	LOSS [training: 0.11645240254704453 | validation: 0.33157785817344315]
	TIME [epoch: 35.3 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12263689548120668		[learning rate: 0.0032609]
	Learning Rate: 0.00326087
	LOSS [training: 0.12263689548120668 | validation: 0.41211717242002804]
	TIME [epoch: 35.2 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13552608347937226		[learning rate: 0.0032455]
	Learning Rate: 0.0032455
	LOSS [training: 0.13552608347937226 | validation: 0.3327971673424854]
	TIME [epoch: 35.3 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1139737763491155		[learning rate: 0.0032302]
	Learning Rate: 0.00323021
	LOSS [training: 0.1139737763491155 | validation: 0.2820135868859951]
	TIME [epoch: 35.2 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13048478269758929		[learning rate: 0.003215]
	Learning Rate: 0.00321499
	LOSS [training: 0.13048478269758929 | validation: 0.3314460482524107]
	TIME [epoch: 35.3 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14054491670318417		[learning rate: 0.0031998]
	Learning Rate: 0.00319984
	LOSS [training: 0.14054491670318417 | validation: 0.32300664558230635]
	TIME [epoch: 35.3 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13203977077423704		[learning rate: 0.0031848]
	Learning Rate: 0.00318476
	LOSS [training: 0.13203977077423704 | validation: 0.28635316781718534]
	TIME [epoch: 35.3 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12914232055381925		[learning rate: 0.0031698]
	Learning Rate: 0.00316975
	LOSS [training: 0.12914232055381925 | validation: 0.35096961596666987]
	TIME [epoch: 35.3 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13807818950555678		[learning rate: 0.0031548]
	Learning Rate: 0.00315482
	LOSS [training: 0.13807818950555678 | validation: 0.30018332186324337]
	TIME [epoch: 35.2 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12140045822106366		[learning rate: 0.00314]
	Learning Rate: 0.00313995
	LOSS [training: 0.12140045822106366 | validation: 0.32079801928044877]
	TIME [epoch: 35.3 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12860299031759406		[learning rate: 0.0031252]
	Learning Rate: 0.00312516
	LOSS [training: 0.12860299031759406 | validation: 0.3207036153047898]
	TIME [epoch: 35.3 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11405348088782585		[learning rate: 0.0031104]
	Learning Rate: 0.00311043
	LOSS [training: 0.11405348088782585 | validation: 0.36282710100710047]
	TIME [epoch: 35.3 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11359491886130849		[learning rate: 0.0030958]
	Learning Rate: 0.00309577
	LOSS [training: 0.11359491886130849 | validation: 0.36121229672206]
	TIME [epoch: 35.3 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12071964980830387		[learning rate: 0.0030812]
	Learning Rate: 0.00308119
	LOSS [training: 0.12071964980830387 | validation: 0.33320073031962694]
	TIME [epoch: 35.3 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1285948386681148		[learning rate: 0.0030667]
	Learning Rate: 0.00306667
	LOSS [training: 0.1285948386681148 | validation: 0.30724739837738035]
	TIME [epoch: 35.3 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1270853227428959		[learning rate: 0.0030522]
	Learning Rate: 0.00305222
	LOSS [training: 0.1270853227428959 | validation: 0.3164501380269133]
	TIME [epoch: 35.3 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14017605091225804		[learning rate: 0.0030378]
	Learning Rate: 0.00303783
	LOSS [training: 0.14017605091225804 | validation: 0.37882610182915954]
	TIME [epoch: 35.3 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11753702430203825		[learning rate: 0.0030235]
	Learning Rate: 0.00302352
	LOSS [training: 0.11753702430203825 | validation: 0.2870986173526879]
	TIME [epoch: 35.2 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13651170120727554		[learning rate: 0.0030093]
	Learning Rate: 0.00300927
	LOSS [training: 0.13651170120727554 | validation: 0.3302240384718761]
	TIME [epoch: 35.2 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13779504134980705		[learning rate: 0.0029951]
	Learning Rate: 0.00299509
	LOSS [training: 0.13779504134980705 | validation: 0.4080832673053627]
	TIME [epoch: 35.3 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1386234468132387		[learning rate: 0.002981]
	Learning Rate: 0.00298098
	LOSS [training: 0.1386234468132387 | validation: 0.3230375085513131]
	TIME [epoch: 35.3 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13369985460217382		[learning rate: 0.0029669]
	Learning Rate: 0.00296693
	LOSS [training: 0.13369985460217382 | validation: 0.323694572273141]
	TIME [epoch: 35.2 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1270225848572984		[learning rate: 0.002953]
	Learning Rate: 0.00295295
	LOSS [training: 0.1270225848572984 | validation: 0.3757119490886565]
	TIME [epoch: 35.3 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12038712707212185		[learning rate: 0.002939]
	Learning Rate: 0.00293904
	LOSS [training: 0.12038712707212185 | validation: 0.2861281841956967]
	TIME [epoch: 35.3 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13057859356198737		[learning rate: 0.0029252]
	Learning Rate: 0.00292519
	LOSS [training: 0.13057859356198737 | validation: 0.36715047681733226]
	TIME [epoch: 35.3 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13753631093818125		[learning rate: 0.0029114]
	Learning Rate: 0.0029114
	LOSS [training: 0.13753631093818125 | validation: 0.2939488995788935]
	TIME [epoch: 35.3 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12384002634152601		[learning rate: 0.0028977]
	Learning Rate: 0.00289769
	LOSS [training: 0.12384002634152601 | validation: 0.3193557720577479]
	TIME [epoch: 35.2 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13102170683211212		[learning rate: 0.002884]
	Learning Rate: 0.00288403
	LOSS [training: 0.13102170683211212 | validation: 0.28771523702810575]
	TIME [epoch: 97.6 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11892665455937163		[learning rate: 0.0028704]
	Learning Rate: 0.00287044
	LOSS [training: 0.11892665455937163 | validation: 0.30445479978892054]
	TIME [epoch: 72.9 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1177556992667866		[learning rate: 0.0028569]
	Learning Rate: 0.00285692
	LOSS [training: 0.1177556992667866 | validation: 0.35545911942387026]
	TIME [epoch: 72.9 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13183065131180566		[learning rate: 0.0028435]
	Learning Rate: 0.00284345
	LOSS [training: 0.13183065131180566 | validation: 0.2877682168789667]
	TIME [epoch: 73 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.124922154736907		[learning rate: 0.0028301]
	Learning Rate: 0.00283005
	LOSS [training: 0.124922154736907 | validation: 0.27910103378928075]
	TIME [epoch: 72.9 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14026255669508203		[learning rate: 0.0028167]
	Learning Rate: 0.00281672
	LOSS [training: 0.14026255669508203 | validation: 0.36466056366942334]
	TIME [epoch: 72.9 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11786827013000879		[learning rate: 0.0028034]
	Learning Rate: 0.00280345
	LOSS [training: 0.11786827013000879 | validation: 0.30893814907690476]
	TIME [epoch: 72.9 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11358442998911557		[learning rate: 0.0027902]
	Learning Rate: 0.00279024
	LOSS [training: 0.11358442998911557 | validation: 0.34747757128385726]
	TIME [epoch: 72.9 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12197089393878575		[learning rate: 0.0027771]
	Learning Rate: 0.00277709
	LOSS [training: 0.12197089393878575 | validation: 0.3781968490945967]
	TIME [epoch: 72.9 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12061384216520069		[learning rate: 0.002764]
	Learning Rate: 0.002764
	LOSS [training: 0.12061384216520069 | validation: 0.2878075531600603]
	TIME [epoch: 72.9 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12535161664060984		[learning rate: 0.002751]
	Learning Rate: 0.00275098
	LOSS [training: 0.12535161664060984 | validation: 0.30339932758387084]
	TIME [epoch: 72.9 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12465543910059129		[learning rate: 0.002738]
	Learning Rate: 0.00273802
	LOSS [training: 0.12465543910059129 | validation: 0.2709532202701566]
	TIME [epoch: 72.9 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1252623581729155		[learning rate: 0.0027251]
	Learning Rate: 0.00272511
	LOSS [training: 0.1252623581729155 | validation: 0.2927905762388736]
	TIME [epoch: 72.9 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1202038267532621		[learning rate: 0.0027123]
	Learning Rate: 0.00271227
	LOSS [training: 0.1202038267532621 | validation: 0.28727355431637325]
	TIME [epoch: 72.9 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1164163628311081		[learning rate: 0.0026995]
	Learning Rate: 0.00269949
	LOSS [training: 0.1164163628311081 | validation: 0.32915348279037415]
	TIME [epoch: 72.9 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12055759657236839		[learning rate: 0.0026868]
	Learning Rate: 0.00268677
	LOSS [training: 0.12055759657236839 | validation: 0.3117565475888516]
	TIME [epoch: 72.9 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11269378643457906		[learning rate: 0.0026741]
	Learning Rate: 0.00267411
	LOSS [training: 0.11269378643457906 | validation: 0.3490964399658709]
	TIME [epoch: 72.9 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11361703912955244		[learning rate: 0.0026615]
	Learning Rate: 0.00266151
	LOSS [training: 0.11361703912955244 | validation: 0.31659415202345786]
	TIME [epoch: 72.9 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11908108460398048		[learning rate: 0.002649]
	Learning Rate: 0.00264897
	LOSS [training: 0.11908108460398048 | validation: 0.34882486291592957]
	TIME [epoch: 72.9 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12442184057856287		[learning rate: 0.0026365]
	Learning Rate: 0.00263649
	LOSS [training: 0.12442184057856287 | validation: 0.3227940976579516]
	TIME [epoch: 72.9 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11086172448038152		[learning rate: 0.0026241]
	Learning Rate: 0.00262406
	LOSS [training: 0.11086172448038152 | validation: 0.3180263755952939]
	TIME [epoch: 72.9 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1333160000830971		[learning rate: 0.0026117]
	Learning Rate: 0.0026117
	LOSS [training: 0.1333160000830971 | validation: 0.2873697957447163]
	TIME [epoch: 72.9 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12595146887283937		[learning rate: 0.0025994]
	Learning Rate: 0.00259939
	LOSS [training: 0.12595146887283937 | validation: 0.34661443540752196]
	TIME [epoch: 72.9 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1256993504617869		[learning rate: 0.0025871]
	Learning Rate: 0.00258714
	LOSS [training: 0.1256993504617869 | validation: 0.2977417686006744]
	TIME [epoch: 72.9 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13322888633171404		[learning rate: 0.002575]
	Learning Rate: 0.00257495
	LOSS [training: 0.13322888633171404 | validation: 0.29278164567164106]
	TIME [epoch: 72.9 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12877777656237735		[learning rate: 0.0025628]
	Learning Rate: 0.00256282
	LOSS [training: 0.12877777656237735 | validation: 0.2708139315130195]
	TIME [epoch: 72.9 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12484473146621766		[learning rate: 0.0025507]
	Learning Rate: 0.00255074
	LOSS [training: 0.12484473146621766 | validation: 0.3411793067836051]
	TIME [epoch: 72.9 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12469488592968703		[learning rate: 0.0025387]
	Learning Rate: 0.00253872
	LOSS [training: 0.12469488592968703 | validation: 0.2828649168313675]
	TIME [epoch: 72.9 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13407439176365393		[learning rate: 0.0025268]
	Learning Rate: 0.00252676
	LOSS [training: 0.13407439176365393 | validation: 0.30293282283582784]
	TIME [epoch: 72.9 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1303945135047273		[learning rate: 0.0025149]
	Learning Rate: 0.00251485
	LOSS [training: 0.1303945135047273 | validation: 0.4075574443846494]
	TIME [epoch: 72.9 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1306280693818265		[learning rate: 0.002503]
	Learning Rate: 0.002503
	LOSS [training: 0.1306280693818265 | validation: 0.2956250958542984]
	TIME [epoch: 72.9 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12121807717168825		[learning rate: 0.0024912]
	Learning Rate: 0.00249121
	LOSS [training: 0.12121807717168825 | validation: 0.33128550525991896]
	TIME [epoch: 73 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11949870175334108		[learning rate: 0.0024795]
	Learning Rate: 0.00247947
	LOSS [training: 0.11949870175334108 | validation: 0.325539463208383]
	TIME [epoch: 72.9 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.132644469640752		[learning rate: 0.0024678]
	Learning Rate: 0.00246779
	LOSS [training: 0.132644469640752 | validation: 0.31915870348552255]
	TIME [epoch: 72.9 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11829905020948915		[learning rate: 0.0024562]
	Learning Rate: 0.00245616
	LOSS [training: 0.11829905020948915 | validation: 0.2944914181628762]
	TIME [epoch: 72.9 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1191005965428072		[learning rate: 0.0024446]
	Learning Rate: 0.00244458
	LOSS [training: 0.1191005965428072 | validation: 0.26246579072747894]
	TIME [epoch: 72.9 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v14b_20240719_004750/states/model_facs_v4_dec2b_2dpca_v14b_336.pth
	Model improved!!!
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13329593333425688		[learning rate: 0.0024331]
	Learning Rate: 0.00243307
	LOSS [training: 0.13329593333425688 | validation: 0.3483305389609505]
	TIME [epoch: 73 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1346225880594969		[learning rate: 0.0024216]
	Learning Rate: 0.0024216
	LOSS [training: 0.1346225880594969 | validation: 0.34046613407316567]
	TIME [epoch: 73 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.120942835721724		[learning rate: 0.0024102]
	Learning Rate: 0.00241019
	LOSS [training: 0.120942835721724 | validation: 0.28686434510969394]
	TIME [epoch: 73 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13781380154687473		[learning rate: 0.0023988]
	Learning Rate: 0.00239883
	LOSS [training: 0.13781380154687473 | validation: 0.30017551512434015]
	TIME [epoch: 73 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12018543420033467		[learning rate: 0.0023875]
	Learning Rate: 0.00238753
	LOSS [training: 0.12018543420033467 | validation: 0.32385924463914584]
	TIME [epoch: 73.1 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11836418412683337		[learning rate: 0.0023763]
	Learning Rate: 0.00237628
	LOSS [training: 0.11836418412683337 | validation: 0.3682618597597071]
	TIME [epoch: 73 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11206979980733718		[learning rate: 0.0023651]
	Learning Rate: 0.00236508
	LOSS [training: 0.11206979980733718 | validation: 0.304750662230996]
	TIME [epoch: 73.1 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11199099892560552		[learning rate: 0.0023539]
	Learning Rate: 0.00235394
	LOSS [training: 0.11199099892560552 | validation: 0.29597155744961834]
	TIME [epoch: 73 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13550443212580593		[learning rate: 0.0023428]
	Learning Rate: 0.00234285
	LOSS [training: 0.13550443212580593 | validation: 0.3109994503923299]
	TIME [epoch: 73.1 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15070468009138555		[learning rate: 0.0023318]
	Learning Rate: 0.00233181
	LOSS [training: 0.15070468009138555 | validation: 0.3245787404917906]
	TIME [epoch: 73 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1220365211069222		[learning rate: 0.0023208]
	Learning Rate: 0.00232082
	LOSS [training: 0.1220365211069222 | validation: 0.286969081807932]
	TIME [epoch: 73.1 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11450898622074682		[learning rate: 0.0023099]
	Learning Rate: 0.00230988
	LOSS [training: 0.11450898622074682 | validation: 0.29978730624698474]
	TIME [epoch: 73 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12654276954478666		[learning rate: 0.002299]
	Learning Rate: 0.002299
	LOSS [training: 0.12654276954478666 | validation: 0.31568230487229354]
	TIME [epoch: 73.1 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12438126241701732		[learning rate: 0.0022882]
	Learning Rate: 0.00228816
	LOSS [training: 0.12438126241701732 | validation: 0.2927575965178969]
	TIME [epoch: 73 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1311376189354712		[learning rate: 0.0022774]
	Learning Rate: 0.00227738
	LOSS [training: 0.1311376189354712 | validation: 0.31436357221762645]
	TIME [epoch: 73 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11844356977164641		[learning rate: 0.0022667]
	Learning Rate: 0.00226665
	LOSS [training: 0.11844356977164641 | validation: 0.35025563216895184]
	TIME [epoch: 73 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11629574133827099		[learning rate: 0.002256]
	Learning Rate: 0.00225597
	LOSS [training: 0.11629574133827099 | validation: 0.3151916700113866]
	TIME [epoch: 73 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12011546768044504		[learning rate: 0.0022453]
	Learning Rate: 0.00224534
	LOSS [training: 0.12011546768044504 | validation: 0.3081899799405888]
	TIME [epoch: 73 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12047915735041853		[learning rate: 0.0022348]
	Learning Rate: 0.00223476
	LOSS [training: 0.12047915735041853 | validation: 0.3039137219400738]
	TIME [epoch: 72.9 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13559474390906945		[learning rate: 0.0022242]
	Learning Rate: 0.00222423
	LOSS [training: 0.13559474390906945 | validation: 0.372863596535022]
	TIME [epoch: 72.9 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12778158619008034		[learning rate: 0.0022137]
	Learning Rate: 0.00221375
	LOSS [training: 0.12778158619008034 | validation: 0.29890330960062883]
	TIME [epoch: 72.9 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12749200042323183		[learning rate: 0.0022033]
	Learning Rate: 0.00220332
	LOSS [training: 0.12749200042323183 | validation: 0.3256917835104217]
	TIME [epoch: 73 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11734415972251895		[learning rate: 0.0021929]
	Learning Rate: 0.00219293
	LOSS [training: 0.11734415972251895 | validation: 0.30541651722926016]
	TIME [epoch: 72.9 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11248721106284806		[learning rate: 0.0021826]
	Learning Rate: 0.0021826
	LOSS [training: 0.11248721106284806 | validation: 0.3009771257071735]
	TIME [epoch: 73 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10878369372560723		[learning rate: 0.0021723]
	Learning Rate: 0.00217232
	LOSS [training: 0.10878369372560723 | validation: 0.38006566996683755]
	TIME [epoch: 72.9 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11483944079923888		[learning rate: 0.0021621]
	Learning Rate: 0.00216208
	LOSS [training: 0.11483944079923888 | validation: 0.2976133319834839]
	TIME [epoch: 73 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12194356926920408		[learning rate: 0.0021519]
	Learning Rate: 0.00215189
	LOSS [training: 0.12194356926920408 | validation: 0.28219663418643126]
	TIME [epoch: 73 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11677594797092815		[learning rate: 0.0021418]
	Learning Rate: 0.00214175
	LOSS [training: 0.11677594797092815 | validation: 0.31907012286797987]
	TIME [epoch: 73 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1159314745337137		[learning rate: 0.0021317]
	Learning Rate: 0.00213166
	LOSS [training: 0.1159314745337137 | validation: 0.3083802718038167]
	TIME [epoch: 73 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11963950329460718		[learning rate: 0.0021216]
	Learning Rate: 0.00212162
	LOSS [training: 0.11963950329460718 | validation: 0.2883305387777357]
	TIME [epoch: 73 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11222801959480341		[learning rate: 0.0021116]
	Learning Rate: 0.00211162
	LOSS [training: 0.11222801959480341 | validation: 0.31380170878497426]
	TIME [epoch: 73 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11345826312852623		[learning rate: 0.0021017]
	Learning Rate: 0.00210167
	LOSS [training: 0.11345826312852623 | validation: 0.29300380639667445]
	TIME [epoch: 73 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13608925737290656		[learning rate: 0.0020918]
	Learning Rate: 0.00209176
	LOSS [training: 0.13608925737290656 | validation: 0.2790142922241828]
	TIME [epoch: 73.1 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1240425143459769		[learning rate: 0.0020819]
	Learning Rate: 0.00208191
	LOSS [training: 0.1240425143459769 | validation: 0.3041483686368171]
	TIME [epoch: 73 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12540367948873204		[learning rate: 0.0020721]
	Learning Rate: 0.0020721
	LOSS [training: 0.12540367948873204 | validation: 0.29303850129513015]
	TIME [epoch: 73 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11326280770826862		[learning rate: 0.0020623]
	Learning Rate: 0.00206233
	LOSS [training: 0.11326280770826862 | validation: 0.3547491253698547]
	TIME [epoch: 73 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11170068179193418		[learning rate: 0.0020526]
	Learning Rate: 0.00205262
	LOSS [training: 0.11170068179193418 | validation: 0.30052737787406975]
	TIME [epoch: 73 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10871500980606139		[learning rate: 0.0020429]
	Learning Rate: 0.00204294
	LOSS [training: 0.10871500980606139 | validation: 0.2775541826442532]
	TIME [epoch: 73 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1216528719273439		[learning rate: 0.0020333]
	Learning Rate: 0.00203332
	LOSS [training: 0.1216528719273439 | validation: 0.2710754260052085]
	TIME [epoch: 73.1 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10441644649124553		[learning rate: 0.0020237]
	Learning Rate: 0.00202374
	LOSS [training: 0.10441644649124553 | validation: 0.29788151886794945]
	TIME [epoch: 73.1 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11839572444432236		[learning rate: 0.0020142]
	Learning Rate: 0.0020142
	LOSS [training: 0.11839572444432236 | validation: 0.38151741116426113]
	TIME [epoch: 73 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11779930167844758		[learning rate: 0.0020047]
	Learning Rate: 0.00200471
	LOSS [training: 0.11779930167844758 | validation: 0.317916676203876]
	TIME [epoch: 73 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11326991784877692		[learning rate: 0.0019953]
	Learning Rate: 0.00199526
	LOSS [training: 0.11326991784877692 | validation: 0.3469927048864055]
	TIME [epoch: 72.9 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12428262159585024		[learning rate: 0.0019859]
	Learning Rate: 0.00198586
	LOSS [training: 0.12428262159585024 | validation: 0.29910694549603434]
	TIME [epoch: 73 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11488469567117096		[learning rate: 0.0019765]
	Learning Rate: 0.0019765
	LOSS [training: 0.11488469567117096 | validation: 0.3364417158344245]
	TIME [epoch: 72.8 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11497678974113121		[learning rate: 0.0019672]
	Learning Rate: 0.00196719
	LOSS [training: 0.11497678974113121 | validation: 0.28262124472576333]
	TIME [epoch: 73 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12009711823101854		[learning rate: 0.0019579]
	Learning Rate: 0.00195792
	LOSS [training: 0.12009711823101854 | validation: 0.30849015055705353]
	TIME [epoch: 73 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11213806916795395		[learning rate: 0.0019487]
	Learning Rate: 0.00194869
	LOSS [training: 0.11213806916795395 | validation: 0.327036137086898]
	TIME [epoch: 72.9 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10963404744772652		[learning rate: 0.0019395]
	Learning Rate: 0.00193951
	LOSS [training: 0.10963404744772652 | validation: 0.3164568218157979]
	TIME [epoch: 72.9 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11156326109699785		[learning rate: 0.0019304]
	Learning Rate: 0.00193037
	LOSS [training: 0.11156326109699785 | validation: 0.2873532175043213]
	TIME [epoch: 72.9 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11917139556485988		[learning rate: 0.0019213]
	Learning Rate: 0.00192128
	LOSS [training: 0.11917139556485988 | validation: 0.2808125510987138]
	TIME [epoch: 73 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11452611351779633		[learning rate: 0.0019122]
	Learning Rate: 0.00191222
	LOSS [training: 0.11452611351779633 | validation: 0.2914446112419115]
	TIME [epoch: 73 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11582711140442396		[learning rate: 0.0019032]
	Learning Rate: 0.00190321
	LOSS [training: 0.11582711140442396 | validation: 0.3109536218325834]
	TIME [epoch: 73 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1100771233777528		[learning rate: 0.0018942]
	Learning Rate: 0.00189424
	LOSS [training: 0.1100771233777528 | validation: 0.2823739958551382]
	TIME [epoch: 73 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1282890933348676		[learning rate: 0.0018853]
	Learning Rate: 0.00188532
	LOSS [training: 0.1282890933348676 | validation: 0.29351916001877876]
	TIME [epoch: 73 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13067850905002984		[learning rate: 0.0018764]
	Learning Rate: 0.00187643
	LOSS [training: 0.13067850905002984 | validation: 0.29380465337405065]
	TIME [epoch: 73 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1421493838526517		[learning rate: 0.0018676]
	Learning Rate: 0.00186759
	LOSS [training: 0.1421493838526517 | validation: 0.34509874073740576]
	TIME [epoch: 73 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1287323020180627		[learning rate: 0.0018588]
	Learning Rate: 0.00185879
	LOSS [training: 0.1287323020180627 | validation: 0.3018507706939502]
	TIME [epoch: 73 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12391624452116165		[learning rate: 0.00185]
	Learning Rate: 0.00185003
	LOSS [training: 0.12391624452116165 | validation: 0.314346245316517]
	TIME [epoch: 73 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11367020609452144		[learning rate: 0.0018413]
	Learning Rate: 0.00184132
	LOSS [training: 0.11367020609452144 | validation: 0.3024977454515155]
	TIME [epoch: 73 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10581133440272267		[learning rate: 0.0018326]
	Learning Rate: 0.00183264
	LOSS [training: 0.10581133440272267 | validation: 0.288904085622947]
	TIME [epoch: 73 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10612037364514013		[learning rate: 0.001824]
	Learning Rate: 0.001824
	LOSS [training: 0.10612037364514013 | validation: 0.30599515307564124]
	TIME [epoch: 73.1 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12678571257584173		[learning rate: 0.0018154]
	Learning Rate: 0.00181541
	LOSS [training: 0.12678571257584173 | validation: 0.29587267407252876]
	TIME [epoch: 73 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10341135152827982		[learning rate: 0.0018069]
	Learning Rate: 0.00180685
	LOSS [training: 0.10341135152827982 | validation: 0.3241278895432018]
	TIME [epoch: 73 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12894860152504217		[learning rate: 0.0017983]
	Learning Rate: 0.00179834
	LOSS [training: 0.12894860152504217 | validation: 0.31259070917834]
	TIME [epoch: 73 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11522155059463185		[learning rate: 0.0017899]
	Learning Rate: 0.00178987
	LOSS [training: 0.11522155059463185 | validation: 0.2815298803825673]
	TIME [epoch: 73 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10200733633575043		[learning rate: 0.0017814]
	Learning Rate: 0.00178143
	LOSS [training: 0.10200733633575043 | validation: 0.28116667523951616]
	TIME [epoch: 73 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12157529803546205		[learning rate: 0.001773]
	Learning Rate: 0.00177304
	LOSS [training: 0.12157529803546205 | validation: 0.2926546672198093]
	TIME [epoch: 73 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12377516589548238		[learning rate: 0.0017647]
	Learning Rate: 0.00176468
	LOSS [training: 0.12377516589548238 | validation: 0.296510504113779]
	TIME [epoch: 72.9 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10523540117900551		[learning rate: 0.0017564]
	Learning Rate: 0.00175637
	LOSS [training: 0.10523540117900551 | validation: 0.29444506093166883]
	TIME [epoch: 73 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10985327649079893		[learning rate: 0.0017481]
	Learning Rate: 0.00174809
	LOSS [training: 0.10985327649079893 | validation: 0.294898724768727]
	TIME [epoch: 72.9 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11417707863081966		[learning rate: 0.0017399]
	Learning Rate: 0.00173985
	LOSS [training: 0.11417707863081966 | validation: 0.3158353372324705]
	TIME [epoch: 72.9 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11351046679901672		[learning rate: 0.0017317]
	Learning Rate: 0.00173166
	LOSS [training: 0.11351046679901672 | validation: 0.3686197025949338]
	TIME [epoch: 73 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13365859428259097		[learning rate: 0.0017235]
	Learning Rate: 0.0017235
	LOSS [training: 0.13365859428259097 | validation: 0.28839635752495757]
	TIME [epoch: 73 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11543226820362862		[learning rate: 0.0017154]
	Learning Rate: 0.00171537
	LOSS [training: 0.11543226820362862 | validation: 0.2918099276938067]
	TIME [epoch: 73 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10262468676347045		[learning rate: 0.0017073]
	Learning Rate: 0.00170729
	LOSS [training: 0.10262468676347045 | validation: 0.2887075200486186]
	TIME [epoch: 73 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12420810810397831		[learning rate: 0.0016992]
	Learning Rate: 0.00169925
	LOSS [training: 0.12420810810397831 | validation: 0.297284162511067]
	TIME [epoch: 73 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1078941914042871		[learning rate: 0.0016912]
	Learning Rate: 0.00169124
	LOSS [training: 0.1078941914042871 | validation: 0.30306840405331736]
	TIME [epoch: 73 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12309975157421377		[learning rate: 0.0016833]
	Learning Rate: 0.00168327
	LOSS [training: 0.12309975157421377 | validation: 0.2757872972325109]
	TIME [epoch: 73.1 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11153090603812776		[learning rate: 0.0016753]
	Learning Rate: 0.00167534
	LOSS [training: 0.11153090603812776 | validation: 0.32425928532323794]
	TIME [epoch: 72.9 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11941814331960016		[learning rate: 0.0016674]
	Learning Rate: 0.00166744
	LOSS [training: 0.11941814331960016 | validation: 0.28827058843284464]
	TIME [epoch: 73 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11973536066235319		[learning rate: 0.0016596]
	Learning Rate: 0.00165959
	LOSS [training: 0.11973536066235319 | validation: 0.2662701371563513]
	TIME [epoch: 73.1 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10381920774490122		[learning rate: 0.0016518]
	Learning Rate: 0.00165177
	LOSS [training: 0.10381920774490122 | validation: 0.3257749588832297]
	TIME [epoch: 73 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12760788234903014		[learning rate: 0.001644]
	Learning Rate: 0.00164398
	LOSS [training: 0.12760788234903014 | validation: 0.29530359566810643]
	TIME [epoch: 73 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1066399893427316		[learning rate: 0.0016362]
	Learning Rate: 0.00163624
	LOSS [training: 0.1066399893427316 | validation: 0.30063694466548463]
	TIME [epoch: 73 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1166146176581512		[learning rate: 0.0016285]
	Learning Rate: 0.00162853
	LOSS [training: 0.1166146176581512 | validation: 0.3552135784771547]
	TIME [epoch: 73.1 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11861149856853992		[learning rate: 0.0016209]
	Learning Rate: 0.00162085
	LOSS [training: 0.11861149856853992 | validation: 0.2892607995736157]
	TIME [epoch: 73.1 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11402125775279995		[learning rate: 0.0016132]
	Learning Rate: 0.00161322
	LOSS [training: 0.11402125775279995 | validation: 0.2903507187776483]
	TIME [epoch: 73 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11158310028837538		[learning rate: 0.0016056]
	Learning Rate: 0.00160561
	LOSS [training: 0.11158310028837538 | validation: 0.28308506262341143]
	TIME [epoch: 73 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12104071364292612		[learning rate: 0.001598]
	Learning Rate: 0.00159805
	LOSS [training: 0.12104071364292612 | validation: 0.29292553223648526]
	TIME [epoch: 73 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1101768806079882		[learning rate: 0.0015905]
	Learning Rate: 0.00159052
	LOSS [training: 0.1101768806079882 | validation: 0.31167692232927413]
	TIME [epoch: 73 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12066614076887834		[learning rate: 0.001583]
	Learning Rate: 0.00158302
	LOSS [training: 0.12066614076887834 | validation: 0.29110648575810605]
	TIME [epoch: 73 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11378680145289394		[learning rate: 0.0015756]
	Learning Rate: 0.00157556
	LOSS [training: 0.11378680145289394 | validation: 0.28356787243813314]
	TIME [epoch: 73 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11753545351811272		[learning rate: 0.0015681]
	Learning Rate: 0.00156814
	LOSS [training: 0.11753545351811272 | validation: 0.2967019444213524]
	TIME [epoch: 73 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12611384173784312		[learning rate: 0.0015607]
	Learning Rate: 0.00156075
	LOSS [training: 0.12611384173784312 | validation: 0.3296772169097898]
	TIME [epoch: 73 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11253709972065215		[learning rate: 0.0015534]
	Learning Rate: 0.0015534
	LOSS [training: 0.11253709972065215 | validation: 0.3098147330097758]
	TIME [epoch: 73 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11861730309355692		[learning rate: 0.0015461]
	Learning Rate: 0.00154608
	LOSS [training: 0.11861730309355692 | validation: 0.3058349401530897]
	TIME [epoch: 73 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10077144938954098		[learning rate: 0.0015388]
	Learning Rate: 0.00153879
	LOSS [training: 0.10077144938954098 | validation: 0.30406825585597985]
	TIME [epoch: 73 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1261948815536942		[learning rate: 0.0015315]
	Learning Rate: 0.00153154
	LOSS [training: 0.1261948815536942 | validation: 0.2699446832326201]
	TIME [epoch: 72.9 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1230409412599544		[learning rate: 0.0015243]
	Learning Rate: 0.00152432
	LOSS [training: 0.1230409412599544 | validation: 0.2787875284679311]
	TIME [epoch: 73 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11536747152355695		[learning rate: 0.0015171]
	Learning Rate: 0.00151714
	LOSS [training: 0.11536747152355695 | validation: 0.307659530141852]
	TIME [epoch: 73 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11022501441500207		[learning rate: 0.00151]
	Learning Rate: 0.00150999
	LOSS [training: 0.11022501441500207 | validation: 0.30372011888624856]
	TIME [epoch: 73 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10536686798754857		[learning rate: 0.0015029]
	Learning Rate: 0.00150288
	LOSS [training: 0.10536686798754857 | validation: 0.302271336822459]
	TIME [epoch: 73 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11035200729011536		[learning rate: 0.0014958]
	Learning Rate: 0.00149579
	LOSS [training: 0.11035200729011536 | validation: 0.29761937670707]
	TIME [epoch: 73 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11505871514166746		[learning rate: 0.0014887]
	Learning Rate: 0.00148875
	LOSS [training: 0.11505871514166746 | validation: 0.29569004820513295]
	TIME [epoch: 73 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11228438977449473		[learning rate: 0.0014817]
	Learning Rate: 0.00148173
	LOSS [training: 0.11228438977449473 | validation: 0.2911525303609865]
	TIME [epoch: 73 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12426566148265064		[learning rate: 0.0014747]
	Learning Rate: 0.00147475
	LOSS [training: 0.12426566148265064 | validation: 0.3198889159272438]
	TIME [epoch: 73 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11073611631140187		[learning rate: 0.0014678]
	Learning Rate: 0.0014678
	LOSS [training: 0.11073611631140187 | validation: 0.3039732419827685]
	TIME [epoch: 72.9 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13931352633423838		[learning rate: 0.0014609]
	Learning Rate: 0.00146088
	LOSS [training: 0.13931352633423838 | validation: 0.27017704471740145]
	TIME [epoch: 73 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11954063012382833		[learning rate: 0.001454]
	Learning Rate: 0.001454
	LOSS [training: 0.11954063012382833 | validation: 0.27930404295694145]
	TIME [epoch: 73 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10427927499203295		[learning rate: 0.0014471]
	Learning Rate: 0.00144715
	LOSS [training: 0.10427927499203295 | validation: 0.29915939513495277]
	TIME [epoch: 73 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11485377029723587		[learning rate: 0.0014403]
	Learning Rate: 0.00144033
	LOSS [training: 0.11485377029723587 | validation: 0.28332568484386306]
	TIME [epoch: 73 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11360881301029425		[learning rate: 0.0014335]
	Learning Rate: 0.00143354
	LOSS [training: 0.11360881301029425 | validation: 0.30696399311391365]
	TIME [epoch: 73 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11457769375132301		[learning rate: 0.0014268]
	Learning Rate: 0.00142679
	LOSS [training: 0.11457769375132301 | validation: 0.33610323547819926]
	TIME [epoch: 73 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10544630512418937		[learning rate: 0.0014201]
	Learning Rate: 0.00142006
	LOSS [training: 0.10544630512418937 | validation: 0.28485678050758595]
	TIME [epoch: 73 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12147256425065206		[learning rate: 0.0014134]
	Learning Rate: 0.00141337
	LOSS [training: 0.12147256425065206 | validation: 0.28125423027174573]
	TIME [epoch: 73 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10703173996530023		[learning rate: 0.0014067]
	Learning Rate: 0.00140671
	LOSS [training: 0.10703173996530023 | validation: 0.3033074408437476]
	TIME [epoch: 73 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11340628949717481		[learning rate: 0.0014001]
	Learning Rate: 0.00140008
	LOSS [training: 0.11340628949717481 | validation: 0.27804156721235607]
	TIME [epoch: 73 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11004729522954945		[learning rate: 0.0013935]
	Learning Rate: 0.00139349
	LOSS [training: 0.11004729522954945 | validation: 0.30181114146915655]
	TIME [epoch: 73 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12274880431522227		[learning rate: 0.0013869]
	Learning Rate: 0.00138692
	LOSS [training: 0.12274880431522227 | validation: 0.32162972863416694]
	TIME [epoch: 73 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11196011028299745		[learning rate: 0.0013804]
	Learning Rate: 0.00138038
	LOSS [training: 0.11196011028299745 | validation: 0.2776273676447205]
	TIME [epoch: 73 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12606026536228954		[learning rate: 0.0013739]
	Learning Rate: 0.00137388
	LOSS [training: 0.12606026536228954 | validation: 0.28472080333479594]
	TIME [epoch: 73 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1056565738263851		[learning rate: 0.0013674]
	Learning Rate: 0.00136741
	LOSS [training: 0.1056565738263851 | validation: 0.309373588639911]
	TIME [epoch: 73 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1123722947235469		[learning rate: 0.001361]
	Learning Rate: 0.00136096
	LOSS [training: 0.1123722947235469 | validation: 0.293115862235106]
	TIME [epoch: 73 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12445726043602547		[learning rate: 0.0013545]
	Learning Rate: 0.00135455
	LOSS [training: 0.12445726043602547 | validation: 0.27432850850374646]
	TIME [epoch: 73.1 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1210461373297686		[learning rate: 0.0013482]
	Learning Rate: 0.00134817
	LOSS [training: 0.1210461373297686 | validation: 0.29574445936988963]
	TIME [epoch: 73.1 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12547986035676145		[learning rate: 0.0013418]
	Learning Rate: 0.00134181
	LOSS [training: 0.12547986035676145 | validation: 0.27841827796073365]
	TIME [epoch: 73 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10036105272693568		[learning rate: 0.0013355]
	Learning Rate: 0.00133549
	LOSS [training: 0.10036105272693568 | validation: 0.2896607414370051]
	TIME [epoch: 73.1 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11441937702620113		[learning rate: 0.0013292]
	Learning Rate: 0.0013292
	LOSS [training: 0.11441937702620113 | validation: 0.3037640361981522]
	TIME [epoch: 73.1 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11855838689817548		[learning rate: 0.0013229]
	Learning Rate: 0.00132293
	LOSS [training: 0.11855838689817548 | validation: 0.2739695428819807]
	TIME [epoch: 73 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11095215552969327		[learning rate: 0.0013167]
	Learning Rate: 0.0013167
	LOSS [training: 0.11095215552969327 | validation: 0.3202617488139705]
	TIME [epoch: 73 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11070645346609762		[learning rate: 0.0013105]
	Learning Rate: 0.0013105
	LOSS [training: 0.11070645346609762 | validation: 0.29105073769968687]
	TIME [epoch: 73 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12316317899385129		[learning rate: 0.0013043]
	Learning Rate: 0.00130432
	LOSS [training: 0.12316317899385129 | validation: 0.2871156433465287]
	TIME [epoch: 73 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11900307374540806		[learning rate: 0.0012982]
	Learning Rate: 0.00129818
	LOSS [training: 0.11900307374540806 | validation: 0.28686924880369996]
	TIME [epoch: 73 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1133470731041565		[learning rate: 0.0012921]
	Learning Rate: 0.00129206
	LOSS [training: 0.1133470731041565 | validation: 0.2848130832977119]
	TIME [epoch: 73 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11375345015357707		[learning rate: 0.001286]
	Learning Rate: 0.00128597
	LOSS [training: 0.11375345015357707 | validation: 0.2644049329596664]
	TIME [epoch: 73 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11147939026088576		[learning rate: 0.0012799]
	Learning Rate: 0.00127991
	LOSS [training: 0.11147939026088576 | validation: 0.30872903266258045]
	TIME [epoch: 73 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11616537953276992		[learning rate: 0.0012739]
	Learning Rate: 0.00127388
	LOSS [training: 0.11616537953276992 | validation: 0.3074091056267358]
	TIME [epoch: 73 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11645535842810437		[learning rate: 0.0012679]
	Learning Rate: 0.00126788
	LOSS [training: 0.11645535842810437 | validation: 0.29274128168939634]
	TIME [epoch: 73 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1270975551834934		[learning rate: 0.0012619]
	Learning Rate: 0.0012619
	LOSS [training: 0.1270975551834934 | validation: 0.29207013860387504]
	TIME [epoch: 73 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10705721800608722		[learning rate: 0.001256]
	Learning Rate: 0.00125596
	LOSS [training: 0.10705721800608722 | validation: 0.31812533962110123]
	TIME [epoch: 73 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1173561155104947		[learning rate: 0.00125]
	Learning Rate: 0.00125004
	LOSS [training: 0.1173561155104947 | validation: 0.30317135338651025]
	TIME [epoch: 73 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13913407150656293		[learning rate: 0.0012441]
	Learning Rate: 0.00124415
	LOSS [training: 0.13913407150656293 | validation: 0.30251001826680307]
	TIME [epoch: 73 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12477369806284477		[learning rate: 0.0012383]
	Learning Rate: 0.00123828
	LOSS [training: 0.12477369806284477 | validation: 0.28521149193004564]
	TIME [epoch: 73.1 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11096942845013712		[learning rate: 0.0012324]
	Learning Rate: 0.00123245
	LOSS [training: 0.11096942845013712 | validation: 0.28531663355456377]
	TIME [epoch: 73 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10424319901603755		[learning rate: 0.0012266]
	Learning Rate: 0.00122664
	LOSS [training: 0.10424319901603755 | validation: 0.29739953580208767]
	TIME [epoch: 73 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11531420881714652		[learning rate: 0.0012209]
	Learning Rate: 0.00122086
	LOSS [training: 0.11531420881714652 | validation: 0.277436485625502]
	TIME [epoch: 72.9 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1016807129770844		[learning rate: 0.0012151]
	Learning Rate: 0.00121511
	LOSS [training: 0.1016807129770844 | validation: 0.3312494287328753]
	TIME [epoch: 73.1 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10482743637599272		[learning rate: 0.0012094]
	Learning Rate: 0.00120938
	LOSS [training: 0.10482743637599272 | validation: 0.301117180378174]
	TIME [epoch: 73 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11795394192844491		[learning rate: 0.0012037]
	Learning Rate: 0.00120368
	LOSS [training: 0.11795394192844491 | validation: 0.3366927237127076]
	TIME [epoch: 73.1 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11688857933719995		[learning rate: 0.001198]
	Learning Rate: 0.00119801
	LOSS [training: 0.11688857933719995 | validation: 0.2946920928119185]
	TIME [epoch: 73.1 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10013570983500353		[learning rate: 0.0011924]
	Learning Rate: 0.00119237
	LOSS [training: 0.10013570983500353 | validation: 0.3129968049325036]
	TIME [epoch: 73.1 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10918000104741006		[learning rate: 0.0011867]
	Learning Rate: 0.00118675
	LOSS [training: 0.10918000104741006 | validation: 0.2856803146253078]
	TIME [epoch: 73 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12050919682255591		[learning rate: 0.0011812]
	Learning Rate: 0.00118116
	LOSS [training: 0.12050919682255591 | validation: 0.2716634130412262]
	TIME [epoch: 73 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10216273469004561		[learning rate: 0.0011756]
	Learning Rate: 0.00117559
	LOSS [training: 0.10216273469004561 | validation: 0.2843906965034854]
	TIME [epoch: 73 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11726151929389428		[learning rate: 0.0011701]
	Learning Rate: 0.00117005
	LOSS [training: 0.11726151929389428 | validation: 0.32616007491991067]
	TIME [epoch: 73 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1084050168351976		[learning rate: 0.0011645]
	Learning Rate: 0.00116454
	LOSS [training: 0.1084050168351976 | validation: 0.27840400298507983]
	TIME [epoch: 73 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10506099733074059		[learning rate: 0.0011591]
	Learning Rate: 0.00115905
	LOSS [training: 0.10506099733074059 | validation: 0.274329507783246]
	TIME [epoch: 73 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12296155939639977		[learning rate: 0.0011536]
	Learning Rate: 0.00115359
	LOSS [training: 0.12296155939639977 | validation: 0.2819042528369033]
	TIME [epoch: 73 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10957550359211973		[learning rate: 0.0011482]
	Learning Rate: 0.00114815
	LOSS [training: 0.10957550359211973 | validation: 0.296114166879748]
	TIME [epoch: 73.1 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12025460680838704		[learning rate: 0.0011427]
	Learning Rate: 0.00114274
	LOSS [training: 0.12025460680838704 | validation: 0.26609966904047694]
	TIME [epoch: 73 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10429340978224597		[learning rate: 0.0011374]
	Learning Rate: 0.00113736
	LOSS [training: 0.10429340978224597 | validation: 0.2707128513190843]
	TIME [epoch: 73.1 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1096393610554199		[learning rate: 0.001132]
	Learning Rate: 0.001132
	LOSS [training: 0.1096393610554199 | validation: 0.29171050971382456]
	TIME [epoch: 73 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11634346302262205		[learning rate: 0.0011267]
	Learning Rate: 0.00112667
	LOSS [training: 0.11634346302262205 | validation: 0.2826831450905585]
	TIME [epoch: 72.9 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11908039056734758		[learning rate: 0.0011214]
	Learning Rate: 0.00112136
	LOSS [training: 0.11908039056734758 | validation: 0.3003827119997208]
	TIME [epoch: 73.1 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13181634705457224		[learning rate: 0.0011161]
	Learning Rate: 0.00111607
	LOSS [training: 0.13181634705457224 | validation: 0.3261056868714277]
	TIME [epoch: 73 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12212655594371155		[learning rate: 0.0011108]
	Learning Rate: 0.00111081
	LOSS [training: 0.12212655594371155 | validation: 0.2835991153343153]
	TIME [epoch: 73 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09793720590517901		[learning rate: 0.0011056]
	Learning Rate: 0.00110558
	LOSS [training: 0.09793720590517901 | validation: 0.28971997159149143]
	TIME [epoch: 72.9 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10697885088470077		[learning rate: 0.0011004]
	Learning Rate: 0.00110037
	LOSS [training: 0.10697885088470077 | validation: 0.27370317798275445]
	TIME [epoch: 72.9 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11347543424815533		[learning rate: 0.0010952]
	Learning Rate: 0.00109518
	LOSS [training: 0.11347543424815533 | validation: 0.2999597872118994]
	TIME [epoch: 73 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11660113195771868		[learning rate: 0.00109]
	Learning Rate: 0.00109002
	LOSS [training: 0.11660113195771868 | validation: 0.26675556930206795]
	TIME [epoch: 73 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12211541585750083		[learning rate: 0.0010849]
	Learning Rate: 0.00108489
	LOSS [training: 0.12211541585750083 | validation: 0.283120531438265]
	TIME [epoch: 72.9 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10842194790454468		[learning rate: 0.0010798]
	Learning Rate: 0.00107978
	LOSS [training: 0.10842194790454468 | validation: 0.2805551722173121]
	TIME [epoch: 73 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1091737379311397		[learning rate: 0.0010747]
	Learning Rate: 0.00107469
	LOSS [training: 0.1091737379311397 | validation: 0.2806419906007776]
	TIME [epoch: 72.9 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11899313144800619		[learning rate: 0.0010696]
	Learning Rate: 0.00106962
	LOSS [training: 0.11899313144800619 | validation: 0.28528120066819945]
	TIME [epoch: 73 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09959616517423833		[learning rate: 0.0010646]
	Learning Rate: 0.00106458
	LOSS [training: 0.09959616517423833 | validation: 0.2734726552351587]
	TIME [epoch: 73 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1141213424523733		[learning rate: 0.0010596]
	Learning Rate: 0.00105957
	LOSS [training: 0.1141213424523733 | validation: 0.31109124256712384]
	TIME [epoch: 73 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09202112750103462		[learning rate: 0.0010546]
	Learning Rate: 0.00105457
	LOSS [training: 0.09202112750103462 | validation: 0.305567760865608]
	TIME [epoch: 72.9 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12402368046944616		[learning rate: 0.0010496]
	Learning Rate: 0.0010496
	LOSS [training: 0.12402368046944616 | validation: 0.26979297705472927]
	TIME [epoch: 72.9 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11814787060774326		[learning rate: 0.0010447]
	Learning Rate: 0.00104466
	LOSS [training: 0.11814787060774326 | validation: 0.2997743464910103]
	TIME [epoch: 73 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10546150751919132		[learning rate: 0.0010397]
	Learning Rate: 0.00103974
	LOSS [training: 0.10546150751919132 | validation: 0.2750511952692762]
	TIME [epoch: 73 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12617511504443935		[learning rate: 0.0010348]
	Learning Rate: 0.00103484
	LOSS [training: 0.12617511504443935 | validation: 0.29252321439523465]
	TIME [epoch: 72.9 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12068241405589791		[learning rate: 0.00103]
	Learning Rate: 0.00102996
	LOSS [training: 0.12068241405589791 | validation: 0.27485875488384]
	TIME [epoch: 72.9 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.116711945593165		[learning rate: 0.0010251]
	Learning Rate: 0.00102511
	LOSS [training: 0.116711945593165 | validation: 0.28027358339497666]
	TIME [epoch: 72.9 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11503897007752603		[learning rate: 0.0010203]
	Learning Rate: 0.00102028
	LOSS [training: 0.11503897007752603 | validation: 0.25903134857870447]
	TIME [epoch: 72.9 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v14b_20240719_004750/states/model_facs_v4_dec2b_2dpca_v14b_521.pth
	Model improved!!!
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10767413855289429		[learning rate: 0.0010155]
	Learning Rate: 0.00101547
	LOSS [training: 0.10767413855289429 | validation: 0.3129394541898908]
	TIME [epoch: 72.9 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10831659179325463		[learning rate: 0.0010107]
	Learning Rate: 0.00101068
	LOSS [training: 0.10831659179325463 | validation: 0.3260524286330107]
	TIME [epoch: 72.9 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12228362808210425		[learning rate: 0.0010059]
	Learning Rate: 0.00100592
	LOSS [training: 0.12228362808210425 | validation: 0.28712289863529245]
	TIME [epoch: 72.9 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10136523277245832		[learning rate: 0.0010012]
	Learning Rate: 0.00100118
	LOSS [training: 0.10136523277245832 | validation: 0.29147288459744947]
	TIME [epoch: 72.9 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10003793430570862		[learning rate: 0.00099646]
	Learning Rate: 0.000996464
	LOSS [training: 0.10003793430570862 | validation: 0.29514889249059617]
	TIME [epoch: 72.9 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11624357052778878		[learning rate: 0.00099177]
	Learning Rate: 0.000991768
	LOSS [training: 0.11624357052778878 | validation: 0.27239733182669]
	TIME [epoch: 72.9 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11113741397446344		[learning rate: 0.0009871]
	Learning Rate: 0.000987095
	LOSS [training: 0.11113741397446344 | validation: 0.2814500309323362]
	TIME [epoch: 72.9 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10245944114949641		[learning rate: 0.00098244]
	Learning Rate: 0.000982444
	LOSS [training: 0.10245944114949641 | validation: 0.27472777426414435]
	TIME [epoch: 72.9 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10211103054117845		[learning rate: 0.00097781]
	Learning Rate: 0.000977814
	LOSS [training: 0.10211103054117845 | validation: 0.29290765429562265]
	TIME [epoch: 72.9 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09562454237807279		[learning rate: 0.00097321]
	Learning Rate: 0.000973207
	LOSS [training: 0.09562454237807279 | validation: 0.25208771242834405]
	TIME [epoch: 72.9 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v14b_20240719_004750/states/model_facs_v4_dec2b_2dpca_v14b_531.pth
	Model improved!!!
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11756962927077524		[learning rate: 0.00096862]
	Learning Rate: 0.000968621
	LOSS [training: 0.11756962927077524 | validation: 0.2890837707737733]
	TIME [epoch: 73 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11311790746851855		[learning rate: 0.00096406]
	Learning Rate: 0.000964057
	LOSS [training: 0.11311790746851855 | validation: 0.29955297905898887]
	TIME [epoch: 72.9 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0971033424454721		[learning rate: 0.00095951]
	Learning Rate: 0.000959514
	LOSS [training: 0.0971033424454721 | validation: 0.26444614794703736]
	TIME [epoch: 73 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12162276228377766		[learning rate: 0.00095499]
	Learning Rate: 0.000954993
	LOSS [training: 0.12162276228377766 | validation: 0.2677962398243431]
	TIME [epoch: 72.9 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1091438068339191		[learning rate: 0.00095049]
	Learning Rate: 0.000950493
	LOSS [training: 0.1091438068339191 | validation: 0.29413678700710577]
	TIME [epoch: 72.9 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10857053322765761		[learning rate: 0.00094601]
	Learning Rate: 0.000946014
	LOSS [training: 0.10857053322765761 | validation: 0.2664236877027655]
	TIME [epoch: 73 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10737991711238579		[learning rate: 0.00094156]
	Learning Rate: 0.000941556
	LOSS [training: 0.10737991711238579 | validation: 0.26693231043203114]
	TIME [epoch: 73 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12116102497173425		[learning rate: 0.00093712]
	Learning Rate: 0.000937119
	LOSS [training: 0.12116102497173425 | validation: 0.29162845219561206]
	TIME [epoch: 73 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11260887747119051		[learning rate: 0.0009327]
	Learning Rate: 0.000932703
	LOSS [training: 0.11260887747119051 | validation: 0.2662084299080102]
	TIME [epoch: 73 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09666851509045848		[learning rate: 0.00092831]
	Learning Rate: 0.000928309
	LOSS [training: 0.09666851509045848 | validation: 0.2632341522584639]
	TIME [epoch: 73 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10193373420523641		[learning rate: 0.00092393]
	Learning Rate: 0.000923934
	LOSS [training: 0.10193373420523641 | validation: 0.27791963550376847]
	TIME [epoch: 73 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0994407326608241		[learning rate: 0.00091958]
	Learning Rate: 0.000919581
	LOSS [training: 0.0994407326608241 | validation: 0.2689381830207611]
	TIME [epoch: 73 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10527226632783271		[learning rate: 0.00091525]
	Learning Rate: 0.000915247
	LOSS [training: 0.10527226632783271 | validation: 0.27819509979180307]
	TIME [epoch: 73 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12654524600627876		[learning rate: 0.00091093]
	Learning Rate: 0.000910934
	LOSS [training: 0.12654524600627876 | validation: 0.29623052438243]
	TIME [epoch: 73 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10737983388411598		[learning rate: 0.00090664]
	Learning Rate: 0.000906642
	LOSS [training: 0.10737983388411598 | validation: 0.2748441970218654]
	TIME [epoch: 73 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11275108530982311		[learning rate: 0.00090237]
	Learning Rate: 0.00090237
	LOSS [training: 0.11275108530982311 | validation: 0.2683937852935055]
	TIME [epoch: 73 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11113813047393238		[learning rate: 0.00089812]
	Learning Rate: 0.000898118
	LOSS [training: 0.11113813047393238 | validation: 0.26909981189992616]
	TIME [epoch: 73 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10367380337291966		[learning rate: 0.00089389]
	Learning Rate: 0.000893886
	LOSS [training: 0.10367380337291966 | validation: 0.25343792452710745]
	TIME [epoch: 73 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10438086196471759		[learning rate: 0.00088967]
	Learning Rate: 0.000889674
	LOSS [training: 0.10438086196471759 | validation: 0.25570136864500287]
	TIME [epoch: 73 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12211962234947604		[learning rate: 0.00088548]
	Learning Rate: 0.000885481
	LOSS [training: 0.12211962234947604 | validation: 0.28395202891707283]
	TIME [epoch: 73 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11672910577966532		[learning rate: 0.00088131]
	Learning Rate: 0.000881309
	LOSS [training: 0.11672910577966532 | validation: 0.2598845227704572]
	TIME [epoch: 73 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12139100001162521		[learning rate: 0.00087716]
	Learning Rate: 0.000877156
	LOSS [training: 0.12139100001162521 | validation: 0.27549549927662254]
	TIME [epoch: 73 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1112222220302436		[learning rate: 0.00087302]
	Learning Rate: 0.000873023
	LOSS [training: 0.1112222220302436 | validation: 0.2764450062715665]
	TIME [epoch: 73 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11213489870879459		[learning rate: 0.00086891]
	Learning Rate: 0.000868909
	LOSS [training: 0.11213489870879459 | validation: 0.29146236696085764]
	TIME [epoch: 73 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10949528772694003		[learning rate: 0.00086481]
	Learning Rate: 0.000864815
	LOSS [training: 0.10949528772694003 | validation: 0.2596346751070116]
	TIME [epoch: 73 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10691973998062015		[learning rate: 0.00086074]
	Learning Rate: 0.00086074
	LOSS [training: 0.10691973998062015 | validation: 0.27148540490725276]
	TIME [epoch: 73 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12938187939091897		[learning rate: 0.00085668]
	Learning Rate: 0.000856684
	LOSS [training: 0.12938187939091897 | validation: 0.2702435557519449]
	TIME [epoch: 73 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11237121207055467		[learning rate: 0.00085265]
	Learning Rate: 0.000852647
	LOSS [training: 0.11237121207055467 | validation: 0.25965245048981006]
	TIME [epoch: 73 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11171451061450305		[learning rate: 0.00084863]
	Learning Rate: 0.000848629
	LOSS [training: 0.11171451061450305 | validation: 0.25848167518039955]
	TIME [epoch: 73 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11928886513905074		[learning rate: 0.00084463]
	Learning Rate: 0.00084463
	LOSS [training: 0.11928886513905074 | validation: 0.2760619729735355]
	TIME [epoch: 73 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09998692588709295		[learning rate: 0.00084065]
	Learning Rate: 0.00084065
	LOSS [training: 0.09998692588709295 | validation: 0.27245170905903304]
	TIME [epoch: 73 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09738672765969264		[learning rate: 0.00083669]
	Learning Rate: 0.000836689
	LOSS [training: 0.09738672765969264 | validation: 0.2822014425479082]
	TIME [epoch: 73 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11069747099701827		[learning rate: 0.00083275]
	Learning Rate: 0.000832746
	LOSS [training: 0.11069747099701827 | validation: 0.2947269582530843]
	TIME [epoch: 73 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11500669884847929		[learning rate: 0.00082882]
	Learning Rate: 0.000828822
	LOSS [training: 0.11500669884847929 | validation: 0.26611975605279325]
	TIME [epoch: 73 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10434550942758367		[learning rate: 0.00082492]
	Learning Rate: 0.000824917
	LOSS [training: 0.10434550942758367 | validation: 0.2904215056173538]
	TIME [epoch: 73 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12024192943780912		[learning rate: 0.00082103]
	Learning Rate: 0.00082103
	LOSS [training: 0.12024192943780912 | validation: 0.2766428661292336]
	TIME [epoch: 72.9 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10059506135602742		[learning rate: 0.00081716]
	Learning Rate: 0.000817161
	LOSS [training: 0.10059506135602742 | validation: 0.2779630787705728]
	TIME [epoch: 73 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10600243358507216		[learning rate: 0.00081331]
	Learning Rate: 0.000813311
	LOSS [training: 0.10600243358507216 | validation: 0.27807336608716415]
	TIME [epoch: 72.9 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11030907486559641		[learning rate: 0.00080948]
	Learning Rate: 0.000809478
	LOSS [training: 0.11030907486559641 | validation: 0.3169935391163493]
	TIME [epoch: 72.9 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10909795517667546		[learning rate: 0.00080566]
	Learning Rate: 0.000805664
	LOSS [training: 0.10909795517667546 | validation: 0.2596503590951666]
	TIME [epoch: 73 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10912925228531067		[learning rate: 0.00080187]
	Learning Rate: 0.000801868
	LOSS [training: 0.10912925228531067 | validation: 0.2817253217174244]
	TIME [epoch: 73 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10145079533204987		[learning rate: 0.00079809]
	Learning Rate: 0.000798089
	LOSS [training: 0.10145079533204987 | validation: 0.28802906863565736]
	TIME [epoch: 73 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11267421968542538		[learning rate: 0.00079433]
	Learning Rate: 0.000794328
	LOSS [training: 0.11267421968542538 | validation: 0.25337285202065535]
	TIME [epoch: 73 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11394956098391394		[learning rate: 0.00079059]
	Learning Rate: 0.000790585
	LOSS [training: 0.11394956098391394 | validation: 0.2718912826890502]
	TIME [epoch: 73.1 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09833618919200075		[learning rate: 0.00078686]
	Learning Rate: 0.00078686
	LOSS [training: 0.09833618919200075 | validation: 0.2610979888785502]
	TIME [epoch: 73 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10866669272466103		[learning rate: 0.00078315]
	Learning Rate: 0.000783152
	LOSS [training: 0.10866669272466103 | validation: 0.2700504764362261]
	TIME [epoch: 73 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11033856533489851		[learning rate: 0.00077946]
	Learning Rate: 0.000779462
	LOSS [training: 0.11033856533489851 | validation: 0.26449601792654065]
	TIME [epoch: 72.9 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10682354423742176		[learning rate: 0.00077579]
	Learning Rate: 0.000775789
	LOSS [training: 0.10682354423742176 | validation: 0.2974259739298114]
	TIME [epoch: 73 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09836348816705529		[learning rate: 0.00077213]
	Learning Rate: 0.000772133
	LOSS [training: 0.09836348816705529 | validation: 0.2554965260710619]
	TIME [epoch: 73 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13231839100015177		[learning rate: 0.00076849]
	Learning Rate: 0.000768495
	LOSS [training: 0.13231839100015177 | validation: 0.25825811738096865]
	TIME [epoch: 73 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1093087198650127		[learning rate: 0.00076487]
	Learning Rate: 0.000764874
	LOSS [training: 0.1093087198650127 | validation: 0.2707840551701249]
	TIME [epoch: 73 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0948643565318236		[learning rate: 0.00076127]
	Learning Rate: 0.00076127
	LOSS [training: 0.0948643565318236 | validation: 0.3024748740200852]
	TIME [epoch: 73.1 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12907672914511267		[learning rate: 0.00075768]
	Learning Rate: 0.000757682
	LOSS [training: 0.12907672914511267 | validation: 0.2712716238323716]
	TIME [epoch: 73.1 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11412693652898673		[learning rate: 0.00075411]
	Learning Rate: 0.000754112
	LOSS [training: 0.11412693652898673 | validation: 0.26728610632393957]
	TIME [epoch: 73 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10938932368665819		[learning rate: 0.00075056]
	Learning Rate: 0.000750559
	LOSS [training: 0.10938932368665819 | validation: 0.2692149241980229]
	TIME [epoch: 73 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11769790690025844		[learning rate: 0.00074702]
	Learning Rate: 0.000747022
	LOSS [training: 0.11769790690025844 | validation: 0.2696214105968929]
	TIME [epoch: 73 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10790417496254544		[learning rate: 0.0007435]
	Learning Rate: 0.000743502
	LOSS [training: 0.10790417496254544 | validation: 0.26280397488176566]
	TIME [epoch: 73 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1023398973929696		[learning rate: 0.00074]
	Learning Rate: 0.000739998
	LOSS [training: 0.1023398973929696 | validation: 0.26779776811096045]
	TIME [epoch: 73 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09939470880422083		[learning rate: 0.00073651]
	Learning Rate: 0.000736511
	LOSS [training: 0.09939470880422083 | validation: 0.26160910650074864]
	TIME [epoch: 73 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10818047934819885		[learning rate: 0.00073304]
	Learning Rate: 0.000733041
	LOSS [training: 0.10818047934819885 | validation: 0.2812017867899844]
	TIME [epoch: 73 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11297472003491713		[learning rate: 0.00072959]
	Learning Rate: 0.000729587
	LOSS [training: 0.11297472003491713 | validation: 0.27366114217924115]
	TIME [epoch: 72.9 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1054085340234171		[learning rate: 0.00072615]
	Learning Rate: 0.000726149
	LOSS [training: 0.1054085340234171 | validation: 0.27326386579847767]
	TIME [epoch: 73 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1000649564133989		[learning rate: 0.00072273]
	Learning Rate: 0.000722727
	LOSS [training: 0.1000649564133989 | validation: 0.30039743164773325]
	TIME [epoch: 73 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10570897387781751		[learning rate: 0.00071932]
	Learning Rate: 0.000719321
	LOSS [training: 0.10570897387781751 | validation: 0.2581983117569068]
	TIME [epoch: 73 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09679993018474281		[learning rate: 0.00071593]
	Learning Rate: 0.000715932
	LOSS [training: 0.09679993018474281 | validation: 0.27262364005162054]
	TIME [epoch: 73 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1052943165641585		[learning rate: 0.00071256]
	Learning Rate: 0.000712558
	LOSS [training: 0.1052943165641585 | validation: 0.28322983644460414]
	TIME [epoch: 73 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11091208477415264		[learning rate: 0.0007092]
	Learning Rate: 0.000709201
	LOSS [training: 0.11091208477415264 | validation: 0.28242630324415013]
	TIME [epoch: 73 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11232579871715584		[learning rate: 0.00070586]
	Learning Rate: 0.000705859
	LOSS [training: 0.11232579871715584 | validation: 0.2617241134409173]
	TIME [epoch: 73 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10593833575216965		[learning rate: 0.00070253]
	Learning Rate: 0.000702533
	LOSS [training: 0.10593833575216965 | validation: 0.2569825260767556]
	TIME [epoch: 72.9 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12179890959045037		[learning rate: 0.00069922]
	Learning Rate: 0.000699222
	LOSS [training: 0.12179890959045037 | validation: 0.28446671216620456]
	TIME [epoch: 72.9 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10397874508063261		[learning rate: 0.00069593]
	Learning Rate: 0.000695928
	LOSS [training: 0.10397874508063261 | validation: 0.30464734181406955]
	TIME [epoch: 72.9 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09454548647873089		[learning rate: 0.00069265]
	Learning Rate: 0.000692648
	LOSS [training: 0.09454548647873089 | validation: 0.26117146467755187]
	TIME [epoch: 72.9 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09841777002985191		[learning rate: 0.00068938]
	Learning Rate: 0.000689385
	LOSS [training: 0.09841777002985191 | validation: 0.2787276172941806]
	TIME [epoch: 72.9 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09739377877630968		[learning rate: 0.00068614]
	Learning Rate: 0.000686136
	LOSS [training: 0.09739377877630968 | validation: 0.26659258795186075]
	TIME [epoch: 72.9 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10246827406577344		[learning rate: 0.0006829]
	Learning Rate: 0.000682903
	LOSS [training: 0.10246827406577344 | validation: 0.27537601140121587]
	TIME [epoch: 72.9 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11520409409518165		[learning rate: 0.00067969]
	Learning Rate: 0.000679685
	LOSS [training: 0.11520409409518165 | validation: 0.2800620493893274]
	TIME [epoch: 72.9 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10650266615064347		[learning rate: 0.00067648]
	Learning Rate: 0.000676482
	LOSS [training: 0.10650266615064347 | validation: 0.27263081412054835]
	TIME [epoch: 73 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10951068332936995		[learning rate: 0.00067329]
	Learning Rate: 0.000673295
	LOSS [training: 0.10951068332936995 | validation: 0.2689832089633455]
	TIME [epoch: 73 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12817361315768003		[learning rate: 0.00067012]
	Learning Rate: 0.000670122
	LOSS [training: 0.12817361315768003 | validation: 0.27745955141371065]
	TIME [epoch: 73 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11254746282223668		[learning rate: 0.00066696]
	Learning Rate: 0.000666964
	LOSS [training: 0.11254746282223668 | validation: 0.2668175397801967]
	TIME [epoch: 73 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10695129295381868		[learning rate: 0.00066382]
	Learning Rate: 0.000663821
	LOSS [training: 0.10695129295381868 | validation: 0.25998385860831813]
	TIME [epoch: 72.9 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12264231253152828		[learning rate: 0.00066069]
	Learning Rate: 0.000660694
	LOSS [training: 0.12264231253152828 | validation: 0.2695241408555285]
	TIME [epoch: 73 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09504686387670769		[learning rate: 0.00065758]
	Learning Rate: 0.00065758
	LOSS [training: 0.09504686387670769 | validation: 0.275477167018252]
	TIME [epoch: 72.9 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10035513110072168		[learning rate: 0.00065448]
	Learning Rate: 0.000654482
	LOSS [training: 0.10035513110072168 | validation: 0.2823755661471275]
	TIME [epoch: 73.1 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10656026415756967		[learning rate: 0.0006514]
	Learning Rate: 0.000651398
	LOSS [training: 0.10656026415756967 | validation: 0.2801548709269551]
	TIME [epoch: 73 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10294151297001851		[learning rate: 0.00064833]
	Learning Rate: 0.000648328
	LOSS [training: 0.10294151297001851 | validation: 0.26521113117443995]
	TIME [epoch: 73 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10980794457285392		[learning rate: 0.00064527]
	Learning Rate: 0.000645273
	LOSS [training: 0.10980794457285392 | validation: 0.29316407475202577]
	TIME [epoch: 73 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09790567000285233		[learning rate: 0.00064223]
	Learning Rate: 0.000642232
	LOSS [training: 0.09790567000285233 | validation: 0.27170968235194254]
	TIME [epoch: 73 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11181693450588429		[learning rate: 0.00063921]
	Learning Rate: 0.000639206
	LOSS [training: 0.11181693450588429 | validation: 0.2728586002833901]
	TIME [epoch: 73 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10509474604459637		[learning rate: 0.00063619]
	Learning Rate: 0.000636194
	LOSS [training: 0.10509474604459637 | validation: 0.2821555141797966]
	TIME [epoch: 73 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10035126533511043		[learning rate: 0.0006332]
	Learning Rate: 0.000633196
	LOSS [training: 0.10035126533511043 | validation: 0.26533136991698114]
	TIME [epoch: 73 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1051401369438895		[learning rate: 0.00063021]
	Learning Rate: 0.000630213
	LOSS [training: 0.1051401369438895 | validation: 0.27898677909793956]
	TIME [epoch: 73 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11203271336080907		[learning rate: 0.00062724]
	Learning Rate: 0.000627243
	LOSS [training: 0.11203271336080907 | validation: 0.2672525416108672]
	TIME [epoch: 73 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09713522626388524		[learning rate: 0.00062429]
	Learning Rate: 0.000624287
	LOSS [training: 0.09713522626388524 | validation: 0.2792665172067978]
	TIME [epoch: 73 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10200885472850091		[learning rate: 0.00062135]
	Learning Rate: 0.000621346
	LOSS [training: 0.10200885472850091 | validation: 0.26661504248753815]
	TIME [epoch: 73 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10125250878193935		[learning rate: 0.00061842]
	Learning Rate: 0.000618418
	LOSS [training: 0.10125250878193935 | validation: 0.2642226334444068]
	TIME [epoch: 73 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09723167883133041		[learning rate: 0.0006155]
	Learning Rate: 0.000615504
	LOSS [training: 0.09723167883133041 | validation: 0.2749095513009084]
	TIME [epoch: 72.9 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12131785603872276		[learning rate: 0.0006126]
	Learning Rate: 0.000612604
	LOSS [training: 0.12131785603872276 | validation: 0.25719798796811]
	TIME [epoch: 72.9 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10216222461817555		[learning rate: 0.00060972]
	Learning Rate: 0.000609717
	LOSS [training: 0.10216222461817555 | validation: 0.27231107187237]
	TIME [epoch: 73 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09376621584815722		[learning rate: 0.00060684]
	Learning Rate: 0.000606844
	LOSS [training: 0.09376621584815722 | validation: 0.25655884789287103]
	TIME [epoch: 73 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10671194166173464		[learning rate: 0.00060398]
	Learning Rate: 0.000603984
	LOSS [training: 0.10671194166173464 | validation: 0.29596313015424003]
	TIME [epoch: 73 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0913011331617185		[learning rate: 0.00060114]
	Learning Rate: 0.000601138
	LOSS [training: 0.0913011331617185 | validation: 0.26971977385054596]
	TIME [epoch: 73 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09677014409434605		[learning rate: 0.00059831]
	Learning Rate: 0.000598306
	LOSS [training: 0.09677014409434605 | validation: 0.2629692052714628]
	TIME [epoch: 73 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09128044190860067		[learning rate: 0.00059549]
	Learning Rate: 0.000595486
	LOSS [training: 0.09128044190860067 | validation: 0.27092912342842107]
	TIME [epoch: 73 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10656659795636035		[learning rate: 0.00059268]
	Learning Rate: 0.00059268
	LOSS [training: 0.10656659795636035 | validation: 0.3042050965495479]
	TIME [epoch: 73 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1075612017715583		[learning rate: 0.00058989]
	Learning Rate: 0.000589888
	LOSS [training: 0.1075612017715583 | validation: 0.28655848202597994]
	TIME [epoch: 72.9 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09598160470040999		[learning rate: 0.00058711]
	Learning Rate: 0.000587108
	LOSS [training: 0.09598160470040999 | validation: 0.27859543666371395]
	TIME [epoch: 73 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10098639429310445		[learning rate: 0.00058434]
	Learning Rate: 0.000584341
	LOSS [training: 0.10098639429310445 | validation: 0.26238059638162925]
	TIME [epoch: 72.9 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11709880845375321		[learning rate: 0.00058159]
	Learning Rate: 0.000581588
	LOSS [training: 0.11709880845375321 | validation: 0.25239293363510207]
	TIME [epoch: 73 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0944354296336102		[learning rate: 0.00057885]
	Learning Rate: 0.000578847
	LOSS [training: 0.0944354296336102 | validation: 0.28087506878595925]
	TIME [epoch: 73 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09310358287768443		[learning rate: 0.00057612]
	Learning Rate: 0.00057612
	LOSS [training: 0.09310358287768443 | validation: 0.2637959057160681]
	TIME [epoch: 72.9 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10074518000015405		[learning rate: 0.00057341]
	Learning Rate: 0.000573405
	LOSS [training: 0.10074518000015405 | validation: 0.25976953554578386]
	TIME [epoch: 73 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11598868852412275		[learning rate: 0.0005707]
	Learning Rate: 0.000570703
	LOSS [training: 0.11598868852412275 | validation: 0.2532079078356618]
	TIME [epoch: 73 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09750480647689551		[learning rate: 0.00056801]
	Learning Rate: 0.000568014
	LOSS [training: 0.09750480647689551 | validation: 0.2655109616620127]
	TIME [epoch: 73.1 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11620256956384864		[learning rate: 0.00056534]
	Learning Rate: 0.000565337
	LOSS [training: 0.11620256956384864 | validation: 0.2665119277680351]
	TIME [epoch: 73 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1010874515253071		[learning rate: 0.00056267]
	Learning Rate: 0.000562673
	LOSS [training: 0.1010874515253071 | validation: 0.2716321301117738]
	TIME [epoch: 73 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11866394319456855		[learning rate: 0.00056002]
	Learning Rate: 0.000560022
	LOSS [training: 0.11866394319456855 | validation: 0.2653703677616899]
	TIME [epoch: 73.1 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10977255771318431		[learning rate: 0.00055738]
	Learning Rate: 0.000557383
	LOSS [training: 0.10977255771318431 | validation: 0.2835412946039876]
	TIME [epoch: 73 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10678565150741547		[learning rate: 0.00055476]
	Learning Rate: 0.000554757
	LOSS [training: 0.10678565150741547 | validation: 0.26211977504874945]
	TIME [epoch: 72.9 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09996863087501094		[learning rate: 0.00055214]
	Learning Rate: 0.000552143
	LOSS [training: 0.09996863087501094 | validation: 0.2695177074311376]
	TIME [epoch: 73 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10548504649764522		[learning rate: 0.00054954]
	Learning Rate: 0.000549541
	LOSS [training: 0.10548504649764522 | validation: 0.27960411064843305]
	TIME [epoch: 73 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11416349877773066		[learning rate: 0.00054695]
	Learning Rate: 0.000546951
	LOSS [training: 0.11416349877773066 | validation: 0.2709783648245577]
	TIME [epoch: 73.1 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0947638271431523		[learning rate: 0.00054437]
	Learning Rate: 0.000544374
	LOSS [training: 0.0947638271431523 | validation: 0.2585631641607848]
	TIME [epoch: 73 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11236149050253177		[learning rate: 0.00054181]
	Learning Rate: 0.000541809
	LOSS [training: 0.11236149050253177 | validation: 0.2690210712920914]
	TIME [epoch: 73 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09474749797038359		[learning rate: 0.00053926]
	Learning Rate: 0.000539256
	LOSS [training: 0.09474749797038359 | validation: 0.24643744195073608]
	TIME [epoch: 73 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v14b_20240719_004750/states/model_facs_v4_dec2b_2dpca_v14b_656.pth
	Model improved!!!
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10393722895926086		[learning rate: 0.00053671]
	Learning Rate: 0.000536715
	LOSS [training: 0.10393722895926086 | validation: 0.2675791073017352]
	TIME [epoch: 73 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09651414115096146		[learning rate: 0.00053419]
	Learning Rate: 0.000534186
	LOSS [training: 0.09651414115096146 | validation: 0.26192472568646924]
	TIME [epoch: 73 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10354061125175498		[learning rate: 0.00053167]
	Learning Rate: 0.000531669
	LOSS [training: 0.10354061125175498 | validation: 0.26763593045475226]
	TIME [epoch: 73 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10156583431242505		[learning rate: 0.00052916]
	Learning Rate: 0.000529163
	LOSS [training: 0.10156583431242505 | validation: 0.27269277333251374]
	TIME [epoch: 73 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11105815411651158		[learning rate: 0.00052667]
	Learning Rate: 0.00052667
	LOSS [training: 0.11105815411651158 | validation: 0.2818141708791248]
	TIME [epoch: 73 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10875246599491245		[learning rate: 0.00052419]
	Learning Rate: 0.000524188
	LOSS [training: 0.10875246599491245 | validation: 0.27940221392719555]
	TIME [epoch: 73 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11462064864249362		[learning rate: 0.00052172]
	Learning Rate: 0.000521718
	LOSS [training: 0.11462064864249362 | validation: 0.26685309906291504]
	TIME [epoch: 73 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09858811835511502		[learning rate: 0.00051926]
	Learning Rate: 0.00051926
	LOSS [training: 0.09858811835511502 | validation: 0.2781435003763977]
	TIME [epoch: 73 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12254825196480318		[learning rate: 0.00051681]
	Learning Rate: 0.000516813
	LOSS [training: 0.12254825196480318 | validation: 0.26129868129479383]
	TIME [epoch: 73 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10633647153760799		[learning rate: 0.00051438]
	Learning Rate: 0.000514378
	LOSS [training: 0.10633647153760799 | validation: 0.2910592539112151]
	TIME [epoch: 73 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10542540763811344		[learning rate: 0.00051195]
	Learning Rate: 0.000511954
	LOSS [training: 0.10542540763811344 | validation: 0.2588700993278188]
	TIME [epoch: 73 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10139102305840199		[learning rate: 0.00050954]
	Learning Rate: 0.000509541
	LOSS [training: 0.10139102305840199 | validation: 0.27049884932906376]
	TIME [epoch: 73 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11011770892808437		[learning rate: 0.00050714]
	Learning Rate: 0.00050714
	LOSS [training: 0.11011770892808437 | validation: 0.2505091060277673]
	TIME [epoch: 73 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09494846627341781		[learning rate: 0.00050475]
	Learning Rate: 0.000504751
	LOSS [training: 0.09494846627341781 | validation: 0.26089465150046787]
	TIME [epoch: 73 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10440669296355959		[learning rate: 0.00050237]
	Learning Rate: 0.000502372
	LOSS [training: 0.10440669296355959 | validation: 0.26098385197509283]
	TIME [epoch: 73 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11306313258683352		[learning rate: 0.00050001]
	Learning Rate: 0.000500005
	LOSS [training: 0.11306313258683352 | validation: 0.27770529015695916]
	TIME [epoch: 73 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11571197446450118		[learning rate: 0.00049765]
	Learning Rate: 0.000497649
	LOSS [training: 0.11571197446450118 | validation: 0.26497163620907827]
	TIME [epoch: 72.9 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0973441825939894		[learning rate: 0.0004953]
	Learning Rate: 0.000495304
	LOSS [training: 0.0973441825939894 | validation: 0.3064216781148535]
	TIME [epoch: 73 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11717106135902927		[learning rate: 0.00049297]
	Learning Rate: 0.00049297
	LOSS [training: 0.11717106135902927 | validation: 0.2721261021882904]
	TIME [epoch: 73.1 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09769303293765466		[learning rate: 0.00049065]
	Learning Rate: 0.000490647
	LOSS [training: 0.09769303293765466 | validation: 0.27146242891687267]
	TIME [epoch: 73 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10165764171316541		[learning rate: 0.00048834]
	Learning Rate: 0.000488335
	LOSS [training: 0.10165764171316541 | validation: 0.28054873095118377]
	TIME [epoch: 73 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09356954342017564		[learning rate: 0.00048603]
	Learning Rate: 0.000486034
	LOSS [training: 0.09356954342017564 | validation: 0.2547437477002356]
	TIME [epoch: 72.9 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09865830488012739		[learning rate: 0.00048374]
	Learning Rate: 0.000483744
	LOSS [training: 0.09865830488012739 | validation: 0.2773010094465106]
	TIME [epoch: 72.8 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11942354161334201		[learning rate: 0.00048146]
	Learning Rate: 0.000481464
	LOSS [training: 0.11942354161334201 | validation: 0.285675498244732]
	TIME [epoch: 73 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10248098637706177		[learning rate: 0.0004792]
	Learning Rate: 0.000479196
	LOSS [training: 0.10248098637706177 | validation: 0.27629291279492313]
	TIME [epoch: 73.1 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12025546795300986		[learning rate: 0.00047694]
	Learning Rate: 0.000476938
	LOSS [training: 0.12025546795300986 | validation: 0.26156690950652045]
	TIME [epoch: 73 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11402024337341099		[learning rate: 0.00047469]
	Learning Rate: 0.00047469
	LOSS [training: 0.11402024337341099 | validation: 0.2565928929417597]
	TIME [epoch: 72.9 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0998998290243697		[learning rate: 0.00047245]
	Learning Rate: 0.000472453
	LOSS [training: 0.0998998290243697 | validation: 0.26496215388091643]
	TIME [epoch: 73 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12113608945676987		[learning rate: 0.00047023]
	Learning Rate: 0.000470227
	LOSS [training: 0.12113608945676987 | validation: 0.2683573071701722]
	TIME [epoch: 73 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10925625502948855		[learning rate: 0.00046801]
	Learning Rate: 0.000468011
	LOSS [training: 0.10925625502948855 | validation: 0.2659606462855756]
	TIME [epoch: 73 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0898875027148297		[learning rate: 0.00046581]
	Learning Rate: 0.000465806
	LOSS [training: 0.0898875027148297 | validation: 0.2713598509495207]
	TIME [epoch: 73.1 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11022860414801422		[learning rate: 0.00046361]
	Learning Rate: 0.000463611
	LOSS [training: 0.11022860414801422 | validation: 0.2573802072101687]
	TIME [epoch: 73 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1147687491004646		[learning rate: 0.00046143]
	Learning Rate: 0.000461426
	LOSS [training: 0.1147687491004646 | validation: 0.2574104943176346]
	TIME [epoch: 73.1 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10668856457638498		[learning rate: 0.00045925]
	Learning Rate: 0.000459252
	LOSS [training: 0.10668856457638498 | validation: 0.2781467765768833]
	TIME [epoch: 73 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08729928484024646		[learning rate: 0.00045709]
	Learning Rate: 0.000457088
	LOSS [training: 0.08729928484024646 | validation: 0.2560635939060903]
	TIME [epoch: 73 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.096152367317472		[learning rate: 0.00045493]
	Learning Rate: 0.000454934
	LOSS [training: 0.096152367317472 | validation: 0.27535054741121223]
	TIME [epoch: 73 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1170224937829116		[learning rate: 0.00045279]
	Learning Rate: 0.000452791
	LOSS [training: 0.1170224937829116 | validation: 0.25822737203544743]
	TIME [epoch: 73 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10144477729868508		[learning rate: 0.00045066]
	Learning Rate: 0.000450657
	LOSS [training: 0.10144477729868508 | validation: 0.2559438809223554]
	TIME [epoch: 73 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09709313211275568		[learning rate: 0.00044853]
	Learning Rate: 0.000448533
	LOSS [training: 0.09709313211275568 | validation: 0.24624632969818525]
	TIME [epoch: 72.9 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v14b_20240719_004750/states/model_facs_v4_dec2b_2dpca_v14b_695.pth
	Model improved!!!
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11607327127431782		[learning rate: 0.00044642]
	Learning Rate: 0.00044642
	LOSS [training: 0.11607327127431782 | validation: 0.2638674330106972]
	TIME [epoch: 73.1 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09515855780249027		[learning rate: 0.00044432]
	Learning Rate: 0.000444316
	LOSS [training: 0.09515855780249027 | validation: 0.2774509381055866]
	TIME [epoch: 73 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10248885976539798		[learning rate: 0.00044222]
	Learning Rate: 0.000442223
	LOSS [training: 0.10248885976539798 | validation: 0.27862890582592525]
	TIME [epoch: 73 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09643089772237581		[learning rate: 0.00044014]
	Learning Rate: 0.000440139
	LOSS [training: 0.09643089772237581 | validation: 0.2615729611058173]
	TIME [epoch: 73 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11040338487984219		[learning rate: 0.00043806]
	Learning Rate: 0.000438065
	LOSS [training: 0.11040338487984219 | validation: 0.26005960215704493]
	TIME [epoch: 73 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10600006154811709		[learning rate: 0.000436]
	Learning Rate: 0.000436001
	LOSS [training: 0.10600006154811709 | validation: 0.25104720603530994]
	TIME [epoch: 73 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1044185159345423		[learning rate: 0.00043395]
	Learning Rate: 0.000433946
	LOSS [training: 0.1044185159345423 | validation: 0.2824688695689127]
	TIME [epoch: 73 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09529273115299751		[learning rate: 0.0004319]
	Learning Rate: 0.000431901
	LOSS [training: 0.09529273115299751 | validation: 0.2658783903247605]
	TIME [epoch: 73 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09826719226908037		[learning rate: 0.00042987]
	Learning Rate: 0.000429866
	LOSS [training: 0.09826719226908037 | validation: 0.25303147185064007]
	TIME [epoch: 73 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1060228212030654		[learning rate: 0.00042784]
	Learning Rate: 0.000427841
	LOSS [training: 0.1060228212030654 | validation: 0.26836482519471416]
	TIME [epoch: 73 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10715318044531312		[learning rate: 0.00042582]
	Learning Rate: 0.000425825
	LOSS [training: 0.10715318044531312 | validation: 0.27139164043537756]
	TIME [epoch: 73 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09804467641318361		[learning rate: 0.00042382]
	Learning Rate: 0.000423818
	LOSS [training: 0.09804467641318361 | validation: 0.2616812015323668]
	TIME [epoch: 73 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10458868473220423		[learning rate: 0.00042182]
	Learning Rate: 0.000421821
	LOSS [training: 0.10458868473220423 | validation: 0.26117372374204995]
	TIME [epoch: 73 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11893224002960791		[learning rate: 0.00041983]
	Learning Rate: 0.000419833
	LOSS [training: 0.11893224002960791 | validation: 0.275147320062846]
	TIME [epoch: 73 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11623920718702307		[learning rate: 0.00041786]
	Learning Rate: 0.000417855
	LOSS [training: 0.11623920718702307 | validation: 0.2564072111548287]
	TIME [epoch: 73 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10878304694538232		[learning rate: 0.00041589]
	Learning Rate: 0.000415886
	LOSS [training: 0.10878304694538232 | validation: 0.2713051300231855]
	TIME [epoch: 73 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1002586964742292		[learning rate: 0.00041393]
	Learning Rate: 0.000413926
	LOSS [training: 0.1002586964742292 | validation: 0.27061864670581826]
	TIME [epoch: 73 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09987077188491889		[learning rate: 0.00041198]
	Learning Rate: 0.000411976
	LOSS [training: 0.09987077188491889 | validation: 0.27653991234232095]
	TIME [epoch: 73 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11412144131461782		[learning rate: 0.00041003]
	Learning Rate: 0.000410035
	LOSS [training: 0.11412144131461782 | validation: 0.24916826316282187]
	TIME [epoch: 73 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11321630788612058		[learning rate: 0.0004081]
	Learning Rate: 0.000408102
	LOSS [training: 0.11321630788612058 | validation: 0.26688831646083905]
	TIME [epoch: 73 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10024310836209308		[learning rate: 0.00040618]
	Learning Rate: 0.000406179
	LOSS [training: 0.10024310836209308 | validation: 0.24930517360271098]
	TIME [epoch: 72.9 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1106045356474619		[learning rate: 0.00040427]
	Learning Rate: 0.000404266
	LOSS [training: 0.1106045356474619 | validation: 0.27367134262314885]
	TIME [epoch: 73 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10986518823578253		[learning rate: 0.00040236]
	Learning Rate: 0.000402361
	LOSS [training: 0.10986518823578253 | validation: 0.2625724432045407]
	TIME [epoch: 73 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10488457167347817		[learning rate: 0.00040046]
	Learning Rate: 0.000400465
	LOSS [training: 0.10488457167347817 | validation: 0.26398794261228253]
	TIME [epoch: 73 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10418114193997179		[learning rate: 0.00039858]
	Learning Rate: 0.000398578
	LOSS [training: 0.10418114193997179 | validation: 0.25400058825325295]
	TIME [epoch: 73 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10486379032708834		[learning rate: 0.0003967]
	Learning Rate: 0.000396699
	LOSS [training: 0.10486379032708834 | validation: 0.25861297560609525]
	TIME [epoch: 73 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10605039942976406		[learning rate: 0.00039483]
	Learning Rate: 0.00039483
	LOSS [training: 0.10605039942976406 | validation: 0.2631804075183525]
	TIME [epoch: 73 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0972234587748603		[learning rate: 0.00039297]
	Learning Rate: 0.00039297
	LOSS [training: 0.0972234587748603 | validation: 0.2459269955752887]
	TIME [epoch: 73 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v14b_20240719_004750/states/model_facs_v4_dec2b_2dpca_v14b_723.pth
	Model improved!!!
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1253906733375177		[learning rate: 0.00039112]
	Learning Rate: 0.000391118
	LOSS [training: 0.1253906733375177 | validation: 0.27480821715870096]
	TIME [epoch: 73 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12007902814436491		[learning rate: 0.00038927]
	Learning Rate: 0.000389275
	LOSS [training: 0.12007902814436491 | validation: 0.25299098187578256]
	TIME [epoch: 73 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11888749161333509		[learning rate: 0.00038744]
	Learning Rate: 0.000387441
	LOSS [training: 0.11888749161333509 | validation: 0.2588367582273907]
	TIME [epoch: 73 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10203006758526463		[learning rate: 0.00038561]
	Learning Rate: 0.000385615
	LOSS [training: 0.10203006758526463 | validation: 0.2513967517963082]
	TIME [epoch: 73 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09615197906999305		[learning rate: 0.0003838]
	Learning Rate: 0.000383798
	LOSS [training: 0.09615197906999305 | validation: 0.26328717601720736]
	TIME [epoch: 73 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1145873673570203		[learning rate: 0.00038199]
	Learning Rate: 0.000381989
	LOSS [training: 0.1145873673570203 | validation: 0.2820024224087492]
	TIME [epoch: 73 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09942197014897147		[learning rate: 0.00038019]
	Learning Rate: 0.000380189
	LOSS [training: 0.09942197014897147 | validation: 0.2774430897864158]
	TIME [epoch: 73 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10202087799873273		[learning rate: 0.0003784]
	Learning Rate: 0.000378398
	LOSS [training: 0.10202087799873273 | validation: 0.24884035937174426]
	TIME [epoch: 72.9 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10402627957145258		[learning rate: 0.00037661]
	Learning Rate: 0.000376615
	LOSS [training: 0.10402627957145258 | validation: 0.2593160435985572]
	TIME [epoch: 73 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11258905984816658		[learning rate: 0.00037484]
	Learning Rate: 0.00037484
	LOSS [training: 0.11258905984816658 | validation: 0.2743088825263093]
	TIME [epoch: 73 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0956488194560321		[learning rate: 0.00037307]
	Learning Rate: 0.000373074
	LOSS [training: 0.0956488194560321 | validation: 0.2717843833746057]
	TIME [epoch: 72.9 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1081215477459522		[learning rate: 0.00037132]
	Learning Rate: 0.000371316
	LOSS [training: 0.1081215477459522 | validation: 0.25965632394936294]
	TIME [epoch: 72.9 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1038937940378648		[learning rate: 0.00036957]
	Learning Rate: 0.000369566
	LOSS [training: 0.1038937940378648 | validation: 0.2766760192981786]
	TIME [epoch: 73 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11379739745218573		[learning rate: 0.00036782]
	Learning Rate: 0.000367825
	LOSS [training: 0.11379739745218573 | validation: 0.24908563451883914]
	TIME [epoch: 72.9 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10984655141600638		[learning rate: 0.00036609]
	Learning Rate: 0.000366092
	LOSS [training: 0.10984655141600638 | validation: 0.2833124224341234]
	TIME [epoch: 73 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10052187855866868		[learning rate: 0.00036437]
	Learning Rate: 0.000364367
	LOSS [training: 0.10052187855866868 | validation: 0.2575729412188641]
	TIME [epoch: 73 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10490336521755118		[learning rate: 0.00036265]
	Learning Rate: 0.00036265
	LOSS [training: 0.10490336521755118 | validation: 0.26992927553252816]
	TIME [epoch: 73 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09769910479882786		[learning rate: 0.00036094]
	Learning Rate: 0.000360941
	LOSS [training: 0.09769910479882786 | validation: 0.2732485428974274]
	TIME [epoch: 73 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10048960629971136		[learning rate: 0.00035924]
	Learning Rate: 0.00035924
	LOSS [training: 0.10048960629971136 | validation: 0.27246221854700287]
	TIME [epoch: 73 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09240148896479516		[learning rate: 0.00035755]
	Learning Rate: 0.000357547
	LOSS [training: 0.09240148896479516 | validation: 0.26995929353768483]
	TIME [epoch: 72.9 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12285219298312353		[learning rate: 0.00035586]
	Learning Rate: 0.000355862
	LOSS [training: 0.12285219298312353 | validation: 0.2621807651704213]
	TIME [epoch: 72.9 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1069210507860611		[learning rate: 0.00035419]
	Learning Rate: 0.000354185
	LOSS [training: 0.1069210507860611 | validation: 0.2598050459761935]
	TIME [epoch: 73 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08669460240233774		[learning rate: 0.00035252]
	Learning Rate: 0.000352517
	LOSS [training: 0.08669460240233774 | validation: 0.26079758243815726]
	TIME [epoch: 73 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11571305344563416		[learning rate: 0.00035086]
	Learning Rate: 0.000350855
	LOSS [training: 0.11571305344563416 | validation: 0.25573456947049616]
	TIME [epoch: 73 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1104334430996621		[learning rate: 0.0003492]
	Learning Rate: 0.000349202
	LOSS [training: 0.1104334430996621 | validation: 0.2635406341278176]
	TIME [epoch: 73 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10646751499432652		[learning rate: 0.00034756]
	Learning Rate: 0.000347557
	LOSS [training: 0.10646751499432652 | validation: 0.25622840276054015]
	TIME [epoch: 73 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11192055009189393		[learning rate: 0.00034592]
	Learning Rate: 0.000345919
	LOSS [training: 0.11192055009189393 | validation: 0.2513408065307296]
	TIME [epoch: 73 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11115324055471686		[learning rate: 0.00034429]
	Learning Rate: 0.000344289
	LOSS [training: 0.11115324055471686 | validation: 0.27508742223148036]
	TIME [epoch: 73 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09755049763460222		[learning rate: 0.00034267]
	Learning Rate: 0.000342667
	LOSS [training: 0.09755049763460222 | validation: 0.2764634883527526]
	TIME [epoch: 73 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10299788934463676		[learning rate: 0.00034105]
	Learning Rate: 0.000341052
	LOSS [training: 0.10299788934463676 | validation: 0.2592747354258985]
	TIME [epoch: 73 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09753367031282971		[learning rate: 0.00033944]
	Learning Rate: 0.000339445
	LOSS [training: 0.09753367031282971 | validation: 0.2588611388839095]
	TIME [epoch: 73 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09579143342378701		[learning rate: 0.00033785]
	Learning Rate: 0.000337845
	LOSS [training: 0.09579143342378701 | validation: 0.26799700344628574]
	TIME [epoch: 73 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10149465867296248		[learning rate: 0.00033625]
	Learning Rate: 0.000336253
	LOSS [training: 0.10149465867296248 | validation: 0.2574898406791392]
	TIME [epoch: 73 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1018330145552163		[learning rate: 0.00033467]
	Learning Rate: 0.000334669
	LOSS [training: 0.1018330145552163 | validation: 0.25263410500029637]
	TIME [epoch: 73 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10198839977256982		[learning rate: 0.00033309]
	Learning Rate: 0.000333092
	LOSS [training: 0.10198839977256982 | validation: 0.2625295877426729]
	TIME [epoch: 73 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1004658171521749		[learning rate: 0.00033152]
	Learning Rate: 0.000331522
	LOSS [training: 0.1004658171521749 | validation: 0.2617585850353465]
	TIME [epoch: 73 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10593071527424479		[learning rate: 0.00032996]
	Learning Rate: 0.00032996
	LOSS [training: 0.10593071527424479 | validation: 0.2674301569182138]
	TIME [epoch: 73 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09170753152108617		[learning rate: 0.00032841]
	Learning Rate: 0.000328405
	LOSS [training: 0.09170753152108617 | validation: 0.25808983850908623]
	TIME [epoch: 72.9 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10021754165970155		[learning rate: 0.00032686]
	Learning Rate: 0.000326858
	LOSS [training: 0.10021754165970155 | validation: 0.2544857527896301]
	TIME [epoch: 73 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10467448355003117		[learning rate: 0.00032532]
	Learning Rate: 0.000325318
	LOSS [training: 0.10467448355003117 | validation: 0.2689031526800702]
	TIME [epoch: 73 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08614584697957066		[learning rate: 0.00032378]
	Learning Rate: 0.000323785
	LOSS [training: 0.08614584697957066 | validation: 0.25898128962390166]
	TIME [epoch: 72.9 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09238961449813414		[learning rate: 0.00032226]
	Learning Rate: 0.000322259
	LOSS [training: 0.09238961449813414 | validation: 0.2677892788228735]
	TIME [epoch: 73 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09706171971568699		[learning rate: 0.00032074]
	Learning Rate: 0.000320741
	LOSS [training: 0.09706171971568699 | validation: 0.25903095203682236]
	TIME [epoch: 72.9 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09534202656369001		[learning rate: 0.00031923]
	Learning Rate: 0.000319229
	LOSS [training: 0.09534202656369001 | validation: 0.2514291128008209]
	TIME [epoch: 73 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10650774240962081		[learning rate: 0.00031772]
	Learning Rate: 0.000317725
	LOSS [training: 0.10650774240962081 | validation: 0.2495752859194801]
	TIME [epoch: 73 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09406576411751025		[learning rate: 0.00031623]
	Learning Rate: 0.000316228
	LOSS [training: 0.09406576411751025 | validation: 0.26672471013125265]
	TIME [epoch: 73 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09512326596294514		[learning rate: 0.00031474]
	Learning Rate: 0.000314738
	LOSS [training: 0.09512326596294514 | validation: 0.24925629839676827]
	TIME [epoch: 73 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0960745184502161		[learning rate: 0.00031325]
	Learning Rate: 0.000313255
	LOSS [training: 0.0960745184502161 | validation: 0.2529915069127681]
	TIME [epoch: 73 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10072127503359732		[learning rate: 0.00031178]
	Learning Rate: 0.000311778
	LOSS [training: 0.10072127503359732 | validation: 0.26464455336245035]
	TIME [epoch: 73 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10789912717407088		[learning rate: 0.00031031]
	Learning Rate: 0.000310309
	LOSS [training: 0.10789912717407088 | validation: 0.2664684475971663]
	TIME [epoch: 73 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10114181004649012		[learning rate: 0.00030885]
	Learning Rate: 0.000308847
	LOSS [training: 0.10114181004649012 | validation: 0.2549541333289539]
	TIME [epoch: 73 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10210700451050922		[learning rate: 0.00030739]
	Learning Rate: 0.000307392
	LOSS [training: 0.10210700451050922 | validation: 0.27206015128053984]
	TIME [epoch: 73 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09410846273479684		[learning rate: 0.00030594]
	Learning Rate: 0.000305943
	LOSS [training: 0.09410846273479684 | validation: 0.26995627654025467]
	TIME [epoch: 73 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10629092033677817		[learning rate: 0.0003045]
	Learning Rate: 0.000304502
	LOSS [training: 0.10629092033677817 | validation: 0.2624765100185073]
	TIME [epoch: 73 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1108277190017594		[learning rate: 0.00030307]
	Learning Rate: 0.000303067
	LOSS [training: 0.1108277190017594 | validation: 0.2639043926249724]
	TIME [epoch: 73 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12663613429922976		[learning rate: 0.00030164]
	Learning Rate: 0.000301639
	LOSS [training: 0.12663613429922976 | validation: 0.2653106665085855]
	TIME [epoch: 73 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10363416527938407		[learning rate: 0.00030022]
	Learning Rate: 0.000300217
	LOSS [training: 0.10363416527938407 | validation: 0.2756428911257423]
	TIME [epoch: 72.9 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10669760046319089		[learning rate: 0.0002988]
	Learning Rate: 0.000298803
	LOSS [training: 0.10669760046319089 | validation: 0.2709247511764176]
	TIME [epoch: 73 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0929233499556848		[learning rate: 0.00029739]
	Learning Rate: 0.000297395
	LOSS [training: 0.0929233499556848 | validation: 0.26633676295729464]
	TIME [epoch: 73 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11009312312295433		[learning rate: 0.00029599]
	Learning Rate: 0.000295993
	LOSS [training: 0.11009312312295433 | validation: 0.2806097608443172]
	TIME [epoch: 73 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0964781512403955		[learning rate: 0.0002946]
	Learning Rate: 0.000294599
	LOSS [training: 0.0964781512403955 | validation: 0.2607129903997501]
	TIME [epoch: 73 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10378805966118101		[learning rate: 0.00029321]
	Learning Rate: 0.00029321
	LOSS [training: 0.10378805966118101 | validation: 0.24542113972517338]
	TIME [epoch: 73 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v14b_20240719_004750/states/model_facs_v4_dec2b_2dpca_v14b_785.pth
	Model improved!!!
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10375416080209893		[learning rate: 0.00029183]
	Learning Rate: 0.000291829
	LOSS [training: 0.10375416080209893 | validation: 0.26476578530445877]
	TIME [epoch: 73.1 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10018045142044252		[learning rate: 0.00029045]
	Learning Rate: 0.000290454
	LOSS [training: 0.10018045142044252 | validation: 0.26665074504852226]
	TIME [epoch: 73.1 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11590289603402076		[learning rate: 0.00028909]
	Learning Rate: 0.000289085
	LOSS [training: 0.11590289603402076 | validation: 0.26218277642060167]
	TIME [epoch: 73.1 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10849314566822987		[learning rate: 0.00028772]
	Learning Rate: 0.000287723
	LOSS [training: 0.10849314566822987 | validation: 0.266392519753411]
	TIME [epoch: 73.1 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10266336488152629		[learning rate: 0.00028637]
	Learning Rate: 0.000286367
	LOSS [training: 0.10266336488152629 | validation: 0.2757578846620319]
	TIME [epoch: 73 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1146980326819545		[learning rate: 0.00028502]
	Learning Rate: 0.000285018
	LOSS [training: 0.1146980326819545 | validation: 0.25823129150652274]
	TIME [epoch: 73.1 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09499217372189263		[learning rate: 0.00028367]
	Learning Rate: 0.000283675
	LOSS [training: 0.09499217372189263 | validation: 0.2650975355065625]
	TIME [epoch: 73.1 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11273452299696651		[learning rate: 0.00028234]
	Learning Rate: 0.000282338
	LOSS [training: 0.11273452299696651 | validation: 0.269113076889691]
	TIME [epoch: 73.1 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09093304667341683		[learning rate: 0.00028101]
	Learning Rate: 0.000281008
	LOSS [training: 0.09093304667341683 | validation: 0.25919410019589356]
	TIME [epoch: 73.1 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08454181140141306		[learning rate: 0.00027968]
	Learning Rate: 0.000279683
	LOSS [training: 0.08454181140141306 | validation: 0.2588718178363436]
	TIME [epoch: 73.1 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10414484021674109		[learning rate: 0.00027837]
	Learning Rate: 0.000278366
	LOSS [training: 0.10414484021674109 | validation: 0.24640353417237654]
	TIME [epoch: 73.1 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10172902433000464		[learning rate: 0.00027705]
	Learning Rate: 0.000277054
	LOSS [training: 0.10172902433000464 | validation: 0.2591529257254089]
	TIME [epoch: 73 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09849574382868248		[learning rate: 0.00027575]
	Learning Rate: 0.000275748
	LOSS [training: 0.09849574382868248 | validation: 0.2662149557727701]
	TIME [epoch: 73 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10083463465497909		[learning rate: 0.00027445]
	Learning Rate: 0.000274449
	LOSS [training: 0.10083463465497909 | validation: 0.2832867662996878]
	TIME [epoch: 73 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10939148572182557		[learning rate: 0.00027316]
	Learning Rate: 0.000273156
	LOSS [training: 0.10939148572182557 | validation: 0.2775304989387845]
	TIME [epoch: 73.1 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08626170965055782		[learning rate: 0.00027187]
	Learning Rate: 0.000271869
	LOSS [training: 0.08626170965055782 | validation: 0.2622367682312641]
	TIME [epoch: 73 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09787951425629114		[learning rate: 0.00027059]
	Learning Rate: 0.000270587
	LOSS [training: 0.09787951425629114 | validation: 0.2676877407035489]
	TIME [epoch: 73.1 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10281021156599232		[learning rate: 0.00026931]
	Learning Rate: 0.000269312
	LOSS [training: 0.10281021156599232 | validation: 0.26957530379309014]
	TIME [epoch: 73.1 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11437517774840486		[learning rate: 0.00026804]
	Learning Rate: 0.000268043
	LOSS [training: 0.11437517774840486 | validation: 0.26526068368126876]
	TIME [epoch: 73 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11033915097583616		[learning rate: 0.00026678]
	Learning Rate: 0.00026678
	LOSS [training: 0.11033915097583616 | validation: 0.2706185692232392]
	TIME [epoch: 73 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09994564014037248		[learning rate: 0.00026552]
	Learning Rate: 0.000265523
	LOSS [training: 0.09994564014037248 | validation: 0.24502877967995496]
	TIME [epoch: 73.1 sec]
	Saving model to: out/model_training/model_facs_v4_dec2b_2dpca_v14b_20240719_004750/states/model_facs_v4_dec2b_2dpca_v14b_806.pth
	Model improved!!!
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08986202338751327		[learning rate: 0.00026427]
	Learning Rate: 0.000264272
	LOSS [training: 0.08986202338751327 | validation: 0.29522484402212557]
	TIME [epoch: 73 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1021085715759513		[learning rate: 0.00026303]
	Learning Rate: 0.000263027
	LOSS [training: 0.1021085715759513 | validation: 0.2656300530916621]
	TIME [epoch: 73.1 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1065198410625717		[learning rate: 0.00026179]
	Learning Rate: 0.000261787
	LOSS [training: 0.1065198410625717 | validation: 0.2703571781369647]
	TIME [epoch: 73 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10159511653731836		[learning rate: 0.00026055]
	Learning Rate: 0.000260554
	LOSS [training: 0.10159511653731836 | validation: 0.26873853092876493]
	TIME [epoch: 73 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09499301991262579		[learning rate: 0.00025933]
	Learning Rate: 0.000259326
	LOSS [training: 0.09499301991262579 | validation: 0.26549962133927113]
	TIME [epoch: 73 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09702982860702684		[learning rate: 0.0002581]
	Learning Rate: 0.000258104
	LOSS [training: 0.09702982860702684 | validation: 0.2570419320941867]
	TIME [epoch: 73 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0906604885946156		[learning rate: 0.00025689]
	Learning Rate: 0.000256888
	LOSS [training: 0.0906604885946156 | validation: 0.26965619399889296]
	TIME [epoch: 73 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12109960981992207		[learning rate: 0.00025568]
	Learning Rate: 0.000255677
	LOSS [training: 0.12109960981992207 | validation: 0.2693208281409907]
	TIME [epoch: 73 sec]
EPOCH 815/2000:
	Training over batches...
