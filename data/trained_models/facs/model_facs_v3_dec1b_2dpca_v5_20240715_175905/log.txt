Args:
Namespace(name='model_facs_v3_dec1b_2dpca_v5', outdir='out/model_training/model_facs_v3_dec1b_2dpca_v5', training_data='data/training_data/facs_v3/pca/dec1_fitonsubset/transition1_subset_epi_tr_ce_an_pc12/training', validation_data='data/training_data/facs_v3/pca/dec1_fitonsubset/transition1_subset_epi_tr_ce_an_pc12/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=10, batch_size=50, patience=200, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, quadratic_a=1.0, quadratic_b=1.0, ndims=2, nparams=2, nsigs=2, ncells=50, ncells_sample=50, model_do_sample=False, dt=0.005, dt_schedule='stepped', dt_schedule_bounds=[500, 1000, 1500], dt_schedule_scales=[0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=True, sigma=0.02, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', kernel='multiscale', bw_range=[0.2, 0.5, 0.9, 1.1, 1.3, 1.5, 2.0], optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 3232197115

Training model...

Saving initial model state to: out/model_training/model_facs_v3_dec1b_2dpca_v5_20240715_175905/states/model_facs_v3_dec1b_2dpca_v5_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.2673376755968804		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2673376755968804 | validation: 1.1500981223960611]
	TIME [epoch: 28.6 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v5_20240715_175905/states/model_facs_v3_dec1b_2dpca_v5_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.190114793397523		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.190114793397523 | validation: 1.0159014392083823]
	TIME [epoch: 4.75 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v5_20240715_175905/states/model_facs_v3_dec1b_2dpca_v5_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.1530154212097163		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1530154212097163 | validation: 0.9899684395329548]
	TIME [epoch: 4.71 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v5_20240715_175905/states/model_facs_v3_dec1b_2dpca_v5_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.1266241742648122		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1266241742648122 | validation: 0.9675527233308724]
	TIME [epoch: 4.72 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v5_20240715_175905/states/model_facs_v3_dec1b_2dpca_v5_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.1099210622797238		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1099210622797238 | validation: 0.9741057594031041]
	TIME [epoch: 4.74 sec]
EPOCH 6/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.119562040430046		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.119562040430046 | validation: 1.0045719521878351]
	TIME [epoch: 4.72 sec]
EPOCH 7/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.086157344824348		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.086157344824348 | validation: 0.8880341639767151]
	TIME [epoch: 4.76 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v5_20240715_175905/states/model_facs_v3_dec1b_2dpca_v5_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.0551663642116034		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0551663642116034 | validation: 0.9257208002020979]
	TIME [epoch: 4.73 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.0638912796834887		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0638912796834887 | validation: 0.9188323283460254]
	TIME [epoch: 4.81 sec]
EPOCH 10/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.9814627609468082		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9814627609468082 | validation: 0.8489011085599876]
	TIME [epoch: 4.73 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v5_20240715_175905/states/model_facs_v3_dec1b_2dpca_v5_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.9956265532416412		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9956265532416412 | validation: 0.8685524580679221]
	TIME [epoch: 4.71 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.8880776970839043		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8880776970839043 | validation: 0.8059458242946729]
	TIME [epoch: 4.71 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v5_20240715_175905/states/model_facs_v3_dec1b_2dpca_v5_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.8753140407905544		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8753140407905544 | validation: 0.7073809181239601]
	TIME [epoch: 4.71 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v5_20240715_175905/states/model_facs_v3_dec1b_2dpca_v5_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.7775684332490966		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7775684332490966 | validation: 0.763182001522229]
	TIME [epoch: 4.7 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.7929040022936382		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7929040022936382 | validation: 0.6989923686859514]
	TIME [epoch: 4.7 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v5_20240715_175905/states/model_facs_v3_dec1b_2dpca_v5_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.7816786744753511		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7816786744753511 | validation: 0.6812050986065793]
	TIME [epoch: 4.71 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v5_20240715_175905/states/model_facs_v3_dec1b_2dpca_v5_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.7261165230196142		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7261165230196142 | validation: 0.7072099687927575]
	TIME [epoch: 4.74 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.6910071460646029		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6910071460646029 | validation: 0.6001189031397635]
	TIME [epoch: 4.73 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v5_20240715_175905/states/model_facs_v3_dec1b_2dpca_v5_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.81695646822195		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.81695646822195 | validation: 0.6752003711320353]
	TIME [epoch: 4.75 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.8217745328506117		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8217745328506117 | validation: 0.6077819439796179]
	TIME [epoch: 4.75 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.7084459527483009		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7084459527483009 | validation: 0.6080211623776374]
	TIME [epoch: 4.71 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.6801556532889194		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6801556532889194 | validation: 0.6414507488686743]
	TIME [epoch: 4.71 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.6432475862029116		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6432475862029116 | validation: 0.6772301225597278]
	TIME [epoch: 4.7 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.667973422130898		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.667973422130898 | validation: 0.5763995025894186]
	TIME [epoch: 4.71 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v5_20240715_175905/states/model_facs_v3_dec1b_2dpca_v5_24.pth
	Model improved!!!
EPOCH 25/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.6297483521164622		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6297483521164622 | validation: 0.5712837446321567]
	TIME [epoch: 4.73 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v5_20240715_175905/states/model_facs_v3_dec1b_2dpca_v5_25.pth
	Model improved!!!
EPOCH 26/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.6731660330551801		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6731660330551801 | validation: 0.5528412464799487]
	TIME [epoch: 4.74 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v5_20240715_175905/states/model_facs_v3_dec1b_2dpca_v5_26.pth
	Model improved!!!
EPOCH 27/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.6495854045019805		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6495854045019805 | validation: 0.568214297733085]
	TIME [epoch: 4.72 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.6917100338518557		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6917100338518557 | validation: 0.5334994657150658]
	TIME [epoch: 4.73 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v5_20240715_175905/states/model_facs_v3_dec1b_2dpca_v5_28.pth
	Model improved!!!
EPOCH 29/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.6257239553252615		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6257239553252615 | validation: 0.54687155886268]
	TIME [epoch: 4.71 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.7141139828477688		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7141139828477688 | validation: 0.5960892078551584]
	TIME [epoch: 4.72 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.6478383369972477		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6478383369972477 | validation: 0.6660424764049322]
	TIME [epoch: 4.73 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.6399816282751937		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6399816282751937 | validation: 0.5236106207100705]
	TIME [epoch: 4.71 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v5_20240715_175905/states/model_facs_v3_dec1b_2dpca_v5_32.pth
	Model improved!!!
EPOCH 33/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.6271209116240648		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6271209116240648 | validation: 0.5698231862767015]
	TIME [epoch: 4.75 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.6006555444647405		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6006555444647405 | validation: 0.5238451948219287]
	TIME [epoch: 4.73 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.579438267632822		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.579438267632822 | validation: 0.5446331465577735]
	TIME [epoch: 4.73 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5603037602002479		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5603037602002479 | validation: 0.5224239764663366]
	TIME [epoch: 4.72 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v5_20240715_175905/states/model_facs_v3_dec1b_2dpca_v5_36.pth
	Model improved!!!
EPOCH 37/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.6472389966252524		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6472389966252524 | validation: 0.6168213791276792]
	TIME [epoch: 4.72 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.6330342127275724		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6330342127275724 | validation: 0.48196457413132504]
	TIME [epoch: 4.74 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v5_20240715_175905/states/model_facs_v3_dec1b_2dpca_v5_38.pth
	Model improved!!!
EPOCH 39/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.62012001264825		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.62012001264825 | validation: 0.5289042497460061]
	TIME [epoch: 4.72 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5980384602586216		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5980384602586216 | validation: 0.541304223768631]
	TIME [epoch: 4.71 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5532258135566513		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5532258135566513 | validation: 0.5494874768610782]
	TIME [epoch: 4.72 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5871911131221761		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5871911131221761 | validation: 0.5046412450689639]
	TIME [epoch: 4.71 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.6303286555171371		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6303286555171371 | validation: 0.4967359310871224]
	TIME [epoch: 4.73 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.52447094721327		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.52447094721327 | validation: 0.6203337559939278]
	TIME [epoch: 4.75 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5503130512017718		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5503130512017718 | validation: 0.5717285854689089]
	TIME [epoch: 4.72 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5749440267680813		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5749440267680813 | validation: 0.522803004756145]
	TIME [epoch: 4.73 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.6197283618984262		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6197283618984262 | validation: 0.5356827112114705]
	TIME [epoch: 4.74 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5218422165783907		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5218422165783907 | validation: 0.5104263394537948]
	TIME [epoch: 4.71 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5197775915388595		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5197775915388595 | validation: 0.5066363442005931]
	TIME [epoch: 4.72 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5261664989079968		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5261664989079968 | validation: 0.5537109830983671]
	TIME [epoch: 4.72 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.6823205239724954		[learning rate: 0.0099705]
	Learning Rate: 0.00997052
	LOSS [training: 0.6823205239724954 | validation: 0.5350524366200101]
	TIME [epoch: 4.72 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5064509040426882		[learning rate: 0.0099353]
	Learning Rate: 0.00993527
	LOSS [training: 0.5064509040426882 | validation: 0.5628870996311929]
	TIME [epoch: 4.73 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5074846366497597		[learning rate: 0.0099001]
	Learning Rate: 0.00990013
	LOSS [training: 0.5074846366497597 | validation: 0.46210088593202725]
	TIME [epoch: 4.7 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v5_20240715_175905/states/model_facs_v3_dec1b_2dpca_v5_53.pth
	Model improved!!!
EPOCH 54/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5775189375059823		[learning rate: 0.0098651]
	Learning Rate: 0.00986512
	LOSS [training: 0.5775189375059823 | validation: 0.5011643128759479]
	TIME [epoch: 4.73 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.523082871382475		[learning rate: 0.0098302]
	Learning Rate: 0.00983024
	LOSS [training: 0.523082871382475 | validation: 0.4928909284631498]
	TIME [epoch: 4.74 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5441434126332976		[learning rate: 0.0097955]
	Learning Rate: 0.00979548
	LOSS [training: 0.5441434126332976 | validation: 0.4860404243591053]
	TIME [epoch: 4.73 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5054033398714209		[learning rate: 0.0097608]
	Learning Rate: 0.00976084
	LOSS [training: 0.5054033398714209 | validation: 0.49973089924162817]
	TIME [epoch: 4.72 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.49335579635916166		[learning rate: 0.0097263]
	Learning Rate: 0.00972632
	LOSS [training: 0.49335579635916166 | validation: 0.44458729042059275]
	TIME [epoch: 4.72 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v5_20240715_175905/states/model_facs_v3_dec1b_2dpca_v5_58.pth
	Model improved!!!
EPOCH 59/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5839540567278939		[learning rate: 0.0096919]
	Learning Rate: 0.00969193
	LOSS [training: 0.5839540567278939 | validation: 0.5913299372337051]
	TIME [epoch: 4.7 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.6292328848687309		[learning rate: 0.0096577]
	Learning Rate: 0.00965766
	LOSS [training: 0.6292328848687309 | validation: 0.47624442468220396]
	TIME [epoch: 4.73 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5461760649507048		[learning rate: 0.0096235]
	Learning Rate: 0.00962351
	LOSS [training: 0.5461760649507048 | validation: 0.5490149752009235]
	TIME [epoch: 4.73 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.7188679111801081		[learning rate: 0.0095895]
	Learning Rate: 0.00958948
	LOSS [training: 0.7188679111801081 | validation: 0.5583694850172861]
	TIME [epoch: 4.73 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.6624062837897963		[learning rate: 0.0095556]
	Learning Rate: 0.00955557
	LOSS [training: 0.6624062837897963 | validation: 0.4827540707447455]
	TIME [epoch: 4.72 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.6721817958120267		[learning rate: 0.0095218]
	Learning Rate: 0.00952177
	LOSS [training: 0.6721817958120267 | validation: 0.499021293392624]
	TIME [epoch: 4.72 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5794722206333625		[learning rate: 0.0094881]
	Learning Rate: 0.0094881
	LOSS [training: 0.5794722206333625 | validation: 0.5696327273721485]
	TIME [epoch: 4.72 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5895345430633334		[learning rate: 0.0094546]
	Learning Rate: 0.00945455
	LOSS [training: 0.5895345430633334 | validation: 0.4289077967362046]
	TIME [epoch: 4.73 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v5_20240715_175905/states/model_facs_v3_dec1b_2dpca_v5_66.pth
	Model improved!!!
EPOCH 67/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5499324742301062		[learning rate: 0.0094211]
	Learning Rate: 0.00942112
	LOSS [training: 0.5499324742301062 | validation: 0.5798461458503084]
	TIME [epoch: 4.74 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5374130780200338		[learning rate: 0.0093878]
	Learning Rate: 0.00938781
	LOSS [training: 0.5374130780200338 | validation: 0.4807245620936634]
	TIME [epoch: 4.73 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5969664501508914		[learning rate: 0.0093546]
	Learning Rate: 0.00935461
	LOSS [training: 0.5969664501508914 | validation: 0.5353075645631993]
	TIME [epoch: 4.72 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5348192896744349		[learning rate: 0.0093215]
	Learning Rate: 0.00932153
	LOSS [training: 0.5348192896744349 | validation: 0.5981443812302376]
	TIME [epoch: 4.73 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5256160802006377		[learning rate: 0.0092886]
	Learning Rate: 0.00928857
	LOSS [training: 0.5256160802006377 | validation: 0.46718996176117694]
	TIME [epoch: 4.72 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5441576013114507		[learning rate: 0.0092557]
	Learning Rate: 0.00925572
	LOSS [training: 0.5441576013114507 | validation: 0.4447236089545387]
	TIME [epoch: 4.72 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5015190172524455		[learning rate: 0.009223]
	Learning Rate: 0.00922299
	LOSS [training: 0.5015190172524455 | validation: 0.4967620250290727]
	TIME [epoch: 4.71 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4668634195960033		[learning rate: 0.0091904]
	Learning Rate: 0.00919038
	LOSS [training: 0.4668634195960033 | validation: 0.43944004534674974]
	TIME [epoch: 4.72 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5389601964455836		[learning rate: 0.0091579]
	Learning Rate: 0.00915788
	LOSS [training: 0.5389601964455836 | validation: 0.46351755744029804]
	TIME [epoch: 4.71 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.46723166711294456		[learning rate: 0.0091255]
	Learning Rate: 0.00912549
	LOSS [training: 0.46723166711294456 | validation: 0.6950466704906731]
	TIME [epoch: 4.71 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5346421321051466		[learning rate: 0.0090932]
	Learning Rate: 0.00909323
	LOSS [training: 0.5346421321051466 | validation: 0.4691813399871565]
	TIME [epoch: 4.72 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4534989843219064		[learning rate: 0.0090611]
	Learning Rate: 0.00906107
	LOSS [training: 0.4534989843219064 | validation: 0.4238533946366038]
	TIME [epoch: 4.71 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v5_20240715_175905/states/model_facs_v3_dec1b_2dpca_v5_78.pth
	Model improved!!!
EPOCH 79/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5590357753740255		[learning rate: 0.009029]
	Learning Rate: 0.00902903
	LOSS [training: 0.5590357753740255 | validation: 0.5031600704063914]
	TIME [epoch: 4.71 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5355497163663914		[learning rate: 0.0089971]
	Learning Rate: 0.0089971
	LOSS [training: 0.5355497163663914 | validation: 0.5816587730374572]
	TIME [epoch: 4.72 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.49462941465588445		[learning rate: 0.0089653]
	Learning Rate: 0.00896528
	LOSS [training: 0.49462941465588445 | validation: 0.44826387553249436]
	TIME [epoch: 4.73 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5277338452323587		[learning rate: 0.0089336]
	Learning Rate: 0.00893358
	LOSS [training: 0.5277338452323587 | validation: 0.48790406223387545]
	TIME [epoch: 4.71 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4657309649577919		[learning rate: 0.008902]
	Learning Rate: 0.00890199
	LOSS [training: 0.4657309649577919 | validation: 0.42750916697550634]
	TIME [epoch: 4.7 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4882419751484501		[learning rate: 0.0088705]
	Learning Rate: 0.00887051
	LOSS [training: 0.4882419751484501 | validation: 0.4878814233209285]
	TIME [epoch: 4.73 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5177786155588253		[learning rate: 0.0088391]
	Learning Rate: 0.00883914
	LOSS [training: 0.5177786155588253 | validation: 0.4855158350676742]
	TIME [epoch: 4.71 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4740948008154042		[learning rate: 0.0088079]
	Learning Rate: 0.00880789
	LOSS [training: 0.4740948008154042 | validation: 0.44260613254845926]
	TIME [epoch: 4.71 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.516852091420905		[learning rate: 0.0087767]
	Learning Rate: 0.00877674
	LOSS [training: 0.516852091420905 | validation: 0.42566460336950396]
	TIME [epoch: 4.72 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4654869592956737		[learning rate: 0.0087457]
	Learning Rate: 0.00874571
	LOSS [training: 0.4654869592956737 | validation: 0.42847513585188046]
	TIME [epoch: 4.71 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.46697000046202675		[learning rate: 0.0087148]
	Learning Rate: 0.00871478
	LOSS [training: 0.46697000046202675 | validation: 0.4346083705334398]
	TIME [epoch: 4.73 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4585515222801668		[learning rate: 0.008684]
	Learning Rate: 0.00868396
	LOSS [training: 0.4585515222801668 | validation: 0.41943747159449635]
	TIME [epoch: 4.71 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v5_20240715_175905/states/model_facs_v3_dec1b_2dpca_v5_90.pth
	Model improved!!!
EPOCH 91/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.48091920496465534		[learning rate: 0.0086533]
	Learning Rate: 0.00865326
	LOSS [training: 0.48091920496465534 | validation: 0.4544750527048803]
	TIME [epoch: 4.72 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4411743072929461		[learning rate: 0.0086227]
	Learning Rate: 0.00862265
	LOSS [training: 0.4411743072929461 | validation: 0.4355600460919665]
	TIME [epoch: 4.73 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4709339886949277		[learning rate: 0.0085922]
	Learning Rate: 0.00859216
	LOSS [training: 0.4709339886949277 | validation: 0.45708233153635797]
	TIME [epoch: 4.72 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4344983754033083		[learning rate: 0.0085618]
	Learning Rate: 0.00856178
	LOSS [training: 0.4344983754033083 | validation: 0.45255206530162295]
	TIME [epoch: 4.75 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4498181888650477		[learning rate: 0.0085315]
	Learning Rate: 0.0085315
	LOSS [training: 0.4498181888650477 | validation: 0.46716346180436136]
	TIME [epoch: 4.74 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.48894836489496657		[learning rate: 0.0085013]
	Learning Rate: 0.00850134
	LOSS [training: 0.48894836489496657 | validation: 0.4623309008271688]
	TIME [epoch: 4.72 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.43934580668889955		[learning rate: 0.0084713]
	Learning Rate: 0.00847127
	LOSS [training: 0.43934580668889955 | validation: 0.4962129563704325]
	TIME [epoch: 4.71 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4933616541690559		[learning rate: 0.0084413]
	Learning Rate: 0.00844132
	LOSS [training: 0.4933616541690559 | validation: 0.459354736096601]
	TIME [epoch: 4.73 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4451501494840413		[learning rate: 0.0084115]
	Learning Rate: 0.00841147
	LOSS [training: 0.4451501494840413 | validation: 0.49277697615349714]
	TIME [epoch: 4.72 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4296628722326523		[learning rate: 0.0083817]
	Learning Rate: 0.00838172
	LOSS [training: 0.4296628722326523 | validation: 0.4164015950760288]
	TIME [epoch: 4.72 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v5_20240715_175905/states/model_facs_v3_dec1b_2dpca_v5_100.pth
	Model improved!!!
EPOCH 101/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.45137051095536057		[learning rate: 0.0083521]
	Learning Rate: 0.00835208
	LOSS [training: 0.45137051095536057 | validation: 0.4153813470279431]
	TIME [epoch: 4.72 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v5_20240715_175905/states/model_facs_v3_dec1b_2dpca_v5_101.pth
	Model improved!!!
EPOCH 102/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4602507048663042		[learning rate: 0.0083225]
	Learning Rate: 0.00832255
	LOSS [training: 0.4602507048663042 | validation: 0.4490128136311015]
	TIME [epoch: 4.71 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.43371279971194854		[learning rate: 0.0082931]
	Learning Rate: 0.00829312
	LOSS [training: 0.43371279971194854 | validation: 0.43407831646083694]
	TIME [epoch: 4.7 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.44604934377202893		[learning rate: 0.0082638]
	Learning Rate: 0.00826379
	LOSS [training: 0.44604934377202893 | validation: 0.4337984654198583]
	TIME [epoch: 4.71 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4797240125468582		[learning rate: 0.0082346]
	Learning Rate: 0.00823457
	LOSS [training: 0.4797240125468582 | validation: 0.41559656796050926]
	TIME [epoch: 4.69 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.509286830651447		[learning rate: 0.0082055]
	Learning Rate: 0.00820545
	LOSS [training: 0.509286830651447 | validation: 0.49914682593566545]
	TIME [epoch: 4.72 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4347395372339164		[learning rate: 0.0081764]
	Learning Rate: 0.00817644
	LOSS [training: 0.4347395372339164 | validation: 0.41160971344213104]
	TIME [epoch: 4.7 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v5_20240715_175905/states/model_facs_v3_dec1b_2dpca_v5_107.pth
	Model improved!!!
EPOCH 108/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.46942967491046966		[learning rate: 0.0081475]
	Learning Rate: 0.00814752
	LOSS [training: 0.46942967491046966 | validation: 0.3884860616827129]
	TIME [epoch: 4.72 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v5_20240715_175905/states/model_facs_v3_dec1b_2dpca_v5_108.pth
	Model improved!!!
EPOCH 109/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.40207217394874		[learning rate: 0.0081187]
	Learning Rate: 0.00811871
	LOSS [training: 0.40207217394874 | validation: 0.42840310679323634]
	TIME [epoch: 4.71 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.42966609898872404		[learning rate: 0.00809]
	Learning Rate: 0.00809
	LOSS [training: 0.42966609898872404 | validation: 0.43565946794355714]
	TIME [epoch: 4.72 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.43900356613111535		[learning rate: 0.0080614]
	Learning Rate: 0.0080614
	LOSS [training: 0.43900356613111535 | validation: 0.4204020821861919]
	TIME [epoch: 4.72 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4287666791532032		[learning rate: 0.0080329]
	Learning Rate: 0.00803289
	LOSS [training: 0.4287666791532032 | validation: 0.4486383673917208]
	TIME [epoch: 4.7 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4845416128830204		[learning rate: 0.0080045]
	Learning Rate: 0.00800448
	LOSS [training: 0.4845416128830204 | validation: 0.40481265355859486]
	TIME [epoch: 4.72 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4420482780489599		[learning rate: 0.0079762]
	Learning Rate: 0.00797618
	LOSS [training: 0.4420482780489599 | validation: 0.46508786356179765]
	TIME [epoch: 4.71 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.45127142021661176		[learning rate: 0.007948]
	Learning Rate: 0.00794797
	LOSS [training: 0.45127142021661176 | validation: 0.43411044625652995]
	TIME [epoch: 4.71 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4487382190394353		[learning rate: 0.0079199]
	Learning Rate: 0.00791987
	LOSS [training: 0.4487382190394353 | validation: 0.41345514093940067]
	TIME [epoch: 4.71 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.42787241346222366		[learning rate: 0.0078919]
	Learning Rate: 0.00789186
	LOSS [training: 0.42787241346222366 | validation: 0.469189050565039]
	TIME [epoch: 4.73 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4761336034261087		[learning rate: 0.007864]
	Learning Rate: 0.00786395
	LOSS [training: 0.4761336034261087 | validation: 0.42940224962519674]
	TIME [epoch: 4.7 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.41104277815660084		[learning rate: 0.0078361]
	Learning Rate: 0.00783615
	LOSS [training: 0.41104277815660084 | validation: 0.4390769842463581]
	TIME [epoch: 4.7 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4186008193565795		[learning rate: 0.0078084]
	Learning Rate: 0.00780844
	LOSS [training: 0.4186008193565795 | validation: 0.42378955094167753]
	TIME [epoch: 4.71 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.39684544666767047		[learning rate: 0.0077808]
	Learning Rate: 0.00778083
	LOSS [training: 0.39684544666767047 | validation: 0.40521448834596496]
	TIME [epoch: 4.72 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3997276929147315		[learning rate: 0.0077533]
	Learning Rate: 0.00775331
	LOSS [training: 0.3997276929147315 | validation: 0.5480416593924665]
	TIME [epoch: 4.72 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.41680345622065396		[learning rate: 0.0077259]
	Learning Rate: 0.00772589
	LOSS [training: 0.41680345622065396 | validation: 0.4295545822026325]
	TIME [epoch: 4.71 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4062680451018061		[learning rate: 0.0076986]
	Learning Rate: 0.00769857
	LOSS [training: 0.4062680451018061 | validation: 0.4029581534852407]
	TIME [epoch: 4.7 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.38321745210994673		[learning rate: 0.0076714]
	Learning Rate: 0.00767135
	LOSS [training: 0.38321745210994673 | validation: 0.39954525690685755]
	TIME [epoch: 4.7 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3933501302805047		[learning rate: 0.0076442]
	Learning Rate: 0.00764422
	LOSS [training: 0.3933501302805047 | validation: 0.43040947625313625]
	TIME [epoch: 4.7 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4587702201933421		[learning rate: 0.0076172]
	Learning Rate: 0.00761719
	LOSS [training: 0.4587702201933421 | validation: 0.43542171268623786]
	TIME [epoch: 4.72 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.39131442576313175		[learning rate: 0.0075903]
	Learning Rate: 0.00759025
	LOSS [training: 0.39131442576313175 | validation: 0.38883826289269463]
	TIME [epoch: 4.71 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3950656535041202		[learning rate: 0.0075634]
	Learning Rate: 0.00756341
	LOSS [training: 0.3950656535041202 | validation: 0.39741550011316873]
	TIME [epoch: 4.71 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.43799253391964327		[learning rate: 0.0075367]
	Learning Rate: 0.00753667
	LOSS [training: 0.43799253391964327 | validation: 0.45548420629643793]
	TIME [epoch: 4.69 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.39720930539044347		[learning rate: 0.00751]
	Learning Rate: 0.00751002
	LOSS [training: 0.39720930539044347 | validation: 0.37937533254861944]
	TIME [epoch: 4.71 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v5_20240715_175905/states/model_facs_v3_dec1b_2dpca_v5_131.pth
	Model improved!!!
EPOCH 132/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.39429243076951553		[learning rate: 0.0074835]
	Learning Rate: 0.00748346
	LOSS [training: 0.39429243076951553 | validation: 0.3834877218165752]
	TIME [epoch: 4.73 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3932138782078424		[learning rate: 0.007457]
	Learning Rate: 0.007457
	LOSS [training: 0.3932138782078424 | validation: 0.4252290117374186]
	TIME [epoch: 4.73 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.41665130387449345		[learning rate: 0.0074306]
	Learning Rate: 0.00743063
	LOSS [training: 0.41665130387449345 | validation: 0.38948137869010324]
	TIME [epoch: 4.73 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.38612657699885666		[learning rate: 0.0074044]
	Learning Rate: 0.00740435
	LOSS [training: 0.38612657699885666 | validation: 0.3829008779087771]
	TIME [epoch: 4.74 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4100655946905896		[learning rate: 0.0073782]
	Learning Rate: 0.00737817
	LOSS [training: 0.4100655946905896 | validation: 0.43552330107767173]
	TIME [epoch: 4.74 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.46039999802576875		[learning rate: 0.0073521]
	Learning Rate: 0.00735208
	LOSS [training: 0.46039999802576875 | validation: 0.37849951402126963]
	TIME [epoch: 4.73 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v5_20240715_175905/states/model_facs_v3_dec1b_2dpca_v5_137.pth
	Model improved!!!
EPOCH 138/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3644503826515481		[learning rate: 0.0073261]
	Learning Rate: 0.00732608
	LOSS [training: 0.3644503826515481 | validation: 0.40961323670821825]
	TIME [epoch: 4.75 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.35919389532129964		[learning rate: 0.0073002]
	Learning Rate: 0.00730018
	LOSS [training: 0.35919389532129964 | validation: 0.3704467391023112]
	TIME [epoch: 4.75 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v5_20240715_175905/states/model_facs_v3_dec1b_2dpca_v5_139.pth
	Model improved!!!
EPOCH 140/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4301845611912453		[learning rate: 0.0072744]
	Learning Rate: 0.00727436
	LOSS [training: 0.4301845611912453 | validation: 0.38359204461491647]
	TIME [epoch: 4.73 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.36246956315713114		[learning rate: 0.0072486]
	Learning Rate: 0.00724864
	LOSS [training: 0.36246956315713114 | validation: 0.4451108508918374]
	TIME [epoch: 4.74 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.41830566579961753		[learning rate: 0.007223]
	Learning Rate: 0.007223
	LOSS [training: 0.41830566579961753 | validation: 0.47687093175510864]
	TIME [epoch: 4.74 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4617302290717719		[learning rate: 0.0071975]
	Learning Rate: 0.00719746
	LOSS [training: 0.4617302290717719 | validation: 0.42345306828996615]
	TIME [epoch: 4.74 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.43313737779885747		[learning rate: 0.007172]
	Learning Rate: 0.00717201
	LOSS [training: 0.43313737779885747 | validation: 0.41198476808284334]
	TIME [epoch: 4.74 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.36702676969947995		[learning rate: 0.0071467]
	Learning Rate: 0.00714665
	LOSS [training: 0.36702676969947995 | validation: 0.39179760627067917]
	TIME [epoch: 4.75 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.37891106366238597		[learning rate: 0.0071214]
	Learning Rate: 0.00712138
	LOSS [training: 0.37891106366238597 | validation: 0.36925719938760126]
	TIME [epoch: 4.74 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v5_20240715_175905/states/model_facs_v3_dec1b_2dpca_v5_146.pth
	Model improved!!!
EPOCH 147/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.40031245744202826		[learning rate: 0.0070962]
	Learning Rate: 0.0070962
	LOSS [training: 0.40031245744202826 | validation: 0.3809681734753916]
	TIME [epoch: 4.72 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3606870831968072		[learning rate: 0.0070711]
	Learning Rate: 0.0070711
	LOSS [training: 0.3606870831968072 | validation: 0.4240220211460806]
	TIME [epoch: 4.73 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.46662088021297515		[learning rate: 0.0070461]
	Learning Rate: 0.0070461
	LOSS [training: 0.46662088021297515 | validation: 0.45248910593296837]
	TIME [epoch: 4.73 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4336755262522279		[learning rate: 0.0070212]
	Learning Rate: 0.00702118
	LOSS [training: 0.4336755262522279 | validation: 0.4156248197024267]
	TIME [epoch: 4.73 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4010114005045448		[learning rate: 0.0069964]
	Learning Rate: 0.00699635
	LOSS [training: 0.4010114005045448 | validation: 0.39286103753356766]
	TIME [epoch: 4.73 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3817753178586624		[learning rate: 0.0069716]
	Learning Rate: 0.00697161
	LOSS [training: 0.3817753178586624 | validation: 0.42544448300473325]
	TIME [epoch: 4.73 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.35597322276592197		[learning rate: 0.006947]
	Learning Rate: 0.00694696
	LOSS [training: 0.35597322276592197 | validation: 0.41435390691828583]
	TIME [epoch: 4.73 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.39086891794624856		[learning rate: 0.0069224]
	Learning Rate: 0.00692239
	LOSS [training: 0.39086891794624856 | validation: 0.4426603212644412]
	TIME [epoch: 4.72 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.36115833470208414		[learning rate: 0.0068979]
	Learning Rate: 0.00689792
	LOSS [training: 0.36115833470208414 | validation: 0.42406784780164886]
	TIME [epoch: 4.73 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.36488961969031664		[learning rate: 0.0068735]
	Learning Rate: 0.00687352
	LOSS [training: 0.36488961969031664 | validation: 0.3863889588268242]
	TIME [epoch: 4.74 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.38280839213164336		[learning rate: 0.0068492]
	Learning Rate: 0.00684922
	LOSS [training: 0.38280839213164336 | validation: 0.40852817539205455]
	TIME [epoch: 4.72 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3504592246370352		[learning rate: 0.006825]
	Learning Rate: 0.006825
	LOSS [training: 0.3504592246370352 | validation: 0.39144563451643444]
	TIME [epoch: 4.72 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.36185159568806274		[learning rate: 0.0068009]
	Learning Rate: 0.00680086
	LOSS [training: 0.36185159568806274 | validation: 0.3781198628733743]
	TIME [epoch: 4.72 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3922571410765762		[learning rate: 0.0067768]
	Learning Rate: 0.00677681
	LOSS [training: 0.3922571410765762 | validation: 0.38414876755106164]
	TIME [epoch: 4.72 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3782902645613351		[learning rate: 0.0067529]
	Learning Rate: 0.00675285
	LOSS [training: 0.3782902645613351 | validation: 0.39192713837924287]
	TIME [epoch: 4.71 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4030047197675642		[learning rate: 0.006729]
	Learning Rate: 0.00672897
	LOSS [training: 0.4030047197675642 | validation: 0.6415434754790026]
	TIME [epoch: 4.72 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4752028023301013		[learning rate: 0.0067052]
	Learning Rate: 0.00670518
	LOSS [training: 0.4752028023301013 | validation: 0.4039243536605519]
	TIME [epoch: 4.73 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3627005104952456		[learning rate: 0.0066815]
	Learning Rate: 0.00668147
	LOSS [training: 0.3627005104952456 | validation: 0.3908285708720563]
	TIME [epoch: 4.72 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3587203055275731		[learning rate: 0.0066578]
	Learning Rate: 0.00665784
	LOSS [training: 0.3587203055275731 | validation: 0.3944896083871357]
	TIME [epoch: 4.72 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.38345499312200554		[learning rate: 0.0066343]
	Learning Rate: 0.0066343
	LOSS [training: 0.38345499312200554 | validation: 0.37935153253945003]
	TIME [epoch: 4.71 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.33969886971189517		[learning rate: 0.0066108]
	Learning Rate: 0.00661084
	LOSS [training: 0.33969886971189517 | validation: 0.35374960471683325]
	TIME [epoch: 4.72 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v5_20240715_175905/states/model_facs_v3_dec1b_2dpca_v5_167.pth
	Model improved!!!
EPOCH 168/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3394258790184513		[learning rate: 0.0065875]
	Learning Rate: 0.00658746
	LOSS [training: 0.3394258790184513 | validation: 0.3537625377822521]
	TIME [epoch: 4.72 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3531431020325311		[learning rate: 0.0065642]
	Learning Rate: 0.00656416
	LOSS [training: 0.3531431020325311 | validation: 0.35840485187930815]
	TIME [epoch: 4.74 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.33673789099525614		[learning rate: 0.006541]
	Learning Rate: 0.00654095
	LOSS [training: 0.33673789099525614 | validation: 0.3805793425557754]
	TIME [epoch: 4.73 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.38919074372430945		[learning rate: 0.0065178]
	Learning Rate: 0.00651782
	LOSS [training: 0.38919074372430945 | validation: 0.37964542019282094]
	TIME [epoch: 4.74 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3718480654609681		[learning rate: 0.0064948]
	Learning Rate: 0.00649477
	LOSS [training: 0.3718480654609681 | validation: 0.4048422158309851]
	TIME [epoch: 4.72 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.33886230732356853		[learning rate: 0.0064718]
	Learning Rate: 0.00647181
	LOSS [training: 0.33886230732356853 | validation: 0.3698703629504053]
	TIME [epoch: 4.72 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3404907426410145		[learning rate: 0.0064489]
	Learning Rate: 0.00644892
	LOSS [training: 0.3404907426410145 | validation: 0.3583937237365292]
	TIME [epoch: 4.72 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.34982176411371063		[learning rate: 0.0064261]
	Learning Rate: 0.00642612
	LOSS [training: 0.34982176411371063 | validation: 0.4212703317273537]
	TIME [epoch: 4.73 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.36071703407291794		[learning rate: 0.0064034]
	Learning Rate: 0.00640339
	LOSS [training: 0.36071703407291794 | validation: 0.38452197255178044]
	TIME [epoch: 4.74 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.361088542089018		[learning rate: 0.0063808]
	Learning Rate: 0.00638075
	LOSS [training: 0.361088542089018 | validation: 0.4088922386527584]
	TIME [epoch: 4.73 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.36445236915709245		[learning rate: 0.0063582]
	Learning Rate: 0.00635819
	LOSS [training: 0.36445236915709245 | validation: 0.49010298127994234]
	TIME [epoch: 4.73 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.43585621195449115		[learning rate: 0.0063357]
	Learning Rate: 0.0063357
	LOSS [training: 0.43585621195449115 | validation: 0.3673550787872878]
	TIME [epoch: 4.73 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3398426811538355		[learning rate: 0.0063133]
	Learning Rate: 0.0063133
	LOSS [training: 0.3398426811538355 | validation: 0.3708819600108403]
	TIME [epoch: 4.74 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.32200187468542457		[learning rate: 0.006291]
	Learning Rate: 0.00629097
	LOSS [training: 0.32200187468542457 | validation: 0.3357410366401289]
	TIME [epoch: 4.73 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v5_20240715_175905/states/model_facs_v3_dec1b_2dpca_v5_181.pth
	Model improved!!!
EPOCH 182/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3158639195007769		[learning rate: 0.0062687]
	Learning Rate: 0.00626873
	LOSS [training: 0.3158639195007769 | validation: 0.3523800673142458]
	TIME [epoch: 4.72 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3647954839551429		[learning rate: 0.0062466]
	Learning Rate: 0.00624656
	LOSS [training: 0.3647954839551429 | validation: 0.3370202638944489]
	TIME [epoch: 4.73 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3405157467053137		[learning rate: 0.0062245]
	Learning Rate: 0.00622447
	LOSS [training: 0.3405157467053137 | validation: 0.3604442403348769]
	TIME [epoch: 4.72 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.32831959365018193		[learning rate: 0.0062025]
	Learning Rate: 0.00620246
	LOSS [training: 0.32831959365018193 | validation: 0.4120153758044157]
	TIME [epoch: 4.72 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3511099479913519		[learning rate: 0.0061805]
	Learning Rate: 0.00618053
	LOSS [training: 0.3511099479913519 | validation: 0.36431689783076404]
	TIME [epoch: 4.71 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3420038710812046		[learning rate: 0.0061587]
	Learning Rate: 0.00615867
	LOSS [training: 0.3420038710812046 | validation: 0.34375185065013]
	TIME [epoch: 4.72 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3400126251833682		[learning rate: 0.0061369]
	Learning Rate: 0.00613689
	LOSS [training: 0.3400126251833682 | validation: 0.4046308594639119]
	TIME [epoch: 4.71 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3534857849032429		[learning rate: 0.0061152]
	Learning Rate: 0.00611519
	LOSS [training: 0.3534857849032429 | validation: 0.34117003780995897]
	TIME [epoch: 4.72 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3346801817351006		[learning rate: 0.0060936]
	Learning Rate: 0.00609357
	LOSS [training: 0.3346801817351006 | validation: 0.36225003000355305]
	TIME [epoch: 4.73 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.33970650496691546		[learning rate: 0.006072]
	Learning Rate: 0.00607202
	LOSS [training: 0.33970650496691546 | validation: 0.36367056632532885]
	TIME [epoch: 4.73 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3495417547946867		[learning rate: 0.0060505]
	Learning Rate: 0.00605055
	LOSS [training: 0.3495417547946867 | validation: 0.3724891099795231]
	TIME [epoch: 4.71 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.35991552221103157		[learning rate: 0.0060292]
	Learning Rate: 0.00602915
	LOSS [training: 0.35991552221103157 | validation: 0.37114939419869863]
	TIME [epoch: 4.72 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.36085391884864726		[learning rate: 0.0060078]
	Learning Rate: 0.00600783
	LOSS [training: 0.36085391884864726 | validation: 0.3653061029663731]
	TIME [epoch: 4.72 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3570577621812849		[learning rate: 0.0059866]
	Learning Rate: 0.00598659
	LOSS [training: 0.3570577621812849 | validation: 0.3999811057994002]
	TIME [epoch: 4.72 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.356752593194172		[learning rate: 0.0059654]
	Learning Rate: 0.00596542
	LOSS [training: 0.356752593194172 | validation: 0.3487102024841845]
	TIME [epoch: 4.73 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3321626063583714		[learning rate: 0.0059443]
	Learning Rate: 0.00594433
	LOSS [training: 0.3321626063583714 | validation: 0.4102973610073374]
	TIME [epoch: 4.73 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.401860884597619		[learning rate: 0.0059233]
	Learning Rate: 0.0059233
	LOSS [training: 0.401860884597619 | validation: 0.4109392723130053]
	TIME [epoch: 4.73 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.34527208982803254		[learning rate: 0.0059024]
	Learning Rate: 0.00590236
	LOSS [training: 0.34527208982803254 | validation: 0.36486684623191057]
	TIME [epoch: 4.73 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.38386111015287394		[learning rate: 0.0058815]
	Learning Rate: 0.00588149
	LOSS [training: 0.38386111015287394 | validation: 0.41330917252701277]
	TIME [epoch: 4.72 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3308376463188489		[learning rate: 0.0058607]
	Learning Rate: 0.00586069
	LOSS [training: 0.3308376463188489 | validation: 0.3653559208765557]
	TIME [epoch: 4.74 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.32369467741713226		[learning rate: 0.00584]
	Learning Rate: 0.00583996
	LOSS [training: 0.32369467741713226 | validation: 0.3756644082005597]
	TIME [epoch: 4.74 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3580471755405299		[learning rate: 0.0058193]
	Learning Rate: 0.00581931
	LOSS [training: 0.3580471755405299 | validation: 0.36602947282065385]
	TIME [epoch: 4.74 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.34926583235903386		[learning rate: 0.0057987]
	Learning Rate: 0.00579874
	LOSS [training: 0.34926583235903386 | validation: 0.343400935953753]
	TIME [epoch: 4.74 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3668115356414389		[learning rate: 0.0057782]
	Learning Rate: 0.00577823
	LOSS [training: 0.3668115356414389 | validation: 0.33507336726723863]
	TIME [epoch: 4.75 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v5_20240715_175905/states/model_facs_v3_dec1b_2dpca_v5_205.pth
	Model improved!!!
EPOCH 206/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.31894266286356787		[learning rate: 0.0057578]
	Learning Rate: 0.0057578
	LOSS [training: 0.31894266286356787 | validation: 0.3570325120967963]
	TIME [epoch: 4.74 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.32184671202322307		[learning rate: 0.0057374]
	Learning Rate: 0.00573744
	LOSS [training: 0.32184671202322307 | validation: 0.32950788983331447]
	TIME [epoch: 4.73 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v5_20240715_175905/states/model_facs_v3_dec1b_2dpca_v5_207.pth
	Model improved!!!
EPOCH 208/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.34191057474781666		[learning rate: 0.0057171]
	Learning Rate: 0.00571715
	LOSS [training: 0.34191057474781666 | validation: 0.32231774194631746]
	TIME [epoch: 4.76 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v5_20240715_175905/states/model_facs_v3_dec1b_2dpca_v5_208.pth
	Model improved!!!
EPOCH 209/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3576456656521055		[learning rate: 0.0056969]
	Learning Rate: 0.00569693
	LOSS [training: 0.3576456656521055 | validation: 0.4360085856971508]
	TIME [epoch: 4.73 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3519937854264026		[learning rate: 0.0056768]
	Learning Rate: 0.00567679
	LOSS [training: 0.3519937854264026 | validation: 0.3417797205101948]
	TIME [epoch: 4.74 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.340319746504256		[learning rate: 0.0056567]
	Learning Rate: 0.00565671
	LOSS [training: 0.340319746504256 | validation: 0.36181648346381073]
	TIME [epoch: 4.73 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3322725429279761		[learning rate: 0.0056367]
	Learning Rate: 0.00563671
	LOSS [training: 0.3322725429279761 | validation: 0.3411208566647007]
	TIME [epoch: 4.74 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.30362806659941916		[learning rate: 0.0056168]
	Learning Rate: 0.00561678
	LOSS [training: 0.30362806659941916 | validation: 0.34020479158083206]
	TIME [epoch: 4.74 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.34268843231101664		[learning rate: 0.0055969]
	Learning Rate: 0.00559691
	LOSS [training: 0.34268843231101664 | validation: 0.37216012894622574]
	TIME [epoch: 4.74 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.33521330113488457		[learning rate: 0.0055771]
	Learning Rate: 0.00557712
	LOSS [training: 0.33521330113488457 | validation: 0.33325634634526263]
	TIME [epoch: 4.74 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.30138627332971346		[learning rate: 0.0055574]
	Learning Rate: 0.0055574
	LOSS [training: 0.30138627332971346 | validation: 0.3421818295140669]
	TIME [epoch: 4.73 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.33802815620845333		[learning rate: 0.0055378]
	Learning Rate: 0.00553775
	LOSS [training: 0.33802815620845333 | validation: 0.3489373608868268]
	TIME [epoch: 4.74 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4201986791536547		[learning rate: 0.0055182]
	Learning Rate: 0.00551817
	LOSS [training: 0.4201986791536547 | validation: 0.3715554496663577]
	TIME [epoch: 4.73 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3717669999842304		[learning rate: 0.0054987]
	Learning Rate: 0.00549865
	LOSS [training: 0.3717669999842304 | validation: 0.37030231684077564]
	TIME [epoch: 4.74 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3236342761212325		[learning rate: 0.0054792]
	Learning Rate: 0.00547921
	LOSS [training: 0.3236342761212325 | validation: 0.33738255286391877]
	TIME [epoch: 4.73 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.32385868286904135		[learning rate: 0.0054598]
	Learning Rate: 0.00545983
	LOSS [training: 0.32385868286904135 | validation: 0.33325066622737143]
	TIME [epoch: 4.74 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.36409485093866084		[learning rate: 0.0054405]
	Learning Rate: 0.00544053
	LOSS [training: 0.36409485093866084 | validation: 0.3719507961454954]
	TIME [epoch: 4.73 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.32466857672413074		[learning rate: 0.0054213]
	Learning Rate: 0.00542129
	LOSS [training: 0.32466857672413074 | validation: 0.351014312172302]
	TIME [epoch: 4.73 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3360616363897198		[learning rate: 0.0054021]
	Learning Rate: 0.00540212
	LOSS [training: 0.3360616363897198 | validation: 0.3529375063595571]
	TIME [epoch: 4.73 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.34051770929247577		[learning rate: 0.005383]
	Learning Rate: 0.00538302
	LOSS [training: 0.34051770929247577 | validation: 0.3460853220031179]
	TIME [epoch: 4.73 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.34071118901436886		[learning rate: 0.005364]
	Learning Rate: 0.00536398
	LOSS [training: 0.34071118901436886 | validation: 0.3564168615197355]
	TIME [epoch: 4.72 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3346141381587297		[learning rate: 0.005345]
	Learning Rate: 0.00534501
	LOSS [training: 0.3346141381587297 | validation: 0.35296165956399533]
	TIME [epoch: 4.74 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3039396945279606		[learning rate: 0.0053261]
	Learning Rate: 0.00532611
	LOSS [training: 0.3039396945279606 | validation: 0.3299247741773492]
	TIME [epoch: 4.73 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3430445537394042		[learning rate: 0.0053073]
	Learning Rate: 0.00530728
	LOSS [training: 0.3430445537394042 | validation: 0.36225553931202653]
	TIME [epoch: 4.73 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3433334280826544		[learning rate: 0.0052885]
	Learning Rate: 0.00528851
	LOSS [training: 0.3433334280826544 | validation: 0.3214380329381455]
	TIME [epoch: 4.73 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v5_20240715_175905/states/model_facs_v3_dec1b_2dpca_v5_230.pth
	Model improved!!!
EPOCH 231/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3258275198410871		[learning rate: 0.0052698]
	Learning Rate: 0.00526981
	LOSS [training: 0.3258275198410871 | validation: 0.3916018495543328]
	TIME [epoch: 4.72 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3602213866684489		[learning rate: 0.0052512]
	Learning Rate: 0.00525117
	LOSS [training: 0.3602213866684489 | validation: 0.3960234012480888]
	TIME [epoch: 4.72 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.34229248853468563		[learning rate: 0.0052326]
	Learning Rate: 0.0052326
	LOSS [training: 0.34229248853468563 | validation: 0.3878653912969886]
	TIME [epoch: 4.73 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.33055651037458456		[learning rate: 0.0052141]
	Learning Rate: 0.0052141
	LOSS [training: 0.33055651037458456 | validation: 0.317357958152394]
	TIME [epoch: 4.74 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v5_20240715_175905/states/model_facs_v3_dec1b_2dpca_v5_234.pth
	Model improved!!!
EPOCH 235/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.30927518431642487		[learning rate: 0.0051957]
	Learning Rate: 0.00519566
	LOSS [training: 0.30927518431642487 | validation: 0.3410727895324824]
	TIME [epoch: 4.71 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3221498604110442		[learning rate: 0.0051773]
	Learning Rate: 0.00517729
	LOSS [training: 0.3221498604110442 | validation: 0.3431902220392515]
	TIME [epoch: 4.71 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3221927453671457		[learning rate: 0.005159]
	Learning Rate: 0.00515898
	LOSS [training: 0.3221927453671457 | validation: 0.31587904501850783]
	TIME [epoch: 4.71 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v5_20240715_175905/states/model_facs_v3_dec1b_2dpca_v5_237.pth
	Model improved!!!
EPOCH 238/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.30630616022445784		[learning rate: 0.0051407]
	Learning Rate: 0.00514074
	LOSS [training: 0.30630616022445784 | validation: 0.32054130278483495]
	TIME [epoch: 4.74 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2940971636433261		[learning rate: 0.0051226]
	Learning Rate: 0.00512256
	LOSS [training: 0.2940971636433261 | validation: 0.33232019176597705]
	TIME [epoch: 4.73 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.37697941998700263		[learning rate: 0.0051044]
	Learning Rate: 0.00510445
	LOSS [training: 0.37697941998700263 | validation: 0.3210504585569488]
	TIME [epoch: 4.73 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3181018587061098		[learning rate: 0.0050864]
	Learning Rate: 0.0050864
	LOSS [training: 0.3181018587061098 | validation: 0.33960969420663734]
	TIME [epoch: 4.74 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.33429716849331825		[learning rate: 0.0050684]
	Learning Rate: 0.00506841
	LOSS [training: 0.33429716849331825 | validation: 0.4522735897768627]
	TIME [epoch: 4.72 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.34740557905207164		[learning rate: 0.0050505]
	Learning Rate: 0.00505049
	LOSS [training: 0.34740557905207164 | validation: 0.35650492958930224]
	TIME [epoch: 4.73 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3248424567914369		[learning rate: 0.0050326]
	Learning Rate: 0.00503263
	LOSS [training: 0.3248424567914369 | validation: 0.3696968124019852]
	TIME [epoch: 4.73 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3189540925096707		[learning rate: 0.0050148]
	Learning Rate: 0.00501483
	LOSS [training: 0.3189540925096707 | validation: 0.33349120457169]
	TIME [epoch: 4.72 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.31703235195939444		[learning rate: 0.0049971]
	Learning Rate: 0.0049971
	LOSS [training: 0.31703235195939444 | validation: 0.32742799622967556]
	TIME [epoch: 4.71 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.43671289606886976		[learning rate: 0.0049794]
	Learning Rate: 0.00497943
	LOSS [training: 0.43671289606886976 | validation: 0.6685136698209172]
	TIME [epoch: 4.73 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.6862130538029684		[learning rate: 0.0049618]
	Learning Rate: 0.00496182
	LOSS [training: 0.6862130538029684 | validation: 0.8900170596539028]
	TIME [epoch: 4.72 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.9662915727760675		[learning rate: 0.0049443]
	Learning Rate: 0.00494427
	LOSS [training: 0.9662915727760675 | validation: 0.9649759256095489]
	TIME [epoch: 4.73 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.058035445595245		[learning rate: 0.0049268]
	Learning Rate: 0.00492679
	LOSS [training: 1.058035445595245 | validation: 0.8856564445447791]
	TIME [epoch: 4.72 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.1367767763082577		[learning rate: 0.0049094]
	Learning Rate: 0.00490937
	LOSS [training: 1.1367767763082577 | validation: 0.9964392986295248]
	TIME [epoch: 4.74 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.3070831509283936		[learning rate: 0.004892]
	Learning Rate: 0.00489201
	LOSS [training: 1.3070831509283936 | validation: 1.359074134108262]
	TIME [epoch: 4.72 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.716361750690285		[learning rate: 0.0048747]
	Learning Rate: 0.00487471
	LOSS [training: 1.716361750690285 | validation: 1.4619606768762576]
	TIME [epoch: 4.73 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.6741367677745718		[learning rate: 0.0048575]
	Learning Rate: 0.00485747
	LOSS [training: 1.6741367677745718 | validation: 1.36050706848008]
	TIME [epoch: 4.72 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.5353175221986473		[learning rate: 0.0048403]
	Learning Rate: 0.00484029
	LOSS [training: 1.5353175221986473 | validation: 1.4511205175433652]
	TIME [epoch: 4.72 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.9792779729895342		[learning rate: 0.0048232]
	Learning Rate: 0.00482318
	LOSS [training: 1.9792779729895342 | validation: 2.30061922713193]
	TIME [epoch: 4.72 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 6/6] avg loss: 2.779474543324916		[learning rate: 0.0048061]
	Learning Rate: 0.00480612
	LOSS [training: 2.779474543324916 | validation: 2.0496279755561946]
	TIME [epoch: 4.73 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 6/6] avg loss: 2.000324670925304		[learning rate: 0.0047891]
	Learning Rate: 0.00478913
	LOSS [training: 2.000324670925304 | validation: 1.612670864453517]
	TIME [epoch: 4.73 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.6693264376604329		[learning rate: 0.0047722]
	Learning Rate: 0.00477219
	LOSS [training: 1.6693264376604329 | validation: 1.697691243050714]
	TIME [epoch: 4.72 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.708694165642463		[learning rate: 0.0047553]
	Learning Rate: 0.00475532
	LOSS [training: 1.708694165642463 | validation: 1.4016244198936743]
	TIME [epoch: 4.72 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.544679602953518		[learning rate: 0.0047385]
	Learning Rate: 0.0047385
	LOSS [training: 1.544679602953518 | validation: 1.64170618964672]
	TIME [epoch: 4.73 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 6/6] avg loss: 2.710628211388053		[learning rate: 0.0047217]
	Learning Rate: 0.00472175
	LOSS [training: 2.710628211388053 | validation: 3.7811335835163717]
	TIME [epoch: 4.72 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 6/6] avg loss: 2.205498229545482		[learning rate: 0.004705]
	Learning Rate: 0.00470505
	LOSS [training: 2.205498229545482 | validation: 1.3964989034932838]
	TIME [epoch: 4.73 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.9633798385362498		[learning rate: 0.0046884]
	Learning Rate: 0.00468841
	LOSS [training: 1.9633798385362498 | validation: 2.4921852609459036]
	TIME [epoch: 4.72 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 6/6] avg loss: 2.250391039453078		[learning rate: 0.0046718]
	Learning Rate: 0.00467183
	LOSS [training: 2.250391039453078 | validation: 2.2533338424382867]
	TIME [epoch: 4.73 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 6/6] avg loss: 2.5928177946423236		[learning rate: 0.0046553]
	Learning Rate: 0.00465531
	LOSS [training: 2.5928177946423236 | validation: 2.7716598378922424]
	TIME [epoch: 4.73 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 6/6] avg loss: 2.440122130924595		[learning rate: 0.0046388]
	Learning Rate: 0.00463885
	LOSS [training: 2.440122130924595 | validation: 1.9640332839681975]
	TIME [epoch: 4.72 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.6703776338430816		[learning rate: 0.0046224]
	Learning Rate: 0.00462245
	LOSS [training: 1.6703776338430816 | validation: 0.9870416719861426]
	TIME [epoch: 4.72 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.0552631530447112		[learning rate: 0.0046061]
	Learning Rate: 0.0046061
	LOSS [training: 1.0552631530447112 | validation: 0.669106762696819]
	TIME [epoch: 4.71 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.8476397197646454		[learning rate: 0.0045898]
	Learning Rate: 0.00458981
	LOSS [training: 0.8476397197646454 | validation: 0.5861865387408786]
	TIME [epoch: 4.72 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.7971037578375776		[learning rate: 0.0045736]
	Learning Rate: 0.00457358
	LOSS [training: 0.7971037578375776 | validation: 0.5575326422716185]
	TIME [epoch: 4.77 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.7880756446746203		[learning rate: 0.0045574]
	Learning Rate: 0.00455741
	LOSS [training: 0.7880756446746203 | validation: 0.5505399506779043]
	TIME [epoch: 4.73 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.7444988967385001		[learning rate: 0.0045413]
	Learning Rate: 0.00454129
	LOSS [training: 0.7444988967385001 | validation: 0.5556292768149341]
	TIME [epoch: 4.72 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.726443188112746		[learning rate: 0.0045252]
	Learning Rate: 0.00452523
	LOSS [training: 0.726443188112746 | validation: 0.5259221936387234]
	TIME [epoch: 4.72 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.6993082768378608		[learning rate: 0.0045092]
	Learning Rate: 0.00450923
	LOSS [training: 0.6993082768378608 | validation: 0.7347398563784348]
	TIME [epoch: 4.72 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.776734784619958		[learning rate: 0.0044933]
	Learning Rate: 0.00449329
	LOSS [training: 0.776734784619958 | validation: 0.5951416817078229]
	TIME [epoch: 4.73 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.9100661403064434		[learning rate: 0.0044774]
	Learning Rate: 0.0044774
	LOSS [training: 1.9100661403064434 | validation: 3.3597090506787963]
	TIME [epoch: 4.71 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 6/6] avg loss: 3.4216302815281234		[learning rate: 0.0044616]
	Learning Rate: 0.00446156
	LOSS [training: 3.4216302815281234 | validation: 2.761925938514149]
	TIME [epoch: 4.72 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 6/6] avg loss: 2.568485027537205		[learning rate: 0.0044458]
	Learning Rate: 0.00444579
	LOSS [training: 2.568485027537205 | validation: 1.9298425432325863]
	TIME [epoch: 4.72 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 6/6] avg loss: 2.040273211640199		[learning rate: 0.0044301]
	Learning Rate: 0.00443007
	LOSS [training: 2.040273211640199 | validation: 1.4781004111110758]
	TIME [epoch: 4.73 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.1550773258938778		[learning rate: 0.0044144]
	Learning Rate: 0.0044144
	LOSS [training: 1.1550773258938778 | validation: 0.7640622829483554]
	TIME [epoch: 4.72 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.761839033604588		[learning rate: 0.0043988]
	Learning Rate: 0.00439879
	LOSS [training: 0.761839033604588 | validation: 0.7216357443872512]
	TIME [epoch: 4.73 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.7386150264296035		[learning rate: 0.0043832]
	Learning Rate: 0.00438324
	LOSS [training: 0.7386150264296035 | validation: 0.5584051936216272]
	TIME [epoch: 4.72 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.7196967507174928		[learning rate: 0.0043677]
	Learning Rate: 0.00436774
	LOSS [training: 0.7196967507174928 | validation: 0.6817820667985995]
	TIME [epoch: 4.72 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.8213621780848652		[learning rate: 0.0043523]
	Learning Rate: 0.00435229
	LOSS [training: 0.8213621780848652 | validation: 0.574953545592529]
	TIME [epoch: 4.73 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.6526790000706899		[learning rate: 0.0043369]
	Learning Rate: 0.0043369
	LOSS [training: 0.6526790000706899 | validation: 0.5529831972746315]
	TIME [epoch: 4.74 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.6325910053498074		[learning rate: 0.0043216]
	Learning Rate: 0.00432156
	LOSS [training: 0.6325910053498074 | validation: 0.5355356776927186]
	TIME [epoch: 4.72 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.569098143700843		[learning rate: 0.0043063]
	Learning Rate: 0.00430628
	LOSS [training: 0.569098143700843 | validation: 0.5205813353439974]
	TIME [epoch: 4.72 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5868275639121066		[learning rate: 0.0042911]
	Learning Rate: 0.00429106
	LOSS [training: 0.5868275639121066 | validation: 0.5368694365430506]
	TIME [epoch: 4.72 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5736462318114519		[learning rate: 0.0042759]
	Learning Rate: 0.00427588
	LOSS [training: 0.5736462318114519 | validation: 0.5094581487046173]
	TIME [epoch: 4.71 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.6726834634780308		[learning rate: 0.0042608]
	Learning Rate: 0.00426076
	LOSS [training: 0.6726834634780308 | validation: 0.6385944818346477]
	TIME [epoch: 4.72 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.6669036742161182		[learning rate: 0.0042457]
	Learning Rate: 0.00424569
	LOSS [training: 0.6669036742161182 | validation: 0.5520266488254381]
	TIME [epoch: 4.73 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5416309848532431		[learning rate: 0.0042307]
	Learning Rate: 0.00423068
	LOSS [training: 0.5416309848532431 | validation: 0.514625393564039]
	TIME [epoch: 4.73 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5440212655280292		[learning rate: 0.0042157]
	Learning Rate: 0.00421572
	LOSS [training: 0.5440212655280292 | validation: 0.5509877228373016]
	TIME [epoch: 4.72 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5620994055128353		[learning rate: 0.0042008]
	Learning Rate: 0.00420081
	LOSS [training: 0.5620994055128353 | validation: 0.5575104406774216]
	TIME [epoch: 4.73 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5224698849012301		[learning rate: 0.004186]
	Learning Rate: 0.00418596
	LOSS [training: 0.5224698849012301 | validation: 0.5169898546223299]
	TIME [epoch: 4.72 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5098573316874797		[learning rate: 0.0041712]
	Learning Rate: 0.00417116
	LOSS [training: 0.5098573316874797 | validation: 0.5076948580897109]
	TIME [epoch: 4.72 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5395948169281674		[learning rate: 0.0041564]
	Learning Rate: 0.00415641
	LOSS [training: 0.5395948169281674 | validation: 0.5974392405208009]
	TIME [epoch: 4.72 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5232130431461047		[learning rate: 0.0041417]
	Learning Rate: 0.00414171
	LOSS [training: 0.5232130431461047 | validation: 0.48991626158348167]
	TIME [epoch: 4.73 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5087951665554913		[learning rate: 0.0041271]
	Learning Rate: 0.00412706
	LOSS [training: 0.5087951665554913 | validation: 0.4664731366564099]
	TIME [epoch: 4.72 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.48694632999814397		[learning rate: 0.0041125]
	Learning Rate: 0.00411247
	LOSS [training: 0.48694632999814397 | validation: 0.4704127710596767]
	TIME [epoch: 4.75 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4594716652763828		[learning rate: 0.0040979]
	Learning Rate: 0.00409793
	LOSS [training: 0.4594716652763828 | validation: 0.47070964070756605]
	TIME [epoch: 4.75 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4538672990977612		[learning rate: 0.0040834]
	Learning Rate: 0.00408344
	LOSS [training: 0.4538672990977612 | validation: 0.5571241996096628]
	TIME [epoch: 4.73 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.6811680931720914		[learning rate: 0.004069]
	Learning Rate: 0.004069
	LOSS [training: 0.6811680931720914 | validation: 0.5001412290951825]
	TIME [epoch: 4.73 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.47685351052350494		[learning rate: 0.0040546]
	Learning Rate: 0.00405461
	LOSS [training: 0.47685351052350494 | validation: 0.489251852188927]
	TIME [epoch: 4.74 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4898795397541653		[learning rate: 0.0040403]
	Learning Rate: 0.00404027
	LOSS [training: 0.4898795397541653 | validation: 0.4573762113904506]
	TIME [epoch: 4.75 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4489137642033832		[learning rate: 0.004026]
	Learning Rate: 0.00402598
	LOSS [training: 0.4489137642033832 | validation: 0.4409253331557248]
	TIME [epoch: 4.74 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.43996490435031205		[learning rate: 0.0040117]
	Learning Rate: 0.00401175
	LOSS [training: 0.43996490435031205 | validation: 0.45081729573520263]
	TIME [epoch: 4.73 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.44726350129670384		[learning rate: 0.0039976]
	Learning Rate: 0.00399756
	LOSS [training: 0.44726350129670384 | validation: 0.460905601942987]
	TIME [epoch: 4.73 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.42322920495978794		[learning rate: 0.0039834]
	Learning Rate: 0.00398342
	LOSS [training: 0.42322920495978794 | validation: 0.42497196677888993]
	TIME [epoch: 4.73 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4506923418151268		[learning rate: 0.0039693]
	Learning Rate: 0.00396934
	LOSS [training: 0.4506923418151268 | validation: 0.44359131273872093]
	TIME [epoch: 4.74 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.43891130613212864		[learning rate: 0.0039553]
	Learning Rate: 0.0039553
	LOSS [training: 0.43891130613212864 | validation: 0.4101717238015283]
	TIME [epoch: 4.74 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4394368539289688		[learning rate: 0.0039413]
	Learning Rate: 0.00394131
	LOSS [training: 0.4394368539289688 | validation: 0.4842310009259526]
	TIME [epoch: 4.74 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.46037182800562787		[learning rate: 0.0039274]
	Learning Rate: 0.00392738
	LOSS [training: 0.46037182800562787 | validation: 0.4458186952453646]
	TIME [epoch: 4.72 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4107068956014812		[learning rate: 0.0039135]
	Learning Rate: 0.00391349
	LOSS [training: 0.4107068956014812 | validation: 0.4314621173385181]
	TIME [epoch: 4.73 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4107915553701916		[learning rate: 0.0038997]
	Learning Rate: 0.00389965
	LOSS [training: 0.4107915553701916 | validation: 0.4328273890998965]
	TIME [epoch: 4.73 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.41422228160783275		[learning rate: 0.0038859]
	Learning Rate: 0.00388586
	LOSS [training: 0.41422228160783275 | validation: 0.5288157716989402]
	TIME [epoch: 4.73 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.6011244102458647		[learning rate: 0.0038721]
	Learning Rate: 0.00387212
	LOSS [training: 0.6011244102458647 | validation: 0.4710370149070025]
	TIME [epoch: 4.73 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4452562977072407		[learning rate: 0.0038584]
	Learning Rate: 0.00385843
	LOSS [training: 0.4452562977072407 | validation: 0.4520046227044624]
	TIME [epoch: 4.74 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4228502802950442		[learning rate: 0.0038448]
	Learning Rate: 0.00384478
	LOSS [training: 0.4228502802950442 | validation: 0.44170453459960884]
	TIME [epoch: 4.73 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4192869872457645		[learning rate: 0.0038312]
	Learning Rate: 0.00383119
	LOSS [training: 0.4192869872457645 | validation: 0.4167856884258122]
	TIME [epoch: 4.74 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4025641156146306		[learning rate: 0.0038176]
	Learning Rate: 0.00381764
	LOSS [training: 0.4025641156146306 | validation: 0.40515648481730365]
	TIME [epoch: 4.73 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3915678709372088		[learning rate: 0.0038041]
	Learning Rate: 0.00380414
	LOSS [training: 0.3915678709372088 | validation: 0.4564381319344356]
	TIME [epoch: 4.74 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.38412461710320805		[learning rate: 0.0037907]
	Learning Rate: 0.00379069
	LOSS [training: 0.38412461710320805 | validation: 0.4125015291668303]
	TIME [epoch: 4.73 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4022380442310669		[learning rate: 0.0037773]
	Learning Rate: 0.00377728
	LOSS [training: 0.4022380442310669 | validation: 0.4312469214461262]
	TIME [epoch: 4.74 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.394685380688303		[learning rate: 0.0037639]
	Learning Rate: 0.00376393
	LOSS [training: 0.394685380688303 | validation: 0.3927695663776434]
	TIME [epoch: 4.74 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.38806680702794977		[learning rate: 0.0037506]
	Learning Rate: 0.00375062
	LOSS [training: 0.38806680702794977 | validation: 0.49548310963016934]
	TIME [epoch: 4.74 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.41496093411528895		[learning rate: 0.0037374]
	Learning Rate: 0.00373735
	LOSS [training: 0.41496093411528895 | validation: 0.38276188083857826]
	TIME [epoch: 4.73 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.37484906805735685		[learning rate: 0.0037241]
	Learning Rate: 0.00372414
	LOSS [training: 0.37484906805735685 | validation: 0.387737980574249]
	TIME [epoch: 4.73 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.37791000876979847		[learning rate: 0.003711]
	Learning Rate: 0.00371097
	LOSS [training: 0.37791000876979847 | validation: 0.45915080399127]
	TIME [epoch: 4.72 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.37408352533028344		[learning rate: 0.0036978]
	Learning Rate: 0.00369785
	LOSS [training: 0.37408352533028344 | validation: 0.43800050290455494]
	TIME [epoch: 4.72 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3933152799962986		[learning rate: 0.0036848]
	Learning Rate: 0.00368477
	LOSS [training: 0.3933152799962986 | validation: 0.4046727453855035]
	TIME [epoch: 4.72 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.6033531726667148		[learning rate: 0.0036717]
	Learning Rate: 0.00367174
	LOSS [training: 0.6033531726667148 | validation: 0.611965545110362]
	TIME [epoch: 4.74 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.49814655856233553		[learning rate: 0.0036588]
	Learning Rate: 0.00365875
	LOSS [training: 0.49814655856233553 | validation: 0.4468146843566787]
	TIME [epoch: 4.73 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.424741736577873		[learning rate: 0.0036458]
	Learning Rate: 0.00364582
	LOSS [training: 0.424741736577873 | validation: 0.458750343445441]
	TIME [epoch: 4.73 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4052399069063017		[learning rate: 0.0036329]
	Learning Rate: 0.00363292
	LOSS [training: 0.4052399069063017 | validation: 0.4096193481249637]
	TIME [epoch: 4.72 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.6689293712522836		[learning rate: 0.0036201]
	Learning Rate: 0.00362008
	LOSS [training: 0.6689293712522836 | validation: 0.9413401443718146]
	TIME [epoch: 4.72 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.275118580989392		[learning rate: 0.0036073]
	Learning Rate: 0.00360728
	LOSS [training: 1.275118580989392 | validation: 1.2659294889545893]
	TIME [epoch: 4.72 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.4059070028277254		[learning rate: 0.0035945]
	Learning Rate: 0.00359452
	LOSS [training: 1.4059070028277254 | validation: 1.5606832222994365]
	TIME [epoch: 4.73 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 6/6] avg loss: 2.1438391485708244		[learning rate: 0.0035818]
	Learning Rate: 0.00358181
	LOSS [training: 2.1438391485708244 | validation: 2.6127002685283904]
	TIME [epoch: 4.74 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 6/6] avg loss: 2.439140360186204		[learning rate: 0.0035691]
	Learning Rate: 0.00356914
	LOSS [training: 2.439140360186204 | validation: 1.9433776759839247]
	TIME [epoch: 4.73 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 6/6] avg loss: 2.362247608941684		[learning rate: 0.0035565]
	Learning Rate: 0.00355652
	LOSS [training: 2.362247608941684 | validation: 2.118217326966843]
	TIME [epoch: 4.73 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 6/6] avg loss: 2.169055164933091		[learning rate: 0.0035439]
	Learning Rate: 0.00354395
	LOSS [training: 2.169055164933091 | validation: 2.031690823498676]
	TIME [epoch: 4.72 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 6/6] avg loss: 2.1840177814357395		[learning rate: 0.0035314]
	Learning Rate: 0.00353141
	LOSS [training: 2.1840177814357395 | validation: 2.2414190820329254]
	TIME [epoch: 4.72 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 6/6] avg loss: 2.3073583410567875		[learning rate: 0.0035189]
	Learning Rate: 0.00351893
	LOSS [training: 2.3073583410567875 | validation: 1.728428225541429]
	TIME [epoch: 4.73 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.5226680158232961		[learning rate: 0.0035065]
	Learning Rate: 0.00350648
	LOSS [training: 1.5226680158232961 | validation: 1.2982781819878018]
	TIME [epoch: 4.72 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.2620104866079496		[learning rate: 0.0034941]
	Learning Rate: 0.00349408
	LOSS [training: 1.2620104866079496 | validation: 1.1422507666004011]
	TIME [epoch: 4.73 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.1857605669149407		[learning rate: 0.0034817]
	Learning Rate: 0.00348173
	LOSS [training: 1.1857605669149407 | validation: 1.3224393607709535]
	TIME [epoch: 4.71 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.339648524635203		[learning rate: 0.0034694]
	Learning Rate: 0.00346942
	LOSS [training: 1.339648524635203 | validation: 1.5585832583580692]
	TIME [epoch: 4.71 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.7689927266469152		[learning rate: 0.0034571]
	Learning Rate: 0.00345715
	LOSS [training: 1.7689927266469152 | validation: 1.7789562163542603]
	TIME [epoch: 4.71 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.90390942360803		[learning rate: 0.0034449]
	Learning Rate: 0.00344492
	LOSS [training: 1.90390942360803 | validation: 1.8864841525457294]
	TIME [epoch: 4.72 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.8463286980615214		[learning rate: 0.0034327]
	Learning Rate: 0.00343274
	LOSS [training: 1.8463286980615214 | validation: 1.862051022684599]
	TIME [epoch: 4.71 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 6/6] avg loss: 2.1203308999363566		[learning rate: 0.0034206]
	Learning Rate: 0.0034206
	LOSS [training: 2.1203308999363566 | validation: 2.4709749106312078]
	TIME [epoch: 4.72 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 6/6] avg loss: 2.2837315955128576		[learning rate: 0.0034085]
	Learning Rate: 0.00340851
	LOSS [training: 2.2837315955128576 | validation: 2.4409773404226596]
	TIME [epoch: 4.71 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 6/6] avg loss: 2.783560893439907		[learning rate: 0.0033965]
	Learning Rate: 0.00339645
	LOSS [training: 2.783560893439907 | validation: 3.1463322821855755]
	TIME [epoch: 4.71 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 6/6] avg loss: 3.3771228678812393		[learning rate: 0.0033844]
	Learning Rate: 0.00338444
	LOSS [training: 3.3771228678812393 | validation: 3.8702331818186053]
	TIME [epoch: 4.71 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 6/6] avg loss: 4.054747390356471		[learning rate: 0.0033725]
	Learning Rate: 0.00337247
	LOSS [training: 4.054747390356471 | validation: 4.37863342465605]
	TIME [epoch: 4.72 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 6/6] avg loss: 3.798205647034024		[learning rate: 0.0033605]
	Learning Rate: 0.00336055
	LOSS [training: 3.798205647034024 | validation: 3.10687030971586]
	TIME [epoch: 4.71 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 6/6] avg loss: 3.132020539200024		[learning rate: 0.0033487]
	Learning Rate: 0.00334867
	LOSS [training: 3.132020539200024 | validation: 2.805376853782934]
	TIME [epoch: 4.71 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 6/6] avg loss: 2.8084424404523016		[learning rate: 0.0033368]
	Learning Rate: 0.00333682
	LOSS [training: 2.8084424404523016 | validation: 3.445000202619314]
	TIME [epoch: 4.73 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 6/6] avg loss: 3.659261436821236		[learning rate: 0.003325]
	Learning Rate: 0.00332502
	LOSS [training: 3.659261436821236 | validation: 4.007195654246333]
	TIME [epoch: 4.73 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 6/6] avg loss: 3.88085099515491		[learning rate: 0.0033133]
	Learning Rate: 0.00331327
	LOSS [training: 3.88085099515491 | validation: 4.07031858960593]
	TIME [epoch: 4.71 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 6/6] avg loss: 3.9976271871547304		[learning rate: 0.0033016]
	Learning Rate: 0.00330155
	LOSS [training: 3.9976271871547304 | validation: 4.238923441658553]
	TIME [epoch: 4.72 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 6/6] avg loss: 4.289791919604899		[learning rate: 0.0032899]
	Learning Rate: 0.00328988
	LOSS [training: 4.289791919604899 | validation: 4.0946985526314865]
	TIME [epoch: 4.7 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 6/6] avg loss: 3.2651465622902633		[learning rate: 0.0032782]
	Learning Rate: 0.00327824
	LOSS [training: 3.2651465622902633 | validation: 2.207161814828195]
	TIME [epoch: 4.7 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.9738716697215406		[learning rate: 0.0032666]
	Learning Rate: 0.00326665
	LOSS [training: 1.9738716697215406 | validation: 1.571296091267326]
	TIME [epoch: 4.72 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.3930070672597061		[learning rate: 0.0032551]
	Learning Rate: 0.0032551
	LOSS [training: 1.3930070672597061 | validation: 1.0917885250159076]
	TIME [epoch: 4.71 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.0125298002668022		[learning rate: 0.0032436]
	Learning Rate: 0.00324359
	LOSS [training: 1.0125298002668022 | validation: 0.9221706233655634]
	TIME [epoch: 4.71 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.8475081173878892		[learning rate: 0.0032321]
	Learning Rate: 0.00323212
	LOSS [training: 0.8475081173878892 | validation: 0.8319911546065883]
	TIME [epoch: 4.71 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.7500852066306695		[learning rate: 0.0032207]
	Learning Rate: 0.00322069
	LOSS [training: 0.7500852066306695 | validation: 0.7453190703834769]
	TIME [epoch: 4.72 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.6287884948754413		[learning rate: 0.0032093]
	Learning Rate: 0.0032093
	LOSS [training: 0.6287884948754413 | validation: 0.7201709178948915]
	TIME [epoch: 4.71 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.7490022956408794		[learning rate: 0.003198]
	Learning Rate: 0.00319795
	LOSS [training: 0.7490022956408794 | validation: 0.9897486909042745]
	TIME [epoch: 4.71 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.8078672466403715		[learning rate: 0.0031866]
	Learning Rate: 0.00318664
	LOSS [training: 0.8078672466403715 | validation: 0.7091186609334071]
	TIME [epoch: 4.71 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.629057007292225		[learning rate: 0.0031754]
	Learning Rate: 0.00317537
	LOSS [training: 0.629057007292225 | validation: 0.6611879150781199]
	TIME [epoch: 4.73 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.6409363226783299		[learning rate: 0.0031641]
	Learning Rate: 0.00316415
	LOSS [training: 0.6409363226783299 | validation: 0.703618197891366]
	TIME [epoch: 4.7 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.6054449143634395		[learning rate: 0.003153]
	Learning Rate: 0.00315296
	LOSS [training: 0.6054449143634395 | validation: 0.6301421134192154]
	TIME [epoch: 4.72 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5522172033003185		[learning rate: 0.0031418]
	Learning Rate: 0.00314181
	LOSS [training: 0.5522172033003185 | validation: 0.6284771107313104]
	TIME [epoch: 4.7 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5468734861873498		[learning rate: 0.0031307]
	Learning Rate: 0.0031307
	LOSS [training: 0.5468734861873498 | validation: 0.6288971938950991]
	TIME [epoch: 4.73 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5307432737677249		[learning rate: 0.0031196]
	Learning Rate: 0.00311963
	LOSS [training: 0.5307432737677249 | validation: 0.5833539261261284]
	TIME [epoch: 4.7 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5219042751647645		[learning rate: 0.0031086]
	Learning Rate: 0.00310859
	LOSS [training: 0.5219042751647645 | validation: 0.5632583033792167]
	TIME [epoch: 4.72 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5944015228289053		[learning rate: 0.0030976]
	Learning Rate: 0.0030976
	LOSS [training: 0.5944015228289053 | validation: 0.7517239662280424]
	TIME [epoch: 4.74 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.7098307308336197		[learning rate: 0.0030866]
	Learning Rate: 0.00308665
	LOSS [training: 0.7098307308336197 | validation: 0.6627268794366438]
	TIME [epoch: 4.7 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.6002625579844679		[learning rate: 0.0030757]
	Learning Rate: 0.00307573
	LOSS [training: 0.6002625579844679 | validation: 0.5705360021583494]
	TIME [epoch: 4.72 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.548806181621924		[learning rate: 0.0030649]
	Learning Rate: 0.00306486
	LOSS [training: 0.548806181621924 | validation: 0.5450616851938231]
	TIME [epoch: 4.71 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5196625452745527		[learning rate: 0.003054]
	Learning Rate: 0.00305402
	LOSS [training: 0.5196625452745527 | validation: 0.549938602578009]
	TIME [epoch: 4.7 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.548163238757768		[learning rate: 0.0030432]
	Learning Rate: 0.00304322
	LOSS [training: 0.548163238757768 | validation: 0.5301123547457802]
	TIME [epoch: 4.7 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.476132949470887		[learning rate: 0.0030325]
	Learning Rate: 0.00303246
	LOSS [training: 0.476132949470887 | validation: 0.5336844967261933]
	TIME [epoch: 4.71 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.465872930277656		[learning rate: 0.0030217]
	Learning Rate: 0.00302174
	LOSS [training: 0.465872930277656 | validation: 0.47696089380616946]
	TIME [epoch: 4.71 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4850875179114697		[learning rate: 0.003011]
	Learning Rate: 0.00301105
	LOSS [training: 0.4850875179114697 | validation: 0.4970181505244762]
	TIME [epoch: 4.71 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4607134011084924		[learning rate: 0.0030004]
	Learning Rate: 0.0030004
	LOSS [training: 0.4607134011084924 | validation: 0.47980454313963444]
	TIME [epoch: 4.71 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.44407997089858897		[learning rate: 0.0029898]
	Learning Rate: 0.00298979
	LOSS [training: 0.44407997089858897 | validation: 0.4657472536483812]
	TIME [epoch: 4.74 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.48835776422319466		[learning rate: 0.0029792]
	Learning Rate: 0.00297922
	LOSS [training: 0.48835776422319466 | validation: 0.47281665047601484]
	TIME [epoch: 4.7 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.501510682950249		[learning rate: 0.0029687]
	Learning Rate: 0.00296869
	LOSS [training: 0.501510682950249 | validation: 0.46038427520373537]
	TIME [epoch: 4.71 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.49817287305038627		[learning rate: 0.0029582]
	Learning Rate: 0.00295819
	LOSS [training: 0.49817287305038627 | validation: 0.46906685447951235]
	TIME [epoch: 4.71 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.47517314796707844		[learning rate: 0.0029477]
	Learning Rate: 0.00294773
	LOSS [training: 0.47517314796707844 | validation: 0.4742351762010567]
	TIME [epoch: 4.73 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4282009320283859		[learning rate: 0.0029373]
	Learning Rate: 0.0029373
	LOSS [training: 0.4282009320283859 | validation: 0.42826585698096487]
	TIME [epoch: 4.72 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5304491718547509		[learning rate: 0.0029269]
	Learning Rate: 0.00292692
	LOSS [training: 0.5304491718547509 | validation: 0.4913277471013302]
	TIME [epoch: 4.71 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.45431902320733747		[learning rate: 0.0029166]
	Learning Rate: 0.00291657
	LOSS [training: 0.45431902320733747 | validation: 0.46555790128859076]
	TIME [epoch: 4.71 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4418463446129786		[learning rate: 0.0029063]
	Learning Rate: 0.00290625
	LOSS [training: 0.4418463446129786 | validation: 0.41633902371276293]
	TIME [epoch: 4.7 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4308928743209106		[learning rate: 0.002896]
	Learning Rate: 0.00289598
	LOSS [training: 0.4308928743209106 | validation: 0.4392835565888415]
	TIME [epoch: 4.73 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.42472871279665214		[learning rate: 0.0028857]
	Learning Rate: 0.00288573
	LOSS [training: 0.42472871279665214 | validation: 0.4461571756313186]
	TIME [epoch: 4.72 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3890994166851634		[learning rate: 0.0028755]
	Learning Rate: 0.00287553
	LOSS [training: 0.3890994166851634 | validation: 0.40111434502520893]
	TIME [epoch: 4.72 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3848443191492081		[learning rate: 0.0028654]
	Learning Rate: 0.00286536
	LOSS [training: 0.3848443191492081 | validation: 0.4344868560552354]
	TIME [epoch: 4.73 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.42071467197464374		[learning rate: 0.0028552]
	Learning Rate: 0.00285523
	LOSS [training: 0.42071467197464374 | validation: 0.4727779613408133]
	TIME [epoch: 4.73 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4125922813114		[learning rate: 0.0028451]
	Learning Rate: 0.00284513
	LOSS [training: 0.4125922813114 | validation: 0.4184747600103006]
	TIME [epoch: 4.73 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4408466265967618		[learning rate: 0.0028351]
	Learning Rate: 0.00283507
	LOSS [training: 0.4408466265967618 | validation: 0.5280781726521202]
	TIME [epoch: 4.73 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5625830311874634		[learning rate: 0.002825]
	Learning Rate: 0.00282505
	LOSS [training: 0.5625830311874634 | validation: 0.458242197652473]
	TIME [epoch: 4.73 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4374490387697545		[learning rate: 0.0028151]
	Learning Rate: 0.00281506
	LOSS [training: 0.4374490387697545 | validation: 0.4242084604234141]
	TIME [epoch: 4.73 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4076233026270244		[learning rate: 0.0028051]
	Learning Rate: 0.0028051
	LOSS [training: 0.4076233026270244 | validation: 0.38713271947373296]
	TIME [epoch: 4.74 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3951494341291711		[learning rate: 0.0027952]
	Learning Rate: 0.00279518
	LOSS [training: 0.3951494341291711 | validation: 0.37830619104453983]
	TIME [epoch: 4.72 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3983819362365806		[learning rate: 0.0027853]
	Learning Rate: 0.0027853
	LOSS [training: 0.3983819362365806 | validation: 0.3876095983881701]
	TIME [epoch: 4.74 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3864580864688773		[learning rate: 0.0027754]
	Learning Rate: 0.00277545
	LOSS [training: 0.3864580864688773 | validation: 0.3823254768295652]
	TIME [epoch: 4.73 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4204393197258949		[learning rate: 0.0027656]
	Learning Rate: 0.00276564
	LOSS [training: 0.4204393197258949 | validation: 0.4009179929171034]
	TIME [epoch: 4.73 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3753472390099754		[learning rate: 0.0027559]
	Learning Rate: 0.00275586
	LOSS [training: 0.3753472390099754 | validation: 0.4049184428319033]
	TIME [epoch: 4.72 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3808077539533076		[learning rate: 0.0027461]
	Learning Rate: 0.00274611
	LOSS [training: 0.3808077539533076 | validation: 0.3826970473831535]
	TIME [epoch: 4.75 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3880426875254646		[learning rate: 0.0027364]
	Learning Rate: 0.0027364
	LOSS [training: 0.3880426875254646 | validation: 0.4051240912323544]
	TIME [epoch: 4.75 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3903769738163318		[learning rate: 0.0027267]
	Learning Rate: 0.00272672
	LOSS [training: 0.3903769738163318 | validation: 0.41433957220616435]
	TIME [epoch: 4.74 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3879074490328705		[learning rate: 0.0027171]
	Learning Rate: 0.00271708
	LOSS [training: 0.3879074490328705 | validation: 0.3770113471681125]
	TIME [epoch: 4.73 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.41397238891310506		[learning rate: 0.0027075]
	Learning Rate: 0.00270747
	LOSS [training: 0.41397238891310506 | validation: 0.38012179478972685]
	TIME [epoch: 4.73 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5058599298894294		[learning rate: 0.0026979]
	Learning Rate: 0.0026979
	LOSS [training: 0.5058599298894294 | validation: 0.5556459219889884]
	TIME [epoch: 4.73 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.46907204745900505		[learning rate: 0.0026884]
	Learning Rate: 0.00268836
	LOSS [training: 0.46907204745900505 | validation: 0.40572551313894395]
	TIME [epoch: 4.73 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3536397020092698		[learning rate: 0.0026789]
	Learning Rate: 0.00267885
	LOSS [training: 0.3536397020092698 | validation: 0.40435889114647744]
	TIME [epoch: 4.73 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.37216683450206983		[learning rate: 0.0026694]
	Learning Rate: 0.00266938
	LOSS [training: 0.37216683450206983 | validation: 0.37354326367384705]
	TIME [epoch: 4.74 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3675090865722206		[learning rate: 0.0026599]
	Learning Rate: 0.00265994
	LOSS [training: 0.3675090865722206 | validation: 0.3944180244769665]
	TIME [epoch: 4.73 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.373937159288396		[learning rate: 0.0026505]
	Learning Rate: 0.00265053
	LOSS [training: 0.373937159288396 | validation: 0.35121711333757333]
	TIME [epoch: 4.72 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.6485781647889127		[learning rate: 0.0026412]
	Learning Rate: 0.00264116
	LOSS [training: 0.6485781647889127 | validation: 1.563120806123674]
	TIME [epoch: 4.73 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.4268767139902165		[learning rate: 0.0026318]
	Learning Rate: 0.00263182
	LOSS [training: 1.4268767139902165 | validation: 1.0082442514085805]
	TIME [epoch: 4.73 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.8732335801283634		[learning rate: 0.0026225]
	Learning Rate: 0.00262251
	LOSS [training: 0.8732335801283634 | validation: 0.6760352675423293]
	TIME [epoch: 4.73 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.7774416908554064		[learning rate: 0.0026132]
	Learning Rate: 0.00261324
	LOSS [training: 0.7774416908554064 | validation: 1.0247295529952691]
	TIME [epoch: 4.74 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.8766137792197838		[learning rate: 0.002604]
	Learning Rate: 0.002604
	LOSS [training: 0.8766137792197838 | validation: 0.7208100484068055]
	TIME [epoch: 4.72 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.8118489947882855		[learning rate: 0.0025948]
	Learning Rate: 0.00259479
	LOSS [training: 0.8118489947882855 | validation: 0.7668310687635829]
	TIME [epoch: 4.72 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.830421040214813		[learning rate: 0.0025856]
	Learning Rate: 0.00258562
	LOSS [training: 0.830421040214813 | validation: 0.8460005246746558]
	TIME [epoch: 4.72 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.8150957040914091		[learning rate: 0.0025765]
	Learning Rate: 0.00257647
	LOSS [training: 0.8150957040914091 | validation: 0.6716147476171017]
	TIME [epoch: 4.72 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.7463236787606026		[learning rate: 0.0025674]
	Learning Rate: 0.00256736
	LOSS [training: 0.7463236787606026 | validation: 0.6543837816890613]
	TIME [epoch: 4.72 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.7769379291971119		[learning rate: 0.0025583]
	Learning Rate: 0.00255828
	LOSS [training: 0.7769379291971119 | validation: 0.7408921489320608]
	TIME [epoch: 4.73 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.8197475614905101		[learning rate: 0.0025492]
	Learning Rate: 0.00254924
	LOSS [training: 0.8197475614905101 | validation: 0.7598158287841346]
	TIME [epoch: 4.72 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.375304028271204		[learning rate: 0.0025402]
	Learning Rate: 0.00254022
	LOSS [training: 1.375304028271204 | validation: 1.784332857107173]
	TIME [epoch: 4.72 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 6/6] avg loss: 2.3679901270206023		[learning rate: 0.0025312]
	Learning Rate: 0.00253124
	LOSS [training: 2.3679901270206023 | validation: 2.3456179252288036]
	TIME [epoch: 4.7 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v5_20240715_175905/states/model_facs_v3_dec1b_2dpca_v5_438.pth
Halted early. No improvement in validation loss for 200 epochs.
Finished training in 2133.162 seconds.
