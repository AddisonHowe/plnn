Args:
Namespace(name='model_facs_v2_dec2b_2dpca_v9', outdir='out/model_training/model_facs_v2_dec2b_2dpca_v9', training_data='data/training_data/facs_v2/pca/dec2_fitonsubset/transition2_subset_ce_pn_m_pc12/training', validation_data='data/training_data/facs_v2/pca/dec2_fitonsubset/transition2_subset_ce_pn_m_pc12/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=10, batch_size=50, patience=200, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, quadratic_a=1.0, quadratic_b=1.0, ndims=2, nparams=2, nsigs=2, ncells=400, ncells_sample=400, model_do_sample=False, dt=0.005, dt_schedule='stepped', dt_schedule_bounds=[500, 1000, 1500], dt_schedule_scales=[0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=True, sigma=0.2, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', kernel='multiscale', bw_range=[0.2, 0.5, 0.9, 1.1, 1.3, 1.5, 2.0], optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 81298002

Training model...

Saving initial model state to: out/model_training/model_facs_v2_dec2b_2dpca_v9_20240712_133637/states/model_facs_v2_dec2b_2dpca_v9_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.872203455046235		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.872203455046235 | validation: 0.926485796093428]
	TIME [epoch: 35.4 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v9_20240712_133637/states/model_facs_v2_dec2b_2dpca_v9_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6782873802356851		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6782873802356851 | validation: 0.8011692402145756]
	TIME [epoch: 6.06 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v9_20240712_133637/states/model_facs_v2_dec2b_2dpca_v9_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.601035756674045		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.601035756674045 | validation: 0.7036369468940886]
	TIME [epoch: 6.03 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v9_20240712_133637/states/model_facs_v2_dec2b_2dpca_v9_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5765775355242904		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5765775355242904 | validation: 0.6187223743348448]
	TIME [epoch: 6.04 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v9_20240712_133637/states/model_facs_v2_dec2b_2dpca_v9_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43014090930983767		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.43014090930983767 | validation: 0.5473371924494289]
	TIME [epoch: 6.05 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v9_20240712_133637/states/model_facs_v2_dec2b_2dpca_v9_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40376533862371244		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.40376533862371244 | validation: 0.549348523491088]
	TIME [epoch: 6.03 sec]
EPOCH 7/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38525033131325753		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.38525033131325753 | validation: 0.5272602027645399]
	TIME [epoch: 6.03 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v9_20240712_133637/states/model_facs_v2_dec2b_2dpca_v9_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3493396236517883		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3493396236517883 | validation: 0.5345753249486868]
	TIME [epoch: 6.04 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3787638457514827		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3787638457514827 | validation: 0.5233990844633623]
	TIME [epoch: 6.04 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v9_20240712_133637/states/model_facs_v2_dec2b_2dpca_v9_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3196752259682588		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3196752259682588 | validation: 0.5539134525179696]
	TIME [epoch: 6.03 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42015942511681337		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.42015942511681337 | validation: 0.5208385306608713]
	TIME [epoch: 6.03 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v9_20240712_133637/states/model_facs_v2_dec2b_2dpca_v9_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3495027509402784		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3495027509402784 | validation: 0.5836889747703088]
	TIME [epoch: 6.05 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33432232939795364		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.33432232939795364 | validation: 0.5274154516896329]
	TIME [epoch: 6.04 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3789012388792694		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3789012388792694 | validation: 0.4840327304819484]
	TIME [epoch: 6.03 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v9_20240712_133637/states/model_facs_v2_dec2b_2dpca_v9_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2970758351580433		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2970758351580433 | validation: 0.5100389896683032]
	TIME [epoch: 6.04 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37748665867212117		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.37748665867212117 | validation: 0.47017435004423885]
	TIME [epoch: 6.03 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v9_20240712_133637/states/model_facs_v2_dec2b_2dpca_v9_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2937235482494992		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2937235482494992 | validation: 0.4568777663532117]
	TIME [epoch: 6.04 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v9_20240712_133637/states/model_facs_v2_dec2b_2dpca_v9_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34544723681467565		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.34544723681467565 | validation: 0.4827519800531237]
	TIME [epoch: 6.03 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30727574537987207		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.30727574537987207 | validation: 0.4727381536973013]
	TIME [epoch: 6.04 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30380753012598954		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.30380753012598954 | validation: 0.4834418026808179]
	TIME [epoch: 6.03 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3000176502186697		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3000176502186697 | validation: 0.44568364189579446]
	TIME [epoch: 6.03 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v9_20240712_133637/states/model_facs_v2_dec2b_2dpca_v9_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30830044878875784		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.30830044878875784 | validation: 0.45260597418020077]
	TIME [epoch: 6.03 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2805293970481887		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2805293970481887 | validation: 0.4657632491492996]
	TIME [epoch: 6.03 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38863493584379627		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.38863493584379627 | validation: 0.48062055056699216]
	TIME [epoch: 6.03 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3121338343845045		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3121338343845045 | validation: 0.5027305368636222]
	TIME [epoch: 6.02 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31446366574302564		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.31446366574302564 | validation: 0.4640336148320794]
	TIME [epoch: 6.03 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2985758587734308		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2985758587734308 | validation: 0.4681530710280139]
	TIME [epoch: 6.03 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35651394761931043		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.35651394761931043 | validation: 0.46643018742699205]
	TIME [epoch: 6.03 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2813868744649655		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2813868744649655 | validation: 0.42115887210893627]
	TIME [epoch: 6.03 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v9_20240712_133637/states/model_facs_v2_dec2b_2dpca_v9_29.pth
	Model improved!!!
EPOCH 30/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25181585699330156		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.25181585699330156 | validation: 0.4367574597155789]
	TIME [epoch: 6.04 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2889789661701553		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2889789661701553 | validation: 0.47234788556495455]
	TIME [epoch: 6.03 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3376597242376939		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3376597242376939 | validation: 0.4254072445395802]
	TIME [epoch: 6.03 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3232392965855896		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3232392965855896 | validation: 0.44636138938506015]
	TIME [epoch: 6.03 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28283453431075645		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.28283453431075645 | validation: 0.46778866538048564]
	TIME [epoch: 6.04 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2948919348488375		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2948919348488375 | validation: 0.4751333071554048]
	TIME [epoch: 6.03 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26935351438067545		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.26935351438067545 | validation: 0.4914863598711369]
	TIME [epoch: 6.02 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2673911571378903		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2673911571378903 | validation: 0.44388225654762564]
	TIME [epoch: 6.02 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29039147753704747		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.29039147753704747 | validation: 0.40061716824528826]
	TIME [epoch: 6.02 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v9_20240712_133637/states/model_facs_v2_dec2b_2dpca_v9_38.pth
	Model improved!!!
EPOCH 39/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24270434859001727		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24270434859001727 | validation: 0.4187619608442402]
	TIME [epoch: 6.03 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2675944372234628		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2675944372234628 | validation: 0.39084185898537255]
	TIME [epoch: 6.02 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v9_20240712_133637/states/model_facs_v2_dec2b_2dpca_v9_40.pth
	Model improved!!!
EPOCH 41/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2974550012317455		[learning rate: 0.0099646]
	Learning Rate: 0.00996464
	LOSS [training: 0.2974550012317455 | validation: 0.584064604502517]
	TIME [epoch: 6.05 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27497265076849164		[learning rate: 0.0099206]
	Learning Rate: 0.00992061
	LOSS [training: 0.27497265076849164 | validation: 0.4255336463835667]
	TIME [epoch: 6.03 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2606063256128435		[learning rate: 0.0098768]
	Learning Rate: 0.00987678
	LOSS [training: 0.2606063256128435 | validation: 0.4290281619970508]
	TIME [epoch: 6.03 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2707006784162961		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 0.2707006784162961 | validation: 0.4285639204796215]
	TIME [epoch: 6.03 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25096057853643244		[learning rate: 0.0097897]
	Learning Rate: 0.0097897
	LOSS [training: 0.25096057853643244 | validation: 0.4190967401855834]
	TIME [epoch: 6.03 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27897649762356136		[learning rate: 0.0097464]
	Learning Rate: 0.00974644
	LOSS [training: 0.27897649762356136 | validation: 0.4187048611614422]
	TIME [epoch: 6.03 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24596954888247632		[learning rate: 0.0097034]
	Learning Rate: 0.00970338
	LOSS [training: 0.24596954888247632 | validation: 0.37978794467495747]
	TIME [epoch: 6.03 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v9_20240712_133637/states/model_facs_v2_dec2b_2dpca_v9_47.pth
	Model improved!!!
EPOCH 48/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2563794734138758		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 0.2563794734138758 | validation: 0.4031733187779871]
	TIME [epoch: 6.04 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23966200785734565		[learning rate: 0.0096178]
	Learning Rate: 0.00961783
	LOSS [training: 0.23966200785734565 | validation: 0.44780817806582407]
	TIME [epoch: 6.03 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26982470020190813		[learning rate: 0.0095753]
	Learning Rate: 0.00957533
	LOSS [training: 0.26982470020190813 | validation: 0.37359741353554815]
	TIME [epoch: 6.03 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v9_20240712_133637/states/model_facs_v2_dec2b_2dpca_v9_50.pth
	Model improved!!!
EPOCH 51/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24524976092019085		[learning rate: 0.009533]
	Learning Rate: 0.00953303
	LOSS [training: 0.24524976092019085 | validation: 0.3797591494738254]
	TIME [epoch: 6.03 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2660063117573077		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 0.2660063117573077 | validation: 0.38004397347819635]
	TIME [epoch: 6.03 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24713142531007942		[learning rate: 0.009449]
	Learning Rate: 0.00944897
	LOSS [training: 0.24713142531007942 | validation: 0.3904739631671277]
	TIME [epoch: 6.03 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25547183408715907		[learning rate: 0.0094072]
	Learning Rate: 0.00940722
	LOSS [training: 0.25547183408715907 | validation: 0.41600572428602894]
	TIME [epoch: 6.03 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.241594525492807		[learning rate: 0.0093657]
	Learning Rate: 0.00936566
	LOSS [training: 0.241594525492807 | validation: 0.36090455711438885]
	TIME [epoch: 6.03 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v9_20240712_133637/states/model_facs_v2_dec2b_2dpca_v9_55.pth
	Model improved!!!
EPOCH 56/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2456006715573013		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 0.2456006715573013 | validation: 0.42599538926783104]
	TIME [epoch: 6.05 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.249059958698106		[learning rate: 0.0092831]
	Learning Rate: 0.00928308
	LOSS [training: 0.249059958698106 | validation: 0.35727385278059076]
	TIME [epoch: 6.04 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v9_20240712_133637/states/model_facs_v2_dec2b_2dpca_v9_57.pth
	Model improved!!!
EPOCH 58/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2685794211818991		[learning rate: 0.0092421]
	Learning Rate: 0.00924207
	LOSS [training: 0.2685794211818991 | validation: 0.3458235566814155]
	TIME [epoch: 6.04 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v9_20240712_133637/states/model_facs_v2_dec2b_2dpca_v9_58.pth
	Model improved!!!
EPOCH 59/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22579004913496967		[learning rate: 0.0092012]
	Learning Rate: 0.00920124
	LOSS [training: 0.22579004913496967 | validation: 0.3832670800383441]
	TIME [epoch: 6.03 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2500624553293653		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 0.2500624553293653 | validation: 0.38768389459518454]
	TIME [epoch: 6.03 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22670624671549788		[learning rate: 0.0091201]
	Learning Rate: 0.00912011
	LOSS [training: 0.22670624671549788 | validation: 0.3433084194049548]
	TIME [epoch: 6.03 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v9_20240712_133637/states/model_facs_v2_dec2b_2dpca_v9_61.pth
	Model improved!!!
EPOCH 62/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2509271169451284		[learning rate: 0.0090798]
	Learning Rate: 0.00907981
	LOSS [training: 0.2509271169451284 | validation: 0.3570376367868066]
	TIME [epoch: 6.03 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21668423756326466		[learning rate: 0.0090397]
	Learning Rate: 0.0090397
	LOSS [training: 0.21668423756326466 | validation: 0.38069841128375304]
	TIME [epoch: 6.04 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2341051897799899		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 0.2341051897799899 | validation: 0.377041459165573]
	TIME [epoch: 6.03 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2502638759362606		[learning rate: 0.00896]
	Learning Rate: 0.00895999
	LOSS [training: 0.2502638759362606 | validation: 0.3863836918538549]
	TIME [epoch: 6.03 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23488402000266126		[learning rate: 0.0089204]
	Learning Rate: 0.00892041
	LOSS [training: 0.23488402000266126 | validation: 0.3760562294288228]
	TIME [epoch: 6.03 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2299487315649782		[learning rate: 0.008881]
	Learning Rate: 0.00888099
	LOSS [training: 0.2299487315649782 | validation: 0.34073192389789103]
	TIME [epoch: 6.03 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v9_20240712_133637/states/model_facs_v2_dec2b_2dpca_v9_67.pth
	Model improved!!!
EPOCH 68/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24631632536514259		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 0.24631632536514259 | validation: 0.43077200026531204]
	TIME [epoch: 6.04 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27597058779151834		[learning rate: 0.0088027]
	Learning Rate: 0.00880269
	LOSS [training: 0.27597058779151834 | validation: 0.3479798448383002]
	TIME [epoch: 6.02 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24259914497164417		[learning rate: 0.0087638]
	Learning Rate: 0.0087638
	LOSS [training: 0.24259914497164417 | validation: 0.3658999612341294]
	TIME [epoch: 6.03 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21330095401671464		[learning rate: 0.0087251]
	Learning Rate: 0.00872508
	LOSS [training: 0.21330095401671464 | validation: 0.3485576255736283]
	TIME [epoch: 6.03 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.210636944548791		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 0.210636944548791 | validation: 0.36759770717202356]
	TIME [epoch: 6.03 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2278036380985579		[learning rate: 0.0086481]
	Learning Rate: 0.00864815
	LOSS [training: 0.2278036380985579 | validation: 0.41502934541333447]
	TIME [epoch: 6.02 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24943929019768016		[learning rate: 0.0086099]
	Learning Rate: 0.00860994
	LOSS [training: 0.24943929019768016 | validation: 0.415007352451201]
	TIME [epoch: 6.03 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24218807564871309		[learning rate: 0.0085719]
	Learning Rate: 0.0085719
	LOSS [training: 0.24218807564871309 | validation: 0.3440745784145217]
	TIME [epoch: 6.03 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24230579114320103		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 0.24230579114320103 | validation: 0.441019309987732]
	TIME [epoch: 6.03 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2362006709590229		[learning rate: 0.0084963]
	Learning Rate: 0.00849632
	LOSS [training: 0.2362006709590229 | validation: 0.4013271401312818]
	TIME [epoch: 6.02 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24483664906050265		[learning rate: 0.0084588]
	Learning Rate: 0.00845878
	LOSS [training: 0.24483664906050265 | validation: 0.33160213372260183]
	TIME [epoch: 6.04 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v9_20240712_133637/states/model_facs_v2_dec2b_2dpca_v9_78.pth
	Model improved!!!
EPOCH 79/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2395330004301232		[learning rate: 0.0084214]
	Learning Rate: 0.00842141
	LOSS [training: 0.2395330004301232 | validation: 0.4226191537888072]
	TIME [epoch: 6.04 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2548433239672119		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 0.2548433239672119 | validation: 0.35877819412152423]
	TIME [epoch: 6.03 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2501774470905677		[learning rate: 0.0083472]
	Learning Rate: 0.00834715
	LOSS [training: 0.2501774470905677 | validation: 0.49504101224313307]
	TIME [epoch: 6.03 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23800563314710402		[learning rate: 0.0083103]
	Learning Rate: 0.00831027
	LOSS [training: 0.23800563314710402 | validation: 0.4342827709081768]
	TIME [epoch: 6.04 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25611314840467225		[learning rate: 0.0082736]
	Learning Rate: 0.00827356
	LOSS [training: 0.25611314840467225 | validation: 0.39323874350000076]
	TIME [epoch: 6.03 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2219372291045744		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 0.2219372291045744 | validation: 0.3735322429493316]
	TIME [epoch: 6.04 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.216795418517512		[learning rate: 0.0082006]
	Learning Rate: 0.00820061
	LOSS [training: 0.216795418517512 | validation: 0.41871655127706325]
	TIME [epoch: 6.04 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22666705651482086		[learning rate: 0.0081644]
	Learning Rate: 0.00816438
	LOSS [training: 0.22666705651482086 | validation: 0.39721408742138475]
	TIME [epoch: 6.04 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2183080615928435		[learning rate: 0.0081283]
	Learning Rate: 0.0081283
	LOSS [training: 0.2183080615928435 | validation: 0.37166577040284443]
	TIME [epoch: 6.03 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22640595631576788		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 0.22640595631576788 | validation: 0.3932120907414391]
	TIME [epoch: 6.03 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1982131632257663		[learning rate: 0.0080566]
	Learning Rate: 0.00805664
	LOSS [training: 0.1982131632257663 | validation: 0.36718974811241095]
	TIME [epoch: 6.03 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24168707130336148		[learning rate: 0.008021]
	Learning Rate: 0.00802104
	LOSS [training: 0.24168707130336148 | validation: 0.31957697977475313]
	TIME [epoch: 6.03 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v9_20240712_133637/states/model_facs_v2_dec2b_2dpca_v9_90.pth
	Model improved!!!
EPOCH 91/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21764505024055797		[learning rate: 0.0079856]
	Learning Rate: 0.0079856
	LOSS [training: 0.21764505024055797 | validation: 0.41190998284583363]
	TIME [epoch: 6.03 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21249024477658934		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 0.21249024477658934 | validation: 0.35119957763715853]
	TIME [epoch: 6.03 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24028990039688747		[learning rate: 0.0079152]
	Learning Rate: 0.00791519
	LOSS [training: 0.24028990039688747 | validation: 0.3817629855645445]
	TIME [epoch: 6.04 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21982457329727406		[learning rate: 0.0078802]
	Learning Rate: 0.00788022
	LOSS [training: 0.21982457329727406 | validation: 0.37822613743044825]
	TIME [epoch: 6.02 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28606174400751916		[learning rate: 0.0078454]
	Learning Rate: 0.00784541
	LOSS [training: 0.28606174400751916 | validation: 0.3704076680454457]
	TIME [epoch: 6.03 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23129092383913133		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 0.23129092383913133 | validation: 0.35990622706161735]
	TIME [epoch: 6.02 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21199163110019467		[learning rate: 0.0077762]
	Learning Rate: 0.00777623
	LOSS [training: 0.21199163110019467 | validation: 0.3763417224070663]
	TIME [epoch: 6.03 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21840321266661933		[learning rate: 0.0077419]
	Learning Rate: 0.00774188
	LOSS [training: 0.21840321266661933 | validation: 0.3895325339282852]
	TIME [epoch: 6.02 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24783557463281025		[learning rate: 0.0077077]
	Learning Rate: 0.00770767
	LOSS [training: 0.24783557463281025 | validation: 0.3844941199043821]
	TIME [epoch: 6.03 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20966992798174147		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 0.20966992798174147 | validation: 0.3663790667629428]
	TIME [epoch: 6.04 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21773457141593852		[learning rate: 0.0076397]
	Learning Rate: 0.00763971
	LOSS [training: 0.21773457141593852 | validation: 0.3554112715937325]
	TIME [epoch: 6.04 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21332452910812233		[learning rate: 0.007606]
	Learning Rate: 0.00760596
	LOSS [training: 0.21332452910812233 | validation: 0.33056167612817206]
	TIME [epoch: 6.03 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24856841334250496		[learning rate: 0.0075724]
	Learning Rate: 0.00757235
	LOSS [training: 0.24856841334250496 | validation: 0.3742008011878039]
	TIME [epoch: 6.03 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2065080341540944		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 0.2065080341540944 | validation: 0.3501586061025539]
	TIME [epoch: 6.03 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1915623923935192		[learning rate: 0.0075056]
	Learning Rate: 0.00750559
	LOSS [training: 0.1915623923935192 | validation: 0.3563083493577431]
	TIME [epoch: 6.03 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19449536067294632		[learning rate: 0.0074724]
	Learning Rate: 0.00747242
	LOSS [training: 0.19449536067294632 | validation: 0.32009491101608295]
	TIME [epoch: 6.03 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20437219663091422		[learning rate: 0.0074394]
	Learning Rate: 0.00743941
	LOSS [training: 0.20437219663091422 | validation: 0.4031066662523174]
	TIME [epoch: 6.03 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2140961563114409		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 0.2140961563114409 | validation: 0.3739099245215491]
	TIME [epoch: 6.04 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1999982295344242		[learning rate: 0.0073738]
	Learning Rate: 0.00737382
	LOSS [training: 0.1999982295344242 | validation: 0.3712605616919974]
	TIME [epoch: 6.03 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19916454905728898		[learning rate: 0.0073412]
	Learning Rate: 0.00734124
	LOSS [training: 0.19916454905728898 | validation: 0.38506092554101934]
	TIME [epoch: 6.02 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22963910899712045		[learning rate: 0.0073088]
	Learning Rate: 0.0073088
	LOSS [training: 0.22963910899712045 | validation: 0.37671795971852845]
	TIME [epoch: 6.03 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21321765378973842		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 0.21321765378973842 | validation: 0.3419420949091278]
	TIME [epoch: 6.02 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21378249427246043		[learning rate: 0.0072444]
	Learning Rate: 0.00724436
	LOSS [training: 0.21378249427246043 | validation: 0.46902262883969503]
	TIME [epoch: 6.03 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23813995082437636		[learning rate: 0.0072124]
	Learning Rate: 0.00721235
	LOSS [training: 0.23813995082437636 | validation: 0.33239389325873114]
	TIME [epoch: 6.03 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19225032080426852		[learning rate: 0.0071805]
	Learning Rate: 0.00718049
	LOSS [training: 0.19225032080426852 | validation: 0.3550701839678157]
	TIME [epoch: 6.04 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19878294776988784		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 0.19878294776988784 | validation: 0.3363470099415721]
	TIME [epoch: 6.03 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19201984928254903		[learning rate: 0.0071172]
	Learning Rate: 0.00711718
	LOSS [training: 0.19201984928254903 | validation: 0.4406750600974857]
	TIME [epoch: 6.03 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19212402404102727		[learning rate: 0.0070857]
	Learning Rate: 0.00708573
	LOSS [training: 0.19212402404102727 | validation: 0.31963862440218543]
	TIME [epoch: 6.03 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19437183821337917		[learning rate: 0.0070544]
	Learning Rate: 0.00705442
	LOSS [training: 0.19437183821337917 | validation: 0.315289858925193]
	TIME [epoch: 6.03 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v9_20240712_133637/states/model_facs_v2_dec2b_2dpca_v9_119.pth
	Model improved!!!
EPOCH 120/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19184848503731666		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 0.19184848503731666 | validation: 0.3441759465369461]
	TIME [epoch: 6.03 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21239582812150318		[learning rate: 0.0069922]
	Learning Rate: 0.00699222
	LOSS [training: 0.21239582812150318 | validation: 0.32455652113928396]
	TIME [epoch: 6.03 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20398488506840665		[learning rate: 0.0069613]
	Learning Rate: 0.00696133
	LOSS [training: 0.20398488506840665 | validation: 0.33241398211352907]
	TIME [epoch: 6.03 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21807102532297268		[learning rate: 0.0069306]
	Learning Rate: 0.00693057
	LOSS [training: 0.21807102532297268 | validation: 0.43044465361686635]
	TIME [epoch: 6.04 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.284780247697494		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 0.284780247697494 | validation: 0.37806600839848614]
	TIME [epoch: 6.02 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21946354769010884		[learning rate: 0.0068695]
	Learning Rate: 0.00686947
	LOSS [training: 0.21946354769010884 | validation: 0.31661915580490835]
	TIME [epoch: 6.02 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19410359020281615		[learning rate: 0.0068391]
	Learning Rate: 0.00683912
	LOSS [training: 0.19410359020281615 | validation: 0.3297699438101276]
	TIME [epoch: 6.03 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21782429459047797		[learning rate: 0.0068089]
	Learning Rate: 0.0068089
	LOSS [training: 0.21782429459047797 | validation: 0.33221233812811046]
	TIME [epoch: 6.02 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20358039416255078		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 0.20358039416255078 | validation: 0.3588952444524282]
	TIME [epoch: 6.03 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20538858526606218		[learning rate: 0.0067489]
	Learning Rate: 0.00674887
	LOSS [training: 0.20538858526606218 | validation: 0.34616073398631214]
	TIME [epoch: 6.03 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23758636928869645		[learning rate: 0.006719]
	Learning Rate: 0.00671905
	LOSS [training: 0.23758636928869645 | validation: 0.34678635174573685]
	TIME [epoch: 6.04 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20132144490073442		[learning rate: 0.0066894]
	Learning Rate: 0.00668936
	LOSS [training: 0.20132144490073442 | validation: 0.42060200319700675]
	TIME [epoch: 6.03 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2396718128229919		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 0.2396718128229919 | validation: 0.32993972741202493]
	TIME [epoch: 6.03 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19252334753371408		[learning rate: 0.0066304]
	Learning Rate: 0.00663038
	LOSS [training: 0.19252334753371408 | validation: 0.39955955802041043]
	TIME [epoch: 6.03 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2008540122790703		[learning rate: 0.0066011]
	Learning Rate: 0.00660109
	LOSS [training: 0.2008540122790703 | validation: 0.33107905367328055]
	TIME [epoch: 6.03 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18700588587156414		[learning rate: 0.0065719]
	Learning Rate: 0.00657192
	LOSS [training: 0.18700588587156414 | validation: 0.33795077370487453]
	TIME [epoch: 6.05 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19003892759934488		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 0.19003892759934488 | validation: 0.3542050861538144]
	TIME [epoch: 6.03 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2170912109047603		[learning rate: 0.006514]
	Learning Rate: 0.00651398
	LOSS [training: 0.2170912109047603 | validation: 0.3382706026700344]
	TIME [epoch: 6.03 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2070018651654701		[learning rate: 0.0064852]
	Learning Rate: 0.00648519
	LOSS [training: 0.2070018651654701 | validation: 0.35623409491584546]
	TIME [epoch: 6.04 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20289576031644874		[learning rate: 0.0064565]
	Learning Rate: 0.00645654
	LOSS [training: 0.20289576031644874 | validation: 0.3553791271370334]
	TIME [epoch: 6.03 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20549922845649943		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 0.20549922845649943 | validation: 0.3530025124590449]
	TIME [epoch: 6.03 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19039440294330326		[learning rate: 0.0063996]
	Learning Rate: 0.00639961
	LOSS [training: 0.19039440294330326 | validation: 0.3095605820160589]
	TIME [epoch: 6.03 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v9_20240712_133637/states/model_facs_v2_dec2b_2dpca_v9_141.pth
	Model improved!!!
EPOCH 142/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18380024712434892		[learning rate: 0.0063713]
	Learning Rate: 0.00637134
	LOSS [training: 0.18380024712434892 | validation: 0.35162277450938406]
	TIME [epoch: 6.03 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2046386686483795		[learning rate: 0.0063432]
	Learning Rate: 0.00634319
	LOSS [training: 0.2046386686483795 | validation: 0.37734689552086864]
	TIME [epoch: 6.03 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19969128933127195		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 0.19969128933127195 | validation: 0.37943944248090794]
	TIME [epoch: 6.03 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2013770442666102		[learning rate: 0.0062873]
	Learning Rate: 0.00628726
	LOSS [training: 0.2013770442666102 | validation: 0.33638909444536313]
	TIME [epoch: 6.04 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21789187939177196		[learning rate: 0.0062595]
	Learning Rate: 0.00625948
	LOSS [training: 0.21789187939177196 | validation: 0.3346623689121859]
	TIME [epoch: 6.03 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1807953795628052		[learning rate: 0.0062318]
	Learning Rate: 0.00623183
	LOSS [training: 0.1807953795628052 | validation: 0.36898629450439896]
	TIME [epoch: 6.03 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19532030392070784		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 0.19532030392070784 | validation: 0.35063930760309087]
	TIME [epoch: 6.03 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18248275359675686		[learning rate: 0.0061769]
	Learning Rate: 0.00617688
	LOSS [training: 0.18248275359675686 | validation: 0.35333406282854385]
	TIME [epoch: 6.03 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18890141622767448		[learning rate: 0.0061496]
	Learning Rate: 0.00614959
	LOSS [training: 0.18890141622767448 | validation: 0.349916119472482]
	TIME [epoch: 6.02 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1857466107784569		[learning rate: 0.0061224]
	Learning Rate: 0.00612242
	LOSS [training: 0.1857466107784569 | validation: 0.3361834857145437]
	TIME [epoch: 6.03 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2237338781934362		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 0.2237338781934362 | validation: 0.35744498222729226]
	TIME [epoch: 6.03 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19186754019604793		[learning rate: 0.0060684]
	Learning Rate: 0.00606844
	LOSS [training: 0.19186754019604793 | validation: 0.30470469537424505]
	TIME [epoch: 6.03 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v9_20240712_133637/states/model_facs_v2_dec2b_2dpca_v9_153.pth
	Model improved!!!
EPOCH 154/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18965871851023158		[learning rate: 0.0060416]
	Learning Rate: 0.00604163
	LOSS [training: 0.18965871851023158 | validation: 0.3301851801593633]
	TIME [epoch: 6.03 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20398352748788834		[learning rate: 0.0060149]
	Learning Rate: 0.00601493
	LOSS [training: 0.20398352748788834 | validation: 0.32162314720969853]
	TIME [epoch: 6.02 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2093822928737107		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 0.2093822928737107 | validation: 0.3656896085679646]
	TIME [epoch: 6.03 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19925761117693783		[learning rate: 0.0059619]
	Learning Rate: 0.0059619
	LOSS [training: 0.19925761117693783 | validation: 0.31545193619732914]
	TIME [epoch: 6.02 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20538496434316134		[learning rate: 0.0059356]
	Learning Rate: 0.00593556
	LOSS [training: 0.20538496434316134 | validation: 0.30817463368276693]
	TIME [epoch: 6.03 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23479904107377542		[learning rate: 0.0059093]
	Learning Rate: 0.00590933
	LOSS [training: 0.23479904107377542 | validation: 0.4129496941196864]
	TIME [epoch: 6.03 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18365973391009366		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 0.18365973391009366 | validation: 0.3811633244531828]
	TIME [epoch: 6.04 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18494442048684906		[learning rate: 0.0058572]
	Learning Rate: 0.00585723
	LOSS [training: 0.18494442048684906 | validation: 0.3112574552598218]
	TIME [epoch: 6.03 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21741590564444238		[learning rate: 0.0058314]
	Learning Rate: 0.00583135
	LOSS [training: 0.21741590564444238 | validation: 0.37936132585331955]
	TIME [epoch: 6.03 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1921391207690004		[learning rate: 0.0058056]
	Learning Rate: 0.00580559
	LOSS [training: 0.1921391207690004 | validation: 0.31215953022278814]
	TIME [epoch: 6.02 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1864217186060236		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 0.1864217186060236 | validation: 0.3829863143703639]
	TIME [epoch: 6.03 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20101943657807125		[learning rate: 0.0057544]
	Learning Rate: 0.0057544
	LOSS [training: 0.20101943657807125 | validation: 0.331726621083169]
	TIME [epoch: 6.02 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1920193981358413		[learning rate: 0.005729]
	Learning Rate: 0.00572897
	LOSS [training: 0.1920193981358413 | validation: 0.33014387796142997]
	TIME [epoch: 6.03 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18449977151694535		[learning rate: 0.0057037]
	Learning Rate: 0.00570366
	LOSS [training: 0.18449977151694535 | validation: 0.3013651310509628]
	TIME [epoch: 6.03 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v9_20240712_133637/states/model_facs_v2_dec2b_2dpca_v9_167.pth
	Model improved!!!
EPOCH 168/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17520097183586994		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 0.17520097183586994 | validation: 0.3432527103826983]
	TIME [epoch: 6.04 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19818719826580325		[learning rate: 0.0056534]
	Learning Rate: 0.00565337
	LOSS [training: 0.19818719826580325 | validation: 0.30295438589945756]
	TIME [epoch: 6.03 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19694314544026675		[learning rate: 0.0056284]
	Learning Rate: 0.0056284
	LOSS [training: 0.19694314544026675 | validation: 0.38699501121477625]
	TIME [epoch: 6.02 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18554053272798957		[learning rate: 0.0056035]
	Learning Rate: 0.00560353
	LOSS [training: 0.18554053272798957 | validation: 0.33502149791683256]
	TIME [epoch: 6.03 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19409059958720642		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 0.19409059958720642 | validation: 0.32101289937150124]
	TIME [epoch: 6.03 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18436016575330427		[learning rate: 0.0055541]
	Learning Rate: 0.00555412
	LOSS [training: 0.18436016575330427 | validation: 0.3155320093921313]
	TIME [epoch: 6.03 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20832407976908382		[learning rate: 0.0055296]
	Learning Rate: 0.00552958
	LOSS [training: 0.20832407976908382 | validation: 0.34151591983249896]
	TIME [epoch: 6.03 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20449528695231453		[learning rate: 0.0055052]
	Learning Rate: 0.00550515
	LOSS [training: 0.20449528695231453 | validation: 0.30921089804040736]
	TIME [epoch: 6.04 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18038049824965136		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 0.18038049824965136 | validation: 0.31963229900020057]
	TIME [epoch: 6.03 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19873072057880822		[learning rate: 0.0054566]
	Learning Rate: 0.00545661
	LOSS [training: 0.19873072057880822 | validation: 0.30961093772365417]
	TIME [epoch: 6.02 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17948225798785455		[learning rate: 0.0054325]
	Learning Rate: 0.0054325
	LOSS [training: 0.17948225798785455 | validation: 0.34317293872972826]
	TIME [epoch: 6.02 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18728605252367525		[learning rate: 0.0054085]
	Learning Rate: 0.0054085
	LOSS [training: 0.18728605252367525 | validation: 0.34056533042205794]
	TIME [epoch: 6.02 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18990814316337462		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 0.18990814316337462 | validation: 0.3118465769435655]
	TIME [epoch: 6.02 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18122535273844656		[learning rate: 0.0053608]
	Learning Rate: 0.00536081
	LOSS [training: 0.18122535273844656 | validation: 0.3371461664698714]
	TIME [epoch: 6.03 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18967169336004616		[learning rate: 0.0053371]
	Learning Rate: 0.00533713
	LOSS [training: 0.18967169336004616 | validation: 0.3493320777028536]
	TIME [epoch: 6.03 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19887487132500128		[learning rate: 0.0053135]
	Learning Rate: 0.00531355
	LOSS [training: 0.19887487132500128 | validation: 0.3005740353024125]
	TIME [epoch: 6.03 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v9_20240712_133637/states/model_facs_v2_dec2b_2dpca_v9_183.pth
	Model improved!!!
EPOCH 184/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1860687363572982		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 0.1860687363572982 | validation: 0.3018649420474328]
	TIME [epoch: 6.03 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1794813871109977		[learning rate: 0.0052667]
	Learning Rate: 0.0052667
	LOSS [training: 0.1794813871109977 | validation: 0.32191463275982457]
	TIME [epoch: 6.03 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18506939110133563		[learning rate: 0.0052434]
	Learning Rate: 0.00524343
	LOSS [training: 0.18506939110133563 | validation: 0.38150176159924476]
	TIME [epoch: 6.02 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2118279603326047		[learning rate: 0.0052203]
	Learning Rate: 0.00522026
	LOSS [training: 0.2118279603326047 | validation: 0.38420945128329104]
	TIME [epoch: 6.03 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18345099164703668		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 0.18345099164703668 | validation: 0.31353355591136106]
	TIME [epoch: 6.03 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17890562285848446		[learning rate: 0.0051742]
	Learning Rate: 0.00517423
	LOSS [training: 0.17890562285848446 | validation: 0.3157545365521863]
	TIME [epoch: 6.02 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19946161344859176		[learning rate: 0.0051514]
	Learning Rate: 0.00515137
	LOSS [training: 0.19946161344859176 | validation: 0.3286137891416413]
	TIME [epoch: 6.04 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20671113295794755		[learning rate: 0.0051286]
	Learning Rate: 0.00512861
	LOSS [training: 0.20671113295794755 | validation: 0.31700480306650464]
	TIME [epoch: 6.03 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1799264365049172		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 0.1799264365049172 | validation: 0.31768682344800625]
	TIME [epoch: 6.02 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18945516395399398		[learning rate: 0.0050834]
	Learning Rate: 0.00508339
	LOSS [training: 0.18945516395399398 | validation: 0.31814560908354955]
	TIME [epoch: 6.03 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19312039716706075		[learning rate: 0.0050609]
	Learning Rate: 0.00506093
	LOSS [training: 0.19312039716706075 | validation: 0.348201454096859]
	TIME [epoch: 6.03 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18939990740682494		[learning rate: 0.0050386]
	Learning Rate: 0.00503857
	LOSS [training: 0.18939990740682494 | validation: 0.34160313394864417]
	TIME [epoch: 6.03 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1941003553583847		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 0.1941003553583847 | validation: 0.30505041331480365]
	TIME [epoch: 6.03 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1837171403664672		[learning rate: 0.0049941]
	Learning Rate: 0.00499415
	LOSS [training: 0.1837171403664672 | validation: 0.30666263300555835]
	TIME [epoch: 6.04 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17171990282524927		[learning rate: 0.0049721]
	Learning Rate: 0.00497208
	LOSS [training: 0.17171990282524927 | validation: 0.3282531282911903]
	TIME [epoch: 6.03 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20953393340504226		[learning rate: 0.0049501]
	Learning Rate: 0.00495012
	LOSS [training: 0.20953393340504226 | validation: 0.34902301769597666]
	TIME [epoch: 6.03 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19360406331924573		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 0.19360406331924573 | validation: 0.3084958039787048]
	TIME [epoch: 6.04 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.185656501301713		[learning rate: 0.0049065]
	Learning Rate: 0.00490647
	LOSS [training: 0.185656501301713 | validation: 0.29703794775853726]
	TIME [epoch: 6.04 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v9_20240712_133637/states/model_facs_v2_dec2b_2dpca_v9_201.pth
	Model improved!!!
EPOCH 202/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17261392795700709		[learning rate: 0.0048848]
	Learning Rate: 0.00488479
	LOSS [training: 0.17261392795700709 | validation: 0.36336747788145973]
	TIME [epoch: 6.04 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19116742877060217		[learning rate: 0.0048632]
	Learning Rate: 0.00486321
	LOSS [training: 0.19116742877060217 | validation: 0.40853208399981367]
	TIME [epoch: 6.04 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18741101460738951		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 0.18741101460738951 | validation: 0.3858487847375636]
	TIME [epoch: 6.05 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.183439498959496		[learning rate: 0.0048203]
	Learning Rate: 0.00482033
	LOSS [training: 0.183439498959496 | validation: 0.33863793668770464]
	TIME [epoch: 6.04 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17154580288728977		[learning rate: 0.004799]
	Learning Rate: 0.00479903
	LOSS [training: 0.17154580288728977 | validation: 0.31217479754306626]
	TIME [epoch: 6.03 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17475805649656606		[learning rate: 0.0047778]
	Learning Rate: 0.00477783
	LOSS [training: 0.17475805649656606 | validation: 0.3276982117372458]
	TIME [epoch: 6.03 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17839703839272264		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.17839703839272264 | validation: 0.3293650870917112]
	TIME [epoch: 6.04 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1712449695328871		[learning rate: 0.0047357]
	Learning Rate: 0.0047357
	LOSS [training: 0.1712449695328871 | validation: 0.34917136012760064]
	TIME [epoch: 6.03 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17744341049503215		[learning rate: 0.0047148]
	Learning Rate: 0.00471478
	LOSS [training: 0.17744341049503215 | validation: 0.3504465325810739]
	TIME [epoch: 6.03 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17679208132133306		[learning rate: 0.0046939]
	Learning Rate: 0.00469395
	LOSS [training: 0.17679208132133306 | validation: 0.31303562417168945]
	TIME [epoch: 6.03 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18215133760314026		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 0.18215133760314026 | validation: 0.33893956062900926]
	TIME [epoch: 6.04 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18572675335107341		[learning rate: 0.0046526]
	Learning Rate: 0.00465256
	LOSS [training: 0.18572675335107341 | validation: 0.3261640651898147]
	TIME [epoch: 6.03 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18279802043579887		[learning rate: 0.004632]
	Learning Rate: 0.00463201
	LOSS [training: 0.18279802043579887 | validation: 0.3211052181397388]
	TIME [epoch: 6.03 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17703311844856381		[learning rate: 0.0046115]
	Learning Rate: 0.00461154
	LOSS [training: 0.17703311844856381 | validation: 0.29991060701693756]
	TIME [epoch: 6.03 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19536244997937152		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 0.19536244997937152 | validation: 0.3503732509305712]
	TIME [epoch: 6.03 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18232057132128063		[learning rate: 0.0045709]
	Learning Rate: 0.00457088
	LOSS [training: 0.18232057132128063 | validation: 0.3283573005241438]
	TIME [epoch: 6.03 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17443630908647187		[learning rate: 0.0045507]
	Learning Rate: 0.00455069
	LOSS [training: 0.17443630908647187 | validation: 0.32565289382505525]
	TIME [epoch: 6.03 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16738322867624977		[learning rate: 0.0045306]
	Learning Rate: 0.00453058
	LOSS [training: 0.16738322867624977 | validation: 0.3111558543246018]
	TIME [epoch: 6.03 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18110852902036972		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 0.18110852902036972 | validation: 0.2930280978227673]
	TIME [epoch: 6.03 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v9_20240712_133637/states/model_facs_v2_dec2b_2dpca_v9_220.pth
	Model improved!!!
EPOCH 221/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17817293841849707		[learning rate: 0.0044906]
	Learning Rate: 0.00449063
	LOSS [training: 0.17817293841849707 | validation: 0.2999405379486172]
	TIME [epoch: 6.04 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1972319187305796		[learning rate: 0.0044708]
	Learning Rate: 0.00447079
	LOSS [training: 0.1972319187305796 | validation: 0.3098189616631055]
	TIME [epoch: 6.03 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1930760033954208		[learning rate: 0.004451]
	Learning Rate: 0.00445104
	LOSS [training: 0.1930760033954208 | validation: 0.32150653245546434]
	TIME [epoch: 6.03 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18170020544003546		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 0.18170020544003546 | validation: 0.4007132068192821]
	TIME [epoch: 6.02 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18541029004588977		[learning rate: 0.0044118]
	Learning Rate: 0.0044118
	LOSS [training: 0.18541029004588977 | validation: 0.3328148528521759]
	TIME [epoch: 6.02 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17373692808868357		[learning rate: 0.0043923]
	Learning Rate: 0.0043923
	LOSS [training: 0.17373692808868357 | validation: 0.31260663245318576]
	TIME [epoch: 6.03 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17863125685014394		[learning rate: 0.0043729]
	Learning Rate: 0.0043729
	LOSS [training: 0.17863125685014394 | validation: 0.35493182181153293]
	TIME [epoch: 6.05 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1811441938619063		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 0.1811441938619063 | validation: 0.30906620888529673]
	TIME [epoch: 6.03 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17811497174201668		[learning rate: 0.0043343]
	Learning Rate: 0.00433434
	LOSS [training: 0.17811497174201668 | validation: 0.3795087384485889]
	TIME [epoch: 6.02 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2065365166500268		[learning rate: 0.0043152]
	Learning Rate: 0.00431519
	LOSS [training: 0.2065365166500268 | validation: 0.30951890809141713]
	TIME [epoch: 6.02 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17958555672475462		[learning rate: 0.0042961]
	Learning Rate: 0.00429612
	LOSS [training: 0.17958555672475462 | validation: 0.3321159488185294]
	TIME [epoch: 6.02 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18077544809564883		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 0.18077544809564883 | validation: 0.29459264429666754]
	TIME [epoch: 6.03 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17860762052194795		[learning rate: 0.0042582]
	Learning Rate: 0.00425825
	LOSS [training: 0.17860762052194795 | validation: 0.2902553800163845]
	TIME [epoch: 6.03 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v9_20240712_133637/states/model_facs_v2_dec2b_2dpca_v9_233.pth
	Model improved!!!
EPOCH 234/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1705820936245768		[learning rate: 0.0042394]
	Learning Rate: 0.00423943
	LOSS [training: 0.1705820936245768 | validation: 0.30051800400150197]
	TIME [epoch: 6.04 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17692372380513008		[learning rate: 0.0042207]
	Learning Rate: 0.0042207
	LOSS [training: 0.17692372380513008 | validation: 0.30583953375475265]
	TIME [epoch: 6.03 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1848535315961436		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 0.1848535315961436 | validation: 0.32990013703184284]
	TIME [epoch: 6.03 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17886691271122707		[learning rate: 0.0041835]
	Learning Rate: 0.00418349
	LOSS [training: 0.17886691271122707 | validation: 0.4147847327448649]
	TIME [epoch: 6.04 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18176523948588771		[learning rate: 0.004165]
	Learning Rate: 0.004165
	LOSS [training: 0.18176523948588771 | validation: 0.3158885719602413]
	TIME [epoch: 6.03 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17850211302880695		[learning rate: 0.0041466]
	Learning Rate: 0.0041466
	LOSS [training: 0.17850211302880695 | validation: 0.3666033091423513]
	TIME [epoch: 6.03 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18076613128245192		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 0.18076613128245192 | validation: 0.33538511886770744]
	TIME [epoch: 6.03 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19638850418850115		[learning rate: 0.00411]
	Learning Rate: 0.00411004
	LOSS [training: 0.19638850418850115 | validation: 0.2951799953470968]
	TIME [epoch: 6.04 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19160645569725354		[learning rate: 0.0040919]
	Learning Rate: 0.00409188
	LOSS [training: 0.19160645569725354 | validation: 0.3542995334955561]
	TIME [epoch: 6.04 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1804495782407788		[learning rate: 0.0040738]
	Learning Rate: 0.0040738
	LOSS [training: 0.1804495782407788 | validation: 0.3211034717420462]
	TIME [epoch: 6.04 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18780444521135656		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.18780444521135656 | validation: 0.3043411419429037]
	TIME [epoch: 6.02 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17391114524833237		[learning rate: 0.0040379]
	Learning Rate: 0.00403788
	LOSS [training: 0.17391114524833237 | validation: 0.33374153132365764]
	TIME [epoch: 6.03 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1934062475968577		[learning rate: 0.00402]
	Learning Rate: 0.00402004
	LOSS [training: 0.1934062475968577 | validation: 0.4143084731193493]
	TIME [epoch: 6.03 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18965027308499638		[learning rate: 0.0040023]
	Learning Rate: 0.00400228
	LOSS [training: 0.18965027308499638 | validation: 0.3137016302488207]
	TIME [epoch: 6.03 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16955570289413352		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 0.16955570289413352 | validation: 0.30525592550358477]
	TIME [epoch: 6.03 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17434630986152932		[learning rate: 0.003967]
	Learning Rate: 0.00396699
	LOSS [training: 0.17434630986152932 | validation: 0.3560941882584931]
	TIME [epoch: 6.04 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1751492035564573		[learning rate: 0.0039495]
	Learning Rate: 0.00394947
	LOSS [training: 0.1751492035564573 | validation: 0.3094887684978455]
	TIME [epoch: 6.03 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17768863836406407		[learning rate: 0.003932]
	Learning Rate: 0.00393202
	LOSS [training: 0.17768863836406407 | validation: 0.29158087626317736]
	TIME [epoch: 6.03 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17870415664394262		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 0.17870415664394262 | validation: 0.30960741030261585]
	TIME [epoch: 6.03 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18057156977729874		[learning rate: 0.0038973]
	Learning Rate: 0.00389735
	LOSS [training: 0.18057156977729874 | validation: 0.3046802892371024]
	TIME [epoch: 6.03 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17165258944991457		[learning rate: 0.0038801]
	Learning Rate: 0.00388013
	LOSS [training: 0.17165258944991457 | validation: 0.30195893479416325]
	TIME [epoch: 6.03 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17980702659478737		[learning rate: 0.003863]
	Learning Rate: 0.00386299
	LOSS [training: 0.17980702659478737 | validation: 0.29725219075948023]
	TIME [epoch: 6.03 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17339669227618287		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 0.17339669227618287 | validation: 0.30338834021061234]
	TIME [epoch: 6.03 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17579641800011714		[learning rate: 0.0038289]
	Learning Rate: 0.00382893
	LOSS [training: 0.17579641800011714 | validation: 0.3148521501168421]
	TIME [epoch: 6.04 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17335846870008326		[learning rate: 0.003812]
	Learning Rate: 0.00381201
	LOSS [training: 0.17335846870008326 | validation: 0.3084120462970457]
	TIME [epoch: 6.03 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18038199273982192		[learning rate: 0.0037952]
	Learning Rate: 0.00379517
	LOSS [training: 0.18038199273982192 | validation: 0.33287172650979924]
	TIME [epoch: 6.03 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17585178825054576		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 0.17585178825054576 | validation: 0.30736728754876075]
	TIME [epoch: 6.03 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16307891272307415		[learning rate: 0.0037617]
	Learning Rate: 0.0037617
	LOSS [training: 0.16307891272307415 | validation: 0.3067571783425215]
	TIME [epoch: 6.03 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16530298544883806		[learning rate: 0.0037451]
	Learning Rate: 0.00374508
	LOSS [training: 0.16530298544883806 | validation: 0.32326409354615254]
	TIME [epoch: 6.03 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.178293743772524		[learning rate: 0.0037285]
	Learning Rate: 0.00372854
	LOSS [training: 0.178293743772524 | validation: 0.3198298390649365]
	TIME [epoch: 6.03 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.172723506905		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 0.172723506905 | validation: 0.32473237136777994]
	TIME [epoch: 6.04 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17355948730481968		[learning rate: 0.0036957]
	Learning Rate: 0.00369566
	LOSS [training: 0.17355948730481968 | validation: 0.30519576145094013]
	TIME [epoch: 6.03 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1782467398371719		[learning rate: 0.0036793]
	Learning Rate: 0.00367933
	LOSS [training: 0.1782467398371719 | validation: 0.31020602909978673]
	TIME [epoch: 6.03 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17414262198015468		[learning rate: 0.0036631]
	Learning Rate: 0.00366308
	LOSS [training: 0.17414262198015468 | validation: 0.3295723335189092]
	TIME [epoch: 6.03 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1650002231076207		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 0.1650002231076207 | validation: 0.33901451000431837]
	TIME [epoch: 6.03 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17108121733775875		[learning rate: 0.0036308]
	Learning Rate: 0.00363078
	LOSS [training: 0.17108121733775875 | validation: 0.3100279069059864]
	TIME [epoch: 6.03 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16715796297430147		[learning rate: 0.0036147]
	Learning Rate: 0.00361474
	LOSS [training: 0.16715796297430147 | validation: 0.3384070997644676]
	TIME [epoch: 6.03 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17663479067037832		[learning rate: 0.0035988]
	Learning Rate: 0.00359877
	LOSS [training: 0.17663479067037832 | validation: 0.31439065555884543]
	TIME [epoch: 6.03 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1729520816420235		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 0.1729520816420235 | validation: 0.32215521164307676]
	TIME [epoch: 6.04 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17970549537190547		[learning rate: 0.003567]
	Learning Rate: 0.00356704
	LOSS [training: 0.17970549537190547 | validation: 0.29455707236356704]
	TIME [epoch: 6.03 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16773293656605062		[learning rate: 0.0035513]
	Learning Rate: 0.00355128
	LOSS [training: 0.16773293656605062 | validation: 0.3014156339036078]
	TIME [epoch: 6.03 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17108588423259308		[learning rate: 0.0035356]
	Learning Rate: 0.00353559
	LOSS [training: 0.17108588423259308 | validation: 0.2988533213692328]
	TIME [epoch: 6.03 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16931513889043304		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 0.16931513889043304 | validation: 0.3538471314557536]
	TIME [epoch: 6.03 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18291383131749178		[learning rate: 0.0035044]
	Learning Rate: 0.00350441
	LOSS [training: 0.18291383131749178 | validation: 0.35836906191985557]
	TIME [epoch: 6.03 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18152259435811116		[learning rate: 0.0034889]
	Learning Rate: 0.00348893
	LOSS [training: 0.18152259435811116 | validation: 0.3059369303101283]
	TIME [epoch: 6.03 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1718161443801945		[learning rate: 0.0034735]
	Learning Rate: 0.00347352
	LOSS [training: 0.1718161443801945 | validation: 0.3018857076762344]
	TIME [epoch: 6.04 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16515792924563336		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.16515792924563336 | validation: 0.3055804216141975]
	TIME [epoch: 6.03 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17854049334404118		[learning rate: 0.0034429]
	Learning Rate: 0.00344289
	LOSS [training: 0.17854049334404118 | validation: 0.3164144197507675]
	TIME [epoch: 6.03 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1686413734807857		[learning rate: 0.0034277]
	Learning Rate: 0.00342768
	LOSS [training: 0.1686413734807857 | validation: 0.3136753204291136]
	TIME [epoch: 6.03 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17639551460503028		[learning rate: 0.0034125]
	Learning Rate: 0.00341253
	LOSS [training: 0.17639551460503028 | validation: 0.3047174476753748]
	TIME [epoch: 6.03 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16960845859875853		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 0.16960845859875853 | validation: 0.3159270802551318]
	TIME [epoch: 6.04 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1740041292906128		[learning rate: 0.0033824]
	Learning Rate: 0.00338245
	LOSS [training: 0.1740041292906128 | validation: 0.2812797211149469]
	TIME [epoch: 6.04 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v9_20240712_133637/states/model_facs_v2_dec2b_2dpca_v9_285.pth
	Model improved!!!
EPOCH 286/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1698560226434714		[learning rate: 0.0033675]
	Learning Rate: 0.0033675
	LOSS [training: 0.1698560226434714 | validation: 0.30230306636850907]
	TIME [epoch: 6.04 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16571339968753435		[learning rate: 0.0033526]
	Learning Rate: 0.00335262
	LOSS [training: 0.16571339968753435 | validation: 0.31947496326596825]
	TIME [epoch: 6.05 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16779015798897312		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 0.16779015798897312 | validation: 0.31366142590595264]
	TIME [epoch: 6.04 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16844612268080844		[learning rate: 0.0033231]
	Learning Rate: 0.00332306
	LOSS [training: 0.16844612268080844 | validation: 0.3515250572570578]
	TIME [epoch: 6.04 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17193877363206936		[learning rate: 0.0033084]
	Learning Rate: 0.00330838
	LOSS [training: 0.17193877363206936 | validation: 0.30922463460125227]
	TIME [epoch: 6.04 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1666569019259597		[learning rate: 0.0032938]
	Learning Rate: 0.00329376
	LOSS [training: 0.1666569019259597 | validation: 0.3120761848562653]
	TIME [epoch: 6.04 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16857709097481263		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 0.16857709097481263 | validation: 0.3104114760538259]
	TIME [epoch: 6.03 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16631514614470175		[learning rate: 0.0032647]
	Learning Rate: 0.00326472
	LOSS [training: 0.16631514614470175 | validation: 0.3358216554955593]
	TIME [epoch: 6.03 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16705795323662015		[learning rate: 0.0032503]
	Learning Rate: 0.0032503
	LOSS [training: 0.16705795323662015 | validation: 0.3045454055940774]
	TIME [epoch: 6.05 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16835977678373654		[learning rate: 0.0032359]
	Learning Rate: 0.00323594
	LOSS [training: 0.16835977678373654 | validation: 0.30276737851787217]
	TIME [epoch: 6.04 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16674443912961295		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 0.16674443912961295 | validation: 0.2889005672208539]
	TIME [epoch: 6.03 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16895147530899074		[learning rate: 0.0032074]
	Learning Rate: 0.00320741
	LOSS [training: 0.16895147530899074 | validation: 0.34996051401383255]
	TIME [epoch: 6.03 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16963323004362837		[learning rate: 0.0031932]
	Learning Rate: 0.00319323
	LOSS [training: 0.16963323004362837 | validation: 0.3188220214420364]
	TIME [epoch: 6.03 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17534261203987203		[learning rate: 0.0031791]
	Learning Rate: 0.00317913
	LOSS [training: 0.17534261203987203 | validation: 0.30915219487434115]
	TIME [epoch: 6.03 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1626834008706898		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 0.1626834008706898 | validation: 0.301160971466262]
	TIME [epoch: 6.03 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1705378982228601		[learning rate: 0.0031511]
	Learning Rate: 0.0031511
	LOSS [training: 0.1705378982228601 | validation: 0.3168588815675022]
	TIME [epoch: 6.03 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17120609223516245		[learning rate: 0.0031372]
	Learning Rate: 0.00313717
	LOSS [training: 0.17120609223516245 | validation: 0.3365746891865377]
	TIME [epoch: 6.03 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16527424585826894		[learning rate: 0.0031233]
	Learning Rate: 0.00312331
	LOSS [training: 0.16527424585826894 | validation: 0.3651854440418937]
	TIME [epoch: 6.03 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17279988761988033		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 0.17279988761988033 | validation: 0.35592558069453184]
	TIME [epoch: 6.03 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1877661502732732		[learning rate: 0.0030958]
	Learning Rate: 0.00309577
	LOSS [training: 0.1877661502732732 | validation: 0.32080184848469373]
	TIME [epoch: 6.03 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1707383592388317		[learning rate: 0.0030821]
	Learning Rate: 0.0030821
	LOSS [training: 0.1707383592388317 | validation: 0.3149478666241774]
	TIME [epoch: 6.03 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1668114406427356		[learning rate: 0.0030685]
	Learning Rate: 0.00306848
	LOSS [training: 0.1668114406427356 | validation: 0.3149605649362865]
	TIME [epoch: 6.03 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16689326112035194		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 0.16689326112035194 | validation: 0.33983413942113405]
	TIME [epoch: 6.03 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17373021629478272		[learning rate: 0.0030414]
	Learning Rate: 0.00304142
	LOSS [training: 0.17373021629478272 | validation: 0.29037083599938546]
	TIME [epoch: 6.04 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1737636187649845		[learning rate: 0.003028]
	Learning Rate: 0.00302799
	LOSS [training: 0.1737636187649845 | validation: 0.31744165568673494]
	TIME [epoch: 6.03 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16777543610395793		[learning rate: 0.0030146]
	Learning Rate: 0.00301461
	LOSS [training: 0.16777543610395793 | validation: 0.35142766124200076]
	TIME [epoch: 6.04 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1732957637062832		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 0.1732957637062832 | validation: 0.3101617807964209]
	TIME [epoch: 6.04 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17096280165103067		[learning rate: 0.002988]
	Learning Rate: 0.00298803
	LOSS [training: 0.17096280165103067 | validation: 0.29628687418664573]
	TIME [epoch: 6.04 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.162899798799354		[learning rate: 0.0029748]
	Learning Rate: 0.00297483
	LOSS [training: 0.162899798799354 | validation: 0.2828027448320898]
	TIME [epoch: 6.03 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16552945322990684		[learning rate: 0.0029617]
	Learning Rate: 0.00296168
	LOSS [training: 0.16552945322990684 | validation: 0.3147016768823695]
	TIME [epoch: 6.03 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16612385445393765		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.16612385445393765 | validation: 0.3348828467692808]
	TIME [epoch: 6.04 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17168972618781916		[learning rate: 0.0029356]
	Learning Rate: 0.00293557
	LOSS [training: 0.17168972618781916 | validation: 0.3244734916327113]
	TIME [epoch: 6.04 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16887319444329602		[learning rate: 0.0029226]
	Learning Rate: 0.0029226
	LOSS [training: 0.16887319444329602 | validation: 0.30092764608221784]
	TIME [epoch: 6.03 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16695951445767468		[learning rate: 0.0029097]
	Learning Rate: 0.00290969
	LOSS [training: 0.16695951445767468 | validation: 0.3170265336643457]
	TIME [epoch: 6.03 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16427812280355117		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 0.16427812280355117 | validation: 0.3182544117073012]
	TIME [epoch: 6.03 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1713945304045001		[learning rate: 0.002884]
	Learning Rate: 0.00288403
	LOSS [training: 0.1713945304045001 | validation: 0.30605444892875433]
	TIME [epoch: 6.03 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17517165517933447		[learning rate: 0.0028713]
	Learning Rate: 0.00287129
	LOSS [training: 0.17517165517933447 | validation: 0.3079697686695897]
	TIME [epoch: 6.04 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1669763414508993		[learning rate: 0.0028586]
	Learning Rate: 0.0028586
	LOSS [training: 0.1669763414508993 | validation: 0.2977083343308774]
	TIME [epoch: 6.03 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17006914578724516		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 0.17006914578724516 | validation: 0.29576037736533894]
	TIME [epoch: 6.04 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17501349625970905		[learning rate: 0.0028334]
	Learning Rate: 0.0028334
	LOSS [training: 0.17501349625970905 | validation: 0.32700084379293587]
	TIME [epoch: 6.03 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16400423042251755		[learning rate: 0.0028209]
	Learning Rate: 0.00282088
	LOSS [training: 0.16400423042251755 | validation: 0.33116699169357794]
	TIME [epoch: 6.02 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1663017754880134		[learning rate: 0.0028084]
	Learning Rate: 0.00280842
	LOSS [training: 0.1663017754880134 | validation: 0.3181429622007066]
	TIME [epoch: 6.03 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16266954596437877		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 0.16266954596437877 | validation: 0.3203418491205173]
	TIME [epoch: 6.03 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17465790682001797		[learning rate: 0.0027837]
	Learning Rate: 0.00278366
	LOSS [training: 0.17465790682001797 | validation: 0.2943896876109957]
	TIME [epoch: 6.03 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1671466054453607		[learning rate: 0.0027714]
	Learning Rate: 0.00277136
	LOSS [training: 0.1671466054453607 | validation: 0.30879681124126374]
	TIME [epoch: 6.03 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16649940623835974		[learning rate: 0.0027591]
	Learning Rate: 0.00275911
	LOSS [training: 0.16649940623835974 | validation: 0.3322032005477338]
	TIME [epoch: 6.03 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16521428350864908		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 0.16521428350864908 | validation: 0.31635340443776316]
	TIME [epoch: 6.03 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16123486303234985		[learning rate: 0.0027348]
	Learning Rate: 0.00273478
	LOSS [training: 0.16123486303234985 | validation: 0.27764694223968417]
	TIME [epoch: 6.03 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v9_20240712_133637/states/model_facs_v2_dec2b_2dpca_v9_333.pth
	Model improved!!!
EPOCH 334/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16668563494191818		[learning rate: 0.0027227]
	Learning Rate: 0.0027227
	LOSS [training: 0.16668563494191818 | validation: 0.29546345112957484]
	TIME [epoch: 6.03 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16158888314342226		[learning rate: 0.0027107]
	Learning Rate: 0.00271067
	LOSS [training: 0.16158888314342226 | validation: 0.3015885110603126]
	TIME [epoch: 6.02 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1715028063219537		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 0.1715028063219537 | validation: 0.30848261940216476]
	TIME [epoch: 6.02 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16608592492489277		[learning rate: 0.0026868]
	Learning Rate: 0.00268677
	LOSS [training: 0.16608592492489277 | validation: 0.31196879578197645]
	TIME [epoch: 6.03 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16796345684665387		[learning rate: 0.0026749]
	Learning Rate: 0.0026749
	LOSS [training: 0.16796345684665387 | validation: 0.30556906628697184]
	TIME [epoch: 6.02 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1660206866498678		[learning rate: 0.0026631]
	Learning Rate: 0.00266308
	LOSS [training: 0.1660206866498678 | validation: 0.29598362619844754]
	TIME [epoch: 6.04 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16279355599338072		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 0.16279355599338072 | validation: 0.30486653257243523]
	TIME [epoch: 6.03 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16786126700255896		[learning rate: 0.0026396]
	Learning Rate: 0.0026396
	LOSS [training: 0.16786126700255896 | validation: 0.31615890790625223]
	TIME [epoch: 6.03 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1598988790476789		[learning rate: 0.0026279]
	Learning Rate: 0.00262794
	LOSS [training: 0.1598988790476789 | validation: 0.30999252043359216]
	TIME [epoch: 6.03 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16516281249848264		[learning rate: 0.0026163]
	Learning Rate: 0.00261633
	LOSS [training: 0.16516281249848264 | validation: 0.31947203509772193]
	TIME [epoch: 6.03 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16519698285412546		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 0.16519698285412546 | validation: 0.31459510778422123]
	TIME [epoch: 6.03 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16339726615466904		[learning rate: 0.0025933]
	Learning Rate: 0.00259326
	LOSS [training: 0.16339726615466904 | validation: 0.30659701401860057]
	TIME [epoch: 6.04 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16469481472387876		[learning rate: 0.0025818]
	Learning Rate: 0.0025818
	LOSS [training: 0.16469481472387876 | validation: 0.3153777568372233]
	TIME [epoch: 6.03 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15872591593866764		[learning rate: 0.0025704]
	Learning Rate: 0.0025704
	LOSS [training: 0.15872591593866764 | validation: 0.3000227576023413]
	TIME [epoch: 6.04 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1645605327445044		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.1645605327445044 | validation: 0.29955090442098226]
	TIME [epoch: 6.03 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16506294759669013		[learning rate: 0.0025477]
	Learning Rate: 0.00254773
	LOSS [training: 0.16506294759669013 | validation: 0.29490561625134565]
	TIME [epoch: 6.03 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1641612531189559		[learning rate: 0.0025365]
	Learning Rate: 0.00253648
	LOSS [training: 0.1641612531189559 | validation: 0.32492151134412084]
	TIME [epoch: 6.03 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16969644677147638		[learning rate: 0.0025253]
	Learning Rate: 0.00252527
	LOSS [training: 0.16969644677147638 | validation: 0.30673023540029415]
	TIME [epoch: 6.03 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16650096224137098		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.16650096224137098 | validation: 0.28643892469032384]
	TIME [epoch: 6.03 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16679763130982123		[learning rate: 0.002503]
	Learning Rate: 0.002503
	LOSS [training: 0.16679763130982123 | validation: 0.32672866131125805]
	TIME [epoch: 6.03 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16533728158931063		[learning rate: 0.0024919]
	Learning Rate: 0.00249194
	LOSS [training: 0.16533728158931063 | validation: 0.3019667047414921]
	TIME [epoch: 6.03 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16364414459930376		[learning rate: 0.0024809]
	Learning Rate: 0.00248093
	LOSS [training: 0.16364414459930376 | validation: 0.3004322814789159]
	TIME [epoch: 6.03 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1595986078503019		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 0.1595986078503019 | validation: 0.30355837994090185]
	TIME [epoch: 6.03 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.159713030400458		[learning rate: 0.0024591]
	Learning Rate: 0.00245906
	LOSS [training: 0.159713030400458 | validation: 0.30167903736183227]
	TIME [epoch: 6.03 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16328591466308529		[learning rate: 0.0024482]
	Learning Rate: 0.0024482
	LOSS [training: 0.16328591466308529 | validation: 0.3571509668225989]
	TIME [epoch: 6.04 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16172995320758574		[learning rate: 0.0024374]
	Learning Rate: 0.00243738
	LOSS [training: 0.16172995320758574 | validation: 0.2911535412332265]
	TIME [epoch: 6.03 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.166611150878175		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.166611150878175 | validation: 0.29707707011626994]
	TIME [epoch: 6.04 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.165375809170123		[learning rate: 0.0024159]
	Learning Rate: 0.00241589
	LOSS [training: 0.165375809170123 | validation: 0.3399046857311644]
	TIME [epoch: 6.04 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1720254551431881		[learning rate: 0.0024052]
	Learning Rate: 0.00240521
	LOSS [training: 0.1720254551431881 | validation: 0.30503864127707364]
	TIME [epoch: 6.05 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1567604196979649		[learning rate: 0.0023946]
	Learning Rate: 0.00239459
	LOSS [training: 0.1567604196979649 | validation: 0.3049958581030055]
	TIME [epoch: 6.04 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1586438867081962		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 0.1586438867081962 | validation: 0.28712527453776276]
	TIME [epoch: 6.03 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16437898766709447		[learning rate: 0.0023735]
	Learning Rate: 0.00237347
	LOSS [training: 0.16437898766709447 | validation: 0.3123009161529493]
	TIME [epoch: 6.03 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1658302174006594		[learning rate: 0.002363]
	Learning Rate: 0.00236299
	LOSS [training: 0.1658302174006594 | validation: 0.3406607875311739]
	TIME [epoch: 6.02 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15915855479212376		[learning rate: 0.0023525]
	Learning Rate: 0.00235255
	LOSS [training: 0.15915855479212376 | validation: 0.2884802031765269]
	TIME [epoch: 6.03 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16738107194326252		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.16738107194326252 | validation: 0.3013017115216944]
	TIME [epoch: 6.03 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15779220532388202		[learning rate: 0.0023318]
	Learning Rate: 0.00233181
	LOSS [training: 0.15779220532388202 | validation: 0.30606648955228766]
	TIME [epoch: 6.04 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16625857649062378		[learning rate: 0.0023215]
	Learning Rate: 0.0023215
	LOSS [training: 0.16625857649062378 | validation: 0.2967783437222596]
	TIME [epoch: 6.03 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15989119767310375		[learning rate: 0.0023112]
	Learning Rate: 0.00231125
	LOSS [training: 0.15989119767310375 | validation: 0.30382056332193164]
	TIME [epoch: 6.03 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15972912343940576		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.15972912343940576 | validation: 0.28972212142714127]
	TIME [epoch: 6.03 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16477202212690556		[learning rate: 0.0022909]
	Learning Rate: 0.00229087
	LOSS [training: 0.16477202212690556 | validation: 0.32735180862768387]
	TIME [epoch: 6.03 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16238016224820648		[learning rate: 0.0022807]
	Learning Rate: 0.00228075
	LOSS [training: 0.16238016224820648 | validation: 0.30274993828882013]
	TIME [epoch: 6.03 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16364502585283341		[learning rate: 0.0022707]
	Learning Rate: 0.00227067
	LOSS [training: 0.16364502585283341 | validation: 0.2868095349831705]
	TIME [epoch: 6.03 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1634918551403431		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.1634918551403431 | validation: 0.28740730244685847]
	TIME [epoch: 6.03 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15650215724376512		[learning rate: 0.0022506]
	Learning Rate: 0.00225065
	LOSS [training: 0.15650215724376512 | validation: 0.3076773975526643]
	TIME [epoch: 6.03 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1638358603285241		[learning rate: 0.0022407]
	Learning Rate: 0.0022407
	LOSS [training: 0.1638358603285241 | validation: 0.3206970867332207]
	TIME [epoch: 6.03 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16316688353343756		[learning rate: 0.0022308]
	Learning Rate: 0.0022308
	LOSS [training: 0.16316688353343756 | validation: 0.32552354576174825]
	TIME [epoch: 6.02 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16056105634785262		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.16056105634785262 | validation: 0.31550119223308243]
	TIME [epoch: 6.03 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16331557819617848		[learning rate: 0.0022111]
	Learning Rate: 0.00221114
	LOSS [training: 0.16331557819617848 | validation: 0.34093674515275785]
	TIME [epoch: 6.02 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1642512049774431		[learning rate: 0.0022014]
	Learning Rate: 0.00220137
	LOSS [training: 0.1642512049774431 | validation: 0.3483443606481899]
	TIME [epoch: 6.03 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1611732911973374		[learning rate: 0.0021916]
	Learning Rate: 0.00219164
	LOSS [training: 0.1611732911973374 | validation: 0.2994885076992008]
	TIME [epoch: 6.03 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15734705880880048		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.15734705880880048 | validation: 0.29931007634081563]
	TIME [epoch: 6.04 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1606304187859349		[learning rate: 0.0021723]
	Learning Rate: 0.00217232
	LOSS [training: 0.1606304187859349 | validation: 0.31689038951077736]
	TIME [epoch: 6.03 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16089445671571373		[learning rate: 0.0021627]
	Learning Rate: 0.00216272
	LOSS [training: 0.16089445671571373 | validation: 0.3254363055115457]
	TIME [epoch: 6.03 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16189733850520618		[learning rate: 0.0021532]
	Learning Rate: 0.00215316
	LOSS [training: 0.16189733850520618 | validation: 0.3073434542831011]
	TIME [epoch: 6.03 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1505297215210387		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.1505297215210387 | validation: 0.29564247563943996]
	TIME [epoch: 6.03 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16033902599874145		[learning rate: 0.0021342]
	Learning Rate: 0.00213418
	LOSS [training: 0.16033902599874145 | validation: 0.2936467008671653]
	TIME [epoch: 6.03 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16970249389026434		[learning rate: 0.0021247]
	Learning Rate: 0.00212475
	LOSS [training: 0.16970249389026434 | validation: 0.2885249867791874]
	TIME [epoch: 6.03 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16204468071807004		[learning rate: 0.0021154]
	Learning Rate: 0.00211536
	LOSS [training: 0.16204468071807004 | validation: 0.3020334177061681]
	TIME [epoch: 6.04 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15594138156199722		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.15594138156199722 | validation: 0.3106907648454107]
	TIME [epoch: 6.03 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1602959395476367		[learning rate: 0.0020967]
	Learning Rate: 0.00209671
	LOSS [training: 0.1602959395476367 | validation: 0.2947071593516728]
	TIME [epoch: 6.03 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.156249257180132		[learning rate: 0.0020874]
	Learning Rate: 0.00208745
	LOSS [training: 0.156249257180132 | validation: 0.28450131451938765]
	TIME [epoch: 6.06 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1603958102099576		[learning rate: 0.0020782]
	Learning Rate: 0.00207822
	LOSS [training: 0.1603958102099576 | validation: 0.3209956212841374]
	TIME [epoch: 6.03 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16144446078589458		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.16144446078589458 | validation: 0.32682686453813875]
	TIME [epoch: 6.05 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16514351751090744		[learning rate: 0.0020599]
	Learning Rate: 0.0020599
	LOSS [training: 0.16514351751090744 | validation: 0.3173599459594136]
	TIME [epoch: 6.03 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1545777658293255		[learning rate: 0.0020508]
	Learning Rate: 0.0020508
	LOSS [training: 0.1545777658293255 | validation: 0.3008608608056582]
	TIME [epoch: 6.03 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16092769691487926		[learning rate: 0.0020417]
	Learning Rate: 0.00204174
	LOSS [training: 0.16092769691487926 | validation: 0.2862082571333623]
	TIME [epoch: 6.04 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1575784337829516		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.1575784337829516 | validation: 0.3064875306956963]
	TIME [epoch: 6.03 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15721473121060744		[learning rate: 0.0020237]
	Learning Rate: 0.00202374
	LOSS [training: 0.15721473121060744 | validation: 0.28684782841131257]
	TIME [epoch: 6.04 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16209754688723896		[learning rate: 0.0020148]
	Learning Rate: 0.00201479
	LOSS [training: 0.16209754688723896 | validation: 0.28828204132424434]
	TIME [epoch: 6.04 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16019491733330896		[learning rate: 0.0020059]
	Learning Rate: 0.00200589
	LOSS [training: 0.16019491733330896 | validation: 0.3149756664866471]
	TIME [epoch: 6.03 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16523084173260744		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.16523084173260744 | validation: 0.27774367281684176]
	TIME [epoch: 6.04 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15879963754466683		[learning rate: 0.0019882]
	Learning Rate: 0.00198821
	LOSS [training: 0.15879963754466683 | validation: 0.30606043471224276]
	TIME [epoch: 6.03 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15489790525319572		[learning rate: 0.0019794]
	Learning Rate: 0.00197942
	LOSS [training: 0.15489790525319572 | validation: 0.2948612620806476]
	TIME [epoch: 6.05 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1596646445595632		[learning rate: 0.0019707]
	Learning Rate: 0.00197068
	LOSS [training: 0.1596646445595632 | validation: 0.2770560171273059]
	TIME [epoch: 6.03 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v9_20240712_133637/states/model_facs_v2_dec2b_2dpca_v9_407.pth
	Model improved!!!
EPOCH 408/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16395708018654326		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.16395708018654326 | validation: 0.2919983043569058]
	TIME [epoch: 6.05 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1617590713956053		[learning rate: 0.0019533]
	Learning Rate: 0.0019533
	LOSS [training: 0.1617590713956053 | validation: 0.29322038567173]
	TIME [epoch: 6.04 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15899021416265802		[learning rate: 0.0019447]
	Learning Rate: 0.00194467
	LOSS [training: 0.15899021416265802 | validation: 0.30022143968504567]
	TIME [epoch: 6.04 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1638257598969208		[learning rate: 0.0019361]
	Learning Rate: 0.00193608
	LOSS [training: 0.1638257598969208 | validation: 0.28242156140634755]
	TIME [epoch: 6.05 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15826486813648616		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.15826486813648616 | validation: 0.30104550183736895]
	TIME [epoch: 6.04 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15942431331402662		[learning rate: 0.001919]
	Learning Rate: 0.00191901
	LOSS [training: 0.15942431331402662 | validation: 0.29893668553108477]
	TIME [epoch: 6.04 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16412324738360495		[learning rate: 0.0019105]
	Learning Rate: 0.00191053
	LOSS [training: 0.16412324738360495 | validation: 0.29204298361096387]
	TIME [epoch: 6.05 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1606877899194411		[learning rate: 0.0019021]
	Learning Rate: 0.00190209
	LOSS [training: 0.1606877899194411 | validation: 0.2802794587681931]
	TIME [epoch: 6.04 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15994349538617203		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.15994349538617203 | validation: 0.3068579642166029]
	TIME [epoch: 6.03 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15759971672758702		[learning rate: 0.0018853]
	Learning Rate: 0.00188532
	LOSS [training: 0.15759971672758702 | validation: 0.32625489080353787]
	TIME [epoch: 6.03 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16454924231895113		[learning rate: 0.001877]
	Learning Rate: 0.00187699
	LOSS [training: 0.16454924231895113 | validation: 0.2892661711754011]
	TIME [epoch: 6.03 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15643981290361353		[learning rate: 0.0018687]
	Learning Rate: 0.0018687
	LOSS [training: 0.15643981290361353 | validation: 0.32637708334258964]
	TIME [epoch: 6.03 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1565188435800164		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.1565188435800164 | validation: 0.31113044317272337]
	TIME [epoch: 6.03 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16072938741138837		[learning rate: 0.0018522]
	Learning Rate: 0.00185222
	LOSS [training: 0.16072938741138837 | validation: 0.2935936759605063]
	TIME [epoch: 6.04 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15632800936258096		[learning rate: 0.001844]
	Learning Rate: 0.00184404
	LOSS [training: 0.15632800936258096 | validation: 0.2830254576920007]
	TIME [epoch: 6.04 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16173914145778967		[learning rate: 0.0018359]
	Learning Rate: 0.00183589
	LOSS [training: 0.16173914145778967 | validation: 0.29745844360089596]
	TIME [epoch: 6.03 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1569864739799754		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.1569864739799754 | validation: 0.3221102988078146]
	TIME [epoch: 6.03 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15606950283604853		[learning rate: 0.0018197]
	Learning Rate: 0.0018197
	LOSS [training: 0.15606950283604853 | validation: 0.3116288364516316]
	TIME [epoch: 6.03 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15549931909784517		[learning rate: 0.0018117]
	Learning Rate: 0.00181166
	LOSS [training: 0.15549931909784517 | validation: 0.29278546626394]
	TIME [epoch: 6.03 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15251527633247583		[learning rate: 0.0018037]
	Learning Rate: 0.00180366
	LOSS [training: 0.15251527633247583 | validation: 0.29118811140144635]
	TIME [epoch: 6.03 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15275622487197305		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.15275622487197305 | validation: 0.31450500938186393]
	TIME [epoch: 6.03 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1608489400543776		[learning rate: 0.0017878]
	Learning Rate: 0.00178775
	LOSS [training: 0.1608489400543776 | validation: 0.29894333492465336]
	TIME [epoch: 6.04 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.160588688621445		[learning rate: 0.0017799]
	Learning Rate: 0.00177985
	LOSS [training: 0.160588688621445 | validation: 0.3023034865267018]
	TIME [epoch: 6.03 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15553233353099002		[learning rate: 0.001772]
	Learning Rate: 0.00177199
	LOSS [training: 0.15553233353099002 | validation: 0.3316030863348684]
	TIME [epoch: 6.03 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1612118048818299		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.1612118048818299 | validation: 0.30361304669328176]
	TIME [epoch: 6.03 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15744648456855237		[learning rate: 0.0017564]
	Learning Rate: 0.00175637
	LOSS [training: 0.15744648456855237 | validation: 0.3055145019157028]
	TIME [epoch: 6.03 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1700625149696437		[learning rate: 0.0017486]
	Learning Rate: 0.00174861
	LOSS [training: 0.1700625149696437 | validation: 0.32083023920244996]
	TIME [epoch: 6.03 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15451326401001117		[learning rate: 0.0017409]
	Learning Rate: 0.00174088
	LOSS [training: 0.15451326401001117 | validation: 0.30998726558232986]
	TIME [epoch: 6.03 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1618814978986896		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.1618814978986896 | validation: 0.3221530180533479]
	TIME [epoch: 6.04 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1609695193512104		[learning rate: 0.0017255]
	Learning Rate: 0.00172553
	LOSS [training: 0.1609695193512104 | validation: 0.2845448535054714]
	TIME [epoch: 6.03 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15621272767688496		[learning rate: 0.0017179]
	Learning Rate: 0.00171791
	LOSS [training: 0.15621272767688496 | validation: 0.3193527447264986]
	TIME [epoch: 6.03 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15648194092436016		[learning rate: 0.0017103]
	Learning Rate: 0.00171032
	LOSS [training: 0.15648194092436016 | validation: 0.3105232762806084]
	TIME [epoch: 6.03 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15817512202972261		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.15817512202972261 | validation: 0.28643544192544085]
	TIME [epoch: 6.03 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15464110806371273		[learning rate: 0.0016952]
	Learning Rate: 0.00169524
	LOSS [training: 0.15464110806371273 | validation: 0.2998791445997781]
	TIME [epoch: 6.03 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15285573328096264		[learning rate: 0.0016877]
	Learning Rate: 0.00168775
	LOSS [training: 0.15285573328096264 | validation: 0.2985082297719774]
	TIME [epoch: 6.03 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16180164363450814		[learning rate: 0.0016803]
	Learning Rate: 0.00168029
	LOSS [training: 0.16180164363450814 | validation: 0.2915052251940394]
	TIME [epoch: 6.03 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1568281880198525		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.1568281880198525 | validation: 0.28526521984456843]
	TIME [epoch: 6.04 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15916401340939187		[learning rate: 0.0016655]
	Learning Rate: 0.00166548
	LOSS [training: 0.15916401340939187 | validation: 0.2819710172779982]
	TIME [epoch: 6.03 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16328226053456368		[learning rate: 0.0016581]
	Learning Rate: 0.00165812
	LOSS [training: 0.16328226053456368 | validation: 0.28672809188694526]
	TIME [epoch: 6.03 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.157468554806961		[learning rate: 0.0016508]
	Learning Rate: 0.00165079
	LOSS [training: 0.157468554806961 | validation: 0.3199727893597034]
	TIME [epoch: 6.03 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1658574242911501		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.1658574242911501 | validation: 0.3016934933066976]
	TIME [epoch: 6.03 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15883412470638733		[learning rate: 0.0016362]
	Learning Rate: 0.00163624
	LOSS [training: 0.15883412470638733 | validation: 0.29518913059651103]
	TIME [epoch: 6.03 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1606819382450826		[learning rate: 0.001629]
	Learning Rate: 0.00162901
	LOSS [training: 0.1606819382450826 | validation: 0.2954846650812082]
	TIME [epoch: 6.03 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15794953790040184		[learning rate: 0.0016218]
	Learning Rate: 0.00162181
	LOSS [training: 0.15794953790040184 | validation: 0.3075612007812213]
	TIME [epoch: 6.04 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1577010585150502		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.1577010585150502 | validation: 0.2989035389450304]
	TIME [epoch: 6.04 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15606873246241187		[learning rate: 0.0016075]
	Learning Rate: 0.00160751
	LOSS [training: 0.15606873246241187 | validation: 0.28210235880268975]
	TIME [epoch: 6.04 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16388881577925568		[learning rate: 0.0016004]
	Learning Rate: 0.00160041
	LOSS [training: 0.16388881577925568 | validation: 0.31474705827952193]
	TIME [epoch: 6.03 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16066301087065435		[learning rate: 0.0015933]
	Learning Rate: 0.00159334
	LOSS [training: 0.16066301087065435 | validation: 0.2855500168157932]
	TIME [epoch: 6.03 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15755806758182272		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.15755806758182272 | validation: 0.2963906810875176]
	TIME [epoch: 6.03 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1602268401434442		[learning rate: 0.0015793]
	Learning Rate: 0.00157929
	LOSS [training: 0.1602268401434442 | validation: 0.28777965010530976]
	TIME [epoch: 6.03 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15687898907869474		[learning rate: 0.0015723]
	Learning Rate: 0.00157231
	LOSS [training: 0.15687898907869474 | validation: 0.29176933421886275]
	TIME [epoch: 6.04 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15989059404808215		[learning rate: 0.0015654]
	Learning Rate: 0.00156536
	LOSS [training: 0.15989059404808215 | validation: 0.2913864776469441]
	TIME [epoch: 6.04 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15379763552870845		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.15379763552870845 | validation: 0.28242045141168975]
	TIME [epoch: 6.03 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15661816486217667		[learning rate: 0.0015516]
	Learning Rate: 0.00155156
	LOSS [training: 0.15661816486217667 | validation: 0.28486991988885824]
	TIME [epoch: 6.03 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1586362725637847		[learning rate: 0.0015447]
	Learning Rate: 0.00154471
	LOSS [training: 0.1586362725637847 | validation: 0.2937847784429862]
	TIME [epoch: 6.03 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1600171739433618		[learning rate: 0.0015379]
	Learning Rate: 0.00153788
	LOSS [training: 0.1600171739433618 | validation: 0.2853625635448545]
	TIME [epoch: 6.03 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1571525101275959		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.1571525101275959 | validation: 0.2782951445796709]
	TIME [epoch: 6.03 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1562030658509583		[learning rate: 0.0015243]
	Learning Rate: 0.00152432
	LOSS [training: 0.1562030658509583 | validation: 0.31198859763081543]
	TIME [epoch: 6.03 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15360739755487568		[learning rate: 0.0015176]
	Learning Rate: 0.00151759
	LOSS [training: 0.15360739755487568 | validation: 0.29088794429678666]
	TIME [epoch: 6.05 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15578384597007885		[learning rate: 0.0015109]
	Learning Rate: 0.00151088
	LOSS [training: 0.15578384597007885 | validation: 0.30860262257033877]
	TIME [epoch: 6.03 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15409080299237257		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.15409080299237257 | validation: 0.2873726187630739]
	TIME [epoch: 6.03 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15400323017443643		[learning rate: 0.0014976]
	Learning Rate: 0.00149756
	LOSS [training: 0.15400323017443643 | validation: 0.3149576861462924]
	TIME [epoch: 6.03 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15978609304302543		[learning rate: 0.0014909]
	Learning Rate: 0.00149094
	LOSS [training: 0.15978609304302543 | validation: 0.28939968918389286]
	TIME [epoch: 6.03 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16230515491842407		[learning rate: 0.0014844]
	Learning Rate: 0.00148436
	LOSS [training: 0.16230515491842407 | validation: 0.28657085707848073]
	TIME [epoch: 6.03 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16375609151175377		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.16375609151175377 | validation: 0.2801082892633317]
	TIME [epoch: 6.03 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15399953552375784		[learning rate: 0.0014713]
	Learning Rate: 0.00147127
	LOSS [training: 0.15399953552375784 | validation: 0.2877667920282342]
	TIME [epoch: 6.03 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1598554400406244		[learning rate: 0.0014648]
	Learning Rate: 0.00146477
	LOSS [training: 0.1598554400406244 | validation: 0.301539462694554]
	TIME [epoch: 6.04 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15836556884299466		[learning rate: 0.0014583]
	Learning Rate: 0.0014583
	LOSS [training: 0.15836556884299466 | validation: 0.30197473622137905]
	TIME [epoch: 6.03 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1558312946838687		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.1558312946838687 | validation: 0.2860156510841492]
	TIME [epoch: 6.03 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1575681767865372		[learning rate: 0.0014454]
	Learning Rate: 0.00144544
	LOSS [training: 0.1575681767865372 | validation: 0.29184258872325436]
	TIME [epoch: 6.03 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15745322429838077		[learning rate: 0.0014391]
	Learning Rate: 0.00143905
	LOSS [training: 0.15745322429838077 | validation: 0.32227241885623714]
	TIME [epoch: 6.03 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15104813705915743		[learning rate: 0.0014327]
	Learning Rate: 0.0014327
	LOSS [training: 0.15104813705915743 | validation: 0.3182128598960399]
	TIME [epoch: 6.03 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15900690518944344		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.15900690518944344 | validation: 0.2916606961180317]
	TIME [epoch: 6.03 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15631973655158052		[learning rate: 0.0014201]
	Learning Rate: 0.00142006
	LOSS [training: 0.15631973655158052 | validation: 0.2852621724286896]
	TIME [epoch: 6.04 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14851673405079335		[learning rate: 0.0014138]
	Learning Rate: 0.00141379
	LOSS [training: 0.14851673405079335 | validation: 0.2993263109187982]
	TIME [epoch: 6.03 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15842792247592122		[learning rate: 0.0014075]
	Learning Rate: 0.00140754
	LOSS [training: 0.15842792247592122 | validation: 0.3004288608806343]
	TIME [epoch: 6.04 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1543155518741428		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.1543155518741428 | validation: 0.28619662582540545]
	TIME [epoch: 6.03 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15988197400500057		[learning rate: 0.0013951]
	Learning Rate: 0.00139513
	LOSS [training: 0.15988197400500057 | validation: 0.28246833183702125]
	TIME [epoch: 6.03 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1598167014698828		[learning rate: 0.001389]
	Learning Rate: 0.00138897
	LOSS [training: 0.1598167014698828 | validation: 0.28448439783854423]
	TIME [epoch: 6.04 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16004083984553563		[learning rate: 0.0013828]
	Learning Rate: 0.00138283
	LOSS [training: 0.16004083984553563 | validation: 0.28778053591257474]
	TIME [epoch: 6.04 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15477641971173686		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.15477641971173686 | validation: 0.3070485016073628]
	TIME [epoch: 6.04 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15763137263471189		[learning rate: 0.0013706]
	Learning Rate: 0.00137064
	LOSS [training: 0.15763137263471189 | validation: 0.31195551415971734]
	TIME [epoch: 6.04 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1508763311272043		[learning rate: 0.0013646]
	Learning Rate: 0.00136458
	LOSS [training: 0.1508763311272043 | validation: 0.2879666433182377]
	TIME [epoch: 6.04 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1575698711761834		[learning rate: 0.0013586]
	Learning Rate: 0.00135855
	LOSS [training: 0.1575698711761834 | validation: 0.28908170405831707]
	TIME [epoch: 6.03 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1528920501633979		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.1528920501633979 | validation: 0.30837686375773543]
	TIME [epoch: 6.04 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15515882965366043		[learning rate: 0.0013466]
	Learning Rate: 0.00134658
	LOSS [training: 0.15515882965366043 | validation: 0.3002201946126485]
	TIME [epoch: 6.03 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15076462322853415		[learning rate: 0.0013406]
	Learning Rate: 0.00134063
	LOSS [training: 0.15076462322853415 | validation: 0.28120406826824673]
	TIME [epoch: 6.04 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15530388087176078		[learning rate: 0.0013347]
	Learning Rate: 0.0013347
	LOSS [training: 0.15530388087176078 | validation: 0.3099515508024976]
	TIME [epoch: 6.03 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1575180162143069		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.1575180162143069 | validation: 0.28985472721247557]
	TIME [epoch: 6.05 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15610456425827543		[learning rate: 0.0013229]
	Learning Rate: 0.00132293
	LOSS [training: 0.15610456425827543 | validation: 0.3006308338832899]
	TIME [epoch: 6.04 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1599719292267246		[learning rate: 0.0013171]
	Learning Rate: 0.00131709
	LOSS [training: 0.1599719292267246 | validation: 0.30312525079682195]
	TIME [epoch: 6.03 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15252727449138503		[learning rate: 0.0013113]
	Learning Rate: 0.00131127
	LOSS [training: 0.15252727449138503 | validation: 0.3074419853587554]
	TIME [epoch: 6.03 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1601880904696994		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.1601880904696994 | validation: 0.28940995447582973]
	TIME [epoch: 6.03 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1562138850783079		[learning rate: 0.0012997]
	Learning Rate: 0.00129971
	LOSS [training: 0.1562138850783079 | validation: 0.30082240878043104]
	TIME [epoch: 32.6 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15961421068256745		[learning rate: 0.001294]
	Learning Rate: 0.00129397
	LOSS [training: 0.15961421068256745 | validation: 0.2867446295352291]
	TIME [epoch: 12 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15729067224814983		[learning rate: 0.0012882]
	Learning Rate: 0.00128825
	LOSS [training: 0.15729067224814983 | validation: 0.2908296652768899]
	TIME [epoch: 11.7 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15615911107876643		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.15615911107876643 | validation: 0.2789778577168442]
	TIME [epoch: 11.7 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15166871407282553		[learning rate: 0.0012769]
	Learning Rate: 0.00127689
	LOSS [training: 0.15166871407282553 | validation: 0.28504915076966236]
	TIME [epoch: 11.7 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1549437125815602		[learning rate: 0.0012712]
	Learning Rate: 0.00127125
	LOSS [training: 0.1549437125815602 | validation: 0.28241878394349423]
	TIME [epoch: 11.7 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1553494187675244		[learning rate: 0.0012656]
	Learning Rate: 0.00126563
	LOSS [training: 0.1553494187675244 | validation: 0.29600852147957296]
	TIME [epoch: 11.7 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15275069523075718		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.15275069523075718 | validation: 0.3006112565417144]
	TIME [epoch: 11.7 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1508295451990125		[learning rate: 0.0012545]
	Learning Rate: 0.00125447
	LOSS [training: 0.1508295451990125 | validation: 0.29016380654626767]
	TIME [epoch: 11.7 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15262030745756686		[learning rate: 0.0012489]
	Learning Rate: 0.00124893
	LOSS [training: 0.15262030745756686 | validation: 0.3049366539675279]
	TIME [epoch: 11.7 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1526183173637195		[learning rate: 0.0012434]
	Learning Rate: 0.00124341
	LOSS [training: 0.1526183173637195 | validation: 0.2827084607420482]
	TIME [epoch: 11.7 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15650778922166866		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.15650778922166866 | validation: 0.2807465686175428]
	TIME [epoch: 11.7 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1538595462874826		[learning rate: 0.0012324]
	Learning Rate: 0.00123245
	LOSS [training: 0.1538595462874826 | validation: 0.2902365798148024]
	TIME [epoch: 11.7 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15566362852380303		[learning rate: 0.001227]
	Learning Rate: 0.001227
	LOSS [training: 0.15566362852380303 | validation: 0.2871109057028384]
	TIME [epoch: 11.7 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15525876155813123		[learning rate: 0.0012216]
	Learning Rate: 0.00122158
	LOSS [training: 0.15525876155813123 | validation: 0.3005264174214121]
	TIME [epoch: 11.7 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1568762780663288		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.1568762780663288 | validation: 0.2751646888524649]
	TIME [epoch: 11.7 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v9_20240712_133637/states/model_facs_v2_dec2b_2dpca_v9_516.pth
	Model improved!!!
EPOCH 517/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15870737254871972		[learning rate: 0.0012108]
	Learning Rate: 0.00121081
	LOSS [training: 0.15870737254871972 | validation: 0.2941301886202266]
	TIME [epoch: 11.7 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1598123155055099		[learning rate: 0.0012055]
	Learning Rate: 0.00120546
	LOSS [training: 0.1598123155055099 | validation: 0.3047981220075893]
	TIME [epoch: 11.7 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15595197742604203		[learning rate: 0.0012001]
	Learning Rate: 0.00120014
	LOSS [training: 0.15595197742604203 | validation: 0.28472987541907463]
	TIME [epoch: 11.7 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14959131882255156		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.14959131882255156 | validation: 0.28342837886267547]
	TIME [epoch: 11.7 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15221340732194905		[learning rate: 0.0011896]
	Learning Rate: 0.00118956
	LOSS [training: 0.15221340732194905 | validation: 0.2770149051151358]
	TIME [epoch: 11.7 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15152659112723088		[learning rate: 0.0011843]
	Learning Rate: 0.0011843
	LOSS [training: 0.15152659112723088 | validation: 0.31152628920918135]
	TIME [epoch: 11.7 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1594463463606603		[learning rate: 0.0011791]
	Learning Rate: 0.00117907
	LOSS [training: 0.1594463463606603 | validation: 0.29238353562715286]
	TIME [epoch: 11.7 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15787452338339297		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.15787452338339297 | validation: 0.28269425838593837]
	TIME [epoch: 11.7 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15452624701572473		[learning rate: 0.0011687]
	Learning Rate: 0.00116867
	LOSS [training: 0.15452624701572473 | validation: 0.30220199083829363]
	TIME [epoch: 11.7 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1543836080896523		[learning rate: 0.0011635]
	Learning Rate: 0.00116351
	LOSS [training: 0.1543836080896523 | validation: 0.2954633834898381]
	TIME [epoch: 11.7 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1550818696448139		[learning rate: 0.0011584]
	Learning Rate: 0.00115837
	LOSS [training: 0.1550818696448139 | validation: 0.2947825197621056]
	TIME [epoch: 11.7 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15258277287752395		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.15258277287752395 | validation: 0.2839504386706001]
	TIME [epoch: 11.7 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1516186348569301		[learning rate: 0.0011482]
	Learning Rate: 0.00114815
	LOSS [training: 0.1516186348569301 | validation: 0.2865022274331777]
	TIME [epoch: 11.7 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1519985144886846		[learning rate: 0.0011431]
	Learning Rate: 0.00114308
	LOSS [training: 0.1519985144886846 | validation: 0.2743592082872589]
	TIME [epoch: 11.7 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v9_20240712_133637/states/model_facs_v2_dec2b_2dpca_v9_530.pth
	Model improved!!!
EPOCH 531/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1569245935512987		[learning rate: 0.001138]
	Learning Rate: 0.00113803
	LOSS [training: 0.1569245935512987 | validation: 0.29312267942711623]
	TIME [epoch: 11.7 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1624887324040993		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.1624887324040993 | validation: 0.3057921452264737]
	TIME [epoch: 11.7 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15865700514889114		[learning rate: 0.001128]
	Learning Rate: 0.001128
	LOSS [training: 0.15865700514889114 | validation: 0.28547778907504995]
	TIME [epoch: 11.7 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14833134846875706		[learning rate: 0.001123]
	Learning Rate: 0.00112301
	LOSS [training: 0.14833134846875706 | validation: 0.2853144576148272]
	TIME [epoch: 11.7 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1539150597355931		[learning rate: 0.0011181]
	Learning Rate: 0.00111805
	LOSS [training: 0.1539150597355931 | validation: 0.2849434192754246]
	TIME [epoch: 11.7 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15344484100718275		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.15344484100718275 | validation: 0.29532947245257996]
	TIME [epoch: 11.7 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.155097373483571		[learning rate: 0.0011082]
	Learning Rate: 0.00110819
	LOSS [training: 0.155097373483571 | validation: 0.28784677366789463]
	TIME [epoch: 11.7 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.157364218046516		[learning rate: 0.0011033]
	Learning Rate: 0.0011033
	LOSS [training: 0.157364218046516 | validation: 0.2911206461264144]
	TIME [epoch: 11.7 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15087801997568623		[learning rate: 0.0010984]
	Learning Rate: 0.00109842
	LOSS [training: 0.15087801997568623 | validation: 0.2879722076841543]
	TIME [epoch: 11.7 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15478463486734167		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.15478463486734167 | validation: 0.2849419525420838]
	TIME [epoch: 11.7 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1638829381737245		[learning rate: 0.0010887]
	Learning Rate: 0.00108874
	LOSS [training: 0.1638829381737245 | validation: 0.2936163691907078]
	TIME [epoch: 11.7 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15134082611040053		[learning rate: 0.0010839]
	Learning Rate: 0.00108393
	LOSS [training: 0.15134082611040053 | validation: 0.279826152491171]
	TIME [epoch: 11.7 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14970964863547698		[learning rate: 0.0010791]
	Learning Rate: 0.00107914
	LOSS [training: 0.14970964863547698 | validation: 0.29296683985206495]
	TIME [epoch: 11.7 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15731594299472715		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.15731594299472715 | validation: 0.2844704699555204]
	TIME [epoch: 11.7 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.148996246888153		[learning rate: 0.0010696]
	Learning Rate: 0.00106962
	LOSS [training: 0.148996246888153 | validation: 0.27687065901137337]
	TIME [epoch: 11.7 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1537295899019844		[learning rate: 0.0010649]
	Learning Rate: 0.0010649
	LOSS [training: 0.1537295899019844 | validation: 0.2850053524996509]
	TIME [epoch: 11.7 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15514799756965975		[learning rate: 0.0010602]
	Learning Rate: 0.00106019
	LOSS [training: 0.15514799756965975 | validation: 0.2962879312852778]
	TIME [epoch: 11.7 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15124540261640113		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.15124540261640113 | validation: 0.2961268753119566]
	TIME [epoch: 11.7 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15542667409803085		[learning rate: 0.0010508]
	Learning Rate: 0.00105084
	LOSS [training: 0.15542667409803085 | validation: 0.2817752993645114]
	TIME [epoch: 11.7 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14986485188726517		[learning rate: 0.0010462]
	Learning Rate: 0.0010462
	LOSS [training: 0.14986485188726517 | validation: 0.3056602135491251]
	TIME [epoch: 11.7 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1518584767845547		[learning rate: 0.0010416]
	Learning Rate: 0.00104158
	LOSS [training: 0.1518584767845547 | validation: 0.29603816610161926]
	TIME [epoch: 11.7 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14807862766711816		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.14807862766711816 | validation: 0.28160700710751085]
	TIME [epoch: 11.7 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1526464058157842		[learning rate: 0.0010324]
	Learning Rate: 0.0010324
	LOSS [training: 0.1526464058157842 | validation: 0.2966976807572976]
	TIME [epoch: 11.7 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15640801820610667		[learning rate: 0.0010278]
	Learning Rate: 0.00102783
	LOSS [training: 0.15640801820610667 | validation: 0.280889282072492]
	TIME [epoch: 11.7 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15004897945553416		[learning rate: 0.0010233]
	Learning Rate: 0.00102329
	LOSS [training: 0.15004897945553416 | validation: 0.2903223167730425]
	TIME [epoch: 11.7 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15520919573898534		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.15520919573898534 | validation: 0.2909925009605269]
	TIME [epoch: 11.7 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1538677954234279		[learning rate: 0.0010143]
	Learning Rate: 0.00101427
	LOSS [training: 0.1538677954234279 | validation: 0.2761764032068706]
	TIME [epoch: 11.7 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16237369454648704		[learning rate: 0.0010098]
	Learning Rate: 0.00100979
	LOSS [training: 0.16237369454648704 | validation: 0.28685909761202294]
	TIME [epoch: 11.7 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15206194706585752		[learning rate: 0.0010053]
	Learning Rate: 0.00100533
	LOSS [training: 0.15206194706585752 | validation: 0.2883639377638745]
	TIME [epoch: 11.7 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15149111754862857		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.15149111754862857 | validation: 0.28373547972928015]
	TIME [epoch: 11.7 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15405871294778706		[learning rate: 0.00099646]
	Learning Rate: 0.000996464
	LOSS [training: 0.15405871294778706 | validation: 0.2847181628743166]
	TIME [epoch: 11.7 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1505451605999189		[learning rate: 0.00099206]
	Learning Rate: 0.000992061
	LOSS [training: 0.1505451605999189 | validation: 0.27526827558526706]
	TIME [epoch: 11.7 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15592352374704363		[learning rate: 0.00098768]
	Learning Rate: 0.000987678
	LOSS [training: 0.15592352374704363 | validation: 0.2876449392287821]
	TIME [epoch: 11.7 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15290412897499164		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.15290412897499164 | validation: 0.28576681755810246]
	TIME [epoch: 11.7 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15661480310159456		[learning rate: 0.00097897]
	Learning Rate: 0.00097897
	LOSS [training: 0.15661480310159456 | validation: 0.2796816188009678]
	TIME [epoch: 11.7 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14883976157058565		[learning rate: 0.00097464]
	Learning Rate: 0.000974644
	LOSS [training: 0.14883976157058565 | validation: 0.28403931308196717]
	TIME [epoch: 11.7 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1548265375536148		[learning rate: 0.00097034]
	Learning Rate: 0.000970338
	LOSS [training: 0.1548265375536148 | validation: 0.3013731898160758]
	TIME [epoch: 11.7 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1533828291800243		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.1533828291800243 | validation: 0.28584625033136374]
	TIME [epoch: 11.7 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14904127565482983		[learning rate: 0.00096178]
	Learning Rate: 0.000961783
	LOSS [training: 0.14904127565482983 | validation: 0.28429875531384946]
	TIME [epoch: 11.7 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15400688176434585		[learning rate: 0.00095753]
	Learning Rate: 0.000957533
	LOSS [training: 0.15400688176434585 | validation: 0.28695765858341676]
	TIME [epoch: 11.7 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15502180691133066		[learning rate: 0.0009533]
	Learning Rate: 0.000953303
	LOSS [training: 0.15502180691133066 | validation: 0.2874502199370867]
	TIME [epoch: 11.7 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15640965684526623		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.15640965684526623 | validation: 0.3011564193795787]
	TIME [epoch: 11.7 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14989725291528722		[learning rate: 0.0009449]
	Learning Rate: 0.000944897
	LOSS [training: 0.14989725291528722 | validation: 0.2933843951512459]
	TIME [epoch: 11.7 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15511911504252562		[learning rate: 0.00094072]
	Learning Rate: 0.000940723
	LOSS [training: 0.15511911504252562 | validation: 0.28045379880097515]
	TIME [epoch: 11.7 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15274891683937253		[learning rate: 0.00093657]
	Learning Rate: 0.000936566
	LOSS [training: 0.15274891683937253 | validation: 0.2858844219199795]
	TIME [epoch: 11.7 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14993927553130984		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.14993927553130984 | validation: 0.28422155006987326]
	TIME [epoch: 11.7 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14758010397081073		[learning rate: 0.00092831]
	Learning Rate: 0.000928309
	LOSS [training: 0.14758010397081073 | validation: 0.2905624459747009]
	TIME [epoch: 11.7 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1546851633609423		[learning rate: 0.00092421]
	Learning Rate: 0.000924207
	LOSS [training: 0.1546851633609423 | validation: 0.28902963565787304]
	TIME [epoch: 11.7 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15560176284880053		[learning rate: 0.00092012]
	Learning Rate: 0.000920124
	LOSS [training: 0.15560176284880053 | validation: 0.283793264985037]
	TIME [epoch: 11.7 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15418998185351707		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.15418998185351707 | validation: 0.2899750618617756]
	TIME [epoch: 11.7 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14749089054555192		[learning rate: 0.00091201]
	Learning Rate: 0.000912011
	LOSS [training: 0.14749089054555192 | validation: 0.2881839850805021]
	TIME [epoch: 11.7 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1458305635923886		[learning rate: 0.00090798]
	Learning Rate: 0.000907981
	LOSS [training: 0.1458305635923886 | validation: 0.2900093668854445]
	TIME [epoch: 11.7 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1560609936627854		[learning rate: 0.00090397]
	Learning Rate: 0.00090397
	LOSS [training: 0.1560609936627854 | validation: 0.2997784756017248]
	TIME [epoch: 11.7 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15249557726282453		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.15249557726282453 | validation: 0.2824015309036657]
	TIME [epoch: 11.7 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15275778656665437		[learning rate: 0.000896]
	Learning Rate: 0.000895999
	LOSS [training: 0.15275778656665437 | validation: 0.2940746105304996]
	TIME [epoch: 11.7 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15557215431123467		[learning rate: 0.00089204]
	Learning Rate: 0.000892041
	LOSS [training: 0.15557215431123467 | validation: 0.2972673410926517]
	TIME [epoch: 11.7 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1550123565481049		[learning rate: 0.0008881]
	Learning Rate: 0.000888099
	LOSS [training: 0.1550123565481049 | validation: 0.3009927116278783]
	TIME [epoch: 11.7 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1544872965987888		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.1544872965987888 | validation: 0.2968543309681812]
	TIME [epoch: 11.7 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1545778458200195		[learning rate: 0.00088027]
	Learning Rate: 0.000880269
	LOSS [training: 0.1545778458200195 | validation: 0.2955118463056102]
	TIME [epoch: 11.7 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15159635888518225		[learning rate: 0.00087638]
	Learning Rate: 0.00087638
	LOSS [training: 0.15159635888518225 | validation: 0.2954839227377282]
	TIME [epoch: 11.7 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1552186509715231		[learning rate: 0.00087251]
	Learning Rate: 0.000872508
	LOSS [training: 0.1552186509715231 | validation: 0.29448124899245787]
	TIME [epoch: 11.7 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15175414579821017		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.15175414579821017 | validation: 0.30124378472350544]
	TIME [epoch: 11.7 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14867741540951218		[learning rate: 0.00086481]
	Learning Rate: 0.000864815
	LOSS [training: 0.14867741540951218 | validation: 0.30057387490598025]
	TIME [epoch: 11.7 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15892371692949808		[learning rate: 0.00086099]
	Learning Rate: 0.000860994
	LOSS [training: 0.15892371692949808 | validation: 0.2954867179402247]
	TIME [epoch: 11.7 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1536606610802355		[learning rate: 0.00085719]
	Learning Rate: 0.00085719
	LOSS [training: 0.1536606610802355 | validation: 0.296405606945965]
	TIME [epoch: 11.7 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15165268532746223		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.15165268532746223 | validation: 0.2791408416864401]
	TIME [epoch: 11.7 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15207561264185285		[learning rate: 0.00084963]
	Learning Rate: 0.000849632
	LOSS [training: 0.15207561264185285 | validation: 0.2883630504752635]
	TIME [epoch: 11.7 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15168572161522373		[learning rate: 0.00084588]
	Learning Rate: 0.000845878
	LOSS [training: 0.15168572161522373 | validation: 0.28690573758229426]
	TIME [epoch: 11.7 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1512695660731163		[learning rate: 0.00084214]
	Learning Rate: 0.000842141
	LOSS [training: 0.1512695660731163 | validation: 0.2709948520609198]
	TIME [epoch: 11.7 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v9_20240712_133637/states/model_facs_v2_dec2b_2dpca_v9_599.pth
	Model improved!!!
EPOCH 600/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14663178023250395		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.14663178023250395 | validation: 0.2926913779551172]
	TIME [epoch: 11.7 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1517989453664277		[learning rate: 0.00083472]
	Learning Rate: 0.000834715
	LOSS [training: 0.1517989453664277 | validation: 0.29636039453221846]
	TIME [epoch: 11.7 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1533151469043373		[learning rate: 0.00083103]
	Learning Rate: 0.000831028
	LOSS [training: 0.1533151469043373 | validation: 0.2818828731984027]
	TIME [epoch: 11.7 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15037863037370328		[learning rate: 0.00082736]
	Learning Rate: 0.000827356
	LOSS [training: 0.15037863037370328 | validation: 0.29238825145561526]
	TIME [epoch: 11.7 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1526174582986963		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.1526174582986963 | validation: 0.28017406726495986]
	TIME [epoch: 11.7 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15173841542163288		[learning rate: 0.00082006]
	Learning Rate: 0.000820061
	LOSS [training: 0.15173841542163288 | validation: 0.2947068756293619]
	TIME [epoch: 11.7 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14816591904469487		[learning rate: 0.00081644]
	Learning Rate: 0.000816438
	LOSS [training: 0.14816591904469487 | validation: 0.2784352685236054]
	TIME [epoch: 11.7 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15073208745567093		[learning rate: 0.00081283]
	Learning Rate: 0.000812831
	LOSS [training: 0.15073208745567093 | validation: 0.29388619639707897]
	TIME [epoch: 11.7 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14794209860247515		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.14794209860247515 | validation: 0.2882166404764988]
	TIME [epoch: 11.7 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15612211794670455		[learning rate: 0.00080566]
	Learning Rate: 0.000805664
	LOSS [training: 0.15612211794670455 | validation: 0.2862188953923455]
	TIME [epoch: 11.7 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1536644543387251		[learning rate: 0.0008021]
	Learning Rate: 0.000802104
	LOSS [training: 0.1536644543387251 | validation: 0.2895443020598417]
	TIME [epoch: 11.7 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15119107135644747		[learning rate: 0.00079856]
	Learning Rate: 0.00079856
	LOSS [training: 0.15119107135644747 | validation: 0.29330390090546266]
	TIME [epoch: 11.7 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14774796756315198		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.14774796756315198 | validation: 0.2986775592954241]
	TIME [epoch: 11.7 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15235829334057066		[learning rate: 0.00079152]
	Learning Rate: 0.000791519
	LOSS [training: 0.15235829334057066 | validation: 0.2771048248118246]
	TIME [epoch: 11.7 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15300519769438564		[learning rate: 0.00078802]
	Learning Rate: 0.000788022
	LOSS [training: 0.15300519769438564 | validation: 0.2940490918339287]
	TIME [epoch: 11.7 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15244887277693062		[learning rate: 0.00078454]
	Learning Rate: 0.000784541
	LOSS [training: 0.15244887277693062 | validation: 0.29553685572792715]
	TIME [epoch: 11.7 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15416772385271113		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.15416772385271113 | validation: 0.30784375563429994]
	TIME [epoch: 11.7 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14980950236166515		[learning rate: 0.00077762]
	Learning Rate: 0.000777623
	LOSS [training: 0.14980950236166515 | validation: 0.2983262441984378]
	TIME [epoch: 11.7 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14261628293034773		[learning rate: 0.00077419]
	Learning Rate: 0.000774188
	LOSS [training: 0.14261628293034773 | validation: 0.28558013372313773]
	TIME [epoch: 11.7 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14857770853057		[learning rate: 0.00077077]
	Learning Rate: 0.000770767
	LOSS [training: 0.14857770853057 | validation: 0.28183896351280435]
	TIME [epoch: 11.7 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1495679805514163		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.1495679805514163 | validation: 0.279975298363006]
	TIME [epoch: 11.7 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15420570114553284		[learning rate: 0.00076397]
	Learning Rate: 0.000763971
	LOSS [training: 0.15420570114553284 | validation: 0.290451003561774]
	TIME [epoch: 11.7 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15170702903257804		[learning rate: 0.0007606]
	Learning Rate: 0.000760596
	LOSS [training: 0.15170702903257804 | validation: 0.28172337565458927]
	TIME [epoch: 11.7 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15560743188989756		[learning rate: 0.00075724]
	Learning Rate: 0.000757235
	LOSS [training: 0.15560743188989756 | validation: 0.2868800339755596]
	TIME [epoch: 11.7 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15811097839584534		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.15811097839584534 | validation: 0.3020721185603543]
	TIME [epoch: 11.7 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1551731789764969		[learning rate: 0.00075056]
	Learning Rate: 0.000750559
	LOSS [training: 0.1551731789764969 | validation: 0.285486056669053]
	TIME [epoch: 11.7 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14555877995473954		[learning rate: 0.00074724]
	Learning Rate: 0.000747242
	LOSS [training: 0.14555877995473954 | validation: 0.2934873228599508]
	TIME [epoch: 11.7 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15948400285414768		[learning rate: 0.00074394]
	Learning Rate: 0.000743941
	LOSS [training: 0.15948400285414768 | validation: 0.28348136212421954]
	TIME [epoch: 11.7 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15030005071315222		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.15030005071315222 | validation: 0.2825970850124563]
	TIME [epoch: 11.7 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1528419355944624		[learning rate: 0.00073738]
	Learning Rate: 0.000737382
	LOSS [training: 0.1528419355944624 | validation: 0.29334351961136707]
	TIME [epoch: 11.7 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15185277969951358		[learning rate: 0.00073412]
	Learning Rate: 0.000734124
	LOSS [training: 0.15185277969951358 | validation: 0.30076822715421425]
	TIME [epoch: 11.7 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1500508380695024		[learning rate: 0.00073088]
	Learning Rate: 0.00073088
	LOSS [training: 0.1500508380695024 | validation: 0.2878306021944439]
	TIME [epoch: 11.7 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1531711055366109		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 0.1531711055366109 | validation: 0.29160952962070674]
	TIME [epoch: 11.7 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15182955616360977		[learning rate: 0.00072444]
	Learning Rate: 0.000724436
	LOSS [training: 0.15182955616360977 | validation: 0.29860056723159245]
	TIME [epoch: 11.7 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1515316811995982		[learning rate: 0.00072124]
	Learning Rate: 0.000721235
	LOSS [training: 0.1515316811995982 | validation: 0.29018112781207]
	TIME [epoch: 11.7 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15177194293442628		[learning rate: 0.00071805]
	Learning Rate: 0.000718049
	LOSS [training: 0.15177194293442628 | validation: 0.28026303403732394]
	TIME [epoch: 11.7 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15399575619457953		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.15399575619457953 | validation: 0.29889356320770544]
	TIME [epoch: 11.7 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1497351902233814		[learning rate: 0.00071172]
	Learning Rate: 0.000711718
	LOSS [training: 0.1497351902233814 | validation: 0.281758938239957]
	TIME [epoch: 11.7 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14943241858352793		[learning rate: 0.00070857]
	Learning Rate: 0.000708573
	LOSS [training: 0.14943241858352793 | validation: 0.2886919964482299]
	TIME [epoch: 11.7 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1524336593268018		[learning rate: 0.00070544]
	Learning Rate: 0.000705442
	LOSS [training: 0.1524336593268018 | validation: 0.27683464603040936]
	TIME [epoch: 11.7 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15074680240979677		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.15074680240979677 | validation: 0.29760935344513945]
	TIME [epoch: 11.7 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14873226464281097		[learning rate: 0.00069922]
	Learning Rate: 0.000699222
	LOSS [training: 0.14873226464281097 | validation: 0.2879497705277193]
	TIME [epoch: 11.7 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1519319110172903		[learning rate: 0.00069613]
	Learning Rate: 0.000696133
	LOSS [training: 0.1519319110172903 | validation: 0.2970915391883496]
	TIME [epoch: 11.7 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14945267643631518		[learning rate: 0.00069306]
	Learning Rate: 0.000693058
	LOSS [training: 0.14945267643631518 | validation: 0.29506456079823357]
	TIME [epoch: 11.7 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15088801890903608		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 0.15088801890903608 | validation: 0.3057156462198409]
	TIME [epoch: 11.7 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1492180511951329		[learning rate: 0.00068695]
	Learning Rate: 0.000686947
	LOSS [training: 0.1492180511951329 | validation: 0.2881530307171059]
	TIME [epoch: 11.7 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15217422721299642		[learning rate: 0.00068391]
	Learning Rate: 0.000683912
	LOSS [training: 0.15217422721299642 | validation: 0.2823802435243249]
	TIME [epoch: 11.7 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14851940121773619		[learning rate: 0.00068089]
	Learning Rate: 0.00068089
	LOSS [training: 0.14851940121773619 | validation: 0.28325878936563376]
	TIME [epoch: 11.7 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15107602852110327		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 0.15107602852110327 | validation: 0.30171178509231994]
	TIME [epoch: 11.7 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14961826812427342		[learning rate: 0.00067489]
	Learning Rate: 0.000674887
	LOSS [training: 0.14961826812427342 | validation: 0.26965788866568074]
	TIME [epoch: 11.7 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v9_20240712_133637/states/model_facs_v2_dec2b_2dpca_v9_649.pth
	Model improved!!!
EPOCH 650/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14987337731197395		[learning rate: 0.0006719]
	Learning Rate: 0.000671905
	LOSS [training: 0.14987337731197395 | validation: 0.2822021311025879]
	TIME [epoch: 11.7 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1510908905712645		[learning rate: 0.00066894]
	Learning Rate: 0.000668936
	LOSS [training: 0.1510908905712645 | validation: 0.2896262623229431]
	TIME [epoch: 11.7 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15225952245006552		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 0.15225952245006552 | validation: 0.2914081380214562]
	TIME [epoch: 11.7 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15539864638276862		[learning rate: 0.00066304]
	Learning Rate: 0.000663038
	LOSS [training: 0.15539864638276862 | validation: 0.28262771293044026]
	TIME [epoch: 11.7 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.146140292000687		[learning rate: 0.00066011]
	Learning Rate: 0.000660109
	LOSS [training: 0.146140292000687 | validation: 0.28031810426312487]
	TIME [epoch: 11.7 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15024714861847244		[learning rate: 0.00065719]
	Learning Rate: 0.000657192
	LOSS [training: 0.15024714861847244 | validation: 0.28335125732330113]
	TIME [epoch: 11.7 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1488212059180624		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 0.1488212059180624 | validation: 0.2933349676190636]
	TIME [epoch: 11.7 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1529107493438686		[learning rate: 0.0006514]
	Learning Rate: 0.000651398
	LOSS [training: 0.1529107493438686 | validation: 0.2893304223124549]
	TIME [epoch: 11.7 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15254376997075497		[learning rate: 0.00064852]
	Learning Rate: 0.00064852
	LOSS [training: 0.15254376997075497 | validation: 0.28804065576546917]
	TIME [epoch: 11.7 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15672070823850856		[learning rate: 0.00064565]
	Learning Rate: 0.000645654
	LOSS [training: 0.15672070823850856 | validation: 0.2850583855397928]
	TIME [epoch: 11.7 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15008939299145654		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 0.15008939299145654 | validation: 0.28400782421261483]
	TIME [epoch: 11.7 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15100347372803455		[learning rate: 0.00063996]
	Learning Rate: 0.000639962
	LOSS [training: 0.15100347372803455 | validation: 0.2905241558517454]
	TIME [epoch: 11.7 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14873732881289095		[learning rate: 0.00063713]
	Learning Rate: 0.000637134
	LOSS [training: 0.14873732881289095 | validation: 0.27644072387790847]
	TIME [epoch: 11.7 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14569243696425974		[learning rate: 0.00063432]
	Learning Rate: 0.000634319
	LOSS [training: 0.14569243696425974 | validation: 0.29049438493982177]
	TIME [epoch: 11.7 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15024928333271667		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 0.15024928333271667 | validation: 0.2923739563614843]
	TIME [epoch: 11.7 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1553252310696926		[learning rate: 0.00062873]
	Learning Rate: 0.000628726
	LOSS [training: 0.1553252310696926 | validation: 0.2775576596780913]
	TIME [epoch: 11.7 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14775829921536868		[learning rate: 0.00062595]
	Learning Rate: 0.000625948
	LOSS [training: 0.14775829921536868 | validation: 0.305186974622658]
	TIME [epoch: 11.7 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15601669252583003		[learning rate: 0.00062318]
	Learning Rate: 0.000623183
	LOSS [training: 0.15601669252583003 | validation: 0.2903358622721054]
	TIME [epoch: 11.7 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1512471368288309		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 0.1512471368288309 | validation: 0.2791174079717902]
	TIME [epoch: 11.7 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15286825293904402		[learning rate: 0.00061769]
	Learning Rate: 0.000617688
	LOSS [training: 0.15286825293904402 | validation: 0.28988103937300563]
	TIME [epoch: 11.7 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15034198856518768		[learning rate: 0.00061496]
	Learning Rate: 0.000614959
	LOSS [training: 0.15034198856518768 | validation: 0.28575499887445116]
	TIME [epoch: 11.7 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15454874310494482		[learning rate: 0.00061224]
	Learning Rate: 0.000612242
	LOSS [training: 0.15454874310494482 | validation: 0.28813781064259564]
	TIME [epoch: 11.7 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15600822633008046		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 0.15600822633008046 | validation: 0.2875550127823432]
	TIME [epoch: 11.7 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1460021507438624		[learning rate: 0.00060684]
	Learning Rate: 0.000606844
	LOSS [training: 0.1460021507438624 | validation: 0.28591874598913125]
	TIME [epoch: 11.7 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14997104344323223		[learning rate: 0.00060416]
	Learning Rate: 0.000604163
	LOSS [training: 0.14997104344323223 | validation: 0.28116900244797466]
	TIME [epoch: 11.7 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15187292467712935		[learning rate: 0.00060149]
	Learning Rate: 0.000601493
	LOSS [training: 0.15187292467712935 | validation: 0.2859190747203347]
	TIME [epoch: 11.7 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1535466950968258		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.1535466950968258 | validation: 0.28246251223897884]
	TIME [epoch: 11.7 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14673147641223372		[learning rate: 0.00059619]
	Learning Rate: 0.00059619
	LOSS [training: 0.14673147641223372 | validation: 0.2829398213418134]
	TIME [epoch: 11.7 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15261992671716032		[learning rate: 0.00059356]
	Learning Rate: 0.000593556
	LOSS [training: 0.15261992671716032 | validation: 0.2987610064338536]
	TIME [epoch: 11.7 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1522591364242724		[learning rate: 0.00059093]
	Learning Rate: 0.000590933
	LOSS [training: 0.1522591364242724 | validation: 0.2867593301684722]
	TIME [epoch: 11.7 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14614264065464905		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 0.14614264065464905 | validation: 0.28290410177056347]
	TIME [epoch: 11.7 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15204315287606604		[learning rate: 0.00058572]
	Learning Rate: 0.000585723
	LOSS [training: 0.15204315287606604 | validation: 0.2868031542622777]
	TIME [epoch: 11.7 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15160157412519		[learning rate: 0.00058314]
	Learning Rate: 0.000583135
	LOSS [training: 0.15160157412519 | validation: 0.2902065730976302]
	TIME [epoch: 11.7 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14557526488193662		[learning rate: 0.00058056]
	Learning Rate: 0.000580559
	LOSS [training: 0.14557526488193662 | validation: 0.30549853371672325]
	TIME [epoch: 11.7 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1494153484910876		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 0.1494153484910876 | validation: 0.2893327965744157]
	TIME [epoch: 11.7 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.154054388853411		[learning rate: 0.00057544]
	Learning Rate: 0.00057544
	LOSS [training: 0.154054388853411 | validation: 0.28322643913250783]
	TIME [epoch: 11.7 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14933778192898522		[learning rate: 0.0005729]
	Learning Rate: 0.000572898
	LOSS [training: 0.14933778192898522 | validation: 0.2880350922257739]
	TIME [epoch: 11.7 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1511126422144362		[learning rate: 0.00057037]
	Learning Rate: 0.000570366
	LOSS [training: 0.1511126422144362 | validation: 0.29555228141530415]
	TIME [epoch: 11.7 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15070165806752445		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 0.15070165806752445 | validation: 0.28401005595136053]
	TIME [epoch: 11.7 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1580823071530094		[learning rate: 0.00056534]
	Learning Rate: 0.000565337
	LOSS [training: 0.1580823071530094 | validation: 0.28734992911995033]
	TIME [epoch: 11.7 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15164303143277574		[learning rate: 0.00056284]
	Learning Rate: 0.00056284
	LOSS [training: 0.15164303143277574 | validation: 0.28015447652725156]
	TIME [epoch: 11.7 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15077394810196873		[learning rate: 0.00056035]
	Learning Rate: 0.000560353
	LOSS [training: 0.15077394810196873 | validation: 0.2872952203065857]
	TIME [epoch: 11.7 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1537720079032797		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 0.1537720079032797 | validation: 0.28684640050119875]
	TIME [epoch: 11.7 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1542958485765214		[learning rate: 0.00055541]
	Learning Rate: 0.000555412
	LOSS [training: 0.1542958485765214 | validation: 0.28928451608794725]
	TIME [epoch: 11.7 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15188918402571291		[learning rate: 0.00055296]
	Learning Rate: 0.000552958
	LOSS [training: 0.15188918402571291 | validation: 0.27370064272772693]
	TIME [epoch: 11.7 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1496513179483892		[learning rate: 0.00055052]
	Learning Rate: 0.000550515
	LOSS [training: 0.1496513179483892 | validation: 0.28589323793575844]
	TIME [epoch: 11.7 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1494312818349714		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 0.1494312818349714 | validation: 0.28615332095319285]
	TIME [epoch: 11.7 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1437089191623668		[learning rate: 0.00054566]
	Learning Rate: 0.000545661
	LOSS [training: 0.1437089191623668 | validation: 0.29976244627010146]
	TIME [epoch: 11.7 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14911102036246734		[learning rate: 0.00054325]
	Learning Rate: 0.00054325
	LOSS [training: 0.14911102036246734 | validation: 0.2876678120666072]
	TIME [epoch: 11.7 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1536315336025998		[learning rate: 0.00054085]
	Learning Rate: 0.00054085
	LOSS [training: 0.1536315336025998 | validation: 0.27719136836285607]
	TIME [epoch: 11.7 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15231378952164198		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 0.15231378952164198 | validation: 0.29727733808652845]
	TIME [epoch: 11.7 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1504092831995705		[learning rate: 0.00053608]
	Learning Rate: 0.000536081
	LOSS [training: 0.1504092831995705 | validation: 0.3000050879458601]
	TIME [epoch: 11.7 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14694739210105784		[learning rate: 0.00053371]
	Learning Rate: 0.000533713
	LOSS [training: 0.14694739210105784 | validation: 0.292199138872602]
	TIME [epoch: 11.7 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15237253192243636		[learning rate: 0.00053135]
	Learning Rate: 0.000531355
	LOSS [training: 0.15237253192243636 | validation: 0.29423376841808657]
	TIME [epoch: 11.7 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15194820509934054		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 0.15194820509934054 | validation: 0.297477242447496]
	TIME [epoch: 11.7 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14978977100993568		[learning rate: 0.00052667]
	Learning Rate: 0.00052667
	LOSS [training: 0.14978977100993568 | validation: 0.28190493265269323]
	TIME [epoch: 11.7 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1463177503706614		[learning rate: 0.00052434]
	Learning Rate: 0.000524343
	LOSS [training: 0.1463177503706614 | validation: 0.29738573112966493]
	TIME [epoch: 11.7 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14971627275698127		[learning rate: 0.00052203]
	Learning Rate: 0.000522026
	LOSS [training: 0.14971627275698127 | validation: 0.28709233415256813]
	TIME [epoch: 11.7 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14650210193222196		[learning rate: 0.00051972]
	Learning Rate: 0.00051972
	LOSS [training: 0.14650210193222196 | validation: 0.284589221444357]
	TIME [epoch: 11.7 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15358505506435965		[learning rate: 0.00051742]
	Learning Rate: 0.000517423
	LOSS [training: 0.15358505506435965 | validation: 0.29116270383822773]
	TIME [epoch: 11.7 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14898312893163207		[learning rate: 0.00051514]
	Learning Rate: 0.000515137
	LOSS [training: 0.14898312893163207 | validation: 0.2828741303008466]
	TIME [epoch: 11.7 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14986301594267382		[learning rate: 0.00051286]
	Learning Rate: 0.000512861
	LOSS [training: 0.14986301594267382 | validation: 0.2803449903952754]
	TIME [epoch: 11.7 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1458483963302593		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 0.1458483963302593 | validation: 0.3030569909826287]
	TIME [epoch: 11.7 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14877986418803932		[learning rate: 0.00050834]
	Learning Rate: 0.000508339
	LOSS [training: 0.14877986418803932 | validation: 0.29301849796247004]
	TIME [epoch: 11.7 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1477975526899386		[learning rate: 0.00050609]
	Learning Rate: 0.000506094
	LOSS [training: 0.1477975526899386 | validation: 0.2832683912500364]
	TIME [epoch: 11.7 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15349966226817147		[learning rate: 0.00050386]
	Learning Rate: 0.000503858
	LOSS [training: 0.15349966226817147 | validation: 0.2849909064433642]
	TIME [epoch: 11.7 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14813623961871664		[learning rate: 0.00050163]
	Learning Rate: 0.000501631
	LOSS [training: 0.14813623961871664 | validation: 0.28544792470287056]
	TIME [epoch: 11.7 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15119078967029112		[learning rate: 0.00049941]
	Learning Rate: 0.000499415
	LOSS [training: 0.15119078967029112 | validation: 0.28339492799895116]
	TIME [epoch: 11.7 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14721685084047195		[learning rate: 0.00049721]
	Learning Rate: 0.000497208
	LOSS [training: 0.14721685084047195 | validation: 0.27989607615217516]
	TIME [epoch: 11.7 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14522992306797636		[learning rate: 0.00049501]
	Learning Rate: 0.000495012
	LOSS [training: 0.14522992306797636 | validation: 0.2941534437972103]
	TIME [epoch: 11.7 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14928071597898468		[learning rate: 0.00049282]
	Learning Rate: 0.000492825
	LOSS [training: 0.14928071597898468 | validation: 0.2896015224194716]
	TIME [epoch: 11.7 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15375685030810807		[learning rate: 0.00049065]
	Learning Rate: 0.000490647
	LOSS [training: 0.15375685030810807 | validation: 0.2936424781074577]
	TIME [epoch: 11.7 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15070311364706615		[learning rate: 0.00048848]
	Learning Rate: 0.000488479
	LOSS [training: 0.15070311364706615 | validation: 0.28599023600734963]
	TIME [epoch: 11.7 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15581853630235926		[learning rate: 0.00048632]
	Learning Rate: 0.000486321
	LOSS [training: 0.15581853630235926 | validation: 0.2800819955996586]
	TIME [epoch: 11.7 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15112552262514986		[learning rate: 0.00048417]
	Learning Rate: 0.000484172
	LOSS [training: 0.15112552262514986 | validation: 0.3020898012612374]
	TIME [epoch: 11.7 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14866786437553087		[learning rate: 0.00048203]
	Learning Rate: 0.000482033
	LOSS [training: 0.14866786437553087 | validation: 0.2866180355078393]
	TIME [epoch: 11.7 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15242506923282922		[learning rate: 0.0004799]
	Learning Rate: 0.000479903
	LOSS [training: 0.15242506923282922 | validation: 0.27664445672654775]
	TIME [epoch: 11.7 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15070262045968547		[learning rate: 0.00047778]
	Learning Rate: 0.000477783
	LOSS [training: 0.15070262045968547 | validation: 0.2976718982411106]
	TIME [epoch: 11.7 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15013912507733798		[learning rate: 0.00047567]
	Learning Rate: 0.000475672
	LOSS [training: 0.15013912507733798 | validation: 0.2802081516957781]
	TIME [epoch: 11.7 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15100815868952838		[learning rate: 0.00047357]
	Learning Rate: 0.00047357
	LOSS [training: 0.15100815868952838 | validation: 0.28857711336433595]
	TIME [epoch: 11.7 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15035111733932335		[learning rate: 0.00047148]
	Learning Rate: 0.000471478
	LOSS [training: 0.15035111733932335 | validation: 0.29829881114129136]
	TIME [epoch: 11.7 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14536554647825		[learning rate: 0.0004694]
	Learning Rate: 0.000469395
	LOSS [training: 0.14536554647825 | validation: 0.2766115426521621]
	TIME [epoch: 11.7 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14689491211455324		[learning rate: 0.00046732]
	Learning Rate: 0.000467321
	LOSS [training: 0.14689491211455324 | validation: 0.28021389432663846]
	TIME [epoch: 11.7 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14949601285329472		[learning rate: 0.00046526]
	Learning Rate: 0.000465256
	LOSS [training: 0.14949601285329472 | validation: 0.29823450662362555]
	TIME [epoch: 11.7 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.153437406475669		[learning rate: 0.0004632]
	Learning Rate: 0.000463201
	LOSS [training: 0.153437406475669 | validation: 0.28476301978492363]
	TIME [epoch: 11.7 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15188474212917946		[learning rate: 0.00046115]
	Learning Rate: 0.000461154
	LOSS [training: 0.15188474212917946 | validation: 0.28326684979592565]
	TIME [epoch: 11.7 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14525698147969443		[learning rate: 0.00045912]
	Learning Rate: 0.000459117
	LOSS [training: 0.14525698147969443 | validation: 0.28811475992891206]
	TIME [epoch: 11.7 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14990046755602		[learning rate: 0.00045709]
	Learning Rate: 0.000457088
	LOSS [training: 0.14990046755602 | validation: 0.2861620079035152]
	TIME [epoch: 11.8 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14926946866493615		[learning rate: 0.00045507]
	Learning Rate: 0.000455069
	LOSS [training: 0.14926946866493615 | validation: 0.28975805036864377]
	TIME [epoch: 11.7 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15371165141720255		[learning rate: 0.00045306]
	Learning Rate: 0.000453058
	LOSS [training: 0.15371165141720255 | validation: 0.2803354550488907]
	TIME [epoch: 11.7 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15108597167116974		[learning rate: 0.00045106]
	Learning Rate: 0.000451056
	LOSS [training: 0.15108597167116974 | validation: 0.2854108079553987]
	TIME [epoch: 11.7 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15108823211067915		[learning rate: 0.00044906]
	Learning Rate: 0.000449064
	LOSS [training: 0.15108823211067915 | validation: 0.28904108145801327]
	TIME [epoch: 11.7 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15189089177571907		[learning rate: 0.00044708]
	Learning Rate: 0.000447079
	LOSS [training: 0.15189089177571907 | validation: 0.27895333947555484]
	TIME [epoch: 11.7 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15242729315488826		[learning rate: 0.0004451]
	Learning Rate: 0.000445104
	LOSS [training: 0.15242729315488826 | validation: 0.28880177295730886]
	TIME [epoch: 11.7 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14937187445164235		[learning rate: 0.00044314]
	Learning Rate: 0.000443138
	LOSS [training: 0.14937187445164235 | validation: 0.2910318772534534]
	TIME [epoch: 11.7 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15198994084912643		[learning rate: 0.00044118]
	Learning Rate: 0.00044118
	LOSS [training: 0.15198994084912643 | validation: 0.284927166037699]
	TIME [epoch: 11.7 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14723925947027527		[learning rate: 0.00043923]
	Learning Rate: 0.00043923
	LOSS [training: 0.14723925947027527 | validation: 0.2872734139042448]
	TIME [epoch: 11.7 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15382747585127018		[learning rate: 0.00043729]
	Learning Rate: 0.00043729
	LOSS [training: 0.15382747585127018 | validation: 0.2824631221220123]
	TIME [epoch: 11.7 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14869155960057084		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 0.14869155960057084 | validation: 0.28821665343227604]
	TIME [epoch: 11.7 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14686253761239818		[learning rate: 0.00043343]
	Learning Rate: 0.000433434
	LOSS [training: 0.14686253761239818 | validation: 0.288263415823369]
	TIME [epoch: 11.7 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1586226822906309		[learning rate: 0.00043152]
	Learning Rate: 0.000431519
	LOSS [training: 0.1586226822906309 | validation: 0.28979318356081957]
	TIME [epoch: 11.7 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1487960406371188		[learning rate: 0.00042961]
	Learning Rate: 0.000429613
	LOSS [training: 0.1487960406371188 | validation: 0.2888362092992093]
	TIME [epoch: 11.7 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14911767055673342		[learning rate: 0.00042771]
	Learning Rate: 0.000427714
	LOSS [training: 0.14911767055673342 | validation: 0.27567685508853457]
	TIME [epoch: 11.7 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14759554431904087		[learning rate: 0.00042582]
	Learning Rate: 0.000425825
	LOSS [training: 0.14759554431904087 | validation: 0.28189721319801664]
	TIME [epoch: 11.7 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15640705482315953		[learning rate: 0.00042394]
	Learning Rate: 0.000423943
	LOSS [training: 0.15640705482315953 | validation: 0.28423579632851004]
	TIME [epoch: 11.7 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1507334396351525		[learning rate: 0.00042207]
	Learning Rate: 0.00042207
	LOSS [training: 0.1507334396351525 | validation: 0.28724376169067645]
	TIME [epoch: 11.7 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14865245087119142		[learning rate: 0.00042021]
	Learning Rate: 0.000420205
	LOSS [training: 0.14865245087119142 | validation: 0.2909947170604201]
	TIME [epoch: 11.7 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15117757659772416		[learning rate: 0.00041835]
	Learning Rate: 0.000418349
	LOSS [training: 0.15117757659772416 | validation: 0.2847526628705564]
	TIME [epoch: 11.7 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14745910908722928		[learning rate: 0.0004165]
	Learning Rate: 0.0004165
	LOSS [training: 0.14745910908722928 | validation: 0.27668051519602443]
	TIME [epoch: 11.7 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14923661035325425		[learning rate: 0.00041466]
	Learning Rate: 0.00041466
	LOSS [training: 0.14923661035325425 | validation: 0.2907363337380375]
	TIME [epoch: 11.7 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1511460036238254		[learning rate: 0.00041283]
	Learning Rate: 0.000412828
	LOSS [training: 0.1511460036238254 | validation: 0.29215417890668804]
	TIME [epoch: 11.7 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14442274376644212		[learning rate: 0.000411]
	Learning Rate: 0.000411004
	LOSS [training: 0.14442274376644212 | validation: 0.2822420971256494]
	TIME [epoch: 11.7 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14903388880260937		[learning rate: 0.00040919]
	Learning Rate: 0.000409188
	LOSS [training: 0.14903388880260937 | validation: 0.2860629706281644]
	TIME [epoch: 11.7 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1492639819504974		[learning rate: 0.00040738]
	Learning Rate: 0.00040738
	LOSS [training: 0.1492639819504974 | validation: 0.2850664781548617]
	TIME [epoch: 11.7 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14667792263623328		[learning rate: 0.00040558]
	Learning Rate: 0.00040558
	LOSS [training: 0.14667792263623328 | validation: 0.28756943271241]
	TIME [epoch: 11.7 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15090185139540133		[learning rate: 0.00040379]
	Learning Rate: 0.000403788
	LOSS [training: 0.15090185139540133 | validation: 0.2941539751924996]
	TIME [epoch: 11.7 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14948023144146366		[learning rate: 0.000402]
	Learning Rate: 0.000402004
	LOSS [training: 0.14948023144146366 | validation: 0.27473608752970813]
	TIME [epoch: 11.7 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15209877248165418		[learning rate: 0.00040023]
	Learning Rate: 0.000400228
	LOSS [training: 0.15209877248165418 | validation: 0.2854818133133914]
	TIME [epoch: 11.7 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15051570053425528		[learning rate: 0.00039846]
	Learning Rate: 0.00039846
	LOSS [training: 0.15051570053425528 | validation: 0.28758077674717164]
	TIME [epoch: 11.7 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14665070068814443		[learning rate: 0.0003967]
	Learning Rate: 0.000396699
	LOSS [training: 0.14665070068814443 | validation: 0.28903611888072334]
	TIME [epoch: 11.7 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1463613508691287		[learning rate: 0.00039495]
	Learning Rate: 0.000394947
	LOSS [training: 0.1463613508691287 | validation: 0.2843051943311834]
	TIME [epoch: 11.7 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1486816722145648		[learning rate: 0.0003932]
	Learning Rate: 0.000393202
	LOSS [training: 0.1486816722145648 | validation: 0.28197272387021594]
	TIME [epoch: 11.7 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1502358199680976		[learning rate: 0.00039146]
	Learning Rate: 0.000391464
	LOSS [training: 0.1502358199680976 | validation: 0.29123827008029296]
	TIME [epoch: 11.7 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14818995433476548		[learning rate: 0.00038973]
	Learning Rate: 0.000389735
	LOSS [training: 0.14818995433476548 | validation: 0.2799632107202532]
	TIME [epoch: 11.7 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1461825996570203		[learning rate: 0.00038801]
	Learning Rate: 0.000388013
	LOSS [training: 0.1461825996570203 | validation: 0.2895096413434854]
	TIME [epoch: 11.7 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15028521884969723		[learning rate: 0.0003863]
	Learning Rate: 0.000386299
	LOSS [training: 0.15028521884969723 | validation: 0.284483564816989]
	TIME [epoch: 11.7 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14790883083720013		[learning rate: 0.00038459]
	Learning Rate: 0.000384592
	LOSS [training: 0.14790883083720013 | validation: 0.292153225171977]
	TIME [epoch: 11.7 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14968661242820688		[learning rate: 0.00038289]
	Learning Rate: 0.000382893
	LOSS [training: 0.14968661242820688 | validation: 0.2866364188292017]
	TIME [epoch: 11.7 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14638134789677343		[learning rate: 0.0003812]
	Learning Rate: 0.000381201
	LOSS [training: 0.14638134789677343 | validation: 0.2866165006100519]
	TIME [epoch: 11.7 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14495482758506986		[learning rate: 0.00037952]
	Learning Rate: 0.000379517
	LOSS [training: 0.14495482758506986 | validation: 0.2942231384472091]
	TIME [epoch: 11.7 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15488536626114946		[learning rate: 0.00037784]
	Learning Rate: 0.00037784
	LOSS [training: 0.15488536626114946 | validation: 0.28564892767323913]
	TIME [epoch: 11.7 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14843689963370976		[learning rate: 0.00037617]
	Learning Rate: 0.00037617
	LOSS [training: 0.14843689963370976 | validation: 0.27981301188978863]
	TIME [epoch: 11.7 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15115462845856692		[learning rate: 0.00037451]
	Learning Rate: 0.000374508
	LOSS [training: 0.15115462845856692 | validation: 0.2884056198031814]
	TIME [epoch: 11.7 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14863924042311688		[learning rate: 0.00037285]
	Learning Rate: 0.000372854
	LOSS [training: 0.14863924042311688 | validation: 0.29239094740795113]
	TIME [epoch: 11.7 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14834976190893587		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 0.14834976190893587 | validation: 0.2800131107973724]
	TIME [epoch: 11.7 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1477705211307438		[learning rate: 0.00036957]
	Learning Rate: 0.000369566
	LOSS [training: 0.1477705211307438 | validation: 0.28766039797426896]
	TIME [epoch: 11.7 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14971130748198078		[learning rate: 0.00036793]
	Learning Rate: 0.000367933
	LOSS [training: 0.14971130748198078 | validation: 0.28342140844693736]
	TIME [epoch: 11.7 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1475905649117199		[learning rate: 0.00036631]
	Learning Rate: 0.000366308
	LOSS [training: 0.1475905649117199 | validation: 0.29617624003988474]
	TIME [epoch: 11.7 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14739211519689402		[learning rate: 0.00036469]
	Learning Rate: 0.000364689
	LOSS [training: 0.14739211519689402 | validation: 0.28974225778382284]
	TIME [epoch: 11.7 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15117564445476042		[learning rate: 0.00036308]
	Learning Rate: 0.000363078
	LOSS [training: 0.15117564445476042 | validation: 0.28897347201290263]
	TIME [epoch: 11.7 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1456425775895208		[learning rate: 0.00036147]
	Learning Rate: 0.000361474
	LOSS [training: 0.1456425775895208 | validation: 0.28595397875541445]
	TIME [epoch: 11.7 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1493440775525317		[learning rate: 0.00035988]
	Learning Rate: 0.000359877
	LOSS [training: 0.1493440775525317 | validation: 0.2860234552401476]
	TIME [epoch: 11.7 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14972700083686608		[learning rate: 0.00035829]
	Learning Rate: 0.000358287
	LOSS [training: 0.14972700083686608 | validation: 0.2966455068524106]
	TIME [epoch: 11.7 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1465789843770605		[learning rate: 0.0003567]
	Learning Rate: 0.000356704
	LOSS [training: 0.1465789843770605 | validation: 0.28959518881049057]
	TIME [epoch: 11.7 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14466443437590196		[learning rate: 0.00035513]
	Learning Rate: 0.000355128
	LOSS [training: 0.14466443437590196 | validation: 0.28073934237562115]
	TIME [epoch: 11.7 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15019385636412266		[learning rate: 0.00035356]
	Learning Rate: 0.000353559
	LOSS [training: 0.15019385636412266 | validation: 0.28861857758303583]
	TIME [epoch: 11.7 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14953987245520145		[learning rate: 0.000352]
	Learning Rate: 0.000351997
	LOSS [training: 0.14953987245520145 | validation: 0.2750902144045662]
	TIME [epoch: 11.7 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14633757280807816		[learning rate: 0.00035044]
	Learning Rate: 0.000350441
	LOSS [training: 0.14633757280807816 | validation: 0.2808058016089997]
	TIME [epoch: 11.7 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15244732011952195		[learning rate: 0.00034889]
	Learning Rate: 0.000348893
	LOSS [training: 0.15244732011952195 | validation: 0.2853162978822758]
	TIME [epoch: 11.7 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14191250492041044		[learning rate: 0.00034735]
	Learning Rate: 0.000347352
	LOSS [training: 0.14191250492041044 | validation: 0.2944429571872922]
	TIME [epoch: 11.7 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15108550606899834		[learning rate: 0.00034582]
	Learning Rate: 0.000345817
	LOSS [training: 0.15108550606899834 | validation: 0.2886421199677712]
	TIME [epoch: 11.7 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14791998127128095		[learning rate: 0.00034429]
	Learning Rate: 0.000344289
	LOSS [training: 0.14791998127128095 | validation: 0.285409991601842]
	TIME [epoch: 11.7 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1459896029318053		[learning rate: 0.00034277]
	Learning Rate: 0.000342768
	LOSS [training: 0.1459896029318053 | validation: 0.2892424095924381]
	TIME [epoch: 11.7 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15031396890288962		[learning rate: 0.00034125]
	Learning Rate: 0.000341253
	LOSS [training: 0.15031396890288962 | validation: 0.2913307555856014]
	TIME [epoch: 11.7 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15571753693448892		[learning rate: 0.00033975]
	Learning Rate: 0.000339746
	LOSS [training: 0.15571753693448892 | validation: 0.28781767604528524]
	TIME [epoch: 11.7 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14590330477810917		[learning rate: 0.00033824]
	Learning Rate: 0.000338245
	LOSS [training: 0.14590330477810917 | validation: 0.2802491199479719]
	TIME [epoch: 11.7 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1452521340049337		[learning rate: 0.00033675]
	Learning Rate: 0.00033675
	LOSS [training: 0.1452521340049337 | validation: 0.28494159810740677]
	TIME [epoch: 11.7 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14906808065789506		[learning rate: 0.00033526]
	Learning Rate: 0.000335262
	LOSS [training: 0.14906808065789506 | validation: 0.2830120480713442]
	TIME [epoch: 11.7 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14843243177817414		[learning rate: 0.00033378]
	Learning Rate: 0.000333781
	LOSS [training: 0.14843243177817414 | validation: 0.2909422573752863]
	TIME [epoch: 11.8 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14739306791529572		[learning rate: 0.00033231]
	Learning Rate: 0.000332306
	LOSS [training: 0.14739306791529572 | validation: 0.2896912654681015]
	TIME [epoch: 11.7 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1486445091263584		[learning rate: 0.00033084]
	Learning Rate: 0.000330838
	LOSS [training: 0.1486445091263584 | validation: 0.2867900998308225]
	TIME [epoch: 11.7 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14821098429792684		[learning rate: 0.00032938]
	Learning Rate: 0.000329376
	LOSS [training: 0.14821098429792684 | validation: 0.2923075372158842]
	TIME [epoch: 11.7 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14991521508383945		[learning rate: 0.00032792]
	Learning Rate: 0.000327921
	LOSS [training: 0.14991521508383945 | validation: 0.2984310952753392]
	TIME [epoch: 11.7 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1483769193032835		[learning rate: 0.00032647]
	Learning Rate: 0.000326472
	LOSS [training: 0.1483769193032835 | validation: 0.2769368479017961]
	TIME [epoch: 11.7 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14704288903918045		[learning rate: 0.00032503]
	Learning Rate: 0.00032503
	LOSS [training: 0.14704288903918045 | validation: 0.28437162550129425]
	TIME [epoch: 11.7 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15011560663471332		[learning rate: 0.00032359]
	Learning Rate: 0.000323594
	LOSS [training: 0.15011560663471332 | validation: 0.2867694149521601]
	TIME [epoch: 11.7 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14576613814156192		[learning rate: 0.00032216]
	Learning Rate: 0.000322164
	LOSS [training: 0.14576613814156192 | validation: 0.28056266937077634]
	TIME [epoch: 11.7 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14884210676810553		[learning rate: 0.00032074]
	Learning Rate: 0.000320741
	LOSS [training: 0.14884210676810553 | validation: 0.2922952889363501]
	TIME [epoch: 11.7 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14884116431396693		[learning rate: 0.00031932]
	Learning Rate: 0.000319323
	LOSS [training: 0.14884116431396693 | validation: 0.28465330440206177]
	TIME [epoch: 11.7 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14990088485074207		[learning rate: 0.00031791]
	Learning Rate: 0.000317913
	LOSS [training: 0.14990088485074207 | validation: 0.27680912351502696]
	TIME [epoch: 11.7 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14737302926734777		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 0.14737302926734777 | validation: 0.295105930371316]
	TIME [epoch: 11.7 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15151545415812778		[learning rate: 0.00031511]
	Learning Rate: 0.00031511
	LOSS [training: 0.15151545415812778 | validation: 0.2917776539183299]
	TIME [epoch: 11.7 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15137790613729404		[learning rate: 0.00031372]
	Learning Rate: 0.000313717
	LOSS [training: 0.15137790613729404 | validation: 0.2883662452889814]
	TIME [epoch: 11.7 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15436070251615364		[learning rate: 0.00031233]
	Learning Rate: 0.000312331
	LOSS [training: 0.15436070251615364 | validation: 0.29816607415547247]
	TIME [epoch: 11.7 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1485538048414646		[learning rate: 0.00031095]
	Learning Rate: 0.000310951
	LOSS [training: 0.1485538048414646 | validation: 0.2879044270941865]
	TIME [epoch: 11.7 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1557410031823943		[learning rate: 0.00030958]
	Learning Rate: 0.000309577
	LOSS [training: 0.1557410031823943 | validation: 0.2881547325176586]
	TIME [epoch: 11.7 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14692224337804505		[learning rate: 0.00030821]
	Learning Rate: 0.00030821
	LOSS [training: 0.14692224337804505 | validation: 0.2753428134897326]
	TIME [epoch: 11.7 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1490571889616338		[learning rate: 0.00030685]
	Learning Rate: 0.000306848
	LOSS [training: 0.1490571889616338 | validation: 0.2875390370050736]
	TIME [epoch: 11.7 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15299912677563096		[learning rate: 0.00030549]
	Learning Rate: 0.000305492
	LOSS [training: 0.15299912677563096 | validation: 0.29512991556843843]
	TIME [epoch: 11.7 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14938018232416087		[learning rate: 0.00030414]
	Learning Rate: 0.000304142
	LOSS [training: 0.14938018232416087 | validation: 0.2866066422126376]
	TIME [epoch: 11.7 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15117881936186556		[learning rate: 0.0003028]
	Learning Rate: 0.000302799
	LOSS [training: 0.15117881936186556 | validation: 0.2940778482124983]
	TIME [epoch: 11.7 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15101153036403958		[learning rate: 0.00030146]
	Learning Rate: 0.000301461
	LOSS [training: 0.15101153036403958 | validation: 0.28416047857389465]
	TIME [epoch: 11.7 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14860622293043219		[learning rate: 0.00030013]
	Learning Rate: 0.000300129
	LOSS [training: 0.14860622293043219 | validation: 0.2929254501242859]
	TIME [epoch: 11.7 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14807738065559378		[learning rate: 0.0002988]
	Learning Rate: 0.000298803
	LOSS [training: 0.14807738065559378 | validation: 0.2905918805017447]
	TIME [epoch: 11.7 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14395466843475718		[learning rate: 0.00029748]
	Learning Rate: 0.000297483
	LOSS [training: 0.14395466843475718 | validation: 0.290024287389611]
	TIME [epoch: 11.7 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1475667088809245		[learning rate: 0.00029617]
	Learning Rate: 0.000296168
	LOSS [training: 0.1475667088809245 | validation: 0.29585343783330126]
	TIME [epoch: 11.7 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14763163701844104		[learning rate: 0.00029486]
	Learning Rate: 0.00029486
	LOSS [training: 0.14763163701844104 | validation: 0.2876711235921093]
	TIME [epoch: 11.7 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14927164908125304		[learning rate: 0.00029356]
	Learning Rate: 0.000293557
	LOSS [training: 0.14927164908125304 | validation: 0.2891123294924774]
	TIME [epoch: 11.7 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1508349924665346		[learning rate: 0.00029226]
	Learning Rate: 0.00029226
	LOSS [training: 0.1508349924665346 | validation: 0.28483627039906434]
	TIME [epoch: 11.7 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14418578875944205		[learning rate: 0.00029097]
	Learning Rate: 0.000290969
	LOSS [training: 0.14418578875944205 | validation: 0.28272891495415153]
	TIME [epoch: 11.7 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1453058725945961		[learning rate: 0.00028968]
	Learning Rate: 0.000289683
	LOSS [training: 0.1453058725945961 | validation: 0.28363876222184536]
	TIME [epoch: 11.7 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14515604056809753		[learning rate: 0.0002884]
	Learning Rate: 0.000288403
	LOSS [training: 0.14515604056809753 | validation: 0.2925457784102085]
	TIME [epoch: 11.7 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14792831242299992		[learning rate: 0.00028713]
	Learning Rate: 0.000287129
	LOSS [training: 0.14792831242299992 | validation: 0.2859832119157134]
	TIME [epoch: 11.7 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14268674162707287		[learning rate: 0.00028586]
	Learning Rate: 0.00028586
	LOSS [training: 0.14268674162707287 | validation: 0.2963512872383573]
	TIME [epoch: 11.7 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14961996591411522		[learning rate: 0.0002846]
	Learning Rate: 0.000284597
	LOSS [training: 0.14961996591411522 | validation: 0.28223287036644334]
	TIME [epoch: 11.7 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14554388497175882		[learning rate: 0.00028334]
	Learning Rate: 0.00028334
	LOSS [training: 0.14554388497175882 | validation: 0.28372014285753716]
	TIME [epoch: 11.7 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15156337976884987		[learning rate: 0.00028209]
	Learning Rate: 0.000282088
	LOSS [training: 0.15156337976884987 | validation: 0.29196510688098615]
	TIME [epoch: 11.7 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14577270666089184		[learning rate: 0.00028084]
	Learning Rate: 0.000280842
	LOSS [training: 0.14577270666089184 | validation: 0.28707443156137913]
	TIME [epoch: 11.7 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14637752301270626		[learning rate: 0.0002796]
	Learning Rate: 0.000279601
	LOSS [training: 0.14637752301270626 | validation: 0.2819199187932597]
	TIME [epoch: 11.7 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14576729473255892		[learning rate: 0.00027837]
	Learning Rate: 0.000278366
	LOSS [training: 0.14576729473255892 | validation: 0.27757173318653716]
	TIME [epoch: 11.7 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1494220516541073		[learning rate: 0.00027714]
	Learning Rate: 0.000277136
	LOSS [training: 0.1494220516541073 | validation: 0.29550806475845326]
	TIME [epoch: 11.7 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v9_20240712_133637/states/model_facs_v2_dec2b_2dpca_v9_850.pth
Halted early. No improvement in validation loss for 200 epochs.
Finished training in 7213.651 seconds.
