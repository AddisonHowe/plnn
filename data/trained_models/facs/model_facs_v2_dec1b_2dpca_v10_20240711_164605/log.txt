Args:
Namespace(name='model_facs_v2_dec1b_2dpca_v10', outdir='out/model_training/model_facs_v2_dec1b_2dpca_v10', training_data='data/training_data/facs_v2/pca/dec1_fitonsubset/transition1_subset_epi_tr_ce_an_pc12/training', validation_data='data/training_data/facs_v2/pca/dec1_fitonsubset/transition1_subset_epi_tr_ce_an_pc12/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=10, batch_size=50, patience=200, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, quadratic_a=1.0, quadratic_b=1.0, ndims=2, nparams=2, nsigs=2, ncells=400, ncells_sample=400, model_do_sample=False, dt=0.005, dt_schedule='stepped', dt_schedule_bounds=[500, 1000, 1500], dt_schedule_scales=[0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=True, sigma=0.4, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', kernel='multiscale', bw_range=[0.2, 0.5, 0.9, 1.1, 1.3, 1.5, 2.0], optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 2029394924

Training model...

Saving initial model state to: out/model_training/model_facs_v2_dec1b_2dpca_v10_20240711_164605/states/model_facs_v2_dec1b_2dpca_v10_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.253804657353787		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.253804657353787 | validation: 1.0835060867562276]
	TIME [epoch: 44 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v10_20240711_164605/states/model_facs_v2_dec1b_2dpca_v10_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.0982903967180377		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0982903967180377 | validation: 0.9874862498067134]
	TIME [epoch: 9.52 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v10_20240711_164605/states/model_facs_v2_dec1b_2dpca_v10_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.0539187666951844		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0539187666951844 | validation: 0.9360765003414329]
	TIME [epoch: 9.5 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v10_20240711_164605/states/model_facs_v2_dec1b_2dpca_v10_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.9890782526386869		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9890782526386869 | validation: 0.924172364505378]
	TIME [epoch: 9.52 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v10_20240711_164605/states/model_facs_v2_dec1b_2dpca_v10_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.9048261711523706		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9048261711523706 | validation: 0.8368574252941052]
	TIME [epoch: 9.51 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v10_20240711_164605/states/model_facs_v2_dec1b_2dpca_v10_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.884657097415888		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.884657097415888 | validation: 0.8018506901592719]
	TIME [epoch: 9.51 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v10_20240711_164605/states/model_facs_v2_dec1b_2dpca_v10_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.8184497673141512		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8184497673141512 | validation: 0.8070662598805374]
	TIME [epoch: 9.53 sec]
EPOCH 8/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.8060961633466481		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8060961633466481 | validation: 0.7710157134868981]
	TIME [epoch: 9.52 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v10_20240711_164605/states/model_facs_v2_dec1b_2dpca_v10_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7774368491043585		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7774368491043585 | validation: 0.7625602665159511]
	TIME [epoch: 9.5 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v10_20240711_164605/states/model_facs_v2_dec1b_2dpca_v10_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7502930065827516		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7502930065827516 | validation: 0.6966889164098626]
	TIME [epoch: 9.52 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v10_20240711_164605/states/model_facs_v2_dec1b_2dpca_v10_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7311105269584905		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7311105269584905 | validation: 0.6900597922828229]
	TIME [epoch: 9.53 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v10_20240711_164605/states/model_facs_v2_dec1b_2dpca_v10_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7088417198802218		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7088417198802218 | validation: 0.6825204723704786]
	TIME [epoch: 9.52 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v10_20240711_164605/states/model_facs_v2_dec1b_2dpca_v10_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6588846394858867		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6588846394858867 | validation: 0.8981351018428926]
	TIME [epoch: 9.52 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6943510114091593		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6943510114091593 | validation: 0.64905920678033]
	TIME [epoch: 9.53 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v10_20240711_164605/states/model_facs_v2_dec1b_2dpca_v10_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6195004226339003		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6195004226339003 | validation: 0.6760429366433423]
	TIME [epoch: 9.52 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6302854971327694		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6302854971327694 | validation: 0.611334179946229]
	TIME [epoch: 9.51 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v10_20240711_164605/states/model_facs_v2_dec1b_2dpca_v10_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6015505304048884		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6015505304048884 | validation: 0.5461646553044905]
	TIME [epoch: 9.51 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v10_20240711_164605/states/model_facs_v2_dec1b_2dpca_v10_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5907397422994982		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5907397422994982 | validation: 0.6935139472787613]
	TIME [epoch: 9.52 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5606154500710243		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5606154500710243 | validation: 0.5146315626323558]
	TIME [epoch: 9.5 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v10_20240711_164605/states/model_facs_v2_dec1b_2dpca_v10_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5460544651579194		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5460544651579194 | validation: 0.4938901577684055]
	TIME [epoch: 9.51 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v10_20240711_164605/states/model_facs_v2_dec1b_2dpca_v10_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5546175536255183		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5546175536255183 | validation: 0.45588771141049794]
	TIME [epoch: 9.53 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v10_20240711_164605/states/model_facs_v2_dec1b_2dpca_v10_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.556249901546789		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.556249901546789 | validation: 0.6084051936048651]
	TIME [epoch: 9.53 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5874203055452604		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5874203055452604 | validation: 0.5097463152926778]
	TIME [epoch: 9.52 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.47449761800640655		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.47449761800640655 | validation: 0.4832430774391149]
	TIME [epoch: 9.52 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5211056213270415		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5211056213270415 | validation: 0.43741959719658174]
	TIME [epoch: 9.53 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v10_20240711_164605/states/model_facs_v2_dec1b_2dpca_v10_25.pth
	Model improved!!!
EPOCH 26/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5391748236489421		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5391748236489421 | validation: 0.5247664401623697]
	TIME [epoch: 9.53 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.47185203053826263		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.47185203053826263 | validation: 0.5457021686676422]
	TIME [epoch: 9.52 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.45625224741262715		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.45625224741262715 | validation: 0.5651954736072013]
	TIME [epoch: 9.52 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5180242745191082		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5180242745191082 | validation: 0.4341103322493714]
	TIME [epoch: 9.53 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v10_20240711_164605/states/model_facs_v2_dec1b_2dpca_v10_29.pth
	Model improved!!!
EPOCH 30/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.498542542253686		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.498542542253686 | validation: 0.47926567551024873]
	TIME [epoch: 9.53 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.43883340158617834		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.43883340158617834 | validation: 0.41131379242379884]
	TIME [epoch: 9.52 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v10_20240711_164605/states/model_facs_v2_dec1b_2dpca_v10_31.pth
	Model improved!!!
EPOCH 32/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4508243490010857		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4508243490010857 | validation: 0.4064698486901948]
	TIME [epoch: 9.53 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v10_20240711_164605/states/model_facs_v2_dec1b_2dpca_v10_32.pth
	Model improved!!!
EPOCH 33/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.45371607144207776		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.45371607144207776 | validation: 0.5741425844896175]
	TIME [epoch: 9.5 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.48303521764339		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.48303521764339 | validation: 0.3937320932566696]
	TIME [epoch: 9.5 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v10_20240711_164605/states/model_facs_v2_dec1b_2dpca_v10_34.pth
	Model improved!!!
EPOCH 35/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4414798581274986		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4414798581274986 | validation: 0.7919562923850335]
	TIME [epoch: 9.5 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5136215321638704		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5136215321638704 | validation: 0.38476399426631225]
	TIME [epoch: 9.51 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v10_20240711_164605/states/model_facs_v2_dec1b_2dpca_v10_36.pth
	Model improved!!!
EPOCH 37/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4585469349238743		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4585469349238743 | validation: 0.44580344140642697]
	TIME [epoch: 9.52 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.41438732575541204		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.41438732575541204 | validation: 0.6212268868019377]
	TIME [epoch: 9.52 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.46616524157549627		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.46616524157549627 | validation: 0.4483995890854235]
	TIME [epoch: 9.52 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.43854139347963783		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.43854139347963783 | validation: 0.46486091580602534]
	TIME [epoch: 9.53 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.419558636258129		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.419558636258129 | validation: 0.4396587795009827]
	TIME [epoch: 9.53 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4264380612634493		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4264380612634493 | validation: 0.4308872120093046]
	TIME [epoch: 9.52 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.42289078208456604		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.42289078208456604 | validation: 0.4510727900212223]
	TIME [epoch: 9.53 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4055576089851325		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4055576089851325 | validation: 0.37673746650498635]
	TIME [epoch: 9.53 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v10_20240711_164605/states/model_facs_v2_dec1b_2dpca_v10_44.pth
	Model improved!!!
EPOCH 45/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4047645825414912		[learning rate: 0.0099823]
	Learning Rate: 0.0099823
	LOSS [training: 0.4047645825414912 | validation: 0.4180928359605681]
	TIME [epoch: 9.52 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4199038417165465		[learning rate: 0.0099426]
	Learning Rate: 0.0099426
	LOSS [training: 0.4199038417165465 | validation: 0.44156596344653154]
	TIME [epoch: 9.52 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3994598577920429		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 0.3994598577920429 | validation: 0.38710331050171765]
	TIME [epoch: 9.54 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4226203569956838		[learning rate: 0.0098637]
	Learning Rate: 0.00986367
	LOSS [training: 0.4226203569956838 | validation: 0.5147995110301345]
	TIME [epoch: 9.52 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3831449280644664		[learning rate: 0.0098244]
	Learning Rate: 0.00982444
	LOSS [training: 0.3831449280644664 | validation: 0.3852983169092382]
	TIME [epoch: 9.52 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3993588391027721		[learning rate: 0.0097854]
	Learning Rate: 0.00978536
	LOSS [training: 0.3993588391027721 | validation: 0.36938144433784587]
	TIME [epoch: 9.51 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v10_20240711_164605/states/model_facs_v2_dec1b_2dpca_v10_50.pth
	Model improved!!!
EPOCH 51/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.39155294719337586		[learning rate: 0.0097464]
	Learning Rate: 0.00974644
	LOSS [training: 0.39155294719337586 | validation: 0.42201082032898407]
	TIME [epoch: 9.54 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5048750032864239		[learning rate: 0.0097077]
	Learning Rate: 0.00970768
	LOSS [training: 0.5048750032864239 | validation: 0.39950961941724045]
	TIME [epoch: 9.52 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.47141902193100826		[learning rate: 0.0096691]
	Learning Rate: 0.00966907
	LOSS [training: 0.47141902193100826 | validation: 0.4127247731564035]
	TIME [epoch: 9.52 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4955530672460221		[learning rate: 0.0096306]
	Learning Rate: 0.00963061
	LOSS [training: 0.4955530672460221 | validation: 0.3971435708418834]
	TIME [epoch: 9.53 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4234286404225968		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 0.4234286404225968 | validation: 0.4423800017003415]
	TIME [epoch: 9.53 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.41578852914277026		[learning rate: 0.0095542]
	Learning Rate: 0.00955415
	LOSS [training: 0.41578852914277026 | validation: 0.42825230199300873]
	TIME [epoch: 9.52 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.41280235291139666		[learning rate: 0.0095162]
	Learning Rate: 0.00951616
	LOSS [training: 0.41280235291139666 | validation: 0.3397608096058224]
	TIME [epoch: 9.52 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v10_20240711_164605/states/model_facs_v2_dec1b_2dpca_v10_57.pth
	Model improved!!!
EPOCH 58/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4370692755461014		[learning rate: 0.0094783]
	Learning Rate: 0.00947831
	LOSS [training: 0.4370692755461014 | validation: 0.4093611671655698]
	TIME [epoch: 9.54 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3976861859959315		[learning rate: 0.0094406]
	Learning Rate: 0.00944061
	LOSS [training: 0.3976861859959315 | validation: 0.4329721120220021]
	TIME [epoch: 9.52 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.38334626828173524		[learning rate: 0.0094031]
	Learning Rate: 0.00940306
	LOSS [training: 0.38334626828173524 | validation: 0.40988077762693165]
	TIME [epoch: 9.52 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.43393346227748364		[learning rate: 0.0093657]
	Learning Rate: 0.00936566
	LOSS [training: 0.43393346227748364 | validation: 0.4640369496158975]
	TIME [epoch: 9.52 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4227696646254451		[learning rate: 0.0093284]
	Learning Rate: 0.00932841
	LOSS [training: 0.4227696646254451 | validation: 0.42382146301064816]
	TIME [epoch: 9.53 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.375751536132507		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 0.375751536132507 | validation: 0.4158038885680213]
	TIME [epoch: 9.52 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.42496803978223463		[learning rate: 0.0092544]
	Learning Rate: 0.00925435
	LOSS [training: 0.42496803978223463 | validation: 0.3822274725807029]
	TIME [epoch: 9.51 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3764651611646285		[learning rate: 0.0092175]
	Learning Rate: 0.00921755
	LOSS [training: 0.3764651611646285 | validation: 0.3490615554773356]
	TIME [epoch: 9.52 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.34316487082245656		[learning rate: 0.0091809]
	Learning Rate: 0.00918089
	LOSS [training: 0.34316487082245656 | validation: 0.3611591110041035]
	TIME [epoch: 9.53 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3644968485136306		[learning rate: 0.0091444]
	Learning Rate: 0.00914437
	LOSS [training: 0.3644968485136306 | validation: 0.3732391751339903]
	TIME [epoch: 9.52 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.36234818801237606		[learning rate: 0.009108]
	Learning Rate: 0.009108
	LOSS [training: 0.36234818801237606 | validation: 0.3846739952178783]
	TIME [epoch: 9.52 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.36982080094949155		[learning rate: 0.0090718]
	Learning Rate: 0.00907178
	LOSS [training: 0.36982080094949155 | validation: 0.3609711119842394]
	TIME [epoch: 9.53 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3563476481676204		[learning rate: 0.0090357]
	Learning Rate: 0.00903569
	LOSS [training: 0.3563476481676204 | validation: 0.4103258422202215]
	TIME [epoch: 9.52 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3595971380807813		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 0.3595971380807813 | validation: 0.4370536484262712]
	TIME [epoch: 9.52 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.397226126957333		[learning rate: 0.008964]
	Learning Rate: 0.00896396
	LOSS [training: 0.397226126957333 | validation: 0.36901584076624144]
	TIME [epoch: 9.52 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3831273574494862		[learning rate: 0.0089283]
	Learning Rate: 0.00892831
	LOSS [training: 0.3831273574494862 | validation: 0.4355502784241635]
	TIME [epoch: 9.53 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.35161626251627054		[learning rate: 0.0088928]
	Learning Rate: 0.0088928
	LOSS [training: 0.35161626251627054 | validation: 0.35836801146534364]
	TIME [epoch: 9.52 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4115508261953653		[learning rate: 0.0088574]
	Learning Rate: 0.00885743
	LOSS [training: 0.4115508261953653 | validation: 0.31417067894153516]
	TIME [epoch: 9.52 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v10_20240711_164605/states/model_facs_v2_dec1b_2dpca_v10_75.pth
	Model improved!!!
EPOCH 76/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3461877853121408		[learning rate: 0.0088222]
	Learning Rate: 0.0088222
	LOSS [training: 0.3461877853121408 | validation: 0.34223020566587803]
	TIME [epoch: 9.52 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32540952264988715		[learning rate: 0.0087871]
	Learning Rate: 0.00878711
	LOSS [training: 0.32540952264988715 | validation: 0.37026264130642217]
	TIME [epoch: 9.53 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.37108903107369684		[learning rate: 0.0087522]
	Learning Rate: 0.00875216
	LOSS [training: 0.37108903107369684 | validation: 0.32400475009566765]
	TIME [epoch: 9.52 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3438031105593462		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 0.3438031105593462 | validation: 0.34985420661339117]
	TIME [epoch: 9.52 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3468605876938589		[learning rate: 0.0086827]
	Learning Rate: 0.00868268
	LOSS [training: 0.3468605876938589 | validation: 0.4381654099913955]
	TIME [epoch: 9.53 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3602632940412403		[learning rate: 0.0086481]
	Learning Rate: 0.00864815
	LOSS [training: 0.3602632940412403 | validation: 0.38366916970984094]
	TIME [epoch: 9.52 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3302066860909825		[learning rate: 0.0086138]
	Learning Rate: 0.00861375
	LOSS [training: 0.3302066860909825 | validation: 0.32872292169543116]
	TIME [epoch: 9.52 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3377672173753754		[learning rate: 0.0085795]
	Learning Rate: 0.00857949
	LOSS [training: 0.3377672173753754 | validation: 0.33691827988766165]
	TIME [epoch: 9.52 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3282644935043733		[learning rate: 0.0085454]
	Learning Rate: 0.00854537
	LOSS [training: 0.3282644935043733 | validation: 0.3272028614191932]
	TIME [epoch: 9.53 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32453971660952885		[learning rate: 0.0085114]
	Learning Rate: 0.00851138
	LOSS [training: 0.32453971660952885 | validation: 0.32458693771863856]
	TIME [epoch: 9.52 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3456485865433179		[learning rate: 0.0084775]
	Learning Rate: 0.00847753
	LOSS [training: 0.3456485865433179 | validation: 0.35684174925867973]
	TIME [epoch: 9.51 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32587477540322973		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 0.32587477540322973 | validation: 0.39597180092468565]
	TIME [epoch: 9.52 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.33977724029799267		[learning rate: 0.0084102]
	Learning Rate: 0.00841023
	LOSS [training: 0.33977724029799267 | validation: 0.3647791674264684]
	TIME [epoch: 9.53 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.321067470081557		[learning rate: 0.0083768]
	Learning Rate: 0.00837678
	LOSS [training: 0.321067470081557 | validation: 0.35464512471039084]
	TIME [epoch: 9.51 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3346169352409011		[learning rate: 0.0083435]
	Learning Rate: 0.00834346
	LOSS [training: 0.3346169352409011 | validation: 0.35844856948828097]
	TIME [epoch: 9.52 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3312847062938081		[learning rate: 0.0083103]
	Learning Rate: 0.00831027
	LOSS [training: 0.3312847062938081 | validation: 0.34766422685632475]
	TIME [epoch: 9.52 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3214565953180057		[learning rate: 0.0082772]
	Learning Rate: 0.00827722
	LOSS [training: 0.3214565953180057 | validation: 0.305684104861254]
	TIME [epoch: 9.53 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v10_20240711_164605/states/model_facs_v2_dec1b_2dpca_v10_92.pth
	Model improved!!!
EPOCH 93/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3424340889493522		[learning rate: 0.0082443]
	Learning Rate: 0.0082443
	LOSS [training: 0.3424340889493522 | validation: 0.35783450386512533]
	TIME [epoch: 9.51 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.31793710513892137		[learning rate: 0.0082115]
	Learning Rate: 0.00821151
	LOSS [training: 0.31793710513892137 | validation: 0.3273893842729455]
	TIME [epoch: 9.5 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3259620637595267		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 0.3259620637595267 | validation: 0.3333488653644014]
	TIME [epoch: 9.52 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.33456952721121336		[learning rate: 0.0081463]
	Learning Rate: 0.00814632
	LOSS [training: 0.33456952721121336 | validation: 0.307179179433361]
	TIME [epoch: 9.5 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.34455898307404564		[learning rate: 0.0081139]
	Learning Rate: 0.00811392
	LOSS [training: 0.34455898307404564 | validation: 0.31219590990564383]
	TIME [epoch: 9.5 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3293085261787371		[learning rate: 0.0080816]
	Learning Rate: 0.00808165
	LOSS [training: 0.3293085261787371 | validation: 0.32677116779127785]
	TIME [epoch: 9.5 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32990777146964306		[learning rate: 0.0080495]
	Learning Rate: 0.00804951
	LOSS [training: 0.32990777146964306 | validation: 0.32525804197679287]
	TIME [epoch: 9.52 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.33840309801726903		[learning rate: 0.0080175]
	Learning Rate: 0.00801749
	LOSS [training: 0.33840309801726903 | validation: 0.4125895192388526]
	TIME [epoch: 9.5 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.34969946773902844		[learning rate: 0.0079856]
	Learning Rate: 0.0079856
	LOSS [training: 0.34969946773902844 | validation: 0.3877675817699427]
	TIME [epoch: 9.5 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3228520048449557		[learning rate: 0.0079538]
	Learning Rate: 0.00795384
	LOSS [training: 0.3228520048449557 | validation: 0.32022019702501703]
	TIME [epoch: 9.51 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3310474307194276		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 0.3310474307194276 | validation: 0.31142442653198327]
	TIME [epoch: 9.51 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.33038537501978876		[learning rate: 0.0078907]
	Learning Rate: 0.0078907
	LOSS [training: 0.33038537501978876 | validation: 0.4319690309428325]
	TIME [epoch: 9.5 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3361812231083185		[learning rate: 0.0078593]
	Learning Rate: 0.00785931
	LOSS [training: 0.3361812231083185 | validation: 0.30495479569288914]
	TIME [epoch: 9.5 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v10_20240711_164605/states/model_facs_v2_dec1b_2dpca_v10_105.pth
	Model improved!!!
EPOCH 106/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.29713781863223043		[learning rate: 0.0078281]
	Learning Rate: 0.00782805
	LOSS [training: 0.29713781863223043 | validation: 0.326122344962832]
	TIME [epoch: 9.53 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32330428679033535		[learning rate: 0.0077969]
	Learning Rate: 0.00779692
	LOSS [training: 0.32330428679033535 | validation: 0.31360204555502696]
	TIME [epoch: 9.52 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.30242115118974894		[learning rate: 0.0077659]
	Learning Rate: 0.00776591
	LOSS [training: 0.30242115118974894 | validation: 0.3235226507754436]
	TIME [epoch: 9.52 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.31791000384459245		[learning rate: 0.007735]
	Learning Rate: 0.00773502
	LOSS [training: 0.31791000384459245 | validation: 0.3298013382789152]
	TIME [epoch: 9.52 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.31566812175247416		[learning rate: 0.0077043]
	Learning Rate: 0.00770426
	LOSS [training: 0.31566812175247416 | validation: 0.31360660446863553]
	TIME [epoch: 9.53 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3037211988189356		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 0.3037211988189356 | validation: 0.3367153389054326]
	TIME [epoch: 9.52 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3019359526916859		[learning rate: 0.0076431]
	Learning Rate: 0.00764309
	LOSS [training: 0.3019359526916859 | validation: 0.317848698765473]
	TIME [epoch: 9.52 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3230540599212635		[learning rate: 0.0076127]
	Learning Rate: 0.00761269
	LOSS [training: 0.3230540599212635 | validation: 0.3407877511450252]
	TIME [epoch: 9.52 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32882525638691174		[learning rate: 0.0075824]
	Learning Rate: 0.00758242
	LOSS [training: 0.32882525638691174 | validation: 0.33582776557913946]
	TIME [epoch: 9.53 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32404432611706424		[learning rate: 0.0075523]
	Learning Rate: 0.00755226
	LOSS [training: 0.32404432611706424 | validation: 0.2970665889040989]
	TIME [epoch: 9.52 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v10_20240711_164605/states/model_facs_v2_dec1b_2dpca_v10_115.pth
	Model improved!!!
EPOCH 116/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2974794437348531		[learning rate: 0.0075222]
	Learning Rate: 0.00752222
	LOSS [training: 0.2974794437348531 | validation: 0.29694991620105526]
	TIME [epoch: 9.51 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v10_20240711_164605/states/model_facs_v2_dec1b_2dpca_v10_116.pth
	Model improved!!!
EPOCH 117/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.30949838567400884		[learning rate: 0.0074923]
	Learning Rate: 0.0074923
	LOSS [training: 0.30949838567400884 | validation: 0.34876345328163316]
	TIME [epoch: 9.53 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3160739621895312		[learning rate: 0.0074625]
	Learning Rate: 0.0074625
	LOSS [training: 0.3160739621895312 | validation: 0.2852818819461739]
	TIME [epoch: 9.5 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v10_20240711_164605/states/model_facs_v2_dec1b_2dpca_v10_118.pth
	Model improved!!!
EPOCH 119/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2876377295567317		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 0.2876377295567317 | validation: 0.39019754394841283]
	TIME [epoch: 9.51 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3065637918130293		[learning rate: 0.0074033]
	Learning Rate: 0.00740326
	LOSS [training: 0.3065637918130293 | validation: 0.32034338656820605]
	TIME [epoch: 9.5 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.30058670054080167		[learning rate: 0.0073738]
	Learning Rate: 0.00737382
	LOSS [training: 0.30058670054080167 | validation: 0.30780823793721757]
	TIME [epoch: 9.53 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3136206565112532		[learning rate: 0.0073445]
	Learning Rate: 0.00734449
	LOSS [training: 0.3136206565112532 | validation: 0.3713337788703953]
	TIME [epoch: 9.51 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3264310142700985		[learning rate: 0.0073153]
	Learning Rate: 0.00731528
	LOSS [training: 0.3264310142700985 | validation: 0.29817095051131204]
	TIME [epoch: 9.51 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.30747179736308355		[learning rate: 0.0072862]
	Learning Rate: 0.00728618
	LOSS [training: 0.30747179736308355 | validation: 0.30639757939937684]
	TIME [epoch: 9.51 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.30330035819697193		[learning rate: 0.0072572]
	Learning Rate: 0.0072572
	LOSS [training: 0.30330035819697193 | validation: 0.3147886810140935]
	TIME [epoch: 9.52 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3669849219946322		[learning rate: 0.0072283]
	Learning Rate: 0.00722834
	LOSS [training: 0.3669849219946322 | validation: 0.5283030909012656]
	TIME [epoch: 9.51 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.44398649902151077		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 0.44398649902151077 | validation: 0.35512254530949805]
	TIME [epoch: 9.51 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.340759312874826		[learning rate: 0.007171]
	Learning Rate: 0.00717095
	LOSS [training: 0.340759312874826 | validation: 0.3388888128059341]
	TIME [epoch: 9.52 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3066639762598984		[learning rate: 0.0071424]
	Learning Rate: 0.00714243
	LOSS [training: 0.3066639762598984 | validation: 0.30957930423962077]
	TIME [epoch: 9.52 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.311932486158639		[learning rate: 0.007114]
	Learning Rate: 0.00711403
	LOSS [training: 0.311932486158639 | validation: 0.31156173646251767]
	TIME [epoch: 9.51 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.29800403269372044		[learning rate: 0.0070857]
	Learning Rate: 0.00708573
	LOSS [training: 0.29800403269372044 | validation: 0.2965714151446376]
	TIME [epoch: 9.51 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.30815668169184424		[learning rate: 0.0070575]
	Learning Rate: 0.00705755
	LOSS [training: 0.30815668169184424 | validation: 0.33326989542224233]
	TIME [epoch: 9.53 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32899420854722		[learning rate: 0.0070295]
	Learning Rate: 0.00702948
	LOSS [training: 0.32899420854722 | validation: 0.32631803590835806]
	TIME [epoch: 9.51 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2963068046071651		[learning rate: 0.0070015]
	Learning Rate: 0.00700152
	LOSS [training: 0.2963068046071651 | validation: 0.30510207130290706]
	TIME [epoch: 9.51 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3203306518568339		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 0.3203306518568339 | validation: 0.3078959667374379]
	TIME [epoch: 9.51 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.29299480308852277		[learning rate: 0.0069459]
	Learning Rate: 0.00694594
	LOSS [training: 0.29299480308852277 | validation: 0.3007876731446663]
	TIME [epoch: 9.53 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3151193181146456		[learning rate: 0.0069183]
	Learning Rate: 0.00691831
	LOSS [training: 0.3151193181146456 | validation: 0.29551902666050556]
	TIME [epoch: 9.5 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3028798712714213		[learning rate: 0.0068908]
	Learning Rate: 0.00689079
	LOSS [training: 0.3028798712714213 | validation: 0.33713664602375265]
	TIME [epoch: 9.51 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.31635081439019264		[learning rate: 0.0068634]
	Learning Rate: 0.00686339
	LOSS [training: 0.31635081439019264 | validation: 0.33730863767524494]
	TIME [epoch: 9.51 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.29196706764243646		[learning rate: 0.0068361]
	Learning Rate: 0.00683609
	LOSS [training: 0.29196706764243646 | validation: 0.3140513996035166]
	TIME [epoch: 9.53 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.31168904926175983		[learning rate: 0.0068089]
	Learning Rate: 0.0068089
	LOSS [training: 0.31168904926175983 | validation: 0.29472943529955253]
	TIME [epoch: 9.51 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.30944869762978555		[learning rate: 0.0067818]
	Learning Rate: 0.00678182
	LOSS [training: 0.30944869762978555 | validation: 0.31885041528785285]
	TIME [epoch: 9.51 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2791889588267908		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 0.2791889588267908 | validation: 0.2844298659350023]
	TIME [epoch: 9.52 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v10_20240711_164605/states/model_facs_v2_dec1b_2dpca_v10_143.pth
	Model improved!!!
EPOCH 144/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2998890589520791		[learning rate: 0.006728]
	Learning Rate: 0.00672798
	LOSS [training: 0.2998890589520791 | validation: 0.32798033922913916]
	TIME [epoch: 9.53 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3074221123035057		[learning rate: 0.0067012]
	Learning Rate: 0.00670122
	LOSS [training: 0.3074221123035057 | validation: 0.30021311000490136]
	TIME [epoch: 9.51 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.31295719270383376		[learning rate: 0.0066746]
	Learning Rate: 0.00667457
	LOSS [training: 0.31295719270383376 | validation: 0.3459218330838258]
	TIME [epoch: 9.51 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.33082689996123665		[learning rate: 0.006648]
	Learning Rate: 0.00664802
	LOSS [training: 0.33082689996123665 | validation: 0.30604200284150157]
	TIME [epoch: 9.53 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.28878437084913805		[learning rate: 0.0066216]
	Learning Rate: 0.00662158
	LOSS [training: 0.28878437084913805 | validation: 0.29626782692077025]
	TIME [epoch: 9.52 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.31356616541445653		[learning rate: 0.0065952]
	Learning Rate: 0.00659524
	LOSS [training: 0.31356616541445653 | validation: 0.33666915618735294]
	TIME [epoch: 9.51 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32714085491273814		[learning rate: 0.006569]
	Learning Rate: 0.00656901
	LOSS [training: 0.32714085491273814 | validation: 0.2993668114608167]
	TIME [epoch: 9.52 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3042638874382224		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 0.3042638874382224 | validation: 0.3248095117055905]
	TIME [epoch: 9.52 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.30079516152813474		[learning rate: 0.0065169]
	Learning Rate: 0.00651686
	LOSS [training: 0.30079516152813474 | validation: 0.347323273805117]
	TIME [epoch: 9.52 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.30135790935666085		[learning rate: 0.0064909]
	Learning Rate: 0.00649094
	LOSS [training: 0.30135790935666085 | validation: 0.30586816186903537]
	TIME [epoch: 9.51 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3194145015324771		[learning rate: 0.0064651]
	Learning Rate: 0.00646512
	LOSS [training: 0.3194145015324771 | validation: 0.3044903697405275]
	TIME [epoch: 9.52 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3028022337884427		[learning rate: 0.0064394]
	Learning Rate: 0.00643941
	LOSS [training: 0.3028022337884427 | validation: 0.2954489959242467]
	TIME [epoch: 9.52 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.29930628196282183		[learning rate: 0.0064138]
	Learning Rate: 0.0064138
	LOSS [training: 0.29930628196282183 | validation: 0.33322017694101425]
	TIME [epoch: 9.52 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3119398416662006		[learning rate: 0.0063883]
	Learning Rate: 0.00638829
	LOSS [training: 0.3119398416662006 | validation: 0.3235707494224579]
	TIME [epoch: 9.51 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3122398099943231		[learning rate: 0.0063629]
	Learning Rate: 0.00636288
	LOSS [training: 0.3122398099943231 | validation: 0.28686438590589003]
	TIME [epoch: 9.52 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2979419247747733		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 0.2979419247747733 | validation: 0.35197246275713184]
	TIME [epoch: 9.52 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.28394787503178054		[learning rate: 0.0063124]
	Learning Rate: 0.00631237
	LOSS [training: 0.28394787503178054 | validation: 0.3126298417487344]
	TIME [epoch: 9.51 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3157130453886066		[learning rate: 0.0062873]
	Learning Rate: 0.00628726
	LOSS [training: 0.3157130453886066 | validation: 0.3233079948048433]
	TIME [epoch: 9.5 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2886865753168526		[learning rate: 0.0062623]
	Learning Rate: 0.00626226
	LOSS [training: 0.2886865753168526 | validation: 0.3005378872457748]
	TIME [epoch: 9.54 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3194974727264789		[learning rate: 0.0062373]
	Learning Rate: 0.00623735
	LOSS [training: 0.3194974727264789 | validation: 0.3216572862639658]
	TIME [epoch: 9.5 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.30735827506404834		[learning rate: 0.0062125]
	Learning Rate: 0.00621254
	LOSS [training: 0.30735827506404834 | validation: 0.33324852473625]
	TIME [epoch: 9.51 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3029390276931523		[learning rate: 0.0061878]
	Learning Rate: 0.00618783
	LOSS [training: 0.3029390276931523 | validation: 0.2982039647451933]
	TIME [epoch: 9.5 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.29733365708331266		[learning rate: 0.0061632]
	Learning Rate: 0.00616322
	LOSS [training: 0.29733365708331266 | validation: 0.2946433101903344]
	TIME [epoch: 9.53 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2926142205087278		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 0.2926142205087278 | validation: 0.3061476806552948]
	TIME [epoch: 9.52 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2752145327174295		[learning rate: 0.0061143]
	Learning Rate: 0.00611429
	LOSS [training: 0.2752145327174295 | validation: 0.27572997196077953]
	TIME [epoch: 9.51 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v10_20240711_164605/states/model_facs_v2_dec1b_2dpca_v10_168.pth
	Model improved!!!
EPOCH 169/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2961365362875047		[learning rate: 0.00609]
	Learning Rate: 0.00608997
	LOSS [training: 0.2961365362875047 | validation: 0.37308452641294215]
	TIME [epoch: 9.53 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3197517986986944		[learning rate: 0.0060658]
	Learning Rate: 0.00606575
	LOSS [training: 0.3197517986986944 | validation: 0.29202319390424397]
	TIME [epoch: 9.51 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2855897361814156		[learning rate: 0.0060416]
	Learning Rate: 0.00604163
	LOSS [training: 0.2855897361814156 | validation: 0.29860565983309906]
	TIME [epoch: 9.51 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2787452729339415		[learning rate: 0.0060176]
	Learning Rate: 0.0060176
	LOSS [training: 0.2787452729339415 | validation: 0.3593823784154339]
	TIME [epoch: 9.51 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2985772619612331		[learning rate: 0.0059937]
	Learning Rate: 0.00599366
	LOSS [training: 0.2985772619612331 | validation: 0.3165417072576842]
	TIME [epoch: 9.52 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.28399450343878		[learning rate: 0.0059698]
	Learning Rate: 0.00596982
	LOSS [training: 0.28399450343878 | validation: 0.2929259298602473]
	TIME [epoch: 9.51 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2845135002712474		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 0.2845135002712474 | validation: 0.27578181756378894]
	TIME [epoch: 9.51 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3625729734918876		[learning rate: 0.0059224]
	Learning Rate: 0.00592243
	LOSS [training: 0.3625729734918876 | validation: 0.2927558864633652]
	TIME [epoch: 9.51 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.28271460307093244		[learning rate: 0.0058989]
	Learning Rate: 0.00589888
	LOSS [training: 0.28271460307093244 | validation: 0.4033332562929397]
	TIME [epoch: 9.53 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2872923871621876		[learning rate: 0.0058754]
	Learning Rate: 0.00587541
	LOSS [training: 0.2872923871621876 | validation: 0.2905683979839758]
	TIME [epoch: 9.49 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2800071088108973		[learning rate: 0.005852]
	Learning Rate: 0.00585205
	LOSS [training: 0.2800071088108973 | validation: 0.2844979226377478]
	TIME [epoch: 9.5 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2739435341909106		[learning rate: 0.0058288]
	Learning Rate: 0.00582877
	LOSS [training: 0.2739435341909106 | validation: 0.28835994026216116]
	TIME [epoch: 9.51 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.30248410473292586		[learning rate: 0.0058056]
	Learning Rate: 0.00580559
	LOSS [training: 0.30248410473292586 | validation: 0.3281924202459892]
	TIME [epoch: 9.52 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3012828590670631		[learning rate: 0.0057825]
	Learning Rate: 0.0057825
	LOSS [training: 0.3012828590670631 | validation: 0.30969604483089275]
	TIME [epoch: 9.51 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2941730308004581		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 0.2941730308004581 | validation: 0.3100345533216102]
	TIME [epoch: 9.51 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.30251679191515857		[learning rate: 0.0057366]
	Learning Rate: 0.00573659
	LOSS [training: 0.30251679191515857 | validation: 0.3481737026011554]
	TIME [epoch: 9.52 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.28794009810438637		[learning rate: 0.0057138]
	Learning Rate: 0.00571377
	LOSS [training: 0.28794009810438637 | validation: 0.29906058364808563]
	TIME [epoch: 9.52 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2961762151765298		[learning rate: 0.005691]
	Learning Rate: 0.00569105
	LOSS [training: 0.2961762151765298 | validation: 0.3292782733363985]
	TIME [epoch: 9.51 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2882478078037729		[learning rate: 0.0056684]
	Learning Rate: 0.00566841
	LOSS [training: 0.2882478078037729 | validation: 0.3131440450255455]
	TIME [epoch: 9.51 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.31122636633642825		[learning rate: 0.0056459]
	Learning Rate: 0.00564587
	LOSS [training: 0.31122636633642825 | validation: 0.31239131437601936]
	TIME [epoch: 9.51 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2995298884720742		[learning rate: 0.0056234]
	Learning Rate: 0.00562341
	LOSS [training: 0.2995298884720742 | validation: 0.2787061753375167]
	TIME [epoch: 9.51 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2811851422001717		[learning rate: 0.005601]
	Learning Rate: 0.00560105
	LOSS [training: 0.2811851422001717 | validation: 0.30263383917660636]
	TIME [epoch: 9.51 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.29132673460015773		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 0.29132673460015773 | validation: 0.2866395005167507]
	TIME [epoch: 9.51 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.28840354423915066		[learning rate: 0.0055566]
	Learning Rate: 0.00555658
	LOSS [training: 0.28840354423915066 | validation: 0.28420559164499754]
	TIME [epoch: 9.52 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.29878603632002687		[learning rate: 0.0055345]
	Learning Rate: 0.00553448
	LOSS [training: 0.29878603632002687 | validation: 0.2842567616672819]
	TIME [epoch: 9.52 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.27173439629321927		[learning rate: 0.0055125]
	Learning Rate: 0.00551247
	LOSS [training: 0.27173439629321927 | validation: 0.2760972403686514]
	TIME [epoch: 9.5 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3098813866839317		[learning rate: 0.0054905]
	Learning Rate: 0.00549054
	LOSS [training: 0.3098813866839317 | validation: 0.3277879271618908]
	TIME [epoch: 9.52 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2986073773164362		[learning rate: 0.0054687]
	Learning Rate: 0.00546871
	LOSS [training: 0.2986073773164362 | validation: 0.38667017897156414]
	TIME [epoch: 9.53 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.34565247101870145		[learning rate: 0.005447]
	Learning Rate: 0.00544696
	LOSS [training: 0.34565247101870145 | validation: 0.33824534665855444]
	TIME [epoch: 9.51 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2994342387339548		[learning rate: 0.0054253]
	Learning Rate: 0.00542529
	LOSS [training: 0.2994342387339548 | validation: 0.28919042131463313]
	TIME [epoch: 9.51 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.27432911146445343		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 0.27432911146445343 | validation: 0.28534981379162316]
	TIME [epoch: 9.52 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2622463544108653		[learning rate: 0.0053822]
	Learning Rate: 0.00538222
	LOSS [training: 0.2622463544108653 | validation: 0.2814141785817782]
	TIME [epoch: 9.52 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.28301960802415027		[learning rate: 0.0053608]
	Learning Rate: 0.00536081
	LOSS [training: 0.28301960802415027 | validation: 0.27675167147321206]
	TIME [epoch: 9.51 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.28636467219849693		[learning rate: 0.0053395]
	Learning Rate: 0.00533949
	LOSS [training: 0.28636467219849693 | validation: 0.3308485307767542]
	TIME [epoch: 9.51 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2896502688690559		[learning rate: 0.0053183]
	Learning Rate: 0.00531826
	LOSS [training: 0.2896502688690559 | validation: 0.29079839384352274]
	TIME [epoch: 9.53 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.28813430294436376		[learning rate: 0.0052971]
	Learning Rate: 0.0052971
	LOSS [training: 0.28813430294436376 | validation: 0.27770413002664285]
	TIME [epoch: 9.51 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.27853730536748295		[learning rate: 0.005276]
	Learning Rate: 0.00527604
	LOSS [training: 0.27853730536748295 | validation: 0.2813433254982882]
	TIME [epoch: 9.51 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3132067401506975		[learning rate: 0.0052551]
	Learning Rate: 0.00525505
	LOSS [training: 0.3132067401506975 | validation: 0.2962333283268098]
	TIME [epoch: 9.51 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.28991990233380693		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 0.28991990233380693 | validation: 0.2805096956808239]
	TIME [epoch: 9.54 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2745566557607647		[learning rate: 0.0052133]
	Learning Rate: 0.00521333
	LOSS [training: 0.2745566557607647 | validation: 0.31470951705170597]
	TIME [epoch: 9.52 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.30042333193438986		[learning rate: 0.0051926]
	Learning Rate: 0.0051926
	LOSS [training: 0.30042333193438986 | validation: 0.31851232049951694]
	TIME [epoch: 9.52 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.30685648777276187		[learning rate: 0.0051719]
	Learning Rate: 0.00517194
	LOSS [training: 0.30685648777276187 | validation: 0.2896790569858285]
	TIME [epoch: 9.52 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3345097580923509		[learning rate: 0.0051514]
	Learning Rate: 0.00515137
	LOSS [training: 0.3345097580923509 | validation: 0.3056778747378849]
	TIME [epoch: 9.52 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.28592578270287056		[learning rate: 0.0051309]
	Learning Rate: 0.00513089
	LOSS [training: 0.28592578270287056 | validation: 0.30172608189916933]
	TIME [epoch: 9.51 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2897618836135274		[learning rate: 0.0051105]
	Learning Rate: 0.00511048
	LOSS [training: 0.2897618836135274 | validation: 0.2999904586663949]
	TIME [epoch: 9.5 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3396096936511745		[learning rate: 0.0050902]
	Learning Rate: 0.00509015
	LOSS [training: 0.3396096936511745 | validation: 0.3083174192498561]
	TIME [epoch: 9.53 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2829830441480731		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 0.2829830441480731 | validation: 0.2748207513524363]
	TIME [epoch: 9.51 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v10_20240711_164605/states/model_facs_v2_dec1b_2dpca_v10_215.pth
	Model improved!!!
EPOCH 216/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2732570204636796		[learning rate: 0.0050497]
	Learning Rate: 0.00504974
	LOSS [training: 0.2732570204636796 | validation: 0.2838284895580435]
	TIME [epoch: 9.51 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2629822139658736		[learning rate: 0.0050297]
	Learning Rate: 0.00502966
	LOSS [training: 0.2629822139658736 | validation: 0.28105487897086434]
	TIME [epoch: 9.51 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.30033764681543484		[learning rate: 0.0050097]
	Learning Rate: 0.00500965
	LOSS [training: 0.30033764681543484 | validation: 0.2814655026507401]
	TIME [epoch: 9.53 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.27174315030869667		[learning rate: 0.0049897]
	Learning Rate: 0.00498973
	LOSS [training: 0.27174315030869667 | validation: 0.292602379914332]
	TIME [epoch: 9.51 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3038488217966576		[learning rate: 0.0049699]
	Learning Rate: 0.00496988
	LOSS [training: 0.3038488217966576 | validation: 0.3091999370853582]
	TIME [epoch: 9.5 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3168217228529449		[learning rate: 0.0049501]
	Learning Rate: 0.00495012
	LOSS [training: 0.3168217228529449 | validation: 0.4099326006975995]
	TIME [epoch: 9.51 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.37742721599887796		[learning rate: 0.0049304]
	Learning Rate: 0.00493043
	LOSS [training: 0.37742721599887796 | validation: 0.30327050517109266]
	TIME [epoch: 9.51 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32997998658211025		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 0.32997998658211025 | validation: 0.3058180809371308]
	TIME [epoch: 9.5 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.30430260916884994		[learning rate: 0.0048913]
	Learning Rate: 0.00489129
	LOSS [training: 0.30430260916884994 | validation: 0.3708849530877534]
	TIME [epoch: 9.5 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3054346526179689		[learning rate: 0.0048718]
	Learning Rate: 0.00487183
	LOSS [training: 0.3054346526179689 | validation: 0.28072002100362703]
	TIME [epoch: 9.51 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.29754390512613677		[learning rate: 0.0048525]
	Learning Rate: 0.00485245
	LOSS [training: 0.29754390512613677 | validation: 0.3049179547124005]
	TIME [epoch: 9.52 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3993798642436923		[learning rate: 0.0048332]
	Learning Rate: 0.00483316
	LOSS [training: 0.3993798642436923 | validation: 0.48118001331537696]
	TIME [epoch: 9.51 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.40574845526926134		[learning rate: 0.0048139]
	Learning Rate: 0.00481393
	LOSS [training: 0.40574845526926134 | validation: 0.3317047478687856]
	TIME [epoch: 9.51 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.39209797397795615		[learning rate: 0.0047948]
	Learning Rate: 0.00479479
	LOSS [training: 0.39209797397795615 | validation: 0.33046417666111505]
	TIME [epoch: 9.52 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32756896665597846		[learning rate: 0.0047757]
	Learning Rate: 0.00477572
	LOSS [training: 0.32756896665597846 | validation: 0.3479900681180559]
	TIME [epoch: 9.51 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3332692708216399		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.3332692708216399 | validation: 0.3421763757931006]
	TIME [epoch: 9.51 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3176897254092459		[learning rate: 0.0047378]
	Learning Rate: 0.0047378
	LOSS [training: 0.3176897254092459 | validation: 0.2876062943529015]
	TIME [epoch: 9.51 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.30302842930621454		[learning rate: 0.004719]
	Learning Rate: 0.00471896
	LOSS [training: 0.30302842930621454 | validation: 0.342980728272912]
	TIME [epoch: 9.53 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3228579510933307		[learning rate: 0.0047002]
	Learning Rate: 0.00470019
	LOSS [training: 0.3228579510933307 | validation: 0.3142712486949836]
	TIME [epoch: 9.5 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3108155317551212		[learning rate: 0.0046815]
	Learning Rate: 0.0046815
	LOSS [training: 0.3108155317551212 | validation: 0.29380278472994387]
	TIME [epoch: 9.52 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3001447562558723		[learning rate: 0.0046629]
	Learning Rate: 0.00466288
	LOSS [training: 0.3001447562558723 | validation: 0.28141011313794934]
	TIME [epoch: 9.79 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2956182304685353		[learning rate: 0.0046443]
	Learning Rate: 0.00464433
	LOSS [training: 0.2956182304685353 | validation: 0.27052862107870873]
	TIME [epoch: 9.53 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v10_20240711_164605/states/model_facs_v2_dec1b_2dpca_v10_237.pth
	Model improved!!!
EPOCH 238/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.291638049532301		[learning rate: 0.0046259]
	Learning Rate: 0.00462586
	LOSS [training: 0.291638049532301 | validation: 0.28553363587855995]
	TIME [epoch: 9.53 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3102274100591324		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 0.3102274100591324 | validation: 0.32857589673390974]
	TIME [epoch: 9.52 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3660074797861658		[learning rate: 0.0045891]
	Learning Rate: 0.00458913
	LOSS [training: 0.3660074797861658 | validation: 0.6179530428057697]
	TIME [epoch: 9.54 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 9/9] avg loss: 2.568999564994122		[learning rate: 0.0045709]
	Learning Rate: 0.00457088
	LOSS [training: 2.568999564994122 | validation: 3.6474307186674784]
	TIME [epoch: 9.52 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 9/9] avg loss: 4.446580866625884		[learning rate: 0.0045527]
	Learning Rate: 0.0045527
	LOSS [training: 4.446580866625884 | validation: 5.4994550004176705]
	TIME [epoch: 9.52 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 9/9] avg loss: 5.044277489290038		[learning rate: 0.0045346]
	Learning Rate: 0.00453459
	LOSS [training: 5.044277489290038 | validation: 4.500039943816679]
	TIME [epoch: 9.51 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 9/9] avg loss: 4.064382864143316		[learning rate: 0.0045166]
	Learning Rate: 0.00451656
	LOSS [training: 4.064382864143316 | validation: 3.2680612042980415]
	TIME [epoch: 9.53 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 9/9] avg loss: 3.2256505385866934		[learning rate: 0.0044986]
	Learning Rate: 0.0044986
	LOSS [training: 3.2256505385866934 | validation: 2.7580590183456035]
	TIME [epoch: 9.51 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 9/9] avg loss: 2.7955255889090616		[learning rate: 0.0044807]
	Learning Rate: 0.0044807
	LOSS [training: 2.7955255889090616 | validation: 2.3192290345545623]
	TIME [epoch: 9.51 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 9/9] avg loss: 2.4984294903021858		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 2.4984294903021858 | validation: 2.0614027269842077]
	TIME [epoch: 9.51 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.892479224168106		[learning rate: 0.0044451]
	Learning Rate: 0.00444513
	LOSS [training: 1.892479224168106 | validation: 1.8386878088630199]
	TIME [epoch: 9.53 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.8503715511362482		[learning rate: 0.0044275]
	Learning Rate: 0.00442745
	LOSS [training: 1.8503715511362482 | validation: 1.0262167404115572]
	TIME [epoch: 9.51 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.2750545140062066		[learning rate: 0.0044098]
	Learning Rate: 0.00440984
	LOSS [training: 1.2750545140062066 | validation: 1.396725181236285]
	TIME [epoch: 9.51 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.7621787248886234		[learning rate: 0.0043923]
	Learning Rate: 0.0043923
	LOSS [training: 1.7621787248886234 | validation: 1.9334848016258879]
	TIME [epoch: 9.52 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 9/9] avg loss: 2.5348091951986103		[learning rate: 0.0043748]
	Learning Rate: 0.00437483
	LOSS [training: 2.5348091951986103 | validation: 3.288225040636933]
	TIME [epoch: 9.52 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 9/9] avg loss: 2.6260124867408092		[learning rate: 0.0043574]
	Learning Rate: 0.00435743
	LOSS [training: 2.6260124867408092 | validation: 1.0832445265470556]
	TIME [epoch: 9.51 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.1906048496729862		[learning rate: 0.0043401]
	Learning Rate: 0.0043401
	LOSS [training: 1.1906048496729862 | validation: 1.048628952698814]
	TIME [epoch: 9.51 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.3813559974303369		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 1.3813559974303369 | validation: 1.3575895316829558]
	TIME [epoch: 9.53 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.3355651120591507		[learning rate: 0.0043056]
	Learning Rate: 0.00430565
	LOSS [training: 1.3355651120591507 | validation: 1.0789004035304723]
	TIME [epoch: 9.51 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.2368889130935037		[learning rate: 0.0042885]
	Learning Rate: 0.00428852
	LOSS [training: 1.2368889130935037 | validation: 1.2248126584211267]
	TIME [epoch: 9.51 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.5415683427961648		[learning rate: 0.0042715]
	Learning Rate: 0.00427147
	LOSS [training: 1.5415683427961648 | validation: 0.9046835978990048]
	TIME [epoch: 9.51 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.0871978009173489		[learning rate: 0.0042545]
	Learning Rate: 0.00425448
	LOSS [training: 1.0871978009173489 | validation: 0.7010198621492363]
	TIME [epoch: 9.52 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.0156719500336877		[learning rate: 0.0042376]
	Learning Rate: 0.00423756
	LOSS [training: 1.0156719500336877 | validation: 0.8316587374989373]
	TIME [epoch: 9.51 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.9145940177591648		[learning rate: 0.0042207]
	Learning Rate: 0.0042207
	LOSS [training: 0.9145940177591648 | validation: 0.6491010388173157]
	TIME [epoch: 9.51 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.043923833180748		[learning rate: 0.0042039]
	Learning Rate: 0.00420391
	LOSS [training: 1.043923833180748 | validation: 0.8945176056056647]
	TIME [epoch: 9.52 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.894659963572058		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 0.894659963572058 | validation: 0.5743654991841101]
	TIME [epoch: 9.52 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7534795782092647		[learning rate: 0.0041705]
	Learning Rate: 0.00417054
	LOSS [training: 0.7534795782092647 | validation: 0.5638685183898727]
	TIME [epoch: 9.51 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7224693485883235		[learning rate: 0.004154]
	Learning Rate: 0.00415395
	LOSS [training: 0.7224693485883235 | validation: 0.560682985815918]
	TIME [epoch: 9.51 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7168343060474792		[learning rate: 0.0041374]
	Learning Rate: 0.00413743
	LOSS [training: 0.7168343060474792 | validation: 0.5302129205779843]
	TIME [epoch: 9.52 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6773001302674516		[learning rate: 0.004121]
	Learning Rate: 0.00412098
	LOSS [training: 0.6773001302674516 | validation: 0.499084118913089]
	TIME [epoch: 9.52 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6777893248729674		[learning rate: 0.0041046]
	Learning Rate: 0.00410458
	LOSS [training: 0.6777893248729674 | validation: 0.4991887952606615]
	TIME [epoch: 9.51 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6599346561267776		[learning rate: 0.0040883]
	Learning Rate: 0.00408826
	LOSS [training: 0.6599346561267776 | validation: 0.45162639914212716]
	TIME [epoch: 9.51 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.48246244146315576		[learning rate: 0.004072]
	Learning Rate: 0.004072
	LOSS [training: 0.48246244146315576 | validation: 0.3692522328849611]
	TIME [epoch: 9.53 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4767208568738959		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.4767208568738959 | validation: 0.36635638082156463]
	TIME [epoch: 9.51 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4308351247622003		[learning rate: 0.0040397]
	Learning Rate: 0.00403967
	LOSS [training: 0.4308351247622003 | validation: 0.36776588651495784]
	TIME [epoch: 9.51 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.434048736429039		[learning rate: 0.0040236]
	Learning Rate: 0.00402361
	LOSS [training: 0.434048736429039 | validation: 0.37158324329279424]
	TIME [epoch: 9.51 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4184546464939312		[learning rate: 0.0040076]
	Learning Rate: 0.0040076
	LOSS [training: 0.4184546464939312 | validation: 0.3390753341952134]
	TIME [epoch: 9.53 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3701136283673589		[learning rate: 0.0039917]
	Learning Rate: 0.00399166
	LOSS [training: 0.3701136283673589 | validation: 0.34494945345291655]
	TIME [epoch: 9.52 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3670158703592212		[learning rate: 0.0039758]
	Learning Rate: 0.00397579
	LOSS [training: 0.3670158703592212 | validation: 0.40588612578224026]
	TIME [epoch: 9.51 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.390429554690516		[learning rate: 0.00396]
	Learning Rate: 0.00395997
	LOSS [training: 0.390429554690516 | validation: 0.33719013553357047]
	TIME [epoch: 9.51 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.33832617517080216		[learning rate: 0.0039442]
	Learning Rate: 0.00394422
	LOSS [training: 0.33832617517080216 | validation: 0.31807351481753227]
	TIME [epoch: 9.52 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.35936284007558855		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 0.35936284007558855 | validation: 0.3864241408549637]
	TIME [epoch: 9.51 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.35008591319389676		[learning rate: 0.0039129]
	Learning Rate: 0.00391291
	LOSS [training: 0.35008591319389676 | validation: 0.6890895356967308]
	TIME [epoch: 9.51 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.541748273143122		[learning rate: 0.0038973]
	Learning Rate: 0.00389735
	LOSS [training: 0.541748273143122 | validation: 0.34074304384922127]
	TIME [epoch: 9.52 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.34842590175870797		[learning rate: 0.0038818]
	Learning Rate: 0.00388185
	LOSS [training: 0.34842590175870797 | validation: 0.3313608669541906]
	TIME [epoch: 9.51 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3308497201260138		[learning rate: 0.0038664]
	Learning Rate: 0.00386641
	LOSS [training: 0.3308497201260138 | validation: 0.3157985850410573]
	TIME [epoch: 9.51 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3300850925735939		[learning rate: 0.003851]
	Learning Rate: 0.00385103
	LOSS [training: 0.3300850925735939 | validation: 0.30893970824542627]
	TIME [epoch: 9.51 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32308909221904986		[learning rate: 0.0038357]
	Learning Rate: 0.00383571
	LOSS [training: 0.32308909221904986 | validation: 0.34533655163264443]
	TIME [epoch: 9.53 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.35833122649925636		[learning rate: 0.0038205]
	Learning Rate: 0.00382046
	LOSS [training: 0.35833122649925636 | validation: 0.3263551773129851]
	TIME [epoch: 9.51 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32622990415125885		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 0.32622990415125885 | validation: 0.4192316439700516]
	TIME [epoch: 9.51 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5293785362522003		[learning rate: 0.0037901]
	Learning Rate: 0.00379013
	LOSS [training: 0.5293785362522003 | validation: 0.3865961719388932]
	TIME [epoch: 9.51 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.36205085593609804		[learning rate: 0.0037751]
	Learning Rate: 0.00377505
	LOSS [training: 0.36205085593609804 | validation: 0.33220285426223817]
	TIME [epoch: 9.53 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3250241457391366		[learning rate: 0.00376]
	Learning Rate: 0.00376004
	LOSS [training: 0.3250241457391366 | validation: 0.3154054106394567]
	TIME [epoch: 9.51 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3209845220470392		[learning rate: 0.0037451]
	Learning Rate: 0.00374508
	LOSS [training: 0.3209845220470392 | validation: 0.357880738982791]
	TIME [epoch: 9.51 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.37405137026675633		[learning rate: 0.0037302]
	Learning Rate: 0.00373019
	LOSS [training: 0.37405137026675633 | validation: 0.31268117636410264]
	TIME [epoch: 9.51 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3196429003030477		[learning rate: 0.0037154]
	Learning Rate: 0.00371535
	LOSS [training: 0.3196429003030477 | validation: 0.35488286151557863]
	TIME [epoch: 9.52 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3236370523062586		[learning rate: 0.0037006]
	Learning Rate: 0.00370058
	LOSS [training: 0.3236370523062586 | validation: 0.32801600877716236]
	TIME [epoch: 9.51 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3063343987952086		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 0.3063343987952086 | validation: 0.3513701885897087]
	TIME [epoch: 9.51 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3266362950957776		[learning rate: 0.0036712]
	Learning Rate: 0.0036712
	LOSS [training: 0.3266362950957776 | validation: 0.3071313224876392]
	TIME [epoch: 9.53 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.33787843144119994		[learning rate: 0.0036566]
	Learning Rate: 0.0036566
	LOSS [training: 0.33787843144119994 | validation: 1.6464257663165935]
	TIME [epoch: 9.51 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.9612206508636638		[learning rate: 0.0036421]
	Learning Rate: 0.00364205
	LOSS [training: 0.9612206508636638 | validation: 0.38364870449765887]
	TIME [epoch: 9.51 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.322366973065669		[learning rate: 0.0036276]
	Learning Rate: 0.00362757
	LOSS [training: 0.322366973065669 | validation: 0.2891486223708606]
	TIME [epoch: 9.51 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2849237978674108		[learning rate: 0.0036131]
	Learning Rate: 0.00361314
	LOSS [training: 0.2849237978674108 | validation: 0.2953668228383416]
	TIME [epoch: 9.53 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2919182672043048		[learning rate: 0.0035988]
	Learning Rate: 0.00359877
	LOSS [training: 0.2919182672043048 | validation: 0.2914851368571198]
	TIME [epoch: 9.51 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.28851167315040066		[learning rate: 0.0035845]
	Learning Rate: 0.00358445
	LOSS [training: 0.28851167315040066 | validation: 0.2969922599020284]
	TIME [epoch: 9.51 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3298513935964041		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 0.3298513935964041 | validation: 0.5031392171607696]
	TIME [epoch: 9.52 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32361192496046476		[learning rate: 0.003556]
	Learning Rate: 0.003556
	LOSS [training: 0.32361192496046476 | validation: 0.2881376164247146]
	TIME [epoch: 9.52 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.30037411734871045		[learning rate: 0.0035419]
	Learning Rate: 0.00354185
	LOSS [training: 0.30037411734871045 | validation: 0.32007460934544685]
	TIME [epoch: 9.51 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2968929972764485		[learning rate: 0.0035278]
	Learning Rate: 0.00352777
	LOSS [training: 0.2968929972764485 | validation: 0.2997467444848644]
	TIME [epoch: 9.51 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.29953083671758546		[learning rate: 0.0035137]
	Learning Rate: 0.00351374
	LOSS [training: 0.29953083671758546 | validation: 0.3098562098875513]
	TIME [epoch: 9.52 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.28600850785667636		[learning rate: 0.0034998]
	Learning Rate: 0.00349976
	LOSS [training: 0.28600850785667636 | validation: 0.29141338894523666]
	TIME [epoch: 9.51 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.2807958881180628		[learning rate: 0.0034858]
	Learning Rate: 0.00348584
	LOSS [training: 0.2807958881180628 | validation: 0.2992806995760749]
	TIME [epoch: 9.51 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3581812037335704		[learning rate: 0.003472]
	Learning Rate: 0.00347198
	LOSS [training: 0.3581812037335704 | validation: 0.8525407590809759]
	TIME [epoch: 9.51 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5614688546669976		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.5614688546669976 | validation: 0.4083466755819307]
	TIME [epoch: 9.52 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4704279173436162		[learning rate: 0.0034444]
	Learning Rate: 0.00344441
	LOSS [training: 0.4704279173436162 | validation: 0.42022140465677005]
	TIME [epoch: 9.51 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.346703666874551		[learning rate: 0.0034307]
	Learning Rate: 0.00343071
	LOSS [training: 0.346703666874551 | validation: 0.31758726836378093]
	TIME [epoch: 9.51 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.33087035822722677		[learning rate: 0.0034171]
	Learning Rate: 0.00341707
	LOSS [training: 0.33087035822722677 | validation: 0.3270799987626671]
	TIME [epoch: 9.51 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3625612959369188		[learning rate: 0.0034035]
	Learning Rate: 0.00340348
	LOSS [training: 0.3625612959369188 | validation: 0.35798659303397806]
	TIME [epoch: 9.52 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3366699714856748		[learning rate: 0.0033899]
	Learning Rate: 0.00338994
	LOSS [training: 0.3366699714856748 | validation: 0.32618399437664064]
	TIME [epoch: 9.51 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3325199914357879		[learning rate: 0.0033765]
	Learning Rate: 0.00337646
	LOSS [training: 0.3325199914357879 | validation: 0.31350868615265204]
	TIME [epoch: 9.51 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3199659014857827		[learning rate: 0.003363]
	Learning Rate: 0.00336303
	LOSS [training: 0.3199659014857827 | validation: 0.6825574414944239]
	TIME [epoch: 9.52 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.8464829009232244		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 0.8464829009232244 | validation: 0.5857838099214263]
	TIME [epoch: 9.51 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.8530831085648996		[learning rate: 0.0033363]
	Learning Rate: 0.00333633
	LOSS [training: 0.8530831085648996 | validation: 0.9715119419023089]
	TIME [epoch: 9.51 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.9947931063848708		[learning rate: 0.0033231]
	Learning Rate: 0.00332306
	LOSS [training: 0.9947931063848708 | validation: 0.6452315581091087]
	TIME [epoch: 9.51 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.699262723269783		[learning rate: 0.0033098]
	Learning Rate: 0.00330985
	LOSS [training: 0.699262723269783 | validation: 0.554263831001136]
	TIME [epoch: 9.52 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7592329687469033		[learning rate: 0.0032967]
	Learning Rate: 0.00329668
	LOSS [training: 0.7592329687469033 | validation: 0.5871055485673757]
	TIME [epoch: 9.51 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.8852209694747334		[learning rate: 0.0032836]
	Learning Rate: 0.00328357
	LOSS [training: 0.8852209694747334 | validation: 0.6261151304216066]
	TIME [epoch: 9.51 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.9459312245798065		[learning rate: 0.0032705]
	Learning Rate: 0.00327051
	LOSS [training: 0.9459312245798065 | validation: 0.7481643675539329]
	TIME [epoch: 9.51 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.9626300607277428		[learning rate: 0.0032575]
	Learning Rate: 0.0032575
	LOSS [training: 0.9626300607277428 | validation: 0.7723021041636609]
	TIME [epoch: 9.52 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.9309244600040955		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 0.9309244600040955 | validation: 0.773433450278321]
	TIME [epoch: 9.51 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.9545050144276901		[learning rate: 0.0032316]
	Learning Rate: 0.00323164
	LOSS [training: 0.9545050144276901 | validation: 0.9122183225769648]
	TIME [epoch: 9.51 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.194805496706107		[learning rate: 0.0032188]
	Learning Rate: 0.00321879
	LOSS [training: 1.194805496706107 | validation: 1.1900836798671866]
	TIME [epoch: 9.51 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.5574435756821035		[learning rate: 0.003206]
	Learning Rate: 0.00320599
	LOSS [training: 1.5574435756821035 | validation: 1.8394005316415378]
	TIME [epoch: 9.52 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 9/9] avg loss: 2.4755991248632907		[learning rate: 0.0031932]
	Learning Rate: 0.00319323
	LOSS [training: 2.4755991248632907 | validation: 2.0682356684487404]
	TIME [epoch: 9.51 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 9/9] avg loss: 2.0315984515688252		[learning rate: 0.0031805]
	Learning Rate: 0.00318053
	LOSS [training: 2.0315984515688252 | validation: 1.7587928565669675]
	TIME [epoch: 9.51 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.4933454006017455		[learning rate: 0.0031679]
	Learning Rate: 0.00316788
	LOSS [training: 1.4933454006017455 | validation: 0.978674728186558]
	TIME [epoch: 9.51 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.140962818012609		[learning rate: 0.0031553]
	Learning Rate: 0.00315528
	LOSS [training: 1.140962818012609 | validation: 0.810193722727764]
	TIME [epoch: 9.51 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.8635293849460735		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 0.8635293849460735 | validation: 0.6343883668932458]
	TIME [epoch: 9.51 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.8238015320884655		[learning rate: 0.0031302]
	Learning Rate: 0.00313023
	LOSS [training: 0.8238015320884655 | validation: 0.6286802098940508]
	TIME [epoch: 9.5 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.8190681146617129		[learning rate: 0.0031178]
	Learning Rate: 0.00311779
	LOSS [training: 0.8190681146617129 | validation: 0.587422004298764]
	TIME [epoch: 9.52 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7713878351927457		[learning rate: 0.0031054]
	Learning Rate: 0.00310538
	LOSS [training: 0.7713878351927457 | validation: 0.5681460841981951]
	TIME [epoch: 9.5 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.7385567113118613		[learning rate: 0.003093]
	Learning Rate: 0.00309303
	LOSS [training: 0.7385567113118613 | validation: 0.5405277221311098]
	TIME [epoch: 9.51 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6995202621180411		[learning rate: 0.0030807]
	Learning Rate: 0.00308073
	LOSS [training: 0.6995202621180411 | validation: 0.5266880836538949]
	TIME [epoch: 9.5 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.671372586390389		[learning rate: 0.0030685]
	Learning Rate: 0.00306848
	LOSS [training: 0.671372586390389 | validation: 0.512090544782654]
	TIME [epoch: 9.52 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6630498928403363		[learning rate: 0.0030563]
	Learning Rate: 0.00305627
	LOSS [training: 0.6630498928403363 | validation: 0.5041823803131892]
	TIME [epoch: 9.51 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6683410262582181		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 0.6683410262582181 | validation: 0.5340340434151136]
	TIME [epoch: 9.51 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.677051806924787		[learning rate: 0.003032]
	Learning Rate: 0.00303201
	LOSS [training: 0.677051806924787 | validation: 0.5122058987677481]
	TIME [epoch: 9.51 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6706792644337766		[learning rate: 0.00302]
	Learning Rate: 0.00301995
	LOSS [training: 0.6706792644337766 | validation: 0.49325725563284484]
	TIME [epoch: 9.52 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6576814200579295		[learning rate: 0.0030079]
	Learning Rate: 0.00300794
	LOSS [training: 0.6576814200579295 | validation: 0.47843576152301537]
	TIME [epoch: 9.51 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6195896679199275		[learning rate: 0.002996]
	Learning Rate: 0.00299598
	LOSS [training: 0.6195896679199275 | validation: 0.473070530297819]
	TIME [epoch: 9.5 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6170848312008216		[learning rate: 0.0029841]
	Learning Rate: 0.00298406
	LOSS [training: 0.6170848312008216 | validation: 0.4639383612781495]
	TIME [epoch: 9.51 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5918434468691289		[learning rate: 0.0029722]
	Learning Rate: 0.00297219
	LOSS [training: 0.5918434468691289 | validation: 0.4402950538180403]
	TIME [epoch: 9.52 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6012055625204529		[learning rate: 0.0029604]
	Learning Rate: 0.00296037
	LOSS [training: 0.6012055625204529 | validation: 0.43433059734379514]
	TIME [epoch: 9.51 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5928329934269895		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.5928329934269895 | validation: 0.4392714015479909]
	TIME [epoch: 9.5 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5880094330142414		[learning rate: 0.0029369]
	Learning Rate: 0.00293687
	LOSS [training: 0.5880094330142414 | validation: 0.4258777664156689]
	TIME [epoch: 9.52 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5836386854160996		[learning rate: 0.0029252]
	Learning Rate: 0.00292519
	LOSS [training: 0.5836386854160996 | validation: 0.3884276291830465]
	TIME [epoch: 9.51 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5308047911193824		[learning rate: 0.0029136]
	Learning Rate: 0.00291355
	LOSS [training: 0.5308047911193824 | validation: 0.3906408072288646]
	TIME [epoch: 9.5 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4832857346920298		[learning rate: 0.002902]
	Learning Rate: 0.00290197
	LOSS [training: 0.4832857346920298 | validation: 0.3659933246150979]
	TIME [epoch: 9.5 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4889161289254516		[learning rate: 0.0028904]
	Learning Rate: 0.00289042
	LOSS [training: 0.4889161289254516 | validation: 0.8578623313230629]
	TIME [epoch: 9.52 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.3163510631161504		[learning rate: 0.0028789]
	Learning Rate: 0.00287893
	LOSS [training: 1.3163510631161504 | validation: 0.838572259042429]
	TIME [epoch: 9.51 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.6325106484216125		[learning rate: 0.0028675]
	Learning Rate: 0.00286748
	LOSS [training: 0.6325106484216125 | validation: 0.43206829607905367]
	TIME [epoch: 9.51 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5115057241716365		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 0.5115057241716365 | validation: 0.37792221428352]
	TIME [epoch: 9.51 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4683680819387269		[learning rate: 0.0028447]
	Learning Rate: 0.00284471
	LOSS [training: 0.4683680819387269 | validation: 0.37717023613163975]
	TIME [epoch: 9.52 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.443948255806058		[learning rate: 0.0028334]
	Learning Rate: 0.0028334
	LOSS [training: 0.443948255806058 | validation: 0.37272940092625706]
	TIME [epoch: 9.51 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.46707767399754196		[learning rate: 0.0028221]
	Learning Rate: 0.00282213
	LOSS [training: 0.46707767399754196 | validation: 0.3931009635223828]
	TIME [epoch: 9.5 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.44247151740833296		[learning rate: 0.0028109]
	Learning Rate: 0.00281091
	LOSS [training: 0.44247151740833296 | validation: 0.4082548292958025]
	TIME [epoch: 9.51 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4064775172404507		[learning rate: 0.0027997]
	Learning Rate: 0.00279973
	LOSS [training: 0.4064775172404507 | validation: 0.3558487086714396]
	TIME [epoch: 9.51 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3859367917090643		[learning rate: 0.0027886]
	Learning Rate: 0.00278859
	LOSS [training: 0.3859367917090643 | validation: 0.34809972174848686]
	TIME [epoch: 9.51 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3690344623563867		[learning rate: 0.0027775]
	Learning Rate: 0.0027775
	LOSS [training: 0.3690344623563867 | validation: 0.3395798604329344]
	TIME [epoch: 9.5 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.36591337556836145		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 0.36591337556836145 | validation: 0.34669430886511166]
	TIME [epoch: 9.52 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.36293460712422687		[learning rate: 0.0027554]
	Learning Rate: 0.00275545
	LOSS [training: 0.36293460712422687 | validation: 0.35549397391606297]
	TIME [epoch: 9.51 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3451560779730094		[learning rate: 0.0027445]
	Learning Rate: 0.00274449
	LOSS [training: 0.3451560779730094 | validation: 0.32506424454803773]
	TIME [epoch: 9.51 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3232370425637317		[learning rate: 0.0027336]
	Learning Rate: 0.00273357
	LOSS [training: 0.3232370425637317 | validation: 0.313297596585315]
	TIME [epoch: 9.51 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32583376045937645		[learning rate: 0.0027227]
	Learning Rate: 0.0027227
	LOSS [training: 0.32583376045937645 | validation: 0.3457116174505913]
	TIME [epoch: 9.53 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32979385498307245		[learning rate: 0.0027119]
	Learning Rate: 0.00271187
	LOSS [training: 0.32979385498307245 | validation: 0.34988123786784464]
	TIME [epoch: 9.5 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32347859284542757		[learning rate: 0.0027011]
	Learning Rate: 0.00270109
	LOSS [training: 0.32347859284542757 | validation: 0.3242148709228747]
	TIME [epoch: 9.51 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3279159628531017		[learning rate: 0.0026903]
	Learning Rate: 0.00269034
	LOSS [training: 0.3279159628531017 | validation: 0.33654114124124784]
	TIME [epoch: 9.51 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3317416246022921		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 0.3317416246022921 | validation: 0.34738245571099935]
	TIME [epoch: 9.52 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3359423346172272		[learning rate: 0.002669]
	Learning Rate: 0.00266899
	LOSS [training: 0.3359423346172272 | validation: 0.35249139367907106]
	TIME [epoch: 9.5 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.30126981110258155		[learning rate: 0.0026584]
	Learning Rate: 0.00265837
	LOSS [training: 0.30126981110258155 | validation: 0.3334913188713874]
	TIME [epoch: 9.5 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3113808227636897		[learning rate: 0.0026478]
	Learning Rate: 0.0026478
	LOSS [training: 0.3113808227636897 | validation: 0.31134313807085834]
	TIME [epoch: 9.51 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.30421720895913085		[learning rate: 0.0026373]
	Learning Rate: 0.00263727
	LOSS [training: 0.30421720895913085 | validation: 0.31279667962462054]
	TIME [epoch: 9.51 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3065348858755497		[learning rate: 0.0026268]
	Learning Rate: 0.00262678
	LOSS [training: 0.3065348858755497 | validation: 0.3064614919520537]
	TIME [epoch: 9.5 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.33313595687081093		[learning rate: 0.0026163]
	Learning Rate: 0.00261633
	LOSS [training: 0.33313595687081093 | validation: 0.314032151039704]
	TIME [epoch: 9.5 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3076843340828478		[learning rate: 0.0026059]
	Learning Rate: 0.00260592
	LOSS [training: 0.3076843340828478 | validation: 0.3158056836105677]
	TIME [epoch: 9.52 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3026083311774742		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 0.3026083311774742 | validation: 0.30457044567578057]
	TIME [epoch: 9.51 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3058755854505408		[learning rate: 0.0025852]
	Learning Rate: 0.00258523
	LOSS [training: 0.3058755854505408 | validation: 0.314938927184809]
	TIME [epoch: 9.51 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.34769869079249954		[learning rate: 0.002575]
	Learning Rate: 0.00257495
	LOSS [training: 0.34769869079249954 | validation: 0.33098866825465806]
	TIME [epoch: 9.51 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3338972640830442		[learning rate: 0.0025647]
	Learning Rate: 0.00256471
	LOSS [training: 0.3338972640830442 | validation: 0.3397234824418458]
	TIME [epoch: 9.52 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3177205055218884		[learning rate: 0.0025545]
	Learning Rate: 0.00255451
	LOSS [training: 0.3177205055218884 | validation: 0.3096475182471354]
	TIME [epoch: 9.5 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.29999223574528966		[learning rate: 0.0025444]
	Learning Rate: 0.00254435
	LOSS [training: 0.29999223574528966 | validation: 0.3050206369324545]
	TIME [epoch: 9.51 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.4888517316761854		[learning rate: 0.0025342]
	Learning Rate: 0.00253423
	LOSS [training: 0.4888517316761854 | validation: 0.37047067290185015]
	TIME [epoch: 9.51 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.42406438534683505		[learning rate: 0.0025242]
	Learning Rate: 0.00252415
	LOSS [training: 0.42406438534683505 | validation: 0.3543921205437931]
	TIME [epoch: 9.52 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3741456397837866		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.3741456397837866 | validation: 0.326337052482431]
	TIME [epoch: 9.51 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.351895119089695		[learning rate: 0.0025041]
	Learning Rate: 0.00250411
	LOSS [training: 0.351895119089695 | validation: 0.32840752760715347]
	TIME [epoch: 9.5 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3261292697523842		[learning rate: 0.0024942]
	Learning Rate: 0.00249415
	LOSS [training: 0.3261292697523842 | validation: 0.32828707892884584]
	TIME [epoch: 9.52 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.41079164106143595		[learning rate: 0.0024842]
	Learning Rate: 0.00248423
	LOSS [training: 0.41079164106143595 | validation: 0.362755804894891]
	TIME [epoch: 9.51 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3843729731853514		[learning rate: 0.0024744]
	Learning Rate: 0.00247435
	LOSS [training: 0.3843729731853514 | validation: 0.3557293047579992]
	TIME [epoch: 9.66 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3699231827504231		[learning rate: 0.0024645]
	Learning Rate: 0.00246451
	LOSS [training: 0.3699231827504231 | validation: 0.3417120553659247]
	TIME [epoch: 9.5 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.34075423353421175		[learning rate: 0.0024547]
	Learning Rate: 0.00245471
	LOSS [training: 0.34075423353421175 | validation: 0.3231031620029955]
	TIME [epoch: 9.52 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32019947657974523		[learning rate: 0.0024449]
	Learning Rate: 0.00244495
	LOSS [training: 0.32019947657974523 | validation: 0.3483925300774987]
	TIME [epoch: 9.51 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32714360023771977		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 0.32714360023771977 | validation: 0.3462154154977207]
	TIME [epoch: 9.54 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.324604177302261		[learning rate: 0.0024255]
	Learning Rate: 0.00242554
	LOSS [training: 0.324604177302261 | validation: 0.33189392381115806]
	TIME [epoch: 9.5 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.37175972662017603		[learning rate: 0.0024159]
	Learning Rate: 0.00241589
	LOSS [training: 0.37175972662017603 | validation: 0.47034375559380787]
	TIME [epoch: 9.51 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.48438680892962527		[learning rate: 0.0024063]
	Learning Rate: 0.00240628
	LOSS [training: 0.48438680892962527 | validation: 0.36605473602909533]
	TIME [epoch: 9.49 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.41988408022871426		[learning rate: 0.0023967]
	Learning Rate: 0.00239671
	LOSS [training: 0.41988408022871426 | validation: 0.35983402251404395]
	TIME [epoch: 9.49 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.37376137952799726		[learning rate: 0.0023872]
	Learning Rate: 0.00238718
	LOSS [training: 0.37376137952799726 | validation: 0.33956049193341376]
	TIME [epoch: 9.5 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3309155770546203		[learning rate: 0.0023777]
	Learning Rate: 0.00237768
	LOSS [training: 0.3309155770546203 | validation: 0.3326869586156668]
	TIME [epoch: 9.5 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3279084146502094		[learning rate: 0.0023682]
	Learning Rate: 0.00236823
	LOSS [training: 0.3279084146502094 | validation: 0.3344735071701096]
	TIME [epoch: 9.49 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.38201176146094556		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 0.38201176146094556 | validation: 0.33678726964093997]
	TIME [epoch: 9.49 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.34011579149967686		[learning rate: 0.0023494]
	Learning Rate: 0.00234942
	LOSS [training: 0.34011579149967686 | validation: 0.3197329813346198]
	TIME [epoch: 9.51 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3088024150410747		[learning rate: 0.0023401]
	Learning Rate: 0.00234008
	LOSS [training: 0.3088024150410747 | validation: 0.31357574850045955]
	TIME [epoch: 9.5 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32222255812586426		[learning rate: 0.0023308]
	Learning Rate: 0.00233077
	LOSS [training: 0.32222255812586426 | validation: 0.33536491504605426]
	TIME [epoch: 9.49 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3142566675835565		[learning rate: 0.0023215]
	Learning Rate: 0.0023215
	LOSS [training: 0.3142566675835565 | validation: 0.3113363889581392]
	TIME [epoch: 9.5 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.33721768211887254		[learning rate: 0.0023123]
	Learning Rate: 0.00231227
	LOSS [training: 0.33721768211887254 | validation: 0.33583176366176104]
	TIME [epoch: 9.51 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3407936230626034		[learning rate: 0.0023031]
	Learning Rate: 0.00230307
	LOSS [training: 0.3407936230626034 | validation: 0.37075102732275844]
	TIME [epoch: 9.49 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.33864096579445285		[learning rate: 0.0022939]
	Learning Rate: 0.00229391
	LOSS [training: 0.33864096579445285 | validation: 0.3389253603947483]
	TIME [epoch: 9.49 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.33912127235895073		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 0.33912127235895073 | validation: 0.3252257848211489]
	TIME [epoch: 9.5 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.33591016036864146		[learning rate: 0.0022757]
	Learning Rate: 0.0022757
	LOSS [training: 0.33591016036864146 | validation: 0.32772190961788644]
	TIME [epoch: 9.51 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.31901174415004974		[learning rate: 0.0022667]
	Learning Rate: 0.00226665
	LOSS [training: 0.31901174415004974 | validation: 0.31957049146782285]
	TIME [epoch: 9.5 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3213202084332027		[learning rate: 0.0022576]
	Learning Rate: 0.00225764
	LOSS [training: 0.3213202084332027 | validation: 0.3227701892804885]
	TIME [epoch: 9.49 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.33734532958765917		[learning rate: 0.0022487]
	Learning Rate: 0.00224866
	LOSS [training: 0.33734532958765917 | validation: 0.30765424399398633]
	TIME [epoch: 9.5 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.31943960189531106		[learning rate: 0.0022397]
	Learning Rate: 0.00223971
	LOSS [training: 0.31943960189531106 | validation: 0.33212590922437174]
	TIME [epoch: 9.5 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3235450231730553		[learning rate: 0.0022308]
	Learning Rate: 0.0022308
	LOSS [training: 0.3235450231730553 | validation: 0.32157738051895046]
	TIME [epoch: 9.49 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.32040388194431857		[learning rate: 0.0022219]
	Learning Rate: 0.00222193
	LOSS [training: 0.32040388194431857 | validation: 0.322859004734973]
	TIME [epoch: 9.49 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.30326772582062406		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.30326772582062406 | validation: 0.31298855898293654]
	TIME [epoch: 9.51 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.31164312382399934		[learning rate: 0.0022043]
	Learning Rate: 0.00220429
	LOSS [training: 0.31164312382399934 | validation: 0.3359007550975281]
	TIME [epoch: 9.49 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.3281792962027177		[learning rate: 0.0021955]
	Learning Rate: 0.00219553
	LOSS [training: 0.3281792962027177 | validation: 0.31757645211266866]
	TIME [epoch: 9.5 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.31782467456957453		[learning rate: 0.0021868]
	Learning Rate: 0.00218679
	LOSS [training: 0.31782467456957453 | validation: 0.31969858370540594]
	TIME [epoch: 9.5 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.31153495806949294		[learning rate: 0.0021781]
	Learning Rate: 0.0021781
	LOSS [training: 0.31153495806949294 | validation: 0.32145073771713]
	TIME [epoch: 9.52 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.5669159009202616		[learning rate: 0.0021694]
	Learning Rate: 0.00216943
	LOSS [training: 0.5669159009202616 | validation: 0.8604424339599287]
	TIME [epoch: 9.49 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.8724400111354558		[learning rate: 0.0021608]
	Learning Rate: 0.0021608
	LOSS [training: 0.8724400111354558 | validation: 0.6939104401644688]
	TIME [epoch: 9.49 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 9/9] avg loss: 0.719060736101532		[learning rate: 0.0021522]
	Learning Rate: 0.00215221
	LOSS [training: 0.719060736101532 | validation: 1.0216020683391662]
	TIME [epoch: 9.49 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.3475588454440357		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 1.3475588454440357 | validation: 1.6822132896139603]
	TIME [epoch: 9.5 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.7844699557077621		[learning rate: 0.0021351]
	Learning Rate: 0.00213512
	LOSS [training: 1.7844699557077621 | validation: 1.866916137209449]
	TIME [epoch: 9.49 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.9153257849227383		[learning rate: 0.0021266]
	Learning Rate: 0.00212663
	LOSS [training: 1.9153257849227383 | validation: 1.8807962880859836]
	TIME [epoch: 9.5 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.9435144035699408		[learning rate: 0.0021182]
	Learning Rate: 0.00211817
	LOSS [training: 1.9435144035699408 | validation: 2.1691718693715614]
	TIME [epoch: 9.51 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 9/9] avg loss: 2.2371426928518416		[learning rate: 0.0021097]
	Learning Rate: 0.00210975
	LOSS [training: 2.2371426928518416 | validation: 2.3071622799731233]
	TIME [epoch: 9.5 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 9/9] avg loss: 2.294772314529346		[learning rate: 0.0021014]
	Learning Rate: 0.00210136
	LOSS [training: 2.294772314529346 | validation: 2.189076172351883]
	TIME [epoch: 9.49 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 9/9] avg loss: 1.9191004493479857		[learning rate: 0.002093]
	Learning Rate: 0.002093
	LOSS [training: 1.9191004493479857 | validation: 2.3408820175062184]
	TIME [epoch: 9.49 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 9/9] avg loss: 2.1173475546739673		[learning rate: 0.0020847]
	Learning Rate: 0.00208468
	LOSS [training: 2.1173475546739673 | validation: 2.9418763957282286]
	TIME [epoch: 9.51 sec]
	Saving model to: out/model_training/model_facs_v2_dec1b_2dpca_v10_20240711_164605/states/model_facs_v2_dec1b_2dpca_v10_438.pth
Halted early. No improvement in validation loss for 200 epochs.
Finished training in 4240.250 seconds.
