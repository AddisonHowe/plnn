Args:
Namespace(name='model_facs_v3_dec1b_2dpca_v14', outdir='out/model_training/model_facs_v3_dec1b_2dpca_v14', training_data='data/training_data/facs_v3/pca/dec1_fitonsubset/transition1_subset_epi_tr_ce_an_pc12/training', validation_data='data/training_data/facs_v3/pca/dec1_fitonsubset/transition1_subset_epi_tr_ce_an_pc12/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=10, batch_size=50, patience=200, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, quadratic_a=1.0, quadratic_b=1.0, ndims=2, nparams=2, nsigs=2, ncells=200, ncells_sample=200, model_do_sample=False, dt=0.005, dt_schedule='stepped', dt_schedule_bounds=[50, 500, 1000], dt_schedule_scales=[0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', kernel='multiscale', bw_range=[0.2, 0.5, 0.9, 1.1, 1.3, 1.5, 2.0], optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 3197229563

Training model...

Saving initial model state to: out/model_training/model_facs_v3_dec1b_2dpca_v14_20240716_142138/states/model_facs_v3_dec1b_2dpca_v14_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.6994621356618127		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6994621356618127 | validation: 1.3546141547095776]
	TIME [epoch: 21.5 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14_20240716_142138/states/model_facs_v3_dec1b_2dpca_v14_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.4182830856122768		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4182830856122768 | validation: 1.298255480204605]
	TIME [epoch: 5.79 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14_20240716_142138/states/model_facs_v3_dec1b_2dpca_v14_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.384557498854688		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.384557498854688 | validation: 1.2196861203250378]
	TIME [epoch: 5.78 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14_20240716_142138/states/model_facs_v3_dec1b_2dpca_v14_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.322326240045894		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.322326240045894 | validation: 1.203774527902156]
	TIME [epoch: 5.77 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14_20240716_142138/states/model_facs_v3_dec1b_2dpca_v14_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.2831428698172687		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2831428698172687 | validation: 1.1156200876502693]
	TIME [epoch: 5.77 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14_20240716_142138/states/model_facs_v3_dec1b_2dpca_v14_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.1926180348197404		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1926180348197404 | validation: 1.08239668289015]
	TIME [epoch: 5.78 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14_20240716_142138/states/model_facs_v3_dec1b_2dpca_v14_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.157332463180459		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.157332463180459 | validation: 1.0698619848735995]
	TIME [epoch: 5.77 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14_20240716_142138/states/model_facs_v3_dec1b_2dpca_v14_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.1166082567723359		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1166082567723359 | validation: 1.0837952827886483]
	TIME [epoch: 5.77 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.9917677182708312		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9917677182708312 | validation: 0.9405340144248573]
	TIME [epoch: 5.76 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14_20240716_142138/states/model_facs_v3_dec1b_2dpca_v14_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 6/6] avg loss: 1.0452288424680412		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0452288424680412 | validation: 0.8909164329781104]
	TIME [epoch: 5.78 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14_20240716_142138/states/model_facs_v3_dec1b_2dpca_v14_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.8718968437301293		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8718968437301293 | validation: 0.87092320060479]
	TIME [epoch: 5.78 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14_20240716_142138/states/model_facs_v3_dec1b_2dpca_v14_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.8267701551004497		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8267701551004497 | validation: 0.8164986370964673]
	TIME [epoch: 5.78 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14_20240716_142138/states/model_facs_v3_dec1b_2dpca_v14_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.8642421687726531		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8642421687726531 | validation: 0.7392231965857862]
	TIME [epoch: 5.78 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14_20240716_142138/states/model_facs_v3_dec1b_2dpca_v14_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.7203720593895836		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7203720593895836 | validation: 0.6873143678254492]
	TIME [epoch: 5.77 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14_20240716_142138/states/model_facs_v3_dec1b_2dpca_v14_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.6602058273970014		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6602058273970014 | validation: 0.806803398008538]
	TIME [epoch: 5.78 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.6751980943586497		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6751980943586497 | validation: 0.6618091131429592]
	TIME [epoch: 5.79 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14_20240716_142138/states/model_facs_v3_dec1b_2dpca_v14_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.7330621578260904		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7330621578260904 | validation: 0.5694863353655116]
	TIME [epoch: 5.78 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14_20240716_142138/states/model_facs_v3_dec1b_2dpca_v14_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.572209119469561		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.572209119469561 | validation: 0.5488632382475098]
	TIME [epoch: 5.78 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14_20240716_142138/states/model_facs_v3_dec1b_2dpca_v14_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5408793617674448		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5408793617674448 | validation: 0.5312463404997716]
	TIME [epoch: 5.77 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14_20240716_142138/states/model_facs_v3_dec1b_2dpca_v14_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.56767649646824		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.56767649646824 | validation: 0.4785661046386764]
	TIME [epoch: 5.77 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14_20240716_142138/states/model_facs_v3_dec1b_2dpca_v14_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5021997102472388		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5021997102472388 | validation: 0.4118236041534855]
	TIME [epoch: 5.78 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14_20240716_142138/states/model_facs_v3_dec1b_2dpca_v14_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4595451936440398		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4595451936440398 | validation: 0.3848737596925499]
	TIME [epoch: 5.78 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14_20240716_142138/states/model_facs_v3_dec1b_2dpca_v14_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4451249782805267		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4451249782805267 | validation: 0.38106907519147415]
	TIME [epoch: 5.79 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14_20240716_142138/states/model_facs_v3_dec1b_2dpca_v14_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.5296909252179985		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5296909252179985 | validation: 0.37563706812795317]
	TIME [epoch: 5.77 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14_20240716_142138/states/model_facs_v3_dec1b_2dpca_v14_24.pth
	Model improved!!!
EPOCH 25/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4324261198498521		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4324261198498521 | validation: 0.3932926912659512]
	TIME [epoch: 5.77 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.438353909629209		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.438353909629209 | validation: 0.3584092614606832]
	TIME [epoch: 5.77 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14_20240716_142138/states/model_facs_v3_dec1b_2dpca_v14_26.pth
	Model improved!!!
EPOCH 27/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4359052334516668		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4359052334516668 | validation: 0.3787324280237856]
	TIME [epoch: 5.76 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4011776577409423		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4011776577409423 | validation: 0.42874270798946607]
	TIME [epoch: 5.77 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.41549010429143546		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.41549010429143546 | validation: 0.4402747280741533]
	TIME [epoch: 5.78 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.44434693176250933		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.44434693176250933 | validation: 0.33334286376591776]
	TIME [epoch: 5.78 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14_20240716_142138/states/model_facs_v3_dec1b_2dpca_v14_30.pth
	Model improved!!!
EPOCH 31/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3791396948959634		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3791396948959634 | validation: 0.32539455327700495]
	TIME [epoch: 5.78 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14_20240716_142138/states/model_facs_v3_dec1b_2dpca_v14_31.pth
	Model improved!!!
EPOCH 32/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.37512789400935764		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.37512789400935764 | validation: 0.32424174907556236]
	TIME [epoch: 5.78 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14_20240716_142138/states/model_facs_v3_dec1b_2dpca_v14_32.pth
	Model improved!!!
EPOCH 33/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3692806978103485		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3692806978103485 | validation: 0.314531791258426]
	TIME [epoch: 5.78 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14_20240716_142138/states/model_facs_v3_dec1b_2dpca_v14_33.pth
	Model improved!!!
EPOCH 34/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.4008626256824983		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4008626256824983 | validation: 0.30031423697278037]
	TIME [epoch: 5.77 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14_20240716_142138/states/model_facs_v3_dec1b_2dpca_v14_34.pth
	Model improved!!!
EPOCH 35/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3577818396615114		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3577818396615114 | validation: 0.3325481003232966]
	TIME [epoch: 5.78 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3766613079197514		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3766613079197514 | validation: 0.31635181195706463]
	TIME [epoch: 5.79 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3861419159540706		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3861419159540706 | validation: 0.3067227638662676]
	TIME [epoch: 5.76 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3579404643948672		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3579404643948672 | validation: 0.31269840268633936]
	TIME [epoch: 5.77 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3684654392584041		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3684654392584041 | validation: 0.31486174685527163]
	TIME [epoch: 5.87 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.34434025702265075		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.34434025702265075 | validation: 0.3154017560831826]
	TIME [epoch: 5.76 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.38229461130832015		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.38229461130832015 | validation: 0.31009613399979863]
	TIME [epoch: 5.77 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3367958789395311		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3367958789395311 | validation: 0.27935513125639155]
	TIME [epoch: 5.76 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14_20240716_142138/states/model_facs_v3_dec1b_2dpca_v14_42.pth
	Model improved!!!
EPOCH 43/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.35316006049298326		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.35316006049298326 | validation: 0.28640900045450474]
	TIME [epoch: 5.79 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3499223899175015		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3499223899175015 | validation: 0.29413650344438313]
	TIME [epoch: 5.77 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3535489491839175		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3535489491839175 | validation: 0.27459411982142984]
	TIME [epoch: 5.79 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14_20240716_142138/states/model_facs_v3_dec1b_2dpca_v14_45.pth
	Model improved!!!
EPOCH 46/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3345814802110982		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3345814802110982 | validation: 0.2773204684717413]
	TIME [epoch: 5.78 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3348186321903894		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3348186321903894 | validation: 0.289947535305142]
	TIME [epoch: 5.77 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.31341000244646017		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.31341000244646017 | validation: 0.2513935525011718]
	TIME [epoch: 5.78 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14_20240716_142138/states/model_facs_v3_dec1b_2dpca_v14_48.pth
	Model improved!!!
EPOCH 49/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3464108315022741		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3464108315022741 | validation: 0.27579416252558964]
	TIME [epoch: 5.77 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.33780318459943853		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.33780318459943853 | validation: 0.2976994474117286]
	TIME [epoch: 5.78 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.32573804527319666		[learning rate: 0.0099705]
	Learning Rate: 0.00997052
	LOSS [training: 0.32573804527319666 | validation: 0.2714724397296321]
	TIME [epoch: 24.3 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3043883624417492		[learning rate: 0.0099353]
	Learning Rate: 0.00993527
	LOSS [training: 0.3043883624417492 | validation: 0.2596026533754524]
	TIME [epoch: 11.1 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3179595106645166		[learning rate: 0.0099001]
	Learning Rate: 0.00990013
	LOSS [training: 0.3179595106645166 | validation: 0.2748087422454974]
	TIME [epoch: 11.1 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3201039836191666		[learning rate: 0.0098651]
	Learning Rate: 0.00986512
	LOSS [training: 0.3201039836191666 | validation: 0.25903567252896476]
	TIME [epoch: 11.1 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2958479192701412		[learning rate: 0.0098302]
	Learning Rate: 0.00983024
	LOSS [training: 0.2958479192701412 | validation: 0.2565742870101291]
	TIME [epoch: 11.1 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.31208081512137914		[learning rate: 0.0097955]
	Learning Rate: 0.00979548
	LOSS [training: 0.31208081512137914 | validation: 0.27043236060743847]
	TIME [epoch: 11.1 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.31058122426504614		[learning rate: 0.0097608]
	Learning Rate: 0.00976084
	LOSS [training: 0.31058122426504614 | validation: 0.25597234615906983]
	TIME [epoch: 11.1 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.30836735022318124		[learning rate: 0.0097263]
	Learning Rate: 0.00972632
	LOSS [training: 0.30836735022318124 | validation: 0.2675260443436744]
	TIME [epoch: 11.1 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.33308838823911957		[learning rate: 0.0096919]
	Learning Rate: 0.00969193
	LOSS [training: 0.33308838823911957 | validation: 0.2574777804185899]
	TIME [epoch: 11.1 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29173555419886554		[learning rate: 0.0096577]
	Learning Rate: 0.00965766
	LOSS [training: 0.29173555419886554 | validation: 0.2421659931149483]
	TIME [epoch: 11.1 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14_20240716_142138/states/model_facs_v3_dec1b_2dpca_v14_60.pth
	Model improved!!!
EPOCH 61/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29295989205169415		[learning rate: 0.0096235]
	Learning Rate: 0.00962351
	LOSS [training: 0.29295989205169415 | validation: 0.25024240832509903]
	TIME [epoch: 11.1 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3483459885631324		[learning rate: 0.0095895]
	Learning Rate: 0.00958948
	LOSS [training: 0.3483459885631324 | validation: 0.29467841481847457]
	TIME [epoch: 11.1 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.32632970635317277		[learning rate: 0.0095556]
	Learning Rate: 0.00955557
	LOSS [training: 0.32632970635317277 | validation: 0.25353961429682464]
	TIME [epoch: 11.1 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3008878508066999		[learning rate: 0.0095218]
	Learning Rate: 0.00952177
	LOSS [training: 0.3008878508066999 | validation: 0.25450686385837573]
	TIME [epoch: 11.1 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2992664500030983		[learning rate: 0.0094881]
	Learning Rate: 0.0094881
	LOSS [training: 0.2992664500030983 | validation: 0.2632190775171765]
	TIME [epoch: 11.1 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3160463738032156		[learning rate: 0.0094546]
	Learning Rate: 0.00945455
	LOSS [training: 0.3160463738032156 | validation: 0.22973612735644733]
	TIME [epoch: 11.1 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14_20240716_142138/states/model_facs_v3_dec1b_2dpca_v14_66.pth
	Model improved!!!
EPOCH 67/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.30297898729475287		[learning rate: 0.0094211]
	Learning Rate: 0.00942112
	LOSS [training: 0.30297898729475287 | validation: 0.25182315331312244]
	TIME [epoch: 11.1 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.30692630934810067		[learning rate: 0.0093878]
	Learning Rate: 0.00938781
	LOSS [training: 0.30692630934810067 | validation: 0.3006348385656038]
	TIME [epoch: 11 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.30793416555446324		[learning rate: 0.0093546]
	Learning Rate: 0.00935461
	LOSS [training: 0.30793416555446324 | validation: 0.23462097295393555]
	TIME [epoch: 11.1 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.30597675170388383		[learning rate: 0.0093215]
	Learning Rate: 0.00932153
	LOSS [training: 0.30597675170388383 | validation: 0.2526480905675195]
	TIME [epoch: 11 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.296707265428257		[learning rate: 0.0092886]
	Learning Rate: 0.00928857
	LOSS [training: 0.296707265428257 | validation: 0.2498658783349069]
	TIME [epoch: 11 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29839968023032365		[learning rate: 0.0092557]
	Learning Rate: 0.00925572
	LOSS [training: 0.29839968023032365 | validation: 0.23919369017840655]
	TIME [epoch: 11 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2992539901440414		[learning rate: 0.009223]
	Learning Rate: 0.00922299
	LOSS [training: 0.2992539901440414 | validation: 0.2438451599226213]
	TIME [epoch: 11.1 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.30408150548698454		[learning rate: 0.0091904]
	Learning Rate: 0.00919038
	LOSS [training: 0.30408150548698454 | validation: 0.2518496116793747]
	TIME [epoch: 11.1 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.31647555141054134		[learning rate: 0.0091579]
	Learning Rate: 0.00915788
	LOSS [training: 0.31647555141054134 | validation: 0.2686984508081395]
	TIME [epoch: 11 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3038332648313619		[learning rate: 0.0091255]
	Learning Rate: 0.00912549
	LOSS [training: 0.3038332648313619 | validation: 0.2650037340577761]
	TIME [epoch: 11.1 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.291274455706578		[learning rate: 0.0090932]
	Learning Rate: 0.00909323
	LOSS [training: 0.291274455706578 | validation: 0.2448775682266872]
	TIME [epoch: 11.1 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29702097049183945		[learning rate: 0.0090611]
	Learning Rate: 0.00906107
	LOSS [training: 0.29702097049183945 | validation: 0.24102302837609396]
	TIME [epoch: 11 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28680118612748035		[learning rate: 0.009029]
	Learning Rate: 0.00902903
	LOSS [training: 0.28680118612748035 | validation: 0.24529579670758447]
	TIME [epoch: 11 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28732424807290513		[learning rate: 0.0089971]
	Learning Rate: 0.0089971
	LOSS [training: 0.28732424807290513 | validation: 0.23292274652858475]
	TIME [epoch: 11 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3005623267470658		[learning rate: 0.0089653]
	Learning Rate: 0.00896528
	LOSS [training: 0.3005623267470658 | validation: 0.24931302688226786]
	TIME [epoch: 11 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2934689858006728		[learning rate: 0.0089336]
	Learning Rate: 0.00893358
	LOSS [training: 0.2934689858006728 | validation: 0.2407206510318311]
	TIME [epoch: 11 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2934714551918861		[learning rate: 0.008902]
	Learning Rate: 0.00890199
	LOSS [training: 0.2934714551918861 | validation: 0.23764413736943166]
	TIME [epoch: 11.1 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29412023279794414		[learning rate: 0.0088705]
	Learning Rate: 0.00887051
	LOSS [training: 0.29412023279794414 | validation: 0.24600162071716128]
	TIME [epoch: 11 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.30420328716635386		[learning rate: 0.0088391]
	Learning Rate: 0.00883914
	LOSS [training: 0.30420328716635386 | validation: 0.2321546275566006]
	TIME [epoch: 11 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29017503686486573		[learning rate: 0.0088079]
	Learning Rate: 0.00880789
	LOSS [training: 0.29017503686486573 | validation: 0.22788443101174377]
	TIME [epoch: 11 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14_20240716_142138/states/model_facs_v3_dec1b_2dpca_v14_86.pth
	Model improved!!!
EPOCH 87/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2794263146236521		[learning rate: 0.0087767]
	Learning Rate: 0.00877674
	LOSS [training: 0.2794263146236521 | validation: 0.24493825625816684]
	TIME [epoch: 11.1 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.283806432375615		[learning rate: 0.0087457]
	Learning Rate: 0.00874571
	LOSS [training: 0.283806432375615 | validation: 0.23435689164659285]
	TIME [epoch: 11.1 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2914741836864927		[learning rate: 0.0087148]
	Learning Rate: 0.00871478
	LOSS [training: 0.2914741836864927 | validation: 0.23426579056137334]
	TIME [epoch: 11 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2941467290374469		[learning rate: 0.008684]
	Learning Rate: 0.00868396
	LOSS [training: 0.2941467290374469 | validation: 0.22709970822952963]
	TIME [epoch: 11 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14_20240716_142138/states/model_facs_v3_dec1b_2dpca_v14_90.pth
	Model improved!!!
EPOCH 91/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2854114809367961		[learning rate: 0.0086533]
	Learning Rate: 0.00865326
	LOSS [training: 0.2854114809367961 | validation: 0.2324669817143538]
	TIME [epoch: 11.1 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2865694962893542		[learning rate: 0.0086227]
	Learning Rate: 0.00862265
	LOSS [training: 0.2865694962893542 | validation: 0.24645679619850389]
	TIME [epoch: 11.1 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.3084529319485841		[learning rate: 0.0085922]
	Learning Rate: 0.00859216
	LOSS [training: 0.3084529319485841 | validation: 0.22311512803514014]
	TIME [epoch: 11.1 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14_20240716_142138/states/model_facs_v3_dec1b_2dpca_v14_93.pth
	Model improved!!!
EPOCH 94/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.29214551330146027		[learning rate: 0.0085618]
	Learning Rate: 0.00856178
	LOSS [training: 0.29214551330146027 | validation: 0.2194727448761659]
	TIME [epoch: 11.1 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14_20240716_142138/states/model_facs_v3_dec1b_2dpca_v14_94.pth
	Model improved!!!
EPOCH 95/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2877422325478051		[learning rate: 0.0085315]
	Learning Rate: 0.0085315
	LOSS [training: 0.2877422325478051 | validation: 0.2310523906001448]
	TIME [epoch: 11.1 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2850422174976364		[learning rate: 0.0085013]
	Learning Rate: 0.00850134
	LOSS [training: 0.2850422174976364 | validation: 0.23974211741145196]
	TIME [epoch: 11.1 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2972404884509958		[learning rate: 0.0084713]
	Learning Rate: 0.00847127
	LOSS [training: 0.2972404884509958 | validation: 0.23766888728748023]
	TIME [epoch: 11.1 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.31869077516385574		[learning rate: 0.0084413]
	Learning Rate: 0.00844132
	LOSS [training: 0.31869077516385574 | validation: 0.23783446869096445]
	TIME [epoch: 11 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2891375447448185		[learning rate: 0.0084115]
	Learning Rate: 0.00841147
	LOSS [training: 0.2891375447448185 | validation: 0.2233519581462177]
	TIME [epoch: 11 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2854374968503402		[learning rate: 0.0083817]
	Learning Rate: 0.00838172
	LOSS [training: 0.2854374968503402 | validation: 0.21911264007299858]
	TIME [epoch: 11 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14_20240716_142138/states/model_facs_v3_dec1b_2dpca_v14_100.pth
	Model improved!!!
EPOCH 101/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27798928869040385		[learning rate: 0.0083521]
	Learning Rate: 0.00835208
	LOSS [training: 0.27798928869040385 | validation: 0.22373400237915658]
	TIME [epoch: 11.1 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2791347681090845		[learning rate: 0.0083225]
	Learning Rate: 0.00832255
	LOSS [training: 0.2791347681090845 | validation: 0.23267080591666392]
	TIME [epoch: 11.1 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27853476034194335		[learning rate: 0.0082931]
	Learning Rate: 0.00829312
	LOSS [training: 0.27853476034194335 | validation: 0.21678721257014688]
	TIME [epoch: 11.1 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14_20240716_142138/states/model_facs_v3_dec1b_2dpca_v14_103.pth
	Model improved!!!
EPOCH 104/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28220787049264623		[learning rate: 0.0082638]
	Learning Rate: 0.00826379
	LOSS [training: 0.28220787049264623 | validation: 0.2164149091027187]
	TIME [epoch: 11.1 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14_20240716_142138/states/model_facs_v3_dec1b_2dpca_v14_104.pth
	Model improved!!!
EPOCH 105/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27750708321252965		[learning rate: 0.0082346]
	Learning Rate: 0.00823457
	LOSS [training: 0.27750708321252965 | validation: 0.22718691152689258]
	TIME [epoch: 11.1 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27769506954660245		[learning rate: 0.0082055]
	Learning Rate: 0.00820545
	LOSS [training: 0.27769506954660245 | validation: 0.2221456108652733]
	TIME [epoch: 11.1 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28387669090760487		[learning rate: 0.0081764]
	Learning Rate: 0.00817644
	LOSS [training: 0.28387669090760487 | validation: 0.22833037170079779]
	TIME [epoch: 11.1 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27825166166158394		[learning rate: 0.0081475]
	Learning Rate: 0.00814752
	LOSS [training: 0.27825166166158394 | validation: 0.22138841370434656]
	TIME [epoch: 11.1 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2777031306449497		[learning rate: 0.0081187]
	Learning Rate: 0.00811871
	LOSS [training: 0.2777031306449497 | validation: 0.22642412526688607]
	TIME [epoch: 11 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28049410023724813		[learning rate: 0.00809]
	Learning Rate: 0.00809
	LOSS [training: 0.28049410023724813 | validation: 0.22361294522170683]
	TIME [epoch: 11 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28644954487971713		[learning rate: 0.0080614]
	Learning Rate: 0.0080614
	LOSS [training: 0.28644954487971713 | validation: 0.23890180014936]
	TIME [epoch: 11.1 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27639498801666523		[learning rate: 0.0080329]
	Learning Rate: 0.00803289
	LOSS [training: 0.27639498801666523 | validation: 0.22066636263215278]
	TIME [epoch: 11.1 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2778488189148309		[learning rate: 0.0080045]
	Learning Rate: 0.00800448
	LOSS [training: 0.2778488189148309 | validation: 0.2233421659647708]
	TIME [epoch: 11.1 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27728175555705453		[learning rate: 0.0079762]
	Learning Rate: 0.00797618
	LOSS [training: 0.27728175555705453 | validation: 0.21514948181562454]
	TIME [epoch: 11.1 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14_20240716_142138/states/model_facs_v3_dec1b_2dpca_v14_114.pth
	Model improved!!!
EPOCH 115/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2706486751126356		[learning rate: 0.007948]
	Learning Rate: 0.00794797
	LOSS [training: 0.2706486751126356 | validation: 0.22030693084496106]
	TIME [epoch: 11.1 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2891373168657076		[learning rate: 0.0079199]
	Learning Rate: 0.00791987
	LOSS [training: 0.2891373168657076 | validation: 0.2215905748651427]
	TIME [epoch: 11.1 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2634305875428308		[learning rate: 0.0078919]
	Learning Rate: 0.00789186
	LOSS [training: 0.2634305875428308 | validation: 0.21940522658089284]
	TIME [epoch: 11.1 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27195764145107315		[learning rate: 0.007864]
	Learning Rate: 0.00786395
	LOSS [training: 0.27195764145107315 | validation: 0.23663605919202818]
	TIME [epoch: 11.1 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27075540883885274		[learning rate: 0.0078361]
	Learning Rate: 0.00783615
	LOSS [training: 0.27075540883885274 | validation: 0.22526769395101126]
	TIME [epoch: 11.1 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.276633913057821		[learning rate: 0.0078084]
	Learning Rate: 0.00780844
	LOSS [training: 0.276633913057821 | validation: 0.22201270858632918]
	TIME [epoch: 11.1 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2883269140725307		[learning rate: 0.0077808]
	Learning Rate: 0.00778083
	LOSS [training: 0.2883269140725307 | validation: 0.21918059581695754]
	TIME [epoch: 11 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26998399668687223		[learning rate: 0.0077533]
	Learning Rate: 0.00775331
	LOSS [training: 0.26998399668687223 | validation: 0.2379584132183417]
	TIME [epoch: 11.1 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28543439290394806		[learning rate: 0.0077259]
	Learning Rate: 0.00772589
	LOSS [training: 0.28543439290394806 | validation: 0.22248345633704947]
	TIME [epoch: 11.1 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2799464746271717		[learning rate: 0.0076986]
	Learning Rate: 0.00769857
	LOSS [training: 0.2799464746271717 | validation: 0.22115282799144653]
	TIME [epoch: 11.1 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27470922302868545		[learning rate: 0.0076714]
	Learning Rate: 0.00767135
	LOSS [training: 0.27470922302868545 | validation: 0.20747419518017995]
	TIME [epoch: 11.1 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14_20240716_142138/states/model_facs_v3_dec1b_2dpca_v14_125.pth
	Model improved!!!
EPOCH 126/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2682888795150152		[learning rate: 0.0076442]
	Learning Rate: 0.00764422
	LOSS [training: 0.2682888795150152 | validation: 0.21609315768964352]
	TIME [epoch: 11.1 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2644272627185734		[learning rate: 0.0076172]
	Learning Rate: 0.00761719
	LOSS [training: 0.2644272627185734 | validation: 0.21619163878819353]
	TIME [epoch: 11.1 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27351856168084027		[learning rate: 0.0075903]
	Learning Rate: 0.00759025
	LOSS [training: 0.27351856168084027 | validation: 0.23191703085537574]
	TIME [epoch: 11.1 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2774873101184308		[learning rate: 0.0075634]
	Learning Rate: 0.00756341
	LOSS [training: 0.2774873101184308 | validation: 0.23035941136306573]
	TIME [epoch: 11.1 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2676140558013364		[learning rate: 0.0075367]
	Learning Rate: 0.00753667
	LOSS [training: 0.2676140558013364 | validation: 0.22095934544337598]
	TIME [epoch: 11.1 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2782528765313297		[learning rate: 0.00751]
	Learning Rate: 0.00751002
	LOSS [training: 0.2782528765313297 | validation: 0.22443791470385915]
	TIME [epoch: 11 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26824108992624957		[learning rate: 0.0074835]
	Learning Rate: 0.00748346
	LOSS [training: 0.26824108992624957 | validation: 0.22851969403542155]
	TIME [epoch: 11.1 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2802346661044904		[learning rate: 0.007457]
	Learning Rate: 0.007457
	LOSS [training: 0.2802346661044904 | validation: 0.24140872263345076]
	TIME [epoch: 11.1 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2734608918233424		[learning rate: 0.0074306]
	Learning Rate: 0.00743063
	LOSS [training: 0.2734608918233424 | validation: 0.2152173511203391]
	TIME [epoch: 11.1 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27330185407058954		[learning rate: 0.0074044]
	Learning Rate: 0.00740435
	LOSS [training: 0.27330185407058954 | validation: 0.23020390196318335]
	TIME [epoch: 11.1 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26732224023215706		[learning rate: 0.0073782]
	Learning Rate: 0.00737817
	LOSS [training: 0.26732224023215706 | validation: 0.20642843719117193]
	TIME [epoch: 11.1 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14_20240716_142138/states/model_facs_v3_dec1b_2dpca_v14_136.pth
	Model improved!!!
EPOCH 137/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2705780845247024		[learning rate: 0.0073521]
	Learning Rate: 0.00735208
	LOSS [training: 0.2705780845247024 | validation: 0.21934145171211178]
	TIME [epoch: 11.1 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2658090390260991		[learning rate: 0.0073261]
	Learning Rate: 0.00732608
	LOSS [training: 0.2658090390260991 | validation: 0.21501275481495857]
	TIME [epoch: 11.1 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26175997345871566		[learning rate: 0.0073002]
	Learning Rate: 0.00730018
	LOSS [training: 0.26175997345871566 | validation: 0.22046259165213605]
	TIME [epoch: 11 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2659189638251423		[learning rate: 0.0072744]
	Learning Rate: 0.00727436
	LOSS [training: 0.2659189638251423 | validation: 0.2306874424588043]
	TIME [epoch: 11.1 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27019321312313443		[learning rate: 0.0072486]
	Learning Rate: 0.00724864
	LOSS [training: 0.27019321312313443 | validation: 0.22406931010212877]
	TIME [epoch: 11.1 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28121846910157344		[learning rate: 0.007223]
	Learning Rate: 0.007223
	LOSS [training: 0.28121846910157344 | validation: 0.21137909845020247]
	TIME [epoch: 11 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26847818386319094		[learning rate: 0.0071975]
	Learning Rate: 0.00719746
	LOSS [training: 0.26847818386319094 | validation: 0.21965417595367537]
	TIME [epoch: 11 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2648636480128444		[learning rate: 0.007172]
	Learning Rate: 0.00717201
	LOSS [training: 0.2648636480128444 | validation: 0.22423968223117755]
	TIME [epoch: 11.1 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2639570799890356		[learning rate: 0.0071467]
	Learning Rate: 0.00714665
	LOSS [training: 0.2639570799890356 | validation: 0.22063183511111983]
	TIME [epoch: 11.1 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2603152424122001		[learning rate: 0.0071214]
	Learning Rate: 0.00712138
	LOSS [training: 0.2603152424122001 | validation: 0.2364529873272599]
	TIME [epoch: 11 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2698005731624918		[learning rate: 0.0070962]
	Learning Rate: 0.0070962
	LOSS [training: 0.2698005731624918 | validation: 0.2079554191409912]
	TIME [epoch: 11.1 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2612686544258376		[learning rate: 0.0070711]
	Learning Rate: 0.0070711
	LOSS [training: 0.2612686544258376 | validation: 0.22501094472653702]
	TIME [epoch: 11.1 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25978527507272425		[learning rate: 0.0070461]
	Learning Rate: 0.0070461
	LOSS [training: 0.25978527507272425 | validation: 0.2231046575897461]
	TIME [epoch: 11.1 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2700430491162395		[learning rate: 0.0070212]
	Learning Rate: 0.00702118
	LOSS [training: 0.2700430491162395 | validation: 0.22290723586509215]
	TIME [epoch: 11.1 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2716646596887377		[learning rate: 0.0069964]
	Learning Rate: 0.00699635
	LOSS [training: 0.2716646596887377 | validation: 0.20885111099223647]
	TIME [epoch: 11.1 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26607733227212826		[learning rate: 0.0069716]
	Learning Rate: 0.00697161
	LOSS [training: 0.26607733227212826 | validation: 0.21899541742378448]
	TIME [epoch: 11.1 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2672291543082141		[learning rate: 0.006947]
	Learning Rate: 0.00694696
	LOSS [training: 0.2672291543082141 | validation: 0.22117882152668816]
	TIME [epoch: 11.1 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2598284330133189		[learning rate: 0.0069224]
	Learning Rate: 0.00692239
	LOSS [training: 0.2598284330133189 | validation: 0.22265809767023761]
	TIME [epoch: 11 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26136285628494577		[learning rate: 0.0068979]
	Learning Rate: 0.00689792
	LOSS [training: 0.26136285628494577 | validation: 0.22609246095118643]
	TIME [epoch: 11.1 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.285304430147394		[learning rate: 0.0068735]
	Learning Rate: 0.00687352
	LOSS [training: 0.285304430147394 | validation: 0.2279530173216456]
	TIME [epoch: 11.1 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26634085602767227		[learning rate: 0.0068492]
	Learning Rate: 0.00684922
	LOSS [training: 0.26634085602767227 | validation: 0.2269418193097504]
	TIME [epoch: 11.1 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28590623268779186		[learning rate: 0.006825]
	Learning Rate: 0.006825
	LOSS [training: 0.28590623268779186 | validation: 0.21732235097737554]
	TIME [epoch: 11.1 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2748982583772326		[learning rate: 0.0068009]
	Learning Rate: 0.00680086
	LOSS [training: 0.2748982583772326 | validation: 0.23228606816161856]
	TIME [epoch: 11.1 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2597128493918562		[learning rate: 0.0067768]
	Learning Rate: 0.00677681
	LOSS [training: 0.2597128493918562 | validation: 0.21642269754369758]
	TIME [epoch: 11.1 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2610995001604292		[learning rate: 0.0067529]
	Learning Rate: 0.00675285
	LOSS [training: 0.2610995001604292 | validation: 0.2100368000406268]
	TIME [epoch: 11.1 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2718069027789795		[learning rate: 0.006729]
	Learning Rate: 0.00672897
	LOSS [training: 0.2718069027789795 | validation: 0.2185174496983026]
	TIME [epoch: 11.1 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2596290966669021		[learning rate: 0.0067052]
	Learning Rate: 0.00670518
	LOSS [training: 0.2596290966669021 | validation: 0.21276503806755115]
	TIME [epoch: 11.1 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2766680491226002		[learning rate: 0.0066815]
	Learning Rate: 0.00668147
	LOSS [training: 0.2766680491226002 | validation: 0.23045679874053518]
	TIME [epoch: 11.1 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.28080905724762606		[learning rate: 0.0066578]
	Learning Rate: 0.00665784
	LOSS [training: 0.28080905724762606 | validation: 0.21074863457503396]
	TIME [epoch: 11.1 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26316392038960595		[learning rate: 0.0066343]
	Learning Rate: 0.0066343
	LOSS [training: 0.26316392038960595 | validation: 0.22103122012630805]
	TIME [epoch: 11.1 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25957419672564286		[learning rate: 0.0066108]
	Learning Rate: 0.00661084
	LOSS [training: 0.25957419672564286 | validation: 0.20946777197331584]
	TIME [epoch: 11.1 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26833514454762536		[learning rate: 0.0065875]
	Learning Rate: 0.00658746
	LOSS [training: 0.26833514454762536 | validation: 0.22151973554098597]
	TIME [epoch: 11 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2667457947250522		[learning rate: 0.0065642]
	Learning Rate: 0.00656416
	LOSS [training: 0.2667457947250522 | validation: 0.221877339194823]
	TIME [epoch: 11.1 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26091646503116867		[learning rate: 0.006541]
	Learning Rate: 0.00654095
	LOSS [training: 0.26091646503116867 | validation: 0.2145774403473737]
	TIME [epoch: 11.1 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2687542133918505		[learning rate: 0.0065178]
	Learning Rate: 0.00651782
	LOSS [training: 0.2687542133918505 | validation: 0.21529656607964523]
	TIME [epoch: 11.1 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27521365124751024		[learning rate: 0.0064948]
	Learning Rate: 0.00649477
	LOSS [training: 0.27521365124751024 | validation: 0.22429974596891142]
	TIME [epoch: 11.1 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26540945293659707		[learning rate: 0.0064718]
	Learning Rate: 0.00647181
	LOSS [training: 0.26540945293659707 | validation: 0.21931065051208365]
	TIME [epoch: 11.1 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26244552772793156		[learning rate: 0.0064489]
	Learning Rate: 0.00644892
	LOSS [training: 0.26244552772793156 | validation: 0.21436355566050333]
	TIME [epoch: 11 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2537838007857702		[learning rate: 0.0064261]
	Learning Rate: 0.00642612
	LOSS [training: 0.2537838007857702 | validation: 0.2094509234882626]
	TIME [epoch: 11.1 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2632270161512774		[learning rate: 0.0064034]
	Learning Rate: 0.00640339
	LOSS [training: 0.2632270161512774 | validation: 0.21248986840199313]
	TIME [epoch: 11 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26545251815596177		[learning rate: 0.0063808]
	Learning Rate: 0.00638075
	LOSS [training: 0.26545251815596177 | validation: 0.21682105529065604]
	TIME [epoch: 11.1 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2702156534576298		[learning rate: 0.0063582]
	Learning Rate: 0.00635819
	LOSS [training: 0.2702156534576298 | validation: 0.22735103094729886]
	TIME [epoch: 11.1 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2650458281854688		[learning rate: 0.0063357]
	Learning Rate: 0.0063357
	LOSS [training: 0.2650458281854688 | validation: 0.22346375348949646]
	TIME [epoch: 11.1 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2666731457849893		[learning rate: 0.0063133]
	Learning Rate: 0.0063133
	LOSS [training: 0.2666731457849893 | validation: 0.22156755725220795]
	TIME [epoch: 11.1 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2717952503353522		[learning rate: 0.006291]
	Learning Rate: 0.00629097
	LOSS [training: 0.2717952503353522 | validation: 0.21332675099221282]
	TIME [epoch: 11.1 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2728001180092487		[learning rate: 0.0062687]
	Learning Rate: 0.00626873
	LOSS [training: 0.2728001180092487 | validation: 0.22670949610349211]
	TIME [epoch: 11.1 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2717057467097999		[learning rate: 0.0062466]
	Learning Rate: 0.00624656
	LOSS [training: 0.2717057467097999 | validation: 0.22238807299868824]
	TIME [epoch: 11.1 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26007118234601606		[learning rate: 0.0062245]
	Learning Rate: 0.00622447
	LOSS [training: 0.26007118234601606 | validation: 0.22907464665017563]
	TIME [epoch: 11.1 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26189479624373674		[learning rate: 0.0062025]
	Learning Rate: 0.00620246
	LOSS [training: 0.26189479624373674 | validation: 0.22123842951982256]
	TIME [epoch: 11 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.276740758877388		[learning rate: 0.0061805]
	Learning Rate: 0.00618053
	LOSS [training: 0.276740758877388 | validation: 0.21296711049878847]
	TIME [epoch: 11.1 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26218881478806255		[learning rate: 0.0061587]
	Learning Rate: 0.00615867
	LOSS [training: 0.26218881478806255 | validation: 0.2092434951999768]
	TIME [epoch: 11.1 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2757269837018555		[learning rate: 0.0061369]
	Learning Rate: 0.00613689
	LOSS [training: 0.2757269837018555 | validation: 0.22074445031149298]
	TIME [epoch: 11.1 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25909460997641226		[learning rate: 0.0061152]
	Learning Rate: 0.00611519
	LOSS [training: 0.25909460997641226 | validation: 0.22048634300371245]
	TIME [epoch: 11.1 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.256409923335613		[learning rate: 0.0060936]
	Learning Rate: 0.00609357
	LOSS [training: 0.256409923335613 | validation: 0.21515506068421986]
	TIME [epoch: 11.1 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27278514259305453		[learning rate: 0.006072]
	Learning Rate: 0.00607202
	LOSS [training: 0.27278514259305453 | validation: 0.22725194923488728]
	TIME [epoch: 11.1 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2654888322040699		[learning rate: 0.0060505]
	Learning Rate: 0.00605055
	LOSS [training: 0.2654888322040699 | validation: 0.22435408810485233]
	TIME [epoch: 11.1 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27144373029780827		[learning rate: 0.0060292]
	Learning Rate: 0.00602915
	LOSS [training: 0.27144373029780827 | validation: 0.2181951537875914]
	TIME [epoch: 11.1 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26021291128989227		[learning rate: 0.0060078]
	Learning Rate: 0.00600783
	LOSS [training: 0.26021291128989227 | validation: 0.21557968683354461]
	TIME [epoch: 11.1 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26013103833921586		[learning rate: 0.0059866]
	Learning Rate: 0.00598659
	LOSS [training: 0.26013103833921586 | validation: 0.21335457611628753]
	TIME [epoch: 11.1 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2812825506825441		[learning rate: 0.0059654]
	Learning Rate: 0.00596542
	LOSS [training: 0.2812825506825441 | validation: 0.22723452395027638]
	TIME [epoch: 11.1 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27756512259527405		[learning rate: 0.0059443]
	Learning Rate: 0.00594433
	LOSS [training: 0.27756512259527405 | validation: 0.2267806557241226]
	TIME [epoch: 11.1 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2608820670232719		[learning rate: 0.0059233]
	Learning Rate: 0.0059233
	LOSS [training: 0.2608820670232719 | validation: 0.20952435275751]
	TIME [epoch: 11.1 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25235619113635754		[learning rate: 0.0059024]
	Learning Rate: 0.00590236
	LOSS [training: 0.25235619113635754 | validation: 0.21699564460477716]
	TIME [epoch: 11.1 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2627692611058699		[learning rate: 0.0058815]
	Learning Rate: 0.00588149
	LOSS [training: 0.2627692611058699 | validation: 0.21041058981261]
	TIME [epoch: 11.1 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26681203584199387		[learning rate: 0.0058607]
	Learning Rate: 0.00586069
	LOSS [training: 0.26681203584199387 | validation: 0.21749868252810217]
	TIME [epoch: 11.1 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26554176983590494		[learning rate: 0.00584]
	Learning Rate: 0.00583996
	LOSS [training: 0.26554176983590494 | validation: 0.21808537109085582]
	TIME [epoch: 11.1 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2612813464598988		[learning rate: 0.0058193]
	Learning Rate: 0.00581931
	LOSS [training: 0.2612813464598988 | validation: 0.2121920918202093]
	TIME [epoch: 11.1 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27284506768460354		[learning rate: 0.0057987]
	Learning Rate: 0.00579874
	LOSS [training: 0.27284506768460354 | validation: 0.21162512572175443]
	TIME [epoch: 11.1 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26803174461268914		[learning rate: 0.0057782]
	Learning Rate: 0.00577823
	LOSS [training: 0.26803174461268914 | validation: 0.20911315523147564]
	TIME [epoch: 11.1 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25799728781377		[learning rate: 0.0057578]
	Learning Rate: 0.0057578
	LOSS [training: 0.25799728781377 | validation: 0.21363843563953572]
	TIME [epoch: 11.1 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.266178044789802		[learning rate: 0.0057374]
	Learning Rate: 0.00573744
	LOSS [training: 0.266178044789802 | validation: 0.21299282487677157]
	TIME [epoch: 11.1 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25880055109243333		[learning rate: 0.0057171]
	Learning Rate: 0.00571715
	LOSS [training: 0.25880055109243333 | validation: 0.21448288416005887]
	TIME [epoch: 11.1 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2697286786600101		[learning rate: 0.0056969]
	Learning Rate: 0.00569693
	LOSS [training: 0.2697286786600101 | validation: 0.20537434201709076]
	TIME [epoch: 11 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14_20240716_142138/states/model_facs_v3_dec1b_2dpca_v14_209.pth
	Model improved!!!
EPOCH 210/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26566360365820324		[learning rate: 0.0056768]
	Learning Rate: 0.00567679
	LOSS [training: 0.26566360365820324 | validation: 0.223869204863904]
	TIME [epoch: 11.1 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27520681022705296		[learning rate: 0.0056567]
	Learning Rate: 0.00565671
	LOSS [training: 0.27520681022705296 | validation: 0.22096313438463241]
	TIME [epoch: 11.1 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2589261635149298		[learning rate: 0.0056367]
	Learning Rate: 0.00563671
	LOSS [training: 0.2589261635149298 | validation: 0.22216853053718494]
	TIME [epoch: 11.1 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.266962836370456		[learning rate: 0.0056168]
	Learning Rate: 0.00561678
	LOSS [training: 0.266962836370456 | validation: 0.20812457789566916]
	TIME [epoch: 11.1 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25356229280423076		[learning rate: 0.0055969]
	Learning Rate: 0.00559691
	LOSS [training: 0.25356229280423076 | validation: 0.21228509225658132]
	TIME [epoch: 11.1 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25140849258022974		[learning rate: 0.0055771]
	Learning Rate: 0.00557712
	LOSS [training: 0.25140849258022974 | validation: 0.214502066059919]
	TIME [epoch: 11.1 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2674151786241014		[learning rate: 0.0055574]
	Learning Rate: 0.0055574
	LOSS [training: 0.2674151786241014 | validation: 0.21645966490966692]
	TIME [epoch: 11 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2619308660593905		[learning rate: 0.0055378]
	Learning Rate: 0.00553775
	LOSS [training: 0.2619308660593905 | validation: 0.21736590008198928]
	TIME [epoch: 11 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2693869061887315		[learning rate: 0.0055182]
	Learning Rate: 0.00551817
	LOSS [training: 0.2693869061887315 | validation: 0.2151946173994883]
	TIME [epoch: 11.1 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26246498477593416		[learning rate: 0.0054987]
	Learning Rate: 0.00549865
	LOSS [training: 0.26246498477593416 | validation: 0.21225195740237032]
	TIME [epoch: 11.1 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2623597089760334		[learning rate: 0.0054792]
	Learning Rate: 0.00547921
	LOSS [training: 0.2623597089760334 | validation: 0.21681949694138733]
	TIME [epoch: 11.1 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25998565522629247		[learning rate: 0.0054598]
	Learning Rate: 0.00545983
	LOSS [training: 0.25998565522629247 | validation: 0.22449034241680046]
	TIME [epoch: 11.1 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25695610670996527		[learning rate: 0.0054405]
	Learning Rate: 0.00544053
	LOSS [training: 0.25695610670996527 | validation: 0.21719135404274947]
	TIME [epoch: 11.1 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.256920468795526		[learning rate: 0.0054213]
	Learning Rate: 0.00542129
	LOSS [training: 0.256920468795526 | validation: 0.21812771117354773]
	TIME [epoch: 11.1 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2543396105411903		[learning rate: 0.0054021]
	Learning Rate: 0.00540212
	LOSS [training: 0.2543396105411903 | validation: 0.21202350041219292]
	TIME [epoch: 11.1 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2647226676674596		[learning rate: 0.005383]
	Learning Rate: 0.00538302
	LOSS [training: 0.2647226676674596 | validation: 0.22498692705972392]
	TIME [epoch: 11.1 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2582244724009246		[learning rate: 0.005364]
	Learning Rate: 0.00536398
	LOSS [training: 0.2582244724009246 | validation: 0.21207860311261012]
	TIME [epoch: 11.1 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2584090821116905		[learning rate: 0.005345]
	Learning Rate: 0.00534501
	LOSS [training: 0.2584090821116905 | validation: 0.20742537036258227]
	TIME [epoch: 11.1 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2581876844320056		[learning rate: 0.0053261]
	Learning Rate: 0.00532611
	LOSS [training: 0.2581876844320056 | validation: 0.21877458323897042]
	TIME [epoch: 11.1 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2551296830933704		[learning rate: 0.0053073]
	Learning Rate: 0.00530728
	LOSS [training: 0.2551296830933704 | validation: 0.21659217994271543]
	TIME [epoch: 11.1 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25997009017821304		[learning rate: 0.0052885]
	Learning Rate: 0.00528851
	LOSS [training: 0.25997009017821304 | validation: 0.2152822301427983]
	TIME [epoch: 11.1 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25902942976691257		[learning rate: 0.0052698]
	Learning Rate: 0.00526981
	LOSS [training: 0.25902942976691257 | validation: 0.2128613337746624]
	TIME [epoch: 11.1 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24902647503257191		[learning rate: 0.0052512]
	Learning Rate: 0.00525117
	LOSS [training: 0.24902647503257191 | validation: 0.2109799687705495]
	TIME [epoch: 11.1 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2602176598475462		[learning rate: 0.0052326]
	Learning Rate: 0.0052326
	LOSS [training: 0.2602176598475462 | validation: 0.21288706375020666]
	TIME [epoch: 11.1 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2723598338137051		[learning rate: 0.0052141]
	Learning Rate: 0.0052141
	LOSS [training: 0.2723598338137051 | validation: 0.22637248032024004]
	TIME [epoch: 11.1 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26645984615002155		[learning rate: 0.0051957]
	Learning Rate: 0.00519566
	LOSS [training: 0.26645984615002155 | validation: 0.21676242598898837]
	TIME [epoch: 11.1 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26041763968250303		[learning rate: 0.0051773]
	Learning Rate: 0.00517729
	LOSS [training: 0.26041763968250303 | validation: 0.21790196642698073]
	TIME [epoch: 11.1 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2587556341822211		[learning rate: 0.005159]
	Learning Rate: 0.00515898
	LOSS [training: 0.2587556341822211 | validation: 0.2130837217919579]
	TIME [epoch: 11.1 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2555697446608556		[learning rate: 0.0051407]
	Learning Rate: 0.00514074
	LOSS [training: 0.2555697446608556 | validation: 0.2175605683563989]
	TIME [epoch: 11 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26194708674411665		[learning rate: 0.0051226]
	Learning Rate: 0.00512256
	LOSS [training: 0.26194708674411665 | validation: 0.21445978323889703]
	TIME [epoch: 11.1 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25904247897082927		[learning rate: 0.0051044]
	Learning Rate: 0.00510445
	LOSS [training: 0.25904247897082927 | validation: 0.21504135853981637]
	TIME [epoch: 11.1 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.27157282480699085		[learning rate: 0.0050864]
	Learning Rate: 0.0050864
	LOSS [training: 0.27157282480699085 | validation: 0.21562395826026332]
	TIME [epoch: 11.1 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25647144308128905		[learning rate: 0.0050684]
	Learning Rate: 0.00506841
	LOSS [training: 0.25647144308128905 | validation: 0.21104274972023304]
	TIME [epoch: 11.1 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2658762781585309		[learning rate: 0.0050505]
	Learning Rate: 0.00505049
	LOSS [training: 0.2658762781585309 | validation: 0.21313780362404428]
	TIME [epoch: 11.1 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25611080956102633		[learning rate: 0.0050326]
	Learning Rate: 0.00503263
	LOSS [training: 0.25611080956102633 | validation: 0.21555102748173455]
	TIME [epoch: 11.1 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26472701008630595		[learning rate: 0.0050148]
	Learning Rate: 0.00501483
	LOSS [training: 0.26472701008630595 | validation: 0.2100867550239321]
	TIME [epoch: 11.1 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25739680756415484		[learning rate: 0.0049971]
	Learning Rate: 0.0049971
	LOSS [training: 0.25739680756415484 | validation: 0.22220367476178854]
	TIME [epoch: 11.1 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2569044114704149		[learning rate: 0.0049794]
	Learning Rate: 0.00497943
	LOSS [training: 0.2569044114704149 | validation: 0.21905037589665577]
	TIME [epoch: 11.1 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25312363078614597		[learning rate: 0.0049618]
	Learning Rate: 0.00496182
	LOSS [training: 0.25312363078614597 | validation: 0.21376363100078405]
	TIME [epoch: 11.1 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25544651602215135		[learning rate: 0.0049443]
	Learning Rate: 0.00494427
	LOSS [training: 0.25544651602215135 | validation: 0.2165597717733724]
	TIME [epoch: 11.1 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2486723766262686		[learning rate: 0.0049268]
	Learning Rate: 0.00492679
	LOSS [training: 0.2486723766262686 | validation: 0.21506524072785763]
	TIME [epoch: 11.1 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2596354454990564		[learning rate: 0.0049094]
	Learning Rate: 0.00490937
	LOSS [training: 0.2596354454990564 | validation: 0.22084880562362325]
	TIME [epoch: 11.1 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25209677334336383		[learning rate: 0.004892]
	Learning Rate: 0.00489201
	LOSS [training: 0.25209677334336383 | validation: 0.21014349895766124]
	TIME [epoch: 11.1 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2665044313303414		[learning rate: 0.0048747]
	Learning Rate: 0.00487471
	LOSS [training: 0.2665044313303414 | validation: 0.21581046361095463]
	TIME [epoch: 11.1 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2606895589432036		[learning rate: 0.0048575]
	Learning Rate: 0.00485747
	LOSS [training: 0.2606895589432036 | validation: 0.21417190780579415]
	TIME [epoch: 11.1 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2579169338914653		[learning rate: 0.0048403]
	Learning Rate: 0.00484029
	LOSS [training: 0.2579169338914653 | validation: 0.22357628440822902]
	TIME [epoch: 11.1 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2530189846607304		[learning rate: 0.0048232]
	Learning Rate: 0.00482318
	LOSS [training: 0.2530189846607304 | validation: 0.21399931924856105]
	TIME [epoch: 11.1 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2587770331887916		[learning rate: 0.0048061]
	Learning Rate: 0.00480612
	LOSS [training: 0.2587770331887916 | validation: 0.2267971047515281]
	TIME [epoch: 11.1 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2620136750063144		[learning rate: 0.0047891]
	Learning Rate: 0.00478913
	LOSS [training: 0.2620136750063144 | validation: 0.21199032455325492]
	TIME [epoch: 11.1 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2506315947205158		[learning rate: 0.0047722]
	Learning Rate: 0.00477219
	LOSS [training: 0.2506315947205158 | validation: 0.21393003696261986]
	TIME [epoch: 11.1 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2711499952837721		[learning rate: 0.0047553]
	Learning Rate: 0.00475532
	LOSS [training: 0.2711499952837721 | validation: 0.21662238959873764]
	TIME [epoch: 11.1 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2564476121133334		[learning rate: 0.0047385]
	Learning Rate: 0.0047385
	LOSS [training: 0.2564476121133334 | validation: 0.22077425089447217]
	TIME [epoch: 11.1 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2556310159821024		[learning rate: 0.0047217]
	Learning Rate: 0.00472175
	LOSS [training: 0.2556310159821024 | validation: 0.2117199375266831]
	TIME [epoch: 11.1 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2675730979917556		[learning rate: 0.004705]
	Learning Rate: 0.00470505
	LOSS [training: 0.2675730979917556 | validation: 0.21630163984150252]
	TIME [epoch: 11.1 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26028113114324675		[learning rate: 0.0046884]
	Learning Rate: 0.00468841
	LOSS [training: 0.26028113114324675 | validation: 0.21992760806325115]
	TIME [epoch: 11.1 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2533237654697745		[learning rate: 0.0046718]
	Learning Rate: 0.00467183
	LOSS [training: 0.2533237654697745 | validation: 0.2141963899653831]
	TIME [epoch: 11.1 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25591571274139585		[learning rate: 0.0046553]
	Learning Rate: 0.00465531
	LOSS [training: 0.25591571274139585 | validation: 0.21708530257439596]
	TIME [epoch: 11.1 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25137438685538976		[learning rate: 0.0046388]
	Learning Rate: 0.00463885
	LOSS [training: 0.25137438685538976 | validation: 0.22116168637235023]
	TIME [epoch: 11.1 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26650886629762643		[learning rate: 0.0046224]
	Learning Rate: 0.00462245
	LOSS [training: 0.26650886629762643 | validation: 0.2154389718335604]
	TIME [epoch: 11.1 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2579859868217122		[learning rate: 0.0046061]
	Learning Rate: 0.0046061
	LOSS [training: 0.2579859868217122 | validation: 0.23095610194143634]
	TIME [epoch: 11.1 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25869300662864386		[learning rate: 0.0045898]
	Learning Rate: 0.00458981
	LOSS [training: 0.25869300662864386 | validation: 0.2164555538719851]
	TIME [epoch: 11.1 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.253897008076739		[learning rate: 0.0045736]
	Learning Rate: 0.00457358
	LOSS [training: 0.253897008076739 | validation: 0.2212260235643148]
	TIME [epoch: 11.1 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.258920704866639		[learning rate: 0.0045574]
	Learning Rate: 0.00455741
	LOSS [training: 0.258920704866639 | validation: 0.21749003411789336]
	TIME [epoch: 11.1 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26400522186416403		[learning rate: 0.0045413]
	Learning Rate: 0.00454129
	LOSS [training: 0.26400522186416403 | validation: 0.21181409459196274]
	TIME [epoch: 11.1 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.263690933539721		[learning rate: 0.0045252]
	Learning Rate: 0.00452523
	LOSS [training: 0.263690933539721 | validation: 0.21056162226187766]
	TIME [epoch: 11.1 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2541690055209448		[learning rate: 0.0045092]
	Learning Rate: 0.00450923
	LOSS [training: 0.2541690055209448 | validation: 0.21687793043530768]
	TIME [epoch: 11.1 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24901476713790113		[learning rate: 0.0044933]
	Learning Rate: 0.00449329
	LOSS [training: 0.24901476713790113 | validation: 0.22390178104759034]
	TIME [epoch: 11.1 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2524446824470552		[learning rate: 0.0044774]
	Learning Rate: 0.0044774
	LOSS [training: 0.2524446824470552 | validation: 0.21269214535881567]
	TIME [epoch: 11.1 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2511661306733903		[learning rate: 0.0044616]
	Learning Rate: 0.00446156
	LOSS [training: 0.2511661306733903 | validation: 0.21725073945644763]
	TIME [epoch: 11.1 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25732249732328555		[learning rate: 0.0044458]
	Learning Rate: 0.00444579
	LOSS [training: 0.25732249732328555 | validation: 0.21358659942416858]
	TIME [epoch: 11.1 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2599527096519684		[learning rate: 0.0044301]
	Learning Rate: 0.00443007
	LOSS [training: 0.2599527096519684 | validation: 0.21374597069457998]
	TIME [epoch: 11.1 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2543112790891404		[learning rate: 0.0044144]
	Learning Rate: 0.0044144
	LOSS [training: 0.2543112790891404 | validation: 0.21444686851481815]
	TIME [epoch: 11.1 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25819686685097826		[learning rate: 0.0043988]
	Learning Rate: 0.00439879
	LOSS [training: 0.25819686685097826 | validation: 0.2181578791012031]
	TIME [epoch: 11.1 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2559302252792438		[learning rate: 0.0043832]
	Learning Rate: 0.00438324
	LOSS [training: 0.2559302252792438 | validation: 0.2193752207365919]
	TIME [epoch: 11.1 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2576216840201255		[learning rate: 0.0043677]
	Learning Rate: 0.00436774
	LOSS [training: 0.2576216840201255 | validation: 0.21269573472204378]
	TIME [epoch: 11.1 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24753718292044788		[learning rate: 0.0043523]
	Learning Rate: 0.00435229
	LOSS [training: 0.24753718292044788 | validation: 0.21107553952815422]
	TIME [epoch: 11.1 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25793275872290444		[learning rate: 0.0043369]
	Learning Rate: 0.0043369
	LOSS [training: 0.25793275872290444 | validation: 0.2166391799207938]
	TIME [epoch: 11.1 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2567030061738908		[learning rate: 0.0043216]
	Learning Rate: 0.00432156
	LOSS [training: 0.2567030061738908 | validation: 0.21357580613191796]
	TIME [epoch: 11.1 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2654324963969598		[learning rate: 0.0043063]
	Learning Rate: 0.00430628
	LOSS [training: 0.2654324963969598 | validation: 0.20888406257098366]
	TIME [epoch: 11.1 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.257078912008264		[learning rate: 0.0042911]
	Learning Rate: 0.00429106
	LOSS [training: 0.257078912008264 | validation: 0.21555879857192445]
	TIME [epoch: 11.1 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24066539987504423		[learning rate: 0.0042759]
	Learning Rate: 0.00427588
	LOSS [training: 0.24066539987504423 | validation: 0.20919063813702393]
	TIME [epoch: 11.1 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25990569394071705		[learning rate: 0.0042608]
	Learning Rate: 0.00426076
	LOSS [training: 0.25990569394071705 | validation: 0.20831843453950089]
	TIME [epoch: 11.1 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24886778802813378		[learning rate: 0.0042457]
	Learning Rate: 0.00424569
	LOSS [training: 0.24886778802813378 | validation: 0.22165510627708113]
	TIME [epoch: 11.1 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25915574380505		[learning rate: 0.0042307]
	Learning Rate: 0.00423068
	LOSS [training: 0.25915574380505 | validation: 0.21675695583830734]
	TIME [epoch: 11 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2559150346464158		[learning rate: 0.0042157]
	Learning Rate: 0.00421572
	LOSS [training: 0.2559150346464158 | validation: 0.21336521555160598]
	TIME [epoch: 11.1 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25116467722514696		[learning rate: 0.0042008]
	Learning Rate: 0.00420081
	LOSS [training: 0.25116467722514696 | validation: 0.21423550711029052]
	TIME [epoch: 11.1 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26226201614367084		[learning rate: 0.004186]
	Learning Rate: 0.00418596
	LOSS [training: 0.26226201614367084 | validation: 0.2187278005331012]
	TIME [epoch: 11.1 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2592952015620618		[learning rate: 0.0041712]
	Learning Rate: 0.00417116
	LOSS [training: 0.2592952015620618 | validation: 0.21381967347703554]
	TIME [epoch: 11.1 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2531170528501188		[learning rate: 0.0041564]
	Learning Rate: 0.00415641
	LOSS [training: 0.2531170528501188 | validation: 0.21220650272378835]
	TIME [epoch: 11.1 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2485721212424845		[learning rate: 0.0041417]
	Learning Rate: 0.00414171
	LOSS [training: 0.2485721212424845 | validation: 0.21612578926539266]
	TIME [epoch: 11.1 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2507633908119277		[learning rate: 0.0041271]
	Learning Rate: 0.00412706
	LOSS [training: 0.2507633908119277 | validation: 0.22499595032134043]
	TIME [epoch: 11.1 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2557312424688915		[learning rate: 0.0041125]
	Learning Rate: 0.00411247
	LOSS [training: 0.2557312424688915 | validation: 0.21072732764041618]
	TIME [epoch: 11.1 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25235225121407445		[learning rate: 0.0040979]
	Learning Rate: 0.00409793
	LOSS [training: 0.25235225121407445 | validation: 0.21712064923863097]
	TIME [epoch: 11.1 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26291361406691266		[learning rate: 0.0040834]
	Learning Rate: 0.00408344
	LOSS [training: 0.26291361406691266 | validation: 0.21473275639797534]
	TIME [epoch: 11.1 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25699496790394843		[learning rate: 0.004069]
	Learning Rate: 0.004069
	LOSS [training: 0.25699496790394843 | validation: 0.21118002442084585]
	TIME [epoch: 11.1 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25113507680758973		[learning rate: 0.0040546]
	Learning Rate: 0.00405461
	LOSS [training: 0.25113507680758973 | validation: 0.21161437767148422]
	TIME [epoch: 11.1 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2568795464532527		[learning rate: 0.0040403]
	Learning Rate: 0.00404027
	LOSS [training: 0.2568795464532527 | validation: 0.21689702988309714]
	TIME [epoch: 11.1 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2607548898067971		[learning rate: 0.004026]
	Learning Rate: 0.00402598
	LOSS [training: 0.2607548898067971 | validation: 0.21024326959940215]
	TIME [epoch: 11.1 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.248282873754298		[learning rate: 0.0040117]
	Learning Rate: 0.00401175
	LOSS [training: 0.248282873754298 | validation: 0.20922977065928836]
	TIME [epoch: 11.1 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26212809499081496		[learning rate: 0.0039976]
	Learning Rate: 0.00399756
	LOSS [training: 0.26212809499081496 | validation: 0.21205419605785464]
	TIME [epoch: 11.1 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2531033631488368		[learning rate: 0.0039834]
	Learning Rate: 0.00398342
	LOSS [training: 0.2531033631488368 | validation: 0.21688589200567762]
	TIME [epoch: 11.1 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24429442130503368		[learning rate: 0.0039693]
	Learning Rate: 0.00396934
	LOSS [training: 0.24429442130503368 | validation: 0.21129446290937387]
	TIME [epoch: 11.1 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26026165751188085		[learning rate: 0.0039553]
	Learning Rate: 0.0039553
	LOSS [training: 0.26026165751188085 | validation: 0.2129902559059662]
	TIME [epoch: 11.1 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2647924599543508		[learning rate: 0.0039413]
	Learning Rate: 0.00394131
	LOSS [training: 0.2647924599543508 | validation: 0.208161530649974]
	TIME [epoch: 11.1 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2528289473390343		[learning rate: 0.0039274]
	Learning Rate: 0.00392738
	LOSS [training: 0.2528289473390343 | validation: 0.20457138704740344]
	TIME [epoch: 11.1 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14_20240716_142138/states/model_facs_v3_dec1b_2dpca_v14_314.pth
	Model improved!!!
EPOCH 315/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25264786922736443		[learning rate: 0.0039135]
	Learning Rate: 0.00391349
	LOSS [training: 0.25264786922736443 | validation: 0.22398878906290035]
	TIME [epoch: 11.1 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2592126747725067		[learning rate: 0.0038997]
	Learning Rate: 0.00389965
	LOSS [training: 0.2592126747725067 | validation: 0.21669231241959497]
	TIME [epoch: 11.1 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25251373380676373		[learning rate: 0.0038859]
	Learning Rate: 0.00388586
	LOSS [training: 0.25251373380676373 | validation: 0.20712475078876552]
	TIME [epoch: 11.1 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25470449800240236		[learning rate: 0.0038721]
	Learning Rate: 0.00387212
	LOSS [training: 0.25470449800240236 | validation: 0.21612268793136233]
	TIME [epoch: 11.1 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25529618400832765		[learning rate: 0.0038584]
	Learning Rate: 0.00385843
	LOSS [training: 0.25529618400832765 | validation: 0.20725426253482096]
	TIME [epoch: 11 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25352681296828117		[learning rate: 0.0038448]
	Learning Rate: 0.00384478
	LOSS [training: 0.25352681296828117 | validation: 0.22398167479602024]
	TIME [epoch: 11 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25779156059445213		[learning rate: 0.0038312]
	Learning Rate: 0.00383119
	LOSS [training: 0.25779156059445213 | validation: 0.2055278964796599]
	TIME [epoch: 11.1 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24897998977650582		[learning rate: 0.0038176]
	Learning Rate: 0.00381764
	LOSS [training: 0.24897998977650582 | validation: 0.21127044950755086]
	TIME [epoch: 11 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2552198532223468		[learning rate: 0.0038041]
	Learning Rate: 0.00380414
	LOSS [training: 0.2552198532223468 | validation: 0.21830913419603232]
	TIME [epoch: 11.1 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25745702588207625		[learning rate: 0.0037907]
	Learning Rate: 0.00379069
	LOSS [training: 0.25745702588207625 | validation: 0.2122107903737951]
	TIME [epoch: 11 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25778462808212893		[learning rate: 0.0037773]
	Learning Rate: 0.00377728
	LOSS [training: 0.25778462808212893 | validation: 0.2144940057231183]
	TIME [epoch: 11.1 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25028677592719656		[learning rate: 0.0037639]
	Learning Rate: 0.00376393
	LOSS [training: 0.25028677592719656 | validation: 0.22314835784319348]
	TIME [epoch: 11 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2572650323411258		[learning rate: 0.0037506]
	Learning Rate: 0.00375062
	LOSS [training: 0.2572650323411258 | validation: 0.20893670172974876]
	TIME [epoch: 11 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24513885443424513		[learning rate: 0.0037374]
	Learning Rate: 0.00373735
	LOSS [training: 0.24513885443424513 | validation: 0.20911971982864846]
	TIME [epoch: 11.1 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2494886500379027		[learning rate: 0.0037241]
	Learning Rate: 0.00372414
	LOSS [training: 0.2494886500379027 | validation: 0.21470500512087948]
	TIME [epoch: 11.1 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2537222756504499		[learning rate: 0.003711]
	Learning Rate: 0.00371097
	LOSS [training: 0.2537222756504499 | validation: 0.20565820610052463]
	TIME [epoch: 11 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2561036723199067		[learning rate: 0.0036978]
	Learning Rate: 0.00369785
	LOSS [training: 0.2561036723199067 | validation: 0.21674902895522905]
	TIME [epoch: 11.1 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2454563182239703		[learning rate: 0.0036848]
	Learning Rate: 0.00368477
	LOSS [training: 0.2454563182239703 | validation: 0.21729920968106703]
	TIME [epoch: 11.1 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25873904367792105		[learning rate: 0.0036717]
	Learning Rate: 0.00367174
	LOSS [training: 0.25873904367792105 | validation: 0.2125156543591716]
	TIME [epoch: 11 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2606479095673279		[learning rate: 0.0036588]
	Learning Rate: 0.00365875
	LOSS [training: 0.2606479095673279 | validation: 0.2141877876613504]
	TIME [epoch: 11.1 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25798774139297825		[learning rate: 0.0036458]
	Learning Rate: 0.00364582
	LOSS [training: 0.25798774139297825 | validation: 0.2145436412977118]
	TIME [epoch: 11 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2492088637216937		[learning rate: 0.0036329]
	Learning Rate: 0.00363292
	LOSS [training: 0.2492088637216937 | validation: 0.21342479686487442]
	TIME [epoch: 11.1 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2494086886889387		[learning rate: 0.0036201]
	Learning Rate: 0.00362008
	LOSS [training: 0.2494086886889387 | validation: 0.21483105070269085]
	TIME [epoch: 11 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25182823385976005		[learning rate: 0.0036073]
	Learning Rate: 0.00360728
	LOSS [training: 0.25182823385976005 | validation: 0.21574207198078188]
	TIME [epoch: 11.1 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24857029836190467		[learning rate: 0.0035945]
	Learning Rate: 0.00359452
	LOSS [training: 0.24857029836190467 | validation: 0.22265072922642384]
	TIME [epoch: 11.1 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25175520108600474		[learning rate: 0.0035818]
	Learning Rate: 0.00358181
	LOSS [training: 0.25175520108600474 | validation: 0.2151635500256849]
	TIME [epoch: 11.1 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24582024625882629		[learning rate: 0.0035691]
	Learning Rate: 0.00356914
	LOSS [training: 0.24582024625882629 | validation: 0.2093212615491992]
	TIME [epoch: 11 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24558196469671614		[learning rate: 0.0035565]
	Learning Rate: 0.00355652
	LOSS [training: 0.24558196469671614 | validation: 0.2174636065638495]
	TIME [epoch: 11.1 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2555319884713393		[learning rate: 0.0035439]
	Learning Rate: 0.00354395
	LOSS [training: 0.2555319884713393 | validation: 0.21812322563897482]
	TIME [epoch: 11.1 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2539926213301651		[learning rate: 0.0035314]
	Learning Rate: 0.00353141
	LOSS [training: 0.2539926213301651 | validation: 0.215024504986541]
	TIME [epoch: 11.1 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2580074740630652		[learning rate: 0.0035189]
	Learning Rate: 0.00351893
	LOSS [training: 0.2580074740630652 | validation: 0.2092458343821529]
	TIME [epoch: 11.1 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2514353101704536		[learning rate: 0.0035065]
	Learning Rate: 0.00350648
	LOSS [training: 0.2514353101704536 | validation: 0.21416466454888144]
	TIME [epoch: 11.1 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2450929789389064		[learning rate: 0.0034941]
	Learning Rate: 0.00349408
	LOSS [training: 0.2450929789389064 | validation: 0.21094270244725574]
	TIME [epoch: 11.1 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25397858130151457		[learning rate: 0.0034817]
	Learning Rate: 0.00348173
	LOSS [training: 0.25397858130151457 | validation: 0.2080698971692659]
	TIME [epoch: 11.1 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2508957845902715		[learning rate: 0.0034694]
	Learning Rate: 0.00346942
	LOSS [training: 0.2508957845902715 | validation: 0.21570777090606094]
	TIME [epoch: 11 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2591810945222794		[learning rate: 0.0034571]
	Learning Rate: 0.00345715
	LOSS [training: 0.2591810945222794 | validation: 0.20694166365986771]
	TIME [epoch: 11.1 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25395428218804666		[learning rate: 0.0034449]
	Learning Rate: 0.00344492
	LOSS [training: 0.25395428218804666 | validation: 0.21185257671153207]
	TIME [epoch: 11 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2568725667019171		[learning rate: 0.0034327]
	Learning Rate: 0.00343274
	LOSS [training: 0.2568725667019171 | validation: 0.2212784250393293]
	TIME [epoch: 11 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24624488223259247		[learning rate: 0.0034206]
	Learning Rate: 0.0034206
	LOSS [training: 0.24624488223259247 | validation: 0.21569334672525325]
	TIME [epoch: 11 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2542010558997125		[learning rate: 0.0034085]
	Learning Rate: 0.00340851
	LOSS [training: 0.2542010558997125 | validation: 0.20737847537756116]
	TIME [epoch: 11.1 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2594757184978058		[learning rate: 0.0033965]
	Learning Rate: 0.00339645
	LOSS [training: 0.2594757184978058 | validation: 0.21349798436855255]
	TIME [epoch: 11 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24974273010325457		[learning rate: 0.0033844]
	Learning Rate: 0.00338444
	LOSS [training: 0.24974273010325457 | validation: 0.2088637274558899]
	TIME [epoch: 11 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25848107451926144		[learning rate: 0.0033725]
	Learning Rate: 0.00337247
	LOSS [training: 0.25848107451926144 | validation: 0.21145892288601426]
	TIME [epoch: 11.1 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25234525483559506		[learning rate: 0.0033605]
	Learning Rate: 0.00336055
	LOSS [training: 0.25234525483559506 | validation: 0.22055120490656047]
	TIME [epoch: 11.1 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2550080440231281		[learning rate: 0.0033487]
	Learning Rate: 0.00334867
	LOSS [training: 0.2550080440231281 | validation: 0.22401752308417514]
	TIME [epoch: 11.1 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24992757948349234		[learning rate: 0.0033368]
	Learning Rate: 0.00333682
	LOSS [training: 0.24992757948349234 | validation: 0.21120784412154112]
	TIME [epoch: 11.1 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25227052867405275		[learning rate: 0.003325]
	Learning Rate: 0.00332502
	LOSS [training: 0.25227052867405275 | validation: 0.20981753121976446]
	TIME [epoch: 11.1 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24541407660332418		[learning rate: 0.0033133]
	Learning Rate: 0.00331327
	LOSS [training: 0.24541407660332418 | validation: 0.213202040682991]
	TIME [epoch: 11.1 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2471268113722698		[learning rate: 0.0033016]
	Learning Rate: 0.00330155
	LOSS [training: 0.2471268113722698 | validation: 0.2189325417346839]
	TIME [epoch: 11.1 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24795785599804362		[learning rate: 0.0032899]
	Learning Rate: 0.00328988
	LOSS [training: 0.24795785599804362 | validation: 0.21725216715035808]
	TIME [epoch: 11.1 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2569326044564249		[learning rate: 0.0032782]
	Learning Rate: 0.00327824
	LOSS [training: 0.2569326044564249 | validation: 0.2170102219705868]
	TIME [epoch: 11.1 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25398717332565945		[learning rate: 0.0032666]
	Learning Rate: 0.00326665
	LOSS [training: 0.25398717332565945 | validation: 0.21226950519488072]
	TIME [epoch: 11.1 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2489212244392166		[learning rate: 0.0032551]
	Learning Rate: 0.0032551
	LOSS [training: 0.2489212244392166 | validation: 0.20903429728406975]
	TIME [epoch: 11.1 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25253543699081366		[learning rate: 0.0032436]
	Learning Rate: 0.00324359
	LOSS [training: 0.25253543699081366 | validation: 0.21578317785248782]
	TIME [epoch: 11.1 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.253723518451854		[learning rate: 0.0032321]
	Learning Rate: 0.00323212
	LOSS [training: 0.253723518451854 | validation: 0.21227412358336237]
	TIME [epoch: 11.1 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2518558442060442		[learning rate: 0.0032207]
	Learning Rate: 0.00322069
	LOSS [training: 0.2518558442060442 | validation: 0.21768631661908405]
	TIME [epoch: 11.1 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2602487326458481		[learning rate: 0.0032093]
	Learning Rate: 0.0032093
	LOSS [training: 0.2602487326458481 | validation: 0.20155595219935693]
	TIME [epoch: 11.1 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14_20240716_142138/states/model_facs_v3_dec1b_2dpca_v14_371.pth
	Model improved!!!
EPOCH 372/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24818446927135981		[learning rate: 0.003198]
	Learning Rate: 0.00319795
	LOSS [training: 0.24818446927135981 | validation: 0.20966568823434617]
	TIME [epoch: 11.1 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2525086404902916		[learning rate: 0.0031866]
	Learning Rate: 0.00318664
	LOSS [training: 0.2525086404902916 | validation: 0.215189282024477]
	TIME [epoch: 11.1 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2539398080585393		[learning rate: 0.0031754]
	Learning Rate: 0.00317537
	LOSS [training: 0.2539398080585393 | validation: 0.20905669104224295]
	TIME [epoch: 11.1 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2571161819294144		[learning rate: 0.0031641]
	Learning Rate: 0.00316415
	LOSS [training: 0.2571161819294144 | validation: 0.21480855506595037]
	TIME [epoch: 11.1 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2559068402658365		[learning rate: 0.003153]
	Learning Rate: 0.00315296
	LOSS [training: 0.2559068402658365 | validation: 0.21963307385764635]
	TIME [epoch: 11.1 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24810373918448056		[learning rate: 0.0031418]
	Learning Rate: 0.00314181
	LOSS [training: 0.24810373918448056 | validation: 0.21519735856588867]
	TIME [epoch: 11 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24474192082198012		[learning rate: 0.0031307]
	Learning Rate: 0.0031307
	LOSS [training: 0.24474192082198012 | validation: 0.2094492703508848]
	TIME [epoch: 11.1 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2655891478335958		[learning rate: 0.0031196]
	Learning Rate: 0.00311963
	LOSS [training: 0.2655891478335958 | validation: 0.21104542508344676]
	TIME [epoch: 11.1 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2510077324280389		[learning rate: 0.0031086]
	Learning Rate: 0.00310859
	LOSS [training: 0.2510077324280389 | validation: 0.21076335031471358]
	TIME [epoch: 11.1 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2498112741731396		[learning rate: 0.0030976]
	Learning Rate: 0.0030976
	LOSS [training: 0.2498112741731396 | validation: 0.20974127977349627]
	TIME [epoch: 11 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26245530678519485		[learning rate: 0.0030866]
	Learning Rate: 0.00308665
	LOSS [training: 0.26245530678519485 | validation: 0.22056167939053797]
	TIME [epoch: 11.1 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25694942818403715		[learning rate: 0.0030757]
	Learning Rate: 0.00307573
	LOSS [training: 0.25694942818403715 | validation: 0.20948905743503973]
	TIME [epoch: 11.1 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24549297078533902		[learning rate: 0.0030649]
	Learning Rate: 0.00306486
	LOSS [training: 0.24549297078533902 | validation: 0.2132162656878641]
	TIME [epoch: 11 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25119143185122844		[learning rate: 0.003054]
	Learning Rate: 0.00305402
	LOSS [training: 0.25119143185122844 | validation: 0.21913979491331773]
	TIME [epoch: 11.1 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24742022786593187		[learning rate: 0.0030432]
	Learning Rate: 0.00304322
	LOSS [training: 0.24742022786593187 | validation: 0.21549130419540505]
	TIME [epoch: 11 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2493649700507221		[learning rate: 0.0030325]
	Learning Rate: 0.00303246
	LOSS [training: 0.2493649700507221 | validation: 0.21447999387838088]
	TIME [epoch: 11.1 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24326046977490146		[learning rate: 0.0030217]
	Learning Rate: 0.00302174
	LOSS [training: 0.24326046977490146 | validation: 0.21395546700710208]
	TIME [epoch: 11 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2456753690940046		[learning rate: 0.003011]
	Learning Rate: 0.00301105
	LOSS [training: 0.2456753690940046 | validation: 0.20721534953236415]
	TIME [epoch: 11 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2507011278447094		[learning rate: 0.0030004]
	Learning Rate: 0.0030004
	LOSS [training: 0.2507011278447094 | validation: 0.2146199776666622]
	TIME [epoch: 11 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24655665309460797		[learning rate: 0.0029898]
	Learning Rate: 0.00298979
	LOSS [training: 0.24655665309460797 | validation: 0.2201419187925945]
	TIME [epoch: 11.1 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25571892527009626		[learning rate: 0.0029792]
	Learning Rate: 0.00297922
	LOSS [training: 0.25571892527009626 | validation: 0.2077011509848158]
	TIME [epoch: 11.1 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.26108273393453674		[learning rate: 0.0029687]
	Learning Rate: 0.00296869
	LOSS [training: 0.26108273393453674 | validation: 0.22082486272204022]
	TIME [epoch: 11 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25371512834862786		[learning rate: 0.0029582]
	Learning Rate: 0.00295819
	LOSS [training: 0.25371512834862786 | validation: 0.2104439299803443]
	TIME [epoch: 11.1 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24920754410631704		[learning rate: 0.0029477]
	Learning Rate: 0.00294773
	LOSS [training: 0.24920754410631704 | validation: 0.21362058516132515]
	TIME [epoch: 11 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24986210735832634		[learning rate: 0.0029373]
	Learning Rate: 0.0029373
	LOSS [training: 0.24986210735832634 | validation: 0.21157250209381612]
	TIME [epoch: 11 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2552995070297874		[learning rate: 0.0029269]
	Learning Rate: 0.00292692
	LOSS [training: 0.2552995070297874 | validation: 0.2100560115044699]
	TIME [epoch: 11 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2546458417455804		[learning rate: 0.0029166]
	Learning Rate: 0.00291657
	LOSS [training: 0.2546458417455804 | validation: 0.20832178622784497]
	TIME [epoch: 11.1 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2460963638343978		[learning rate: 0.0029063]
	Learning Rate: 0.00290625
	LOSS [training: 0.2460963638343978 | validation: 0.21117658624246075]
	TIME [epoch: 11.1 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2643941932469252		[learning rate: 0.002896]
	Learning Rate: 0.00289598
	LOSS [training: 0.2643941932469252 | validation: 0.21020582509677724]
	TIME [epoch: 11 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24686748284150206		[learning rate: 0.0028857]
	Learning Rate: 0.00288573
	LOSS [training: 0.24686748284150206 | validation: 0.21781813357703378]
	TIME [epoch: 11.1 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24945722473652673		[learning rate: 0.0028755]
	Learning Rate: 0.00287553
	LOSS [training: 0.24945722473652673 | validation: 0.21655441760965438]
	TIME [epoch: 11.1 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2493371947551195		[learning rate: 0.0028654]
	Learning Rate: 0.00286536
	LOSS [training: 0.2493371947551195 | validation: 0.22673026620765638]
	TIME [epoch: 11 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2393506187349919		[learning rate: 0.0028552]
	Learning Rate: 0.00285523
	LOSS [training: 0.2393506187349919 | validation: 0.21203780153970034]
	TIME [epoch: 11.1 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24687377782313272		[learning rate: 0.0028451]
	Learning Rate: 0.00284513
	LOSS [training: 0.24687377782313272 | validation: 0.2150631771500758]
	TIME [epoch: 11.1 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2550368051497522		[learning rate: 0.0028351]
	Learning Rate: 0.00283507
	LOSS [training: 0.2550368051497522 | validation: 0.20962136644284235]
	TIME [epoch: 11 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24723674796125816		[learning rate: 0.002825]
	Learning Rate: 0.00282505
	LOSS [training: 0.24723674796125816 | validation: 0.206522957856426]
	TIME [epoch: 11 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24837085577450138		[learning rate: 0.0028151]
	Learning Rate: 0.00281506
	LOSS [training: 0.24837085577450138 | validation: 0.20655836407943018]
	TIME [epoch: 11.1 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2518484475609532		[learning rate: 0.0028051]
	Learning Rate: 0.0028051
	LOSS [training: 0.2518484475609532 | validation: 0.20579691156022445]
	TIME [epoch: 11.1 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24648382076543554		[learning rate: 0.0027952]
	Learning Rate: 0.00279518
	LOSS [training: 0.24648382076543554 | validation: 0.21444173820427617]
	TIME [epoch: 11 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24935867986044324		[learning rate: 0.0027853]
	Learning Rate: 0.0027853
	LOSS [training: 0.24935867986044324 | validation: 0.2071746735462603]
	TIME [epoch: 11 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25227530024829276		[learning rate: 0.0027754]
	Learning Rate: 0.00277545
	LOSS [training: 0.25227530024829276 | validation: 0.21190267553328193]
	TIME [epoch: 11.1 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2531534809381108		[learning rate: 0.0027656]
	Learning Rate: 0.00276564
	LOSS [training: 0.2531534809381108 | validation: 0.21337337908130935]
	TIME [epoch: 11 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2514513138174464		[learning rate: 0.0027559]
	Learning Rate: 0.00275586
	LOSS [training: 0.2514513138174464 | validation: 0.22411967066751806]
	TIME [epoch: 11 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2532098107816613		[learning rate: 0.0027461]
	Learning Rate: 0.00274611
	LOSS [training: 0.2532098107816613 | validation: 0.21841877369514565]
	TIME [epoch: 11.1 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.246283020310792		[learning rate: 0.0027364]
	Learning Rate: 0.0027364
	LOSS [training: 0.246283020310792 | validation: 0.21794720445446228]
	TIME [epoch: 11.1 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24453095782527368		[learning rate: 0.0027267]
	Learning Rate: 0.00272672
	LOSS [training: 0.24453095782527368 | validation: 0.21382266499791128]
	TIME [epoch: 11 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24504026105594578		[learning rate: 0.0027171]
	Learning Rate: 0.00271708
	LOSS [training: 0.24504026105594578 | validation: 0.21739068339413187]
	TIME [epoch: 11 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2439660710958557		[learning rate: 0.0027075]
	Learning Rate: 0.00270747
	LOSS [training: 0.2439660710958557 | validation: 0.21249680241256552]
	TIME [epoch: 11 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25600077497447843		[learning rate: 0.0026979]
	Learning Rate: 0.0026979
	LOSS [training: 0.25600077497447843 | validation: 0.2152960861318307]
	TIME [epoch: 11 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24109449332652697		[learning rate: 0.0026884]
	Learning Rate: 0.00268836
	LOSS [training: 0.24109449332652697 | validation: 0.21498251031912238]
	TIME [epoch: 11 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2485462115600684		[learning rate: 0.0026789]
	Learning Rate: 0.00267885
	LOSS [training: 0.2485462115600684 | validation: 0.21163238255784136]
	TIME [epoch: 11 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2547265921073169		[learning rate: 0.0026694]
	Learning Rate: 0.00266938
	LOSS [training: 0.2547265921073169 | validation: 0.20858586633045512]
	TIME [epoch: 11.1 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24896452525278187		[learning rate: 0.0026599]
	Learning Rate: 0.00265994
	LOSS [training: 0.24896452525278187 | validation: 0.21627150799312678]
	TIME [epoch: 11 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2504417812372459		[learning rate: 0.0026505]
	Learning Rate: 0.00265053
	LOSS [training: 0.2504417812372459 | validation: 0.21191466159418657]
	TIME [epoch: 11 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24662413657030804		[learning rate: 0.0026412]
	Learning Rate: 0.00264116
	LOSS [training: 0.24662413657030804 | validation: 0.20111994899958674]
	TIME [epoch: 11 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14_20240716_142138/states/model_facs_v3_dec1b_2dpca_v14_426.pth
	Model improved!!!
EPOCH 427/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24944666816691666		[learning rate: 0.0026318]
	Learning Rate: 0.00263182
	LOSS [training: 0.24944666816691666 | validation: 0.2142959075247383]
	TIME [epoch: 11.1 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2517232661894475		[learning rate: 0.0026225]
	Learning Rate: 0.00262251
	LOSS [training: 0.2517232661894475 | validation: 0.2188275170604042]
	TIME [epoch: 11 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24221067405426386		[learning rate: 0.0026132]
	Learning Rate: 0.00261324
	LOSS [training: 0.24221067405426386 | validation: 0.2066817222513527]
	TIME [epoch: 11.1 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24763671470057044		[learning rate: 0.002604]
	Learning Rate: 0.002604
	LOSS [training: 0.24763671470057044 | validation: 0.21808364541432756]
	TIME [epoch: 11 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25325804095448456		[learning rate: 0.0025948]
	Learning Rate: 0.00259479
	LOSS [training: 0.25325804095448456 | validation: 0.2189675746905903]
	TIME [epoch: 11.1 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24389624079637526		[learning rate: 0.0025856]
	Learning Rate: 0.00258562
	LOSS [training: 0.24389624079637526 | validation: 0.21195375705357894]
	TIME [epoch: 11 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2535580278426605		[learning rate: 0.0025765]
	Learning Rate: 0.00257647
	LOSS [training: 0.2535580278426605 | validation: 0.20864056349374263]
	TIME [epoch: 11.1 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2455913497628335		[learning rate: 0.0025674]
	Learning Rate: 0.00256736
	LOSS [training: 0.2455913497628335 | validation: 0.20611991602333496]
	TIME [epoch: 11 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24421210511924918		[learning rate: 0.0025583]
	Learning Rate: 0.00255828
	LOSS [training: 0.24421210511924918 | validation: 0.21072768883398102]
	TIME [epoch: 11.1 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2501310758185266		[learning rate: 0.0025492]
	Learning Rate: 0.00254924
	LOSS [training: 0.2501310758185266 | validation: 0.2128650811134774]
	TIME [epoch: 11 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2581966736786973		[learning rate: 0.0025402]
	Learning Rate: 0.00254022
	LOSS [training: 0.2581966736786973 | validation: 0.20530749939867676]
	TIME [epoch: 11 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24614498204912963		[learning rate: 0.0025312]
	Learning Rate: 0.00253124
	LOSS [training: 0.24614498204912963 | validation: 0.2211482463315549]
	TIME [epoch: 11.1 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24953775790446062		[learning rate: 0.0025223]
	Learning Rate: 0.00252229
	LOSS [training: 0.24953775790446062 | validation: 0.21183303565980008]
	TIME [epoch: 11.1 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24413521294424037		[learning rate: 0.0025134]
	Learning Rate: 0.00251337
	LOSS [training: 0.24413521294424037 | validation: 0.2191138457323921]
	TIME [epoch: 11 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2542395956953238		[learning rate: 0.0025045]
	Learning Rate: 0.00250448
	LOSS [training: 0.2542395956953238 | validation: 0.21523894532578866]
	TIME [epoch: 11 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2524487631901136		[learning rate: 0.0024956]
	Learning Rate: 0.00249563
	LOSS [training: 0.2524487631901136 | validation: 0.21217730443928015]
	TIME [epoch: 11.1 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2545739258295625		[learning rate: 0.0024868]
	Learning Rate: 0.0024868
	LOSS [training: 0.2545739258295625 | validation: 0.2057810294091614]
	TIME [epoch: 11 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24858701672005654		[learning rate: 0.002478]
	Learning Rate: 0.00247801
	LOSS [training: 0.24858701672005654 | validation: 0.21222571602898072]
	TIME [epoch: 11 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25763296616644377		[learning rate: 0.0024692]
	Learning Rate: 0.00246924
	LOSS [training: 0.25763296616644377 | validation: 0.21509118041662156]
	TIME [epoch: 11.1 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2547324677876632		[learning rate: 0.0024605]
	Learning Rate: 0.00246051
	LOSS [training: 0.2547324677876632 | validation: 0.20488703013291604]
	TIME [epoch: 11.1 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25277827196596786		[learning rate: 0.0024518]
	Learning Rate: 0.00245181
	LOSS [training: 0.25277827196596786 | validation: 0.21093150066249486]
	TIME [epoch: 11.1 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24583805714467075		[learning rate: 0.0024431]
	Learning Rate: 0.00244314
	LOSS [training: 0.24583805714467075 | validation: 0.21410258479867875]
	TIME [epoch: 11.1 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24617196947005346		[learning rate: 0.0024345]
	Learning Rate: 0.0024345
	LOSS [training: 0.24617196947005346 | validation: 0.2080267628016604]
	TIME [epoch: 11.1 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2519126833146		[learning rate: 0.0024259]
	Learning Rate: 0.00242589
	LOSS [training: 0.2519126833146 | validation: 0.2037385565538968]
	TIME [epoch: 11.1 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24789972984648842		[learning rate: 0.0024173]
	Learning Rate: 0.00241732
	LOSS [training: 0.24789972984648842 | validation: 0.20771501588833335]
	TIME [epoch: 11 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24758121840148195		[learning rate: 0.0024088]
	Learning Rate: 0.00240877
	LOSS [training: 0.24758121840148195 | validation: 0.2162095387495479]
	TIME [epoch: 11 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24396190710878007		[learning rate: 0.0024002]
	Learning Rate: 0.00240025
	LOSS [training: 0.24396190710878007 | validation: 0.2056941683896328]
	TIME [epoch: 11.1 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25184216593199454		[learning rate: 0.0023918]
	Learning Rate: 0.00239176
	LOSS [training: 0.25184216593199454 | validation: 0.2051578028806836]
	TIME [epoch: 11.1 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2456786366730892		[learning rate: 0.0023833]
	Learning Rate: 0.0023833
	LOSS [training: 0.2456786366730892 | validation: 0.21085541607972275]
	TIME [epoch: 11 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25774520282536545		[learning rate: 0.0023749]
	Learning Rate: 0.00237488
	LOSS [training: 0.25774520282536545 | validation: 0.20980480600865384]
	TIME [epoch: 11 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2472038255139284		[learning rate: 0.0023665]
	Learning Rate: 0.00236648
	LOSS [training: 0.2472038255139284 | validation: 0.2136636144605249]
	TIME [epoch: 11.1 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24471357328536025		[learning rate: 0.0023581]
	Learning Rate: 0.00235811
	LOSS [training: 0.24471357328536025 | validation: 0.21819725211571955]
	TIME [epoch: 11 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2519521551692576		[learning rate: 0.0023498]
	Learning Rate: 0.00234977
	LOSS [training: 0.2519521551692576 | validation: 0.21297484472917388]
	TIME [epoch: 11 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24906181058565605		[learning rate: 0.0023415]
	Learning Rate: 0.00234146
	LOSS [training: 0.24906181058565605 | validation: 0.20205946662287996]
	TIME [epoch: 11.1 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2505429615112456		[learning rate: 0.0023332]
	Learning Rate: 0.00233318
	LOSS [training: 0.2505429615112456 | validation: 0.20558848550442005]
	TIME [epoch: 11.1 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24977882842882082		[learning rate: 0.0023249]
	Learning Rate: 0.00232493
	LOSS [training: 0.24977882842882082 | validation: 0.20050929138619972]
	TIME [epoch: 11 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14_20240716_142138/states/model_facs_v3_dec1b_2dpca_v14_462.pth
	Model improved!!!
EPOCH 463/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23712286735906696		[learning rate: 0.0023167]
	Learning Rate: 0.00231671
	LOSS [training: 0.23712286735906696 | validation: 0.21828403594138707]
	TIME [epoch: 11.1 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.257578749197272		[learning rate: 0.0023085]
	Learning Rate: 0.00230852
	LOSS [training: 0.257578749197272 | validation: 0.22131336342469704]
	TIME [epoch: 11.1 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2625796427924608		[learning rate: 0.0023004]
	Learning Rate: 0.00230035
	LOSS [training: 0.2625796427924608 | validation: 0.2106849237423014]
	TIME [epoch: 11.1 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.245445187664193		[learning rate: 0.0022922]
	Learning Rate: 0.00229222
	LOSS [training: 0.245445187664193 | validation: 0.20905151743484404]
	TIME [epoch: 11.1 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2515074228893003		[learning rate: 0.0022841]
	Learning Rate: 0.00228411
	LOSS [training: 0.2515074228893003 | validation: 0.2082292227548585]
	TIME [epoch: 11.1 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24550802033338467		[learning rate: 0.002276]
	Learning Rate: 0.00227604
	LOSS [training: 0.24550802033338467 | validation: 0.20609770458213847]
	TIME [epoch: 11.1 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24158014637239275		[learning rate: 0.002268]
	Learning Rate: 0.00226799
	LOSS [training: 0.24158014637239275 | validation: 0.20768004547745195]
	TIME [epoch: 11.1 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24084024747103375		[learning rate: 0.00226]
	Learning Rate: 0.00225997
	LOSS [training: 0.24084024747103375 | validation: 0.21331885544961038]
	TIME [epoch: 11.1 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2497981175818701		[learning rate: 0.002252]
	Learning Rate: 0.00225198
	LOSS [training: 0.2497981175818701 | validation: 0.20582938322772426]
	TIME [epoch: 11.1 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24417437125808839		[learning rate: 0.002244]
	Learning Rate: 0.00224401
	LOSS [training: 0.24417437125808839 | validation: 0.21220934983212159]
	TIME [epoch: 11.1 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25194344421851367		[learning rate: 0.0022361]
	Learning Rate: 0.00223608
	LOSS [training: 0.25194344421851367 | validation: 0.20750108252121852]
	TIME [epoch: 11.1 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25214097021268866		[learning rate: 0.0022282]
	Learning Rate: 0.00222817
	LOSS [training: 0.25214097021268866 | validation: 0.2007014933961718]
	TIME [epoch: 11.1 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24673315015926325		[learning rate: 0.0022203]
	Learning Rate: 0.00222029
	LOSS [training: 0.24673315015926325 | validation: 0.20921928880484258]
	TIME [epoch: 11.1 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2569966928737963		[learning rate: 0.0022124]
	Learning Rate: 0.00221244
	LOSS [training: 0.2569966928737963 | validation: 0.21005006703232007]
	TIME [epoch: 11.1 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2500452221314608		[learning rate: 0.0022046]
	Learning Rate: 0.00220462
	LOSS [training: 0.2500452221314608 | validation: 0.20667090775822547]
	TIME [epoch: 11.1 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24437113557998455		[learning rate: 0.0021968]
	Learning Rate: 0.00219682
	LOSS [training: 0.24437113557998455 | validation: 0.21115091234099087]
	TIME [epoch: 11.1 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24935329207345613		[learning rate: 0.0021891]
	Learning Rate: 0.00218905
	LOSS [training: 0.24935329207345613 | validation: 0.2103542371000254]
	TIME [epoch: 11.1 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25226590286903544		[learning rate: 0.0021813]
	Learning Rate: 0.00218131
	LOSS [training: 0.25226590286903544 | validation: 0.20905947250658447]
	TIME [epoch: 11.1 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.248031968442038		[learning rate: 0.0021736]
	Learning Rate: 0.0021736
	LOSS [training: 0.248031968442038 | validation: 0.2005813281676377]
	TIME [epoch: 11.1 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24636639451791054		[learning rate: 0.0021659]
	Learning Rate: 0.00216591
	LOSS [training: 0.24636639451791054 | validation: 0.20657428492732238]
	TIME [epoch: 11.1 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24725628631640442		[learning rate: 0.0021583]
	Learning Rate: 0.00215825
	LOSS [training: 0.24725628631640442 | validation: 0.20704006834151478]
	TIME [epoch: 11.1 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24182027417716276		[learning rate: 0.0021506]
	Learning Rate: 0.00215062
	LOSS [training: 0.24182027417716276 | validation: 0.20796519510825076]
	TIME [epoch: 11.1 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24799810247713214		[learning rate: 0.002143]
	Learning Rate: 0.00214302
	LOSS [training: 0.24799810247713214 | validation: 0.19812468913352918]
	TIME [epoch: 11 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14_20240716_142138/states/model_facs_v3_dec1b_2dpca_v14_485.pth
	Model improved!!!
EPOCH 486/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.253596571208863		[learning rate: 0.0021354]
	Learning Rate: 0.00213544
	LOSS [training: 0.253596571208863 | validation: 0.21534475182025686]
	TIME [epoch: 11.1 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2532809266770834		[learning rate: 0.0021279]
	Learning Rate: 0.00212789
	LOSS [training: 0.2532809266770834 | validation: 0.20922530047096516]
	TIME [epoch: 11.1 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24754651135110708		[learning rate: 0.0021204]
	Learning Rate: 0.00212036
	LOSS [training: 0.24754651135110708 | validation: 0.20779305145271804]
	TIME [epoch: 11.1 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2504125113803309		[learning rate: 0.0021129]
	Learning Rate: 0.00211287
	LOSS [training: 0.2504125113803309 | validation: 0.210798451866343]
	TIME [epoch: 11.1 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2503523603158391		[learning rate: 0.0021054]
	Learning Rate: 0.00210539
	LOSS [training: 0.2503523603158391 | validation: 0.20366788661036422]
	TIME [epoch: 11.1 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24839081814936667		[learning rate: 0.0020979]
	Learning Rate: 0.00209795
	LOSS [training: 0.24839081814936667 | validation: 0.2135571924312906]
	TIME [epoch: 11.1 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24634838208693013		[learning rate: 0.0020905]
	Learning Rate: 0.00209053
	LOSS [training: 0.24634838208693013 | validation: 0.2069477950610779]
	TIME [epoch: 11.1 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2425303860850165		[learning rate: 0.0020831]
	Learning Rate: 0.00208314
	LOSS [training: 0.2425303860850165 | validation: 0.20775575368688806]
	TIME [epoch: 11.1 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2459684439420863		[learning rate: 0.0020758]
	Learning Rate: 0.00207577
	LOSS [training: 0.2459684439420863 | validation: 0.2087729492400773]
	TIME [epoch: 11.1 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25129692042539703		[learning rate: 0.0020684]
	Learning Rate: 0.00206843
	LOSS [training: 0.25129692042539703 | validation: 0.20959903872069705]
	TIME [epoch: 11.1 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2408634535131301		[learning rate: 0.0020611]
	Learning Rate: 0.00206112
	LOSS [training: 0.2408634535131301 | validation: 0.2151867535352086]
	TIME [epoch: 11.1 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24233921783620904		[learning rate: 0.0020538]
	Learning Rate: 0.00205383
	LOSS [training: 0.24233921783620904 | validation: 0.21204488525073564]
	TIME [epoch: 11.1 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24305537456840506		[learning rate: 0.0020466]
	Learning Rate: 0.00204657
	LOSS [training: 0.24305537456840506 | validation: 0.2095218387027334]
	TIME [epoch: 11.1 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2556089982998601		[learning rate: 0.0020393]
	Learning Rate: 0.00203933
	LOSS [training: 0.2556089982998601 | validation: 0.20272078417535516]
	TIME [epoch: 11.1 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24644349233248133		[learning rate: 0.0020321]
	Learning Rate: 0.00203212
	LOSS [training: 0.24644349233248133 | validation: 0.2129966121809415]
	TIME [epoch: 11 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2516528219536475		[learning rate: 0.0020249]
	Learning Rate: 0.00202493
	LOSS [training: 0.2516528219536475 | validation: 0.20535786301908607]
	TIME [epoch: 36.8 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2511145322036173		[learning rate: 0.0020178]
	Learning Rate: 0.00201777
	LOSS [training: 0.2511145322036173 | validation: 0.20672633344003769]
	TIME [epoch: 23.9 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24760767549963747		[learning rate: 0.0020106]
	Learning Rate: 0.00201064
	LOSS [training: 0.24760767549963747 | validation: 0.20300129603031195]
	TIME [epoch: 23.8 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24826599213557796		[learning rate: 0.0020035]
	Learning Rate: 0.00200353
	LOSS [training: 0.24826599213557796 | validation: 0.20317060320620145]
	TIME [epoch: 23.9 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24879587561046898		[learning rate: 0.0019964]
	Learning Rate: 0.00199644
	LOSS [training: 0.24879587561046898 | validation: 0.21161807316277076]
	TIME [epoch: 23.8 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23725473439305297		[learning rate: 0.0019894]
	Learning Rate: 0.00198938
	LOSS [training: 0.23725473439305297 | validation: 0.2135351421395811]
	TIME [epoch: 23.8 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24352160690573652		[learning rate: 0.0019823]
	Learning Rate: 0.00198235
	LOSS [training: 0.24352160690573652 | validation: 0.20178798223942765]
	TIME [epoch: 23.9 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24584572416855285		[learning rate: 0.0019753]
	Learning Rate: 0.00197534
	LOSS [training: 0.24584572416855285 | validation: 0.21165570575113746]
	TIME [epoch: 23.9 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2483325788832291		[learning rate: 0.0019684]
	Learning Rate: 0.00196835
	LOSS [training: 0.2483325788832291 | validation: 0.217055950814601]
	TIME [epoch: 23.9 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2536489630075131		[learning rate: 0.0019614]
	Learning Rate: 0.00196139
	LOSS [training: 0.2536489630075131 | validation: 0.21610428396081655]
	TIME [epoch: 23.9 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25157488315757465		[learning rate: 0.0019545]
	Learning Rate: 0.00195445
	LOSS [training: 0.25157488315757465 | validation: 0.2119062213767659]
	TIME [epoch: 23.9 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24756640759444093		[learning rate: 0.0019475]
	Learning Rate: 0.00194754
	LOSS [training: 0.24756640759444093 | validation: 0.21202107331804582]
	TIME [epoch: 23.8 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2498096075235511		[learning rate: 0.0019407]
	Learning Rate: 0.00194066
	LOSS [training: 0.2498096075235511 | validation: 0.21219379103715652]
	TIME [epoch: 23.8 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24672561028014303		[learning rate: 0.0019338]
	Learning Rate: 0.00193379
	LOSS [training: 0.24672561028014303 | validation: 0.210203321346114]
	TIME [epoch: 23.9 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2547068316441484		[learning rate: 0.001927]
	Learning Rate: 0.00192696
	LOSS [training: 0.2547068316441484 | validation: 0.21339857259677997]
	TIME [epoch: 23.8 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25351735144893883		[learning rate: 0.0019201]
	Learning Rate: 0.00192014
	LOSS [training: 0.25351735144893883 | validation: 0.20754718894259847]
	TIME [epoch: 23.9 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24412876452065793		[learning rate: 0.0019134]
	Learning Rate: 0.00191335
	LOSS [training: 0.24412876452065793 | validation: 0.20908691378845648]
	TIME [epoch: 23.9 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24836229698795806		[learning rate: 0.0019066]
	Learning Rate: 0.00190659
	LOSS [training: 0.24836229698795806 | validation: 0.2106591127098604]
	TIME [epoch: 23.9 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24969481140948735		[learning rate: 0.0018998]
	Learning Rate: 0.00189984
	LOSS [training: 0.24969481140948735 | validation: 0.21412262695361212]
	TIME [epoch: 23.9 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24839697455765752		[learning rate: 0.0018931]
	Learning Rate: 0.00189313
	LOSS [training: 0.24839697455765752 | validation: 0.20883029302384454]
	TIME [epoch: 23.9 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2448477032458736		[learning rate: 0.0018864]
	Learning Rate: 0.00188643
	LOSS [training: 0.2448477032458736 | validation: 0.2135470883302164]
	TIME [epoch: 24 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23958432313444092		[learning rate: 0.0018798]
	Learning Rate: 0.00187976
	LOSS [training: 0.23958432313444092 | validation: 0.20441782815980206]
	TIME [epoch: 23.9 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24069349350543448		[learning rate: 0.0018731]
	Learning Rate: 0.00187311
	LOSS [training: 0.24069349350543448 | validation: 0.2116315346842299]
	TIME [epoch: 23.8 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23779674939885662		[learning rate: 0.0018665]
	Learning Rate: 0.00186649
	LOSS [training: 0.23779674939885662 | validation: 0.2071659203229939]
	TIME [epoch: 23.9 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24189103958831049		[learning rate: 0.0018599]
	Learning Rate: 0.00185989
	LOSS [training: 0.24189103958831049 | validation: 0.20887965185155138]
	TIME [epoch: 23.9 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24306000778074707		[learning rate: 0.0018533]
	Learning Rate: 0.00185331
	LOSS [training: 0.24306000778074707 | validation: 0.20458950832918887]
	TIME [epoch: 23.9 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24091307372252083		[learning rate: 0.0018468]
	Learning Rate: 0.00184676
	LOSS [training: 0.24091307372252083 | validation: 0.21016571709827286]
	TIME [epoch: 24.2 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24440569268869716		[learning rate: 0.0018402]
	Learning Rate: 0.00184023
	LOSS [training: 0.24440569268869716 | validation: 0.201553010456752]
	TIME [epoch: 24.4 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24733513399552884		[learning rate: 0.0018337]
	Learning Rate: 0.00183372
	LOSS [training: 0.24733513399552884 | validation: 0.21096339420127927]
	TIME [epoch: 24.1 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24693676298711864		[learning rate: 0.0018272]
	Learning Rate: 0.00182724
	LOSS [training: 0.24693676298711864 | validation: 0.21001791811448847]
	TIME [epoch: 24.2 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2516453338601791		[learning rate: 0.0018208]
	Learning Rate: 0.00182078
	LOSS [training: 0.2516453338601791 | validation: 0.21251616215099017]
	TIME [epoch: 24.1 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25117141467020665		[learning rate: 0.0018143]
	Learning Rate: 0.00181434
	LOSS [training: 0.25117141467020665 | validation: 0.20581772311150912]
	TIME [epoch: 23.9 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24807413407336154		[learning rate: 0.0018079]
	Learning Rate: 0.00180792
	LOSS [training: 0.24807413407336154 | validation: 0.2086548495384085]
	TIME [epoch: 23.9 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2388142094485708		[learning rate: 0.0018015]
	Learning Rate: 0.00180153
	LOSS [training: 0.2388142094485708 | validation: 0.205179045919671]
	TIME [epoch: 23.9 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2376456525421744		[learning rate: 0.0017952]
	Learning Rate: 0.00179516
	LOSS [training: 0.2376456525421744 | validation: 0.20346596284941904]
	TIME [epoch: 23.9 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2445373223525409		[learning rate: 0.0017888]
	Learning Rate: 0.00178881
	LOSS [training: 0.2445373223525409 | validation: 0.2260439762630778]
	TIME [epoch: 23.9 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25419423910865646		[learning rate: 0.0017825]
	Learning Rate: 0.00178248
	LOSS [training: 0.25419423910865646 | validation: 0.2115222329290337]
	TIME [epoch: 23.9 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2535406345110139		[learning rate: 0.0017762]
	Learning Rate: 0.00177618
	LOSS [training: 0.2535406345110139 | validation: 0.20771257840523522]
	TIME [epoch: 23.9 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24416353511205516		[learning rate: 0.0017699]
	Learning Rate: 0.0017699
	LOSS [training: 0.24416353511205516 | validation: 0.20904182286804787]
	TIME [epoch: 23.8 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24653968223866288		[learning rate: 0.0017636]
	Learning Rate: 0.00176364
	LOSS [training: 0.24653968223866288 | validation: 0.20897760147322497]
	TIME [epoch: 23.9 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25903172312344874		[learning rate: 0.0017574]
	Learning Rate: 0.0017574
	LOSS [training: 0.25903172312344874 | validation: 0.21196321332404686]
	TIME [epoch: 23.9 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24967785629687148		[learning rate: 0.0017512]
	Learning Rate: 0.00175119
	LOSS [training: 0.24967785629687148 | validation: 0.2050343185804217]
	TIME [epoch: 23.9 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2476082499805131		[learning rate: 0.001745]
	Learning Rate: 0.001745
	LOSS [training: 0.2476082499805131 | validation: 0.20254381692826615]
	TIME [epoch: 23.9 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24068699828345755		[learning rate: 0.0017388]
	Learning Rate: 0.00173883
	LOSS [training: 0.24068699828345755 | validation: 0.20396762985642575]
	TIME [epoch: 23.9 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24602686345513178		[learning rate: 0.0017327]
	Learning Rate: 0.00173268
	LOSS [training: 0.24602686345513178 | validation: 0.2003991557654814]
	TIME [epoch: 23.9 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25055712117663553		[learning rate: 0.0017266]
	Learning Rate: 0.00172655
	LOSS [training: 0.25055712117663553 | validation: 0.20309198277358012]
	TIME [epoch: 23.9 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25046789473435		[learning rate: 0.0017204]
	Learning Rate: 0.00172045
	LOSS [training: 0.25046789473435 | validation: 0.21033555220486355]
	TIME [epoch: 23.9 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2491197595937719		[learning rate: 0.0017144]
	Learning Rate: 0.00171436
	LOSS [training: 0.2491197595937719 | validation: 0.20904507236210765]
	TIME [epoch: 23.9 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24651642347342662		[learning rate: 0.0017083]
	Learning Rate: 0.0017083
	LOSS [training: 0.24651642347342662 | validation: 0.2133551443104152]
	TIME [epoch: 23.9 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24887845722186752		[learning rate: 0.0017023]
	Learning Rate: 0.00170226
	LOSS [training: 0.24887845722186752 | validation: 0.21143212344071297]
	TIME [epoch: 23.9 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2452086781909563		[learning rate: 0.0016962]
	Learning Rate: 0.00169624
	LOSS [training: 0.2452086781909563 | validation: 0.20870502913308603]
	TIME [epoch: 23.9 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24292711735371195		[learning rate: 0.0016902]
	Learning Rate: 0.00169024
	LOSS [training: 0.24292711735371195 | validation: 0.20629384644802204]
	TIME [epoch: 23.9 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25001023576764153		[learning rate: 0.0016843]
	Learning Rate: 0.00168426
	LOSS [training: 0.25001023576764153 | validation: 0.20309530241499107]
	TIME [epoch: 23.9 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2450641662702943		[learning rate: 0.0016783]
	Learning Rate: 0.00167831
	LOSS [training: 0.2450641662702943 | validation: 0.2135930744803028]
	TIME [epoch: 23.9 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24677088866322971		[learning rate: 0.0016724]
	Learning Rate: 0.00167237
	LOSS [training: 0.24677088866322971 | validation: 0.2090462725794248]
	TIME [epoch: 23.9 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23947951099984136		[learning rate: 0.0016665]
	Learning Rate: 0.00166646
	LOSS [training: 0.23947951099984136 | validation: 0.2026983499261743]
	TIME [epoch: 23.9 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24750222195946728		[learning rate: 0.0016606]
	Learning Rate: 0.00166057
	LOSS [training: 0.24750222195946728 | validation: 0.2130224539913101]
	TIME [epoch: 23.9 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23846375324518662		[learning rate: 0.0016547]
	Learning Rate: 0.00165469
	LOSS [training: 0.23846375324518662 | validation: 0.20521792839615333]
	TIME [epoch: 23.9 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2409859259299549		[learning rate: 0.0016488]
	Learning Rate: 0.00164884
	LOSS [training: 0.2409859259299549 | validation: 0.21294120710296788]
	TIME [epoch: 23.9 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24677314421817687		[learning rate: 0.001643]
	Learning Rate: 0.00164301
	LOSS [training: 0.24677314421817687 | validation: 0.2160203361157799]
	TIME [epoch: 23.9 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2387118486728996		[learning rate: 0.0016372]
	Learning Rate: 0.0016372
	LOSS [training: 0.2387118486728996 | validation: 0.2151819829278995]
	TIME [epoch: 23.9 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24014070387084815		[learning rate: 0.0016314]
	Learning Rate: 0.00163141
	LOSS [training: 0.24014070387084815 | validation: 0.2032431635765529]
	TIME [epoch: 23.9 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24452230391738083		[learning rate: 0.0016256]
	Learning Rate: 0.00162564
	LOSS [training: 0.24452230391738083 | validation: 0.21158985775052214]
	TIME [epoch: 23.9 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2538186565220654		[learning rate: 0.0016199]
	Learning Rate: 0.0016199
	LOSS [training: 0.2538186565220654 | validation: 0.2120918796290042]
	TIME [epoch: 23.9 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2440080568441335		[learning rate: 0.0016142]
	Learning Rate: 0.00161417
	LOSS [training: 0.2440080568441335 | validation: 0.20954694949905064]
	TIME [epoch: 23.9 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2449346710760615		[learning rate: 0.0016085]
	Learning Rate: 0.00160846
	LOSS [training: 0.2449346710760615 | validation: 0.2096366627918988]
	TIME [epoch: 23.9 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23697685809486368		[learning rate: 0.0016028]
	Learning Rate: 0.00160277
	LOSS [training: 0.23697685809486368 | validation: 0.20815657500323698]
	TIME [epoch: 23.8 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24648267334018573		[learning rate: 0.0015971]
	Learning Rate: 0.0015971
	LOSS [training: 0.24648267334018573 | validation: 0.20954256092757215]
	TIME [epoch: 23.9 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24560746237114983		[learning rate: 0.0015915]
	Learning Rate: 0.00159146
	LOSS [training: 0.24560746237114983 | validation: 0.20928508820648045]
	TIME [epoch: 23.9 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24842625800819876		[learning rate: 0.0015858]
	Learning Rate: 0.00158583
	LOSS [training: 0.24842625800819876 | validation: 0.20634936337719073]
	TIME [epoch: 23.9 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25724033182494027		[learning rate: 0.0015802]
	Learning Rate: 0.00158022
	LOSS [training: 0.25724033182494027 | validation: 0.20805770976899046]
	TIME [epoch: 23.9 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2415463411115304		[learning rate: 0.0015746]
	Learning Rate: 0.00157463
	LOSS [training: 0.2415463411115304 | validation: 0.2035909877507324]
	TIME [epoch: 23.9 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24815626622558826		[learning rate: 0.0015691]
	Learning Rate: 0.00156907
	LOSS [training: 0.24815626622558826 | validation: 0.2023789690834074]
	TIME [epoch: 25.8 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.244896621347286		[learning rate: 0.0015635]
	Learning Rate: 0.00156352
	LOSS [training: 0.244896621347286 | validation: 0.22042046584673575]
	TIME [epoch: 23.9 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24760530727305927		[learning rate: 0.001558]
	Learning Rate: 0.00155799
	LOSS [training: 0.24760530727305927 | validation: 0.2010989361800747]
	TIME [epoch: 23.9 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23980354940218976		[learning rate: 0.0015525]
	Learning Rate: 0.00155248
	LOSS [training: 0.23980354940218976 | validation: 0.21309315674953613]
	TIME [epoch: 23.9 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24429243929306052		[learning rate: 0.001547]
	Learning Rate: 0.00154699
	LOSS [training: 0.24429243929306052 | validation: 0.20839999499872836]
	TIME [epoch: 23.9 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24324509471992128		[learning rate: 0.0015415]
	Learning Rate: 0.00154152
	LOSS [training: 0.24324509471992128 | validation: 0.21005537370973587]
	TIME [epoch: 23.9 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2417225810492354		[learning rate: 0.0015361]
	Learning Rate: 0.00153607
	LOSS [training: 0.2417225810492354 | validation: 0.20270460862165587]
	TIME [epoch: 23.9 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2436410733253791		[learning rate: 0.0015306]
	Learning Rate: 0.00153064
	LOSS [training: 0.2436410733253791 | validation: 0.21058536867381655]
	TIME [epoch: 23.9 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24913879499081104		[learning rate: 0.0015252]
	Learning Rate: 0.00152522
	LOSS [training: 0.24913879499081104 | validation: 0.21096410470103297]
	TIME [epoch: 23.8 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24701081683295953		[learning rate: 0.0015198]
	Learning Rate: 0.00151983
	LOSS [training: 0.24701081683295953 | validation: 0.20802753490542125]
	TIME [epoch: 23.9 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24085646685302783		[learning rate: 0.0015145]
	Learning Rate: 0.00151446
	LOSS [training: 0.24085646685302783 | validation: 0.21180410716227044]
	TIME [epoch: 23.9 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24620631129824422		[learning rate: 0.0015091]
	Learning Rate: 0.0015091
	LOSS [training: 0.24620631129824422 | validation: 0.21662101252118005]
	TIME [epoch: 23.9 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24477946661083358		[learning rate: 0.0015038]
	Learning Rate: 0.00150376
	LOSS [training: 0.24477946661083358 | validation: 0.20799346458932275]
	TIME [epoch: 23.9 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23975189320228937		[learning rate: 0.0014984]
	Learning Rate: 0.00149845
	LOSS [training: 0.23975189320228937 | validation: 0.2107751641267551]
	TIME [epoch: 23.9 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24128112323340645		[learning rate: 0.0014931]
	Learning Rate: 0.00149315
	LOSS [training: 0.24128112323340645 | validation: 0.20007421998646663]
	TIME [epoch: 23.9 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24293617049755456		[learning rate: 0.0014879]
	Learning Rate: 0.00148787
	LOSS [training: 0.24293617049755456 | validation: 0.2049237480799971]
	TIME [epoch: 23.9 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2532667630612898		[learning rate: 0.0014826]
	Learning Rate: 0.00148261
	LOSS [training: 0.2532667630612898 | validation: 0.21109826689085365]
	TIME [epoch: 23.9 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24156116656696833		[learning rate: 0.0014774]
	Learning Rate: 0.00147736
	LOSS [training: 0.24156116656696833 | validation: 0.20512523801188146]
	TIME [epoch: 23.9 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24687332807445758		[learning rate: 0.0014721]
	Learning Rate: 0.00147214
	LOSS [training: 0.24687332807445758 | validation: 0.21008795815236195]
	TIME [epoch: 23.8 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.239578237027714		[learning rate: 0.0014669]
	Learning Rate: 0.00146693
	LOSS [training: 0.239578237027714 | validation: 0.20890056890644768]
	TIME [epoch: 23.9 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24475063574740494		[learning rate: 0.0014617]
	Learning Rate: 0.00146175
	LOSS [training: 0.24475063574740494 | validation: 0.2098698750316291]
	TIME [epoch: 23.9 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2438172091462275		[learning rate: 0.0014566]
	Learning Rate: 0.00145658
	LOSS [training: 0.2438172091462275 | validation: 0.19876940673336613]
	TIME [epoch: 23.9 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24955301598805438		[learning rate: 0.0014514]
	Learning Rate: 0.00145143
	LOSS [training: 0.24955301598805438 | validation: 0.2127829264657526]
	TIME [epoch: 23.8 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25329117830488995		[learning rate: 0.0014463]
	Learning Rate: 0.00144629
	LOSS [training: 0.25329117830488995 | validation: 0.21217252013047708]
	TIME [epoch: 23.9 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24588523674775528		[learning rate: 0.0014412]
	Learning Rate: 0.00144118
	LOSS [training: 0.24588523674775528 | validation: 0.21450848450627746]
	TIME [epoch: 23.9 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2405872479013129		[learning rate: 0.0014361]
	Learning Rate: 0.00143608
	LOSS [training: 0.2405872479013129 | validation: 0.1997383847301795]
	TIME [epoch: 23.9 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24763121375581285		[learning rate: 0.001431]
	Learning Rate: 0.001431
	LOSS [training: 0.24763121375581285 | validation: 0.2088149184701425]
	TIME [epoch: 23.9 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23949103043206857		[learning rate: 0.0014259]
	Learning Rate: 0.00142594
	LOSS [training: 0.23949103043206857 | validation: 0.20529414714157318]
	TIME [epoch: 23.9 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24167031358577748		[learning rate: 0.0014209]
	Learning Rate: 0.0014209
	LOSS [training: 0.24167031358577748 | validation: 0.20630310405222635]
	TIME [epoch: 23.8 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24402535368791875		[learning rate: 0.0014159]
	Learning Rate: 0.00141588
	LOSS [training: 0.24402535368791875 | validation: 0.2098316789635506]
	TIME [epoch: 23.9 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24418353465114326		[learning rate: 0.0014109]
	Learning Rate: 0.00141087
	LOSS [training: 0.24418353465114326 | validation: 0.20580559667730766]
	TIME [epoch: 23.8 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2492844754626804		[learning rate: 0.0014059]
	Learning Rate: 0.00140588
	LOSS [training: 0.2492844754626804 | validation: 0.21017439965396562]
	TIME [epoch: 23.9 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24031018008415192		[learning rate: 0.0014009]
	Learning Rate: 0.00140091
	LOSS [training: 0.24031018008415192 | validation: 0.1979965830152937]
	TIME [epoch: 23.9 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14_20240716_142138/states/model_facs_v3_dec1b_2dpca_v14_605.pth
	Model improved!!!
EPOCH 606/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24479398201346755		[learning rate: 0.001396]
	Learning Rate: 0.00139596
	LOSS [training: 0.24479398201346755 | validation: 0.20798678423912617]
	TIME [epoch: 23.9 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2394816298569238		[learning rate: 0.001391]
	Learning Rate: 0.00139102
	LOSS [training: 0.2394816298569238 | validation: 0.2033118028925351]
	TIME [epoch: 23.9 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24979526253737636		[learning rate: 0.0013861]
	Learning Rate: 0.0013861
	LOSS [training: 0.24979526253737636 | validation: 0.2101686373268627]
	TIME [epoch: 23.9 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25345737054825657		[learning rate: 0.0013812]
	Learning Rate: 0.0013812
	LOSS [training: 0.25345737054825657 | validation: 0.20946852394099524]
	TIME [epoch: 23.9 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2453505955845615		[learning rate: 0.0013763]
	Learning Rate: 0.00137632
	LOSS [training: 0.2453505955845615 | validation: 0.20861370461905296]
	TIME [epoch: 23.9 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24299223518858085		[learning rate: 0.0013714]
	Learning Rate: 0.00137145
	LOSS [training: 0.24299223518858085 | validation: 0.20107689515947688]
	TIME [epoch: 23.9 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25397021387490276		[learning rate: 0.0013666]
	Learning Rate: 0.0013666
	LOSS [training: 0.25397021387490276 | validation: 0.20515862299018206]
	TIME [epoch: 23.9 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24106811895313232		[learning rate: 0.0013618]
	Learning Rate: 0.00136177
	LOSS [training: 0.24106811895313232 | validation: 0.20764558294612234]
	TIME [epoch: 23.8 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24727047776427033		[learning rate: 0.001357]
	Learning Rate: 0.00135695
	LOSS [training: 0.24727047776427033 | validation: 0.21871646292426328]
	TIME [epoch: 23.8 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25632995727846447		[learning rate: 0.0013522]
	Learning Rate: 0.00135215
	LOSS [training: 0.25632995727846447 | validation: 0.2036035851385606]
	TIME [epoch: 23.8 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24512007501508534		[learning rate: 0.0013474]
	Learning Rate: 0.00134737
	LOSS [training: 0.24512007501508534 | validation: 0.20657475623745655]
	TIME [epoch: 23.9 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24459454136509254		[learning rate: 0.0013426]
	Learning Rate: 0.00134261
	LOSS [training: 0.24459454136509254 | validation: 0.21281086092613744]
	TIME [epoch: 23.8 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24244179160094062		[learning rate: 0.0013379]
	Learning Rate: 0.00133786
	LOSS [training: 0.24244179160094062 | validation: 0.2006000554239454]
	TIME [epoch: 23.9 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.243152017420924		[learning rate: 0.0013331]
	Learning Rate: 0.00133313
	LOSS [training: 0.243152017420924 | validation: 0.20691609924564514]
	TIME [epoch: 23.9 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24600026019214127		[learning rate: 0.0013284]
	Learning Rate: 0.00132841
	LOSS [training: 0.24600026019214127 | validation: 0.2088601897640216]
	TIME [epoch: 23.9 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24272895839097744		[learning rate: 0.0013237]
	Learning Rate: 0.00132372
	LOSS [training: 0.24272895839097744 | validation: 0.20039457965473387]
	TIME [epoch: 23.9 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24689081174785255		[learning rate: 0.001319]
	Learning Rate: 0.00131904
	LOSS [training: 0.24689081174785255 | validation: 0.2061802130427704]
	TIME [epoch: 23.8 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2437551602848136		[learning rate: 0.0013144]
	Learning Rate: 0.00131437
	LOSS [training: 0.2437551602848136 | validation: 0.20788700058820836]
	TIME [epoch: 23.9 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2460390981092794		[learning rate: 0.0013097]
	Learning Rate: 0.00130972
	LOSS [training: 0.2460390981092794 | validation: 0.21182902014167532]
	TIME [epoch: 23.9 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24291640088928998		[learning rate: 0.0013051]
	Learning Rate: 0.00130509
	LOSS [training: 0.24291640088928998 | validation: 0.21134502389657134]
	TIME [epoch: 23.8 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24356924675467295		[learning rate: 0.0013005]
	Learning Rate: 0.00130048
	LOSS [training: 0.24356924675467295 | validation: 0.20534059408139313]
	TIME [epoch: 24.1 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24485729254529487		[learning rate: 0.0012959]
	Learning Rate: 0.00129588
	LOSS [training: 0.24485729254529487 | validation: 0.20050986733546244]
	TIME [epoch: 23.9 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24183238279701338		[learning rate: 0.0012913]
	Learning Rate: 0.0012913
	LOSS [training: 0.24183238279701338 | validation: 0.21399845163450143]
	TIME [epoch: 23.9 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24456511291873725		[learning rate: 0.0012867]
	Learning Rate: 0.00128673
	LOSS [training: 0.24456511291873725 | validation: 0.20032514354142075]
	TIME [epoch: 23.9 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25117144603943936		[learning rate: 0.0012822]
	Learning Rate: 0.00128218
	LOSS [training: 0.25117144603943936 | validation: 0.20280148466193268]
	TIME [epoch: 23.9 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24721152481278963		[learning rate: 0.0012776]
	Learning Rate: 0.00127765
	LOSS [training: 0.24721152481278963 | validation: 0.20138022014793533]
	TIME [epoch: 23.9 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2520864399263023		[learning rate: 0.0012731]
	Learning Rate: 0.00127313
	LOSS [training: 0.2520864399263023 | validation: 0.20657714727302218]
	TIME [epoch: 23.9 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24677150669973344		[learning rate: 0.0012686]
	Learning Rate: 0.00126863
	LOSS [training: 0.24677150669973344 | validation: 0.21145836494760245]
	TIME [epoch: 23.9 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24876449961637148		[learning rate: 0.0012641]
	Learning Rate: 0.00126414
	LOSS [training: 0.24876449961637148 | validation: 0.2090473531075748]
	TIME [epoch: 23.9 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24722069502946697		[learning rate: 0.0012597]
	Learning Rate: 0.00125967
	LOSS [training: 0.24722069502946697 | validation: 0.21322258026895474]
	TIME [epoch: 23.9 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23947996888997988		[learning rate: 0.0012552]
	Learning Rate: 0.00125521
	LOSS [training: 0.23947996888997988 | validation: 0.20667120419810203]
	TIME [epoch: 23.9 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2555884868350233		[learning rate: 0.0012508]
	Learning Rate: 0.00125078
	LOSS [training: 0.2555884868350233 | validation: 0.20022855613650997]
	TIME [epoch: 23.9 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2377715429983356		[learning rate: 0.0012464]
	Learning Rate: 0.00124635
	LOSS [training: 0.2377715429983356 | validation: 0.20299478650969588]
	TIME [epoch: 23.9 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24295469196810168		[learning rate: 0.0012419]
	Learning Rate: 0.00124195
	LOSS [training: 0.24295469196810168 | validation: 0.2100894061491932]
	TIME [epoch: 23.9 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24632282914237422		[learning rate: 0.0012376]
	Learning Rate: 0.00123755
	LOSS [training: 0.24632282914237422 | validation: 0.20492538533573385]
	TIME [epoch: 23.9 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24845346315517594		[learning rate: 0.0012332]
	Learning Rate: 0.00123318
	LOSS [training: 0.24845346315517594 | validation: 0.20315611037181083]
	TIME [epoch: 23.9 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24217254907533178		[learning rate: 0.0012288]
	Learning Rate: 0.00122882
	LOSS [training: 0.24217254907533178 | validation: 0.20543359608782558]
	TIME [epoch: 23.9 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2473921629937871		[learning rate: 0.0012245]
	Learning Rate: 0.00122447
	LOSS [training: 0.2473921629937871 | validation: 0.2124851524631978]
	TIME [epoch: 23.9 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24982504926134527		[learning rate: 0.0012201]
	Learning Rate: 0.00122014
	LOSS [training: 0.24982504926134527 | validation: 0.21301670811525336]
	TIME [epoch: 23.9 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2421158973934406		[learning rate: 0.0012158]
	Learning Rate: 0.00121583
	LOSS [training: 0.2421158973934406 | validation: 0.21511340110887317]
	TIME [epoch: 23.9 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2432538965515331		[learning rate: 0.0012115]
	Learning Rate: 0.00121153
	LOSS [training: 0.2432538965515331 | validation: 0.21044915916357257]
	TIME [epoch: 23.9 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24070629822505832		[learning rate: 0.0012072]
	Learning Rate: 0.00120724
	LOSS [training: 0.24070629822505832 | validation: 0.21165601124515482]
	TIME [epoch: 23.9 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24717477101720442		[learning rate: 0.001203]
	Learning Rate: 0.00120297
	LOSS [training: 0.24717477101720442 | validation: 0.21050716162668365]
	TIME [epoch: 23.9 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24146446638864305		[learning rate: 0.0011987]
	Learning Rate: 0.00119872
	LOSS [training: 0.24146446638864305 | validation: 0.2077047702491496]
	TIME [epoch: 23.9 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24383374738351246		[learning rate: 0.0011945]
	Learning Rate: 0.00119448
	LOSS [training: 0.24383374738351246 | validation: 0.20906202319141465]
	TIME [epoch: 23.9 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2476699929915623		[learning rate: 0.0011903]
	Learning Rate: 0.00119026
	LOSS [training: 0.2476699929915623 | validation: 0.2101737530916735]
	TIME [epoch: 23.9 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24217064702003002		[learning rate: 0.001186]
	Learning Rate: 0.00118605
	LOSS [training: 0.24217064702003002 | validation: 0.21539256306042298]
	TIME [epoch: 23.9 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24534041999858894		[learning rate: 0.0011819]
	Learning Rate: 0.00118185
	LOSS [training: 0.24534041999858894 | validation: 0.20469938709604674]
	TIME [epoch: 23.9 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24063471730356234		[learning rate: 0.0011777]
	Learning Rate: 0.00117768
	LOSS [training: 0.24063471730356234 | validation: 0.21339417356409912]
	TIME [epoch: 23.9 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2461215396846722		[learning rate: 0.0011735]
	Learning Rate: 0.00117351
	LOSS [training: 0.2461215396846722 | validation: 0.20725103294817598]
	TIME [epoch: 23.9 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.249131384969522		[learning rate: 0.0011694]
	Learning Rate: 0.00116936
	LOSS [training: 0.249131384969522 | validation: 0.20669486412349508]
	TIME [epoch: 23.9 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24095712324658516		[learning rate: 0.0011652]
	Learning Rate: 0.00116523
	LOSS [training: 0.24095712324658516 | validation: 0.21012662580643662]
	TIME [epoch: 23.9 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2461198450730572		[learning rate: 0.0011611]
	Learning Rate: 0.00116111
	LOSS [training: 0.2461198450730572 | validation: 0.20834520822502575]
	TIME [epoch: 23.9 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24065117125365332		[learning rate: 0.001157]
	Learning Rate: 0.001157
	LOSS [training: 0.24065117125365332 | validation: 0.20559480514268036]
	TIME [epoch: 23.9 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2511331243117687		[learning rate: 0.0011529]
	Learning Rate: 0.00115291
	LOSS [training: 0.2511331243117687 | validation: 0.20870100489870058]
	TIME [epoch: 23.9 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24217761315731282		[learning rate: 0.0011488]
	Learning Rate: 0.00114883
	LOSS [training: 0.24217761315731282 | validation: 0.2030971076214128]
	TIME [epoch: 23.9 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24270452485926994		[learning rate: 0.0011448]
	Learning Rate: 0.00114477
	LOSS [training: 0.24270452485926994 | validation: 0.21229506447178248]
	TIME [epoch: 23.9 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24114653152656704		[learning rate: 0.0011407]
	Learning Rate: 0.00114072
	LOSS [training: 0.24114653152656704 | validation: 0.20038671707225125]
	TIME [epoch: 23.8 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2529558115960069		[learning rate: 0.0011367]
	Learning Rate: 0.00113669
	LOSS [training: 0.2529558115960069 | validation: 0.20791392477011567]
	TIME [epoch: 23.9 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24674741735730354		[learning rate: 0.0011327]
	Learning Rate: 0.00113267
	LOSS [training: 0.24674741735730354 | validation: 0.2120716305315386]
	TIME [epoch: 23.9 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24657353304989005		[learning rate: 0.0011287]
	Learning Rate: 0.00112866
	LOSS [training: 0.24657353304989005 | validation: 0.21116900100951969]
	TIME [epoch: 23.9 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2324428330672307		[learning rate: 0.0011247]
	Learning Rate: 0.00112467
	LOSS [training: 0.2324428330672307 | validation: 0.1994655868941944]
	TIME [epoch: 23.9 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24642678000541687		[learning rate: 0.0011207]
	Learning Rate: 0.00112069
	LOSS [training: 0.24642678000541687 | validation: 0.21023791712016365]
	TIME [epoch: 23.9 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23716396746242027		[learning rate: 0.0011167]
	Learning Rate: 0.00111673
	LOSS [training: 0.23716396746242027 | validation: 0.21352369159697088]
	TIME [epoch: 23.9 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24429645360189464		[learning rate: 0.0011128]
	Learning Rate: 0.00111278
	LOSS [training: 0.24429645360189464 | validation: 0.20981890105455286]
	TIME [epoch: 23.9 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2494321457949862		[learning rate: 0.0011088]
	Learning Rate: 0.00110885
	LOSS [training: 0.2494321457949862 | validation: 0.2076930427795757]
	TIME [epoch: 23.9 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25093778536997086		[learning rate: 0.0011049]
	Learning Rate: 0.00110493
	LOSS [training: 0.25093778536997086 | validation: 0.2062422282907082]
	TIME [epoch: 23.9 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25023128642120424		[learning rate: 0.001101]
	Learning Rate: 0.00110102
	LOSS [training: 0.25023128642120424 | validation: 0.2023552512331989]
	TIME [epoch: 23.9 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24445785688524788		[learning rate: 0.0010971]
	Learning Rate: 0.00109713
	LOSS [training: 0.24445785688524788 | validation: 0.21210386594502562]
	TIME [epoch: 23.9 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24961942384393854		[learning rate: 0.0010932]
	Learning Rate: 0.00109325
	LOSS [training: 0.24961942384393854 | validation: 0.21461947785328128]
	TIME [epoch: 23.9 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2445813507142285		[learning rate: 0.0010894]
	Learning Rate: 0.00108938
	LOSS [training: 0.2445813507142285 | validation: 0.20837359707920533]
	TIME [epoch: 23.9 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24747411654094786		[learning rate: 0.0010855]
	Learning Rate: 0.00108553
	LOSS [training: 0.24747411654094786 | validation: 0.20477833771206053]
	TIME [epoch: 23.9 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25106520535283106		[learning rate: 0.0010817]
	Learning Rate: 0.00108169
	LOSS [training: 0.25106520535283106 | validation: 0.2091977048230646]
	TIME [epoch: 23.9 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24518433945394968		[learning rate: 0.0010779]
	Learning Rate: 0.00107786
	LOSS [training: 0.24518433945394968 | validation: 0.21552949896952392]
	TIME [epoch: 23.8 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23653715098900183		[learning rate: 0.0010741]
	Learning Rate: 0.00107405
	LOSS [training: 0.23653715098900183 | validation: 0.20997537949119147]
	TIME [epoch: 23.9 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24754427315749986		[learning rate: 0.0010703]
	Learning Rate: 0.00107025
	LOSS [training: 0.24754427315749986 | validation: 0.20655855707892695]
	TIME [epoch: 23.8 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23998626848475904		[learning rate: 0.0010665]
	Learning Rate: 0.00106647
	LOSS [training: 0.23998626848475904 | validation: 0.2101028383234287]
	TIME [epoch: 23.9 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2422950056664588		[learning rate: 0.0010627]
	Learning Rate: 0.0010627
	LOSS [training: 0.2422950056664588 | validation: 0.20013791212519827]
	TIME [epoch: 23.9 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23912757679031713		[learning rate: 0.0010589]
	Learning Rate: 0.00105894
	LOSS [training: 0.23912757679031713 | validation: 0.2125718472581463]
	TIME [epoch: 23.9 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2421655467966006		[learning rate: 0.0010552]
	Learning Rate: 0.0010552
	LOSS [training: 0.2421655467966006 | validation: 0.21507547563019996]
	TIME [epoch: 23.8 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24629402513706325		[learning rate: 0.0010515]
	Learning Rate: 0.00105147
	LOSS [training: 0.24629402513706325 | validation: 0.2208736316299432]
	TIME [epoch: 23.9 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2451779438272693		[learning rate: 0.0010477]
	Learning Rate: 0.00104775
	LOSS [training: 0.2451779438272693 | validation: 0.21601985516528263]
	TIME [epoch: 23.8 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24408020628129237		[learning rate: 0.001044]
	Learning Rate: 0.00104404
	LOSS [training: 0.24408020628129237 | validation: 0.2082927770580182]
	TIME [epoch: 23.9 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24107452565715634		[learning rate: 0.0010404]
	Learning Rate: 0.00104035
	LOSS [training: 0.24107452565715634 | validation: 0.2028623548228016]
	TIME [epoch: 23.9 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24433357298252134		[learning rate: 0.0010367]
	Learning Rate: 0.00103667
	LOSS [training: 0.24433357298252134 | validation: 0.21149964171024954]
	TIME [epoch: 23.9 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24597201995795692		[learning rate: 0.001033]
	Learning Rate: 0.00103301
	LOSS [training: 0.24597201995795692 | validation: 0.20750322903765275]
	TIME [epoch: 23.9 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24485373568035954		[learning rate: 0.0010294]
	Learning Rate: 0.00102935
	LOSS [training: 0.24485373568035954 | validation: 0.21206455738632773]
	TIME [epoch: 23.9 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24462439066706523		[learning rate: 0.0010257]
	Learning Rate: 0.00102571
	LOSS [training: 0.24462439066706523 | validation: 0.21408558669038547]
	TIME [epoch: 23.9 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24575499958929947		[learning rate: 0.0010221]
	Learning Rate: 0.00102209
	LOSS [training: 0.24575499958929947 | validation: 0.2179879461394211]
	TIME [epoch: 23.9 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24743858635483718		[learning rate: 0.0010185]
	Learning Rate: 0.00101847
	LOSS [training: 0.24743858635483718 | validation: 0.2170728986083963]
	TIME [epoch: 23.9 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2380304484257925		[learning rate: 0.0010149]
	Learning Rate: 0.00101487
	LOSS [training: 0.2380304484257925 | validation: 0.21256098704555693]
	TIME [epoch: 23.9 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23915094775304402		[learning rate: 0.0010113]
	Learning Rate: 0.00101128
	LOSS [training: 0.23915094775304402 | validation: 0.21711474940927716]
	TIME [epoch: 23.8 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24496761166389		[learning rate: 0.0010077]
	Learning Rate: 0.0010077
	LOSS [training: 0.24496761166389 | validation: 0.20893274300786616]
	TIME [epoch: 23.9 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23544308902070007		[learning rate: 0.0010041]
	Learning Rate: 0.00100414
	LOSS [training: 0.23544308902070007 | validation: 0.20868629797387692]
	TIME [epoch: 23.9 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24680444930122714		[learning rate: 0.0010006]
	Learning Rate: 0.00100059
	LOSS [training: 0.24680444930122714 | validation: 0.20590412427932298]
	TIME [epoch: 23.9 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24649059903197124		[learning rate: 0.00099705]
	Learning Rate: 0.000997052
	LOSS [training: 0.24649059903197124 | validation: 0.20689793715050767]
	TIME [epoch: 23.9 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2439360834019413		[learning rate: 0.00099353]
	Learning Rate: 0.000993527
	LOSS [training: 0.2439360834019413 | validation: 0.2102595605872637]
	TIME [epoch: 23.9 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24630396377917962		[learning rate: 0.00099001]
	Learning Rate: 0.000990013
	LOSS [training: 0.24630396377917962 | validation: 0.20643101927834612]
	TIME [epoch: 23.9 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24568583238590558		[learning rate: 0.00098651]
	Learning Rate: 0.000986513
	LOSS [training: 0.24568583238590558 | validation: 0.20895275659328347]
	TIME [epoch: 23.9 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23821688259865212		[learning rate: 0.00098302]
	Learning Rate: 0.000983024
	LOSS [training: 0.23821688259865212 | validation: 0.2065847113652842]
	TIME [epoch: 23.9 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24260781485054364		[learning rate: 0.00097955]
	Learning Rate: 0.000979548
	LOSS [training: 0.24260781485054364 | validation: 0.214158285979396]
	TIME [epoch: 23.9 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24217052476160547		[learning rate: 0.00097608]
	Learning Rate: 0.000976084
	LOSS [training: 0.24217052476160547 | validation: 0.2099889203797644]
	TIME [epoch: 23.9 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24810900834059044		[learning rate: 0.00097263]
	Learning Rate: 0.000972632
	LOSS [training: 0.24810900834059044 | validation: 0.20809858720909524]
	TIME [epoch: 23.9 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2474055792419736		[learning rate: 0.00096919]
	Learning Rate: 0.000969193
	LOSS [training: 0.2474055792419736 | validation: 0.20815497228093846]
	TIME [epoch: 23.9 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24637904663573465		[learning rate: 0.00096577]
	Learning Rate: 0.000965766
	LOSS [training: 0.24637904663573465 | validation: 0.20788102609598025]
	TIME [epoch: 23.9 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24756117066337244		[learning rate: 0.00096235]
	Learning Rate: 0.000962351
	LOSS [training: 0.24756117066337244 | validation: 0.21109905189843517]
	TIME [epoch: 23.9 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24358831535029704		[learning rate: 0.00095895]
	Learning Rate: 0.000958948
	LOSS [training: 0.24358831535029704 | validation: 0.21072836706176373]
	TIME [epoch: 23.8 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24782980875667135		[learning rate: 0.00095556]
	Learning Rate: 0.000955557
	LOSS [training: 0.24782980875667135 | validation: 0.21565461248523565]
	TIME [epoch: 23.9 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24552211848908367		[learning rate: 0.00095218]
	Learning Rate: 0.000952178
	LOSS [training: 0.24552211848908367 | validation: 0.2161460282970899]
	TIME [epoch: 23.9 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24802580676598093		[learning rate: 0.00094881]
	Learning Rate: 0.00094881
	LOSS [training: 0.24802580676598093 | validation: 0.19778959428701334]
	TIME [epoch: 23.9 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14_20240716_142138/states/model_facs_v3_dec1b_2dpca_v14_715.pth
	Model improved!!!
EPOCH 716/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2415038757835978		[learning rate: 0.00094546]
	Learning Rate: 0.000945455
	LOSS [training: 0.2415038757835978 | validation: 0.20867837900355898]
	TIME [epoch: 23.9 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24010419919320533		[learning rate: 0.00094211]
	Learning Rate: 0.000942112
	LOSS [training: 0.24010419919320533 | validation: 0.20595366956624012]
	TIME [epoch: 23.9 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2387241750935576		[learning rate: 0.00093878]
	Learning Rate: 0.000938781
	LOSS [training: 0.2387241750935576 | validation: 0.20551015372509437]
	TIME [epoch: 23.9 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24367484297285844		[learning rate: 0.00093546]
	Learning Rate: 0.000935461
	LOSS [training: 0.24367484297285844 | validation: 0.20925503375488508]
	TIME [epoch: 23.9 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2399335531185721		[learning rate: 0.00093215]
	Learning Rate: 0.000932153
	LOSS [training: 0.2399335531185721 | validation: 0.2118041161817493]
	TIME [epoch: 23.8 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23831315323971794		[learning rate: 0.00092886]
	Learning Rate: 0.000928857
	LOSS [training: 0.23831315323971794 | validation: 0.2052475017216718]
	TIME [epoch: 23.9 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24106405263792266		[learning rate: 0.00092557]
	Learning Rate: 0.000925572
	LOSS [training: 0.24106405263792266 | validation: 0.21814162439739965]
	TIME [epoch: 23.8 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2390647954501047		[learning rate: 0.0009223]
	Learning Rate: 0.000922299
	LOSS [training: 0.2390647954501047 | validation: 0.20742253621476153]
	TIME [epoch: 23.8 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24212708963788845		[learning rate: 0.00091904]
	Learning Rate: 0.000919038
	LOSS [training: 0.24212708963788845 | validation: 0.21479685469625637]
	TIME [epoch: 23.9 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23951576396312677		[learning rate: 0.00091579]
	Learning Rate: 0.000915788
	LOSS [training: 0.23951576396312677 | validation: 0.203625911263393]
	TIME [epoch: 23.9 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.247653624537164		[learning rate: 0.00091255]
	Learning Rate: 0.000912549
	LOSS [training: 0.247653624537164 | validation: 0.21307738824891528]
	TIME [epoch: 23.9 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24315836641798313		[learning rate: 0.00090932]
	Learning Rate: 0.000909323
	LOSS [training: 0.24315836641798313 | validation: 0.20995771587314613]
	TIME [epoch: 23.9 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23944839305102775		[learning rate: 0.00090611]
	Learning Rate: 0.000906107
	LOSS [training: 0.23944839305102775 | validation: 0.20841064974749565]
	TIME [epoch: 23.9 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23930295597936638		[learning rate: 0.0009029]
	Learning Rate: 0.000902903
	LOSS [training: 0.23930295597936638 | validation: 0.20986795869747848]
	TIME [epoch: 23.9 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2451529757937553		[learning rate: 0.00089971]
	Learning Rate: 0.00089971
	LOSS [training: 0.2451529757937553 | validation: 0.20650592762501682]
	TIME [epoch: 23.9 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23408023877932338		[learning rate: 0.00089653]
	Learning Rate: 0.000896529
	LOSS [training: 0.23408023877932338 | validation: 0.2084348861952293]
	TIME [epoch: 23.9 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2510449250227502		[learning rate: 0.00089336]
	Learning Rate: 0.000893358
	LOSS [training: 0.2510449250227502 | validation: 0.21007024441452513]
	TIME [epoch: 23.9 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24687443517021793		[learning rate: 0.0008902]
	Learning Rate: 0.000890199
	LOSS [training: 0.24687443517021793 | validation: 0.2029224060234734]
	TIME [epoch: 23.9 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24793951076917267		[learning rate: 0.00088705]
	Learning Rate: 0.000887051
	LOSS [training: 0.24793951076917267 | validation: 0.2178876652079386]
	TIME [epoch: 23.9 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24094635631412378		[learning rate: 0.00088391]
	Learning Rate: 0.000883914
	LOSS [training: 0.24094635631412378 | validation: 0.20278633340021485]
	TIME [epoch: 23.9 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24049835943598105		[learning rate: 0.00088079]
	Learning Rate: 0.000880789
	LOSS [training: 0.24049835943598105 | validation: 0.2079702612793996]
	TIME [epoch: 23.9 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24410821727721524		[learning rate: 0.00087767]
	Learning Rate: 0.000877674
	LOSS [training: 0.24410821727721524 | validation: 0.2093976806918625]
	TIME [epoch: 23.9 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24521641211321912		[learning rate: 0.00087457]
	Learning Rate: 0.000874571
	LOSS [training: 0.24521641211321912 | validation: 0.2161248356016575]
	TIME [epoch: 23.9 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2435922531613283		[learning rate: 0.00087148]
	Learning Rate: 0.000871478
	LOSS [training: 0.2435922531613283 | validation: 0.2069429040502929]
	TIME [epoch: 23.9 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2389795944918339		[learning rate: 0.0008684]
	Learning Rate: 0.000868396
	LOSS [training: 0.2389795944918339 | validation: 0.2115583309506269]
	TIME [epoch: 23.9 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24800977740825073		[learning rate: 0.00086533]
	Learning Rate: 0.000865326
	LOSS [training: 0.24800977740825073 | validation: 0.20098339246947075]
	TIME [epoch: 23.9 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24718553753657724		[learning rate: 0.00086227]
	Learning Rate: 0.000862266
	LOSS [training: 0.24718553753657724 | validation: 0.21134688823973122]
	TIME [epoch: 23.9 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24851818548409854		[learning rate: 0.00085922]
	Learning Rate: 0.000859216
	LOSS [training: 0.24851818548409854 | validation: 0.20719846207095785]
	TIME [epoch: 23.9 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24701094941005383		[learning rate: 0.00085618]
	Learning Rate: 0.000856178
	LOSS [training: 0.24701094941005383 | validation: 0.19774955024069357]
	TIME [epoch: 23.8 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14_20240716_142138/states/model_facs_v3_dec1b_2dpca_v14_744.pth
	Model improved!!!
EPOCH 745/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2425306332660165		[learning rate: 0.00085315]
	Learning Rate: 0.00085315
	LOSS [training: 0.2425306332660165 | validation: 0.1985641099336815]
	TIME [epoch: 23.9 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2394522963633554		[learning rate: 0.00085013]
	Learning Rate: 0.000850134
	LOSS [training: 0.2394522963633554 | validation: 0.20072079801629145]
	TIME [epoch: 23.9 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24116399955726697		[learning rate: 0.00084713]
	Learning Rate: 0.000847127
	LOSS [training: 0.24116399955726697 | validation: 0.2085347306747777]
	TIME [epoch: 23.9 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23810134699143282		[learning rate: 0.00084413]
	Learning Rate: 0.000844132
	LOSS [training: 0.23810134699143282 | validation: 0.21143997545468998]
	TIME [epoch: 23.9 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24065138096262487		[learning rate: 0.00084115]
	Learning Rate: 0.000841147
	LOSS [training: 0.24065138096262487 | validation: 0.196566087750258]
	TIME [epoch: 23.8 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14_20240716_142138/states/model_facs_v3_dec1b_2dpca_v14_749.pth
	Model improved!!!
EPOCH 750/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24125762164234896		[learning rate: 0.00083817]
	Learning Rate: 0.000838172
	LOSS [training: 0.24125762164234896 | validation: 0.20113736678865485]
	TIME [epoch: 23.9 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23879213179270775		[learning rate: 0.00083521]
	Learning Rate: 0.000835209
	LOSS [training: 0.23879213179270775 | validation: 0.21087757077149621]
	TIME [epoch: 23.9 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23621257035348764		[learning rate: 0.00083225]
	Learning Rate: 0.000832255
	LOSS [training: 0.23621257035348764 | validation: 0.20304904156410392]
	TIME [epoch: 23.9 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24631872346856465		[learning rate: 0.00082931]
	Learning Rate: 0.000829312
	LOSS [training: 0.24631872346856465 | validation: 0.2074731235187488]
	TIME [epoch: 23.9 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24391249985811747		[learning rate: 0.00082638]
	Learning Rate: 0.000826379
	LOSS [training: 0.24391249985811747 | validation: 0.19895915062123642]
	TIME [epoch: 23.8 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24929545828356794		[learning rate: 0.00082346]
	Learning Rate: 0.000823457
	LOSS [training: 0.24929545828356794 | validation: 0.19738412337638248]
	TIME [epoch: 23.9 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24570614481372252		[learning rate: 0.00082055]
	Learning Rate: 0.000820545
	LOSS [training: 0.24570614481372252 | validation: 0.20569289346237643]
	TIME [epoch: 23.9 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24804327158832892		[learning rate: 0.00081764]
	Learning Rate: 0.000817644
	LOSS [training: 0.24804327158832892 | validation: 0.20783232134237695]
	TIME [epoch: 23.9 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24661628444019623		[learning rate: 0.00081475]
	Learning Rate: 0.000814752
	LOSS [training: 0.24661628444019623 | validation: 0.20590813323340185]
	TIME [epoch: 23.9 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24962361250736767		[learning rate: 0.00081187]
	Learning Rate: 0.000811871
	LOSS [training: 0.24962361250736767 | validation: 0.20041682089275623]
	TIME [epoch: 23.8 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2500066408328732		[learning rate: 0.000809]
	Learning Rate: 0.000809
	LOSS [training: 0.2500066408328732 | validation: 0.20806417282785228]
	TIME [epoch: 23.9 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24256094171780776		[learning rate: 0.00080614]
	Learning Rate: 0.00080614
	LOSS [training: 0.24256094171780776 | validation: 0.20598298449863278]
	TIME [epoch: 23.9 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24530863899718766		[learning rate: 0.00080329]
	Learning Rate: 0.000803289
	LOSS [training: 0.24530863899718766 | validation: 0.2047847324009994]
	TIME [epoch: 23.8 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23828344215270694		[learning rate: 0.00080045]
	Learning Rate: 0.000800448
	LOSS [training: 0.23828344215270694 | validation: 0.2049264721399487]
	TIME [epoch: 23.9 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2313191975189086		[learning rate: 0.00079762]
	Learning Rate: 0.000797618
	LOSS [training: 0.2313191975189086 | validation: 0.21215874020853134]
	TIME [epoch: 23.9 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24577826220231866		[learning rate: 0.0007948]
	Learning Rate: 0.000794797
	LOSS [training: 0.24577826220231866 | validation: 0.20417938373800454]
	TIME [epoch: 23.8 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2419493372211331		[learning rate: 0.00079199]
	Learning Rate: 0.000791987
	LOSS [training: 0.2419493372211331 | validation: 0.19915398913633484]
	TIME [epoch: 23.8 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24400805620210608		[learning rate: 0.00078919]
	Learning Rate: 0.000789186
	LOSS [training: 0.24400805620210608 | validation: 0.20949661482211832]
	TIME [epoch: 23.8 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23723350032958712		[learning rate: 0.0007864]
	Learning Rate: 0.000786396
	LOSS [training: 0.23723350032958712 | validation: 0.2068878112206855]
	TIME [epoch: 23.8 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24833636998999956		[learning rate: 0.00078361]
	Learning Rate: 0.000783615
	LOSS [training: 0.24833636998999956 | validation: 0.20513960599522835]
	TIME [epoch: 23.9 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24434028446775255		[learning rate: 0.00078084]
	Learning Rate: 0.000780844
	LOSS [training: 0.24434028446775255 | validation: 0.20212701968953145]
	TIME [epoch: 23.9 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2414199820525662		[learning rate: 0.00077808]
	Learning Rate: 0.000778082
	LOSS [training: 0.2414199820525662 | validation: 0.20675393784229684]
	TIME [epoch: 23.9 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2448668616734431		[learning rate: 0.00077533]
	Learning Rate: 0.000775331
	LOSS [training: 0.2448668616734431 | validation: 0.20589558447198017]
	TIME [epoch: 23.8 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24332461767660316		[learning rate: 0.00077259]
	Learning Rate: 0.000772589
	LOSS [training: 0.24332461767660316 | validation: 0.2130319962652672]
	TIME [epoch: 23.9 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24669541086786087		[learning rate: 0.00076986]
	Learning Rate: 0.000769857
	LOSS [training: 0.24669541086786087 | validation: 0.21290398621719522]
	TIME [epoch: 23.9 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24508479802958041		[learning rate: 0.00076714]
	Learning Rate: 0.000767135
	LOSS [training: 0.24508479802958041 | validation: 0.2108209259357082]
	TIME [epoch: 23.8 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24216428614218077		[learning rate: 0.00076442]
	Learning Rate: 0.000764422
	LOSS [training: 0.24216428614218077 | validation: 0.20513799705522642]
	TIME [epoch: 23.9 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2419748179423791		[learning rate: 0.00076172]
	Learning Rate: 0.000761719
	LOSS [training: 0.2419748179423791 | validation: 0.2067499393774644]
	TIME [epoch: 23.8 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24422230271192058		[learning rate: 0.00075903]
	Learning Rate: 0.000759026
	LOSS [training: 0.24422230271192058 | validation: 0.20770428490484516]
	TIME [epoch: 23.9 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2404545961356456		[learning rate: 0.00075634]
	Learning Rate: 0.000756342
	LOSS [training: 0.2404545961356456 | validation: 0.2130300550041448]
	TIME [epoch: 23.8 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24583089835370295		[learning rate: 0.00075367]
	Learning Rate: 0.000753667
	LOSS [training: 0.24583089835370295 | validation: 0.20717951324793438]
	TIME [epoch: 23.8 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25094967287730324		[learning rate: 0.000751]
	Learning Rate: 0.000751002
	LOSS [training: 0.25094967287730324 | validation: 0.2077504472191854]
	TIME [epoch: 23.8 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25254541779317735		[learning rate: 0.00074835]
	Learning Rate: 0.000748346
	LOSS [training: 0.25254541779317735 | validation: 0.21194112543719154]
	TIME [epoch: 23.8 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24751004743950603		[learning rate: 0.0007457]
	Learning Rate: 0.0007457
	LOSS [training: 0.24751004743950603 | validation: 0.20667087915187082]
	TIME [epoch: 23.8 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24360640243292705		[learning rate: 0.00074306]
	Learning Rate: 0.000743063
	LOSS [training: 0.24360640243292705 | validation: 0.20896720365030372]
	TIME [epoch: 23.8 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23996522531370448		[learning rate: 0.00074044]
	Learning Rate: 0.000740435
	LOSS [training: 0.23996522531370448 | validation: 0.21122001316640313]
	TIME [epoch: 23.8 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2485263704301788		[learning rate: 0.00073782]
	Learning Rate: 0.000737817
	LOSS [training: 0.2485263704301788 | validation: 0.20281646204877438]
	TIME [epoch: 23.8 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2454502192359752		[learning rate: 0.00073521]
	Learning Rate: 0.000735208
	LOSS [training: 0.2454502192359752 | validation: 0.2003919088730691]
	TIME [epoch: 23.8 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24811120214856308		[learning rate: 0.00073261]
	Learning Rate: 0.000732608
	LOSS [training: 0.24811120214856308 | validation: 0.20134639285467024]
	TIME [epoch: 23.9 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24980355481836733		[learning rate: 0.00073002]
	Learning Rate: 0.000730018
	LOSS [training: 0.24980355481836733 | validation: 0.1953283292004799]
	TIME [epoch: 23.8 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14_20240716_142138/states/model_facs_v3_dec1b_2dpca_v14_789.pth
	Model improved!!!
EPOCH 790/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24730695186737986		[learning rate: 0.00072744]
	Learning Rate: 0.000727436
	LOSS [training: 0.24730695186737986 | validation: 0.204686720055755]
	TIME [epoch: 23.9 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24001086083390932		[learning rate: 0.00072486]
	Learning Rate: 0.000724864
	LOSS [training: 0.24001086083390932 | validation: 0.2045176632890154]
	TIME [epoch: 23.8 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24327275631150028		[learning rate: 0.0007223]
	Learning Rate: 0.000722301
	LOSS [training: 0.24327275631150028 | validation: 0.20757312103826578]
	TIME [epoch: 23.8 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24741344090449402		[learning rate: 0.00071975]
	Learning Rate: 0.000719746
	LOSS [training: 0.24741344090449402 | validation: 0.2083143003983489]
	TIME [epoch: 23.8 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23149087916732994		[learning rate: 0.0007172]
	Learning Rate: 0.000717201
	LOSS [training: 0.23149087916732994 | validation: 0.2049666268094045]
	TIME [epoch: 23.8 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24040523211402332		[learning rate: 0.00071467]
	Learning Rate: 0.000714665
	LOSS [training: 0.24040523211402332 | validation: 0.2062982409690297]
	TIME [epoch: 23.9 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24118579425224107		[learning rate: 0.00071214]
	Learning Rate: 0.000712138
	LOSS [training: 0.24118579425224107 | validation: 0.2032552650598381]
	TIME [epoch: 23.8 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2516585691988041		[learning rate: 0.00070962]
	Learning Rate: 0.00070962
	LOSS [training: 0.2516585691988041 | validation: 0.21103959599056216]
	TIME [epoch: 23.8 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2428150019695723		[learning rate: 0.00070711]
	Learning Rate: 0.00070711
	LOSS [training: 0.2428150019695723 | validation: 0.20163292779681244]
	TIME [epoch: 23.8 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24401710478220084		[learning rate: 0.00070461]
	Learning Rate: 0.00070461
	LOSS [training: 0.24401710478220084 | validation: 0.20425923281636713]
	TIME [epoch: 23.9 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24694268087509333		[learning rate: 0.00070212]
	Learning Rate: 0.000702118
	LOSS [training: 0.24694268087509333 | validation: 0.20689099993734644]
	TIME [epoch: 23.9 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23836095854748682		[learning rate: 0.00069964]
	Learning Rate: 0.000699635
	LOSS [training: 0.23836095854748682 | validation: 0.2083564907391325]
	TIME [epoch: 23.8 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24278250898050946		[learning rate: 0.00069716]
	Learning Rate: 0.000697161
	LOSS [training: 0.24278250898050946 | validation: 0.20339573275588996]
	TIME [epoch: 23.8 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2441363257168436		[learning rate: 0.0006947]
	Learning Rate: 0.000694696
	LOSS [training: 0.2441363257168436 | validation: 0.209038610072376]
	TIME [epoch: 23.8 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2393258965621797		[learning rate: 0.00069224]
	Learning Rate: 0.00069224
	LOSS [training: 0.2393258965621797 | validation: 0.20674835212772863]
	TIME [epoch: 23.8 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23954747322672879		[learning rate: 0.00068979]
	Learning Rate: 0.000689792
	LOSS [training: 0.23954747322672879 | validation: 0.2032050443261988]
	TIME [epoch: 23.8 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24523407970156694		[learning rate: 0.00068735]
	Learning Rate: 0.000687352
	LOSS [training: 0.24523407970156694 | validation: 0.20881434873265842]
	TIME [epoch: 23.8 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23849844744839188		[learning rate: 0.00068492]
	Learning Rate: 0.000684922
	LOSS [training: 0.23849844744839188 | validation: 0.20882829260016864]
	TIME [epoch: 23.8 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2382457107916883		[learning rate: 0.0006825]
	Learning Rate: 0.0006825
	LOSS [training: 0.2382457107916883 | validation: 0.21548016025489375]
	TIME [epoch: 23.8 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24999007217122104		[learning rate: 0.00068009]
	Learning Rate: 0.000680086
	LOSS [training: 0.24999007217122104 | validation: 0.21558833430976784]
	TIME [epoch: 23.8 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24398796295320535		[learning rate: 0.00067768]
	Learning Rate: 0.000677682
	LOSS [training: 0.24398796295320535 | validation: 0.2106186493398731]
	TIME [epoch: 23.8 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24161722001727534		[learning rate: 0.00067529]
	Learning Rate: 0.000675285
	LOSS [training: 0.24161722001727534 | validation: 0.20857237646661467]
	TIME [epoch: 23.8 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2442439293692984		[learning rate: 0.0006729]
	Learning Rate: 0.000672897
	LOSS [training: 0.2442439293692984 | validation: 0.20614292736029208]
	TIME [epoch: 23.8 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2436975476436598		[learning rate: 0.00067052]
	Learning Rate: 0.000670518
	LOSS [training: 0.2436975476436598 | validation: 0.21101765458929034]
	TIME [epoch: 23.8 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24035230671206428		[learning rate: 0.00066815]
	Learning Rate: 0.000668147
	LOSS [training: 0.24035230671206428 | validation: 0.20701931585996625]
	TIME [epoch: 23.8 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2406088198880129		[learning rate: 0.00066578]
	Learning Rate: 0.000665784
	LOSS [training: 0.2406088198880129 | validation: 0.20794579315496628]
	TIME [epoch: 23.8 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23615143000712965		[learning rate: 0.00066343]
	Learning Rate: 0.00066343
	LOSS [training: 0.23615143000712965 | validation: 0.2083361647150419]
	TIME [epoch: 23.9 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2409740963451206		[learning rate: 0.00066108]
	Learning Rate: 0.000661084
	LOSS [training: 0.2409740963451206 | validation: 0.2066442007642904]
	TIME [epoch: 23.8 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23637178794471644		[learning rate: 0.00065875]
	Learning Rate: 0.000658746
	LOSS [training: 0.23637178794471644 | validation: 0.2039484812014381]
	TIME [epoch: 23.9 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24950269658199228		[learning rate: 0.00065642]
	Learning Rate: 0.000656417
	LOSS [training: 0.24950269658199228 | validation: 0.20680041145455413]
	TIME [epoch: 23.8 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23035033644650174		[learning rate: 0.0006541]
	Learning Rate: 0.000654095
	LOSS [training: 0.23035033644650174 | validation: 0.20641969040554814]
	TIME [epoch: 23.9 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23916723765368578		[learning rate: 0.00065178]
	Learning Rate: 0.000651782
	LOSS [training: 0.23916723765368578 | validation: 0.20681453651436268]
	TIME [epoch: 23.8 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23727704769529767		[learning rate: 0.00064948]
	Learning Rate: 0.000649477
	LOSS [training: 0.23727704769529767 | validation: 0.21164384009626774]
	TIME [epoch: 23.8 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2376089144868733		[learning rate: 0.00064718]
	Learning Rate: 0.000647181
	LOSS [training: 0.2376089144868733 | validation: 0.2074861950574554]
	TIME [epoch: 23.8 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24875621320132657		[learning rate: 0.00064489]
	Learning Rate: 0.000644892
	LOSS [training: 0.24875621320132657 | validation: 0.20693032473733136]
	TIME [epoch: 23.8 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2393235054060827		[learning rate: 0.00064261]
	Learning Rate: 0.000642612
	LOSS [training: 0.2393235054060827 | validation: 0.2054041040571603]
	TIME [epoch: 23.8 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24145260075228805		[learning rate: 0.00064034]
	Learning Rate: 0.000640339
	LOSS [training: 0.24145260075228805 | validation: 0.20891262709483502]
	TIME [epoch: 23.8 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24199399371241248		[learning rate: 0.00063808]
	Learning Rate: 0.000638075
	LOSS [training: 0.24199399371241248 | validation: 0.20560095611550366]
	TIME [epoch: 23.8 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23308946882556061		[learning rate: 0.00063582]
	Learning Rate: 0.000635819
	LOSS [training: 0.23308946882556061 | validation: 0.2011693254480754]
	TIME [epoch: 23.8 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2440327148839375		[learning rate: 0.00063357]
	Learning Rate: 0.00063357
	LOSS [training: 0.2440327148839375 | validation: 0.20332983261146084]
	TIME [epoch: 23.9 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2379256361715294		[learning rate: 0.00063133]
	Learning Rate: 0.00063133
	LOSS [training: 0.2379256361715294 | validation: 0.2091718783588322]
	TIME [epoch: 23.9 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23763452675414765		[learning rate: 0.0006291]
	Learning Rate: 0.000629098
	LOSS [training: 0.23763452675414765 | validation: 0.21408154207757196]
	TIME [epoch: 23.9 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23684266784064423		[learning rate: 0.00062687]
	Learning Rate: 0.000626873
	LOSS [training: 0.23684266784064423 | validation: 0.2103473057799984]
	TIME [epoch: 23.8 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23838306308122736		[learning rate: 0.00062466]
	Learning Rate: 0.000624656
	LOSS [training: 0.23838306308122736 | validation: 0.20695043509474584]
	TIME [epoch: 23.8 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24004659094633807		[learning rate: 0.00062245]
	Learning Rate: 0.000622447
	LOSS [training: 0.24004659094633807 | validation: 0.21052293155235463]
	TIME [epoch: 23.8 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24377338079878805		[learning rate: 0.00062025]
	Learning Rate: 0.000620246
	LOSS [training: 0.24377338079878805 | validation: 0.2080998147357115]
	TIME [epoch: 23.8 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24467155044333222		[learning rate: 0.00061805]
	Learning Rate: 0.000618053
	LOSS [training: 0.24467155044333222 | validation: 0.20651892423813373]
	TIME [epoch: 23.9 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23846721979108224		[learning rate: 0.00061587]
	Learning Rate: 0.000615867
	LOSS [training: 0.23846721979108224 | validation: 0.21150320278329424]
	TIME [epoch: 23.8 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24538599492291568		[learning rate: 0.00061369]
	Learning Rate: 0.00061369
	LOSS [training: 0.24538599492291568 | validation: 0.21489302428423862]
	TIME [epoch: 23.8 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24350354034897195		[learning rate: 0.00061152]
	Learning Rate: 0.000611519
	LOSS [training: 0.24350354034897195 | validation: 0.20958726379128736]
	TIME [epoch: 23.8 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24586906729737193		[learning rate: 0.00060936]
	Learning Rate: 0.000609357
	LOSS [training: 0.24586906729737193 | validation: 0.21060276286275545]
	TIME [epoch: 23.9 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23951902758459562		[learning rate: 0.0006072]
	Learning Rate: 0.000607202
	LOSS [training: 0.23951902758459562 | validation: 0.20866395137512583]
	TIME [epoch: 23.9 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24213171034887346		[learning rate: 0.00060506]
	Learning Rate: 0.000605055
	LOSS [training: 0.24213171034887346 | validation: 0.20441082879039546]
	TIME [epoch: 23.9 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23656214482849117		[learning rate: 0.00060292]
	Learning Rate: 0.000602915
	LOSS [training: 0.23656214482849117 | validation: 0.21291022348758554]
	TIME [epoch: 23.9 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24735180264076462		[learning rate: 0.00060078]
	Learning Rate: 0.000600784
	LOSS [training: 0.24735180264076462 | validation: 0.20347143326372627]
	TIME [epoch: 23.8 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24380201757762576		[learning rate: 0.00059866]
	Learning Rate: 0.000598659
	LOSS [training: 0.24380201757762576 | validation: 0.21384876078581838]
	TIME [epoch: 23.9 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24752117589829456		[learning rate: 0.00059654]
	Learning Rate: 0.000596542
	LOSS [training: 0.24752117589829456 | validation: 0.2079197250099397]
	TIME [epoch: 23.8 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24646702119562905		[learning rate: 0.00059443]
	Learning Rate: 0.000594432
	LOSS [training: 0.24646702119562905 | validation: 0.21203026584973478]
	TIME [epoch: 23.9 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24524749681223776		[learning rate: 0.00059233]
	Learning Rate: 0.00059233
	LOSS [training: 0.24524749681223776 | validation: 0.2042935436938628]
	TIME [epoch: 23.9 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24124596461649883		[learning rate: 0.00059024]
	Learning Rate: 0.000590236
	LOSS [training: 0.24124596461649883 | validation: 0.20510796929204603]
	TIME [epoch: 23.8 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24544263287864823		[learning rate: 0.00058815]
	Learning Rate: 0.000588149
	LOSS [training: 0.24544263287864823 | validation: 0.20849482791526208]
	TIME [epoch: 23.8 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23766035801575527		[learning rate: 0.00058607]
	Learning Rate: 0.000586069
	LOSS [training: 0.23766035801575527 | validation: 0.2047977496455943]
	TIME [epoch: 23.8 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24600218493915152		[learning rate: 0.000584]
	Learning Rate: 0.000583996
	LOSS [training: 0.24600218493915152 | validation: 0.20931329448706432]
	TIME [epoch: 23.8 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23957565721184115		[learning rate: 0.00058193]
	Learning Rate: 0.000581931
	LOSS [training: 0.23957565721184115 | validation: 0.21148379590479513]
	TIME [epoch: 23.8 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24828199289594657		[learning rate: 0.00057987]
	Learning Rate: 0.000579874
	LOSS [training: 0.24828199289594657 | validation: 0.2078830076914744]
	TIME [epoch: 23.8 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2477262689024724		[learning rate: 0.00057782]
	Learning Rate: 0.000577823
	LOSS [training: 0.2477262689024724 | validation: 0.21307686346771454]
	TIME [epoch: 23.8 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2440570251154014		[learning rate: 0.00057578]
	Learning Rate: 0.00057578
	LOSS [training: 0.2440570251154014 | validation: 0.20147975450520822]
	TIME [epoch: 23.8 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23634438007050432		[learning rate: 0.00057374]
	Learning Rate: 0.000573744
	LOSS [training: 0.23634438007050432 | validation: 0.2016321979577671]
	TIME [epoch: 23.8 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24282589220218653		[learning rate: 0.00057171]
	Learning Rate: 0.000571715
	LOSS [training: 0.24282589220218653 | validation: 0.207140867128827]
	TIME [epoch: 23.8 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24071271121818716		[learning rate: 0.00056969]
	Learning Rate: 0.000569693
	LOSS [training: 0.24071271121818716 | validation: 0.1979554918461417]
	TIME [epoch: 23.8 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24097057474641895		[learning rate: 0.00056768]
	Learning Rate: 0.000567679
	LOSS [training: 0.24097057474641895 | validation: 0.20808728319938882]
	TIME [epoch: 23.8 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2496495515111031		[learning rate: 0.00056567]
	Learning Rate: 0.000565671
	LOSS [training: 0.2496495515111031 | validation: 0.20478026872725402]
	TIME [epoch: 23.8 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24690354792203428		[learning rate: 0.00056367]
	Learning Rate: 0.000563671
	LOSS [training: 0.24690354792203428 | validation: 0.20379435045934588]
	TIME [epoch: 23.8 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2420540231864937		[learning rate: 0.00056168]
	Learning Rate: 0.000561678
	LOSS [training: 0.2420540231864937 | validation: 0.20751326019660676]
	TIME [epoch: 23.8 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24339102454353947		[learning rate: 0.00055969]
	Learning Rate: 0.000559692
	LOSS [training: 0.24339102454353947 | validation: 0.2077529850724975]
	TIME [epoch: 23.8 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23655866368681044		[learning rate: 0.00055771]
	Learning Rate: 0.000557712
	LOSS [training: 0.23655866368681044 | validation: 0.20951050058419315]
	TIME [epoch: 23.9 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24930009089308106		[learning rate: 0.00055574]
	Learning Rate: 0.00055574
	LOSS [training: 0.24930009089308106 | validation: 0.20336075501801082]
	TIME [epoch: 23.8 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2408895967767778		[learning rate: 0.00055377]
	Learning Rate: 0.000553775
	LOSS [training: 0.2408895967767778 | validation: 0.21198838665613762]
	TIME [epoch: 23.8 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2432125524567799		[learning rate: 0.00055182]
	Learning Rate: 0.000551817
	LOSS [training: 0.2432125524567799 | validation: 0.20493126763058767]
	TIME [epoch: 23.8 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2395353549486546		[learning rate: 0.00054987]
	Learning Rate: 0.000549865
	LOSS [training: 0.2395353549486546 | validation: 0.20042219975833991]
	TIME [epoch: 23.8 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24225949771239189		[learning rate: 0.00054792]
	Learning Rate: 0.000547921
	LOSS [training: 0.24225949771239189 | validation: 0.20299327216930324]
	TIME [epoch: 23.8 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23685838552399474		[learning rate: 0.00054598]
	Learning Rate: 0.000545983
	LOSS [training: 0.23685838552399474 | validation: 0.20915700656618066]
	TIME [epoch: 23.8 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24372042346474895		[learning rate: 0.00054405]
	Learning Rate: 0.000544053
	LOSS [training: 0.24372042346474895 | validation: 0.20389877990197403]
	TIME [epoch: 23.8 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2458100878591102		[learning rate: 0.00054213]
	Learning Rate: 0.000542129
	LOSS [training: 0.2458100878591102 | validation: 0.21140300151537184]
	TIME [epoch: 23.8 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23984244883155093		[learning rate: 0.00054021]
	Learning Rate: 0.000540212
	LOSS [training: 0.23984244883155093 | validation: 0.20576587395889484]
	TIME [epoch: 23.9 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23978175188005083		[learning rate: 0.0005383]
	Learning Rate: 0.000538302
	LOSS [training: 0.23978175188005083 | validation: 0.20622775839844637]
	TIME [epoch: 23.8 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23847970339609048		[learning rate: 0.0005364]
	Learning Rate: 0.000536398
	LOSS [training: 0.23847970339609048 | validation: 0.21051954486812843]
	TIME [epoch: 23.8 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24084341335545986		[learning rate: 0.0005345]
	Learning Rate: 0.000534501
	LOSS [training: 0.24084341335545986 | validation: 0.20277814022912777]
	TIME [epoch: 23.8 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24528368272334558		[learning rate: 0.00053261]
	Learning Rate: 0.000532611
	LOSS [training: 0.24528368272334558 | validation: 0.20836654383886039]
	TIME [epoch: 23.8 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23484802677239994		[learning rate: 0.00053073]
	Learning Rate: 0.000530728
	LOSS [training: 0.23484802677239994 | validation: 0.20706823456158596]
	TIME [epoch: 23.8 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2475824752738255		[learning rate: 0.00052885]
	Learning Rate: 0.000528851
	LOSS [training: 0.2475824752738255 | validation: 0.20909601921843998]
	TIME [epoch: 23.8 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2436405397526791		[learning rate: 0.00052698]
	Learning Rate: 0.000526981
	LOSS [training: 0.2436405397526791 | validation: 0.20183309056671161]
	TIME [epoch: 23.8 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23616924909372053		[learning rate: 0.00052512]
	Learning Rate: 0.000525117
	LOSS [training: 0.23616924909372053 | validation: 0.21111186790666112]
	TIME [epoch: 23.8 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24457905620038403		[learning rate: 0.00052326]
	Learning Rate: 0.000523261
	LOSS [training: 0.24457905620038403 | validation: 0.20357328598352425]
	TIME [epoch: 23.8 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24865805148757292		[learning rate: 0.00052141]
	Learning Rate: 0.00052141
	LOSS [training: 0.24865805148757292 | validation: 0.20939294198447014]
	TIME [epoch: 23.8 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23706135994112454		[learning rate: 0.00051957]
	Learning Rate: 0.000519566
	LOSS [training: 0.23706135994112454 | validation: 0.2033197951768999]
	TIME [epoch: 23.8 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2369562960427112		[learning rate: 0.00051773]
	Learning Rate: 0.000517729
	LOSS [training: 0.2369562960427112 | validation: 0.20180001385356325]
	TIME [epoch: 23.8 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24758298808749676		[learning rate: 0.0005159]
	Learning Rate: 0.000515898
	LOSS [training: 0.24758298808749676 | validation: 0.20801066388436937]
	TIME [epoch: 23.8 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24464530857628697		[learning rate: 0.00051407]
	Learning Rate: 0.000514074
	LOSS [training: 0.24464530857628697 | validation: 0.20264973990715865]
	TIME [epoch: 23.8 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24094794412668483		[learning rate: 0.00051226]
	Learning Rate: 0.000512256
	LOSS [training: 0.24094794412668483 | validation: 0.20998009426372954]
	TIME [epoch: 23.9 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2444106851983732		[learning rate: 0.00051044]
	Learning Rate: 0.000510445
	LOSS [training: 0.2444106851983732 | validation: 0.204774737935638]
	TIME [epoch: 23.8 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24229481256516783		[learning rate: 0.00050864]
	Learning Rate: 0.00050864
	LOSS [training: 0.24229481256516783 | validation: 0.20068728612329273]
	TIME [epoch: 23.8 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24280922108180283		[learning rate: 0.00050684]
	Learning Rate: 0.000506841
	LOSS [training: 0.24280922108180283 | validation: 0.2005643581699962]
	TIME [epoch: 23.8 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2414169409936323		[learning rate: 0.00050505]
	Learning Rate: 0.000505049
	LOSS [training: 0.2414169409936323 | validation: 0.20364893165921744]
	TIME [epoch: 23.9 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.244847135710909		[learning rate: 0.00050326]
	Learning Rate: 0.000503263
	LOSS [training: 0.244847135710909 | validation: 0.20729379903330739]
	TIME [epoch: 23.8 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23881100786178303		[learning rate: 0.00050148]
	Learning Rate: 0.000501483
	LOSS [training: 0.23881100786178303 | validation: 0.19934614407710077]
	TIME [epoch: 23.8 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24573776238964584		[learning rate: 0.00049971]
	Learning Rate: 0.00049971
	LOSS [training: 0.24573776238964584 | validation: 0.2059829479063032]
	TIME [epoch: 23.8 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2393800671490437		[learning rate: 0.00049794]
	Learning Rate: 0.000497943
	LOSS [training: 0.2393800671490437 | validation: 0.20029758522848162]
	TIME [epoch: 23.8 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24297804035740547		[learning rate: 0.00049618]
	Learning Rate: 0.000496182
	LOSS [training: 0.24297804035740547 | validation: 0.1988127676936788]
	TIME [epoch: 23.8 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2450427577445851		[learning rate: 0.00049443]
	Learning Rate: 0.000494427
	LOSS [training: 0.2450427577445851 | validation: 0.20568204128382553]
	TIME [epoch: 23.9 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2449552446693791		[learning rate: 0.00049268]
	Learning Rate: 0.000492679
	LOSS [training: 0.2449552446693791 | validation: 0.2074556249709461]
	TIME [epoch: 23.8 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24257595096967668		[learning rate: 0.00049094]
	Learning Rate: 0.000490937
	LOSS [training: 0.24257595096967668 | validation: 0.21414818121018125]
	TIME [epoch: 23.8 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24696809775301698		[learning rate: 0.0004892]
	Learning Rate: 0.000489201
	LOSS [training: 0.24696809775301698 | validation: 0.21045893817753622]
	TIME [epoch: 23.8 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23806483914057616		[learning rate: 0.00048747]
	Learning Rate: 0.000487471
	LOSS [training: 0.23806483914057616 | validation: 0.2051978962403708]
	TIME [epoch: 23.8 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2438546496173599		[learning rate: 0.00048575]
	Learning Rate: 0.000485747
	LOSS [training: 0.2438546496173599 | validation: 0.19975622073147598]
	TIME [epoch: 23.8 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2412978280337241		[learning rate: 0.00048403]
	Learning Rate: 0.000484029
	LOSS [training: 0.2412978280337241 | validation: 0.19964056458097204]
	TIME [epoch: 23.8 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24267655482765083		[learning rate: 0.00048232]
	Learning Rate: 0.000482318
	LOSS [training: 0.24267655482765083 | validation: 0.20650762990781227]
	TIME [epoch: 23.8 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24010426209713964		[learning rate: 0.00048061]
	Learning Rate: 0.000480612
	LOSS [training: 0.24010426209713964 | validation: 0.20880735600856842]
	TIME [epoch: 23.8 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24020156287472605		[learning rate: 0.00047891]
	Learning Rate: 0.000478913
	LOSS [training: 0.24020156287472605 | validation: 0.21441145959124847]
	TIME [epoch: 23.8 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2369747292873792		[learning rate: 0.00047722]
	Learning Rate: 0.000477219
	LOSS [training: 0.2369747292873792 | validation: 0.20239741633483926]
	TIME [epoch: 23.8 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24274068196928963		[learning rate: 0.00047553]
	Learning Rate: 0.000475532
	LOSS [training: 0.24274068196928963 | validation: 0.21241391823286157]
	TIME [epoch: 23.8 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23915337501079126		[learning rate: 0.00047385]
	Learning Rate: 0.00047385
	LOSS [training: 0.23915337501079126 | validation: 0.2121334361215162]
	TIME [epoch: 23.8 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23206164877863275		[learning rate: 0.00047217]
	Learning Rate: 0.000472175
	LOSS [training: 0.23206164877863275 | validation: 0.2050711126185083]
	TIME [epoch: 23.8 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23977800579043		[learning rate: 0.0004705]
	Learning Rate: 0.000470505
	LOSS [training: 0.23977800579043 | validation: 0.2119984988945033]
	TIME [epoch: 23.8 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24633530315855615		[learning rate: 0.00046884]
	Learning Rate: 0.000468841
	LOSS [training: 0.24633530315855615 | validation: 0.19705748665997674]
	TIME [epoch: 23.8 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2516552343002574		[learning rate: 0.00046718]
	Learning Rate: 0.000467183
	LOSS [training: 0.2516552343002574 | validation: 0.21352574952260625]
	TIME [epoch: 23.9 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24491264125853815		[learning rate: 0.00046553]
	Learning Rate: 0.000465531
	LOSS [training: 0.24491264125853815 | validation: 0.21019375586328368]
	TIME [epoch: 23.8 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24428129313576127		[learning rate: 0.00046388]
	Learning Rate: 0.000463885
	LOSS [training: 0.24428129313576127 | validation: 0.21068315147788708]
	TIME [epoch: 23.8 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23697886584800262		[learning rate: 0.00046224]
	Learning Rate: 0.000462245
	LOSS [training: 0.23697886584800262 | validation: 0.20780152356354925]
	TIME [epoch: 23.8 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24917718753467558		[learning rate: 0.00046061]
	Learning Rate: 0.00046061
	LOSS [training: 0.24917718753467558 | validation: 0.19994784620131884]
	TIME [epoch: 23.8 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24546851972126685		[learning rate: 0.00045898]
	Learning Rate: 0.000458981
	LOSS [training: 0.24546851972126685 | validation: 0.20593006045952417]
	TIME [epoch: 23.8 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23940525522612288		[learning rate: 0.00045736]
	Learning Rate: 0.000457358
	LOSS [training: 0.23940525522612288 | validation: 0.2036810448666982]
	TIME [epoch: 23.8 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24298592278322473		[learning rate: 0.00045574]
	Learning Rate: 0.000455741
	LOSS [training: 0.24298592278322473 | validation: 0.2142540084593935]
	TIME [epoch: 23.8 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24062282205773186		[learning rate: 0.00045413]
	Learning Rate: 0.000454129
	LOSS [training: 0.24062282205773186 | validation: 0.215175853870269]
	TIME [epoch: 23.8 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24640105193810313		[learning rate: 0.00045252]
	Learning Rate: 0.000452523
	LOSS [training: 0.24640105193810313 | validation: 0.2149326356694011]
	TIME [epoch: 23.8 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24237861440254174		[learning rate: 0.00045092]
	Learning Rate: 0.000450923
	LOSS [training: 0.24237861440254174 | validation: 0.20563785286452374]
	TIME [epoch: 23.8 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24070100402991845		[learning rate: 0.00044933]
	Learning Rate: 0.000449329
	LOSS [training: 0.24070100402991845 | validation: 0.21056202635004517]
	TIME [epoch: 23.8 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24656447320545594		[learning rate: 0.00044774]
	Learning Rate: 0.00044774
	LOSS [training: 0.24656447320545594 | validation: 0.21275305284154414]
	TIME [epoch: 23.8 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2421542574081932		[learning rate: 0.00044616]
	Learning Rate: 0.000446156
	LOSS [training: 0.2421542574081932 | validation: 0.2027701645338588]
	TIME [epoch: 23.8 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2464971454252245		[learning rate: 0.00044458]
	Learning Rate: 0.000444579
	LOSS [training: 0.2464971454252245 | validation: 0.209351520779801]
	TIME [epoch: 23.8 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24122269618992895		[learning rate: 0.00044301]
	Learning Rate: 0.000443007
	LOSS [training: 0.24122269618992895 | validation: 0.20991222264390014]
	TIME [epoch: 23.8 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24012736961021022		[learning rate: 0.00044144]
	Learning Rate: 0.00044144
	LOSS [training: 0.24012736961021022 | validation: 0.20661436953537443]
	TIME [epoch: 23.9 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2451149717138992		[learning rate: 0.00043988]
	Learning Rate: 0.000439879
	LOSS [training: 0.2451149717138992 | validation: 0.21349786466546225]
	TIME [epoch: 23.8 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23567737083301088		[learning rate: 0.00043832]
	Learning Rate: 0.000438324
	LOSS [training: 0.23567737083301088 | validation: 0.20970518580757025]
	TIME [epoch: 23.8 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24102459007459828		[learning rate: 0.00043677]
	Learning Rate: 0.000436774
	LOSS [training: 0.24102459007459828 | validation: 0.2162276964431809]
	TIME [epoch: 23.8 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23832240049677747		[learning rate: 0.00043523]
	Learning Rate: 0.000435229
	LOSS [training: 0.23832240049677747 | validation: 0.20917607976156863]
	TIME [epoch: 23.8 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23531801010788952		[learning rate: 0.00043369]
	Learning Rate: 0.00043369
	LOSS [training: 0.23531801010788952 | validation: 0.20405863890363993]
	TIME [epoch: 23.8 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24345866399432378		[learning rate: 0.00043216]
	Learning Rate: 0.000432156
	LOSS [training: 0.24345866399432378 | validation: 0.20510953324605713]
	TIME [epoch: 23.8 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24542594140957896		[learning rate: 0.00043063]
	Learning Rate: 0.000430628
	LOSS [training: 0.24542594140957896 | validation: 0.22030527909622633]
	TIME [epoch: 23.9 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2405983795286524		[learning rate: 0.00042911]
	Learning Rate: 0.000429106
	LOSS [training: 0.2405983795286524 | validation: 0.20530164823379887]
	TIME [epoch: 23.8 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24661086809799426		[learning rate: 0.00042759]
	Learning Rate: 0.000427588
	LOSS [training: 0.24661086809799426 | validation: 0.2094660399181186]
	TIME [epoch: 23.8 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24515860176686557		[learning rate: 0.00042608]
	Learning Rate: 0.000426076
	LOSS [training: 0.24515860176686557 | validation: 0.21066563445401765]
	TIME [epoch: 23.8 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24112164616126655		[learning rate: 0.00042457]
	Learning Rate: 0.000424569
	LOSS [training: 0.24112164616126655 | validation: 0.20876013479176816]
	TIME [epoch: 23.8 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24113322688553906		[learning rate: 0.00042307]
	Learning Rate: 0.000423068
	LOSS [training: 0.24113322688553906 | validation: 0.2093959083156399]
	TIME [epoch: 23.8 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24071439813959583		[learning rate: 0.00042157]
	Learning Rate: 0.000421572
	LOSS [training: 0.24071439813959583 | validation: 0.20747235003612122]
	TIME [epoch: 23.8 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2395018320705091		[learning rate: 0.00042008]
	Learning Rate: 0.000420081
	LOSS [training: 0.2395018320705091 | validation: 0.21149560307630838]
	TIME [epoch: 23.8 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24472765631860516		[learning rate: 0.0004186]
	Learning Rate: 0.000418596
	LOSS [training: 0.24472765631860516 | validation: 0.21092114024753433]
	TIME [epoch: 23.8 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2415114431502463		[learning rate: 0.00041712]
	Learning Rate: 0.000417116
	LOSS [training: 0.2415114431502463 | validation: 0.21494140311442642]
	TIME [epoch: 23.8 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24689651353228362		[learning rate: 0.00041564]
	Learning Rate: 0.000415641
	LOSS [training: 0.24689651353228362 | validation: 0.20298737528611968]
	TIME [epoch: 23.8 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23286596183084304		[learning rate: 0.00041417]
	Learning Rate: 0.000414171
	LOSS [training: 0.23286596183084304 | validation: 0.2024533645683224]
	TIME [epoch: 23.8 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23964480996681534		[learning rate: 0.00041271]
	Learning Rate: 0.000412706
	LOSS [training: 0.23964480996681534 | validation: 0.21058460836729492]
	TIME [epoch: 23.8 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23996851817909315		[learning rate: 0.00041125]
	Learning Rate: 0.000411247
	LOSS [training: 0.23996851817909315 | validation: 0.2084958829179599]
	TIME [epoch: 23.9 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24100476989835162		[learning rate: 0.00040979]
	Learning Rate: 0.000409793
	LOSS [training: 0.24100476989835162 | validation: 0.2073581071674504]
	TIME [epoch: 23.8 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24028895575619993		[learning rate: 0.00040834]
	Learning Rate: 0.000408344
	LOSS [training: 0.24028895575619993 | validation: 0.2059653748859597]
	TIME [epoch: 23.8 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.25065204087205767		[learning rate: 0.0004069]
	Learning Rate: 0.0004069
	LOSS [training: 0.25065204087205767 | validation: 0.2118070180315475]
	TIME [epoch: 23.8 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24394374865337898		[learning rate: 0.00040546]
	Learning Rate: 0.000405461
	LOSS [training: 0.24394374865337898 | validation: 0.21436167793890712]
	TIME [epoch: 23.8 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23872166088753122		[learning rate: 0.00040403]
	Learning Rate: 0.000404027
	LOSS [training: 0.23872166088753122 | validation: 0.2108016837942194]
	TIME [epoch: 23.8 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23777171136048333		[learning rate: 0.0004026]
	Learning Rate: 0.000402598
	LOSS [training: 0.23777171136048333 | validation: 0.2002722296402218]
	TIME [epoch: 23.8 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24494503901071027		[learning rate: 0.00040117]
	Learning Rate: 0.000401175
	LOSS [training: 0.24494503901071027 | validation: 0.20127491098532252]
	TIME [epoch: 23.8 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.242901326376876		[learning rate: 0.00039976]
	Learning Rate: 0.000399756
	LOSS [training: 0.242901326376876 | validation: 0.21104876209828927]
	TIME [epoch: 23.8 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23834275232678656		[learning rate: 0.00039834]
	Learning Rate: 0.000398342
	LOSS [training: 0.23834275232678656 | validation: 0.21014769528478125]
	TIME [epoch: 23.8 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23986556272339446		[learning rate: 0.00039693]
	Learning Rate: 0.000396934
	LOSS [training: 0.23986556272339446 | validation: 0.20813631381164543]
	TIME [epoch: 23.8 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24224537933803017		[learning rate: 0.00039553]
	Learning Rate: 0.00039553
	LOSS [training: 0.24224537933803017 | validation: 0.20894780157933468]
	TIME [epoch: 23.8 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2438260836260555		[learning rate: 0.00039413]
	Learning Rate: 0.000394131
	LOSS [training: 0.2438260836260555 | validation: 0.20470357359000396]
	TIME [epoch: 23.8 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24267769761795258		[learning rate: 0.00039274]
	Learning Rate: 0.000392738
	LOSS [training: 0.24267769761795258 | validation: 0.20381477102521445]
	TIME [epoch: 23.8 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23765602850691167		[learning rate: 0.00039135]
	Learning Rate: 0.000391349
	LOSS [training: 0.23765602850691167 | validation: 0.21768513326766126]
	TIME [epoch: 23.8 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24258405507806943		[learning rate: 0.00038997]
	Learning Rate: 0.000389965
	LOSS [training: 0.24258405507806943 | validation: 0.20677540452653434]
	TIME [epoch: 23.8 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23898987038968755		[learning rate: 0.00038859]
	Learning Rate: 0.000388586
	LOSS [training: 0.23898987038968755 | validation: 0.21269514927280014]
	TIME [epoch: 23.8 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24179730056171891		[learning rate: 0.00038721]
	Learning Rate: 0.000387212
	LOSS [training: 0.24179730056171891 | validation: 0.20000404760871313]
	TIME [epoch: 23.9 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.22976455108802377		[learning rate: 0.00038584]
	Learning Rate: 0.000385843
	LOSS [training: 0.22976455108802377 | validation: 0.20614783519115748]
	TIME [epoch: 23.8 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2403646983339455		[learning rate: 0.00038448]
	Learning Rate: 0.000384478
	LOSS [training: 0.2403646983339455 | validation: 0.20556316204311886]
	TIME [epoch: 23.8 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2337312521127527		[learning rate: 0.00038312]
	Learning Rate: 0.000383119
	LOSS [training: 0.2337312521127527 | validation: 0.19958155325374202]
	TIME [epoch: 23.9 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2407627542128797		[learning rate: 0.00038176]
	Learning Rate: 0.000381764
	LOSS [training: 0.2407627542128797 | validation: 0.2043748102154649]
	TIME [epoch: 23.8 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24294460039383334		[learning rate: 0.00038041]
	Learning Rate: 0.000380414
	LOSS [training: 0.24294460039383334 | validation: 0.21127869604935445]
	TIME [epoch: 23.8 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23909629801920254		[learning rate: 0.00037907]
	Learning Rate: 0.000379069
	LOSS [training: 0.23909629801920254 | validation: 0.20163459560531427]
	TIME [epoch: 23.8 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24074633628101103		[learning rate: 0.00037773]
	Learning Rate: 0.000377728
	LOSS [training: 0.24074633628101103 | validation: 0.20953694878188384]
	TIME [epoch: 23.8 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24363563779353514		[learning rate: 0.00037639]
	Learning Rate: 0.000376393
	LOSS [training: 0.24363563779353514 | validation: 0.20466939415831825]
	TIME [epoch: 23.8 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24225429069342885		[learning rate: 0.00037506]
	Learning Rate: 0.000375062
	LOSS [training: 0.24225429069342885 | validation: 0.20524115289497766]
	TIME [epoch: 23.8 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2450313684603863		[learning rate: 0.00037374]
	Learning Rate: 0.000373735
	LOSS [training: 0.2450313684603863 | validation: 0.20971160951864407]
	TIME [epoch: 23.8 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2438472251646054		[learning rate: 0.00037241]
	Learning Rate: 0.000372414
	LOSS [training: 0.2438472251646054 | validation: 0.20840498586247555]
	TIME [epoch: 23.8 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23657386915162468		[learning rate: 0.0003711]
	Learning Rate: 0.000371097
	LOSS [training: 0.23657386915162468 | validation: 0.2070084014672283]
	TIME [epoch: 23.8 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24208549623009734		[learning rate: 0.00036978]
	Learning Rate: 0.000369785
	LOSS [training: 0.24208549623009734 | validation: 0.2088165211167295]
	TIME [epoch: 23.8 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2401029339711075		[learning rate: 0.00036848]
	Learning Rate: 0.000368477
	LOSS [training: 0.2401029339711075 | validation: 0.2039931167643975]
	TIME [epoch: 23.8 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23920904309924193		[learning rate: 0.00036717]
	Learning Rate: 0.000367174
	LOSS [training: 0.23920904309924193 | validation: 0.2080726219237004]
	TIME [epoch: 23.9 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24289515067958722		[learning rate: 0.00036588]
	Learning Rate: 0.000365875
	LOSS [training: 0.24289515067958722 | validation: 0.2063735708340944]
	TIME [epoch: 23.8 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2376383614560633		[learning rate: 0.00036458]
	Learning Rate: 0.000364582
	LOSS [training: 0.2376383614560633 | validation: 0.2050766544391454]
	TIME [epoch: 23.8 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24172823227221493		[learning rate: 0.00036329]
	Learning Rate: 0.000363293
	LOSS [training: 0.24172823227221493 | validation: 0.21165586523557067]
	TIME [epoch: 23.8 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.2421784993899142		[learning rate: 0.00036201]
	Learning Rate: 0.000362008
	LOSS [training: 0.2421784993899142 | validation: 0.21217518493557247]
	TIME [epoch: 23.8 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24065689011421987		[learning rate: 0.00036073]
	Learning Rate: 0.000360728
	LOSS [training: 0.24065689011421987 | validation: 0.2148852528153423]
	TIME [epoch: 23.8 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.24691327064450241		[learning rate: 0.00035945]
	Learning Rate: 0.000359452
	LOSS [training: 0.24691327064450241 | validation: 0.20616224661986884]
	TIME [epoch: 23.8 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 6/6] avg loss: 0.23611750240262894		[learning rate: 0.00035818]
	Learning Rate: 0.000358181
	LOSS [training: 0.23611750240262894 | validation: 0.20960278899008794]
	TIME [epoch: 23.8 sec]
	Saving model to: out/model_training/model_facs_v3_dec1b_2dpca_v14_20240716_142138/states/model_facs_v3_dec1b_2dpca_v14_990.pth
Halted early. No improvement in validation loss for 200 epochs.
Finished training in 17160.832 seconds.
