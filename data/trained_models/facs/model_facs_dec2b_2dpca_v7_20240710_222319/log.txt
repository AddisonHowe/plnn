Args:
Namespace(name='model_facs_dec2b_2dpca_v7', outdir='out/model_training/model_facs_dec2b_2dpca_v7', training_data='data/training_data/facs/pca/dec2_fitonsubset/transition2_subset_ce_pn_m_pc12/training', validation_data='data/training_data/facs/pca/dec2_fitonsubset/transition2_subset_ce_pn_m_pc12/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=10, batch_size=50, patience=200, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=200, ncells_sample=200, model_do_sample=False, dt=0.005, dt_schedule='stepped', dt_schedule_bounds=[500, 1000, 1500], dt_schedule_scales=[0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=True, sigma=0.02, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', kernel='multiscale', bw_range=[0.2, 0.5, 0.9, 1.1, 1.3, 1.5, 2.0], optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 4218128465

Training model...

Saving initial model state to: out/model_training/model_facs_dec2b_2dpca_v7_20240710_222319/states/model_facs_dec2b_2dpca_v7_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9402346784127683		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9402346784127683 | validation: 0.8289305311682568]
	TIME [epoch: 34.7 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v7_20240710_222319/states/model_facs_dec2b_2dpca_v7_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6351490480978095		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6351490480978095 | validation: 0.7563137196910517]
	TIME [epoch: 4.73 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v7_20240710_222319/states/model_facs_dec2b_2dpca_v7_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6156476200635419		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6156476200635419 | validation: 0.8021636463262648]
	TIME [epoch: 4.71 sec]
EPOCH 4/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5758321677423234		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5758321677423234 | validation: 0.7225647549545124]
	TIME [epoch: 4.71 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v7_20240710_222319/states/model_facs_dec2b_2dpca_v7_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5174649915577569		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5174649915577569 | validation: 0.7133501995457354]
	TIME [epoch: 4.71 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v7_20240710_222319/states/model_facs_dec2b_2dpca_v7_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6078050002353781		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6078050002353781 | validation: 0.7189515246756482]
	TIME [epoch: 4.71 sec]
EPOCH 7/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5066994597978413		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5066994597978413 | validation: 0.6883629520791363]
	TIME [epoch: 4.71 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v7_20240710_222319/states/model_facs_dec2b_2dpca_v7_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.49563769907898614		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.49563769907898614 | validation: 0.6458967011310802]
	TIME [epoch: 4.71 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v7_20240710_222319/states/model_facs_dec2b_2dpca_v7_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4956511674981548		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4956511674981548 | validation: 0.6808985521622741]
	TIME [epoch: 4.72 sec]
EPOCH 10/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4794239846363495		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4794239846363495 | validation: 0.6051742888467116]
	TIME [epoch: 4.71 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v7_20240710_222319/states/model_facs_dec2b_2dpca_v7_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4617595542524887		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4617595542524887 | validation: 0.5921692688898976]
	TIME [epoch: 4.71 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v7_20240710_222319/states/model_facs_dec2b_2dpca_v7_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3791014114994736		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3791014114994736 | validation: 0.563630198588071]
	TIME [epoch: 4.71 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v7_20240710_222319/states/model_facs_dec2b_2dpca_v7_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48901060495043647		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.48901060495043647 | validation: 0.5355954414099773]
	TIME [epoch: 4.71 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v7_20240710_222319/states/model_facs_dec2b_2dpca_v7_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3145104793188455		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3145104793188455 | validation: 0.49735323453439906]
	TIME [epoch: 4.71 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v7_20240710_222319/states/model_facs_dec2b_2dpca_v7_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33150093068671127		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.33150093068671127 | validation: 0.6787421823290266]
	TIME [epoch: 4.71 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40611945486522927		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.40611945486522927 | validation: 0.48025431965577603]
	TIME [epoch: 4.71 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v7_20240710_222319/states/model_facs_dec2b_2dpca_v7_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3054787484607473		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3054787484607473 | validation: 0.5759643995557816]
	TIME [epoch: 4.7 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3909318600741593		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3909318600741593 | validation: 0.5714136519451507]
	TIME [epoch: 4.7 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3674813072172227		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3674813072172227 | validation: 0.5312132517952907]
	TIME [epoch: 4.73 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32681730750196303		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.32681730750196303 | validation: 0.5178547567772562]
	TIME [epoch: 4.7 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3327009120555759		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3327009120555759 | validation: 0.4427003578545638]
	TIME [epoch: 4.71 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v7_20240710_222319/states/model_facs_dec2b_2dpca_v7_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2959261376886958		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2959261376886958 | validation: 0.45494003134599736]
	TIME [epoch: 4.72 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3128219170945012		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3128219170945012 | validation: 0.5199036194522751]
	TIME [epoch: 4.7 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3187925453904297		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3187925453904297 | validation: 0.4246349450432413]
	TIME [epoch: 4.71 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v7_20240710_222319/states/model_facs_dec2b_2dpca_v7_24.pth
	Model improved!!!
EPOCH 25/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28377325985199536		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.28377325985199536 | validation: 0.5865297993671595]
	TIME [epoch: 4.71 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2955824372530593		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2955824372530593 | validation: 0.4258784958143138]
	TIME [epoch: 4.7 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.293461047533272		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.293461047533272 | validation: 0.5125910546363649]
	TIME [epoch: 4.7 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2891434392811212		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2891434392811212 | validation: 0.4217402357067359]
	TIME [epoch: 4.71 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v7_20240710_222319/states/model_facs_dec2b_2dpca_v7_28.pth
	Model improved!!!
EPOCH 29/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2526597606087986		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2526597606087986 | validation: 0.43976695144608224]
	TIME [epoch: 4.7 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28549681277607064		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.28549681277607064 | validation: 0.4568672266085514]
	TIME [epoch: 4.69 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28197423385586023		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.28197423385586023 | validation: 0.4997389827457868]
	TIME [epoch: 4.72 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2900849327100191		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2900849327100191 | validation: 0.4789477000482172]
	TIME [epoch: 4.74 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2746996075187141		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2746996075187141 | validation: 0.44223659811130694]
	TIME [epoch: 4.69 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2719525236586978		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2719525236586978 | validation: 0.41076549733223566]
	TIME [epoch: 4.69 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v7_20240710_222319/states/model_facs_dec2b_2dpca_v7_34.pth
	Model improved!!!
EPOCH 35/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23892349153262438		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23892349153262438 | validation: 0.4040538821850763]
	TIME [epoch: 4.72 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v7_20240710_222319/states/model_facs_dec2b_2dpca_v7_35.pth
	Model improved!!!
EPOCH 36/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2428961288775798		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2428961288775798 | validation: 0.5879160100234435]
	TIME [epoch: 4.71 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4389298163943451		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4389298163943451 | validation: 0.5387579572933899]
	TIME [epoch: 4.72 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3326554400918325		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3326554400918325 | validation: 0.562349498924774]
	TIME [epoch: 4.71 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29652384977628593		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.29652384977628593 | validation: 0.43376437382120014]
	TIME [epoch: 4.72 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2753133448843732		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2753133448843732 | validation: 0.43823308722760507]
	TIME [epoch: 4.73 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34202139589457636		[learning rate: 0.0099646]
	Learning Rate: 0.00996464
	LOSS [training: 0.34202139589457636 | validation: 0.504478305592537]
	TIME [epoch: 4.71 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2652736850798843		[learning rate: 0.0099206]
	Learning Rate: 0.00992061
	LOSS [training: 0.2652736850798843 | validation: 0.41342624010085993]
	TIME [epoch: 4.7 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2530818908946457		[learning rate: 0.0098768]
	Learning Rate: 0.00987678
	LOSS [training: 0.2530818908946457 | validation: 0.44711166228170424]
	TIME [epoch: 4.69 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2774810731312739		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 0.2774810731312739 | validation: 0.4610811941790046]
	TIME [epoch: 4.71 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2600071088919666		[learning rate: 0.0097897]
	Learning Rate: 0.0097897
	LOSS [training: 0.2600071088919666 | validation: 0.4205409907380157]
	TIME [epoch: 4.71 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26171145764436676		[learning rate: 0.0097464]
	Learning Rate: 0.00974644
	LOSS [training: 0.26171145764436676 | validation: 0.4621095408837859]
	TIME [epoch: 4.72 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22720009131740548		[learning rate: 0.0097034]
	Learning Rate: 0.00970338
	LOSS [training: 0.22720009131740548 | validation: 0.3912765201766579]
	TIME [epoch: 4.73 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v7_20240710_222319/states/model_facs_dec2b_2dpca_v7_47.pth
	Model improved!!!
EPOCH 48/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2577286816016199		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 0.2577286816016199 | validation: 0.47498575459115455]
	TIME [epoch: 4.71 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26068777044822566		[learning rate: 0.0096178]
	Learning Rate: 0.00961783
	LOSS [training: 0.26068777044822566 | validation: 0.49502794214194207]
	TIME [epoch: 4.71 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2879895296580658		[learning rate: 0.0095753]
	Learning Rate: 0.00957533
	LOSS [training: 0.2879895296580658 | validation: 0.5307314927330419]
	TIME [epoch: 4.72 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2520671658863229		[learning rate: 0.009533]
	Learning Rate: 0.00953303
	LOSS [training: 0.2520671658863229 | validation: 0.4504716671995375]
	TIME [epoch: 4.71 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25106029948538294		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 0.25106029948538294 | validation: 0.3710899248087399]
	TIME [epoch: 4.7 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v7_20240710_222319/states/model_facs_dec2b_2dpca_v7_52.pth
	Model improved!!!
EPOCH 53/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21174787026382766		[learning rate: 0.009449]
	Learning Rate: 0.00944897
	LOSS [training: 0.21174787026382766 | validation: 0.4170348785758974]
	TIME [epoch: 4.71 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21085960094529602		[learning rate: 0.0094072]
	Learning Rate: 0.00940722
	LOSS [training: 0.21085960094529602 | validation: 0.39919292953387475]
	TIME [epoch: 4.7 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31802932673583767		[learning rate: 0.0093657]
	Learning Rate: 0.00936566
	LOSS [training: 0.31802932673583767 | validation: 0.4647754646273491]
	TIME [epoch: 4.7 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24753571024129642		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 0.24753571024129642 | validation: 0.4121073217747445]
	TIME [epoch: 4.7 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2200080331869044		[learning rate: 0.0092831]
	Learning Rate: 0.00928308
	LOSS [training: 0.2200080331869044 | validation: 0.6002540700959157]
	TIME [epoch: 4.7 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2246355493201065		[learning rate: 0.0092421]
	Learning Rate: 0.00924207
	LOSS [training: 0.2246355493201065 | validation: 0.3658673280234904]
	TIME [epoch: 4.7 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v7_20240710_222319/states/model_facs_dec2b_2dpca_v7_58.pth
	Model improved!!!
EPOCH 59/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2413439566882694		[learning rate: 0.0092012]
	Learning Rate: 0.00920124
	LOSS [training: 0.2413439566882694 | validation: 0.3849682070763891]
	TIME [epoch: 4.72 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2023903848661845		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 0.2023903848661845 | validation: 0.35651231826636054]
	TIME [epoch: 4.71 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v7_20240710_222319/states/model_facs_dec2b_2dpca_v7_60.pth
	Model improved!!!
EPOCH 61/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24862730026291352		[learning rate: 0.0091201]
	Learning Rate: 0.00912011
	LOSS [training: 0.24862730026291352 | validation: 0.3805641386742354]
	TIME [epoch: 4.71 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21658407869286922		[learning rate: 0.0090798]
	Learning Rate: 0.00907981
	LOSS [training: 0.21658407869286922 | validation: 0.40554750023950514]
	TIME [epoch: 4.7 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2236764359875211		[learning rate: 0.0090397]
	Learning Rate: 0.0090397
	LOSS [training: 0.2236764359875211 | validation: 0.38947511779505356]
	TIME [epoch: 4.7 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2631603302904878		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 0.2631603302904878 | validation: 0.3566083296241604]
	TIME [epoch: 4.69 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25627565742157926		[learning rate: 0.00896]
	Learning Rate: 0.00895999
	LOSS [training: 0.25627565742157926 | validation: 0.5010943046828418]
	TIME [epoch: 4.7 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33593256305545954		[learning rate: 0.0089204]
	Learning Rate: 0.00892041
	LOSS [training: 0.33593256305545954 | validation: 0.4464904454420377]
	TIME [epoch: 4.7 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2705587806206919		[learning rate: 0.008881]
	Learning Rate: 0.00888099
	LOSS [training: 0.2705587806206919 | validation: 0.39062644544663616]
	TIME [epoch: 4.7 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24755697270981275		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 0.24755697270981275 | validation: 0.47678653847865926]
	TIME [epoch: 4.69 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25672564831774447		[learning rate: 0.0088027]
	Learning Rate: 0.00880269
	LOSS [training: 0.25672564831774447 | validation: 0.3790825968757547]
	TIME [epoch: 4.74 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23500316563900006		[learning rate: 0.0087638]
	Learning Rate: 0.0087638
	LOSS [training: 0.23500316563900006 | validation: 0.3518271605566078]
	TIME [epoch: 4.71 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v7_20240710_222319/states/model_facs_dec2b_2dpca_v7_70.pth
	Model improved!!!
EPOCH 71/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23171132313648993		[learning rate: 0.0087251]
	Learning Rate: 0.00872508
	LOSS [training: 0.23171132313648993 | validation: 0.4461643130000452]
	TIME [epoch: 4.71 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22472543457571548		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 0.22472543457571548 | validation: 0.3527899927808559]
	TIME [epoch: 4.71 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22013391611888172		[learning rate: 0.0086481]
	Learning Rate: 0.00864815
	LOSS [training: 0.22013391611888172 | validation: 0.35023410971731456]
	TIME [epoch: 4.7 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v7_20240710_222319/states/model_facs_dec2b_2dpca_v7_73.pth
	Model improved!!!
EPOCH 74/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35866444431536043		[learning rate: 0.0086099]
	Learning Rate: 0.00860994
	LOSS [training: 0.35866444431536043 | validation: 0.4882097503958015]
	TIME [epoch: 4.7 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32601131987853516		[learning rate: 0.0085719]
	Learning Rate: 0.0085719
	LOSS [training: 0.32601131987853516 | validation: 0.43979213242723936]
	TIME [epoch: 4.71 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2974827578046645		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 0.2974827578046645 | validation: 0.43280479780823905]
	TIME [epoch: 4.7 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23981430184988034		[learning rate: 0.0084963]
	Learning Rate: 0.00849632
	LOSS [training: 0.23981430184988034 | validation: 0.4080975172687682]
	TIME [epoch: 4.7 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2753051401149998		[learning rate: 0.0084588]
	Learning Rate: 0.00845878
	LOSS [training: 0.2753051401149998 | validation: 0.39820726108536814]
	TIME [epoch: 4.72 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.209158322709958		[learning rate: 0.0084214]
	Learning Rate: 0.00842141
	LOSS [training: 0.209158322709958 | validation: 0.3501270447399474]
	TIME [epoch: 4.7 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v7_20240710_222319/states/model_facs_dec2b_2dpca_v7_79.pth
	Model improved!!!
EPOCH 80/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25644688922233294		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 0.25644688922233294 | validation: 0.43475988168038604]
	TIME [epoch: 4.71 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21885747822476853		[learning rate: 0.0083472]
	Learning Rate: 0.00834715
	LOSS [training: 0.21885747822476853 | validation: 0.4461806820450791]
	TIME [epoch: 4.72 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23905239190417693		[learning rate: 0.0083103]
	Learning Rate: 0.00831027
	LOSS [training: 0.23905239190417693 | validation: 0.4138167057288792]
	TIME [epoch: 4.7 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24705316676353783		[learning rate: 0.0082736]
	Learning Rate: 0.00827356
	LOSS [training: 0.24705316676353783 | validation: 0.32273730802392364]
	TIME [epoch: 4.7 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v7_20240710_222319/states/model_facs_dec2b_2dpca_v7_83.pth
	Model improved!!!
EPOCH 84/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20603876373580454		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 0.20603876373580454 | validation: 0.5037910735231254]
	TIME [epoch: 4.73 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22438243818830722		[learning rate: 0.0082006]
	Learning Rate: 0.00820061
	LOSS [training: 0.22438243818830722 | validation: 0.35285196420712184]
	TIME [epoch: 4.7 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21533094232220124		[learning rate: 0.0081644]
	Learning Rate: 0.00816438
	LOSS [training: 0.21533094232220124 | validation: 0.4476835078131175]
	TIME [epoch: 4.7 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24692761858863		[learning rate: 0.0081283]
	Learning Rate: 0.0081283
	LOSS [training: 0.24692761858863 | validation: 0.3538567221100014]
	TIME [epoch: 4.71 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20497821828866258		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 0.20497821828866258 | validation: 0.3824081647678761]
	TIME [epoch: 4.7 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20096609325295045		[learning rate: 0.0080566]
	Learning Rate: 0.00805664
	LOSS [training: 0.20096609325295045 | validation: 0.37785481662661596]
	TIME [epoch: 4.7 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21066062022182477		[learning rate: 0.008021]
	Learning Rate: 0.00802104
	LOSS [training: 0.21066062022182477 | validation: 0.36100187839910614]
	TIME [epoch: 4.72 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1973798050080317		[learning rate: 0.0079856]
	Learning Rate: 0.0079856
	LOSS [training: 0.1973798050080317 | validation: 0.3587448479948072]
	TIME [epoch: 4.72 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21508385897105525		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 0.21508385897105525 | validation: 0.469246975615108]
	TIME [epoch: 4.7 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27297163943116753		[learning rate: 0.0079152]
	Learning Rate: 0.00791519
	LOSS [training: 0.27297163943116753 | validation: 0.37186847843277226]
	TIME [epoch: 4.71 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22694514671375568		[learning rate: 0.0078802]
	Learning Rate: 0.00788022
	LOSS [training: 0.22694514671375568 | validation: 0.364267464941994]
	TIME [epoch: 4.7 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2226754654154382		[learning rate: 0.0078454]
	Learning Rate: 0.00784541
	LOSS [training: 0.2226754654154382 | validation: 0.4053718885740285]
	TIME [epoch: 4.7 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21863354325345466		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 0.21863354325345466 | validation: 0.35207073689430324]
	TIME [epoch: 4.7 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24349024624086688		[learning rate: 0.0077762]
	Learning Rate: 0.00777623
	LOSS [training: 0.24349024624086688 | validation: 0.34955592981879136]
	TIME [epoch: 4.7 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21075399817412066		[learning rate: 0.0077419]
	Learning Rate: 0.00774188
	LOSS [training: 0.21075399817412066 | validation: 0.38319277721710615]
	TIME [epoch: 4.7 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2177477907452691		[learning rate: 0.0077077]
	Learning Rate: 0.00770767
	LOSS [training: 0.2177477907452691 | validation: 0.3993920497155856]
	TIME [epoch: 4.7 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22121214396444472		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 0.22121214396444472 | validation: 0.3300224944375701]
	TIME [epoch: 4.7 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21109888268783933		[learning rate: 0.0076397]
	Learning Rate: 0.00763971
	LOSS [training: 0.21109888268783933 | validation: 0.4065977725030889]
	TIME [epoch: 4.72 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2202431145731229		[learning rate: 0.007606]
	Learning Rate: 0.00760596
	LOSS [training: 0.2202431145731229 | validation: 0.3268924523469015]
	TIME [epoch: 4.71 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22201234057477165		[learning rate: 0.0075724]
	Learning Rate: 0.00757235
	LOSS [training: 0.22201234057477165 | validation: 0.33032125794899736]
	TIME [epoch: 4.71 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20935017597856537		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 0.20935017597856537 | validation: 0.3323109657349794]
	TIME [epoch: 4.7 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21129931872394553		[learning rate: 0.0075056]
	Learning Rate: 0.00750559
	LOSS [training: 0.21129931872394553 | validation: 0.3309678424377153]
	TIME [epoch: 4.7 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2122875890656938		[learning rate: 0.0074724]
	Learning Rate: 0.00747242
	LOSS [training: 0.2122875890656938 | validation: 0.3714670333682969]
	TIME [epoch: 4.7 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20881311786012652		[learning rate: 0.0074394]
	Learning Rate: 0.00743941
	LOSS [training: 0.20881311786012652 | validation: 0.3797498951282827]
	TIME [epoch: 4.7 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22967376236392525		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 0.22967376236392525 | validation: 0.34207830161993213]
	TIME [epoch: 4.7 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22371881916933084		[learning rate: 0.0073738]
	Learning Rate: 0.00737382
	LOSS [training: 0.22371881916933084 | validation: 0.42324099411959215]
	TIME [epoch: 4.71 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2365994953119337		[learning rate: 0.0073412]
	Learning Rate: 0.00734124
	LOSS [training: 0.2365994953119337 | validation: 0.3134962599768385]
	TIME [epoch: 4.7 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v7_20240710_222319/states/model_facs_dec2b_2dpca_v7_110.pth
	Model improved!!!
EPOCH 111/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20931531342827886		[learning rate: 0.0073088]
	Learning Rate: 0.0073088
	LOSS [training: 0.20931531342827886 | validation: 0.34871643357028725]
	TIME [epoch: 4.71 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20524712285867713		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 0.20524712285867713 | validation: 0.38955357720648753]
	TIME [epoch: 4.71 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21069507463608667		[learning rate: 0.0072444]
	Learning Rate: 0.00724436
	LOSS [training: 0.21069507463608667 | validation: 0.36756089025319805]
	TIME [epoch: 4.7 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19555581120830157		[learning rate: 0.0072124]
	Learning Rate: 0.00721235
	LOSS [training: 0.19555581120830157 | validation: 0.4422054013411875]
	TIME [epoch: 4.7 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26570762832598066		[learning rate: 0.0071805]
	Learning Rate: 0.00718049
	LOSS [training: 0.26570762832598066 | validation: 0.35182328518051836]
	TIME [epoch: 4.7 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20728370001573299		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 0.20728370001573299 | validation: 0.3377861403483491]
	TIME [epoch: 4.7 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21023084572738324		[learning rate: 0.0071172]
	Learning Rate: 0.00711718
	LOSS [training: 0.21023084572738324 | validation: 0.3555864282797859]
	TIME [epoch: 4.7 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20954384660666533		[learning rate: 0.0070857]
	Learning Rate: 0.00708573
	LOSS [training: 0.20954384660666533 | validation: 0.35065427627752493]
	TIME [epoch: 4.69 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19364851021940457		[learning rate: 0.0070544]
	Learning Rate: 0.00705442
	LOSS [training: 0.19364851021940457 | validation: 0.32367934634766793]
	TIME [epoch: 4.7 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20857095016569258		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 0.20857095016569258 | validation: 0.37795008990969176]
	TIME [epoch: 4.7 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22287917599429408		[learning rate: 0.0069922]
	Learning Rate: 0.00699222
	LOSS [training: 0.22287917599429408 | validation: 0.3697078579951086]
	TIME [epoch: 4.7 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22107882384359012		[learning rate: 0.0069613]
	Learning Rate: 0.00696133
	LOSS [training: 0.22107882384359012 | validation: 0.33008621969079444]
	TIME [epoch: 4.72 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2009417255945533		[learning rate: 0.0069306]
	Learning Rate: 0.00693057
	LOSS [training: 0.2009417255945533 | validation: 0.43145649539256203]
	TIME [epoch: 4.74 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3141899946352184		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 0.3141899946352184 | validation: 0.3812743984761696]
	TIME [epoch: 4.73 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24756966925954765		[learning rate: 0.0068695]
	Learning Rate: 0.00686947
	LOSS [training: 0.24756966925954765 | validation: 0.3437267963007914]
	TIME [epoch: 4.71 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21987733292657619		[learning rate: 0.0068391]
	Learning Rate: 0.00683912
	LOSS [training: 0.21987733292657619 | validation: 0.31591383594198774]
	TIME [epoch: 4.71 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19231429911062325		[learning rate: 0.0068089]
	Learning Rate: 0.0068089
	LOSS [training: 0.19231429911062325 | validation: 0.3192099617588049]
	TIME [epoch: 4.7 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2082998382619176		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 0.2082998382619176 | validation: 0.4439100724907073]
	TIME [epoch: 4.74 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25606301598394604		[learning rate: 0.0067489]
	Learning Rate: 0.00674887
	LOSS [training: 0.25606301598394604 | validation: 0.386071046537789]
	TIME [epoch: 4.7 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1953688210277854		[learning rate: 0.006719]
	Learning Rate: 0.00671905
	LOSS [training: 0.1953688210277854 | validation: 0.31749933316447376]
	TIME [epoch: 4.72 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21184495494691613		[learning rate: 0.0066894]
	Learning Rate: 0.00668936
	LOSS [training: 0.21184495494691613 | validation: 0.3750414839461606]
	TIME [epoch: 4.72 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19172469132799		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 0.19172469132799 | validation: 0.32463653025686234]
	TIME [epoch: 4.72 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22666492718441988		[learning rate: 0.0066304]
	Learning Rate: 0.00663038
	LOSS [training: 0.22666492718441988 | validation: 0.37602325441157336]
	TIME [epoch: 4.75 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1987142070266077		[learning rate: 0.0066011]
	Learning Rate: 0.00660109
	LOSS [training: 0.1987142070266077 | validation: 0.37334826478774263]
	TIME [epoch: 4.7 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19466658267497974		[learning rate: 0.0065719]
	Learning Rate: 0.00657192
	LOSS [training: 0.19466658267497974 | validation: 0.34452470940113933]
	TIME [epoch: 4.7 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.214220496149858		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 0.214220496149858 | validation: 0.3200650433702803]
	TIME [epoch: 4.72 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20281265352662295		[learning rate: 0.006514]
	Learning Rate: 0.00651398
	LOSS [training: 0.20281265352662295 | validation: 0.36221694295393747]
	TIME [epoch: 4.71 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20353191036369633		[learning rate: 0.0064852]
	Learning Rate: 0.00648519
	LOSS [training: 0.20353191036369633 | validation: 0.36219965515472985]
	TIME [epoch: 4.7 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2066399492430417		[learning rate: 0.0064565]
	Learning Rate: 0.00645654
	LOSS [training: 0.2066399492430417 | validation: 0.36786465167419286]
	TIME [epoch: 4.74 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1876302812985413		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 0.1876302812985413 | validation: 0.3593346591946201]
	TIME [epoch: 4.73 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2045731172792024		[learning rate: 0.0063996]
	Learning Rate: 0.00639961
	LOSS [training: 0.2045731172792024 | validation: 0.3395660355242883]
	TIME [epoch: 4.72 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19254508759712802		[learning rate: 0.0063713]
	Learning Rate: 0.00637134
	LOSS [training: 0.19254508759712802 | validation: 0.3548529439899839]
	TIME [epoch: 4.72 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19517111652572566		[learning rate: 0.0063432]
	Learning Rate: 0.00634319
	LOSS [training: 0.19517111652572566 | validation: 0.3470050353299613]
	TIME [epoch: 4.71 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20498482120752398		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 0.20498482120752398 | validation: 0.32154387574117976]
	TIME [epoch: 4.73 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20714814788621752		[learning rate: 0.0062873]
	Learning Rate: 0.00628726
	LOSS [training: 0.20714814788621752 | validation: 0.33122488755666296]
	TIME [epoch: 4.74 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19464932594791656		[learning rate: 0.0062595]
	Learning Rate: 0.00625948
	LOSS [training: 0.19464932594791656 | validation: 0.3155509443333569]
	TIME [epoch: 4.73 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2024272963642336		[learning rate: 0.0062318]
	Learning Rate: 0.00623183
	LOSS [training: 0.2024272963642336 | validation: 0.3264851238350893]
	TIME [epoch: 4.72 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19282027808682808		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 0.19282027808682808 | validation: 0.33370174322133184]
	TIME [epoch: 4.71 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18074495894478143		[learning rate: 0.0061769]
	Learning Rate: 0.00617688
	LOSS [training: 0.18074495894478143 | validation: 0.3083867951154765]
	TIME [epoch: 4.7 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v7_20240710_222319/states/model_facs_dec2b_2dpca_v7_149.pth
	Model improved!!!
EPOCH 150/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20192100545843933		[learning rate: 0.0061496]
	Learning Rate: 0.00614959
	LOSS [training: 0.20192100545843933 | validation: 0.3373234083227017]
	TIME [epoch: 4.7 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1937513482610908		[learning rate: 0.0061224]
	Learning Rate: 0.00612242
	LOSS [training: 0.1937513482610908 | validation: 0.29715353696806]
	TIME [epoch: 4.74 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v7_20240710_222319/states/model_facs_dec2b_2dpca_v7_151.pth
	Model improved!!!
EPOCH 152/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19619374450577792		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 0.19619374450577792 | validation: 0.3288983382461943]
	TIME [epoch: 4.7 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18181294976674894		[learning rate: 0.0060684]
	Learning Rate: 0.00606844
	LOSS [training: 0.18181294976674894 | validation: 0.4033644352320108]
	TIME [epoch: 4.72 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20118273399890327		[learning rate: 0.0060416]
	Learning Rate: 0.00604163
	LOSS [training: 0.20118273399890327 | validation: 0.3334888618063978]
	TIME [epoch: 4.71 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18073055661040854		[learning rate: 0.0060149]
	Learning Rate: 0.00601493
	LOSS [training: 0.18073055661040854 | validation: 0.3275989929286567]
	TIME [epoch: 4.72 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1837801239066114		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 0.1837801239066114 | validation: 0.3097520397557997]
	TIME [epoch: 4.72 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18030000835122095		[learning rate: 0.0059619]
	Learning Rate: 0.0059619
	LOSS [training: 0.18030000835122095 | validation: 0.3375486482482673]
	TIME [epoch: 4.71 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18502875332339558		[learning rate: 0.0059356]
	Learning Rate: 0.00593556
	LOSS [training: 0.18502875332339558 | validation: 0.29713299440821384]
	TIME [epoch: 4.7 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v7_20240710_222319/states/model_facs_dec2b_2dpca_v7_158.pth
	Model improved!!!
EPOCH 159/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25778407701563466		[learning rate: 0.0059093]
	Learning Rate: 0.00590933
	LOSS [training: 0.25778407701563466 | validation: 0.44131120521565725]
	TIME [epoch: 4.73 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20362040796212094		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 0.20362040796212094 | validation: 0.34178500387513916]
	TIME [epoch: 4.74 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24742921625582537		[learning rate: 0.0058572]
	Learning Rate: 0.00585723
	LOSS [training: 0.24742921625582537 | validation: 0.4220063954203958]
	TIME [epoch: 4.74 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22518122072956093		[learning rate: 0.0058314]
	Learning Rate: 0.00583135
	LOSS [training: 0.22518122072956093 | validation: 0.31202449255830506]
	TIME [epoch: 4.7 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18428833886073034		[learning rate: 0.0058056]
	Learning Rate: 0.00580559
	LOSS [training: 0.18428833886073034 | validation: 0.35477436793652417]
	TIME [epoch: 4.72 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1819933341850681		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 0.1819933341850681 | validation: 0.37458370904936555]
	TIME [epoch: 4.71 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21942069279874668		[learning rate: 0.0057544]
	Learning Rate: 0.0057544
	LOSS [training: 0.21942069279874668 | validation: 0.3254589802923495]
	TIME [epoch: 4.71 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18321998697305458		[learning rate: 0.005729]
	Learning Rate: 0.00572897
	LOSS [training: 0.18321998697305458 | validation: 0.3274678851440461]
	TIME [epoch: 4.72 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1778665534232223		[learning rate: 0.0057037]
	Learning Rate: 0.00570366
	LOSS [training: 0.1778665534232223 | validation: 0.33556387753716244]
	TIME [epoch: 4.71 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19272634163223737		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 0.19272634163223737 | validation: 0.3041887560268305]
	TIME [epoch: 4.71 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20348286929786016		[learning rate: 0.0056534]
	Learning Rate: 0.00565337
	LOSS [training: 0.20348286929786016 | validation: 0.34838527526788315]
	TIME [epoch: 4.74 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19058163108231324		[learning rate: 0.0056284]
	Learning Rate: 0.0056284
	LOSS [training: 0.19058163108231324 | validation: 0.3566120131566236]
	TIME [epoch: 4.75 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2035260308356972		[learning rate: 0.0056035]
	Learning Rate: 0.00560353
	LOSS [training: 0.2035260308356972 | validation: 0.31807794567544095]
	TIME [epoch: 4.71 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1886994358267226		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 0.1886994358267226 | validation: 0.31739487675047423]
	TIME [epoch: 4.73 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1911097171655251		[learning rate: 0.0055541]
	Learning Rate: 0.00555412
	LOSS [training: 0.1911097171655251 | validation: 0.3531275005847947]
	TIME [epoch: 4.72 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20372324941967804		[learning rate: 0.0055296]
	Learning Rate: 0.00552958
	LOSS [training: 0.20372324941967804 | validation: 0.3579646072710141]
	TIME [epoch: 4.71 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20423718382987488		[learning rate: 0.0055052]
	Learning Rate: 0.00550515
	LOSS [training: 0.20423718382987488 | validation: 0.3043677321309538]
	TIME [epoch: 4.75 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1766376237116531		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 0.1766376237116531 | validation: 0.3331688088772831]
	TIME [epoch: 4.74 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18268910004162725		[learning rate: 0.0054566]
	Learning Rate: 0.00545661
	LOSS [training: 0.18268910004162725 | validation: 0.35946499199996307]
	TIME [epoch: 4.73 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20436969815288358		[learning rate: 0.0054325]
	Learning Rate: 0.0054325
	LOSS [training: 0.20436969815288358 | validation: 0.3304480248624483]
	TIME [epoch: 4.73 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19211182960595793		[learning rate: 0.0054085]
	Learning Rate: 0.0054085
	LOSS [training: 0.19211182960595793 | validation: 0.3563809340928273]
	TIME [epoch: 4.71 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18954034562748978		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 0.18954034562748978 | validation: 0.32026919313248603]
	TIME [epoch: 4.71 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1904498427526294		[learning rate: 0.0053608]
	Learning Rate: 0.00536081
	LOSS [training: 0.1904498427526294 | validation: 0.3722306441713186]
	TIME [epoch: 4.75 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19692283902497204		[learning rate: 0.0053371]
	Learning Rate: 0.00533713
	LOSS [training: 0.19692283902497204 | validation: 0.3041449957155387]
	TIME [epoch: 4.71 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18202791782322564		[learning rate: 0.0053135]
	Learning Rate: 0.00531355
	LOSS [training: 0.18202791782322564 | validation: 0.32493557056240446]
	TIME [epoch: 4.73 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20282013129773238		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 0.20282013129773238 | validation: 0.35940818558067333]
	TIME [epoch: 4.71 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2062351587969157		[learning rate: 0.0052667]
	Learning Rate: 0.0052667
	LOSS [training: 0.2062351587969157 | validation: 0.2934127863705404]
	TIME [epoch: 4.72 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v7_20240710_222319/states/model_facs_dec2b_2dpca_v7_185.pth
	Model improved!!!
EPOCH 186/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1675288841335777		[learning rate: 0.0052434]
	Learning Rate: 0.00524343
	LOSS [training: 0.1675288841335777 | validation: 0.33612516319112]
	TIME [epoch: 4.71 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1926900941299931		[learning rate: 0.0052203]
	Learning Rate: 0.00522026
	LOSS [training: 0.1926900941299931 | validation: 0.36239418897203224]
	TIME [epoch: 4.72 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18301866200213984		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 0.18301866200213984 | validation: 0.3240323451264389]
	TIME [epoch: 4.71 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19057004998153498		[learning rate: 0.0051742]
	Learning Rate: 0.00517423
	LOSS [training: 0.19057004998153498 | validation: 0.33006368685619897]
	TIME [epoch: 4.71 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1822003435671333		[learning rate: 0.0051514]
	Learning Rate: 0.00515137
	LOSS [training: 0.1822003435671333 | validation: 0.314122748669424]
	TIME [epoch: 4.75 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1870449944577095		[learning rate: 0.0051286]
	Learning Rate: 0.00512861
	LOSS [training: 0.1870449944577095 | validation: 0.33533269806929966]
	TIME [epoch: 4.72 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18077110227129065		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 0.18077110227129065 | validation: 0.35786944599453174]
	TIME [epoch: 4.71 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18668585355805203		[learning rate: 0.0050834]
	Learning Rate: 0.00508339
	LOSS [training: 0.18668585355805203 | validation: 0.3671733545753538]
	TIME [epoch: 4.71 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18477829037831636		[learning rate: 0.0050609]
	Learning Rate: 0.00506093
	LOSS [training: 0.18477829037831636 | validation: 0.35280248789039265]
	TIME [epoch: 4.71 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17770556071200405		[learning rate: 0.0050386]
	Learning Rate: 0.00503857
	LOSS [training: 0.17770556071200405 | validation: 0.3319050356402941]
	TIME [epoch: 4.71 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19462874485090192		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 0.19462874485090192 | validation: 0.320998432198391]
	TIME [epoch: 4.71 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19504306605334215		[learning rate: 0.0049941]
	Learning Rate: 0.00499415
	LOSS [training: 0.19504306605334215 | validation: 0.3421033013956759]
	TIME [epoch: 4.71 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18351952980899117		[learning rate: 0.0049721]
	Learning Rate: 0.00497208
	LOSS [training: 0.18351952980899117 | validation: 0.3248002278287345]
	TIME [epoch: 4.71 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1810367400727962		[learning rate: 0.0049501]
	Learning Rate: 0.00495012
	LOSS [training: 0.1810367400727962 | validation: 0.3692237791360056]
	TIME [epoch: 4.71 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1990584208669479		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 0.1990584208669479 | validation: 0.30583159173296515]
	TIME [epoch: 4.72 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18129374759078495		[learning rate: 0.0049065]
	Learning Rate: 0.00490647
	LOSS [training: 0.18129374759078495 | validation: 0.3367225730563844]
	TIME [epoch: 4.73 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17370373509326886		[learning rate: 0.0048848]
	Learning Rate: 0.00488479
	LOSS [training: 0.17370373509326886 | validation: 0.3348089230615699]
	TIME [epoch: 4.71 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20443966600855762		[learning rate: 0.0048632]
	Learning Rate: 0.00486321
	LOSS [training: 0.20443966600855762 | validation: 0.37932066738722886]
	TIME [epoch: 4.71 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1896332257101939		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 0.1896332257101939 | validation: 0.3035504589557078]
	TIME [epoch: 4.7 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17773800242329102		[learning rate: 0.0048203]
	Learning Rate: 0.00482033
	LOSS [training: 0.17773800242329102 | validation: 0.33251684066365805]
	TIME [epoch: 4.7 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18149384612483033		[learning rate: 0.004799]
	Learning Rate: 0.00479903
	LOSS [training: 0.18149384612483033 | validation: 0.3454277547960931]
	TIME [epoch: 4.7 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18810707203835783		[learning rate: 0.0047778]
	Learning Rate: 0.00477783
	LOSS [training: 0.18810707203835783 | validation: 0.3378716099417075]
	TIME [epoch: 4.71 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1910732552282423		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.1910732552282423 | validation: 0.3172072538623898]
	TIME [epoch: 4.7 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1825655199971517		[learning rate: 0.0047357]
	Learning Rate: 0.0047357
	LOSS [training: 0.1825655199971517 | validation: 0.30477581708246765]
	TIME [epoch: 4.7 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20126010199296615		[learning rate: 0.0047148]
	Learning Rate: 0.00471478
	LOSS [training: 0.20126010199296615 | validation: 0.3391594746859005]
	TIME [epoch: 4.71 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19230149403978505		[learning rate: 0.0046939]
	Learning Rate: 0.00469395
	LOSS [training: 0.19230149403978505 | validation: 0.42771343035328957]
	TIME [epoch: 4.71 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19880371285232074		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 0.19880371285232074 | validation: 0.3134491181903009]
	TIME [epoch: 4.75 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2171509571325311		[learning rate: 0.0046526]
	Learning Rate: 0.00465256
	LOSS [training: 0.2171509571325311 | validation: 0.33552156797260596]
	TIME [epoch: 4.71 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18897619874454843		[learning rate: 0.004632]
	Learning Rate: 0.00463201
	LOSS [training: 0.18897619874454843 | validation: 0.30205615585343176]
	TIME [epoch: 4.7 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17322274978062194		[learning rate: 0.0046115]
	Learning Rate: 0.00461154
	LOSS [training: 0.17322274978062194 | validation: 0.3066782419181562]
	TIME [epoch: 4.7 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17526537042335627		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 0.17526537042335627 | validation: 0.3302854493104182]
	TIME [epoch: 4.71 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19339356456409865		[learning rate: 0.0045709]
	Learning Rate: 0.00457088
	LOSS [training: 0.19339356456409865 | validation: 0.302701318429057]
	TIME [epoch: 4.7 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17533575091581122		[learning rate: 0.0045507]
	Learning Rate: 0.00455069
	LOSS [training: 0.17533575091581122 | validation: 0.3041041022609383]
	TIME [epoch: 4.73 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17543508762678475		[learning rate: 0.0045306]
	Learning Rate: 0.00453058
	LOSS [training: 0.17543508762678475 | validation: 0.36872392863674347]
	TIME [epoch: 4.71 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1845229131208411		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 0.1845229131208411 | validation: 0.33622464012023323]
	TIME [epoch: 4.72 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18264476380126737		[learning rate: 0.0044906]
	Learning Rate: 0.00449063
	LOSS [training: 0.18264476380126737 | validation: 0.3327677873094566]
	TIME [epoch: 4.71 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1852186854439188		[learning rate: 0.0044708]
	Learning Rate: 0.00447079
	LOSS [training: 0.1852186854439188 | validation: 0.3323641963034376]
	TIME [epoch: 4.7 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19617099368143698		[learning rate: 0.004451]
	Learning Rate: 0.00445104
	LOSS [training: 0.19617099368143698 | validation: 0.33234985151732055]
	TIME [epoch: 4.71 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19161815278004254		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 0.19161815278004254 | validation: 0.3146737965120043]
	TIME [epoch: 4.7 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18948514848083475		[learning rate: 0.0044118]
	Learning Rate: 0.0044118
	LOSS [training: 0.18948514848083475 | validation: 0.3406304924316709]
	TIME [epoch: 4.71 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1832565115512531		[learning rate: 0.0043923]
	Learning Rate: 0.0043923
	LOSS [training: 0.1832565115512531 | validation: 0.3225664367100329]
	TIME [epoch: 4.7 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17684711162337236		[learning rate: 0.0043729]
	Learning Rate: 0.0043729
	LOSS [training: 0.17684711162337236 | validation: 0.319111208139388]
	TIME [epoch: 4.71 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18560172903552075		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 0.18560172903552075 | validation: 0.3331089182306047]
	TIME [epoch: 4.71 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19003044538863806		[learning rate: 0.0043343]
	Learning Rate: 0.00433434
	LOSS [training: 0.19003044538863806 | validation: 0.34890337525364734]
	TIME [epoch: 4.71 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1879476246504519		[learning rate: 0.0043152]
	Learning Rate: 0.00431519
	LOSS [training: 0.1879476246504519 | validation: 0.3163649708698705]
	TIME [epoch: 4.71 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1783022265528898		[learning rate: 0.0042961]
	Learning Rate: 0.00429612
	LOSS [training: 0.1783022265528898 | validation: 0.3728011657617356]
	TIME [epoch: 4.72 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20739705158292593		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 0.20739705158292593 | validation: 0.2890499208611831]
	TIME [epoch: 4.71 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v7_20240710_222319/states/model_facs_dec2b_2dpca_v7_232.pth
	Model improved!!!
EPOCH 233/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1905617513348012		[learning rate: 0.0042582]
	Learning Rate: 0.00425825
	LOSS [training: 0.1905617513348012 | validation: 0.2910414326742153]
	TIME [epoch: 4.71 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.173033247609236		[learning rate: 0.0042394]
	Learning Rate: 0.00423943
	LOSS [training: 0.173033247609236 | validation: 0.3211064033324322]
	TIME [epoch: 4.7 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18543193263232413		[learning rate: 0.0042207]
	Learning Rate: 0.0042207
	LOSS [training: 0.18543193263232413 | validation: 0.3557802008370719]
	TIME [epoch: 4.71 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17764137201846866		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 0.17764137201846866 | validation: 0.3487602715741645]
	TIME [epoch: 4.7 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20023741707391157		[learning rate: 0.0041835]
	Learning Rate: 0.00418349
	LOSS [training: 0.20023741707391157 | validation: 0.3648090761384474]
	TIME [epoch: 4.71 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23266462688143466		[learning rate: 0.004165]
	Learning Rate: 0.004165
	LOSS [training: 0.23266462688143466 | validation: 0.34169549249182773]
	TIME [epoch: 4.71 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1870303495408307		[learning rate: 0.0041466]
	Learning Rate: 0.0041466
	LOSS [training: 0.1870303495408307 | validation: 0.3309145946424565]
	TIME [epoch: 4.7 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17328136807022787		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 0.17328136807022787 | validation: 0.2982869195310285]
	TIME [epoch: 4.71 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17641461424859603		[learning rate: 0.00411]
	Learning Rate: 0.00411004
	LOSS [training: 0.17641461424859603 | validation: 0.354711191433481]
	TIME [epoch: 4.72 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17843391574032488		[learning rate: 0.0040919]
	Learning Rate: 0.00409188
	LOSS [training: 0.17843391574032488 | validation: 0.31832861131552104]
	TIME [epoch: 4.71 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1780868956887823		[learning rate: 0.0040738]
	Learning Rate: 0.0040738
	LOSS [training: 0.1780868956887823 | validation: 0.30537345263949534]
	TIME [epoch: 4.7 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1632532805305577		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.1632532805305577 | validation: 0.34066324427807265]
	TIME [epoch: 4.7 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17763082215640108		[learning rate: 0.0040379]
	Learning Rate: 0.00403788
	LOSS [training: 0.17763082215640108 | validation: 0.3132847256143403]
	TIME [epoch: 4.71 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1829694373355415		[learning rate: 0.00402]
	Learning Rate: 0.00402004
	LOSS [training: 0.1829694373355415 | validation: 0.3570299448547866]
	TIME [epoch: 4.7 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17839245331379763		[learning rate: 0.0040023]
	Learning Rate: 0.00400228
	LOSS [training: 0.17839245331379763 | validation: 0.31499451056997346]
	TIME [epoch: 4.7 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19668733816882197		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 0.19668733816882197 | validation: 0.3031260502453384]
	TIME [epoch: 4.71 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17853202118400802		[learning rate: 0.003967]
	Learning Rate: 0.00396699
	LOSS [training: 0.17853202118400802 | validation: 0.339768824729492]
	TIME [epoch: 4.7 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17140226657304797		[learning rate: 0.0039495]
	Learning Rate: 0.00394947
	LOSS [training: 0.17140226657304797 | validation: 0.30216979871142846]
	TIME [epoch: 4.7 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20557453892708497		[learning rate: 0.003932]
	Learning Rate: 0.00393202
	LOSS [training: 0.20557453892708497 | validation: 0.36789561283233996]
	TIME [epoch: 4.72 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24930129331167397		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 0.24930129331167397 | validation: 0.3921907900942019]
	TIME [epoch: 4.72 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21262990147498187		[learning rate: 0.0038973]
	Learning Rate: 0.00389735
	LOSS [training: 0.21262990147498187 | validation: 0.3573636743496304]
	TIME [epoch: 4.7 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19214679241367333		[learning rate: 0.0038801]
	Learning Rate: 0.00388013
	LOSS [training: 0.19214679241367333 | validation: 0.3408177883351209]
	TIME [epoch: 4.72 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18626401845997412		[learning rate: 0.003863]
	Learning Rate: 0.00386299
	LOSS [training: 0.18626401845997412 | validation: 0.34588509635352327]
	TIME [epoch: 4.7 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17487537034476028		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 0.17487537034476028 | validation: 0.34520352677119515]
	TIME [epoch: 4.7 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16709105573600444		[learning rate: 0.0038289]
	Learning Rate: 0.00382893
	LOSS [training: 0.16709105573600444 | validation: 0.32524162016323105]
	TIME [epoch: 4.73 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1921566403352353		[learning rate: 0.003812]
	Learning Rate: 0.00381201
	LOSS [training: 0.1921566403352353 | validation: 0.318513859936899]
	TIME [epoch: 4.7 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19623149146473043		[learning rate: 0.0037952]
	Learning Rate: 0.00379517
	LOSS [training: 0.19623149146473043 | validation: 0.2830610283198387]
	TIME [epoch: 4.7 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v7_20240710_222319/states/model_facs_dec2b_2dpca_v7_259.pth
	Model improved!!!
EPOCH 260/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1590269720232414		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 0.1590269720232414 | validation: 0.31655677173410074]
	TIME [epoch: 4.71 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17381528074805383		[learning rate: 0.0037617]
	Learning Rate: 0.0037617
	LOSS [training: 0.17381528074805383 | validation: 0.2825302505515576]
	TIME [epoch: 4.71 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v7_20240710_222319/states/model_facs_dec2b_2dpca_v7_261.pth
	Model improved!!!
EPOCH 262/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18207473311767502		[learning rate: 0.0037451]
	Learning Rate: 0.00374508
	LOSS [training: 0.18207473311767502 | validation: 0.3205181586059631]
	TIME [epoch: 4.7 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17604678337902008		[learning rate: 0.0037285]
	Learning Rate: 0.00372854
	LOSS [training: 0.17604678337902008 | validation: 0.39422218237954276]
	TIME [epoch: 4.7 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18871386761465087		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 0.18871386761465087 | validation: 0.3086969586788139]
	TIME [epoch: 4.7 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17905192563880004		[learning rate: 0.0036957]
	Learning Rate: 0.00369566
	LOSS [training: 0.17905192563880004 | validation: 0.29274236395789505]
	TIME [epoch: 4.73 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18278708839253605		[learning rate: 0.0036793]
	Learning Rate: 0.00367933
	LOSS [training: 0.18278708839253605 | validation: 0.38169309514099414]
	TIME [epoch: 4.7 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1815093380258699		[learning rate: 0.0036631]
	Learning Rate: 0.00366308
	LOSS [training: 0.1815093380258699 | validation: 0.2878446335530095]
	TIME [epoch: 4.7 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1725991000882678		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 0.1725991000882678 | validation: 0.2983728931883991]
	TIME [epoch: 4.7 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16835609539524604		[learning rate: 0.0036308]
	Learning Rate: 0.00363078
	LOSS [training: 0.16835609539524604 | validation: 0.3065279057542716]
	TIME [epoch: 4.7 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17374190076446389		[learning rate: 0.0036147]
	Learning Rate: 0.00361474
	LOSS [training: 0.17374190076446389 | validation: 0.32206592885212115]
	TIME [epoch: 4.71 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1756018891273575		[learning rate: 0.0035988]
	Learning Rate: 0.00359877
	LOSS [training: 0.1756018891273575 | validation: 0.3392747041531744]
	TIME [epoch: 4.71 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17591880302771956		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 0.17591880302771956 | validation: 0.3195250796480457]
	TIME [epoch: 4.7 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1661043893084461		[learning rate: 0.003567]
	Learning Rate: 0.00356704
	LOSS [training: 0.1661043893084461 | validation: 0.33902769753870654]
	TIME [epoch: 4.73 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1707088493985629		[learning rate: 0.0035513]
	Learning Rate: 0.00355128
	LOSS [training: 0.1707088493985629 | validation: 0.3320573061167543]
	TIME [epoch: 4.7 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17681256045201632		[learning rate: 0.0035356]
	Learning Rate: 0.00353559
	LOSS [training: 0.17681256045201632 | validation: 0.30480586217315064]
	TIME [epoch: 4.7 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.175130242931056		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 0.175130242931056 | validation: 0.30079129807308824]
	TIME [epoch: 4.71 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18761774279659305		[learning rate: 0.0035044]
	Learning Rate: 0.00350441
	LOSS [training: 0.18761774279659305 | validation: 0.30800500983101403]
	TIME [epoch: 4.7 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16569978976840896		[learning rate: 0.0034889]
	Learning Rate: 0.00348893
	LOSS [training: 0.16569978976840896 | validation: 0.34661051651355096]
	TIME [epoch: 4.72 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1724494700986407		[learning rate: 0.0034735]
	Learning Rate: 0.00347352
	LOSS [training: 0.1724494700986407 | validation: 0.3301705623291412]
	TIME [epoch: 4.72 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16752132769231995		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.16752132769231995 | validation: 0.2949853825344177]
	TIME [epoch: 4.71 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17292942667880756		[learning rate: 0.0034429]
	Learning Rate: 0.00344289
	LOSS [training: 0.17292942667880756 | validation: 0.30531051982506213]
	TIME [epoch: 4.71 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1675531313453221		[learning rate: 0.0034277]
	Learning Rate: 0.00342768
	LOSS [training: 0.1675531313453221 | validation: 0.3060739190713074]
	TIME [epoch: 4.7 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1676545292731808		[learning rate: 0.0034125]
	Learning Rate: 0.00341253
	LOSS [training: 0.1676545292731808 | validation: 0.3013176178941204]
	TIME [epoch: 4.72 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1769136922311699		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 0.1769136922311699 | validation: 0.39430607607376267]
	TIME [epoch: 4.71 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17930643322205425		[learning rate: 0.0033824]
	Learning Rate: 0.00338245
	LOSS [training: 0.17930643322205425 | validation: 0.31690019787113954]
	TIME [epoch: 4.7 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16349201614990388		[learning rate: 0.0033675]
	Learning Rate: 0.0033675
	LOSS [training: 0.16349201614990388 | validation: 0.2980607785739719]
	TIME [epoch: 4.73 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17490335704466234		[learning rate: 0.0033526]
	Learning Rate: 0.00335262
	LOSS [training: 0.17490335704466234 | validation: 0.30581924489810236]
	TIME [epoch: 4.7 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1636482435544395		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 0.1636482435544395 | validation: 0.3190251465794502]
	TIME [epoch: 4.7 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20665480961861027		[learning rate: 0.0033231]
	Learning Rate: 0.00332306
	LOSS [training: 0.20665480961861027 | validation: 0.3082022956064721]
	TIME [epoch: 4.7 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1768230441732975		[learning rate: 0.0033084]
	Learning Rate: 0.00330838
	LOSS [training: 0.1768230441732975 | validation: 0.31575092928194287]
	TIME [epoch: 4.71 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17405333390908068		[learning rate: 0.0032938]
	Learning Rate: 0.00329376
	LOSS [training: 0.17405333390908068 | validation: 0.30119524763703576]
	TIME [epoch: 4.7 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16101284883318032		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 0.16101284883318032 | validation: 0.2990703460500166]
	TIME [epoch: 4.71 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16965681485194614		[learning rate: 0.0032647]
	Learning Rate: 0.00326472
	LOSS [training: 0.16965681485194614 | validation: 0.3125287887849614]
	TIME [epoch: 4.7 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16056068918780103		[learning rate: 0.0032503]
	Learning Rate: 0.0032503
	LOSS [training: 0.16056068918780103 | validation: 0.2972140396988617]
	TIME [epoch: 4.7 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17494955652802383		[learning rate: 0.0032359]
	Learning Rate: 0.00323594
	LOSS [training: 0.17494955652802383 | validation: 0.3027612032878798]
	TIME [epoch: 4.72 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17202810570721566		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 0.17202810570721566 | validation: 0.3535707958559596]
	TIME [epoch: 4.7 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19413292939107116		[learning rate: 0.0032074]
	Learning Rate: 0.00320741
	LOSS [training: 0.19413292939107116 | validation: 0.34003727886610163]
	TIME [epoch: 4.7 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16244025482749383		[learning rate: 0.0031932]
	Learning Rate: 0.00319323
	LOSS [training: 0.16244025482749383 | validation: 0.3248085323448383]
	TIME [epoch: 4.71 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17241550480749152		[learning rate: 0.0031791]
	Learning Rate: 0.00317913
	LOSS [training: 0.17241550480749152 | validation: 0.33119062048270825]
	TIME [epoch: 4.7 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17879645143068112		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 0.17879645143068112 | validation: 0.3468356015745468]
	TIME [epoch: 4.72 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16443914064847004		[learning rate: 0.0031511]
	Learning Rate: 0.0031511
	LOSS [training: 0.16443914064847004 | validation: 0.3394445879299298]
	TIME [epoch: 4.7 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1696082670176057		[learning rate: 0.0031372]
	Learning Rate: 0.00313717
	LOSS [training: 0.1696082670176057 | validation: 0.3044803292516593]
	TIME [epoch: 4.7 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17119987911391152		[learning rate: 0.0031233]
	Learning Rate: 0.00312331
	LOSS [training: 0.17119987911391152 | validation: 0.33863903982355137]
	TIME [epoch: 4.7 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1733507051340047		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 0.1733507051340047 | validation: 0.3094049073574376]
	TIME [epoch: 4.7 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17395860351466175		[learning rate: 0.0030958]
	Learning Rate: 0.00309577
	LOSS [training: 0.17395860351466175 | validation: 0.32026852107253934]
	TIME [epoch: 4.7 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16507389000013703		[learning rate: 0.0030821]
	Learning Rate: 0.0030821
	LOSS [training: 0.16507389000013703 | validation: 0.317694121078332]
	TIME [epoch: 4.7 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17018904216570258		[learning rate: 0.0030685]
	Learning Rate: 0.00306848
	LOSS [training: 0.17018904216570258 | validation: 0.2763265630379446]
	TIME [epoch: 4.7 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v7_20240710_222319/states/model_facs_dec2b_2dpca_v7_307.pth
	Model improved!!!
EPOCH 308/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17457549429177205		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 0.17457549429177205 | validation: 0.2929493373563154]
	TIME [epoch: 4.71 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16953900260151067		[learning rate: 0.0030414]
	Learning Rate: 0.00304142
	LOSS [training: 0.16953900260151067 | validation: 0.32509934124025586]
	TIME [epoch: 4.7 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16251101976044846		[learning rate: 0.003028]
	Learning Rate: 0.00302799
	LOSS [training: 0.16251101976044846 | validation: 0.32820364232480953]
	TIME [epoch: 4.72 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1681771337203663		[learning rate: 0.0030146]
	Learning Rate: 0.00301461
	LOSS [training: 0.1681771337203663 | validation: 0.33515325207035906]
	TIME [epoch: 4.71 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17219379984791047		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 0.17219379984791047 | validation: 0.3297527579742563]
	TIME [epoch: 4.71 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1723503304239398		[learning rate: 0.002988]
	Learning Rate: 0.00298803
	LOSS [training: 0.1723503304239398 | validation: 0.36478626919294693]
	TIME [epoch: 4.7 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17108825868248317		[learning rate: 0.0029748]
	Learning Rate: 0.00297483
	LOSS [training: 0.17108825868248317 | validation: 0.3424520868726986]
	TIME [epoch: 4.7 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16445805611697584		[learning rate: 0.0029617]
	Learning Rate: 0.00296168
	LOSS [training: 0.16445805611697584 | validation: 0.33456833382479806]
	TIME [epoch: 4.7 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18558200183759463		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.18558200183759463 | validation: 0.2805678519537374]
	TIME [epoch: 4.7 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1679896069694855		[learning rate: 0.0029356]
	Learning Rate: 0.00293557
	LOSS [training: 0.1679896069694855 | validation: 0.35334809187984134]
	TIME [epoch: 4.71 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18282572430762617		[learning rate: 0.0029226]
	Learning Rate: 0.0029226
	LOSS [training: 0.18282572430762617 | validation: 0.324292378378161]
	TIME [epoch: 4.7 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16491268680638835		[learning rate: 0.0029097]
	Learning Rate: 0.00290969
	LOSS [training: 0.16491268680638835 | validation: 0.31513092361416956]
	TIME [epoch: 4.7 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16623681569411444		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 0.16623681569411444 | validation: 0.32428378979545736]
	TIME [epoch: 4.72 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16311916050846084		[learning rate: 0.002884]
	Learning Rate: 0.00288403
	LOSS [training: 0.16311916050846084 | validation: 0.3008353041691537]
	TIME [epoch: 4.71 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16091787868191612		[learning rate: 0.0028713]
	Learning Rate: 0.00287129
	LOSS [training: 0.16091787868191612 | validation: 0.309894566638427]
	TIME [epoch: 4.71 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17418328095447094		[learning rate: 0.0028586]
	Learning Rate: 0.0028586
	LOSS [training: 0.17418328095447094 | validation: 0.2998263297054285]
	TIME [epoch: 4.7 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16771925069175514		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 0.16771925069175514 | validation: 0.320337113778731]
	TIME [epoch: 4.71 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17849999697069324		[learning rate: 0.0028334]
	Learning Rate: 0.0028334
	LOSS [training: 0.17849999697069324 | validation: 0.30124364844704143]
	TIME [epoch: 4.71 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16949646779342814		[learning rate: 0.0028209]
	Learning Rate: 0.00282088
	LOSS [training: 0.16949646779342814 | validation: 0.2827153264000321]
	TIME [epoch: 4.71 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17126510098492598		[learning rate: 0.0028084]
	Learning Rate: 0.00280842
	LOSS [training: 0.17126510098492598 | validation: 0.3038448446214625]
	TIME [epoch: 4.72 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17506394320826613		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 0.17506394320826613 | validation: 0.3068182267441605]
	TIME [epoch: 4.71 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1678437896133467		[learning rate: 0.0027837]
	Learning Rate: 0.00278366
	LOSS [training: 0.1678437896133467 | validation: 0.30905036059249824]
	TIME [epoch: 4.71 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17144336989609527		[learning rate: 0.0027714]
	Learning Rate: 0.00277136
	LOSS [training: 0.17144336989609527 | validation: 0.30414085797201035]
	TIME [epoch: 4.72 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1810337772636199		[learning rate: 0.0027591]
	Learning Rate: 0.00275911
	LOSS [training: 0.1810337772636199 | validation: 0.3240643272979735]
	TIME [epoch: 4.71 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1629675742095827		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 0.1629675742095827 | validation: 0.33193249313873624]
	TIME [epoch: 4.71 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17240495663955133		[learning rate: 0.0027348]
	Learning Rate: 0.00273478
	LOSS [training: 0.17240495663955133 | validation: 0.3048901959353801]
	TIME [epoch: 4.71 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16060534010883454		[learning rate: 0.0027227]
	Learning Rate: 0.0027227
	LOSS [training: 0.16060534010883454 | validation: 0.32373581945698654]
	TIME [epoch: 4.7 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16378885137085875		[learning rate: 0.0027107]
	Learning Rate: 0.00271067
	LOSS [training: 0.16378885137085875 | validation: 0.304390612380694]
	TIME [epoch: 4.7 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1681162089851089		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 0.1681162089851089 | validation: 0.3171145222970072]
	TIME [epoch: 4.71 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15927716669251932		[learning rate: 0.0026868]
	Learning Rate: 0.00268677
	LOSS [training: 0.15927716669251932 | validation: 0.3158197139097203]
	TIME [epoch: 4.7 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16310498158802816		[learning rate: 0.0026749]
	Learning Rate: 0.0026749
	LOSS [training: 0.16310498158802816 | validation: 0.3060105937601886]
	TIME [epoch: 4.71 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16522905407354252		[learning rate: 0.0026631]
	Learning Rate: 0.00266308
	LOSS [training: 0.16522905407354252 | validation: 0.3040072606200503]
	TIME [epoch: 4.71 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16987052379103335		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 0.16987052379103335 | validation: 0.3162992221700188]
	TIME [epoch: 4.72 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16595022360023942		[learning rate: 0.0026396]
	Learning Rate: 0.0026396
	LOSS [training: 0.16595022360023942 | validation: 0.30119439257525005]
	TIME [epoch: 4.7 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16788234123740695		[learning rate: 0.0026279]
	Learning Rate: 0.00262794
	LOSS [training: 0.16788234123740695 | validation: 0.3350321299514948]
	TIME [epoch: 4.7 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16600063768436457		[learning rate: 0.0026163]
	Learning Rate: 0.00261633
	LOSS [training: 0.16600063768436457 | validation: 0.3074808390624326]
	TIME [epoch: 4.71 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16663794018263844		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 0.16663794018263844 | validation: 0.3006742309770612]
	TIME [epoch: 4.71 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16707087386396144		[learning rate: 0.0025933]
	Learning Rate: 0.00259326
	LOSS [training: 0.16707087386396144 | validation: 0.29871945240463804]
	TIME [epoch: 4.7 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.177130688894268		[learning rate: 0.0025818]
	Learning Rate: 0.0025818
	LOSS [training: 0.177130688894268 | validation: 0.2969649903417657]
	TIME [epoch: 4.71 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16373344065462808		[learning rate: 0.0025704]
	Learning Rate: 0.0025704
	LOSS [training: 0.16373344065462808 | validation: 0.34514318380587106]
	TIME [epoch: 4.7 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17872958111132844		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.17872958111132844 | validation: 0.2924470872582932]
	TIME [epoch: 4.71 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1686263664963307		[learning rate: 0.0025477]
	Learning Rate: 0.00254773
	LOSS [training: 0.1686263664963307 | validation: 0.34582345796639546]
	TIME [epoch: 4.73 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16477087786615463		[learning rate: 0.0025365]
	Learning Rate: 0.00253648
	LOSS [training: 0.16477087786615463 | validation: 0.30049378633383067]
	TIME [epoch: 4.71 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1661550046316551		[learning rate: 0.0025253]
	Learning Rate: 0.00252527
	LOSS [training: 0.1661550046316551 | validation: 0.3147692178959024]
	TIME [epoch: 4.71 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16316755863342688		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.16316755863342688 | validation: 0.31128517157934465]
	TIME [epoch: 4.7 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.164835994251554		[learning rate: 0.002503]
	Learning Rate: 0.002503
	LOSS [training: 0.164835994251554 | validation: 0.30986802488703297]
	TIME [epoch: 4.7 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1783011636450195		[learning rate: 0.0024919]
	Learning Rate: 0.00249194
	LOSS [training: 0.1783011636450195 | validation: 0.3152985428589565]
	TIME [epoch: 4.7 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15879986555019257		[learning rate: 0.0024809]
	Learning Rate: 0.00248093
	LOSS [training: 0.15879986555019257 | validation: 0.3223106861983529]
	TIME [epoch: 4.71 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1608254388565702		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 0.1608254388565702 | validation: 0.30713017410667887]
	TIME [epoch: 4.7 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16704677551194955		[learning rate: 0.0024591]
	Learning Rate: 0.00245906
	LOSS [training: 0.16704677551194955 | validation: 0.3010247164826605]
	TIME [epoch: 4.74 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16036384746674895		[learning rate: 0.0024482]
	Learning Rate: 0.0024482
	LOSS [training: 0.16036384746674895 | validation: 0.33605863379898093]
	TIME [epoch: 4.71 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16968705071889972		[learning rate: 0.0024374]
	Learning Rate: 0.00243738
	LOSS [training: 0.16968705071889972 | validation: 0.30965668461970036]
	TIME [epoch: 4.71 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17003075970647402		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.17003075970647402 | validation: 0.29861102428195985]
	TIME [epoch: 4.7 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1535472722677595		[learning rate: 0.0024159]
	Learning Rate: 0.00241589
	LOSS [training: 0.1535472722677595 | validation: 0.2978805405035825]
	TIME [epoch: 4.7 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1690191759782142		[learning rate: 0.0024052]
	Learning Rate: 0.00240521
	LOSS [training: 0.1690191759782142 | validation: 0.30300341423424604]
	TIME [epoch: 4.71 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1674526976092722		[learning rate: 0.0023946]
	Learning Rate: 0.00239459
	LOSS [training: 0.1674526976092722 | validation: 0.33847720136751996]
	TIME [epoch: 4.7 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16303223087364976		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 0.16303223087364976 | validation: 0.33246131705835763]
	TIME [epoch: 4.73 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1706166635868884		[learning rate: 0.0023735]
	Learning Rate: 0.00237347
	LOSS [training: 0.1706166635868884 | validation: 0.303459369484962]
	TIME [epoch: 4.71 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1715014897677267		[learning rate: 0.002363]
	Learning Rate: 0.00236299
	LOSS [training: 0.1715014897677267 | validation: 0.3014927186789765]
	TIME [epoch: 4.7 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15789931218573594		[learning rate: 0.0023525]
	Learning Rate: 0.00235255
	LOSS [training: 0.15789931218573594 | validation: 0.3255668385861857]
	TIME [epoch: 4.75 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17045835038153548		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.17045835038153548 | validation: 0.30090716838556786]
	TIME [epoch: 4.7 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1578341446969414		[learning rate: 0.0023318]
	Learning Rate: 0.00233181
	LOSS [training: 0.1578341446969414 | validation: 0.3096064225991479]
	TIME [epoch: 4.72 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15988422107584435		[learning rate: 0.0023215]
	Learning Rate: 0.0023215
	LOSS [training: 0.15988422107584435 | validation: 0.3169697155073928]
	TIME [epoch: 4.71 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17510860326091443		[learning rate: 0.0023112]
	Learning Rate: 0.00231125
	LOSS [training: 0.17510860326091443 | validation: 0.29807161519677006]
	TIME [epoch: 4.71 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16917259467654272		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.16917259467654272 | validation: 0.3204100902412292]
	TIME [epoch: 4.7 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16660168440828232		[learning rate: 0.0022909]
	Learning Rate: 0.00229087
	LOSS [training: 0.16660168440828232 | validation: 0.3097251777424494]
	TIME [epoch: 4.7 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16313825258387873		[learning rate: 0.0022807]
	Learning Rate: 0.00228075
	LOSS [training: 0.16313825258387873 | validation: 0.32293251694063935]
	TIME [epoch: 4.71 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.177589470396406		[learning rate: 0.0022707]
	Learning Rate: 0.00227067
	LOSS [training: 0.177589470396406 | validation: 0.3642999514752816]
	TIME [epoch: 4.71 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16897025072560562		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.16897025072560562 | validation: 0.31940322627047235]
	TIME [epoch: 4.7 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1529784030957368		[learning rate: 0.0022506]
	Learning Rate: 0.00225065
	LOSS [training: 0.1529784030957368 | validation: 0.2993934003669906]
	TIME [epoch: 4.7 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16626145291911057		[learning rate: 0.0022407]
	Learning Rate: 0.0022407
	LOSS [training: 0.16626145291911057 | validation: 0.29955312841254006]
	TIME [epoch: 4.71 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17058038424749697		[learning rate: 0.0022308]
	Learning Rate: 0.0022308
	LOSS [training: 0.17058038424749697 | validation: 0.31020689421198205]
	TIME [epoch: 4.71 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16425437992125524		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.16425437992125524 | validation: 0.2998568660762852]
	TIME [epoch: 4.7 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1627518576953207		[learning rate: 0.0022111]
	Learning Rate: 0.00221114
	LOSS [training: 0.1627518576953207 | validation: 0.294956978221066]
	TIME [epoch: 4.72 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15965511065690158		[learning rate: 0.0022014]
	Learning Rate: 0.00220137
	LOSS [training: 0.15965511065690158 | validation: 0.3074435711910201]
	TIME [epoch: 4.7 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16332613689387665		[learning rate: 0.0021916]
	Learning Rate: 0.00219164
	LOSS [training: 0.16332613689387665 | validation: 0.30913337062340057]
	TIME [epoch: 4.7 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16689145887841517		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.16689145887841517 | validation: 0.3086758480402057]
	TIME [epoch: 4.7 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16903588416580032		[learning rate: 0.0021723]
	Learning Rate: 0.00217232
	LOSS [training: 0.16903588416580032 | validation: 0.31396132940039445]
	TIME [epoch: 4.7 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16238569593636876		[learning rate: 0.0021627]
	Learning Rate: 0.00216272
	LOSS [training: 0.16238569593636876 | validation: 0.32240599850903917]
	TIME [epoch: 4.73 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1606336138920573		[learning rate: 0.0021532]
	Learning Rate: 0.00215316
	LOSS [training: 0.1606336138920573 | validation: 0.3034774880726095]
	TIME [epoch: 4.71 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15861054647576242		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.15861054647576242 | validation: 0.28828286861981567]
	TIME [epoch: 4.71 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16503783985886988		[learning rate: 0.0021342]
	Learning Rate: 0.00213418
	LOSS [training: 0.16503783985886988 | validation: 0.3253357629511495]
	TIME [epoch: 4.7 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18250406904104716		[learning rate: 0.0021247]
	Learning Rate: 0.00212475
	LOSS [training: 0.18250406904104716 | validation: 0.30833227787267925]
	TIME [epoch: 4.7 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16352333010795408		[learning rate: 0.0021154]
	Learning Rate: 0.00211536
	LOSS [training: 0.16352333010795408 | validation: 0.3115541649594112]
	TIME [epoch: 4.7 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16695896091521706		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.16695896091521706 | validation: 0.3038431087613376]
	TIME [epoch: 4.71 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15772527380602144		[learning rate: 0.0020967]
	Learning Rate: 0.00209671
	LOSS [training: 0.15772527380602144 | validation: 0.3242027729912145]
	TIME [epoch: 4.7 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16621474586205254		[learning rate: 0.0020874]
	Learning Rate: 0.00208745
	LOSS [training: 0.16621474586205254 | validation: 0.3263023388122378]
	TIME [epoch: 4.7 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16993339333064794		[learning rate: 0.0020782]
	Learning Rate: 0.00207822
	LOSS [training: 0.16993339333064794 | validation: 0.29852036907753676]
	TIME [epoch: 4.7 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17031679917359044		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.17031679917359044 | validation: 0.2990485581795932]
	TIME [epoch: 4.71 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1563663909015666		[learning rate: 0.0020599]
	Learning Rate: 0.0020599
	LOSS [training: 0.1563663909015666 | validation: 0.30648561821855896]
	TIME [epoch: 4.74 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15996378294860175		[learning rate: 0.0020508]
	Learning Rate: 0.0020508
	LOSS [training: 0.15996378294860175 | validation: 0.30779941473266403]
	TIME [epoch: 4.71 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1611478250616289		[learning rate: 0.0020417]
	Learning Rate: 0.00204174
	LOSS [training: 0.1611478250616289 | validation: 0.32208692214041207]
	TIME [epoch: 4.7 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16085924158234371		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.16085924158234371 | validation: 0.2937790628367619]
	TIME [epoch: 4.72 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16162260355414557		[learning rate: 0.0020237]
	Learning Rate: 0.00202374
	LOSS [training: 0.16162260355414557 | validation: 0.2896399666793654]
	TIME [epoch: 4.71 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1731925244509332		[learning rate: 0.0020148]
	Learning Rate: 0.00201479
	LOSS [training: 0.1731925244509332 | validation: 0.3056685224464286]
	TIME [epoch: 4.71 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1679661942768606		[learning rate: 0.0020059]
	Learning Rate: 0.00200589
	LOSS [training: 0.1679661942768606 | validation: 0.30542009712646795]
	TIME [epoch: 4.71 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16593338299058236		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.16593338299058236 | validation: 0.3130121586449608]
	TIME [epoch: 4.71 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1617430162731593		[learning rate: 0.0019882]
	Learning Rate: 0.00198821
	LOSS [training: 0.1617430162731593 | validation: 0.302433433049381]
	TIME [epoch: 4.7 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16945670060371512		[learning rate: 0.0019794]
	Learning Rate: 0.00197942
	LOSS [training: 0.16945670060371512 | validation: 0.3186353870129848]
	TIME [epoch: 4.74 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16127151947691626		[learning rate: 0.0019707]
	Learning Rate: 0.00197068
	LOSS [training: 0.16127151947691626 | validation: 0.30450042713890113]
	TIME [epoch: 4.72 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15670478083202571		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.15670478083202571 | validation: 0.2882487390822037]
	TIME [epoch: 4.7 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17383903344208196		[learning rate: 0.0019533]
	Learning Rate: 0.0019533
	LOSS [training: 0.17383903344208196 | validation: 0.32507978960223244]
	TIME [epoch: 4.71 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16559222514051913		[learning rate: 0.0019447]
	Learning Rate: 0.00194467
	LOSS [training: 0.16559222514051913 | validation: 0.31936727008789867]
	TIME [epoch: 4.7 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17577354532720163		[learning rate: 0.0019361]
	Learning Rate: 0.00193608
	LOSS [training: 0.17577354532720163 | validation: 0.3031075087678587]
	TIME [epoch: 4.7 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1679668892290113		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.1679668892290113 | validation: 0.31410331757897414]
	TIME [epoch: 4.72 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1603724186588665		[learning rate: 0.001919]
	Learning Rate: 0.00191901
	LOSS [training: 0.1603724186588665 | validation: 0.302612337593526]
	TIME [epoch: 4.7 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16218437284362253		[learning rate: 0.0019105]
	Learning Rate: 0.00191053
	LOSS [training: 0.16218437284362253 | validation: 0.3134505585230914]
	TIME [epoch: 4.7 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16252851849563682		[learning rate: 0.0019021]
	Learning Rate: 0.00190209
	LOSS [training: 0.16252851849563682 | validation: 0.3112624255361542]
	TIME [epoch: 4.7 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1597481331432964		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.1597481331432964 | validation: 0.29971250625797996]
	TIME [epoch: 4.7 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16612615769422917		[learning rate: 0.0018853]
	Learning Rate: 0.00188532
	LOSS [training: 0.16612615769422917 | validation: 0.29633421440363916]
	TIME [epoch: 4.71 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1578481056854257		[learning rate: 0.001877]
	Learning Rate: 0.00187699
	LOSS [training: 0.1578481056854257 | validation: 0.3017227889634381]
	TIME [epoch: 4.72 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16557157893714336		[learning rate: 0.0018687]
	Learning Rate: 0.0018687
	LOSS [training: 0.16557157893714336 | validation: 0.2988806057420527]
	TIME [epoch: 4.72 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1660833239170909		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.1660833239170909 | validation: 0.3021005956980197]
	TIME [epoch: 4.71 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18433218003204205		[learning rate: 0.0018522]
	Learning Rate: 0.00185222
	LOSS [training: 0.18433218003204205 | validation: 0.3211079498957932]
	TIME [epoch: 4.75 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17766442148500924		[learning rate: 0.001844]
	Learning Rate: 0.00184404
	LOSS [training: 0.17766442148500924 | validation: 0.3048024076477494]
	TIME [epoch: 4.71 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1580328773180192		[learning rate: 0.0018359]
	Learning Rate: 0.00183589
	LOSS [training: 0.1580328773180192 | validation: 0.2996827553376917]
	TIME [epoch: 4.7 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16200868768080373		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.16200868768080373 | validation: 0.32531215445044015]
	TIME [epoch: 4.71 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.169114259624025		[learning rate: 0.0018197]
	Learning Rate: 0.0018197
	LOSS [training: 0.169114259624025 | validation: 0.3054781539524063]
	TIME [epoch: 4.72 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16058889901474568		[learning rate: 0.0018117]
	Learning Rate: 0.00181166
	LOSS [training: 0.16058889901474568 | validation: 0.2945120129530707]
	TIME [epoch: 4.71 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15826938364344972		[learning rate: 0.0018037]
	Learning Rate: 0.00180366
	LOSS [training: 0.15826938364344972 | validation: 0.2958219167610458]
	TIME [epoch: 4.72 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16333826219362818		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.16333826219362818 | validation: 0.30113706073374724]
	TIME [epoch: 4.72 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16374565479908554		[learning rate: 0.0017878]
	Learning Rate: 0.00178775
	LOSS [training: 0.16374565479908554 | validation: 0.3029782239609931]
	TIME [epoch: 4.71 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1661283139406505		[learning rate: 0.0017799]
	Learning Rate: 0.00177985
	LOSS [training: 0.1661283139406505 | validation: 0.31534815172417124]
	TIME [epoch: 4.71 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15964744086697796		[learning rate: 0.001772]
	Learning Rate: 0.00177199
	LOSS [training: 0.15964744086697796 | validation: 0.3095143638582837]
	TIME [epoch: 4.73 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1688172807685433		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.1688172807685433 | validation: 0.3023926130571396]
	TIME [epoch: 4.71 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1638772476111972		[learning rate: 0.0017564]
	Learning Rate: 0.00175637
	LOSS [training: 0.1638772476111972 | validation: 0.3009655246621502]
	TIME [epoch: 4.7 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16035249210704056		[learning rate: 0.0017486]
	Learning Rate: 0.00174861
	LOSS [training: 0.16035249210704056 | validation: 0.2866612857019037]
	TIME [epoch: 4.71 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16628578670699398		[learning rate: 0.0017409]
	Learning Rate: 0.00174088
	LOSS [training: 0.16628578670699398 | validation: 0.2779408171369374]
	TIME [epoch: 4.7 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15908861305530225		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.15908861305530225 | validation: 0.3166050413042765]
	TIME [epoch: 4.7 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16592643689975686		[learning rate: 0.0017255]
	Learning Rate: 0.00172553
	LOSS [training: 0.16592643689975686 | validation: 0.2869629930835331]
	TIME [epoch: 4.71 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1574522551948686		[learning rate: 0.0017179]
	Learning Rate: 0.00171791
	LOSS [training: 0.1574522551948686 | validation: 0.3033721655586819]
	TIME [epoch: 4.72 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16810467752025224		[learning rate: 0.0017103]
	Learning Rate: 0.00171032
	LOSS [training: 0.16810467752025224 | validation: 0.3160334183491261]
	TIME [epoch: 4.7 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15627219948584917		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.15627219948584917 | validation: 0.305246019442864]
	TIME [epoch: 4.71 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16256491831698652		[learning rate: 0.0016952]
	Learning Rate: 0.00169524
	LOSS [training: 0.16256491831698652 | validation: 0.3089121890117436]
	TIME [epoch: 4.72 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1638069904174742		[learning rate: 0.0016877]
	Learning Rate: 0.00168775
	LOSS [training: 0.1638069904174742 | validation: 0.3008186340856506]
	TIME [epoch: 4.7 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16932114122605085		[learning rate: 0.0016803]
	Learning Rate: 0.00168029
	LOSS [training: 0.16932114122605085 | validation: 0.310417928039653]
	TIME [epoch: 4.7 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16912226837820882		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.16912226837820882 | validation: 0.29757146109975624]
	TIME [epoch: 4.72 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16170161032445657		[learning rate: 0.0016655]
	Learning Rate: 0.00166548
	LOSS [training: 0.16170161032445657 | validation: 0.30943492495357133]
	TIME [epoch: 4.7 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16243924829090783		[learning rate: 0.0016581]
	Learning Rate: 0.00165812
	LOSS [training: 0.16243924829090783 | validation: 0.28626808453322744]
	TIME [epoch: 4.73 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15341388013006918		[learning rate: 0.0016508]
	Learning Rate: 0.00165079
	LOSS [training: 0.15341388013006918 | validation: 0.3191466413268962]
	TIME [epoch: 4.72 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1644524410374601		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.1644524410374601 | validation: 0.2928340662513235]
	TIME [epoch: 4.71 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16229530773964615		[learning rate: 0.0016362]
	Learning Rate: 0.00163624
	LOSS [training: 0.16229530773964615 | validation: 0.3054141650099873]
	TIME [epoch: 4.7 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1576474812693856		[learning rate: 0.001629]
	Learning Rate: 0.00162901
	LOSS [training: 0.1576474812693856 | validation: 0.2920949011849714]
	TIME [epoch: 4.73 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15241461358161495		[learning rate: 0.0016218]
	Learning Rate: 0.00162181
	LOSS [training: 0.15241461358161495 | validation: 0.3159702661867502]
	TIME [epoch: 4.71 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16280060253164302		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.16280060253164302 | validation: 0.29258459685160565]
	TIME [epoch: 4.7 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15860395912614475		[learning rate: 0.0016075]
	Learning Rate: 0.00160751
	LOSS [training: 0.15860395912614475 | validation: 0.3464292578167797]
	TIME [epoch: 4.7 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15530848109845458		[learning rate: 0.0016004]
	Learning Rate: 0.00160041
	LOSS [training: 0.15530848109845458 | validation: 0.29303378925160584]
	TIME [epoch: 4.7 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16149625131968834		[learning rate: 0.0015933]
	Learning Rate: 0.00159334
	LOSS [training: 0.16149625131968834 | validation: 0.30109118223011966]
	TIME [epoch: 4.7 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1593818073316452		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.1593818073316452 | validation: 0.3035139988381644]
	TIME [epoch: 4.72 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15925518085276721		[learning rate: 0.0015793]
	Learning Rate: 0.00157929
	LOSS [training: 0.15925518085276721 | validation: 0.30766308280032195]
	TIME [epoch: 4.7 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15912309231435995		[learning rate: 0.0015723]
	Learning Rate: 0.00157231
	LOSS [training: 0.15912309231435995 | validation: 0.3083620093538689]
	TIME [epoch: 4.7 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15141593194791425		[learning rate: 0.0015654]
	Learning Rate: 0.00156536
	LOSS [training: 0.15141593194791425 | validation: 0.301134685158952]
	TIME [epoch: 4.7 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15833233954214698		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.15833233954214698 | validation: 0.29100811312139985]
	TIME [epoch: 4.73 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16189589970934054		[learning rate: 0.0015516]
	Learning Rate: 0.00155156
	LOSS [training: 0.16189589970934054 | validation: 0.2858756224183382]
	TIME [epoch: 4.7 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16986248039109558		[learning rate: 0.0015447]
	Learning Rate: 0.00154471
	LOSS [training: 0.16986248039109558 | validation: 0.31233867731665416]
	TIME [epoch: 4.71 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16960951581236977		[learning rate: 0.0015379]
	Learning Rate: 0.00153788
	LOSS [training: 0.16960951581236977 | validation: 0.2903608379703075]
	TIME [epoch: 4.71 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17667720697075312		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.17667720697075312 | validation: 0.29872246107496586]
	TIME [epoch: 4.7 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15924423488710837		[learning rate: 0.0015243]
	Learning Rate: 0.00152432
	LOSS [training: 0.15924423488710837 | validation: 0.2965470638202209]
	TIME [epoch: 4.7 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1556293282058558		[learning rate: 0.0015176]
	Learning Rate: 0.00151759
	LOSS [training: 0.1556293282058558 | validation: 0.3106843664728288]
	TIME [epoch: 4.72 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1572236685056994		[learning rate: 0.0015109]
	Learning Rate: 0.00151088
	LOSS [training: 0.1572236685056994 | validation: 0.3029596877921455]
	TIME [epoch: 4.71 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15538107082876063		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.15538107082876063 | validation: 0.2840155682642876]
	TIME [epoch: 4.7 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1608711531860135		[learning rate: 0.0014976]
	Learning Rate: 0.00149756
	LOSS [training: 0.1608711531860135 | validation: 0.3022834516966335]
	TIME [epoch: 4.71 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16009610221107		[learning rate: 0.0014909]
	Learning Rate: 0.00149094
	LOSS [training: 0.16009610221107 | validation: 0.3046794375166158]
	TIME [epoch: 4.7 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16227729871399385		[learning rate: 0.0014844]
	Learning Rate: 0.00148436
	LOSS [training: 0.16227729871399385 | validation: 0.3092606491954633]
	TIME [epoch: 4.71 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15456504607839933		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.15456504607839933 | validation: 0.3056315109896764]
	TIME [epoch: 4.71 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16121971150410347		[learning rate: 0.0014713]
	Learning Rate: 0.00147127
	LOSS [training: 0.16121971150410347 | validation: 0.29397585561860823]
	TIME [epoch: 4.7 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15950681622769675		[learning rate: 0.0014648]
	Learning Rate: 0.00146477
	LOSS [training: 0.15950681622769675 | validation: 0.32233656563978813]
	TIME [epoch: 4.7 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.167198497538051		[learning rate: 0.0014583]
	Learning Rate: 0.0014583
	LOSS [training: 0.167198497538051 | validation: 0.2955399132474691]
	TIME [epoch: 4.71 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15979715665914512		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.15979715665914512 | validation: 0.30539467373328705]
	TIME [epoch: 4.72 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15487318865295804		[learning rate: 0.0014454]
	Learning Rate: 0.00144544
	LOSS [training: 0.15487318865295804 | validation: 0.28071467748634615]
	TIME [epoch: 4.71 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1624556754163749		[learning rate: 0.0014391]
	Learning Rate: 0.00143905
	LOSS [training: 0.1624556754163749 | validation: 0.2995597112486768]
	TIME [epoch: 4.7 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16145752783054618		[learning rate: 0.0014327]
	Learning Rate: 0.0014327
	LOSS [training: 0.16145752783054618 | validation: 0.31704116242831565]
	TIME [epoch: 4.71 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16508929449123527		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.16508929449123527 | validation: 0.3026812546640526]
	TIME [epoch: 4.7 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15711172753174077		[learning rate: 0.0014201]
	Learning Rate: 0.00142006
	LOSS [training: 0.15711172753174077 | validation: 0.29994117435003476]
	TIME [epoch: 4.7 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15944779322109953		[learning rate: 0.0014138]
	Learning Rate: 0.00141379
	LOSS [training: 0.15944779322109953 | validation: 0.3093151783451184]
	TIME [epoch: 4.75 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15833175897708146		[learning rate: 0.0014075]
	Learning Rate: 0.00140754
	LOSS [training: 0.15833175897708146 | validation: 0.287386129185376]
	TIME [epoch: 4.75 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17133757017238554		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.17133757017238554 | validation: 0.29331443104277144]
	TIME [epoch: 4.73 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15830707232835894		[learning rate: 0.0013951]
	Learning Rate: 0.00139513
	LOSS [training: 0.15830707232835894 | validation: 0.30018633680698253]
	TIME [epoch: 4.75 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15826857103987182		[learning rate: 0.001389]
	Learning Rate: 0.00138897
	LOSS [training: 0.15826857103987182 | validation: 0.29954954922700505]
	TIME [epoch: 4.71 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16012858774783384		[learning rate: 0.0013828]
	Learning Rate: 0.00138283
	LOSS [training: 0.16012858774783384 | validation: 0.34414374937760245]
	TIME [epoch: 4.71 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1629833040503863		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.1629833040503863 | validation: 0.29901569501168734]
	TIME [epoch: 4.73 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1612715632980859		[learning rate: 0.0013706]
	Learning Rate: 0.00137064
	LOSS [training: 0.1612715632980859 | validation: 0.297184024200689]
	TIME [epoch: 4.71 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1632351384635617		[learning rate: 0.0013646]
	Learning Rate: 0.00136458
	LOSS [training: 0.1632351384635617 | validation: 0.31026824263535974]
	TIME [epoch: 4.72 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16284224528188615		[learning rate: 0.0013586]
	Learning Rate: 0.00135855
	LOSS [training: 0.16284224528188615 | validation: 0.28035683418182955]
	TIME [epoch: 4.72 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16227950217634587		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.16227950217634587 | validation: 0.294752237722651]
	TIME [epoch: 4.71 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1591624390436766		[learning rate: 0.0013466]
	Learning Rate: 0.00134658
	LOSS [training: 0.1591624390436766 | validation: 0.29520910934942596]
	TIME [epoch: 4.7 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1567700641547508		[learning rate: 0.0013406]
	Learning Rate: 0.00134063
	LOSS [training: 0.1567700641547508 | validation: 0.30236371389040306]
	TIME [epoch: 4.74 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15837417365871892		[learning rate: 0.0013347]
	Learning Rate: 0.0013347
	LOSS [training: 0.15837417365871892 | validation: 0.3004213586039691]
	TIME [epoch: 4.73 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16267475521479588		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.16267475521479588 | validation: 0.3080245698631609]
	TIME [epoch: 4.72 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15443046987388964		[learning rate: 0.0013229]
	Learning Rate: 0.00132293
	LOSS [training: 0.15443046987388964 | validation: 0.31865618011862173]
	TIME [epoch: 4.71 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16277071718143782		[learning rate: 0.0013171]
	Learning Rate: 0.00131709
	LOSS [training: 0.16277071718143782 | validation: 0.281738119317537]
	TIME [epoch: 4.72 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15784044608662776		[learning rate: 0.0013113]
	Learning Rate: 0.00131127
	LOSS [training: 0.15784044608662776 | validation: 0.3097927820690977]
	TIME [epoch: 4.74 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16317056070499927		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.16317056070499927 | validation: 0.3096226969498085]
	TIME [epoch: 4.7 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1537128668899666		[learning rate: 0.0012997]
	Learning Rate: 0.00129971
	LOSS [training: 0.1537128668899666 | validation: 0.30366808731821004]
	TIME [epoch: 30.2 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15906207428208452		[learning rate: 0.001294]
	Learning Rate: 0.00129397
	LOSS [training: 0.15906207428208452 | validation: 0.2797775208233058]
	TIME [epoch: 9.03 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16574322788110904		[learning rate: 0.0012882]
	Learning Rate: 0.00128825
	LOSS [training: 0.16574322788110904 | validation: 0.29876673717249197]
	TIME [epoch: 9.01 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1633872596596939		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.1633872596596939 | validation: 0.30280977844759277]
	TIME [epoch: 9.02 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15850894983051173		[learning rate: 0.0012769]
	Learning Rate: 0.00127689
	LOSS [training: 0.15850894983051173 | validation: 0.28918896091610574]
	TIME [epoch: 9.06 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1580132915329874		[learning rate: 0.0012712]
	Learning Rate: 0.00127125
	LOSS [training: 0.1580132915329874 | validation: 0.29660739267556596]
	TIME [epoch: 9.04 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15123904873174582		[learning rate: 0.0012656]
	Learning Rate: 0.00126563
	LOSS [training: 0.15123904873174582 | validation: 0.2958158008785322]
	TIME [epoch: 9.03 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15858192244729075		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.15858192244729075 | validation: 0.2830079876708954]
	TIME [epoch: 9.02 sec]
	Saving model to: out/model_training/model_facs_dec2b_2dpca_v7_20240710_222319/states/model_facs_dec2b_2dpca_v7_508.pth
Halted early. No improvement in validation loss for 200 epochs.
Finished training in 2514.961 seconds.
