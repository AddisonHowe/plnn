Args:
Namespace(name='model_facs_v2_dec2b_2dpca_v13b', outdir='out/model_training/model_facs_v2_dec2b_2dpca_v13b', training_data='data/training_data/facs_v2/pca/dec2_fitonsubset/transition2_subset_ce_pn_m_pc12/training', validation_data='data/training_data/facs_v2/pca/dec2_fitonsubset/transition2_subset_ce_pn_m_pc12/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=10, batch_size=50, patience=200, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, quadratic_a=1.0, quadratic_b=1.0, ndims=2, nparams=2, nsigs=2, ncells=400, ncells_sample=400, model_do_sample=False, dt=0.005, dt_schedule='stepped', dt_schedule_bounds=[50, 100, 200, 300], dt_schedule_scales=[0.5, 0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', kernel='multiscale', bw_range=[0.2, 0.5, 0.9, 1.1, 1.3, 1.5, 2.0], optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 3685342449

Training model...

Saving initial model state to: out/model_training/model_facs_v2_dec2b_2dpca_v13b_20240716_180629/states/model_facs_v2_dec2b_2dpca_v13b_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4086018751214202		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4086018751214202 | validation: 0.9724865983265163]
	TIME [epoch: 33.6 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v13b_20240716_180629/states/model_facs_v2_dec2b_2dpca_v13b_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.754564731585931		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.754564731585931 | validation: 0.8141702040077192]
	TIME [epoch: 5.79 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v13b_20240716_180629/states/model_facs_v2_dec2b_2dpca_v13b_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6391449287109859		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6391449287109859 | validation: 0.7663369955419953]
	TIME [epoch: 5.77 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v13b_20240716_180629/states/model_facs_v2_dec2b_2dpca_v13b_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6163926910028881		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6163926910028881 | validation: 0.7386363061628005]
	TIME [epoch: 5.77 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v13b_20240716_180629/states/model_facs_v2_dec2b_2dpca_v13b_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5665437511196156		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5665437511196156 | validation: 0.6578709248579276]
	TIME [epoch: 5.79 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v13b_20240716_180629/states/model_facs_v2_dec2b_2dpca_v13b_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5549498551836264		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5549498551836264 | validation: 0.5942805965984945]
	TIME [epoch: 5.78 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v13b_20240716_180629/states/model_facs_v2_dec2b_2dpca_v13b_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.470409393899948		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.470409393899948 | validation: 0.5375491876956369]
	TIME [epoch: 5.77 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v13b_20240716_180629/states/model_facs_v2_dec2b_2dpca_v13b_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.422301715939329		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.422301715939329 | validation: 0.8360814278432811]
	TIME [epoch: 5.78 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46770942539768195		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.46770942539768195 | validation: 0.4998244589506573]
	TIME [epoch: 5.77 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v13b_20240716_180629/states/model_facs_v2_dec2b_2dpca_v13b_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39218903987383696		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.39218903987383696 | validation: 0.570965732473139]
	TIME [epoch: 5.77 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4217812422671886		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4217812422671886 | validation: 0.5429408292145521]
	TIME [epoch: 5.79 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3923190233406836		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3923190233406836 | validation: 0.4984858504521068]
	TIME [epoch: 5.77 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v13b_20240716_180629/states/model_facs_v2_dec2b_2dpca_v13b_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3787656971852595		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3787656971852595 | validation: 0.49680896490038173]
	TIME [epoch: 5.77 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v13b_20240716_180629/states/model_facs_v2_dec2b_2dpca_v13b_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3542823168782737		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3542823168782737 | validation: 0.4510674430768856]
	TIME [epoch: 5.76 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v13b_20240716_180629/states/model_facs_v2_dec2b_2dpca_v13b_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3625404779844468		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3625404779844468 | validation: 0.45747889227715965]
	TIME [epoch: 5.78 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33437748370823595		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.33437748370823595 | validation: 0.6162700112539]
	TIME [epoch: 5.78 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37680670752210765		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.37680670752210765 | validation: 0.45543944780559437]
	TIME [epoch: 5.78 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31945089640382374		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.31945089640382374 | validation: 0.4208110674645201]
	TIME [epoch: 5.77 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v13b_20240716_180629/states/model_facs_v2_dec2b_2dpca_v13b_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35447759190817585		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.35447759190817585 | validation: 0.48532037634941516]
	TIME [epoch: 5.77 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3466665322316265		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3466665322316265 | validation: 0.40851803261337366]
	TIME [epoch: 5.77 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v13b_20240716_180629/states/model_facs_v2_dec2b_2dpca_v13b_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3008180555369793		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3008180555369793 | validation: 0.4185282380774705]
	TIME [epoch: 5.78 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3233165525443152		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3233165525443152 | validation: 0.4165085889346348]
	TIME [epoch: 5.78 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2856629910965599		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2856629910965599 | validation: 0.469909700553629]
	TIME [epoch: 5.79 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34135607342910557		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.34135607342910557 | validation: 0.4141566993661285]
	TIME [epoch: 5.78 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3033976275359114		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3033976275359114 | validation: 0.4248686446087719]
	TIME [epoch: 5.77 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2947718029085889		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2947718029085889 | validation: 0.4067721970374955]
	TIME [epoch: 5.77 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v13b_20240716_180629/states/model_facs_v2_dec2b_2dpca_v13b_26.pth
	Model improved!!!
EPOCH 27/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26610247559363476		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.26610247559363476 | validation: 0.491246106419042]
	TIME [epoch: 5.78 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3027334802969338		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3027334802969338 | validation: 0.3666008757121071]
	TIME [epoch: 5.77 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v13b_20240716_180629/states/model_facs_v2_dec2b_2dpca_v13b_28.pth
	Model improved!!!
EPOCH 29/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28704867285288904		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.28704867285288904 | validation: 0.37954666656258806]
	TIME [epoch: 5.79 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28272974701182063		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.28272974701182063 | validation: 0.4379983641215348]
	TIME [epoch: 5.77 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3036843741770497		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3036843741770497 | validation: 0.4077573930710041]
	TIME [epoch: 5.77 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2817493842444068		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2817493842444068 | validation: 0.4248833738213927]
	TIME [epoch: 5.76 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2919405885219977		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2919405885219977 | validation: 0.40479766150719343]
	TIME [epoch: 5.76 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27478302555610007		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.27478302555610007 | validation: 0.3615606898845649]
	TIME [epoch: 5.77 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v13b_20240716_180629/states/model_facs_v2_dec2b_2dpca_v13b_34.pth
	Model improved!!!
EPOCH 35/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27253333211871045		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.27253333211871045 | validation: 0.4056071449722358]
	TIME [epoch: 5.78 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28224324888651997		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.28224324888651997 | validation: 0.414917723977227]
	TIME [epoch: 5.76 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29005675827550126		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.29005675827550126 | validation: 0.4039784634749928]
	TIME [epoch: 5.87 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2699451038373478		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2699451038373478 | validation: 0.35427481355578716]
	TIME [epoch: 5.76 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v13b_20240716_180629/states/model_facs_v2_dec2b_2dpca_v13b_38.pth
	Model improved!!!
EPOCH 39/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26309422243492386		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.26309422243492386 | validation: 0.372903000471733]
	TIME [epoch: 5.77 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2566064038448623		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2566064038448623 | validation: 0.4123219550798305]
	TIME [epoch: 5.77 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.254574252754599		[learning rate: 0.0099646]
	Learning Rate: 0.00996464
	LOSS [training: 0.254574252754599 | validation: 0.38568862853487196]
	TIME [epoch: 5.77 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2560358244531072		[learning rate: 0.0099206]
	Learning Rate: 0.00992061
	LOSS [training: 0.2560358244531072 | validation: 0.4080405578956552]
	TIME [epoch: 5.77 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27047936534265604		[learning rate: 0.0098768]
	Learning Rate: 0.00987678
	LOSS [training: 0.27047936534265604 | validation: 0.41760766874576416]
	TIME [epoch: 5.76 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24260808594538252		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 0.24260808594538252 | validation: 0.4034750526794312]
	TIME [epoch: 5.77 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27125120529141267		[learning rate: 0.0097897]
	Learning Rate: 0.0097897
	LOSS [training: 0.27125120529141267 | validation: 0.4109449908911141]
	TIME [epoch: 5.76 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23316376194303787		[learning rate: 0.0097464]
	Learning Rate: 0.00974644
	LOSS [training: 0.23316376194303787 | validation: 0.4264234010595828]
	TIME [epoch: 5.77 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2548277927974866		[learning rate: 0.0097034]
	Learning Rate: 0.00970338
	LOSS [training: 0.2548277927974866 | validation: 0.4012366419121539]
	TIME [epoch: 5.78 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2551903096467773		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 0.2551903096467773 | validation: 0.34127896413415015]
	TIME [epoch: 5.76 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v13b_20240716_180629/states/model_facs_v2_dec2b_2dpca_v13b_48.pth
	Model improved!!!
EPOCH 49/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2535293373531337		[learning rate: 0.0096178]
	Learning Rate: 0.00961783
	LOSS [training: 0.2535293373531337 | validation: 0.38036659199664985]
	TIME [epoch: 5.77 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24683548614764458		[learning rate: 0.0095753]
	Learning Rate: 0.00957533
	LOSS [training: 0.24683548614764458 | validation: 0.34815741856542154]
	TIME [epoch: 5.76 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2468794416494923		[learning rate: 0.009533]
	Learning Rate: 0.00953303
	LOSS [training: 0.2468794416494923 | validation: 0.35923450949845237]
	TIME [epoch: 36.8 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22933357005607072		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 0.22933357005607072 | validation: 0.367890143167706]
	TIME [epoch: 11.1 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26457067644665044		[learning rate: 0.009449]
	Learning Rate: 0.00944897
	LOSS [training: 0.26457067644665044 | validation: 0.39967060484382877]
	TIME [epoch: 11.2 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25908016331200295		[learning rate: 0.0094072]
	Learning Rate: 0.00940722
	LOSS [training: 0.25908016331200295 | validation: 0.3965264147415174]
	TIME [epoch: 11.1 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23877418048615334		[learning rate: 0.0093657]
	Learning Rate: 0.00936566
	LOSS [training: 0.23877418048615334 | validation: 0.3566320375343907]
	TIME [epoch: 11.1 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24562985918911986		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 0.24562985918911986 | validation: 0.3588938912345958]
	TIME [epoch: 11.1 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26229861704702645		[learning rate: 0.0092831]
	Learning Rate: 0.00928308
	LOSS [training: 0.26229861704702645 | validation: 0.4349616242962385]
	TIME [epoch: 11.1 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24605608526483932		[learning rate: 0.0092421]
	Learning Rate: 0.00924207
	LOSS [training: 0.24605608526483932 | validation: 0.3645165270978834]
	TIME [epoch: 11.1 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24766499667825306		[learning rate: 0.0092012]
	Learning Rate: 0.00920124
	LOSS [training: 0.24766499667825306 | validation: 0.3662576316953271]
	TIME [epoch: 11.1 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23128091760330402		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 0.23128091760330402 | validation: 0.42431772685156577]
	TIME [epoch: 11.1 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24530403448216642		[learning rate: 0.0091201]
	Learning Rate: 0.00912011
	LOSS [training: 0.24530403448216642 | validation: 0.4113846226150208]
	TIME [epoch: 11.1 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24041302781572194		[learning rate: 0.0090798]
	Learning Rate: 0.00907981
	LOSS [training: 0.24041302781572194 | validation: 0.36176058814359385]
	TIME [epoch: 11.1 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23986982558065462		[learning rate: 0.0090397]
	Learning Rate: 0.0090397
	LOSS [training: 0.23986982558065462 | validation: 0.45821572468880645]
	TIME [epoch: 11.1 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24765719367973849		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 0.24765719367973849 | validation: 0.41296259938454905]
	TIME [epoch: 11.1 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24214669393470434		[learning rate: 0.00896]
	Learning Rate: 0.00895999
	LOSS [training: 0.24214669393470434 | validation: 0.3378862445868858]
	TIME [epoch: 11.1 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v13b_20240716_180629/states/model_facs_v2_dec2b_2dpca_v13b_65.pth
	Model improved!!!
EPOCH 66/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24295908121814375		[learning rate: 0.0089204]
	Learning Rate: 0.00892041
	LOSS [training: 0.24295908121814375 | validation: 0.37806325320359907]
	TIME [epoch: 11.2 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21800091645879408		[learning rate: 0.008881]
	Learning Rate: 0.00888099
	LOSS [training: 0.21800091645879408 | validation: 0.3698032641334444]
	TIME [epoch: 11.1 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2669121071687789		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 0.2669121071687789 | validation: 0.40831441499995935]
	TIME [epoch: 11.1 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21963797013156583		[learning rate: 0.0088027]
	Learning Rate: 0.00880269
	LOSS [training: 0.21963797013156583 | validation: 0.43114889916155696]
	TIME [epoch: 11.1 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2364781315039095		[learning rate: 0.0087638]
	Learning Rate: 0.0087638
	LOSS [training: 0.2364781315039095 | validation: 0.3444918948470673]
	TIME [epoch: 11.1 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2412416517986619		[learning rate: 0.0087251]
	Learning Rate: 0.00872508
	LOSS [training: 0.2412416517986619 | validation: 0.341589202806029]
	TIME [epoch: 11.1 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2599842778058046		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 0.2599842778058046 | validation: 0.3373305905973703]
	TIME [epoch: 11.1 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v13b_20240716_180629/states/model_facs_v2_dec2b_2dpca_v13b_72.pth
	Model improved!!!
EPOCH 73/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21236140151481683		[learning rate: 0.0086481]
	Learning Rate: 0.00864815
	LOSS [training: 0.21236140151481683 | validation: 0.39423823004726466]
	TIME [epoch: 11.1 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2035463647966056		[learning rate: 0.0086099]
	Learning Rate: 0.00860994
	LOSS [training: 0.2035463647966056 | validation: 0.4162128369662901]
	TIME [epoch: 11.1 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2356415889787395		[learning rate: 0.0085719]
	Learning Rate: 0.0085719
	LOSS [training: 0.2356415889787395 | validation: 0.3768761017692848]
	TIME [epoch: 11.1 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23555696580854563		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 0.23555696580854563 | validation: 0.4353046014950896]
	TIME [epoch: 11.1 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.234448456994739		[learning rate: 0.0084963]
	Learning Rate: 0.00849632
	LOSS [training: 0.234448456994739 | validation: 0.32868354900397895]
	TIME [epoch: 11.1 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v13b_20240716_180629/states/model_facs_v2_dec2b_2dpca_v13b_77.pth
	Model improved!!!
EPOCH 78/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24529454729843642		[learning rate: 0.0084588]
	Learning Rate: 0.00845878
	LOSS [training: 0.24529454729843642 | validation: 0.3407965058404454]
	TIME [epoch: 11.1 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23630809165452066		[learning rate: 0.0084214]
	Learning Rate: 0.00842141
	LOSS [training: 0.23630809165452066 | validation: 0.36426655923727136]
	TIME [epoch: 11.1 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24844482375385096		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 0.24844482375385096 | validation: 0.3562850578882529]
	TIME [epoch: 11.1 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21598564924665054		[learning rate: 0.0083472]
	Learning Rate: 0.00834715
	LOSS [training: 0.21598564924665054 | validation: 0.36314323867938586]
	TIME [epoch: 11.1 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22666787168099417		[learning rate: 0.0083103]
	Learning Rate: 0.00831027
	LOSS [training: 0.22666787168099417 | validation: 0.38403335150770623]
	TIME [epoch: 11.1 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21515824057759952		[learning rate: 0.0082736]
	Learning Rate: 0.00827356
	LOSS [training: 0.21515824057759952 | validation: 0.35817271980692095]
	TIME [epoch: 11.2 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22572146525055148		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 0.22572146525055148 | validation: 0.36733808546005964]
	TIME [epoch: 11.1 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.231035976532901		[learning rate: 0.0082006]
	Learning Rate: 0.00820061
	LOSS [training: 0.231035976532901 | validation: 0.32097825382081446]
	TIME [epoch: 11.1 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v13b_20240716_180629/states/model_facs_v2_dec2b_2dpca_v13b_85.pth
	Model improved!!!
EPOCH 86/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21224568587214704		[learning rate: 0.0081644]
	Learning Rate: 0.00816438
	LOSS [training: 0.21224568587214704 | validation: 0.42024248673881043]
	TIME [epoch: 11.1 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2334258306997695		[learning rate: 0.0081283]
	Learning Rate: 0.0081283
	LOSS [training: 0.2334258306997695 | validation: 0.3808455603440289]
	TIME [epoch: 11.1 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19119281019116996		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 0.19119281019116996 | validation: 0.3589531187831952]
	TIME [epoch: 11.1 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24627157441759157		[learning rate: 0.0080566]
	Learning Rate: 0.00805664
	LOSS [training: 0.24627157441759157 | validation: 0.3349329610428794]
	TIME [epoch: 11.2 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21369024809429557		[learning rate: 0.008021]
	Learning Rate: 0.00802104
	LOSS [training: 0.21369024809429557 | validation: 0.4245033008104041]
	TIME [epoch: 11.1 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2311637197580776		[learning rate: 0.0079856]
	Learning Rate: 0.0079856
	LOSS [training: 0.2311637197580776 | validation: 0.4018819276925918]
	TIME [epoch: 11.1 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23619481811885062		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 0.23619481811885062 | validation: 0.34599266283963304]
	TIME [epoch: 11.2 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2547039564366238		[learning rate: 0.0079152]
	Learning Rate: 0.00791519
	LOSS [training: 0.2547039564366238 | validation: 0.4054301443274652]
	TIME [epoch: 11.1 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2289710949494696		[learning rate: 0.0078802]
	Learning Rate: 0.00788022
	LOSS [training: 0.2289710949494696 | validation: 0.39449769166908466]
	TIME [epoch: 11.1 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23747475110865207		[learning rate: 0.0078454]
	Learning Rate: 0.00784541
	LOSS [training: 0.23747475110865207 | validation: 0.372886721177025]
	TIME [epoch: 11.2 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22899684718397237		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 0.22899684718397237 | validation: 0.37142373993270855]
	TIME [epoch: 11.1 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21016955510083996		[learning rate: 0.0077762]
	Learning Rate: 0.00777623
	LOSS [training: 0.21016955510083996 | validation: 0.3225794849551287]
	TIME [epoch: 11.2 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21693647632331511		[learning rate: 0.0077419]
	Learning Rate: 0.00774188
	LOSS [training: 0.21693647632331511 | validation: 0.40144026196350724]
	TIME [epoch: 11.2 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2289275840061221		[learning rate: 0.0077077]
	Learning Rate: 0.00770767
	LOSS [training: 0.2289275840061221 | validation: 0.32141679080218666]
	TIME [epoch: 11.1 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20233596992945407		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 0.20233596992945407 | validation: 0.324756688347066]
	TIME [epoch: 11.1 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21425235017087582		[learning rate: 0.0076397]
	Learning Rate: 0.00763971
	LOSS [training: 0.21425235017087582 | validation: 0.4846720387091241]
	TIME [epoch: 49.7 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22822482425800833		[learning rate: 0.007606]
	Learning Rate: 0.00760596
	LOSS [training: 0.22822482425800833 | validation: 0.32673489662160005]
	TIME [epoch: 24.1 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20040157935737177		[learning rate: 0.0075724]
	Learning Rate: 0.00757235
	LOSS [training: 0.20040157935737177 | validation: 0.31034632033388504]
	TIME [epoch: 24.1 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v13b_20240716_180629/states/model_facs_v2_dec2b_2dpca_v13b_103.pth
	Model improved!!!
EPOCH 104/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19663100769164374		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 0.19663100769164374 | validation: 0.45273106003016905]
	TIME [epoch: 24 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2273013379532851		[learning rate: 0.0075056]
	Learning Rate: 0.00750559
	LOSS [training: 0.2273013379532851 | validation: 0.3788138189595715]
	TIME [epoch: 24.1 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21966465779929623		[learning rate: 0.0074724]
	Learning Rate: 0.00747242
	LOSS [training: 0.21966465779929623 | validation: 0.29604577857757886]
	TIME [epoch: 24.1 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v13b_20240716_180629/states/model_facs_v2_dec2b_2dpca_v13b_106.pth
	Model improved!!!
EPOCH 107/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21601981282168348		[learning rate: 0.0074394]
	Learning Rate: 0.00743941
	LOSS [training: 0.21601981282168348 | validation: 0.35056142816574254]
	TIME [epoch: 24.1 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20752702852358706		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 0.20752702852358706 | validation: 0.33736726107282816]
	TIME [epoch: 24.1 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2015195327297497		[learning rate: 0.0073738]
	Learning Rate: 0.00737382
	LOSS [training: 0.2015195327297497 | validation: 0.3428013486536583]
	TIME [epoch: 24 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19074466035243892		[learning rate: 0.0073412]
	Learning Rate: 0.00734124
	LOSS [training: 0.19074466035243892 | validation: 0.33759523029236477]
	TIME [epoch: 24 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2063518750591209		[learning rate: 0.0073088]
	Learning Rate: 0.0073088
	LOSS [training: 0.2063518750591209 | validation: 0.44343368400876654]
	TIME [epoch: 24 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25050321310571466		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 0.25050321310571466 | validation: 0.3228342059533615]
	TIME [epoch: 24 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20859218327944862		[learning rate: 0.0072444]
	Learning Rate: 0.00724436
	LOSS [training: 0.20859218327944862 | validation: 0.36213384135733856]
	TIME [epoch: 24 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21965379192046086		[learning rate: 0.0072124]
	Learning Rate: 0.00721235
	LOSS [training: 0.21965379192046086 | validation: 0.37458780010085874]
	TIME [epoch: 24 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21231655632415056		[learning rate: 0.0071805]
	Learning Rate: 0.00718049
	LOSS [training: 0.21231655632415056 | validation: 0.3155849194060967]
	TIME [epoch: 24.1 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20412222821901266		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 0.20412222821901266 | validation: 0.3014254680497931]
	TIME [epoch: 24 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21104775797064482		[learning rate: 0.0071172]
	Learning Rate: 0.00711718
	LOSS [training: 0.21104775797064482 | validation: 0.3486198852356793]
	TIME [epoch: 24 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19378610140514738		[learning rate: 0.0070857]
	Learning Rate: 0.00708573
	LOSS [training: 0.19378610140514738 | validation: 0.3508952034131117]
	TIME [epoch: 24 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2273856260115482		[learning rate: 0.0070544]
	Learning Rate: 0.00705442
	LOSS [training: 0.2273856260115482 | validation: 0.3487135780396014]
	TIME [epoch: 24.1 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19715199738065403		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 0.19715199738065403 | validation: 0.37839231342662666]
	TIME [epoch: 24.1 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2118021315414798		[learning rate: 0.0069922]
	Learning Rate: 0.00699222
	LOSS [training: 0.2118021315414798 | validation: 0.3245400767913819]
	TIME [epoch: 24 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21515921514920824		[learning rate: 0.0069613]
	Learning Rate: 0.00696133
	LOSS [training: 0.21515921514920824 | validation: 0.31825629217404383]
	TIME [epoch: 24.1 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19579027518033082		[learning rate: 0.0069306]
	Learning Rate: 0.00693057
	LOSS [training: 0.19579027518033082 | validation: 0.32884800401054054]
	TIME [epoch: 24 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19195393148979983		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 0.19195393148979983 | validation: 0.41217792294680206]
	TIME [epoch: 24 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21851869304903598		[learning rate: 0.0068695]
	Learning Rate: 0.00686947
	LOSS [training: 0.21851869304903598 | validation: 0.3264258462979026]
	TIME [epoch: 24 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1903973599285315		[learning rate: 0.0068391]
	Learning Rate: 0.00683912
	LOSS [training: 0.1903973599285315 | validation: 0.3087891621152073]
	TIME [epoch: 24 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20758297136178375		[learning rate: 0.0068089]
	Learning Rate: 0.0068089
	LOSS [training: 0.20758297136178375 | validation: 0.3836177990869471]
	TIME [epoch: 24 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20813236337895907		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 0.20813236337895907 | validation: 0.34994492528921717]
	TIME [epoch: 24 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19244930079401973		[learning rate: 0.0067489]
	Learning Rate: 0.00674887
	LOSS [training: 0.19244930079401973 | validation: 0.30825960354342885]
	TIME [epoch: 24 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19141038072870392		[learning rate: 0.006719]
	Learning Rate: 0.00671905
	LOSS [training: 0.19141038072870392 | validation: 0.3372527682281348]
	TIME [epoch: 24.1 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24099883385376097		[learning rate: 0.0066894]
	Learning Rate: 0.00668936
	LOSS [training: 0.24099883385376097 | validation: 0.3808554916319795]
	TIME [epoch: 24 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20918315642713017		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 0.20918315642713017 | validation: 0.3313385291736967]
	TIME [epoch: 24.1 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1951477718033823		[learning rate: 0.0066304]
	Learning Rate: 0.00663038
	LOSS [training: 0.1951477718033823 | validation: 0.37767257358130185]
	TIME [epoch: 24.1 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.215215212001059		[learning rate: 0.0066011]
	Learning Rate: 0.00660109
	LOSS [training: 0.215215212001059 | validation: 0.28764780532582607]
	TIME [epoch: 24.1 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v13b_20240716_180629/states/model_facs_v2_dec2b_2dpca_v13b_134.pth
	Model improved!!!
EPOCH 135/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1869786403422697		[learning rate: 0.0065719]
	Learning Rate: 0.00657192
	LOSS [training: 0.1869786403422697 | validation: 0.29334659328978296]
	TIME [epoch: 24.1 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20175878982810672		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 0.20175878982810672 | validation: 0.32706769663093027]
	TIME [epoch: 24.1 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21246330578337477		[learning rate: 0.006514]
	Learning Rate: 0.00651398
	LOSS [training: 0.21246330578337477 | validation: 0.34903467449763553]
	TIME [epoch: 24.1 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18494608431580656		[learning rate: 0.0064852]
	Learning Rate: 0.00648519
	LOSS [training: 0.18494608431580656 | validation: 0.330736341687018]
	TIME [epoch: 24.1 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.184773773649196		[learning rate: 0.0064565]
	Learning Rate: 0.00645654
	LOSS [training: 0.184773773649196 | validation: 0.28969692367525274]
	TIME [epoch: 24.1 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18587965201303824		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 0.18587965201303824 | validation: 0.3052193559695829]
	TIME [epoch: 24.1 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18865334896430763		[learning rate: 0.0063996]
	Learning Rate: 0.00639961
	LOSS [training: 0.18865334896430763 | validation: 0.37056488702326823]
	TIME [epoch: 24.1 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19816028750693188		[learning rate: 0.0063713]
	Learning Rate: 0.00637134
	LOSS [training: 0.19816028750693188 | validation: 0.32246530740785684]
	TIME [epoch: 24.1 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19106367466909185		[learning rate: 0.0063432]
	Learning Rate: 0.00634319
	LOSS [training: 0.19106367466909185 | validation: 0.3532239825033283]
	TIME [epoch: 24.1 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20225547887283302		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 0.20225547887283302 | validation: 0.32309137812979316]
	TIME [epoch: 24.1 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19779444781761954		[learning rate: 0.0062873]
	Learning Rate: 0.00628726
	LOSS [training: 0.19779444781761954 | validation: 0.30710697372093115]
	TIME [epoch: 24.1 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17974597759361616		[learning rate: 0.0062595]
	Learning Rate: 0.00625948
	LOSS [training: 0.17974597759361616 | validation: 0.29908274505303295]
	TIME [epoch: 24.1 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.200972329292921		[learning rate: 0.0062318]
	Learning Rate: 0.00623183
	LOSS [training: 0.200972329292921 | validation: 0.31539686757304786]
	TIME [epoch: 24.1 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1830200536632114		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 0.1830200536632114 | validation: 0.32039716413776254]
	TIME [epoch: 24.1 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18096973518772227		[learning rate: 0.0061769]
	Learning Rate: 0.00617688
	LOSS [training: 0.18096973518772227 | validation: 0.2993000146974847]
	TIME [epoch: 24.1 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19888112992900336		[learning rate: 0.0061496]
	Learning Rate: 0.00614959
	LOSS [training: 0.19888112992900336 | validation: 0.33084928551697534]
	TIME [epoch: 24.1 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1881761116637162		[learning rate: 0.0061224]
	Learning Rate: 0.00612242
	LOSS [training: 0.1881761116637162 | validation: 0.3138866667832345]
	TIME [epoch: 24.1 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19380446944881194		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 0.19380446944881194 | validation: 0.31756025059570436]
	TIME [epoch: 24.1 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18160553950810163		[learning rate: 0.0060684]
	Learning Rate: 0.00606844
	LOSS [training: 0.18160553950810163 | validation: 0.31144321287725385]
	TIME [epoch: 24.1 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.178825972856285		[learning rate: 0.0060416]
	Learning Rate: 0.00604163
	LOSS [training: 0.178825972856285 | validation: 0.3061763764094746]
	TIME [epoch: 24.1 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17947262385027923		[learning rate: 0.0060149]
	Learning Rate: 0.00601493
	LOSS [training: 0.17947262385027923 | validation: 0.3531321192661394]
	TIME [epoch: 24.1 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20226656010780736		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 0.20226656010780736 | validation: 0.30395080910176314]
	TIME [epoch: 24 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18729898875480006		[learning rate: 0.0059619]
	Learning Rate: 0.0059619
	LOSS [training: 0.18729898875480006 | validation: 0.3043918893174397]
	TIME [epoch: 24.1 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1748494990540393		[learning rate: 0.0059356]
	Learning Rate: 0.00593556
	LOSS [training: 0.1748494990540393 | validation: 0.322427528694736]
	TIME [epoch: 24.1 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19520855881603716		[learning rate: 0.0059093]
	Learning Rate: 0.00590933
	LOSS [training: 0.19520855881603716 | validation: 0.3195333551032716]
	TIME [epoch: 24.1 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20280590674113896		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 0.20280590674113896 | validation: 0.2921713832562729]
	TIME [epoch: 24.1 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1890819884305252		[learning rate: 0.0058572]
	Learning Rate: 0.00585723
	LOSS [training: 0.1890819884305252 | validation: 0.33334446922253147]
	TIME [epoch: 24.1 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1917788162628355		[learning rate: 0.0058314]
	Learning Rate: 0.00583135
	LOSS [training: 0.1917788162628355 | validation: 0.33601176756606704]
	TIME [epoch: 24 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2050949176506212		[learning rate: 0.0058056]
	Learning Rate: 0.00580559
	LOSS [training: 0.2050949176506212 | validation: 0.32168101802532034]
	TIME [epoch: 24.1 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2020367998775688		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 0.2020367998775688 | validation: 0.32102862857391573]
	TIME [epoch: 24.1 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18075222909161542		[learning rate: 0.0057544]
	Learning Rate: 0.0057544
	LOSS [training: 0.18075222909161542 | validation: 0.34854787174142426]
	TIME [epoch: 24.1 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18867846052884713		[learning rate: 0.005729]
	Learning Rate: 0.00572897
	LOSS [training: 0.18867846052884713 | validation: 0.32052161106853505]
	TIME [epoch: 24.1 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19180235036646226		[learning rate: 0.0057037]
	Learning Rate: 0.00570366
	LOSS [training: 0.19180235036646226 | validation: 0.329522354059773]
	TIME [epoch: 24.1 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19490476862650147		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 0.19490476862650147 | validation: 0.28389722305395615]
	TIME [epoch: 24.1 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v13b_20240716_180629/states/model_facs_v2_dec2b_2dpca_v13b_168.pth
	Model improved!!!
EPOCH 169/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21545964935327264		[learning rate: 0.0056534]
	Learning Rate: 0.00565337
	LOSS [training: 0.21545964935327264 | validation: 0.30979042538111035]
	TIME [epoch: 24.1 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18477942599848263		[learning rate: 0.0056284]
	Learning Rate: 0.0056284
	LOSS [training: 0.18477942599848263 | validation: 0.2979127381288193]
	TIME [epoch: 24 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18466334381404695		[learning rate: 0.0056035]
	Learning Rate: 0.00560353
	LOSS [training: 0.18466334381404695 | validation: 0.37682834811590726]
	TIME [epoch: 24.1 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19107172691063698		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 0.19107172691063698 | validation: 0.28292806096556933]
	TIME [epoch: 24.1 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v13b_20240716_180629/states/model_facs_v2_dec2b_2dpca_v13b_172.pth
	Model improved!!!
EPOCH 173/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19411954816447302		[learning rate: 0.0055541]
	Learning Rate: 0.00555412
	LOSS [training: 0.19411954816447302 | validation: 0.2896971787785495]
	TIME [epoch: 24.1 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18166015802782665		[learning rate: 0.0055296]
	Learning Rate: 0.00552958
	LOSS [training: 0.18166015802782665 | validation: 0.294425383244286]
	TIME [epoch: 24 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17417292585899533		[learning rate: 0.0055052]
	Learning Rate: 0.00550515
	LOSS [training: 0.17417292585899533 | validation: 0.33140774292864883]
	TIME [epoch: 24 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18309418007595055		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 0.18309418007595055 | validation: 0.3091998575659577]
	TIME [epoch: 24 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17618959831230507		[learning rate: 0.0054566]
	Learning Rate: 0.00545661
	LOSS [training: 0.17618959831230507 | validation: 0.28616060735420007]
	TIME [epoch: 24 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20995843173430484		[learning rate: 0.0054325]
	Learning Rate: 0.0054325
	LOSS [training: 0.20995843173430484 | validation: 0.37931349378124957]
	TIME [epoch: 24 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22535556462759682		[learning rate: 0.0054085]
	Learning Rate: 0.0054085
	LOSS [training: 0.22535556462759682 | validation: 0.40991765450804385]
	TIME [epoch: 24 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20851567145429448		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 0.20851567145429448 | validation: 0.34343240469818087]
	TIME [epoch: 24 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18989608581232348		[learning rate: 0.0053608]
	Learning Rate: 0.00536081
	LOSS [training: 0.18989608581232348 | validation: 0.312371816902157]
	TIME [epoch: 24 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21057079043457322		[learning rate: 0.0053371]
	Learning Rate: 0.00533713
	LOSS [training: 0.21057079043457322 | validation: 0.3181513856038911]
	TIME [epoch: 24 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20666065638996928		[learning rate: 0.0053135]
	Learning Rate: 0.00531355
	LOSS [training: 0.20666065638996928 | validation: 0.3392607744782039]
	TIME [epoch: 24 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1761469789442203		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 0.1761469789442203 | validation: 0.3378203547887132]
	TIME [epoch: 24 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18546787475205026		[learning rate: 0.0052667]
	Learning Rate: 0.0052667
	LOSS [training: 0.18546787475205026 | validation: 0.33953341694606276]
	TIME [epoch: 24.1 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17780469202683008		[learning rate: 0.0052434]
	Learning Rate: 0.00524343
	LOSS [training: 0.17780469202683008 | validation: 0.31666792785322945]
	TIME [epoch: 24 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18082468703405752		[learning rate: 0.0052203]
	Learning Rate: 0.00522026
	LOSS [training: 0.18082468703405752 | validation: 0.3178511074816959]
	TIME [epoch: 24.1 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1750141227536002		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 0.1750141227536002 | validation: 0.2879606297672245]
	TIME [epoch: 24.1 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1767237232797787		[learning rate: 0.0051742]
	Learning Rate: 0.00517423
	LOSS [training: 0.1767237232797787 | validation: 0.2785516329594901]
	TIME [epoch: 24 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v13b_20240716_180629/states/model_facs_v2_dec2b_2dpca_v13b_189.pth
	Model improved!!!
EPOCH 190/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17042571831234093		[learning rate: 0.0051514]
	Learning Rate: 0.00515137
	LOSS [training: 0.17042571831234093 | validation: 0.3152750748760813]
	TIME [epoch: 24.1 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20042089179630276		[learning rate: 0.0051286]
	Learning Rate: 0.00512861
	LOSS [training: 0.20042089179630276 | validation: 0.33738776395672115]
	TIME [epoch: 24.1 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1843058240214518		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 0.1843058240214518 | validation: 0.3401106228250994]
	TIME [epoch: 24.1 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1895183812688809		[learning rate: 0.0050834]
	Learning Rate: 0.00508339
	LOSS [training: 0.1895183812688809 | validation: 0.34240447982507666]
	TIME [epoch: 24.1 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18805990182622379		[learning rate: 0.0050609]
	Learning Rate: 0.00506093
	LOSS [training: 0.18805990182622379 | validation: 0.2873562387023186]
	TIME [epoch: 24.1 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16679557299046452		[learning rate: 0.0050386]
	Learning Rate: 0.00503857
	LOSS [training: 0.16679557299046452 | validation: 0.3078901927202181]
	TIME [epoch: 24.1 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18146101811729312		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 0.18146101811729312 | validation: 0.3213936746817966]
	TIME [epoch: 24.1 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1774175510765574		[learning rate: 0.0049941]
	Learning Rate: 0.00499415
	LOSS [training: 0.1774175510765574 | validation: 0.29838575947929286]
	TIME [epoch: 24.1 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18130694929602412		[learning rate: 0.0049721]
	Learning Rate: 0.00497208
	LOSS [training: 0.18130694929602412 | validation: 0.29098468601740896]
	TIME [epoch: 24.1 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17240459182427106		[learning rate: 0.0049501]
	Learning Rate: 0.00495012
	LOSS [training: 0.17240459182427106 | validation: 0.2964861610743805]
	TIME [epoch: 24.1 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1784381923336279		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 0.1784381923336279 | validation: 0.3158286450388784]
	TIME [epoch: 24.1 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1737727816776456		[learning rate: 0.0049065]
	Learning Rate: 0.00490647
	LOSS [training: 0.1737727816776456 | validation: 0.3096140041747391]
	TIME [epoch: 77 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1742056455668849		[learning rate: 0.0048848]
	Learning Rate: 0.00488479
	LOSS [training: 0.1742056455668849 | validation: 0.29914508334578604]
	TIME [epoch: 51.5 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18057286254477384		[learning rate: 0.0048632]
	Learning Rate: 0.00486321
	LOSS [training: 0.18057286254477384 | validation: 0.29597108149008866]
	TIME [epoch: 51.5 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17737883137819282		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 0.17737883137819282 | validation: 0.2986131294787108]
	TIME [epoch: 51.5 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1708844675530637		[learning rate: 0.0048203]
	Learning Rate: 0.00482033
	LOSS [training: 0.1708844675530637 | validation: 0.3451579175581042]
	TIME [epoch: 51.5 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18942726933201479		[learning rate: 0.004799]
	Learning Rate: 0.00479903
	LOSS [training: 0.18942726933201479 | validation: 0.31774631638183715]
	TIME [epoch: 51.5 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17911523141606692		[learning rate: 0.0047778]
	Learning Rate: 0.00477783
	LOSS [training: 0.17911523141606692 | validation: 0.30053757827226935]
	TIME [epoch: 51.5 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17477528147779667		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.17477528147779667 | validation: 0.3478044556825638]
	TIME [epoch: 51.5 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17617090475313604		[learning rate: 0.0047357]
	Learning Rate: 0.0047357
	LOSS [training: 0.17617090475313604 | validation: 0.33144583272969524]
	TIME [epoch: 51.5 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17473468820541233		[learning rate: 0.0047148]
	Learning Rate: 0.00471478
	LOSS [training: 0.17473468820541233 | validation: 0.33762525007189365]
	TIME [epoch: 51.5 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18437623049719337		[learning rate: 0.0046939]
	Learning Rate: 0.00469395
	LOSS [training: 0.18437623049719337 | validation: 0.31932001932063564]
	TIME [epoch: 51.5 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1643399211896405		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 0.1643399211896405 | validation: 0.31889484629273285]
	TIME [epoch: 51.5 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17180434771276937		[learning rate: 0.0046526]
	Learning Rate: 0.00465256
	LOSS [training: 0.17180434771276937 | validation: 0.3058313459773688]
	TIME [epoch: 51.6 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1756747505797502		[learning rate: 0.004632]
	Learning Rate: 0.00463201
	LOSS [training: 0.1756747505797502 | validation: 0.31041640370563656]
	TIME [epoch: 51.5 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1767657792294114		[learning rate: 0.0046115]
	Learning Rate: 0.00461154
	LOSS [training: 0.1767657792294114 | validation: 0.33871500091665946]
	TIME [epoch: 51.5 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16962276903787774		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 0.16962276903787774 | validation: 0.31675164003321127]
	TIME [epoch: 51.5 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17299742385719924		[learning rate: 0.0045709]
	Learning Rate: 0.00457088
	LOSS [training: 0.17299742385719924 | validation: 0.29652361411124073]
	TIME [epoch: 51.6 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17621059545787246		[learning rate: 0.0045507]
	Learning Rate: 0.00455069
	LOSS [training: 0.17621059545787246 | validation: 0.29021024292861974]
	TIME [epoch: 51.5 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17554060083576198		[learning rate: 0.0045306]
	Learning Rate: 0.00453058
	LOSS [training: 0.17554060083576198 | validation: 0.32348900442844764]
	TIME [epoch: 51.6 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19444292398577226		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 0.19444292398577226 | validation: 0.3368657522359089]
	TIME [epoch: 51.5 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17953772720674807		[learning rate: 0.0044906]
	Learning Rate: 0.00449063
	LOSS [training: 0.17953772720674807 | validation: 0.29621724383407694]
	TIME [epoch: 51.6 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17311913191930273		[learning rate: 0.0044708]
	Learning Rate: 0.00447079
	LOSS [training: 0.17311913191930273 | validation: 0.3032367779825307]
	TIME [epoch: 51.5 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16902226627204717		[learning rate: 0.004451]
	Learning Rate: 0.00445104
	LOSS [training: 0.16902226627204717 | validation: 0.3111700109121922]
	TIME [epoch: 51.5 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16823794799673228		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 0.16823794799673228 | validation: 0.3487571340441941]
	TIME [epoch: 51.5 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1911344447916824		[learning rate: 0.0044118]
	Learning Rate: 0.0044118
	LOSS [training: 0.1911344447916824 | validation: 0.32043888924631103]
	TIME [epoch: 51.5 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1730662036026128		[learning rate: 0.0043923]
	Learning Rate: 0.0043923
	LOSS [training: 0.1730662036026128 | validation: 0.2923060508235941]
	TIME [epoch: 51.5 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1652218124336883		[learning rate: 0.0043729]
	Learning Rate: 0.0043729
	LOSS [training: 0.1652218124336883 | validation: 0.3291733095031123]
	TIME [epoch: 51.5 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17793374454119032		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 0.17793374454119032 | validation: 0.3555463012806322]
	TIME [epoch: 51.5 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17866480854879344		[learning rate: 0.0043343]
	Learning Rate: 0.00433434
	LOSS [training: 0.17866480854879344 | validation: 0.321838412079223]
	TIME [epoch: 51.5 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16642977275100218		[learning rate: 0.0043152]
	Learning Rate: 0.00431519
	LOSS [training: 0.16642977275100218 | validation: 0.32289032721812383]
	TIME [epoch: 51.5 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1750156736307712		[learning rate: 0.0042961]
	Learning Rate: 0.00429612
	LOSS [training: 0.1750156736307712 | validation: 0.33239947500016376]
	TIME [epoch: 51.5 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16698735775764914		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 0.16698735775764914 | validation: 0.32840028922414455]
	TIME [epoch: 51.5 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16070408381783569		[learning rate: 0.0042582]
	Learning Rate: 0.00425825
	LOSS [training: 0.16070408381783569 | validation: 0.3056509862281131]
	TIME [epoch: 51.5 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17258353367996396		[learning rate: 0.0042394]
	Learning Rate: 0.00423943
	LOSS [training: 0.17258353367996396 | validation: 0.36863105536744545]
	TIME [epoch: 51.5 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1793714911118119		[learning rate: 0.0042207]
	Learning Rate: 0.0042207
	LOSS [training: 0.1793714911118119 | validation: 0.3160933974435875]
	TIME [epoch: 51.5 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16474034128157272		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 0.16474034128157272 | validation: 0.28480865364888663]
	TIME [epoch: 51.5 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16909218621084807		[learning rate: 0.0041835]
	Learning Rate: 0.00418349
	LOSS [training: 0.16909218621084807 | validation: 0.28828371138182823]
	TIME [epoch: 51.6 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16683776988921012		[learning rate: 0.004165]
	Learning Rate: 0.004165
	LOSS [training: 0.16683776988921012 | validation: 0.31503220539719473]
	TIME [epoch: 51.5 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16336998055650664		[learning rate: 0.0041466]
	Learning Rate: 0.0041466
	LOSS [training: 0.16336998055650664 | validation: 0.32289953761146006]
	TIME [epoch: 51.5 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17952520009803147		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 0.17952520009803147 | validation: 0.28719397654277895]
	TIME [epoch: 51.5 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1759399303705996		[learning rate: 0.00411]
	Learning Rate: 0.00411004
	LOSS [training: 0.1759399303705996 | validation: 0.32039455523831495]
	TIME [epoch: 51.5 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17300938751090544		[learning rate: 0.0040919]
	Learning Rate: 0.00409188
	LOSS [training: 0.17300938751090544 | validation: 0.3142890875497851]
	TIME [epoch: 51.5 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16487211188185924		[learning rate: 0.0040738]
	Learning Rate: 0.0040738
	LOSS [training: 0.16487211188185924 | validation: 0.29094277190477913]
	TIME [epoch: 51.5 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1700121052679211		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.1700121052679211 | validation: 0.3478017452542367]
	TIME [epoch: 51.5 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1707911597087721		[learning rate: 0.0040379]
	Learning Rate: 0.00403788
	LOSS [training: 0.1707911597087721 | validation: 0.31910793297597656]
	TIME [epoch: 51.5 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16225481755742419		[learning rate: 0.00402]
	Learning Rate: 0.00402004
	LOSS [training: 0.16225481755742419 | validation: 0.2942278217969307]
	TIME [epoch: 51.5 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15914407700848238		[learning rate: 0.0040023]
	Learning Rate: 0.00400228
	LOSS [training: 0.15914407700848238 | validation: 0.2936693307416814]
	TIME [epoch: 51.6 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16855351642007735		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 0.16855351642007735 | validation: 0.30134571398362237]
	TIME [epoch: 51.5 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16140122953831845		[learning rate: 0.003967]
	Learning Rate: 0.00396699
	LOSS [training: 0.16140122953831845 | validation: 0.29913303097451815]
	TIME [epoch: 51.6 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16974824885696832		[learning rate: 0.0039495]
	Learning Rate: 0.00394947
	LOSS [training: 0.16974824885696832 | validation: 0.338743883841377]
	TIME [epoch: 51.5 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18085148214512925		[learning rate: 0.003932]
	Learning Rate: 0.00393202
	LOSS [training: 0.18085148214512925 | validation: 0.3500261093886481]
	TIME [epoch: 51.5 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18216130285400015		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 0.18216130285400015 | validation: 0.2859401690844994]
	TIME [epoch: 51.5 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16113460502368074		[learning rate: 0.0038973]
	Learning Rate: 0.00389735
	LOSS [training: 0.16113460502368074 | validation: 0.31541441871579645]
	TIME [epoch: 51.5 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16081092565330088		[learning rate: 0.0038801]
	Learning Rate: 0.00388013
	LOSS [training: 0.16081092565330088 | validation: 0.3043568496695188]
	TIME [epoch: 51.5 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16541498755954026		[learning rate: 0.003863]
	Learning Rate: 0.00386299
	LOSS [training: 0.16541498755954026 | validation: 0.29693305615401155]
	TIME [epoch: 51.5 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15722070221792855		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 0.15722070221792855 | validation: 0.31951717799222523]
	TIME [epoch: 51.5 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16274603257416886		[learning rate: 0.0038289]
	Learning Rate: 0.00382893
	LOSS [training: 0.16274603257416886 | validation: 0.3116657666687117]
	TIME [epoch: 51.5 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16606250165415853		[learning rate: 0.003812]
	Learning Rate: 0.00381201
	LOSS [training: 0.16606250165415853 | validation: 0.3125568110653639]
	TIME [epoch: 51.5 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.160406812044041		[learning rate: 0.0037952]
	Learning Rate: 0.00379517
	LOSS [training: 0.160406812044041 | validation: 0.2819463257859431]
	TIME [epoch: 51.5 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15909596808473384		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 0.15909596808473384 | validation: 0.2933368207972501]
	TIME [epoch: 51.5 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1637349687833691		[learning rate: 0.0037617]
	Learning Rate: 0.0037617
	LOSS [training: 0.1637349687833691 | validation: 0.3008230534846041]
	TIME [epoch: 51.5 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17929171407353856		[learning rate: 0.0037451]
	Learning Rate: 0.00374508
	LOSS [training: 0.17929171407353856 | validation: 0.3066782685532592]
	TIME [epoch: 51.5 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1644157662010222		[learning rate: 0.0037285]
	Learning Rate: 0.00372854
	LOSS [training: 0.1644157662010222 | validation: 0.3016241725969835]
	TIME [epoch: 51.5 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16436737076464117		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 0.16436737076464117 | validation: 0.30267310909208317]
	TIME [epoch: 51.5 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16177930930500217		[learning rate: 0.0036957]
	Learning Rate: 0.00369566
	LOSS [training: 0.16177930930500217 | validation: 0.30350090437783367]
	TIME [epoch: 51.5 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16080779129043407		[learning rate: 0.0036793]
	Learning Rate: 0.00367933
	LOSS [training: 0.16080779129043407 | validation: 0.3239004950417303]
	TIME [epoch: 51.5 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22211869935726117		[learning rate: 0.0036631]
	Learning Rate: 0.00366308
	LOSS [training: 0.22211869935726117 | validation: 0.344945491645483]
	TIME [epoch: 51.5 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19167107727271915		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 0.19167107727271915 | validation: 0.3121388376052126]
	TIME [epoch: 51.5 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15676071146968598		[learning rate: 0.0036308]
	Learning Rate: 0.00363078
	LOSS [training: 0.15676071146968598 | validation: 0.3440892827464318]
	TIME [epoch: 51.5 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1609747202828785		[learning rate: 0.0036147]
	Learning Rate: 0.00361474
	LOSS [training: 0.1609747202828785 | validation: 0.30305735983508]
	TIME [epoch: 51.5 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1661440567495008		[learning rate: 0.0035988]
	Learning Rate: 0.00359877
	LOSS [training: 0.1661440567495008 | validation: 0.30078642708743797]
	TIME [epoch: 51.5 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1591813280516452		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 0.1591813280516452 | validation: 0.32277611157315095]
	TIME [epoch: 51.5 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16610070999498933		[learning rate: 0.003567]
	Learning Rate: 0.00356704
	LOSS [training: 0.16610070999498933 | validation: 0.32033073289183006]
	TIME [epoch: 51.5 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1586723499187713		[learning rate: 0.0035513]
	Learning Rate: 0.00355128
	LOSS [training: 0.1586723499187713 | validation: 0.281682569531412]
	TIME [epoch: 51.5 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15453710783068586		[learning rate: 0.0035356]
	Learning Rate: 0.00353559
	LOSS [training: 0.15453710783068586 | validation: 0.29115520299402975]
	TIME [epoch: 51.5 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1607960505246922		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 0.1607960505246922 | validation: 0.32647847006351244]
	TIME [epoch: 51.5 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16605464848935023		[learning rate: 0.0035044]
	Learning Rate: 0.00350441
	LOSS [training: 0.16605464848935023 | validation: 0.3218540205552409]
	TIME [epoch: 51.5 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15886077564602333		[learning rate: 0.0034889]
	Learning Rate: 0.00348893
	LOSS [training: 0.15886077564602333 | validation: 0.28251746916361625]
	TIME [epoch: 51.4 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16087309603169728		[learning rate: 0.0034735]
	Learning Rate: 0.00347352
	LOSS [training: 0.16087309603169728 | validation: 0.29002961418019185]
	TIME [epoch: 51.5 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16376945965748785		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.16376945965748785 | validation: 0.30341300705032925]
	TIME [epoch: 51.5 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1593220850843442		[learning rate: 0.0034429]
	Learning Rate: 0.00344289
	LOSS [training: 0.1593220850843442 | validation: 0.2930395261759316]
	TIME [epoch: 51.5 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15930887819602046		[learning rate: 0.0034277]
	Learning Rate: 0.00342768
	LOSS [training: 0.15930887819602046 | validation: 0.3260832191695234]
	TIME [epoch: 51.5 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16645431156409493		[learning rate: 0.0034125]
	Learning Rate: 0.00341253
	LOSS [training: 0.16645431156409493 | validation: 0.27974344862180345]
	TIME [epoch: 51.5 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16145247879133015		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 0.16145247879133015 | validation: 0.27276815500887525]
	TIME [epoch: 51.5 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v13b_20240716_180629/states/model_facs_v2_dec2b_2dpca_v13b_284.pth
	Model improved!!!
EPOCH 285/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16232359858602236		[learning rate: 0.0033824]
	Learning Rate: 0.00338245
	LOSS [training: 0.16232359858602236 | validation: 0.3263781020743441]
	TIME [epoch: 51.6 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16072825768235874		[learning rate: 0.0033675]
	Learning Rate: 0.0033675
	LOSS [training: 0.16072825768235874 | validation: 0.301337254022898]
	TIME [epoch: 51.5 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1579163529472345		[learning rate: 0.0033526]
	Learning Rate: 0.00335262
	LOSS [training: 0.1579163529472345 | validation: 0.30276662561882717]
	TIME [epoch: 51.5 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15991514567439197		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 0.15991514567439197 | validation: 0.36962346338685687]
	TIME [epoch: 51.6 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1596612842819864		[learning rate: 0.0033231]
	Learning Rate: 0.00332306
	LOSS [training: 0.1596612842819864 | validation: 0.2764303893613949]
	TIME [epoch: 51.5 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16170059056885117		[learning rate: 0.0033084]
	Learning Rate: 0.00330838
	LOSS [training: 0.16170059056885117 | validation: 0.3013712492578378]
	TIME [epoch: 51.5 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16113526907285317		[learning rate: 0.0032938]
	Learning Rate: 0.00329376
	LOSS [training: 0.16113526907285317 | validation: 0.31764089298695464]
	TIME [epoch: 51.5 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16101251171108383		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 0.16101251171108383 | validation: 0.3026591635459847]
	TIME [epoch: 51.5 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16376721476186495		[learning rate: 0.0032647]
	Learning Rate: 0.00326472
	LOSS [training: 0.16376721476186495 | validation: 0.30842462617668737]
	TIME [epoch: 51.5 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15534092250496126		[learning rate: 0.0032503]
	Learning Rate: 0.0032503
	LOSS [training: 0.15534092250496126 | validation: 0.30110284661483916]
	TIME [epoch: 51.5 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1684714746715584		[learning rate: 0.0032359]
	Learning Rate: 0.00323594
	LOSS [training: 0.1684714746715584 | validation: 0.2848167565813108]
	TIME [epoch: 51.5 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15496374732476537		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 0.15496374732476537 | validation: 0.3244043444993648]
	TIME [epoch: 51.5 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15943357192431779		[learning rate: 0.0032074]
	Learning Rate: 0.00320741
	LOSS [training: 0.15943357192431779 | validation: 0.30481188421450683]
	TIME [epoch: 51.5 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16120641848487777		[learning rate: 0.0031932]
	Learning Rate: 0.00319323
	LOSS [training: 0.16120641848487777 | validation: 0.3232983476062947]
	TIME [epoch: 51.5 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16424852765881104		[learning rate: 0.0031791]
	Learning Rate: 0.00317913
	LOSS [training: 0.16424852765881104 | validation: 0.3055145996182155]
	TIME [epoch: 51.5 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16060014638937442		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 0.16060014638937442 | validation: 0.3206455042981429]
	TIME [epoch: 51.5 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16455960913228967		[learning rate: 0.0031511]
	Learning Rate: 0.0031511
	LOSS [training: 0.16455960913228967 | validation: 0.28231395696755673]
	TIME [epoch: 132 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1544232233325759		[learning rate: 0.0031372]
	Learning Rate: 0.00313717
	LOSS [training: 0.1544232233325759 | validation: 0.33130170024303507]
	TIME [epoch: 106 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15759780311706956		[learning rate: 0.0031233]
	Learning Rate: 0.00312331
	LOSS [training: 0.15759780311706956 | validation: 0.2816045267208888]
	TIME [epoch: 106 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15609064680598678		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 0.15609064680598678 | validation: 0.29668302224047155]
	TIME [epoch: 106 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16026787215596722		[learning rate: 0.0030958]
	Learning Rate: 0.00309577
	LOSS [training: 0.16026787215596722 | validation: 0.29971458460237344]
	TIME [epoch: 106 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15303583251472347		[learning rate: 0.0030821]
	Learning Rate: 0.0030821
	LOSS [training: 0.15303583251472347 | validation: 0.31269376746353517]
	TIME [epoch: 106 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15465794732924015		[learning rate: 0.0030685]
	Learning Rate: 0.00306848
	LOSS [training: 0.15465794732924015 | validation: 0.28199723335935356]
	TIME [epoch: 106 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15811072148100164		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 0.15811072148100164 | validation: 0.31129243760749925]
	TIME [epoch: 106 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16328344909596534		[learning rate: 0.0030414]
	Learning Rate: 0.00304142
	LOSS [training: 0.16328344909596534 | validation: 0.27925995974675694]
	TIME [epoch: 106 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15765182745669776		[learning rate: 0.003028]
	Learning Rate: 0.00302799
	LOSS [training: 0.15765182745669776 | validation: 0.2900464505749295]
	TIME [epoch: 106 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16312593187648114		[learning rate: 0.0030146]
	Learning Rate: 0.00301461
	LOSS [training: 0.16312593187648114 | validation: 0.2993009615232303]
	TIME [epoch: 106 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16301477969950834		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 0.16301477969950834 | validation: 0.30426870805567]
	TIME [epoch: 106 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16832028068784405		[learning rate: 0.002988]
	Learning Rate: 0.00298803
	LOSS [training: 0.16832028068784405 | validation: 0.30616449456555406]
	TIME [epoch: 106 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16717704609784936		[learning rate: 0.0029748]
	Learning Rate: 0.00297483
	LOSS [training: 0.16717704609784936 | validation: 0.2879555138625726]
	TIME [epoch: 106 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15695833381984933		[learning rate: 0.0029617]
	Learning Rate: 0.00296168
	LOSS [training: 0.15695833381984933 | validation: 0.33619754021177295]
	TIME [epoch: 106 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1595455944626952		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.1595455944626952 | validation: 0.37298701387539274]
	TIME [epoch: 106 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1529170868365845		[learning rate: 0.0029356]
	Learning Rate: 0.00293557
	LOSS [training: 0.1529170868365845 | validation: 0.3020326248961293]
	TIME [epoch: 106 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15695454323897223		[learning rate: 0.0029226]
	Learning Rate: 0.0029226
	LOSS [training: 0.15695454323897223 | validation: 0.30040939702527314]
	TIME [epoch: 106 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15456595474579804		[learning rate: 0.0029097]
	Learning Rate: 0.00290969
	LOSS [training: 0.15456595474579804 | validation: 0.30863435359418756]
	TIME [epoch: 106 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15724811142120146		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 0.15724811142120146 | validation: 0.32910057321025055]
	TIME [epoch: 106 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16111257464712425		[learning rate: 0.002884]
	Learning Rate: 0.00288403
	LOSS [training: 0.16111257464712425 | validation: 0.2960575536330589]
	TIME [epoch: 106 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15708440327489065		[learning rate: 0.0028713]
	Learning Rate: 0.00287129
	LOSS [training: 0.15708440327489065 | validation: 0.3001164070397988]
	TIME [epoch: 106 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15487239333645686		[learning rate: 0.0028586]
	Learning Rate: 0.0028586
	LOSS [training: 0.15487239333645686 | validation: 0.2945722964957542]
	TIME [epoch: 106 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1537628869999581		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 0.1537628869999581 | validation: 0.27182651193589513]
	TIME [epoch: 106 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v13b_20240716_180629/states/model_facs_v2_dec2b_2dpca_v13b_324.pth
	Model improved!!!
EPOCH 325/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15555753487925686		[learning rate: 0.0028334]
	Learning Rate: 0.0028334
	LOSS [training: 0.15555753487925686 | validation: 0.29629264178709874]
	TIME [epoch: 106 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16252816574715806		[learning rate: 0.0028209]
	Learning Rate: 0.00282088
	LOSS [training: 0.16252816574715806 | validation: 0.2992656235812154]
	TIME [epoch: 106 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1610140522728962		[learning rate: 0.0028084]
	Learning Rate: 0.00280842
	LOSS [training: 0.1610140522728962 | validation: 0.3110764809089215]
	TIME [epoch: 106 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1564169888262616		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 0.1564169888262616 | validation: 0.3128172919305923]
	TIME [epoch: 106 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15172892171776337		[learning rate: 0.0027837]
	Learning Rate: 0.00278366
	LOSS [training: 0.15172892171776337 | validation: 0.2721333191628624]
	TIME [epoch: 106 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15525969195245543		[learning rate: 0.0027714]
	Learning Rate: 0.00277136
	LOSS [training: 0.15525969195245543 | validation: 0.3130091762603409]
	TIME [epoch: 106 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1537512700577227		[learning rate: 0.0027591]
	Learning Rate: 0.00275911
	LOSS [training: 0.1537512700577227 | validation: 0.294422202037038]
	TIME [epoch: 106 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15767690865121084		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 0.15767690865121084 | validation: 0.2732832048080573]
	TIME [epoch: 106 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1602642167547274		[learning rate: 0.0027348]
	Learning Rate: 0.00273478
	LOSS [training: 0.1602642167547274 | validation: 0.2761992265541738]
	TIME [epoch: 106 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15577550974761298		[learning rate: 0.0027227]
	Learning Rate: 0.0027227
	LOSS [training: 0.15577550974761298 | validation: 0.27985800686555196]
	TIME [epoch: 106 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15528034556261136		[learning rate: 0.0027107]
	Learning Rate: 0.00271067
	LOSS [training: 0.15528034556261136 | validation: 0.3038328095793244]
	TIME [epoch: 106 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1643304427014581		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 0.1643304427014581 | validation: 0.2880742900080149]
	TIME [epoch: 106 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15452511667224453		[learning rate: 0.0026868]
	Learning Rate: 0.00268677
	LOSS [training: 0.15452511667224453 | validation: 0.27750726108436535]
	TIME [epoch: 106 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1623836676992953		[learning rate: 0.0026749]
	Learning Rate: 0.0026749
	LOSS [training: 0.1623836676992953 | validation: 0.3191898543293332]
	TIME [epoch: 106 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16230598183119788		[learning rate: 0.0026631]
	Learning Rate: 0.00266308
	LOSS [training: 0.16230598183119788 | validation: 0.2758342762744522]
	TIME [epoch: 106 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15859220036068525		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 0.15859220036068525 | validation: 0.2685512436943996]
	TIME [epoch: 106 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v13b_20240716_180629/states/model_facs_v2_dec2b_2dpca_v13b_340.pth
	Model improved!!!
EPOCH 341/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15996442807589992		[learning rate: 0.0026396]
	Learning Rate: 0.0026396
	LOSS [training: 0.15996442807589992 | validation: 0.2908408693456271]
	TIME [epoch: 106 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1516620231949271		[learning rate: 0.0026279]
	Learning Rate: 0.00262794
	LOSS [training: 0.1516620231949271 | validation: 0.28031733227400957]
	TIME [epoch: 106 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15639640090120493		[learning rate: 0.0026163]
	Learning Rate: 0.00261633
	LOSS [training: 0.15639640090120493 | validation: 0.2782304172420354]
	TIME [epoch: 106 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15873684426697734		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 0.15873684426697734 | validation: 0.27611135104812434]
	TIME [epoch: 107 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15272708384335862		[learning rate: 0.0025933]
	Learning Rate: 0.00259326
	LOSS [training: 0.15272708384335862 | validation: 0.3066470103755607]
	TIME [epoch: 106 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1513582320438518		[learning rate: 0.0025818]
	Learning Rate: 0.0025818
	LOSS [training: 0.1513582320438518 | validation: 0.3062884179292592]
	TIME [epoch: 107 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1541583802028787		[learning rate: 0.0025704]
	Learning Rate: 0.0025704
	LOSS [training: 0.1541583802028787 | validation: 0.30875196512685843]
	TIME [epoch: 107 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15591057603119166		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.15591057603119166 | validation: 0.296594565396694]
	TIME [epoch: 107 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16425856162059635		[learning rate: 0.0025477]
	Learning Rate: 0.00254773
	LOSS [training: 0.16425856162059635 | validation: 0.3150315204217194]
	TIME [epoch: 107 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15586708906705807		[learning rate: 0.0025365]
	Learning Rate: 0.00253648
	LOSS [training: 0.15586708906705807 | validation: 0.3037815748659264]
	TIME [epoch: 106 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15386552687790694		[learning rate: 0.0025253]
	Learning Rate: 0.00252527
	LOSS [training: 0.15386552687790694 | validation: 0.2838801398291364]
	TIME [epoch: 106 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1617916027011396		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.1617916027011396 | validation: 0.3046565728426437]
	TIME [epoch: 107 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1537339236835998		[learning rate: 0.002503]
	Learning Rate: 0.002503
	LOSS [training: 0.1537339236835998 | validation: 0.3105432079711284]
	TIME [epoch: 106 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15725740145523262		[learning rate: 0.0024919]
	Learning Rate: 0.00249194
	LOSS [training: 0.15725740145523262 | validation: 0.2696152103583367]
	TIME [epoch: 107 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1525847880488947		[learning rate: 0.0024809]
	Learning Rate: 0.00248093
	LOSS [training: 0.1525847880488947 | validation: 0.28536089054264263]
	TIME [epoch: 107 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15406559740705844		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 0.15406559740705844 | validation: 0.30897240571303786]
	TIME [epoch: 106 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1576994205891999		[learning rate: 0.0024591]
	Learning Rate: 0.00245906
	LOSS [training: 0.1576994205891999 | validation: 0.27521577850763695]
	TIME [epoch: 106 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1619495151691409		[learning rate: 0.0024482]
	Learning Rate: 0.0024482
	LOSS [training: 0.1619495151691409 | validation: 0.30140149090789986]
	TIME [epoch: 107 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15494669756710444		[learning rate: 0.0024374]
	Learning Rate: 0.00243738
	LOSS [training: 0.15494669756710444 | validation: 0.3235065486382209]
	TIME [epoch: 107 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.155487781772201		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.155487781772201 | validation: 0.303444639995436]
	TIME [epoch: 107 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1556401780480247		[learning rate: 0.0024159]
	Learning Rate: 0.00241589
	LOSS [training: 0.1556401780480247 | validation: 0.2926252367480763]
	TIME [epoch: 107 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15252194704620634		[learning rate: 0.0024052]
	Learning Rate: 0.00240521
	LOSS [training: 0.15252194704620634 | validation: 0.2727695420941504]
	TIME [epoch: 106 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15374267777584244		[learning rate: 0.0023946]
	Learning Rate: 0.00239459
	LOSS [training: 0.15374267777584244 | validation: 0.2718775144785904]
	TIME [epoch: 106 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15321359784040647		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 0.15321359784040647 | validation: 0.2994324813462194]
	TIME [epoch: 106 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15381624041949155		[learning rate: 0.0023735]
	Learning Rate: 0.00237347
	LOSS [training: 0.15381624041949155 | validation: 0.2831678799957664]
	TIME [epoch: 106 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15041407409354807		[learning rate: 0.002363]
	Learning Rate: 0.00236299
	LOSS [training: 0.15041407409354807 | validation: 0.31513369913306866]
	TIME [epoch: 107 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16196843957960583		[learning rate: 0.0023525]
	Learning Rate: 0.00235255
	LOSS [training: 0.16196843957960583 | validation: 0.34413436275979825]
	TIME [epoch: 106 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14855400729329235		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.14855400729329235 | validation: 0.2874027245862213]
	TIME [epoch: 107 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15089522232928487		[learning rate: 0.0023318]
	Learning Rate: 0.00233181
	LOSS [training: 0.15089522232928487 | validation: 0.2763045856916811]
	TIME [epoch: 107 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15966816936129705		[learning rate: 0.0023215]
	Learning Rate: 0.0023215
	LOSS [training: 0.15966816936129705 | validation: 0.31449078031045413]
	TIME [epoch: 107 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15674970276390815		[learning rate: 0.0023112]
	Learning Rate: 0.00231125
	LOSS [training: 0.15674970276390815 | validation: 0.30304720074323]
	TIME [epoch: 107 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15307299708780356		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.15307299708780356 | validation: 0.2886797531967254]
	TIME [epoch: 107 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15795525538888827		[learning rate: 0.0022909]
	Learning Rate: 0.00229087
	LOSS [training: 0.15795525538888827 | validation: 0.31417609878129765]
	TIME [epoch: 107 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15463128288268493		[learning rate: 0.0022807]
	Learning Rate: 0.00228075
	LOSS [training: 0.15463128288268493 | validation: 0.3290596737540586]
	TIME [epoch: 107 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1569872842621518		[learning rate: 0.0022707]
	Learning Rate: 0.00227067
	LOSS [training: 0.1569872842621518 | validation: 0.2859367575069993]
	TIME [epoch: 107 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15968769798068727		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.15968769798068727 | validation: 0.33529879713829763]
	TIME [epoch: 107 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15067606345676826		[learning rate: 0.0022506]
	Learning Rate: 0.00225065
	LOSS [training: 0.15067606345676826 | validation: 0.2927155574360418]
	TIME [epoch: 107 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1508783233189514		[learning rate: 0.0022407]
	Learning Rate: 0.0022407
	LOSS [training: 0.1508783233189514 | validation: 0.2837302824054142]
	TIME [epoch: 107 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15257862525249982		[learning rate: 0.0022308]
	Learning Rate: 0.0022308
	LOSS [training: 0.15257862525249982 | validation: 0.27880338995638015]
	TIME [epoch: 107 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15032538762082484		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.15032538762082484 | validation: 0.29179793645995045]
	TIME [epoch: 107 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15565908007408408		[learning rate: 0.0022111]
	Learning Rate: 0.00221114
	LOSS [training: 0.15565908007408408 | validation: 0.31348449444955667]
	TIME [epoch: 107 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1553037944461681		[learning rate: 0.0022014]
	Learning Rate: 0.00220137
	LOSS [training: 0.1553037944461681 | validation: 0.3118131904711723]
	TIME [epoch: 107 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15024689336304245		[learning rate: 0.0021916]
	Learning Rate: 0.00219164
	LOSS [training: 0.15024689336304245 | validation: 0.2808156496934342]
	TIME [epoch: 107 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15828528780247678		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.15828528780247678 | validation: 0.30542108638781035]
	TIME [epoch: 107 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15678452277027974		[learning rate: 0.0021723]
	Learning Rate: 0.00217232
	LOSS [training: 0.15678452277027974 | validation: 0.3104190357987399]
	TIME [epoch: 107 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15763109963276078		[learning rate: 0.0021627]
	Learning Rate: 0.00216272
	LOSS [training: 0.15763109963276078 | validation: 0.31999098972782486]
	TIME [epoch: 107 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1538706462029168		[learning rate: 0.0021532]
	Learning Rate: 0.00215316
	LOSS [training: 0.1538706462029168 | validation: 0.28907063105218755]
	TIME [epoch: 106 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1538549336551955		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.1538549336551955 | validation: 0.293811516469157]
	TIME [epoch: 107 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15041404596056934		[learning rate: 0.0021342]
	Learning Rate: 0.00213418
	LOSS [training: 0.15041404596056934 | validation: 0.2937884903569899]
	TIME [epoch: 106 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15119460474834964		[learning rate: 0.0021247]
	Learning Rate: 0.00212475
	LOSS [training: 0.15119460474834964 | validation: 0.29409683973202455]
	TIME [epoch: 107 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16009722856314265		[learning rate: 0.0021154]
	Learning Rate: 0.00211536
	LOSS [training: 0.16009722856314265 | validation: 0.28189618572663977]
	TIME [epoch: 106 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1501465498141689		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.1501465498141689 | validation: 0.2899444668667832]
	TIME [epoch: 107 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14924497327408442		[learning rate: 0.0020967]
	Learning Rate: 0.00209671
	LOSS [training: 0.14924497327408442 | validation: 0.3052884197244554]
	TIME [epoch: 107 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15939782136810288		[learning rate: 0.0020874]
	Learning Rate: 0.00208745
	LOSS [training: 0.15939782136810288 | validation: 0.3002894739296024]
	TIME [epoch: 107 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15218079187942113		[learning rate: 0.0020782]
	Learning Rate: 0.00207822
	LOSS [training: 0.15218079187942113 | validation: 0.2886420929584032]
	TIME [epoch: 106 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15926245165877978		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.15926245165877978 | validation: 0.2987959838566745]
	TIME [epoch: 107 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15293329511655562		[learning rate: 0.0020599]
	Learning Rate: 0.0020599
	LOSS [training: 0.15293329511655562 | validation: 0.28248195098170426]
	TIME [epoch: 107 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14880800557282697		[learning rate: 0.0020508]
	Learning Rate: 0.0020508
	LOSS [training: 0.14880800557282697 | validation: 0.2833965346187123]
	TIME [epoch: 107 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15204798539440487		[learning rate: 0.0020417]
	Learning Rate: 0.00204174
	LOSS [training: 0.15204798539440487 | validation: 0.2895520405571702]
	TIME [epoch: 106 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16389447788648917		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.16389447788648917 | validation: 0.2842997748593946]
	TIME [epoch: 107 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15364581942928662		[learning rate: 0.0020237]
	Learning Rate: 0.00202374
	LOSS [training: 0.15364581942928662 | validation: 0.2842928711289838]
	TIME [epoch: 107 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1537254780921441		[learning rate: 0.0020148]
	Learning Rate: 0.00201479
	LOSS [training: 0.1537254780921441 | validation: 0.3104378510737743]
	TIME [epoch: 106 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15278783685375483		[learning rate: 0.0020059]
	Learning Rate: 0.00200589
	LOSS [training: 0.15278783685375483 | validation: 0.2761906592478999]
	TIME [epoch: 106 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15400396444617873		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.15400396444617873 | validation: 0.30682911343534786]
	TIME [epoch: 107 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1481299990183486		[learning rate: 0.0019882]
	Learning Rate: 0.00198821
	LOSS [training: 0.1481299990183486 | validation: 0.3185781891174692]
	TIME [epoch: 106 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15315975752117544		[learning rate: 0.0019794]
	Learning Rate: 0.00197942
	LOSS [training: 0.15315975752117544 | validation: 0.2805466495583686]
	TIME [epoch: 106 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15412079950519625		[learning rate: 0.0019707]
	Learning Rate: 0.00197068
	LOSS [training: 0.15412079950519625 | validation: 0.2942554738455176]
	TIME [epoch: 106 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1525021611989537		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.1525021611989537 | validation: 0.29250973916977385]
	TIME [epoch: 107 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1517696870511173		[learning rate: 0.0019533]
	Learning Rate: 0.0019533
	LOSS [training: 0.1517696870511173 | validation: 0.2843669504628507]
	TIME [epoch: 107 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15417701709825665		[learning rate: 0.0019447]
	Learning Rate: 0.00194467
	LOSS [training: 0.15417701709825665 | validation: 0.3134425743567514]
	TIME [epoch: 107 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15410291444715257		[learning rate: 0.0019361]
	Learning Rate: 0.00193608
	LOSS [training: 0.15410291444715257 | validation: 0.2937185904957672]
	TIME [epoch: 106 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15402895270476025		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.15402895270476025 | validation: 0.2968766751335259]
	TIME [epoch: 107 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15078239911014096		[learning rate: 0.001919]
	Learning Rate: 0.00191901
	LOSS [training: 0.15078239911014096 | validation: 0.28459859608314164]
	TIME [epoch: 107 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1593402691302459		[learning rate: 0.0019105]
	Learning Rate: 0.00191053
	LOSS [training: 0.1593402691302459 | validation: 0.321276340390138]
	TIME [epoch: 107 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15360768226470928		[learning rate: 0.0019021]
	Learning Rate: 0.00190209
	LOSS [training: 0.15360768226470928 | validation: 0.2890893189732223]
	TIME [epoch: 107 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1503340470955204		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.1503340470955204 | validation: 0.30036534084869404]
	TIME [epoch: 107 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.153047711597961		[learning rate: 0.0018853]
	Learning Rate: 0.00188532
	LOSS [training: 0.153047711597961 | validation: 0.31792066199046304]
	TIME [epoch: 107 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1546172299062047		[learning rate: 0.001877]
	Learning Rate: 0.00187699
	LOSS [training: 0.1546172299062047 | validation: 0.2827255396941525]
	TIME [epoch: 107 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15295359223668148		[learning rate: 0.0018687]
	Learning Rate: 0.0018687
	LOSS [training: 0.15295359223668148 | validation: 0.2761812702840289]
	TIME [epoch: 106 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1528635837638065		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.1528635837638065 | validation: 0.2745302561657162]
	TIME [epoch: 107 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15185828959548547		[learning rate: 0.0018522]
	Learning Rate: 0.00185222
	LOSS [training: 0.15185828959548547 | validation: 0.2862666525783891]
	TIME [epoch: 106 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15007132868425052		[learning rate: 0.001844]
	Learning Rate: 0.00184404
	LOSS [training: 0.15007132868425052 | validation: 0.2935683566937495]
	TIME [epoch: 107 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1482999905908218		[learning rate: 0.0018359]
	Learning Rate: 0.00183589
	LOSS [training: 0.1482999905908218 | validation: 0.28187712248022284]
	TIME [epoch: 106 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15332779379224404		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.15332779379224404 | validation: 0.31041409490648186]
	TIME [epoch: 107 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1605045810884316		[learning rate: 0.0018197]
	Learning Rate: 0.0018197
	LOSS [training: 0.1605045810884316 | validation: 0.3038669402333776]
	TIME [epoch: 107 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15174403100966005		[learning rate: 0.0018117]
	Learning Rate: 0.00181166
	LOSS [training: 0.15174403100966005 | validation: 0.28328922852946753]
	TIME [epoch: 106 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15235940722636418		[learning rate: 0.0018037]
	Learning Rate: 0.00180366
	LOSS [training: 0.15235940722636418 | validation: 0.27560842435409727]
	TIME [epoch: 107 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15491972135945886		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.15491972135945886 | validation: 0.27676438521678065]
	TIME [epoch: 107 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14899157583967954		[learning rate: 0.0017878]
	Learning Rate: 0.00178775
	LOSS [training: 0.14899157583967954 | validation: 0.2750429108820419]
	TIME [epoch: 107 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15171013705986272		[learning rate: 0.0017799]
	Learning Rate: 0.00177985
	LOSS [training: 0.15171013705986272 | validation: 0.31493761169172935]
	TIME [epoch: 107 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1457804811356515		[learning rate: 0.001772]
	Learning Rate: 0.00177199
	LOSS [training: 0.1457804811356515 | validation: 0.28909912000597066]
	TIME [epoch: 106 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15308661946138485		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.15308661946138485 | validation: 0.2852832081976188]
	TIME [epoch: 107 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15168711938661628		[learning rate: 0.0017564]
	Learning Rate: 0.00175637
	LOSS [training: 0.15168711938661628 | validation: 0.28067690179002697]
	TIME [epoch: 106 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14699297801345018		[learning rate: 0.0017486]
	Learning Rate: 0.00174861
	LOSS [training: 0.14699297801345018 | validation: 0.28545079771150406]
	TIME [epoch: 106 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15621568982365203		[learning rate: 0.0017409]
	Learning Rate: 0.00174088
	LOSS [training: 0.15621568982365203 | validation: 0.281050000905288]
	TIME [epoch: 106 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15583289916111892		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.15583289916111892 | validation: 0.26803104545326173]
	TIME [epoch: 106 sec]
	Saving model to: out/model_training/model_facs_v2_dec2b_2dpca_v13b_20240716_180629/states/model_facs_v2_dec2b_2dpca_v13b_436.pth
	Model improved!!!
EPOCH 437/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1459027258925627		[learning rate: 0.0017255]
	Learning Rate: 0.00172553
	LOSS [training: 0.1459027258925627 | validation: 0.2860671293257624]
	TIME [epoch: 107 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15231694723839945		[learning rate: 0.0017179]
	Learning Rate: 0.00171791
	LOSS [training: 0.15231694723839945 | validation: 0.28988209006276444]
	TIME [epoch: 107 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15078803351677816		[learning rate: 0.0017103]
	Learning Rate: 0.00171032
	LOSS [training: 0.15078803351677816 | validation: 0.28625521017889627]
	TIME [epoch: 106 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14868314256668885		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.14868314256668885 | validation: 0.27986186581400563]
	TIME [epoch: 106 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1521717768263652		[learning rate: 0.0016952]
	Learning Rate: 0.00169524
	LOSS [training: 0.1521717768263652 | validation: 0.28093678267038463]
	TIME [epoch: 106 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15022451993657074		[learning rate: 0.0016877]
	Learning Rate: 0.00168775
	LOSS [training: 0.15022451993657074 | validation: 0.2960778214826761]
	TIME [epoch: 106 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15366003335487063		[learning rate: 0.0016803]
	Learning Rate: 0.00168029
	LOSS [training: 0.15366003335487063 | validation: 0.28954011546136155]
	TIME [epoch: 106 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15364106858946625		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.15364106858946625 | validation: 0.3078089816530923]
	TIME [epoch: 106 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15217995521662492		[learning rate: 0.0016655]
	Learning Rate: 0.00166548
	LOSS [training: 0.15217995521662492 | validation: 0.29202337589905925]
	TIME [epoch: 106 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15700555680451156		[learning rate: 0.0016581]
	Learning Rate: 0.00165812
	LOSS [training: 0.15700555680451156 | validation: 0.2910369956877239]
	TIME [epoch: 107 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15038292673224823		[learning rate: 0.0016508]
	Learning Rate: 0.00165079
	LOSS [training: 0.15038292673224823 | validation: 0.30604773405516883]
	TIME [epoch: 107 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15009443486926147		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.15009443486926147 | validation: 0.32262725738815123]
	TIME [epoch: 107 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14971512985313767		[learning rate: 0.0016362]
	Learning Rate: 0.00163624
	LOSS [training: 0.14971512985313767 | validation: 0.29428483177290915]
	TIME [epoch: 106 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1553303907659323		[learning rate: 0.001629]
	Learning Rate: 0.00162901
	LOSS [training: 0.1553303907659323 | validation: 0.30033618863146616]
	TIME [epoch: 106 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14991142599909918		[learning rate: 0.0016218]
	Learning Rate: 0.00162181
	LOSS [training: 0.14991142599909918 | validation: 0.3009719656071398]
	TIME [epoch: 106 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.150820428807328		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.150820428807328 | validation: 0.30327786624895625]
	TIME [epoch: 106 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15128194585111085		[learning rate: 0.0016075]
	Learning Rate: 0.00160751
	LOSS [training: 0.15128194585111085 | validation: 0.2684997381683866]
	TIME [epoch: 106 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14871443776673202		[learning rate: 0.0016004]
	Learning Rate: 0.00160041
	LOSS [training: 0.14871443776673202 | validation: 0.27506002958187903]
	TIME [epoch: 106 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15244517571637178		[learning rate: 0.0015933]
	Learning Rate: 0.00159334
	LOSS [training: 0.15244517571637178 | validation: 0.28338028649641034]
	TIME [epoch: 106 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14916458134296195		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.14916458134296195 | validation: 0.28896972955942113]
	TIME [epoch: 106 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1510143897160446		[learning rate: 0.0015793]
	Learning Rate: 0.00157929
	LOSS [training: 0.1510143897160446 | validation: 0.2790550360603477]
	TIME [epoch: 106 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15731833020158467		[learning rate: 0.0015723]
	Learning Rate: 0.00157231
	LOSS [training: 0.15731833020158467 | validation: 0.2837595649371074]
	TIME [epoch: 106 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15252116571349894		[learning rate: 0.0015654]
	Learning Rate: 0.00156536
	LOSS [training: 0.15252116571349894 | validation: 0.293224642045275]
	TIME [epoch: 106 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15844068078456958		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.15844068078456958 | validation: 0.28754933231993196]
	TIME [epoch: 106 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15340222356361097		[learning rate: 0.0015516]
	Learning Rate: 0.00155156
	LOSS [training: 0.15340222356361097 | validation: 0.3151128891178849]
	TIME [epoch: 106 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.155052716396892		[learning rate: 0.0015447]
	Learning Rate: 0.00154471
	LOSS [training: 0.155052716396892 | validation: 0.2934077038224861]
	TIME [epoch: 106 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1558770621437767		[learning rate: 0.0015379]
	Learning Rate: 0.00153788
	LOSS [training: 0.1558770621437767 | validation: 0.29228090190874]
	TIME [epoch: 106 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15287147044320074		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.15287147044320074 | validation: 0.3032053028548909]
	TIME [epoch: 106 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15805503992801517		[learning rate: 0.0015243]
	Learning Rate: 0.00152432
	LOSS [training: 0.15805503992801517 | validation: 0.2839384306321031]
	TIME [epoch: 106 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14818596666079745		[learning rate: 0.0015176]
	Learning Rate: 0.00151759
	LOSS [training: 0.14818596666079745 | validation: 0.3156675489872307]
	TIME [epoch: 106 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15087698040937342		[learning rate: 0.0015109]
	Learning Rate: 0.00151088
	LOSS [training: 0.15087698040937342 | validation: 0.27343526911900967]
	TIME [epoch: 106 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15260215312037667		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.15260215312037667 | validation: 0.2836858333965507]
	TIME [epoch: 106 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1574471739044949		[learning rate: 0.0014976]
	Learning Rate: 0.00149756
	LOSS [training: 0.1574471739044949 | validation: 0.27867374752682605]
	TIME [epoch: 106 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15153219288681175		[learning rate: 0.0014909]
	Learning Rate: 0.00149094
	LOSS [training: 0.15153219288681175 | validation: 0.29611314007621]
	TIME [epoch: 106 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15239458265237		[learning rate: 0.0014844]
	Learning Rate: 0.00148436
	LOSS [training: 0.15239458265237 | validation: 0.279815348008597]
	TIME [epoch: 106 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15091838806178906		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.15091838806178906 | validation: 0.2740744295068085]
	TIME [epoch: 106 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16038638079593617		[learning rate: 0.0014713]
	Learning Rate: 0.00147127
	LOSS [training: 0.16038638079593617 | validation: 0.2938922431579434]
	TIME [epoch: 106 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15106127382408152		[learning rate: 0.0014648]
	Learning Rate: 0.00146477
	LOSS [training: 0.15106127382408152 | validation: 0.2798744071182933]
	TIME [epoch: 106 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15521888342807239		[learning rate: 0.0014583]
	Learning Rate: 0.0014583
	LOSS [training: 0.15521888342807239 | validation: 0.2963406143728062]
	TIME [epoch: 106 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1532593374503281		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.1532593374503281 | validation: 0.28094031842335576]
	TIME [epoch: 106 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15000033528816512		[learning rate: 0.0014454]
	Learning Rate: 0.00144544
	LOSS [training: 0.15000033528816512 | validation: 0.26900270425418055]
	TIME [epoch: 106 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14388484375499136		[learning rate: 0.0014391]
	Learning Rate: 0.00143905
	LOSS [training: 0.14388484375499136 | validation: 0.2952944393161074]
	TIME [epoch: 106 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15194020831004357		[learning rate: 0.0014327]
	Learning Rate: 0.0014327
	LOSS [training: 0.15194020831004357 | validation: 0.29656322847238725]
	TIME [epoch: 106 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15214124102570786		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.15214124102570786 | validation: 0.27855335182425967]
	TIME [epoch: 106 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.154088747761774		[learning rate: 0.0014201]
	Learning Rate: 0.00142006
	LOSS [training: 0.154088747761774 | validation: 0.2853633501264572]
	TIME [epoch: 106 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15566198793850494		[learning rate: 0.0014138]
	Learning Rate: 0.00141379
	LOSS [training: 0.15566198793850494 | validation: 0.29114232954569474]
	TIME [epoch: 107 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15027142877053576		[learning rate: 0.0014075]
	Learning Rate: 0.00140754
	LOSS [training: 0.15027142877053576 | validation: 0.30709669203489626]
	TIME [epoch: 106 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15457205619238493		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.15457205619238493 | validation: 0.2950328141008766]
	TIME [epoch: 106 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14965150806862085		[learning rate: 0.0013951]
	Learning Rate: 0.00139513
	LOSS [training: 0.14965150806862085 | validation: 0.2883669513983226]
	TIME [epoch: 106 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15394808449088487		[learning rate: 0.001389]
	Learning Rate: 0.00138897
	LOSS [training: 0.15394808449088487 | validation: 0.2930644714412923]
	TIME [epoch: 106 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15149399071851527		[learning rate: 0.0013828]
	Learning Rate: 0.00138283
	LOSS [training: 0.15149399071851527 | validation: 0.29013076872771393]
	TIME [epoch: 107 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1477926854799066		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.1477926854799066 | validation: 0.28109939565030245]
	TIME [epoch: 106 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15396318699061515		[learning rate: 0.0013706]
	Learning Rate: 0.00137064
	LOSS [training: 0.15396318699061515 | validation: 0.28925659799307324]
	TIME [epoch: 106 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1508996813465941		[learning rate: 0.0013646]
	Learning Rate: 0.00136458
	LOSS [training: 0.1508996813465941 | validation: 0.28502168900092006]
	TIME [epoch: 106 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15070696582685278		[learning rate: 0.0013586]
	Learning Rate: 0.00135855
	LOSS [training: 0.15070696582685278 | validation: 0.2780727131386423]
	TIME [epoch: 106 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.150762943659219		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.150762943659219 | validation: 0.2911755631003345]
	TIME [epoch: 106 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14852164661558048		[learning rate: 0.0013466]
	Learning Rate: 0.00134658
	LOSS [training: 0.14852164661558048 | validation: 0.29956027766789406]
	TIME [epoch: 106 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16019674714819862		[learning rate: 0.0013406]
	Learning Rate: 0.00134063
	LOSS [training: 0.16019674714819862 | validation: 0.28785437317570134]
	TIME [epoch: 106 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15359131196315598		[learning rate: 0.0013347]
	Learning Rate: 0.0013347
	LOSS [training: 0.15359131196315598 | validation: 0.2781382223684314]
	TIME [epoch: 106 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14766866793870928		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.14766866793870928 | validation: 0.29372231237955454]
	TIME [epoch: 106 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1492650953962083		[learning rate: 0.0013229]
	Learning Rate: 0.00132293
	LOSS [training: 0.1492650953962083 | validation: 0.2839312366838832]
	TIME [epoch: 106 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14495615893394556		[learning rate: 0.0013171]
	Learning Rate: 0.00131709
	LOSS [training: 0.14495615893394556 | validation: 0.2894886206357358]
	TIME [epoch: 106 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15046388500890764		[learning rate: 0.0013113]
	Learning Rate: 0.00131127
	LOSS [training: 0.15046388500890764 | validation: 0.2904835107241287]
	TIME [epoch: 106 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15136983988137312		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.15136983988137312 | validation: 0.28039205839231895]
	TIME [epoch: 106 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14943570926932537		[learning rate: 0.0012997]
	Learning Rate: 0.00129971
	LOSS [training: 0.14943570926932537 | validation: 0.27120612662026156]
	TIME [epoch: 106 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1459810662734032		[learning rate: 0.001294]
	Learning Rate: 0.00129397
	LOSS [training: 0.1459810662734032 | validation: 0.2854031014000997]
	TIME [epoch: 106 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1511084118597355		[learning rate: 0.0012882]
	Learning Rate: 0.00128825
	LOSS [training: 0.1511084118597355 | validation: 0.2790237881635011]
	TIME [epoch: 106 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1495110998956146		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.1495110998956146 | validation: 0.28882446087879554]
	TIME [epoch: 106 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1526863560383133		[learning rate: 0.0012769]
	Learning Rate: 0.00127689
	LOSS [training: 0.1526863560383133 | validation: 0.30101794988483355]
	TIME [epoch: 106 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1445121614376879		[learning rate: 0.0012712]
	Learning Rate: 0.00127125
	LOSS [training: 0.1445121614376879 | validation: 0.28434398500324537]
	TIME [epoch: 106 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14892776844909253		[learning rate: 0.0012656]
	Learning Rate: 0.00126563
	LOSS [training: 0.14892776844909253 | validation: 0.2860626858422037]
	TIME [epoch: 106 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14452085434691525		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.14452085434691525 | validation: 0.30272720970941325]
	TIME [epoch: 106 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15208038330973742		[learning rate: 0.0012545]
	Learning Rate: 0.00125447
	LOSS [training: 0.15208038330973742 | validation: 0.292183867785968]
	TIME [epoch: 106 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15386202102772836		[learning rate: 0.0012489]
	Learning Rate: 0.00124893
	LOSS [training: 0.15386202102772836 | validation: 0.2744124704786647]
	TIME [epoch: 106 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14858773667254502		[learning rate: 0.0012434]
	Learning Rate: 0.00124341
	LOSS [training: 0.14858773667254502 | validation: 0.2941657377581101]
	TIME [epoch: 106 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14740065061955324		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.14740065061955324 | validation: 0.30397083536288927]
	TIME [epoch: 106 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15274563026330976		[learning rate: 0.0012324]
	Learning Rate: 0.00123245
	LOSS [training: 0.15274563026330976 | validation: 0.2869149878258726]
	TIME [epoch: 106 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1536413621970073		[learning rate: 0.001227]
	Learning Rate: 0.001227
	LOSS [training: 0.1536413621970073 | validation: 0.3038143708058386]
	TIME [epoch: 106 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1529850697265916		[learning rate: 0.0012216]
	Learning Rate: 0.00122158
	LOSS [training: 0.1529850697265916 | validation: 0.279310833437847]
	TIME [epoch: 106 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14959502739968886		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.14959502739968886 | validation: 0.28204734502816503]
	TIME [epoch: 106 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1473897182345331		[learning rate: 0.0012108]
	Learning Rate: 0.00121081
	LOSS [training: 0.1473897182345331 | validation: 0.29638164079776697]
	TIME [epoch: 106 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14392428000853535		[learning rate: 0.0012055]
	Learning Rate: 0.00120546
	LOSS [training: 0.14392428000853535 | validation: 0.2864266002863317]
	TIME [epoch: 106 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15032412676859958		[learning rate: 0.0012001]
	Learning Rate: 0.00120014
	LOSS [training: 0.15032412676859958 | validation: 0.2785473822124642]
	TIME [epoch: 106 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15013097483692905		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.15013097483692905 | validation: 0.29619390909971693]
	TIME [epoch: 106 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14883892437862972		[learning rate: 0.0011896]
	Learning Rate: 0.00118956
	LOSS [training: 0.14883892437862972 | validation: 0.2954143915046562]
	TIME [epoch: 106 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1478733939784192		[learning rate: 0.0011843]
	Learning Rate: 0.0011843
	LOSS [training: 0.1478733939784192 | validation: 0.29002421068633905]
	TIME [epoch: 106 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15163417799592468		[learning rate: 0.0011791]
	Learning Rate: 0.00117907
	LOSS [training: 0.15163417799592468 | validation: 0.2960297784240882]
	TIME [epoch: 106 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14954598307574296		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.14954598307574296 | validation: 0.2899889974698628]
	TIME [epoch: 106 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15012534488518542		[learning rate: 0.0011687]
	Learning Rate: 0.00116867
	LOSS [training: 0.15012534488518542 | validation: 0.27642783951293753]
	TIME [epoch: 106 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15141088297511113		[learning rate: 0.0011635]
	Learning Rate: 0.00116351
	LOSS [training: 0.15141088297511113 | validation: 0.28425567206912833]
	TIME [epoch: 106 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1444973526758456		[learning rate: 0.0011584]
	Learning Rate: 0.00115837
	LOSS [training: 0.1444973526758456 | validation: 0.29395471207353346]
	TIME [epoch: 106 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15458029423624906		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.15458029423624906 | validation: 0.29930794712872344]
	TIME [epoch: 107 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14893541650518746		[learning rate: 0.0011482]
	Learning Rate: 0.00114815
	LOSS [training: 0.14893541650518746 | validation: 0.31319096505007143]
	TIME [epoch: 106 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15007220292338957		[learning rate: 0.0011431]
	Learning Rate: 0.00114308
	LOSS [training: 0.15007220292338957 | validation: 0.285463308841964]
	TIME [epoch: 106 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14903512183859471		[learning rate: 0.001138]
	Learning Rate: 0.00113803
	LOSS [training: 0.14903512183859471 | validation: 0.278853616043561]
	TIME [epoch: 107 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15102269156789241		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.15102269156789241 | validation: 0.2781090089768732]
	TIME [epoch: 107 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14894766359513295		[learning rate: 0.001128]
	Learning Rate: 0.001128
	LOSS [training: 0.14894766359513295 | validation: 0.2881642461721084]
	TIME [epoch: 107 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14925251018819016		[learning rate: 0.001123]
	Learning Rate: 0.00112301
	LOSS [training: 0.14925251018819016 | validation: 0.2794542176989498]
	TIME [epoch: 106 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14779779138211155		[learning rate: 0.0011181]
	Learning Rate: 0.00111805
	LOSS [training: 0.14779779138211155 | validation: 0.2813646229136705]
	TIME [epoch: 107 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14816752889225218		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.14816752889225218 | validation: 0.28462915603712424]
	TIME [epoch: 107 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15311057781640985		[learning rate: 0.0011082]
	Learning Rate: 0.00110819
	LOSS [training: 0.15311057781640985 | validation: 0.29739331779218564]
	TIME [epoch: 107 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1491615110080619		[learning rate: 0.0011033]
	Learning Rate: 0.0011033
	LOSS [training: 0.1491615110080619 | validation: 0.2838624483288041]
	TIME [epoch: 106 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14944372464819602		[learning rate: 0.0010984]
	Learning Rate: 0.00109842
	LOSS [training: 0.14944372464819602 | validation: 0.28393189647340433]
	TIME [epoch: 106 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1551651122528442		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.1551651122528442 | validation: 0.2926680349793488]
	TIME [epoch: 107 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14977899291472713		[learning rate: 0.0010887]
	Learning Rate: 0.00108874
	LOSS [training: 0.14977899291472713 | validation: 0.2855069841730202]
	TIME [epoch: 107 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1430888259092459		[learning rate: 0.0010839]
	Learning Rate: 0.00108393
	LOSS [training: 0.1430888259092459 | validation: 0.27379717262786957]
	TIME [epoch: 106 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1490507998561882		[learning rate: 0.0010791]
	Learning Rate: 0.00107914
	LOSS [training: 0.1490507998561882 | validation: 0.2915153854682465]
	TIME [epoch: 106 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14750871325786263		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.14750871325786263 | validation: 0.2901407817724055]
	TIME [epoch: 106 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14864196057298726		[learning rate: 0.0010696]
	Learning Rate: 0.00106962
	LOSS [training: 0.14864196057298726 | validation: 0.2865900146756347]
	TIME [epoch: 107 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1534537293996929		[learning rate: 0.0010649]
	Learning Rate: 0.0010649
	LOSS [training: 0.1534537293996929 | validation: 0.2976677952052565]
	TIME [epoch: 107 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14963842059821136		[learning rate: 0.0010602]
	Learning Rate: 0.00106019
	LOSS [training: 0.14963842059821136 | validation: 0.2900785273203948]
	TIME [epoch: 107 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15243764041457136		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.15243764041457136 | validation: 0.2864444299614967]
	TIME [epoch: 107 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15089446040545376		[learning rate: 0.0010508]
	Learning Rate: 0.00105084
	LOSS [training: 0.15089446040545376 | validation: 0.27770911843218526]
	TIME [epoch: 106 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15105361662484693		[learning rate: 0.0010462]
	Learning Rate: 0.0010462
	LOSS [training: 0.15105361662484693 | validation: 0.2794765526214315]
	TIME [epoch: 106 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14904089080888688		[learning rate: 0.0010416]
	Learning Rate: 0.00104158
	LOSS [training: 0.14904089080888688 | validation: 0.2803560267315456]
	TIME [epoch: 107 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1446196132298919		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.1446196132298919 | validation: 0.2870153467372296]
	TIME [epoch: 106 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15147465610502325		[learning rate: 0.0010324]
	Learning Rate: 0.0010324
	LOSS [training: 0.15147465610502325 | validation: 0.29023392475096305]
	TIME [epoch: 106 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1488199080907208		[learning rate: 0.0010278]
	Learning Rate: 0.00102783
	LOSS [training: 0.1488199080907208 | validation: 0.2794104561688273]
	TIME [epoch: 106 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1447198551096483		[learning rate: 0.0010233]
	Learning Rate: 0.00102329
	LOSS [training: 0.1447198551096483 | validation: 0.2856854696785284]
	TIME [epoch: 106 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14537535479192637		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.14537535479192637 | validation: 0.2847750635272605]
	TIME [epoch: 106 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1497869504541826		[learning rate: 0.0010143]
	Learning Rate: 0.00101427
	LOSS [training: 0.1497869504541826 | validation: 0.2805012810712422]
	TIME [epoch: 106 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15091968349328727		[learning rate: 0.0010098]
	Learning Rate: 0.00100979
	LOSS [training: 0.15091968349328727 | validation: 0.3170716781024444]
	TIME [epoch: 106 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1468305391092654		[learning rate: 0.0010053]
	Learning Rate: 0.00100533
	LOSS [training: 0.1468305391092654 | validation: 0.3125701614767771]
	TIME [epoch: 106 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15420898687306353		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.15420898687306353 | validation: 0.2994505746157868]
	TIME [epoch: 106 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14837064273622108		[learning rate: 0.00099646]
	Learning Rate: 0.000996464
	LOSS [training: 0.14837064273622108 | validation: 0.2848612558007266]
	TIME [epoch: 106 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1515760458251856		[learning rate: 0.00099206]
	Learning Rate: 0.000992061
	LOSS [training: 0.1515760458251856 | validation: 0.28519143390263846]
	TIME [epoch: 106 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15057281429298236		[learning rate: 0.00098768]
	Learning Rate: 0.000987678
	LOSS [training: 0.15057281429298236 | validation: 0.29430001826789]
	TIME [epoch: 106 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14797219222779628		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.14797219222779628 | validation: 0.298858021713516]
	TIME [epoch: 106 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1504326637000677		[learning rate: 0.00097897]
	Learning Rate: 0.00097897
	LOSS [training: 0.1504326637000677 | validation: 0.29398715474660975]
	TIME [epoch: 106 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15226129414548623		[learning rate: 0.00097464]
	Learning Rate: 0.000974644
	LOSS [training: 0.15226129414548623 | validation: 0.2831767636363845]
	TIME [epoch: 106 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1530804453958499		[learning rate: 0.00097034]
	Learning Rate: 0.000970338
	LOSS [training: 0.1530804453958499 | validation: 0.3061852772271475]
	TIME [epoch: 106 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1514118616403304		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.1514118616403304 | validation: 0.2908320621467468]
	TIME [epoch: 107 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14871611862743703		[learning rate: 0.00096178]
	Learning Rate: 0.000961783
	LOSS [training: 0.14871611862743703 | validation: 0.2934356551221525]
	TIME [epoch: 106 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1560848540381248		[learning rate: 0.00095753]
	Learning Rate: 0.000957533
	LOSS [training: 0.1560848540381248 | validation: 0.2839859484381946]
	TIME [epoch: 106 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1518875412582036		[learning rate: 0.0009533]
	Learning Rate: 0.000953303
	LOSS [training: 0.1518875412582036 | validation: 0.288085264009973]
	TIME [epoch: 106 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14312478978871992		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.14312478978871992 | validation: 0.290560014385386]
	TIME [epoch: 107 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1451006000691478		[learning rate: 0.0009449]
	Learning Rate: 0.000944897
	LOSS [training: 0.1451006000691478 | validation: 0.29047105437475285]
	TIME [epoch: 107 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14902940993485586		[learning rate: 0.00094072]
	Learning Rate: 0.000940723
	LOSS [training: 0.14902940993485586 | validation: 0.2949520596605028]
	TIME [epoch: 107 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15289350346458888		[learning rate: 0.00093657]
	Learning Rate: 0.000936566
	LOSS [training: 0.15289350346458888 | validation: 0.3000149501193473]
	TIME [epoch: 107 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15397230464063916		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.15397230464063916 | validation: 0.2817728136812359]
	TIME [epoch: 107 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15402486160249115		[learning rate: 0.00092831]
	Learning Rate: 0.000928309
	LOSS [training: 0.15402486160249115 | validation: 0.3012815516072303]
	TIME [epoch: 107 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15259112838738992		[learning rate: 0.00092421]
	Learning Rate: 0.000924207
	LOSS [training: 0.15259112838738992 | validation: 0.27409037318556795]
	TIME [epoch: 107 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15098004932735432		[learning rate: 0.00092012]
	Learning Rate: 0.000920124
	LOSS [training: 0.15098004932735432 | validation: 0.28615601639093785]
	TIME [epoch: 107 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15194924226220935		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.15194924226220935 | validation: 0.2832933447547645]
	TIME [epoch: 107 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15552321755854082		[learning rate: 0.00091201]
	Learning Rate: 0.000912011
	LOSS [training: 0.15552321755854082 | validation: 0.28661152380799515]
	TIME [epoch: 107 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14739107913099528		[learning rate: 0.00090798]
	Learning Rate: 0.000907981
	LOSS [training: 0.14739107913099528 | validation: 0.30679434674233674]
	TIME [epoch: 106 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15127756551664978		[learning rate: 0.00090397]
	Learning Rate: 0.00090397
	LOSS [training: 0.15127756551664978 | validation: 0.28396866025682027]
	TIME [epoch: 107 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1493604823614026		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.1493604823614026 | validation: 0.2845739263043009]
	TIME [epoch: 106 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14632183266516727		[learning rate: 0.000896]
	Learning Rate: 0.000895999
	LOSS [training: 0.14632183266516727 | validation: 0.271557623080019]
	TIME [epoch: 107 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15101965769189032		[learning rate: 0.00089204]
	Learning Rate: 0.000892041
	LOSS [training: 0.15101965769189032 | validation: 0.28351302275979406]
	TIME [epoch: 107 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14739476162671133		[learning rate: 0.0008881]
	Learning Rate: 0.000888099
	LOSS [training: 0.14739476162671133 | validation: 0.2891589135095804]
	TIME [epoch: 107 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15507366515394297		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.15507366515394297 | validation: 0.2826099312654039]
	TIME [epoch: 107 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14929470854520374		[learning rate: 0.00088027]
	Learning Rate: 0.000880269
	LOSS [training: 0.14929470854520374 | validation: 0.28565591851775285]
	TIME [epoch: 107 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14699968367522015		[learning rate: 0.00087638]
	Learning Rate: 0.00087638
	LOSS [training: 0.14699968367522015 | validation: 0.2820689178646414]
	TIME [epoch: 107 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15325881830062935		[learning rate: 0.00087251]
	Learning Rate: 0.000872508
	LOSS [training: 0.15325881830062935 | validation: 0.2996519041798911]
	TIME [epoch: 106 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14451407558002313		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.14451407558002313 | validation: 0.279533276153828]
	TIME [epoch: 107 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15328584620663924		[learning rate: 0.00086481]
	Learning Rate: 0.000864815
	LOSS [training: 0.15328584620663924 | validation: 0.2975353128965555]
	TIME [epoch: 106 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15260147196776502		[learning rate: 0.00086099]
	Learning Rate: 0.000860994
	LOSS [training: 0.15260147196776502 | validation: 0.29878680917547684]
	TIME [epoch: 106 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1473385687320896		[learning rate: 0.00085719]
	Learning Rate: 0.00085719
	LOSS [training: 0.1473385687320896 | validation: 0.29673641774953763]
	TIME [epoch: 107 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1503636537117136		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.1503636537117136 | validation: 0.2811972964868647]
	TIME [epoch: 106 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14454855012148382		[learning rate: 0.00084963]
	Learning Rate: 0.000849632
	LOSS [training: 0.14454855012148382 | validation: 0.30148608010029376]
	TIME [epoch: 106 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14835599058661136		[learning rate: 0.00084588]
	Learning Rate: 0.000845878
	LOSS [training: 0.14835599058661136 | validation: 0.2713723431610266]
	TIME [epoch: 106 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14386319616355628		[learning rate: 0.00084214]
	Learning Rate: 0.000842141
	LOSS [training: 0.14386319616355628 | validation: 0.2918509271090017]
	TIME [epoch: 106 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.153607049163061		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.153607049163061 | validation: 0.27909431802351986]
	TIME [epoch: 106 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14786451985167778		[learning rate: 0.00083472]
	Learning Rate: 0.000834715
	LOSS [training: 0.14786451985167778 | validation: 0.2919464711064435]
	TIME [epoch: 107 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15236259702502777		[learning rate: 0.00083103]
	Learning Rate: 0.000831028
	LOSS [training: 0.15236259702502777 | validation: 0.28389218145330125]
	TIME [epoch: 106 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15040570666710001		[learning rate: 0.00082736]
	Learning Rate: 0.000827356
	LOSS [training: 0.15040570666710001 | validation: 0.2946557785001611]
	TIME [epoch: 106 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14884899309177121		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.14884899309177121 | validation: 0.30400854123397864]
	TIME [epoch: 106 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15523210219669936		[learning rate: 0.00082006]
	Learning Rate: 0.000820061
	LOSS [training: 0.15523210219669936 | validation: 0.2854796607055775]
	TIME [epoch: 106 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1532662457750641		[learning rate: 0.00081644]
	Learning Rate: 0.000816438
	LOSS [training: 0.1532662457750641 | validation: 0.28962276031233947]
	TIME [epoch: 106 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1491134146895586		[learning rate: 0.00081283]
	Learning Rate: 0.000812831
	LOSS [training: 0.1491134146895586 | validation: 0.28168491977646276]
	TIME [epoch: 106 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15534984929273793		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.15534984929273793 | validation: 0.308918644828457]
	TIME [epoch: 106 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15654883812115494		[learning rate: 0.00080566]
	Learning Rate: 0.000805664
	LOSS [training: 0.15654883812115494 | validation: 0.2996401993757627]
	TIME [epoch: 106 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14608277931981806		[learning rate: 0.0008021]
	Learning Rate: 0.000802104
	LOSS [training: 0.14608277931981806 | validation: 0.2887338105963681]
	TIME [epoch: 106 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14836247343386202		[learning rate: 0.00079856]
	Learning Rate: 0.00079856
	LOSS [training: 0.14836247343386202 | validation: 0.2798691908189885]
	TIME [epoch: 106 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15102768502436176		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.15102768502436176 | validation: 0.2729780234959217]
	TIME [epoch: 106 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14692176554581127		[learning rate: 0.00079152]
	Learning Rate: 0.000791519
	LOSS [training: 0.14692176554581127 | validation: 0.2944962611955629]
	TIME [epoch: 106 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14600033685346014		[learning rate: 0.00078802]
	Learning Rate: 0.000788022
	LOSS [training: 0.14600033685346014 | validation: 0.27668908181330243]
	TIME [epoch: 106 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15086422341455255		[learning rate: 0.00078454]
	Learning Rate: 0.000784541
	LOSS [training: 0.15086422341455255 | validation: 0.2787443405751734]
	TIME [epoch: 106 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15055015158843682		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.15055015158843682 | validation: 0.29551707809936545]
	TIME [epoch: 106 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15085871426497355		[learning rate: 0.00077762]
	Learning Rate: 0.000777623
	LOSS [training: 0.15085871426497355 | validation: 0.28775607298876177]
	TIME [epoch: 106 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15155763159304622		[learning rate: 0.00077419]
	Learning Rate: 0.000774188
	LOSS [training: 0.15155763159304622 | validation: 0.3117748445260489]
	TIME [epoch: 106 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15051256060516593		[learning rate: 0.00077077]
	Learning Rate: 0.000770767
	LOSS [training: 0.15051256060516593 | validation: 0.28525445093098567]
	TIME [epoch: 106 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14973523131461638		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.14973523131461638 | validation: 0.2926248419984412]
	TIME [epoch: 106 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14449309050739584		[learning rate: 0.00076397]
	Learning Rate: 0.000763971
	LOSS [training: 0.14449309050739584 | validation: 0.29412118454067715]
	TIME [epoch: 106 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14949622782195457		[learning rate: 0.0007606]
	Learning Rate: 0.000760596
	LOSS [training: 0.14949622782195457 | validation: 0.27505203231754144]
	TIME [epoch: 107 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15295381472975794		[learning rate: 0.00075724]
	Learning Rate: 0.000757235
	LOSS [training: 0.15295381472975794 | validation: 0.29039821143676464]
	TIME [epoch: 106 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15083951903460469		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.15083951903460469 | validation: 0.28824214453489494]
	TIME [epoch: 106 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14154144287699064		[learning rate: 0.00075056]
	Learning Rate: 0.000750559
	LOSS [training: 0.14154144287699064 | validation: 0.3135052225120457]
	TIME [epoch: 107 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1494273788868725		[learning rate: 0.00074724]
	Learning Rate: 0.000747242
	LOSS [training: 0.1494273788868725 | validation: 0.2823981329864898]
	TIME [epoch: 106 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14687355634327898		[learning rate: 0.00074394]
	Learning Rate: 0.000743941
	LOSS [training: 0.14687355634327898 | validation: 0.2973578488865164]
	TIME [epoch: 106 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15022321665456498		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.15022321665456498 | validation: 0.2834923323202556]
	TIME [epoch: 106 sec]
EPOCH 629/2000:
	Training over batches...
